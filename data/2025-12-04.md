<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 论文提出了一种动态评估LLM安全性的框架，通过定义行为分类、训练分类器估计伦理熵S(t)，测量模型在压力测试中的熵动态变化，并开发监控管道检测价值漂移。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全评估主要依赖静态基准，但关键失效是动态的：分布漂移下的价值漂移、越狱攻击、部署中对齐的缓慢退化。需要动态框架来监控和应对这些风险。

Method: 基于"智能第二定律"将伦理熵作为状态变量，定义五维行为分类法，训练分类器从模型转录本估计伦理熵S(t)，测量四个前沿模型的基础版和指令调优版在压力测试中的熵动态，计算有效对齐工作率γ_eff，并将S(t)和γ_eff嵌入监控管道。

Result: 基础模型显示持续的熵增长，而调优变体抑制了漂移并将伦理熵降低了约80%。从这些轨迹中估计出有效对齐工作率，监控管道能在熵漂移超过稳定阈值时发出警报。

Conclusion: 该框架为LLM安全提供了动态监控方法，能够实时监督价值漂移，比静态基准更能捕捉实际部署中的风险，为运行时的对齐监督提供了实用工具。

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [2] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 该论文研究了Embeddings-as-a-Service（EaaS）水印技术的攻防问题，揭示了现有水印可通过文本改写攻击被移除的漏洞，并提出了一种基于线性变换的新型水印技术WET来防御此类攻击。


<details>
  <summary>Details</summary>
Motivation: 随着企业开始提供Embeddings-as-a-Service（EaaS），其模型面临模仿攻击的风险。虽然已有水印技术用于保护EaaS提供者的知识产权，但现有水印存在安全漏洞，需要更强大的防御机制。

Method: 1. 攻击研究：通过文本改写技术（包括不同改写方法和模型）对现有EaaS水印进行攻击，展示其脆弱性。
2. 防御方案：提出WET（Watermarking EaaS with Linear Transformation）水印技术，通过对嵌入向量进行线性变换来嵌入水印，验证时应用逆变换并比较恢复后嵌入与原始嵌入的相似度。

Result: 1. 攻击结果：文本改写攻击在大多数情况下能有效绕过当前最先进的EaaS水印技术，揭示了新的安全漏洞。
2. 防御结果：WET水印技术对改写攻击具有鲁棒性，验证准确率接近完美，并通过消融研究验证了各组件和超参数的重要性。

Conclusion: 该研究揭示了现有EaaS水印技术对文本改写攻击的脆弱性，并提出了一种鲁棒的新型水印技术WET。WET通过线性变换方法有效防御了改写攻击，为EaaS提供者提供了更可靠的模型知识产权保护方案。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [3] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 提出RDG框架，通过生成平衡推理数据来减轻LLMs中的选择支持性偏见，实验显示在记忆和评估任务上分别有81.5%和94.3%的改进。


<details>
  <summary>Details</summary>
Motivation: 现有研究显示大型语言模型存在选择支持性偏见，会系统性地偏向自己选择的选项，这可能影响AI辅助决策的客观性。现有的去偏见方法主要针对人口统计和社会偏见，而针对LLMs中认知偏见的解决方法尚未充分探索。

Method: 提出Reasoning Dependency Generation (RDG)框架，通过自动构建平衡的推理问答对来生成无偏见推理数据，明确建模选择、证据和论证之间的依赖关系。该方法生成跨领域的大规模QA数据集，包含上下文依赖数据和依赖解耦数据。

Result: 实验表明，使用RDG生成数据微调的LLMs在基于记忆的实验中有81.5%的改进，在基于评估的实验中有94.3%的改进，同时在标准BBQ基准测试中保持相似性能。

Conclusion: 这项工作是首个解决LLMs中认知偏见的方法，通过RDG框架生成无偏见推理数据，有助于开发更可靠的AI辅助决策支持系统。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [4] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 该研究开发了一个开源工具，结合句子链接和实体链接两种方法，将招聘文本链接到ESCO和EQF框架，并发布了两个标注数据集用于评估职业和资格在招聘文本中的表示。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改进劳动力市场信息的分类，通过将招聘文本链接到欧洲ESCO技能分类框架和EQF资格框架，超越表面的技能提取，深入分析职业和资格在数字中介经济中的表示。

Method: 研究比较了两种主要方法：句子链接和实体链接，并开发了结合这两种方法的开源工具。同时引入了两个专门标注的数据集来评估职业和资格表示，并探索了生成式大语言模型在此任务中的应用方式。

Result: 研究开发了公开可用的开源工具和标注数据集，为劳动力分类和就业话语研究提供了计算基础设施。研究结果推动了工作实体提取的技术发展，并为分析数字中介经济中的工作、技能和劳动力市场叙事提供了工具支持。

Conclusion: 该研究通过结合传统方法和生成式大语言模型，为劳动力市场信息分类提供了创新解决方案，发布的工具和数据集将促进劳动力分类和就业话语的进一步研究，有助于更深入地理解数字时代的工作和技能需求。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [5] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: InvertiTune：通过可控数据生成和微调，实现单次推理的知识图谱构建，超越现有方法并提升跨数据集泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的文本到知识图谱（Text2KG）方法依赖迭代提示，计算成本高且容易忽略文本中分布的复杂关系，需要更高效、准确的解决方案

Method: 提出InvertiTune框架：1）可控数据生成管道：从大型知识库提取子图，过滤噪声，利用LLM生成对应的自然文本描述；2）监督微调：使用生成的数据集对轻量级模型进行单次推理的KG构建训练

Result: 在CE12k数据集上，InvertiTune超越了更大的非微调LLM和现有Text2KG方法；在CrossEval-1200跨数据集测试中表现出更强的泛化能力

Conclusion: 现实、高质量的训练数据对于推进高效、高性能的Text2KG系统至关重要，InvertiTune框架为这一方向提供了有效解决方案

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [6] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 提出一个检测和解析政治文本中解释的框架，使用轻量级因果语言模型提取因果主张，用于大规模分析政治解释


<details>
  <summary>Details</summary>
Motivation: 解释是公民理解政治世界的基本要素，但政治科学中对解释的系统分析不足，现有方法分散且常针对特定问题

Method: 训练轻量级因果语言模型，返回结构化因果主张数据集（原因-结果对），用于下游分析

Result: 方法展示如何大规模研究因果解释，显示适度的标注要求、良好的泛化能力和相对于人工编码的准确性

Conclusion: 该框架为政治文本中的解释分析提供了系统方法，能够有效提取和分析因果主张，促进政治科学中对解释的深入研究

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [7] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: 提出RMFT隐私保护微调技术，在Enron邮件数据集上减少80%的PII记忆，同时仅增加5.73%的困惑度，优于去重方法


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型容易记忆训练数据中的个人身份信息，带来严重的安全隐私风险，需要开发能减少PII记忆同时保持性能的微调方法

Method: 提出随机掩码微调技术，通过随机掩码训练数据中的PII来减少模型记忆，同时引入MaxTER评估框架分析隐私-效用权衡

Result: 在Enron邮件数据集上，RMFT相比基线微调减少80.81%的总提取率和80.17%的已见提取率，困惑度仅增加5.73%，优于去重方法

Conclusion: RMFT是有效的隐私保护微调技术，能显著减少PII记忆同时最小化性能影响，MaxTER框架为评估隐私-效用权衡提供了帕累托最优方法

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [8] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: LLM辅助标注管道用于西班牙语-英语和西班牙语-瓜拉尼语双语话语的社会语言学和主题分析，自动标注话题、体裁和语用功能，揭示性别、语言优势和语用功能之间的系统性关联。


<details>
  <summary>Details</summary>
Motivation: 传统的社会语言学模式分析依赖人工标注，成本高且难以扩展到大规模语料。本研究旨在探索大语言模型能否可靠地恢复传统上只能通过人工标注获得的可解释社会语言学模式，推进跨语言和低资源双语研究的计算方法。

Method: 使用大语言模型构建自动标注管道，对两种类型学不同的双语语境（西班牙语-英语和西班牙语-瓜拉尼语）中的3,691个语码转换句子进行自动标注，包括话题、体裁和话语语用功能。整合迈阿密双语语料库的人口统计学元数据，并为西班牙语-瓜拉尼语数据集添加新的主题标注。

Result: 在迈阿密数据中发现了性别、语言优势和话语功能之间的系统性联系；在巴拉圭文本中观察到正式瓜拉尼语和非正式西班牙语之间的明显双语分工。这些发现以前只能通过互动和社会语言学观察获得，现在通过语料库规模的定量证据得到了复制和扩展。

Conclusion: 大语言模型能够可靠地恢复传统上只能通过人工标注获得的可解释社会语言学模式，为跨语言和低资源双语研究提供了有效的计算方法，证明了计算社会语言学的可行性。

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [9] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: PERCS数据集：针对四种不同医学知识水平用户（普通大众、医学生、非医学研究者、医学专家）的个性化生物医学摘要简化数据集，支持可控摘要生成研究


<details>
  <summary>Details</summary>
Motivation: 现有医学文本简化资源通常假设单一通用受众，忽略了不同用户群体在医学素养和信息需求上的显著差异，需要针对不同受众的个性化简化方法

Method: 创建PERCS数据集，包含生物医学摘要及其针对四种不同人物角色（普通大众、医学生、非医学研究者、医学专家）的简化版本；由医生根据详细的错误分类法审核事实准确性和角色对齐度

Result: 技术验证显示不同角色在可读性、词汇和内容深度上存在明显差异；基准测试评估了四种大语言模型在PERCS上的表现，使用自动评估指标衡量全面性、可读性和忠实度

Conclusion: PERCS数据集支持个性化医学沟通和可控生物医学摘要研究，公开提供数据集、标注指南和评估材料，为未来研究建立基线结果

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [10] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 提出Idea-Gated Transformer架构，通过分离语义规划和语法生成来解决自回归语言模型中的"主题漂移"问题，使用概念向量实时门控词汇选择，提高生成内容的主题一致性。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型基于下一个词预测训练，容易产生"主题漂移"问题，即生成内容会逐渐偏离初始提示，这是因为模型过度依赖局部关联而非全局规划。虽然增大模型规模可以缓解这个问题，但下一个词预测目标本身的短视性依然存在。

Method: 提出Idea-Gated Transformer架构，引入辅助的"Idea Head"来预测未来上下文窗口的词袋分布，生成潜在的"概念向量"。该向量通过可微分门控机制主动门控主要词汇在生成过程中的选择，抑制语义不相关的词汇，实时修剪搜索空间。

Result: 在WikiText-103上的实验表明，Idea-Gated模型在验证困惑度上与标准GPT-2基线相当，但在领域保持性方面显著更优。定性和定量分析显示，门控机制成功将生成锁定在特定语义簇（如金融、科学）中，有效抵抗关联漂移。

Conclusion: Idea-Gated Transformer提供了一种参数高效的方法来实现更可控的语言建模，通过分离语义规划和语法生成，解决了自回归语言模型中的主题漂移问题，为更可控的文本生成提供了新途径。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [11] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: HBLR提出假设驱动的向后逻辑推理框架，通过置信感知符号翻译和假设驱动向后推理，在五个推理基准上实现精度和效率的双重提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言理解方面取得显著进展，但当前基于前向推理的方法存在推理路径冗余、步骤幻觉和语义漂移等问题，导致推理效率低下且不可靠。

Method: HBLR框架包含两个核心模块：1) 置信感知符号翻译，仅将高置信度片段转换为FOL等逻辑形式，不确定内容保留为自然语言，并通过翻译反思模块确保语义保真度；2) 假设驱动向后推理，模拟人类演绎思维，假设结论为真并递归验证其前提，通过推理反思模块识别和修正错误推理步骤。

Result: 在五个推理基准上的广泛实验表明，HBLR在准确性和效率方面均持续优于强基线方法。

Conclusion: HBLR通过整合置信感知符号翻译和假设驱动向后推理，有效解决了前向推理方法的局限性，实现了更高效可靠的逻辑推理。

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [12] [Nexus: Higher-Order Attention Mechanisms in Transformers](https://arxiv.org/abs/2512.03377)
*Hanting Chen,Chu Zhong,Kai Han,Yuchuan Tian,Yuchen Liang,Tianyu Guo,Xinghao Chen,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出高阶注意力网络(Hon)，通过递归框架增强Transformer的表示能力，打破标准注意力的低秩瓶颈，以参数高效的方式捕捉多跳关系。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer的一阶注意力机制存在低秩瓶颈，难以在单层内捕捉复杂的多跳关系，限制了模型的表示能力。

Method: 提出高阶注意力网络(Hon)，通过递归框架动态精炼查询和键向量：查询和键向量本身是内部注意力循环的输出，允许token在最终注意力计算前聚合全局上下文并建模高阶相关性。采用参数高效的权重共享策略，确保增强表达能力的同时只增加O(1)参数。

Result: 理论分析表明该方法打破了标准注意力的线性瓶颈。在多个基准测试中，Hon优于标准Transformer。

Conclusion: 高阶注意力网络通过递归框架有效增强了Transformer的表示能力，以参数高效的方式解决了标准注意力的低秩瓶颈问题，在多个任务上取得了更好的性能。

Abstract: Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.

</details>


### [13] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 收集了Portal 2合作模式中11.5小时的口语对话语料库，包含24.5K话语，分析了复杂空间指代等独特语言现象，并公开了多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 合作视频游戏中的语言数据具有丰富性，包含复杂环境下的协调沟通和不确定性推理，这些现象在现有闲聊或任务导向对话语料库中很少出现。

Method: 收集Portal 2合作模式中玩家对话，构建包含11.5小时音频、24.5K话语的语料库，分析玩家语言行为，识别独特语言现象，并提供多模态数据标注。

Result: 创建了Portal对话语料库，识别出复杂空间指代、澄清与修复、临时约定形成等独特语言现象，这些在现有对话语料库中很少见。

Conclusion: 合作视频游戏是研究复杂情境下协作问题解决语言使用的宝贵资源，公开的多模态语料库将支持未来相关研究。

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [14] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: Dual LoRA通过将低秩矩阵分为幅度组和方向组，引入ReLU和符号函数来改进LoRA，在多个NLP任务上优于原始LoRA及其变体。


<details>
  <summary>Details</summary>
Motivation: LoRA作为参数高效微调方法虽然流行，但由于其低秩假设，训练出的模型性能往往不理想。需要改进LoRA以更好地模拟基于梯度优化的全参数微调过程。

Method: 提出Dual LoRA方法，将低秩矩阵分为两组：幅度组（控制参数是否更新及更新幅度）和方向组（决定参数更新方向）。通过为幅度组添加ReLU函数，为方向组添加符号函数来实现这一分离。

Result: 在GPT-2、RoBERTa、DeBERTa和LLaMA-1/2/3等基准模型上，在自然语言生成、理解和常识推理任务上的实验表明，Dual LoRA在相同可训练参数数量下一致优于LoRA及其最先进的变体。

Conclusion: Dual LoRA通过引入幅度和方向分离的归纳偏置，有效改进了LoRA的性能，能够更好地模拟全参数微调过程，在多个NLP任务上取得了更好的结果。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [15] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: PretrainZero是一个基于预训练语料的强化主动学习框架，将RL从领域特定的后训练扩展到通用预训练，通过主动识别信息内容、自监督学习和验证扩展来提升基础模型的通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的大思维模型虽然在特定领域表现出专家级能力，但严重依赖可验证的奖励信号，限制了通用推理能力的扩展边界。需要突破验证数据壁垒，实现从领域特定后训练到通用预训练的扩展。

Method: 提出PretrainZero框架：1）主动预训练：学习统一推理策略，主动识别预训练语料中的合理信息内容；2）自监督学习：无需可验证标签或预训练奖励模型，直接在通用Wikipedia语料上使用RL预训练推理器；3）验证扩展：通过处理越来越难的掩码跨度来增强推理能力。

Result: 在强化预训练中，PretrainZero将Qwen3-4B-Base在MMLU-Pro、SuperGPQA和数学平均基准上分别提升了8.43、5.96和10.60分。预训练模型还可作为下游RLVR任务的推理基础模型。

Conclusion: PretrainZero成功将强化学习从领域特定后训练扩展到通用预训练，突破了验证数据壁垒，显著提升了基础模型的通用推理能力，为人工通用智能的发展提供了新方向。

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [16] [A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention](https://arxiv.org/abs/2512.03494)
*Di Xiu,Hongyin Tang,Bolin Rong,Lizhi Yan,Jingang Wang,Yifan Lu,Xunliang Cai*

Main category: cs.CL

TL;DR: Top-k注意力机制在解码和训练阶段的有效性研究，通过保留与查询最相似的关键词作为上下文窗口，在保持性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文建模中日益重要，但其推理计算成本已成为阻碍智能体和多模态应用发展的关键瓶颈，需要探索更高效的注意力机制。

Method: 研究Top-k注意力机制在解码和训练阶段的效果：1）验证精确Top-k解码的有效性；2）探索原生Top-k注意力训练策略；3）研究近似Top-k算法精度对下游任务的影响；4）从熵的角度提供理论解释。

Result: 1）Top-k解码在HELMET和LongBench v2等下游任务上达到或超越全注意力性能；2）训练与推理一致的Top-k注意力策略能进一步释放模型潜力；3）下游任务性能与近似精度正相关；4）Top-k注意力SFT导致下游任务熵降低，验证了低熵状态更适合Top-k解码的假设。

Conclusion: Top-k注意力机制是降低LLMs推理计算成本的有效方法，通过精确或近似的Top-k操作，在保持性能的同时显著提升效率，且低熵状态更适合这种机制。

Abstract: Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.

</details>


### [17] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: 大型语言模型在摘要任务中的推理能力效果有限，存在质量与忠实度的权衡，过度推理反而可能损害事实一致性。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在数学和代码生成等分析任务中表现出色，但其在抽象摘要任务中的效用被广泛假设但未经验证，需要系统研究推理策略在摘要任务中的实际效果。

Method: 首先将通用推理策略适配到摘要领域，然后对8种推理策略和3个大型推理模型在8个多样化数据集上进行大规模比较研究，评估摘要质量和忠实度。

Result: 推理并非通用解决方案，其效果高度依赖于具体策略和上下文。存在摘要质量与事实忠实度的权衡：显式推理策略倾向于提高流畅性但牺牲事实基础，而大型推理模型中的隐式推理则呈现相反模式。增加模型的内部推理预算不会改善甚至可能损害事实一致性。

Conclusion: 有效的摘要需要忠实的压缩而非创造性的过度思考，推理在摘要任务中的应用需要谨慎考虑策略选择和事实一致性要求。

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [18] [Fine-grained Narrative Classification in Biased News Articles](https://arxiv.org/abs/2512.03582)
*Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar*

Main category: cs.CL

TL;DR: 该论文提出了INDI-PROP数据集，用于印度新闻媒体中的宣传分析，包含三个层次的细粒度标注：意识形态偏见、叙事框架和说服技巧，并开发了两种GPT-4o-mini引导的多跳推理框架进行分类。


<details>
  <summary>Details</summary>
Motivation: 叙事是宣传的认知和情感支架，能将孤立的说服技巧组织成连贯的故事。当前缺乏针对印度新闻媒体的意识形态基础细粒度叙事分类数据集，特别是在CAA和农民抗议等两极分化的社会政治事件中。

Method: 1. 创建INDI-PROP数据集：包含1,266篇关于CAA和农民抗议的文章，进行三层标注：意识形态偏见（亲政府、亲反对派、中立）、事件特定细粒度叙事框架、说服技巧。2. 提出两种GPT-4o-mini引导的多跳推理框架：FANTA（集成信息提取和上下文框架进行分层推理）和TPTC（通过两阶段方法系统分解说服线索）。

Result: 提出的FANTA和TPTC框架在偏见、叙事和说服技巧分类任务上相比基线模型有显著改进。INDI-PROP是首个针对印度新闻媒体的意识形态基础细粒度叙事数据集。

Conclusion: 该研究为宣传分析提供了细粒度的多层级标注框架和有效的分类方法，特别针对印度两极分化的社会政治背景。提出的数据集和方法为理解意识形态叙事结构提供了新工具。

Abstract: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

</details>


### [19] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 提出一个可解释的事实一致性评估框架，通过分解文本为原子事实，使用灵活的、无模式的方法，并引入加权指标来增强事实评估


<details>
  <summary>Details</summary>
Motivation: 大语言模型容易产生错误但看似合理的论点（幻觉问题），在临床等高风险领域尤其危险。现有评估指标无法充分评估事实一致性且缺乏可解释性，难以诊断和缓解错误

Method: 提出可解释的事实一致性评估框架：1）将文本分解为原子事实；2）采用灵活的无模式方法；3）引入加权指标而非绝对指标；4）提出控制复杂领域评估复杂性的机制

Result: 在流行的通用和临床数据集上进行基准测试，并发布代码以支持未来研究中事实感知模型的训练

Conclusion: 该框架解决了现有事实一致性评估的局限性，提供了更可解释和灵活的评估方法，特别适用于高风险领域如临床应用

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [20] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 意大利首次全面调查显示：生成式AI被广泛用于工作和个人任务，正取代其他技术成为主要信息来源，但用户数字素养低且存在显著性别鸿沟，女性使用率仅为男性一半。


<details>
  <summary>Details</summary>
Motivation: 研究动机是了解生成式AI在意大利的采用情况、使用模式和数字素养，评估其对社会的影响，特别是识别可能加剧数字鸿沟的风险因素。

Method: 基于新收集的1,906名意大利语成年人的调查数据，进行首次全面的实证映射，分析生成式AI的采用率、使用模式和数字素养水平。

Result: 研究发现：1）生成式AI被广泛用于工作和个人任务，包括情感支持和医疗建议等敏感领域；2）正取代其他技术成为主要信息来源；3）用户数字素养普遍较低，难以识别错误信息；4）存在显著性别鸿沟，女性采用率仅为男性一半，使用频率也更低；5）数字素养是采用的关键预测因素，但只能部分解释性别差异。

Conclusion: 需要针对性的教育计划和进一步调查性别鸿沟背后的深层障碍，仅靠提高数字素养不足以解决公平参与问题，需多维度干预确保AI技术的包容性发展。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [21] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 论文提出了Hydro-SE Bench评估基准，包含4000道选择题，用于评估大语言模型在水科学与工程领域的知识与应用能力，发现商业模型准确率0.74-0.80，小参数模型0.41-0.68，模型在自然物理科学相关子领域表现较好，但在行业标准和水利结构等专业领域存在困难。


<details>
  <summary>Details</summary>
Motivation: 水科学与工程是保障人类供水、清洁水电能源和减灾的关键领域，需要多学科专家协作决策，但大语言模型在该领域的知识和应用能力尚未得到充分评估，因此需要建立专门的评估基准。

Method: 提出Hydro-SE Bench评估基准，包含4000道选择题，涵盖9个子领域，从基本概念知识、工程应用能力、推理计算能力三个维度评估大语言模型表现。

Result: 商业大语言模型准确率0.74-0.80，小参数模型0.41-0.68；模型在自然物理科学相关子领域表现良好，但在行业标准、水利结构等专业领域存在困难；模型扩展主要提升推理计算能力，但在实际工程应用方面仍有改进空间。

Conclusion: 研究揭示了大语言模型在水科学与工程任务中的优势和不足，为模型开发者提供了明确的训练目标，为领域研究人员提供了应用大语言模型的实践指导。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [22] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: LLMs中语法知识的表征研究：发现不同语法现象（特别是语法一致性）在模型中共享功能单元，构成有意义的语法功能类别


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs能够可靠区分语法正确与错误的句子，但语法知识如何在模型中表征仍不清楚。研究者希望探究不同语法现象是否共享或使用不同的模型组件

Method: 采用认知神经科学启发的功能定位方法，识别7个开源模型中67种英语语法现象最响应的单元；进行跨语言分析（英语、俄语、中文）和多语言比较（57种语言）

Result: 不同语法一致性类型（主谓一致、照应一致、限定词-名词一致）招募重叠的单元集合，表明一致性构成LLMs中有意义的功能类别；结构更相似的语言在主谓一致上共享更多单元

Conclusion: 语法一致性作为语法依赖关系的关键标记，在LLMs表征空间中构成有意义的类别，揭示了模型内部语法知识的组织方式

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [23] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: AITutor-EvalKit是一个利用语言技术评估AI导师教学质量的工具，提供演示、评估、模型检查和数据可视化功能。


<details>
  <summary>Details</summary>
Motivation: 当前AI导师系统缺乏系统化的教学质量评估工具，教育利益相关者和ACL社区需要能够评估AI导师教学效果、收集用户反馈和标注的工具。

Method: 开发了一个集成语言技术的应用程序，包含教学质量评估、软件演示、模型检查和数据可视化模块，支持用户反馈和标注收集。

Result: 创建了AITutor-EvalKit工具，为教育利益相关者和ACL社区提供了评估AI导师教学质量的完整解决方案。

Conclusion: 该工具填补了AI导师评估领域的空白，支持学习和用户反馈收集，对教育技术和自然语言处理社区都有重要价值。

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [24] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: DZ-TDPO是一个非破坏性对齐框架，通过动态KL约束和可学习时间注意力偏置解决长对话中的状态惯性问题，在MSC数据集上达到SOTA胜率，同时保持零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 长对话系统存在状态惯性问题，静态约束导致模型无法解决用户意图演变与历史上下文之间的冲突，限制了对话系统的动态适应能力。

Method: 提出DZ-TDPO框架，结合冲突感知的动态KL约束和可学习的时间注意力偏置，通过精确的注意力调节而非破坏性权重更新来缓解状态惯性。

Result: 在MSC数据集上，DZ-TDPO在Phi-3.5上达到86.2%的胜率，Qwen2.5-7B模型达到99.4%的胜率且困惑度开销可忽略。发现"容量-稳定性权衡"现象：小模型需要付出"对齐税"来克服历史惯性，而大模型能实现近乎完美的对齐。

Conclusion: 通过精确的注意力调节而非破坏性权重更新可以有效缓解状态惯性问题，同时保持模型的通用能力。大模型在解决状态惯性问题上具有显著优势，能够实现高性能对齐而几乎不影响困惑度。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [25] [AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation](https://arxiv.org/abs/2512.03737)
*Chuyue Wang,Jie Feng,Yuxi Wu,Hang Zhang,Zhiguo Fan,Bing Cheng,Wei Lin*

Main category: cs.CL

TL;DR: AR-Med是一个用于医疗搜索的自动相关性评估框架，通过检索增强的LLM方法解决传统搜索的局限性，并通过知识蒸馏实现高效部署，在离线准确率达到93%以上，在线性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 在线医疗平台需要准确可靠的搜索功能，传统方法难以理解复杂细微的用户查询，而LLMs虽然具有强大语义理解能力，但在医疗领域部署面临事实幻觉、专业知识缺口和高成本等挑战。

Method: 提出AR-Med框架：1）采用检索增强方法，将LLM推理建立在已验证的医疗知识基础上；2）设计实用的知识蒸馏方案，将大型教师模型压缩为紧凑而强大的学生模型；3）创建LocalQSMed多专家标注基准，指导模型迭代并确保离线与在线性能的一致性。

Result: AR-Med在离线准确率超过93%，比原始在线系统绝对提升24%；在线相关性和用户满意度显著提高；成功在在线医疗配送平台大规模部署。

Conclusion: AR-Med为医疗领域开发可信赖、可扩展的LLM驱动系统提供了实用蓝图，成功解决了LLM在医疗搜索中的准确性和可靠性问题，同时通过知识蒸馏实现了高效部署。

Abstract: Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \textbf{AR-Med}, a novel framework for \textbf{A}utomated \textbf{R}elevance assessment for \textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\%, a 24\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.

</details>


### [26] [Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective](https://arxiv.org/abs/2512.03759)
*Jingyang Ou,Jiaqi Han,Minkai Xu,Shaoxuan Xu,Jianwen Xie,Stefano Ermon,Yi Wu,Chongxuan Li*

Main category: cs.CL

TL;DR: 提出了ESPO框架，通过序列级优化解决扩散大语言模型中的强化学习难题，使用ELBO作为似然代理，在数学推理、编程和规划任务上显著优于词级基线方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自回归语言模型中很有效，但难以应用于扩散大语言模型。核心困难在于似然近似：自回归模型天然提供词级条件概率，而扩散模型通过迭代去噪步骤生成序列，缺乏这种分解。

Method: 提出ELBO-based Sequence-level Policy Optimization (ESPO)框架，将整个序列生成视为单个动作，使用ELBO作为可处理的序列级似然代理。方法包含词级重要性比率归一化和鲁棒的KL散度估计，确保大规模训练的稳定性。

Result: 在数学推理、编程和规划任务上的广泛实验表明，ESPO显著优于词级基线方法，在Countdown任务上实现了20-40分的显著提升，同时在数学和编程基准上保持一致的增益。

Conclusion: ESPO建立了序列级优化作为扩散大语言模型中强化学习的原理性和经验有效的范式，解决了自回归与扩散模型在RL应用中的根本性不匹配问题。

Abstract: Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.

</details>


### [27] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: Doublespeak是一种针对大语言模型的上下文表示劫持攻击，通过将有害关键词替换为良性标记来绕过安全对齐，使模型内部将良性提示解释为有害指令。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全对齐策略存在漏洞，攻击者可能通过操纵内部表示空间来绕过安全防护。研究者希望揭示这种新的攻击面，证明现有对齐方法在表示层面的不足。

Method: 提出Doublespeak攻击方法：在多个上下文示例中系统性地将有害关键词（如"bomb"）替换为良性标记（如"carrot"），并提供一个有害请求的前缀。这种替换导致良性标记的内部表示向有害标记收敛，从而在表示层面嵌入有害语义。

Result: 攻击无需优化，广泛适用于不同模型系列，在闭源和开源系统上均取得高成功率。在Llama-3.3-70B-Instruct上，仅需单句上下文覆盖即可达到74%的攻击成功率。可解释性工具显示语义覆盖逐层发生，早期层的良性含义在后期层收敛为有害语义。

Conclusion: Doublespeak揭示了LLM潜在空间中的新攻击面，表明当前对齐策略不足，需要在表示层面进行操作。这为未来更鲁棒的安全对齐方法提供了重要启示。

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [28] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 本文首次在编码器-解码器架构（T5/FLAN-T5）中实现DoLa对比解码方法，评估其对指令遵循能力的影响，发现该方法在某些任务上提升生成忠实性，在其他任务上则有害。


<details>
  <summary>Details</summary>
Motivation: 对比解码是一种轻量级推理时方法，能提升大语言模型的文本生成质量。但现有方法如DoLa仅应用于仅解码器架构，且主要研究其对事实性的改进。本研究旨在将DoLa适配到编码器-解码器架构（T5/FLAN-T5），并评估其对指令遵循能力的影响。

Method: 将DoLa对比解码方法适配到T5和FLAN-T5模型家族，这是首次在编码器-解码器架构中实现对比解码策略。通过层对层分析FLAN-T5模型的logit演化，量化DoLa对令牌输出概率的影响。

Result: DoLa在某些任务类别上能提升文本生成的忠实性，但在其他任务上会产生负面影响。通过层对层分析揭示了DoLa对令牌输出概率的具体影响机制。

Conclusion: 本研究成功在编码器-解码器架构中实现了DoLa对比解码方法，首次展示了该方法对指令遵循能力的影响具有任务依赖性，为理解对比解码在不同架构中的作用提供了新见解。

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [29] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 研究提出一个通过提示工程优化大语言模型在心理学文本分类任务中性能的实证框架，发现构造定义、任务框架和示例是最关键因素，推荐结合人工和自动生成提示并进行实证评估的方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本分类中表现良好，但其输出高度依赖提示的措辞。现有研究很少关注心理学等专业领域，这些领域的构造具有精确的理论定义，可能未在预训练数据中充分体现。需要系统方法优化LLM在专业分类任务中的表现。

Method: 提出一个优化LLM提示的实证框架，实验评估五种提示策略：代码本引导的实证提示选择、自动提示工程、角色提示、思维链推理和解释性提示，结合零样本和少样本分类方法。

Result: 研究发现角色、思维链和解释并不能完全解决提示措辞不当导致的性能损失。最关键的提示特征是构造定义、任务框架和示例。在三个构造和两个模型中，与专家判断最一致的结果来自结合代码本引导的实证提示选择和自动提示工程的少样本提示。

Conclusion: 建议研究人员生成和评估尽可能多的提示变体（人工制作、自动生成或两者结合），基于训练数据集中的实证性能选择提示和示例，并在保留集中验证最终方法。这为需要与专家判断对齐的场景提供了实用、系统和理论驱动的方法。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [30] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: 该论文提出通过微调LLMs遵循医学共识指南进行逐步推理，以提升医疗预测的可解释性和准确性，并以Sepsis-3定义为例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗机器学习虽然预测性能有所突破，但过度关注准确率而忽视了可解释性，导致难以获得医疗从业者的信任。医学领域普遍存在共识指南，需要让模型遵循这些指南进行推理。

Method: 将医学共识指南转化为可执行的推理规则，利用电子健康记录中的实例对LLMs进行微调，使其学习共识规则及其例外。采用多模态方法整合时间序列预测模型的输出表示。

Result: 微调后的小模型在Sepsis-3任务上优于使用显式定义提示的大型LLMs和基于医学文本训练的模型。微调模型在未见患者数据上对规则推导正确率接近完美，主要瓶颈在于对未来稀疏不规则临床变量的预测。

Conclusion: 通过微调LLMs遵循医学共识指南进行逐步推理，可以显著提升医疗预测的可解释性和准确性。多模态整合时间序列预测能改善对未来临床变量的预测性能，为可信医疗AI提供了有效途径。

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [31] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: FusedKV通过融合底层和中层KV缓存来减少Transformer解码器的内存占用，同时保持性能


<details>
  <summary>Details</summary>
Motivation: Transformer解码器在长序列任务中KV缓存内存消耗过大，现有的跨层KV缓存共享方法性能不如GQA等层内方法，需要找到更高效的KV缓存压缩方案

Method: 分析顶层KV信息流发现：值主要来自底层，键同时来自底层和中层。提出FusedKV，顶层KV缓存是可学习的底层和中层最有信息量的KV融合，直接在RoPE后的键上操作。还提出FusedKV-Lite，顶层KV缓存直接来自底层值和中层键

Result: 在332M到4B参数的LLM实验中，该方法减少50%缓存内存，同时获得比标准Transformer解码器更低的验证困惑度

Conclusion: FusedKV是一种内存高效、高性能的架构替代方案，通过智能融合不同层的KV缓存信息，在减少内存的同时保持甚至提升模型性能

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [32] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 该论文主张语言模型应捕捉语言多样性而非仅依赖标准化文本，通过构建包含标准、社交媒体和历史文本的巴斯克语语料库，训练了三种配置的BERnaT模型，结果显示结合多样数据的模型在所有任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型依赖大规模高质量文本语料库，但过滤过程可能排除非标准语言变体（方言、历史、非正式等），这会降低模型鲁棒性并强化代表性偏见。作者认为语言模型应捕捉完整的语言变异谱系，而非仅依赖标准化文本。

Method: 针对形态丰富且资源稀缺的巴斯克语，构建包含标准文本、社交媒体内容和历史资料的新语料库。预训练三种配置的BERnaT编码器模型：标准版、多样版和结合版。提出将自然语言理解任务分为标准子集和多样子集的评估框架，以评估语言泛化能力。

Result: 实验结果显示，在标准数据和多样数据上训练的模型始终优于仅使用标准语料库训练的模型，在所有任务类型上都有性能提升，且不损害标准基准的准确性。

Conclusion: 研究结果强调了语言多样性在构建包容性、可泛化语言模型中的重要性，表明结合多样语言变体能够提升模型性能而不牺牲标准任务表现。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [33] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: BRAND数据集用于评估多语言模型在宗教背景下的偏见，发现模型在英语中表现优于孟加拉语，且对伊斯兰教存在系统性偏见


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在偏见检测方面有所改进，但宗教等敏感话题仍存在挑战，因为微小错误可能导致严重误解。多语言模型经常误读宗教内容，在宗教语境中准确性不足。

Method: 引入BRAND数据集，聚焦南亚四大宗教（佛教、基督教、印度教、伊斯兰教），包含2400多个条目，使用英语和孟加拉语的三种提示类型进行评估。

Result: 模型在英语中表现优于孟加拉语，即使回答宗教中立问题时也持续表现出对伊斯兰教的偏见，揭示了多语言模型在不同语言中提问相似问题时的持续偏见问题。

Conclusion: 研究结果凸显了多语言模型在处理宗教内容时的偏见问题，并将这些发现与人机交互中宗教和灵性相关的更广泛问题联系起来。

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [34] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 该研究提出两阶段方法将Qwen2.5-3B模型适配到藏语：持续预训练建立语言基础，监督微调提升翻译任务性能，显著降低困惑度并提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在低资源语言（如藏语）上的适配面临数据稀缺和跨语言漂移的挑战，需要探索有效的适配方法。

Method: 采用两阶段适配：1）持续预训练（CPT）建立藏语语言基础；2）监督微调（SFT）进行任务和翻译专业化。对Qwen3-4B的435层进行层间分析。

Result: 困惑度从2.98降至1.54；汉藏翻译质量显著提升（BLEU从0.046到0.261，chrF从2.2到6.6）。适配主要集中在嵌入层和输出头，中后期MLP投影编码领域特定转换。

Conclusion: CPT构建藏语语义流形，SFT以最小表征扰动锐化任务对齐。该研究首次定量探索藏语适配动态，为低资源语言适配提供可复现框架。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [35] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 提出两种tokenizer适应方法：持续BPE训练用于词汇扩展，叶基词汇剪枝用于词汇缩减，共同实现可控词汇修改


<details>
  <summary>Details</summary>
Motivation: 将预训练语言模型迁移到新领域或语言时，tokenizer适应很重要。传统方法扩展词汇时添加的token往往无法访问或从未使用，需要更有效的适应方法

Method: 1. 持续BPE训练：在预训练tokenizer基础上，在新数据上继续BPE合并学习过程来适应tokenizer；2. 叶基词汇剪枝：移除冗余token同时保持模型质量

Result: 跨多种语言和模型家族的实验表明，该方法提高了tokenization效率，并更好地利用了添加的词汇

Conclusion: 这两种方法为可控词汇修改提供了实用工具，已作为开源包发布

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [36] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: AugServe：针对增强型LLM推理服务的高效推理框架，通过两阶段自适应请求调度和动态令牌批处理，显著提升有效吞吐量并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 随着增强型大语言模型在Web应用中日益普及，提升推理服务效率和优化服务级别目标对改善用户体验至关重要。现有系统面临两大挑战：1) 先到先服务调度导致严重的队头阻塞，使许多请求的排队延迟超出SLO；2) 静态批处理令牌限制无法适应波动负载和硬件条件，这两者都降低了有效吞吐量和服务质量。

Method: AugServe采用两阶段自适应请求调度策略：第一阶段结合增强型LLM请求的推理特征优化调度决策顺序；第二阶段利用运行时信息持续优化决策，适应请求特征和系统能力。此外，AugServe根据硬件状态和实时负载动态调整令牌批处理机制。

Result: 实验结果显示，AugServe相比vLLM和InferCept实现了4.7-33.1倍和3.3-13.2倍的有效吞吐量提升，同时将首令牌时间分别降低了96.3%和95.0%。

Conclusion: AugServe通过创新的两阶段自适应调度和动态批处理机制，有效解决了增强型LLM推理服务中的队头阻塞和静态批处理限制问题，显著提升了服务效率和用户体验。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [37] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM是一个24亿参数的多语言视觉语言模型，在2B规模的开源VLM中实现了最先进的多语言视觉问答性能


<details>
  <summary>Details</summary>
Motivation: 开发一个在2B参数规模下具有竞争力的多语言视觉语言模型，能够在保持文本性能的同时，在视觉问答任务上超越同类模型

Method: 结合SigLIP2视觉编码器和Qwen3语言骨干，通过注意力池化连接器实现任意分辨率图像的token高效处理

Result: 在标准VQA基准测试和多语言评估中，Jina-VLM超越了可比模型，同时保持了有竞争力的纯文本性能

Conclusion: Jina-VLM在2B参数规模下实现了最先进的多语言视觉问答性能，证明了其架构设计的有效性

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [38] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: SkillFactory是一种在强化学习前通过监督微调让模型学习认知技能的方法，通过重新排列模型自身输出来创建训练数据，帮助模型在强化学习后更好地泛化到更困难的任务。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型虽然能利用各种认知技能（如验证答案、回溯、尝试不同方法等），但这些技能通常需要基础模型已经具备。当基础模型不具备这些技能时，如何让模型学会利用它们？

Method: SkillFactory在强化学习前增加一个监督微调阶段，使用模型自身的输出重新排列来创建"银标"训练数据，这些数据虽然不完美但能帮助模型初步学习认知技能，为后续强化学习做好准备。

Result: 1) SkillFactory SFT初始化帮助模型在强化学习后更好地泛化到更困难的任务变体；2) 模型确实使用了认知技能；3) SkillFactory模型在域外任务上比基础模型更稳健，不易出现性能退化。

Conclusion: 在强化学习前学习的归纳偏置有助于模型学习稳健的认知技能使用，SkillFactory方法提供了一种不依赖更强模型蒸馏的有效途径。

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [39] [Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments](https://arxiv.org/abs/2512.03166)
*Aya Taourirte,Md Sohag Mia*

Main category: cs.RO

TL;DR: 本文提出一个统一的多智能体强化学习框架，结合分层强化学习和平均场理论，解决动态对抗环境中多智能体系统的实时决策、合作与可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 在机器人足球等动态对抗环境中部署多智能体系统需要实时决策、复杂合作和可扩展算法。现有强化学习方法在处理任务多粒度性（长期策略vs即时动作）和大规模智能体交互复杂性方面存在困难。

Method: 1. 建立基于PPO的客户端-服务器架构基线；2. 引入基于选项框架的分层强化学习结构，将问题分解为高层轨迹规划层（半马尔可夫决策过程）和低层动作执行层；3. 将平均场理论集成到HRL框架中，简化多智能体交互为单智能体vs群体平均。

Result: PPO基线：4.32平均进球，82.9%控球率；HRL：平均进球提升至5.26；平均场actor-critic方法：5.93平均进球，89.1%控球率，92.3%传球准确率，训练稳定性增强。在Webots环境中4v4比赛仿真验证了方法的有效性。

Conclusion: 该统一MARL框架通过结合分层强化学习和平均场理论，在复杂多智能体领域实现了鲁棒、可扩展和合作的行为，为解决动态对抗环境中的多智能体决策问题提供了有效方案。

Abstract: The deployment of multi-agent systems in dynamic, adversarial environments like robotic soccer necessitates real-time decision-making, sophisticated cooperation, and scalable algorithms to avoid the curse of dimensionality. While Reinforcement Learning (RL) offers a promising framework, existing methods often struggle with the multi-granularity of tasks (long-term strategy vs. instant actions) and the complexity of large-scale agent interactions. This paper presents a unified Multi-Agent Reinforcement Learning (MARL) framework that addresses these challenges. First, we establish a baseline using Proximal Policy Optimization (PPO) within a client-server architecture for real-time action scheduling, with PPO demonstrating superior performance (4.32 avg. goals, 82.9% ball control). Second, we introduce a Hierarchical RL (HRL) structure based on the options framework to decompose the problem into a high-level trajectory planning layer (modeled as a Semi-Markov Decision Process) and a low-level action execution layer, improving global strategy (avg. goals increased to 5.26). Finally, to ensure scalability, we integrate mean-field theory into the HRL framework, simplifying many-agent interactions into a single agent vs. the population average. Our mean-field actor-critic method achieves a significant performance boost (5.93 avg. goals, 89.1% ball control, 92.3% passing accuracy) and enhanced training stability. Extensive simulations of 4v4 matches in the Webots environment validate our approach, demonstrating its potential for robust, scalable, and cooperative behavior in complex multi-agent domains.

</details>


### [40] [GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding](https://arxiv.org/abs/2512.03194)
*Johannes Gaber,Meshal Alharbi,Daniele Gammelli,Gioele Zardini*

Main category: cs.RO

TL;DR: 提出一种混合方法，结合学习型全局指导与轻量优化，用于大规模机器人车队任务调度，在500个机器人的仓库场景中提升吞吐量10%


<details>
  <summary>Details</summary>
Motivation: 大型机器人车队在仓库等物流场景中日益普遍，微小的控制改进能带来巨大的运营影响。现有调度方法在处理大规模、高拥堵场景时面临挑战，需要既能实时执行又能提升吞吐量的解决方案。

Method: 提出混合方法：1) 使用图神经网络策略通过强化学习训练，输出自由机器人在聚合仓库图上的期望分布；2) 通过最小成本流将信号转换为区域间再平衡；3) 通过小型局部分配问题完成最终调度，在保持精度的同时将每步延迟控制在1秒计算预算内。

Result: 在League of Robot Runners (LRR)的拥堵仓库基准测试中，最多500个机器人的场景下，相比2024年获胜调度器，吞吐量提升高达10%，同时保持实时执行能力。

Conclusion: 将图结构学习指导与可求解器相结合能有效减少拥堵，为大规模车队的高吞吐量调度提供了实用、可扩展的蓝图，表明学习与优化混合方法在实际应用中的有效性。

Abstract: Large robot fleets are now common in warehouses and other logistics settings, where small control gains translate into large operational impacts. In this article, we address task scheduling for lifelong Multi-Agent Pickup-and-Delivery (MAPD) and propose a hybrid method that couples learning-based global guidance with lightweight optimization. A graph neural network policy trained via reinforcement learning outputs a desired distribution of free agents over an aggregated warehouse graph. This signal is converted into region-to-region rebalancing through a minimum-cost flow, and finalized by small, local assignment problems, preserving accuracy while keeping per-step latency within a 1 s compute budget. On congested warehouse benchmarks from the League of Robot Runners (LRR) with up to 500 agents, our approach improves throughput by up to 10% over the 2024 winning scheduler while maintaining real-time execution. The results indicate that coupling graph-structured learned guidance with tractable solvers reduces congestion and yields a practical, scalable blueprint for high-throughput scheduling in large fleets.

</details>


### [41] [KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems](https://arxiv.org/abs/2512.03256)
*Albert H. Li,Ivan Dario Jimenez Rodriguez,Joel W. Burdick,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: KALIKO方法通过卡尔曼滤波隐式学习嵌入表示，实现高质量的长时程动力学预测，在波浪干扰控制任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 长时程动力学预测对机器人控制至关重要，但许多系统（如非线性、混沌、高维系统）难以建模。Koopman理论通过线性嵌入解决非线性问题，但显式计算合适的基函数很困难，可能导致预测不准确或过拟合。

Method: 提出KALIKO（Kalman-Implicit Koopman Operator Learning）方法，利用卡尔曼滤波隐式学习与潜在动力学对应的嵌入表示，无需显式编码器。该方法产生可解释的表示，保持全局线性潜在动力学。

Result: 在高维PDE生成的波浪数据上评估，KALIKO在开环预测和闭环控制任务中均超越多个基线方法。在模拟控制任务中成功稳定欠驱动机械臂的负载，通过预测和补偿强波浪干扰。

Conclusion: KALIKO通过隐式学习嵌入表示，有效解决了Koopman理论中基函数选择的难题，实现了高质量的长时程预测，在复杂干扰环境下的控制任务中表现出色。

Abstract: Long-horizon dynamical prediction is fundamental in robotics and control, underpinning canonical methods like model predictive control. Yet, many systems and disturbance phenomena are difficult to model due to effects like nonlinearity, chaos, and high-dimensionality. Koopman theory addresses this by modeling the linear evolution of embeddings of the state under an infinite-dimensional linear operator that can be approximated with a suitable finite basis of embedding functions, effectively trading model nonlinearity for representational complexity. However, explicitly computing a good choice of basis is nontrivial, and poor choices may cause inaccurate forecasts or overfitting. To address this, we present Kalman-Implicit Koopman Operator (KALIKO) Learning, a method that leverages the Kalman filter to implicitly learn embeddings corresponding to latent dynamics without requiring an explicit encoder. KALIKO produces interpretable representations consistent with both theory and prior works, yielding high-quality reconstructions and inducing a globally linear latent dynamics. Evaluated on wave data generated by a high-dimensional PDE, KALIKO surpasses several baselines in open-loop prediction and in a demanding closed-loop simulated control task: stabilizing an underactuated manipulator's payload by predicting and compensating for strong wave disturbances.

</details>


### [42] [GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation](https://arxiv.org/abs/2512.03347)
*William van den Bogert,Gregory Linkowski,Nima Fazeli*

Main category: cs.RO

TL;DR: GOMP是一种交互式模仿学习方法，通过将非刚性抓取物体约束到低维流形来减少累积误差，提高精确装配任务的轨迹精度。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在工业装配等重复性操作任务中具有潜力，但常因累积误差导致轨迹精度不足。现有方法难以处理非刚性抓取物体在抓握中的微小位移问题。

Method: 提出GOMP方法：1) 将非刚性抓取物体约束到低维流形；2) 从专家数据中学习增强策略；3) 使用n-arm bandit交互组件进行调整；4) 提供理论分析证明对累积误差界的改进。

Result: 在四个精确装配任务上验证了GOMP的有效性，使用触觉反馈但方法保持模态无关性。实验表明该方法能显著提高装配精度。

Conclusion: GOMP通过流形约束和交互式调整有效解决了模仿学习中的累积误差问题，为精确装配任务提供了可行的解决方案，且具有模态无关的通用性。

Abstract: Imitation Learning (IL) holds great potential for learning repetitive manipulation tasks, such as those in industrial assembly. However, its effectiveness is often limited by insufficient trajectory precision due to compounding errors. In this paper, we introduce Grasped Object Manifold Projection (GOMP), an interactive method that mitigates these errors by constraining a non-rigidly grasped object to a lower-dimensional manifold. GOMP assumes a precise task in which a manipulator holds an object that may shift within the grasp in an observable manner and must be mated with a grounded part. Crucially, all GOMP enhancements are learned from the same expert dataset used to train the base IL policy, and are adjusted with an n-arm bandit-based interactive component. We propose a theoretical basis for GOMP's improvement upon the well-known compounding error bound in IL literature. We demonstrate the framework on four precise assembly tasks using tactile feedback, and note that the approach remains modality-agnostic. Data and videos are available at williamvdb.github.io/GOMPsite.

</details>


### [43] [Surfel-LIO: Fast LiDAR-Inertial Odometry with Pre-computed Surfels and Hierarchical Z-order Voxel Hashing](https://arxiv.org/abs/2512.03397)
*Seungwon Choi,Dong-Gyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: Surfel-LIO：一种基于分层体素结构和预计算面元表示的激光雷达惯性里程计方法，通过O(1)对应关系检索和Z-order曲线编码实现高速处理


<details>
  <summary>Details</summary>
Motivation: 现有LIO系统存在两个可改进之处：(1)最近邻搜索需要检查多个空间单元以收集足够的点进行平面拟合；(2)尽管地图几何未变，但平面参数通常每次迭代都重新计算

Method: 提出Surfel-LIO方法，采用分层体素结构(hVox)和预计算的面元表示，结合Z-order曲线编码实现缓存友好的空间索引，实现O(1)时间复杂度的对应关系检索

Result: 在M3DGR数据集上的实验结果表明，该方法相比现有最先进方法显著提高了处理速度，同时保持了相当的状态估计精度

Conclusion: Surfel-LIO通过创新的分层体素结构和预计算面元表示，解决了LIO系统中的效率瓶颈，实现了高速处理而不牺牲精度，代码已开源

Abstract: LiDAR-inertial odometry (LIO) is an active research area, as it enables accurate real-time state estimation in GPS-denied environments. Recent advances in map data structures and spatial indexing have significantly improved the efficiency of LIO systems. Nevertheless, we observe that two aspects may still leave room for improvement: (1) nearest neighbor search often requires examining multiple spatial units to gather sufficient points for plane fitting, and (2) plane parameters are typically recomputed at every iteration despite unchanged map geometry. Motivated by these observations, we propose Surfel-LIO, which employs a hierarchical voxel structure (hVox) with pre-computed surfel representation. This design enables O(1) correspondence retrieval without runtime neighbor enumeration or plane fitting, combined with Z-order curve encoding for cache-friendly spatial indexing. Experimental results on the M3DGR dataset demonstrate that our method achieves significantly faster processing speed compared to recent state-of-the-art methods while maintaining comparable state estimation accuracy. Our implementation is publicly available at https://github.com/93won/lidar_inertial_odometry.

</details>


### [44] [What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models](https://arxiv.org/abs/2512.03422)
*Tianchen Deng,Yue Pan,Shenghai Yuan,Dong Li,Chen Wang,Mingrui Li,Long Chen,Lihua Xie,Danwei Wang,Jingchuan Wang,Javier Civera,Hesheng Wang,Weidong Chen*

Main category: cs.RO

TL;DR: 本文全面综述了机器人学中的场景表示方法，涵盖传统方法（点云、体素、SDF、场景图）和神经表示（NeRF、3DGS、基础模型），分析它们在机器人五大模块（感知、建图、定位、导航、操作）中的应用，并探讨3D基础模型作为未来统一解决方案的发展趋势。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM和定位系统主要依赖稀疏表示（如点云、体素），但密集场景表示对下游任务（导航、避障）至关重要。神经表示方法（NeRF、3DGS、基础模型）能更好地集成高层语义特征和语言先验，实现更全面的3D场景理解和具身智能。

Method: 将机器人核心模块分为五部分（感知、建图、定位、导航、操作），系统梳理不同场景表示方法的标准公式化表示，比较各模块中不同表示方法的优缺点，围绕"什么是最好的机器人3D场景表示？"这一核心问题展开分析。

Result: 提供了机器人场景表示方法的全面分类和比较框架，指出神经表示方法在语义集成和语言先验方面的优势，预测3D基础模型可能成为未来机器人应用的统一解决方案，并识别了实现该模型面临的主要挑战。

Conclusion: 3D基础模型有望成为未来机器人场景表示的统一解决方案，但需要解决现有挑战。本文为研究者和实践者提供了有价值的资源，并通过开源项目持续更新相关技术和研究成果。

Abstract: In this paper, we provide a comprehensive overview of existing scene representation methods for robotics, covering traditional representations such as point clouds, voxels, signed distance functions (SDF), and scene graphs, as well as more recent neural representations like Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and the emerging Foundation Models. While current SLAM and localization systems predominantly rely on sparse representations like point clouds and voxels, dense scene representations are expected to play a critical role in downstream tasks such as navigation and obstacle avoidance. Moreover, neural representations such as NeRF, 3DGS, and foundation models are well-suited for integrating high-level semantic features and language-based priors, enabling more comprehensive 3D scene understanding and embodied intelligence. In this paper, we categorized the core modules of robotics into five parts (Perception, Mapping, Localization, Navigation, Manipulation). We start by presenting the standard formulation of different scene representation methods and comparing the advantages and disadvantages of scene representation across different modules. This survey is centered around the question: What is the best 3D scene representation for robotics? We then discuss the future development trends of 3D scene representations, with a particular focus on how the 3D Foundation Model could replace current methods as the unified solution for future robotic applications. The remaining challenges in fully realizing this model are also explored. We aim to offer a valuable resource for both newcomers and experienced researchers to explore the future of 3D scene representations and their application in robotics. We have published an open-source project on GitHub and will continue to add new works and technologies to this project.

</details>


### [45] [World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations](https://arxiv.org/abs/2512.03429)
*Raul Steinmetz,Fabio Demo Rosa,Victor Augusto Kich,Jair Augusto Bottega,Ricardo Bedin Grando,Daniel Fernando Tello Gamarra*

Main category: cs.RO

TL;DR: 提出基于DreamerV3的模型强化学习框架，通过MLP-VAE编码高维LIDAR数据，实现更高效和鲁棒的自主导航


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法处理高维LIDAR数据时面临维度灾难和样本效率低的问题，现有方法通常需要简化观测数据，降低了空间感知和导航鲁棒性

Method: 基于DreamerV3算法构建模型强化学习框架，集成MLP-VAE将高维LIDAR读数编码为紧凑的潜在表示，结合学习到的动态预测器，实现基于想象的策略优化

Result: 在TurtleBot3导航任务中，相比SAC、DDPG、TD3等模型无关方法，提出的架构收敛更快、成功率更高，使用完整LIDAR数据时达到100%成功率，而基线方法低于85%

Conclusion: 将预测性世界模型与学习的潜在表示相结合，能够从高维感官数据中实现更高效和鲁棒的导航

Abstract: Autonomous navigation of terrestrial robots using Reinforcement Learning (RL) from LIDAR observations remains challenging due to the high dimensionality of sensor data and the sample inefficiency of model-free approaches. Conventional policy networks struggle to process full-resolution LIDAR inputs, forcing prior works to rely on simplified observations that reduce spatial awareness and navigation robustness. This paper presents a novel model-based RL framework built on top of the DreamerV3 algorithm, integrating a Multi-Layer Perceptron Variational Autoencoder (MLP-VAE) within a world model to encode high-dimensional LIDAR readings into compact latent representations. These latent features, combined with a learned dynamics predictor, enable efficient imagination-based policy optimization. Experiments on simulated TurtleBot3 navigation tasks demonstrate that the proposed architecture achieves faster convergence and higher success rate compared to model-free baselines such as SAC, DDPG, and TD3. It is worth emphasizing that the DreamerV3-based agent attains a 100% success rate across all evaluated environments when using the full dataset of the Turtlebot3 LIDAR (360 readings), while model-free methods plateaued below 85%. These findings demonstrate that integrating predictive world models with learned latent representations enables more efficient and robust navigation from high-dimensional sensory data.

</details>


### [46] [PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers](https://arxiv.org/abs/2512.03444)
*Davood Soleymanzadeh,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本文提出PerFACT方法，结合LLM生成多样化工作空间和大规模数据收集，以及融合动作分块Transformer的通用神经运动规划器，显著提升机器人运动规划速度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有神经运动规划器主要在小规模人工生成工作空间数据集上训练，泛化能力有限，且采用单一网络架构难以编码关键规划信息，需要解决数据规模不足和架构限制问题。

Method: 提出PerFACT方法：1) MotionGeneralizer - 基于大语言模型生成语义可行工作空间，实现大规模规划数据收集；2) MpiNetsFusion - 融合动作分块Transformer的通用神经运动规划器，编码多模态特征。

Result: 使用MotionGeneralizer收集350万条轨迹训练MpiNetsFusion，相比现有最先进规划器，在评估任务上规划速度提升数倍。

Conclusion: PerFACT通过LLM生成多样化工作空间和大规模数据收集，结合融合动作分块Transformer架构，显著提升神经运动规划器的性能和泛化能力。

Abstract: Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.

</details>


### [47] [MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization](https://arxiv.org/abs/2512.03522)
*Gihyeon Lee,Jungwoo Lee,Juwon Kim,Young-Sik Shin,Younggun Cho*

Main category: cs.RO

TL;DR: 提出基于多标签似然的语义图匹配框架，用于解决语义模糊环境下的机器人全局定位问题


<details>
  <summary>Details</summary>
Motivation: 在未知物体类别和语义模糊的环境中，机器人进行全局定位时，高语义模糊度会加剧物体误分类和错误关联，导致姿态估计出现显著误差

Method: 采用多标签图表示而非单标签方案，通过上下文感知的似然传播，将每个节点的似然与其邻居的最大似然相结合，增强图间的语义对应关系

Result: 在闭集和开集检测配置下评估了数据关联和姿态估计性能，并在真实室内场景和合成环境中展示了方法对大词汇量物体类别的可扩展性

Conclusion: 提出的多标签似然语义图匹配框架能有效处理语义模糊环境下的全局定位问题，具有较好的可扩展性和鲁棒性

Abstract: Robots are often required to localize in environments with unknown object classes and semantic ambiguity. However, when performing global localization using semantic objects, high semantic ambiguity intensifies object misclassification and increases the likelihood of incorrect associations, which in turn can cause significant errors in the estimated pose. Thus, in this letter, we propose a multi-label likelihood-based semantic graph matching framework for object-level global localization. The key idea is to exploit multi-label graph representations, rather than single-label alternatives, to capture and leverage the inherent semantic context of object observations. Based on these representations, our approach enhances semantic correspondence across graphs by combining the likelihood of each node with the maximum likelihood of its neighbors via context-aware likelihood propagation. For rigorous validation, data association and pose estimation performance are evaluated under both closed-set and open-set detection configurations. In addition, we demonstrate the scalability of our approach to large-vocabulary object categories in both real-world indoor scenes and synthetic environments.

</details>


### [48] [AdaPower: Specializing World Foundation Models for Predictive Manipulation](https://arxiv.org/abs/2512.03538)
*Yuhang Huang,Shilong Zou,Jiazhao Zhang,Xinwang Liu,Ruizhen Hu,Kai Xu*

Main category: cs.RO

TL;DR: AdaPower是一个轻量级适应框架，通过时空测试时训练和记忆持久化，将通用世界基础模型转化为专业世界模型，显著提升预训练视觉语言动作策略的机器人控制性能。


<details>
  <summary>Details</summary>
Motivation: 世界基础模型具有强大的视觉动态模拟能力，但在精确机器人控制应用中存在生成真实性与控制导向精度之间的差距。现有方法将WFMs用作合成数据生成器，但计算成本高且未充分利用预训练的VLA策略。

Method: AdaPower框架包含两个核心组件：1) 时空测试时训练(TS-TTT)用于推理时适应，2) 记忆持久化(MP)用于长期一致性保持。该框架集成在模型预测控制框架中，将通用WFMs转化为专业世界模型。

Result: 在LIBERO基准测试中，任务成功率提升超过41%，且无需策略重新训练，同时保持了计算效率和通用能力。

Conclusion: AdaPower通过轻量级适应有效弥合了生成真实性与控制精度之间的差距，使预训练的视觉语言动作策略能够充分利用世界基础模型的模拟能力，实现高效精确的机器人控制。

Abstract: World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \textbf{AdaPower} (\textbf{Ada}pt and Em\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.

</details>


### [49] [A Learning-based Control Methodology for Transitioning VTOL UAVs](https://arxiv.org/abs/2512.03548)
*Zexin Lin,Yebin Zhong,Hanwen Wan,Jiu Cheng,Zhenglong Sun,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: 提出基于强化学习的耦合过渡控制方法ST3M，将巡航模式视为悬停特例，有效减少VTOL无人机过渡过程中的振动并提升轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: VTOL无人机在过渡过程中，由于倾斜转子机制导致重心和推力方向变化，现有解耦控制方法会产生显著振动，且缺乏交互考虑和适应性。

Method: 提出基于强化学习的耦合过渡控制方法ST3M，将巡航模式视为悬停的特殊情况，采用新的控制视角。

Result: 在仿真和真实环境中验证了方法的可行性，实现了高效的控制器开发和迁移，能够精确控制无人机位置和姿态，表现出优异的轨迹跟踪能力和减少的过渡振动。

Conclusion: ST3M方法为VTOL无人机过渡控制提供了新的有效解决方案，相比传统相位过渡方法具有更好的性能和适应性。

Abstract: Transition control poses a critical challenge in Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL UAV) development due to the tilting rotor mechanism, which shifts the center of gravity and thrust direction during transitions. Current control methods' decoupled control of altitude and position leads to significant vibration, and limits interaction consideration and adaptability. In this study, we propose a novel coupled transition control methodology based on reinforcement learning (RL) driven controller. Besides, contrasting to the conventional phase-transition approach, the ST3M method demonstrates a new perspective by treating cruise mode as a special case of hover. We validate the feasibility of applying our method in simulation and real-world environments, demonstrating efficient controller development and migration while accurately controlling UAV position and attitude, exhibiting outstanding trajectory tracking and reduced vibrations during the transition process.

</details>


### [50] [RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL](https://arxiv.org/abs/2512.03556)
*Yinzhou Tang,Yu Shang,Yinuo Chen,Bingwen Wei,Xin Zhang,Shu'ang Yu,Liangzhi Shi,Chao Yu,Chen Gao,Wei Wu,Yong Li*

Main category: cs.RO

TL;DR: RoboScape-R利用世界模型作为通用环境代理，通过内生奖励机制增强具身策略的泛化能力，在跨场景任务中比基线提升37.5%性能。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习和强化学习方法在具身智能策略泛化方面存在局限：模仿学习容易过拟合专家轨迹，强化学习缺乏统一的通用奖励信号。现有世界模型虽然能预测观测，但仍依赖任务特定的手工奖励函数，无法提供真正的通用训练环境。

Method: 提出RoboScape-R框架，利用世界模型作为RL范式中的通用环境代理。创新性地引入基于世界模型的内生奖励机制，该奖励源自模型对真实世界状态转移动态的内在理解，而非手工设计的任务特定奖励。

Result: 实验表明RoboScape-R有效解决了传统RL方法的局限，提供了高效通用的训练环境，显著增强了具身策略的泛化能力。在域外场景下，平均性能比基线提升37.5%。

Conclusion: 世界模型可以作为在线训练策略的有效工具，RoboScape-R通过内生奖励机制为具身智能的泛化问题提供了创新解决方案，展示了世界模型作为通用环境代理的潜力。

Abstract: Achieving generalizable embodied policies remains a key challenge. Traditional policy learning paradigms, including both Imitation Learning (IL) and Reinforcement Learning (RL), struggle to cultivate generalizability across diverse scenarios. While IL policies often overfit to specific expert trajectories, RL suffers from the inherent lack of a unified and general reward signal necessary for effective multi-scene generalization. We posit that the world model is uniquely capable of serving as a universal environment proxy to address this limitation. However, current world models primarily focus on their ability to predict observations and still rely on task-specific, handcrafted reward functions, thereby failing to provide a truly general training environment. Toward this problem, we propose RoboScape-R, a framework leveraging the world model to serve as a versatile, general-purpose proxy for the embodied environment within the RL paradigm. We introduce a novel world model-based general reward mechanism that generates ''endogenous'' rewards derived from the model's intrinsic understanding of real-world state transition dynamics. Extensive experiments demonstrate that RoboScape-R effectively addresses the limitations of traditional RL methods by providing an efficient and general training environment that substantially enhances the generalization capability of embodied policies. Our approach offers critical insights into utilizing the world model as an online training strategy and achieves an average 37.5% performance improvement over baselines under out-of-domain scenarios.

</details>


### [51] [Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations](https://arxiv.org/abs/2512.03630)
*Shifa Sulaiman,Amarnath H,Simon Bogh,Naresh Marturi*

Main category: cs.RO

TL;DR: 本文基于雅可比方法实现了三种运动规划方案，用于冗余机械臂与耦合手指夹爪的轨迹跟踪，比较了JT、PI和DLS三种逆解方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为冗余机械臂与耦合手指夹爪系统寻找高效的运动规划方案，通过比较不同雅可比逆解方法在轨迹平滑性、误差等方面的表现，确定适合特定任务的逆解技术。

Method: 使用RRT*算法进行轨迹规划，基于螺旋理论建立正运动学方程，分别采用雅可比转置(JT)、伪逆(PI)和阻尼最小二乘(DLS)三种方法计算逆解，并通过螺旋理论获得空间雅可比和可操作性度量。

Result: 通过仿真研究分析了生成轨迹的平滑性和RMSE误差，以及关节运动的连续性、加速度曲线、急动度和冲击值，比较了三种运动规划方案的优缺点。

Conclusion: 通过仿真研究确定了适合特定任务的逆解技术，分析了三种雅可比逆解方法的优缺点，为冗余机械臂与耦合夹爪系统的运动规划提供了指导。

Abstract: Motion planning schemes are used for planning motions of a manipulator from an initial pose to a final pose during a task execution. A motion planning scheme generally comprises of a trajectory planning method and an inverse kinematic solver to determine trajectories and joints solutions respectively. In this paper, 3 motion planning schemes developed based on Jacobian methods are implemented to traverse a redundant manipulator with a coupled finger gripper through given trajectories. RRT* algorithm is used for planning trajectories and screw theory based forward kinematic equations are solved for determining joint solutions of the manipulator and gripper. Inverse solutions are computed separately using 3 Jacobian based methods such as Jacobian Transpose (JT), Pseudo Inverse (PI), and Damped Least Square (DLS) methods. Space Jacobian and manipulability measurements of the manipulator and gripper are obtained using screw theory formulations. Smoothness and RMSE error of generated trajectories and velocity continuity, acceleration profile, jerk, and snap values of joint motions are analysed for determining an efficient motion planning method for a given task. Advantages and disadvantages of the proposed motion planning schemes mentioned above are analysed using simulation studies to determine a suitable inverse solution technique for the tasks.

</details>


### [52] [Context-Triggered Contingency Games for Strategic Multi-Agent Interaction](https://arxiv.org/abs/2512.03639)
*Kilian Schweppe,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 提出了一种结合战略游戏与动态应急游戏的两层架构，通过上下文触发的应急游戏实现自主多智能体系统中可靠高效的交互


<details>
  <summary>Details</summary>
Motivation: 解决自主多智能体系统中长期战略目标与短期动态适应之间的平衡问题，确保在不确定交互环境中的安全性和进展

Method: 提出上下文触发的应急游戏，将基于时序逻辑规范的战略游戏与实时解决的动态应急游戏相结合，采用两层架构：高层使用策略模板保证目标满足，底层使用基于因子图的新求解器实现可扩展的实时模型预测控制

Result: 在自动驾驶和机器人导航的仿真和硬件实验中验证了该方法，展示了高效、可靠和自适应的多智能体交互能力

Conclusion: 该框架能够在不确定的交互环境中同时保证安全性和进展，为自主多智能体系统提供了一种有效的交互解决方案

Abstract: We address the challenge of reliable and efficient interaction in autonomous multi-agent systems, where agents must balance long-term strategic objectives with short-term dynamic adaptation. We propose context-triggered contingency games, a novel integration of strategic games derived from temporal logic specifications with dynamic contingency games solved in real time. Our two-layered architecture leverages strategy templates to guarantee satisfaction of high-level objectives, while a new factor-graph-based solver enables scalable, real-time model predictive control of dynamic interactions. The resulting framework ensures both safety and progress in uncertain, interactive environments. We validate our approach through simulations and hardware experiments in autonomous driving and robotic navigation, demonstrating efficient, reliable, and adaptive multi-agent interaction.

</details>


### [53] [A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection](https://arxiv.org/abs/2512.03684)
*Shahid Ansari,Mahendra Kumar Gohil,Yusuke Maeda,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 提出一种结合软辅助手指与刚性外骨骼的混合夹爪系统，用于番茄自主采摘，通过视觉感知和力控实现轻柔抓取，平均采摘周期24.34秒，成功率约80%


<details>
  <summary>Details</summary>
Motivation: 现有番茄采摘系统在复杂环境中面临挑战，需要能够处理遮挡、光照变化，并实现轻柔抓取以避免果实损伤。本文旨在开发一种能在杂乱环境中可靠工作的自主采摘系统。

Method: 1. 混合夹爪设计：结合6个软辅助手指、刚性外骨骼和乳胶篮筐，实现笼式抓取；2. 伺服驱动的Scotch-yoke机构；3. 分离叶片形成锥形截头体隔离果实；4. 集成微伺服切割器；5. 基于RGB-D相机和Detectron2的视觉管道，进行语义分割和关键点定位；6. 基于虚功原理的分析模型关联伺服扭矩与抓取力；7. 使用PID控制器和力敏电阻实现闭环力控；8. 基于粒子群优化的5自由度机械臂轨迹规划

Result: 实验展示了完整的采摘周期（接近、分离、切割、抓取、运输、释放），平均周期时间24.34秒，总体成功率约80%，同时保持较低的抓取力（0.20-0.50N）。系统在杂乱环境中验证了可靠性。

Conclusion: 提出的混合夹爪设计和集成的视觉-控制管道在杂乱环境中实现了可靠的番茄采摘，验证了系统在保持低抓取力同时实现高成功率的有效性，为农业自动化提供了实用解决方案。

Abstract: This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.

</details>


### [54] [ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration](https://arxiv.org/abs/2512.03707)
*Sundas Rafat Mulkana,Ronyu Yu,Tanaya Guha,Emma Li*

Main category: cs.RO

TL;DR: ContactRL：基于强化学习的框架，通过力反馈将接触安全直接纳入奖励函数，使机器人学习自适应运动模式，在保持任务效率的同时最小化人机接触力。


<details>
  <summary>Details</summary>
Motivation: 在协作人机任务中，安全不仅需要避免碰撞，还需要确保安全、有意的物理接触。当前方法在接触安全方面存在不足，需要开发能够处理接触安全的新框架。

Method: 提出ContactRL强化学习框架，通过力反馈将接触安全直接纳入奖励函数。同时，为保障部署安全，使用基于动能的控制屏障函数(eCBF)屏蔽器增强学习策略。

Result: 仿真中ContactRL达到0.2%的安全违规率和87.7%的高任务成功率，优于最先进的约束RL基线。在UR3e机器人平台上的360次真实世界实验显示，测量的法向力始终低于10N，确认了安全接触。

Conclusion: ContactRL实现了安全高效的物理协作，推动了协作机器人在接触丰富任务中的部署应用。

Abstract: In collaborative human-robot tasks, safety requires not only avoiding collisions but also ensuring safe, intentional physical contact. We present ContactRL, a reinforcement learning (RL) based framework that directly incorporates contact safety into the reward function through force feedback. This enables a robot to learn adaptive motion profiles that minimize human-robot contact forces while maintaining task efficiency. In simulation, ContactRL achieves a low safety violation rate of 0.2\% with a high task success rate of 87.7\%, outperforming state-of-the-art constrained RL baselines. In order to guarantee deployment safety, we augment the learned policy with a kinetic energy based Control Barrier Function (eCBF) shield. Real-world experiments on an UR3e robotic platform performing small object handovers from a human hand across 360 trials confirm safe contact, with measured normal forces consistently below 10N. These results demonstrate that ContactRL enables safe and efficient physical collaboration, thereby advancing the deployment of collaborative robots in contact-rich tasks.

</details>


### [55] [Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing](https://arxiv.org/abs/2512.03729)
*Samantha Chapin,Kenneth Stewart,Roxana Leontie,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: APIARY实验首次在太空零重力环境中使用强化学习控制自由飞行机器人，通过PPO算法训练6自由度控制策略，并在国际空间站上成功验证。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在太空零重力环境下控制自由飞行机器人的可行性，为空间探索、物流和实时任务需求开发快速部署的自主行为。

Method: 使用基于actor-critic的PPO算法在NVIDIA Isaac Lab仿真环境中训练6自由度控制策略，通过随机化目标姿态和质量分布增强鲁棒性，然后进行地面测试和太空飞行验证。

Result: 2025年5月27日成功在国际空间站上使用NASA Astrobee机器人实现了首次太空中的强化学习控制自由飞行器验证。

Conclusion: 该实验验证了强化学习在太空机器人自主控制中的变革潜力，能够实现分钟到小时级别的快速行为开发和部署。

Abstract: The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.

</details>


### [56] [Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control](https://arxiv.org/abs/2512.03736)
*Kenneth Stewart,Samantha Chapin,Roxana Leontie,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 首次在轨演示基于强化学习的自由飞行机器人自主控制，使用NVIDIA Omniverse模拟器和课程学习训练神经网络，成功在空间站部署验证了仿真到现实的训练流程。


<details>
  <summary>Details</summary>
Motivation: 强化学习在太空机器人控制中具有变革潜力，但需要解决仿真到现实的差距问题，验证在地面训练后能成功部署到太空应用中的可行性。

Method: 使用NVIDIA Omniverse物理模拟器和课程学习训练深度神经网络，替代NASA Astrobee的标准姿态和平移控制，采用GPU加速的科学级仿真环境进行高效的蒙特卡洛强化学习训练。

Result: 成功在国际空间站上部署了基于强化学习的自主控制系统，验证了仿真到现实的训练流程，使Astrobee能够在微重力环境中自主导航。

Conclusion: 证明了在地面训练强化学习策略并转移到太空应用的可行性，为未来的在轨服务、组装和制造（ISAM）应用铺平了道路，使太空系统能够快速适应动态任务需求。

Abstract: Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.

</details>


### [57] [Cross-embodied Co-design for Dexterous Hands](https://arxiv.org/abs/2512.03743)
*Kehlani Fay,Darin Anthony Djapri,Anya Zorin,James Clinton,Ali El Lahib,Hao Su,Michael T. Tolley,Sha Yi,Xiaolong Wang*

Main category: cs.RO

TL;DR: 提出一个机器人手形态与控制策略协同设计框架，能够在24小时内完成从设计、训练、制造到部署的全流程


<details>
  <summary>Details</summary>
Motivation: 灵巧操作受限于控制与设计，缺乏关于何种机械手形态最适合灵巧任务的共识，需要解决如何设计优化灵巧性的机器人操作器这一根本挑战

Method: 开发协同设计框架，支持：1）包含关节、手指和手掌生成的广泛形态搜索空间；2）通过形态条件跨实体控制实现大规模设计空间评估；3）使用易得组件实现真实世界制造

Result: 在多个灵巧任务（包括仿真和真实部署中的手内旋转）上评估方法，框架能够实现端到端流程，在24小时内设计、训练、制造和部署新的机器人手

Conclusion: 该协同设计框架解决了机器人手形态与控制的优化问题，实现了快速迭代和实际部署，完整框架将开源提供

Abstract: Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.

</details>


### [58] [Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models](https://arxiv.org/abs/2512.03756)
*Marlon Steiner,Royden Wagner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 该论文提出将导航信息集成到基于注意力的运动预测模型中，以桥接多智能体运动预测和目标导向的运动规划，在nuPlan数据集上验证了预测驱动运动规划的潜力。


<details>
  <summary>Details</summary>
Motivation: 结合运动预测和运动规划可以增强自动驾驶车辆与其他交通参与者的交互，但存在两个挑战：如何将预测与导航目标相结合，以及如何确保稳定且运动学可行的轨迹。本文主要解决第一个挑战，研究如何将导航信息集成到运动预测模型中。

Method: 提出并评估了多种架构导航集成策略，将自车预期路线和目标姿态集成到基于注意力的运动预测模型架构中，从而桥接多智能体运动预测和目标导向的运动规划。

Result: 在nuPlan数据集上的实验结果表明，导航信息可以同时增强预测和规划任务，证明了预测驱动运动规划的潜力。

Conclusion: 通过将导航信息集成到运动预测模型中，成功桥接了多智能体运动预测和目标导向的运动规划，为预测驱动的运动规划提供了有前景的框架。

Abstract: Combining motion prediction and motion planning offers a promising framework for enhancing interactions between automated vehicles and other traffic participants. However, this introduces challenges in conditioning predictions on navigation goals and ensuring stable, kinematically feasible trajectories. Addressing the former challenge, this paper investigates the extension of attention-based motion prediction models with navigation information. By integrating the ego vehicle's intended route and goal pose into the model architecture, we bridge the gap between multi-agent motion prediction and goal-based motion planning. We propose and evaluate several architectural navigation integration strategies to our model on the nuPlan dataset. Our results demonstrate the potential of prediction-driven motion planning, highlighting how navigation information can enhance both prediction and planning tasks. Our implementation is at: https://github.com/KIT-MRT/future-motion.

</details>


### [59] [Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control](https://arxiv.org/abs/2512.03772)
*Gabriele Fadini,Deepak Ingole,Tong Duy Son,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 提出基于贝叶斯优化的自动调参框架，用于扭矩非线性模型预测控制，通过数字孪生优化MPC参数，显著提升机器人末端轨迹跟踪性能


<details>
  <summary>Details</summary>
Motivation: 传统手动调参非线性模型预测控制参数耗时且难以达到最优性能，需要自动化方法优化高维参数空间以实现精确的机器人末端轨迹跟踪

Method: 使用稀疏轴对齐子空间贝叶斯优化结合数字孪生技术，在仿真环境中高效探索高维参数空间（包括成本函数权重和底层控制器增益），然后安全迁移到真实UR10e机器人硬件

Result: 仿真结果显示跟踪性能提升41.9%，求解时间减少2.5%；真实机器人实验验证了趋势，性能提升25.8%

Conclusion: 数字孪生支持的自动参数优化对机器人操作至关重要，该框架能显著提升非线性模型预测控制的性能并减少人工调参负担

Abstract: This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.

</details>


### [60] [Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving](https://arxiv.org/abs/2512.03774)
*Johannes Fischer,Marlon Steiner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 提出结合安全强化学习和模型预测控制的自动驾驶轨迹规划方法，通过约束强化学习确保安全性，在高速场景中优于单独使用MPC或SRL


<details>
  <summary>Details</summary>
Motivation: 传统MPC使用凸优化近似，将解限制在子空间内，可能错过全局最优解。需要一种方法能够探索更广的解决方案空间，同时确保自动驾驶的安全性。

Method: 使用安全强化学习为MPC提供新的安全参考轨迹。采用约束强化学习框架，使用手工设计的基于能量函数的安全指数作为约束目标，同时学习安全策略和状态相关的拉格朗日乘子。

Result: 在高速公路场景实验中，该方法在安全性和性能指标上均优于单独的MPC和SRL方法。

Conclusion: 结合安全强化学习和模型预测控制的方法能够超越传统凸优化近似的限制，找到更好的全局最优解，同时确保自动驾驶的安全性。

Abstract: Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.

</details>


### [61] [MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving](https://arxiv.org/abs/2512.03795)
*Jia Hu,Zhexi Lian,Xuerun Yan,Ruiang Bi,Dou Shen,Yu Ruan,Haoran Wang*

Main category: cs.RO

TL;DR: MPCFormer：首个显式建模多车社会交互动力学的可解释自动驾驶方法，结合物理先验与Transformer学习，在NGSIM数据集上实现最低轨迹预测误差（5秒预测ADE仅0.86米），闭环实验中规划成功率94.67%，碰撞率从21.25%降至0.5%。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶在高度动态交互场景中难以展现类人行为，主要问题在于缺乏对社会交互底层机制的理解，导致与周围车辆的交互能力有限。

Method: 提出MPCFormer方法，将社会交互动力学建模为离散状态空间表示，嵌入物理先验增强可解释性，通过Transformer编码器-解码器架构从自然驾驶数据中学习动力学系数，并利用MPC框架进行规划。

Result: 在NGSIM数据集上，MPCFormer实现最低轨迹预测误差（5秒预测ADE 0.86米）；在激烈交互场景闭环实验中，规划成功率94.67%，驾驶效率提升15.75%，碰撞率从21.25%降至0.5%，优于前沿强化学习方法。

Conclusion: MPCFormer是首个显式建模多车社会交互动力学的方法，通过结合物理先验与数据驱动学习，实现了可解释、安全且类人的自动驾驶行为，在预测和规划任务中均显著优于现有方法。

Abstract: Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.

</details>


### [62] [IM HERE: Interaction Model for Human Effort Based Robot Engagement](https://arxiv.org/abs/2512.03828)
*Dominykas Strazdas,Magnus Jung,Jan Marquenie,Ingo Siegert,Ayoub Al-Hamadi*

Main category: cs.RO

TL;DR: 提出了IM HERE框架，通过基于努力的描述来建模人-人、人-机器人、机器人-机器人交互中的参与度，将复杂关系简化为关注点放置和四个关键状态，实现社交行为的自动化分析和自主系统的社会规范遵从。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互参与度定义和模型要么过于模糊，要么缺乏跨不同情境的泛化能力。需要一种能够有效建模参与度、支持有意义交流的框架，使自主系统能够在追求自身社交目标的同时实现完全的社会融合。

Method: 提出IM HERE框架，采用基于努力的描述来分析实体间的双边关系，将关系模式简化为关注点放置和四个关键状态。该框架能够捕捉相互关系、群体行为和符合社会规范的行动，并将其转化为自主系统的具体指令。整合主观感知和客观状态来精确识别和描述沟通误解。

Result: IM HERE框架能够有效建模人-人、人-机器人、机器人-机器人交互中的参与度，提供准确的关系模式分解，捕捉相互关系和群体行为，并将这些转化为自主系统的具体指令。该框架能够精确识别沟通误解，支持社交行为的自动化分析。

Conclusion: IM HERE框架为社交行为的自动化分析、建模和描述提供了有效方法，使自主系统能够在遵循社会规范的同时实现完全的社会融合，并追求自身的社交目标。该框架解决了现有参与度模型的模糊性和泛化能力不足问题。

Abstract: The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.

</details>


### [63] [OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance](https://arxiv.org/abs/2512.03874)
*Lei Zhang,Diwen Zheng,Kaixin Bai,Zhenshan Bing,Zoltan-Csaba Marton,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: OmniDexVLG是一个多模态、语义感知的灵巧抓取生成框架，通过联合语言和视觉指导生成结构多样且语义连贯的灵巧抓取姿势。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实现语义可控的灵巧抓取合成方面面临挑战，主要因为缺乏对抓取分类学、接触语义和功能可供性等多个语义维度的统一建模。

Method: 1) OmniDexDataGen：语义丰富的灵巧抓取数据集生成流水线，包含分类学引导的配置采样、功能可供性接触点采样、分类学感知的微分力闭合抓取采样以及基于物理的优化验证；2) OmniDexReasoner：多模态抓取类型语义推理模块，利用多智能体协作、检索增强生成和思维链推理；3) 统一的视觉语言抓取生成模型，显式结合抓取分类学、接触结构和功能可供性语义。

Result: 在仿真和真实世界物体抓取实验中，该方法在抓取多样性、接触语义多样性、功能可供性多样性和语义一致性方面显著优于现有最先进方法。

Conclusion: OmniDexVLG通过统一建模多个语义维度，实现了从自然语言指令进行细粒度控制的语义感知灵巧抓取生成，为任务需求和人类可解释的抓取语义提供了有效解决方案。

Abstract: Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.

</details>


### [64] [A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments](https://arxiv.org/abs/2512.03886)
*Brais Fontan-Costas,M. Diaz-Cacho,Ruben Fernandez-Boullon,Manuel Alonso-Carracedo,Javier Perez-Robles*

Main category: cs.RO

TL;DR: 提出了一种用于封闭赛道车辆的自主系统架构，包含计算机视觉、定位建图、路径规划和车辆控制等子系统，采用模块化设计和管道架构实现实时自主导航。


<details>
  <summary>Details</summary>
Motivation: 为封闭赛道环境中的车辆开发一个完整的自主系统架构，能够执行精确任务，实现实时自主导航。

Method: 采用模块化设计，将系统分为计算机视觉（环境感知）、定位与建图（精确定位）、路径规划（最优轨迹生成）和控制（精确车辆执行）四个独立子系统，通过管道架构连接数据流。

Result: 开发了一个完整的自主系统架构，能够结合最先进技术，在受控环境中实现实时自主导航。

Conclusion: 提出的模块化AS架构成功整合了多个子系统，为封闭赛道车辆的自主导航提供了一个可行的解决方案，展示了在受控环境中实现实时自主操作的潜力。

Abstract: This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.

</details>


### [65] [Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning](https://arxiv.org/abs/2512.03891)
*Ying-Kuan Tsai,Yi-Ping Chen,Vispi Karkaria,Wei Chen*

Main category: cs.RO

TL;DR: 提出基于数字孪生和深度强化学习的主动悬架控制协同设计框架，通过多代设计概念实现个性化优化，在部分可观测条件下减少控制能耗43-52%。


<details>
  <summary>Details</summary>
Motivation: 传统主动悬架系统受限于固定硬件设计和控制策略，无法适应不确定的动态运行条件。数字孪生和深度强化学习为实时数据驱动优化提供了新机会，但将其整合为统一框架仍具挑战。

Method: 1) 将自动微分集成到深度强化学习中，联合优化物理悬架组件和控制策略；2) 使用分位数学习进行模型更新以捕捉数据不确定性；3) 采用多代设计概念实现自改进系统；4) 在部分可观测条件下直接从可用传感器信息学习最优控制动作。

Result: 在温和和激进两种驾驶场景下，优化系统实现了更平滑的轨迹，控制能耗分别减少约43%和52%，同时保持乘坐舒适性和稳定性。

Conclusion: 该研究开发了集成深度强化学习和不确定性感知模型更新的数字孪生控制协同设计框架，通过多代设计策略实现个性化主动悬架优化，为自适应车辆系统提供了有效解决方案。

Abstract: Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.

</details>


### [66] [Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware](https://arxiv.org/abs/2512.03911)
*Kenneth Stewart,Roxana Leontie,Samantha Chapin,Joe Hays,Sumit Bam Shrestha,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 将强化学习训练的ANN转换为脉冲Sigma-Delta神经网络，部署在Intel Loihi 2神经形态芯片上，用于Astrobee自由飞行机器人控制，实现低延迟、高能效的推理。


<details>
  <summary>Details</summary>
Motivation: 探索神经形态硬件在机器人控制中的应用潜力，特别是为未来空间和地面机器人应用提供实时、高能效的计算解决方案。

Method: 开发端到端流程：1）在仿真中训练ANN策略（使用ReLU激活函数）；2）将ANN转换为与Intel Loihi 2兼容的SDNN；3）在NVIDIA Omniverse Isaac Lab仿真环境中进行闭环控制评估；4）比较GPU与Loihi 2的执行性能。

Result: 成功将ANN策略转换为SDNN并在Loihi 2上部署，验证了神经形态平台用于机器人控制的可行性，展示了低延迟和能效优势。

Conclusion: 该研究为未来空间和地面机器人应用中的实时、高能效神经形态计算建立了可行路径，证明了神经形态硬件在机器人控制中的实用价值。

Abstract: We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.

</details>


### [67] [Hierarchical Vision Language Action Model Using Success and Failure Demonstrations](https://arxiv.org/abs/2512.03913)
*Jeongeun Park,Jihwan Yoon,Byungwoo Jeon,Juhan Park,Jinwoo Shin,Namhoon Cho,Kyungjae Lee,Sangdoo Yun,Sungjoon Choi*

Main category: cs.RO

TL;DR: VINE是一个分层视觉-语言-动作模型，通过利用失败数据来增强机器人操作的鲁棒性，将高层推理与低层控制分离，在规划时进行可行性评估。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型通常只使用成功的遥操作演示数据，而丢弃了大量的失败尝试。这些失败数据包含了策略脆弱性的信息，可以用来提高模型的鲁棒性。作者希望利用混合质量的数据集来学习在规划时进行失败感知推理。

Method: 提出VINE分层模型：System 2进行高层推理，在2D场景图抽象上执行可行性引导的树搜索，提出子目标转换，从成功和失败中预测成功概率，并在执行前修剪脆弱分支；System 1执行低层控制。采用分层强化学习形式，将失败作为结构化学习信号而非噪声监督。

Result: 在具有挑战性的操作任务中，该方法持续提高了成功率和鲁棒性，表明失败数据是将VLA的广泛能力转化为鲁棒执行的重要资源。

Conclusion: 通过利用失败数据并将其直接整合到决策循环中，VINE模型能够显著提高机器人操作的鲁棒性，证明了失败经验对于构建更可靠的视觉-语言-动作系统的重要性。

Abstract: Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.

</details>


### [68] [Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response](https://arxiv.org/abs/2512.03936)
*Aron Distelzweig,Yiwei Wang,Faris Janjoš,Marcel Hallgarten,Mihai Dobre,Alexander Langmann,Joschka Boedecker,Johannes Betz*

Main category: cs.RO

TL;DR: BIBeR框架将最先进的运动预测器与迭代最优响应循环结合，实现双向交互感知规划，在密集城市交通中比现有方法提升11%性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶规划系统在常规场景表现良好，但在密集城市交通中（如变道、汇入）仍面临挑战。现有方法要么简单丢弃不安全计划，要么使用端到端模型缺乏双向交互建模，而博弈论方法虽有理论优势但应用有限。

Method: 提出贝叶斯迭代最优响应（BIBeR）框架：1）将最先进的预测器集成到迭代最优响应循环中，反复优化自车和周围车辆策略；2）通过贝叶斯置信度估计量化预测可靠性，调节更新强度；3）近似纳什均衡，实现双向适应（自车既响应又影响其他车辆）。

Result: 在高度交互的interPlan变道场景中，BIBeR比最先进的规划器提升11%性能；在标准nuPlan基准测试中也优于现有方法。

Conclusion: BIBeR成功统一了运动预测和博弈论规划，结合了结构化规划的透明性和学习模型的灵活性，为密集城市交通中的交互感知规划提供了有效解决方案。

Abstract: Autonomous driving planning systems perform nearly perfectly in routine scenarios using lightweight, rule-based methods but still struggle in dense urban traffic, where lane changes and merges require anticipating and influencing other agents. Modern motion predictors offer highly accurate forecasts, yet their integration into planning is mostly rudimental: discarding unsafe plans. Similarly, end-to-end models offer a one-way integration that avoids the challenges of joint prediction and planning modeling under uncertainty. In contrast, game-theoretic formulations offer a principled alternative but have seen limited adoption in autonomous driving. We present Bayesian Iterative Best Response (BIBeR), a framework that unifies motion prediction and game-theoretic planning into a single interaction-aware process. BIBeR is the first to integrate a state-of-the-art predictor into an Iterative Best Response (IBR) loop, repeatedly refining the strategies of the ego vehicle and surrounding agents. This repeated best-response process approximates a Nash equilibrium, enabling bidirectional adaptation where the ego both reacts to and shapes the behavior of others. In addition, our proposed Bayesian confidence estimation quantifies prediction reliability and modulates update strength, more conservative under low confidence and more decisive under high confidence. BIBeR is compatible with modern predictors and planners, combining the transparency of structured planning with the flexibility of learned models. Experiments show that BIBeR achieves an 11% improvement over state-of-the-art planners on highly interactive interPlan lane-change scenarios, while also outperforming existing approaches on standard nuPlan benchmarks.

</details>


### [69] [MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation](https://arxiv.org/abs/2512.03958)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 提出MDE-AgriVLN方法，通过单目深度估计增强农业机器人的视觉语言导航能力，在A2A基准上显著提升成功率并降低导航误差。


<details>
  <summary>Details</summary>
Motivation: 农业机器人通常只配备单目摄像头，导致空间感知能力有限，而现有的农业视觉语言导航方法主要基于双目视觉，需要解决单目视觉下的导航性能问题。

Method: 提出MDE-AgriVLN方法，包含MDE模块从RGB图像生成深度特征，辅助决策模块进行推理，增强单目视觉下的空间感知能力。

Result: 在A2A基准测试中，成功率从0.23提升到0.32，导航误差从4.43米降低到4.08米，达到了农业VLN领域的最先进性能。

Conclusion: MDE-AgriVLN方法通过单目深度估计有效提升了农业机器人在视觉语言导航任务中的性能，为解决单目视觉下的农业导航问题提供了有效方案。

Abstract: Agricultural robots are serving as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily relying on manual operations or railway systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling a robot to navigate to a target position following a natural language instruction. Unlike human binocular vision, most agricultural robots are only given a single camera for monocular vision, which results in limited spatial perception. To bridge this gap, we present the method of Agricultural Vision-and-Language Navigation with Monocular Depth Estimation (MDE-AgriVLN), in which we propose the MDE module generating depth features from RGB images, to assist the decision-maker on reasoning. When evaluated on the A2A benchmark, our MDE-AgriVLN method successfully increases Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m, demonstrating the state-of-the-art performance in the agricultural VLN domain. Code: https://github.com/AlexTraveling/MDE-AgriVLN.

</details>


### [70] [Artificial Microsaccade Compensation: Stable Vision for an Ornithopter](https://arxiv.org/abs/2512.03995)
*Levi Burner,Guido de Croon,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: 提出人工微扫视补偿方法，用于稳定无尾扑翼飞行器拍摄的抖动视频，在实时处理中优于Adobe Premier Pro的变形稳定器


<details>
  <summary>Details</summary>
Motivation: 受生物微扫视现象启发，解决无尾扑翼飞行器因12-20Hz抖动而无法使用相机传感的问题，实现视频稳定化

Method: 通过优化SO(3)表示的三维旋转来最小化图像强度变化，实现无失真的视频稳定，并采用高效的递归更新机制

Result: 方法能实时生成适合人眼观看的稳定视频，在固定视角下显著减少帧间运动，质量优于Adobe Premier Pro的变形稳定器

Conclusion: 人工微扫视补偿方法有效解决了扑翼飞行器的视频稳定问题，在实时性和质量上都优于现有商业解决方案

Abstract: Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for "Artificial Microsaccade Compensation". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.

</details>
