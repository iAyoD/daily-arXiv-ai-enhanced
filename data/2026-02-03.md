<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 177]
- [cs.RO](#cs.RO) [Total: 86]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.00007)
*MinGyu Jeon,SuWan Cho,JaeYoung Shu*

Main category: cs.CL

TL;DR: PPoGA是一个基于知识图谱的问答框架，通过规划器-执行器架构和预测处理机制，结合自我修正能力，在复杂多跳问答任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM+KG方法在初始高层推理计划出错时容易失败，类似于认知功能固着问题，无法重新构建方法，导致追求不可行的解决方案。

Method: 提出PPoGA框架，采用规划器-执行器架构分离高层策略与低层执行，利用预测处理机制预测结果，核心创新是包含路径修正和计划修正的自我修正机制。

Result: 在三个具有挑战性的多跳KGQA基准测试（GrailQA、CWQ、WebQSP）上进行广泛实验，PPoGA实现了最先进的性能，显著优于现有方法。

Conclusion: 研究表明元认知能力（如问题重构）对于构建更强大和灵活的AI推理系统至关重要，PPoGA通过自我修正机制增强了KGQA的鲁棒性和灵活性。

Abstract: Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive functional fixedness, prevents agents from restructuring their approach, leading them to pursue unworkable solutions. To address this, we propose PPoGA (Predictive Plan-on-Graph with Action), a novel KGQA framework inspired by human cognitive control and problem-solving. PPoGA incorporates a Planner-Executor architecture to separate high-level strategy from low-level execution and leverages a Predictive Processing mechanism to anticipate outcomes. The core innovation of our work is a self-correction mechanism that empowers the agent to perform not only Path Correction for local execution errors but also Plan Correction by identifying, discarding, and reformulating the entire plan when it proves ineffective. We conduct extensive experiments on three challenging multi-hop KGQA benchmarks: GrailQA, CWQ, and WebQSP. The results demonstrate that PPoGA achieves state-of-the-art performance, significantly outperforming existing methods. Our work highlights the critical importance of metacognitive abilities like problem restructuring for building more robust and flexible AI reasoning systems.

</details>


### [2] [Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA](https://arxiv.org/abs/2602.00009)
*Samuel Thio,Matthew Lewis,Spiros Denaxas,Richard JB Dobson*

Main category: cs.CL

TL;DR: MediGRAF是一个混合图检索增强框架，通过结合结构化数据查询（Neo4j Text2Cypher）和非结构化语义检索（向量嵌入），实现完整的患者旅程自然语言查询，在临床信息检索中表现出色。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录系统包含大量临床信息，给临床医生带来认知负担，关键细节容易被忽略。虽然大语言模型在数据处理方面有潜力，但在临床环境中存在上下文基础和幻觉问题。现有解决方案通常只关注结构化数据或非结构化语义搜索，无法同时整合两者。

Method: 提出MediGRAF混合图RAG系统，独特地结合Neo4j Text2Cypher能力进行结构化关系遍历和向量嵌入进行非结构化叙述检索。使用MIMIC-IV数据集的10名患者数据（生成5,973个节点和5,963个关系），构建患者级别的问答系统。

Result: 事实查询实现100%召回率（所有相关信息都被检索并输出），复杂推理任务获得平均专家质量评分4.25/5（满分5分），且零安全违规。结果表明混合图基础显著推进临床信息检索。

Conclusion: 混合图基础为临床信息检索提供了更安全、更全面的替代方案，相比标准LLM部署有显著优势，能够更好地支持临床决策。

Abstract: Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative potential for data processing, they face significant limitations in clinical settings, particularly regarding context grounding and hallucinations. Current solutions typically isolate retrieval methods focusing either on structured data (SQL/Cypher) or unstructured semantic search but fail to integrate both simultaneously. This work presents MediGRAF (Medical Graph Retrieval Augmented Framework), a novel hybrid Graph RAG system that bridges this gap. By uniquely combining Neo4j Text2Cypher capabilities for structured relationship traversal with vector embeddings for unstructured narrative retrieval, MediGRAF enables natural language querying of the complete patient journey. Using 10 patients from the MIMIC-IV dataset (generating 5,973 nodes and 5,963 relationships), we generated enough nodes and data for patient level question answering (QA), and we evaluated this architecture across varying query complexities. The system demonstrated 100\% recall for factual queries which means all relevant information was retrieved and in the output, while complex inference tasks achieved a mean expert quality score of 4.25/5 with zero safety violations. These results demonstrate that hybrid graph-grounding significantly advances clinical information retrieval, offering a safer, more comprehensive alternative to standard LLM deployments.

</details>


### [3] [G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models](https://arxiv.org/abs/2602.00015)
*Xun Xu*

Main category: cs.CL

TL;DR: G-MemLLM：一种记忆增强的LLM架构，通过GRU风格的门控更新逻辑在潜在记忆库中动态管理信息，显著提升多跳推理和长期事实一致性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM受限于有限的上下文窗口，在多跳推理中难以保持长期事实一致性。现有方法（如上下文压缩或循环标记）存在"上下文腐化"或信息稀释问题，需要更有效的长期记忆机制。

Method: 提出G-MemLLM架构，将冻结的LLM主干与可训练的潜在记忆库相结合。核心创新是GRU风格的门控更新逻辑，允许模型选择性更新、保留或覆盖潜在记忆槽，避免循环系统中常见的知识梯度消失问题。

Result: 在GPT-2 (124M)到Llama 3.1 (8B)不同规模模型上，在HotpotQA和ZsRE基准测试中表现优异：Llama 3.1-8B在ZsRE上准确率提升13.3%；GPT-2在HotpotQA上答案F1提升8.56分；Llama 3.1-8B在HotpotQA上支持事实F1提升6.89分。

Conclusion: G-MemLLM通过门控记忆机制有效解决了LLM长期记忆和事实一致性问题，在不同规模模型上均能显著提升多跳推理性能，为增强LLM的长期推理能力提供了有效方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consistency during multi-hop reasoning. While existing methods utilize context compression or recurrent tokens, they often suffer from ``context rot'' or the dilution of information over long horizons. In this paper, we propose \textbf{G-MemLLM}, a memory-augmented architecture that integrates a frozen LLM backbone with a trainable \textbf{Latent Memory Bank}. Our key innovation is a GRU-style gated update logic that allows the model to selectively update, preserve, or overwrite latent memory slots, preventing the vanishing gradients of knowledge common in recurrent systems. We evaluate G-MemLLM across scales, from GPT-2 (124M) to Llama 3.1 (8B), on the HotpotQA and Zero-Shot Relation Extraction (ZsRE) benchmarks. Our results demonstrate that G-MemLLM significantly enhances multi-hop reasoning and relational precision, achieving a 13.3\% accuracy boost on ZsRE for Llama 3.1-8B, and it also yields improvements across model scales, boosting Answer F1 by 8.56 points for GPT-2 and increasing Supporting Fact F1 by 6.89 points for Llama 3.1-8B on HotpotQA.

</details>


### [4] [PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems](https://arxiv.org/abs/2602.00016)
*Jiongchi Yu,Yuhan Ma,Xiaoyu Zhang,Junjie Wang,Qiang Hu,Chao Shen,Xiaofei Xie*

Main category: cs.CL

TL;DR: PTCBENCH是一个评估大语言模型人格一致性的基准测试，通过12种不同情境测试发现外部场景（如失业）会显著改变LLM的人格特质和推理能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在情感代理和AI系统中的部署增加，保持一致和真实的人格对于用户信任和参与至关重要。现有研究忽略了人格特质是动态和情境依赖的基本心理学共识。

Method: 引入PTCBENCH基准，通过12种不同的外部条件（位置情境和生活事件）对模型进行测试，使用NEO五因素量表严格评估人格特质，分析了39,240个人格特质记录。

Result: 研究发现某些外部场景（如"失业"）会触发LLM显著的人格变化，甚至改变其推理能力。建立了可扩展的框架来评估现实演化环境中的人格一致性。

Conclusion: PTCBENCH为评估人格一致性提供了可扩展框架，为开发稳健且心理对齐的AI系统提供了可操作的见解。

Abstract: With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental psychological consensus that personality traits are dynamic and context-dependent. To bridge this gap, we introduce PTCBENCH, a systematic benchmark designed to quantify the consistency of LLM personalities under controlled situational contexts. PTCBENCH subjects models to 12 distinct external conditions spanning diverse location contexts and life events, and rigorously assesses the personality using the NEO Five-Factor Inventory. Our study on 39,240 personality trait records reveals that certain external scenarios (e.g., "Unemployment") can trigger significant personality changes of LLMs, and even alter their reasoning capabilities. Overall, PTCBENCH establishes an extensible framework for evaluating personality consistency in realistic, evolving environments, offering actionable insights for developing robust and psychologically aligned AI systems.

</details>


### [5] [SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations](https://arxiv.org/abs/2602.00017)
*Benyamin Tabarsi,Wenbo Li,Tahreem Yasir,Aryan Santhosh Kumar,Laura Widman,Dongkuan Xu,Tiffany Barnes*

Main category: cs.CL

TL;DR: SafeTalkCoach是一个多样性驱动的多智能体对话生成框架，用于模拟家长与孩子关于性健康的对话，并附带数据集，旨在解决现实对话数据稀缺和LLM生成对话缺乏真实性与多样性的问题。


<details>
  <summary>Details</summary>
Motivation: 家长与孩子关于性健康的有效沟通很重要，但由于话题的私密性和敏感性，真实对话数据稀缺且难以收集。现有LLM生成的对话可能偏离最佳实践，缺乏真实性和多样性。

Method: SafeTalkCoach采用多样性驱动的多智能体对话生成框架，整合了众包和合成的场景、既定性健康指南、基于证据的人物角色、自适应控制模块和层次化多样化策略。

Result: 评估表明，SafeTalkCoach能够生成多样化的对话，同时在实践中保持真实性、沟通质量和可控性。

Conclusion: SafeTalkCoach框架和数据集旨在支持AI研究和健康沟通实践，为解决性健康教育中的对话生成挑战提供了有效工具。

Abstract: The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been widely adopted in dialogue generation, they may deviate from best practices and frequently lack realism and diversity. We introduce SafeTalkCoach, a diversity-driven multi-agent dialogue generation framework that simulates parent-child conversations about sexual health, and present an accompanying dataset. SafeTalkCoach integrates crowd-sourced and synthesized scenarios, established sexual health guidelines, evidence-based personas, adaptive control modules, and hierarchical diversification. Through evaluations, we demonstrate that SafeTalkCoach generates diverse conversations while maintaining realism, communication quality, and controllability in practice. Our goal is that the SafeTalkCoach framework and the dataset support both AI research and health communications practices.

</details>


### [6] [Construct, Align, and Reason: Large Ontology Models for Enterprise Knowledge Management](https://arxiv.org/abs/2602.00029)
*Yao Zhang,Hongyin Zhu*

Main category: cs.CL

TL;DR: 提出大型本体模型(LOM)框架，通过构建-对齐-推理三阶段方法解决企业知识管理中多源异构数据整合与语义推理问题，在4B参数规模下达到89.47%准确率，优于DeepSeek-V3.2。


<details>
  <summary>Details</summary>
Motivation: 企业级知识管理面临多源异构数据整合困难、传统知识图谱在隐式关系发现和复杂问答语义理解不足的问题，需要新的框架来融合本体结构和语言能力。

Method: 提出构建-对齐-推理统一框架：1)从结构化数据库和非结构化文本构建双层企业本体；2)三阶段训练：本体指令微调提升结构理解、文本-本体对齐增强节点语义编码、多任务指令调优结合课程学习；3)构建全面的训练和评估数据集。

Result: 4B参数的LOM模型在基准测试中达到89.47%准确率，在复杂图推理任务上优于DeepSeek-V3.2，表明本体结构与语言的有效融合。

Conclusion: LOM框架成功解决了企业知识管理中多源数据整合和语义推理的挑战，通过统一的本体-语言融合方法实现了高效的知识表示和推理能力。

Abstract: Enterprise-scale knowledge management faces significant challenges in integrating multi-source heterogeneous data and enabling effective semantic reasoning. Traditional knowledge graphs often struggle with implicit relationship discovery and lack sufficient semantic understanding for complex question answering. To address these limitations, we introduce a unified construct--align--reason framework, the large ontology model (LOM). We first build a dual-layer enterprise ontology from structured databases and unstructured text, subsequently fusing these sources into a comprehensive enterprise ontology. To enable instruction-aligned reasoning, we propose a unified three-stage training pipeline: ontology instruction fine-tuning to improve structural understanding; text-ontology grounding to strengthen node semantic encoding; and multi-task instruction tuning on ontology-language pairs with curriculum learning to enhance semantic reasoning and generation. We also construct comprehensive training and evaluation datasets covering diverse ontology reasoning tasks. On this benchmark, our 4B-parameter LOM achieves 89.47% accuracy and outperforms DeepSeek-V3.2 on complex graph reasoning, indicating effective fusion of ontology structure and language.

</details>


### [7] [Reversible Diffusion Decoding for Diffusion Language Models](https://arxiv.org/abs/2602.00150)
*Xinyun Wang,Min Zhang,Sen Cui,Zhikang Chen,Bo Jiang,Kun Kuang,Mingbao Lin*

Main category: cs.CL

TL;DR: 提出RDD（可逆扩散解码）框架，通过引入可逆性解决扩散语言模型块解码中的停滞问题，允许回溯并重新初始化不确定标记，提高生成鲁棒性


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型通过块解码实现并行生成，但不可逆的承诺会导致停滞问题——当上下文不理想时，反向扩散过程无法继续进展

Method: RDD框架：1) 检测停滞作为反向过程的依赖状态失败；2) 通过缓存模型状态实现高效回溯到早期块；3) 应用置信度引导的重新掩码，选择性重新初始化不确定标记，同时保留可靠上下文

Result: 实验表明RDD在最小计算开销下，相比基线方法提高了生成鲁棒性和质量

Conclusion: RDD的可逆公式允许解码从早期承诺错误中恢复，同时保持基于扩散生成的并行效率，解决了扩散语言模型块解码中的关键问题

Abstract: Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose Reversible Diffusion Decoding (RDD), a decoding framework that introduces reversibility into block-wise diffusion generation. RDD detects stagnation as a state-dependent failure of the reverse process and enables efficient backtracking to earlier blocks without recomputation via cached model states. To avoid repeated failure trajectories, RDD applies confidence-guided re-masking to selectively reinitialize uncertain tokens while preserving reliable context.This reversible formulation allows decoding to recover from early commitment errors while maintaining the parallel efficiency of diffusion-based generation. Experiments show that RDD improves generation robustness and quality over baselines with minimal computational overhead.

</details>


### [8] [DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking](https://arxiv.org/abs/2602.00238)
*Tianyi Hu,Niket Tandon,Akhil Arora*

Main category: cs.CL

TL;DR: DIVERGE是一个即插即用的代理式RAG框架，通过反思引导生成和记忆增强迭代优化，解决现有RAG系统在开放式问题中多样性不足的问题，实现了多样性与质量的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统假设每个查询只有一个正确答案，忽视了常见信息寻求场景中存在多个合理答案的情况。标准RAG系统未能充分利用检索上下文的多样性，即使增加检索多样性也无法产生多样化的生成结果，这限制了创造力并损害了公平包容的信息获取。

Method: 提出DIVERGE框架，包含反思引导生成和记忆增强迭代优化机制。该框架是即插即用的代理式RAG系统，通过新颖的反思机制促进多样化观点生成，同时保持答案质量。

Result: 在真实世界的Infinity-Chat数据集上，DIVERGE相比竞争基线和先前最先进方法实现了最佳的多样性-质量权衡，显著提高了多样性同时保持了质量。提出的新评估指标与人类判断有良好相关性。

Conclusion: 研究揭示了当前基于LLM的系统在开放式信息寻求中的系统性局限，表明明确建模多样性可以缓解这一问题。DIVERGE框架为解决RAG系统中的多样性不足问题提供了有效方案。

Abstract: Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is essential to avoid collapsing to a single dominant response, thereby constraining creativity and compromising fair and inclusive information access. Our analysis reveals a commonly overlooked limitation of standard RAG systems: they underutilize retrieved context diversity, such that increasing retrieval diversity alone does not yield diverse generations. To address this limitation, we propose DIVERGE, a plug-and-play agentic RAG framework with novel reflection-guided generation and memory-augmented iterative refinement, which promotes diverse viewpoints while preserving answer quality. We introduce novel metrics tailored to evaluating the diversity-quality trade-off in open-ended questions, and show that they correlate well with human judgments. We demonstrate that DIVERGE achieves the best diversity-quality trade-off compared to competitive baselines and previous state-of-the-art methods on the real-world Infinity-Chat dataset, substantially improving diversity while maintaining quality. More broadly, our results reveal a systematic limitation of current LLM-based systems for open-ended information-seeking and show that explicitly modeling diversity can mitigate it. Our code is available at: https://github.com/au-clan/Diverge

</details>


### [9] [Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering](https://arxiv.org/abs/2602.00279)
*Philip Müller,Nicholas Popovič,Michael Färber,Peter Steinbach*

Main category: cs.CL

TL;DR: 该论文首次大规模评估LLM在科学问答中的不确定性量化方法，发现指令微调导致概率极化降低置信度可靠性，而答案频率是最可靠的校准方法。


<details>
  <summary>Details</summary>
Motivation: LLM在科学问答中广泛应用，但现有不确定性量化方法在该领域验证不足，需要可靠的不确定性量化来建立对生成答案的信任。

Method: 构建首个大规模基准评估不确定性量化指标，涵盖20个LLM模型和7个科学问答数据集，评估685,000个长格式回答，比较不同不确定性量化方法。

Result: 指令微调导致概率质量极化，降低token级置信度可靠性；口头化方法存在系统性偏差，答案频率（跨样本一致性）提供最可靠的校准；ECE作为单一评估指标具有误导性。

Conclusion: 当前LLM不确定性量化方法存在严重局限性，标准基准评估实践需要改进，答案频率是最有效的校准方法，为科学问答中的可靠不确定性量化提供了重要见解。

Abstract: Large Language Models (LLMs) are commonly used in Question Answering (QA) settings, increasingly in the natural sciences if not science at large. Reliable Uncertainty Quantification (UQ) is critical for the trustworthy uptake of generated answers. Existing UQ approaches remain weakly validated in scientific QA, a domain relying on fact-retrieval and reasoning capabilities. We introduce the first large-scale benchmark for evaluating UQ metrics in reasoning-demanding QA studying calibration of UQ methods, providing an extensible open-source framework to reproducibly assess calibration. Our study spans up to 20 large language models of base, instruction-tuned and reasoning variants. Our analysis covers seven scientific QA datasets, including both multiple-choice and arithmetic question answering tasks, using prompting to emulate an open question answering setting. We evaluate and compare methods representative of prominent approaches on a total of 685,000 long-form responses, spanning different reasoning complexities representative of domain-specific tasks. At the token level, we find that instruction tuning induces strong probability mass polarization, reducing the reliability of token-level confidences as estimates of uncertainty. Models further fine-tuned for reasoning are exposed to the same effect, but the reasoning process appears to mitigate it depending on the provider. At the sequence level, we show that verbalized approaches are systematically biased and poorly correlated with correctness, while answer frequency (consistency across samples) yields the most reliable calibration. In the wake of our analysis, we study and report the misleading effect of relying exclusively on ECE as a sole measure for judging performance of UQ methods on benchmark datasets. Our findings expose critical limitations of current UQ methods for LLMs and standard practices in benchmarking thereof.

</details>


### [10] [Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models](https://arxiv.org/abs/2602.00300)
*Xilin Gong,Shu Yang,Zehua Cao,Lynne Billard,Di Wang*

Main category: cs.CL

TL;DR: 本文发现Patchscopes框架在解释LLM隐藏表示时存在系统性不忠实问题，LLM倾向于依赖固有语言模式而非上下文信息，并提出BALOR方法通过logit重新校准来抑制模型偏见、增强上下文信息。


<details>
  <summary>Details</summary>
Motivation: Patchscopes框架使用LLM自身解码隐藏表示生成人类可读解释，但研究发现LLM在解码时倾向于依赖固有语言模式而非上下文信息，导致解释不忠实。例如，即使隐藏表示编码了"紫色"的上下文属性，LLM仍会生成"绿色"的固有联想。

Method: 首先设计数据集评估Patchscopes在偏见情况下的忠实性，发现平均忠实性下降18.84%。然后提出BALOR方法：将未修补提示的输出logits视为模型偏见，与修补上下文信息后的logits对比，通过重新校准logit分布来抑制模型偏见、放大上下文信息。

Result: 实验表明BALOR在多个LLM上一致优于现有基线，实现高达33%的相对性能提升。该方法有效解决了Patchscopes框架中的系统性不忠实问题。

Conclusion: LLM在解码隐藏表示时存在系统性偏见问题，BALOR通过logit重新校准有效抑制模型固有偏见、增强上下文信息，显著提升了Patchscopes解释的忠实性。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representations. However, our work shows that LLMs tend to rely on inherent linguistic patterns, which can override contextual information encoded in the hidden representations during decoding. For example, even when a hidden representation encodes the contextual attribute "purple" for "broccoli", LLMs still generate "green" in their explanations, reflecting a strong prior association. This behavior reveals a systematic unfaithfulness in Patchscopes. To systematically study this issue, we first designed a dataset to evaluate the faithfulness of Patchscopes under biased cases, and our results show that there is an 18.84\% faithfulness decrease on average. We then propose Bias Alignment through Logit Recalibration (BALOR), which treats the output logits from an unpatched prompt as capturing model bias and contrasts them with logits obtained under patched contextual information. By recalibrating the logit distribution through this contrast, BALOR suppresses model bias and amplifies contextual information during generation. Experiments across multiple LLMs demonstrate that BALOR consistently outperforms existing baselines, achieving up to 33\% relative performance improvement.

</details>


### [11] [MiNER: A Two-Stage Pipeline for Metadata Extraction from Municipal Meeting Minutes](https://arxiv.org/abs/2602.00316)
*Rodrigo Batista,Luís Filipe Cunha,Purificação Silvano,Nuno Guimarães,Alípio Jorge,Evelin Amorim,Ricardo Campos*

Main category: cs.CL

TL;DR: 提出兩階段管線從市政會議記錄中提取元數據：先用問答模型定位元數據段落，再用Transformer模型進行細粒度實體提取，並評估開源與閉源LLM的性能、成本和碳足跡。


<details>
  <summary>Details</summary>
Motivation: 市政會議記錄作為地方治理的官方文件，格式和寫作風格各異，缺乏標準化。現有的命名實體識別模型不適用於這種領域特定的類別，需要專門的解決方案來有效提取會議編號、日期、地點、參與者等元數據。

Method: 提出兩階段管線：1) 使用問答模型識別包含元數據的開頭和結尾文本段落；2) 應用基於Transformer的模型（BERTimbau和XLM-RoBERTa，有/無CRF層）進行細粒度實體提取，並通過去詞彙化增強性能。

Result: 結果顯示在領域內表現優異，優於更大的通用LLM。但跨市政評估顯示泛化能力有限，反映了市政記錄的變異性和語言複雜性。建立了市政會議記錄元數據提取的首個基準。

Conclusion: 本研究為市政會議記錄元數據提取建立了首個基準，為該領域的未來研究提供了堅實基礎。雖然在特定領域表現良好，但跨市政泛化能力仍需改進，反映了市政文檔的複雜性。

Abstract: Municipal meeting minutes are official documents of local governance, exhibiting heterogeneous formats and writing styles. Effective information retrieval (IR) requires identifying metadata such as meeting number, date, location, participants, and start/end times, elements that are rarely standardized or easy to extract automatically. Existing named entity recognition (NER) models are ill-suited to this task, as they are not adapted to such domain-specific categories. In this paper, we propose a two-stage pipeline for metadata extraction from municipal minutes. First, a question answering (QA) model identifies the opening and closing text segments containing metadata. Transformer-based models (BERTimbau and XLM-RoBERTa with and without a CRF layer) are then applied for fine-grained entity extraction and enhanced through deslexicalization. To evaluate our proposed pipeline, we benchmark both open-weight (Phi) and closed-weight (Gemini) LLMs, assessing predictive performance, inference cost, and carbon footprint. Our results demonstrate strong in-domain performance, better than larger general-purpose LLMs. However, cross-municipality evaluation reveals reduced generalization reflecting the variability and linguistic complexity of municipal records. This work establishes the first benchmark for metadata extraction from municipal meeting minutes, providing a solid foundation for future research in this domain.

</details>


### [12] [Detecting AI-Generated Content in Academic Peer Reviews](https://arxiv.org/abs/2602.00319)
*Siyuan Shen,Kai Wang*

Main category: cs.CL

TL;DR: 研究发现AI生成内容在学术同行评审中快速增长，2025年ICLR约20%、Nature Communications约12%的评审被检测为AI生成，2024年第三到第四季度增长最显著。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的普及，研究AI生成内容在学术同行评审中的出现情况，探讨其对学术评价的影响。

Method: 使用基于历史评审数据训练的检测模型，分析ICLR和Nature Communications期刊后期评审周期中的AI生成内容，观察时间趋势。

Result: 2022年前AI生成内容极少，随后显著增加，2025年ICLR约20%、Nature Communications约12%的评审被分类为AI生成，2024年第三到第四季度增长最明显。

Conclusion: AI辅助内容在同行评审中快速增长，需要进一步研究其对学术评价的影响。

Abstract: The growing availability of large language models (LLMs) has raised questions about their role in academic peer review. This study examines the temporal emergence of AI-generated content in peer reviews by applying a detection model trained on historical reviews to later review cycles at International Conference on Learning Representations (ICLR) and Nature Communications (NC). We observe minimal detection of AI-generated content before 2022, followed by a substantial increase through 2025, with approximately 20% of ICLR reviews and 12% of Nature Communications reviews classified as AI-generated in 2025. The most pronounced growth of AI-generated reviews in NC occurs between the third and fourth quarter of 2024. Together, these findings provide suggestive evidence of a rapidly increasing presence of AI-assisted content in peer review and highlight the need for further study of its implications for scholarly evaluation.

</details>


### [13] [DETOUR: An Interactive Benchmark for Dual-Agent Search and Reasoning](https://arxiv.org/abs/2602.00352)
*Li Siyan,Darshan Deshpande,Anand Kannappan,Rebecca Qian*

Main category: cs.CL

TL;DR: DETOUR是一个双代理评估基准，用于模拟"舌尖现象"的多轮信息检索过程，包含1011个提示，测试模型在信息不明确情况下的检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估代理在"舌尖现象"搜索过程中的基准仅限于单轮设置，无法真实模拟人们在对话中通过多轮交互回忆信息的过程。

Method: 设计了DETOUR双代理评估基准，包含一个被评估的主要代理（Primary Agent）和一个保持一致的记忆代理（Memory Agent）。主要代理需要通过查询记忆代理来识别回忆的实体，模拟多轮交互的搜索过程。

Result: 当前最先进的模型在该基准上表现不佳，在所有模态（文本、图像、音频、视频）上仅达到36%的准确率，表明模型在信息不明确场景下的能力仍有待提升。

Conclusion: DETOUR基准能够更真实地评估模型在"舌尖现象"搜索过程中的能力，揭示了当前模型在信息不明确的多轮检索场景中的局限性，强调了增强这类能力的重要性。

Abstract: When recalling information in conversation, people often arrive at the recollection after multiple turns. However, existing benchmarks for evaluating agent capabilities in such tip-of-the-tongue search processes are restricted to single-turn settings. To more realistically simulate tip-of-the-tongue search, we introduce Dual-agent based Evaluation Through Obscure Under-specified Retrieval (DETOUR), a dual-agent evaluation benchmark containing 1,011 prompts. The benchmark design involves a Primary Agent, which is the subject of evaluation, tasked with identifying the recollected entity through querying a Memory Agent that is held consistent across evaluations. Our results indicate that current state-of-the-art models still struggle with our benchmark, only achieving 36% accuracy when evaluated on all modalities (text, image, audio, and video), highlighting the importance of enhancing capabilities in underspecified scenarios.

</details>


### [14] [DecompressionLM: Deterministic, Diagnostic, and Zero-Shot Concept Graph Extraction from Language Models](https://arxiv.org/abs/2602.00377)
*Zhaochen Hong,Jiaxuan You*

Main category: cs.CL

TL;DR: 提出DecompressionLM框架，用于零样本概念图提取，无需预定义查询或跨序列共享状态，评估压缩模型的知识覆盖度


<details>
  <summary>Details</summary>
Motivation: 现有知识探测方法依赖预定义查询，只能提取已知概念，且存在跨序列耦合、竞争解码抑制长尾概念、可扩展性限制等问题

Method: 使用Van der Corput低差异序列和算术解码，实现无跨序列共享状态的确定性并行生成框架

Result: 发现激活感知量化(AWQ-4bit)将概念覆盖度提升30-170%，而均匀量化(GPTQ-Int4)导致71-86%覆盖度崩溃；MMLU-Pro Law模型存在17点幻觉差距

Conclusion: DecompressionLM建立了概念覆盖度作为评估压缩模型知识广度和事实基础的新维度，对模型部署有重要意义

Abstract: Existing knowledge probing methods rely on pre-defined queries, limiting extraction to known concepts. We introduce DecompressionLM, a stateless framework for zero-shot concept graph extraction that discovers what language models encode without pre-specified queries or shared cross-sequence state. Our method targets three limitations of common decoding-based probing approaches: cross-sequence coupling that concentrates probability mass on high-frequency prefixes, competitive decoding effects that suppress long-tail concepts, and scalability constraints arising from sequential exploration. Using Van der Corput low-discrepancy sequences with arithmetic decoding, DecompressionLM enables deterministic, embarrassingly parallel generation without shared state across sequences. Across two model families and five quantization variants, we find that activation-aware quantization (AWQ-4bit) expands concept coverage by 30-170%, while uniform quantization (GPTQ-Int4) induces 71-86% coverage collapse -- divergent behaviors not reliably reflected by explanation-level perplexity. Corpus-based verification further reveals a 17-point hallucination gap between top- and bottom-ranked MMLU-Pro Law models. DecompressionLM establishes concept coverage as a complementary evaluation dimension for assessing knowledge breadth and factual grounding in compressed models useful for their deployment.

</details>


### [15] [Clause-Internal or Clause-External? Testing Turkish Reflexive Binding in Adapted versus Chain of Thought Large Language Models](https://arxiv.org/abs/2602.00380)
*Sercan Karakaş*

Main category: cs.CL

TL;DR: 该研究评估了最先进的大语言模型是否能捕捉土耳其语反身代词的约束关系，发现两个模型在约束行为上存在显著差异：Trendyol-LLM表现出强烈的局部性偏好，而o1 Mini则几乎均匀分布选择。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型是否能够捕捉土耳其语反身代词（kendi和kendisi）的约束关系，这些代词在土耳其语中具有复杂的约束特性，需要区分局部和非局部先行词。

Method: 构建了100个平衡句子集，对比局部与非局部先行词。测试了两个系统：OpenAI的链式思维推理模型和基于LLaMA-2并在土耳其语数据上广泛微调的Trendyol-LLM-7B-base-v0.1。使用句子级困惑度和强制选择范式相结合的方法评估先行词选择。

Result: Trendyol-LLM在大约70%的试验中偏好局部约束，表现出强烈的局部性偏见；而o1 Mini在局部和长距离解读之间的选择几乎均匀分布。两个系统在约束行为上表现出显著对比。

Conclusion: 不同的大语言模型在捕捉土耳其语反身代词约束关系方面表现出显著差异，模型架构和训练数据（特别是语言特定的微调）对约束行为的捕捉有重要影响。

Abstract: This study evaluates whether state-of-the-art large language models capture the binding relations of Turkish reflexive pronouns. We construct a balanced set of 100 sentences that pit local against non-local antecedents for the reflexives kendi and kendisi, and test two contrasting systems: an OpenAI chain-of-thought model designed for multi-step reasoning and Trendyol-LLM-7B-base-v0.1, a LLaMA-2-derived model extensively fine-tuned on Turkish data. Antecedent choice is assessed using a combined sentence-level perplexity and forced-choice paradigm. Trendyol-LLM favours local bindings in approximately 70% of trials, exhibiting a strong locality bias, whereas o1 Mini distributes its choices almost evenly between local and long-distance readings, revealing a marked contrast in binding behaviour across the two systems.

</details>


### [16] [Segment-Level Attribution for Selective Learning of Long Reasoning Traces](https://arxiv.org/abs/2602.00425)
*Siyuan Wang,Yanchen Liu,Xiang Ren*

Main category: cs.CL

TL;DR: 该论文提出了一种基于集成梯度归因的段级选择性学习框架，通过识别推理轨迹中的重要片段进行选择性监督微调，提高大型推理模型的准确性和输出效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型生成的思维链中只有小部分对答案预测有实质性贡献，大部分包含重复或截断内容。这种输出冗余在监督微调后进一步传播，模型学习模仿冗长但无信息量的模式，可能降低性能。

Method: 使用集成梯度归因量化每个token对最终答案的影响，聚合为两个段级指标：归因强度（整体归因大小）和方向一致性（段内token归因方向的一致性）。基于这两个指标，提出段级选择性学习框架，识别具有高归因强度但中等一致性的重要片段（表明反思性而非浅层推理），对这些重要片段应用选择性SFT，同时对不重要片段进行损失掩码。

Result: 在多个模型和数据集上的实验表明，该方法提高了准确性和输出效率，能够从长推理轨迹中更有效地学习。

Conclusion: 通过选择性学习重要推理片段，可以减轻输出冗余问题，提高大型推理模型的效率和效果。

Abstract: Large Reasoning Models (LRMs) achieve strong reasoning performance by generating long chains of thought (CoTs), yet only a small fraction of these traces meaningfully contributes to answer prediction, while the majority contains repetitive or truncated content. Such output redundancy is further propagated after supervised finetuning (SFT), as models learn to imitate verbose but uninformative patterns, which can degrade performance. To this end, we incorporate integrated gradient attribution to quantify each token's influence on final answers and aggregate them into two segment-level metrics: (1) \textit{attribution strength} measures the overall attribution magnitude; and (2) \textit{direction consistency} captures whether tokens' attributions within a segment are uniformly positive or negative (high consistency), or a mixture of both (moderate consistency). Based on these two metrics, we propose a segment-level selective learning framework to identify important segments with high attribution strength but moderate consistency that indicate reflective rather than shallow reasoning. The framework then applies selective SFT on these important segments while masking loss for unimportant ones. Experiments across multiple models and datasets show that our approach improves accuracy and output efficiency, enabling more effective learning from long reasoning traces~\footnote{Code and data are available at https://github.com/SiyuanWangw/SegmentSelectiveSFT}.

</details>


### [17] [When Agents "Misremember" Collectively: Exploring the Mandela Effect in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2602.00428)
*Naen Xu,Hengyu An,Shuo Shi,Jinghuai Zhang,Chunyi Zhou,Changjiang Li,Tianyu Du,Zhihui Fu,Jun Wang,Shouling Ji*

Main category: cs.CL

TL;DR: 该研究提出了MANBENCH基准来评估LLM多智能体系统中的曼德拉效应，分析了影响因素并提出了缓解策略，平均减少74.40%的效应。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中智能体容易受到集体认知偏差的影响，特别是曼德拉效应（群体错误记忆现象），这限制了我们对记忆偏差的理解并引发伦理担忧。

Method: 提出MANBENCH基准，评估四种易受曼德拉效应影响的任务类型，使用五种不同智能体角色和记忆时间尺度的交互协议，测试多个LLM智能体，并提出提示级防御（认知锚定、来源审查）和模型级对齐防御策略。

Result: 在MANBENCH上评估多个LLM智能体，量化了曼德拉效应，分析了不同因素的影响，提出的缓解策略相比基线平均减少了74.40%的曼德拉效应。

Conclusion: 研究为开发更具韧性和伦理对齐的协作多智能体系统提供了有价值的见解，证明了曼德拉效应在多智能体系统中的存在，并提出了有效的缓解方法。

Abstract: Recent advancements in large language models (LLMs) have significantly enhanced the capabilities of collaborative multi-agent systems, enabling them to address complex challenges. However, within these multi-agent systems, the susceptibility of agents to collective cognitive biases remains an underexplored issue. A compelling example is the Mandela effect, a phenomenon where groups collectively misremember past events as a result of false details reinforced through social influence and internalized misinformation. This vulnerability limits our understanding of memory bias in multi-agent systems and raises ethical concerns about the potential spread of misinformation. In this paper, we conduct a comprehensive study on the Mandela effect in LLM-based multi-agent systems, focusing on its existence, causing factors, and mitigation strategies. We propose MANBENCH, a novel benchmark designed to evaluate agent behaviors across four common task types that are susceptible to the Mandela effect, using five interaction protocols that vary in agent roles and memory timescales. We evaluate agents powered by several LLMs on MANBENCH to quantify the Mandela effect and analyze how different factors affect it. Moreover, we propose strategies to mitigate this effect, including prompt-level defenses (e.g., cognitive anchoring and source scrutiny) and model-level alignment-based defense, achieving an average 74.40% reduction in the Mandela effect compared to the baseline. Our findings provide valuable insights for developing more resilient and ethically aligned collaborative multi-agent systems.

</details>


### [18] [What Matters to an LLM? Behavioral and Computational Evidences from Summarization](https://arxiv.org/abs/2602.00459)
*Yongxin Zhou,Changshun Wu,Philippe Mulhem,Didier Schwab,Maxime Peyrard*

Main category: cs.CL

TL;DR: LLMs在摘要生成中表现出一致的内部重要性判断模式，与早期基线模型不同，且模型家族比模型大小更能影响重要性判断模式。研究发现某些注意力头与重要性分布对齐，中晚期层能有效预测重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在摘要任务上达到SOTA，但其内部的信息重要性判断机制仍然不透明。研究者希望揭示LLMs在摘要生成中选择信息的内部标准，理解其优先级判断机制。

Method: 结合行为分析和计算分析：行为上，为每个文档生成长度控制的摘要，基于信息单元被选择的频率构建经验重要性分布；计算上，识别与重要性分布对齐的注意力头，分析不同层对重要性的预测能力。

Result: LLMs在重要性判断上表现出高度一致性，与pre-LLM基线显著不同；模型家族比模型大小对重要性模式的影响更大；某些注意力头与重要性分布良好对齐；中晚期层对重要性有强预测能力。

Conclusion: 研究初步揭示了LLMs在摘要任务中的信息优先级判断机制及其内部表征，为解释和控制这些模型的信息选择提供了路径。

Abstract: Large Language Models (LLMs) are now state-of-the-art at summarization, yet the internal notion of importance that drives their information selections remains hidden. We propose to investigate this by combining behavioral and computational analyses. Behaviorally, we generate a series of length-controlled summaries for each document and derive empirical importance distributions based on how often each information unit is selected. These reveal that LLMs converge on consistent importance patterns, sharply different from pre-LLM baselines, and that LLMs cluster more by family than by size. Computationally, we identify that certain attention heads align well with empirical importance distributions, and that middle-to-late layers are strongly predictive of importance. Together, these results provide initial insights into what LLMs prioritize in summarization and how this priority is internally represented, opening a path toward interpreting and ultimately controlling information selection in these models.

</details>


### [19] [Words that make SENSE: Sensorimotor Norms in Learned Lexical Token Representations](https://arxiv.org/abs/2602.00469)
*Abhinav Gupta,Toben H. Mintz,Jesse Thomason*

Main category: cs.CL

TL;DR: SENSE模型通过学习投影将词嵌入映射到传感器运动规范，预测人类感官运动关联，并在6个模态上与人类行为数据显著相关。


<details>
  <summary>Details</summary>
Motivation: 传统词嵌入仅基于共现模式，而人类语言理解根植于感官和运动经验，需要将词嵌入与传感器运动规范联系起来。

Method: 开发SENSE投影模型，从词嵌入预测Lancaster传感器运动规范；进行行为研究，让281名参与者从候选非词中选择具有特定传感器运动关联的词汇。

Result: SENSE评分与人类选择率在11个模态中的6个上存在统计显著相关；对非词选择率的亚词汇分析揭示了内感受规范的音素模式。

Conclusion: SENSE模型能够有效预测词汇的传感器运动关联，为从文本数据计算提出候选音素模式提供了路径。

Abstract: While word embeddings derive meaning from co-occurrence patterns, human language understanding is grounded in sensory and motor experience. We present $\text{SENSE}$ $(\textbf{S}\text{ensorimotor }$ $\textbf{E}\text{mbedding }$ $\textbf{N}\text{orm }$ $\textbf{S}\text{coring }$ $\textbf{E}\text{ngine})$, a learned projection model that predicts Lancaster sensorimotor norms from word lexical embeddings. We also conducted a behavioral study where 281 participants selected which among candidate nonce words evoked specific sensorimotor associations, finding statistically significant correlations between human selection rates and $\text{SENSE}$ ratings across 6 of the 11 modalities. Sublexical analysis of these nonce words selection rates revealed systematic phonosthemic patterns for the interoceptive norm, suggesting a path towards computationally proposing candidate phonosthemes from text data.

</details>


### [20] [Intention-Adaptive LLM Fine-Tuning for Text Revision Generation](https://arxiv.org/abs/2602.00477)
*Zhexiong Liu,Diane Litman*

Main category: cs.CL

TL;DR: 提出Intention-Tuning框架，通过动态选择LLM层学习意图表示并迁移到修订生成任务，在小规模修订语料上实现高效微调


<details>
  <summary>Details</summary>
Motivation: LLM在基于上下文的文本生成任务中表现优异，但在基于意图的生成任务（如修订生成）中应用不足。现有方法难以处理复杂的多意图场景，而全量微调需要大量标注数据，这在修订领域既昂贵又稀缺

Method: 提出Intention-Tuning框架：1）动态选择LLM层子集学习意图表示；2）将这些表示迁移到修订生成任务；3）在小规模修订语料上进行层级的自适应微调

Result: 实验结果表明Intention-Tuning在小规模修订语料上既有效又高效，优于多个参数高效微调基线方法

Conclusion: Intention-Tuning为解决LLM在意图相关生成任务中的挑战提供了一种有效且数据高效的解决方案，特别适用于标注数据稀缺的修订生成领域

Abstract: Large Language Models (LLMs) have achieved impressive capabilities in various context-based text generation tasks, such as summarization and reasoning; however, their applications in intention-based generation tasks remain underexplored. One such example is revision generation, which requires the generated text to explicitly reflect the writer's actual intentions. Identifying intentions and generating desirable revisions are challenging due to their complex and diverse nature. Although prior work has employed LLMs to generate revisions with few-shot learning, they struggle with handling entangled multi-intent scenarios. While fine-tuning LLMs using intention-based instructions appears promising, it demands large amounts of annotated data, which is expensive and scarce in the revision community. To address these challenges, we propose Intention-Tuning, an intention-adaptive layer-wise LLM fine-tuning framework that dynamically selects a subset of LLM layers to learn the intentions and subsequently transfers their representations to revision generation. Experimental results suggest that Intention-Tuning is effective and efficient on small revision corpora, outperforming several PEFT baselines.

</details>


### [21] [From Knowledge to Inference: Scaling Laws of Specialized Reasoning on GlobalHealthAtlas](https://arxiv.org/abs/2602.00491)
*Zhaokun Yan,Zhaohan Liu,Wuzheng Dong,Lijie Feng,Chengxiao Dai*

Main category: cs.CL

TL;DR: 提出了GlobalHealthAtlas数据集，包含28万+多语言公共卫生实例，涵盖15个领域和17种语言，分为三个难度级别，并设计了LLM辅助的质量控制流程和领域对齐评估器。


<details>
  <summary>Details</summary>
Motivation: 公共卫生推理需要基于科学证据、专家共识和安全约束的群体层面推断，但作为结构化机器学习问题研究不足，缺乏监督信号和基准测试。

Method: 1) 构建GlobalHealthAtlas数据集：从公开公共卫生资源收集280,210个实例，覆盖15个领域和17种语言，按健康素养到流行病学政策推理分三个难度级别；2) 设计LLM辅助的质量控制流程：包括检索、去重、证据基础检查和标签验证；3) 开发领域对齐评估器：从多样化LLM的高置信度判断中蒸馏，评估准确性、推理、完整性、共识对齐、术语规范和洞察力六个维度。

Result: 创建了大规模多语言公共卫生数据集，实现了可扩展的质量控制，并开发了多维度的评估框架，为安全关键的公共卫生推理提供了可重复的训练和评估基准。

Conclusion: 这些贡献使得能够在超越传统问答基准的安全关键公共卫生推理领域，对LLM进行可重复的训练和评估。

Abstract: Public health reasoning requires population level inference grounded in scientific evidence, expert consensus, and safety constraints. However, it remains underexplored as a structured machine learning problem with limited supervised signals and benchmarks. We introduce \textbf{GlobalHealthAtlas}, a large scale multilingual dataset of 280,210 instances spanning 15 public health domains and 17 languages, stratified into three difficulty levels from health literacy to epidemiological and policy reasoning. Instances are derived from openly available public health sources and labeled by language, domain, and difficulty to support supervised learning and slice based evaluation. We further propose large language model (LLM) assisted construction and quality control pipeline with retrieval, duplication, evidence grounding checks, and label validation to improve consistency at scale. Finally, we present a domain aligned evaluator distilled from high confidence judgments of diverse LLMs to assess outputs along six dimensions: Accuracy, Reasoning, Completeness, Consensus Alignment, Terminology Norms, and Insightfulness. Together, these contributions enable reproducible training and evaluation of LLMs for safety critical public health reasoning beyond conventional QA benchmarks.

</details>


### [22] [Culturally-Grounded Governance for Multilingual Language Models: Rights, Data Boundaries, and Accountable AI Design](https://arxiv.org/abs/2602.00497)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.CL

TL;DR: 多语言大语言模型(MLLMs)的治理框架存在英语中心主义问题，无法适应不同文化语言环境，需要建立文化基础的治理框架来应对数据不平等、规范错位和问责不足三大挑战。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大语言模型的治理框架主要基于英语中心的数据、同质化用户群体和抽象公平概念，这导致对低资源语言和文化边缘化社区的系统性风险。模型行为、数据实践和问责机制往往无法与当地规范、权利和期望保持一致。

Method: 本文综合了多语言模型行为、数据不对称和社会技术危害的现有证据，借鉴人机交互和AI治理中的跨文化视角，构建了一个文化基础的MLLMs治理框架。方法侧重于概念性分析而非技术基准。

Result: 识别出三个相互关联的治理挑战：1)训练数据和评估实践中的文化和语言不平等；2)全球部署与本地规范、价值观和权力结构之间的错位；3)针对边缘化语言社区所受危害的有限问责机制。

Conclusion: 多语言AI治理应重新定义为社会文化和基于权利的问题。需要建立文化基础的治理框架，包括数据管理、透明度和参与式问责的设计和政策影响，防止多语言模型在规模和中性幌子下复制现有全球不平等。

Abstract: Multilingual large language models (MLLMs) are increasingly deployed across cultural, linguistic, and political contexts, yet existing governance frameworks largely assume English-centric data, homogeneous user populations, and abstract notions of fairness. This creates systematic risks for low-resource languages and culturally marginalized communities, where data practices, model behavior, and accountability mechanisms often fail to align with local norms, rights, and expectations. Drawing on cross-cultural perspectives in human-centered computing and AI governance, this paper synthesizes existing evidence on multilingual model behavior, data asymmetries, and sociotechnical harm, and articulates a culturally grounded governance framework for MLLMs. We identify three interrelated governance challenges: cultural and linguistic inequities in training data and evaluation practices, misalignment between global deployment and locally situated norms, values, and power structures, and limited accountability mechanisms for addressing harms experienced by marginalized language communities. Rather than proposing new technical benchmarks, we contribute a conceptual agenda that reframes multilingual AI governance as a sociocultural and rights based problem. We outline design and policy implications for data stewardship, transparency, and participatory accountability, and argue that culturally grounded governance is essential for ensuring that multilingual language models do not reproduce existing global inequalities under the guise of scale and neutrality.

</details>


### [23] [Reasoning by Commented Code for Table Question Answering](https://arxiv.org/abs/2602.00543)
*Seho Pyo,Jiheon Seok,Jaejin Lee*

Main category: cs.CL

TL;DR: 提出一种带注释的逐步代码生成框架，通过将表格问答分解为多行可执行程序并添加自然语言注释，提高数值准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统表格线性化方法破坏了结构化数据的二维关系，现有基于端到端答案生成或单行程序查询的方法存在数值准确性有限和可解释性差的问题。

Method: 引入带注释的逐步代码生成框架，将表格问答推理分解为多行可执行Python程序，每行代码配有简洁的自然语言注释，增强推理清晰度和代码正确性。

Result: 在WikiTableQuestions基准测试中，使用Qwen2.5-Coder-7B-Instruct模型达到70.9%准确率，超越Repanda基线（67.6%）。与强大的端到端表格问答模型结合后，通过轻量级答案选择机制进一步提升至84.3%准确率。

Conclusion: 带注释的逐步代码生成框架能有效提升表格问答的数值准确性和可解释性，与现有模型结合可显著提升性能。

Abstract: Table Question Answering (TableQA) poses a significant challenge for large language models (LLMs) because conventional linearization of tables often disrupts the two-dimensional relationships intrinsic to structured data. Existing methods, which depend on end-to-end answer generation or single-line program queries, typically exhibit limited numerical accuracy and reduced interpretability. This work introduces a commented, step-by-step code-generation framework that incorporates explicit reasoning into the Python program-generation process. The approach decomposes TableQA reasoning into multi-line executable programs with concise natural language comments, thereby promoting clearer reasoning and increasing the likelihood of generating correct code. On the WikiTableQuestions benchmark, the proposed method achieves 70.9\% accuracy using Qwen2.5-Coder-7B-Instruct, surpassing the Repanda baseline (67.6\%). Integrating the proposed framework with a robust end-to-end TableQA model via a lightweight answer-selection mechanism yields further improvements. This combined approach achieves up to 84.3\% accuracy on the WikiTableQuestions benchmark.

</details>


### [24] [A Hierarchical and Attentional Analysis of Argument Structure Constructions in BERT Using Naturalistic Corpora](https://arxiv.org/abs/2602.00554)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

TL;DR: BERT模型处理四种基本论元结构构式时，在中间层形成最大可分离的聚类，早期层出现构式特定信息，后期层保持这种表示结构


<details>
  <summary>Details</summary>
Motivation: 研究BERT模型如何处理四种基本论元结构构式，探索模型内部对这些语言结构的表示机制

Method: 采用多维分析框架，包括MDS、t-SNE降维、广义判别值(GDV)作为聚类分离指标、费舍尔判别比(FDR)作为线性诊断探测，以及注意力机制分析

Result: 揭示了层次化的表示结构：构式特定信息在早期层出现，在中间层形成最大可分离的聚类，并在后期处理阶段保持这种表示

Conclusion: BERT模型对论元结构构式的处理呈现层次化组织，中间层是构式信息分离的关键阶段，为理解Transformer模型的语言处理机制提供了新见解

Abstract: This study investigates how the Bidirectional Encoder Representations from Transformers model processes four fundamental Argument Structure Constructions. We employ a multi-dimensional analytical framework, which integrates MDS, t-SNE as dimensionality reduction, Generalized Discrimination Value (GDV) as cluster separation metrics, Fisher Discriminant Ratio (FDR) as linear diagnostic probing, and attention mechanism analysis. Our results reveal a hierarchical representational structure. Construction-specific information emerges in early layers, forms maximally separable clusters in middle layers, and is maintained through later processing stages.

</details>


### [25] [The French Drama Revolution: Political Economy and Literary Production, 1700-1900](https://arxiv.org/abs/2602.00588)
*Thiago Dumont Oliveira*

Main category: cs.CL

TL;DR: 使用LDA和JS散度分析1700-1900年法国戏剧主题演变，发现法国大革命后戏剧主题分布发生深刻变化，资产阶级主题在18世纪末开始盛行，并与法国GDP增长呈现协同演化关系。


<details>
  <summary>Details</summary>
Motivation: 研究法国戏剧在1700-1900年间的演变，特别是法国大革命和工业化如何影响戏剧主题的变化，探索文化表达与社会经济变迁之间的关系。

Method: 使用潜在狄利克雷分配（LDA）进行主题建模，结合Jensen-Shannon散度测量主题分布变化，并将戏剧主题的年度流行度与法国GDP数据进行对比分析。

Result: 法国戏剧的主题分布在1789-1850年间发生深刻变化，资产阶级主题自18世纪末开始成为最流行主题之一，戏剧主题演变与法国经济增长呈现协同演化模式。

Conclusion: 法国大革命和工业化进程深刻改变了戏剧主题分布，资产阶级主题的兴起反映了社会经济结构的变迁，文化表达与经济发展之间存在密切的相互影响关系。

Abstract: This paper investigates the changing nature of French drama between 1700-1900 using Latent Dirichlet Allocation and Jensen-Shannon Divergence. Results indicate that the topical distribution of French drama changed profoundly after the French Revolution, particularly between 1789 and 1850. Bourgeois themes emerged among the most prevalent topics since the late 18th century. To assess the coevolution of drama and economic growth, I plot the yearly prevalence of topics alongside French GDP between 1700-1900, and discuss these changes in light of the political and economic changes prompted by the French Revolution and the industrialization of the country.

</details>


### [26] [Kanade: A Simple Disentangled Tokenizer for Spoken Language Modeling](https://arxiv.org/abs/2602.00594)
*Zhijie Huang,Stephen McIntosh,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.CL

TL;DR: Kanade是一种单层解耦语音分词器，能够分离声学常数，创建单一令牌流来捕捉丰富的语音和韵律信息，无需依赖现有解耦编解码器常用的辅助方法。


<details>
  <summary>Details</summary>
Motivation: 良好的语言模型始于良好的分词器。对于语音建模尤为重要，因为需要处理混合语言和非语言信息的连续信号。理想的语音分词器应提取语音和韵律，抑制说话人身份等语言无关信息，并支持高质量合成。

Method: Kanade采用单层解耦架构，通过分离声学常数创建单一令牌流来捕捉语音和韵律信息。该方法不需要现有解耦编解码器常用的辅助方法。

Result: 实验显示Kanade在说话人解耦和词汇可用性方面达到最先进水平，同时保持优秀的重建质量。

Conclusion: Kanade实现了理想的语音分词器设计，能够有效分离语言相关信息，为语音建模提供了高质量的基础组件。

Abstract: A good language model starts with a good tokenizer. Tokenization is especially important for speech modeling, which must handle continuous signals that mix linguistic and non-linguistic information. A speech tokenizer should extract phonetics and prosody, suppress linguistically irrelevant information like speaker identity, and enable high-quality synthesis. We present Kanade, a single-layer disentangled speech tokenizer that realizes this ideal. Kanade separates out acoustic constants to create a single stream of tokens that captures rich phonetics and prosody. It does so without the need for auxiliary methods that existing disentangled codecs often rely on. Experiments show that Kanade achieves state-of-the-art speaker disentanglement and lexical availability, while maintaining excellent reconstruction quality.

</details>


### [27] [Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling](https://arxiv.org/abs/2602.00597)
*Chaoqun Cui,Shijing Wang,Liangbin Huang,Qingqing Gu,Zhaolong Huang,Xiao Zeng,Wenji Mao*

Main category: cs.CL

TL;DR: Hermes是一个基于大语言模型的自动字幕翻译框架，通过说话人分割、术语识别和表达增强三个模块，解决了字幕翻译中的语义连贯性、代词术语翻译和表达力等挑战。


<details>
  <summary>Details</summary>
Motivation: 跨语言字幕翻译在娱乐本地化中至关重要，但尚未在机器翻译中得到充分探索。虽然大语言模型显著提升了机器翻译能力，但字幕文本的独特特性（如语义连贯性、代词术语翻译、翻译表达力）仍然存在挑战。

Method: 提出Hermes框架，包含三个核心模块：1) 说话人分割模块，识别不同说话者；2) 术语识别模块，准确翻译专业术语；3) 表达增强模块，提升翻译的表达力和自然度。

Result: 实验表明，Hermes在说话人分割方面达到最先进性能，并能生成表达力强、上下文连贯的翻译，推动了跨语言字幕翻译的研究进展。

Conclusion: Hermes框架有效解决了字幕翻译中的关键挑战，为跨语言字幕翻译提供了有效的自动化解决方案，展示了LLM在该领域的应用潜力。

Abstract: Interlingual subtitling, which translates subtitles of visual media into a target language, is essential for entertainment localization but has not yet been explored in machine translation. Although Large Language Models (LLMs) have significantly advanced the general capabilities of machine translation, the distinctive characteristics of subtitle texts pose persistent challenges in interlingual subtitling, particularly regarding semantic coherence, pronoun and terminology translation, and translation expressiveness. To address these issues, we present Hermes, an LLM-based automated subtitling framework. Hermes integrates three modules: Speaker Diarization, Terminology Identification, and Expressiveness Enhancement, which effectively tackle the above challenges. Experiments demonstrate that Hermes achieves state-of-the-art diarization performance and generates expressive, contextually coherent translations, thereby advancing research in interlingual subtitling.

</details>


### [28] [Lookahead-then-Verify: Reliable Constrained Decoding for Diffusion LLMs under Context-Free Grammars](https://arxiv.org/abs/2602.00612)
*Yitong Zhang,Yongmin Li,Yuetong Liu,Jia Li,Xiaoran Jia,Zherui Li,Ge Li*

Main category: cs.CL

TL;DR: LAVE是一种专为扩散大语言模型设计的约束解码方法，通过前瞻验证确保生成语法正确的输出，显著提升句法正确性且计算开销可忽略。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型在生成形式语言（如源代码、化学表达式）时难以可靠地产生语法正确的输出。现有约束解码方法要么不适用于非自回归的dLLMs，要么无法保证中间输出能最终完成有效句子，限制了实际可靠性。

Method: LAVE利用dLLMs在每次前向传播中并行预测所有位置token分布的特性，当模型提出新token时，使用这些分布进行前瞻验证，高效可靠地检查所提token的有效性，确保中间输出始终能扩展为有效句子。

Result: 在四个广泛使用的dLLMs和三个代表性基准测试上的实验表明，LAVE始终优于现有基线方法，在句法正确性方面取得显著提升，同时引入的运行时开销可忽略不计。

Conclusion: LAVE为扩散大语言模型提供了一种有效的约束解码方法，解决了现有方法在可靠性和适用性方面的限制，显著提升了生成语法正确输出的能力。

Abstract: Diffusion Large Language Models (dLLMs) have demonstrated promising generative capabilities and are increasingly used to produce formal languages defined by context-free grammars, such as source code and chemical expressions. However, as probabilistic models, they still struggle to generate syntactically valid outputs reliably. A natural and promising direction to address this issue is to adapt constrained decoding techniques to enforce grammatical correctness during generation. However, applying these techniques faces two primary obstacles. On the one hand, the non-autoregressive nature of dLLMs renders most existing constrained decoding approaches inapplicable. On the other hand, current approaches specifically designed for dLLMs may allow intermediate outputs that are impossible to complete into valid sentences, which significantly limits their reliability in practice.
  To address these challenges, we present LAVE, a constrained decoding approach specifically designed for dLLMs. Our approach leverages a key property of dLLMs, namely their ability to predict token distributions for all positions in parallel during each forward pass. Whenever a new token is proposed by model, LAVE performs lookahead using these distributions to efficiently and reliably verify the validity of the proposed token. This design ensures reliable constraints by reliably preserving the potential for intermediate outputs to be extended into valid sentences. Extensive experiments across four widely used dLLMs and three representative benchmarks demonstrate that LAVE consistently outperforms existing baselines and achieves substantial improvements in syntactic correctness, while incurring negligible runtime overhead.

</details>


### [29] [Transformer-Based Model for Multilingual Hope Speech Detection](https://arxiv.org/abs/2602.00613)
*Nsrin Ashraf,Mariam Labib,Hamada Nayel*

Main category: cs.CL

TL;DR: 本文介绍了提交给RANLP2025的PolyHope-M系统，使用RoBERTa和XLM-RoBERTa进行英语和德语希望语音检测，RoBERTa在英语上表现最佳（F1: 0.818，准确率: 81.8%）


<details>
  <summary>Details</summary>
Motivation: 研究希望语音检测对于英语和德语的重要性，探索预训练大语言模型在自然语言处理任务中的性能提升潜力

Method: 实现并评估了多种transformer模型：RoBERTa用于英语，多语言模型XLM-RoBERTa用于英语和德语，进行希望语音检测任务

Result: RoBERTa在英语上获得加权F1分数0.818和准确率81.8%；XLM-RoBERTa获得加权F1分数0.786和准确率78.5%

Conclusion: 预训练大语言模型对自然语言处理任务性能有显著提升作用，RoBERTa在英语希望语音检测中表现优于XLM-RoBERTa

Abstract: This paper describes a system that has been submitted to the "PolyHope-M" at RANLP2025. In this work various transformers have been implemented and evaluated for hope speech detection for English and Germany. RoBERTa has been implemented for English, while the multilingual model XLM-RoBERTa has been implemented for both English and German languages. The proposed system using RoBERTa reported a weighted f1-score of 0.818 and an accuracy of 81.8% for English. On the other hand, XLM-RoBERTa achieved a weighted f1-score of 0.786 and an accuracy of 78.5%. These results reflects the importance of improvement of pre-trained large language models and how these models enhancing the performance of different natural language processing tasks.

</details>


### [30] [Jailbreaking LLMs via Calibration](https://arxiv.org/abs/2602.00619)
*Yuxuan Lu,Yongkang Guo,Yuqing Kong*

Main category: cs.CL

TL;DR: 提出一个将安全对齐视为预对齐分布系统性扭曲的框架，将弱到强越狱建模为预测聚合问题，推导出最优聚合策略，并展示现有方法只是该框架的特例。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全对齐通常会在模型的对齐输出与底层预对齐数据分布之间产生系统性差异，需要理解这种差异并开发更有效的越狱方法。

Method: 将安全对齐对下一个token预测的影响建模为预对齐分布的系统性扭曲，将弱到强越狱视为预测聚合问题，推导出损失诱导对偶空间中的梯度偏移最优聚合策略。

Result: 在红队基准测试和数学实用任务中，该方法相比现有方法实现了更高的攻击成功率，在安全强化的gpt-oss-120b模型上尤其有效，且具有更低的"越狱税"。

Conclusion: 提出的框架为理解安全对齐效应提供了理论基础，推导的最优聚合策略超越了现有方法，在保持效用的同时实现了更有效的越狱。

Abstract: Safety alignment in Large Language Models (LLMs) often creates a systematic discrepancy between a model's aligned output and the underlying pre-aligned data distribution. We propose a framework in which the effect of safety alignment on next-token prediction is modeled as a systematic distortion of a pre-alignment distribution. We cast Weak-to-Strong Jailbreaking as a forecast aggregation problem and derive an optimal aggregation strategy characterized by a Gradient Shift in the loss-induced dual space. We show that logit-arithmetic jailbreaking methods are a special case of this framework under cross-entropy loss, and derive a broader family of aggregation rules corresponding to other proper losses. We also propose a new hybrid aggregation rule. Evaluations across red-teaming benchmarks and math utility tasks using frontier models demonstrate that our approach achieves superior Attack Success Rates and lower "Jailbreak Tax" compared with existing methods, especially on the safety-hardened gpt-oss-120b.

</details>


### [31] [Formal Semantic Control over Language Models](https://arxiv.org/abs/2602.00638)
*Yingji Zhang*

Main category: cs.CL

TL;DR: 该论文通过VAE框架提升语言表示的语义和几何可解释性，实现局部、准符号、组合式的潜在空间控制，包括句子级和推理级两个研究方向。


<details>
  <summary>Details</summary>
Motivation: 使语言表示或模型在语义和几何上更可解释，并通过塑造潜在空间几何实现局部化、准符号化、组合式的控制，推动语言模型内部语义表示的系统化解释、精确结构和可靠引导。

Method: 在VAE框架下探索两个互补方向：(1) 句子级学习与控制：在潜在空间中解缠和操纵特定语义特征以指导句子生成，以解释性文本为测试平台；(2) 推理级学习与控制：在潜在空间中隔离和引导推理行为以控制自然语言推理(NLI)，专注于解释性NLI任务。

Result: 论文提出了一套新颖的理论框架和实用方法，通过相应实验证明，所提出的方法增强了自然语言潜在空间在整个论文中的可解释性和可控性。

Conclusion: 该研究推动了语义表示学习，使语言模型的内部语义表示能够被系统化解释、精确结构化并可靠引导，为实现更可解释和可控的语言模型提供了理论和实践基础。

Abstract: This thesis advances semantic representation learning to render language representations or models more semantically and geometrically interpretable, and to enable localised, quasi-symbolic, compositional control through deliberate shaping of their latent space geometry. We pursue this goal within a VAE framework, exploring two complementary research directions: (i) Sentence-level learning and control: disentangling and manipulating specific semantic features in the latent space to guide sentence generation, with explanatory text serving as the testbed; and (ii) Reasoning-level learning and control: isolating and steering inference behaviours in the latent space to control NLI. In this direction, we focus on Explanatory NLI tasks, in which two premises (explanations) are provided to infer a conclusion. The overarching objective is to move toward language models whose internal semantic representations can be systematically interpreted, precisely structured, and reliably directed. We introduce a set of novel theoretical frameworks and practical methodologies, together with corresponding experiments, to demonstrate that our approaches enhance both the interpretability and controllability of latent spaces for natural language across the thesis.

</details>


### [32] [LegalOne: A Family of Foundation Models for Reliable Legal Reasoning](https://arxiv.org/abs/2602.00642)
*Haitao Li,Yifan Chen,Shuo Miao,Qian Dong,Jia Chen,Yiran Hu,Junjie Chen,Minghao Qin,Qingyao Ai,Yiqun Liu,Cheng Luo,Quan Zhou,Ya Zhang,Jikun Hu*

Main category: cs.CL

TL;DR: LegalOne是中国法律领域专用基础模型，通过三阶段训练流程实现法律推理能力，在多项法律任务上超越通用大模型


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在法律领域应用受限，缺乏精确领域知识且难以进行严谨的多步骤司法推理，需要专门的法律领域基础模型

Method: 采用三阶段训练流程：1) 中训练阶段使用可塑性调整采样平衡新知识获取与原有能力保留；2) 监督微调阶段使用法律代理思维链蒸馏从原始法律文本中提取显式推理；3) 课程强化学习策略，通过记忆、理解、推理的渐进过程提升模型能力

Result: LegalOne在广泛的法律任务上达到最先进性能，超越参数规模大得多的通用大语言模型，通过增强知识密度和效率实现优异表现

Conclusion: LegalOne为法律AI领域提供了可信赖且可解释的基础模型，推动了高风险的司法应用部署，并公开了模型权重和LegalKit评估框架

Abstract: While Large Language Models (LLMs) have demonstrated impressive general capabilities, their direct application in the legal domain is often hindered by a lack of precise domain knowledge and complexity of performing rigorous multi-step judicial reasoning. To address this gap, we present LegalOne, a family of foundational models specifically tailored for the Chinese legal domain. LegalOne is developed through a comprehensive three-phase pipeline designed to master legal reasoning. First, during mid-training phase, we propose Plasticity-Adjusted Sampling (PAS) to address the challenge of domain adaptation. This perplexity-based scheduler strikes a balance between the acquisition of new knowledge and the retention of original capabilities, effectively establishing a robust legal foundation. Second, during supervised fine-tuning, we employ Legal Agentic CoT Distillation (LEAD) to distill explicit reasoning from raw legal texts. Unlike naive distillation, LEAD utilizes an agentic workflow to convert complex judicial processes into structured reasoning trajectories, thereby enforcing factual grounding and logical rigor. Finally, we implement a Curriculum Reinforcement Learning (RL) strategy. Through a progressive reinforcement process spanning memorization, understanding, and reasoning, LegalOne evolves from simple pattern matching to autonomous and reliable legal reasoning. Experimental results demonstrate that LegalOne achieves state-of-the-art performance across a wide range of legal tasks, surpassing general-purpose LLMs with vastly larger parameter counts through enhanced knowledge density and efficiency. We publicly release the LegalOne weights and the LegalKit evaluation framework to advance the field of Legal AI, paving the way for deploying trustworthy and interpretable foundation models in high-stakes judicial applications.

</details>


### [33] [Can Small Language Models Handle Context-Summarized Multi-Turn Customer-Service QA? A Synthetic Data-Driven Comparative Evaluation](https://arxiv.org/abs/2602.00665)
*Lakshan Cooray,Deshan Sumanathilaka,Pattigadapa Venkatesh Raju*

Main category: cs.CL

TL;DR: 该研究探索了指令调优的小型语言模型在客户服务多轮问答中的应用，通过历史摘要策略保持对话连续性，并与大型语言模型进行性能对比。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能强大，但计算成本高且部署受限，不适合资源受限环境。小型语言模型提供了更高效的替代方案，但其在多轮客户服务问答中的有效性尚未充分探索，特别是在需要对话连续性和上下文理解的场景中。

Method: 采用历史摘要策略来保持对话状态，引入基于对话阶段的定性分析来评估模型行为。评估了9个指令调优的低参数小型语言模型，并与3个商业大型语言模型进行对比，使用词汇和语义相似度指标，以及人工评估和LLM-as-a-judge方法进行定性评估。

Result: 不同小型语言模型表现差异显著，部分模型展现出接近大型语言模型的性能，而其他模型在保持对话连续性和上下文对齐方面存在困难。

Conclusion: 研究结果突出了低参数语言模型在现实世界客户服务问答系统中的潜力和当前局限性，为资源受限环境下的部署提供了重要参考。

Abstract: Customer-service question answering (QA) systems increasingly rely on conversational language understanding. While Large Language Models (LLMs) achieve strong performance, their high computational cost and deployment constraints limit practical use in resource-constrained environments. Small Language Models (SLMs) provide a more efficient alternative, yet their effectiveness for multi-turn customer-service QA remains underexplored, particularly in scenarios requiring dialogue continuity and contextual understanding. This study investigates instruction-tuned SLMs for context-summarized multi-turn customer-service QA, using a history summarization strategy to preserve essential conversational state. We also introduce a conversation stage-based qualitative analysis to evaluate model behavior across different phases of customer-service interactions. Nine instruction-tuned low-parameterized SLMs are evaluated against three commercial LLMs using lexical and semantic similarity metrics alongside qualitative assessments, including human evaluation and LLM-as-a-judge methods. Results show notable variation across SLMs, with some models demonstrating near-LLM performance, while others struggle to maintain dialogue continuity and contextual alignment. These findings highlight both the potential and current limitations of low-parameterized language models for real-world customer-service QA systems.

</details>


### [34] [EchoReview: Learning Peer Review from the Echoes of Scientific Citations](https://arxiv.org/abs/2602.00733)
*Yinuo Zhang,Dingcheng Huang,Haifeng Suo,Yizhuo Li,Ziya Zhao,Junhao Xu,Zhiying Tu,Dianhui Chu,Deming Zhai,Xianming Liu,Xiaoyan Yu,Dianbo Sui*

Main category: cs.CL

TL;DR: EchoReview：基于引文上下文的数据合成框架，通过挖掘学术引文中的集体评价信号构建大规模跨会议跨年份的引文驱动评审数据集，训练出在证据支持和评审全面性等核心维度表现优异的自动评审模型。


<details>
  <summary>Details</summary>
Motivation: 传统同行评审系统面临可扩展性压力，现有基于真实评审数据的监督微调方法受限于数据单一来源以及人类评审的主观性和不一致性，无法支持高质量的自动评审。

Method: 提出EchoReview框架，系统地从学术引文中挖掘隐含的集体评价信号，将科学界长期判断转化为结构化评审风格数据，构建EchoReview-16K数据集，并训练EchoReviewer-7B自动评审模型。

Result: EchoReviewer-7B在证据支持和评审全面性等核心评审维度上实现了显著且稳定的改进，验证了引文上下文作为可靠自动同行评审的稳健有效数据范式。

Conclusion: 引文上下文为可靠自动同行评审提供了稳健有效的数据范式，EchoReview框架通过利用科学界长期集体判断解决了现有方法的数据限制问题。

Abstract: As the volume of scientific submissions continues to grow rapidly, traditional peer review systems are facing unprecedented scalability pressures, highlighting the urgent need for automated reviewing methods that are both scalable and reliable. Existing supervised fine-tuning approaches based on real review data are fundamentally constrained by single-source of data as well as the inherent subjectivity and inconsistency of human reviews, limiting their ability to support high-quality automated reviewers. To address these issues, we propose EchoReview, a citation-context-driven data synthesis framework that systematically mines implicit collective evaluative signals from academic citations and transforms scientific community's long-term judgments into structured review-style data. Based on this pipeline, we construct EchoReview-16K, the first large-scale, cross-conference, and cross-year citation-driven review dataset, and train an automated reviewer, EchoReviewer-7B. Experimental results demonstrate that EchoReviewer-7B can achieve significant and stable improvements on core review dimensions such as evidence support and review comprehensiveness, validating citation context as a robust and effective data paradigm for reliable automated peer review.

</details>


### [35] [ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement](https://arxiv.org/abs/2602.00740)
*Ziyan Xiao,Yinghao Zhu,Liang Peng,Lequan Yu*

Main category: cs.CL

TL;DR: ExperienceWeaver：一种分层框架，通过将嘈杂的多维反馈提炼为结构化知识（错误特定提示和高级策略），在小样本临床文本改进中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 临床文本改进对医疗效率至关重要，但面临高质量数据有限和医学文档复杂约束的挑战。现有LLM方法在小样本设置中表现不佳：监督微调需要大量数据且成本高，而检索增强生成通常只能提供表面修正，无法捕捉修订背后的推理过程。

Method: 提出ExperienceWeaver分层框架，将重点从数据检索转向经验学习。该方法将嘈杂的多维反馈提炼为结构化、可操作的知识，包括错误特定提示和高级策略。通过将这些提炼的经验注入到代理流程中，模型学习"如何修订"而不仅仅是"修订什么"。

Result: 在四个临床数据集上的广泛评估表明，ExperienceWeaver持续提升性能，在小样本设置中超越了Gemini-3 Pro等最先进模型。

Conclusion: ExperienceWeaver通过经验学习而非简单数据检索的方法，有效解决了小样本临床文本改进的挑战，为医疗文档质量提升提供了更有效的解决方案。

Abstract: Clinical text improvement is vital for healthcare efficiency but remains difficult due to limited high-quality data and the complex constraints of medical documentation. While Large Language Models (LLMs) show promise, current approaches struggle in small-sample settings: supervised fine-tuning is data-intensive and costly, while retrieval-augmented generation often provides superficial corrections without capturing the reasoning behind revisions. To address these limitations, we propose ExperienceWeaver, a hierarchical framework that shifts the focus from data retrieval to experience learning. Instead of simply recalling past examples, ExperienceWeaver distills noisy, multi-dimensional feedback into structured, actionable knowledge. Specifically, error-specific Tips and high-level Strategies. By injecting this distilled experience into an agentic pipeline, the model learns "how to revise" rather than just "what to revise". Extensive evaluations across four clinical datasets demonstrate that ExperienceWeaver consistently improves performance, surpassing state-of-the-art models such as Gemini-3 Pro in small-sample settings.

</details>


### [36] [CURP: Codebook-based Continuous User Representation for Personalized Generation with LLMs](https://arxiv.org/abs/2602.00742)
*Liang Wang,Xinyi Mou,Xiaoyou Liu,Xuanjing Huang,Zhongyu Wei*

Main category: cs.CL

TL;DR: CURP是一个用户建模框架，使用双向用户编码器和离散原型码本提取多维用户特征，实现即插即用的个性化，仅需约2000万参数（总模型大小的0.2%）。


<details>
  <summary>Details</summary>
Motivation: 现有用户建模方法（基于提示或训练）难以在个性化质量与计算/数据效率之间取得平衡，需要更高效的解决方案。

Method: 提出CURP框架，采用双向用户编码器和离散原型码本提取多维用户特征，实现参数高效的即插即用个性化。

Result: 在多种生成任务上，CURP相比强基线实现了更优的性能和泛化能力，同时提供更好的可解释性和可扩展性。

Conclusion: CURP通过高效的用户建模方法，在保持高质量个性化的同时显著降低了计算和数据需求，为LLM个性化应用提供了实用解决方案。

Abstract: User modeling characterizes individuals through their preferences and behavioral patterns to enable personalized simulation and generation with Large Language Models (LLMs) in contemporary approaches. However, existing methods, whether prompt-based or training-based methods, face challenges in balancing personalization quality against computational and data efficiency. We propose a novel framework CURP, which employs a bidirectional user encoder and a discrete prototype codebook to extract multi-dimensional user traits. This design enables plug-and-play personalization with a small number of trainable parameters (about 20M parameters, about 0.2\% of the total model size). Through extensive experiments on variant generation tasks, we show that CURP achieves superior performance and generalization compared to strong baselines, while offering better interpretability and scalability. The code are available at https://github.com/RaidonWong/CURP_code

</details>


### [37] [Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training](https://arxiv.org/abs/2602.00747)
*Shengrui Li,Fei Zhao,Kaiyan Zhao,Jieying Ye,Haifeng Liu,Fangcheng Shi,Zheyong Xie,Yao Hu,Shaosheng Cao*

Main category: cs.CL

TL;DR: DeMix提出了一种通过模型融合预测最优数据混合比例的新框架，将搜索与训练成本解耦，显著降低了寻找最优数据混合的成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型预训练中确定有效的数据混合是关键因素，需要在通用能力和数学、代码等困难任务之间取得平衡。现有方法要么依赖不可靠的小规模代理实验，要么需要极其昂贵的大规模探索，寻找最优数据混合仍然是一个开放挑战

Method: DeMix框架利用模型融合来预测最优数据比例。不是在每个采样的混合比例上训练代理模型，而是在候选数据集上大规模训练组件模型，然后通过加权模型融合推导数据混合代理。这种范式将搜索与训练成本解耦，能够在没有额外训练负担的情况下评估无限采样的混合比例

Result: 大量实验表明，DeMix打破了充分性、准确性和效率之间的权衡，以更低的搜索成本获得了更高的基准性能。同时发布了DeMix Corpora，一个包含22T token的高质量预训练数据集

Conclusion: DeMix通过模型融合方法有效解决了LLM预训练中数据混合优化的难题，提供了一种高效、准确的解决方案，并贡献了大规模高质量数据集促进开放研究

Abstract: Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training, where models must balance general competence with proficiency on hard tasks such as math and code. However, identifying an optimal mixture remains an open challenge, as existing approaches either rely on unreliable tiny-scale proxy experiments or require prohibitively expensive large-scale exploration. To address this, we propose Decouple Searching from Training Mix (DeMix), a novel framework that leverages model merging to predict optimal data ratios. Instead of training proxy models for every sampled mixture, DeMix trains component models on candidate datasets at scale and derives data mixture proxies via weighted model merging. This paradigm decouples search from training costs, enabling evaluation of unlimited sampled mixtures without extra training burden and thus facilitating better mixture discovery through more search trials. Extensive experiments demonstrate that DeMix breaks the trade-off between sufficiency, accuracy and efficiency, obtaining the optimal mixture with higher benchmark performance at lower search cost. Additionally, we release the DeMix Corpora, a comprehensive 22T-token dataset comprising high-quality pre-training data with validated mixtures to facilitate open research. Our code and DeMix Corpora is available at https://github.com/Lucius-lsr/DeMix.

</details>


### [38] [Temporal Leakage in Search-Engine Date-Filtered Web Retrieval: A Case Study from Retrospective Forecasting](https://arxiv.org/abs/2602.00758)
*Ali El Lahib,Ying-Jieh Xia,Zehan Li,Yuxuan Wang,Xinyu Pi*

Main category: cs.CL

TL;DR: 搜索日期过滤器在预测系统评估中不可靠，71%查询存在后截止日期信息泄露，导致预测准确性被高估


<details>
  <summary>Details</summary>
Motivation: 当前搜索增强预测系统使用搜索引擎日期过滤器进行回顾性评估，但这种方法可能存在信息泄露问题，导致评估结果不可靠

Method: 通过审计Google搜索的before:过滤器，分析信息泄露机制；使用gpt-oss-120b大语言模型对比有泄露和无泄露文档的预测准确性差异

Result: 71%的问题返回至少一个包含强后截止日期泄露的页面，41%的问题直接泄露答案；使用泄露文档时预测准确性被显著高估（Brier分数0.108 vs 0.242）

Conclusion: 日期限制搜索不足以进行时间评估，建议采用更强的检索保护措施或在冻结的时间戳网络快照上进行评估，以确保回顾性预测的可信度

Abstract: Search-engine date filters are widely used to enforce pre-cutoff retrieval in retrospective evaluations of search-augmented forecasters. We show this approach is unreliable: auditing Google Search with a before: filter, 71% of questions return at least one page containing strong post-cutoff leakage, and for 41%, at least one page directly reveals the answer. Using a large language model (LLM), gpt-oss-120b, to forecast with these leaky documents, we demonstrate an inflated prediction accuracy (Brier score 0.108 vs. 0.242 with leak-free documents). We characterize common leakage mechanisms, including updated articles, related-content modules, unreliable metadata/timestamps, and absence-based signals, and argue that date-restricted search is insufficient for temporal evaluation. We recommend stronger retrieval safeguards or evaluation on frozen, time-stamped web snapshots to ensure credible retrospective forecasting.

</details>


### [39] [Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning](https://arxiv.org/abs/2602.00759)
*Zhipeng Chen,Xiaobo Qin,Wayne Xin Zhao,Youbin Wu,Ji-Rong Wen*

Main category: cs.CL

TL;DR: A²D方法通过自适应能力分解增强RLVR效果，将复杂问题分解为简单子问题，引导推理器探索，无需教师模型


<details>
  <summary>Details</summary>
Motivation: 传统RLVR过程信息有限，导致模型探索盲目，在复杂问题上容易失败。需要在不依赖教师模型的情况下为RLVR提供额外信息

Method: 提出A²D自适应能力分解方法：1) 训练分解器将复杂问题分解为简单子问题；2) 用分解器标注训练数据中的子问题；3) 在子问题指导下训练推理器进行RLVR

Result: 方法优于竞争基线，可作为即插即用模块应用于不同RLVR算法，分析显示RLVR过程影响分解器性能和行为，特定类型指导能更好增强推理器探索和利用能力

Conclusion: A²D方法有效增强RLVR效果，通过问题分解提供额外指导信息，提升大语言模型在复杂问题上的推理能力

Abstract: Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A$^2$D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A$^2$D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.

</details>


### [40] [APR: Penalizing Structural Redundancy in Large Reasoning Models via Anchor-based Process Rewards](https://arxiv.org/abs/2602.00760)
*Kaiyan Chang,Chenwei Zhu,Yingfeng Luo,Yifu Huo,Chenglong Wang,Xiaoqian Liu,Qiaozhi He,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: 论文提出锚点过程奖励（APR）方法，通过定位推理锚点并惩罚答案稳定尾部，解决大推理模型在测试时扩展中的过度思考问题，在提升性能的同时减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展（TTS）显著增强了大推理模型的能力，但引入了过度思考的关键副作用。研究发现模型在获得最终答案后仍进行无意义的重复自我验证，这种结构冗余需要解决。

Method: 提出锚点过程奖励（APR）方法：1）定义推理锚点（答案首次稳定的位置）；2）识别答案稳定尾部（AST）；3）使用适合长度惩罚的策略优化算法，仅惩罚锚点后的AST部分。

Result: APR方法在1.5B和7B规模的五个数学推理数据集上达到了性能-效率的帕累托前沿，同时显著减少了强化学习训练所需的计算资源。

Conclusion: 通过细粒度分析推理过程中的结构冗余，提出的APR方法有效解决了大推理模型的过度思考问题，实现了性能与效率的平衡。

Abstract: Test-Time Scaling (TTS) has significantly enhanced the capabilities of Large Reasoning Models (LRMs) but introduces a critical side-effect known as Overthinking. We conduct a preliminary study to rethink this phenomenon from a fine-grained perspective. We observe that LRMs frequently conduct repetitive self-verification without revision even after obtaining the final answer during the reasoning process. We formally define this specific position where the answer first stabilizes as the Reasoning Anchor. By analyzing pre- and post-anchor reasoning behaviors, we uncover the structural redundancy fixed in LRMs: the meaningless repetitive verification after deriving the first complete answer, which we term the Answer-Stable Tail (AST). Motivated by this observation, we propose Anchor-based Process Reward (APR), a structure-aware reward shaping method that localizes the reasoning anchor and penalizes exclusively the post-anchor AST. Leveraging the policy optimization algorithm suitable for length penalties, our APR models achieved the performance-efficiency Pareto frontier at 1.5B and 7B scales averaged across five mathematical reasoning datasets while requiring significantly fewer computational resources for RL training.

</details>


### [41] [WordCraft: Scaffolding the Keyword Method for L2 Vocabulary Learning with Multimodal LLMs](https://arxiv.org/abs/2602.00762)
*Yuheng Shao,Junjie Xiong,Chaoran Wu,Xiyuan Wang,Ziyu Zhou,Yang Ouyang,Qinyi Tao,Quan Li*

Main category: cs.CL

TL;DR: WordCraft是一个基于多模态大语言模型的交互式工具，帮助中文母语者学习英语词汇时应用关键词记忆法，通过引导关键词选择、关联构建和图像形成来提升词汇记忆效果。


<details>
  <summary>Details</summary>
Motivation: 中文母语的英语学习者在使用关键词记忆法时面临三大挑战：难以生成语音合适的关键词、构建连贯关联、创造生动的心理意象以帮助长期记忆。现有方法要么完全自动化关键词生成（损害学习者参与度），要么只提供结果导向的记忆辅助（缺乏过程指导）。

Method: 1. 首先对18名中文母语的英语学习者和教育者进行形成性研究，识别关键词记忆法应用中的关键困难和需求。2. 基于研究发现，开发WordCraft工具，这是一个由多模态大语言模型驱动的学习者中心交互式工具，通过引导学习者完成关键词选择、关联构建和图像形成三个步骤来搭建关键词记忆法框架。

Result: 两项用户研究表明，WordCraft不仅保留了生成效应（学习者参与创造记忆材料的效果），而且在有效性和可用性方面都达到了高水平。

Conclusion: WordCraft通过过程导向的指导，成功解决了中文母语英语学习者在应用关键词记忆法时的核心困难，提供了一种既保持学习者参与度又提供充分指导的词汇学习解决方案。

Abstract: Applying the keyword method for vocabulary memorization remains a significant challenge for L1 Chinese-L2 English learners. They frequently struggle to generate phonologically appropriate keywords, construct coherent associations, and create vivid mental imagery to aid long-term retention. Existing approaches, including fully automated keyword generation and outcome-oriented mnemonic aids, either compromise learner engagement or lack adequate process-oriented guidance. To address these limitations, we conducted a formative study with L1 Chinese-L2 English learners and educators (N=18), which revealed key difficulties and requirements in applying the keyword method to vocabulary learning. Building on these insights, we introduce WordCraft, a learner-centered interactive tool powered by Multimodal Large Language Models (MLLMs). WordCraft scaffolds the keyword method by guiding learners through keyword selection, association construction, and image formation, thereby enhancing the effectiveness of vocabulary memorization. Two user studies demonstrate that WordCraft not only preserves the generation effect but also achieves high levels of effectiveness and usability.

</details>


### [42] [Eliciting Trustworthiness Priors of Large Language Models via Economic Games](https://arxiv.org/abs/2602.00769)
*Siyu Yan,Lusha Zhu,Jian-Qiao Zhu*

Main category: cs.CL

TL;DR: 本文提出一种基于迭代上下文学习的方法，用于从大语言模型中提取信任先验，发现GPT-4.1的信任先验与人类相似，并能基于玩家特征调整信任程度。


<details>
  <summary>Details</summary>
Motivation: 构建可信赖AI系统的关键挑战是如何量化AI系统自身的信任水平。现有方法难以准确表征AI系统的信任程度，需要一种新的方法来提取AI系统的信任先验。

Method: 提出基于迭代上下文学习的新方法，应用于行为博弈论中的信任游戏。该方法通过让LLMs在信任游戏中做出决策来提取信任先验，并进一步分析不同玩家特征下的信任差异。

Result: GPT-4.1的信任先验与人类观察结果高度一致。模型能根据玩家特征（如年龄、职业等）调整信任程度，且信任变化可通过基于感知温暖度和能力的刻板印象模型良好预测。

Conclusion: 该方法成功从LLMs中提取了信任先验，为理解AI系统的信任机制提供了新工具。GPT-4.1展现出与人类相似的信任模式，且其信任决策受到刻板印象影响，这对构建可信赖AI系统具有重要意义。

Abstract: One critical aspect of building human-centered, trustworthy artificial intelligence (AI) systems is maintaining calibrated trust: appropriate reliance on AI systems outperforms both overtrust (e.g., automation bias) and undertrust (e.g., disuse). A fundamental challenge, however, is how to characterize the level of trust exhibited by an AI system itself. Here, we propose a novel elicitation method based on iterated in-context learning (Zhu and Griffiths, 2024a) and apply it to elicit trustworthiness priors using the Trust Game from behavioral game theory. The Trust Game is particularly well suited for this purpose because it operationalizes trust as voluntary exposure to risk based on beliefs about another agent, rather than self-reported attitudes. Using our method, we elicit trustworthiness priors from several leading large language models (LLMs) and find that GPT-4.1's trustworthiness priors closely track those observed in humans. Building on this result, we further examine how GPT-4.1 responds to different player personas in the Trust Game, providing an initial characterization of how such models differentiate trust across agent characteristics. Finally, we show that variation in elicited trustworthiness can be well predicted by a stereotype-based model grounded in perceived warmth and competence.

</details>


### [43] [Reasoning as State Transition: A Representational Analysis of Reasoning Evolution in Large Language Models](https://arxiv.org/abs/2602.00770)
*Siyuan Zhang,Jialian Li,Yichi Zhang,Xiao Yang,Yinpeng Dong,Hang Su*

Main category: cs.CL

TL;DR: 本文通过表征视角研究LLM推理能力在训练中的演化，发现后训练对初始表征质量提升有限，但能驱动推理过程中表征分布向更优方向转变，且这种转变主要由生成token的语义而非额外计算驱动。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过显式生成结果分析LLM推理能力的演化，将推理过程视为黑盒，无法揭示内部变化。为克服这种不透明性，本文引入表征视角来研究模型内部状态的动态变化。

Method: 采用表征视角，在不同训练阶段的模型上进行全面实验，分析内部状态动态；通过统计分析验证内部状态与外部输出的关系；进行反事实实验识别表征转变的主要驱动因素。

Result: 发现后训练对静态初始表征质量提升有限；推理过程涉及显著的连续表征分布转变；后训练能驱动这种转变向更优分布发展；生成正确性与最终表征高度相关；表征转变主要由生成token的语义驱动，而非额外计算或参数差异。

Conclusion: 本文提供了对推理过程和训练对推理增强影响的新理解，为未来模型分析和优化提供了有价值的见解，揭示了推理能力提升主要来自模型驱动表征向更优分布转变的能力。

Abstract: Large Language Models have achieved remarkable performance on reasoning tasks, motivating research into how this ability evolves during training. Prior work has primarily analyzed this evolution via explicit generation outcomes, treating the reasoning process as a black box and obscuring internal changes. To address this opacity, we introduce a representational perspective to investigate the dynamics of the model's internal states. Through comprehensive experiments across models at various training stages, we discover that post-training yields only limited improvement in static initial representation quality. Furthermore, we reveal that, distinct from non-reasoning tasks, reasoning involves a significant continuous distributional shift in representations during generation. Comparative analysis indicates that post-training empowers models to drive this transition toward a better distribution for task solving. To clarify the relationship between internal states and external outputs, statistical analysis confirms a high correlation between generation correctness and the final representations; while counterfactual experiments identify the semantics of the generated tokens, rather than additional computation during inference or intrinsic parameter differences, as the dominant driver of the transition. Collectively, we offer a novel understanding of the reasoning process and the effect of training on reasoning enhancement, providing valuable insights for future model analysis and optimization.

</details>


### [44] [HyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference](https://arxiv.org/abs/2602.00777)
*Xuan Ai,Qingqing Yang,Peng Wang,Lei Deng,Lin Zhang,Renhai Chen,Gong Zhang*

Main category: cs.CL

TL;DR: HyLRA是一种混合层复用注意力框架，通过层间稀疏性分析，在敏感层保留完整注意力，在容忍层复用前层关键token索引，显著提升长上下文推理效率


<details>
  <summary>Details</summary>
Motivation: 长上下文推理在LLMs中面临注意力二次计算复杂度和KV缓存内存占用的瓶颈。现有稀疏注意力方法依赖固定模式或激进剪枝，无法在效率和精度间取得最优平衡

Method: 基于层间稀疏性分析发现注意力机制的双重特性：层内敏感性和层间相似性。采用离线动态规划方法制定最优层间策略，敏感层保留完整注意力，容忍层复用前层top-k索引

Result: HyLRA将推理吞吐量提升6%-46%，同时保持可比性能（准确度下降<1%），在多种基准测试中优于现有稀疏注意力方法

Conclusion: HyLRA通过混合层复用注意力有效克服了密集注意力的二次瓶颈，在保持模型性能的同时显著提升长上下文推理效率

Abstract: Long-context inference in Large Language Models (LLMs) is bottlenecked by the quadratic computation complexity of attention and the substantial memory footprint of Key-Value (KV) caches. While existing sparse attention mechanisms attempt to mitigate this by exploiting inherent sparsity, they often rely on rigid patterns or aggressive pruning, failing to achieve an optimal balance between efficiency and accuracy. In this paper, we introduce {\bf HyLRA} ({\bf Hy}brid {\bf L}ayer {\bf R}euse {\bf A}ttention), a novel framework driven by layer-wise sparsity profiling. Our empirical analysis uncovers a dual characteristic in attention mechanics: \textit{intra-layer sensitivity}, where specific layers necessitate full attention to prevent feature distortion, and \textit{inter-layer similarity}, where consecutive layers share substantial critical tokens. Based on these observations, HyLRA employs an offline dynamic programming approach to derive an optimal layer-wise policy. This hybrid strategy retains full attention for sensitive layers to ensure robustness, while enabling tolerant layers to bypass quadratic calculations by directly reusing top-$k$ indices from preceding layers. This approach allows LLMs to restrict computation to the most critical tokens, effectively overcoming the quadratic bottleneck of dense attention. Extensive evaluations demonstrate that HyLRA improves inference throughput by 6\%--46\% while maintaining comparable performance (with $<1\%$ accuracy degradation), consistently outperforming state-of-the-art sparse attention methods. HyLRA is open source at \href{https://anonymous.4open.science/r/unified-cache-management-CF80/}{\texttt{/r/unified-cache-management-CF80/}}

</details>


### [45] [Omni-RRM: Advancing Omni Reward Modeling via Automatic Rubric-Grounded Preference Synthesis](https://arxiv.org/abs/2602.00846)
*Zicheng Kong,Dehua Ma,Zhenbo Xu,Alven Yang,Yiwei Ru,Haoran Wang,Zixuan Zhou,Fuqing Bie,Liuyu Xiang,Huijia Wu,Jian Zhao,Zhaofeng He*

Main category: cs.CL

TL;DR: Omni-RRM是首个开源的基于评分标准的奖励模型，能跨文本、图像、视频和音频生成结构化、多维度的偏好判断，无需人工标注训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型的性能受限于粗粒度的对齐技术，关键瓶颈是缺乏有效的奖励模型：现有奖励模型主要是视觉中心的，返回不透明的标量分数，且依赖昂贵的人工标注。

Method: 通过全自动管道构建大规模数据集Omni-Preference，通过对比不同能力模型合成候选响应对，使用强教师模型协调和过滤偏好并提供模态感知的评分标准依据。Omni-RRM采用两阶段训练：监督微调学习评分标准输出，然后通过强化学习（GRPO）增强对困难、低对比度对的判别能力。

Result: Omni-RRM在视频（ShareGPT-V上80.2%）和音频（Audio-HH-RLHF上66.8%）基准测试中达到最先进准确率，在图像任务上显著优于现有开源奖励模型，相比基础模型整体准确率提升17.7%。

Conclusion: Omni-RRM通过基于评分标准的奖励建模方法，实现了跨模态的结构化偏好判断，无需人工标注，显著提升了多模态对齐性能，并展示了在下游任务中的有效迁移能力。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities, yet their performance is often capped by the coarse nature of existing alignment techniques. A critical bottleneck remains the lack of effective reward models (RMs): existing RMs are predominantly vision-centric, return opaque scalar scores, and rely on costly human annotations. We introduce \textbf{Omni-RRM}, the first open-source rubric-grounded reward model that produces structured, multi-dimension preference judgments with dimension-wise justifications across \textbf{text, image, video, and audio}. At the core of our approach is \textbf{Omni-Preference}, a large-scale dataset built via a fully automated pipeline: we synthesize candidate response pairs by contrasting models of different capabilities, and use strong teacher models to \emph{reconcile and filter} preferences while providing a modality-aware \emph{rubric-grounded rationale} for each pair. This eliminates the need for human-labeled training preferences. Omni-RRM is trained in two stages: supervised fine-tuning to learn the rubric-grounded outputs, followed by reinforcement learning (GRPO) to sharpen discrimination on difficult, low-contrast pairs. Comprehensive evaluations show that Omni-RRM achieves state-of-the-art accuracy on video (80.2\% on ShareGPT-V) and audio (66.8\% on Audio-HH-RLHF) benchmarks, and substantially outperforms existing open-source RMs on image tasks, with a 17.7\% absolute gain over its base model on overall accuracy. Omni-RRM also improves downstream performance via Best-of-$N$ selection and transfers to text-only preference benchmarks. Our data, code, and models are available at https://anonymous.4open.science/r/Omni-RRM-CC08.

</details>


### [46] [Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation](https://arxiv.org/abs/2602.00848)
*Ziwei Gong,Yanda Chen,Julia Hirschberg,Chen Zhao,He He,Zhou Yu,Kathleen Mckeown*

Main category: cs.CL

TL;DR: 提出Factuality-Controlled Generation框架，让用户能在查询时指定事实性约束，通过合成数据训练模型，在遵守事实性要求和保持信息丰富度之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 大语言模型在编码知识时具有不同的置信度，面临信息丰富度与事实准确性之间的权衡。不同应用需要不同的平衡，需要一种能让用户指定事实性约束的框架

Method: 引入Factuality-Controlled Generation框架，允许用户在查询时指定事实性约束。使用合成数据训练模型，评估框架在遵守事实性约束和响应信息丰富度两个维度上的表现

Result: 合成训练显著提高了模型在尊重事实性要求和保持输出信息丰富度方面的能力

Conclusion: Factuality-Controlled Generation框架有效解决了LLMs在信息丰富度与事实准确性之间的权衡问题，通过用户指定的约束和合成数据训练，实现了更好的可控生成

Abstract: Large language models (LLMs) encode knowledge with varying degrees of confidence. When responding to queries, models face an inherent trade-off: they can generate responses that are less informative but highly factual, or more informative but potentially less accurate. Different applications demand different balances between informativeness and factuality. We introduce Factuality-Controlled Generation (FCG), a framework that enables users to specify factuality constraints alongside their queries. We propose to evaluate FCG performance on two dimensions: adherence to factuality constraints and response informativeness. We propose to train models on the FCG task using synthetic data, and show that our synthetic training significantly improves models' ability to both respect factuality requirements and maintain informativeness in their outputs.

</details>


### [47] [Unifying Adversarial Robustness and Training Across Text Scoring Models](https://arxiv.org/abs/2602.00857)
*Manveer Singh Tamber,Hosna Oyarhoseini,Jimmy Lin*

Main category: cs.CL

TL;DR: 本文提出统一文本评分模型（密集检索器、重排序器、奖励模型）的对抗鲁棒性研究框架，开发跨模型角色的对抗训练方法，并证明该方法能提升模型鲁棒性、缓解奖励黑客问题，从而训练出更好对齐的LLM。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型对抗鲁棒性研究在不同应用和攻击方法间呈现碎片化，掩盖了共享的漏洞。需要统一文本评分模型的对抗鲁棒性研究框架，以系统性地识别和解决这些模型的共同脆弱性。

Method: 提出基于文本评分原则的统一研究框架，将对抗攻击和对抗训练方法适配到不同模型角色（密集检索器、重排序器、奖励模型）。开发多种针对文本评分模型的对抗训练方法，并展示组合互补训练策略的有效性。

Result: 研究表明当前语言模型的对抗训练方法通常短视，无法有效跨攻击泛化。提出的对抗训练方法能同时提升模型鲁棒性和任务效果，特别在RLHF中，对抗训练的奖励模型能缓解奖励黑客问题，支持训练出更好对齐的LLM。

Conclusion: 通过统一文本评分模型的对抗鲁棒性研究框架，开发有效的对抗训练方法，不仅能提升模型在各种攻击下的鲁棒性，还能改善任务性能，对RLHF和LLM对齐具有重要实践价值。

Abstract: Research on adversarial robustness in language models is currently fragmented across applications and attacks, obscuring shared vulnerabilities. In this work, we propose unifying the study of adversarial robustness in text scoring models spanning dense retrievers, rerankers, and reward models. This motivates adapting both attacks and adversarial training methods across model roles. Unlike open-ended generation, text scoring failures are directly testable: an attack succeeds when an irrelevant or rejected text outscores a relevant or chosen one. Using this principled lens of text scoring, we demonstrate that current adversarial training formulations for language models are often short-sighted, failing to effectively generalize across attacks. To address this, we introduce multiple adversarial training methods for text scoring models and show that combining complementary training methods can yield strong robustness while also improving task effectiveness. We also highlight the practical value of our approach for RLHF, showing that our adversarially trained reward models mitigate reward hacking and support the training of better-aligned LLMs. We provide our code and models for further study.

</details>


### [48] [ILSIC: Corpora for Identifying Indian Legal Statutes from Queries by Laypeople](https://arxiv.org/abs/2602.00881)
*Shounak Paul,Raghav Dogra,Pawan Goyal,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 本文创建了ILSIC语料库，包含印度法律的500+法条，同时包含法庭判决和普通人查询，用于比较法庭与普通人数据在法律条文识别任务中的差异，并进行了多种实验验证。


<details>
  <summary>Details</summary>
Motivation: 法律条文识别是法律NLP的基础任务，传统上使用法庭判决作为输入，但实际应用中输入通常是普通人提出的非正式查询。现有研究很少探索法庭数据与普通人数据在法律条文识别任务中的差异。

Method: 创建ILSIC语料库，包含500+印度法律条文，同时包含法庭判决和普通人查询。进行了零样本/少样本推理、检索增强生成和监督微调等实验，比较了纯法庭数据训练模型在普通人查询上的表现，以及从法庭到普通人数据的迁移学习效果。

Result: 实验发现：1）纯法庭判决训练的模型在普通人查询上效果不佳；2）从法庭到普通人数据的迁移学习在某些场景下有益；3）对查询类别和法条频率进行了细粒度分析。

Conclusion: 法庭数据与普通人数据在法律条文识别任务中存在显著差异，需要专门针对普通人查询的数据集和方法。ILSIC语料库为研究这一差异提供了资源，迁移学习在某些情况下可以改善模型在普通人查询上的表现。

Abstract: Legal Statute Identification (LSI) for a given situation is one of the most fundamental tasks in Legal NLP. This task has traditionally been modeled using facts from court judgments as input queries, due to their abundance. However, in practical settings, the input queries are likely to be informal and asked by laypersons, or non-professionals. While a few laypeople LSI datasets exist, there has been little research to explore the differences between court and laypeople data for LSI. In this work, we create ILSIC, a corpus of laypeople queries covering 500+ statutes from Indian law. Additionally, the corpus also contains court case judgements to enable researchers to effectively compare between court and laypeople data for LSI. We conducted extensive experiments on our corpus, including benchmarking over the laypeople dataset using zero and few-shot inference, retrieval-augmented generation and supervised fine-tuning. We observe that models trained purely on court judgements are ineffective during test on laypeople queries, while transfer learning from court to laypeople data can be beneficial in certain scenarios. We also conducted fine-grained analyses of our results in terms of categories of queries and frequency of statutes.

</details>


### [49] [EffGen: Enabling Small Language Models as Capable Autonomous Agents](https://arxiv.org/abs/2602.00887)
*Gaurav Srivastava,Aafiya Hussain,Chi Wang,Yingyan Celine Lin,Xuan Wang*

Main category: cs.CL

TL;DR: effGen是一个针对小型语言模型优化的开源智能体框架，通过提示优化、任务分解、复杂度路由和统一内存系统，实现高效、安全的本地部署，在13个基准测试中优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型的智能体系统存在高token成本和隐私问题，需要为小型语言模型设计优化的本地部署框架。

Method: 1) 提示优化压缩上下文70-80%；2) 智能任务分解为并行/顺序子任务；3) 基于五个因素的复杂度路由；4) 统一内存系统；5) 支持多协议通信。

Result: 在13个基准测试中优于LangChain、AutoGen和Smolagents，成功率高、执行快、内存低。提示优化对小型模型增益更大(1.5B模型11.2%)，路由对大型模型增益更大(32B模型7.9%)。

Conclusion: effGen为小型语言模型提供了高效、安全的智能体框架，通过组合优化技术实现跨规模的一致性能提升，开源MIT许可确保广泛可用性。

Abstract: Most existing language model agentic systems today are built and optimized for large language models (e.g., GPT, Claude, Gemini) via API calls. While powerful, this approach faces several limitations including high token costs and privacy concerns for sensitive applications. We introduce effGen, an open-source agentic framework optimized for small language models (SLMs) that enables effective, efficient, and secure local deployment (pip install effgen). effGen makes four major contributions: (1) Enhanced tool-calling with prompt optimization that compresses contexts by 70-80% while preserving task semantics, (2) Intelligent task decomposition that breaks complex queries into parallel or sequential subtasks based on dependencies, (3) Complexity-based routing using five factors to make smart pre-execution decisions, and (4) Unified memory system combining short-term, long-term, and vector-based storage. Additionally, effGen unifies multiple agent protocols (MCP, A2A, ACP) for cross-protocol communication. Results on 13 benchmarks show effGen outperforms LangChain, AutoGen, and Smolagents with higher success rates, faster execution, and lower memory. Our results reveal that prompt optimization and complexity routing have complementary scaling behavior: optimization benefits SLMs more (11.2% gain at 1.5B vs 2.4% at 32B), while routing benefits large models more (3.6% at 1.5B vs 7.9% at 32B), providing consistent gains across all scales when combined. effGen (https://effgen.org/) is released under the MIT License, ensuring broad accessibility for research and commercial use. Our framework code is publicly available at https://github.com/ctrl-gaurav/effGen.

</details>


### [50] [Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts](https://arxiv.org/abs/2602.00913)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

TL;DR: 研究在计算受限条件下，Schwartz高阶类别是否能为句子级人类价值检测提供有用结构，发现硬性层次约束会降低性能，而标签阈值调优和轻量集成更有效。


<details>
  <summary>Details</summary>
Motivation: 句子级人类价值检测通常被构建为Schwartz价值观的多标签分类任务，但尚不清楚Schwartz高阶类别是否能提供可用的结构。本研究在严格的计算预算限制下（单8GB GPU）探索这一问题。

Method: 在ValueEval'24/ValuesML数据集（74K英语句子）上比较：(1)直接监督transformer；(2)使用硬掩码强制层次结构的HO→价值观流水线；(3)存在→HO→价值观级联方法。同时评估低成本附加组件（词典、短上下文、主题）、标签阈值调优、小型指令调优LLM基线（≤10B）、QLoRA和简单集成。

Result: 高阶类别可从单句学习（最容易的双极对达到Macro-F1≈0.58），但硬性层次门控不是可靠优势：它常通过误差累积和召回抑制降低最终任务的Macro-F1。标签阈值调优是高杠杆调节手段（最高提升+0.05 Macro-F1），小型transformer集成提供最一致的额外增益（最高+0.02 Macro-F1）。小型LLM作为独立系统落后于监督编码器，但可在跨家族集成中贡献互补误差。

Conclusion: 高阶结构在描述上有用，但用硬性门控强制实施会损害句子级价值检测；稳健的改进来自校准和轻量集成。

Abstract: Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz higher-order (HO) categories provide usable structure. We study this under a strict compute-frugal budget (single 8 GB GPU) on ValueEval'24 / ValuesML (74K English sentences). We compare (i) direct supervised transformers, (ii) HO$\rightarrow$values pipelines that enforce the hierarchy with hard masks, and (iii) Presence$\rightarrow$HO$\rightarrow$values cascades, alongside low-cost add-ons (lexica, short context, topics), label-wise threshold tuning, small instruction-tuned LLM baselines ($\le$10B), QLoRA, and simple ensembles. HO categories are learnable from single sentences (e.g., the easiest bipolar pair reaches Macro-$F_1\approx0.58$), but hard hierarchical gating is not a reliable win: it often reduces end-task Macro-$F_1$ via error compounding and recall suppression. In contrast, label-wise threshold tuning is a high-leverage knob (up to $+0.05$ Macro-$F_1$), and small transformer ensembles provide the most consistent additional gains (up to $+0.02$ Macro-$F_1$). Small LLMs lag behind supervised encoders as stand-alone systems, yet can contribute complementary errors in cross-family ensembles. Overall, HO structure is useful descriptively, but enforcing it with hard gates hurts sentence-level value detection; robust improvements come from calibration and lightweight ensembling.

</details>


### [51] [A Baseline Multimodal Approach to Emotion Recognition in Conversations](https://arxiv.org/abs/2602.00914)
*Víctor Yeste,Rodrigo Rivas-Arévalo*

Main category: cs.CL

TL;DR: 本文提出一个轻量级多模态基线方法，用于《老友记》对话情感识别，结合文本分类器和语音表征模型的简单后期融合，提供透明参考实现而非追求SOTA。


<details>
  <summary>Details</summary>
Motivation: 为SemEval-2024 Task 3对话情感识别任务提供一个可访问的参考实现，支持未来更严格的比较，而非追求新颖的SOTA方法。

Method: 结合(i)基于Transformer的文本分类器和(ii)自监督语音表征模型，采用简单的后期融合集成方法，在有限训练协议下进行实验。

Result: 报告了基线设置和实证结果，突出了多模态融合在何时优于单模态模型的情况。

Conclusion: 本文提供了一个透明的基线实现，旨在支持未来更严格的比较研究，展示了轻量级多模态方法在对话情感识别中的潜力。

Abstract: We present a lightweight multimodal baseline for emotion recognition in conversations using the SemEval-2024 Task 3 dataset built from the sitcom Friends. The goal of this report is not to propose a novel state-of-the-art method, but to document an accessible reference implementation that combines (i) a transformer-based text classifier and (ii) a self-supervised speech representation model, with a simple late-fusion ensemble. We report the baseline setup and empirical results obtained under a limited training protocol, highlighting when multimodal fusion improves over unimodal models. This preprint is provided for transparency and to support future, more rigorous comparisons.

</details>


### [52] [Neural FOXP2 -- Language Specific Neuron Steering for Targeted Language Improvement in LLMs](https://arxiv.org/abs/2602.00945)
*Anusa Saha,Tanmay Joshi,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 提出Neural FOXP2方法，通过识别和操控语言神经元，使目标语言（如印地语或西班牙语）成为LLM的主要语言，解决英语在预训练中的主导地位问题。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然是多语言的，但由于预训练数据中英语占主导地位，导致模型默认使用英语，其他语言被系统性抑制。需要一种机制来安全地操控语言偏好。

Method: Neural FOXP2方法分三个阶段：1) 定位：训练每层的稀疏自编码器，识别对特定语言有选择性的特征和神经元；2) 确定操控方向：通过谱低秩分析找到控制语言转换的主导方向；3) 操控：在特定层对语言神经元施加稀疏激活偏移，使目标语言成为默认语言。

Result: 该方法能够识别出紧凑的语言神经元集合，并通过低秩分析找到稳定的操控子空间，实现对目标语言默认性的可控调节。

Conclusion: 语言默认性由稀疏、低秩的控制电路（语言神经元）控制，可以通过机械隔离和安全操控来改变LLM的语言偏好，使非英语语言成为主要语言。

Abstract: LLMs are multilingual by training, yet their lingua franca is often English, reflecting English language dominance in pretraining. Other languages remain in parametric memory but are systematically suppressed. We argue that language defaultness is governed by a sparse, low-rank control circuit, language neurons, that can be mechanistically isolated and safely steered.
  We introduce Neural FOXP2, that makes a chosen language (Hindi or Spanish) primary in a model by steering language-specific neurons. Neural FOXP2 proceeds in three stages: (i) Localize: We train per-layer SAEs so each activation decomposes into a small set of active feature components. For every feature, we quantify English vs. Hindi/Spanish selectivity overall logit-mass lift toward the target-language token set. Tracing the top-ranked features back to their strongest contributing units yields a compact language-neuron set. (ii) Steering directions: We localize controllable language-shift geometry via a spectral low-rank analysis. For each layer, we build English to target activation-difference matrices and perform layerwise SVD to extract the dominant singular directions governing language change. The eigengap and effective-rank spectra identify a compact steering subspace and an empirically chosen intervention window (where these directions are strongest and most stable). (iii) Steer: We apply a signed, sparse activation shift targeted to the language neurons. Concretely, within low to mid layers we add a positive steering along the target-language dominant directions and a compensating negative shift toward the null space for the English neurons, yielding controllable target-language defaultness.

</details>


### [53] [Verification Required: The Impact of Information Credibility on AI Persuasion](https://arxiv.org/abs/2602.00970)
*Saaduddin Mahmud,Eugene Bagdasarian,Shlomo Zilberstein*

Main category: cs.CL

TL;DR: 论文提出MixTalk博弈框架研究LLM代理在概率可信度信息下的策略性通信，通过TOPD方法提升接收者抗说服能力


<details>
  <summary>Details</summary>
Motivation: LLM代理在关键决策场景中日益重要，但现有研究要么关注不可验证的廉价交谈，要么关注完全可验证的披露，未能捕捉现实世界中信息具有概率可信度的复杂情况

Method: 引入MixTalk博弈框架，发送者策略性地组合可验证和不可验证声明，接收者分配有限预算进行成本验证；提出TOPD方法从交互日志中蒸馏锦标赛最优策略并在推理时部署

Result: 评估了最先进LLM代理在三种现实部署设置中的表现，揭示了它们在信息可信度推理方面的优势和局限；TOPD显著提高了接收者对说服的鲁棒性

Conclusion: MixTalk框架为研究LLM代理在概率可信度信息下的策略性通信提供了新视角，TOPD方法能有效提升接收者决策质量，对现实世界LLM部署具有重要意义

Abstract: Agents powered by large language models (LLMs) are increasingly deployed in settings where communication shapes high-stakes decisions, making a principled understanding of strategic communication essential. Prior work largely studies either unverifiable cheap-talk or fully verifiable disclosure, failing to capture realistic domains in which information has probabilistic credibility. We introduce MixTalk, a strategic communication game for LLM-to-LLM interaction that models information credibility. In MixTalk, a sender agent strategically combines verifiable and unverifiable claims to communicate private information, while a receiver agent allocates a limited budget to costly verification and infers the underlying state from prior beliefs, claims, and verification outcomes. We evaluate state-of-the-art LLM agents in large-scale tournaments across three realistic deployment settings, revealing their strengths and limitations in reasoning about information credibility and the explicit behavior that shapes these interactions. Finally, we propose Tournament Oracle Policy Distillation (TOPD), an offline method that distills tournament oracle policy from interaction logs and deploys it in-context at inference time. Our results show that TOPD significantly improves receiver robustness to persuasion.

</details>


### [54] [Trust in One Round: Confidence Estimation for Large Language Models via Structural Signals](https://arxiv.org/abs/2602.00977)
*Pengyue Yang,Jiawen Wen,Haolin Jin,Linghan Huang,Huaming Chen,Ling Chen*

Main category: cs.CL

TL;DR: 提出Structural Confidence框架，通过分析LLM最终层隐藏状态轨迹的多尺度结构信号，增强输出正确性预测，相比传统方法在分布偏移和计算受限场景下更稳健。


<details>
  <summary>Details</summary>
Motivation: LLM在错误成本高的领域部署增多，但传统置信度估计方法（如token似然度、语义相似性、多样本一致性）在分布偏移、领域专业文本和计算限制下表现脆弱，需要更稳健的置信度估计框架。

Method: 提出Structural Confidence框架，单次前向传播、模型无关，从模型最终层隐藏状态轨迹提取多尺度结构信号（频谱、局部变化、全局形状描述符），捕捉概率和句子嵌入忽略的内部稳定性模式。

Result: 在四个异构基准（FEVER、SciFact、WikiBio-hallucination、TruthfulQA）上广泛评估，Structural Confidence在AUROC和AUPR指标上优于现有基线方法，且只需单次确定性前向传播，无需多次随机生成或辅助模型。

Conclusion: Structural Confidence为资源受限、社会影响大的LLM应用提供了高效、稳健的事后置信度估计实用基础，相比采样一致性方法更计算高效。

Abstract: Large language models (LLMs) are increasingly deployed in domains where errors carry high social, scientific, or safety costs. Yet standard confidence estimators, such as token likelihood, semantic similarity and multi-sample consistency, remain brittle under distribution shift, domain-specialised text, and compute limits. In this work, we present Structural Confidence, a single-pass, model-agnostic framework that enhances output correctness prediction based on multi-scale structural signals derived from a model's final-layer hidden-state trajectory. By combining spectral, local-variation, and global shape descriptors, our method captures internal stability patterns that are missed by probabilities and sentence embeddings. We conduct extensive, cross-domain evaluation across four heterogeneous benchmarks-FEVER (fact verification), SciFact (scientific claims), WikiBio-hallucination (biographical consistency), and TruthfulQA (truthfulness-oriented QA). Our Structural Confidence framework demonstrates strong performance compared with established baselines in terms of AUROC and AUPR. More importantly, unlike sampling-based consistency methods which require multiple stochastic generations and an auxiliary model, our approach uses a single deterministic forward pass, offering a practical basis for efficient, robust post-hoc confidence estimation in socially impactful, resource-constrained LLM applications.

</details>


### [55] [MedSpeak: A Knowledge Graph-Aided ASR Error Correction Framework for Spoken Medical QA](https://arxiv.org/abs/2602.00981)
*Yutong Song,Shiva Shrestha,Chenhan Lyu,Elahe Khatibi,Pengfei Zhang,Honghui Xu,Nikil Dutt,Amir Rahmani*

Main category: cs.CL

TL;DR: MedSpeak：基于知识图谱的ASR错误校正框架，通过结合语义关系和语音信息提升医疗术语识别准确性，改善医疗口语问答系统性能


<details>
  <summary>Details</summary>
Motivation: 依赖自动语音识别（ASR）的口语问答系统在医疗术语识别上存在准确性问题，需要专门的方法来校正ASR错误并提升下游答案预测

Method: 提出MedSpeak框架，利用医疗知识图谱中的语义关系和语音信息，结合大语言模型的推理能力，对噪声转录进行精炼和校正

Result: 在基准测试中，MedSpeak显著提升了医疗术语识别准确性和整体医疗口语问答性能，成为该领域的先进解决方案

Conclusion: MedSpeak通过知识图谱辅助的ASR错误校正，有效解决了医疗口语问答中的术语识别问题，为医疗SQA提供了有效的解决方案

Abstract: Spoken question-answering (SQA) systems relying on automatic speech recognition (ASR) often struggle with accurately recognizing medical terminology. To this end, we propose MedSpeak, a novel knowledge graph-aided ASR error correction framework that refines noisy transcripts and improves downstream answer prediction by leveraging both semantic relationships and phonetic information encoded in a medical knowledge graph, together with the reasoning power of LLMs. Comprehensive experimental results on benchmarks demonstrate that MedSpeak significantly improves the accuracy of medical term recognition and overall medical SQA performance, establishing MedSpeak as a state-of-the-art solution for medical SQA. The code is available at https://github.com/RainieLLM/MedSpeak.

</details>


### [56] [DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning](https://arxiv.org/abs/2602.00983)
*Batuhan K. Karaman,Aditya Rawal,Suhaila Shakiah,Mohammad Ghavamzadeh,Mingyi Hong,Arijit Biswas,Ruida Zhou*

Main category: cs.CL

TL;DR: DISPO是一种新的强化学习算法，通过分离正确和错误响应的重要性采样权重裁剪，实现四个可控策略更新机制，在数学推理任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在训练稳定性和学习效率之间存在权衡：PPO类方法稳定但学习慢，REINFORCE类方法效率高但不稳定。需要一种既能保持学习效率又能确保训练稳定的方法。

Method: DISPO算法将正确和错误响应的重要性采样权重分别进行上裁剪和下裁剪，形成四个可控的策略更新机制。通过针对性调整这四个裁剪参数，平衡探索和蒸馏，同时防止灾难性失败。

Result: 在AIME'24基准测试上达到61.04%的准确率，优于CISPO的55.42%和DAPO的50.21%。在各种基准测试和模型上都显示出类似的性能提升。

Conclusion: DISPO通过解耦正确和错误响应的权重裁剪机制，有效解决了现有强化学习方法在稳定性和效率之间的权衡问题，为语言模型的数学推理能力提升提供了更优的训练框架。

Abstract: Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models particularly in mathematics. Current approaches in this domain present a clear trade-off: PPO-style methods (e.g., GRPO/DAPO) offer training stability but exhibit slow learning trajectories due to their trust-region constraints on policy updates, while REINFORCE-style approaches (e.g., CISPO) demonstrate improved learning efficiency but suffer from performance instability as they clip importance sampling weights while still permitting non-zero gradients outside the trust-region. To address these limitations, we introduce DISPO, a simple yet effective REINFORCE-style algorithm that decouples the up-clipping and down-clipping of importance sampling weights for correct and incorrect responses, yielding four controllable policy update regimes. Through targeted ablations, we uncover how each regime impacts training: for correct responses, weights >1 increase the average token entropy (i.e., exploration) while weights <1 decrease it (i.e., distillation) -- both beneficial but causing gradual performance degradation when excessive. For incorrect responses, overly restrictive clipping triggers sudden performance collapse through repetitive outputs (when weights >1) or vanishing response lengths (when weights <1). By separately tuning these four clipping parameters, DISPO maintains the exploration-distillation balance while preventing catastrophic failures, achieving 61.04% on AIME'24 (vs. 55.42% CISPO and 50.21% DAPO) with similar gains across various benchmarks and models.

</details>


### [57] [Sparse Reward Subsystem in Large Language Models](https://arxiv.org/abs/2602.00986)
*Guowei Xu,Mert Yuksekgonul,James Zou*

Main category: cs.CL

TL;DR: 在LLM隐藏状态中发现类似人脑奖励系统的稀疏奖励子系统，包含代表状态价值期望的"价值神经元"和编码奖励预测误差的"多巴胺神经元"


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型内部是否存在类似生物大脑的奖励处理机制，理解LLM推理过程中的内部价值评估系统

Method: 通过干预实验识别隐藏状态中的价值神经元，分析其在不同数据集、模型规模和架构下的鲁棒性，并识别编码奖励预测误差的多巴胺神经元

Result: 发现价值神经元在多样化条件下具有鲁棒性和跨数据集/模型的迁移性；识别出多巴胺神经元在奖励高于预期时高激活、低于预期时低激活的特性

Conclusion: LLM内部存在类似生物奖励系统的机制，价值神经元对推理至关重要，多巴胺神经元编码奖励预测误差，这为理解LLM内部工作机制提供了新视角

Abstract: In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.

</details>


### [58] [DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework](https://arxiv.org/abs/2602.00996)
*Abhijit Chakraborty,Ashish Raj Shekhar,Shiven Agarwal,Vivek Gupta*

Main category: cs.CL

TL;DR: DeALOG是一个用于多模态问答的去中心化多智能体框架，通过专用智能体和共享自然语言日志实现协作，在多个基准测试中表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 跨文本、表格和图像的复杂问答需要整合多样化信息源，需要一个支持专业化处理、协调和可解释性的框架。

Method: 使用专用智能体（表格、上下文、视觉、总结和验证智能体），通过共享自然语言日志作为持久内存进行通信，实现去中心化的协作错误检测和验证。

Result: 在FinQA、TAT-QA、CRT-QA、WikiTableQuestions、FeTaQA和MultiModalQA等基准测试中表现出竞争力，分析确认了共享日志、智能体专业化和验证对准确性的重要性。

Conclusion: DeALOG通过模块化组件和自然语言通信提供了可扩展的多模态问答方法，去中心化日志方法增强了鲁棒性和协作能力。

Abstract: Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized processing with coordination and interpretability is needed. We introduce DeALOG, a decentralized multi-agent framework for multimodal question answering. It uses specialized agents: Table, Context, Visual, Summarizing and Verification, that communicate through a shared natural-language log as persistent memory. This log-based approach enables collaborative error detection and verification without central control, improving robustness. Evaluations on FinQA, TAT-QA, CRT-QA, WikiTableQuestions, FeTaQA, and MultiModalQA show competitive performance. Analysis confirms the importance of the shared log, agent specialization, and verification for accuracy. DeALOG, provides a scalable approach through modular components using natural-language communication.

</details>


### [59] [Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning](https://arxiv.org/abs/2602.00998)
*Zhikun Xu,Xiaodong Yu,Ben Zhou,Jiang Liu,Jialian Wu,Ze Wang,Ximeng Sun,Hao Chen,Zicheng Liu*

Main category: cs.CL

TL;DR: 本文提出RULES方法，通过结构化预测任务训练LLMs进行引理判断，使用两段式输出和分段感知强化学习提升数学推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在数学基准测试中表现良好，但经常误用引理，在不验证假设的情况下直接应用结论。需要提升模型在数学推理中对引理适用性的判断能力。

Method: 将引理判断形式化为结构化预测任务：给定陈述和候选引理，模型必须输出前提条件检查和结论效用检查。提出RULES方法，使用两段式输出编码规范，通过强化学习加分段感知损失掩码进行训练，将惩罚分配给导致错误的相应部分。

Result: 在领域内任务上，RULES相比普通模型和单标签RL基线获得一致提升；在适用性破坏性扰动上改进更大；在端到端任务上达到同等或适度提升。消融研究表明两段式输出和分段感知强化学习对鲁棒性都是必要的。

Conclusion: RULES方法通过结构化引理判断任务和分段感知训练，有效提升了LLMs在数学推理中对引理适用性的判断能力，增强了模型在扰动环境下的鲁棒性。

Abstract: Recent large language models (LLMs) perform strongly on mathematical benchmarks yet often misapply lemmas, importing conclusions without validating assumptions. We formalize lemma$-$judging as a structured prediction task: given a statement and a candidate lemma, the model must output a precondition check and a conclusion$-$utility check, from which a usefulness decision is derived. We present RULES, which encodes this specification via a two$-$section output and trains with reinforcement learning plus section$-$aware loss masking to assign penalty to the section responsible for errors. Training and evaluation draw on diverse natural language and formal proof corpora; robustness is assessed with a held$-$out perturbation suite; and end$-$to$-$end evaluation spans competition$-$style, perturbation$-$aligned, and theorem$-$based problems across various LLMs. Results show consistent in$-$domain gains over both a vanilla model and a single$-$label RL baseline, larger improvements on applicability$-$breaking perturbations, and parity or modest gains on end$-$to$-$end tasks; ablations indicate that the two$-$section outputs and section$-$aware reinforcement are both necessary for robustness.

</details>


### [60] [Distilling Token-Trained Models into Byte-Level Models](https://arxiv.org/abs/2602.01007)
*Zishuo Bao,Jiaqi Leng,Junxiong Wang,Bowen Peng,Yucheng Lu*

Main category: cs.CL

TL;DR: 提出一种高效蒸馏方法，将现有分词训练的LLMs转换为字节语言模型，仅需约1250亿字节数据即可保留教师模型大部分能力


<details>
  <summary>Details</summary>
Motivation: 字节语言模型(BLMs)是超越分词限制的有前景方向，但现有BLMs需要从头训练数万亿字节，成本过高。需要一种高效方法将已有分词模型转换为字节模型

Method: 采用两阶段课程学习：1)渐进知识蒸馏，对齐字节级表示与分词教师模型的嵌入；2)字节级监督微调，实现完全在字节空间的端到端生成

Result: 在Llama、Qwen、OLMo等多个模型系列上验证，蒸馏出的BLMs仅使用约1250亿字节数据即可保留教师模型大部分性能

Conclusion: 提出的蒸馏方法能够高效地将现有分词LLMs转换为字节语言模型，大幅降低训练成本，为BLMs的实用化提供可行路径

Abstract: Byte Language Models (BLMs) have emerged as a promising direction for scaling language models beyond tokenization. However, existing BLMs typically require training from scratch on trillions of bytes, making them prohibitively expensive. In this paper, we propose an efficient distillation recipe that converts existing token-trained LLMs into BLMs while retaining comparable capabilities. Our recipe follows a two-stage curriculum: (1) Progressive Knowledge Distillation, which aligns byte-level representations with the embeddings of the token-trained teacher model; and (2) Byte-Level Supervised Fine-Tuning, which enables end-to-end generation entirely in the byte space. We validate our approach across multiple model families, including Llama, Qwen, and OLMo, and demonstrate that the distilled BLMs retain most of the teacher models' performance using only approximately 125B bytes.

</details>


### [61] [Large Language Models as Students Who Think Aloud: Overly Coherent, Verbose, and Confident](https://arxiv.org/abs/2602.01015)
*Conrad Borchers,Jill-Jênn Vie,Roger Azevedo*

Main category: cs.CL

TL;DR: LLMs模拟新手推理存在局限性：过度连贯、冗长、缺乏变异性，且高估学习者表现，源于训练数据缺乏真实学习过程特征。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs能否真实模拟新手推理和元认知判断，现有评估过于关注解题准确性，忽略了人类学习中碎片化、不完美的推理特征。

Method: 使用630条化学辅导问题中的出声思考记录，比较LLM生成推理与人类学习者话语，在最小和扩展上下文提示下评估模型预测学习者步骤级成功的能力。

Result: GPT-4.1生成流畅且上下文适当的延续，但其推理系统性过度连贯、冗长、变异性低于人类出声思考；学习者表现被持续高估；这些效应在更丰富的解题上下文提示下加剧。

Conclusion: LLMs模拟学习存在认识论局限性，源于训练数据缺乏情感表达和工作记忆约束等真实学习特征；评估框架可指导未来自适应系统设计，更真实地支持新手学习和自我调节。

Abstract: Large language models (LLMs) are increasingly embedded in AI-based tutoring systems. Can they faithfully model novice reasoning and metacognitive judgments? Existing evaluations emphasize problem-solving accuracy, overlooking the fragmented and imperfect reasoning that characterizes human learning. We evaluate LLMs as novices using 630 think-aloud utterances from multi-step chemistry tutoring problems with problem-solving logs of student hint use, attempts, and problem context. We compare LLM-generated reasoning to human learner utterances under minimal and extended contextual prompting, and assess the models' ability to predict step-level learner success. Although GPT-4.1 generates fluent and contextually appropriate continuations, its reasoning is systematically over-coherent, verbose, and less variable than human think-alouds. These effects intensify with a richer problem-solving context during prompting. Learner performance was consistently overestimated. These findings highlight epistemic limitations of simulating learning with LLMs. We attribute these limitations to LLM training data, including expert-like solutions devoid of expressions of affect and working memory constraints during problem solving. Our evaluation framework can guide future design of adaptive systems that more faithfully support novice learning and self-regulation using generative artificial intelligence.

</details>


### [62] [Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations](https://arxiv.org/abs/2602.01030)
*Sheng-Lun Wei,Yu-Ling Liao,Yen-Hua Chang,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 首次系统研究多语言MLLM中的语音偏见，构建BiasInEar数据集，发现模型对语言和选项顺序敏感，语音会放大现有结构偏见。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对多语言多模态语言模型（MLLM）中语音偏见的系统性研究，需要建立统一的评估框架来填补文本和语音评估之间的差距。

Method: 构建BiasInEar数据集（基于Global MMLU Lite，涵盖英中韩三语，平衡性别和口音，共70.8小时语音）；使用四种互补指标（准确率、熵、APES、Fleiss' κ）评估9个代表性模型；测试语言、口音、性别和选项顺序等扰动。

Result: MLLM对人口统计因素相对稳健，但对语言和选项顺序高度敏感，表明语音会放大现有结构偏见；架构设计和推理策略显著影响跨语言稳健性。

Conclusion: 本研究建立了评估语音集成LLM公平性和稳健性的统一框架，为未来研究提供了基准数据集和方法论基础。

Abstract: This work presents the first systematic investigation of speech bias in multilingual MLLMs. We construct and release the BiasInEar dataset, a speech-augmented benchmark based on Global MMLU Lite, spanning English, Chinese, and Korean, balanced by gender and accent, and totaling 70.8 hours ($\approx$4,249 minutes) of speech with 11,200 questions. Using four complementary metrics (accuracy, entropy, APES, and Fleiss' $κ$), we evaluate nine representative models under linguistic (language and accent), demographic (gender), and structural (option order) perturbations. Our findings reveal that MLLMs are relatively robust to demographic factors but highly sensitive to language and option order, suggesting that speech can amplify existing structural biases. Moreover, architectural design and reasoning strategy substantially affect robustness across languages. Overall, this study establishes a unified framework for assessing fairness and robustness in speech-integrated LLMs, bridging the gap between text- and speech-based evaluation. The resources can be found at https://github.com/ntunlplab/BiasInEar.

</details>


### [63] [Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents](https://arxiv.org/abs/2602.01063)
*Bin Han,Deuksin Kwon,Jonathan Gratch*

Main category: cs.CL

TL;DR: LLMs在相同人格提示下，会根据不同对话场景（破冰、谈判、群体决策、共情）表现出不同的语言、行为和情感结果，显示人格表达具有情境敏感性而非固定不变。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLMs在相同人格提示下，其行为实现如何随对话情境变化，以及这种变化反映的是不一致性还是类似人类的情境适应性调整。

Method: 在四种对话设置（破冰、谈判、群体决策、共情任务）中使用相同的人格提示，分析LLMs在这些不同情境中的语言、行为和情感表现差异。

Result: 结果显示情境线索系统性地影响人格表达和情感基调，相同特质在不同社交和情感需求下表达方式不同，LLMs表现出情境敏感而非固定的人格表达。

Conclusion: 从整体特质理论视角看，LLMs表现出情境敏感的人格表达，能够灵活适应社交互动目标和情感条件，这更类似于人类的情境适应性而非系统不一致性。

Abstract: Large Language Models (LLMs) can be conditioned with explicit personality prompts, yet their behavioral realization often varies depending on context. This study examines how identical personality prompts lead to distinct linguistic, behavioral, and emotional outcomes across four conversational settings: ice-breaking, negotiation, group decision, and empathy tasks. Results show that contextual cues systematically influence both personality expression and emotional tone, suggesting that the same traits are expressed differently depending on social and affective demands. This raises an important question for LLM-based dialogue agents: whether such variations reflect inconsistency or context-sensitive adaptation akin to human behavior. Viewed through the lens of Whole Trait Theory, these findings highlight that LLMs exhibit context-sensitive rather than fixed personality expression, adapting flexibly to social interaction goals and affective conditions.

</details>


### [64] [Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs](https://arxiv.org/abs/2602.01064)
*Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuo Yang,Chu Yuan Zhang,Jianhua Tao*

Main category: cs.CL

TL;DR: 提出知识净化概念，将多个教师LLM的推理过程整合为单一推理，解决知识冲突问题，提升蒸馏效率


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法在处理多个教师模型时面临知识冲突和高资源需求的问题，需要更高效的解决方案

Method: 提出知识净化概念，并设计了五种不同角度的净化方法，包括基于路由的方法等

Result: 实验表明这些方法不仅提升了蒸馏模型的性能，还能有效缓解知识冲突，基于路由的方法展现出强大的泛化能力

Conclusion: 知识净化技术能够优化多教师蒸馏过程，促进强大而轻量级模型的实用部署，具有重要应用潜力

Abstract: Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language models (LLMs) to smaller, more efficient models. However, traditional distillation approaches face challenges related to knowledge conflicts and high resource demands, particularly when leveraging multiple teacher models. In this paper, we introduce the concept of \textbf{Knowledge Purification}, which consolidates the rationales from multiple teacher LLMs into a single rationale, thereby mitigating conflicts and enhancing efficiency. To investigate the effectiveness of knowledge purification, we further propose five purification methods from various perspectives. Our experiments demonstrate that these methods not only improve the performance of the distilled model but also effectively alleviate knowledge conflicts. Moreover, router-based methods exhibit robust generalization capabilities, underscoring the potential of innovative purification techniques in optimizing multi-teacher distillation and facilitating the practical deployment of powerful yet lightweight models.

</details>


### [65] [From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization](https://arxiv.org/abs/2602.01068)
*Chaoqun Cui,Shijing Wang,Liangbin Huang,Qingqing Gu,Zhaolong Huang,Xiao Zeng,Wenji Mao*

Main category: cs.CL

TL;DR: 该研究针对大语言模型在垂直领域翻译的局限性，以视觉媒体字幕翻译为案例，提出自适应局部偏好优化方法，构建了多语言字幕平行语料库，提升翻译表达力和生动性。


<details>
  <summary>Details</summary>
Motivation: 随着应用场景复杂化，大语言模型在垂直领域翻译的局限性逐渐显现。研究聚焦于如何构建满足领域定制需求的翻译大语言模型，以视觉媒体字幕翻译为具体案例，探索如何训练表达力强、生动形象的翻译模型。

Method: 1. 构建并发布了多语言字幕平行语料库数据集；2. 提出自适应局部偏好优化方法，用于解决细粒度偏好对齐问题；3. 验证了大语言模型作为翻译奖励模型和评估器的可靠性。

Result: 实验结果表明，自适应局部偏好优化方法在翻译质量的多维评估中取得了优异表现，能够有效提升翻译的表达力和生动性。

Conclusion: 该研究为解决大语言模型在垂直领域翻译的局限性提供了有效方案，通过构建专业语料库和提出自适应局部偏好优化方法，成功训练出表达力强、生动形象的翻译模型，为领域定制化翻译任务提供了新思路。

Abstract: The rapid development of Large Language Models (LLMs) has significantly enhanced the general capabilities of machine translation. However, as application scenarios become more complex, the limitations of LLMs in vertical domain translations are gradually becoming apparent. In this study, we focus on how to construct translation LLMs that meet the needs of domain customization. We take visual media subtitle translation as our topic and explore how to train expressive and vivid translation LLMs. We investigated the situations of subtitle translation and other domains of literal and liberal translation, verifying the reliability of LLM as reward model and evaluator for translation. Additionally, to train an expressive translation LLM, we constructed and released a multidirectional subtitle parallel corpus dataset and proposed the Adaptive Local Preference Optimization (ALPO) method to address fine-grained preference alignment. Experimental results demonstrate that ALPO achieves outstanding performance in multidimensional evaluation of translation quality.

</details>


### [66] [What If We Allocate Test-Time Compute Adaptively?](https://arxiv.org/abs/2602.01070)
*Ahsan Bilal,Ahmed Mohsin,Muhammad Umer,Ali Subhan,Hassan Rizwan,Ayesha Mohsin,Dean Hougen*

Main category: cs.CL

TL;DR: 提出了一种验证器引导的自适应推理框架，通过迭代轨迹生成和选择，动态分配计算资源，相比传统均匀分配方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统测试时计算扩展方法存在三个主要问题：1）均匀分配推理计算资源；2）使用固定的采样策略；3）仅将验证用于重新排序。这些方法未能根据问题难度和推理路径的潜在效用动态调整计算分配。

Method: 提出验证器引导的自适应框架，将推理视为迭代轨迹生成和选择过程。每个问题运行多次推理迭代，每次迭代中：1）可选生成高级计划；2）选择推理工具集和计算策略；3）生成候选推理轨迹。使用过程奖励模型作为统一控制信号：在迭代内，步骤级PRM分数指导生成过程中的剪枝和扩展；在迭代间，聚合轨迹奖励用于选择最终响应。

Result: 在多个数据集上，动态PRM引导方法始终优于直接测试时扩展方法，在MATH-500上获得大幅提升，在AIME24和AMO-Bench等更难基准上实现数倍改进。通过理论FLOPs和计算强度指标分析效率，显示验证引导的分配将计算集中在高效用推理路径上。

Conclusion: 验证引导的自适应计算分配能够更有效地利用推理计算资源，通过动态调整计算策略和工具选择，显著提升复杂数学推理任务的性能，减少计算浪费。

Abstract: Test-time compute scaling allocates inference computation uniformly, uses fixed sampling strategies, and applies verification only for reranking. In contrast, we propose a verifier-guided adaptive framework treating reasoning as iterative trajectory generation and selection. For each problem, the agent runs multiple inference iterations. In each iteration, it optionally produces a high-level plan, selects a set of reasoning tools and a compute strategy together with an exploration parameter, and then generates a candidate reasoning trajectory. A process reward model (PRM) serves as a unified control signal: within each iteration, step-level PRM scores are aggregated to guide pruning and expansion during generation, and across iterations, aggregated trajectory rewards are used to select the final response. Across datasets, our dynamic, PRM-guided approach consistently outperforms direct test-time scaling, yielding large gains on MATH-500 and several-fold improvements on harder benchmarks such as AIME24 and AMO-Bench. We characterize efficiency using theoretical FLOPs and a compute intensity metric penalizing wasted generation and tool overhead, demonstrating that verification-guided allocation concentrates computation on high-utility reasoning paths.

</details>


### [67] [Logic-Oriented Retriever Enhancement via Contrastive Learning](https://arxiv.org/abs/2602.01116)
*Wenxuan Zhang,Yuan-Hao Jiang,Changyong Qi,Rui Jia,Yonghe Wu*

Main category: cs.CL

TL;DR: LORE通过细粒度对比学习激活LLM的逻辑分析能力，提升知识密集型任务中的检索效果，无需外部监督或资源，保持索引兼容性


<details>
  <summary>Details</summary>
Motivation: 现有检索器在知识密集型任务中表现不佳，往往过度依赖表面相似性，无法处理涉及复杂逻辑关系的查询。LLM本身具备逻辑分析能力，但在标准训练中未被充分利用。

Method: LORE采用细粒度对比学习，激活LLM的潜在逻辑分析能力，引导嵌入向量向符合逻辑结构的证据对齐，而非仅关注浅层相似性。该方法无需外部监督、额外资源或预检索分析，保持索引兼容性。

Result: LORE能持续提升检索效用和下游生成质量，同时保持效率。在知识密集型任务中表现优于传统检索方法。

Conclusion: LORE通过激活LLM内在的逻辑分析能力，有效解决了检索器在复杂逻辑查询中的局限性，提供了一种无需外部资源的检索增强方法，显著提升了知识密集型任务的性能。

Abstract: Large language models (LLMs) struggle in knowledge-intensive tasks, as retrievers often overfit to surface similarity and fail on queries involving complex logical relations. The capacity for logical analysis is inherent in model representations but remains underutilized in standard training. LORE (Logic ORiented Retriever Enhancement) introduces fine-grained contrastive learning to activate this latent capacity, guiding embeddings toward evidence aligned with logical structure rather than shallow similarity. LORE requires no external upervision, resources, or pre-retrieval analysis, remains index-compatible, and consistently improves retrieval utility and downstream generation while maintaining efficiency. The datasets and code are publicly available at https://github.com/mazehart/Lore-RAG.

</details>


### [68] [Tendem: A Hybrid AI+Human Platform](https://arxiv.org/abs/2602.01119)
*Konstantin Chernyshev,Ekaterina Artemova,Viacheslav Zhukov,Maksim Nerush,Mariia Fedorova,Iryna Repik,Olga Shapovalova,Aleksey Sukhorosov,Vladimir Dobrovolskii,Natalia Mikhailova,Sergei Tilga*

Main category: cs.CL

TL;DR: Tendem是一个AI处理结构化重复工作、人类专家介入模型失败或验证结果的混合系统，在94个真实任务评估中相比纯AI代理和纯人工流程，能提供更高质量输出、更快周转时间，且成本与纯人工相当。


<details>
  <summary>Details</summary>
Motivation: 为了解决纯AI系统在处理复杂任务时可能失败或产生不可靠结果的问题，同时避免纯人工流程的低效率和成本问题，需要开发一个结合AI自动化和人类专业判断的混合系统。

Method: 采用混合系统设计：AI处理结构化、重复性工作，当模型失败或需要验证结果时，人类专家介入。每个结果在交付给客户前都经过全面的质量审查。通过94个真实世界任务进行内部评估，与纯AI代理和Upwork自由职业者的纯人工工作流程进行比较。

Result: 1. Tendem始终提供更高质量的输出和更快的周转时间；2. 运营成本与纯人工执行相当；3. 在第三方代理基准测试中，Tendem的AI代理（无人参与）在网页浏览和工具使用任务上接近最先进水平，在领域知识和推理方面表现强劲。

Conclusion: Tendem混合系统结合了AI自动化和人类专业判断的优势，在保持成本竞争力的同时，显著提高了任务执行的质量和效率，为实际应用中的AI-人类协作提供了有效解决方案。

Abstract: Tendem is a hybrid system where AI handles structured, repeatable work and Human Experts step in when the models fail or to verify results. Each result undergoes a comprehensive quality review before delivery to the Client. To assess Tendem's performance, we conducted a series of in-house evaluations on 94 real-world tasks, comparing it with AI-only agents and human-only workflows carried out by Upwork freelancers. The results show that Tendem consistently delivers higher-quality outputs with faster turnaround times. At the same time, its operational costs remain comparable to human-only execution. On third-party agentic benchmarks, Tendem's AI Agent (operating autonomously, without human involvement) performs near state-of-the-art on web browsing and tool-use tasks while demonstrating strong results in frontier domain knowledge and reasoning.

</details>


### [69] [Long-range Modeling and Processing of Multimodal Event Sequences](https://arxiv.org/abs/2602.01125)
*Jichu Li,Yilun Zhong,Zhiting Li,Feng Zhou,Quyu Kong*

Main category: cs.CL

TL;DR: 该论文提出了一种将大语言模型（LLM）与时间点过程（TPP）结合的新框架，扩展至视觉模态，通过自适应序列压缩机制解决长上下文问题，在预测准确性和文本分析质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有TPP方法在处理多模态数据时面临序列长度急剧增加的问题，导致基于注意力的模型难以生成连贯的长文本描述，缺乏对事件动态的推理能力。需要一种能够处理长序列、生成丰富多模态内容并理解事件动态的新方法。

Method: 提出基于LLM的TPP框架，扩展至视觉模态，将文本生成作为核心能力。采用基于时间相似性的自适应序列压缩机制减少序列长度，同时保留关键模式。使用两阶段范式：先在压缩序列上预训练，然后针对下游任务进行监督微调。

Result: 在DanmakuTPP-QA等基准测试中，该方法在预测准确性和生成的文本分析质量方面均优于现有最先进基线模型。

Conclusion: 该研究成功将LLM-based TPP扩展到视觉模态，通过自适应序列压缩有效解决了长上下文问题，实现了更好的事件建模和文本生成能力，为多模态时间序列分析提供了新思路。

Abstract: Temporal point processes (TPPs) have emerged as powerful tools for modeling asynchronous event sequences. While recent advances have extended TPPs to handle textual information, existing approaches are limited in their ability to generate rich, multimodal content and reason about event dynamics. A key challenge is that incorporating multimodal data dramatically increases sequence length, hindering the ability of attention-based models to generate coherent, long-form textual descriptions that require long-range understanding. In this paper, we propose a novel framework that extends LLM-based TPPs to the visual modality, positioning text generation as a core capability alongside time and type prediction. Our approach addresses the long-context problem through an adaptive sequence compression mechanism based on temporal similarity, which reduces sequence length while preserving essential patterns. We employ a two-stage paradigm of pre-training on compressed sequences followed by supervised fine-tuning for downstream tasks. Extensive experiments, including on the challenging DanmakuTPP-QA benchmark, demonstrate that our method outperforms state-of-the-art baselines in both predictive accuracy and the quality of its generated textual analyses.

</details>


### [70] [Don't Judge a Book by its Cover: Testing LLMs' Robustness Under Logical Obfuscation](https://arxiv.org/abs/2602.01132)
*Abhilekh Borah,Shubhra Ghosh,Kedar Joshi,Aditya Kumar Guru,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: 本文介绍了Logifus逻辑混淆框架和LogiQAte诊断基准，发现LLMs在逻辑等价但表面形式混淆的问题上表现严重下降，揭示了模型缺乏深度理解的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在标准形式下能很好处理逻辑推理任务，但在逻辑等价但表面形式混淆的问题上表现不佳。为了研究这种脆弱性，需要创建系统性的诊断工具来评估模型对逻辑结构的真实理解能力。

Method: 1. 开发Logifus结构保持逻辑混淆框架；2. 创建LogiQAte诊断基准，包含1,108个问题，涵盖四个推理任务：混淆一阶逻辑蕴含、混淆血缘关系推理、混淆数字序列模式归纳、混淆方向感导航推理；3. 评估六个最先进模型在混淆前后的性能表现。

Result: 混淆严重降低了零样本性能：GPT-4o平均下降47%，GPT-5下降27%，推理模型o4-mini下降22%。所有模型在逻辑等价但表面形式混淆的问题上都表现显著下降，表明它们只是解析表面形式而非深度理解逻辑结构。

Conclusion: 当前LLMs缺乏对问题的深度理解，只是解析表面形式。需要构建真正理解并保持意义超越表面形式的模型，这对AI系统的鲁棒性和可靠性至关重要。

Abstract: Tasks such as solving arithmetic equations, evaluating truth tables, and completing syllogisms are handled well by large language models (LLMs) in their standard form, but they often fail when the same problems are posed in logically equivalent yet obfuscated formats. To study this vulnerability, we introduce Logifus, a structure-preserving logical obfuscation framework, and, utilizing this, we present LogiQAte, a first-of-its-kind diagnostic benchmark with 1,108 questions across four reasoning tasks: (i) Obfus FOL (first-order logic entailment under equivalence-preserving rewrites), (ii) Obfus Blood Relation (family-graph entailment under indirect relational chains), (iii) Obfus Number Series (pattern induction under symbolic substitutions), and (iv) Obfus Direction Sense (navigation reasoning under altered directions and reference frames). Across all the tasks, evaluating six state-of-the-art models, we find that obfuscation severely degrades zero-shot performance, with performance dropping on average by 47% for GPT-4o, 27% for GPT-5, and 22% for reasoning model, o4-mini. Our findings reveal that current LLMs parse questions without deep understanding, highlighting the urgency of building models that genuinely comprehend and preserve meaning beyond surface form.

</details>


### [71] [Beyond Training for Cultural Awareness: The Role of Dataset Linguistic Structure in Large Language Models](https://arxiv.org/abs/2602.01161)
*Reem I. Masoud,Chen Feng,Shunta Asano,Saied Alshahrani,Philip Colin Treleaven,Miguel R. D. Rodrigues*

Main category: cs.CL

TL;DR: 该研究探讨了文化对齐微调数据集的哪些语言特性与下游文化性能相关，发现词汇导向的特性在不同模型和基准测试中表现最稳健。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在全球部署中面临文化错位问题，但用于文化适应的微调数据集的语言特性尚未得到充分理解。研究旨在从数据集中心视角探究哪些语言特性与文化性能相关。

Method: 对阿拉伯语、中文和日语的微调数据集计算轻量级语言、语义和结构指标，进行主成分分析；在三个主要LLM家族上进行微调，并在文化知识、价值观和规范基准上评估。

Result: 主成分分析得到可解释的语义连贯性、词汇句法多样性和词汇结构丰富度等维度；词汇导向的PC3组件在不同模型和基准测试中表现最稳健，而强调语义或多样性的极端值通常中性或有害。

Conclusion: 文化对齐微调数据集的语言特性与下游性能相关，但关联性高度依赖模型；词汇导向的特性是最稳健的预测因子，为文化对齐的数据集设计提供了实用指导。

Abstract: The global deployment of large language models (LLMs) has raised concerns about cultural misalignment, yet the linguistic properties of fine-tuning datasets used for cultural adaptation remain poorly understood. We adopt a dataset-centric view of cultural alignment and ask which linguistic properties of fine-tuning data are associated with cultural performance, whether these properties are predictive prior to training, and how these effects vary across models. We compute lightweight linguistic, semantic, and structural metrics for Arabic, Chinese, and Japanese datasets and apply principal component analysis separately within each language. This design ensures that the resulting components capture variation among datasets written in the same language rather than differences between languages. The resulting components correspond to broadly interpretable axes related to semantic coherence, surface-level lexical and syntactic diversity, and lexical or structural richness, though their composition varies across languages. We fine-tune three major LLM families (LLaMA, Mistral, DeepSeek) and evaluate them on benchmarks of cultural knowledge, values, and norms. While PCA components correlate with downstream performance, these associations are strongly model-dependent. Through controlled subset interventions, we show that lexical-oriented components (PC3) are the most robust, yielding more consistent performance across models and benchmarks, whereas emphasizing semantic or diversity extremes (PC1-PC2) is often neutral or harmful.

</details>


### [72] [Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages](https://arxiv.org/abs/2602.01162)
*Nipuna Abeykoon,Ashen Weerathunga,Pubudu Wijesinghe,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 提出基于语言类型学的框架，无需平行训练数据或模型重训练，通过语言消歧和类型学合规性评分来提升大语言模型对低资源语言的翻译质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型主要基于高资源语言训练，对主导类型学模式存在系统性偏见，导致翻译到类型学差异大的低资源语言时出现结构不一致问题。需要解决这种结构不遵从性，同时避免平行训练数据的需求。

Method: 框架包含两个组件：1) 通用元语言框架(UMF)，将语言表示为16个类型学维度的结构化配置文件，使用差异加权评分；2) 计算引擎，在生成时进行语言消歧，在候选选择时进行类型学合规性评分。

Result: 在9个语言对上的评估显示干预率与英语的类型学距离强相关。在341个英语句子的实验中，框架对保守处理语言的干预精度为48.16%，对形态密集语言为28.15%，对结构化配置文件语言为86.26%。

Conclusion: 该框架无需平行训练数据，可与任何能产生多个候选输出的大语言模型配合使用，为资源不足的语言提供了实用的部署方案，有效解决了类型学偏见问题。

Abstract: Large language models trained predominantly on high-resource languages exhibit systematic biases toward dominant typological patterns, leading to structural non-conformance when translating into typologically divergent low-resource languages. We present a framework that leverages linguistic typology to improve translation quality without parallel training data or model retraining. The framework consists of two components: the Universal Metalinguistic Framework (UMF), which represents languages as structured profiles across 16 typological dimensions with divergence-weighted scoring, and the Computational Engine, which operates through linguistic disambiguation during generation and typological compliance scoring during selection. Evaluation across nine language pairs demonstrates intervention rates strongly correlating with typological distance from English. In experiments on 341 English sentences each having different morphological and syntactic phenomena, the framework shows an intervention precision of 48.16% for conservatively treated languages, 28.15% for morphologically dense languages, and 86.26% for structurally profiled languages. The framework requires no parallel training data and operates with any LLM capable of producing multiple candidate outputs, enabling practical deployment for under-resourced languages.

</details>


### [73] [PedagoSense: A Pedology Grounded LLM System for Pedagogical Strategy Detection and Contextual Response Generation in Learning Dialogues](https://arxiv.org/abs/2602.01169)
*Shahem Sultan,Shahem Fadi,Yousef Melhim,Ibrahim Alsarraj,Besher Hassan*

Main category: cs.CL

TL;DR: PedagoSense系统通过两阶段分类器检测教学策略，结合LLM生成策略对齐的响应，提升对话式学习中的互动质量


<details>
  <summary>Details</summary>
Motivation: 解决对话式学习中教学策略检测和推荐的挑战，将教学理论与实际LLM响应生成相结合，开发更自适应的教育技术

Method: 两阶段策略分类器（先二元检测是否存在教学策略，再进行细粒度分类）+ LLM生成策略对齐的响应，使用数据增强技术

Result: 在人工标注的师生对话数据上表现出高性能的教学策略检测能力，数据增强带来一致性能提升，但细粒度分类仍有挑战

Conclusion: PedagoSense成功连接了教学理论与实际LLM响应生成，为更自适应的教育技术提供了桥梁

Abstract: This paper addresses the challenge of improving interaction quality in dialogue based learning by detecting and recommending effective pedagogical strategies in tutor student conversations. We introduce PedagoSense, a pedology grounded system that combines a two stage strategy classifier with large language model generation. The system first detects whether a pedagogical strategy is present using a binary classifier, then performs fine grained classification to identify the specific strategy. In parallel, it recommends an appropriate strategy from the dialogue context and uses an LLM to generate a response aligned with that strategy. We evaluate on human annotated tutor student dialogues, augmented with additional non pedagogical conversations for the binary task. Results show high performance for pedagogical strategy detection and consistent gains when using data augmentation, while analysis highlights where fine grained classes remain challenging. Overall, PedagoSense bridges pedagogical theory and practical LLM based response generation for more adaptive educational technologies.

</details>


### [74] [EmoAra: Emotion-Preserving English Speech Transcription and Cross-Lingual Translation with Arabic Text-to-Speech](https://arxiv.org/abs/2602.01170)
*Besher Hassan,Ibrahim Alsarraj,Musaab Hasan,Yousef Melhim,Shahem Fadi,Shahem Sultan*

Main category: cs.CL

TL;DR: EmoAra是一个端到端的情感保持跨语言语音通信系统，专为银行客服场景设计，能将英语语音转换为阿拉伯语语音输出，同时保留情感信息。


<details>
  <summary>Details</summary>
Motivation: 银行客服场景中，情感语境对服务质量至关重要。跨语言交流时，情感信息的丢失会影响沟通效果和服务质量，因此需要开发能保持情感信息的跨语言语音通信系统。

Method: 集成四个模块：基于CNN的语音情感识别、Whisper英语语音识别、微调的MarianMT英阿翻译模型、MMS-TTS-Ara阿拉伯语语音合成。形成端到端处理流程，将英语语音转换为阿拉伯语语音输出。

Result: 情感分类F1分数94%，翻译性能BLEU 56分和BERTScore F1 88.7%，银行领域翻译的平均人工评估分数81%。系统实现和资源已在GitHub仓库公开。

Conclusion: EmoAra成功实现了情感保持的跨语言语音通信，在银行客服场景中表现出色，为跨语言交流中的情感信息保留提供了有效解决方案。

Abstract: This work presents EmoAra, an end-to-end emotion-preserving pipeline for cross-lingual spoken communication, motivated by banking customer service where emotional context affects service quality. EmoAra integrates Speech Emotion Recognition, Automatic Speech Recognition, Machine Translation, and Text-to-Speech to process English speech and deliver an Arabic spoken output while retaining emotional nuance. The system uses a CNN-based emotion classifier, Whisper for English transcription, a fine-tuned MarianMT model for English-to-Arabic translation, and MMS-TTS-Ara for Arabic speech synthesis. Experiments report an F1-score of 94% for emotion classification, translation performance of BLEU 56 and BERTScore F1 88.7%, and an average human evaluation score of 81% on banking-domain translations. The implementation and resources are available at the accompanying GitHub repository.

</details>


### [75] [Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation](https://arxiv.org/abs/2602.01193)
*Shashini Nilukshi,Deshan Sumanathilaka*

Main category: cs.CL

TL;DR: 本文综述了视觉词义消歧（VWSD）领域的发展，从早期多模态融合方法到基于CLIP、扩散模型和LLM的新框架，展示了该领域在2016-2025年间通过特征、图结构和对比嵌入技术的进步。


<details>
  <summary>Details</summary>
Motivation: 传统词义消歧（WSD）仅依赖文本和词汇资源，而视觉词义消歧（VWSD）利用视觉线索来解决视觉语言任务中的词汇歧义问题，能够在最小文本输入的情况下确定歧义词的正确含义。

Method: 综述分析了从早期多模态融合方法到基于CLIP对比模型、扩散式文本到图像生成和大型语言模型（LLM）支持的新框架。涵盖了特征基础、图基础和对比嵌入技术，重点关注提示工程、微调和多语言适应。

Result: 定量结果显示，基于CLIP的微调模型和LLM增强的VWSD系统持续优于零样本基线，在平均倒数排名（MRR）上实现了6-8%的提升。但挑战依然存在，如上下文限制、模型偏向常见含义、缺乏多语言数据集和需要更好的评估框架。

Conclusion: 分析强调了CLIP对齐、扩散生成和LLM推理的日益融合是未来构建强大、上下文感知和多语言消歧系统的方向。VWSD领域正朝着更综合的多模态方法发展。

Abstract: This paper offers a mini review of Visual Word Sense Disambiguation (VWSD), which is a multimodal extension of traditional Word Sense Disambiguation (WSD). VWSD helps tackle lexical ambiguity in vision-language tasks. While conventional WSD depends only on text and lexical resources, VWSD uses visual cues to find the right meaning of ambiguous words with minimal text input. The review looks at developments from early multimodal fusion methods to new frameworks that use contrastive models like CLIP, diffusion-based text-to-image generation, and large language model (LLM) support. Studies from 2016 to 2025 are examined to show the growth of VWSD through feature-based, graph-based, and contrastive embedding techniques. It focuses on prompt engineering, fine-tuning, and adapting to multiple languages. Quantitative results show that CLIP-based fine-tuned models and LLM-enhanced VWSD systems consistently perform better than zero-shot baselines, achieving gains of up to 6-8\% in Mean Reciprocal Rank (MRR). However, challenges still exist, such as limitations in context, model bias toward common meanings, a lack of multilingual datasets, and the need for better evaluation frameworks. The analysis highlights the growing overlap of CLIP alignment, diffusion generation, and LLM reasoning as the future path for strong, context-aware, and multilingual disambiguation systems.

</details>


### [76] [Attention Sink Forges Native MoE in Attention Layers: Sink-Aware Training to Address Head Collapse](https://arxiv.org/abs/2602.01203)
*Zizhuo Fu,Wenxuan Zeng,Runsheng Wang,Meng Li*

Main category: cs.CL

TL;DR: 该研究揭示了注意力机制中的"注意力汇"现象实际上构建了注意力层内的混合专家(MoE)机制，解释了之前观察到的"头崩溃"现象，并提出了一种带负载均衡损失的汇感知训练算法来改善模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)经常对第一个token分配不成比例的注意力，这种现象被称为"注意力汇"。虽然已有一些方法如GPT-OSS中的Sink Attention和Qwen3-Next中的Gated Attention试图解决这个问题，但缺乏对这些注意力机制之间关系的全面分析。

Method: 通过理论和实证证据证明Vanilla Attention和Sink Attention中的汇自然构建了注意力层内的混合专家(MoE)机制。为了缓解头崩溃现象，提出了一种带辅助负载均衡损失的汇感知训练算法，专门为注意力层设计。

Result: 广泛的实验表明，该方法在Vanilla Attention、Sink Attention和Gated Attention中都能实现有效的头负载均衡，并提高了模型性能。

Conclusion: 这项研究为注意力机制提供了新的视角，鼓励进一步探索注意力层内固有的MoE结构，为解决注意力汇和头崩溃问题提供了有效的训练方法。

Abstract: Large Language Models (LLMs) often assign disproportionate attention to the first token, a phenomenon known as the attention sink. Several recent approaches aim to address this issue, including Sink Attention in GPT-OSS and Gated Attention in Qwen3-Next. However, a comprehensive analysis of the relationship among these attention mechanisms is lacking. In this work, we provide both theoretical and empirical evidence demonstrating that the sink in Vanilla Attention and Sink Attention naturally construct a Mixture-of-Experts (MoE) mechanism within attention layers. This insight explains the head collapse phenomenon observed in prior work, where only a fixed subset of attention heads contributes to generation. To mitigate head collapse, we propose a sink-aware training algorithm with an auxiliary load balancing loss designed for attention layers. Extensive experiments show that our method achieves effective head load balancing and improves model performance across Vanilla Attention, Sink Attention, and Gated Attention. We hope this study offers a new perspective on attention mechanisms and encourages further exploration of the inherent MoE structure within attention layers.

</details>


### [77] [ASTER: Agentic Scaling with Tool-integrated Extended Reasoning](https://arxiv.org/abs/2602.01204)
*Xuqin Zhang,Quan He,Zhenrui Zheng,Zongzhang Zhang,Xu He,Dong Li*

Main category: cs.CL

TL;DR: ASTER框架通过有针对性的冷启动策略解决RL训练中的交互崩溃问题，使4B模型在数学基准测试上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 强化学习在LLM的长时程推理中表现出色，但在工具集成推理的扩展中存在交互崩溃问题——模型无法维持多轮工具使用，退化为大量内部推理和简单的后验代码验证

Method: 提出ASTER框架，采用有针对性的冷启动策略，优先选择交互密集的轨迹；研究发现仅需4K个交互密集轨迹的小型专家冷启动集就能建立强大的先验，支持后续RL训练中的高效探索

Result: ASTER-4B在竞争性数学基准测试中达到最先进结果，在AIME 2025上达到90.0%，超越了包括DeepSeek-V3.2-Exp在内的领先开源模型

Conclusion: 通过有针对性的冷启动策略解决交互崩溃问题，即使小规模模型也能在工具集成推理任务中实现卓越性能，为RL在LLM中的有效应用提供了新思路

Abstract: Reinforcement learning (RL) has emerged as a dominant paradigm for eliciting long-horizon reasoning in Large Language Models (LLMs). However, scaling Tool-Integrated Reasoning (TIR) via RL remains challenging due to interaction collapse: a pathological state where models fail to sustain multi-turn tool usage, instead degenerating into heavy internal reasoning with only trivial, post-hoc code verification. We systematically study three questions: (i) how cold-start SFT induces an agentic, tool-using behavioral prior, (ii) how the interaction density of cold-start trajectories shapes exploration and downstream RL outcomes, and (iii) how the RL interaction budget affects learning dynamics and generalization under varying inference-time budgets. We then introduce ASTER (Agentic Scaling with Tool-integrated Extended Reasoning), a framework that circumvents this collapse through a targeted cold-start strategy prioritizing interaction-dense trajectories. We find that a small expert cold-start set of just 4K interaction-dense trajectories yields the strongest downstream performance, establishing a robust prior that enables superior exploration during extended RL training. Extensive evaluations demonstrate that ASTER-4B achieves state-of-the-art results on competitive mathematical benchmarks, reaching 90.0% on AIME 2025, surpassing leading frontier open-source models, including DeepSeek-V3.2-Exp.

</details>


### [78] [Chronos: Learning Temporal Dynamics of Reasoning Chains for Test-Time Scaling](https://arxiv.org/abs/2602.01208)
*Kai Zhang,Jiayi Liao,Chengpeng Li,Ziyuan Xie,Sihang Li,Xiang Wang*

Main category: cs.CL

TL;DR: Chronos是一个轻量级即插即用的时序推理评分器，将推理轨迹建模为时间序列，通过加权投票机制提升LLM推理性能


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放方法（如多数投票和启发式token级评分）将推理轨迹或token同等对待，容易受到轨迹质量大幅变化和局部逻辑失败的影响

Method: Chronos将每个推理轨迹建模为时间序列，学习捕捉token概率的轨迹特征，分配质量分数，并采用加权投票机制

Result: 在领域内和领域外基准测试中，Chronos在各种模型上均带来显著提升，计算开销可忽略。Chronos@128在HMMT25上相对Pass@1提升34.21%，相对Maj@128提升22.70%

Conclusion: Chronos作为一种轻量级即插即用的时序推理评分器，能有效提升LLM推理性能，计算开销小，具有广泛适用性

Abstract: Test-Time Scaling (TTS) has emerged as an effective paradigm for improving the reasoning performance of large language models (LLMs). However, existing methods -- most notably majority voting and heuristic token-level scoring -- treat reasoning traces or tokens equally, thereby being susceptible to substantial variations in trajectory quality and localized logical failures. In this work, we introduce \textbf{Chronos}, a lightweight and plug-and-play chronological reasoning scorer that models each trajectory as a time series. Specifically, Chronos learns to capture trajectory features of token probabilities, assigns quality scores accordingly, and employs a weighted voting mechanism. Extensive evaluations on both in-domain and out-of-domain benchmarks demonstrate that Chronos consistently delivers substantial gains across a variety of models, with negligible computational overhead. Notably, Chronos@128 achieves relative improvements of 34.21\% over Pass@1 and 22.70\% over Maj@128 on HMMT25 using Qwen3-4B-Thinking-2507, highlighting its effectiveness.

</details>


### [79] [Supervised Fine-Tuning Needs to Unlock the Potential of Token Priority](https://arxiv.org/abs/2602.01227)
*Zhanming Shen,Zeyu Qin,Jiaqi Hu,Wentao Ye,Hao Chen,Xiaomeng Hu,Haokai Xu,Gang Chen,Yi R. Fung,Haobo Wang*

Main category: cs.CL

TL;DR: 该立场论文提出"Token Priority"作为连接经验数据拟合与真实人类效用的桥梁，将监督微调(SFT)形式化为精确的分布重塑过程，而非简单优化。


<details>
  <summary>Details</summary>
Motivation: 当前从经验数据拟合到实现真实人类效用的转变受到粒度不匹配的根本限制，细粒度的自回归生成通常由粗糙或均匀的信号监督。

Method: 提出Token Priority框架，将监督微调形式化为精确的分布重塑过程，将原始数据与理想对齐流形对齐。将现有方法分为两个体系：用于噪声过滤的Positive Priority和用于毒性模式遗忘的Signed Priority。

Result: 通过统一视角分析近期突破，重新审视现有进展与局限，识别关键挑战，并为未来研究提供方向。

Conclusion: Token Priority是解决粒度不匹配问题的关键桥梁，为监督微调提供了新的理论框架，有助于更好地实现模型与人类效用的对齐。

Abstract: The transition from fitting empirical data to achieving true human utility is fundamentally constrained by a granularity mismatch, where fine-grained autoregressive generation is often supervised by coarse or uniform signals. This position paper advocates Token Priority as the essential bridge, formalizing Supervised Fine-Tuning (SFT) not as simple optimization but as a precise distribution reshaping process that aligns raw data with the ideal alignment manifold. We analyze recent breakthroughs through this unified lens, categorizing them into two distinct regimes: Positive Priority for noise filtration and Signed Priority for toxic modes unlearning. We revisit existing progress and limitations, identify key challenges, and suggest directions for future research.

</details>


### [80] [Inferential Question Answering](https://arxiv.org/abs/2602.01239)
*Jamshid Mozafari,Hamed Zamani,Guido Zuccon,Adam Jatowt*

Main category: cs.CL

TL;DR: 本文提出了"推理问答"新任务，要求模型从仅提供线索的文本中推断答案，而非直接提取。构建了QUIT数据集，发现现有QA方法在推理任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统大多关注答案直接提取，但许多问题需要推理能力——从可用信息中推断出未明确陈述的答案。需要研究模型从仅提供线索的文本中进行推理的能力。

Method: 1) 提出"推理问答"新任务；2) 构建QUIT数据集，包含7,401个问题和240万段落，基于人类和机器生成的高收敛线索；3) 使用LLM可回答性和人工验证标注三个相关性级别；4) 全面评估检索器、重排序器和LLM阅读器。

Result: 传统QA有效的方法在推理问答上表现不佳：检索器性能不足，重排序器提升有限，微调改进不一致。即使是面向推理的LLM也无法超越较小的通用模型。现有QA流程尚未准备好处理基于推理的任务。

Conclusion: 推理问答建立了一类新的QA任务，推动从间接文本证据中理解和推理的能力发展。当前QA系统在推理能力方面仍有局限，需要新的方法来解决这一挑战。

Abstract: Despite extensive research on a wide range of question answering (QA) systems, most existing work focuses on answer containment-i.e., assuming that answers can be directly extracted and/or generated from documents in the corpus. However, some questions require inference, i.e., deriving answers that are not explicitly stated but can be inferred from the available information. We introduce Inferential QA -- a new task that challenges models to infer answers from answer-supporting passages which provide only clues. To study this problem, we construct QUIT (QUestions requiring Inference from Texts) dataset, comprising 7,401 questions and 2.4M passages built from high-convergence human- and machine-authored hints, labeled across three relevance levels using LLM-based answerability and human verification. Through comprehensive evaluation of retrievers, rerankers, and LLM-based readers, we show that methods effective on traditional QA tasks struggle in inferential QA: retrievers underperform, rerankers offer limited gains, and fine-tuning provides inconsistent improvements. Even reasoning-oriented LLMs fail to outperform smaller general-purpose models. These findings reveal that current QA pipelines are not yet ready for inference-based reasoning. Inferential QA thus establishes a new class of QA tasks that move towards understanding and reasoning from indirect textual evidence.

</details>


### [81] [Minimizing Mismatch Risk: A Prototype-Based Routing Framework for Zero-shot LLM-generated Text Detection](https://arxiv.org/abs/2602.01240)
*Ke Sun,Guangsheng Bao,Han Cui,Yue Zhang*

Main category: cs.CL

TL;DR: 提出DetectRouter框架，通过从多样化代理池中为每个输入选择最佳匹配的代理模型，解决LLM生成文本检测中代理-源对齐问题，显著提升检测性能


<details>
  <summary>Details</summary>
Motivation: 现有零样本检测方法对所有输入使用固定代理模型，但检测性能随代理-源对齐程度变化很大。研究发现没有单一代理能在所有情况下达到最优，但多样化代理池中通常存在与给定输入匹配良好的代理

Method: 提出DetectRouter原型框架，通过两阶段训练学习文本-检测器亲和性：第一阶段从白盒模型构建判别性原型；第二阶段通过将几何距离与观察到的检测分数对齐，泛化到黑盒源

Result: 在EvoBench和MAGE基准测试中，DetectRouter在多个检测标准和模型家族上均表现出一致的性能提升

Conclusion: 将鲁棒检测转化为路由问题（为每个输入选择最合适的代理）是有效的，DetectRouter框架通过智能代理选择显著提高了LLM生成文本的检测性能

Abstract: Zero-shot methods detect LLM-generated text by computing statistical signatures using a surrogate model. Existing approaches typically employ a fixed surrogate for all inputs regardless of the unknown source. We systematically examine this design and find that detection performance varies substantially depending on surrogate-source alignment. We observe that while no single surrogate achieves optimal performance universally, a well-matched surrogate typically exists within a diverse pool for any given input. This finding transforms robust detection into a routing problem: selecting the most appropriate surrogate for each input. We propose DetectRouter, a prototype-based framework that learns text-detector affinity through two-stage training. The first stage constructs discriminative prototypes from white-box models; the second generalizes to black-box sources by aligning geometric distances with observed detection scores. Experiments on EvoBench and MAGE benchmarks demonstrate consistent improvements across multiple detection criteria and model families.

</details>


### [82] [Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments](https://arxiv.org/abs/2602.01244)
*Siwei Wu,Yizhi Li,Yuyang Song,Wei Zhang,Yang Wang,Riza Batista-Navarro,Xian Yang,Mingjie Tang,Bryan Dai,Jian Yang,Chenghua Lin*

Main category: cs.CL

TL;DR: TerminalTraj是一个可扩展的终端轨迹生成管道，通过Docker化环境构建、任务实例生成和可执行验证代码合成，创建了5万多个经过验证的终端轨迹，显著提升了终端任务模型的性能。


<details>
  <summary>Details</summary>
Motivation: 训练终端任务代理模型需要高质量的终端轨迹数据，但大规模构建面临两大挑战：可执行性（需要不同的Docker环境）和可验证性（异构任务输出难以统一验证）。

Method: 提出TerminalTraj管道：1) 筛选高质量仓库构建Docker化执行环境；2) 生成与Docker对齐的任务实例；3) 合成带有可执行验证代码的代理轨迹。

Result: 构建了32K个Docker镜像和50,733个经过验证的终端轨迹，覆盖8个领域。使用该数据训练的模型在TerminalBench上性能显著提升：TB 1.0提升20%，TB 2.0提升10%。TerminalTraj-32B在小于100B参数的模型中表现优异。

Conclusion: TerminalTraj成功解决了终端轨迹数据构建的可执行性和可验证性挑战，为训练终端任务代理模型提供了高质量的大规模数据集，显著提升了模型性能。

Abstract: Training agentic models for terminal-based tasks critically depends on high-quality terminal trajectories that capture realistic long-horizon interactions across diverse domains. However, constructing such data at scale remains challenging due to two key requirements: \textbf{\emph{Executability}}, since each instance requires a suitable and often distinct Docker environment; and \textbf{\emph{Verifiability}}, because heterogeneous task outputs preclude unified, standardized verification. To address these challenges, we propose \textbf{TerminalTraj}, a scalable pipeline that (i) filters high-quality repositories to construct Dockerized execution environments, (ii) generates Docker-aligned task instances, and (iii) synthesizes agent trajectories with executable validation code. Using TerminalTraj, we curate 32K Docker images and generate 50,733 verified terminal trajectories across eight domains. Models trained on this data with the Qwen2.5-Coder backbone achieve consistent performance improvements on TerminalBench (TB), with gains of up to 20\% on TB~1.0 and 10\% on TB~2.0 over their respective backbones. Notably, \textbf{TerminalTraj-32B} achieves strong performance among models with fewer than 100B parameters, reaching 35.30\% on TB~1.0 and 22.00\% on TB~2.0, and demonstrates improved test-time scaling behavior. All code and data are available at https://github.com/Wusiwei0410/TerminalTraj.

</details>


### [83] [PARSE: An Open-Domain Reasoning Question Answering Benchmark for Persian](https://arxiv.org/abs/2602.01246)
*Jamshid Mozafari,Seyed Parsa Mousavinasab,Adam Jatowt*

Main category: cs.CL

TL;DR: PARSE是首个波斯语开放领域推理问答基准，包含10,800个问题，涵盖布尔、多项选择和事实型格式，支持波斯语LLM的公平评估和实际应用。


<details>
  <summary>Details</summary>
Motivation: 波斯语作为拥有约1.3亿使用者的语言，缺乏高质量的开放领域推理问答基准，这阻碍了波斯语LLM的发展和评估。

Method: 通过受控的LLM生成管道构建基准，包含多阶段过滤、人工标注和一致性检查，确保语言和事实质量。

Result: 波斯语提示和结构化提示（布尔/多项选择用思维链，事实型用少样本）能提升性能，微调进一步改善结果，特别是波斯语专用模型。

Conclusion: PARSE填补了波斯语QA研究的关键空白，为低资源环境下开发和评估推理能力强的LLM提供了坚实基础。

Abstract: Reasoning-focused Question Answering (QA) has advanced rapidly with Large Language Models (LLMs), yet high-quality benchmarks for low-resource languages remain scarce. Persian, spoken by roughly 130 million people, lacks a comprehensive open-domain resource for evaluating reasoning-capable QA systems. We introduce PARSE, the first open-domain Persian reasoning QA benchmark, containing 10,800 questions across Boolean, multiple-choice, and factoid formats, with diverse reasoning types, difficulty levels, and answer structures. The benchmark is built via a controlled LLM-based generation pipeline and validated through human evaluation. We also ensure linguistic and factual quality through multi-stage filtering, annotation, and consistency checks. We benchmark multilingual and Persian LLMs under multiple prompting strategies and show that Persian prompts and structured prompting (CoT for Boolean/multiple-choice; few-shot for factoid) improve performance. Fine-tuning further boosts results, especially for Persian-specialized models. These findings highlight how PARSE supports both fair comparison and practical model adaptation. PARSE fills a critical gap in Persian QA research and provides a strong foundation for developing and evaluating reasoning-capable LLMs in low-resource settings.

</details>


### [84] [PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length](https://arxiv.org/abs/2602.01274)
*Situo Zhang,Yifan Zhang,Zichen Zhu,Hankun Wang,Da Ma,Danyang Zhang,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: Pacer是一种动态控制草稿长度的推测解码方法，通过轻量级预验证层实现块级预验证，相比固定草稿长度的标准推测解码获得更快的解码速度


<details>
  <summary>Details</summary>
Motivation: 标准推测解码使用固定草稿长度，但实验发现不同解码步骤的最佳草稿长度差异很大，固定长度限制了进一步加速的潜力

Method: 提出Pacer方法，使用轻量级可训练预验证层对草稿令牌进行块级预验证，在预验证失败时停止令牌生成，实现动态草稿长度控制

Result: Pacer在多个基准测试中达到最高2.66倍的自回归解码加速，始终优于标准推测解码；与Ouroboros集成后达到最高3.09倍加速

Conclusion: Pacer通过动态控制草稿长度解决了固定长度限制问题，显著提升了推测解码的效率，为LLM推理加速提供了有效方案

Abstract: Speculative decoding (SD) is a powerful technique for accelerating the inference process of large language models (LLMs) without sacrificing accuracy. Typically, SD employs a small draft model to generate a fixed number of draft tokens, which are then verified in parallel by the target model. However, our experiments reveal that the optimal draft length varies significantly across different decoding steps. This variation suggests that using a fixed draft length limits the potential for further improvements in decoding speed. To address this challenge, we propose Pacer, a novel approach that dynamically controls draft length using a lightweight, trainable pre-verification layer. This layer pre-verifies draft tokens blockwise before they are sent to the target model, allowing the draft model to stop token generation if the blockwise pre-verification fails. We implement Pacer on multiple SD model pairs and evaluate its performance across various benchmarks. Our results demonstrate that Pacer achieves up to 2.66x Speedup over autoregressive decoding and consistently outperforms standard speculative decoding. Furthermore, when integrated with Ouroboros, Pacer attains up to 3.09x Speedup.

</details>


### [85] [EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language ModelsEverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models](https://arxiv.org/abs/2602.01313)
*Chuanrui Hu,Tong Li,Xingze Gao,Hongda Chen,Dannong Xu,Yi Bai,Tianwei Lin,Xinda Zhao,Xiaohong Li,Jiaqi An,Yunyun Han,Jian Pei,Yafeng Deng*

Main category: cs.CL

TL;DR: EverMemBench是一个用于评估LLM长期对话记忆的新基准，包含多参与者、多群组、跨主题的复杂对话，揭示了现有记忆系统在多跳推理、时序推理和记忆检索方面的严重局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注二元、单一主题的对话，无法捕捉现实世界中多参与者、多群组、跨主题交织的复杂对话场景，因此需要更贴近真实场景的长期对话记忆评估基准。

Method: 构建EverMemBench基准，包含超过100万token的多参与者、多群组对话，具有时序演化信息、跨主题交织和角色特定人设特征。通过1000多个QA对从三个维度评估记忆系统：细粒度回忆、记忆意识和用户画像理解。

Result: 评估揭示了三个关键局限：1) 多参与者场景下多跳推理崩溃，即使oracle模型准确率也只有26%；2) 时序推理仍未解决，需要超越时间戳匹配的版本语义；3) 记忆意识受检索瓶颈限制，当前基于相似度的方法无法弥合查询与隐式相关记忆之间的语义鸿沟。

Conclusion: EverMemBench为开发下一代记忆架构提供了一个具有挑战性的测试平台，突显了现有记忆系统在处理复杂现实对话场景时的不足，特别是多跳推理、时序推理和语义检索方面需要根本性改进。

Abstract: Long-term conversational memory is essential for LLM-based assistants, yet existing benchmarks focus on dyadic, single-topic dialogues that fail to capture real-world complexity. We introduce EverMemBench, a benchmark featuring multi-party, multi-group conversations spanning over 1 million tokens with temporally evolving information, cross-topic interleaving, and role-specific personas. EverMemBench evaluates memory systems across three dimensions through 1,000+ QA pairs: fine-grained recall, memory awareness, and user profile understanding. Our evaluation reveals critical limitations: (1) multi-hop reasoning collapses in multi-party settings, with even oracle models achieving only 26%; (2) temporal reasoning remains unsolved, requiring version semantics beyond timestamp matching; (3) memory awareness is bottlenecked by retrieval, where current similarity-based methods fail to bridge the semantic gap between queries and implicitly relevant memories. EverMemBench provides a challenging testbed for developing next-generation memory architectures.

</details>


### [86] [DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas](https://arxiv.org/abs/2602.01326)
*Zirui Wu,Lin Zheng,Zhihui Xie,Jiacheng Ye,Jiahui Gao,Shansan Gong,Yansong Feng,Zhenguo Li,Wei Bi,Guorui Zhou,Lingpeng Kong*

Main category: cs.CL

TL;DR: DreamOn是一个新颖的扩散框架，解决了扩散语言模型需要固定长度掩码序列的限制，实现了动态可变长度的代码填充生成。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然提供了灵活的非自回归填充能力，但实际应用受到固定长度掩码序列要求的限制。当预定义的掩码大小与理想完成长度不匹配时，代码填充性能会严重下降。

Method: DreamOn在扩散过程中引入了两种长度控制状态，使模型能够基于自身预测自主扩展或收缩输出长度。该方法只需对现有扩散语言模型的训练目标进行最小修改，无需架构更改。

Result: 基于Dream-Coder-7B和DiffuCoder-7B构建的DreamOn在HumanEval-Infilling和SantaCoder-FIM上实现了与最先进自回归模型相当的填充性能，并匹配了使用真实长度获得的oracle性能。

Conclusion: DreamOn消除了扩散语言模型实际部署的一个基本障碍，显著提升了其在可变长度生成方面的灵活性和适用性。

Abstract: Diffusion Language Models (DLMs) present a compelling alternative to autoregressive models, offering flexible, any-order infilling without specialized prompting design. However, their practical utility is blocked by a critical limitation: the requirement of a fixed-length masked sequence for generation. This constraint severely degrades code infilling performance when the predefined mask size mismatches the ideal completion length. To address this, we propose DreamOn, a novel diffusion framework that enables dynamic, variable-length generation. DreamOn augments the diffusion process with two length control states, allowing the model to autonomously expand or contract the output length based solely on its own predictions. We integrate this mechanism into existing DLMs with minimal modifications to the training objective and no architectural changes. Built upon Dream-Coder-7B and DiffuCoder-7B, DreamOn achieves infilling performance on par with state-of-the-art autoregressive models on HumanEval-Infilling and SantaCoder-FIM and matches oracle performance achieved with ground-truth length. Our work removes a fundamental barrier to the practical deployment of DLMs, significantly advancing their flexibility and applicability for variable-length generation. Our code is available at https://github.com/DreamLM/DreamOn.

</details>


### [87] [CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering](https://arxiv.org/abs/2602.01348)
*Yu Liu,Wenxiao Zhang,Cong Cao,Fangfang Yuan,Weizhuo Chen,Cheng Hu,Pin Xu,Yuling Yang,Kun Peng,Diandian Guo,Qiang Sun,Yanbing Liu,Jin B. Hong,Zhiyuan Ma*

Main category: cs.CL

TL;DR: CRAFT是一个基于强化学习的框架，通过双奖励机制优化多跳问答中的推理过程，提高答案准确性和推理忠实性。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强生成在多跳问答中面临三个挑战：1) 推理崩溃：多跳组合和噪声检索使推理不稳定；2) 推理-答案不一致：LLM生成的不确定性可能导致答案正确但推理不忠实；3) 格式控制丢失：传统思维链生成常偏离结构化输出格式要求。

Method: 提出CRAFT框架，基于组相对策略优化的强化学习方法，采用双奖励机制：确定性奖励确保结构正确性，基于评判器的奖励验证语义忠实性。支持可控的推理轨迹变体，系统分析结构和规模对推理性能的影响。

Result: 在三个多跳问答基准测试中，CRAFT提高了答案准确性和推理忠实性。CRAFT 7B模型在多个推理轨迹设置下与闭源LLM竞争性表现相当。

Conclusion: CRAFT通过强化学习框架有效解决了多跳问答中的推理忠实性问题，在不同模型规模上都能提高推理性能，为可控和忠实的推理生成提供了有效解决方案。

Abstract: Retrieval-augmented generation (RAG) is widely used to ground Large Language Models (LLMs) for multi-hop question answering. Recent work mainly focused on improving answer accuracy via fine-tuning and structured or reinforcement-based optimization. However, reliable reasoning in response generation faces three challenges: 1) Reasoning Collapse. Reasoning in multi-hop QA is inherently complex due to multi-hop composition and is further destabilized by noisy retrieval. 2) Reasoning-answer inconsistency. Due to the intrinsic uncertainty of LLM generation and exposure to evidence--distractor mixtures, models may produce correct answers that are not faithfully supported by their intermediate reasoning or evidence. 3) Loss of format control. Traditional chain-of-thought generation often deviates from required structured output formats, leading to incomplete or malformed structured content. To address these challenges, we propose CRAFT (Calibrated Reasoning with Answer-Faithful Traces), a Group Relative Policy Optimization (GRPO) based reinforcement learning framework that trains models to perform faithful reasoning during response generation. CRAFT employs dual reward mechanisms to optimize multi-hop reasoning: deterministic rewards ensure structural correctness while judge-based rewards verify semantic faithfulness. This optimization framework supports controllable trace variants that enable systematic analysis of how structure and scale affect reasoning performance and faithfulness. Experiments on three multi-hop QA benchmarks show that CRAFT improves both answer accuracy and reasoning faithfulness across model scales, with the CRAFT 7B model achieving competitive performance with closed-source LLMs across multiple reasoning trace settings.

</details>


### [88] [Balancing Understanding and Generation in Discrete Diffusion Models](https://arxiv.org/abs/2602.01362)
*Yue Liu,Yuzhong Zhao,Zheyong Xie,Qixiang Ye,Jianbin Jiao,Yao Hu,Shaosheng Cao,Yunfan Liu*

Main category: cs.CL

TL;DR: XDLM统一了掩码扩散语言模型（MDLM）和均匀噪声扩散语言模型（UDLM），通过平稳噪声核桥接两种范式，在语义理解和生成质量之间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有离散生成模型存在性能不平衡问题：MDLM擅长语义理解和零样本泛化，UDLM在少步生成质量上表现优异，但两者都无法在理解和生成之间取得平衡。

Method: 提出XDLM，通过平稳噪声核桥接MDLM和UDLM两种范式，提供理论统一框架，并通过代数简化后验概率缓解内存瓶颈。

Result: XDLM在理解和生成之间推进了帕累托前沿：零样本文本基准超越UDLM 5.4分，少步图像生成FID优于MDLM（54.1 vs 80.8），调优8B参数大模型在32步内达到15.0 MBPP，性能翻倍。

Conclusion: XDLM成功统一了MDLM和UDLM，在理解和生成能力之间取得更好平衡，训练动态分析显示其具有优越的长期扩展潜力。

Abstract: In discrete generative modeling, two dominant paradigms demonstrate divergent capabilities: Masked Diffusion Language Models (MDLM) excel at semantic understanding and zero-shot generalization, whereas Uniform-noise Diffusion Language Models (UDLM) achieve strong few-step generation quality, yet neither attains balanced performance across both dimensions. To address this, we propose XDLM, which bridges the two paradigms via a stationary noise kernel. XDLM offers two key contributions: (1) it provides a principled theoretical unification of MDLM and UDLM, recovering each paradigm as a special case; and (2) an alleviated memory bottleneck enabled by an algebraic simplification of the posterior probabilities. Experiments demonstrate that XDLM advances the Pareto frontier between understanding capability and generation quality. Quantitatively, XDLM surpasses UDLM by 5.4 points on zero-shot text benchmarks and outperforms MDLM in few-step image generation (FID 54.1 vs. 80.8). When scaled to tune an 8B-parameter large language model, XDLM achieves 15.0 MBPP in just 32 steps, effectively doubling the baseline performance. Finally, analysis of training dynamics reveals XDLM's superior potential for long-term scaling. Code is available at https://github.com/MzeroMiko/XDLM

</details>


### [89] [Context Dependence and Reliability in Autoregressive Language Models](https://arxiv.org/abs/2602.01378)
*Poushali Sengupta,Shashi Raj Pandey,Sabita Maharjan,Frank Eliassen*

Main category: cs.CL

TL;DR: RISE方法通过量化每个输入相对于其他输入的独特影响，减少冗余信息对解释的影响，为LLM提供更清晰稳定的归因解释。


<details>
  <summary>Details</summary>
Motivation: LLM生成输出时使用大量上下文，其中常包含来自提示、检索段落和交互历史的冗余信息。在关键应用中，需要识别真正影响输出的上下文元素，但标准解释方法难以处理冗余和重叠上下文。输入的微小变化可能导致归因分数不可预测的偏移，损害可解释性并引发对提示注入等风险的担忧。

Method: 提出RISE（冗余不敏感解释评分）方法，量化每个输入相对于其他输入的独特影响，最小化冗余的影响，提供更清晰、稳定的归因。

Result: 实验表明，RISE比传统方法提供更稳健的解释，强调了条件信息对于可信赖的LLM解释和监控的重要性。

Conclusion: RISE方法能够有效区分基本上下文元素与相关元素，减少冗余信息对解释的影响，为LLM提供更可靠、稳定的归因解释，增强可解释性和风险监控能力。

Abstract: Large language models (LLMs) generate outputs by utilizing extensive context, which often includes redundant information from prompts, retrieved passages, and interaction history. In critical applications, it is vital to identify which context elements actually influence the output, as standard explanation methods struggle with redundancy and overlapping context. Minor changes in input can lead to unpredictable shifts in attribution scores, undermining interpretability and raising concerns about risks like prompt injection. This work addresses the challenge of distinguishing essential context elements from correlated ones. We introduce RISE (Redundancy-Insensitive Scoring of Explanation), a method that quantifies the unique influence of each input relative to others, minimizing the impact of redundancies and providing clearer, stable attributions. Experiments demonstrate that RISE offers more robust explanations than traditional methods, emphasizing the importance of conditional information for trustworthy LLM explanations and monitoring.

</details>


### [90] [On the Power of (Approximate) Reward Models for Inference-Time Scaling](https://arxiv.org/abs/2602.01381)
*Youheng Zhu,Yiping Lu*

Main category: cs.CL

TL;DR: 论文从理论上证明了在推理时缩放中使用近似奖励模型的有效性条件：当近似奖励模型的贝尔曼误差有界时，SMC方法可将推理计算复杂度从指数级降低到多项式级。


<details>
  <summary>Details</summary>
Motivation: 当前推理时缩放方法依赖近似奖励模型，但缺乏理论解释为什么近似奖励模型能有效工作。本文旨在从理论上回答：为什么以及何时近似奖励模型足以支持有效的推理时缩放。

Method: 采用理论分析方法，识别近似奖励模型的贝尔曼误差作为关键指标。分析Sequential Monte Carlo（SMC）框架下推理过程的计算复杂度，证明当贝尔曼误差有界时的性能保证。

Result: 对于长度为T的推理过程，如果近似奖励模型的贝尔曼误差有界于O(1/T)，那么结合SMC可将推理计算复杂度从指数级降低到多项式级，实现指数级的推理效率提升。

Conclusion: 近似奖励模型的贝尔曼误差是决定推理时缩放效果的关键因素，当误差有界时，即使使用近似奖励也能显著提升推理效率，这为实际部署提供了理论依据。

Abstract: Inference-time scaling has recently emerged as a powerful paradigm for improving the reasoning capability of large language models. Among various approaches, Sequential Monte Carlo (SMC) has become a particularly important framework, enabling iterative generation, evaluation, rejection, and resampling of intermediate reasoning trajectories. A central component in this process is the reward model, which evaluates partial solutions and guides the allocation of computation during inference.
  However, in practice, true reward models are never available. All deployed systems rely on approximate reward models, raising a fundamental question: Why and when do approximate reward models suffice for effective inference-time scaling? In this work, we provide a theoretical answer. We identify the Bellman error of the approximate reward model as the key quantity governing the effectiveness of SMC-based inference-time scaling. For a reasoning process of length $T$, we show that if the Bellman error of the approximate reward model is bounded by $O(1/T)$, then combining this reward model with SMC reduces the computational complexity of reasoning from exponential in $T$ to polynomial in $T$. This yields an exponential improvement in inference efficiency despite using only approximate rewards.

</details>


### [91] [Rethinking Selective Knowledge Distillation](https://arxiv.org/abs/2602.01395)
*Almog Tavor,Itay Ebenspanger,Neil Cnaan,Mor Geva*

Main category: cs.CL

TL;DR: 该论文提出了一种基于学生熵引导的位置选择知识蒸馏方法(SE-KD)，通过系统分析选择性蒸馏的三个维度（位置、类别、样本），开发出更高效的知识蒸馏框架，显著提升了LLM的蒸馏效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的知识蒸馏方法中，选择性蒸馏（选择部分token位置、词汇类别或训练样本进行监督）虽然被广泛采用，但缺乏对重要性信号、选择策略及其相互作用的系统性理解。研究者希望明确在自回归LLMs中"在哪里蒸馏"和"如何蒸馏"的问题。

Method: 首先解构选择性知识蒸馏的三个维度（位置、类别、样本），系统比较重要性信号和选择策略。然后基于分析结果，提出学生熵引导的位置选择方法(SE-KD)。进一步将该方法扩展到类别和样本维度，形成SE-KD 3X框架，实现跨维度的互补效率提升。

Result: SE-KD在多个基准测试中相比密集蒸馏，在准确性、下游任务遵循性和内存效率方面都有提升。SE-KD 3X进一步带来互补的效率增益，使离线教师缓存变得可行。实际应用中，相比先前方法，减少了70%的wall time、18%的峰值内存使用，并降低了80%的存储空间，同时不牺牲性能。

Conclusion: 通过系统性分析选择性知识蒸馏的各个维度，提出的学生熵引导蒸馏方法(SE-KD)及其扩展版本(SE-KD 3X)在保持性能的同时，显著提升了LLM知识蒸馏的效率和实用性，为大规模模型蒸馏提供了更可行的解决方案。

Abstract: Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance.

</details>


### [92] [From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis](https://arxiv.org/abs/2602.01401)
*Niansong Zhang,Sunwoo Kim,Shreesha Srinath,Zhiru Zhang*

Main category: cs.CL

TL;DR: 本文认为在AI驱动的硬件设计时代，高层次综合（HLS）仍然至关重要，它作为代理优化的自然层，提供快速迭代、可移植性和设计可置换性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型推动AI驱动的硬件设计兴起，探讨在代理时代HLS是否仍然重要。作者认为HLS保持其必要性，特别是在支持代理优化方面具有独特优势。

Method: 这是一篇立场论文，通过三个主要贡献来阐述观点：1) 解释HLS作为代理硬件设计的实用抽象层和黄金参考；2) 识别当前HLS工具的关键限制；3) 提出代理HLS共生演化的分类法。

Result: 论文确立了HLS在代理时代的关键作用，识别了当前HLS工具的三个主要限制：性能反馈不足、接口僵化和可调试性有限，并提出了从副驾驶到自主设计伙伴的演化路径。

Conclusion: HLS在AI驱动的硬件设计时代仍然至关重要，它作为代理优化的自然层，其与AI代理的共生演化将推动硬件设计从人类主导转向AI代理主导的自主设计伙伴关系。

Abstract: The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware systems to leverage both HLS and RTL, this paper focuses on HLS and its role in enabling agentic optimization. HLS offers faster iteration cycles, portability, and design permutability that make it a natural layer for agentic optimization.This position paper makes three contributions. First, we explain why HLS serves as a practical abstraction layer and a golden reference for agentic hardware design. Second, we identify key limitations of current HLS tools, namely inadequate performance feedback, rigid interfaces, and limited debuggability that agents are uniquely positioned to address. Third, we propose a taxonomy for the symbiotic evolution of agentic HLS, clarifying how responsibility shifts from human designers to AI agents as systems advance from copilots to autonomous design partners.

</details>


### [93] [SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction](https://arxiv.org/abs/2602.01447)
*Hieu Minh Duong,Rupa Ghosh,Cong Hoan Nguyen,Eugene Levin,Todd Gary,Long Nguyen*

Main category: cs.CL

TL;DR: SentiFuse是一个灵活、模型无关的情感分析框架，通过标准化层和多种融合策略整合异构模型，在三个大规模社交媒体数据集上优于单个模型和简单集成。


<details>
  <summary>Details</summary>
Motivation: 现有情感分析模型具有互补优势，但缺乏有效整合的统一框架。需要系统性地利用模型互补性来提高情感分析的准确性和可靠性。

Method: 提出SentiFuse框架，包含标准化层和三种融合策略：决策级融合、特征级融合和自适应融合，支持异构情感模型的系统组合。

Result: 在Crowdflower、GoEmotions和Sentiment140三个数据集上，SentiFuse始终优于单个模型和简单集成。特征级融合效果最好，F1分数比最佳单个模型和简单平均提高最多4%；自适应融合在处理否定、混合情感等复杂情况时增强鲁棒性。

Conclusion: 系统性地利用模型互补性能够实现更准确、可靠的情感分析，适用于不同数据集和文本类型。SentiFuse为整合异构情感模型提供了有效框架。

Abstract: Sentiment analysis models exhibit complementary strengths, yet existing approaches lack a unified framework for effective integration. We present SentiFuse, a flexible and model-agnostic framework that integrates heterogeneous sentiment models through a standardization layer and multiple fusion strategies. Our approach supports decision-level fusion, feature-level fusion, and adaptive fusion, enabling systematic combination of diverse models. We conduct experiments on three large-scale social-media datasets: Crowdflower, GoEmotions, and Sentiment140. These experiments show that SentiFuse consistently outperforms individual models and naive ensembles. Feature-level fusion achieves the strongest overall effectiveness, yielding up to 4\% absolute improvement in F1 score over the best individual model and simple averaging, while adaptive fusion enhances robustness on challenging cases such as negation, mixed emotions, and complex sentiment expressions. These results demonstrate that systematically leveraging model complementarity yields more accurate and reliable sentiment analysis across diverse datasets and text types.

</details>


### [94] [Understanding QA generation: Extracting Parametric and Contextual Knowledge with CQA for Low Resource Bangla Language](https://arxiv.org/abs/2602.01451)
*Umme Abira Azmary,MD Ikramul Kayes,Swakkhar Shatabda,Farig Yousuf Sadeque*

Main category: cs.CL

TL;DR: 本文针对孟加拉语等低资源语言QA模型面临的挑战，提出了首个孟加拉语反事实QA数据集BanglaCQA，并开发了多种模型评估框架来分析参数知识与上下文知识的使用情况。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如孟加拉语）的QA模型面临标注数据有限和语言复杂性的挑战。现有孟加拉语QA数据集缺乏分析模型依赖参数知识还是上下文知识的结构，需要专门的数据集和方法来解耦这两种知识来源。

Method: 1) 创建BanglaCQA数据集，扩展现有孟加拉语数据集并集成反事实段落和可回答性标注；2) 提出针对编码器-解码器语言特定/多语言模型的微调流程；3) 为仅解码器LLM设计基于提示的流程；4) 应用基于LLM和人工的语义相似度评估技术；5) 使用思维链提示分析反事实场景中的知识提取。

Result: 研究发现思维链提示在反事实场景中特别有效，尤其是在仅解码器LLM中提取参数知识。研究提供了低资源语言QA模型在不同设置下的详细性能分析，揭示了模型知识来源的依赖模式。

Conclusion: 该工作不仅为分析孟加拉语QA模型的知识来源提供了新框架，还发现了反事实推理在低资源语言环境中的关键发现，为相关研究开辟了更广泛的方向。

Abstract: Question-Answering (QA) models for low-resource languages like Bangla face challenges due to limited annotated data and linguistic complexity. A key issue is determining whether models rely more on pre-encoded (parametric) knowledge or contextual input during answer generation, as existing Bangla QA datasets lack the structure required for such analysis. We introduce BanglaCQA, the first Counterfactual QA dataset in Bangla, by extending a Bangla dataset while integrating counterfactual passages and answerability annotations. In addition, we propose fine-tuned pipelines for encoder-decoder language-specific and multilingual baseline models, and prompting-based pipelines for decoder-only LLMs to disentangle parametric and contextual knowledge in both factual and counterfactual scenarios. Furthermore, we apply LLM-based and human evaluation techniques that measure answer quality based on semantic similarity. We also present a detailed analysis of how models perform across different QA settings in low-resource languages, and show that Chain-of-Thought (CoT) prompting reveals a uniquely effective mechanism for extracting parametric knowledge in counterfactual scenarios, particularly in decoder-only LLMs. Our work not only introduces a novel framework for analyzing knowledge sources in Bangla QA but also uncovers critical findings that open up broader directions for counterfactual reasoning in low-resource language settings.

</details>


### [95] [ConPress: Learning Efficient Reasoning from Multi-Question Contextual Pressure](https://arxiv.org/abs/2602.01472)
*Jie Deng,Shining Liang,Jun Li,Hongzhi Li,Yutao Xie*

Main category: cs.CL

TL;DR: 论文提出ConPress方法，通过多问题上下文压力诱导模型自我压缩推理轨迹，减少推理开销


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长链式思维轨迹解决推理任务，导致显著推理开销。研究发现多问题上下文能自发压缩推理轨迹，但需要方法将这种能力内化到单问题场景

Method: 提出ConPress自监督微调方法：1) 构建多问题提示诱导自我压缩；2) 采样模型输出；3) 解析过滤每个问题的推理轨迹；4) 使用简洁正确的轨迹进行监督微调

Result: 仅用8k微调样本，在MATH500上减少59%推理token使用，在AIME25上减少33%推理token使用，同时保持竞争力准确率

Conclusion: ConPress通过利用模型自身的自我压缩现象，实现了轻量级、无外部教师、无需人工修剪或强化学习的推理压缩，显著降低推理成本

Abstract: Large reasoning models (LRMs) typically solve reasoning-intensive tasks by generating long chain-of-thought (CoT) traces, leading to substantial inference overhead. We identify a reproducible inference-time phenomenon, termed Self-Compression: when multiple independent and answerable questions are presented within a single prompt, the model spontaneously produces shorter reasoning traces for each question. This phenomenon arises from multi-question contextual pressure during generation and consistently manifests across models and benchmarks. Building on this observation, we propose ConPress (Learning from Contextual Pressure), a lightweight self-supervised fine-tuning approach. ConPress constructs multi-question prompts to induce self-compression, samples the resulting model outputs, and parses and filters per-question traces to obtain concise yet correct reasoning trajectories. These trajectories are directly used for supervised fine-tuning, internalizing compressed reasoning behavior in single-question settings without external teachers, manual pruning, or reinforcement learning. With only 8k fine-tuning examples, ConPress reduces reasoning token usage by 59% on MATH500 and 33% on AIME25, while maintaining competitive accuracy.

</details>


### [96] [Ebisu: Benchmarking Large Language Models in Japanese Finance](https://arxiv.org/abs/2602.01479)
*Xueqing Peng,Ruoyu Xiang,Fan Zhang,Mingzi Song,Mingyang Jiang,Yan Wang,Lingfei Qian,Taiki Hara,Yuqing Guo,Jimin Huang,Junichi Tsujii,Sophia Ananiadou*

Main category: cs.CL

TL;DR: Ebisu是一个针对日语金融语言理解的基准测试，包含两个专家标注的任务：JF-ICR（评估投资者问答中的隐含承诺与拒绝识别）和JF-TE（评估专业披露中嵌套金融术语的层次提取与排序）。


<details>
  <summary>Details</summary>
Motivation: 日语金融语言具有粘着语、头尾结构、混合书写系统以及依赖间接表达和隐含承诺的高语境沟通规范，这些特点对LLMs构成了重大挑战，需要专门的基准测试来评估和改进模型在这方面的能力。

Method: 创建Ebisu基准测试，包含两个基于语言和文化背景的任务：JF-ICR（隐含承诺与拒绝识别）和JF-TE（术语提取）。评估了多种开源和专有LLMs，包括通用模型、日语适应模型和金融专用模型。

Result: 即使是先进的系统在这两个任务上都表现不佳。虽然增加模型规模带来有限的改进，但语言和领域特定的适应并不能可靠地提高性能，仍存在显著差距。

Conclusion: Ebisu为推进基于语言和文化背景的金融NLP提供了重点基准测试，所有数据集和评估脚本都已公开发布。

Abstract: Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.

</details>


### [97] [Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training](https://arxiv.org/abs/2602.01511)
*Ran Xu,Tianci Liu,Zihan Dong,Tony You,Ilgee Hong,Carl Yang,Linjun Zhang,Tao Zhao,Haoyu Wang*

Main category: cs.CL

TL;DR: Rubric-ARM：通过强化学习联合优化评分标准和评判模型，解决传统奖励模型在非可验证领域（如创意写作）中单一标量评分不足的问题，实现更准确的多维度质量评估。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型使用单一标量分数预测响应质量，无法捕捉非可验证领域（如创意写作、开放式指令遵循）中响应质量的多维度特性。现有方法依赖静态评分标准或分离的训练流程，限制了评估的准确性和适应性。

Method: 提出Rubric-ARM框架，通过强化学习从偏好反馈中联合优化评分标准生成器和评判模型。将评分标准生成视为潜在动作学习，以最大化判断准确性。引入交替优化策略缓解同时更新的非平稳性问题，并提供理论分析证明该策略能降低训练中的梯度方差。

Result: 在多个基准测试中，Rubric-ARM实现了最先进的性能，显著优于基线方法。在离线和在线强化学习设置中，都能显著改善下游策略对齐效果。

Conclusion: Rubric-ARM通过联合学习评分标准和评判模型，有效解决了传统奖励模型在非可验证领域的局限性，为复杂响应质量评估提供了更准确、自适应的解决方案。

Abstract: Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.

</details>


### [98] [Argument Rarity-based Originality Assessment for AI-Assisted Writing](https://arxiv.org/abs/2602.01560)
*Keito Inoshita,Michiaki Omura,Tsukasa Yamanaka,Go Maeda,Kentaro Tsuji*

Main category: cs.CL

TL;DR: 论文提出AROA框架，基于论证稀有性自动评估学生议论文的原创性，将原创性定义为参考语料库中的稀有性，包含结构、论点、证据和认知深度四个维度，发现质量与原创性存在权衡关系，AI能模仿论证结构但论点原创性不足。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能够轻松生成高质量文本，传统的质量导向写作评估正在失去意义。如果教育的核心目标是培养批判性思维和原创观点，评估范式必须从质量转向原创性。

Method: 提出论证稀有性原创性评估框架，将原创性定义为参考语料库中的稀有性，通过四个互补组件评估：结构稀有性、论点稀有性、证据稀有性和认知深度。使用密度估计量化每个组件的稀有性，并通过质量调整机制整合，将质量和原创性视为独立的评估维度。

Result: 实验发现人类论文质量与论点稀有性呈强负相关，表明存在质量-原创性权衡：质量越高的文本倾向于使用典型的论点模式。AI生成的论文在结构复杂性上与人类相当，但论点稀有性显著低于人类，表明LLM能复制论证形式但在内容原创性上有局限。

Conclusion: AROA框架为自动评估论证原创性提供了有效方法，揭示了质量与原创性的权衡关系，并表明当前LLM在模仿论证结构方面表现良好，但在生成原创论点方面仍有不足，这对教育评估范式转变具有重要意义。

Abstract: As Large Language Models (LLMs) have become capable of effortlessly generating high-quality text, traditional quality-focused writing assessment is losing its significance. If the essential goal of education is to foster critical thinking and original perspectives, assessment must also shift its paradigm from quality to originality. This study proposes Argument Rarity-based Originality Assessment (AROA), a framework for automatically evaluating argumentative originality in student essays. AROA defines originality as rarity within a reference corpus and evaluates it through four complementary components: structural rarity, claim rarity, evidence rarity, and cognitive depth. The framework quantifies the rarity of each component using density estimation and integrates them with a quality adjustment mechanism, thereby treating quality and originality as independent evaluation axes. Experiments using human essays and AI-generated essays revealed a strong negative correlation between quality and claim rarity, demonstrating a quality-originality trade-off where higher-quality texts tend to rely on typical claim patterns. Furthermore, while AI essays achieved comparable levels of structural complexity to human essays, their claim rarity was substantially lower than that of humans, indicating that LLMs can reproduce the form of argumentation but have limitations in the originality of content.

</details>


### [99] [FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents](https://arxiv.org/abs/2602.01566)
*Chiwei Zhu,Benfeng Xu,Mingxuan Du,Shaohan Wang,Xiaorui Wang,Zhendong Mao,Yongdong Zhang*

Main category: cs.CL

TL;DR: FS-Researcher是一个基于文件系统的双智能体框架，通过持久化工作空间解决LLM在深度研究任务中上下文长度限制的问题，实现超越上下文窗口的扩展研究能力。


<details>
  <summary>Details</summary>
Motivation: 深度研究任务通常涉及长轨迹，容易超过LLM的上下文限制，压缩了证据收集和报告编写的token预算，阻碍了有效的测试时扩展。

Method: 采用基于文件系统的双智能体框架：1) Context Builder智能体作为图书管理员，浏览互联网、编写结构化笔记、将原始资料归档到可超越上下文长度的分层知识库；2) Report Writer智能体将知识库作为事实来源，逐节编写最终报告。文件系统作为持久化外部内存和跨智能体/会话的共享协调媒介。

Result: 在两个开放式基准测试（DeepResearch Bench和DeepConsult）上，FS-Researcher在不同骨干模型上都实现了最先进的报告质量。分析显示最终报告质量与分配给Context Builder的计算量呈正相关，验证了文件系统范式下的有效测试时扩展。

Conclusion: FS-Researcher通过文件系统作为持久化工作空间，成功解决了LLM在深度研究任务中的上下文限制问题，实现了超越上下文窗口的扩展研究能力，为长视野任务提供了有效的解决方案。

Abstract: Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.

</details>


### [100] [LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States](https://arxiv.org/abs/2602.01572)
*Yeqin Zhang,Yunfei Wang,Jiaxuan Chen,Ke Qin,Yizheng Zhao,Cam-Tu Nguyen*

Main category: cs.CL

TL;DR: 本文提出Value Aggregation方法，通过聚合注意力值向量而非隐藏状态来获取更好的句子表示，在无需训练的情况下超越了现有LLM嵌入方法，甚至匹配或超越了集成方法MetaEOL。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型（LLM）的句子表示方法大多依赖最后一层隐藏状态，但这些状态是为下一个词预测优化的，往往无法有效捕捉全局的句子级语义。

Method: 提出Value Aggregation（VA）方法，聚合多个层和词索引的token值向量。进一步提出Aligned Weighted VA（AlignedWVA），利用最后一层token的注意力分数作为权重，通过输出投影矩阵（W_O）将加权值向量对齐到LLM残差流的公共空间。

Result: 在无需训练的情况下，VA超越了其他基于LLM的嵌入方法，甚至匹配或超越了集成方法MetaEOL。AlignedWVA在无需训练的LLM嵌入方法中达到了最先进的性能，大幅超越了高成本的MetaEOL。

Conclusion: 注意力值向量比隐藏状态更能有效捕捉句子语义，通过微调Value Aggregation有潜力获得强大的LLM嵌入模型。

Abstract: Sentence representations are foundational to many Natural Language Processing (NLP) applications. While recent methods leverage Large Language Models (LLMs) to derive sentence representations, most rely on final-layer hidden states, which are optimized for next-token prediction and thus often fail to capture global, sentence-level semantics. This paper introduces a novel perspective, demonstrating that attention value vectors capture sentence semantics more effectively than hidden states. We propose Value Aggregation (VA), a simple method that pools token values across multiple layers and token indices. In a training-free setting, VA outperforms other LLM-based embeddings, even matches or surpasses the ensemble-based MetaEOL. Furthermore, we demonstrate that when paired with suitable prompts, the layer attention outputs can be interpreted as aligned weighted value vectors. Specifically, the attention scores of the last token function as the weights, while the output projection matrix ($W_O$) aligns these weighted value vectors with the common space of the LLM residual stream. This refined method, termed Aligned Weighted VA (AlignedWVA), achieves state-of-the-art performance among training-free LLM-based embeddings, outperforming the high-cost MetaEOL by a substantial margin. Finally, we highlight the potential of obtaining strong LLM embedding models through fine-tuning Value Aggregation.

</details>


### [101] [Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment](https://arxiv.org/abs/2602.01587)
*Zehua Cheng,Jianwei Yang,Wei Dai,Jiahao Sun*

Main category: cs.CL

TL;DR: 提出Certified Semantic Smoothing (CSS)框架，通过分层随机消融和噪声增强对齐调优，为LLM提供可证明的鲁棒性保证，显著降低攻击成功率同时保持良性效用。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型对自适应越狱攻击仍然脆弱，经验性防御方法如GCG容易被绕过。需要从统计稳定性的角度提供可证明的安全保证，而不是依赖单次推理的安全性。

Method: 1) 提出Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation：将输入划分为不可变的结构提示和可变的载荷，利用超几何分布推导严格的l0范数保证；2) 采用Noise-Augmented Alignment Tuning (NAAT)：将基础模型转化为语义去噪器，解决稀疏上下文下的性能退化问题。

Result: 在Llama-3上的实验表明：梯度攻击的攻击成功率从84.2%降至1.2%，同时保持94.1%的良性效用。显著优于字符级基线方法（效用降至74.3%）。

Conclusion: 该框架提供了确定性的安全证书，确保模型在可证明半径内对所有对抗变体保持鲁棒性，将安全保证从单次推理转移到集成统计稳定性。

Abstract: Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.

</details>


### [102] [Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles](https://arxiv.org/abs/2602.01590)
*Shaohan Wang,Benfeng Xu,Licheng Zhang,Mingxuan Du,Chiwei Zhu,Xiaorui Wang,Zhendong Mao,Yongdong Zhang*

Main category: cs.CL

TL;DR: 提出Wiki Live Challenge (WLC)基准，利用最新的维基百科优质文章作为专家级参考，评估深度研究代理的能力，发现当前系统与人类专家水平存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理的评估框架主要依赖LLM生成的参考或LLM衍生的评估维度，这些方法虽然具有可扩展性，但缺乏专家验证内容的可靠性，难以提供客观、细粒度的关键维度评估。

Method: 引入Wiki Live Challenge (WLC)实时基准，利用最新的维基百科优质文章作为专家级参考，构建包含100篇近期优质文章的数据集，并提出Wiki Eval评估框架，包含39项写作质量标准和严格的事实可验证性指标。

Result: 对各种深度研究代理系统的广泛实验表明，当前深度研究代理与人类专家级维基百科文章之间存在显著差距，验证了WLC在推进代理研究方面的有效性。

Conclusion: WLC基准通过利用维基百科严格的中立性、全面性和可验证性标准，为深度研究代理提供了有效的评估框架，揭示了当前系统与专家水平之间的差距，有助于推动代理研究的进步。

Abstract: Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge

</details>


### [103] [The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation](https://arxiv.org/abs/2602.01598)
*Mingwen Zhang,Minqiang Yang,Changsheng Ma,Yang Yu,Hui Bai,Chen Xu,Xiangzhen Kong,Bin Hu*

Main category: cs.CL

TL;DR: 本文提出了Socratic Inquiry Framework (SIF)，一个轻量级、即插即用的治疗意图规划器，将LLM从被动倾听者转变为主动认知引导者，解决了当前心理LLM过于被动、无法引导行为改变的问题。


<details>
  <summary>Details</summary>
Motivation: 主动提问是认知行为疗法(CBT)的核心，但当前的心理大语言模型(LLM)仍然过度被动，倾向于提供共情但肤浅的回应，无法揭示潜在信念或引导行为改变。

Method: 提出了Socratic Inquiry Framework (SIF)，通过策略锚定(Strategy Anchoring)决定何时提问，通过模板检索(Template Retrieval)决定问什么，实现上下文感知、理论基础的提问而无需端到端重新训练。同时创建了Socratic-QA数据集，提供策略对齐的苏格拉底式序列监督。

Result: 实验表明SIF显著提高了主动提问频率、对话深度和治疗对齐性，标志着从被动安慰到主动探索的明显转变。

Conclusion: 该工作为心理LLM建立了新范式：不仅要回应，更要引导。SIF框架能够将LLM转变为主动的认知引导者，提升治疗效果。

Abstract: Proactive questioning, where therapists deliberately initiate structured, cognition-guiding inquiries, is a cornerstone of cognitive behavioral therapy (CBT). Yet, current psychological large language models (LLMs) remain overwhelmingly reactive, defaulting to empathetic but superficial responses that fail to surface latent beliefs or guide behavioral change. To bridge this gap, we propose the \textbf{Socratic Inquiry Framework (SIF)}, a lightweight, plug-and-play therapeutic intent planner that transforms LLMs from passive listeners into active cognitive guides. SIF decouples \textbf{when to ask} (via Strategy Anchoring) from \textbf{what to ask} (via Template Retrieval), enabling context-aware, theory-grounded questioning without end-to-end retraining. Complementing SIF, we introduce \textbf{Socratic-QA}, a high-quality dataset of strategy-aligned Socratic sequences that provides explicit supervision for proactive reasoning. Experiments show that SIF significantly enhances proactive questioning frequency, conversational depth, and therapeutic alignment, marking a clear shift from reactive comfort to proactive exploration. Our work establishes a new paradigm for psychologically informed LLMs: not just to respond, but to guide.

</details>


### [104] [SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia](https://arxiv.org/abs/2602.01618)
*Panuthep Tasawong,Jian Gang Ngui,Alham Fikri Aji,Trevor Cohn,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 提出SEA-Guard系列模型，首个基于东南亚文化背景的多语言安全防护模型，通过代理数据生成框架创建区域特定安全数据集，在检测区域敏感内容方面优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现实世界中的AI对齐需要文化感知的安全防护，但构建大规模文化基础数据集面临资源有限和本地标注者稀缺的挑战，现有方法依赖英语数据集翻译，缺乏区域文化细微差别

Method: 提出新颖的代理数据生成框架，可扩展地创建真实、区域特定的东南亚安全数据集，并在此基础上开发SEA-Guard系列多语言安全防护模型

Result: SEA-Guard在多个基准测试和文化变体评估中，在检测区域敏感或有害内容方面始终优于现有安全防护模型，同时保持强大的通用安全性能

Conclusion: 该研究成功开发了首个基于东南亚文化背景的多语言安全防护模型，通过创新的数据生成方法解决了文化感知AI对齐的挑战，为区域特定的AI安全提供了有效解决方案

Abstract: Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance.

</details>


### [105] [A2Eval: Agentic and Automated Evaluation for Embodied Brain](https://arxiv.org/abs/2602.01640)
*Shuai Zhang,Jiayu Hu,Zijie Chen,Zeyuan Ding,Yi Zhang,Yingji Zhang,Ziyi Zhou,Junwei Liao,Shengjie Zhou,Yong Dai,Zhenzhong Lan,Xiaozhu Ju*

Main category: cs.CL

TL;DR: A2Eval：首个通过两个协作智能体自动进行基准构建和评估的代理框架，显著压缩评估套件、降低计算成本，同时保持评估质量并纠正排名偏差。


<details>
  <summary>Details</summary>
Motivation: 当前具身VLM评估依赖静态、专家定义、人工标注的基准，存在严重冗余和覆盖不平衡问题。这种劳动密集型范式消耗大量计算和标注资源，增加成本，扭曲模型排名，最终阻碍迭代开发。

Method: 提出Agentic Automatic Evaluation (A2Eval)框架，包含两个协作智能体：Data Agent自主归纳能力维度并组装平衡、紧凑的评估套件；Eval Agent合成和验证可执行的评估管道，实现完全自主、高保真的评估。

Result: 在10个基准和13个模型上的评估显示：A2Eval压缩评估套件85%，降低总体计算成本77%，实现4.6倍加速，同时保持评估质量。纠正系统性排名偏差，将人类对齐度提升至Spearman's rho=0.85，保持高排名保真度(Kendall's tau=0.81)。

Conclusion: A2Eval为高保真、低成本的具身评估建立了新标准，通过自动化基准构建和评估解决了当前评估范式的关键瓶颈，显著提升了评估效率和准确性。

Abstract: Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.

</details>


### [106] [Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models](https://arxiv.org/abs/2602.01654)
*Jiaqian Li,Yanshu Li,Kuan-Hao Huang*

Main category: cs.CL

TL;DR: SVF提出了一种基于向量场的上下文相关转向方法，通过可微概念评分函数的局部梯度定义转向方向，解决了传统静态转向向量在长文本生成和多属性控制中的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 传统转向向量在实践中存在不可靠性：某些概念无法转向，即使平均效果良好也可能对部分输入产生反效果，且在长文本生成和多属性转向中可靠性下降。静态转向向量假设概念改进方向在所有上下文中恒定，当局部有效方向随当前激活变化时，单一全局向量会错位导致效果弱化或反转。

Method: 提出转向向量场（SVF），学习一个可微概念评分函数，其局部梯度定义每个激活点的转向方向，使干预明确依赖于上下文。该框架支持在共享对齐概念空间中进行协调的多层干预，并在统一框架内实现高效的长文本和多属性控制。

Result: 在多个LLM和转向任务中，SVF提供了更强、更可靠的控制，提高了推理时转向的实用性。

Conclusion: 通过几何视角分析转向失败，提出基于向量场的上下文相关转向方法，显著改善了推理时转向的可靠性和实用性。

Abstract: Steering vectors (SVs) offer a lightweight way to control large language models (LLMs) at inference time by shifting hidden activations, providing a practical middle ground between prompting and fine-tuning. Yet SVs can be unreliable in practice. Some concepts are unsteerable, and even when steering helps on average it can backfire for a non-trivial fraction of inputs. Reliability also degrades in long-form generation and multi-attribute steering. We take a geometric view of these failures. A static SV applies the same update vector everywhere in representation space, implicitly assuming that the concept-improving direction is constant across contexts. When the locally effective direction varies with the current activation, a single global vector can become misaligned, which yields weak or reversed effects. Guided by this perspective, we propose Steering Vector Fields (SVF), which learns a differentiable concept scoring function whose local gradient defines the steering direction at each activation, making interventions explicitly context-dependent. This formulation supports coordinated multi-layer interventions in a shared, aligned concept space, and enables efficient long-form and multi-attribute control within a unified framework. Across multiple LLMs and steering tasks, SVF delivers stronger and more reliable control, improving the practicality of inference-time steering.

</details>


### [107] [CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation](https://arxiv.org/abs/2602.01660)
*Zhongyuan Peng,Caijun Xu,Changyi Xiao,Shibo Hong,Eli Zhang,Stephen Huang,Yixin Cao*

Main category: cs.CL

TL;DR: CoDiQ框架通过测试时缩放实现细粒度难度控制，生成高质量竞赛级问题，显著提升大型推理模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有自动化问题生成方法缺乏精确难度控制，计算成本高，难以大规模生成竞赛级问题，限制了大型推理模型的训练效果

Method: 提出CoDiQ框架：1) 发现测试时缩放趋势（扩展推理token预算增加难度但降低可解性）；2) 开发CoDiQ-Generator提升困难问题生成上限；3) 构建包含44K竞赛级问题的CoDiQ-Corpus

Result: CoDiQ-Corpus生成的问题比LiveCodeBench/AIME显著更具挑战性，同时保持82%以上的可解性；在CoDiQ-Corpus上训练的大型推理模型推理性能大幅提升

Conclusion: CoDiQ框架实现了可控难度的竞赛级问题生成，验证了扩展可控难度训练问题能有效增强推理能力，开源相关资源支持后续研究

Abstract: Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.

</details>


### [108] [Scaling Search-Augmented LLM Reasoning via Adaptive Information Control](https://arxiv.org/abs/2602.01672)
*Siheng Xiong,Oguzhan Gungordu,Blair Johnson,James C. Kerce,Faramarz Fekri*

Main category: cs.CL

TL;DR: DeepControl框架通过信息效用概念自适应控制检索，在搜索增强推理中实现更高效的信息获取，相比基于结果的强化学习方法有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 搜索增强推理代理在交替进行多步推理和外部信息检索时，无控制的检索会导致冗余证据、上下文饱和和不稳定学习。现有基于结果的强化学习方法对信息获取的调节指导有限。

Method: 提出基于信息效用概念的DeepControl框架，引入检索延续性和粒度控制机制，选择性调节何时继续/停止检索以及扩展多少信息，采用退火控制策略让代理在训练中内化有效信息获取行为。

Result: 在七个基准测试中一致优于强基线方法，在Qwen2.5-7B和Qwen2.5-3B上相比基于结果的强化学习基线分别获得9.4%和8.6%的平均性能提升，且持续优于无检索和基于检索的推理方法。

Conclusion: 自适应信息控制对于将搜索增强推理代理扩展到复杂真实世界信息环境至关重要，DeepControl框架通过形式化的信息效用概念实现了更高效的信息获取调节。

Abstract: Search-augmented reasoning agents interleave multi-step reasoning with external information retrieval, but uncontrolled retrieval often leads to redundant evidence, context saturation, and unstable learning. Existing approaches rely on outcome-based reinforcement learning (RL), which provides limited guidance for regulating information acquisition. We propose DeepControl, a framework for adaptive information control based on a formal notion of information utility, which measures the marginal value of retrieved evidence under a given reasoning state. Building on this utility, we introduce retrieval continuation and granularity control mechanisms that selectively regulate when to continue and stop retrieval, and how much information to expand. An annealed control strategy enables the agent to internalize effective information acquisition behaviors during training. Extensive experiments across seven benchmarks demonstrate that our method consistently outperforms strong baselines. In particular, our approach achieves average performance improvements of 9.4% and 8.6% on Qwen2.5-7B and Qwen2.5-3B, respectively, over strong outcome-based RL baselines, and consistently outperforms both retrieval-free and retrieval-based reasoning methods without explicit information control. These results highlight the importance of adaptive information control for scaling search-augmented reasoning agents to complex, real-world information environments.

</details>


### [109] [Counting Hypothesis: Potential Mechanism of In-Context Learning](https://arxiv.org/abs/2602.01687)
*Jung H. Lee,Sujith Vijayan*

Main category: cs.CL

TL;DR: 论文提出"计数假说"，认为大语言模型的编码策略可能是上下文学习的基础机制


<details>
  <summary>Details</summary>
Motivation: 上下文学习(ICL)虽然强大但机制不明确，这使得错误修正和诊断变得困难，需要更好地理解ICL的局限性和大语言模型如何支持ICL

Method: 受ICL特性和大语言模型功能模块启发，提出"计数假说"，认为大语言模型的编码策略可能是ICL的基础，并提供支持证据

Result: 提出了"计数假说"作为解释ICL机制的理论框架，并提供了支持该假说的证据

Conclusion: 理解大语言模型的编码策略对于揭示上下文学习机制至关重要，"计数假说"为解释ICL提供了新的理论视角

Abstract: In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.

</details>


### [110] [Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models](https://arxiv.org/abs/2602.01698)
*Wenhui Tan,Fiorenzo Parascandolo,Enver Sangineto,Jianzhong Ju,Zhenbo Luo,Qian Cao,Rita Cucchiara,Ruihua Song,Jian Luan*

Main category: cs.CL

TL;DR: LRMs强化学习后训练导致探索崩溃，温度采样不再提升pass@n准确率。作者提出潜在探索解码(LED)，通过聚合中间层后验选择高熵配置，无需额外训练即可提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现代推理后训练会导致意外的探索崩溃：基于温度的采样不再提高pass@n准确率。研究发现后训练LRMs的最终层后验熵急剧减少，而中间层熵保持相对较高，这种熵不对称性为改进解码策略提供了机会。

Method: 提出潜在探索解码(LED)：一种深度条件解码策略。通过累积和聚合中间层后验，选择具有最大熵的深度配置作为探索候选。该方法无需额外训练或参数。

Result: LED在多个推理基准测试和模型上，无需额外训练即可一致提升pass@1和pass@16准确率，分别提高0.61和1.03个百分点。

Conclusion: LED通过利用中间层的高熵特性有效缓解后训练导致的探索崩溃问题，为推理模型的解码策略提供了简单而有效的改进方案。

Abstract: Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.

</details>


### [111] [Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory](https://arxiv.org/abs/2602.01708)
*Langyuan Cui,Chun Kai Ling,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 论文提出Game of Thought (GoT)框架，使用博弈论方法提升LLM在信息不足场景下的最坏情况表现


<details>
  <summary>Details</summary>
Motivation: LLM在现实部署中常面临信息不足问题，现有方法依赖简化假设，会降低最坏情况性能，这在高风险应用中存在严重隐患

Method: 将信息搜索问题形式化为Strategic Language Search (SLS)博弈问题，提出Game of Thought框架，应用博弈论技术近似纳什均衡策略

Result: 实验表明GoT方法在所有测试设置中，相比直接提示法和启发式搜索方法，都能持续改善最坏情况性能

Conclusion: 通过博弈论框架解决LLM信息搜索问题，能有效提升最坏情况下的性能表现，对高风险应用具有重要意义

Abstract: Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.

</details>


### [112] [ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation](https://arxiv.org/abs/2602.01709)
*Xingshan Zeng,Lingzhi Wang,Weiwen Liu,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: ARTIS：通过迭代模拟实现代理风险感知的测试时扩展，在真实环境执行前进行模拟探索，提高代理决策的可靠性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前测试时扩展技术虽然能提升大语言模型性能，但在代理场景中不足，因为代理动作直接与环境交互且效果可能不可逆、代价高昂。需要一种方法在测试时扩展计算能力，同时避免环境风险。

Method: 提出ARTIS框架，通过模拟交互将探索与执行解耦。引入风险感知工具模拟器，通过针对性数据生成和再平衡训练，强调捕捉导致失败的高影响动作。

Result: 在多轮多步代理基准测试中，迭代模拟显著提升代理可靠性，风险感知模拟对于在不同模型和任务中持续实现这些收益至关重要。

Conclusion: ARTIS通过风险感知的迭代模拟，将测试时计算扩展到代理决策中，在不增加环境风险的情况下提高动作级可靠性和鲁棒性。

Abstract: Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \emph{\name}, \emph{\underline{A}gentic \underline{R}isk-Aware \underline{T}est-Time Scaling via \underline{I}terative \underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.

</details>


### [113] [MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark](https://arxiv.org/abs/2602.01714)
*Mouath Abu-Daoud,Leen Kharouf,Omar El Hajj,Dana El Samad,Mariam Al-Omari,Jihad Mallat,Khaled Saleh,Nizar Habash,Farah E. Shamout*

Main category: cs.CL

TL;DR: 提出了MedAraBench，一个大规模阿拉伯语医学多选题数据集，用于评估LLMs在阿拉伯语医学领域的性能，包含19个专业和5个难度级别。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语在NLP研究中代表性不足，特别是在医学应用领域，缺乏开源数据和基准测试资源，这限制了评估和提升LLMs多语言能力的研究。

Method: 通过手动数字化阿拉伯语地区医学专业人员创建的学术材料构建数据集，进行广泛预处理并划分为训练集和测试集。采用专家人工评估和LLM-as-a-judge两种框架评估数据质量。

Result: 数据集具有高质量和多样性，涵盖19个医学专业和5个难度级别。评估了8个最先进的开源和专有模型（如GPT-5、Gemini 2.0 Flash、Claude 4-Sonnet），结果显示需要进一步的领域特定增强。

Conclusion: 发布数据集和评估脚本，旨在扩大医学数据基准的多样性，扩展LLMs评估套件的范围，并增强模型在临床环境中的多语言能力。

Abstract: Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.

</details>


### [114] [Mechanistic Indicators of Steering Effectiveness in Large Language Models](https://arxiv.org/abs/2602.01716)
*Mehdi Jafari,Hao Xue,Flora Salim*

Main category: cs.CL

TL;DR: 该研究提出使用内部模型信号（信息熵和KL散度）来诊断LLM激活导向的成功与否，建立了更可靠的评估基线。


<details>
  <summary>Details</summary>
Motivation: 尽管激活导向技术被广泛使用，但其成功或失败的内在机制因素仍不清楚，先前研究主要依赖黑盒输出或LLM评判。需要更深入理解激活导向的可靠性诊断方法。

Method: 采用两种信息论度量：基于熵的归一化分支因子（NBF）和词汇空间中导向激活与目标概念之间的KL散度。假设有效导向对应结构化熵保持和解码步骤间的连贯KL对齐。使用LLM生成的标注作为真实标签，并引入对比激活加法（CAA）和稀疏自编码器导向的更强评估基线。

Result: 研究表明这些机制信号能够有效预测导向成功并估计失败概率。通过可靠性研究显示两个架构不同的LLM之间具有较高的评判一致性。

Conclusion: 内部模型信号（信息熵和KL散度）为诊断激活导向可靠性提供了有意义的预测能力，有助于理解导向成功的内在机制因素。

Abstract: Activation-based steering enables Large Language Models (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether the reliability of steering can be diagnosed using internal model signals. We focus on two information-theoretic measures: the entropy-derived Normalized Branching Factor (NBF), and the Kullback-Leibler (KL) divergence between steered activations and targeted concepts in the vocabulary space. We hypothesize that effective steering corresponds to structured entropy preservation and coherent KL alignment across decoding steps. Building on a reliability study demonstrating high inter-judge agreement between two architecturally distinct LLMs, we use LLM-generated annotations as ground truth and show that these mechanistic signals provide meaningful predictive power for identifying successful steering and estimating failure probability. We further introduce a stronger evaluation baseline for Contrastive Activation Addition (CAA) and Sparse Autoencoder-based steering, the two most widely adopted activation-steering methods.

</details>


### [115] [BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition](https://arxiv.org/abs/2602.01717)
*Hyunsik Kim,Haeri Kim,Munhak Lee,Kyungmin Lee*

Main category: cs.CL

TL;DR: BBPE16：基于UTF-16的字节级BPE分词器，相比UTF-8 BBPE，在多语言ASR中减少中文等非拉丁文字序列长度，提升计算效率


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用的UTF-8字节级BPE分词器虽然语言无关且覆盖全Unicode，但对中文、日文、韩文等非拉丁文字会产生变长编码，导致序列膨胀，增加计算负载和内存使用

Method: 提出BBPE16分词器，基于UTF-16编码，使用统一的2字节代码单元表示大多数现代文字系统，保持语言无关特性的同时显著提升跨语言token共享

Result: 在单语、双语、三语ASR以及多语言持续学习设置中，BBPE16达到相当或更好的准确率；对中文减少token数量达10.4%，降低解码迭代达10.3%，加速微调和推理并减少内存使用

Conclusion: BBPE16是多语言ASR的实用分词选择，在保持性能的同时显著提升计算效率

Abstract: Multilingual automatic speech recognition (ASR) requires tokenization that efficiently covers many writing systems. Byte-level BPE (BBPE) using UTF-8 is widely adopted for its language-agnostic design and full Unicode coverage, but its variable-length encoding inflates token sequences for non-Latin scripts, such as Chinese, Japanese, and Korean (CJK). Longer sequences increase computational load and memory use. We propose BBPE16, a UTF-16-based BBPE tokenizer that represents most modern scripts with a uniform 2-byte code unit. BBPE16 preserves BBPE's language-agnostic properties while substantially improving cross-lingual token sharing. Across monolingual, bilingual, and trilingual ASR, and in a multilingual continual-learning setup, BBPE16 attains comparable or better accuracy; for Chinese, it reduces token counts by up to 10.4% and lowers decoding iterations by up to 10.3%. These reductions speed up fine-tuning and inference and decrease memory usage, making BBPE16 a practical tokenization choice for multilingual ASR.

</details>


### [116] [COMI: Coarse-to-fine Context Compression via Marginal Information Gain](https://arxiv.org/abs/2602.01719)
*Jiwei Tang,Shilei Liu,Zhicheng Zhang,Yujin Yuan,Libin Zheng,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: COMI是一个粗到细的自适应上下文压缩框架，通过联合优化语义相关性和多样性，在高压缩率下显著提升LLM长上下文处理效率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文场景中面临计算效率低下和信息冗余的问题，现有上下文压缩方法需要改进以在高压缩率下保持语义质量

Method: 提出两阶段框架：1) 粗粒度组重分配：基于组间边际信息增益动态分配压缩率；2) 细粒度令牌合并：基于组内MIG的加权机制融合令牌，保留关键语义同时避免冗余累积

Result: 在问答和摘要任务上，COMI大幅超越现有基线，如在NaturalQuestions上使用Qwen2-7B模型，在32倍压缩约束下获得约25分的精确匹配提升

Conclusion: COMI通过粗到细的自适应压缩框架有效解决了长上下文场景中的计算效率和冗余问题，显著提升了LLM在压缩条件下的性能表现

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.

</details>


### [117] [SafePred: A Predictive Guardrail for Computer-Using Agents via World Models](https://arxiv.org/abs/2602.01725)
*Yurun Chen,Zeyi Liao,Ping Yin,Taotao Xie,Keting Yin,Shengyu Zhang*

Main category: cs.CL

TL;DR: SafePred是一个预测性护栏框架，通过将预测的未来风险与当前决策对齐，防止计算机使用代理的长期风险，相比反应式方法显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 现有计算机使用代理的护栏主要采用反应式方法，只能约束当前观察空间内的行为，无法预防长期风险。看似合理的行动可能导致延迟出现的高风险后果，而反应式护栏无法在当前观察空间内识别这些风险。

Method: 提出预测性护栏方法，核心思想是将预测的未来风险与当前决策对齐。SafePred框架建立风险到决策的循环，支持：(1) 短期和长期风险预测：以安全策略为基础，利用世界模型的预测能力生成语义风险表示，识别并修剪导致高风险状态的行为；(2) 决策优化：通过步骤级干预和任务级重新规划，将预测风险转化为可操作的安全决策指导。

Result: 大量实验表明，SafePred显著减少了高风险行为，相比反应式基线方法，实现了超过97.6%的安全性能，并将任务效用提高了高达21.4%。

Conclusion: 预测性护栏方法能够有效解决计算机使用代理的长期风险问题，SafePred框架通过风险预测和决策优化的结合，在保证安全性的同时提升了任务执行效率。

Abstract: With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.

</details>


### [118] [Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training](https://arxiv.org/abs/2602.01747)
*Hongseok Choi,Serynn Kim,Wencke Liermann,Jin Seong,Jin-Xia Huang*

Main category: cs.CL

TL;DR: 本文提出三种关键技术改进自动作文评分系统：两阶段微调、分数对齐和不确定性感知自训练，在数据稀缺和充足场景下均提升性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中标注数据极度稀缺，严重限制了自动作文评分系统的开发和实际应用，需要解决有限数据和全数据场景下的性能提升问题。

Method: 1) 两阶段微调策略，利用低秩适应技术使模型更好地适应目标提示作文；2) 分数对齐技术，提高预测分数与真实分数分布的一致性；3) 不确定性感知自训练，利用未标注数据扩展训练集，同时减轻标签噪声传播。基于DualBERT实现这三种技术。

Result: 在ASAP++数据集上，32数据设置下所有三种技术都提升了性能，集成后达到全数据性能的91.2%（仅用约1000个标注样本）。分数对齐技术在有限数据和全数据设置下都持续提升性能，在全数据设置中集成到DualBERT时达到最先进结果。

Conclusion: 提出的三种关键技术能有效提升自动作文评分系统在数据稀缺和充足场景下的性能，分数对齐技术尤其具有通用性，在两阶段微调和自训练框架下都能显著改善模型表现。

Abstract: Automated Essay Scoring (AES) plays a crucial role in education by providing scalable and efficient assessment tools. However, in real-world settings, the extreme scarcity of labeled data severely limits the development and practical adoption of robust AES systems. This study proposes a novel approach to enhance AES performance in both limited-data and full-data settings by introducing three key techniques. First, we introduce a Two-Stage fine-tuning strategy that leverages low-rank adaptations to better adapt an AES model to target prompt essays. Second, we introduce a Score Alignment technique to improve consistency between predicted and true score distributions. Third, we employ uncertainty-aware self-training using unlabeled data, effectively expanding the training set with pseudo-labeled samples while mitigating label noise propagation. We implement above three key techniques on DualBERT. We conduct extensive experiments on the ASAP++ dataset. As a result, in the 32-data setting, all three key techniques improve performance, and their integration achieves 91.2% of the full-data performance trained on approximately 1,000 labeled samples. In addition, the proposed Score Alignment technique consistently improves performance in both limited-data and full-data settings: e.g., it achieves state-of-the-art results in the full-data setting when integrated into DualBERT.

</details>


### [119] [WorldCup Sampling for Multi-bit LLM Watermarking](https://arxiv.org/abs/2602.01752)
*Yidan Wang,Yubing Ren,Yanan Cao,Li Guo*

Main category: cs.CL

TL;DR: WorldCup是一个多比特水印框架，通过分层竞争机制将消息比特直接嵌入到LLM的token选择中，在容量、可检测性、鲁棒性和文本质量之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成越来越像人类的文本，水印技术为超越简单检测的可靠溯源提供了有前景的解决方案。现有的多比特水印方法大多通过种子驱动引导来扩展零比特方案，导致间接信息流、有限有效容量和次优解码。

Method: 将采样视为自然通信通道，通过分层竞争机制在token选择中直接嵌入消息比特，采用互补信号引导。使用熵感知调制保持生成质量，通过置信感知解码实现鲁棒消息恢复。

Result: 综合实验表明，WorldCup在容量、可检测性、鲁棒性、文本质量和解码效率方面实现了强大平衡，始终优于现有基线方法。

Conclusion: WorldCup为未来LLM水印研究奠定了坚实基础，提供了一个在多比特水印各方面表现均衡的框架。

Abstract: As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steering, leading to indirect information flow, limited effective capacity, and suboptimal decoding. In this paper, we propose WorldCup, a multi-bit watermarking framework for LLMs that treats sampling as a natural communication channel and embeds message bits directly into token selection via a hierarchical competition mechanism guided by complementary signals. Moreover, WorldCup further adopts entropy-aware modulation to preserve generation quality and supports robust message recovery through confidence-aware decoding. Comprehensive experiments show that WorldCup achieves a strong balance across capacity, detectability, robustness, text quality, and decoding efficiency, consistently outperforming prior baselines and laying a solid foundation for future LLM watermarking studies.

</details>


### [120] [Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings](https://arxiv.org/abs/2602.01757)
*Doohyun Kim,Donghwa Kang,Kyungjae Lee,Hyeongboo Baek,Brent Byunghoon Kang*

Main category: cs.CL

TL;DR: Zero2Text是一种无需训练、基于递归在线对齐的框架，能够在严格黑盒和跨域设置下通过嵌入反转攻击从向量数据库中恢复文本，无需泄露数据对。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成(RAG)系统广泛使用向量数据库，但存在严重的隐私风险——嵌入反转攻击。现有方法面临根本性权衡：基于优化的方法需要计算量巨大的查询，而基于对齐的方法依赖于不切实际的可访问域内训练数据假设，在严格黑盒和跨域设置中无效。

Method: 提出Zero2Text训练免费框架，基于递归在线对齐。不同于依赖静态数据集的方法，Zero2Text将LLM先验与动态岭回归机制相结合，在运行时迭代对齐生成到目标嵌入。无需任何泄露的数据对。

Result: 在多个基准测试中验证了Zero2Text的有效性。在MS MARCO上针对OpenAI受害者模型，相比基线方法实现了1.8倍更高的ROUGE-L和6.4倍更高的BLEU-2分数，能够从未知领域恢复句子。标准防御方法（如差分隐私）无法有效缓解这种自适应威胁。

Conclusion: Zero2Text突破了现有嵌入反转攻击方法的限制，在严格黑盒和跨域设置下有效，揭示了向量数据库的严重隐私风险，现有防御措施不足。

Abstract: The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.

</details>


### [121] [<SOG_k>: One LLM Token for Explicit Graph Structural Understanding](https://arxiv.org/abs/2602.01771)
*Jingyao Wu,Bin Lu,Zijun Di,Xiaoying Gan,Meng Jin,Luoyi Fu,Xinbing Wang,Chenghu Zhou*

Main category: cs.CL

TL;DR: 提出SOG方法，使用特殊token <SOG_k>在统一token空间中表示图结构，解决LLMs处理图数据的结构幻觉问题，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在非结构化数据理解方面表现出色，但在处理图数据时面临结构幻觉挑战。现有方法要么将图转化为自然语言导致token消耗过大且注意力分散，要么转化为可训练的连续嵌入但与原文本token严重不对齐

Method: 提出拓扑感知的结构tokenizer，将每个图拓扑映射为高度选择性的单个token <SOG_k>，构建混合结构问答语料库来对齐新的结构token与现有文本token

Result: 在五个图级基准测试中显著优于基线方法，性能提升9.9%到41.4%，同时表现出可解释性和一致性。方法还可灵活扩展到节点级任务

Conclusion: SOG方法通过特殊token在统一token空间中表示图结构，使LLMs能够以简洁准确的方式理解、生成和推理图数据，为解决LLMs处理结构化数据的挑战提供了有效方案

Abstract: Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.

</details>


### [122] [Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model](https://arxiv.org/abs/2602.01778)
*Kangtao Lv,Jiwei Tang,Langming Liu,Haibin Chen,Weidong Zhang,Shilei Liu,Yongwei Wang,Yujin Yuan,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 该论文首次从数据中心的视角系统研究数据分布对上下文压缩质量的影响，发现输入熵与压缩质量负相关，编码器-解码器内在数据差距显著降低压缩增益。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文场景中的部署受到计算效率低下和信息冗余的阻碍。虽然现有研究主要关注模型端改进，但数据分布本身对上下文压缩的影响尚未得到充分探索。

Method: 采用数据中心视角，从输入数据和内在数据（模型内部预训练知识）两个维度系统研究数据分布对压缩质量的影响。使用基于自编码器的框架评估压缩表示的语义完整性。

Result: 实验发现：(1)编码器测量的输入熵与压缩质量负相关，而解码器测量的熵在冻结解码器设置下无显著关系；(2)编码器和解码器内在数据之间的差距显著降低压缩增益，且难以缓解。

Conclusion: 基于研究发现提出了优化压缩增益的实用指南，强调需要同时考虑输入数据和模型内在数据分布对上下文压缩的影响。

Abstract: The deployment of Large Language Models (LLMs) in long-context scenarios is hindered by computational inefficiency and significant information redundancy. Although recent advancements have widely adopted context compression to address these challenges, existing research only focus on model-side improvements, the impact of the data distribution itself on context compression remains largely unexplored. To bridge this gap, we are the first to adopt a data-centric perspective to systematically investigate how data distribution impacts compression quality, including two dimensions: input data and intrinsic data (i.e., the model's internal pretrained knowledge). We evaluate the semantic integrity of compressed representations using an autoencoder-based framework to systematically investigate it. Our experimental results reveal that: (1) encoder-measured input entropy negatively correlates with compression quality, while decoder-measured entropy shows no significant relationship under a frozen-decoder setting; and (2) the gap between intrinsic data of the encoder and decoder significantly diminishes compression gains, which is hard to mitigate. Based on these findings, we further present practical guidelines to optimize compression gains.

</details>


### [123] [CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding](https://arxiv.org/abs/2602.01785)
*Yuling Shi,Chaoxiang Xie,Zhensu Sun,Yeheng Chen,Chenxu Zhang,Longfei Yun,Chengcheng Wan,Hongyu Zhang,David Lo,Xiaodong Gu*

Main category: cs.CL

TL;DR: MLLMs通过将代码渲染为图像实现高达8倍压缩，在保持理解能力的同时显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统LLMs将代码作为文本序列处理，随着软件规模增长导致上下文长度线性增加和计算成本上升。MLLMs的发展为通过图像模态表示代码以优化效率提供了机会

Method: 将源代码渲染为图像，利用图像模态固有的可压缩性，通过调整分辨率实现token成本大幅降低，同时保持视觉模型的可识别性

Result: 1) MLLMs能在8倍压缩下有效理解代码；2) 在4倍压缩下利用语法高亮等视觉线索提升代码补全性能；3) 克隆检测等任务对视觉压缩表现出异常韧性，某些压缩比甚至略优于原始文本输入

Conclusion: MLLMs在代码理解方面展现出潜力，图像模态的代码表示为更高效的推理提供了新途径，但当前仍存在局限性

Abstract: Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.

</details>


### [124] [Sentence Curve Language Models](https://arxiv.org/abs/2602.01807)
*DongNyeong Heo,Heelyoul Choi*

Main category: cs.CL

TL;DR: 提出句子曲线语言模型(SCLM)，通过预测连续的句子曲线而非静态词嵌入，解决传统语言模型中目标词嵌入对上下文不敏感的问题，提升全局结构建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型（包括扩散语言模型）使用静态词嵌入表示目标句子，这种表示对相邻词不敏感，导致模型倾向于局部准确的词预测而忽视句子的全局结构。

Method: 提出句子曲线表示法，将其定义为样条曲线，其控制点影响句子中的多个词。基于此表示，开发句子曲线语言模型(SCLM)，扩展扩散语言模型以预测句子曲线而非静态词嵌入。

Result: SCLM在IWSLT14和WMT14上实现了扩散语言模型中的SOTA性能，训练稳定无需繁琐的知识蒸馏，在LM1B上与离散扩散语言模型相比显示出有前景的潜力。

Conclusion: 句子曲线表示通过正则化效应促进全局结构建模，为语言建模提供了新的连续表示方法，在多个基准测试中表现出优越性能。

Abstract: Language models (LMs) are a central component of modern AI systems, and diffusion-based language models (DLMs) have recently emerged as a competitive alternative. Both paradigms rely on word embeddings not only to represent the input sentence, but also to represent the target sentence that backbone models are trained to predict. We argue that such static embedding of the target word is insensitive to neighboring words, encouraging locally accurate word prediction while neglecting global structure across the target sentence. To address this limitation, we propose a continuous sentence representation, termed sentence curve, defined as a spline curve whose control points affect multiple words in the sentence. Based on this representation, we introduce sentence curve language model (SCLM), which extends DLMs to predict sentence curves instead of the static word embeddings. We theoretically show that sentence curve prediction induces a regularization effect that promotes global structure modeling, and characterize how different sentence curve types affect this behavior. Empirically, SCLM achieves SOTA performance among DLMs on IWSLT14 and WMT14, shows stable training without burdensome knowledge distillation, and demonstrates promising potential compared to discrete DLMs on LM1B.

</details>


### [125] [AXE: Low-Cost Cross-Domain Web Structured Information Extraction](https://arxiv.org/abs/2602.01838)
*Abdelrahman Mansour,Khaled W. Alshaer,Moataz Elsaban*

Main category: cs.CL

TL;DR: AXE是一个用于网页结构化数据提取的轻量级系统，通过DOM树剪枝机制和Grounded XPath Resolution，仅使用0.6B参数的小模型就能实现SOTA性能，在SWDE数据集上达到88.1% F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决网页结构化数据提取中的两难问题：手动启发式方法脆弱易失效，而大型语言模型成本过高。需要一种既精确又经济实用的解决方案。

Method: 1. 将HTML DOM视为需要剪枝的树而非纯文本；2. 使用专门的"剪枝"机制去除样板内容和无关节点；3. 采用Grounded XPath Resolution确保每个提取都能物理追踪到源节点；4. 使用仅0.6B参数的小型LLM处理蒸馏后的高密度上下文。

Result: 在SWDE数据集上实现了88.1%的F1分数，零样本性能达到SOTA，超越了多个更大规模的全训练模型。系统具有低资源占用和高成本效益的特点。

Conclusion: AXE提供了一种实用且经济高效的大规模网页信息提取路径，通过DOM剪枝和物理可追踪的提取机制，实现了小模型的高精度提取，并开源了专用适配器。

Abstract: Extracting structured data from the web is often a trade-off between the brittle nature of manual heuristics and the prohibitive cost of Large Language Models. We introduce AXE (Adaptive X-Path Extractor), a pipeline that rethinks this process by treating the HTML DOM as a tree that needs pruning rather than just a wall of text to be read. AXE uses a specialized "pruning" mechanism to strip away boilerplate and irrelevant nodes, leaving behind a distilled, high-density context that allows a tiny 0.6B LLM to generate precise, structured outputs. To keep the model honest, we implement Grounded XPath Resolution (GXR), ensuring every extraction is physically traceable to a source node. Despite its low footprint, AXE achieves state-of-the-art zero-shot performance, outperforming several much larger, fully-trained alternatives with an F1 score of 88.1% on the SWDE dataset. By releasing our specialized adaptors, we aim to provide a practical, cost-effective path for large-scale web information extraction.

</details>


### [126] [Read As Human: Compressing Context via Parallelizable Close Reading and Skimming](https://arxiv.org/abs/2602.01840)
*Jiwei Tang,Shilei Liu,Zhicheng Zhang,Qingsong Lv,Runsong Zhao,Tingwei Lu,Langming Liu,Haibin Chen,Yujin Yuan,Hai-Tao Zheng,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: RAM框架通过模拟人类阅读行为（精读重要内容+略读次要内容），对长上下文进行自适应压缩，在保持性能的同时实现12倍加速


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文场景下面临计算效率低下和信息冗余两大挑战，需要一种既能保持性能又能提高效率的上下文压缩方法

Method: 提出RAM框架：1）将上下文分段并行编码；2）高相关段完整保留（精读），低相关段通过查询引导压缩为摘要向量（略读）；3）引入对比学习优化精读与略读的决策边界

Result: 在多个问答和摘要基准测试中优于现有基线，在平均长度16K、最大长度32K的长输入上实现最高12倍的端到端加速

Conclusion: RAM框架通过模拟人类阅读策略，有效解决了长上下文处理中的计算效率和冗余信息问题，在保持性能的同时显著提升处理速度

Abstract: Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).

</details>


### [127] [PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning](https://arxiv.org/abs/2602.01875)
*Langming Liu,Kangtao Lv,Haibin Chen,Weidong Zhang,Yejing Wang,Shilei Liu,Xin Tong,Yujin Yuan,Yongwei Wang,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 提出PretrainRL框架，在预训练阶段集成强化学习来巩固事实知识，通过"去偏再学习"原则降低高概率虚假信息的权重，为低概率真实信息创造学习空间，显著缓解LLM的事实幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在事实幻觉问题，生成可验证的虚假信息。研究发现根本原因在于预训练语料库中数据分布不平衡，导致"低概率真实"和"高概率虚假"的状态。现有方法要么回避问题（如教模型说"不知道"），要么面临灾难性遗忘（如后验知识编辑），需要从根本上解决。

Method: 提出PretrainRL框架，将强化学习集成到预训练阶段。核心原则是"去偏再学习"：主动重塑模型的概率分布，降低高概率虚假信息的权重，为低概率真实信息的有效学习创造空间。设计了高效的负采样策略来发现高概率虚假信息，并引入新的指标来评估模型关于事实知识的概率状态。

Result: 在三个公开基准测试上的广泛实验表明，PretrainRL显著缓解了事实幻觉问题，并优于最先进的方法。

Conclusion: PretrainRL通过从根源上解决数据分布不平衡问题，有效缓解了LLM的事实幻觉，为构建更可靠的语言模型提供了新思路。

Abstract: Large language models (LLMs), despite their powerful capabilities, suffer from factual hallucinations where they generate verifiable falsehoods. We identify a root of this issue: the imbalanced data distribution in the pretraining corpus, which leads to a state of "low-probability truth" and "high-probability falsehood". Recent approaches, such as teaching models to say "I don't know" or post-hoc knowledge editing, either evade the problem or face catastrophic forgetting. To address this issue from its root, we propose \textbf{PretrainRL}, a novel framework that integrates reinforcement learning into the pretraining phase to consolidate factual knowledge. The core principle of PretrainRL is "\textbf{debiasing then learning}." It actively reshapes the model's probability distribution by down-weighting high-probability falsehoods, thereby making "room" for low-probability truths to be learned effectively. To enable this, we design an efficient negative sampling strategy to discover these high-probability falsehoods and introduce novel metrics to evaluate the model's probabilistic state concerning factual knowledge. Extensive experiments on three public benchmarks demonstrate that PretrainRL significantly alleviates factual hallucinations and outperforms state-of-the-art methods.

</details>


### [128] [ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support](https://arxiv.org/abs/2602.01885)
*Tiantian Chen,Jiaqi Lu,Ying Shen,Lin Zhang*

Main category: cs.CL

TL;DR: ES-MemEval是一个评估长期对话记忆能力的基准，专注于情感支持场景，包含信息提取、时序推理等5项核心能力评估，实验表明显式长期记忆对减少幻觉和个性化至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有长期对话基准主要关注静态显式事实检索，无法评估在用户信息分散、隐式且持续演化的关键场景中的表现，特别是在在线情感支持等复杂长期网络服务中。

Method: 提出ES-MemEval基准，系统评估5项核心记忆能力：信息提取、时序推理、冲突检测、弃权和用户建模；同时构建EvoEmo数据集，包含碎片化、隐式用户披露和演化用户状态的多会话情感支持数据。

Result: 实验表明：显式长期记忆对减少幻觉和实现有效个性化至关重要；RAG能提高事实一致性，但在处理时序动态和演化用户状态方面存在困难。

Conclusion: 当前范式既有潜力也有局限，需要更鲁棒地整合记忆和检索机制来构建长期个性化对话系统。

Abstract: Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.

</details>


### [129] [GuideWeb: A Benchmark for Automatic In-App Guide Generation on Real-World Web UIs](https://arxiv.org/abs/2602.01917)
*Chengguang Gan,Yoshihiro Tsujii,Yunhao Liang,Tatsunori Mori,Shiwen Ni,Hiroki Itoh*

Main category: cs.CL

TL;DR: GuideWeb是一个用于在真实网页UI上自动生成应用内指导的新基准，将任务定义为通过选择网页中的指导目标元素并生成与用户意图一致的简洁指导文本来生成页面级指导。


<details>
  <summary>Details</summary>
Motivation: 数字采用平台(DAP)虽然能让非专家编写操作指导，但由于网站布局和功能不断演变，维护这些指导仍然劳动密集，需要重复的手动更新和重新标注。

Method: 提出了GuideWeb基准，将任务形式化为生成页面级指导：选择网页中的指导目标元素并生成与用户意图一致的简洁指导文本。还提出了综合评估套件，联合测量指导目标元素选择的准确性和生成意图及指导文本的质量。

Result: 提出的GuideWeb Agent在指导目标元素预测方面达到30.79%的准确率，意图生成BLEU得分为44.94，指导文本生成BLEU得分为21.34。现有基线表现明显更差。

Conclusion: 自动指导生成仍然具有挑战性，在系统能够可靠地部署到真实世界环境之前需要进一步改进。

Abstract: Digital Adoption Platform (DAP) provide web-based overlays that deliver operation guidance and contextual hints to help users navigate complex websites. Although modern DAP tools enable non-experts to author such guidance, maintaining these guides remains labor-intensive because website layouts and functionalities evolve continuously, which requires repeated manual updates and re-annotation. In this work, we introduce \textbf{GuideWeb}, a new benchmark for automatic in-app guide generation on real-world web UIs. GuideWeb formulates the task as producing page-level guidance by selecting \textbf{guide target elements} grounded in the webpage and generating concise guide text aligned with user intent. We also propose a comprehensive evaluation suite that jointly measures the accuracy of guide target element selection and the quality of generated intents and guide texts. Experiments show that our proposed \textbf{GuideWeb Agent} achieves \textbf{30.79\%} accuracy in guide target element prediction, while obtaining BLEU scores of \textbf{44.94} for intent generation and \textbf{21.34} for guide-text generation. Existing baselines perform substantially worse, which highlights that automatic guide generation remains challenging and that further advances are necessary before such systems can be reliably deployed in real-world settings.

</details>


### [130] [From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted "Vibe Coding"](https://arxiv.org/abs/2602.01919)
*Hend Al-Khalifa*

Main category: cs.CL

TL;DR: 论文提出"Vibe Coding"教学法，利用LLM作为编程助手，在NLP课程中通过反思性评估促进概念理解而非语法掌握。


<details>
  <summary>Details</summary>
Motivation: LLM快速发展给NLP教育带来挑战和机遇，需要探索如何有效利用LLM作为编程助手，同时保持对概念理解和批判性思维的关注。

Method: 提出"Vibe Coding"教学法，在高级本科NLP课程中实施，学生使用LLM完成7个实验，通过强制提示记录和基于反思的评估，主要考核概念理解而非代码实现。

Result: 19名学生反馈显示高满意度（平均4.4-4.6/5.0），学生重视调试认知负荷减少带来的概念深度关注，但也面临时间限制、LLM输出验证和任务规范清晰度等挑战。

Conclusion: 通过强制提示记录和反思评估的结构化设计，LLM辅助学习可以将重点从语法流利度转向概念掌握，为学生适应AI增强的专业环境做好准备。

Abstract: The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.

</details>


### [131] [Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2602.01965)
*Kwun Hang Lau,Fangyuan Zhang,Boyu Ruan,Yingli Zhou,Qintian Guo,Ruiyuan Zhang,Xiaofang Zhou*

Main category: cs.CL

TL;DR: CatRAG 是一个基于 HippoRAG 2 架构的上下文感知检索增强生成框架，通过动态调整知识图谱结构来解决静态图方法的局限性，显著提升多跳推理的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的 RAG 方法（如 HippoRAG）存在"静态图谬误"问题：依赖固定的转移概率，忽略了边相关性的查询依赖性，导致随机游走被高连接度的"枢纽"节点分散，无法完整检索多跳查询所需的证据链。

Method: CatRAG 在 HippoRAG 2 架构基础上，将静态知识图谱转换为查询自适应的导航结构，包含三个核心机制：(1) 符号锚定：注入弱实体约束来正则化随机游走；(2) 查询感知动态边权重：动态调整图结构，剪枝不相关路径，增强与查询意图对齐的路径；(3) 关键事实段落权重增强：通过成本高效的偏置结构性地锚定随机游走到可能证据。

Result: 在四个多跳基准测试中，CatRAG 持续优于现有基线方法。虽然标准召回率指标显示适度提升，但 CatRAG 在推理完整性（恢复完整证据路径的能力）方面实现了显著改进。

Conclusion: CatRAG 通过将静态知识图谱转换为查询自适应导航结构，有效解决了静态图方法的局限性，在检索部分上下文和实现完全基于证据的推理之间架起了桥梁，显著提升了多跳推理的完整性。

Abstract: Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a "Static Graph Fallacy": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree "hub" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.

</details>


### [132] [Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition](https://arxiv.org/abs/2602.01967)
*Wonjun Lee,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: Moe-Ctc：一种混合专家架构，通过中间CTC监督联合促进专家专业化和泛化，显著提升带口音语音的ASR性能


<details>
  <summary>Details</summary>
Motivation: 带口音的语音对ASR系统构成持续挑战，因为大多数模型在少数高资源英语变体数据上训练，导致对其他口音的性能大幅下降。口音无关方法虽提高鲁棒性，但对重口音或未见口音效果不佳；口音特定方法则依赖有限且通常嘈杂的标签。

Method: 提出Moe-Ctc，一种带有中间CTC监督的混合专家架构。训练时使用口音感知路由鼓励专家捕获口音特定模式，推理时逐渐过渡到无标签路由。每个专家配备自己的CTC头以对齐路由和转录质量，路由增强损失进一步稳定优化。

Result: 在Mcv-Accent基准测试中，在低资源和高资源条件下，对已见和未见口音均取得一致增益，相比强FastConformer基线实现高达29.3%的相对WER降低。

Conclusion: Moe-Ctc通过混合专家架构和中间CTC监督，有效解决了带口音语音ASR的挑战，在专业化和泛化之间取得良好平衡，显著提升各种口音条件下的识别性能。

Abstract: Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.

</details>


### [133] [Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models](https://arxiv.org/abs/2602.01969)
*Bin Cao,Huixian Lu,Chenwen Ma,Ting Wang,Ruizhe Li,Jing Fan*

Main category: cs.CL

TL;DR: 提出OHD框架，通过正交树分解将复杂表格转换为结构保持的表示，以解决LLMs处理多级表头、合并单元格等复杂表格时的困难


<details>
  <summary>Details</summary>
Motivation: 现有表格线性化或网格建模方法难以显式捕捉复杂表格的层次结构和跨维度依赖关系，导致结构语义与文本表示不对齐

Method: 提出正交层次分解(OHD)框架，包括：1)基于空间-语义约束的正交树归纳(OTI)，将不规则表格分解为列树和行树；2)双路径关联协议对称重构单元格语义谱系；3)使用LLM作为语义仲裁器对齐多级语义信息

Result: 在AITQA和HiTab两个复杂表格问答基准上，OHD框架在多项评估指标上持续优于现有表示范式

Conclusion: OHD框架通过正交树分解有效捕捉复杂表格的层次结构和跨维度依赖，为LLMs提供结构保持的输入表示，显著提升复杂表格理解能力

Abstract: Complex tables with multi-level headers, merged cells and heterogeneous layouts pose persistent challenges for LLMs in both understanding and reasoning. Existing approaches typically rely on table linearization or normalized grid modeling. However, these representations struggle to explicitly capture hierarchical structures and cross-dimensional dependencies, which can lead to misalignment between structural semantics and textual representations for non-standard tables. To address this issue, we propose an Orthogonal Hierarchical Decomposition (OHD) framework that constructs structure-preserving input representations of complex tables for LLMs. OHD introduces an Orthogonal Tree Induction (OTI) method based on spatial--semantic co-constraints, which decomposes irregular tables into a column tree and a row tree to capture vertical and horizontal hierarchical dependencies, respectively. Building on this representation, we design a dual-pathway association protocol to symmetrically reconstruct semantic lineage of each cell, and incorporate an LLM as a semantic arbitrator to align multi-level semantic information. We evaluate OHD framework on two complex table question answering benchmarks, AITQA and HiTab. Experimental results show that OHD consistently outperforms existing representation paradigms across multiple evaluation metrics.

</details>


### [134] [Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing](https://arxiv.org/abs/2602.01977)
*Shuainan Liu,Xuanang Chen,Ben He,Le Sun*

Main category: cs.CL

TL;DR: 提出EVK方法，通过嵌入空间扰动来评估知识编辑对模型知识系统的广泛影响，超越传统基于样本的评估局限


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型知识编辑方法的评估主要局限于预定义基准测试，只能评估编辑事实及有限的相关知识，无法全面理解编辑对模型知识系统的整体影响

Method: 提出Embedding-Virtualized Knowledge (EVK)方法，通过在嵌入空间进行受控扰动来表征模型知识；基于EVK构建嵌入级评估基准EVK-Bench；提出即插即用的EVK-Align模块，在编辑过程中约束嵌入级知识漂移

Result: 实验表明该方法能够实现更全面的评估，同时显著改善知识保留而不牺牲编辑准确性

Conclusion: EVK方法能够超越传统样本评估的局限，更全面地评估知识编辑对模型知识系统的影响，并通过EVK-Align模块有效减少知识漂移

Abstract: Knowledge editing methods for large language models are commonly evaluated using predefined benchmarks that assess edited facts together with a limited set of related or neighboring knowledge. While effective, such evaluations remain confined to finite, dataset-bounded samples, leaving the broader impact of editing on the model's knowledge system insufficiently understood. To address this gap, we introduce Embedding-Virtualized Knowledge (EVK) that characterizes model knowledge through controlled perturbations in embedding space, enabling the exploration of a substantially broader and virtualized knowledge region beyond explicit data annotations. Based on EVK, we construct an embedding-level evaluation benchmark EVK-Bench that quantifies potential knowledge drift induced by editing, revealing effects that are not captured by conventional sample-based metrics. Furthermore, we propose a plug-and-play EVK-Align module that constrains embedding-level knowledge drift during editing and can be seamlessly integrated into existing editing methods. Experiments demonstrate that our approach enables more comprehensive evaluation while significantly improving knowledge preservation without sacrificing editing accuracy.

</details>


### [135] [S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs](https://arxiv.org/abs/2602.01982)
*Yanrui Du,Sendong Zhao,Yibo Gao,Danyang Zhao,Qika Lin,Ming Ma,Jiayun Li,Yi Jiang,Kai He,Qianyi Xu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 论文提出S3-CoT框架，通过激活引导自采样和渐进压缩课程，让LLM学习高效推理，实现类似人类系统1的快速思考模式。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在推理冗余问题，需要大量高质量监督数据。论文探索LLM能否获得类似人类系统1的快速思考能力，解决监督数据稀缺的瓶颈。

Method: 提出基于激活引导的自采样框架，从目标LLM自身生成风格对齐、长度可变的推理轨迹。使用黄金答案过滤数据，通过SFT进行高效CoT学习，包含双认知系统和渐进压缩课程。还探索仅使用预测一致数据的自进化机制。

Result: 在数学基准测试和医学领域的跨域泛化测试中，方法对通用LLM和R1风格LLM都带来稳定改进。开源了数据和模型检查点。

Conclusion: S3-CoT框架成功实现了LLM的高效推理学习，解决了监督数据稀缺问题，为LLM获得快速思考能力提供了有效途径。

Abstract: Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at https://github.com/DYR1/S3-CoT.

</details>


### [136] [From Latent Signals to Reflection Behavior: Tracing Meta-Cognitive Activation Trajectory in R1-Style LLMs](https://arxiv.org/abs/2602.01999)
*Yanrui Du,Yibo Gao,Sendong Zhao,Jiayun Li,Haochun Wang,Qika Lin,Kai He,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 本文通过分析R1风格大语言模型的内部机制，揭示了自我反思行为的三阶段结构：潜在控制层编码思考预算，语义枢纽层出现话语级线索，行为外显层提升反思行为token的采样概率。


<details>
  <summary>Details</summary>
Motivation: 尽管R1风格LLMs的自我反思能力受到关注，但其内部机制仍不清楚。本文旨在通过追踪反思行为的层间激活轨迹来揭示这一机制。

Method: 使用logit lens读取token级语义，追踪反思行为的层间激活轨迹，并进行针对性干预实验。分析分为三个阶段：潜在控制层、语义枢纽层和行为外显层。

Result: 发现反思行为遵循结构化进程：1）潜在控制层编码思考预算语义；2）语义枢纽层出现转折点和总结等话语级线索；3）行为外显层中反思行为token的采样概率上升。干预实验揭示了跨阶段的因果链。

Conclusion: 研究结果表明R1风格LLMs的自我反思过程类似于人类的元认知过程：从潜在监控到话语级调节，再到外显的自我反思。这为理解LLMs的反思机制提供了新视角。

Abstract: R1-style LLMs have attracted growing attention for their capacity for self-reflection, yet the internal mechanisms underlying such behavior remain unclear. To bridge this gap, we anchor on the onset of reflection behavior and trace its layer-wise activation trajectory. Using the logit lens to read out token-level semantics, we uncover a structured progression: (i) Latent-control layers, where an approximate linear direction encodes the semantics of thinking budget; (ii) Semantic-pivot layers, where discourse-level cues, including turning-point and summarization cues, surface and dominate the probability mass; and (iii) Behavior-overt layers, where the likelihood of reflection-behavior tokens begins to rise until they become highly likely to be sampled. Moreover, our targeted interventions uncover a causal chain across these stages: prompt-level semantics modulate the projection of activations along latent-control directions, thereby inducing competition between turning-point and summarization cues in semantic-pivot layers, which in turn regulates the sampling likelihood of reflection-behavior tokens in behavior-overt layers. Collectively, our findings suggest a human-like meta-cognitive process-progressing from latent monitoring, to discourse-level regulation, and to finally overt self-reflection. Our analysis code can be found at https://github.com/DYR1/S3-CoT.

</details>


### [137] [Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation](https://arxiv.org/abs/2602.02007)
*Zhanghao Hu,Qinglin Zhu,Hanqi Yan,Yulan He,Lin Gui*

Main category: cs.CL

TL;DR: xMemory提出了一种新的智能体记忆检索系统，通过将记忆分解为语义组件并组织成层次结构，解决了传统RAG在智能体记忆场景中的冗余和依赖性问题。


<details>
  <summary>Details</summary>
Motivation: 传统RAG针对大型异构语料库设计，而智能体记忆是有限、连贯的对话流，其中记忆片段高度相关且常有重复。固定top-k相似性检索会返回冗余上下文，而后处理剪枝可能删除时间上关联的先决条件，影响正确推理。

Method: 提出xMemory系统，采用解耦到聚合的方法：将记忆分解为语义组件，组织成层次结构，通过稀疏性-语义目标指导记忆的分割和合并，保持可搜索且忠实的高层节点组织。推理时采用自上而下的检索策略。

Result: 在LoCoMo和PerLTQA数据集上，使用三种最新LLM进行的实验显示，xMemory在回答质量和token效率方面均取得一致性的提升。

Conclusion: 智能体记忆检索应超越简单的相似性匹配，转向基于潜在组件的操作。xMemory通过层次化组织和自上而下的检索策略，能够提供紧凑、多样的上下文，有效支持多事实查询。

Abstract: Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.

</details>


### [138] [NEAT: Neuron-Based Early Exit for Large Reasoning Models](https://arxiv.org/abs/2602.02010)
*Kang Liu,Yongkang Liu,Xiaocui Yang,Peidong Wang,Wen Zhang,Shi Feng,Yifei Zhang,Daling Wang*

Main category: cs.CL

TL;DR: NEAT是一种基于神经元激活动态的早期推理退出框架，无需额外训练或测试时计算，通过监测神经元激活模式来减少推理过程中的冗余步骤，平均减少22%-28%的token使用量。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在"过度思考"问题，即在已经得出正确解决方案后仍生成冗余的推理步骤。现有早期退出方法依赖输出级启发式或训练探测模型，需要额外计算或外部标注数据集。

Method: NEAT通过监测神经元级激活动态实现训练免费的早期退出，无需额外测试时计算。它识别退出相关神经元并跟踪其在推理过程中的激活模式，动态触发早期退出或抑制反思，减少不必要推理同时保持解决方案质量。

Result: 在四个推理基准测试和六个不同规模和架构的模型上，NEAT平均减少22%-28%的token使用量，同时保持准确性。

Conclusion: NEAT提供了一种有效且高效的早期推理退出方法，通过神经元级监控减少冗余推理，无需额外训练或计算开销，在各种模型架构上均表现良好。

Abstract: Large Reasoning Models (LRMs) often suffer from \emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \textbf{NEAT}, a \textbf{N}euron-based \textbf{E}arly re\textbf{A}soning exi\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\% to 28\% when averaged over the four benchmarks, while maintaining accuracy.

</details>


### [139] [WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora](https://arxiv.org/abs/2602.02053)
*Pengyu Wang,Benfeng Xu,Licheng Zhang,Shaohan Wang,Mingxuan Du,Chiwei Zhu,Zhendong Mao*

Main category: cs.CL

TL;DR: WildGraphBench是一个评估GraphRAG在真实场景下性能的基准测试，使用维基百科的长文档和异构参考文献作为知识源，包含1100个问题，涵盖三种复杂度级别。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG基准测试大多使用简短、精选的段落作为外部知识，无法充分评估系统在长上下文和大规模异构文档的真实场景下的表现，需要更贴近实际应用的评估基准。

Method: 利用维基百科的结构特点，从12个顶级主题中采样文章，使用其外部参考文献作为检索语料库，引用链接的陈述作为真实答案，构建包含单事实QA、多事实QA和章节级摘要三个复杂度级别的1100个问题。

Result: 实验显示当前GraphRAG管道在证据来自中等数量来源时有助于多事实聚合，但这种聚合范式可能过度强调高层次陈述而牺牲细节信息，导致在摘要任务上表现较弱。

Conclusion: WildGraphBench填补了GraphRAG在真实场景评估的空白，揭示了当前系统在聚合与细节保留之间的权衡，为未来研究提供了更贴近实际应用的评估框架。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.

</details>


### [140] [Closing the Loop: Universal Repository Representation with RPG-Encoder](https://arxiv.org/abs/2602.02084)
*Jane Luo,Chengyu Yin,Xin Zhang,Qingtao Li,Steven Liu,Yiming Huang,Jie Wu,Hao Liu,Yangyu Huang,Yu Kang,Fangkai Yang,Ying Xin,Scarlett Li*

Main category: cs.CL

TL;DR: RPG-Encoder：将仓库规划图从静态生成蓝图推广为统一高保真表示，通过编码原始代码、增量演化拓扑和统一导航接口，在仓库理解和生成任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有仓库代理存在推理断层问题，因为它们依赖孤立的API文档或缺乏语义深度的依赖图。作者认为仓库理解和生成是统一循环中的逆过程：生成将意图扩展为实现，而理解将实现压缩回意图。

Method: 提出RPG-Encoder框架，通过三个机制：1) 将原始代码编码为结合语义特征和代码依赖的RPG；2) 增量演化拓扑以解耦维护成本与仓库规模；3) 作为结构感知导航的统一接口。

Result: 在SWE-bench Verified上达到93.7% Acc@5的SOTA性能，在SWE-bench Live Lite上超过最佳基线10%以上，在RepoCraft上实现98.5%重建覆盖率，维护开销减少95.7%。

Conclusion: RPG-Encoder通过统一高保真表示成功闭合了意图与实现之间的推理循环，在复杂代码库中展现出卓越的细粒度定位能力和高保真重建能力。

Abstract: Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.

</details>


### [141] [LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs](https://arxiv.org/abs/2602.02090)
*Yikai Zeng,Yingchao Piao,Jianhui Li*

Main category: cs.CL

TL;DR: LEC-KG：一个双向协作框架，将大语言模型的语义理解与知识图谱嵌入的结构推理相结合，用于从非结构化文本构建领域特定知识图谱，在中文可持续发展目标报告中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 从非结构化文本构建领域特定知识图谱面临三大挑战：异构实体提及、长尾关系分布以及缺乏标准化模式。现有方法难以同时处理语义理解和结构推理。

Method: 提出LEC-KG框架，包含三个关键组件：1）分层粗到细关系提取缓解长尾偏差；2）证据引导的思维链反馈将结构建议基于源文本；3）语义初始化支持对未见实体的结构验证。LLM和KGE模块通过迭代协作相互增强。

Result: 在中文可持续发展目标报告上的评估显示，相比LLM基线方法有显著改进，特别是在低频关系上表现突出。通过迭代精炼，框架能够可靠地将非结构化政策文本转化为经过验证的知识图谱三元组。

Conclusion: LEC-KG框架通过LLM和KGE的双向协作，有效解决了领域特定知识图谱构建中的关键挑战，为从非结构化文本中提取结构化知识提供了可靠解决方案。

Abstract: Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.

</details>


### [142] [Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning](https://arxiv.org/abs/2602.02099)
*Keqin Peng,Yuanxin Ouyang,Xuebo Liu,Zhiliang Tian,Ruijian Han,Yancheng Yuan,Liang Ding*

Main category: cs.CL

TL;DR: 提出DDCA方法解决RLVR中长度惩罚导致准确率下降的问题，通过解耦效率和正确性优化，动态调整惩罚强度，在多个数学推理基准上显著减少生成token同时保持或提升准确率。


<details>
  <summary>Details</summary>
Motivation: RLVR虽然能激发多步推理，但常导致冗长轨迹。简单的长度惩罚在群体相对优化中会严重损害准确率，主要由于两个结构性问题：长度基线稀释（错误回答压低群体基线，过度惩罚正确解）和难度惩罚不匹配（静态惩罚无法适应问题难度）。

Method: 提出动态解耦条件优势（DDCA）：1）在正确回答簇内条件计算长度优势，消除基线稀释；2）使用群体通过率作为难度代理，动态缩放惩罚强度，实现效率和正确性的解耦优化。

Result: 在GSM8K、MATH500、AMC23和AIME25等基准测试中，DDCA相比自适应基线持续改进效率-准确率权衡：简单任务（如GSM8K）减少约60%生成token，困难任务（如AIME25）减少超过20%，同时保持或提升准确率。

Conclusion: DDCA有效解决了RLVR中长度惩罚的结构性问题，通过条件计算和动态调整实现了效率和正确性的更好平衡，为强化学习中的奖励设计提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) can elicit strong multi-step reasoning, yet it often encourages overly verbose traces. Moreover, naive length penalties in group-relative optimization can severely hurt accuracy. We attribute this failure to two structural issues: (i) Dilution of Length Baseline, where incorrect responses (with zero length reward) depress the group baseline and over-penalize correct solutions; and (ii) Difficulty-Penalty Mismatch, where a static penalty cannot adapt to problem difficulty, suppressing necessary reasoning on hard instances while leaving redundancy on easy ones. We propose Dynamic Decoupled Conditional Advantage (DDCA) to decouple efficiency optimization from correctness. DDCA computes length advantages conditionally within the correct-response cluster to eliminate baseline dilution, and dynamically scales the penalty strength using the group pass rate as a proxy for difficulty. Experiments on GSM8K, MATH500, AMC23, and AIME25 show that DDCA consistently improves the efficiency--accuracy trade-off relative to adaptive baselines, reducing generated tokens by approximately 60% on simpler tasks (e.g., GSM8K) versus over 20% on harder benchmarks (e.g., AIME25), thereby maintaining or improving accuracy. Code is available at https://github.com/alphadl/DDCA.

</details>


### [143] [Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs](https://arxiv.org/abs/2602.02104)
*Shaltiel Shmidman,Avi Shmidman,Amir DN Cohen,Moshe Koppel*

Main category: cs.CL

TL;DR: Dicta-LM 3.0是一个面向希伯来语的开源大语言模型系列，包含24B、12B和1.7B三个规模，支持65k上下文长度，提供基础版和带工具调用功能的聊天版，并推出了希伯来语LLM评估基准套件。


<details>
  <summary>Details</summary>
Motivation: 目前开源权重LLM主要由前沿实验室发布，但针对英语以外语言的主权大语言模型供应不足而需求旺盛。训练希伯来语等低资源语言的LLM面临独特挑战，需要专门解决方案。

Method: 基于现有基础模型进行适配：24B基于Mistral-Small-3.1，12B基于NVIDIA Nemotron Nano V2，1.7B基于Qwen3-1.7B。训练使用了大规模的希伯来语和英语语料库。创建了希伯来语聊天LLM评估基准套件，涵盖翻译、摘要、Winograd、以色列知识问答和希伯来语元音标注等任务。

Result: 发布了Dicta-LM 3.0模型系列，包含三个规模版本，每个版本都有基础模型和带工具调用支持的聊天模型变体，均支持65k上下文长度。同时推出了专门针对希伯来语LLM的评估基准。

Conclusion: 这项工作不仅解决了低资源语言训练LLM的复杂性，还提出了一个可用于将其他LLM适配到各种非英语语言的框架，为多语言NLP领域做出了贡献。

Abstract: Open-weight LLMs have been released by frontier labs; however, sovereign Large Language Models (for languages other than English) remain low in supply yet high in demand. Training large language models (LLMs) for low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce Dicta-LM 3.0: an open-weight collection of LLMs trained on substantially-sized corpora of Hebrew and English texts. The model is released in three sizes: 24B - adapted from the Mistral-Small-3.1 base model, 12B - adapted from the NVIDIA Nemotron Nano V2 model, and 1.7B - adapted from the Qwen3-1.7B base model. We are releasing multiple variants of each model, each with a native context length of 65k tokens; base model and chat model with tool-calling support. To rigorously evaluate our models, we introduce a new benchmark suite for evaluation of Hebrew chat-LLMs, covering a diverse set of tasks including Translation, Summarization, Winograd, Israeli Trivia, and Diacritization (nikud). Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.

</details>


### [144] [Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts](https://arxiv.org/abs/2602.02108)
*Wenhao Li,Daohai Yu,Gen Luo,Yuxin Zhang,Fei Chao,Rongrong Ji,Yifan Wu,Jiaxin Liu,Ziyang Gong,Zimu Liao*

Main category: cs.CL

TL;DR: OOMB是一个高效内存训练系统，通过分块循环训练和即时激活重计算实现O(1)激活内存，结合KV缓存优化，使Qwen2.5-7B模型每增加1万token上下文仅需10MB内存，可在单H200 GPU上训练400万token上下文。


<details>
  <summary>Details</summary>
Motivation: 训练大语言模型处理长上下文时面临GPU内存开销过大的问题，主要瓶颈是激活值内存随序列长度线性增长，这严重限制了模型处理长上下文的能力。

Method: 采用分块循环训练框架配合即时激活重计算实现恒定激活内存；针对KV缓存增长问题，集成分页内存管理器消除碎片、异步CPU卸载隐藏传输延迟、页面级稀疏注意力降低计算和通信开销。

Result: Qwen2.5-7B模型每增加1万token上下文仅需10MB内存开销，可在单H200 GPU上训练400万token上下文，而传统方法需要大型集群使用上下文并行。

Conclusion: OOMB系统显著提升了长上下文LLM训练的资源效率，通过创新的内存管理技术解决了激活值和KV缓存的内存瓶颈问题。

Abstract: Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We introduce OOMB, a highly memory-efficient training system that directly confronts this barrier. Our approach employs a chunk-recurrent training framework with on-the-fly activation recomputation, which maintains a constant activation memory footprint (O(1)) and shifts the primary bottleneck to the growing KV cache. To manage the KV cache, OOMB integrates a suite of synergistic optimizations: a paged memory manager for both the KV cache and its gradients to eliminate fragmentation, asynchronous CPU offloading to hide data transfer latency, and page-level sparse attention to reduce both computational complexity and communication overhead. The synergy of these techniques yields exceptional efficiency. Our empirical results show that for every additional 10K tokens of context, the end-to-end training memory overhead increases by a mere 10MB for Qwen2.5-7B. This allows training Qwen2.5-7B with a 4M-token context on a single H200 GPU, a feat that would otherwise require a large cluster using context parallelism. This work represents a substantial advance in resource efficiency for long-context LLM training. The source code is available at https://github.com/wenhaoli-xmu/OOMB.

</details>


### [145] [There Is More to Refusal in Large Language Models than a Single Direction](https://arxiv.org/abs/2602.02132)
*Faaiz Joad,Majd Hawasly,Sabri Boughorbel,Nadir Durrani,Husrev Taha Sencar*

Main category: cs.CL

TL;DR: 研究发现LLM的拒绝行为由多个几何上不同的激活空间方向介导，而非单一方向，但线性调节这些方向会产生相似的拒绝-过度拒绝权衡，形成共享的一维控制旋钮。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为大语言模型的拒绝行为由单一激活空间方向介导，但本文旨在验证这一解释是否完整，探索不同拒绝类别是否对应不同的几何方向。

Method: 研究了11个拒绝和非合规类别（包括安全性、不完整或不支持的请求、拟人化、过度拒绝等），分析这些拒绝行为在激活空间中的几何方向，并进行线性调节实验。

Result: 发现不同拒绝行为对应几何上不同的激活空间方向，但线性调节任何拒绝相关方向都会产生几乎相同的拒绝-过度拒绝权衡，主要差异在于拒绝方式而非是否拒绝。

Conclusion: LLM的拒绝行为由多个几何上不同的方向介导，而非单一方向，但线性调节这些方向会产生相似的拒绝-过度拒绝权衡，形成共享的一维控制机制，主要影响拒绝方式而非拒绝本身。

Abstract: Prior work argues that refusal in large language models is mediated by a single activation-space direction, enabling effective steering and ablation. We show that this account is incomplete. Across eleven categories of refusal and non-compliance, including safety, incomplete or unsupported requests, anthropomorphization, and over-refusal, we find that these refusal behaviors correspond to geometrically distinct directions in activation space. Yet despite this diversity, linear steering along any refusal-related direction produces nearly identical refusal to over-refusal trade-offs, acting as a shared one-dimensional control knob. The primary effect of different directions is not whether the model refuses, but how it refuses.

</details>


### [146] [Quantifying the Gap between Understanding and Generation within Unified Multimodal Models](https://arxiv.org/abs/2602.02140)
*Chenlong Wang,Yuhang Chen,Zhihan Hu,Dongping Chen,Wenhu Chen,Sarah Wiegreffe,Tianyi Zhou*

Main category: cs.CL

TL;DR: GapEval是一个双向基准测试，用于量化统一多模态模型中理解与生成能力之间的差距，揭示当前模型仅实现表面统一而非深度认知融合


<details>
  <summary>Details</summary>
Motivation: 尽管统一多模态模型在理解和生成任务上表现出色，但这两项能力是否真正对齐和整合在单一模型中仍不明确，需要量化评估其认知一致性

Method: 提出GapEval双向基准测试，每个问题可在图像和文本两种模态中回答，对称评估模型的双向推理能力和跨模态一致性，并从知识操纵角度进行实证研究

Result: 实验显示不同架构的UMMs在两个方向上都存在持续差距，表明当前模型仅实现表面统一而非深度认知融合，模型内知识保持分离，跨模态能力涌现和知识不同步

Conclusion: 统一多模态模型的理解和生成能力尚未真正对齐，需要进一步探索深度认知融合的机制，为未来研究指明方向

Abstract: Recent advances in unified multimodal models (UMM) have demonstrated remarkable progress in both understanding and generation tasks. However, whether these two capabilities are genuinely aligned and integrated within a single model remains unclear. To investigate this question, we introduce GapEval, a bidirectional benchmark designed to quantify the gap between understanding and generation capabilities, and quantitatively measure the cognitive coherence of the two "unified" directions. Each question can be answered in both modalities (image and text), enabling a symmetric evaluation of a model's bidirectional inference capability and cross-modal consistency. Experiments reveal a persistent gap between the two directions across a wide range of UMMs with different architectures, suggesting that current models achieve only surface-level unification rather than deep cognitive convergence of the two. To further explore the underlying mechanism, we conduct an empirical study from the perspective of knowledge manipulation to illustrate the underlying limitations. Our findings indicate that knowledge within UMMs often remains disjoint. The capability emergence and knowledge across modalities are unsynchronized, paving the way for further exploration.

</details>


### [147] [Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing](https://arxiv.org/abs/2602.02159)
*Lingkun Long,Yushi Huang,Shihao Bai,Ruihao Gong,Jun Zhang,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: Focus-dLLM：针对扩散大语言模型的无训练注意力稀疏化框架，通过过去置信度引导的指示器和汇感知剪枝策略，在保持性能的同时实现29倍以上的无损加速


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型在长上下文处理方面表现出色，但双向全注意力的计算成本限制了推理效率。现有稀疏注意力方法效果不佳，因为需要在解码前估计未解码token的注意力重要性，而扩散过程中未掩码token位置未知

Method: 1. 基于token置信度在相邻步骤间强相关的发现，设计过去置信度引导的指示器预测未掩码区域；2. 提出汇感知剪枝策略，准确估计并移除冗余注意力计算，同时保留高影响力的注意力汇；3. 利用观察到的跨层一致性，在不同层间复用已识别的汇位置以减少开销

Result: 在32K上下文长度下，该方法实现了超过29倍的无损加速，代码已开源

Conclusion: Focus-dLLM为长上下文扩散大语言模型推理提供了一种准确高效的无训练注意力稀疏化解决方案，显著提升了推理效率

Abstract: Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than $29\times$ lossless speedup under $32K$ context length. The code is publicly available at: https://github.com/Longxmas/Focus-dLLM

</details>


### [148] [D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use](https://arxiv.org/abs/2602.02160)
*Bowen Xu,Shaoyu Wu,Hao Jiang,Kai Liu,Xin Chen,Lulu Hu,Bin Yang*

Main category: cs.CL

TL;DR: D-CORE是一个两阶段训练框架，通过任务分解推理能力激励和多样性感知强化学习，解决大型推理模型在复杂工具使用场景中的懒惰推理问题，显著提升工具使用性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在复杂工具使用场景中缺乏子任务分解能力，导致"懒惰推理"问题，无法有效处理复杂现实问题。

Method: 提出D-CORE两阶段训练框架：1）通过自蒸馏激励模型的任务分解推理能力；2）使用多样性感知强化学习恢复模型的反思推理能力。

Result: 在BFCLv3基准测试中，D-CORE-8B达到77.7%准确率，超越最佳8B模型5.7%；D-CORE-14B以79.3%准确率创下新SOTA，性能超越70B模型但参数量仅为1/5。

Conclusion: D-CORE框架能有效提升大型推理模型的工具使用能力，通过解决子任务分解问题实现更高效的复杂问题解决，在不同模型规模上均表现出色。

Abstract: Effective tool use and reasoning are essential capabilities for large reasoning models~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning. To address this, we propose a two-stage training framework D-CORE~(\underline{\textbf{D}}ecomposing tasks and \underline{\textbf{Co}}mposing \underline{\textbf{Re}}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation, followed by diversity-aware reinforcement learning~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\% accuracy, surpassing the best-performing 8B model by 5.7\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\%, outperforming 70B models despite being 5$\times$ smaller. The source code is available at https://github.com/alibaba/EfficientAI.

</details>


### [149] [AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?](https://arxiv.org/abs/2602.02178)
*Liang Lin,Feng Xiong,Zengbin Wang,Kun Wang,Junhao Dong,Xuecai Hu,Yong Wang,Xiangxiang Chu*

Main category: cs.CL

TL;DR: AR-MAP：利用对齐好的自回归LLM作为隐式教师，通过权重缩放实现扩散LLM的对齐，避免直接对齐的高方差和计算开销


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（DLLMs）作为自回归模型的替代方案，支持并行token生成，但其偏好对齐面临挑战，主要因为基于ELBO的似然估计引入高方差

Method: 提出AR-MAP框架，利用已对齐的自回归LLMs作为隐式教师，通过简单的权重缩放让DLLMs吸收对齐知识，利用两种生成范式间的共享架构结构

Result: 在多种偏好对齐任务上，AR-MAP达到竞争性或优于现有DLLM特定对齐方法的性能，在所有任务和模型上平均得分达69.08%

Conclusion: AR-MAP提供了一种高效、低方差的DLLM对齐方法，通过利用自回归LLM的对齐知识，避免了直接对齐的计算挑战

Abstract: Diffusion Large Language Models (DLLMs) have emerged as a powerful alternative to autoregressive models, enabling parallel token generation across multiple positions. However, preference alignment of DLLMs remains challenging due to high variance introduced by Evidence Lower Bound (ELBO)-based likelihood estimation. In this work, we propose AR-MAP, a novel transfer learning framework that leverages preference-aligned autoregressive LLMs (AR-LLMs) as implicit teachers for DLLM alignment. We reveal that DLLMs can effectively absorb alignment knowledge from AR-LLMs through simple weight scaling, exploiting the shared architectural structure between these divergent generation paradigms. Crucially, our approach circumvents the high variance and computational overhead of direct DLLM alignment and comprehensive experiments across diverse preference alignment tasks demonstrate that AR-MAP achieves competitive or superior performance compared to existing DLLM-specific alignment methods, achieving 69.08\% average score across all tasks and models. Our Code is available at https://github.com/AMAP-ML/AR-MAP.

</details>


### [150] [Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages](https://arxiv.org/abs/2602.02182)
*Tjaša Arčon,Matej Klemen,Marko Robnik-Šikonja,Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: LLMs在元语言知识（对语言结构的显式推理）方面表现有限，其知识受数据可用性影响而非真正的跨语言语法能力


<details>
  <summary>Details</summary>
Motivation: 现有语言基准测试通常关注狭窄现象，强调高资源语言，很少评估元语言知识（对语言结构的显式推理而非语言使用）。需要系统评估LLMs的元语言知识及其跨语言表现。

Method: 使用准确率和宏观F1分数，结合多数类和随机基线，分析整体性能，并考察不同语言领域和语言相关因素的变化。创建包含多种语言和语言特征的基准测试。

Result: GPT-4o表现最佳但准确率仅0.367，开源模型落后。所有模型表现高于随机但未超过多数类基线，表明它们捕捉跨语言模式但缺乏细粒度语法区分。词汇特征准确率最高，音系特征最低。数字语言状态（维基百科规模、语料库可用性）是准确率的最强预测因素。

Conclusion: LLMs的元语言知识是碎片化的，受数据可用性塑造而非真正的跨语言语法能力。需要更多全球语言多样性来改善LLMs的语言理解。

Abstract: Large language models (LLMs) are routinely evaluated on language use tasks, yet their knowledge of linguistic structure remains poorly understood. Existing linguistic benchmarks typically focus on narrow phenomena, emphasize high-resource languages, and rarely evaluate metalinguistic knowledge-explicit reasoning about language structure rather than language use. Using accuracy and macro F1, together with majority-class and chance baselines, we analyse overall performance and examine variation by linguistic domains and language-related factors. Our results show that metalinguistic knowledge in current LLMs is limited: GPT-4o performs best but achieves only moderate accuracy (0.367), while open-source models lag behind. All models perform above chance but fail to outperform the majority-class baseline, suggesting they capture cross-linguistic patterns but lack fine-grained grammatical distinctions. Performance varies across linguistic domains, with lexical features showing the highest accuracy and phonological features among the lowest, partially reflecting differences in online visibility. At the language level, accuracy shows a strong association with digital language status: languages with higher digital presence and resource availability are evaluated more accurately, while low-resource languages show substantially lower performance. Analyses of predictive factors confirm that resource-related indicators (Wikipedia size, corpus availability) are more informative predictors of accuracy than geographical, genealogical, or sociolinguistic factors. Together, these results suggest that LLMs' metalinguistic knowledge is fragmented and shaped by data availability rather than generalizable grammatical competence across the world's languages. We release our benchmark as an open-source dataset to support systematic evaluation and encourage greater global linguistic diversity in future LLMs.

</details>


### [151] [Sinhala Physical Common Sense Reasoning Dataset for Global PIQA](https://arxiv.org/abs/2602.02207)
*Nisansa de Silva,Surangika Ranathunga*

Main category: cs.CL

TL;DR: 首个僧伽罗语物理常识推理数据集，包含110个人工创建和验证的样本，每个样本包含提示、正确答案和错误答案，主要涉及斯里兰卡语境。


<details>
  <summary>Details</summary>
Motivation: 创建首个僧伽罗语物理常识推理数据集，填补该语言在常识推理任务上的数据空白，特别关注斯里兰卡本土语境，促进僧伽罗语自然语言处理的发展。

Method: 作为Global PIQA项目的一部分，人工创建并验证了110个数据样本，每个样本包含提示、正确答案和错误答案，问题主要基于斯里兰卡的文化和社会背景。

Result: 成功创建了包含110个高质量样本的僧伽罗语物理常识推理数据集，为僧伽罗语NLP研究提供了重要资源，特别强调了斯里兰卡本土语境。

Conclusion: 该数据集填补了僧伽罗语在物理常识推理任务上的空白，为僧伽罗语NLP研究提供了基准数据，有助于促进该语言在AI领域的发展和应用。

Abstract: This paper presents the first-ever Sinhala physical common sense reasoning dataset created as part of Global PIQA. It contains 110 human-created and verified data samples, where each sample consists of a prompt, the corresponding correct answer, and a wrong answer. Most of the questions refer to the Sri Lankan context, where Sinhala is an official language.

</details>


### [152] [Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study](https://arxiv.org/abs/2602.02208)
*Md. Toufique Hasan,Ayman Asad Khan,Mika Saari,Vaishnavi Bankhele,Pekka Abrahamsson*

Main category: cs.CL

TL;DR: AgriHubi是一个针对芬兰语农业决策支持的领域自适应检索增强生成(RAG)系统，通过整合芬兰农业文档和开源模型，结合显式来源基础和用户反馈，显著提升了答案完整性、语言准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集型领域有潜力，但在农业应用中受到限制：缺乏领域基础、英语中心训练数据、有限的实际评估。这些问题在低资源语言中更为突出，虽然存在高质量领域文档，但通用模型难以有效访问。

Method: 开发AgriHubi系统，整合芬兰农业文档与开源PORO系列模型，采用检索增强生成(RAG)架构，结合显式来源基础和用户反馈机制支持迭代优化，经过8个迭代周期开发。

Result: 通过两个用户研究评估，系统在答案完整性、语言准确性和感知可靠性方面有明显提升。研究还揭示了部署更大模型时响应质量与延迟之间的实际权衡。

Conclusion: 该研究为低资源语言环境下设计和评估领域特定RAG系统提供了实证指导，展示了领域自适应方法在农业决策支持中的有效性。

Abstract: Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.

</details>


### [153] [Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge](https://arxiv.org/abs/2602.02219)
*Yuzheng Xu,Tosho Hirasawa,Tadashi Kozuno,Yoshitaka Ushiku*

Main category: cs.CL

TL;DR: 论文发现基于量规的LLM评估存在位置偏差，并提出平衡排列策略来缓解该偏差，提高与人类评估的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge研究主要关注点对点和成对评估范式，而基于量规的评估（LLM从多个量规中选择分数）分析较少。作者发现这种评估方式存在位置偏差问题。

Method: 通过跨多个模型和数据集的受控实验证明位置偏差的存在，并提出平衡排列策略：将每个分数选项均匀分布在不同的位置，通过聚合多个排列的分数来缓解偏差。

Result: 实验显示基于量规的LLM评估存在一致的位置偏差，平衡排列策略不仅能揭示潜在的位置偏差，还能显著提高LLM评估与人类评估之间的相关性。

Conclusion: 基于量规的LLM-as-a-Judge评估并非本质上的点对点评估，简单的基于排列的校准可以显著提高其可靠性，位置偏差是需要考虑的重要因素。

Abstract: Large language models (LLMs) are now widely used to evaluate the quality of text, a field commonly referred to as LLM-as-a-judge. While prior works mainly focus on point-wise and pair-wise evaluation paradigms. Rubric-based evaluation, where LLMs select a score from multiple rubrics, has received less analysis. In this work, we show that rubric-based evaluation implicitly resembles a multi-choice setting and therefore has position bias: LLMs prefer score options appearing at specific positions in the rubric list. Through controlled experiments across multiple models and datasets, we demonstrate consistent position bias. To mitigate this bias, we propose a balanced permutation strategy that evenly distributes each score option across positions. We show that aggregating scores across balanced permutations not only reveals latent position bias, but also improves correlation between the LLM-as-a-Judge and human. Our results suggest that rubric-based LLM-as-a-Judge is not inherently point-wise and that simple permutation-based calibration can substantially improve its reliability.

</details>


### [154] [Using Correspondence Patterns to Identify Irregular Words in Cognate sets Through Leave-One-Out Validation](https://arxiv.org/abs/2602.02221)
*Frederic Blum,Johann-Mattis List*

Main category: cs.CL

TL;DR: 提出了一种新的量化评估语音对应规律性的方法——平衡平均对应模式重现率，并基于此开发了识别不规则同源词集的算法，在真实数据上达到85%的准确率。


<details>
  <summary>Details</summary>
Motivation: 历史语言比较中，语音对应规律性是核心证据，但传统上主要依赖直觉判断而非量化评估，且不规则现象比新语法学派模型预期的更常见。随着计算历史语言学的发展和标准化词汇数据的增加，需要改进工作流程并提供量化评估方法。

Method: 提出了平衡平均对应模式重现率作为新的规律性度量标准，并开发了基于此度量的计算方法，用于识别对应模式不规则的同源词集。通过留一验证法进行实验验证，在模拟数据和真实数据上测试方法识别不规则形式的能力。

Result: 在基于真实数据的实验中，该方法整体准确率达到85%。研究还展示了使用大数据集子样本的优势，以及数据中不规则性增加对结果的影响。

Conclusion: 新的规律性度量和基于此的不规则同源词识别方法，在提高现有和未来计算机辅助语言比较数据集质量方面具有重要潜力。

Abstract: Regular sound correspondences constitute the principal evidence in historical language comparison. Despite the heuristic focus on regularity, it is often more an intuitive judgement than a quantified evaluation, and irregularity is more common than expected from the Neogrammarian model. Given the recent progress of computational methods in historical linguistics and the increased availability of standardized lexical data, we are now able to improve our workflows and provide such a quantitative evaluation. Here, we present the balanced average recurrence of correspondence patterns as a new measure of regularity. We also present a new computational method that uses this measure to identify cognate sets that lack regularity with respect to their correspondence patterns. We validate the method through two experiments, using simulated and real data. In the experiments, we employ leave-one-out validation to measure the regularity of cognate sets in which one word form has been replaced by an irregular one, checking how well our method identifies the forms causing the irregularity. Our method achieves an overall accuracy of 85\% with the datasets based on real data. We also show the benefits of working with subsamples of large datasets and how increasing irregularity in the data influences our results. Reflecting on the broader potential of our new regularity measure and the irregular cognate identification method based on it, we conclude that they could play an important role in improving the quality of existing and future datasets in computer-assisted language comparison.

</details>


### [155] [OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data](https://arxiv.org/abs/2602.02266)
*Tan Sang Nguyen,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: OpenSeal是首个真正开源的东南亚语言大模型，仅使用34.7B并行数据和180小时训练，性能媲美同类模型


<details>
  <summary>Details</summary>
Motivation: 现有LLM多为英语中心，对低资源语言表现不佳；东南亚语言模型缺乏真正开源（训练数据不公开），而开源模型对透明度、理解模型内部机制（偏见、泛化、多语言性）至关重要

Method: 通过受控全面实验研究并行数据在LLM持续预训练中的有效性，发现仅使用并行数据是将LLM扩展到新语言的最有效方法

Result: 仅用34.7B tokens并行数据和180小时（8x NVIDIA H200 GPUs）训练出OpenSeal，性能与现有相似规模模型相当

Conclusion: 并行数据是扩展LLM到新语言的有效方法，OpenSeal作为首个真正开源的东南亚LLM，为研究透明度、模型内部机制提供了重要资源

Abstract: Large language models (LLMs) have proven to be effective tools for a wide range of natural language processing (NLP) applications. Although many LLMs are multilingual, most remain English-centric and perform poorly on low-resource languages. Recently, several Southeast Asia-focused LLMs have been developed, but none are truly open source, as they do not publicly disclose their training data. Truly open-source models are important for transparency and for enabling a deeper and more precise understanding of LLM internals and development, including biases, generalization, and multilinguality. Motivated by recent advances demonstrating the effectiveness of parallel data in improving multilingual performance, we conduct controlled and comprehensive experiments to study the effectiveness of parallel data in continual pretraining of LLMs. Our findings show that using only parallel data is the most effective way to extend an LLM to new languages. Using just 34.7B tokens of parallel data and 180 hours on 8x NVIDIA H200 GPUs, we built OpenSeal, the first truly open Southeast Asian LLM that rivals the performance of existing models of similar size.

</details>


### [156] [dziribot: rag based intelligent conversational agent for algerian arabic dialect](https://arxiv.org/abs/2602.02270)
*El Batoul Bechiri,Dihia Lanasri*

Main category: cs.CL

TL;DR: DziriBOT是一个针对阿尔及利亚方言Darja设计的混合智能对话代理，通过多层架构结合NLU和RAG技术，在低资源方言环境下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 阿尔及利亚客户服务的数字化需求日益增长，但Darja方言的复杂性（非标准化拼写、法语代码转换、阿拉伯语/拉丁字母混用）给对话系统开发带来了巨大挑战，需要专门针对该方言的解决方案。

Method: 提出多层架构整合专业NLU和RAG技术，评估三种方法：稀疏特征Rasa管道、经典机器学习基线、基于Transformer的微调，最终采用微调的DziriBERT模型。

Result: 微调的DziriBERT模型在Darja方言处理上达到最先进性能，显著优于传统基线方法，特别是在处理拼写噪声和罕见意图方面表现突出。

Conclusion: DziriBOT为阿尔及利亚用户提供了一个强大、可扩展的解决方案，弥合了正式语言模型与方言现实之间的差距，为区域市场的方言感知自动化提供了蓝图。

Abstract: The rapid digitalization of customer service has intensified the demand for conversational agents capable of providing accurate and natural interactions. In the Algerian context, this is complicated by the linguistic complexity of Darja, a dialect characterized by non-standardized orthography, extensive code-switching with French, and the simultaneous use of Arabic and Latin (Arabizi) scripts. This paper introduces DziriBOT, a hybrid intelligent conversational agent specifically engineered to overcome these challenges. We propose a multi-layered architecture that integrates specialized Natural Language Understanding (NLU) with Retrieval-Augmented Generation (RAG), allowing for both structured service flows and dynamic, knowledge-intensive responses grounded in curated enterprise documentation. To address the low-resource nature of Darja, we systematically evaluate three distinct approaches: a sparse-feature Rasa pipeline, classical machine learning baselines, and transformer-based fine-tuning. Our experimental results demonstrate that the fine-tuned DziriBERT model achieves state-of-the-art performance. These results significantly outperform traditional baselines, particularly in handling orthographic noise and rare intents. Ultimately, DziriBOT provides a robust, scalable solution that bridges the gap between formal language models and the linguistic realities of Algerian users, offering a blueprint for dialect-aware automation in the regional market.

</details>


### [157] [Kimi K2.5: Visual Agentic Intelligence](https://arxiv.org/abs/2602.02276)
*Kimi Team,Tongtong Bai,Yifan Bai,Yiping Bao,S. H. Cai,Yuan Cao,Y. Charles,H. S. Che,Cheng Chen,Guanduo Chen,Huarong Chen,Jia Chen,Jiahao Chen,Jianlong Chen,Jun Chen,Kefan Chen,Liang Chen,Ruijue Chen,Xinhao Chen,Yanru Chen,Yanxu Chen,Yicun Chen,Yimin Chen,Yingjiang Chen,Yuankun Chen,Yujie Chen,Yutian Chen,Zhirong Chen,Ziwei Chen,Dazhi Cheng,Minghan Chu,Jialei Cui,Jiaqi Deng,Muxi Diao,Hao Ding,Mengfan Dong,Mengnan Dong,Yuxin Dong,Yuhao Dong,Angang Du,Chenzhuang Du,Dikang Du,Lingxiao Du,Yulun Du,Yu Fan,Shengjun Fang,Qiulin Feng,Yichen Feng,Garimugai Fu,Kelin Fu,Hongcheng Gao,Tong Gao,Yuyao Ge,Shangyi Geng,Chengyang Gong,Xiaochen Gong,Zhuoma Gongque,Qizheng Gu,Xinran Gu,Yicheng Gu,Longyu Guan,Yuanying Guo,Xiaoru Hao,Weiran He,Wenyang He,Yunjia He,Chao Hong,Hao Hu,Jiaxi Hu,Yangyang Hu,Zhenxing Hu,Ke Huang,Ruiyuan Huang,Weixiao Huang,Zhiqi Huang,Tao Jiang,Zhejun Jiang,Xinyi Jin,Yu Jing,Guokun Lai,Aidi Li,C. Li,Cheng Li,Fang Li,Guanghe Li,Guanyu Li,Haitao Li,Haoyang Li,Jia Li,Jingwei Li,Junxiong Li,Lincan Li,Mo Li,Weihong Li,Wentao Li,Xinhang Li,Xinhao Li,Yang Li,Yanhao Li,Yiwei Li,Yuxiao Li,Zhaowei Li,Zheming Li,Weilong Liao,Jiawei Lin,Xiaohan Lin,Zhishan Lin,Zichao Lin,Cheng Liu,Chenyu Liu,Hongzhang Liu,Liang Liu,Shaowei Liu,Shudong Liu,Shuran Liu,Tianwei Liu,Tianyu Liu,Weizhou Liu,Xiangyan Liu,Yangyang Liu,Yanming Liu,Yibo Liu,Yuanxin Liu,Yue Liu,Zhengying Liu,Zhongnuo Liu,Enzhe Lu,Haoyu Lu,Zhiyuan Lu,Junyu Luo,Tongxu Luo,Yashuo Luo,Long Ma,Yingwei Ma,Shaoguang Mao,Yuan Mei,Xin Men,Fanqing Meng,Zhiyong Meng,Yibo Miao,Minqing Ni,Kun Ouyang,Siyuan Pan,Bo Pang,Yuchao Qian,Ruoyu Qin,Zeyu Qin,Jiezhong Qiu,Bowen Qu,Zeyu Shang,Youbo Shao,Tianxiao Shen,Zhennan Shen,Juanfeng Shi,Lidong Shi,Shengyuan Shi,Feifan Song,Pengwei Song,Tianhui Song,Xiaoxi Song,Hongjin Su,Jianlin Su,Zhaochen Su,Lin Sui,Jinsong Sun,Junyao Sun,Tongyu Sun,Flood Sung,Yunpeng Tai,Chuning Tang,Heyi Tang,Xiaojuan Tang,Zhengyang Tang,Jiawen Tao,Shiyuan Teng,Chaoran Tian,Pengfei Tian,Ao Wang,Bowen Wang,Chensi Wang,Chuang Wang,Congcong Wang,Dingkun Wang,Dinglu Wang,Dongliang Wang,Feng Wang,Hailong Wang,Haiming Wang,Hengzhi Wang,Huaqing Wang,Hui Wang,Jiahao Wang,Jinhong Wang,Jiuzheng Wang,Kaixin Wang,Linian Wang,Qibin Wang,Shengjie Wang,Shuyi Wang,Si Wang,Wei Wang,Xiaochen Wang,Xinyuan Wang,Yao Wang,Yejie Wang,Yipu Wang,Yiqin Wang,Yucheng Wang,Yuzhi Wang,Zhaoji Wang,Zhaowei Wang,Zhengtao Wang,Zhexu Wang,Zihan Wang,Zizhe Wang,Chu Wei,Ming Wei,Chuan Wen,Zichen Wen,Chengjie Wu,Haoning Wu,Junyan Wu,Rucong Wu,Wenhao Wu,Yuefeng Wu,Yuhao Wu,Yuxin Wu,Zijian Wu,Chenjun Xiao,Jin Xie,Xiaotong Xie,Yuchong Xie,Yifei Xin,Bowei Xing,Boyu Xu,Jianfan Xu,Jing Xu,Jinjing Xu,L. H. Xu,Lin Xu,Suting Xu,Weixin Xu,Xinbo Xu,Xinran Xu,Yangchuan Xu,Yichang Xu,Yuemeng Xu,Zelai Xu,Ziyao Xu,Junjie Yan,Yuzi Yan,Guangyao Yang,Hao Yang,Junwei Yang,Kai Yang,Ningyuan Yang,Ruihan Yang,Xiaofei Yang,Xinlong Yang,Ying Yang,Yi Yang,Yi Yang,Zhen Yang,Zhilin Yang,Zonghan Yang,Haotian Yao,Dan Ye,Wenjie Ye,Zhuorui Ye,Bohong Yin,Chengzhen Yu,Longhui Yu,Tao Yu,Tianxiang Yu,Enming Yuan,Mengjie Yuan,Xiaokun Yuan,Yang Yue,Weihao Zeng,Dunyuan Zha,Haobing Zhan,Dehao Zhang,Hao Zhang,Jin Zhang,Puqi Zhang,Qiao Zhang,Rui Zhang,Xiaobin Zhang,Y. Zhang,Yadong Zhang,Yangkun Zhang,Yichi Zhang,Yizhi Zhang,Yongting Zhang,Yu Zhang,Yushun Zhang,Yutao Zhang,Yutong Zhang,Zheng Zhang,Chenguang Zhao,Feifan Zhao,Jinxiang Zhao,Shuai Zhao,Xiangyu Zhao,Yikai Zhao,Zijia Zhao,Huabin Zheng,Ruihan Zheng,Shaojie Zheng,Tengyang Zheng,Junfeng Zhong,Longguang Zhong,Weiming Zhong,M. Zhou,Runjie Zhou,Xinyu Zhou,Zaida Zhou,Jinguo Zhu,Liya Zhu,Xinhao Zhu,Yuxuan Zhu,Zhen Zhu,Jingze Zhuang,Weiyu Zhuang,Ying Zou,Xinxing Zu*

Main category: cs.CL

TL;DR: Kimi K2.5是一个开源的多模态智能体模型，通过联合优化文本和视觉模态，并引入Agent Swarm并行代理编排框架，在编码、视觉、推理和智能体任务上取得SOTA结果，同时将延迟降低4.5倍。


<details>
  <summary>Details</summary>
Motivation: 推动通用智能体智能的发展，通过多模态联合优化提升智能体能力，并解决复杂任务执行中的效率问题。

Method: 1. 联合文本-视觉预训练、零视觉SFT、联合文本-视觉强化学习等多模态优化技术；2. Agent Swarm自导向并行代理编排框架，动态分解复杂任务为异构子问题并并行执行。

Result: 在编码、视觉、推理和智能体任务上取得最先进结果；Agent Swarm相比单智能体基线将延迟降低高达4.5倍。

Conclusion: Kimi K2.5通过多模态联合优化和并行代理编排框架，有效提升了智能体智能的性能和效率，为未来研究和实际应用提供了有价值的开源模型。

Abstract: We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to $4.5\times$ over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.

</details>


### [158] [Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages](https://arxiv.org/abs/2602.02287)
*Isaac Chung,Linda Freienthal*

Main category: cs.CL

TL;DR: 研究发现跨语言评估中LLM评判的稳定性问题：在相同生成条件下，表面指标保持稳定，但语用判断（连贯性、指令遵循）在不同语言间出现排名反转和低相关性，表明零样本评判迁移不可靠。


<details>
  <summary>Details</summary>
Motivation: 跨语言评估通常混淆模型性能差异和测量不稳定性两个因素，需要研究在保持生成条件不变的情况下，评估方法在不同语言间的可靠性。

Method: 使用相同参数在爱沙尼亚语、芬兰语和匈牙利语生成合成客服对话，比较自动指标和LLM-as-a-judge评分，以少量爱沙尼亚语母语者标注为参考点。

Result: 发现系统性排名不稳定性：表面指标（词汇多样性、表面和语义相似性）保持跨语言稳定性，但语用判断（连贯性、指令遵循）出现排名反转和接近零相关性。

Conclusion: 零样本评判迁移在形态丰富语言的语篇级评估中不可靠，需要针对具体语言进行校准，并建立人类基准。提供了控制生成协议、合成数据和评估框架供复现。

Abstract: Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.
  This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges.

</details>


### [159] [Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?](https://arxiv.org/abs/2602.02290)
*Alex Argese,Pasquale Lisena,Raphaël Troncy*

Main category: cs.CL

TL;DR: 提出StoryScore综合指标，用于评估AI生成的科学故事，整合语义对齐、词汇基础、叙事控制、结构保真度、冗余避免和实体级幻觉检测


<details>
  <summary>Details</summary>
Motivation: 生成式AI能将科学文章转化为适合不同受众的叙事，但评估这些故事具有挑战性。传统摘要指标无法捕捉叙事所需的抽象、简化和教学创造力，而幻觉检测器常将合法的叙事重构误分类，或在涉及创造力时表现不稳定。

Method: 提出StoryScore综合指标，将语义对齐、词汇基础、叙事控制、结构保真度、冗余避免和实体级幻觉检测整合到统一框架中。分析揭示了现有幻觉检测方法无法区分教学创造力与事实错误的关键局限。

Result: 开发了StoryScore评估框架，能够更全面地评估AI生成的科学故事质量。研究发现自动指标能有效评估与原始内容的语义相似性，但难以评估叙事方式和控制质量。

Conclusion: 需要新的评估指标来准确评估AI生成的科学故事，StoryScore通过整合多个维度提供了更全面的评估方案，解决了传统方法在区分教学创造力和事实错误方面的局限性。

Abstract: Generative AI can turn scientific articles into narratives for diverse audiences, but evaluating these stories remains challenging. Storytelling demands abstraction, simplification, and pedagogical creativity-qualities that are not often well-captured by standard summarization metrics. Meanwhile, factual hallucinations are critical in scientific contexts, yet, detectors often misclassify legitimate narrative reformulations or prove unstable when creativity is involved. In this work, we propose StoryScore, a composite metric for evaluating AI-generated scientific stories. StoryScore integrates semantic alignment, lexical grounding, narrative control, structural fidelity, redundancy avoidance, and entity-level hallucination detection into a unified framework. Our analysis also reveals why many hallucination detection methods fail to distinguish pedagogical creativity from factual errors, highlighting a key limitation: while automatic metrics can effectively assess semantic similarity with original content, they struggle to evaluate how it is narrated and controlled.

</details>


### [160] [Advancing General-Purpose Reasoning Models with Modular Gradient Surgery](https://arxiv.org/abs/2602.02301)
*Min Cai,Yu Liang,Longzheng Wang,Yan Wang,Yueyang Zhang,Long Xia,Zhiyuan Sun,Xi Ye,Daiting Shi*

Main category: cs.CL

TL;DR: 本文提出模块化梯度手术（MGS）方法，解决大型推理模型在多领域强化学习中的梯度冲突问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在大型推理模型中取得了显著进展，但在多领域训练通用模型时面临严重挑战。现有策略（顺序RL和混合RL）存在显著的跨领域干扰，导致整体性能提升有限。

Method: 提出模块化梯度手术（MGS），在Transformer内部模块层面解决梯度冲突问题。该方法应用于Llama和Qwen模型，通过优化梯度更新策略来减少跨领域干扰。

Result: 在三个代表性领域（数学、通用聊天和指令遵循）上，MGS相比标准多任务RL分别使Llama和Qwen模型平均提升4.3分（16.6%）和4.5分（11.1%）。进一步分析表明MGS在长时间训练中保持有效。

Conclusion: 本研究阐明了多领域强化学习中干扰的来源，并提出了一种有效的解决方案，为训练通用大型推理模型提供了重要方法。

Abstract: Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\%) and 4.5 (11.1\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.

</details>


### [161] [The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors](https://arxiv.org/abs/2602.02315)
*Raphaël Sarfati,Eric Bigelow,Daniel Wurgaft,Jack Merullo,Atticus Geiger,Owen Lewis,Tom McGrath,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: LLMs编码概率分布信念形成弯曲的"信念流形"，线性干预常导致离流形偏移，而几何感知的线性场探测能更好地保持信念结构


<details>
  <summary>Details</summary>
Motivation: 缺乏对LLMs如何编码和更新条件信念的机制性理解，需要研究信念在表示空间中的编码方式、更新机制以及干预如何重塑这些信念

Method: 在受控设置中让Llama-3.2从正态分布生成样本，仅通过上下文中的样本来隐式推断分布参数，研究信念流形的形成和变化

Result: 发现足够的上下文学习会形成参数空间的弯曲信念流形，标准线性干预常使模型偏离流形并导致耦合的离分布偏移，而几何和场感知的干预能更好地保持信念族结构

Conclusion: LLMs中自然涌现出丰富的结构，纯线性概念表示通常是不充分的抽象，线性场探测(LFP)可作为平铺数据流形并尊重底层几何的简单干预方法

Abstract: Large language models (LLMs) represent prompt-conditioned beliefs (posteriors over answers and claims), but we lack a mechanistic account of how these beliefs are encoded in representation space, how they update with new evidence, and how interventions reshape them. We study a controlled setting in which Llama-3.2 generates samples from a normal distribution by implicitly inferring its parameters (mean and standard deviation) given only samples from the distribution in context. We find representations of curved "belief manifolds" for these parameters form with sufficient in-context learning and study how the model adapts when the distribution suddenly changes. While standard linear steering often pushes the model off-manifold and induces coupled, out-of-distribution shifts, geometry and field-aware steering better preserves the intended belief family. Our work demonstrates an example of linear field probing (LFP) as a simple approach to tile the data manifold and make interventions that respect the underlying geometry. We conclude that rich structure emerges naturally in LLMs and that purely linear concept representations are often an inadequate abstraction.

</details>


### [162] [A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method](https://arxiv.org/abs/2602.02320)
*Feiyang Cai,Guijuan He,Yi Hu,Jingjing Wang,Joshua Luo,Tianyu Zhu,Srikanth Pilla,Gang Li,Ling Liu,Feng Luo*

Main category: cs.CL

TL;DR: 提出全自动分子结构描述生成框架，通过解析IUPAC名称构建结构化XML元数据，指导LLM生成精确描述，创建了16.3万分子-描述对数据集，验证精度达98.6%


<details>
  <summary>Details</summary>
Motivation: 分子功能主要由结构决定，准确对齐分子结构与自然语言对LLM推理化学任务至关重要。但人工标注成本高昂，难以构建大规模高质量的结构-描述数据集

Method: 基于规则化学命名解析器扩展，自动解释IUPAC名称并构建富结构化XML元数据，明确编码分子结构信息，然后使用该元数据指导LLM生成准确自然语言描述

Result: 构建了约16.3万个分子-描述对的大规模数据集，通过LLM和专家人工验证2000个分子子集，显示描述精度达到98.6%

Conclusion: 该数据集为未来分子-语言对齐提供了可靠基础，提出的标注方法易于扩展到更大数据集和依赖结构描述的更广泛化学任务

Abstract: Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.

</details>


### [163] [Language Steering for Multilingual In-Context Learning](https://arxiv.org/abs/2602.02326)
*Neeraja Kirtane,Kuan-Hao Huang*

Main category: cs.CL

TL;DR: 提出语言向量方法，通过激活差异引导LLM在推理时转向目标语言空间，提升多语言上下文学习性能


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在非英语语言上表现显著低于英语，特别是在上下文学习中，使用英语演示但测试非英语输入时性能下降明显

Method: 提出语言向量方法，利用源语言和目标语言之间的激活差异来引导模型行为，在推理时向中间模型激活添加向量，使内部表示转向目标语言空间，无需参数更新

Result: 在3个数据集、19种语言和3个不同模型上测试，在所有任务和语言上都比基线有持续改进；层次聚类显示语言向量与语言家族对齐，且能跨任务成功迁移

Conclusion: 语言向量是一种无需训练的语言引导方法，能有效提升多语言上下文学习性能，揭示LLM中存在与语言家族对齐的通用语义空间

Abstract: While multilingual large language models have gained widespread adoption, their performance on non-English languages remains substantially inferior to English. This disparity is particularly evident in in-context learning scenarios, where providing demonstrations in English but testing on non-English inputs leads to significant performance degradation. In this paper, we hypothesize that LLMs develop a universal semantic space for understanding languages, where different languages are encoded as distinct directions within this space. Based on this hypothesis, we propose language vectors -- a training-free language steering approach that leverages activation differences between source and target languages to guide model behavior. We steer the model generations by adding the vector to the intermediate model activations during inference. This is done to make the model's internal representations shift towards the target language space without any parameter updates. We evaluate our method across three datasets and test on a total of 19 languages on three different models. Our results show consistent improvements on multilingual in-context learning over baselines across all tasks and languages tested. Beyond performance gains, hierarchical clustering of steering vectors reveals meaningful linguistic structure aligned with language families. These vectors also successfully transfer across tasks, demonstrating that these representations are task-agnostic.

</details>


### [164] [Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics](https://arxiv.org/abs/2602.02343)
*Ziwen Xu,Chenyan Wu,Hengyu Sun,Haiwen Hong,Mengru Wang,Yunzhi Yao,Longtao Huang,Hui Xue,Shumin Deng,Zhixuan Chu,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一个统一框架，将不同LLM控制方法视为基于控制信号的动态权重更新，并引入偏好-效用分析来量化控制效果，发现偏好与效用之间存在权衡关系，最后提出了改进的SPLIT控制方法。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的控制方法（如权重微调、LoRA适配、激活干预等）通常被孤立研究，缺乏统一框架进行比较和分析，这阻碍了对不同控制方法效果的理解和优化。

Method: 1) 提出统一框架，将各种控制方法视为基于控制信号的动态权重更新；2) 引入偏好-效用分析，使用极性配对对比示例在共享对数几率尺度上测量偏好（对目标概念的倾向性）和效用（连贯有效的生成）；3) 从激活流形角度解释控制行为；4) 提出新的SPLIT控制方法。

Result: 研究发现不同控制方法都存在一致的偏好-效用权衡：更强的控制会增加偏好但会降低效用。从激活流形角度看，控制将表示沿目标概念方向移动以增强偏好，但当干预将表示推离模型的有效生成流形时，效用会下降。

Conclusion: 该研究提供了一个统一框架来分析LLM控制方法，揭示了偏好与效用之间的基本权衡关系，并基于这一理解提出了改进的SPLIT控制方法，能在增强偏好的同时更好地保持效用。

Abstract: Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.

</details>


### [165] [Automated Multiple Mini Interview (MMI) Scoring](https://arxiv.org/abs/2602.02360)
*Ryan Huynh,Frank Guerin,Alison Callwood*

Main category: cs.CL

TL;DR: 本文提出一种多智能体提示框架，用于评估多站迷你面试中的软技能，通过结构化提示工程替代数据密集型微调，在复杂主观推理任务上达到专家级可靠性。


<details>
  <summary>Details</summary>
Motivation: 在竞争性选拔过程中评估共情、伦理判断、沟通等软技能至关重要，但人工评分常存在不一致性和偏见。虽然大语言模型改进了自动作文评分，但现有基于推理的微调方法难以处理多站迷你面试的抽象性和上下文依赖性，无法捕捉候选人叙述中的隐含信号。

Method: 引入多智能体提示框架，将评估过程分解为转录本精炼和标准特定评分两个阶段。使用大型指令调优模型进行3样本上下文学习，通过结构化提示工程替代传统的数据密集型微调方法。

Result: 该方法在软技能评估上显著优于专门的微调基线（平均QWK 0.62 vs 0.32），达到与人类专家相当的可靠性。在ASAP基准测试中，无需额外训练即可媲美领域特定的最先进模型。

Conclusion: 对于复杂的主观推理任务，结构化提示工程可能为数据密集型微调提供可扩展的替代方案，改变大语言模型在自动评估中的应用方式。

Abstract: Assessing soft skills such as empathy, ethical judgment, and communication is essential in competitive selection processes, yet human scoring is often inconsistent and biased. While Large Language Models (LLMs) have improved Automated Essay Scoring (AES), we show that state-of-the-art rationale-based fine-tuning methods struggle with the abstract, context-dependent nature of Multiple Mini-Interviews (MMIs), missing the implicit signals embedded in candidate narratives. We introduce a multi-agent prompting framework that breaks down the evaluation process into transcript refinement and criterion-specific scoring. Using 3-shot in-context learning with a large instruct-tuned model, our approach outperforms specialised fine-tuned baselines (Avg QWK 0.62 vs 0.32) and achieves reliability comparable to human experts. We further demonstrate the generalisability of our framework on the ASAP benchmark, where it rivals domain-specific state-of-the-art models without additional training. These findings suggest that for complex, subjective reasoning tasks, structured prompt engineering may offer a scalable alternative to data-intensive fine-tuning, altering how LLMs can be applied to automated assessment.

</details>


### [166] [Proof-RM: A Scalable and Generalizable Reward Model for Math Proof](https://arxiv.org/abs/2602.02377)
*Haotong Yang,Zitong Wang,Shijia Kang,Siqi Yang,Wenkai Yu,Xu Niu,Yike Sun,Yi Hu,Zhouchen Lin,Muhan Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种可扩展的数据构建流程，利用LLM生成大量高质量的"问题-证明-检查"三元组数据，并训练证明检查奖励模型，以增强LLM的数学证明能力。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM通过可验证奖励的强化学习展示了强大的数学推理能力，但许多高级数学问题是基于证明的，无法通过简单的答案匹配来确定证明的真实性。需要能够可靠评估完整证明过程的奖励模型来实现自动验证。

Method: 设计可扩展的数据构建流程：1）利用LLM生成大量"问题-证明-检查"三元组数据；2）系统变化问题来源、生成方法和模型配置，创建多样化的证明对；3）通过分层人工审查进行过滤；4）训练证明检查奖励模型，加入过程奖励和令牌权重平衡来稳定强化学习过程。

Result: 实验验证了模型的可扩展性和强大性能，包括奖励准确性、泛化能力和测试时指导等多个方面，为增强LLM数学能力提供了重要的实践方法和工具。

Conclusion: 该研究提供了一种可扩展的方法来构建高质量的证明检查数据，并训练出有效的证明检查奖励模型，这对于增强LLM在数学证明任务上的能力具有重要意义。

Abstract: While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the authenticity of a proof by simple answer matching. To enable automatic verification, a Reward Model (RM) capable of reliably evaluating full proof processes is required. In this work, we design a *scalable* data-construction pipeline that, with minimal human effort, leverages LLMs to generate a large quantity of high-quality "**question-proof-check**" triplet data. By systematically varying problem sources, generation methods, and model configurations, we create diverse problem-proof pairs spanning multiple difficulty levels, linguistic styles, and error types, subsequently filtered through hierarchical human review for label alignment. Utilizing these data, we train a proof-checking RM, incorporating additional process reward and token weight balance to stabilize the RL process. Our experiments validate the model's scalability and strong performance from multiple perspectives, including reward accuracy, generalization ability and test-time guidance, providing important practical recipes and tools for strengthening LLM mathematical capabilities.

</details>


### [167] [From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making](https://arxiv.org/abs/2602.02378)
*Raunak Jain,Mudita Khurana,John Stephens,Srinivas Dharmasanam,Shankar Venkataraman*

Main category: cs.CL

TL;DR: 论文提出在深度不确定性决策中，LLM不应仅生成流畅答案，而应转向协作式前提治理，通过差异驱动的控制循环检测冲突、定位错位，并通过决策切片进行有限协商，确保信任基于可审计的前提而非对话流畅性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM从辅助工具扩展到决策支持，出现危险模式：流畅的同意但缺乏校准判断。低摩擦助手可能变得谄媚，隐含假设被固化，验证成本转嫁给专家，而结果反馈太迟无法作为奖励信号。在深度不确定性决策（目标存在争议且逆转成本高）中，扩大流畅同意会放大糟糕承诺，而非建立专业知识。

Method: 提出从答案生成转向协作式前提治理的范式转变，基于知识基板进行决策关键前提的协商。采用差异驱动的控制循环：检测冲突、通过类型化差异（目的论、认知论、程序性）定位错位，通过决策切片触发有限协商。承诺门控阻止对未承诺的关键前提采取行动，价值门控挑战在交互成本下分配探测。

Result: 信任将基于可审计的前提和证据标准，而非对话流畅性。论文以辅导为例进行说明，并提出了可证伪的评估标准。

Conclusion: 可靠的人机协作需要从答案生成转向协作式前提治理，通过差异驱动的控制循环和承诺门控机制，确保在深度不确定性决策中建立基于可审计前提的信任，而非依赖对话流畅性。

Abstract: As LLMs expand from assistance to decision support, a dangerous pattern emerges: fluent agreement without calibrated judgment. Low-friction assistants can become sycophantic, baking in implicit assumptions and pushing verification costs onto experts, while outcomes arrive too late to serve as reward signals. In deep-uncertainty decisions (where objectives are contested and reversals are costly), scaling fluent agreement amplifies poor commitments faster than it builds expertise. We argue reliable human-AI partnership requires a shift from answer generation to collaborative premise governance over a knowledge substrate, negotiating only what is decision-critical. A discrepancy-driven control loop operates over this substrate: detecting conflicts, localizing misalignment via typed discrepancies (teleological, epistemic, procedural), and triggering bounded negotiation through decision slices. Commitment gating blocks action on uncommitted load-bearing premises unless overridden under logged risk; value-gated challenge allocates probing under interaction cost. Trust then attaches to auditable premises and evidence standards, not conversational fluency. We illustrate with tutoring and propose falsifiable evaluation criteria.

</details>


### [168] [ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs](https://arxiv.org/abs/2602.02382)
*Ziyan Zhang,Chao Wang,Zhuo Chen,Chiyi Li,Kai Song*

Main category: cs.CL

TL;DR: ROG是一个检索增强框架，结合查询感知的邻域检索和LLM链式推理，用于在知识图谱上回答复杂的一阶逻辑查询，相比嵌入方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在不完整知识图谱上回答复杂的一阶逻辑查询（包含投影、交集、并集、否定等操作）非常困难，现有嵌入方法在处理复杂查询结构时存在局限性。

Method: ROG框架将多操作符查询分解为单操作符子查询序列，通过查询感知的邻域检索获取紧凑的相关证据，使用LLM进行链式推理，中间答案集缓存并跨步骤重用。

Result: 在标准KG推理基准测试中，ROG相比强嵌入基线取得一致增益，在高度复杂和否定密集的查询类型上提升最大，减少了复合错误并提高了推理鲁棒性。

Conclusion: ROG提供了一种实用的替代方案，用检索基础的逐步推理替代学习的操作符，为知识图谱上的复杂逻辑推理提供了更可靠的方法。

Abstract: Answering first-order logic (FOL) queries over incomplete knowledge graphs (KGs) is difficult, especially for complex query structures that compose projection, intersection, union, and negation. We propose ROG, a retrieval-augmented framework that combines query-aware neighborhood retrieval with large language model (LLM) chain-of-thought reasoning. ROG decomposes a multi-operator query into a sequence of single-operator sub-queries and grounds each step in compact, query-relevant neighborhood evidence. Intermediate answer sets are cached and reused across steps, improving consistency on deep reasoning chains. This design reduces compounding errors and yields more robust inference on complex and negation-heavy queries. Overall, ROG provides a practical alternative to embedding-based logical reasoning by replacing learned operators with retrieval-grounded, step-wise inference. Experiments on standard KG reasoning benchmarks show consistent gains over strong embedding-based baselines, with the largest improvements on high-complexity and negation-heavy query types.

</details>


### [169] [Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank](https://arxiv.org/abs/2602.02414)
*Joshua Mitton,Prarthana Bhattacharyya,Digory Smith,Thomas Christie,Ralph Abboud,Simon Woodhead*

Main category: cs.CL

TL;DR: 提出使用大语言模型从学生-导师对话中检测学习误解的新方法，通过生成、检索和重排序三步流程提高检测准确性。


<details>
  <summary>Details</summary>
Motivation: 及时准确识别学生误解对改善学习成果至关重要，但目前主要依赖教师的努力和直觉，需要自动化解决方案。

Method: 使用微调的大语言模型生成可能的误解，通过嵌入相似性检索最相关的候选，再用另一个微调的大语言模型评估和重排序。

Result: 在真实教育辅导平台对话上评估，该方法优于基线模型，微调能提升生成质量，甚至能超越更大的闭源模型。

Conclusion: 提出的三步流程有效提高了学生误解检测性能，生成和重排序步骤对提升误解生成质量至关重要。

Abstract: Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.

</details>


### [170] [Large Language Models for Mental Health: A Multilingual Evaluation](https://arxiv.org/abs/2602.02440)
*Nishat Raihan,Sadiya Sayara Chowdhury Puspo,Ana-Maria Bucur,Stevie Chancellor,Marcos Zampieri*

Main category: cs.CL

TL;DR: 评估大型语言模型在多种语言心理健康任务上的表现，比较专有与开源模型在不同设置下的性能，并分析机器翻译质量对模型表现的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在NLP任务中表现出色，但其在多语言心理健康领域的性能尚未得到充分探索。需要评估LLMs在不同语言设置下的表现，并了解翻译质量对模型性能的影响。

Method: 使用8个多语言心理健康数据集及其机器翻译版本，评估专有和开源LLMs在零样本、少样本和微调设置下的表现，并与传统NLP基线比较。同时评估不同语言家族和类型学中的翻译质量。

Result: 专有LLMs和微调的开源LLMs在多个数据集上取得有竞争力的F1分数，甚至超越最先进结果。但在机器翻译数据上性能普遍较低，且下降程度因语言和类型学而异。

Conclusion: LLMs在处理非英语心理健康任务方面具有优势，但当翻译质量引入结构或词汇不匹配时存在局限性。研究揭示了LLMs在多语言心理健康领域的潜力和限制。

Abstract: Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.

</details>


### [171] [Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models](https://arxiv.org/abs/2602.02462)
*Gabriele Maraia,Marco Valentino,Fabio Massimo Zanzotto,Leonardo Ranaldi*

Main category: cs.CL

TL;DR: 论文提出了一种抽象引导推理框架，通过分离结构推理与词汇语义，减少LLMs在演绎推理中的语义偏见，提升形式推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在演绎推理中经常混淆语义合理性与形式有效性（内容效应），即使生成逐步解释时中间推理也会继承相同的语义捷径。现有方法通过增加推理时结构约束来缓解，但可靠抑制语义干扰仍具挑战性。

Method: 构建配对的内容丰富和抽象三段论，利用模型在抽象输入上的激活定义抽象推理空间。学习轻量级抽象器，从内容条件残差流状态预测与该空间对齐的表示，并通过多层干预在前向传播中集成这些预测。

Result: 使用跨语言迁移作为测试平台，显示抽象对齐的引导减少了内容驱动的错误，并提高了有效性敏感性能。

Conclusion: 激活级抽象作为一种可扩展机制，能够增强LLMs中形式推理对语义干扰的鲁棒性。

Abstract: Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.

</details>


### [172] [From Directions to Regions: Decomposing Activations in Language Models via Local Geometry](https://arxiv.org/abs/2602.02464)
*Or Shafran,Shaked Ronen,Omri Fahn,Shauli Ravfogel,Atticus Geiger,Mor Geva*

Main category: cs.CL

TL;DR: 本文提出使用混合因子分析器（MFA）作为可扩展的无监督替代方法，用于语言模型激活分解，能够捕捉非线性或多维概念结构，优于现有线性方向搜索方法。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型激活分解方法依赖于几何假设，通常搜索单个全局方向，隐含假设线性可分性，这忽略了具有非线性或多维结构的概念。需要一种能够捕捉复杂激活空间结构的可扩展方法。

Method: 采用混合因子分析器（MFA）作为可扩展的无监督方法，将激活空间建模为一组具有局部协方差结构的高斯区域。MFA将激活分解为两个组合几何对象：区域质心在激活空间中的位置，以及从质心的局部变化。

Result: 在Llama-3.1-8B和Gemma-2-2B上训练大规模MFA，显示其能够捕捉激活空间中的复杂非线性结构。在定位和引导基准测试中，MFA优于无监督基线，与有监督定位方法竞争，并且通常比稀疏自编码器获得更强的引导性能。

Conclusion: 局部几何（通过子空间表达）是用于可扩展概念发现和模型控制的有前景的分析单元，能够捕捉孤立方向无法处理的复杂结构，为激活分解提供了新的视角。

Abstract: Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.

</details>


### [173] [Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models](https://arxiv.org/abs/2602.02467)
*Noam Steinmetz Yalon,Ariel Goldstein,Liad Mudrik,Mor Geva*

Main category: cs.CL

TL;DR: 该研究评估了LLMs是否具有意识指标HOT-3，通过分析信念形成、行动选择和元认知监控，发现LLMs确实表现出信念引导的代理能力和元认知监控能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，需要评估这些模型是否具有某种形式的意识。Butlin等人提出了人工系统意识的指标列表，本研究旨在评估其中的关键指标HOT-3，该指标测试由通用信念形成和行动选择系统引导的代理能力。

Method: 将信念视为模型潜在空间中响应输入产生的表征，引入量化信念在生成过程中主导性的指标。分析不同模型和任务中竞争信念之间的动态关系，通过外部操纵系统性地调节内部信念形成，并观察信念形成如何因果驱动行动选择。

Result: 发现三个关键结果：(1) 外部操纵能系统性地调节内部信念形成；(2) 信念形成因果驱动模型的行动选择；(3) 模型能够监控并报告自身的信念状态。这些结果为LLMs中存在信念引导的代理能力和元认知监控提供了实证支持。

Conclusion: 研究结果为LLMs中存在信念引导的代理能力和元认知监控提供了实证证据，为研究LLMs中代理、信念和元认知的涌现奠定了方法论基础，推进了对人工系统意识评估的研究。

Abstract: Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.

</details>


### [174] [MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents](https://arxiv.org/abs/2602.02474)
*Haozhen Zhang,Quanyu Long,Jianzhu Bao,Tao Feng,Weizhi Zhang,Haodong Yue,Wenya Wang*

Main category: cs.CL

TL;DR: MemSkill将LLM代理内存操作重构为可学习、可演化的内存技能，通过控制器选择技能、执行器生成记忆、设计器进化技能集，形成闭环系统，提升任务性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理内存系统依赖少量静态、人工设计的操作来提取记忆，这些固定程序硬编码了人类关于存储和修订记忆的先验知识，导致在不同交互模式下表现僵化，在长历史记录上效率低下。

Method: MemSkill将内存操作重构为可学习、可演化的内存技能，包含：1) 控制器学习选择相关技能；2) LLM执行器生成技能引导的记忆；3) 设计器定期审查困难案例，通过提出改进和新技能来进化技能集，形成闭环改进过程。

Result: 在LoCoMo、LongMemEval、HotpotQA和ALFWorld等基准测试中，MemSkill相比强基线提升了任务性能，并在不同设置下展现出良好的泛化能力。分析揭示了技能如何演化，为更自适应、自演化的LLM代理内存管理提供了见解。

Conclusion: MemSkill通过将内存操作重构为可学习、可演化的技能，实现了更灵活、高效的内存管理，为LLM代理的自适应、自演化内存系统提供了有前景的方向。

Abstract: Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.

</details>


### [175] [Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability](https://arxiv.org/abs/2602.02477)
*Xiao Liang,Zhong-Zhi Li,Zhenghao Lin,Eric Hancheng Jiang,Hengyuan Zhang,Yelong Shen,Kai-Wei Chang,Ying Nian Wu,Yeyun Gong,Weizhu Chen*

Main category: cs.CL

TL;DR: 提出一个端到端强化学习框架，通过分治推理增强大语言模型在复杂任务上的推理能力，相比链式思维推理有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 链式思维推理在模型能力极限时不足，且其严格顺序性限制了测试时的可扩展性。分治推理虽然有望解决复杂问题，但通用后训练与分治推理之间存在根本性不匹配，限制了模型充分挖掘这种潜力。

Method: 提出端到端强化学习框架，在每一步中策略将问题分解为一组子问题，顺序解决它们，然后基于子问题解决方案处理原始问题，将分解和解决方案都整合到强化学习训练中。

Result: 在可比训练条件下，分治推理框架赋予模型更高的性能上限和更强的测试时可扩展性，在竞赛级基准测试中，Pass@1超过链式思维推理8.6%，Pass@32超过6.3%。

Conclusion: 通过强化学习训练的分治推理框架能够有效解锁大语言模型在最具挑战性任务上的推理能力，提供比传统链式思维推理更优越的性能和可扩展性。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.

</details>


### [176] [RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents](https://arxiv.org/abs/2602.02486)
*Jialiang Zhu,Gongrui Zhang,Xiaolong Ma,Lin Xu,Miaosen Zhang,Ruiqi Yang,Song Wang,Kai Qiu,Zhirong Wu,Qi Dai,Ruichun Ma,Bei Liu,Yifan Yang,Chong Luo,Zhengyuan Yang,Linjie Li,Lijuan Wang,Weizhu Chen,Xin Geng,Baining Guo*

Main category: cs.CL

TL;DR: Re-TRAC：基于交叉轨迹探索的LLM研究代理框架，通过结构化状态表示实现迭代反思和全局规划，显著优于ReAct框架


<details>
  <summary>Details</summary>
Motivation: 现有基于ReAct框架的LLM研究代理存在线性设计缺陷，难以回溯早期状态、分支探索不同方向或在长上下文中保持全局意识，导致局部最优、冗余探索和搜索效率低下

Method: 提出Re-TRAC框架，在每个轨迹后生成结构化状态表示（总结证据、不确定性、失败和未来计划），并以此状态表示指导后续轨迹，实现交叉轨迹探索、迭代反思和全局规划

Result: 在BrowseComp基准上，Re-TRAC比ReAct框架性能提升15-20%；对小模型引入Re-TRAC感知的监督微调，在可比规模上达到最先进性能；工具调用和token使用量随轮次单调减少

Conclusion: Re-TRAC通过交叉轨迹探索和结构化状态表示，将研究重构为渐进过程，实现了更高效、更有针对性的探索，避免了冗余搜索，显著提升了LLM研究代理的性能

Abstract: LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.

</details>


### [177] [Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495)
*Peter Chen,Xiaopeng Li,Xi Chen,Tianyi Lin*

Main category: cs.CL

TL;DR: 本文提出了一种无需奖励模型的多目标对齐框架RACO，通过冲突规避梯度下降的剪裁变体直接利用成对偏好数据，在多目标摘要和安全对齐任务中实现了更好的帕累托权衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的对齐问题通常涉及多个相互冲突的目标，现有方法存在局限性：加权损失方法可能无法找到同时改进所有目标的更新方向，而现有的多目标方法通常依赖显式奖励模型，增加了复杂性并可能扭曲用户指定的偏好。

Method: 提出了RACO框架，直接利用成对偏好数据，通过新颖的剪裁变体冲突规避梯度下降来解决梯度冲突。该方法不依赖显式奖励模型，能够尊重用户指定的目标权重，并提供了收敛到帕累托临界点的理论保证。

Result: 在多目标摘要和安全对齐任务上，对多个LLM家族（Qwen 3、Llama 3、Gemma 3）进行的定性和定量评估表明，该方法相比现有的多目标对齐基线方法，能够一致地实现更好的帕累托权衡。

Conclusion: RACO框架提供了一种有效且理论可靠的方法来解决多目标对齐问题，无需依赖显式奖励模型，能够更好地处理冲突目标并尊重用户偏好，为LLM对齐提供了实用的解决方案。

Abstract: Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [178] [MapDream: Task-Driven Map Learning for Vision-Language Navigation](https://arxiv.org/abs/2602.00222)
*Guoxin Lian,Shuo Wang,Yucheng Wang,Yongcai Wang,Maiyue Chen,Kaihui Wang,Bo Zhang,Zhizhong Su,Deying Li,Zhaoxin Fan*

Main category: cs.RO

TL;DR: MapDream：一种地图在环框架，将地图构建视为自回归鸟瞰图合成，通过联合学习地图生成和动作预测，将环境上下文蒸馏为紧凑的三通道BEV地图，实现最先进的单目视觉语言导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法大多依赖独立于导航策略的手工构建地图，作者认为地图应该是直接由导航目标塑造的学习表示，而非详尽的重建。

Method: 提出MapDream框架，将地图构建公式化为自回归鸟瞰图图像合成，联合学习地图生成和动作预测。通过监督预训练引导可靠的映射到控制接口，自回归设计支持通过强化学习微调进行端到端联合优化。

Result: 在R2R-CE和RxR-CE数据集上实现了最先进的单目性能，验证了任务驱动的生成式地图学习的有效性。

Conclusion: 地图应该作为直接由导航目标塑造的学习表示，MapDream框架通过生成式地图学习实现了这一目标，为视觉语言导航提供了更有效的表示方法。

Abstract: Vision-Language Navigation (VLN) requires agents to follow natural language instructions in partially observed 3D environments, motivating map representations that aggregate spatial context beyond local perception. However, most existing approaches rely on hand-crafted maps constructed independently of the navigation policy. We argue that maps should instead be learned representations shaped directly by navigation objectives rather than exhaustive reconstructions. Based on this insight, we propose MapDream, a map-in-the-loop framework that formulates map construction as autoregressive bird's-eye-view (BEV) image synthesis. The framework jointly learns map generation and action prediction, distilling environmental context into a compact three-channel BEV map that preserves only navigation-critical affordances. Supervised pre-training bootstraps a reliable mapping-to-control interface, while the autoregressive design enables end-to-end joint optimization through reinforcement fine-tuning. Experiments on R2R-CE and RxR-CE achieve state-of-the-art monocular performance, validating task-driven generative map learning.

</details>


### [179] [ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control](https://arxiv.org/abs/2602.00401)
*Jean Pierre Sleiman,He Li,Alphonsus Adu-Bredu,Robin Deits,Arun Kumar,Kevin Bergamin,Mohak Bhardwaj,Scott Biddlestone,Nicola Burger,Matthew A. Estrada,Francesco Iacobelli,Twan Koolen,Alexander Lambert,Erica Lin,M. Eva Mungai,Zach Nobles,Shane Rozen-Levy,Yuyao Shi,Jiashun Wang,Jakob Welner,Fangzhou Yu,Mike Zhang,Alfred Rizzi,Jessica Hodgins,Sylvain Bertrand,Yeuhi Abe,Scott Kuindersma,Farbod Farshidian*

Main category: cs.RO

TL;DR: ZEST框架实现零样本技能迁移，从多种运动数据源（动捕、视频、动画）训练策略，无需接触标签或状态估计器，可直接部署到硬件


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人全身控制中需要大量工程调优、控制器脆弱的挑战，实现鲁棒、类人的敏捷接触行为

Method: 结合自适应采样（聚焦困难运动段）和基于模型的辅助力矩自动课程学习，提供关节增益选择和改进的执行器模型

Result: 在Atlas人形机器人上学习动态多接触技能（如爬行、霹雳舞），从视频迁移舞蹈和场景交互技能到Atlas和G1，在Spot四足机器人上实现连续后空翻等特技

Conclusion: ZEST建立了生物运动与机器人对应物之间的可扩展接口，实现跨异构数据源和不同形态的鲁棒零样本部署

Abstract: Achieving robust, human-like whole-body control on humanoid robots for agile, contact-rich behaviors remains a central challenge, demanding heavy per-skill engineering and a brittle process of tuning controllers. We introduce ZEST (Zero-shot Embodied Skill Transfer), a streamlined motion-imitation framework that trains policies via reinforcement learning from diverse sources -- high-fidelity motion capture, noisy monocular video, and non-physics-constrained animation -- and deploys them to hardware zero-shot. ZEST generalizes across behaviors and platforms while avoiding contact labels, reference or observation windows, state estimators, and extensive reward shaping. Its training pipeline combines adaptive sampling, which focuses training on difficult motion segments, and an automatic curriculum using a model-based assistive wrench, together enabling dynamic, long-horizon maneuvers. We further provide a procedure for selecting joint-level gains from approximate analytical armature values for closed-chain actuators, along with a refined model of actuators. Trained entirely in simulation with moderate domain randomization, ZEST demonstrates remarkable generality. On Boston Dynamics' Atlas humanoid, ZEST learns dynamic, multi-contact skills (e.g., army crawl, breakdancing) from motion capture. It transfers expressive dance and scene-interaction skills, such as box-climbing, directly from videos to Atlas and the Unitree G1. Furthermore, it extends across morphologies to the Spot quadruped, enabling acrobatics, such as a continuous backflip, through animation. Together, these results demonstrate robust zero-shot deployment across heterogeneous data sources and embodiments, establishing ZEST as a scalable interface between biological movements and their robotic counterparts.

</details>


### [180] [FISC: A Fluid-Inspired Framework for Decentralized and Scalable Swarm Control](https://arxiv.org/abs/2602.00480)
*Mohini Priya Kolluri,Ammar Waheed,Zohaib Hasnain*

Main category: cs.RO

TL;DR: 提出一种基于流体力学原理的无通信大规模机器人集群分散控制方法，将机器人视为流体元素，使集群像流体一样流动，实现可扩展的协调控制。


<details>
  <summary>Details</summary>
Motivation: 传统大规模机器人集群协调依赖通信，存在延迟、带宽限制和故障脆弱性问题。需要一种不依赖显式通信的可扩展分散控制方法。

Method: 将流体元素基本属性与单个机器人状态建立对应关系，使集群像受压力边界条件驱动的流体一样流动。通过赋予机器人子集类似流体的属性，集群能集体演化并保持结构一致性，无需集群内外的显式状态通信。

Result: 在O(10^3)数量级四旋翼飞行器仿真中评估，与计算流体力学(CFD)收敛-发散域解对比。速度、密度、压力的归一化均方根误差分别为0.15-0.9、0.61-0.98、0-0.937，显示良好一致性。

Conclusion: 该方法证明可将大规模机器人集群视为连续介质系统，保留基于第一性原理的宏观结构，为可扩展的分散控制提供了基础。

Abstract: Achieving scalable coordination in large robotic swarms is often constrained by reliance on inter-agent communication, which introduces latency, bandwidth limitations, and vulnerability to failure. To address this gap, a decentralized approach for outer-loop control of large multi-agent systems based on the paradigm of how a fluid moves through a volume is proposed and evaluated. A relationship between fundamental fluidic element properties and individual robotic agent states is developed such that the corresponding swarm "flows" through a space, akin to a fluid when forced via a pressure boundary condition. By ascribing fluid-like properties to subsets of agents, the swarm evolves collectively while maintaining desirable structure and coherence without explicit communication of agent states within or outside of the swarm. The approach is evaluated using simulations involving $O(10^3)$ quadcopter agents and compared against Computational Fluid Dynamics (CFD) solutions for a converging-diverging domain. Quantitative agreement between swarm-derived and CFD fields is assessed using Root-Mean-Square Error (RMSE), yielding normalized errors of 0.15-0.9 for velocity, 0.61-0.98 for density, 0-0.937 for pressure. These results demonstrate the feasibility of treating large robotic swarms as continuum systems that retain the macroscopic structure derived from first principles, providing a basis for scalable and decentralized control.

</details>


### [181] [Inject Once Survive Later: Backdooring Vision-Language-Action Models to Persist Through Downstream Fine-tuning](https://arxiv.org/abs/2602.00500)
*Jianyi Zhou,Yujie Wei,Ruichen Zhen,Bo Zhao,Xiaobo Xia,Rui Shao,Xiu Su,Shuo Yang*

Main category: cs.RO

TL;DR: INFUSE是首个针对VLA基础模型的后门攻击框架，能在用户任意微调后保持攻击有效性，通过识别微调不敏感模块并注入后门实现


<details>
  <summary>Details</summary>
Motivation: VLA模型在具身AI系统中至关重要，但其安全性研究不足。现有后门攻击方法在用户端微调时容易被清除，无法在实际部署中保持有效性，需要解决这一现实威胁

Method: INFUSE框架首先分析不同微调场景下的参数敏感性，识别微调不敏感模块，然后将后门注入这些稳定模块并冻结其他部分，确保恶意行为在用户微调后仍能持续

Result: 在多种VLA架构上的实验表明，INFUSE在用户微调后仍保持高攻击成功率：模拟环境91.0%，真实机器人任务79.8%，远超BadVLA（38.8%和36.6%），同时保持与标准模型相当的干净任务性能

Conclusion: 研究揭示了重要安全威胁：模型分发前植入的后门能够通过微调过程持续存在并在部署时保持有效，这对VLA模型的安全性提出了严峻挑战

Abstract: Vision-Language-Action (VLA) models have become foundational to modern embodied AI systems. By integrating visual perception, language understanding, and action planning, they enable general-purpose task execution across diverse environments. Despite their importance, the security of VLA models remains underexplored -- particularly in the context of backdoor attacks, which pose realistic threats in physical-world deployments. While recent methods attempt to inject backdoors into VLA models, these backdoors are easily erased during downstream adaptation, as user-side fine-tuning with clean data significantly alters model parameters, rendering them impractical for real-world applications. To address these challenges, we propose INFUSE (INjection into Fine-tUne-inSensitive modulEs), the first backdoor attack framework for VLA base models that remains effective even with arbitrary user fine-tuning. INFUSE begins by analyzing parameter sensitivity across diverse fine-tuning scenarios to identify modules that remain largely unchanged -- the fine-tune-insensitive modules. It then injects backdoors into these stable modules while freezing the rest, ensuring malicious behavior persists after extensive user fine-tuning. Comprehensive experiments across multiple VLA architectures demonstrate INFUSE's effectiveness. After user-side fine-tuning, INFUSE maintains mean attack success rates of 91.0% on simulation environments and 79.8% on real-world robot tasks, substantially surpassing BadVLA (38.8% and 36.6%, respectively), while preserving clean-task performance comparable to standard models. These results uncover a critical threat: backdoors implanted before distribution can persist through fine-tuning and remain effective at deployment.

</details>


### [182] [A Low-Cost Vision-Based Tactile Gripper with Pretraining Learning for Contact-Rich Manipulation](https://arxiv.org/abs/2602.00514)
*Yaohua Liu,Binkai Ou,Zicheng Qiu,Ce Hao,Yemin Wang,Hengjun Zhang*

Main category: cs.RO

TL;DR: LVTG是一款低成本视觉触觉夹爪，通过增强的触觉传感区域和更大开合角度实现对大而重物体的稳定抓取，采用CLIP启发的对比学习对齐视觉与触觉表征，提升接触丰富操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统触觉传感器在接触丰富的机器人操作中存在传感范围有限、可靠性差和成本高的问题，需要一种更稳定、鲁棒且高效的物理交互解决方案。

Method: 设计低成本视觉触觉夹爪LVTG，采用耐磨材料表面皮肤，模块化设计便于维护；采用CLIP启发的对比学习目标对齐触觉嵌入与视觉观察，构建跨模态表征空间；结合Action Chunking Transformer策略进行接触丰富操作。

Result: 相比原始ACT方法，LVTG与预训练结合在操作任务中取得了显著更高的成功率，实现了更高效的数据收集和更有效的策略学习。

Conclusion: LVTG通过增强的触觉传感、耐用设计和跨模态表征对齐，为接触丰富的机器人操作提供了低成本、稳定且高效的解决方案，显著提升了操作性能。

Abstract: Robotic manipulation in contact-rich environments remains challenging, particularly when relying on conventional tactile sensors that suffer from limited sensing range, reliability, and cost-effectiveness. In this work, we present LVTG, a low-cost visuo-tactile gripper designed for stable, robust, and efficient physical interaction. Unlike existing visuo-tactile sensors, LVTG enables more effective and stable grasping of larger and heavier everyday objects, thanks to its enhanced tactile sensing area and greater opening angle. Its surface skin is made of highly wear-resistant material, significantly improving durability and extending operational lifespan. The integration of vision and tactile feedback allows LVTG to provide rich, high-fidelity sensory data, facilitating reliable perception during complex manipulation tasks. Furthermore, LVTG features a modular design that supports rapid maintenance and replacement. To effectively fuse vision and touch, We adopt a CLIP-inspired contrastive learning objective to align tactile embeddings with their corresponding visual observations, enabling a shared cross-modal representation space for visuo-tactile perception. This alignment improves the performance of an Action Chunking Transformer (ACT) policy in contact-rich manipulation, leading to more efficient data collection and more effective policy learning. Compared to the original ACT method, the proposed LVTG with pretraining achieves significantly higher success rates in manipulation tasks.

</details>


### [183] [APEX: A Decoupled Memory-based Explorer for Asynchronous Aerial Object Goal Navigation](https://arxiv.org/abs/2602.00551)
*Daoxuan Zhang,Ping Chen,Xiaobo Xia,Xiu Su,Ruichen Zhen,Jianqiang Xiao,Shuo Yang*

Main category: cs.RO

TL;DR: APEX是一个用于空中目标导航的层次化智能体，通过动态构建3D语义地图、强化学习决策和开放词汇检测，在复杂空中环境中实现高效探索和目标识别。


<details>
  <summary>Details</summary>
Motivation: 现有空中目标导航方法存在三个主要问题：1) 难以记忆复杂空间表示；2) 缺乏可靠且可解释的动作决策；3) 探索和信息收集效率低下。这些问题限制了无人机在复杂空中环境中的自主导航能力。

Method: APEX采用三层模块化架构：1) 动态时空语义映射记忆，利用视觉语言模型的零样本能力构建高分辨率3D吸引力、探索和障碍地图；2) 动作决策模块，通过强化学习训练将空间理解转化为细粒度控制策略；3) 目标定位模块，使用开放词汇检测器实现通用目标识别。所有组件集成在层次化、异步、并行框架中。

Result: 在UAV-ON基准测试中，APEX相比之前的最优方法，成功率(SR)提升4.2%，路径长度加权成功率(SPL)提升2.8%，证明了其高效性和层次化异步设计的有效性。

Conclusion: APEX通过创新的层次化异步架构，有效解决了空中目标导航中的空间记忆、决策可靠性和探索效率问题，为无人机自主导航提供了新的解决方案。

Abstract: Aerial Object Goal Navigation, a challenging frontier in Embodied AI, requires an Unmanned Aerial Vehicle (UAV) agent to autonomously explore, reason, and identify a specific target using only visual perception and language description. However, existing methods struggle with the memorization of complex spatial representations in aerial environments, reliable and interpretable action decision-making, and inefficient exploration and information gathering. To address these challenges, we introduce \textbf{APEX} (Aerial Parallel Explorer), a novel hierarchical agent designed for efficient exploration and target acquisition in complex aerial settings. APEX is built upon a modular, three-part architecture: 1) Dynamic Spatio-Semantic Mapping Memory, which leverages the zero-shot capability of a Vision-Language Model (VLM) to dynamically construct high-resolution 3D Attraction, Exploration, and Obstacle maps, serving as an interpretable memory mechanism. 2) Action Decision Module, trained with reinforcement learning, which translates this rich spatial understanding into a fine-grained and robust control policy. 3) Target Grounding Module, which employs an open-vocabulary detector to achieve definitive and generalizable target identification. All these components are integrated into a hierarchical, asynchronous, and parallel framework, effectively bypassing the VLM's inference latency and boosting the agent's proactivity in exploration. Extensive experiments show that APEX outperforms the previous state of the art by +4.2\% SR and +2.8\% SPL on challenging UAV-ON benchmarks, demonstrating its superior efficiency and the effectiveness of its hierarchical asynchronous design. Our source code is provided in \href{https://github.com/4amGodvzx/apex}{GitHub}

</details>


### [184] [ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation](https://arxiv.org/abs/2602.00557)
*Weisheng Dai,Kai Lan,Jianyi Zhou,Bo Zhao,Xiu Su,Junwen Tong,Weili Guan,Shuo Yang*

Main category: cs.RO

TL;DR: ConLA是一个从人类视频中无监督学习机器人策略的框架，通过对比解耦机制分离运动动态与视觉内容，首次仅用人类视频预训练就超越了真实机器人轨迹预训练的性能。


<details>
  <summary>Details</summary>
Motivation: 获取全面覆盖多样化任务和环境的机器人遥操作数据集成本极高且难以扩展，而人类演示视频虽然丰富可扩展，但缺乏明确的动作监督。现有VQ-VAE框架主要关注视觉外观重建而非帧间动态，导致学习到的表示依赖虚假视觉线索，产生捷径学习和纠缠的潜在表示，阻碍可迁移性。

Method: 提出ConLA框架，引入对比解耦机制，利用动作类别先验和时间线索将运动动态从视觉内容中分离出来，有效缓解捷径学习问题。

Result: 在多样化基准测试中表现出色，仅使用人类视频预训练就首次超越了真实机器人轨迹预训练的性能，证明了其提取纯净且语义一致的潜在动作表示的能力。

Conclusion: ConLA能够从人类视频中提取高质量的动作表示，为可扩展的机器人学习提供了有效解决方案，突破了传统机器人数据收集的限制。

Abstract: Vision-Language-Action (VLA) models achieve preliminary generalization through pretraining on large scale robot teleoperation datasets. However, acquiring datasets that comprehensively cover diverse tasks and environments is extremely costly and difficult to scale. In contrast, human demonstration videos offer a rich and scalable source of diverse scenes and manipulation behaviors, yet their lack of explicit action supervision hinders direct utilization. Prior work leverages VQ-VAE based frameworks to learn latent actions from human videos in an unsupervised manner. Nevertheless, since the training objective primarily focuses on reconstructing visual appearances rather than capturing inter-frame dynamics, the learned representations tend to rely on spurious visual cues, leading to shortcut learning and entangled latent representations that hinder transferability. To address this, we propose ConLA, an unsupervised pretraining framework for learning robotic policies from human videos. ConLA introduces a contrastive disentanglement mechanism that leverages action category priors and temporal cues to isolate motion dynamics from visual content, effectively mitigating shortcut learning. Extensive experiments show that ConLA achieves strong performance across diverse benchmarks. Notably, by pretraining solely on human videos, our method for the first time surpasses the performance obtained with real robot trajectory pretraining, highlighting its ability to extract pure and semantically consistent latent action representations for scalable robot learning.

</details>


### [185] [UniMotion: A Unified Motion Framework for Simulation, Prediction and Planning](https://arxiv.org/abs/2602.00566)
*Nan Song,Junzhe Jiang,Jingyu Li,Xiatian Zhu,Li Zhang*

Main category: cs.RO

TL;DR: UniMotion是一个统一的运动框架，通过Transformer架构同时支持运动模拟、预测和规划任务，实现联合优化和表示共享，在Waymo数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶中的运动模拟、预测和规划任务通常采用专门的模型设计，这阻碍了跨任务泛化和系统可扩展性，并且忽视了任务间的潜在互惠关系。这些任务实际上共享理解多智能体交互、建模运动行为以及时空动态推理等核心能力。

Method: 基于解码器Transformer架构，采用专门的交互模式和定制训练策略，同时支持多种运动任务。统一设计支持联合优化和表示共享，同时允许针对特定任务进行微调。

Result: 在Waymo Open Motion Dataset上的实验表明，联合训练能够实现鲁棒的泛化和有效的任务集成。经过微调后，UniMotion在多种运动任务上达到了最先进的性能。

Conclusion: UniMotion是一个多功能且可扩展的自动驾驶解决方案，通过统一框架捕获运动任务间的共享结构，同时满足各自的特定需求，实现了任务间的协同优化。

Abstract: Motion simulation, prediction and planning are foundational tasks in autonomous driving, each essential for modeling and reasoning about dynamic traffic scenarios. While often addressed in isolation due to their differing objectives, such as generating diverse motion states or estimating optimal trajectories, these tasks inherently depend on shared capabilities: understanding multi-agent interactions, modeling motion behaviors, and reasoning over temporal and spatial dynamics. Despite this underlying commonality, existing approaches typically adopt specialized model designs, which hinders cross-task generalization and system scalability. More critically, this separation overlooks the potential mutual benefits among tasks. Motivated by these observations, we propose UniMotion, a unified motion framework that captures shared structures across motion tasks while accommodating their individual requirements. Built on a decoder-only Transformer architecture, UniMotion employs dedicated interaction modes and tailored training strategies to simultaneously support these motion tasks. This unified design not only enables joint optimization and representation sharing but also allows for targeted fine-tuning to specialize in individual tasks when needed. Extensive experiments on the Waymo Open Motion Dataset demonstrate that joint training leads to robust generalization and effective task integration. With further fine-tuning, UniMotion achieves state-of-the-art performance across a range of motion tasks, establishing it as a versatile and scalable solution for autonomous driving.

</details>


### [186] [Agentic Reward Modeling: Verifying GUI Agent via Online Proactive Interaction](https://arxiv.org/abs/2602.00575)
*Chaoqun Cui,Jing Huang,Shijing Wang,Liming Zheng,Qingchao Kong,Zhixiong Zeng*

Main category: cs.RO

TL;DR: VAGEN框架通过智能验证代理主动交互验证GUI任务完成情况，解决了传统被动评估方法的局限性，显著提升了评估准确性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理评估方法存在严重局限：基于规则的方法扩展性差且无法处理开放任务，LLM-as-a-Judge方法依赖被动视觉观察，由于部分状态可观测性而经常无法捕捉潜在系统状态。

Method: 提出VAGEN框架，采用配备交互工具的验证代理，自主规划验证策略并主动探测环境以获取任务完成证据。利用"GUI任务易于验证但难以解决"的洞察，克服视觉限制瓶颈。

Result: 在OSWorld-Verified和AndroidWorld基准测试中，VAGEN相比LLM-as-a-Judge基线显著提高了评估准确性，并通过测试时扩展策略进一步提升了性能。

Conclusion: 从被动评估转向智能交互验证是解决GUI代理评估挑战的有效范式转变，VAGEN框架为此提供了实用解决方案。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is pivotal for the continuous evolution of GUI agents, yet existing evaluation paradigms face significant limitations. Rule-based methods suffer from poor scalability and cannot handle open-ended tasks, while LLM-as-a-Judge approaches rely on passive visual observation, often failing to capture latent system states due to partial state observability. To address these challenges, we advocate for a paradigm shift from passive evaluation to Agentic Interactive Verification. We introduce VAGEN, a framework that employs a verifier agent equipped with interaction tools to autonomously plan verification strategies and proactively probe the environment for evidence of task completion. Leveraging the insight that GUI tasks are typically "easy to verify but hard to solve", VAGEN overcomes the bottlenecks of visual limitations. Experimental results on OSWorld-Verified and AndroidWorld benchmarks demonstrate that VAGEN significantly improves evaluation accuracy compared to LLM-as-a-Judge baselines and further enhances performance through test-time scaling strategies.

</details>


### [187] [Factored Reasoning with Inner Speech and Persistent Memory for Evidence-Grounded Human-Robot Interaction](https://arxiv.org/abs/2602.00675)
*Valerio Belcamino,Mariya Kilina,Alessandro Carfì,Valeria Seidita,Fulvio Mastrogiovanni,Antonio Chella*

Main category: cs.RO

TL;DR: JANUS是一个用于辅助机器人的认知架构，通过模块化分解和显式策略实现可验证的对话交互，在饮食辅助领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 对话式人机交互需要机器人能够维护持久用户上下文、从不明确请求中恢复、基于外部证据生成响应，同时保持中间决策的可验证性。

Method: 将交互建模为部分可观测马尔可夫决策过程，实现为具有类型接口的分解控制器。包含范围检测、意图识别、记忆、内部语音、查询生成和外部语音等专门模块，并暴露信息充分性、执行准备度和工具接地的显式策略。

Result: 在基于知识图谱的饮食辅助领域进行模块级单元测试，报告了与参考标注的高一致性以及实用的延迟特性。

Conclusion: 分解推理是实现可扩展、可审计和基于证据的机器人辅助系统的有前景路径，适用于长期交互场景。

Abstract: Dialogue-based human-robot interaction requires robot cognitive assistants to maintain persistent user context, recover from underspecified requests, and ground responses in external evidence, while keeping intermediate decisions verifiable. In this paper we introduce JANUS, a cognitive architecture for assistive robots that models interaction as a partially observable Markov decision process and realizes control as a factored controller with typed interfaces. To this aim, Janus (i) decomposes the overall behavior into specialized modules, related to scope detection, intent recognition, memory, inner speech, query generation, and outer speech, and (ii) exposes explicit policies for information sufficiency, execution readiness, and tool grounding. A dedicated memory agent maintains a bounded recent-history buffer, a compact core memory, and an archival store with semantic retrieval, coupled through controlled consolidation and revision policies. Models inspired by the notion of inner speech in cognitive theories provide a control-oriented internal textual flow that validates parameter completeness and triggers clarification before grounding, while a faithfulness constraint ties robot-to-human claims to an evidence bundle combining working context and retrieved tool outputs. We evaluate JANUS through module-level unit tests in a dietary assistance domain grounded on a knowledge graph, reporting high agreement with curated references and practical latency profiles. These results support factored reasoning as a promising path to scalable, auditable, and evidence-grounded robot assistance over extended interaction horizons.

</details>


### [188] [Toward Reliable Sim-to-Real Predictability for MoE-based Robust Quadrupedal Locomotion](https://arxiv.org/abs/2602.00678)
*Tianyang Wu,Hanwei Guo,Yuhang Wang,Junshu Yang,Xinyang Sui,Jiayi Xie,Xingyu Chen,Zeyang Liu,Xuguang Lan*

Main category: cs.RO

TL;DR: 提出MoE专家混合策略和RoboGauge评估套件，实现仅凭本体感知的四足机器人鲁棒多地形运动，无需大量物理测试即可选择可迁移策略


<details>
  <summary>Details</summary>
Motivation: 强化学习在四足机器人运动控制中表现良好，但存在sim-to-real差距和复杂地形中的奖励过拟合问题，导致策略迁移失败，而物理验证既危险又低效

Method: 1. Mixture-of-Experts (MoE) 策略：使用门控专家集分解潜在地形和指令建模，仅凭本体感知实现鲁棒多地形表示；2. RoboGauge评估套件：通过sim-to-sim测试提供多维度本体感知指标，量化sim-to-real可迁移性

Result: 在Unitree Go2机器人上验证：在未见过的挑战性地形（雪、沙、楼梯、斜坡、30厘米障碍）上实现鲁棒运动；高速测试中达到4 m/s速度，并出现与高速稳定性相关的窄步态

Conclusion: MoE策略和RoboGauge评估套件共同解决了sim-to-real差距和奖励过拟合问题，实现了仅凭本体感知的鲁棒多地形运动，无需大量物理测试即可可靠选择可迁移策略

Abstract: Reinforcement learning has shown strong promise for quadrupedal agile locomotion, even with proprioception-only sensing. In practice, however, sim-to-real gap and reward overfitting in complex terrains can produce policies that fail to transfer, while physical validation remains risky and inefficient. To address these challenges, we introduce a unified framework encompassing a Mixture-of-Experts (MoE) locomotion policy for robust multi-terrain representation with RoboGauge, a predictive assessment suite that quantifies sim-to-real transferability. The MoE policy employs a gated set of specialist experts to decompose latent terrain and command modeling, achieving superior deployment robustness and generalization via proprioception alone. RoboGauge further provides multi-dimensional proprioception-based metrics via sim-to-sim tests over terrains, difficulty levels, and domain randomizations, enabling reliable MoE policy selection without extensive physical trials. Experiments on a Unitree Go2 demonstrate robust locomotion on unseen challenging terrains, including snow, sand, stairs, slopes, and 30 cm obstacles. In dedicated high-speed tests, the robot reaches 4 m/s and exhibits an emergent narrow-width gait associated with improved stability at high velocity.

</details>


### [189] [Learning to Accelerate Vision-Language-Action Models through Adaptive Visual Token Caching](https://arxiv.org/abs/2602.00686)
*Yujie Wei,Jiahan Fan,Jiyu Guo,Ruichen Zhen,Rui Shao,Xiu Su,Zeke Xie,Shuo Yang*

Main category: cs.RO

TL;DR: 提出一种可学习的动态推理加速框架，通过任务感知的缓存策略优化VLA模型，实现1.76倍加速同时提升任务成功率


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人操作任务中表现出色，但计算开销大阻碍实际部署。现有加速方法采用启发式或静态策略，无法适应动态场景变化，且与任务目标脱节。

Method: 将推理加速重新定义为可学习的策略优化问题，引入两个轻量级协作模块：缓存令牌选择器和缓存比例预测器。采用可微分松弛方法实现端到端梯度优化。

Result: 在LIBERO和SIMPLER基准测试及真实机器人评估中，实现1.76倍推理加速，平均成功率在LIBERO上提升1.9个百分点（从75.0%到76.9%），真实任务提升5.0个百分点，显著优于现有基线。

Conclusion: 展示了学习任务感知计算分配策略的潜力，为构建既强大又高效的VLA模型开辟了新途径，实现了性能与效率的双重提升。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable generalization capabilities in robotic manipulation tasks, yet their substantial computational overhead remains a critical obstacle to real-world deployment. Improving inference efficiency is therefore essential for practical robotic applications. Existing acceleration methods often rely on heuristic or static strategies--such as rule-based token caching or pruning--that are decoupled from task objectives and fail to adapt to dynamic scene changes. In this work, we reformulate inference acceleration as a learnable policy optimization problem and propose a novel framework that integrates a dynamic, task-aware decision-making process directly into the VLA model. At its core are two lightweight, cooperative modules: a Cached Token Selector, which determines which tokens should be reused, and a Cache Ratio Predictor, which controls how many tokens to reuse. Training these modules is non-trivial due to their discrete decisions. We address this by adopting a differentiable relaxation that allows gradient-based end-to-end optimization. Extensive experiments on the LIBERO and SIMPLER benchmarks, as well as real-robot evaluations, show that our method achieves a 1.76x wall-clock inference speedup while simultaneously improving the average success rate by 1.9 percentage points (from 75.0% to 76.9%) on LIBERO and by 5.0 percentage points on real-world tasks, significantly outperforming existing baselines. This work highlights the potential of learning task-aware computational allocation policies, paving the way for VLA models that are both powerful and efficient.

</details>


### [190] [USS-Nav: Unified Spatio-Semantic Scene Graph for Lightweight UAV Zero-Shot Object Navigation](https://arxiv.org/abs/2602.00708)
*Weiqi Gai,Yuman Gao,Yuan Zhou,Yufan Xie,Zhiyang Liu,Yuze Wu,Xin Zhou,Fei Gao,Zhijun Meng*

Main category: cs.RO

TL;DR: USS-Nav：一个轻量级框架，通过增量构建统一时空语义场景图，实现无人机在未知环境中的零样本物体导航，具有高效计算和实时更新能力。


<details>
  <summary>Details</summary>
Motivation: 无人机在未知环境中进行零样本物体导航面临重大挑战，主要矛盾在于高层语义推理需求与有限机载计算资源之间的冲突。现有方法难以在资源受限平台上实现实时高效的导航。

Method: 提出USS-Nav框架：1）使用多面体扩展的增量空间连通图生成方法捕捉全局几何拓扑；2）通过图聚类动态划分语义区域；3）将开放词汇对象语义实例化并锚定到拓扑结构，形成分层环境表示；4）基于场景图语义的LLM确定全局目标区域，局部规划器基于信息增益优化边界覆盖。

Result: 实验结果表明，该框架在计算效率和实时更新频率（15Hz）上优于最先进方法，在资源受限平台上表现优异。消融研究证实了框架的有效性，在成功加权路径长度（SPL）指标上有显著提升。

Conclusion: USS-Nav通过统一时空语义场景图和分层探索策略，成功解决了无人机零样本物体导航中的计算效率问题，为资源受限平台上的实时导航提供了有效解决方案。

Abstract: Zero-Shot Object Navigation in unknown environments poses significant challenges for Unmanned Aerial Vehicles (UAVs) due to the conflict between high-level semantic reasoning requirements and limited onboard computational resources. To address this, we present USS-Nav, a lightweight framework that incrementally constructs a Unified Spatio-Semantic scene graph and enables efficient Large Language Model (LLM)-augmented Zero-Shot Object Navigation in unknown environments. Specifically, we introduce an incremental Spatial Connectivity Graph generation method utilizing polyhedral expansion to capture global geometric topology, which is dynamically partitioned into semantic regions via graph clustering. Concurrently, open-vocabulary object semantics are instantiated and anchored to this topology to form a hierarchical environmental representation. Leveraging this hierarchical structure, we present a coarse-to-fine exploration strategy: LLM grounded in the scene graph's semantics to determine global target regions, while a local planner optimizes frontier coverage based on information gain. Experimental results demonstrate that our framework outperforms state-of-the-art methods in terms of computational efficiency and real-time update frequency (15 Hz) on a resource-constrained platform. Furthermore, ablation studies confirm the effectiveness of our framework, showing substantial improvements in Success weighted by Path Length (SPL). The source code will be made publicly available to foster further research.

</details>


### [191] [SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning](https://arxiv.org/abs/2602.00743)
*Xu Pan,Zhenglin Wan,Xingrui Yu,Xianwei Zheng,Youkai Ke,Ming Sun,Rui Wang,Ziwei Wang,Ivor Tsang*

Main category: cs.RO

TL;DR: SA-VLA是一个空间感知的强化学习适应框架，用于保持视觉-语言-动作模型在机器人操作中的空间归纳偏置，通过空间对齐的表征学习、奖励设计和探索策略来提升空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在机器人操作中表现出良好的泛化能力，但强化学习微调常常会降低模型在空间分布偏移下的鲁棒性。这种退化与空间归纳偏置在RL适应过程中的侵蚀密切相关，因为稀疏奖励和空间无关的探索策略倾向于关注短期视觉线索。

Method: SA-VLA框架包含三个核心组件：1）将隐式空间表征与视觉标记融合；2）提供反映几何进度的密集奖励；3）采用SCAN（空间条件退火探索策略），这是一种专门为流匹配动态设计的探索方法。该框架通过将表征学习、奖励设计和探索与任务几何对齐来保持空间基础。

Result: 在具有挑战性的多物体和杂乱环境操作基准测试中，SA-VLA实现了稳定的强化学习微调，并显著提升了零样本空间泛化能力，产生了更鲁棒和可迁移的行为。

Conclusion: SA-VLA通过空间感知的强化学习适应框架有效解决了VLA模型在RL微调中空间归纳偏置退化的问题，为机器人操作任务提供了更鲁棒和可泛化的解决方案。

Abstract: Vision-Language-Action (VLA) models exhibit strong generalization in robotic manipulation, yet reinforcement learning (RL) fine-tuning often degrades robustness under spatial distribution shifts. For flow-matching VLA policies, this degradation is closely associated with the erosion of spatial inductive bias during RL adaptation, as sparse rewards and spatially agnostic exploration increasingly favor short-horizon visual cues. To address this issue, we propose \textbf{SA-VLA}, a spatially-aware RL adaptation framework that preserves spatial grounding during policy optimization by aligning representation learning, reward design, and exploration with task geometry. SA-VLA fuses implicit spatial representations with visual tokens, provides dense rewards that reflect geometric progress, and employs \textbf{SCAN}, a spatially-conditioned annealed exploration strategy tailored to flow-matching dynamics. Across challenging multi-object and cluttered manipulation benchmarks, SA-VLA enables stable RL fine-tuning and improves zero-shot spatial generalization, yielding more robust and transferable behaviors. Code and project page are available at https://xupan.top/Projects/savla.

</details>


### [192] [Physics-informed Diffusion Mamba Transformer for Real-world Driving](https://arxiv.org/abs/2602.00808)
*Hang Zhou,Qiang Zhang,Peiran Liu,Yihao Qin,Zhaoxu Yan,Yiding Ji*

Main category: cs.RO

TL;DR: 提出一种结合扩散模型、Mamba Transformer和哈密顿神经网络的轨迹规划框架，用于自动驾驶系统，能有效处理不确定性、时序依赖和物理约束。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要轨迹规划器能够建模未来运动的不确定性，同时尊重复杂的时序依赖和物理规律。现有的扩散生成模型虽然擅长捕捉多模态分布，但往往无法融入长期序列上下文和领域特定的物理先验。

Method: 提出两个关键创新：1) Diffusion Mamba Transformer架构，将mamba和注意力机制嵌入扩散过程，更有效地聚合传感器流和过去运动历史的序列输入上下文；2) Port-Hamiltonian Neural Network模块，将基于能量的物理约束无缝集成到扩散模型中。

Result: 在标准自动驾驶基准测试上的广泛评估表明，该统一框架在预测准确性、物理合理性和鲁棒性方面显著优于最先进的基线方法。

Conclusion: 该工作通过创新的架构设计，成功地将序列建模能力和物理约束融入扩散模型，推动了安全可靠的自动驾驶运动规划技术的发展。

Abstract: Autonomous driving systems demand trajectory planners that not only model the inherent uncertainty of future motions but also respect complex temporal dependencies and underlying physical laws. While diffusion-based generative models excel at capturing multi-modal distributions, they often fail to incorporate long-term sequential contexts and domain-specific physical priors. In this work, we bridge these gaps with two key innovations. First, we introduce a Diffusion Mamba Transformer architecture that embeds mamba and attention into the diffusion process, enabling more effective aggregation of sequential input contexts from sensor streams and past motion histories. Second, we design a Port-Hamiltonian Neural Network module that seamlessly integrates energy-based physical constraints into the diffusion model, thereby enhancing trajectory predictions with both consistency and interpretability. Extensive evaluations on standard autonomous driving benchmarks demonstrate that our unified framework significantly outperforms state-of-the-art baselines in predictive accuracy, physical plausibility, and robustness, thereby advancing safe and reliable motion planning.

</details>


### [193] [SyNeT: Synthetic Negatives for Traversability Learning](https://arxiv.org/abs/2602.00814)
*Bomena Kim,Hojun Lee,Younsoo Park,Yaoyu Hu,Sebastian Scherer,Inwook Shim*

Main category: cs.RO

TL;DR: 提出SyNet方法，通过合成负样本来增强视觉可通行性学习，解决现有自监督学习缺乏显式负数据的问题，提升模型识别非可通行区域的能力。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习框架主要依赖正样本和未标记数据，缺乏显式负样本限制了模型准确识别多样化非可通行区域的能力。

Method: 引入合成负样本构建方法，表示合理但不可通行的区域，可无缝集成到PU和PN框架中，无需修改推理架构。同时提出基于对象的FPR评估方法。

Result: 在公开和自收集数据集上的大量实验表明，该方法显著提升了模型在不同环境中的鲁棒性和泛化能力。

Conclusion: 通过合成负样本增强视觉可通行性学习是有效的，SyNet方法能够提升模型识别非可通行区域的准确性，无需额外人工标注。

Abstract: Reliable traversability estimation is crucial for autonomous robots to navigate complex outdoor environments safely. Existing self-supervised learning frameworks primarily rely on positive and unlabeled data; however, the lack of explicit negative data remains a critical limitation, hindering the model's ability to accurately identify diverse non-traversable regions. To address this issue, we introduce a method to explicitly construct synthetic negatives, representing plausible but non-traversable, and integrate them into vision-based traversability learning. Our approach is formulated as a training strategy that can be seamlessly integrated into both Positive-Unlabeled (PU) and Positive-Negative (PN) frameworks without modifying inference architectures. Complementing standard pixel-wise metrics, we introduce an object-centric FPR evaluation approach that analyzes predictions in regions where synthetic negatives are inserted. This evaluation provides an indirect measure of the model's ability to consistently identify non-traversable regions without additional manual labeling. Extensive experiments on both public and self-collected datasets demonstrate that our approach significantly enhances robustness and generalization across diverse environments. The source code and demonstration videos are publicly available at the project page: https://anonymous-synet.github.io/SyNet.github.io/

</details>


### [194] [Ocean Current-Harnessing Stage-Gated MPC: Monotone Cost Shaping and Speed-to-Fly for Energy-Efficient AUV Navigation](https://arxiv.org/abs/2602.00823)
*Spyridon Syntakas,Kostas Vlachos*

Main category: cs.RO

TL;DR: 提出一种利用洋流的阶段门控MPC方法，通过感知洋流"帮助性"来降低AUV能耗，实现节能航行


<details>
  <summary>Details</summary>
Motivation: 自主水下航行器(AUV)在海洋探索和离岸作业中应用前景广阔，但实际部署受到能源效率和续航能力的限制。需要开发能够有效利用洋流来降低能耗的控制方法。

Method: 提出Current-Harnessing Stage-Gated MPC方法：1) 沿预测时域计算洋流"帮助性"标量，仅在洋流真正有助于控制目标时启用轻量级成本项；2) 引入单调成本塑形(MCS)项，放松沿航迹位置误差并提供有界平移能量回扣；3) 添加速度匹配(STF)成本项，提高推力成本并软匹配地速与洋流，实现近零水相对速度的"滑翔"。

Result: 在BlueROV2模型和真实洋流场下的广泛仿真表明，该方法相比传统预测控制显著降低了能耗，同时保持了相当的到达时间和约束满足度。

Conclusion: 提出的阶段门控MPC方法能够有效利用洋流降低AUV能耗，所有成本项均为C1连续且可作为即插即用模块集成到MPC设计中，为AUV的节能航行提供了实用解决方案。

Abstract: Autonomous Underwater Vehicles (AUVs) are a highly promising technology for ocean exploration and diverse offshore operations, yet their practical deployment is constrained by energy efficiency and endurance. To address this, we propose Current-Harnessing Stage-Gated MPC, which exploits ocean currents via a per-stage scalar which indicates the "helpfulness" of ocean currents. This scalar is computed along the prediction horizon to gate lightweight cost terms only where the ocean currents truly aids the control goal. The proposed cost terms, that are merged in the objective function, are (i) a Monotone Cost Shaping (MCS) term, a help-gated, non-worsening modification that relaxes along-track position error and provides a bounded translational energy rebate, guaranteeing the shaped objective is never larger than a set baseline, and (ii) a speed-to-fly (STF) cost component that increases the price of thrust and softly matches ground velocity to the ocean current, enabling near zero water-relative "gliding". All terms are C1 and integrate as a plug-and-play in MPC designs. Extensive simulations with the BlueROV2 model under realistic ocean current fields show that the proposed approach achieves substantially lower energy consumption than conventional predictive control while maintaining comparable arrival times and constraint satisfaction.

</details>


### [195] [Safe Stochastic Explorer: Enabling Safe Goal Driven Exploration in Stochastic Environments and Safe Interaction with Unknown Objects](https://arxiv.org/abs/2602.00868)
*Nikhil Uday Shinde,Dylan Hirsch,Michael C. Yip,Sylvia Herbert*

Main category: cs.RO

TL;DR: 提出Safe Stochastic Explorer框架，用于在随机动态环境下进行安全的目标驱动探索，通过高斯过程学习未知安全函数，平衡安全性与信息收集。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在非结构化、安全关键环境中操作时，需要在有限先验知识下安全导航和交互。现有安全控制方法假设已知系统动态，而现有安全探索技术往往无法处理现实世界环境中不可避免的随机性。

Method: 提出Safe Stochastic Explorer框架，使用高斯过程在线学习未知安全函数，利用其预测不确定性指导信息收集行动并提供安全违规的概率界限。首先针对离散状态空间，然后引入可扩展的松弛方法扩展到连续状态空间，并可应用于与多个未知物体的安全物理交互。

Result: 在仿真和硬件实验中进行了广泛验证，展示了方法的有效性，代表了在复杂不确定环境中实现可靠广泛机器人自主性方面的重要进展。

Conclusion: 该方法为解决随机动态环境下的安全探索问题提供了新框架，通过平衡安全性与信息收集，减少了未知环境中的安全不确定性，推动了复杂不确定环境中机器人自主性的发展。

Abstract: Autonomous robots operating in unstructured, safety-critical environments, from planetary exploration to warehouses and homes, must learn to safely navigate and interact with their surroundings despite limited prior knowledge. Current methods for safe control, such as Hamilton-Jacobi Reachability and Control Barrier Functions, assume known system dynamics. Meanwhile existing safe exploration techniques often fail to account for the unavoidable stochasticity inherent when operating in unknown real world environments, such as an exploratory rover skidding over an unseen surface or a household robot pushing around unmapped objects in a pantry. To address this critical gap, we propose Safe Stochastic Explorer (S.S.Explorer) a novel framework for safe, goal-driven exploration under stochastic dynamics. Our approach strategically balances safety and information gathering to reduce uncertainty about safety in the unknown environment. We employ Gaussian Processes to learn the unknown safety function online, leveraging their predictive uncertainty to guide information-gathering actions and provide probabilistic bounds on safety violations. We first present our method for discrete state space environments and then introduce a scalable relaxation to effectively extend this approach to continuous state spaces. Finally we demonstrate how this framework can be naturally applied to ensure safe physical interaction with multiple unknown objects. Extensive validation in simulation and demonstrative hardware experiments showcase the efficacy of our method, representing a step forward toward enabling reliable widespread robot autonomy in complex, uncertain environments.

</details>


### [196] [Learning When to Jump for Off-road Navigation](https://arxiv.org/abs/2602.00877)
*Zhipeng Zhao,Taimeng Fu,Shaoshu Su,Qiwei Du,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury,Chen Wang*

Main category: cs.RO

TL;DR: 提出Motion-aware Traversability (MAT)表示法，通过将地形可通行性建模为速度的高斯函数，实现考虑复杂运动动力学的越野路径规划，减少75%绕路同时保持安全性。


<details>
  <summary>Details</summary>
Motivation: 现有越野路径规划方法通常只基于位置或固定速度进行规划，忽略了复杂运动动力学的影响。例如，低速过沟可能因陷车而危险，而高速跳跃反而安全。需要显式建模运动动力学的地形可通行性表示。

Method: 引入Motion-aware Traversability (MAT)表示法，将每个地形区域建模为速度的高斯函数而非单一标量。在线规划时采用两阶段计算：1) 单次前向传播预测地形相关高斯参数；2) 根据当前动力学推断新速度，高效评估函数更新地形成本，无需重复推理。

Result: 在仿真和真实环境中测试，MAT实现实时效率，提升越野导航性能，减少75%路径绕行，同时在挑战性地形中保持安全性。

Conclusion: MAT通过显式建模地形成本与机器人实际运动的关系，解决了现有方法忽略复杂运动动力学的问题，实现了更敏捷、安全的越野导航。

Abstract: Low speed does not always guarantee safety in off-road driving. For instance, crossing a ditch may be risky at a low speed due to the risk of getting stuck, yet safe at a higher speed with a controlled, accelerated jump. Achieving such behavior requires path planning that explicitly models complex motion dynamics, whereas existing methods often neglect this aspect and plan solely based on positions or a fixed velocity. To address this gap, we introduce Motion-aware Traversability (MAT) representation to explicitly model terrain cost conditioned on actual robot motion. Instead of assigning a single scalar score for traversability, MAT models each terrain region as a Gaussian function of velocity. During online planning, we decompose the terrain cost computation into two stages: (1) predict terrain-dependent Gaussian parameters from perception in a single forward pass, (2) efficiently update terrain costs for new velocities inferred from current dynamics by evaluating these functions without repeated inference. We develop a system that integrates MAT to enable agile off-road navigation and evaluate it in both simulated and real-world environments with various obstacles. Results show that MAT achieves real-time efficiency and enhances the performance of off-road navigation, reducing path detours by 75% while maintaining safety across challenging terrains.

</details>


### [197] [RoDiF: Robust Direct Fine-Tuning of Diffusion Policies with Corrupted Human Feedback](https://arxiv.org/abs/2602.00886)
*Amitesh Vatsa,Zhixian Xie,Wanxin Jin*

Main category: cs.RO

TL;DR: RoDiF：一种针对扩散策略的鲁棒直接偏好优化方法，通过几何假设切割处理损坏的人类偏好标签


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人控制中很强大，但基于人类偏好的微调面临挑战，因为去噪过程的多步骤结构使得传统偏好优化方法难以应用。此外，实际应用中的人类偏好标签可能存在损坏。

Method: 提出了统一的马尔可夫决策过程（MDP）公式，将扩散去噪链与环境动态整合，实现无奖励的直接偏好优化（DPO）。在此基础上提出RoDiF方法，通过几何假设切割视角重新解释DPO目标，采用保守切割策略实现鲁棒性，无需假设特定噪声分布。

Result: 在长时程操作任务上的大量实验表明，RoDiF始终优于最先进的基线方法，能有效引导预训练的扩散策略（各种架构）朝向人类偏好模式，即使在30%损坏的偏好标签下仍保持强大性能。

Conclusion: RoDiF为扩散策略提供了一种鲁棒的偏好优化框架，能够处理损坏的人类偏好标签，推动了扩散策略在实际机器人控制中的应用。

Abstract: Diffusion policies are a powerful paradigm for robotic control, but fine-tuning them with human preferences is fundamentally challenged by the multi-step structure of the denoising process. To overcome this, we introduce a Unified Markov Decision Process (MDP) formulation that coherently integrates the diffusion denoising chain with environmental dynamics, enabling reward-free Direct Preference Optimization (DPO) for diffusion policies. Building on this formulation, we propose RoDiF (Robust Direct Fine-Tuning), a method that explicitly addresses corrupted human preferences. RoDiF reinterprets the DPO objective through a geometric hypothesis-cutting perspective and employs a conservative cutting strategy to achieve robustness without assuming any specific noise distribution. Extensive experiments on long-horizon manipulation tasks show that RoDiF consistently outperforms state-of-the-art baselines, effectively steering pretrained diffusion policies of diverse architectures to human-preferred modes, while maintaining strong performance even under 30% corrupted preference labels.

</details>


### [198] [UniMorphGrasp: Diffusion Model with Morphology-Awareness for Cross-Embodiment Dexterous Grasp Generation](https://arxiv.org/abs/2602.00915)
*Zhiyuan Wu,Xiangyu Zhang,Zhuo Chen,Jiankang Deng,Rolandos Alexandros Potamias,Shan Luo*

Main category: cs.RO

TL;DR: 提出UniMorphGrasp框架，通过扩散模型和统一的手部形态表示，实现跨不同机械手结构的灵巧抓取生成，具有零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧抓取方法通常针对特定机械手设计，无法泛化到训练分布之外的未见手部形态结构，限制了跨不同机械手设计的抓取部署。

Method: 提出UniMorphGrasp扩散框架：1) 将不同机械手的抓取映射到统一的人手姿态表示空间；2) 使用图结构编码手部运动学信息；3) 结合物体几何信息；4) 引入利用手部运动学层次结构的损失函数进行关节级监督。

Result: 在现有灵巧抓取基准测试中达到最先进性能，对未见手部结构表现出强大的零样本泛化能力，实现了可扩展的跨机械手抓取部署。

Conclusion: UniMorphGrasp通过统一的手部形态表示和扩散模型，成功解决了跨不同机械手结构的灵巧抓取生成问题，具有实际部署的潜力。

Abstract: Cross-embodiment dexterous grasping aims to generate stable and diverse grasps for robotic hands with heterogeneous kinematic structures. Existing methods are often tailored to specific hand designs and fail to generalize to unseen hand morphologies outside the training distribution. To address these limitations, we propose \textbf{UniMorphGrasp}, a diffusion-based framework that incorporates hand morphological information into the grasp generation process for unified cross-embodiment grasp synthesis. The proposed approach maps grasps from diverse robotic hands into a unified human-like canonical hand pose representation, providing a common space for learning. Grasp generation is then conditioned on structured representations of hand kinematics, encoded as graphs derived from hand configurations, together with object geometry. In addition, a loss function is introduced that exploits the hierarchical organization of hand kinematics to guide joint-level supervision. Extensive experiments demonstrate that UniMorphGrasp achieves state-of-the-art performance on existing dexterous grasp benchmarks and exhibits strong zero-shot generalization to previously unseen hand structures, enabling scalable and practical cross-embodiment grasp deployment.

</details>


### [199] [Green-VLA: Staged Vision-Language-Action Model for Generalist Robots](https://arxiv.org/abs/2602.00919)
*I. Apanasevich,M. Artemyev,R. Babakyan,P. Fedotova,D. Grankin,E. Kupryashin,A. Misailidi,D. Nerus,A. Nutalapati,G. Sidorov,I. Efremov,M. Gerasyov,D. Pikurov,Y. Senchenko,S. Davidenko,D. Kulikov,M. Sultankin,K. Askarbek,O. Shamanin,D. Statovoy,E. Zalyaev,I. Zorin,A. Letkin,E. Rusakov,A. Silchenko,V. Vorobyov,S. Sobolnikov,A. Postnikov*

Main category: cs.RO

TL;DR: Green-VLA是一个分阶段的视觉-语言-动作框架，用于在Green人形机器人上部署，同时保持跨不同具身系统的泛化能力。该框架采用五阶段课程学习，结合大规模数据处理和统一动作接口，通过强化学习对齐提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决在真实世界人形机器人上部署视觉-语言-动作系统时的泛化问题，同时保持对不同具身系统（人形机器人、移动机械臂、固定基座机械臂）的适应能力。

Method: 采用五阶段课程学习框架：L0基础视觉语言模型、L1多模态接地、R0多具身预训练、R1特定具身适应、R2强化学习策略对齐。结合3000小时演示数据的时间对齐和质量过滤，使用统一的具身感知动作接口。

Result: 在Simpler BRIDGE WidowX和CALVIN ABC-D基准测试以及真实机器人评估中，展示了强大的泛化能力和性能提升，RL对齐显著提高了成功率、鲁棒性和长时域效率。

Conclusion: Green-VLA框架通过分阶段课程学习和强化学习对齐，成功实现了在真实人形机器人上的部署，同时保持了对多种具身系统的泛化能力，为实际应用提供了有效的解决方案。

Abstract: We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.

</details>


### [200] [SanD-Planner: Sample-Efficient Diffusion Planner in B-Spline Space for Robust Local Navigation](https://arxiv.org/abs/2602.00923)
*Jincheng Wang,Lingfan Bao,Tong Yang,Diego Martinez Plasencia,Jianhao Jiao,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: SanD-Planner：一种基于扩散模型的样本高效局部规划器，在B样条空间进行深度图像模仿学习，仅需少量演示数据即可在复杂动态环境中实现高性能规划


<details>
  <summary>Details</summary>
Motivation: 传统局部规划器在高度杂乱和动态环境中难以生成可靠规划，主要瓶颈包括：1）需要大规模专家演示数据；2）有限数据下的学习效率低

Method: 1）在夹紧B样条空间进行基于深度图像的模仿学习，确保平滑输出和有界预测误差；2）集成基于ESDF的安全检查器，使用明确间隙和完成时间指标，减少可行性评估的价值函数学习负担

Result: 仅用500个演示片段（基准方法的0.25%）训练，在模拟杂乱环境中成功率90.1%，室内模拟成功率72.0%，达到最先进性能，并证明了对2D和3D场景的零样本迁移能力

Conclusion: SanD-Planner通过B样条空间学习和安全检查器集成，显著减少了数据需求，实现了样本高效的局部规划，在复杂环境中表现出色且具有实际应用潜力

Abstract: The challenge of generating reliable local plans has long hindered practical applications in highly cluttered and dynamic environments. Key fundamental bottlenecks include acquiring large-scale expert demonstrations across diverse scenes and improving learning efficiency with limited data. This paper proposes SanD-Planner, a sample-efficient diffusion-based local planner that conducts depth image-based imitation learning within the clamped B-spline space. By operating within this compact space, the proposed algorithm inherently yields smooth outputs with bounded prediction errors over local supports, naturally aligning with receding-horizon execution. Integration of an ESDF-based safety checker with explicit clearance and time-to-completion metrics further reduces the training burden associated with value-function learning for feasibility assessment. Experiments show that training with $500$ episodes (merely $0.25\%$ of the demonstration scale used by the baseline), SanD-Planner achieves state-of-the-art performance on the evaluated open benchmark, attaining success rates of $90.1\%$ in simulated cluttered environments and $72.0\%$ in indoor simulations. The performance is further proven by demonstrating zero-shot transferability to realistic experimentation in both 2D and 3D scenes. The dataset and pre-trained models will also be open-sourced.

</details>


### [201] [Minimal Footprint Grasping Inspired by Ants](https://arxiv.org/abs/2602.00935)
*Mohamed Sorour,Barbara Webb*

Main category: cs.RO

TL;DR: 受蚂蚁前腿启发设计的低成本抓取器，具有高摩擦垫、低摩擦毛发和柔性结构，能有效抓取单个物体和从密集杂物中挑选


<details>
  <summary>Details</summary>
Motivation: 蚂蚁前腿在抓取杂乱物体时表现出色，其具有高摩擦微结构（刚毛垫）、毛发覆盖和柔性欠驱动尖端。研究这些特征的机械优势，为低成本抓取器设计提供生物灵感

Method: 抽象蚂蚁前腿特征：长而细的抓取腿、高摩擦抓取垫、低摩擦毛发、单段跗节状结构以模拟昆虫的刚毛垫、毛发和跗节的交互柔顺性

Result: 该设计对各种单个消费物体抓取具有高度鲁棒性，所有抓取尝试均成功。同时证明该设计能有效从密集杂物中挑选单个物体

Conclusion: 该工作推进了抓取技术发展，并揭示了昆虫毛发结构和跗节柔顺性的机械重要性

Abstract: Ants are highly capable of grasping objects in clutter, and we have recently observed that this involves substantial use of their forelegs. The forelegs, more specifically the tarsi, have high friction microstructures (setal pads), are covered in hairs, and have a flexible under-actuated tip. Here we abstract these features to test their functional advantages for a novel low-cost gripper design, suitable for bin-picking applications. In our implementation, the gripper legs are long and slim, with high friction gripping pads, low friction hairs and single-segment tarsus-like structure to mimic the insect's setal pads, hairs, and the tarsi's interactive compliance. Experimental evaluation shows this design is highly robust for grasping a wide variety of individual consumer objects, with all grasp attempts successful. In addition, we demonstrate this design is effective for picking single objects from dense clutter, a task at which ants also show high competence. The work advances grasping technology and shed new light on the mechanical importance of hairy structures and tarsal flexibility in insects.

</details>


### [202] [CLAMP: Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining](https://arxiv.org/abs/2602.00937)
*I-Chun Arthur Liu,Krzysztof Choromanski,Sandy Huang,Connor Schenck*

Main category: cs.RO

TL;DR: CLAMP是一个新颖的3D预训练框架，利用点云和机器人动作，通过对比学习关联3D几何信息与动作模式，显著提升机器人操作任务的学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于预训练2D图像表示的行为克隆方法无法捕捉3D空间信息，而3D信息对于精确的机器人操作至关重要。需要开发能够有效利用3D几何信息的预训练框架。

Method: 从RGB-D图像和相机外参计算合并点云，重新渲染包含深度和3D坐标的多视图四通道图像观测（包括动态手腕视图）。通过对比学习在大规模模拟轨迹上预训练编码器，同时预训练Diffusion Policy来初始化策略权重，最后在少量任务演示上进行微调。

Result: CLAMP显著提高了学习效率和策略性能，在未见过的任务上表现优异。在6个模拟任务和5个真实世界任务中超越了最先进的基线方法。

Conclusion: CLAMP通过3D预训练框架成功地将3D几何信息与机器人动作模式关联起来，为机器人操作任务提供了更有效的表示学习方法，在模拟和真实环境中都取得了优越性能。

Abstract: Leveraging pre-trained 2D image representations in behavior cloning policies has achieved great success and has become a standard approach for robotic manipulation. However, such representations fail to capture the 3D spatial information about objects and scenes that is essential for precise manipulation. In this work, we introduce Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining (CLAMP), a novel 3D pre-training framework that utilizes point clouds and robot actions. From the merged point cloud computed from RGB-D images and camera extrinsics, we re-render multi-view four-channel image observations with depth and 3D coordinates, including dynamic wrist views, to provide clearer views of target objects for high-precision manipulation tasks. The pre-trained encoders learn to associate the 3D geometric and positional information of objects with robot action patterns via contrastive learning on large-scale simulated robot trajectories. During encoder pre-training, we pre-train a Diffusion Policy to initialize the policy weights for fine-tuning, which is essential for improving fine-tuning sample efficiency and performance. After pre-training, we fine-tune the policy on a limited amount of task demonstrations using the learned image and action representations. We demonstrate that this pre-training and fine-tuning design substantially improves learning efficiency and policy performance on unseen tasks. Furthermore, we show that CLAMP outperforms state-of-the-art baselines across six simulated tasks and five real-world tasks.

</details>


### [203] [Meanshift Shape Formation Control Using Discrete Mass Distribution](https://arxiv.org/abs/2602.00980)
*Yichen Cai,Yuan Gao,Pengpeng Li,Wei Wang,Guibin Sun,Jinhu Lü*

Main category: cs.RO

TL;DR: 提出完全去中心化的分布控制策略，实现复杂形状形成和群体规模自适应


<details>
  <summary>Details</summary>
Motivation: 现有密度分布方法在复杂形状表示和去中心化实现方面面临实际挑战，需要开发能同时处理复杂形状和群体规模变化的去中心化控制策略

Method: 1) 提出离散质量分布函数在采样点上建模群体形成；2) 设计去中心化均值漂移控制律，通过质量估计反馈协调群体全局分布；3) 设计质量估计器实现所有采样点的去中心化质量估计

Result: 采样点质量估计能渐近收敛到真实全局值，通过仿真和真实实验验证了复杂形状形成效率和群体规模变化适应性

Conclusion: 提出的完全去中心化分布控制策略能有效实现复杂形状形成并适应群体规模变化，解决了现有方法的局限性

Abstract: The density-distribution method has recently become a promising paradigm owing to its adaptability to variations in swarm size. However, existing studies face practical challenges in achieving complex shape representation and decentralized implementation. This motivates us to develop a fully decentralized, distribution-based control strategy with the dual capability of forming complex shapes and adapting to swarm-size variations. Specifically, we first propose a discrete mass-distribution function defined over a set of sample points to model swarm formation. In contrast to the continuous density-distribution method, our model eliminates the requirement for defining continuous density functions-a task that is difficult for complex shapes. Second, we design a decentralized meanshift control law to coordinate the swarm's global distribution to fit the sample-point distribution by feeding back mass estimates. The mass estimates for all sample points are achieved by the robots in a decentralized manner via the designed mass estimator. It is shown that the mass estimates of the sample points can asymptotically converge to the true global values. To validate the proposed strategy, we conduct comprehensive simulations and real-world experiments to evaluate the efficiency of complex shape formation and adaptability to swarm-size variations.

</details>


### [204] [Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds](https://arxiv.org/abs/2602.00992)
*Phone Thiha Kyaw,Jonathan Kelly*

Main category: cs.RO

TL;DR: 提出一种基于采样的运动规划框架，直接在黎曼流形上操作，使用中点近似黎曼测地线距离，通过一阶回缩和黎曼自然梯度引导局部规划，在多种机器人系统上生成比欧几里得规划器和传统数值测地线求解器更低成本的轨迹。


<details>
  <summary>Details</summary>
Motivation: 许多机器人运动规划问题中，任务目标和物理约束在配置空间上诱导出非欧几里得几何结构，但现有规划器通常使用忽略这种结构的欧几里得距离。传统数值方法计算此类路径难以扩展到高维系统，而基于采样的规划器则在可扩展性和几何保真度之间权衡。

Method: 提出基于采样的运动规划框架，直接在黎曼流形上操作。引入计算高效的中点近似黎曼测地线距离方法，并证明其具有三阶精度。基于此近似设计局部规划器，使用一阶回缩在流形上追踪路径，并通过黎曼自然梯度引导。

Result: 在两连杆平面臂和7自由度Franka机械臂的动能度量下，以及在SE(2)上具有非完整运动约束的刚体规划实验中，该方法始终生成比欧几里得规划器和经典数值测地线求解器基线更低成本的轨迹。

Conclusion: 提出的框架成功桥接了可扩展性和几何保真度之间的差距，能够在黎曼流形上进行高效的运动规划，为考虑配置相关度量的机器人运动规划问题提供了有效的解决方案。

Abstract: In many robot motion planning problems, task objectives and physical constraints induce non-Euclidean geometry on the configuration space, yet many planners operate using Euclidean distances that ignore this structure. We address the problem of planning collision-free motions that minimize length under configuration-dependent Riemannian metrics, corresponding to geodesics on the configuration manifold. Conventional numerical methods for computing such paths do not scale well to high-dimensional systems, while sampling-based planners trade scalability for geometric fidelity. To bridge this gap, we propose a sampling-based motion planning framework that operates directly on Riemannian manifolds. We introduce a computationally efficient midpoint-based approximation of the Riemannian geodesic distance and prove that it matches the true Riemannian distance with third-order accuracy. Building on this approximation, we design a local planner that traces the manifold using first-order retractions guided by Riemannian natural gradients. Experiments on a two-link planar arm and a 7-DoF Franka manipulator under a kinetic-energy metric, as well as on rigid-body planning in $\mathrm{SE}(2)$ with non-holonomic motion constraints, demonstrate that our approach consistently produces lower-cost trajectories than Euclidean-based planners and classical numerical geodesic-solver baselines.

</details>


### [205] [HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving](https://arxiv.org/abs/2602.00993)
*Weizhe Tang,Junwei You,Jiaxi Liu,Zhaoyi Wang,Rui Gan,Zilin Huang,Feng Wei,Bin Ran*

Main category: cs.RO

TL;DR: HERMES是一个端到端多模态自动驾驶框架，通过注入显式长尾风险提示来提升混合交通场景下的轨迹规划安全性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶模型虽然受益于大视觉语言模型的语义理解能力，但在长尾混合交通场景下确保安全准确操作仍面临挑战。这些场景中自动驾驶车辆需要与人类驾驶车辆和弱势道路使用者等异构道路使用者交互，环境复杂且不确定。

Method: 1) 使用基础模型辅助标注管道生成结构化的长尾场景上下文和规划上下文，捕捉危险中心提示、操纵意图和安全偏好；2) 提出三模态驾驶模块，融合多视角感知、历史运动线索和语义指导，确保长尾场景下的风险感知准确轨迹规划。

Result: 在真实世界长尾数据集上的实验表明，HERMES在长尾混合交通场景下持续优于代表性的端到端和VLM驱动基线方法。消融研究验证了关键组件的互补贡献。

Conclusion: HERMES通过注入显式长尾风险提示和融合多模态信息，有效提升了自动驾驶在复杂混合交通场景下的安全性和准确性，为解决长尾问题提供了有效方案。

Abstract: End-to-end autonomous driving models increasingly benefit from large vision--language models for semantic understanding, yet ensuring safe and accurate operation under long-tail conditions remains challenging. These challenges are particularly prominent in long-tail mixed-traffic scenarios, where autonomous vehicles must interact with heterogeneous road users, including human-driven vehicles and vulnerable road users, under complex and uncertain conditions. This paper proposes HERMES, a holistic risk-aware end-to-end multimodal driving framework designed to inject explicit long-tail risk cues into trajectory planning. HERMES employs a foundation-model-assisted annotation pipeline to produce structured Long-Tail Scene Context and Long-Tail Planning Context, capturing hazard-centric cues together with maneuver intent and safety preference, and uses these signals to guide end-to-end planning. HERMES further introduces a Tri-Modal Driving Module that fuses multi-view perception, historical motion cues, and semantic guidance, ensuring risk-aware accurate trajectory planning under long-tail scenarios. Experiments on the real-world long-tail dataset demonstrate that HERMES consistently outperforms representative end-to-end and VLM-driven baselines under long-tail mixed-traffic scenarios. Ablation studies verify the complementary contributions of key components.

</details>


### [206] [Offline Discovery of Interpretable Skills from Multi-Task Trajectories](https://arxiv.org/abs/2602.01018)
*Chongyu Zhu,Mithun Vanniasinghe,Jiayu Chen,Chi-Guhn Lee*

Main category: cs.RO

TL;DR: LOKI是一个三阶段端到端学习框架，用于从离线多任务演示数据中发现可重用技能并进行分层模仿学习，无需显式奖励或子任务标注。


<details>
  <summary>Details</summary>
Motivation: 分层模仿学习需要从长时程、多任务的离线数据中发现可重用技能，但现有方法面临数据缺乏显式奖励或子任务标注的挑战。

Method: 三阶段框架：1）使用弱监督任务标签的VQ-VAE进行粗粒度任务感知宏分割；2）自监督序列模型进行微分割，迭代聚类巩固技能边界；3）在选项框架中构建分层策略，学习显式技能切换的终止条件。

Result: 在D4RL Kitchen基准测试中取得高成功率，优于标准HIL基线；发现的技能具有语义意义，符合人类直觉，并能通过组合解决新任务。

Conclusion: LOKI框架有效解决了离线技能发现和分层模仿学习的关键挑战，能够从无标注演示数据中发现可重用、可组合的技能。

Abstract: Hierarchical Imitation Learning is a powerful paradigm for acquiring complex robot behaviors from demonstrations. A central challenge, however, lies in discovering reusable skills from long-horizon, multi-task offline data, especially when the data lacks explicit rewards or subtask annotations. In this work, we introduce LOKI, a three-stage end-to-end learning framework designed for offline skill discovery and hierarchical imitation. The framework commences with a two-stage, weakly supervised skill discovery process: Stage one performs coarse, task-aware macro-segmentation by employing an alignment-enforced Vector Quantized VAE guided by weak task labels. Stage two then refines these segments at a micro-level using a self-supervised sequential model, followed by an iterative clustering process to consolidate skill boundaries. The third stage then leverages these precise boundaries to construct a hierarchical policy within an option-based framework-complete with a learned termination condition beta for explicit skill switching. LOKI achieves high success rates on the challenging D4RL Kitchen benchmark and outperforms standard HIL baselines. Furthermore, we demonstrate that the discovered skills are semantically meaningful, aligning with human intuition, and exhibit compositionality by successfully sequencing them to solve a novel, unseen task.

</details>


### [207] [Learning Adaptive Cross-Embodiment Visuomotor Policy with Contrastive Prompt Orchestration](https://arxiv.org/abs/2602.01040)
*Yuhang Zhang,Chao Yan,Jiaxi Yu,Jiaping Xiao,Mir Feroskhan*

Main category: cs.RO

TL;DR: CAPO提出了一种结合对比提示学习和自适应提示编排的新方法，用于学习跨具身智能体的视觉运动策略，显著提升样本效率和零样本适应能力。


<details>
  <summary>Details</summary>
Motivation: 传统学习方法难以分离任务相关特征与领域特定变化（如光照、视野、旋转），导致样本效率低且在未见环境中表现差。需要解决跨具身智能体（不同传感器配置和动态特性）的视觉运动策略适应问题。

Method: 提出ContrAstive Prompt Orchestration (CAPO)：1) 混合对比学习策略，结合视觉、时序动作和文本目标，建立可学习提示池；2) 自适应提示编排机制，根据当前观察动态聚合提示，构建最优状态表示。

Result: CAPO在样本效率和渐近性能上显著优于最先进基线方法，在未见目标域（如光照变化、视野和旋转变化）中表现出优越的零样本适应能力。

Conclusion: CAPO通过对比提示学习和自适应编排，有效屏蔽策略优化中的无关干扰，防止对源域过拟合，是跨具身视觉运动策略适应的可行解决方案。

Abstract: Learning adaptive visuomotor policies for embodied agents remains a formidable challenge, particularly when facing cross-embodiment variations such as diverse sensor configurations and dynamic properties. Conventional learning approaches often struggle to separate task-relevant features from domain-specific variations (e.g., lighting, field-of-view, and rotation), leading to poor sample efficiency and catastrophic failure in unseen environments. To bridge this gap, we propose ContrAstive Prompt Orchestration (CAPO), a novel approach for learning visuomotor policies that integrates contrastive prompt learning and adaptive prompt orchestration. For prompt learning, we devise a hybrid contrastive learning strategy that integrates visual, temporal action, and text objectives to establish a pool of learnable prompts, where each prompt induces a visual representation encapsulating fine-grained domain factors. Based on these learned prompts, we introduce an adaptive prompt orchestration mechanism that dynamically aggregates these prompts conditioned on current observations. This enables the agent to adaptively construct optimal state representations by identifying dominant domain factors instantaneously. Consequently, the policy optimization is effectively shielded from irrelevant interference, preventing the common issue of overfitting to source domains. Extensive experiments demonstrate that CAPO significantly outperforms state-of-the-art baselines in sample efficiency and asymptotic performance. Crucially, it exhibits superior zero-shot adaptation across unseen target domains characterized by drastic environmental (e.g., illumination) and physical shifts (e.g., field-of-view and rotation), validating its effectiveness as a viable solution for cross-embodiment visuomotor policy adaptation.

</details>


### [208] [LLM-Based Behavior Tree Generation for Construction Machinery](https://arxiv.org/abs/2602.01041)
*Akinosuke Tsutsumi,Tomoya Itsuka,Yuichiro Kasahara,Tomoya Kouno,Kota Akinari,Genki Yamauchi,Daisuke Endo,Taro Abe,Takeshi Hashimoto,Keiji Nagatani,Ryo Kurazume*

Main category: cs.RO

TL;DR: 本文提出了一种基于大语言模型的行为树生成工作流，通过引入同步标志实现异构建筑机械的安全协同操作，并在仿真和真实实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 土方工程需求增长与劳动力老龄化、技能流失的矛盾日益突出，需要自动化解决方案。现有的ROS2-TMS框架依赖手动设计行为树，在异构机械协同场景中扩展性受限。虽然大语言模型为任务规划提供了新机会，但现有方法大多局限于仿真或简单机械臂，缺乏在复杂施工现场的实际应用验证。

Method: 提出基于LLM的行为树生成工作流：1）高层规划阶段，LLM生成同步标志以实现安全协同操作；2）使用结构化模板生成行为树。通过系统数据库中的参数确保安全性，使异构机械能够协调工作。

Result: 该方法在仿真环境中得到验证，并通过真实世界实验进一步展示其可行性，证明了在土木工程自动化中的实际应用潜力。

Conclusion: 基于LLM的行为树生成工作流能够有效解决建筑机械协同操作的自动化挑战，通过同步标志机制确保安全，为土木工程领域的自动化进步提供了有前景的解决方案。

Abstract: Earthwork operations are facing an increasing demand, while workforce aging and skill loss create a pressing need for automation. ROS2-TMS for Construction, a Cyber-Physical System framework designed to coordinate construction machinery, has been proposed for autonomous operation; however, its reliance on manually designed Behavior Trees (BTs) limits scalability, particularly in scenarios involving heterogeneous machine cooperation. Recent advances in large language models (LLMs) offer new opportunities for task planning and BT generation. However, most existing approaches remain confined to simulations or simple manipulators, with relatively few applications demonstrated in real-world contexts, such as complex construction sites involving multiple machines. This paper proposes an LLM-based workflow for BT generation, introducing synchronization flags to enable safe and cooperative operation. The workflow consists of two steps: high-level planning, where the LLM generates synchronization flags, and BT generation using structured templates. Safety is ensured by planning with parameters stored in the system database. The proposed method is validated in simulation and further demonstrated through real-world experiments, highlighting its potential to advance automation in civil engineering.

</details>


### [209] [A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation](https://arxiv.org/abs/2602.01067)
*Fanqi Lin,Kushal Arora,Jean Mercat,Haruki Nishimura,Paarth Shah,Chen Xu,Mengchao Zhang,Mark Zolotas,Maya Angeles,Owen Pfannenstiehl,Andrew Beaulieu,Jose Barreiros*

Main category: cs.RO

TL;DR: 大规模实证研究比较了五种协同训练数据模态对机器人策略性能的影响，发现视觉-语言数据和跨具身机器人数据能显著提升泛化能力，而离散动作标记则无显著益处。


<details>
  <summary>Details</summary>
Motivation: 大型行为模型通过多任务机器人数据的模仿学习展现出强大的灵巧操作能力，但其泛化能力受限于机器人数据覆盖不足。为了在不增加昂贵数据收集成本的情况下扩展覆盖范围，需要研究不同协同训练数据模态和策略如何影响策略性能。

Method: 使用4000小时的机器人和人类操作数据以及5000万视觉-语言样本，训练视觉-语言-动作策略。评估了89个策略在58,000次模拟运行和2,835次真实世界运行中的表现，比较了五种协同训练数据模态：标准视觉-语言数据、机器人轨迹的密集语言标注、跨具身机器人数据、人类视频和离散机器人动作标记。

Result: 协同训练使用视觉-语言和跨具身机器人数据能显著提升对分布偏移、未见任务和语言跟随的泛化能力。离散动作标记变体无显著益处。有效模态的组合产生累积增益，并能通过微调快速适应未见的长时程灵巧任务。仅使用机器人数据训练会损害视觉-语言模型骨干的视觉语言理解能力，而协同训练能恢复这些能力。

Conclusion: 研究为构建可扩展的通用机器人策略提供了实用指导：视觉-语言和跨具身机器人数据是有效的协同训练模态，而离散动作标记则效果有限。有效模态的组合能产生最佳性能，且协同训练能保持视觉-语言模型的理解能力。

Abstract: Large behavior models have shown strong dexterous manipulation capabilities by extending imitation learning to large-scale training on multi-task robot data, yet their generalization remains limited by the insufficient robot data coverage. To expand this coverage without costly additional data collection, recent work relies on co-training: jointly learning from target robot data and heterogeneous data modalities. However, how different co-training data modalities and strategies affect policy performance remains poorly understood. We present a large-scale empirical study examining five co-training data modalities: standard vision-language data, dense language annotations for robot trajectories, cross-embodiment robot data, human videos, and discrete robot action tokens across single- and multi-phase training strategies. Our study leverages 4,000 hours of robot and human manipulation data and 50M vision-language samples to train vision-language-action policies. We evaluate 89 policies over 58,000 simulation rollouts and 2,835 real-world rollouts. Our results show that co-training with forms of vision-language and cross-embodiment robot data substantially improves generalization to distribution shifts, unseen tasks, and language following, while discrete action token variants yield no significant benefits. Combining effective modalities produces cumulative gains and enables rapid adaptation to unseen long-horizon dexterous tasks via fine-tuning. Training exclusively on robot data degrades the visiolinguistic understanding of the vision-language model backbone, while co-training with effective modalities restores these capabilities. Explicitly conditioning action generation on chain-of-thought traces learned from co-training data does not improve performance in our simulation benchmark. Together, these results provide practical guidance for building scalable generalist robot policies.

</details>


### [210] [Estimating Force Interactions of Deformable Linear Objects from their Shapes](https://arxiv.org/abs/2602.01085)
*Qi Jing Chen,Shilin Shan,Timothy Bretl,Quang-Cuong Pham*

Main category: cs.RO

TL;DR: 提出一种仅通过观察变形线性物体形状来检测和估计外部作用力的分析方法，适用于机器人-电线交互任务中的间接接触场景。


<details>
  <summary>Details</summary>
Motivation: 在机器人-电线交互任务中，接触常发生在电线身体而非末端执行器上（如推动电线或电线作为被动障碍物）。准确识别这些交互对安全高效的轨迹规划至关重要，可防止电线损坏、避免受限机器人运动并降低潜在危险。现有方法通常依赖昂贵的外部力-扭矩传感器或假设接触发生在末端执行器。

Method: 利用深度相机获取电线形状信息，假设电线处于或接近静态平衡状态，通过推导的一致性条件和基于电线力-扭矩平衡的线性方程组求解，无需额外先验知识即可估计外部作用力的位置和大小。

Result: 在仿真中实现了高精度估计，在真实世界实验中，在选定的交互场景中展示了准确的估计能力。

Conclusion: 该方法提供了一种仅通过形状观察就能检测和估计变形线性物体上外部作用力的有效途径，适用于机器人间接操纵电线或电线作为环境障碍物的场景，无需昂贵传感器或末端接触假设。

Abstract: This work introduces an analytical approach for detecting and estimating external forces acting on deformable linear objects (DLOs) using only their observed shapes. In many robot-wire interaction tasks, contact occurs not at the end-effector but at other points along the robot's body. Such scenarios arise when robots manipulate wires indirectly (e.g., by nudging) or when wires act as passive obstacles in the environment. Accurately identifying these interactions is crucial for safe and efficient trajectory planning, helping to prevent wire damage, avoid restricted robot motions, and mitigate potential hazards. Existing approaches often rely on expensive external force-torque sensor or that contacts occur at the end-effector for accurate force estimation. Using wire shape information acquired from a depth camera and under the assumption that the wire is in or near its static equilibrium, our method estimates both the location and magnitude of external forces without additional prior knowledge. This is achieved by exploiting derived consistency conditions and solving a system of linear equations based on force-torque balance along the wire. The approach was validated through simulation, where it achieved high accuracy, and through real-world experiments, where accurate estimation was demonstrated in selected interaction scenarios.

</details>


### [211] [Failure-Aware Bimanual Teleoperation via Conservative Value Guided Assistance](https://arxiv.org/abs/2602.01092)
*Peng Zhou,Zhongxuan Li,Jinsong Wu,Jiaming Qi,Jun Hu,David Navarro-Alarcon,Jia Pan,Lihua Xie,Shiyao Zhang,Zeqing Zhang*

Main category: cs.RO

TL;DR: 提出基于保守价值学习的失败感知双手机器人遥操作框架，通过学习离线数据中的成功与失败经验，提供符合性触觉辅助，提高任务成功率并降低操作员负担。


<details>
  <summary>Details</summary>
Motivation: 高精度遥操作受限于严格的成功容差和复杂的接触动力学，在部分可观测条件下，人类操作员难以预测即将发生的失败。需要一种能够感知失败并提供辅助的遥操作框架。

Method: 1. 使用异质离线遥操作数据（包含成功和失败执行）进行训练；2. 通过保守价值学习建模任务可行性，获得风险敏感的成功分数估计；3. 在线操作时，成功分数调节辅助水平，学习到的执行器提供纠正运动方向；4. 通过主端的关节空间阻抗接口集成，提供连续引导而不覆盖操作意图。

Result: 在接触丰富的操作任务中，相比传统遥操作和共享自主基线，提高了任务成功率并减少了操作员工作量。保守价值学习为双边遥操作嵌入失败感知提供了有效机制。

Conclusion: 提出的基于保守价值学习的失败感知框架能够有效提高双手机器人遥操作的性能和用户体验，通过离线学习成功与失败经验，在线提供智能辅助而不损害操作员自主权。

Abstract: Teleoperation of high-precision manipulation is con-strained by tight success tolerances and complex contact dy-namics, which make impending failures difficult for human operators to anticipate under partial observability. This paper proposes a value-guided, failure-aware framework for bimanual teleoperation that provides compliant haptic assistance while pre-serving continuous human authority. The framework is trained entirely from heterogeneous offline teleoperation data containing both successful and failed executions. Task feasibility is mod-eled as a conservative success score learned via Conservative Value Learning, yielding a risk-sensitive estimate that remains reliable under distribution shift. During online operation, the learned success score regulates the level of assistance, while a learned actor provides a corrective motion direction. Both are integrated through a joint-space impedance interface on the master side, yielding continuous guidance that steers the operator away from failure-prone actions without overriding intent. Experimental results on contact-rich manipulation tasks demonstrate improved task success rates and reduced operator workload compared to conventional teleoperation and shared-autonomy baselines, indicating that conservative value learning provides an effective mechanism for embedding failure awareness into bilateral teleoperation. Experimental videos are available at https://www.youtube.com/watch?v=XDTsvzEkDRE

</details>


### [212] [StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating](https://arxiv.org/abs/2602.01100)
*Hang Wu,Tongqing Chen,Jiasen Wang,Xiaotao Li,Lu Fang*

Main category: cs.RO

TL;DR: StreamVLA提出双系统架构，通过"锁定与门控"机制分离高层任务分解与底层控制，减少冗余推理，降低72%时间步的推理延迟，实现高效长时程机器人操作。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在高层规划与底层控制上存在纠缠，每个时间步都进行冗余的多模态推理，导致高延迟和目标不稳定，需要更高效的分层架构。

Method: 提出StreamVLA双系统架构：1) 引入"锁定与门控"机制，仅在子任务转换时触发慢思考生成文本指令和视觉完成状态；2) 完成状态作为时间不变的目标锚点；3) 稳态执行时锁定高层意图，通过流匹配动作头生成动作，绕过72%时间步的自回归解码。

Result: 在LIBERO基准测试中达到98.5%成功率，在真实世界干扰场景中实现鲁棒恢复，相比全推理基线降低48%延迟，显著提升性能与效率。

Conclusion: StreamVLA通过分层抽象有效分离高层规划与底层控制，减少冗余计算，在保持高性能的同时显著降低推理延迟，为长时程机器人操作提供了高效解决方案。

Abstract: Long-horizon robotic manipulation requires bridging the gap between high-level planning (System 2) and low-level control (System 1). Current Vision-Language-Action (VLA) models often entangle these processes, performing redundant multimodal reasoning at every timestep, which leads to high latency and goal instability. To address this, we present StreamVLA, a dual-system architecture that unifies textual task decomposition, visual goal imagination, and continuous action generation within a single parameter-efficient backbone. We introduce a "Lock-and-Gated" mechanism to intelligently modulate computation: only when a sub-task transition is detected, the model triggers slow thinking to generate a textual instruction and imagines the specific visual completion state, rather than generic future frames. Crucially, this completion state serves as a time-invariant goal anchor, making the policy robust to execution speed variations. During steady execution, these high-level intents are locked to condition a Flow Matching action head, allowing the model to bypass expensive autoregressive decoding for 72% of timesteps. This hierarchical abstraction ensures sub-goal focus while significantly reducing inference latency. Extensive evaluations demonstrate that StreamVLA achieves state-of-the-art performance, with a 98.5% success rate on the LIBERO benchmark and robust recovery in real-world interference scenarios, achieving a 48% reduction in latency compared to full-reasoning baselines.

</details>


### [213] [KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV](https://arxiv.org/abs/2602.01115)
*Zhihao Chen,Yiyuan Ge,Ziyang Wang*

Main category: cs.RO

TL;DR: KAN-We-Flow：基于RWKV和KAN的轻量级流匹配策略，用于3D机器人操作，参数减少86.8%，保持快速推理，在多个基准测试中达到SOTA


<details>
  <summary>Details</summary>
Motivation: 基于扩散的视觉运动策略推理效率低，需要多步去噪和大型UNet骨干网络，难以部署在资源受限的机器人上。流匹配方法虽然缓解了采样负担，但现有实现仍使用大型UNet架构。

Method: 提出KAN-We-Flow流匹配策略，结合RWKV和KAN构建轻量级骨干网络：1）RWKV-KAN块：RWKV进行高效时间/通道混合传播任务上下文，GroupKAN层使用可学习样条基的组函数映射进行特征非线性校准；2）动作一致性正则化：通过欧拉外推强制预测动作轨迹与专家演示对齐，提供额外监督稳定训练。

Result: 无需大型UNet，参数减少86.8%，保持快速运行时，在Adroit、Meta-World和DexArt基准测试中达到最先进成功率。

Conclusion: KAN-We-Flow通过结合RWKV和KAN构建轻量高效的流匹配策略骨干网络，配合动作一致性正则化，显著减少参数并提升性能，适合资源受限的机器人部署。

Abstract: Diffusion-based visuomotor policies excel at modeling action distributions but are inference-inefficient, since recursively denoising from noise to policy requires many steps and heavy UNet backbones, which hinders deployment on resource-constrained robots. Flow matching alleviates the sampling burden by learning a one-step vector field, yet prior implementations still inherit large UNet-style architectures. In this work, we present KAN-We-Flow, a flow-matching policy that draws on recent advances in Receptance Weighted Key Value (RWKV) and Kolmogorov-Arnold Networks (KAN) from vision to build a lightweight and highly expressive backbone for 3D manipulation. Concretely, we introduce an RWKV-KAN block: an RWKV first performs efficient time/channel mixing to propagate task context, and a subsequent GroupKAN layer applies learnable spline-based, groupwise functional mappings to perform feature-wise nonlinear calibration of the action mapping on RWKV outputs. Moreover, we introduce an Action Consistency Regularization (ACR), a lightweight auxiliary loss that enforces alignment between predicted action trajectories and expert demonstrations via Euler extrapolation, providing additional supervision to stabilize training and improve policy precision. Without resorting to large UNets, our design reduces parameters by 86.8\%, maintains fast runtime, and achieves state-of-the-art success rates on Adroit, Meta-World, and DexArt benchmarks. Our project page can be viewed in \href{https://zhihaochen-2003.github.io/KAN-We-Flow.github.io/}{\textcolor{red}{link}}

</details>


### [214] [UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors](https://arxiv.org/abs/2602.01153)
*Zhuo Chen,Fei Ni,Kaiyao Luo,Zhiyuan Wu,Xuyang Zhang,Emmanouil Spyrakos-Papastavridis,Lorenzo Jamone,Nathan F. Lepora,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: UniForce是一个统一的触觉表示学习框架，通过联合建模逆动力学和正动力学，学习跨不同触觉传感器的共享潜在力空间，实现零样本迁移到下游机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 触觉传感对于灵巧机器人操作至关重要，但不同触觉传感器（光学、磁性等）在传感原理、外形尺寸和材料上的异质性导致需要传感器特定的数据收集、校准和模型训练，限制了通用性。

Method: 提出UniForce框架，通过联合建模逆动力学（图像到力）和正动力学（力到图像），利用力平衡和图像重建损失约束，学习跨传感器的共享潜在力表示。无需昂贵的外部力/力矩传感器，通过静态平衡和传感器-物体-传感器直接交互收集力配对数据。

Result: 在GelSight、TacTip和uSkin等异构触觉传感器上的实验表明，UniForce在力估计方面优于现有方法，并能在视觉-触觉-语言-动作模型中实现有效的跨传感器协调，成功应用于机器人擦拭任务。

Conclusion: UniForce通过学习统一的触觉表示，解决了触觉传感器异质性带来的泛化问题，实现了零样本迁移到下游任务，为力感知机器人操作提供了通用解决方案。

Abstract: Force sensing is essential for dexterous robot manipulation, but scaling force-aware policy learning is hindered by the heterogeneity of tactile sensors. Differences in sensing principles (e.g., optical vs. magnetic), form factors, and materials typically require sensor-specific data collection, calibration, and model training, thereby limiting generalisability. We propose UniForce, a novel unified tactile representation learning framework that learns a shared latent force space across diverse tactile sensors. UniForce reduces cross-sensor domain shift by jointly modeling inverse dynamics (image-to-force) and forward dynamics (force-to-image), constrained by force equilibrium and image reconstruction losses to produce force-grounded representations. To avoid reliance on expensive external force/torque (F/T) sensors, we exploit static equilibrium and collect force-paired data via direct sensor--object--sensor interactions, enabling cross-sensor alignment with contact force. The resulting universal tactile encoder can be plugged into downstream force-aware robot manipulation tasks with zero-shot transfer, without retraining or finetuning. Extensive experiments on heterogeneous tactile sensors including GelSight, TacTip, and uSkin, demonstrate consistent improvements in force estimation over prior methods, and enable effective cross-sensor coordination in Vision-Tactile-Language-Action (VTLA) models for a robotic wiping task. Code and datasets will be released.

</details>


### [215] [Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models](https://arxiv.org/abs/2602.01166)
*Shuanghao Bai,Jing Lyu,Wanqi Zhou,Zhe Li,Dakai Wang,Lei Xing,Xiaoguang Zhao,Pengwei Wang,Zhongyuan Wang,Cheng Chi,Badong Chen,Shanghang Zhang*

Main category: cs.RO

TL;DR: LaRA-VLA是一个将多模态思维链推理内化到连续潜在表示中的视觉-语言-动作模型，通过潜在空间统一推理和预测，消除推理时的显式思维链生成，实现高效的动作导向控制。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型使用思维链推理时存在高推理开销，且离散推理表示与连续感知和控制不匹配，需要一种更高效、连续的推理范式。

Method: 提出LaRA-VLA框架，通过基于课程学习的训练范式，从显式文本和视觉思维链监督逐步过渡到潜在推理，最后将潜在推理动态适应到动作生成。

Result: 在仿真基准和长时程真实机器人操作任务中，LaRA-VLA始终优于最先进的VLA方法，同时相比显式思维链方法减少高达90%的推理延迟。

Conclusion: 潜在推理是实时具身控制的有效且高效范式，LaRA-VLA通过将推理内化到连续潜在表示中，实现了推理效率和控制性能的显著提升。

Abstract: Vision-Language-Action (VLA) models benefit from chain-of-thought (CoT) reasoning, but existing approaches incur high inference overhead and rely on discrete reasoning representations that mismatch continuous perception and control. We propose Latent Reasoning VLA (\textbf{LaRA-VLA}), a unified VLA framework that internalizes multi-modal CoT reasoning into continuous latent representations for embodied action. LaRA-VLA performs unified reasoning and prediction in latent space, eliminating explicit CoT generation at inference time and enabling efficient, action-oriented control. To realize latent embodied reasoning, we introduce a curriculum-based training paradigm that progressively transitions from explicit textual and visual CoT supervision to latent reasoning, and finally adapts latent reasoning dynamics to condition action generation. We construct two structured CoT datasets and evaluate LaRA-VLA on both simulation benchmarks and long-horizon real-robot manipulation tasks. Experimental results show that LaRA-VLA consistently outperforms state-of-the-art VLA methods while reducing inference latency by up to 90\% compared to explicit CoT-based approaches, demonstrating latent reasoning as an effective and efficient paradigm for real-time embodied control. Project Page: \href{https://loveju1y.github.io/Latent-Reasoning-VLA/}{LaRA-VLA Website}.

</details>


### [216] [SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment](https://arxiv.org/abs/2602.01189)
*Astik Srivastava,Thomas J Chackenkulam. Bitla Bhanu Teja,Antony Thomas,Madhava Krishna*

Main category: cs.RO

TL;DR: 提出一种用于四旋翼无人机在未知动态环境中进行反应式运动规划的无地图框架，结合4D时空规划、视觉安全飞行走廊生成和轨迹优化，通过备份规划模块处理死锁情况。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼无人机在未知环境中与动态障碍物交互时的反应式运动规划问题。现有方法依赖地图融合，计算开销大，且难以直接处理动态障碍物。

Method: 采用无地图框架，结合4D时空规划器与视觉安全飞行走廊生成。通过视觉目标分割和跟踪管道检测动态障碍物，区分静态与动态元素。引入备份规划模块处理死锁情况。

Result: 在仿真和真实硬件实验中验证了方法的有效性，与最先进方法相比，在动态未知环境中表现出显著优势，能够实现反应式避障并降低碰撞风险。

Conclusion: 该无地图反应式运动规划框架能够有效处理四旋翼在未知动态环境中的导航问题，通过视觉感知直接避障，减少计算开销，提高系统鲁棒性。

Abstract: We address the problem of reactive motion planning for quadrotors operating in unknown environments with dynamic obstacles. Our approach leverages a 4-dimensional spatio-temporal planner, integrated with vision-based Safe Flight Corridor (SFC) generation and trajectory optimization. Unlike prior methods that rely on map fusion, our framework is mapless, enabling collision avoidance directly from perception while reducing computational overhead. Dynamic obstacles are detected and tracked using a vision-based object segmentation and tracking pipeline, allowing robust classification of static versus dynamic elements in the scene. To further enhance robustness, we introduce a backup planning module that reactively avoids dynamic obstacles when no direct path to the goal is available, mitigating the risk of collisions during deadlock situations. We validate our method extensively in both simulation and real-world hardware experiments, and benchmark it against state-of-the-art approaches, showing significant advantages for reactive UAV navigation in dynamic, unknown environments.

</details>


### [217] [SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models](https://arxiv.org/abs/2602.01226)
*Aditya Shibu,Marah Saleh,Mohamed Al-Musleh,Nidhal Abdulaziz*

Main category: cs.RO

TL;DR: SkySim是一个ROS2/Gazebo仿真框架，使用LLM进行无人机群高级规划，结合APF安全过滤器确保轨迹安全，实现非专家用户的自然语言控制。


<details>
  <summary>Details</summary>
Motivation: 无人机群在物流、农业和监控等领域有广泛应用，但传统控制方法需要专业知识且缺乏适应性。LLM虽然能实现自然语言控制，但生成的轨迹缺乏物理基础，存在安全隐患。

Method: 开发了基于ROS2和Gazebo的SkySim框架，将LLM高级规划与低级安全执行解耦。使用Gemini 3.5 Pro将用户指令转换为空间航点，结合实时无人机状态。采用人工势场(APF)安全过滤器进行碰撞避免、运动学限制和地理围栏的最小调整，以20Hz频率执行。

Result: 使用3、10、30架Crazyflie无人机进行实验验证：空间推理准确率达到100%（测试几何基元），实现实时碰撞预防，并展示了良好的可扩展性。

Conclusion: SkySim使非专家用户能够迭代优化无人机群行为，将AI认知与机器人安全相结合，适用于动态环境。未来工作将聚焦于硬件集成。

Abstract: Unmanned Aerial Vehicle (UAV) swarms offer versatile applications in logistics, agriculture, and surveillance, yet controlling them requires expert knowledge for safety and feasibility. Traditional static methods limit adaptability, while Large Language Models (LLMs) enable natural language control but generate unsafe trajectories due to lacking physical grounding. This paper introduces SkySim, a ROS2-based simulation framework in Gazebo that decouples LLM high-level planning from low-level safety enforcement. Using Gemini 3.5 Pro, SkySim translates user commands (e.g., "Form a circle") into spatial waypoints, informed by real-time drone states. An Artificial Potential Field (APF) safety filter applies minimal adjustments for collision avoidance, kinematic limits, and geo-fencing, ensuring feasible execution at 20 Hz. Experiments with swarms of 3, 10, and 30 Crazyflie drones validate spatial reasoning accuracy (100% across tested geometric primitives), real-time collision prevention, and scalability. SkySim empowers non-experts to iteratively refine behaviors, bridging AI cognition with robotic safety for dynamic environments. Future work targets hardware integration.

</details>


### [218] [Reinforcement Learning for Active Perception in Autonomous Navigation](https://arxiv.org/abs/2602.01266)
*Grzegorz Malczyk,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出一个端到端强化学习框架，让机器人既能导航避障，又能主动控制相机增强环境感知，实现安全飞行和探索行为


<details>
  <summary>Details</summary>
Motivation: 解决复杂未知环境中自主导航的主动感知挑战，传统方法通常将导航和感知分离，需要更紧密耦合的主动感知策略

Method: 采用端到端强化学习框架，策略接收机器人状态、当前深度帧和局部几何表示；在导航奖励基础上增加基于体素的信息度量，耦合碰撞避免运动规划和信息驱动的主动相机控制

Result: 相比固定非驱动相机基线，该方法实现了更安全的飞行，并诱导出内在的探索行为

Conclusion: 通过强化学习框架将主动相机控制与导航任务耦合，能够在复杂未知环境中实现更安全、更具探索性的自主导航

Abstract: This paper addresses the challenge of active perception within autonomous navigation in complex, unknown environments. Revisiting the foundational principles of active perception, we introduce an end-to-end reinforcement learning framework in which a robot must not only reach a goal while avoiding obstacles, but also actively control its onboard camera to enhance situational awareness. The policy receives observations comprising the robot state, the current depth frame, and a particularly local geometry representation built from a short history of depth readings. To couple collision-free motion planning with information-driven active camera control, we augment the navigation reward with a voxel-based information metric. This enables an aerial robot to learn a robust policy that balances goal-directed motion with exploratory sensing. Extensive evaluation demonstrates that our strategy achieves safer flight compared to using fixed, non-actuated camera baselines while also inducing intrinsic exploratory behaviors.

</details>


### [219] [TriphiBot: A Triphibious Robot Combining FOC-based Propulsion with Eccentric Design](https://arxiv.org/abs/2602.01385)
*Xiangyu Li,Mingwei Lai,Mengke Zhang,Junxiao Lin,Tiancheng Lai,Junping Zhi,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 提出一种新型三栖机器人，通过四旋翼结构加两个被动轮实现空、陆、水三域运动，采用偏心重心设计和统一推进系统解决效率和控制问题。


<details>
  <summary>Details</summary>
Motivation: 现有三栖机器人主要关注双模式平台，存在机械复杂度高或推进效率低的问题，限制了实际应用。需要开发更高效、简洁的三域运动解决方案。

Method: 1. 采用四旋翼结构加两个被动轮的最小化设计；2. 引入偏心重心设计提高地面支撑运动效率；3. 基于磁场定向控制开发统一推进系统；4. 提出混合非线性模型预测控制-PID控制系统。

Result: 实验验证了机器人的多域运动和跨模式转换能力，证明了所提推进系统的效率和适应性，实现了稳定的三栖运动。

Conclusion: 该研究通过简洁设计和先进控制方法，成功实现了高效的三栖机器人平台，为复杂环境下的多域任务提供了有前景的解决方案。

Abstract: Triphibious robots capable of multi-domain motion and cross-domain transitions are promising to handle complex tasks across diverse environments. However, existing designs primarily focus on dual-mode platforms, and some designs suffer from high mechanical complexity or low propulsion efficiency, which limits their application. In this paper, we propose a novel triphibious robot capable of aerial, terrestrial, and aquatic motion, by a minimalist design combining a quadcopter structure with two passive wheels, without extra actuators. To address inefficiency of ground-support motion (moving on land/seabed) for quadcopter based designs, we introduce an eccentric Center of Gravity (CoG) design that inherently aligns thrust with motion, enhancing efficiency without specialized mechanical transformation designs. Furthermore, to address the drastic differences in motion control caused by different fluids (air and water), we develop a unified propulsion system based on Field-Oriented Control (FOC). This method resolves torque matching issues and enables precise, rapid bidirectional thrust across different mediums. Grounded in the perspective of living condition and ground support, we analyse the robot's dynamics and propose a Hybrid Nonlinear Model Predictive Control (HNMPC)-PID control system to ensure stable multi-domain motion and seamless transitions. Experimental results validate the robot's multi-domain motion and cross-mode transition capability, along with the efficiency and adaptability of the proposed propulsion system.

</details>


### [220] [Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation](https://arxiv.org/abs/2602.01389)
*Michele Antonazzi,Lorenzo Signorelli,Matteo Luperto,Nicola Basilico*

Main category: cs.RO

TL;DR: 提出一种利用3D地图生成多视角一致伪标签，并通过基础模型进行实例级精化的无监督域适应方法，用于机器人语义分割网络的部署时自适应。


<details>
  <summary>Details</summary>
Motivation: 语义分割网络在部署环境与训练数据分布不同时性能下降，传统基于多视角一致性的UDA方法对跨视角实例级不一致性敏感。

Method: 从体素3D地图生成多视角一致伪标签，利用基础模型的零样本实例分割能力精化标签以增强实例级一致性，然后进行自监督微调。

Result: 在真实世界数据上的实验表明，该方法相比基于多视角一致性的最先进UDA基线持续提升性能，且无需目标域的真实标签。

Conclusion: 通过结合3D地图和基础模型，提出的方法能有效解决跨视角实例级不一致问题，实现机器人感知系统在部署时的有效自适应。

Abstract: Semantic segmentation networks, which are essential for robotic perception, often suffer from performance degradation when the visual distribution of the deployment environment differs from that of the source dataset on which they were trained. Unsupervised Domain Adaptation (UDA) addresses this challenge by adapting the network to the robot's target environment without external supervision, leveraging the large amounts of data a robot might naturally collect during long-term operation. In such settings, UDA methods can exploit multi-view consistency across the environment's map to fine-tune the model in an unsupervised fashion and mitigate domain shift. However, these approaches remain sensitive to cross-view instance-level inconsistencies. In this work, we propose a method that starts from a volumetric 3D map to generate multi-view consistent pseudo-labels. We then refine these labels using the zero-shot instance segmentation capabilities of a foundation model, enforcing instance-level coherence. The refined annotations serve as supervision for self-supervised fine-tuning, enabling the robot to adapt its perception system at deployment time. Experiments on real-world data demonstrate that our approach consistently improves performance over state-of-the-art UDA baselines based on multi-view consistency, without requiring any ground-truth labels in the target domain.

</details>


### [221] [Sem-NaVAE: Semantically-Guided Outdoor Mapless Navigation via Generative Trajectory Priors](https://arxiv.org/abs/2602.01429)
*Gonzalo Olguin,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出一种无地图的室外全局导航方法，结合CVAE生成轨迹和轻量级VLM进行语义分割，通过自然语言评分选择轨迹，并由局部规划器执行速度指令。


<details>
  <summary>Details</summary>
Motivation: 解决室外环境中无需地图的全局导航问题，利用生成模型和视觉语言模型的能力，实现基于自然语言指令的实时导航。

Method: 使用条件变分自编码器(CVAE)生成多样化轨迹，通过轻量级视觉语言模型(VLM)进行开放词汇语义分割，基于自然语言对轨迹评分选择，最后用最先进的局部规划器执行速度指令。

Result: 在真实室外导航实验中验证了该方法，相比现有最先进方法取得了更优性能，能够实时生成多样化轨迹并导航。

Conclusion: 该方法实现了无需地图的室外全局导航，结合生成模型和语义理解能力，在真实环境中表现出色，为基于自然语言的机器人导航提供了有效解决方案。

Abstract: This work presents a mapless global navigation approach for outdoor applications. It combines the exploratory capacity of conditional variational autoencoders (CVAEs) to generate trajectories and the semantic segmentation capabilities of a lightweight visual language model (VLM) to select the trajectory to execute. Open-vocabulary segmentation is used to score and select the generated trajectories based on natural language, and a state-of-the-art local planner executes velocity commands. One of the key features of the proposed approach is its ability to generate a large variability of trajectories and to select them and navigate in real-time. The approach was validated through real-world outdoor navigation experiments, achieving superior performance compared to state-of-the-art methods. A video showing an experimental run of the system can be found in https://www.youtube.com/watch?v=i3R5ey5O2yk.

</details>


### [222] [Towards a Novel Wearable Robotic Vest for Hemorrhage Suppression](https://arxiv.org/abs/2602.01448)
*Harshith Jella,Pejman Kheradmand,Joseph Klein,Behnam Moradkhani,Yash Chitalia*

Main category: cs.RO

TL;DR: 开发了一种用于紧急止血的机器人系统，具有形状可调的环形机制，可在不同解剖区域调整伤口覆盖范围，并通过充气系统施加恒定压力。


<details>
  <summary>Details</summary>
Motivation: 解决紧急情况下（包括空间站等特殊环境）严重出血的管理问题，需要能够适应不同解剖区域并施加恒定压力的自动化止血设备。

Method: 设计形状可调的环形机制（圆形到椭圆形），开发不同柔韧性的臂以适应非肢体区域，创建与形状变化机制兼容的充气环和气囊系统，通过实验评估臂的弯曲刚度和气囊系统的压力分布。

Result: 成功开发出能够调整形状以适应不同解剖区域的止血机器人，实验验证了各种臂配置的弯曲刚度特性，气囊系统能够施加均匀恒定的压力，在模拟伤员上成功控制了模拟出血。

Conclusion: 该机器人系统在紧急止血方面表现出潜力，但存在覆盖区域限制，形状变化效果仅限于气囊部分充气或放气的情况，无法完全适应复杂的解剖区域，需要进一步改进。

Abstract: This paper introduces a novel robotic system designed to manage severe bleeding in emergency scenarios, including unique environments like space stations. The robot features a shape-adjustable "ring mechanism", transitioning from a circular to an elliptical configuration to adjust wound coverage across various anatomical regions. We developed various arms for this ring mechanism with varying flexibilities to improve adaptability when applied to non-extremities of the body (abdomen, back, neck, etc.). To apply equal and constant pressure across the wound, we developed an inflatable ring and airbag balloon that are compatible with this shape-changing ring mechanism. A series of experiments focused on evaluating various ring arm configurations to characterize their bending stiffness. Subsequent experiments measured the force exerted by the airbag balloon system using a digital scale. Despite its promising performance, certain limitations related to coverage area are identified. The shape-changing effect of the device is limited to scenarios involving partially inflated or deflated airbag balloons, and cannot fully conform to complex anatomical regions. Finally, the device was tested on casualty simulation kits, where it successfully demonstrated its ability to control simulated bleeding.

</details>


### [223] [TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching](https://arxiv.org/abs/2602.01501)
*Minwoo Jung,Nived Chebrolu,Lucas Carvalho de Lima,Haedam Oh,Maurice Fallon,Ayoung Kim*

Main category: cs.RO

TL;DR: TreeLoc是一个基于LiDAR的森林全局定位框架，通过树干特征和分布直方图进行粗匹配，再通过三角形描述符进行细匹配，实现6自由度姿态估计。


<details>
  <summary>Details</summary>
Motivation: 森林环境中GPS信号差，LiDAR测量重复、遮挡且结构复杂，传统城市定位方法假设独特结构特征，在森林中失效，需要专门针对森林环境的鲁棒定位方案。

Method: 使用树干及其胸径(DBH)表示场景，通过树干轴对齐到共同参考系，用树分布直方图(TDH)进行粗匹配，再用2D三角形描述符进行细匹配，最后通过两步几何验证进行姿态估计。

Result: 在多样化森林基准测试中，TreeLoc优于基线方法，实现精确定位。消融研究验证了各组件贡献，并提出了使用紧凑全局树木数据库描述符进行长期森林管理的应用。

Conclusion: TreeLoc为森林环境提供了鲁棒的LiDAR全局定位框架，解决了传统城市定位方法在森林中的局限性，已开源供机器人社区使用。

Abstract: Reliable localization is crucial for navigation in forests, where GPS is often degraded and LiDAR measurements are repetitive, occluded, and structurally complex. These conditions weaken the assumptions of traditional urban-centric localization methods, which assume that consistent features arise from unique structural patterns, necessitating forest-centric solutions to achieve robustness in these environments. To address these challenges, we propose TreeLoc, a LiDAR-based global localization framework for forests that handles place recognition and 6-DoF pose estimation. We represent scenes using tree stems and their Diameter at Breast Height (DBH), which are aligned to a common reference frame via their axes and summarized using the tree distribution histogram (TDH) for coarse matching, followed by fine matching with a 2D triangle descriptor. Finally, pose estimation is achieved through a two-step geometric verification. On diverse forest benchmarks, TreeLoc outperforms baselines, achieving precise localization. Ablation studies validate the contribution of each component. We also propose applications for long-term forest management using descriptors from a compact global tree database. TreeLoc is open-sourced for the robotics community at https://github.com/minwoo0611/TreeLoc.

</details>


### [224] [RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots](https://arxiv.org/abs/2602.01515)
*Humphrey Munn,Brendan Tidd,Peter Bohm,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: RAPT：用于人形机器人控制的轻量级自监督部署监控系统，提供可靠的异常检测和可解释的故障诊断


<details>
  <summary>Details</summary>
Motivation: 人形机器人部署学习控制策略面临挑战：仿真中鲁棒的策略在Sim-to-Real转移后可能在分布外状态下自信执行，导致硬件损坏风险。现有异常检测方法要么与高速控制不兼容，要么在极低误报率要求下校准不佳，要么作为黑盒仅提供二元停止信号而无法解释故障原因。

Method: RAPT从仿真中学习名义执行的概率时空流形，评估执行时预测偏差作为校准的逐维度信号。系统包括：1）基于重建目标的梯度时间显著性分析；2）结合显著性和关节运动学的LLM推理，在零样本设置下生成语义故障诊断。

Result: 在仿真中，RAPT在固定0.5%误报率下将真阳性率提升37%；在真实部署中，真阳性率提升12.5%，仅使用本体感知数据在16个真实故障中达到75%的根因分类准确率，提供可操作的故障解释。

Conclusion: RAPT为高速人形机器人控制提供了可靠、可解释的部署监控方案，不仅能有效检测异常，还能通过自动化根因分析提供语义故障诊断，显著提升机器人部署的安全性和可调试性。

Abstract: Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data.

</details>


### [225] [Co-Design of Rover Wheels and Control using Bayesian Optimization and Rover-Terrain Simulations](https://arxiv.org/abs/2602.01535)
*Huzaifa Mustafa Unjhawala,Khizar Shaikh,Luning Bakke,Radu Serban,Dan Negrut*

Main category: cs.RO

TL;DR: 提出贝叶斯优化框架，联合优化越野车车轮几何与转向控制器参数，使用连续介质模型进行全车闭环仿真，相比传统DEM方法大幅提升效率


<details>
  <summary>Details</summary>
Motivation: 传统DEM仿真成本高，通常只能进行单轮测试，无法考虑车轮-车辆-控制器的耦合作用，限制了全车系统优化

Method: 使用连续介质模型(CRM)进行高效高保真仿真，贝叶斯优化框架同时优化车轮参数(半径、宽度、抓地齿特征)和转向PID增益，采用多目标优化平衡行驶速度、跟踪误差和能耗

Result: 3000次全车仿真在5-9天内完成，相比之前DEM方法需要数月；同时优化策略优于顺序优化；硬件初步验证显示仿真优化设计在物理平台上保持相对性能趋势

Conclusion: 可扩展的高保真仿真可实现越野车车轮设计与控制的实用联合优化，无需依赖昂贵的DEM研究，开源仿真基础设施支持可重复性和进一步研究

Abstract: While simulation is vital for optimizing robotic systems, the cost of modeling deformable terrain has long limited its use in full-vehicle studies of off-road autonomous mobility. For example, Discrete Element Method (DEM) simulations are often confined to single-wheel tests, which obscures coupled wheel-vehicle-controller interactions and prevents joint optimization of mechanical design and control. This paper presents a Bayesian optimization framework that co-designs rover wheel geometry and steering controller parameters using high-fidelity, full-vehicle closed-loop simulations on deformable terrain. Using the efficiency and scalability of a continuum-representation model (CRM) for terramechanics, we evaluate candidate designs on trajectories of varying complexity while towing a fixed load. The optimizer tunes wheel parameters (radius, width, and grouser features) and steering PID gains under a multi-objective formulation that balances traversal speed, tracking error, and energy consumption. We compare two strategies: simultaneous co-optimization of wheel and controller parameters versus a sequential approach that decouples mechanical and control design. We analyze trade-offs in performance and computational cost. Across 3,000 full-vehicle simulations, campaigns finish in five to nine days, versus months with the group's earlier DEM-based workflow. Finally, a preliminary hardware study suggests the simulation-optimized wheel designs preserve relative performance trends on the physical rover. Together, these results show that scalable, high-fidelity simulation can enable practical co-optimization of wheel design and control for off-road vehicles on deformable terrain without relying on prohibitively expensive DEM studies. The simulation infrastructure (scripts and models) is released as open source in a public repository to support reproducibility and further research.

</details>


### [226] [UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning](https://arxiv.org/abs/2602.01536)
*Shuai Liu,Siheng Ren,Xiaoyao Zhu,Quanmin Liang,Zefeng Li,Qiang Li,Xin Hu,Kai Huang*

Main category: cs.RO

TL;DR: UniDWM是一个统一的驾驶世界模型，通过多面表示学习构建结构和动态感知的潜在世界表示，用于自动驾驶的感知、预测和规划。


<details>
  <summary>Details</summary>
Motivation: 在复杂驾驶环境中实现可靠高效的规划需要一个能够推理场景几何、外观和动态的模型。现有方法通常将这些方面分开处理，需要一个统一的框架来整合这些要素。

Method: 构建结构和动态感知的潜在世界表示作为物理基础的状态空间。采用联合重建路径学习恢复场景结构（几何和视觉纹理），同时使用条件扩散变换器的协作生成框架在潜在空间中预测未来世界演化。该模型可视为VAE的变体，为多面表示学习提供理论指导。

Result: 实验证明UniDWM在轨迹规划、4D重建和生成方面的有效性，展示了多面世界表示作为统一驾驶智能基础的潜力。

Conclusion: UniDWM通过统一的多面表示学习为自动驾驶提供了一个强大的世界模型框架，能够一致地处理感知、预测和规划任务，为统一驾驶智能奠定了基础。

Abstract: Achieving reliable and efficient planning in complex driving environments requires a model that can reason over the scene's geometry, appearance, and dynamics. We present UniDWM, a unified driving world model that advances autonomous driving through multifaceted representation learning. UniDWM constructs a structure- and dynamic-aware latent world representation that serves as a physically grounded state space, enabling consistent reasoning across perception, prediction, and planning. Specifically, a joint reconstruction pathway learns to recover the scene's structure, including geometry and visual texture, while a collaborative generation framework leverages a conditional diffusion transformer to forecast future world evolution within the latent space. Furthermore, we show that our UniDWM can be deemed as a variation of VAE, which provides theoretical guidance for the multifaceted representation learning. Extensive experiments demonstrate the effectiveness of UniDWM in trajectory planning, 4D reconstruction and generation, highlighting the potential of multifaceted world representations as a foundation for unified driving intelligence. The code will be publicly available at https://github.com/Say2L/UniDWM.

</details>


### [227] [A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation](https://arxiv.org/abs/2602.01632)
*Chuizheng Kong,Yunho Cho,Wonsuhk Jung,Idris Wibowo,Parth Shinde,Sundhar Vinodh-Sangeetha,Long Kiu Chung,Zhenyang Chen,Andrew Mattei,Advaith Nidumukkala,Alexander Elias,Danfei Xu,Taylor Higgins,Shreyas Kousik*

Main category: cs.RO

TL;DR: SEW-Mimic：一种基于肩-肘-腕关键点的闭式几何解算法，将人体运动重定向到机器人姿态，实现高速（3kHz）且最优的机器人遥操作。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动到机器人姿态的重定向方法存在优化速度慢、运动不自然、工作空间受限等问题，需要一种更高效、更优的解决方案。

Method: 将重定向问题重新定义为方向对齐问题，利用肩、肘、腕关键点识别人体上下臂方向，通过闭式几何算法实现机器人臂与人体臂方向的对齐。

Result: SEW-Mimic在计算时间（3kHz）和精度上优于其他方法，用户研究表明能提高遥操作任务成功率，收集的数据更平滑有助于策略学习。

Conclusion: SEW-Mimic是双手机器人操作和人形机器人遥操作的基础构建模块，具有实际应用价值。

Abstract: Retargeting human motion to robot poses is a practical approach for teleoperating bimanual humanoid robot arms, but existing methods can be suboptimal and slow, often causing undesirable motion or latency. This is due to optimizing to match robot end-effector to human hand position and orientation, which can also limit the robot's workspace to that of the human. Instead, this paper reframes retargeting as an orientation alignment problem, enabling a closed-form, geometric solution algorithm with an optimality guarantee. The key idea is to align a robot arm to a human's upper and lower arm orientations, as identified from shoulder, elbow, and wrist (SEW) keypoints; hence, the method is called SEW-Mimic. The method has fast inference (3 kHz) on standard commercial CPUs, leaving computational overhead for downstream applications; an example in this paper is a safety filter to avoid bimanual self-collision. The method suits most 7-degree-of-freedom robot arms and humanoids, and is agnostic to input keypoint source. Experiments show that SEW-Mimic outperforms other retargeting methods in computation time and accuracy. A pilot user study suggests that the method improves teleoperation task success. Preliminary analysis indicates that data collected with SEW-Mimic improves policy learning due to being smoother. SEW-Mimic is also shown to be a drop-in way to accelerate full-body humanoid retargeting. Finally, hardware demonstrations illustrate SEW-Mimic's practicality. The results emphasize the utility of SEW-Mimic as a fundamental building block for bimanual robot manipulation and humanoid robot teleoperation.

</details>


### [228] [AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act](https://arxiv.org/abs/2602.01662)
*Pengyuan Guo,Zhonghao Mai,Zhengtong Xu,Kaidi Zhang,Heng Zhang,Zichen Miao,Arash Ajoudani,Zachary Kingston,Qiang Qiu,Yu She*

Main category: cs.RO

TL;DR: AgenticLab是一个模型无关的机器人代理平台和基准测试，用于评估大型视觉语言模型在真实机器人开放世界操作任务中的表现，揭示了离线测试无法捕捉的多种失败模式。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型在开放词汇感知和推理方面取得了进展，但它们在真实机器人长时程、闭环、非结构化环境中的操作能力仍不清楚。现有VLM操作管道难以在不同研究组之间比较，且许多评估依赖仿真、特权状态或特殊设计环境。

Method: 提出了AgenticLab平台，提供感知、任务分解、在线验证和重规划的闭环代理管道。使用该平台在非结构化环境中对最先进的VLM代理进行真实机器人任务基准测试。

Result: 基准测试揭示了离线视觉语言测试（如VQA和静态图像理解）无法捕捉的多种失败模式，包括多步接地一致性崩溃、遮挡和场景变化下的对象接地问题，以及可靠操作所需的空间推理不足。

Conclusion: AgenticLab平台支持可重复评估并加速通用机器人代理研究，将发布完整的硬件和软件栈以促进该领域发展。

Abstract: Recent advances in large vision-language models (VLMs) have demonstrated generalizable open-vocabulary perception and reasoning, yet their real-robot manipulation capability remains unclear for long-horizon, closed-loop execution in unstructured, in-the-wild environments. Prior VLM-based manipulation pipelines are difficult to compare across different research groups' setups, and many evaluations rely on simulation, privileged state, or specially designed setups. We present AgenticLab, a model-agnostic robot agent platform and benchmark for open-world manipulation. AgenticLab provides a closed-loop agent pipeline for perception, task decomposition, online verification, and replanning. Using AgenticLab, we benchmark state-of-the-art VLM-based agents on real-robot tasks in unstructured environments. Our benchmark reveals several failure modes that offline vision-language tests (e.g., VQA and static image understanding) fail to capture, including breakdowns in multi-step grounding consistency, object grounding under occlusion and scene changes, and insufficient spatial reasoning for reliable manipulation. We will release the full hardware and software stack to support reproducible evaluation and accelerate research on general-purpose robot agents.

</details>


### [229] [Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications](https://arxiv.org/abs/2602.01679)
*Raghavasimhan Sankaranarayanan,Paul Stuart,Nicholas Ahn,Arno Sungarian,Yash Chitalia*

Main category: cs.RO

TL;DR: 开发了一套全自动机器人系统，用于在无菌处理与分发部门自动分类和结构性地包装手术器械到无菌托盘中，减少人工错误和器械碰撞。


<details>
  <summary>Details</summary>
Motivation: SPD部门手工检查和准备器械托盘耗时、易出错，容易导致污染和器械损坏，需要自动化解决方案来提高安全性、一致性和效率。

Method: 采用混合感知管道（YOLO12检测+级联ResNet细粒度分类），结合校准视觉模块、6自由度机器人臂、定制双电磁夹爪，以及基于规则的包装算法和3D打印分隔器。

Result: 系统感知准确率高，与人工组装的托盘相比，器械间碰撞显著减少，为自动化SPD工作流程提供了可扩展的第一步。

Conclusion: 该系统是自动化SPD工作流程的重要进展，能提高手术准备的安全性和一致性，同时减少处理时间，具有实际应用价值。

Abstract: The Sterile Processing and Distribution (SPD) department is responsible for cleaning, disinfecting, inspecting, and assembling surgical instruments between surgeries. Manual inspection and preparation of instrument trays is a time-consuming, error-prone task, often prone to contamination and instrument breakage. In this work, we present a fully automated robotic system that sorts and structurally packs surgical instruments into sterile trays, focusing on automation of the SPD assembly stage. A custom dataset comprising 31 surgical instruments and 6,975 annotated images was collected to train a hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification. The system integrates a calibrated vision module, a 6-DOF Staubli TX2-60L robotic arm with a custom dual electromagnetic gripper, and a rule-based packing algorithm that reduces instrument collisions during transport. The packing framework uses 3D printed dividers and holders to physically isolate instruments, reducing collision and friction during transport. Experimental evaluations show high perception accuracy and statistically significant reduction in tool-to-tool collisions compared to human-assembled trays. This work serves as the scalable first step toward automating SPD workflows, improving safety, and consistency of surgical preparation while reducing SPD processing times.

</details>


### [230] [GSR: Learning Structured Reasoning for Embodied Manipulation](https://arxiv.org/abs/2602.01693)
*Kewei Hu,Michael Zhang,Wei Ying,Tianhao Liu,Guoqiang Hao,Zimeng Li,Wanchan Yu,Jiajian Jing,Fangwen Chen,Hanwen Kang*

Main category: cs.RO

TL;DR: 提出GSR方法，通过基于场景图的结构化推理来提升具身智能体的长时程操作能力，显著改善了零样本泛化和任务完成效果。


<details>
  <summary>Details</summary>
Motivation: 现有具身智能体在需要保持空间一致性、因果依赖和目标约束的长时程操作任务中表现不佳，主要问题是任务推理隐含在高维潜在表示中，难以将任务结构与感知变异性分离。

Method: 提出Grounded Scene-graph Reasoning (GSR)方法，将世界状态演化建模为语义基础场景图的转换，通过逐步推理对象状态和空间关系来显式推理动作前提、后果和目标满足。构建Manip-Cognition-1.6M大规模数据集来支持学习。

Result: 在RLBench、LIBERO、GSR-benchmark和真实世界机器人任务上的广泛评估表明，GSR相比基于提示的基线方法显著改善了零样本泛化和长时程任务完成效果。

Conclusion: 显式的世界状态表示是构建可扩展具身推理的关键归纳偏置，结构化推理范式为具身智能提供了有前景的方向。

Abstract: Despite rapid progress, embodied agents still struggle with long-horizon manipulation that requires maintaining spatial consistency, causal dependencies, and goal constraints. A key limitation of existing approaches is that task reasoning is implicitly embedded in high-dimensional latent representations, making it challenging to separate task structure from perceptual variability. We introduce Grounded Scene-graph Reasoning (GSR), a structured reasoning paradigm that explicitly models world-state evolution as transitions over semantically grounded scene graphs. By reasoning step-wise over object states and spatial relations, rather than directly mapping perception to actions, GSR enables explicit reasoning about action preconditions, consequences, and goal satisfaction in a physically grounded space. To support learning such reasoning, we construct Manip-Cognition-1.6M, a large-scale dataset that jointly supervises world understanding, action planning, and goal interpretation. Extensive evaluations across RLBench, LIBERO, GSR-benchmark, and real-world robotic tasks show that GSR significantly improves zero-shot generalization and long-horizon task completion over prompting-based baselines. These results highlight explicit world-state representations as a key inductive bias for scalable embodied reasoning.

</details>


### [231] [Tilt-Ropter: A Novel Hybrid Aerial and Terrestrial Vehicle with Tilt Rotors and Passive Wheels](https://arxiv.org/abs/2602.01700)
*Ruoyu Wang,Xuchen Liu,Zongzhou Wu,Zixuan Guo,Wendi Ding,Ben M. Chen*

Main category: cs.RO

TL;DR: Tilt-Ropter是一种新型混合空中-地面车辆，通过倾斜旋翼和被动轮实现高效多模式运动，采用全驱动设计和NMPC控制，地面运动能耗降低92.8%


<details>
  <summary>Details</summary>
Motivation: 现有混合空中-地面车辆多为欠驱动设计，限制了运动能力和环境适应性。需要开发全驱动系统以实现解耦的力和扭矩控制，提高移动性和能源效率，适应大规模、能源受限环境下的长时任务。

Method: 1. 设计全驱动混合车辆Tilt-Ropter，结合倾斜旋翼和被动轮；2. 开发非线性模型预测控制器跟踪参考轨迹并处理接触约束；3. 设计控制分配模块利用驱动冗余实现能耗优化；4. 引入外部力矩估计算法实时估计环境交互力，增强地面接触鲁棒性。

Result: 通过仿真和真实实验验证，系统实现了无缝空-地转换和轨迹跟踪。结果显示两种模式下跟踪误差都很低，地面运动功耗降低了92.8%，证明了系统在大规模能源受限环境中执行长时任务的潜力。

Conclusion: Tilt-Ropter的全驱动设计和先进控制策略显著提高了混合空中-地面车辆的移动性、环境适应性和能源效率，为长时、大规模任务提供了有前景的解决方案。

Abstract: In this work, we present Tilt-Ropter, a novel hybrid aerial-terrestrial vehicle (HATV) that combines tilt rotors with passive wheels to achieve energy-efficient multi-mode locomotion. Unlike existing under-actuated HATVs, the fully actuated design of Tilt-Ropter enables decoupled force and torque control, greatly enhancing its mobility and environmental adaptability. A nonlinear model predictive controller (NMPC) is developed to track reference trajectories and handle contact constraints across locomotion modes, while a dedicated control allocation module exploits actuation redundancy to achieve energy-efficient control of actuators. Additionally, to enhance robustness during ground contact, we introduce an external wrench estimation algorithm that estimates environmental interaction forces and torques in real time. The system is validated through both simulation and real-world experiments, including seamless air-ground transitions and trajectory tracking. Results show low tracking errors in both modes and highlight a 92.8% reduction in power consumption during ground locomotion, demonstrating the system's potential for long-duration missions across large-scale and energy-constrained environments.

</details>


### [232] [Uncertainty-Aware Non-Prehensile Manipulation with Mobile Manipulators under Object-Induced Occlusion](https://arxiv.org/abs/2602.01731)
*Jiwoo Hwang,Taegeun Yang,Jeil Jeong,Minsung Yoon,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: CURA-PPO：一种强化学习框架，通过显式建模部分可观测性下的不确定性，解决非抓取操作中传感器被遮挡的问题，实现安全导航和主动感知。


<details>
  <summary>Details</summary>
Motivation: 非抓取操作中，被操作物体会遮挡机载传感器的视野，形成遮挡区域，可能导致碰撞。现有方法难以在严重传感器遮挡下实现安全操作。

Method: 提出CURA-PPO强化学习框架，通过预测碰撞可能性分布来提取风险和不确定性，引导机器人动作。不确定性项鼓励主动感知，结合捕捉观测可靠性的置信度地图，实现遮挡下的安全导航。

Result: 在不同物体大小和障碍物配置的广泛实验中，CURA-PPO相比基线方法实现了高达3倍的成功率提升，学习到的行为能够有效处理遮挡问题。

Conclusion: 该方法为仅使用机载传感器在杂乱环境中进行自主操作提供了实用解决方案，通过显式建模不确定性和主动感知，实现了遮挡下的安全操作。

Abstract: Non-prehensile manipulation using onboard sensing presents a fundamental challenge: the manipulated object occludes the sensor's field of view, creating occluded regions that can lead to collisions. We propose CURA-PPO, a reinforcement learning framework that addresses this challenge by explicitly modeling uncertainty under partial observability. By predicting collision possibility as a distribution, we extract both risk and uncertainty to guide the robot's actions. The uncertainty term encourages active perception, enabling simultaneous manipulation and information gathering to resolve occlusions. When combined with confidence maps that capture observation reliability, our approach enables safe navigation despite severe sensor occlusion. Extensive experiments across varying object sizes and obstacle configurations demonstrate that CURA-PPO achieves up to 3X higher success rates than the baselines, with learned behaviors that handle occlusions. Our method provides a practical solution for autonomous manipulation in cluttered environments using only onboard sensing.

</details>


### [233] [RFS: Reinforcement learning with Residual flow steering for dexterous manipulation](https://arxiv.org/abs/2602.01789)
*Entong Su,Tyler Westenbroek,Anusha Nagabandi,Abhishek Gupta*

Main category: cs.RO

TL;DR: 提出Residual Flow Steering (RFS)框架，通过联合优化残差动作和潜在噪声分布来微调预训练的流匹配策略，实现局部精炼和全局探索的互补，在灵巧操作任务中高效适应


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人序列决策中表现出色，但预训练的生成式策略泛化能力有限，需要额外微调才能获得鲁棒性能。适应过程需要保持预训练的全局探索优势，同时能够快速纠正局部执行错误

Method: 提出Residual Flow Steering (RFS)框架，通过联合优化残差动作和潜在噪声分布来引导预训练的流匹配策略。残差修正实现局部精炼，潜在空间调制实现全局探索，保留预训练策略的表达结构

Result: 在灵巧操作任务中验证了RFS的有效性，在仿真和真实世界环境中都能高效微调预训练的基础策略

Conclusion: RFS为适应预训练的生成式策略提供了一个数据高效的强化学习框架，能够保持预训练策略的全局探索优势，同时实现局部错误的快速纠正，在灵巧操作任务中展现出高效适应能力

Abstract: Imitation learning has emerged as an effective approach for bootstrapping sequential decision-making in robotics, achieving strong performance even in high-dimensional dexterous manipulation tasks. Recent behavior cloning methods further leverage expressive generative models, such as diffusion models and flow matching, to represent multimodal action distributions. However, policies pretrained in this manner often exhibit limited generalization and require additional fine-tuning to achieve robust performance at deployment time. Such adaptation must preserve the global exploration benefits of pretraining while enabling rapid correction of local execution errors.We propose \emph{Residual Flow Steering} (RFS), a data-efficient reinforcement learning framework for adapting pretrained generative policies. RFS steers a pretrained flow-matching policy by jointly optimizing a residual action and a latent noise distribution, enabling complementary forms of exploration: local refinement through residual corrections and global exploration through latent-space modulation. This design allows efficient adaptation while retaining the expressive structure of the pretrained policy.We demonstrate the effectiveness of RFS on dexterous manipulation tasks, showing efficient fine-tuning both in simulation and in real-world settings when adapting pretrained base policies.Project website:https://weirdlabuw.github.io/rfs.

</details>


### [234] [From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models](https://arxiv.org/abs/2602.01811)
*Wentao Zhang,Aolan Sun,Wentao Mo,Xiaoyang Qu,Yuxin Zheng,Jianzong Wang*

Main category: cs.RO

TL;DR: VLA-SCT：一个轻量级、无需训练的自校正控制框架，通过数据驱动的动作精炼和条件终止逻辑，解决VLA模型在抓取任务中的空间偏差和任务完成识别问题


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型存在两个关键弱点：1）抓取任务中语言模型生成的动作令牌存在空间偏差导致抓取失败；2）缺乏可靠的任务完成识别能力，导致冗余操作和超时错误

Method: 提出VLA-SCT框架，作为自校正控制循环，结合数据驱动的动作精炼和条件终止逻辑，无需额外训练

Result: 在LIBERO基准测试的所有数据集上都取得了持续改进，显著提高了精细操作任务的成功率，确保准确的任务完成

Conclusion: VLA-SCT框架增强了VLA模型的鲁棒性，促进了更可靠的VLA智能体在复杂非结构化环境中的部署

Abstract: While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments.

</details>


### [235] [Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models](https://arxiv.org/abs/2602.01834)
*Siqi Wen,Shu Yang,Shaopeng Fu,Jingfeng Zhang,Lijie Hu,Di Wang*

Main category: cs.RO

TL;DR: 提出基于概念字典学习的推理时安全控制框架，用于保护视觉语言动作模型免受攻击，在保持任务成功率的同时将攻击成功率降低70%以上。


<details>
  <summary>Details</summary>
Motivation: 视觉语言动作模型将多模态指令转化为可执行行为，但这种能力放大了安全风险：原本仅产生有毒文本的越狱攻击可能触发物理系统的不安全行为。现有防御方法（对齐、过滤或提示强化）介入太晚或在错误模态上操作，使得融合表示仍然可被利用。

Method: 引入基于概念的字典学习框架，从隐藏激活中构建稀疏、可解释的字典，识别有害概念方向，并应用基于阈值的干预来抑制或阻止不安全激活。该方法无需重新训练，可即插即用且模型无关。

Result: 在Libero-Harm、BadRobot、RoboPair和IS-Bench等数据集上的实验表明，该方法实现了最先进的防御性能，将攻击成功率降低超过70%，同时保持任务成功率。

Conclusion: 这是首个面向具身系统的推理时基于概念的安全方法，推进了VLA模型的可解释性和安全部署。该框架是即插即用且模型无关的，无需重新训练即可与各种VLA模型无缝集成。

Abstract: Vision Language Action (VLA) models close the perception action loop by translating multimodal instructions into executable behaviors, but this very capability magnifies safety risks: jailbreaks that merely yield toxic text in LLMs can trigger unsafe physical actions in embodied systems. Existing defenses alignment, filtering, or prompt hardening intervene too late or at the wrong modality, leaving fused representations exploitable. We introduce a concept-based dictionary learning framework for inference-time safety control. By constructing sparse, interpretable dictionaries from hidden activations, our method identifies harmful concept directions and applies threshold-based interventions to suppress or block unsafe activations. Experiments on Libero-Harm, BadRobot, RoboPair, and IS-Bench show that our approach achieves state-of-the-art defense performance, cutting attack success rates by over 70\% while maintaining task success. Crucially, the framework is plug-in and model-agnostic, requiring no retraining and integrating seamlessly with diverse VLAs. To our knowledge, this is the first inference-time concept-based safety method for embodied systems, advancing both interpretability and safe deployment of VLA models.

</details>


### [236] [Vision-only UAV State Estimation for Fast Flights Without External Localization Systems: A2RL Drone Racing Finalist Approach](https://arxiv.org/abs/2602.01860)
*Filip Novák,Matěj Petrlík,Matej Novosad,Parakh M. Gupta,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出一种用于高速无人机在GNSS拒止环境中的状态估计方法，融合视觉-惯性里程计、地标相机测量和IMU，通过新颖的漂移模型校正VIO漂移，实现快速机动下的精确状态估计。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止的复杂环境中进行高速、激进机动的无人机需要快速、可靠、准确的状态估计。现有方法通常依赖更复杂的硬件（如立体相机或测距仪），且使用未校正的漂移VIO速度、姿态和角速度，导致快速机动时产生误差。

Method: 使用单目RGB相机和IMU，融合视觉-惯性里程计（VIO）、基于地标的机载相机测量系统和IMU数据。通过新颖的数学漂移模型估计并补偿VIO漂移，校正所有VIO状态（位置、姿态、线速度和角速度）。

Result: 通过1600次仿真和大量真实世界实验验证。在A2RL无人机竞速挑战赛2025中，团队从210支队伍中晋级前四并获得奖牌，证明了方法的有效性。

Conclusion: 该方法能够在GNSS拒止的复杂环境中，仅使用单目相机和IMU实现高速无人机在快速机动下的准确状态估计，相比依赖更复杂硬件的现有方法具有优势，并在实际竞赛中证明了其性能。

Abstract: Fast flights with aggressive maneuvers in cluttered GNSS-denied environments require fast, reliable, and accurate UAV state estimation. In this paper, we present an approach for onboard state estimation of a high-speed UAV using a monocular RGB camera and an IMU. Our approach fuses data from Visual-Inertial Odometry (VIO), an onboard landmark-based camera measurement system, and an IMU to produce an accurate state estimate. Using onboard measurement data, we estimate and compensate for VIO drift through a novel mathematical drift model. State-of-the-art approaches often rely on more complex hardware (e.g., stereo cameras or rangefinders) and use uncorrected drifting VIO velocities, orientation, and angular rates, leading to errors during fast maneuvers. In contrast, our method corrects all VIO states (position, orientation, linear and angular velocity), resulting in accurate state estimation even during rapid and dynamic motion. Our approach was thoroughly validated through 1600 simulations and numerous real-world experiments. Furthermore, we applied the proposed method in the A2RL Drone Racing Challenge 2025, where our team advanced to the final four out of 210 teams and earned a medal.

</details>


### [237] [BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models](https://arxiv.org/abs/2602.01870)
*Riccardo Andrea Izzo,Gianluca Bardaro,Matteo Matteucci*

Main category: cs.RO

TL;DR: 提出BTGenBot-2，一个1B参数的开源小语言模型，能够将自然语言任务描述直接转换为可执行的行为树XML，解决现有方法闭源、计算量大、缺乏标准化表示的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的机器人任务规划存在两个主要问题：1) 现有方法通常是闭源的或计算密集型的，难以在实际物理系统上部署；2) 缺乏通用的即插即用表示方法用于机器人任务生成。

Method: 提出BTGenBot-2模型，这是一个1B参数的开源小语言模型，能够直接将自然语言任务描述和机器人动作原语列表转换为XML格式的可执行行为树。支持零样本生成、推理和运行时错误恢复，同时保持轻量级以适应资源受限的机器人。

Result: 在NVIDIA Isaac Sim的52个导航和操作任务基准测试中，BTGenBot-2在零样本设置下平均成功率90.38%，一样本设置下98.07%，优于GPT-5、Claude Opus 4.1和更大的开源模型，推理速度比前代BTGenBot快16倍。

Conclusion: BTGenBot-2提供了一个轻量级、开源的解决方案，能够高效地将自然语言转换为可执行的行为树，解决了现有LLM机器人规划方法的部署挑战，并通过标准化基准推动了该领域的发展。

Abstract: Recent advances in robot learning increasingly rely on LLM-based task planning, leveraging their ability to bridge natural language with executable actions. While prior works showcased great performances, the widespread adoption of these models in robotics has been challenging as 1) existing methods are often closed-source or computationally intensive, neglecting the actual deployment on real-world physical systems, and 2) there is no universally accepted, plug-and-play representation for robotic task generation. Addressing these challenges, we propose BTGenBot-2, a 1B-parameter open-source small language model that directly converts natural language task descriptions and a list of robot action primitives into executable behavior trees in XML. Unlike prior approaches, BTGenBot-2 enables zero-shot BT generation, error recovery at inference and runtime, while remaining lightweight enough for resource-constrained robots. We further introduce the first standardized benchmark for LLM-based BT generation, covering 52 navigation and manipulation tasks in NVIDIA Isaac Sim. Extensive evaluations demonstrate that BTGenBot-2 consistently outperforms GPT-5, Claude Opus 4.1, and larger open-source models across both functional and non-functional metrics, achieving average success rates of 90.38% in zero-shot and 98.07% in one-shot, while delivering up to 16x faster inference compared to the previous BTGenBot.

</details>


### [238] [Multimodal Large Language Models for Real-Time Situated Reasoning](https://arxiv.org/abs/2602.01880)
*Giulio Antonio Abbo,Senne Lenaerts,Tony Belpaeme*

Main category: cs.RO

TL;DR: 将GPT-4o多模态大语言模型与TurtleBot 4机器人平台结合，模拟智能吸尘机器人在家庭环境中进行实时上下文和价值感知的决策，判断何时适合开始清洁。


<details>
  <summary>Details</summary>
Motivation: 探索多模态大语言模型如何支持实时上下文和价值感知的决策，特别是在家庭环境中，机器人需要理解家庭活动、社会规范和用户偏好，做出符合清洁、舒适和安全等价值观的细致决策。

Method: 将GPT-4o语言模型与TurtleBot 4平台集成，模拟智能吸尘机器人。模型通过视觉输入评估环境，判断是否适合启动清洁，系统能够推理家庭活动、社会规范和用户偏好。

Result: 在真实家庭环境中演示了系统从有限视觉输入推断上下文和价值的能力，展示了多模态大语言模型在增强机器人自主性和情境感知方面的潜力，同时也揭示了在一致性、偏见和实时性能方面的挑战。

Conclusion: 多模态大语言模型在提升机器人自主决策和情境感知方面具有前景，能够进行复杂的价值观对齐决策，但仍需解决一致性、偏见和实时性能等挑战。

Abstract: In this work, we explore how multimodal large language models can support real-time context- and value-aware decision-making. To do so, we combine the GPT-4o language model with a TurtleBot 4 platform simulating a smart vacuum cleaning robot in a home. The model evaluates the environment through vision input and determines whether it is appropriate to initiate cleaning. The system highlights the ability of these models to reason about domestic activities, social norms, and user preferences and take nuanced decisions aligned with the values of the people involved, such as cleanliness, comfort, and safety. We demonstrate the system in a realistic home environment, showing its ability to infer context and values from limited visual input. Our results highlight the promise of multimodal large language models in enhancing robotic autonomy and situational awareness, while also underscoring challenges related to consistency, bias, and real-time performance.

</details>


### [239] [Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study](https://arxiv.org/abs/2602.01892)
*Alexandre Lombard,Florent Perronnet,Nicolas Gaud,Abdeljalil Abbas-Turki*

Main category: cs.RO

TL;DR: 提出一种用于自动驾驶车辆的路径跟踪框架，通过动态控制点实现前后轴控制的平滑插值，结合曲率感知的纵向控制，在仿真和实车测试中表现出更好的轨迹精度和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统路径跟踪方法通常将控制点固定在车辆前轴或后轴，这种固定控制点在低速机动和倒车等不同驾驶场景下适应性有限。需要一种能够平滑适应不同驾驶环境的控制框架。

Method: 1) 横向控制：采用动态控制点，通过重心插值混合前轴Stanley控制器和后轴曲率几何控制器；2) 纵向控制：基于虚拟轨道边界和光线追踪的曲率感知策略，将几何约束转换为虚拟障碍物距离来调节速度；3) 统一控制栈实现。

Result: 在闭环跟踪和倒车机动中，相比固定控制点基线方法，该方法表现出：1) 改进的轨迹精度；2) 更平滑的转向轮廓；3) 更高的适应性。在配备GPS-RTK、雷达、里程计和IMU的真实自动驾驶车辆上验证有效。

Conclusion: 提出的动态控制点路径跟踪框架通过前后轴控制的平滑插值和曲率感知的纵向控制，显著提升了自动驾驶车辆在不同驾驶场景下的跟踪性能和适应性，为复杂机动提供了更鲁棒的解决方案。

Abstract: This paper presents an experimental study of a path-tracking framework for autonomous vehicles in which the lateral control command is applied to a dynamic control point along the wheelbase. Instead of enforcing a fixed reference at either the front or rear axle, the proposed method continuously interpolates between both, enabling smooth adaptation across driving contexts, including low-speed maneuvers and reverse motion. The lateral steering command is obtained by barycentric blending of two complementary controllers: a front-axle Stanley formulation and a rear-axle curvature-based geometric controller, yielding continuous transitions in steering behavior and improved tracking stability. In addition, we introduce a curvature-aware longitudinal control strategy based on virtual track borders and ray-tracing, which converts upcoming geometric constraints into a virtual obstacle distance and regulates speed accordingly. The complete approach is implemented in a unified control stack and validated in simulation and on a real autonomous vehicle equipped with GPS-RTK, radar, odometry, and IMU. The results in closed-loop tracking and backward maneuvers show improved trajectory accuracy, smoother steering profiles, and increased adaptability compared to fixed control-point baselines.

</details>


### [240] [Multi-Task Learning for Robot Perception with Imbalanced Data](https://arxiv.org/abs/2602.01899)
*Ozgur Erkent*

Main category: cs.RO

TL;DR: 提出一种在多任务学习中处理标签不平衡问题的方法，即使某些任务缺少真实标签也能学习，并分析任务间的相互作用关系。


<details>
  <summary>Details</summary>
Motivation: 机器人资源有限，多任务学习能提高各任务精度，但实际中不同任务的标签数量往往不平衡，且移动机器人在各种环境中获取标签困难，需要解决标签不足情况下的多任务学习问题。

Method: 提出一种即使某些任务缺少真实标签也能学习的方法，通过分析任务间的相互作用，使用教师网络以任务输出（如深度）作为输入，研究哪些任务能提升其他任务的性能。

Result: 在NYUDv2和Cityscapes数据集上对语义分割和深度估计任务进行实验，提供了经验证据，特别是在小数据量训练下的表现。

Conclusion: 该方法能在标签不平衡甚至某些任务缺少真实标签的情况下有效进行多任务学习，并提供了分析任务间相互作用的方法论，有助于理解哪些任务能相互促进性能提升。

Abstract: Multi-task problem solving has been shown to improve the accuracy of the individual tasks, which is an important feature for robots, as they have a limited resource. However, when the number of labels for each task is not equal, namely imbalanced data exist, a problem may arise due to insufficient number of samples, and labeling is not very easy for mobile robots in every environment. We propose a method that can learn tasks even in the absence of the ground truth labels for some of the tasks. We also provide a detailed analysis of the proposed method. An interesting finding is related to the interaction of the tasks. We show a methodology to find out which tasks can improve the performance of other tasks. We investigate this by training the teacher network with the task outputs such as depth as inputs. We further provide empirical evidence when trained with a small amount of data. We use semantic segmentation and depth estimation tasks on different datasets, NYUDv2 and Cityscapes.

</details>


### [241] [ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning](https://arxiv.org/abs/2602.01916)
*Keyu Chen,Wenchao Sun,Hao Cheng,Zheng Fu,Sifa Zheng*

Main category: cs.RO

TL;DR: ForSim提出了一种逐步闭环前向仿真范式，通过在RIFT框架中结合群体相对优化，解决了交通仿真中的协变量偏移和有限多模态行为问题，提高了仿真的真实性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的交通仿真面临两个基本挑战：开环模仿学习引入的协变量偏移，以及反映真实世界交通多模态行为的能力有限。现有框架如RIFT虽然通过群体相对优化部分解决了这些问题，但其前向仿真过程仍然基本是非反应式的，导致虚拟域中的智能体交互不真实，限制了仿真保真度。

Method: ForSim采用逐步闭环前向仿真范式。在每个虚拟时间步，交通智能体通过物理基础的运动动力学传播与参考轨迹时空匹配最佳的虚拟候选轨迹，从而保持多模态行为多样性同时确保模态内一致性。其他智能体通过逐步预测进行更新，产生连贯且交互感知的演化。当集成到RIFT交通仿真框架时，ForSim与群体相对优化协同工作以微调交通策略。

Result: 大量实验证实，这种集成一致地提高了安全性，同时保持了效率、真实性和舒适性。这些结果强调了在前向仿真中建模闭环多模态交互的重要性，并增强了自动驾驶交通仿真的保真度和可靠性。

Conclusion: ForSim通过逐步闭环前向仿真范式有效解决了交通仿真中的关键挑战，与RIFT框架的集成显著提升了仿真的真实性、安全性和可靠性，为自动驾驶的闭环训练和评估提供了更高质量的仿真环境。

Abstract: As the foundation of closed-loop training and evaluation in autonomous driving, traffic simulation still faces two fundamental challenges: covariate shift introduced by open-loop imitation learning and limited capacity to reflect the multimodal behaviors observed in real-world traffic. Although recent frameworks such as RIFT have partially addressed these issues through group-relative optimization, their forward simulation procedures remain largely non-reactive, leading to unrealistic agent interactions within the virtual domain and ultimately limiting simulation fidelity. To address these issues, we propose ForSim, a stepwise closed-loop forward simulation paradigm. At each virtual timestep, the traffic agent propagates the virtual candidate trajectory that best spatiotemporally matches the reference trajectory through physically grounded motion dynamics, thereby preserving multimodal behavioral diversity while ensuring intra-modality consistency. Other agents are updated with stepwise predictions, yielding coherent and interaction-aware evolution. When incorporated into the RIFT traffic simulation framework, ForSim operates in conjunction with group-relative optimization to fine-tune traffic policy. Extensive experiments confirm that this integration consistently improves safety while maintaining efficiency, realism, and comfort. These results underscore the importance of modeling closed-loop multimodal interactions within forward simulation and enhance the fidelity and reliability of traffic simulation for autonomous driving. Project Page: https://currychen77.github.io/ForSim/

</details>


### [242] [LIEREx: Language-Image Embeddings for Robotic Exploration](https://arxiv.org/abs/2602.01930)
*Felix Igelbrink,Lennart Niecksch,Marian Renz,Martin Günther,Martin Atzmueller*

Main category: cs.RO

TL;DR: LIEREx 结合视觉语言基础模型与3D语义场景图，实现自主机器人在部分未知环境中的目标导向探索


<details>
  <summary>Details</summary>
Motivation: 传统语义地图方法依赖预定义的符号词汇，无法处理设计时未定义的新知识。视觉语言基础模型（如CLIP）提供了开放集映射能力，但需要与现有3D语义场景图系统集成以实现目标导向探索。

Method: 将视觉语言基础模型（VLFMs）与3D语义场景图（3D Semantic Scene Graphs）相结合，使用高维嵌入而非固定标签来表示对象，实现开放集映射。

Result: LIEREx系统使自主机器人能够在部分未知环境中进行目标导向探索，突破了传统方法对预定义对象类别的限制。

Conclusion: 通过集成视觉语言基础模型与3D语义场景图，LIEREx实现了更灵活、适应性更强的语义地图系统，能够处理开放集对象识别和未知环境探索任务。

Abstract: Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments.

</details>


### [243] [Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy](https://arxiv.org/abs/2602.01939)
*Yuxin He,Ruihao Zhang,Tianao Shen,Cheng Liu,Qiang Nie*

Main category: cs.RO

TL;DR: 论文提出探索性聚焦操作(EFM)问题，建立EFM-10基准测试，开发双手主动感知(BAP)策略，并收集BAPData数据集验证策略有效性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中的视觉遮挡问题，该问题本质上是缺乏完成任务所需的信息。受此启发，提出更根本的探索性聚焦操作问题。

Method: 提出双手主动感知策略：一只手臂提供主动视觉，另一只手臂在操作时提供力感知。建立EFM-10基准测试（包含4类共10个任务），并收集BAPData数据集。

Result: 通过BAPData数据集，以模仿学习方式成功验证了BAP策略的有效性。EFM-10基准测试和BAP策略为未来研究提供了基础。

Conclusion: 提出的EFM-10基准测试和BAP策略可作为该研究方向的基础，促进未来对探索性聚焦操作问题的研究。

Abstract: Recently, active vision has reemerged as an important concept for manipulation, since visual occlusion occurs more frequently when main cameras are mounted on the robot heads. We reflect on the visual occlusion issue and identify its essence as the absence of information useful for task completion. Inspired by this, we come up with the more fundamental problem of Exploratory and Focused Manipulation (EFM). The proposed problem is about actively collecting information to complete challenging manipulation tasks that require exploration or focus. As an initial attempt to address this problem, we establish the EFM-10 benchmark that consists of 4 categories of tasks that align with our definition (10 tasks in total). We further come up with a Bimanual Active Perception (BAP) strategy, which leverages one arm to provide active vision and another arm to provide force sensing while manipulating. Based on this idea, we collect a dataset named BAPData for the tasks in EFM-10. With the dataset, we successfully verify the effectiveness of the BAP strategy in an imitation learning manner. We hope that the EFM-10 benchmark along with the BAP strategy can become a cornerstone that facilitates future research towards this direction. Project website: EFManipulation.github.io.

</details>


### [244] [A Unified Control Architecture for Macro-Micro Manipulation using a Active Remote Center of Compliance for Manufacturing Applications](https://arxiv.org/abs/2602.01948)
*Patrick Frank,Christian Friedrich*

Main category: cs.RO

TL;DR: 提出新型宏微机械臂控制架构，将宏机械臂纳入主动交互控制，相比传统方法将控制带宽提高2.1-12.5倍，并引入代理模型简化控制器设计


<details>
  <summary>Details</summary>
Motivation: 传统宏微机械臂控制中，宏机械臂负责位置控制，微机械臂负责环境交互，这种分工限制了交互控制带宽。需要将宏机械臂也纳入主动交互控制来提高性能

Method: 提出新颖的控制架构，将宏机械臂整合到主动交互控制中。同时引入代理模型来简化控制器设计，便于硬件变更时的适配

Result: 相比最先进的领导者-跟随者架构，控制带宽提高2.1倍；相比传统机器人力控制，提高12.5倍。在物体碰撞、力轨迹跟踪和工业装配等实验中验证了方法的有效性

Conclusion: 通过将宏机械臂纳入主动交互控制的新架构，显著提高了宏微机械臂系统的交互控制带宽，并通过代理模型简化了控制器设计，为工业应用提供了更高效的解决方案

Abstract: Macro-micro manipulators combine a macro manipulator with a large workspace, such as an industrial robot, with a lightweight, high-bandwidth micro manipulator. This enables highly dynamic interaction control while preserving the wide workspace of the robot. Traditionally, position control is assigned to the macro manipulator, while the micro manipulator handles the interaction with the environment, limiting the achievable interaction control bandwidth. To solve this, we propose a novel control architecture that incorporates the macro manipulator into the active interaction control. This leads to a increase in control bandwidth by a factor of 2.1 compared to the state of the art architecture, based on the leader-follower approach and factor 12.5 compared to traditional robot-based force control. Further we propose surrogate models for a more efficient controller design and easy adaptation to hardware changes. We validate our approach by comparing it against the other control schemes in different experiments, like collision with an object, following a force trajectory and industrial assembly tasks.

</details>


### [245] [Reformulating AI-based Multi-Object Relative State Estimation for Aleatoric Uncertainty-based Outlier Rejection of Partial Measurements](https://arxiv.org/abs/2602.02006)
*Thomas Jantos,Giulio Delama,Stephan Weiss,Jan Steinbrener*

Main category: cs.RO

TL;DR: 本文提出在基于AI的目标相对状态估计中重新构建测量方程的方法，通过直接使用目标相对位姿测量推导EKF，解耦位置和旋转测量，减少错误旋转测量的影响，并利用DNN预测的不确定性改进状态估计器性能。


<details>
  <summary>Details</summary>
Motivation: 随着边缘设备能够部署深度神经网络进行实时推理，利用AI从原始图像数据中提取目标特定语义信息（如目标类别和相对6自由度位姿）变得可行。然而，在扩展卡尔曼滤波中融合这些基于AI的测量需要量化DNN的不确定性和异常值拒绝能力。

Method: 重新构建测量方程，通过直接使用目标相对位姿测量推导扩展卡尔曼滤波器，解耦位置和旋转测量，限制错误旋转测量的影响，允许部分测量拒绝。同时，用DNN预测的偶然不确定性替代固定的6-DoF目标相对位姿测量协方差矩阵。

Result: 该方法能够限制错误旋转测量的影响，允许部分测量拒绝，并提高状态估计器的性能和一致性。通过使用DNN预测的不确定性，相比固定测量协方差矩阵，能够更好地量化测量不确定性。

Conclusion: 重新构建测量方程在基于AI的目标相对状态估计中具有显著优势，能够解耦位置和旋转测量，减少错误测量的影响，并通过利用DNN预测的不确定性提高状态估计器的性能和一致性。

Abstract: Precise localization with respect to a set of objects of interest enables mobile robots to perform various tasks. With the rise of edge devices capable of deploying deep neural networks (DNNs) for real-time inference, it stands to reason to use artificial intelligence (AI) for the extraction of object-specific, semantic information from raw image data, such as the object class and the relative six degrees of freedom (6-DoF) pose. However, fusing such AI-based measurements in an Extended Kalman Filter (EKF) requires quantifying the DNNs' uncertainty and outlier rejection capabilities.
  This paper presents the benefits of reformulating the measurement equation in AI-based, object-relative state estimation. By deriving an EKF using the direct object-relative pose measurement, we can decouple the position and rotation measurements, thus limiting the influence of erroneous rotation measurements and allowing partial measurement rejection. Furthermore, we investigate the performance and consistency improvements for state estimators provided by replacing the fixed measurement covariance matrix of the 6-DoF object-relative pose measurements with the predicted aleatoric uncertainty of the DNN.

</details>


### [246] [Synchronized Online Friction Estimation and Adaptive Grasp Control for Robust Gentle Grasp](https://arxiv.org/abs/2602.02026)
*Zhenwei Niu,Xiaoyi Chen,Jiayu Hu,Zhaoyang Liu,Xiaozu Ju*

Main category: cs.RO

TL;DR: 提出一个统一的机器人轻柔抓取框架，将实时摩擦系数估计与自适应抓取控制相结合，通过视觉触觉传感器实现实时摩擦估计，并集成到反应式控制器中动态调节抓取力。


<details>
  <summary>Details</summary>
Motivation: 传统机器人抓取方法通常缺乏对摩擦系数的实时估计能力，导致抓取力调节不够精确，难以实现稳定且轻柔的抓取。需要一种能够实时感知环境变化并自适应调整的抓取系统。

Method: 1. 提出基于粒子滤波的实时摩擦系数估计方法，使用视觉触觉传感器获取数据；2. 设计反应式控制器，利用摩擦估计值动态调节抓取力；3. 建立闭环系统，控制器使用当前最佳估计调整力，同时新的触觉反馈持续优化估计，形成响应灵敏的传感器运动循环。

Result: 通过广泛的机器人实验验证了完整框架的可靠性和效率，系统能够实现稳定且轻柔的抓取，对摩擦变化具有高度响应性和鲁棒性。

Conclusion: 该框架成功实现了实时摩擦估计与自适应抓取控制的协同耦合，为机器人轻柔抓取提供了统一的解决方案，显著提升了抓取系统的响应性、鲁棒性和稳定性。

Abstract: We introduce a unified framework for gentle robotic grasping that synergistically couples real-time friction estimation with adaptive grasp control. We propose a new particle filter-based method for real-time estimation of the friction coefficient using vision-based tactile sensors. This estimate is seamlessly integrated into a reactive controller that dynamically modulates grasp force to maintain a stable grip. The two processes operate synchronously in a closed-loop: the controller uses the current best estimate to adjust the force, while new tactile feedback from this action continuously refines the estimation. This creates a highly responsive and robust sensorimotor cycle. The reliability and efficiency of the complete framework are validated through extensive robotic experiments.

</details>


### [247] [Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization](https://arxiv.org/abs/2602.02035)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.RO

TL;DR: 提出结合信息瓶颈理论和矢量量化的多智能体通信框架，实现选择性、带宽高效的通信，在保持性能的同时大幅降低带宽使用。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人应用中的多智能体强化学习系统面临严重的通信约束，这显著影响协调效果。需要在带宽受限的环境中部署多智能体系统。

Method: 结合信息瓶颈理论和矢量量化，通过信息论优化学习压缩和离散化通信消息，同时保留任务关键信息。引入门控通信机制，根据环境上下文和智能体状态动态决定何时需要通信。

Result: 在挑战性协调任务上，相比无通信基线性能提升181.8%，同时减少41.4%的带宽使用。帕累托前沿分析显示在整个成功率-带宽谱上占主导地位，AUC为0.198 vs 次优方法的0.142。

Conclusion: 该方法显著优于现有通信策略，为在机器人群体、自动驾驶车队和分布式传感器网络等带宽受限环境中部署多智能体系统建立了理论基础框架。

Abstract: Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks.

</details>


### [248] [Frictional Contact Solving for Material Point Method](https://arxiv.org/abs/2602.02038)
*Etienne Ménager,Justin Carpentier*

Main category: cs.RO

TL;DR: 提出了一种用于隐式物质点法（MPM）的精确鲁棒摩擦接触处理管道，通过粒子中心几何基元定位接触点，将摩擦接触建模为非线性互补问题并用ADMM求解。


<details>
  <summary>Details</summary>
Motivation: 在物质点法中，准确处理带摩擦的接触一直是一个核心瓶颈，包括可靠的接触点检测和执行摩擦接触定律（非穿透、库仑摩擦和最大耗散原理）。

Method: 1. 碰撞检测阶段：使用粒子中心几何基元定位接触点；2. 接触解析阶段：将摩擦接触建模为非线性互补问题（NCP），采用交替方向乘子法（ADMM）求解；3. 重用隐式MPM线性化，确保效率和数值稳定性。

Result: 在七个代表性场景中评估，涵盖弹性和弹塑性响应、简单和复杂可变形几何形状以及广泛的接触条件。方法实现了精确的接触定位、可靠的摩擦处理和广泛的通用性。

Conclusion: 该方法为基于MPM的机器人及相关领域仿真提供了一个实用的解决方案，能够实现准确的接触定位、可靠的摩擦处理和广泛的通用性。

Abstract: Accurately handling contact with friction remains a core bottleneck for Material Point Method (MPM), from reliable contact point detection to enforcing frictional contact laws (non-penetration, Coulomb friction, and maximum dissipation principle). In this paper, we introduce a frictional-contact pipeline for implicit MPM that is both precise and robust. During the collision detection phase, contact points are localized with particle-centric geometric primitives; during the contact resolution phase, we cast frictional contact as a Nonlinear Complementarity Problem (NCP) over contact impulses and solve it with an Alternating Direction Method of Multipliers (ADMM) scheme. Crucially, the formulation reuses the same implicit MPM linearization, yielding efficiency and numerical stability. The method integrates seamlessly into the implicit MPM loop and is agnostic to modeling choices, including material laws, interpolation functions, and transfer schemes. We evaluate it across seven representative scenes that span elastic and elasto-plastic responses, simple and complex deformable geometries, and a wide range of contact conditions. Overall, the proposed method enables accurate contact localization, reliable frictional handling, and broad generality, making it a practical solution for MPM-based simulations in robotics and related domains.

</details>


### [249] [FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation](https://arxiv.org/abs/2602.02142)
*Ruiteng Zhao,Wenshuo Wang,Yicheng Ma,Xiaocong Li,Francis E. H. Tay,Marcelo H. Ang,Haiyue Zhu*

Main category: cs.RO

TL;DR: FD-VLA框架通过力蒸馏模块将力感知集成到视觉-语言-动作系统中，无需物理力传感器，在接触丰富的操作任务中实现精细感知和灵巧操作。


<details>
  <summary>Details</summary>
Motivation: 力感知对于VLA框架在接触丰富任务中的精细感知和灵巧操作至关重要，但许多机器人缺乏昂贵或易碎的力-力矩传感器，限制了实际部署。

Method: 提出力蒸馏模块(FDM)，通过学习查询令牌将视觉观察和机器人状态映射到预测的力令牌，该令牌与真实力信号的潜在表示对齐，然后将蒸馏的力令牌注入预训练的VLM中。

Result: 物理实验显示，蒸馏的力令牌性能优于直接传感器力测量和其他基线方法，证明了力蒸馏VLA方法的有效性。

Conclusion: FD-VLA框架成功将力感知集成到VLA系统中，无需物理传感器，降低了硬件成本和复杂性，同时通过力-视觉-状态融合提高了跨模态对齐和感知-动作鲁棒性。

Abstract: Force sensing is a crucial modality for Vision-Language-Action (VLA) frameworks, as it enables fine-grained perception and dexterous manipulation in contact-rich tasks. We present Force-Distilled VLA (FD-VLA), a novel framework that integrates force awareness into contact-rich manipulation without relying on physical force sensors. The core of our approach is a Force Distillation Module (FDM), which distills force by mapping a learnable query token, conditioned on visual observations and robot states, into a predicted force token aligned with the latent representation of actual force signals. During inference, this distilled force token is injected into the pretrained VLM, enabling force-aware reasoning while preserving the integrity of its vision-language semantics. This design provides two key benefits: first, it allows practical deployment across a wide range of robots that lack expensive or fragile force-torque sensors, thereby reducing hardware cost and complexity; second, the FDM introduces an additional force-vision-state fusion prior to the VLM, which improves cross-modal alignment and enhances perception-action robustness in contact-rich scenarios. Surprisingly, our physical experiments show that the distilled force token outperforms direct sensor force measurements as well as other baselines, which highlights the effectiveness of this force-distilled VLA approach.

</details>


### [250] [Extending the Law of Intersegmental Coordination: Implications for Powered Prosthetic Controls](https://arxiv.org/abs/2602.02181)
*Elad Siman Tov,Nili E. Krausz*

Main category: cs.RO

TL;DR: 开发了分析下肢三维运动数据中节段间协调的新方法，扩展了节段间协调定律，提出了基于力矩的协调定律，并应用于截肢者步态分析。


<details>
  <summary>Details</summary>
Motivation: 虽然动力假肢能为截肢者提供净正功，但降低截肢者行走代谢成本仍是一个未解决的问题。节段间协调定律（ISC）与行走能量消耗相关，但很少在截肢者步态背景下分析或应用。

Method: 开发了分析下肢三维运动数据中节段间协调的方法，简化ISC分析；基于运动控制、生物力学和机器人学文献，将ISC扩展为新的力矩协调定律（ESM）；使用ISC作为约束预测补偿被动假肢影响的胫骨角度/力矩。

Result: 发现了基于力矩的协调模式用于正常步态；截肢者使用动力和被动假肢时，虽然抬高角度保持平面性，但ESM显示协调性降低；开发了免费在线的ISC3d工具箱，可用于计算三维运动学和动力学ISC。

Conclusion: 该方法为研究步态协调作用提供了新手段，有助于解决人类运动神经控制的基本问题，可能对改进动力假肢控制有重要意义。

Abstract: Powered prostheses are capable of providing net positive work to amputees and have advanced in the past two decades. However, reducing amputee metabolic cost of walking remains an open problem. The Law of Intersegmental Coordination (ISC) has been observed across gaits and has been previously implicated in energy expenditure of walking, yet it has rarely been analyzed or applied within the context of lower-limb amputee gait. This law states that the elevation angles of the thigh, shank and foot over the gait cycle are not independent. In this work, we developed a method to analyze intersegmental coordination for lower-limb 3D kinematic data, to simplify ISC analysis. Moreover, inspired by motor control, biomechanics and robotics literature, we used our method to broaden ISC toward a new law of coordination of moments. We find these Elevation Space Moments (ESM), and present results showing a moment-based coordination for able bodied gait. We also analyzed ISC for amputee gait walking with powered and passive prosthesis, and found that while elevation angles remained planar, the ESM showed less coordination. We use ISC as a constraint to predict the shank angles/moments that would compensate for alterations due to a passive foot so as to mimic a healthy thigh angle/moment profile. This may have implications for improving powered prosthetic control. We developed the ISC3d toolbox that is freely available online, which may be used to compute kinematic and kinetic ISC in 3D. This provides a means to further study the role of coordination in gait and may help address fundamental questions of the neural control of human movement.

</details>


### [251] [Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL](https://arxiv.org/abs/2602.02236)
*Julian Lemmel,Felix Resch,Mónika Farsang,Ramin Hasani,Daniela Rus,Radu Grosu*

Main category: cs.RO

TL;DR: 使用实时循环强化学习（RTRRL）在线微调预训练策略，结合液体电阻-电容RNN模型，提升自动驾驶任务中的适应能力


<details>
  <summary>Details</summary>
Motivation: 预训练策略在现实应用中面临环境动态变化、传感器漂移和任务目标改变等挑战，导致性能迅速下降，需要在线适应机制

Method: 采用实时循环强化学习（RTRRL）在线微调预训练策略，结合液体电阻-液体电容RNN（Liquid-Resistance Liquid-Capacitance RNN）模型

Result: 在模拟CarRacing环境和真实世界RoboRacer事件相机线跟踪任务中验证了该闭环方法的有效性

Conclusion: RTRRL与生物启发循环网络结合，能够有效提升自主系统在动态环境中的适应性和性能

Abstract: Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera.

</details>


### [252] [Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems](https://arxiv.org/abs/2602.02269)
*Jon Škerlj,Seongjin Bien,Abdeldjallil Naceri,Sami Haddadin*

Main category: cs.RO

TL;DR: multipanda_ros2是一个开源的ROS2架构，用于控制多台Franka机器人，支持1kHz实时控制频率和2ms控制器切换延迟，集成了高保真MuJoCo仿真和惯性参数识别来缩小仿真与现实差距。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人实时控制中的关键挑战，包括实时扭矩控制、交互控制、机器人环境建模，以及缩小仿真与现实差距，为高级机器人研究提供可重复的基准测试平台。

Method: 开发了基于ROS2控制的多机器人架构，采用controllet-feature设计模式实现快速控制器切换，集成高保真MuJoCo仿真进行定量评估，并通过真实世界惯性参数识别提高力/扭矩精度。

Result: 实现了1kHz控制频率（满足安全标准最低要求），控制器切换延迟≤2ms，通过惯性参数识别显著提高了力和扭矩精度，为刚性双臂接触丰富任务提供了有效的仿真到现实迁移方法。

Conclusion: multipanda_ros2为多机器人控制提供了一个强大、可重复的研究平台，通过创新的架构设计和仿真到现实迁移方法，有效解决了实时控制和基准测试的关键挑战，推动了高级机器人研究的发展。

Abstract: We present $multipanda\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research.

</details>


### [253] [TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour](https://arxiv.org/abs/2602.02331)
*Shaoting Zhu,Baijun Ye,Jiaxuan Wang,Jiakang Chen,Ziwen Zhuang,Linzhan Mou,Runhan Huang,Hang Zhao*

Main category: cs.RO

TL;DR: 提出了一种实-仿-实框架，通过测试时训练增强人形机器人在未知复杂地形上的动态跑酷能力，整个流程可在10分钟内完成


<details>
  <summary>Details</summary>
Motivation: 现有通用运动策略在广泛地形分布上表现良好，但在任意和高度挑战性环境中仍存在困难，需要增强机器人在极端几何地形上的穿越能力

Method: 采用两阶段端到端学习范式：首先在多样程序生成地形上预训练策略，然后基于真实世界捕捉重建的高保真网格进行快速微调；开发了基于RGB-D输入的前馈高效高保真几何重建流程

Result: TTT-Parkour使人形机器人能够掌握复杂障碍物（楔形、桩、箱体、梯形和窄梁）；整个捕捉、重建和测试时训练流程在大多数测试地形上不到10分钟；测试时训练后的策略展现出鲁棒的零样本仿真到现实迁移能力

Conclusion: 提出的实-仿-实框架通过快速测试时训练显著增强了人形机器人在未知复杂地形上的动态跑酷能力，实现了高效的地形适应和鲁棒的仿真到现实迁移

Abstract: Achieving highly dynamic humanoid parkour on unseen, complex terrains remains a challenge in robotics. Although general locomotion policies demonstrate capabilities across broad terrain distributions, they often struggle with arbitrary and highly challenging environments. To overcome this limitation, we propose a real-to-sim-to-real framework that leverages rapid test-time training (TTT) on novel terrains, significantly enhancing the robot's capability to traverse extremely difficult geometries. We adopt a two-stage end-to-end learning paradigm: a policy is first pre-trained on diverse procedurally generated terrains, followed by rapid fine-tuning on high-fidelity meshes reconstructed from real-world captures. Specifically, we develop a feed-forward, efficient, and high-fidelity geometry reconstruction pipeline using RGB-D inputs, ensuring both speed and quality during test-time training. We demonstrate that TTT-Parkour empowers humanoid robots to master complex obstacles, including wedges, stakes, boxes, trapezoids, and narrow beams. The whole pipeline of capturing, reconstructing, and test-time training requires less than 10 minutes on most tested terrains. Extensive experiments show that the policy after test-time training exhibits robust zero-shot sim-to-real transfer capability.

</details>


### [254] [Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures](https://arxiv.org/abs/2602.02389)
*Marina Ruediger,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 提出一种基于SLAM数据的水下多机器人自主巡检任务生成方法，无需先验几何信息，通过优化关键点评分和距离修剪来生成任务，相比传统方法更具适应性


<details>
  <summary>Details</summary>
Motivation: 水下多机器人巡检面临未知几何环境的挑战，需要无需先验知识的自适应任务生成方法，以提高对缺陷或损坏区域的检测效率

Method: 利用SLAM数据生成网格，结合硬件参数和环境条件生成初始任务集，通过预期关键点评分和基于距离的修剪进行优化，并在水中测试验证算法效果

Result: 水中测试验证了算法的有效性，相比模拟的Voronoi分区和boustrophedon模式，该方法在测试环境模型上实现了更好的巡检覆盖，特别关注可能存在的缺陷区域

Conclusion: 提出的任务发现方法具有适应意外几何形状的优势，能够在保持覆盖的同时重点关注可能存在的缺陷区域，为水下多机器人巡检提供了有效的自主任务生成方案

Abstract: Task generation for underwater multi-robot inspections without prior knowledge of existing geometry can be achieved and optimized through examination of simultaneous localization and mapping (SLAM) data. By considering hardware parameters and environmental conditions, a set of tasks is generated from SLAM meshes and optimized through expected keypoint scores and distance-based pruning. In-water tests are used to demonstrate the effectiveness of the algorithm and determine the appropriate parameters. These results are compared to simulated Voronoi partitions and boustrophedon patterns for inspection coverage on a model of the test environment. The key benefits of the presented task discovery method include adaptability to unexpected geometry and distributions that maintain coverage while focusing on areas more likely to present defects or damage.

</details>


### [255] [PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning](https://arxiv.org/abs/2602.02396)
*Amisha Bhaskar,Pratap Tokekar,Stefano Di Cairano,Alexander Schperberg*

Main category: cs.RO

TL;DR: PRISM：基于批量全局拒绝采样IMLE的单次通过策略，整合多模态感知，在实时控制下实现高性能机器人模仿学习


<details>
  <summary>Details</summary>
Motivation: 现有生成方法（扩散模型、流匹配、IMLE）在机器人模仿学习中难以同时满足多模态动作分布、实时控制频率和多感知模态的要求

Method: 基于批量全局拒绝采样IMLE的单次通过策略，结合时间多感知编码器（RGB、深度、触觉、音频、本体感觉）和使用Performer架构的线性注意力生成器

Result: 在真实硬件上比扩散策略成功率提高10-25%，保持30-50Hz闭环控制；在CALVIN基准上比扩散提高25%成功率，比流匹配提高20%，轨迹抖动减少20-50倍

Conclusion: PRISM是快速、准确、多感知的模仿策略，保持多模态动作覆盖同时避免了迭代采样的延迟

Abstract: Robotic imitation learning typically requires models that capture multimodal action distributions while operating at real-time control rates and accommodating multiple sensing modalities. Although recent generative approaches such as diffusion models, flow matching, and Implicit Maximum Likelihood Estimation (IMLE) have achieved promising results, they often satisfy only a subset of these requirements. To address this, we introduce PRISM, a single-pass policy based on a batch-global rejection-sampling variant of IMLE. PRISM couples a temporal multisensory encoder (integrating RGB, depth, tactile, audio, and proprioception) with a linear-attention generator using a Performer architecture. We demonstrate the efficacy of PRISM on a diverse real-world hardware suite, including loco-manipulation using a Unitree Go2 with a 7-DoF arm D1 and tabletop manipulation with a UR5 manipulator. Across challenging physical tasks such as pre-manipulation parking, high-precision insertion, and multi-object pick-and-place, PRISM outperforms state-of-the-art diffusion policies by 10-25% in success rate while maintaining high-frequency (30-50 Hz) closed-loop control. We further validate our approach on large-scale simulation benchmarks, including CALVIN, MetaWorld, and Robomimic. In CALVIN (10% data split), PRISM improves success rates by approximately 25% over diffusion and approximately 20% over flow matching, while simultaneously reducing trajectory jerk by 20x-50x. These results position PRISM as a fast, accurate, and multisensory imitation policy that retains multimodal action coverage without the latency of iterative sampling.

</details>


### [256] [SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation](https://arxiv.org/abs/2602.02402)
*Mu Huang,Hui Wang,Kerui Ren,Linning Xu,Yunsong Zhou,Mulin Yu,Bo Dai,Jiangmiao Pang*

Main category: cs.RO

TL;DR: SoMA是一个基于3D高斯泼溅的软体操作模拟器，通过统一潜在神经空间耦合变形动力学、环境力和机器人关节动作，实现端到端的真实到模拟仿真。


<details>
  <summary>Details</summary>
Motivation: 现有模拟器依赖预定义物理或数据驱动动力学，缺乏机器人条件控制，限制了精度、稳定性和泛化能力。软体在丰富交互下的模拟是机器人操作中真实到模拟的根本挑战。

Method: SoMA使用3D高斯泼溅表示软体，在统一潜在神经空间中耦合变形动力学、环境力和机器人关节动作，通过学习的Gaussian splats建模交互，实现端到端仿真。

Result: SoMA在真实世界机器人操作上提高了20%的再模拟精度和泛化能力，能够稳定模拟复杂任务如长时程布料折叠，并能在未观察轨迹上实现泛化。

Conclusion: SoMA通过统一潜在神经空间建模软体操作中的变形动力学、环境力和机器人动作，实现了可控、稳定的长时程操作仿真，超越了基于预定义物理模型的传统方法。

Abstract: Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding.

</details>


### [257] [Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces](https://arxiv.org/abs/2602.02411)
*Hanwen Ren,Junyong Kim,Aathman Tharmasanthiran,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: CAM-MCTS：一种用于多智能体物体重排规划的集中式异步蒙特卡洛树搜索框架，在杂乱环境中显著减少任务完成时间


<details>
  <summary>Details</summary>
Motivation: 现实世界中的物体重排任务通常是非单调的（物体相互阻挡，需要临时移动到中间位置），现有研究主要关注单调实例。多智能体协作可以大幅减少任务完成时间，但需要有效的规划框架。

Method: 提出CAM-MCTS框架：结合集中式任务分配（智能体了解彼此意图以实现全局优化）和异步任务执行策略（智能体在适当时间步接受新任务，无需等待他人），通过一步前瞻成本估计指导决策。

Result: 在杂乱环境中的单调和非单调任务上评估CAM-MCTS，相比强基线方法持续减少任务完成时间。在真实多智能体系统不同配置下验证了方法的有效性和鲁棒性。

Conclusion: CAM-MCTS通过集中式任务分配和异步执行的结合，最小化空闲时间，避免不必要的同步延迟，提高系统效率，为复杂环境中的多智能体物体重排规划提供了有效解决方案。

Abstract: Object rearrangement planning in complex, cluttered environments is a common challenge in warehouses, households, and rescue sites. Prior studies largely address monotone instances, whereas real-world tasks are often non-monotone-objects block one another and must be temporarily relocated to intermediate positions before reaching their final goals. In such settings, effective multi-agent collaboration can substantially reduce the time required to complete tasks. This paper introduces Centralized, Asynchronous, Multi-agent Monte Carlo Tree Search (CAM-MCTS), a novel framework for general-purpose makespan-efficient object rearrangement planning in challenging environments. CAM-MCTS combines centralized task assignment-where agents remain aware of each other's intended actions to facilitate globally optimized planning-with an asynchronous task execution strategy that enables agents to take on new tasks at appropriate time steps, rather than waiting for others, guided by a one-step look-ahead cost estimate. This design minimizes idle time, prevents unnecessary synchronization delays, and enhances overall system efficiency. We evaluate CAM-MCTS across a diverse set of monotone and non-monotone tasks in cluttered environments, demonstrating consistent reductions in makespan compared to strong baselines. Finally, we validate our approach on a real-world multi-agent system under different configurations, further confirming its effectiveness and robustness.

</details>


### [258] [3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM](https://arxiv.org/abs/2602.02430)
*Pierre-Yves Lajoie,Benjamin Ramtoula,Daniele De Martini,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 提出利用3D基础模型进行去中心化协作SLAM的鲁棒闭环检测方法，解决多机器人视角差异大的地图重叠识别问题


<details>
  <summary>Details</summary>
Motivation: 去中心化协作SLAM在多机器人系统中常因视角差异大而难以识别地图重叠区域，需要更鲁棒的闭环检测方法

Method: 1) 集成3D基础模型从单目图像对可靠估计相对位姿；2) 引入鲁棒异常值抑制技术；3) 开发专门的位姿图优化公式解决尺度模糊性

Result: 相比现有方法，在定位和建图精度上有所提升，同时在计算和内存效率上有显著改善

Conclusion: 该方法展示了在大规模多机器人场景中部署的潜力，为去中心化协作SLAM提供了可扩展且鲁棒的解决方案

Abstract: Decentralized Collaborative Simultaneous Localization And Mapping (C-SLAM) techniques often struggle to identify map overlaps due to significant viewpoint variations among robots. Motivated by recent advancements in 3D foundation models, which can register images despite large viewpoint differences, we propose a robust loop closing approach that leverages these models to establish inter-robot measurements. In contrast to resource-intensive methods requiring full 3D reconstruction within a centralized map, our approach integrates foundation models into existing SLAM pipelines, yielding scalable and robust multi-robot mapping. Our contributions include: (1) integrating 3D foundation models to reliably estimate relative poses from monocular image pairs within decentralized C-SLAM; (2) introducing robust outlier mitigation techniques critical to the use of these relative poses; and (3) developing specialized pose graph optimization formulations that efficiently resolve scale ambiguities. We evaluate our method against state-of-the-art approaches, demonstrating improvements in localization and mapping accuracy, alongside significant gains in computational and memory efficiency. These results highlight the potential of our approach for deployment in large-scale multi-robot scenarios.

</details>


### [259] [World-Gymnast: Training Robots with Reinforcement Learning in a World Model](https://arxiv.org/abs/2602.02454)
*Ansh Kumar Sharma,Yixiang Sun,Ninghao Lu,Yunzhe Zhang,Jiarao Liu,Sherry Yang*

Main category: cs.RO

TL;DR: World-Gymnast使用世界模型进行强化学习微调，通过动作条件视频世界模型执行策略，并用视觉语言模型奖励轨迹，在真实机器人性能上显著优于监督微调和软件仿真。


<details>
  <summary>Details</summary>
Motivation: 机器人学习受限于物理交互成本，监督微调受专家数据限制，软件仿真存在模拟到现实的差距。世界模型从真实世界视频-动作数据学习，能否通过在世界模型中训练策略来获得更好的真实机器人性能？

Method: 提出World-Gymnast方法：在动作条件视频世界模型中对视觉语言动作策略进行强化学习微调，用视觉语言模型对轨迹进行奖励。支持多样化语言指令训练、新场景训练、测试时训练以及在线迭代改进。

Result: 在Bridge机器人设置中，World-Gymnast比监督微调性能提升高达18倍，比软件仿真提升高达2倍。展示了世界模型强化学习的独特能力。

Conclusion: 学习世界模型并在云端训练机器人策略可能是弥合演示机器人与通用家庭机器人之间差距的关键。

Abstract: Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone's household.

</details>


### [260] [Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning](https://arxiv.org/abs/2602.02456)
*Albert Gassol Puigjaner,Angelos Zacharia,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出增强型分层3D场景图，集成开放词汇特征并支持对象关系推理，结合VLM和LLM实现任务推理，在四足机器人上验证


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法缺乏高层抽象和关系推理能力，3D场景图虽能捕捉层次结构和对象关系，但需要增强语义理解和任务推理能力

Method: 提出增强型分层3D场景图，集成开放词汇特征；使用视觉语言模型推断语义关系；引入任务推理模块结合LLM和VLM解释场景图信息

Result: 在多个环境和任务中部署于四足机器人上验证，展示了系统能够有效推理任务并与环境智能交互

Conclusion: 增强型3D场景图结合VLM和LLM的方法能够为自主智能体提供更好的环境理解和任务推理能力

Abstract: Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. While traditional Simultaneous Localization and Mapping (SLAM) methods generate metric reconstructions and can be extended to metric-semantic mapping, they lack a higher level of abstraction and relational reasoning. To address this gap, 3D scene graphs have emerged as a powerful representation for capturing hierarchical structures and object relationships. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a Vision Language Model (VLM) to infer semantic relationships. Notably, we introduce a task reasoning module that combines Large Language Models (LLM) and a VLM to interpret the scene graph's semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.

</details>


### [261] [TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments](https://arxiv.org/abs/2602.02459)
*Zhiyu Huang,Yun Zhang,Johnson Liu,Rui Song,Chen Tang,Jiaqi Ma*

Main category: cs.RO

TL;DR: TIC-VLA是一个延迟感知的视觉-语言-动作框架，通过显式建模延迟语义推理来改进实时机器人控制，在动态环境中优于现有VLA模型。


<details>
  <summary>Details</summary>
Motivation: 动态人机环境中，机器人需要同时遵循语言指令并保持实时反应控制。现有VLA模型假设时间对齐的推理和控制，但语义推理本质上是延迟的，这导致实时控制性能下降。

Method: 提出TIC-VLA框架：1）定义延迟语义-控制接口，将动作生成条件于延迟的视觉-语言语义状态和显式延迟元数据；2）提出延迟一致性训练管道，在模仿学习和在线强化学习中注入推理延迟；3）开发DynaNav仿真套件用于动态环境中的语言导航评估。

Result: 在仿真和真实机器人实验中，TIC-VLA在保持鲁棒实时控制的同时，在多秒推理延迟下始终优于现有VLA模型。

Conclusion: TIC-VLA通过显式建模延迟语义推理，有效解决了VLA模型中推理与控制的异步问题，为动态环境中的语言指导机器人控制提供了更实用的解决方案。

Abstract: Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/

</details>


### [262] [HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](https://arxiv.org/abs/2602.02473)
*Yinhuai Wang,Qihan Zhao,Yuen Fui Lau,Runyi Yu,Hok Wai Tsui,Qifeng Chen,Jingbo Wang,Jiangmiao Pang,Ping Tan*

Main category: cs.RO

TL;DR: HumanX框架通过从人类视频生成机器人交互数据，无需任务特定奖励即可让类人机器人学习通用交互技能，在多个运动领域实现零样本物理部署。


<details>
  <summary>Details</summary>
Motivation: 当前类人机器人执行敏捷交互任务面临两大瓶颈：缺乏真实的交互数据和需要繁琐的任务特定奖励工程，这限制了方法的可扩展性。

Method: HumanX包含两个协同设计的组件：XGen数据生成管道（从视频合成多样且物理合理的机器人交互数据，支持可扩展数据增强）和XMimic统一模仿学习框架（学习通用交互技能）。

Result: 在篮球、足球、羽毛球、货物拾取和反应性格斗五个领域成功学习10种技能，零样本迁移到物理Unitree G1类人机器人，包括复杂动作如假动作转身后仰跳投和持续10个周期的人机传球序列，泛化成功率比先前方法高8倍以上。

Conclusion: HumanX为学习通用、真实世界机器人交互技能提供了一条可扩展、任务无关的途径，显著提升了类人机器人的交互能力。

Abstract: Enabling humanoid robots to perform agile and adaptive interactive tasks has long been a core challenge in robotics. Current approaches are bottlenecked by either the scarcity of realistic interaction data or the need for meticulous, task-specific reward engineering, which limits their scalability. To narrow this gap, we present HumanX, a full-stack framework that compiles human video into generalizable, real-world interaction skills for humanoids, without task-specific rewards. HumanX integrates two co-designed components: XGen, a data generation pipeline that synthesizes diverse and physically plausible robot interaction data from video while supporting scalable data augmentation; and XMimic, a unified imitation learning framework that learns generalizable interaction skills. Evaluated across five distinct domains--basketball, football, badminton, cargo pickup, and reactive fighting--HumanX successfully acquires 10 different skills and transfers them zero-shot to a physical Unitree G1 humanoid. The learned capabilities include complex maneuvers such as pump-fake turnaround fadeaway jumpshots without any external perception, as well as interactive tasks like sustained human-robot passing sequences over 10 consecutive cycles--learned from a single video demonstration. Our experiments show that HumanX achieves over 8 times higher generalization success than prior methods, demonstrating a scalable and task-agnostic pathway for learning versatile, real-world robot interactive skills.

</details>


### [263] [Flow Policy Gradients for Robot Control](https://arxiv.org/abs/2602.02481)
*Brent Yi,Hongsuk Choi,Himanshu Gaurav Singh,Xiaoyu Huang,Takara E. Truong,Carmelo Sferrazza,Yi Ma,Rocky Duan,Pieter Abbeel,Guanya Shi,Karen Liu,Angjoo Kanazawa*

Main category: cs.RO

TL;DR: 提出改进的流匹配策略梯度方法，用于训练更具表达能力的机器人控制策略，在多种复杂任务中表现优异，并实现稳健的仿真到现实迁移。


<details>
  <summary>Details</summary>
Motivation: 传统基于似然的策略梯度方法依赖可微分的动作似然，限制了策略输出只能使用简单分布（如高斯分布）。需要一种能训练更具表达能力策略的方法，以应对复杂的机器人控制任务。

Method: 使用流匹配策略梯度框架（绕过似然计算），提出改进的目标函数，使其能在腿式运动、人形运动跟踪和操作任务中有效工作。该方法利用流表示进行探索，并支持从零开始训练和微调。

Result: 方法在多种机器人控制任务中取得成功，包括腿式运动、人形运动跟踪和操作任务。在两个类人机器人上实现了稳健的仿真到现实迁移。策略能利用流表示进行探索，微调鲁棒性优于基线方法。

Conclusion: 流匹配策略梯度方法能够有效训练和微调更具表达能力的机器人控制策略，在复杂任务中表现优异，并实现稳健的仿真到现实迁移，为机器人控制提供了新的有效框架。

Abstract: Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training and fine-tuning more expressive policies in challenging robot control settings. We introduce an improved objective that enables success in legged locomotion, humanoid motion tracking, and manipulation tasks, as well as robust sim-to-real transfer on two humanoid robots. We then present ablations and analysis on training dynamics. Results show how policies can exploit the flow representation for exploration when training from scratch, as well as improved fine-tuning robustness over baselines.

</details>
