<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing](https://arxiv.org/abs/2510.08705)
*Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser*

Main category: cs.RO

TL;DR: 提出了一种结合大语言模型推理能力和局部搜索的接触点选择方法ConPoSe，用于多机器人协作推动物体在杂乱环境中的运输，相比解析方法和纯LLM方法具有更好的可扩展性和性能。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中进行物体运输是服务机器人和仓储物流的基本任务。多机器人协作推动大型物体时，需要仔细选择机器人与物体的接触点以确保按预定路径移动。虽然解析方法可以解决这个问题，但随着机器人数量和物体尺寸的增加，解空间呈组合式增长，限制了可扩展性。

Method: 结合大语言模型的推理能力和局部搜索来选择合适的接触点。提出的ConPoSe方法利用LLM进行常识推理指导局部搜索过程，为长方体、圆柱体和T形等多种形状的物体选择接触点。

Result: ConPoSe成功为多种形状的物体选择了合适的接触点。相比解析方法，ConPoSe在机器人数量和物体尺寸增加时具有更好的可扩展性，并且性能优于纯基于LLM的选择方法。

Conclusion: 结合大语言模型推理和局部搜索的ConPoSe方法为多机器人协作物体运输中的接触点选择问题提供了一种有效的解决方案，在可扩展性和性能方面均优于现有方法。

Abstract: Object transportation in cluttered environments is a fundamental task in
various domains, including domestic service and warehouse logistics. In
cooperative object transport, multiple robots must coordinate to move objects
that are too large for a single robot. One transport strategy is pushing, which
only requires simple robots. However, careful selection of robot-object contact
points is necessary to push the object along a preplanned path. Although this
selection can be solved analytically, the solution space grows combinatorially
with the number of robots and object size, limiting scalability. Inspired by
how humans rely on common-sense reasoning for cooperative transport, we propose
combining the reasoning capabilities of Large Language Models with local search
to select suitable contact points. Our LLM-guided local search method for
contact point selection, ConPoSe, successfully selects contact points for a
variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate
that ConPoSe scales better with the number of robots and object size than the
analytical approach, and also outperforms pure LLM-based selection.

</details>


### [2] [Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics](https://arxiv.org/abs/2510.08753)
*A. Wang,C. Jiang,M. Przystupa,J. Valentine,M. Jagersand*

Main category: cs.RO

TL;DR: 提出Point and Go模式切换方法，通过重新分配笛卡尔模式切换参考系到更直观的动作空间，减少轮椅机器人操作难度，提高性能。


<details>
  <summary>Details</summary>
Motivation: 传统笛卡尔空间模式切换存在控制参考系不直观、平移和旋转控制分离、运动能力有限等问题，影响轮椅机器人操作性能。

Method: 使用新颖的扫掠运动指向夹具，在机器人基座水平面定义新的平移轴，创建直观的'指向并移动'平移模式；旋转模式结合位置控制和精化的末端执行器定向框架。

Result: 实验显示Point and Go模式切换使完成时间减少31%、暂停减少41%、模式切换减少33%，用户调查获得显著积极反馈。

Conclusion: Point and Go模式切换方法有效提高了轮椅机器人操作的直观性和性能，优于传统笛卡尔模式切换和先进学习方法。

Abstract: Operating high degree of freedom robots can be difficult for users of
wheelchair mounted robotic manipulators. Mode switching in Cartesian space has
several drawbacks such as unintuitive control reference frames, separate
translation and orientation control, and limited movement capabilities that
hinder performance. We propose Point and Go mode switching, which reallocates
the Cartesian mode switching reference frames into a more intuitive action
space comprised of new translation and rotation modes. We use a novel sweeping
motion to point the gripper, which defines the new translation axis along the
robot base frame's horizontal plane. This creates an intuitive `point and go'
translation mode that allows the user to easily perform complex, human-like
movements without switching control modes. The system's rotation mode combines
position control with a refined end-effector oriented frame that provides
precise and consistent robot actions in various end-effector poses. We verified
its effectiveness through initial experiments, followed by a three-task user
study that compared our method to Cartesian mode switching and a state of the
art learning method. Results show that Point and Go mode switching reduced
completion times by 31\%, pauses by 41\%, and mode switches by 33\%, while
receiving significantly favorable responses in user surveys.

</details>


### [3] [Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis](https://arxiv.org/abs/2510.08754)
*David Nguyen,Zulfiqar Zaidi,Kevin Karol,Jessica Hodgins,Zhaoming Xie*

Main category: cs.RO

TL;DR: 开发了一个用于四足机器人的动态乒乓球系统，集成了高速感知、轨迹预测和敏捷控制，能够与人类玩家进行对打。


<details>
  <summary>Details</summary>
Motivation: 开发能够匹配人类速度、精度和预测各种球旋转能力的乒乓球机器人对腿式机器人来说仍是一个重大挑战。

Method: 使用外部摄像头进行高速球定位，采用带学习残差的物理模型推断旋转和预测轨迹，以及新颖的模型预测控制(MPC)公式进行敏捷全身控制。

Result: 在Spot四足机器人上实现了真实世界的演示，能够瞄准并回击不同旋转类型的球，并能与人类玩家进行对打。

Conclusion: 该系统展示了四足机器人在动态乒乓球任务中的协调能力，自动涌现出连续的击球策略，为腿式机器人的敏捷控制提供了新范例。

Abstract: Developing table tennis robots that mirror human speed, accuracy, and ability
to predict and respond to the full range of ball spins remains a significant
challenge for legged robots. To demonstrate these capabilities we present a
system to play dynamic table tennis for quadrupedal robots that integrates high
speed perception, trajectory prediction, and agile control. Our system uses
external cameras for high-speed ball localization, physical models with learned
residuals to infer spin and predict trajectories, and a novel model predictive
control (MPC) formulation for agile full-body control. Notably, a continuous
set of stroke strategies emerge automatically from different ball return
objectives using this control paradigm. We demonstrate our system in the real
world on a Spot quadruped, evaluate accuracy of each system component, and
exhibit coordination through the system's ability to aim and return balls with
varying spin types. As a further demonstration, the system is able to rally
with human players.

</details>


### [4] [Geometry-aware Policy Imitation](https://arxiv.org/abs/2510.08787)
*Yiming Li,Nael Darwiche,Amirreza Razmjoo,Sichao Liu,Yilun Du,Auke Ijspeert,Sylvain Calinon*

Main category: cs.RO

TL;DR: GPI将演示视为几何曲线而非状态-动作样本，通过距离场生成推进流和吸引流两种控制原语，构建可控的非参数化向量场直接指导机器人行为。


<details>
  <summary>Details</summary>
Motivation: 重新思考模仿学习，将演示数据视为几何曲线，实现度量学习与策略合成的解耦，支持模块化适应和多模态演示。

Method: 从演示曲线推导距离场，生成推进流（沿专家轨迹前进）和吸引流（纠正偏差），组合成可控向量场直接指导机器人行为。

Result: 在仿真和真实机器人实验中，GPI比基于扩散的策略获得更高成功率，运行速度快20倍，内存需求更少，对扰动具有鲁棒性。

Conclusion: GPI为机器人模仿学习提供了一种高效、可解释、可扩展的生成方法替代方案。

Abstract: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks
imitation learning by treating demonstrations as geometric curves rather than
collections of state-action samples. From these curves, GPI derives distance
fields that give rise to two complementary control primitives: a progression
flow that advances along expert trajectories and an attraction flow that
corrects deviations. Their combination defines a controllable, non-parametric
vector field that directly guides robot behavior. This formulation decouples
metric learning from policy synthesis, enabling modular adaptation across
low-dimensional robot states and high-dimensional perceptual inputs. GPI
naturally supports multimodality by preserving distinct demonstrations as
separate models and allows efficient composition of new demonstrations through
simple additions to the distance field. We evaluate GPI in simulation and on
real robots across diverse tasks. Experiments show that GPI achieves higher
success rates than diffusion-based policies while running 20 times faster,
requiring less memory, and remaining robust to perturbations. These results
establish GPI as an efficient, interpretable, and scalable alternative to
generative approaches for robotic imitation learning. Project website:
https://yimingli1998.github.io/projects/GPI/

</details>


### [5] [Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation](https://arxiv.org/abs/2510.08807)
*Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: 提出了Humanoid Everyday数据集，这是一个大规模多样化的人形机器人操作数据集，包含10.3k轨迹和300万帧数据，涵盖260个任务，并提供云端评估平台。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习数据集主要关注固定机械臂，现有人形机器人数据集要么局限于固定环境，要么任务多样性不足，缺乏人机交互和下半身运动，且缺乏标准化评估平台。

Method: 使用高效的人类监督遥操作流程，收集高质量多模态感知数据（RGB、深度、LiDAR、触觉输入）和自然语言标注。

Result: 构建了包含10.3k轨迹和300万帧数据的大规模数据集，涵盖7大类别260个任务，并对代表性策略学习方法进行了分析。

Conclusion: 通过发布Humanoid Everyday数据集、策略学习分析和标准化云端评估平台，旨在推动通用人形机器人操作研究，为现实场景中更强大的具身智能体奠定基础。

Abstract: From loco-motion to dextrous manipulation, humanoid robots have made
remarkable strides in demonstrating complex full-body capabilities. However,
the majority of current robot learning datasets and benchmarks mainly focus on
stationary robot arms, and the few existing humanoid datasets are either
confined to fixed environments or limited in task diversity, often lacking
human-humanoid interaction and lower-body locomotion. Moreover, there are a few
standardized evaluation platforms for benchmarking learning-based policies on
humanoid data. In this work, we present Humanoid Everyday, a large-scale and
diverse humanoid manipulation dataset characterized by extensive task variety
involving dextrous object manipulation, human-humanoid interaction,
locomotion-integrated actions, and more. Leveraging a highly efficient
human-supervised teleoperation pipeline, Humanoid Everyday aggregates
high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile
inputs, together with natural language annotations, comprising 10.3k
trajectories and over 3 million frames of data across 260 tasks across 7 broad
categories. In addition, we conduct an analysis of representative policy
learning methods on our dataset, providing insights into their strengths and
limitations across different task categories. For standardized evaluation, we
introduce a cloud-based evaluation platform that allows researchers to
seamlessly deploy their policies in our controlled setting and receive
performance feedback. By releasing Humanoid Everyday along with our policy
learning analysis and a standardized cloud-based evaluation platform, we intend
to advance research in general-purpose humanoid manipulation and lay the
groundwork for more capable and embodied robotic agents in real-world
scenarios. Our dataset, data collection code, and cloud evaluation website are
made publicly available on our project website.

</details>


### [6] [Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration](https://arxiv.org/abs/2510.08811)
*Jiurun Song,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于接触感知的自适应运动规划框架，通过物理接触直接推断人类意图，并用于人机协作中的在线运动校正。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中机器人如何安全高效地适应人类意图的问题。传统方法中，大语言模型难以可靠应用于运动规划，而物理人机交互需要持续的运动引导，给操作者带来负担。

Method: 1) 基于优化的力估计方法，从关节扭矩测量和机器人动力学模型推断人类意图的接触力和位置；2) 基于扭矩的接触检测机制，实现链接级定位；3) 接触感知的自适应运动规划器，在线重新规划机器人运动。

Result: 在7自由度机械臂上的实验表明，所提出的力估计方法具有准确性，接触感知的自适应运动规划器在人机协作中感知不确定性的情况下具有有效性。

Conclusion: 该框架通过物理接触直接推断人类意图，实现了可靠的人机协作运动规划，减少了操作负担和安装复杂性。

Abstract: Human-robot collaboration (HRC) requires robots to adapt their motions to
human intent to ensure safe and efficient cooperation in shared spaces.
Although large language models (LLMs) provide high-level reasoning for
inferring human intent, their application to reliable motion planning in HRC
remains challenging. Physical human-robot interaction (pHRI) is intuitive but
often relies on continuous kinesthetic guidance, which imposes burdens on
operators. To address these challenges, a contact-informed adaptive
motion-planning framework is introduced to infer human intent directly from
physical contact and employ the inferred intent for online motion correction in
HRC. First, an optimization-based force estimation method is proposed to infer
human-intended contact forces and locations from joint torque measurements and
a robot dynamics model, thereby reducing cost and installation complexity while
enabling whole-body sensitivity. Then, a torque-based contact detection
mechanism with link-level localization is introduced to reduce the optimization
search space and to enable real-time estimation. Subsequently, a
contact-informed adaptive motion planner is developed to infer human intent
from contacts and to replan robot motion online, while maintaining smoothness
and adapting to human corrections. Finally, experiments on a 7-DOF manipulator
are conducted to demonstrate the accuracy of the proposed force estimation
method and the effectiveness of the contact-informed adaptive motion planner
under perception uncertainty in HRC.

</details>


### [7] [Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning](https://arxiv.org/abs/2510.08812)
*Grace Ra Kim,Hailey Warner,Duncan Eddy,Evan Astle,Zachary Booth,Edward Balaban,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出了一种基于部分可观测马尔可夫决策过程（POMDP）的框架，用于在深空任务中自适应排序航天器科学仪器，以支持通信受限环境下的自主科学操作。


<details>
  <summary>Details</summary>
Motivation: 深空任务面临极端的通信延迟和环境不确定性，无法进行实时地面操作，需要自主科学操作能力。

Method: 将贝叶斯网络集成到POMDP观测空间中，管理高维和不确定的测量数据；离线计算仪器操作策略，允许在发射前生成资源感知计划并进行充分验证。

Result: 使用Enceladus Orbilander的Life Detection Suite作为案例研究，与基线概念操作相比，样本识别错误率降低了近40%。

Conclusion: 该方法通过贝叶斯网络结构和奖励塑造提高了系统性能，显著减少了样本识别错误，适用于通信受限的深空科学任务。

Abstract: Deep space missions face extreme communication delays and environmental
uncertainty that prevent real-time ground operations. To support autonomous
science operations in communication-constrained environments, we present a
partially observable Markov decision process (POMDP) framework that adaptively
sequences spacecraft science instruments. We integrate a Bayesian network into
the POMDP observation space to manage the high-dimensional and uncertain
measurements typical of astrobiology missions. This network compactly encodes
dependencies among measurements and improves the interpretability and
computational tractability of science data. Instrument operation policies are
computed offline, allowing resource-aware plans to be generated and thoroughly
validated prior to launch. We use the Enceladus Orbilander's proposed Life
Detection Suite (LDS) as a case study, demonstrating how Bayesian network
structure and reward shaping influence system performance. We compare our
method against the mission's baseline Concept of Operations (ConOps),
evaluating both misclassification rates and performance in off-nominal sample
accumulation scenarios. Our approach reduces sample identification errors by
nearly 40%

</details>


### [8] [CDE: Concept-Driven Exploration for Reinforcement Learning](https://arxiv.org/abs/2510.08851)
*Le Mao,Andrew H. Liu,Renos Zabounidis,Zachary Kingston,Joseph Campbell*

Main category: cs.RO

TL;DR: 提出CDE方法，利用预训练视觉语言模型从文本任务描述生成物体中心视觉概念，通过重建这些概念作为内在奖励来指导视觉强化学习中的探索。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习需要从原始像素中提取任务相关结构，导致探索效率低下，智能探索仍是关键挑战。

Method: 使用预训练VLM从文本任务描述生成物体中心视觉概念，训练策略通过辅助目标重建这些概念，将重建精度作为内在奖励来指导探索。

Result: 在五个模拟视觉操作任务中实现高效、定向探索，对噪声VLM预测保持鲁棒性；在真实世界Franka机械臂上达到80%成功率。

Conclusion: CDE方法通过概念重建内在奖励有效解决了视觉强化学习的探索问题，减少了对外部模型的依赖，并在真实世界任务中验证了有效性。

Abstract: Intelligent exploration remains a critical challenge in reinforcement
learning (RL), especially in visual control tasks. Unlike low-dimensional
state-based RL, visual RL must extract task-relevant structure from raw pixels,
making exploration inefficient. We propose Concept-Driven Exploration (CDE),
which leverages a pre-trained vision-language model (VLM) to generate
object-centric visual concepts from textual task descriptions as weak,
potentially noisy supervisory signals. Rather than directly conditioning on
these noisy signals, CDE trains a policy to reconstruct the concepts via an
auxiliary objective, using reconstruction accuracy as an intrinsic reward to
guide exploration toward task-relevant objects. Because the policy internalizes
these concepts, VLM queries are only needed during training, reducing
dependence on external models during deployment. Across five challenging
simulated visual manipulation tasks, CDE achieves efficient, targeted
exploration and remains robust to noisy VLM predictions. Finally, we
demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm,
attaining an 80\% success rate in a real-world manipulation task.

</details>


### [9] [Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization](https://arxiv.org/abs/2510.08880)
*Baoshan Song,Xiao Xia,Penggao Yan,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 提出了一种紧耦合的在线校准方法，融合IMU、里程计和原始GNSS测量数据，用于自主地面车辆的标定和定位。


<details>
  <summary>Details</summary>
Motivation: 现有GNSS辅助方法依赖定位结果或未解决模糊度的原始测量，且可观测性分析不足，需要更精确的标定方法。

Method: 在可扩展因子图优化框架中融合IMU、里程计和原始GNSS测量（伪距、载波相位和多普勒），包含异常值抑制和模糊度解决。

Result: 仿真和真实实验显示，相比最先进的松耦合方法，标定和定位性能显著提升，IMU-里程计定位绝对最大误差从61.51米降至17.75米，提升71.14%。

Conclusion: 该方法有效解决了自主地面车辆定位中的标定问题，并发布了首个结合IMU、2D里程计和原始GNSS测量的开源数据集。

Abstract: Accurate calibration of intrinsic (odometer scaling factors) and extrinsic
parameters (IMU-odometer translation and rotation) is essential for autonomous
ground vehicle localization. Existing GNSS-aided approaches often rely on
positioning results or raw measurements without ambiguity resolution, and their
observability properties remain underexplored. This paper proposes a tightly
coupled online calibration method that fuses IMU, odometer, and raw GNSS
measurements (pseudo-range, carrier-phase, and Doppler) within an extendable
factor graph optimization (FGO) framework, incorporating outlier mitigation and
ambiguity resolution. Observability analysis reveals that two horizontal
translation and three rotation parameters are observable under general motion,
while vertical translation remains unobservable. Simulation and real-world
experiments demonstrate superior calibration and localization performance over
state-of-the-art loosely coupled methods. Specifically, the IMU-odometer
positioning using our calibrated parameters achieves the absolute maximum error
of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent
improvement. To foster further research, we also release the first open-source
dataset that combines IMU, 2D odometer, and raw GNSS measurements from both
rover and base stations.

</details>


### [10] [Model-Based Lookahead Reinforcement Learning for in-hand manipulation](https://arxiv.org/abs/2510.08884)
*Alexandre Lopes,Catarina Barata,Plinio Moreno*

Main category: cs.RO

TL;DR: 将混合强化学习框架应用于手内操作任务，结合模型无关和模型相关方法，通过轨迹评估提升性能，但会增加计算成本


<details>
  <summary>Details</summary>
Motivation: 手内操作是机器人领域的挑战性任务，需要控制复杂动态系统并操纵各种物体。现有方法在性能和泛化能力方面仍有不足

Method: 使用混合强化学习框架，结合模型无关和模型相关RL，通过动态模型和价值函数进行轨迹评估（类似模型预测控制），在完全驱动和欠驱动仿真机械手上测试

Result: 在大多数测试案例中，混合框架提升了手内操作任务的性能，即使物体属性发生变化也能保持改进，但计算成本增加

Conclusion: 混合强化学习框架能有效提升手内操作任务的性能，具有良好的泛化能力，但需要权衡性能提升与计算成本

Abstract: In-Hand Manipulation, as many other dexterous tasks, remains a difficult
challenge in robotics by combining complex dynamic systems with the capability
to control and manoeuvre various objects using its actuators. This work
presents the application of a previously developed hybrid Reinforcement
Learning (RL) Framework to In-Hand Manipulation task, verifying that it is
capable of improving the performance of the task. The model combines concepts
of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained
policy with the help of a dynamic model and value-function through trajectory
evaluation, as done in Model Predictive Control. This work evaluates the
performance of the model by comparing it with the policy that will be guided.
To fully explore this, various tests are performed using both fully-actuated
and under-actuated simulated robotic hands to manipulate different objects for
a given task. The performance of the model will also be tested for
generalization tests, by changing the properties of the objects in which both
the policy and dynamic model were trained, such as density and size, and
additionally by guiding a trained policy in a certain object to perform the
same task in a different one. The results of this work show that, given a
policy with high average reward and an accurate dynamic model, the hybrid
framework improves the performance of in-hand manipulation tasks for most test
cases, even when the object properties are changed. However, this improvement
comes at the expense of increasing the computational cost, due to the
complexity of trajectory evaluation.

</details>


### [11] [Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm](https://arxiv.org/abs/2510.08953)
*Cheng Ouyang,Moeen Ul Islam,Dong Chen,Kaixiang Zhang,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本文开发了一种基于数据驱动预测控制(DeePC)的软体机器人控制框架，并在3D缆驱软臂上进行了实验验证，相比传统模型控制器展现出更优的精度、鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有安全性和适应性优势，但由于其复杂的非线性动力学特性，实现精确动态控制仍面临挑战。DeePC作为一种无需显式系统辨识的模型无关方法，在软体机器人领域的应用尚未充分探索。

Method: 设计制造了具有厚管状骨架、密集硅胶体和刚性端盖的3D缆驱软臂，采用基于奇异值分解降维的DeePC方法，实现了固定点调节和3D空间轨迹跟踪两种控制任务。

Result: 与基线模型控制器相比，DeePC在精度、鲁棒性和适应性方面表现更优，验证了该方法在软体机器人动态控制中的有效性。

Conclusion: DeePC为软体机器人的动态控制提供了一种实用的解决方案，展现了在复杂3D软体系统控制中的潜力。

Abstract: Soft robots offer significant advantages in safety and adaptability, yet
achieving precise and dynamic control remains a major challenge due to their
inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive
Control (DeePC) has emerged as a promising model-free approach that bypasses
explicit system identification by directly leveraging input-output data. While
DeePC has shown success in other domains, its application to soft robots
remains underexplored, particularly for three-dimensional (3D) soft robotic
systems. This paper addresses this gap by developing and experimentally
validating an effective DeePC framework on a 3D, cable-driven soft arm.
Specifically, we design and fabricate a soft robotic arm with a thick tubing
backbone for stability, a dense silicone body with large cavities for strength
and flexibility, and rigid endcaps for secure termination. Using this platform,
we implement DeePC with singular value decomposition (SVD)-based dimension
reduction for two key control tasks: fixed-point regulation and trajectory
tracking in 3D space. Comparative experiments with a baseline model-based
controller demonstrate DeePC's superior accuracy, robustness, and adaptability,
highlighting its potential as a practical solution for dynamic control of soft
robots.

</details>


### [12] [A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space](https://arxiv.org/abs/2510.08973)
*Bibekananda Patra,Aditya Mahesh Kolte,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 该论文提出了一种将一般二次曲面分类为轴对称二次曲面(AQ)的方法，并解决了点到AQ的邻近度问题。通过将R^3空间的问题简化为R^2空间，利用圆锥曲线的几何特性开发了新算法，在性能上优于商业库Bullet。


<details>
  <summary>Details</summary>
Motivation: 解决三维空间中点到轴对称二次曲面的邻近度计算问题，现有方法效率不高，需要开发更高效的算法。

Method: 将R^3空间的邻近度问题简化为R^2空间，基于圆锥曲线的几何特性(如次法线、半长轴长度、偏心率、斜率和半径)开发新方法，并根据点的位置将问题分为抛物线和椭圆/双曲线的子情况。

Result: 提出的方法适合在C等编程语言中实现，经测试比商业库Bullet更快。

Conclusion: 通过几何特性分析和问题分类，成功开发了高效的点到轴对称二次曲面邻近度计算方法，在三维到二维的简化过程中实现了性能优化。

Abstract: This paper presents the classification of a general quadric into an
axisymmetric quadric (AQ) and the solution to the problem of the proximity of a
given point to an AQ. The problem of proximity in $R^3$ is reduced to the same
in $R^2$, which is not found in the literature. A new method to solve the
problem in $R^2$ is used based on the geometrical properties of the conics,
such as sub-normal, length of the semi-major axis, eccentricity, slope and
radius. Furthermore, the problem in $R^2$ is categorised into two and three
more sub-cases for parabola and ellipse/hyperbola, respectively, depending on
the location of the point, which is a novel approach as per the authors'
knowledge. The proposed method is suitable for implementation in a common
programming language, such as C and proved to be faster than a commercial
library, namely, Bullet.

</details>


### [13] [Trust Modeling and Estimation in Human-Autonomy Interactions](https://arxiv.org/abs/2510.09013)
*Daniel A. Williams,Airlie Chapman,Daniel R. Little,Chris Manzie*

Main category: cs.RO

TL;DR: 本文提出了一个基于切换线性系统的监督者信任动态模型，该模型考虑了自主系统性能的不对称响应和间歇性通信特性。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏能够处理自主系统性能不对称响应和监督者-自主系统间歇性通信的信任动态模型，这影响了人机交互质量。

Method: 采用切换线性系统结构，结合事件触发的模型输入输出采样，基于51名参与者的用户研究数据识别模型参数。

Result: 开发了一个基于切换线性模型的监督者信任观测器，能够准确捕捉信任动态变化。

Conclusion: 所提出的模型能够有效表征监督者对自主系统的信任动态，为人机交互系统的设计提供了重要参考。

Abstract: Advances in the control of autonomous systems have accompanied an expansion
in the potential applications for autonomous robotic systems. The success of
applications involving humans depends on the quality of interaction between the
autonomous system and the human supervisor, which is particularly affected by
the degree of trust that the supervisor places in the autonomous system. Absent
from the literature are models of supervisor trust dynamics that can
accommodate asymmetric responses to autonomous system performance and the
intermittent nature of supervisor-autonomous system communication. This paper
focuses on formulating an estimated model of supervisor trust that incorporates
both of these features by employing a switched linear system structure with
event-triggered sampling of the model input and output. Trust response data
collected in a user study with 51 participants were then used identify
parameters for a switched linear model-based observer of supervisor trust.

</details>


### [14] [iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation](https://arxiv.org/abs/2510.09036)
*Chuanrui Zhang,Zhengxian Wu,Guanxing Lu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: iMoWM是一个用于机器人操作的交互式世界模型，通过多模态token化器统一处理彩色图像、深度图和机器人臂掩码，在保持高效的同时整合丰富的物理信息，提升未来预测质量并支持基于模型的强化学习和模仿学习。


<details>
  <summary>Details</summary>
Motivation: 现有的2D视频世界模型缺乏几何和空间推理能力，无法充分捕捉3D世界的物理结构，这限制了它们在机器人操作中的应用。

Method: 提出iMoWM交互式世界模型和MMTokenizer多模态token化器，将多模态输入统一为紧凑的token表示，利用预训练的VideoGPT模型进行自回归生成。

Result: 实验表明iMoWM在视觉质量、基于模型的强化学习和真实世界模仿学习任务中表现出优越性。

Conclusion: 多模态世界建模为机器人操作带来了显著优势，iMoWM通过整合3D几何信息有效提升了世界模型的性能和应用价值。

Abstract: Learned world models hold significant potential for robotic manipulation, as
they can serve as simulator for real-world interactions. While extensive
progress has been made in 2D video-based world models, these approaches often
lack geometric and spatial reasoning, which is essential for capturing the
physical structure of the 3D world. To address this limitation, we introduce
iMoWM, a novel interactive world model designed to generate color images, depth
maps, and robot arm masks in an autoregressive manner conditioned on actions.
To overcome the high computational cost associated with three-dimensional
information, we propose MMTokenizer, which unifies multi-modal inputs into a
compact token representation. This design enables iMoWM to leverage large-scale
pretrained VideoGPT models while maintaining high efficiency and incorporating
richer physical information. With its multi-modal representation, iMoWM not
only improves the visual quality of future predictions but also serves as an
effective simulator for model-based reinforcement learning (MBRL) and
facilitates real-world imitation learning. Extensive experiments demonstrate
the superiority of iMoWM across these tasks, showcasing the advantages of
multi-modal world modeling for robotic manipulation. Homepage:
https://xingyoujun.github.io/imowm/

</details>


### [15] [Training Models to Detect Successive Robot Errors from Human Reactions](https://arxiv.org/abs/2510.09080)
*Shannon Liu,Maria Teresa Parreira,Wendy Ju*

Main category: cs.RO

TL;DR: 使用机器学习从人类对机器人连续错误的反应中识别错误阶段，最佳模型在检测错误和分类连续失败方面分别达到93.5%和84.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在社会中的集成度提高，检测机器人错误对有效的人机交互至关重要。人类对机器人错误的反应会随着连续失败而加剧，但很少有研究关注这些演变反应如何揭示连续失败。

Method: 在26名参与者与犯重复对话错误的机器人互动的研究中，从视频数据中提取行为特征，为个体用户训练模型。

Result: 最佳模型在检测错误方面达到93.5%的准确率，在分类连续失败方面达到84.1%的准确率。

Conclusion: 对人类反应进展进行建模可以增强错误检测能力，并更好地理解人机交互中重复的交互中断。

Abstract: As robots become more integrated into society, detecting robot errors is
essential for effective human-robot interaction (HRI). When a robot fails
repeatedly, how can it know when to change its behavior? Humans naturally
respond to robot errors through verbal and nonverbal cues that intensify over
successive failures-from confusion and subtle speech changes to visible
frustration and impatience. While prior work shows that human reactions can
indicate robot failures, few studies examine how these evolving responses
reveal successive failures. This research uses machine learning to recognize
stages of robot failure from human reactions. In a study with 26 participants
interacting with a robot that made repeated conversational errors, behavioral
features were extracted from video data to train models for individual users.
The best model achieved 93.5% accuracy for detecting errors and 84.1% for
classifying successive failures. Modeling the progression of human reactions
enhances error detection and understanding of repeated interaction breakdowns
in HRI.

</details>


### [16] [Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation](https://arxiv.org/abs/2510.09089)
*Jikai Wang,Yunqi Cheng,Kezhi Wang,Zonghai Chen*

Main category: cs.RO

TL;DR: 提出了一种新颖的视觉教导-重复导航系统，通过灵活的地图表示、鲁棒的地图匹配和无地图局部导航模块，解决了环境变化和动态物体带来的导航挑战。


<details>
  <summary>Details</summary>
Motivation: 视觉教导-重复导航是移动机器人在未知环境中部署的直接解决方案，但由于环境变化和动态物体的存在，鲁棒的轨迹重复导航仍然面临挑战。

Method: 系统包含三个关键模块：1）将关键帧构建为拓扑度量图的灵活地图表示；2）通过关键帧聚类实现视觉帧到局部地图匹配的鲁棒地图匹配；3）包含长期目标管理和局部轨迹控制优化的无地图局部导航模块。

Result: 在移动平台上进行了广泛实验，结果表明该系统在鲁棒性和有效性方面优于基线方法。

Conclusion: 所提出的视觉教导-重复导航系统能够有效应对环境变化和动态障碍物，实现鲁棒的轨迹重复导航。

Abstract: Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to
be deployed in unknown environments. However, robust trajectory repeat
navigation still remains challenged due to environmental changing and dynamic
objects. In this paper, we propose a novel visual teach-and-repeat navigation
system, which consists of a flexible map representation, robust map matching
and a map-less local navigation module. During the teaching process, the
recorded keyframes are formulated as a topo-metric graph and each node can be
further extended to save new observations. Such representation also alleviates
the requirement of globally consistent mapping. To enhance the place
recognition performance during repeating process, instead of using
frame-to-frame matching, we firstly implement keyframe clustering to aggregate
similar connected keyframes into local map and perform place recognition based
on visual frame-tolocal map matching strategy. To promote the local goal
persistent tracking performance, a long-term goal management algorithm is
constructed, which can avoid the robot getting lost due to environmental
changes or obstacle occlusion. To achieve the goal without map, a local
trajectory-control candidate optimization algorithm is proposed. Extensively
experiments are conducted on our mobile platform. The results demonstrate that
our system is superior to the baselines in terms of robustness and
effectiveness.

</details>


### [17] [When a Robot is More Capable than a Human: Learning from Constrained Demonstrators](https://arxiv.org/abs/2510.09096)
*Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık*

Main category: cs.RO

TL;DR: 论文提出了一种从受限专家演示中学习更优策略的方法，通过推断状态奖励信号和自标记未知状态奖励，实现比行为克隆更高效的任务完成。


<details>
  <summary>Details</summary>
Motivation: 现有演示接口（如遥操作、模拟到真实迁移）限制了专家展示最优行为的能力，导致学习到的策略性能不佳，需要让机器人能够学习比受限专家演示更好的策略。

Method: 使用演示推断仅状态奖励信号来衡量任务进展，并通过时间插值为未知状态自标记奖励，让智能体探索比专家演示更短更高效的轨迹。

Result: 方法在样本效率和任务完成时间上均优于常见模仿学习方法，在真实WidowX机械臂上完成任务仅需12秒，比行为克隆快10倍。

Conclusion: 通过超越直接模仿专家动作，探索更高效轨迹，可以从受限专家演示中学习到比演示本身更优的策略。

Abstract: Learning from demonstrations enables experts to teach robots complex tasks
using interfaces such as kinesthetic teaching, joystick control, and
sim-to-real transfer. However, these interfaces often constrain the expert's
ability to demonstrate optimal behavior due to indirect control, setup
restrictions, and hardware safety. For example, a joystick can move a robotic
arm only in a 2D plane, even though the robot operates in a higher-dimensional
space. As a result, the demonstrations collected by constrained experts lead to
suboptimal performance of the learned policies. This raises a key question: Can
a robot learn a better policy than the one demonstrated by a constrained
expert? We address this by allowing the agent to go beyond direct imitation of
expert actions and explore shorter and more efficient trajectories. We use the
demonstrations to infer a state-only reward signal that measures task progress,
and self-label reward for unknown states using temporal interpolation. Our
approach outperforms common imitation learning in both sample efficiency and
task completion time. On a real WidowX robotic arm, it completes the task in 12
seconds, 10x faster than behavioral cloning, as shown in real-robot videos on
https://sites.google.com/view/constrainedexpert .

</details>


### [18] [Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication](https://arxiv.org/abs/2510.09188)
*Zihao Mao,Yunheng Wang,Yunting Ji,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: 提出了一种完全去中心化的分层相对导航框架，在GPS缺失环境中实现战略远见和战术敏捷性，无需统一坐标系


<details>
  <summary>Details</summary>
Motivation: 解决多机器人导航中集中式方法通信开销大、分布式方法缺乏全局意识导致死锁和拓扑陷阱的问题

Method: 分层框架：战略层通过轻量拓扑地图交换实现全局意识，战术层使用基于采样的逃逸点策略解决时空冲突

Result: 在通信受限和复杂拓扑环境中显著提高了成功率和效率

Conclusion: 该框架成功平衡了全局战略远见和局部战术敏捷性，在GPS缺失环境中表现优异

Abstract: Multi-robot navigation in unknown, structurally constrained, and GPS-denied
environments presents a fundamental trade-off between global strategic
foresight and local tactical agility, particularly under limited communication.
Centralized methods achieve global optimality but suffer from high
communication overhead, while distributed methods are efficient but lack the
broader awareness to avoid deadlocks and topological traps. To address this, we
propose a fully decentralized, hierarchical relative navigation framework that
achieves both strategic foresight and tactical agility without a unified
coordinate system. At the strategic layer, robots build and exchange
lightweight topological maps upon opportunistic encounters. This process
fosters an emergent global awareness, enabling the planning of efficient,
trap-avoiding routes at an abstract level. This high-level plan then inspires
the tactical layer, which operates on local metric information. Here, a
sampling-based escape point strategy resolves dense spatio-temporal conflicts
by generating dynamically feasible trajectories in real time, concurrently
satisfying tight environmental and kinodynamic constraints. Extensive
simulations and real-world experiments demonstrate that our system
significantly outperforms in success rate and efficiency, especially in
communication-limited environments with complex topological structures.

</details>


### [19] [Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization](https://arxiv.org/abs/2510.09204)
*Simon Idoko,Arun Kumar Singh*

Main category: cs.RO

TL;DR: Flow-Opt：一种基于学习的集中式多机器人轨迹优化方法，通过生成模型采样候选轨迹，并使用安全过滤器确保约束满足，实现毫秒级轨迹生成


<details>
  <summary>Details</summary>
Motivation: 集中式多机器人轨迹优化在紧空间规划中能产生更平滑的轨迹，但计算复杂度随机器人数量增加而急剧上升，难以扩展到大规模群体

Method: 使用基于流匹配和扩散变换器的生成模型采样轨迹，配合可微安全过滤器及上下文特定初始化网络，实现快速约束满足

Result: 能在数十毫秒内生成数十个机器人在复杂环境中的轨迹，比现有集中式优化方法快数倍，比基于扩散模型的基线方法快几个数量级

Conclusion: 该方法首次实现了批量解决数十个问题实例的能力，并能生成起点到目标点之间的多样化轨迹，捕捉不同的避碰行为

Abstract: Centralized trajectory optimization in the joint space of multiple robots
allows access to a larger feasible space that can result in smoother
trajectories, especially while planning in tight spaces. Unfortunately, it is
often computationally intractable beyond a very small swarm size. In this
paper, we propose Flow-Opt, a learning-based approach towards improving the
computational tractability of centralized multi-robot trajectory optimization.
Specifically, we reduce the problem to first learning a generative model to
sample different candidate trajectories and then using a learned
Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We
propose a flow-matching model with a diffusion transformer (DiT) augmented with
permutation invariant robot position and map encoders as the generative model.
We develop a custom solver for our SF and equip it with a neural network that
predicts context-specific initialization. The initialization network is trained
in a self-supervised manner, taking advantage of the differentiability of the
SF solver. We advance the state-of-the-art in the following respects. First, we
show that we can generate trajectories of tens of robots in cluttered
environments in a few tens of milliseconds. This is several times faster than
existing centralized optimization approaches. Moreover, our approach also
generates smoother trajectories orders of magnitude faster than competing
baselines based on diffusion models. Second, each component of our approach can
be batched, allowing us to solve a few tens of problem instances in a fraction
of a second. We believe this is a first such result; no existing approach
provides such capabilities. Finally, our approach can generate a diverse set of
trajectories between a given set of start and goal locations, which can capture
different collision-avoidance behaviors.

</details>


### [20] [PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation](https://arxiv.org/abs/2510.09209)
*Yuki Kuroda,Tomoya Takahashi,Cristian C Beltran-Hernandez,Masashi Hamaya,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: 开发了一种轻量级（311克）电动假肢手，仅使用四个电机实现了基本抓握姿势和手内操作（精确抓握和侧向抓握之间的重新定向），解决了现有假肢手重量过大或机构复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 电动假肢手需要轻量化以减轻用户负担，外形像人手以美观，电机内置以保护免受损坏和污垢。除了执行日常活动的能力外，手内操作对于日常使用至关重要，但目前使用的电动假肢手仅能实现静态抓握姿势，现有操作方法要么需要许多电机（使假肢过重），要么需要复杂机构（占用大内部空间并需要外部电机放置）。

Method: 结合单轴拇指和优化的拇指定位，仅使用四个电机在轻量级（311克）假肢手中实现基本姿势和手内操作（精确抓握和侧向抓握之间的重新定向）。

Result: 使用各种宽度（5-30毫米）和形状（圆柱体和棱柱）的原始物体进行实验验证，重新定向任务的成功率为90-100%。该手能够执行印章盖章和USB设备插入，以及旋转操作螺丝刀。

Conclusion: 通过结合单轴拇指和优化的拇指定位，仅使用四个电机在轻量级假肢手中实现了基本姿势和手内操作，成功完成了各种日常任务的重新定向操作。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the
user, shaped like human hands for cosmetic purposes, and have motors inside to
protect them from damage and dirt. In addition to the ability to perform daily
activities, these features are essential for everyday use of the hand. In-hand
manipulation is necessary to perform daily activities such as transitioning
between different postures, particularly through rotational movements, such as
reorienting cards before slot insertion and operating tools such as
screwdrivers. However, currently used electric prosthetic hands only achieve
static grasp postures, and existing manipulation approaches require either many
motors, which makes the prosthesis heavy for daily use in the hand, or complex
mechanisms that demand a large internal space and force external motor
placement, complicating attachment and exposing the components to damage.
Alternatively, we combine a single-axis thumb and optimized thumb positioning
to achieve basic posture and in-hand manipulation, that is, the reorientation
between precision and lateral grasps, using only four motors in a lightweight
(311 g) prosthetic hand. Experimental validation using primitive objects of
various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success
rates of 90-100% for reorientation tasks. The hand performed seal stamping and
USB device insertion, as well as rotation to operate a screwdriver.

</details>


### [21] [HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation](https://arxiv.org/abs/2510.09221)
*Jingyuan Sun,Chaoran Wang,Mingyu Zhang,Cui Miao,Hongyu Ji,Zihan Qu,Han Sun,Bing Wang,Qingyi Si*

Main category: cs.RO

TL;DR: HANDO框架：为配备机械臂的腿式机器人设计的双层系统，实现自主导航和全身协调操作


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现无缝的移动操作，需要机器人结合自主探索和全身控制来进行物理交互

Method: 双层框架：第一层使用目标条件自主探索策略导航到语义指定目标；第二层使用统一的全身移动操作策略协调手臂和腿部进行精确交互

Result: 已完成导航模块的初步部署，将继续推进全身移动操作的更精细部署

Conclusion: HANDO框架为腿式机器人提供了在动态环境中执行以人为中心的移动操作任务的可行方案

Abstract: Seamless loco-manipulation in unstructured environments requires robots to
leverage autonomous exploration alongside whole-body control for physical
interaction. In this work, we introduce HANDO (Hierarchical Autonomous
Navigation and Dexterous Omni-loco-manipulation), a two-layer framework
designed for legged robots equipped with manipulators to perform human-centered
mobile manipulation tasks. The first layer utilizes a goal-conditioned
autonomous exploration policy to guide the robot to semantically specified
targets, such as a black office chair in a dynamic environment. The second
layer employs a unified whole-body loco-manipulation policy to coordinate the
arm and legs for precise interaction tasks-for example, handing a drink to a
person seated on the chair. We have conducted an initial deployment of the
navigation module, and will continue to pursue finer-grained deployment of
whole-body loco-manipulation.

</details>


### [22] [Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System](https://arxiv.org/abs/2510.09229)
*Yuyang Gao,Haofei Ma,Pai Zheng*

Main category: cs.RO

TL;DR: Glovity是一个低成本的可穿戴遥操作系统，集成了空间力反馈设备和带有指尖霍尔传感器校准的触觉手套，实现了反馈丰富的灵巧操作。该系统通过直观的力反馈和触觉反馈解决接触密集任务中的关键挑战，并通过精确重定向克服体现差距。


<details>
  <summary>Details</summary>
Motivation: 解决接触密集任务中的关键挑战，提供直观的力反馈和触觉反馈，同时通过精确重定向克服体现差距。

Method: 集成空间力反馈设备与带有指尖霍尔传感器校准的触觉手套，结合DP-R3M进行模仿学习。

Result: 力反馈将书本翻页任务的成功率从48%提升至78%，完成时间减少25%；指尖校准显著提高了薄物体抓取成功率；在新型接触密集场景中实现了高成功率。

Conclusion: Glovity系统在接触密集任务中表现出显著优势，所有硬件设计和软件将开源发布。

Abstract: We present Glovity, a novel, low-cost wearable teleoperation system that
integrates a spatial wrench (force-torque) feedback device with a haptic glove
featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous
manipulation. Glovity addresses key challenges in contact-rich tasks by
providing intuitive wrench and tactile feedback, while overcoming embodiment
gaps through precise retargeting. User studies demonstrate significant
improvements: wrench feedback boosts success rates in book-flipping tasks from
48% to 78% and reduces completion time by 25%, while fingertip calibration
enhances thin-object grasping success significantly compared to commercial
glove. Furthermore, incorporating wrench signals into imitation learning (via
DP-R3M) achieves high success rate in novel contact-rich scenarios, such as
adaptive page flipping and force-aware handovers. All hardware designs,
software will be open-sourced. Project website: https://glovity.github.io/

</details>


### [23] [Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning](https://arxiv.org/abs/2510.09254)
*Dominik Urbaniak,Alejandro Agostini,Pol Ramon,Jan Rosell,Raúl Suárez,Michael Suppa*

Main category: cs.RO

TL;DR: 提出一种从单个人工演示快速生成平滑、接近最优的无碰撞3D笛卡尔轨迹的方法，使用动态运动基元编码演示并通过策略强化学习迭代重塑，训练神经网络输出轨迹参数，在计算和执行时间上优于RRT-Connect基准。


<details>
  <summary>Details</summary>
Motivation: 基于学习的运动规划通常需要大量训练数据或昂贵的人类演示收集，本文旨在通过单个人工演示快速生成高质量轨迹。

Method: 将演示编码为动态运动基元，使用基于策略的强化学习迭代重塑生成多样化轨迹数据集，训练神经网络根据障碍物参数输出DMP参数。

Result: 在仿真和真实机器人实验中验证，在计算和执行时间、轨迹长度方面优于RRT-Connect基准，支持不同障碍物几何和末端执行器尺寸的多模态轨迹生成。

Conclusion: 该方法能够从单个人工演示快速生成高质量轨迹，在效率和性能上优于传统方法，支持多种场景的轨迹生成。

Abstract: Learning-based motion planning can quickly generate near-optimal
trajectories. However, it often requires either large training datasets or
costly collection of human demonstrations. This work proposes an alternative
approach that quickly generates smooth, near-optimal collision-free 3D
Cartesian trajectories from a single artificial demonstration. The
demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively
reshaped using policy-based reinforcement learning to create a diverse
trajectory dataset for varying obstacle configurations. This dataset is used to
train a neural network that takes as inputs the task parameters describing the
obstacle dimensions and location, derived automatically from a point cloud, and
outputs the DMP parameters that generate the trajectory. The approach is
validated in simulation and real-robot experiments, outperforming a RRT-Connect
baseline in terms of computation and execution time, as well as trajectory
length, while supporting multi-modal trajectory generation for different
obstacle geometries and end-effector dimensions. Videos and the implementation
code are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.

</details>


### [24] [Placeit! A Framework for Learning Robot Object Placement Skills](https://arxiv.org/abs/2510.09267)
*Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux*

Main category: cs.RO

TL;DR: Placeit!是一个基于进化计算的框架，用于自动生成刚性物体的有效放置位置，支持桌面放置、堆叠和插入等任务，在真实世界部署中达到90%的成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人学习面临大规模高质量数据获取的瓶颈，现有方法通常需要手动且费力的数据收集过程。

Method: 采用进化计算和质量多样性优化框架，自动生成多样化的有效放置姿态，支持多种放置场景。

Result: 在所有测试场景中显著优于现有最优方法，基于该框架的拾放管道在120次真实世界部署中达到90%的成功率。

Conclusion: Placeit!是开放环境拾放任务的有力工具，也是训练基于仿真的机器人基础模型所需数据生成的重要引擎。

Abstract: Robotics research has made significant strides in learning, yet mastering
basic skills like object placement remains a fundamental challenge. A key
bottleneck is the acquisition of large-scale, high-quality data, which is often
a manual and laborious process. Inspired by Graspit!, a foundational work that
used simulation to automatically generate dexterous grasp poses, we introduce
Placeit!, an evolutionary-computation framework for generating valid placement
positions for rigid objects. Placeit! is highly versatile, supporting tasks
from placing objects on tables to stacking and inserting them. Our experiments
show that by leveraging quality-diversity optimization, Placeit! significantly
outperforms state-of-the-art methods across all scenarios for generating
diverse valid poses. A pick&place pipeline built on our framework achieved a
90% success rate over 120 real-world deployments. This work positions Placeit!
as a powerful tool for open-environment pick-and-place tasks and as a valuable
engine for generating the data needed to train simulation-based foundation
models in robotics.

</details>


### [25] [Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems](https://arxiv.org/abs/2510.09396)
*Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella*

Main category: cs.RO

TL;DR: 将Surrealist仿真测试框架从无人机扩展到ANYmal四足机器人工业检测应用，通过搜索算法自动生成障碍规避场景，在工业评估中验证了五个专有算法并发现关键故障。


<details>
  <summary>Details</summary>
Motivation: 传统测试方法难以覆盖动态环境中机器人导航的全部操作需求，需要自动化测试框架来发现手动测试遗漏的故障。

Method: 使用基于搜索的算法自动生成具有挑战性的障碍规避测试场景，将框架集成到ANYbotics工作流程中进行工业评估。

Result: 在试点阶段，测试套件发现一个实验算法的关键弱点（成功率40.3%），并证明另一个算法的优越鲁棒性（成功率71.2%）。六个月工业评估中测试了五个专有算法，正式调查确认了框架的价值。

Conclusion: Surrealist框架能有效增强开发流程，发现关键故障，提供客观基准测试，并加强整体验证流程，在工业机器人导航测试中具有重要价值。

Abstract: Ensuring robust robotic navigation in dynamic environments is a key
challenge, as traditional testing methods often struggle to cover the full
spectrum of operational requirements. This paper presents the industrial
adoption of Surrealist, a simulation-based test generation framework originally
for UAVs, now applied to the ANYmal quadrupedal robot for industrial
inspection. Our method uses a search-based algorithm to automatically generate
challenging obstacle avoidance scenarios, uncovering failures often missed by
manual testing. In a pilot phase, generated test suites revealed critical
weaknesses in one experimental algorithm (40.3% success rate) and served as an
effective benchmark to prove the superior robustness of another (71.2% success
rate). The framework was then integrated into the ANYbotics workflow for a
six-month industrial evaluation, where it was used to test five proprietary
algorithms. A formal survey confirmed its value, showing it enhances the
development process, uncovers critical failures, provides objective benchmarks,
and strengthens the overall verification pipeline.

</details>


### [26] [Failure Prediction at Runtime for Generative Robot Policies](https://arxiv.org/abs/2510.09459)
*Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig*

Main category: cs.RO

TL;DR: FIPER是一个无需失败数据的运行时故障预测框架，通过检测分布外观测和动作不确定性来预测生成式模仿学习策略的故障。


<details>
  <summary>Details</summary>
Motivation: 生成式模仿学习策略在复杂任务中表现良好，但分布偏移和动作误差累积会导致不可预测的不安全行为，需要运行时故障预测来确保机器人部署安全。

Method: 使用随机网络蒸馏检测分布外观测，提出动作块熵分数量化动作不确定性，通过保形预测校准预测分数，当两个指标超过阈值时触发故障警报。

Result: 在五个仿真和真实环境中的评估显示，FIPER能更好地区分实际故障与良性分布外情况，比现有方法更准确、更早地预测故障。

Conclusion: FIPER是迈向更可解释、更安全的生成式机器人策略的重要一步，为机器人部署提供了有效的故障预测解决方案。

Abstract: Imitation learning (IL) with generative models, such as diffusion and flow
matching, has enabled robots to perform complex, long-horizon tasks. However,
distribution shifts from unseen environments or compounding action errors can
still cause unpredictable and unsafe behavior, leading to task failure. Early
failure prediction during runtime is therefore essential for deploying robots
in human-centered and safety-critical environments. We propose FIPER, a general
framework for Failure Prediction at Runtime for generative IL policies that
does not require failure data. FIPER identifies two key indicators of impending
failure: (i) out-of-distribution (OOD) observations detected via random network
distillation in the policy's embedding space, and (ii) high uncertainty in
generated actions measured by a novel action-chunk entropy score. Both failure
prediction scores are calibrated using a small set of successful rollouts via
conformal prediction. A failure alarm is triggered when both indicators,
aggregated over short time windows, exceed their thresholds. We evaluate FIPER
across five simulation and real-world environments involving diverse failure
modes. Our results demonstrate that FIPER better distinguishes actual failures
from benign OOD situations and predicts failures more accurately and earlier
than existing methods. We thus consider this work an important step towards
more interpretable and safer generative robot policies. Code, data and videos
are available at https://tum-lsy.github.io/fiper_website.

</details>


### [27] [FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents](https://arxiv.org/abs/2510.09483)
*Lars Ohnemus,Nils Hantke,Max Weißer,Kai Furmans*

Main category: cs.RO

TL;DR: FOGMACHINE是一个开源框架，将动态场景图与离散事件模拟相结合，用于在不确定环境中建模对象动态、智能体观察和交互，支持多智能体行为研究和不确定性传播分析。


<details>
  <summary>Details</summary>
Motivation: 当前动态场景图方法难以捕捉随机动态、部分可观测性和多智能体活动，而这些对于具身AI在不确定性和延迟感知下的决策至关重要。

Method: 将动态场景图与离散事件模拟融合，建模对象动态、智能体观察和交互，支持大规模仿真。

Result: 在城市场景实验中展示了真实的时空模式，同时揭示了在稀疏观察下信念估计的挑战。

Conclusion: 通过结合结构化表示和高效模拟，FOGMACHINE为复杂不确定环境中的基准测试、模型训练和具身AI发展提供了有效工具。

Abstract: Dynamic Scene Graphs (DSGs) provide a structured representation of
hierarchical, interconnected environments, but current approaches struggle to
capture stochastic dynamics, partial observability, and multi-agent activity.
These aspects are critical for embodied AI, where agents must act under
uncertainty and delayed perception. We introduce FOGMACHINE , an open-source
framework that fuses DSGs with discrete-event simulation to model object
dynamics, agent observations, and interactions at scale. This setup enables the
study of uncertainty propagation, planning under limited perception, and
emergent multi-agent behavior. Experiments in urban scenarios illustrate
realistic temporal and spatial patterns while revealing the challenges of
belief estimation under sparse observations. By combining structured
representations with efficient simulation, FOGMACHINE establishes an effective
tool for benchmarking, model training, and advancing embodied AI in complex,
uncertain environments.

</details>


### [28] [Autonomous Soft Robotic Guidewire Navigation via Imitation Learning](https://arxiv.org/abs/2510.09497)
*Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger*

Main category: cs.RO

TL;DR: 提出基于Transformer的模仿学习框架，用于软体机器人导丝在血管内导航，在动脉瘤靶向任务中实现83%的成功率


<details>
  <summary>Details</summary>
Motivation: 解决软体机器人导丝在血管内导航中的建模和控制挑战，提高血管内导航的精确性和安全性

Method: 开发基于Transformer的模仿学习框架，包含目标条件、相对动作输出和自动对比剂注射功能，在36种不同分叉几何结构上进行训练

Result: 在未见过的血管几何结构上，模型能够自主将机器人尖端导航至动脉瘤位置，成功率达到83%，优于多个基线方法

Conclusion: 该方法展示了软体机器人导丝导航的泛化能力，为血管内手术自动化提供了有前景的解决方案

Abstract: In endovascular surgery, endovascular interventionists push a thin tube
called a catheter, guided by a thin wire to a treatment site inside the
patient's blood vessels to treat various conditions such as blood clots,
aneurysms, and malformations. Guidewires with robotic tips can enhance
maneuverability, but they present challenges in modeling and control.
Automation of soft robotic guidewire navigation has the potential to overcome
these challenges, increasing the precision and safety of endovascular
navigation. In other surgical domains, end-to-end imitation learning has shown
promising results. Thus, we develop a transformer-based imitation learning
framework with goal conditioning, relative action outputs, and automatic
contrast dye injections to enable generalizable soft robotic guidewire
navigation in an aneurysm targeting task. We train the model on 36 different
modular bifurcated geometries, generating 647 total demonstrations under
simulated fluoroscopy, and evaluate it on three previously unseen vascular
geometries. The model can autonomously drive the tip of the robot to the
aneurysm location with a success rate of 83% on the unseen geometries,
outperforming several baselines. In addition, we present ablation and baseline
studies to evaluate the effectiveness of each design and data collection
choice. Project website: https://softrobotnavigation.github.io/

</details>


### [29] [Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing](https://arxiv.org/abs/2510.09526)
*Chenghao Wang,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Ioannis Mandralis,Eric Sihite,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: 本文介绍了Husky v.2多模态地面-空中机器人的硬件设计，该机器人通过结构重利用实现了动态四足行走和悬停飞行功能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态机器人在不同操作模式下的冲突需求整合问题，实现地面移动和空中飞行的无缝切换。

Method: 采用结构重利用技术，将腿部结构重新配置用于动态四足行走和飞行，结合姿态操纵和推力矢量控制。

Result: 成功实现了动态四足行走和悬停飞行功能，验证了多模态机器人的可行性。

Conclusion: Husky v.2机器人通过创新的结构重利用设计，有效解决了多模态机器人的集成挑战，为地面-空中机器人系统提供了新的解决方案。

Abstract: Multi-modal ground-aerial robots have been extensively studied, with a
significant challenge lying in the integration of conflicting requirements
across different modes of operation. The Husky robot family, developed at
Northeastern University, and specifically the Husky v.2 discussed in this
study, addresses this challenge by incorporating posture manipulation and
thrust vectoring into multi-modal locomotion through structure repurposing.
This quadrupedal robot features leg structures that can be repurposed for
dynamic legged locomotion and flight. In this paper, we present the hardware
design of the robot and report primary results on dynamic quadrupedal legged
locomotion and hovering.

</details>


### [30] [Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards](https://arxiv.org/abs/2510.09543)
*Chenghao Wang,Arjun Viswanathan,Eric Sihite,Alireza Ramezani*

Main category: cs.RO

TL;DR: 该论文提出了一种结合冲击缓解因子(IMF)和对抗运动先验(AMP)的方法，使强化学习策略能够同时学习动物的显性运动轨迹和隐性被动动力学，实现了高达32%的能源效率提升。


<details>
  <summary>Details</summary>
Motivation: 动物通过其固有的被动动力学实现高能效运动，但现有的模仿学习方法主要捕捉显性步态模式，忽略了隐性被动动力学。

Method: 通过引入基于物理的冲击缓解因子(IMF)作为奖励项，结合对抗运动先验(AMP)和强化学习，使机器人学习动物的显性运动轨迹和隐性被动动力学。

Result: 在AMP和手工设计的奖励结构中，实现了高达32%的运输成本(CoT)改善，显著提升了能源效率。

Conclusion: 结合IMF和AMP的方法能够有效学习动物的被动动力学特性，为机器人实现更自然、高效的仿生运动提供了新途径。

Abstract: Animals achieve energy-efficient locomotion by their implicit passive
dynamics, a marvel that has captivated roboticists for decades.Recently,
methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning
(RL) shows promising progress to replicate Animals' naturalistic motion.
However, such imitation learning approaches predominantly capture explicit
kinematic patterns, so-called gaits, while overlooking the implicit passive
dynamics. This work bridges this gap by incorporating a reward term guided by
Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a
robot's ability to passively mitigate impacts. By integrating IMF with AMP, our
approach enables RL policies to learn both explicit motion trajectories from
animal reference motion and the implicit passive dynamic. We demonstrate energy
efficiency improvements of up to 32%, as measured by the Cost of Transport
(CoT), across both AMP and handcrafted reward structure.

</details>


### [31] [Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference](https://arxiv.org/abs/2510.09574)
*Daria de tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: AIMAPP是一个基于主动推理的生物启发式自主导航框架，统一了建图、定位和决策，能够在陌生环境中进行在线拓扑建图、动态学习状态转移，并通过最小化期望自由能量来规划行动。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在陌生环境中同时进行探索、定位和规划的问题，不依赖预定义地图或大量训练，实现完全自监督的导航。

Method: 使用主动推理框架，结合海马体导航的生物启发机制，包括拓扑推理、位置细胞编码和情景记忆，构建稀疏拓扑地图并动态学习状态转移。

Result: 在大型真实和模拟环境中表现出鲁棒性能，能够适应模糊观测、环境变化和传感器噪声，支持探索和目标导向导航。

Conclusion: AIMAPP提供了一个生物启发的模块化解决方案，适用于非结构化环境中的可扩展自监督导航。

Abstract: Autonomous navigation in unfamiliar environments requires robots to
simultaneously explore, localise, and plan under uncertainty, without relying
on predefined maps or extensive training. We present a biologically inspired,
Active Inference-based framework, Active Inference MAPping and Planning
(AIMAPP). This model unifies mapping, localisation, and decision-making within
a single generative model. Inspired by hippocampal navigation, it uses
topological reasoning, place-cell encoding, and episodic memory to guide
behaviour. The agent builds and updates a sparse topological map online, learns
state transitions dynamically, and plans actions by minimising Expected Free
Energy. This allows it to balance goal-directed and exploratory behaviours. We
implemented a ROS-compatible navigation system that is sensor and
robot-agnostic, capable of integrating with diverse hardware configurations. It
operates in a fully self-supervised manner, is resilient to drift, and supports
both exploration and goal-directed navigation without any pre-training. We
demonstrate robust performance in large-scale real and simulated environments
against state-of-the-art planning models, highlighting the system's
adaptability to ambiguous observations, environmental changes, and sensor
noise. The model offers a biologically inspired, modular solution to scalable,
self-supervised navigation in unstructured settings. AIMAPP is available at
https://github.com/decide-ugent/AIMAPP.

</details>
