<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 61]
- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [In Vino Veritas and Vulnerabilities: Examining LLM Safety via Drunk Language Inducement](https://arxiv.org/abs/2601.22169)
*Anudeex Shetty,Aditya Joshi,Salil S. Kanhere*

Main category: cs.CL

TL;DR: 该论文研究如何通过"醉酒语言"诱导LLM产生安全漏洞，发现三种诱导方法能显著提高LLM的越狱和隐私泄露风险，揭示了人类醉酒行为与LLM拟人化之间的对应关系。


<details>
  <summary>Details</summary>
Motivation: 人类在酒精影响下容易产生不良行为和隐私泄露，研究者想探索LLM是否也会在"醉酒语言"影响下出现类似的安全漏洞，以评估LLM的安全风险。

Method: 提出了三种诱导LLM产生醉酒语言的方法：基于角色的提示、因果微调、基于强化的后训练。在5个LLM上评估，使用JailbreakBench和ConfAIde两个英文基准测试，结合人工评估和LLM评估器进行综合分析。

Result: 醉酒语言诱导显著提高了LLM在JailbreakBench上的越狱成功率（即使在防御机制存在时）和在ConfAIde上的隐私泄露率，效果优于先前方法。发现了人类醉酒行为与LLM拟人化之间的对应关系。

Conclusion: 醉酒语言诱导方法简单高效，可能成为对抗LLM安全调优的手段，突显了LLM安全面临的重大风险。需要关注LLM拟人化带来的安全漏洞。

Abstract: Humans are susceptible to undesirable behaviours and privacy leaks under the influence of alcohol. This paper investigates drunk language, i.e., text written under the influence of alcohol, as a driver for safety failures in large language models (LLMs). We investigate three mechanisms for inducing drunk language in LLMs: persona-based prompting, causal fine-tuning, and reinforcement-based post-training. When evaluated on 5 LLMs, we observe a higher susceptibility to jailbreaking on JailbreakBench (even in the presence of defences) and privacy leaks on ConfAIde, where both benchmarks are in English, as compared to the base LLMs as well as previously reported approaches. Via a robust combination of manual evaluation and LLM-based evaluators and analysis of error categories, our findings highlight a correspondence between human-intoxicated behaviour, and anthropomorphism in LLMs induced with drunk language. The simplicity and efficiency of our drunk language inducement approaches position them as potential counters for LLM safety tuning, highlighting significant risks to LLM safety.

</details>


### [2] [MrRoPE: Mixed-radix Rotary Position Embedding](https://arxiv.org/abs/2601.22181)
*Qingyuan Tian,Wenhong Zhu,Xiaoran Liu,Xiaofeng Wang,Rui Wang*

Main category: cs.CL

TL;DR: 提出MrRoPE（混合进制RoPE），基于进制转换视角统一各种RoPE扩展方法，并引入两种免训练扩展策略，显著提升长序列处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前RoPE扩展策略多样但缺乏统一理论基础，需要一种能够系统化理解和改进RoPE扩展的方法。

Method: 基于进制系统转换视角提出MrRoPE框架，将不同RoPE扩展方法统一为不同的进制转换策略，并设计了MrRoPE-Uni（均匀进制转换）和MrRoPE-Pro（渐进进制转换）两种免训练扩展方法。

Result: MrRoPE-Pro在128K上下文Needle-in-a-Haystack测试中保持85%以上召回率，在Infinite-Bench检索和对话子集上的准确率是YaRN的两倍以上，有效提高了RoPE编码长度的上限。

Conclusion: MrRoPE提供了一个统一的理论框架来理解和改进RoPE扩展，其提出的免训练扩展方法在长序列处理上表现出色，验证了该理论和方法的可靠性和实用性。

Abstract: Rotary Position Embedding (RoPE)-extension refers to modifying or generalizing the Rotary Position Embedding scheme to handle longer sequences than those encountered during pre-training. However, current extension strategies are highly diverse and lack a unified theoretical foundation. In this paper, we propose MrRoPE (Mixed-radix RoPE), a generalized encoding formulation based on a radix system conversion perspective, which elegantly unifies various RoPE-extension approaches as distinct radix conversion strategies. Based on this theory, we introduce two training-free extensions, MrRoPE-Uni and MrRoPE-Pro, which leverage uniform and progressive radix conversion strategies, respectively, to achieve 'train short, test long' generalization. Without fine-tuning, MrRoPE-Pro sustains over 85% recall in the 128K-context Needle-in-a-Haystack test and achieves more than double YaRN's accuracy on Infinite-Bench retrieval and dialogue subsets. Theoretical analysis confirms that MrRoPE-Pro effectively raises the upper bound of RoPE's attainable encoding length, which further validates the reliability and utility of our theory and methodology.

</details>


### [3] [Prepare Reasoning Language Models for Multi-Agent Debate with Self-Debate Reinforcement Learning](https://arxiv.org/abs/2601.22297)
*Chenxi Liu,Yanshuo Chen,Ruibo Chen,Tianyi Xiong,Tong Zheng,Heng Huang*

Main category: cs.CL

TL;DR: SDRL训练框架让单个LLM既能独立解决问题，又能从多智能体辩论中的多样化推理轨迹中学习，提升单模型推理能力和辩论性能。


<details>
  <summary>Details</summary>
Motivation: 当前RLVR方法通常训练LLMs单独解决问题，没有明确准备它们来综合和利用辩论中出现的不同推理路径。需要一种训练框架既能增强单模型推理能力，又能使其从辩论中受益。

Method: SDRL框架：1) 对同一提示采样多个候选解决方案；2) 用多样化推理路径构建辩论上下文；3) 基于此上下文生成第二轮响应；4) 联合优化初始响应和辩论条件响应，训练模型既作为独立求解器又作为辩论参与者。

Result: 在多个基础模型和推理基准测试中，SDRL在提升多智能体辩论整体性能的同时，也增强了单模型推理能力。

Conclusion: SDRL是一种有效的训练框架，能够同时提升LLM的独立问题解决能力和从辩论中学习的能力，为强化学习与协作推理的结合提供了新思路。

Abstract: The reasoning abilities of large language models (LLMs) have been substantially improved by reinforcement learning with verifiable rewards (RLVR). At test time, collaborative reasoning through Multi-Agent Debate (MAD) has emerged as a promising approach for enhancing LLM performance. However, current RLVR methods typically train LLMs to solve problems in isolation, without explicitly preparing them to synthesize and benefit from different rationales that arise during debate. In this work, we propose Self-Debate Reinforcement Learning (SDRL), a training framework that equips a single LLM with strong standalone problem-solving ability and the capability to learn from diverse reasoning trajectories in MAD. Given a prompt, SDRL first samples multiple candidate solutions, then constructs a debate context with diverse reasoning paths and generates second-turn responses conditioned on this context. Finally, SDRL jointly optimizes both the initial and debate-conditioned responses, yielding a model that is effective as both a standalone solver and a debate participant. Experiments across multiple base models and reasoning benchmarks show that SDRL improves overall MAD performance while simultaneously strengthening single model reasoning.

</details>


### [4] [MERMAID: Memory-Enhanced Retrieval and Reasoning with Multi-Agent Iterative Knowledge Grounding for Veracity Assessment](https://arxiv.org/abs/2601.22361)
*Yupeng Cao,Chengyang He,Yangyang Yu,Ping Wang,K. P. Subbalakshmi*

Main category: cs.CL

TL;DR: MERMAID是一个基于记忆增强的多智能体真实性评估框架，通过紧密耦合检索与推理过程，实现动态证据获取和跨声明证据复用，在多个事实核查基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有真实性评估方法通常将证据检索作为静态、孤立的步骤处理，未能有效管理和复用跨声明的检索证据，导致效率低下和冗余搜索。

Method: 提出MERMAID框架，集成智能体驱动搜索、结构化知识表示和持久记忆模块，采用Reason-Action迭代过程，实现动态证据获取和证据记忆中的证据复用。

Result: 在三个事实核查基准和两个声明验证数据集上使用GPT、LLaMA、Qwen等LLMs进行评估，MERMAID达到最先进性能，同时显著提高搜索效率。

Conclusion: 通过协同检索、推理和记忆机制，MERMAID框架能够实现更可靠、高效的真实性评估，证明了紧密耦合检索与推理过程的有效性。

Abstract: Assessing the veracity of online content has become increasingly critical. Large language models (LLMs) have recently enabled substantial progress in automated veracity assessment, including automated fact-checking and claim verification systems. Typical veracity assessment pipelines break down complex claims into sub-claims, retrieve external evidence, and then apply LLM reasoning to assess veracity. However, existing methods often treat evidence retrieval as a static, isolated step and do not effectively manage or reuse retrieved evidence across claims. In this work, we propose MERMAID, a memory-enhanced multi-agent veracity assessment framework that tightly couples the retrieval and reasoning processes. MERMAID integrates agent-driven search, structured knowledge representations, and a persistent memory module within a Reason-Action style iterative process, enabling dynamic evidence acquisition and cross-claim evidence reuse. By retaining retrieved evidence in an evidence memory, the framework reduces redundant searches and improves verification efficiency and consistency. We evaluate MERMAID on three fact-checking benchmarks and two claim-verification datasets using multiple LLMs, including GPT, LLaMA, and Qwen families. Experimental results show that MERMAID achieves state-of-the-art performance while improving the search efficiency, demonstrating the effectiveness of synergizing retrieval, reasoning, and memory for reliable veracity assessment.

</details>


### [5] [Context Structure Reshapes the Representational Geometry of Language Models](https://arxiv.org/abs/2601.22364)
*Eghbal A. Hosseini,Yuxuan Li,Yasaman Bahri,Declan Campbell,Andrew Kyle Lampinen*

Main category: cs.CL

TL;DR: LLMs在上下文学习中表现出两种不同的表征直线化模式：在连续预测任务中，上下文增加会提高神经轨迹的直线化程度并改善预测；而在结构化预测任务中，直线化仅出现在有明确结构的阶段。


<details>
  <summary>Details</summary>
Motivation: 将LLMs表征直线化与上下文学习两个研究方向结合起来，探索在上下文学习过程中表征是否会发生直线化，以及这种直线化如何反映LLMs的学习策略。

Method: 在Gemma 2模型上测量多种上下文任务中的表征直线化程度，包括连续预测任务（如自然语言、网格世界遍历）和结构化预测任务（如少样本学习）。

Result: 发现LLMs在上下文学习中存在二分现象：连续预测任务中，上下文增加会提高神经轨迹直线化程度，且与预测性能提升相关；结构化预测任务中，直线化仅出现在有明确模板结构的阶段，其他阶段消失。

Conclusion: 上下文学习不是单一过程，LLMs像瑞士军刀一样根据任务结构动态选择策略，只有部分策略会产生表征直线化，这反映了LLMs灵活适应不同任务的能力。

Abstract: Large Language Models (LLMs) have been shown to organize the representations of input sequences into straighter neural trajectories in their deep layers, which has been hypothesized to facilitate next-token prediction via linear extrapolation. Language models can also adapt to diverse tasks and learn new structure in context, and recent work has shown that this in-context learning (ICL) can be reflected in representational changes. Here we bring these two lines of research together to explore whether representation straightening occurs \emph{within} a context during ICL. We measure representational straightening in Gemma 2 models across a diverse set of in-context tasks, and uncover a dichotomy in how LLMs' representations change in context. In continual prediction settings (e.g., natural language, grid world traversal tasks) we observe that increasing context increases the straightness of neural sequence trajectories, which is correlated with improvement in model prediction. Conversely, in structured prediction settings (e.g., few-shot tasks), straightening is inconsistent -- it is only present in phases of the task with explicit structure (e.g., repeating a template), but vanishes elsewhere. These results suggest that ICL is not a monolithic process. Instead, we propose that LLMs function like a Swiss Army knife: depending on task structure, the LLM dynamically selects between strategies, only some of which yield representational straightening.

</details>


### [6] [Stability-Aware Prompt Optimization for Clinical Data Abstraction](https://arxiv.org/abs/2601.22373)
*Arinbjörn Kolbeinsson,Daniel Timbie,Sajjan Narsinghani,Sanjay Hariharan*

Main category: cs.CL

TL;DR: 临床LLM对提示词敏感，但现有研究多孤立处理。本文提出联合优化准确性和稳定性，通过双目标提示优化降低翻转率，建议将提示敏感性作为临床LLM验证的明确目标。


<details>
  <summary>Details</summary>
Motivation: 临床抽象任务中，大语言模型对提示词措辞敏感，但现有研究通常将提示词视为固定参数，且孤立地研究不确定性。作者认为应将准确性和提示敏感性联合考虑，因为即使模型表现良好，仍可能对提示词变化脆弱。

Method: 在两个临床任务（MedAlign适用性/正确性和MS亚型抽象）上，使用多个开源和专有模型，通过翻转率测量提示敏感性，并将其与校准和选择性预测关联。提出双目标提示优化循环，同时针对准确性和稳定性进行优化。

Result: 研究发现：1）高准确性不能保证提示稳定性；2）模型可能看似校准良好但对提示词改写仍脆弱；3）明确包含稳定性项的双目标优化能降低跨任务和模型的翻转率，有时以适度准确性为代价。

Conclusion: 提示敏感性应作为临床LLM系统验证的明确目标。双目标优化方法能有效提升模型对提示词变化的鲁棒性，建议在临床LLM部署中联合考虑准确性和稳定性。

Abstract: Large language models used for clinical abstraction are sensitive to prompt wording, yet most work treats prompts as fixed and studies uncertainty in isolation. We argue these should be treated jointly. Across two clinical tasks (MedAlign applicability/correctness and MS subtype abstraction) and multiple open and proprietary models, we measure prompt sensitivity via flip rates and relate it to calibration and selective prediction. We find that higher accuracy does not guarantee prompt stability, and that models can appear well-calibrated yet remain fragile to paraphrases. We propose a dual-objective prompt optimization loop that jointly targets accuracy and stability, showing that explicitly including a stability term reduces flip rates across tasks and models, sometimes at modest accuracy cost. Our results suggest prompt sensitivity should be an explicit objective when validating clinical LLM systems.

</details>


### [7] [SPLA: Block Sparse Plus Linear Attention for Long Context Modeling](https://arxiv.org/abs/2601.22379)
*Bailin Wang,Dan Friedman,Tao Lei,Chong Wang*

Main category: cs.CL

TL;DR: SPLA通过二阶泰勒展开选择相关块进行精确注意力计算，同时用残差线性注意力压缩未选块，避免IO开销，在长上下文任务中超越密集注意力模型


<details>
  <summary>Details</summary>
Motivation: 现有块稀疏注意力方法存在选择保真度低和累积上下文损失的问题，因为它们完全丢弃未选块，需要更准确的选择机制和保留未选块信息的方法

Method: 使用二阶泰勒展开导出的选择指标准确识别相关块进行精确注意力计算；通过残差线性注意力模块将未选块压缩为紧凑的循环状态；采用优化的减法公式避免IO开销

Result: SPLA在持续预训练中缩小了性能差距，在RULER等长上下文基准测试中超越了密集注意力模型，同时保持了竞争性的通用知识和推理能力

Conclusion: SPLA框架通过准确块选择和高效未选块压缩，解决了现有稀疏注意力方法的局限性，在长上下文建模中实现了更好的效率和性能平衡

Abstract: Block-wise sparse attention offers significant efficiency gains for long-context modeling, yet existing methods often suffer from low selection fidelity and cumulative contextual loss by completely discarding unselected blocks. To address these limitations, we introduce Sparse Plus Linear Attention (SPLA), a framework that utilizes a selection metric derived from second-order Taylor expansions to accurately identify relevant blocks for exact attention. Instead of discarding the remaining "long tail," SPLA compresses unselected blocks into a compact recurrent state via a residual linear attention (RLA) module. Crucially, to avoid IO overhead, we derive an optimized subtraction-based formulation for RLA -- calculating the residual as the difference between global and selected linear attention -- ensuring that unselected blocks are never explicitly accessed during inference. Our experiments demonstrate that SPLA closes the performance gap in continual pretraining, surpassing dense attention models on long-context benchmarks like RULER while maintaining competitive general knowledge and reasoning capabilities.

</details>


### [8] [SP^2DPO: An LLM-assisted Semantic Per-Pair DPO Generalization](https://arxiv.org/abs/2601.22385)
*Chaoyue He,Xin Zhou,Di Wang,Hong Xu,Wei Liu,Chunyan Miao*

Main category: cs.CL

TL;DR: SP2DPO是一种改进的DPO方法，用基于语义差距注释的实例特定温度调度替代全局温度参数，在UltraFeedback数据集上实现零训练开销的偏好优化。


<details>
  <summary>Details</summary>
Motivation: 传统DPO使用单一全局温度参数处理所有偏好对，但真实世界的偏好数据具有异质性：混合了高信号目标失败（安全性、事实性）和低信号主观区别（风格），且包含标签噪声，需要更精细的处理方式。

Method: SP2DPO将全局温度替换为基于教师语言模型生成的语义差距注释（类别、幅度、置信度）的实例特定调度beta_i，在UltraFeedback偏好语料库上大规模构建可审计的beta_i工件，训练时保持标准DPO优化器但为每对偏好设置特定beta值。

Result: 在四个开源指令调优学生骨干模型（4B-8B）上，SP2DPO与调优的全局beta DPO基线竞争，在两个骨干模型上提高了AlpacaEval 2.0长度控制胜率，同时避免了每个模型的beta扫描。

Conclusion: SP2DPO通过语义感知的每对温度调度改进了DPO，能够更好地处理异质偏好数据，在保持训练效率的同时提升性能，为偏好优化提供了更精细的控制机制。

Abstract: Direct Preference Optimization (DPO) controls the trade-off between fitting preference labels and staying close to a reference model using a single global temperature beta, implicitly treating all preference pairs as equally informative. Real-world preference corpora are heterogeneous: they mix high-signal, objective failures (for example, safety, factuality, instruction violations) with low-signal or subjective distinctions (for example, style), and also include label noise. We introduce our method, SP2DPO (Semantic Per-Pair DPO), a generalization that replaces the global temperature with an instance-specific schedule beta_i pre-decided offline from structured semantic-gap annotations (category, magnitude, confidence) produced by teacher language models. We instantiate this procedure on the UltraFeedback preference corpus (59,960 pairs), enabling large-scale construction of an auditable beta_i artifact, and incur zero training-time overhead: the inner-loop optimizer remains standard DPO with beta set per pair. We focus our empirical study on AlpacaEval 2.0, reporting both raw win rate and length-controlled win rate. Across four open-weight, instruction-tuned student backbones (4B-8B), SP2DPO is competitive with a tuned global-beta DPO baseline and improves AlpacaEval 2.0 length-controlled win rate on two of four backbones, while avoiding per-model beta sweeps. All code, annotations, and artifacts will be released.

</details>


### [9] [Specialists or Generalists? Multi-Agent and Single-Agent LLMs for Essay Grading](https://arxiv.org/abs/2601.22386)
*Jamiu Adekunle Idowu,Ahmed Almasoud*

Main category: cs.CL

TL;DR: 多智能体LLM架构在识别弱作文方面表现更好，单智能体架构在中档作文上表现更优，两种架构都难以处理高质量作文，少量样本校准是性能提升的关键因素


<details>
  <summary>Details</summary>
Motivation: 尽管自动作文评分系统越来越依赖大语言模型，但不同架构选择如何影响其在不同质量作文上的表现尚不清楚，需要系统评估单智能体和多智能体架构的性能差异

Method: 使用ASAP 2.0语料库评估单智能体和多智能体LLM架构，多智能体系统包含三个专业智能体（内容、结构、语言）和一个协调的主席智能体，采用零样本和少样本条件测试GPT-5.1

Result: 多智能体系统在识别弱作文方面显著更好，单智能体系统在中档作文上表现更优，两种架构都难以处理高质量作文，少样本校准是性能提升的关键因素（仅两个示例就能提升约26%的QWK）

Conclusion: 架构选择应根据具体部署需求：多智能体AI特别适合高风险学生的诊断筛查，单智能体模型则为一般评估提供经济有效的解决方案

Abstract: Automated essay scoring (AES) systems increasingly rely on large language models, yet little is known about how architectural choices shape their performance across different essay quality levels. This paper evaluates single-agent and multi-agent LLM architectures for essay grading using the ASAP 2.0 corpus. Our multi-agent system decomposes grading into three specialist agents (Content, Structure, Language) coordinated by a Chairman Agent that implements rubric-aligned logic including veto rules and score capping. We test both architectures in zero-shot and few-shot conditions using GPT-5.1. Results show that the multi-agent system is significantly better at identifying weak essays while the single-agent system performs better on mid-range essays. Both architectures struggle with high-quality essays. Critically, few-shot calibration emerges as the dominant factor in system performance -- providing just two examples per score level improves QWK by approximately 26% for both architectures. These findings suggest architectural choice should align with specific deployment priorities, with multi-agent AI particularly suited for diagnostic screening of at-risk students, while single-agent models provide a cost-effective solution for general assessment.

</details>


### [10] [Culturally Grounded Personas in Large Language Models: Characterization and Alignment with Socio-Psychological Value Frameworks](https://arxiv.org/abs/2601.22396)
*Candida M. Greco,Lucio La Cava,Andrea Tagarelli*

Main category: cs.CL

TL;DR: 该研究评估了LLM生成的文化基础角色与世界价值观调查、英格尔哈特-韦尔泽文化地图和道德基础理论的契合度，发现这些合成角色能够反映不同文化背景下的价值观和道德差异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在模拟人类行为方面越来越有用，但这些合成角色在不同文化背景下是否能准确反映世界和道德价值体系仍不确定。研究旨在评估文化基础LLM角色与现有文化价值观框架的一致性。

Method: 基于世界价值观调查的可解释变量生成LLM角色，通过三个互补视角分析：1) 在英格尔哈特-韦尔泽文化地图上的定位；2) 与世界价值观调查的人口统计层面一致性；3) 道德基础问卷的道德特征分析，通过文化到道德的映射来表征不同文化配置下的道德反应变化。

Result: 生成的LLM角色能够反映不同文化背景下的稳定差异，其回答分布大致跟踪人类群体模式，道德反应随文化配置而变化，显示出文化基础角色生成方法能够有效评估跨文化结构和道德变异。

Conclusion: 文化基础角色生成和分析方法能够有效评估跨文化结构和道德变异，LLM生成的角色在不同文化背景下能够反映相应的价值观和道德特征，为研究文化差异提供了新工具。

Abstract: Despite the growing utility of Large Language Models (LLMs) for simulating human behavior, the extent to which these synthetic personas accurately reflect world and moral value systems across different cultural conditionings remains uncertain. This paper investigates the alignment of synthetic, culturally-grounded personas with established frameworks, specifically the World Values Survey (WVS), the Inglehart-Welzel Cultural Map, and Moral Foundations Theory. We conceptualize and produce LLM-generated personas based on a set of interpretable WVS-derived variables, and we examine the generated personas through three complementary lenses: positioning on the Inglehart-Welzel map, which unveils their interpretation reflecting stable differences across cultural conditionings; demographic-level consistency with the World Values Survey, where response distributions broadly track human group patterns; and moral profiles derived from a Moral Foundations questionnaire, which we analyze through a culture-to-morality mapping to characterize how moral responses vary across different cultural configurations. Our approach of culturally-grounded persona generation and analysis enables evaluation of cross-cultural structure and moral variation.

</details>


### [11] [Bifocal Attention: Harmonizing Geometric and Spectral Positional Embeddings for Algorithmic Generalization](https://arxiv.org/abs/2601.22402)
*Kanishk Awadhiya*

Main category: cs.CL

TL;DR: 论文提出Bifocal Attention架构，通过几何眼和谱眼分离位置编码，解决RoPE在长距离递归推理中的谱刚性限制


<details>
  <summary>Details</summary>
Motivation: 标准RoPE使用固定的几何衰减，虽然适合局部句法连贯性，但无法捕捉递归逻辑和算法推理中的长距离周期性结构，导致模型在浅层推理链训练后无法外推到更深递归步骤的结构性差距

Method: 引入Bifocal Attention架构，将位置编码解耦为两种模态：几何眼（标准RoPE）用于精确的token级操作，谱眼（可学习谐波算子）用于跟踪长距离递归深度。提出谱演化训练协议，将位置频率初始化为静态几何参数，但允许通过梯度下降演化为针对任务特定算法拓扑优化的谐波基

Result: 论文提出了解决RoPE谱刚性限制的新方法，但摘要中未提供具体实验结果

Conclusion: Bifocal Attention通过分离几何和谱位置编码，能够更好地处理长距离递归推理任务，谱演化训练协议使模型能够适应特定任务的算法拓扑结构

Abstract: Rotary Positional Embeddings (RoPE) have become the standard for Large Language Models (LLMs) due to their ability to encode relative positions through geometric rotation. However, we identify a significant limitation we term ''Spectral Rigidity'': standard RoPE utilizes a fixed geometric decay ($θ^{-i}$) optimized for local syntactic coherence, which fails to capture the long-range, periodic structures inherent in recursive logic and algorithmic reasoning. This results in a ''Structure Gap'', where models trained on shallow reasoning chains fail to extrapolate to deeper recursive steps. In this work, we introduce Bifocal Attention, an architectural paradigm that decouples positional encoding into two distinct modalities: Geometric Eyes (Standard RoPE) for precise token-level manipulation, and Spectral Eyes (Learnable Harmonic Operators) for tracking long-range recursive depth. We propose a novel training protocol, Spectral Evolution, which initializes positional frequencies as static geometric parameters but allows them to evolve via gradient descent into a harmonic basis optimized for the specific algorithmic topology of the task.

</details>


### [12] [Word-Centered Semantic Graphs for Interpretable Diachronic Sense Tracking](https://arxiv.org/abs/2601.22410)
*Imene Kolli,Kai-Robin Lange,Jonas Rieger,Carsten Jentsch*

Main category: cs.CL

TL;DR: 提出基于图的可解释框架，通过构建词中心语义网络分析历时语料库中的语义演变，结合分布相似性和词汇可替换性，识别意义结构并追踪变化轨迹。


<details>
  <summary>Details</summary>
Motivation: 需要一种可解释且不依赖预定义意义清单的方法来分析历时语料中的语义演变，传统方法往往缺乏透明性或需要人工标注的意义库。

Method: 为每个目标词和时间切片构建词中心语义网络，整合历时Skip-gram嵌入的分布相似性和时间特定掩码语言模型的词汇可替换性。通过聚类外围图识别意义相关结构，通过节点重叠对齐跨时间聚类，通过聚类组成和归一化聚类质量追踪变化。

Result: 在《纽约时报杂志》文章语料库（1980-2017）的应用研究中，图连接性反映了多义性动态，诱导的社区捕捉了对比轨迹：事件驱动的意义替换（trump）、具有聚类过度分割效应的语义稳定性（god），以及与数字通信相关的渐进关联变化（post）。

Conclusion: 词中心语义图为探索意义演变提供了紧凑透明的表示方法，无需依赖预定义的意义清单，能够有效捕捉不同类型的语义变化模式。

Abstract: We propose an interpretable, graph-based framework for analyzing semantic shift in diachronic corpora. For each target word and time slice, we induce a word-centered semantic network that integrates distributional similarity from diachronic Skip-gram embeddings with lexical substitutability from time-specific masked language models. We identify sense-related structure by clustering the peripheral graph, align clusters across time via node overlap, and track change through cluster composition and normalized cluster mass. In an application study on a corpus of New York Times Magazine articles (1980 - 2017), we show that graph connectivity reflects polysemy dynamics and that the induced communities capture contrasting trajectories: event-driven sense replacement (trump), semantic stability with cluster over-segmentation effects (god), and gradual association shifts tied to digital communication (post). Overall, word-centered semantic graphs offer a compact and transparent representation for exploring sense evolution without relying on predefined sense inventories.

</details>


### [13] [Large Language Model Agents Are Not Always Faithful Self-Evolvers](https://arxiv.org/abs/2601.22436)
*Weixiang Zhao,Yingshuo Wang,Yichen Zhang,Yang Deng,Yanyan Zhao,Wanxiang Che,Bing Qin,Ting Liu*

Main category: cs.CL

TL;DR: 研究发现自进化LLM代理在经验忠实性上存在不对称性：虽然依赖原始经验，但经常忽视或误解浓缩经验，即使这是唯一提供的经验。


<details>
  <summary>Details</summary>
Motivation: 自进化LLM代理通过积累和重用过去经验不断改进，但尚不清楚它们是否真正依赖这些经验来指导行为。需要系统研究经验忠实性，即代理决策对给定经验的因果依赖性。

Method: 通过受控因果干预对原始和浓缩形式的经验进行实验，全面评估4个代表性框架、10个LLM主干和9个环境，分析单代理和多代理配置。

Result: 发现显著的不对称性：代理始终依赖原始经验，但经常忽视或误解浓缩经验，即使这是唯一提供的经验。这种差距在单/多代理配置和不同规模的主干中都存在。

Conclusion: 经验忠实性差距源于三个因素：浓缩内容的语义限制、抑制经验的内部处理偏见、以及预训练先验已足够的任务机制。这些发现挑战了自进化方法的普遍假设，强调需要更忠实可靠的经验整合方法。

Abstract: Self-evolving large language model (LLM) agents continually improve by accumulating and reusing past experience, yet it remains unclear whether they faithfully rely on that experience to guide their behavior. We present the first systematic investigation of experience faithfulness, the causal dependence of an agent's decisions on the experience it is given, in self-evolving LLM agents. Using controlled causal interventions on both raw and condensed forms of experience, we comprehensively evaluate four representative frameworks across 10 LLM backbones and 9 environments. Our analysis uncovers a striking asymmetry: while agents consistently depend on raw experience, they often disregard or misinterpret condensed experience, even when it is the only experience provided. This gap persists across single- and multi-agent configurations and across backbone scales. We trace its underlying causes to three factors: the semantic limitations of condensed content, internal processing biases that suppress experience, and task regimes where pretrained priors already suffice. These findings challenge prevailing assumptions about self-evolving methods and underscore the need for more faithful and reliable approaches to experience integration.

</details>


### [14] [Stop Jostling: Adaptive Negative Sampling Reduces the Marginalization of Low-Resource Language Tokens by Cross-Entropy Loss](https://arxiv.org/abs/2601.22439)
*Galim Turumtaev*

Main category: cs.CL

TL;DR: 提出阈值技术减少罕见词元在训练中的边缘化影响，提升低资源语言的语言模型性能


<details>
  <summary>Details</summary>
Motivation: 神经语言模型在低资源语言上表现不佳，因为训练数据有限，这些语言的词元在训练集中很罕见。罕见词元在训练过程中受到不成比例的边缘化影响，阻碍了它们有效学习。

Method: 提出一种阈值技术，减少边缘化对罕见词元的影响，使它们能够获得更有意义的对齐。这是首次展示如何通过负采样来改善罕见词元的表示，通过限制过度边缘化的有害影响。

Result: 通过字符级语言模型的实验证明，该方法显著提升了在低资源语言验证数据上的性能。

Conclusion: 这项工作为改善低资源语言的语言模型性能提供了一种新方法，通过减少罕见词元的边缘化影响，使它们能够更好地学习表示。

Abstract: Neural language models often struggle with low-resource languages due to the limited availability of training data, making tokens from these languages rare in the training set. This paper addresses a specific challenge during training: rare tokens are disproportionately affected by marginalization, which prevents them from learning effectively. We propose a thresholding technique that reduces the impact of this marginalization, allowing rare tokens to benefit from more meaningful alignment. Through experiments with a character-level language model, we demonstrate that this method significantly improves performance on low-resource language validation data. This work is the first to show how negative sampling can be applied to improve the representation of rare tokens by limiting the harmful influence of excessive marginalization, offering a new approach to enhancing language model performance for underrepresented languages.

</details>


### [15] [SSL: Sweet Spot Learning for Differentiated Guidance in Agentic Optimization](https://arxiv.org/abs/2601.22491)
*Jinyang Wu,Changpeng Yang,Yuhao Shen,Fangzhi Xu,Bolin Ni,Chonghua Liao,Yuchen Liu,Hongzhen Wang,Shuai Nie,Shuai Zhang,Haoran Luo,Jiaming Xu*

Main category: cs.CL

TL;DR: Sweet Spot Learning (SSL) 是一种新颖的强化学习框架，通过渐进式分层奖励引导智能体走向解空间的"甜点"区域，在视觉感知和复杂推理等任务中显著提升样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法通常使用二元奖励，无法区分实现相同结果但质量不同的轨迹，忽略了解空间中的潜在多样性。受网球"甜点"概念启发，作者希望开发一种能提供差异化指导的框架。

Method: SSL采用渐进式放大的分层奖励机制：视觉感知任务使用距离分层建模奖励接近程度，复杂推理任务奖励向有前景解决方案的渐进进展。该方法保持最优解排序并增强梯度信噪比。

Result: 在GUI感知、短期/长期规划和复杂推理等12个基准测试中，SSL相比强基线取得一致改进，实现高达2.5倍的样本效率提升，并展现出有效的跨任务可迁移性。

Conclusion: SSL作为一种通用训练原则，能够培养更强大和鲁棒的智能体，为强化学习提供了新的差异化奖励设计范式。

Abstract: Reinforcement learning with verifiable rewards has emerged as a powerful paradigm for training intelligent agents. However, existing methods typically employ binary rewards that fail to capture quality differences among trajectories achieving identical outcomes, thereby overlooking potential diversity within the solution space. Inspired by the ``sweet spot'' concept in tennis-the racket's core region that produces optimal hitting effects, we introduce \textbf{S}weet \textbf{S}pot \textbf{L}earning (\textbf{SSL}), a novel framework that provides differentiated guidance for agent optimization. SSL follows a simple yet effective principle: progressively amplified, tiered rewards guide policies toward the sweet-spot region of the solution space. This principle naturally adapts across diverse tasks: visual perception tasks leverage distance-tiered modeling to reward proximity, while complex reasoning tasks reward incremental progress toward promising solutions. We theoretically demonstrate that SSL preserves optimal solution ordering and enhances the gradient signal-to-noise ratio, thereby fostering more directed optimization. Extensive experiments across GUI perception, short/long-term planning, and complex reasoning tasks show consistent improvements over strong baselines on 12 benchmarks, achieving up to 2.5X sample efficiency gains and effective cross-task transferability. Our work establishes SSL as a general principle for training capable and robust agents.

</details>


### [16] [Mock Worlds, Real Skills: Building Small Agentic Language Models with Synthetic Tasks, Simulated Environments, and Rubric-Based Rewards](https://arxiv.org/abs/2601.22511)
*Yuan-Jay Lü,Chengyu Wang,Lei Shen,Jun Huang,Tong Xu*

Main category: cs.CL

TL;DR: SYNTHAGENT框架通过合成多样化工具使用训练数据和模拟完整环境，解决小语言模型在代理能力上的瓶颈，使小模型在多项任务上超越更大基线模型。


<details>
  <summary>Details</summary>
Motivation: 小语言模型难以匹配大模型的代理能力，现有强化学习方法存在两个瓶颈：开源代理训练数据任务单一且容易解决；真实API缺乏多样性且在大规模强化学习过程中不稳定。

Method: SYNTHAGENT框架联合合成多样化工具使用训练数据并模拟完整环境。强教师模型创建新颖任务和工具生态系统，并将其重写为故意不完整的指令，迫使代理主动向用户查询缺失细节。处理合成任务时，基于LLM的用户模拟器提供用户私有信息，模拟工具系统提供稳定工具响应。基于所需子目标、用户-代理交互和禁止行为构建任务级奖励标准。

Result: 在数学、搜索和工具使用等14个具有挑战性的数据集上，使用合成数据训练的模型取得了显著提升，小模型表现优于更大的基线模型。

Conclusion: SYNTHAGENT框架通过合成多样化训练数据和模拟环境，有效解决了小语言模型代理能力训练的瓶颈问题，使小模型能够获得超越更大模型的代理性能。

Abstract: Small LLMs often struggle to match the agentic capabilities of large, costly models. While reinforcement learning can help, progress has been limited by two structural bottlenecks: existing open-source agentic training data are narrow in task variety and easily solved; real-world APIs lack diversity and are unstable for large-scale reinforcement learning rollout processes. We address these challenges with SYNTHAGENT, a framework that jointly synthesizes diverse tool-use training data and simulates complete environments. Specifically, a strong teacher model creates novel tasks and tool ecosystems, then rewrites them into intentionally underspecified instructions. This compels agents to actively query users for missing details. When handling synthetic tasks, an LLM-based user simulator provides user-private information, while a mock tool system delivers stable tool responses. For rewards, task-level rubrics are constructed based on required subgoals, user-agent interactions, and forbidden behaviors. Across 14 challenging datasets in math, search, and tool use, models trained on our synthetic data achieve substantial gains, with small models outperforming larger baselines.

</details>


### [17] [One Ring to Rule Them All: Unifying Group-Based RL via Dynamic Power-Mean Geometry](https://arxiv.org/abs/2601.22521)
*Weisong Zhao,Tong Wang,Zichang Tan,Te Yang,Siran Peng,Haoyuan Zhang,Tianshuo Zhang,Haichao Shi,Meng Meng,Yang Yang,Xiangyu Zhu,Zhen Lei,Xiao-Yu Zhang,Xu Zhou*

Main category: cs.CL

TL;DR: PMPO统一了GRPO和GMPO，通过可调节的幂均值几何参数p来动态适应不同轨迹的特性，使用Clip-aware ESS机制自适应选择p值，在数学推理基准上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于群体的强化学习方法（GRPO和GMPO）都依赖于固定的聚合几何结构，忽略了每个轨迹的演化和异质性。需要一种能够动态适应不同轨迹特性的统一框架。

Method: 提出幂均值策略优化（PMPO）框架，通过参数p控制聚合几何结构，其中p=1对应算术均值（GRPO），p→0对应几何均值（GMPO）。引入Clip-aware有效样本大小（ESS）机制，根据轨迹裁剪分数确定目标ESS，然后求解相应的p值，实现动态调整。

Result: 理论分析表明调整p可以调节梯度更新的集中度，根据优势贡献重新加权token。在多个数学推理基准测试中，PMPO优于强基线方法。

Conclusion: PMPO提供了一个统一的框架，能够根据轨迹可靠性在激进的算术均值和保守的几何均值之间动态过渡，解决了现有方法固定聚合几何结构的局限性。

Abstract: Group-based reinforcement learning has evolved from the arithmetic mean of GRPO to the geometric mean of GMPO. While GMPO improves stability by constraining a conservative objective, it shares a fundamental limitation with GRPO: reliance on a fixed aggregation geometry that ignores the evolving and heterogeneous nature of each trajectory. In this work, we unify these approaches under Power-Mean Policy Optimization (PMPO), a generalized framework that parameterizes the aggregation geometry via the power-mean geometry exponent p. Within this framework, GRPO and GMPO are recovered as special cases. Theoretically, we demonstrate that adjusting p modulates the concentration of gradient updates, effectively reweighting tokens based on their advantage contribution. To determine p adaptively, we introduce a Clip-aware Effective Sample Size (ESS) mechanism. Specifically, we propose a deterministic rule that maps a trajectory clipping fraction to a target ESS. Then, we solve for the specific p to align the trajectory induced ESS with this target one. This allows PMPO to dynamically transition between the aggressive arithmetic mean for reliable trajectories and the conservative geometric mean for unstable ones. Experiments on multiple mathematical reasoning benchmarks demonstrate that PMPO outperforms strong baselines.

</details>


### [18] [$ρ$-$\texttt{EOS}$: Training-free Bidirectional Variable-Length Control for Masked Diffusion LLMs](https://arxiv.org/abs/2601.22527)
*Jingyi Yang,Yuxian Jiang,Jing Shao*

Main category: cs.CL

TL;DR: 提出ρ-EOS方法，通过监测EOS令牌的隐式密度实现双向可变长度生成，解决掩码扩散大语言模型固定生成长度的限制。


<details>
  <summary>Details</summary>
Motivation: 当前掩码扩散大语言模型需要预定义固定生成长度，缺乏灵活性，导致输出质量和计算效率之间的必然权衡。需要一种能够动态调整生成长度的方法。

Method: 通过研究去噪动态，发现EOS令牌的隐式密度(ρ)可作为生成充分性的可靠信号。提出ρ-EOS方法，在统一去噪过程中持续估计隐式EOS密度：密度过高时触发MASK令牌收缩，密度不足时诱导扩展，实现双向长度调整。

Result: 在数学和代码基准测试上的广泛实验表明，ρ-EOS在保持相当性能的同时，显著提高了推理效率和令牌利用率。

Conclusion: ρ-EOS是一种无需训练的单阶段策略，能够实现掩码dLLMs的双向可变长度生成，解决了固定生成长度的根本限制，相比之前的两阶段方法更加高效灵活。

Abstract: Beyond parallel generation and global context modeling, current masked diffusion large language models (dLLMs) suffer from a fundamental limitation: they require a predefined, fixed generation length, which lacks flexibility and forces an inevitable trade-off between output quality and computational efficiency. To address this, we study the denoising dynamics and find that the implicit density ($ρ$) of end-of-sequence ($\texttt{EOS}$) tokens serves as a reliable signal of generation sufficiency. In particular, the evolving implicit $\texttt{EOS}$ density during denoising reveals whether the current masked space is excessive or insufficient, thereby guiding the adjustment direction for generation length. Building on this insight, we propose $\textbf{$ρ$-$\texttt{EOS}$}$, a training-free, single-stage strategy that enables bidirectional variable-length generation for masked dLLMs. Unlike prior two-stage approaches--which require separate length adjustment and iterative mask insertion phases while supporting only unidirectional expansion--$\textbf{$ρ$-$\texttt{EOS}$}$ achieves bidirectional length adjustment within a unified denoising process by continuously estimating the implicit $\texttt{EOS}$ density: excessively high density triggers $\texttt{MASK}$ token contraction, while insufficient density induces expansion. Extensive experiments on mathematics and code benchmarks demonstrate that $\textbf{$ρ$-$\texttt{EOS}$}$ achieves comparable performance while substantially improving inference efficiency and token utilization.

</details>


### [19] [Towards the Holographic Characteristic of LLMs for Efficient Short-text Generation](https://arxiv.org/abs/2601.22546)
*Shun Qian,Bingquan Liu,Chengjie Sun,Zhen Xu,Baoxun Wang*

Main category: cs.CL

TL;DR: 本文提出LLMs具有"全息特性"——在生成初期就捕获目标侧关键词，并基于此开发了HOLO插件，通过并行词汇约束生成提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在上下文学习和思维链方面表现出色，但对其强大生成能力的具体特征研究较少。本文旨在深入探究LLMs的生成特性，特别是发现语言模型在生成初期就倾向于捕获目标侧关键词的现象。

Method: 提出HOLO插件，利用"全息特性"在有限生成步骤内从语言模型中提取目标侧关键词，然后通过并行词汇约束文本生成方法补充完整句子。

Result: 在不同架构和规模的短文本生成场景中进行大量实验，结果显示HOLO在自动评估和人工评估指标上与基线方法表现相当，验证了全息特性的潜力。

Conclusion: 语言模型确实存在"全息特性"——在生成初期捕获目标侧关键词，基于此开发的HOLO插件能有效提高推理效率，为LLMs的生成机制研究提供了新视角。

Abstract: The recent advancements in Large Language Models (LLMs) have attracted interest in exploring their in-context learning abilities and chain-of-thought capabilities. However, there are few studies investigating the specific traits related to the powerful generation capacity of LLMs. This paper aims to delve into the generation characteristics exhibited by LLMs. Through our investigation, we have discovered that language models tend to capture target-side keywords at the beginning of the generation process. We name this phenomenon the Holographic Characteristic of language models. For the purpose of exploring this characteristic and further improving the inference efficiency of language models, we propose a plugin called HOLO, which leverages the Holographic Characteristic to extract target-side keywords from language models within a limited number of generation steps and complements the sentence with a parallel lexically constrained text generation method. To verify the effectiveness of HOLO, we conduct massive experiments on language models of varying architectures and scales in the short-text generation scenario. The results demonstrate that HOLO achieves comparable performance to the baselines in terms of both automatic and human-like evaluation metrics and highlight the potential of the Holographic Characteristic.

</details>


### [20] [Are LLM Evaluators Really Narcissists? Sanity Checking Self-Preference Evaluations](https://arxiv.org/abs/2601.22548)
*Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Mackenzie Puig-Hall,Narmeen Oozeer*

Main category: cs.CL

TL;DR: 该论文发现LLM评估中的自偏好偏差测量存在方法学混淆，提出评估者质量基线来分离信号与噪声，显著减少测量误差。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现LLM作为评估者时会偏好自己的输出，这影响了自动化后训练和评估流程的完整性。但很难区分哪些评估偏差是真正的自恋偏好，哪些是实验混淆因素，导致自偏好偏差测量失真。

Method: 提出评估者质量基线方法，比较评估者错误投票给自己输出的概率与投票给其他模型错误输出的概率。通过这种方法分离自偏好信号与困难问题上的噪声输出。在37,448个查询上评估该方法。

Result: 发现核心方法学混淆可将测量误差减少89.6%。应用基线后，只有51%的初始发现保持统计显著性。此外，还分析了LLM评估者对"简单"与"困难"评估投票的熵特征。

Conclusion: 该校正基线通过消除噪声数据，为未来自偏好研究提供了更可靠的方法。这项工作更广泛地促进了关于编目和隔离评估者偏差效应的研究。

Abstract: Recent research has shown that large language models (LLM) favor own outputs when acting as judges, undermining the integrity of automated post-training and evaluation workflows. However, it is difficult to disentangle which evaluation biases are explained by narcissism versus general experimental confounds, distorting measurements of self-preference bias. We discover a core methodological confound which could reduce measurement error by 89.6%. Specifically, LLM evaluators may deliver self-preferring verdicts when the judge responds to queries which they completed incorrectly themselves; this would be true regardless of whether one of their responses is their own. To decouple self-preference signals from noisy outputs on hard problems, we introduce an Evaluator Quality Baseline, which compares the probability that a judge incorrectly votes for itself against the probability that it votes for an incorrect response from another model. Evaluating this simple baseline on 37,448 queries, only 51% of initial findings retain statistical significance. Finally, we turn towards characterizing the entropy of "easy" versus "hard" evaluation votes from LLM judges. Our corrective baseline enables future research on self-preference by eliminating noisy data from potential solutions. More widely, this work contributes to the growing body of work on cataloging and isolating judge-bias effects.

</details>


### [21] [SpanNorm: Reconciling Training Stability and Performance in Deep Transformers](https://arxiv.org/abs/2601.22580)
*Chao Wang,Bei Li,Jiaqi Zhang,Xinyu Liu,Yuchun Fan,Linkun Lyu,Xin Chen,Jingang Wang,Tong Xiao,Peng Pei,Xunliang Cai*

Main category: cs.CL

TL;DR: SpanNorm是一种新的Transformer归一化方法，通过建立跨越整个Transformer块的残差连接来稳定训练，同时采用PostNorm风格的计算来提升性能，解决了PreNorm和PostNorm之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: Transformer架构中归一化层的放置存在根本性权衡：PreNorm架构确保训练稳定性但可能导致深度模型性能下降，而PostNorm架构提供强大性能但存在严重的训练不稳定性。需要一种方法能够同时获得两者的优势。

Method: 提出SpanNorm技术，建立跨越整个Transformer块的干净残差连接以稳定信号传播，同时采用PostNorm风格的计算来归一化聚合输出以增强模型性能。结合原则性的缩放策略来维持网络中的有界信号方差。

Result: 理论分析表明SpanNorm结合缩放策略能够维持有界信号方差，防止PostNorm模型的梯度问题，并缓解PreNorm的表示崩溃。实证结果显示SpanNorm在密集和MoE场景中均优于标准归一化方案。

Conclusion: SpanNorm成功解决了Transformer架构中归一化层放置的权衡问题，为更强大和稳定的Transformer架构铺平了道路，结合了PreNorm的训练稳定性和PostNorm的性能优势。

Abstract: The success of Large Language Models (LLMs) hinges on the stable training of deep Transformer architectures. A critical design choice is the placement of normalization layers, leading to a fundamental trade-off: the ``PreNorm'' architecture ensures training stability at the cost of potential performance degradation in deep models, while the ``PostNorm'' architecture offers strong performance but suffers from severe training instability. In this work, we propose SpanNorm, a novel technique designed to resolve this dilemma by integrating the strengths of both paradigms. Structurally, SpanNorm establishes a clean residual connection that spans the entire transformer block to stabilize signal propagation, while employing a PostNorm-style computation that normalizes the aggregated output to enhance model performance. We provide a theoretical analysis demonstrating that SpanNorm, combined with a principled scaling strategy, maintains bounded signal variance throughout the network, preventing the gradient issues that plague PostNorm models, and also alleviating the representation collapse of PreNorm. Empirically, SpanNorm consistently outperforms standard normalization schemes in both dense and Mixture-of-Experts (MoE) scenarios, paving the way for more powerful and stable Transformer architectures.

</details>


### [22] [Rethinking LLM-as-a-Judge: Representation-as-a-Judge with Small Language Models via Semantic Capacity Asymmetry](https://arxiv.org/abs/2601.22588)
*Zhuochun Li,Yong Zhang,Ming Li,Yuelyu Ji,Yiming Zeng,Ning Cheng,Yun Zhu,Yanmeng Wang,Shaojun Wang,Jing Xiao,Daqing He*

Main category: cs.CL

TL;DR: 本文提出Representation-as-a-Judge新范式，通过小模型的内部表征而非生成输出来进行评价任务，比传统LLM-as-a-Judge更高效可靠。


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用的"LLM-as-a-Judge"范式存在成本高、不透明、对提示设计敏感等问题，需要探索更高效的评估方法。

Method: 提出语义容量不对称假设：评价任务比生成任务需要更少的语义容量，可以通过小模型的中间表征实现。基于此开发INSPECTOR框架，通过探测小模型的内部表征来预测评价分数。

Result: 在推理基准测试（GSM8K、MATH、GPQA）上，INSPECTOR显著优于基于提示的小模型，性能接近完整的大语言模型法官，同时提供更高效、可靠和可解释的评估方案。

Conclusion: 小模型的内部表征包含丰富的评价信号，Representation-as-a-Judge范式为可扩展评估提供了更高效、可靠和可解释的替代方案，有望取代传统的LLM-as-a-Judge范式。

Abstract: Large language models (LLMs) are widely used as reference-free evaluators via prompting, but this "LLM-as-a-Judge" paradigm is costly, opaque, and sensitive to prompt design. In this work, we investigate whether smaller models can serve as efficient evaluators by leveraging internal representations instead of surface generation. We uncover a consistent empirical pattern: small LMs, despite with weak generative ability, encode rich evaluative signals in their hidden states. This motivates us to propose the Semantic Capacity Asymmetry Hypothesis: evaluation requires significantly less semantic capacity than generation and can be grounded in intermediate representations, suggesting that evaluation does not necessarily need to rely on large-scale generative models but can instead leverage latent features from smaller ones. Our findings motivate a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge, a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output. We instantiate this paradigm through INSPECTOR, a probing-based framework that predicts aspect-level evaluation scores from small model representations. Experiments on reasoning benchmarks (GSM8K, MATH, GPQA) show that INSPECTOR substantially outperforms prompting-based small LMs and closely approximates full LLM judges, while offering a more efficient, reliable, and interpretable alternative for scalable evaluation.

</details>


### [23] [Language Model Circuits Are Sparse in the Neuron Basis](https://arxiv.org/abs/2601.22594)
*Aryaman Arora,Zhengxuan Wu,Jacob Steinhardt,Sarah Schwettmann*

Main category: cs.CL

TL;DR: 研究发现MLP神经元与稀疏自编码器一样稀疏，可直接用于电路追踪，无需额外训练成本


<details>
  <summary>Details</summary>
Motivation: 神经网络的高层概念不一定与单个神经元对齐，传统方法使用稀疏自编码器分解神经元基础，但并非所有基于神经元的表示都不可解释

Method: 首次实证证明MLP神经元与SAEs一样稀疏，开发了基于MLP神经元的端到端电路追踪流程，使用基于梯度的归因方法定位因果电路

Result: 在主语-动词一致基准任务中，约100个MLP神经元足以控制模型行为；在多跳城市→州→首都任务中，发现小神经元集编码特定潜在推理步骤，可通过引导改变模型输出

Conclusion: 这项工作无需额外训练成本即可推进语言模型的自动化可解释性，MLP神经元本身可作为有效的特征基础用于电路分析

Abstract: The high-level concepts that a neural network uses to perform computation need not be aligned to individual neurons (Smolensky, 1986). Language model interpretability research has thus turned to techniques such as \textit{sparse autoencoders} (SAEs) to decompose the neuron basis into more interpretable units of model computation, for tasks such as \textit{circuit tracing}. However, not all neuron-based representations are uninterpretable. For the first time, we empirically show that \textbf{MLP neurons are as sparse a feature basis as SAEs}. We use this finding to develop an end-to-end pipeline for circuit tracing on the MLP neuron basis, which locates causal circuitry on a variety of tasks using gradient-based attribution. On a standard subject-verb agreement benchmark (Marks et al., 2025), a circuit of $\approx 10^2$ MLP neurons is enough to control model behaviour. On the multi-hop city $\to$ state $\to$ capital task from Lindsey et al., 2025, we find a circuit in which small sets of neurons encode specific latent reasoning steps (e.g.~`map city to its state'), and can be steered to change the model's output. This work thus advances automated interpretability of language models without additional training costs.

</details>


### [24] [Layer-wise Swapping for Generalizable Multilingual Safety](https://arxiv.org/abs/2601.22620)
*Hyunseo Shin,Wonseok Hwang*

Main category: cs.CL

TL;DR: 提出一种安全感知层交换方法，将英语安全专家的安全对齐能力转移到低资源语言专家模型，无需额外训练，提升低资源语言的安全性


<details>
  <summary>Details</summary>
Motivation: 现有安全数据集主要针对英语，限制了多语言安全对齐的进展。低资源专家模型在各自指令数据集上微调后，往往比高资源模型表现出更高的不安全率

Method: 采用安全感知层交换方法，将英语安全专家的安全对齐能力转移到低资源语言专家。通过自适应选择或混合模块，基于其专业化程度增强转移能力

Result: 在MMMLU、BELEBELE和MGSM等通用基准测试中保持与语言专家相当的性能，同时在MultiJail安全基准测试中产生更对齐、危害更小的响应

Conclusion: 该方法能有效提升低资源语言模型的安全性，同时保持通用语言理解能力，为多语言安全对齐提供了有效解决方案

Abstract: Despite the rapid advancements of Large Language Models (LLMs), safety risks remain a critical challenge for low-resource languages. Existing safety datasets are predominantly English centric, limiting progress in multilingual safety alignment. As a result, low resource expert models, finetuned on their respective instruction datasets, tend to exhibit higher unsafety rates compared to their high resource counterparts. In this work, we propose a safety aware layer swapping method that transfers safety alignment from an English safety expert to low resource language experts without additional training. To further enhance transfer ability, our method adaptively selects or blends modules based on their degree of specialization. Our approach preserves performance on general language understanding tasks while enhancing safety in the target languages. Experimental results show that the proposed method achieves comparable performance to the language expert on general benchmarks such as MMMLU, BELEBELE, and MGSM, while producing more aligned and less harmful responses on the MultiJail safety benchmark.

</details>


### [25] [Time-Annealed Perturbation Sampling: Diverse Generation for Diffusion Language Models](https://arxiv.org/abs/2601.22629)
*Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Yiqiao Huang,Ivor Tsang,Yang You*

Main category: cs.CL

TL;DR: 本文提出TAPS方法，利用扩散语言模型的时间结构特性，在早期去噪阶段鼓励语义分支以增加多样性，后期减少扰动保持流畅度，无需额外训练即可提升生成多样性。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型引入了显式的时间维度，但如何利用这一结构来控制生成多样性、探索多个有效的语义或推理路径尚未得到充分研究。作者发现扩散语言模型存在时间分工特性，希望利用这一特性来平衡生成多样性与质量。

Method: 提出Time-Annealed Perturbation Sampling (TAPS)方法，这是一种无需训练的策略。基于扩散模型早期去噪步骤决定全局语义结构、后期步骤专注于局部词汇精炼的观察，TAPS在扩散过程早期鼓励语义分支，同时逐步减少扰动以保持流畅度和指令遵循性。该方法兼容非自回归和半自回归扩散骨干网络。

Result: 在LLaDA和TraDo等模型上验证，TAPS在创意写作和推理基准测试中一致地提高了输出多样性，同时不损害生成质量。该方法展示了扩散语言模型时间结构在控制生成多样性方面的潜力。

Conclusion: 扩散语言模型具有时间分工特性，早期步骤决定语义结构，后期步骤负责词汇精炼。TAPS方法利用这一特性，通过时间退火扰动采样策略，在无需额外训练的情况下有效平衡了生成多样性与质量，为扩散语言模型的控制生成提供了新思路。

Abstract: Diffusion language models (Diffusion-LMs) introduce an explicit temporal dimension into text generation, yet how this structure can be leveraged to control generation diversity for exploring multiple valid semantic or reasoning paths remains underexplored. In this paper, we show that Diffusion-LMs, like diffusion models in image generation, exhibit a temporal division of labor: early denoising steps largely determine the global semantic structure, while later steps focus on local lexical refinement. Building on this insight, we propose Time-Annealed Perturbation Sampling (TAPS), a training-free inference strategy that encourages semantic branching early in the diffusion process while progressively reducing perturbations to preserve fluency and instruction adherence. TAPS is compatible with both non-autoregressive and semi-autoregressive Diffusion backbones, demonstrated on LLaDA and TraDo in our paper, and consistently improves output diversity across creative writing and reasoning benchmarks without compromising generation quality.

</details>


### [26] [DART-ing Through the Drift: Dynamic Tracing of Knowledge Neurons for Adaptive Inference-Time Pruning](https://arxiv.org/abs/2601.22632)
*Abhishek Tyagi,Yunuo Cen,Shrey Dhorajiya,Bharadwaj Veeravalli,Xuanyao Fong*

Main category: cs.CL

TL;DR: DART是一种轻量级、无需训练的动态剪枝方法，通过监控注意力分数分布变化来实时调整神经元掩码，在保持模型性能的同时显著减少FFN参数冗余。


<details>
  <summary>Details</summary>
Motivation: 现有LLM剪枝方法存在两个主要问题：1）依赖数据集特定校准，导致数据依赖性和计算开销大；2）主要是静态方法，无法适应自回归生成过程中上下文变化时知识神经元的动态演变。

Method: 提出DART（动态注意力引导运行时追踪）方法，通过监控注意力分数分布的变化来推断上下文变化，动态更新神经元级掩码以保留重要参数。该方法无需训练，内存占用小（<10MB），FLOPs开销仅0.1%。

Result: 在10个基准测试中，DART优于现有动态基线方法，在LLAMA-3.1-8B模型70% FFN稀疏度下准确率提升达14.5%。在摘要任务中，ROUGE-L分数比静态掩码剪枝高3倍，性能接近原始密集模型。

Conclusion: DART框架能有效适应不同语义上下文，在通用和领域特定任务中保持模型能力，同时显著减少计算和内存开销，为解决LLM参数冗余问题提供了有效的动态剪枝方案。

Abstract: Large Language Models (LLMs) exhibit substantial parameter redundancy, particularly in Feed-Forward Networks (FFNs). Existing pruning methods suffer from two primary limitations. First, reliance on dataset-specific calibration introduces significant data dependency and computational overhead. Second, being predominantly static, they fail to account for the evolving subset of knowledge neurons in LLMs during autoregressive generation as the context evolves. To address this, we introduce DART, i.e., Dynamic Attention-Guided Runtime Tracing), a lightweight, training-free method that performs on-the-fly context-based pruning. DART monitors shifts in attention score distributions to infer context changes, dynamically updating neuron-level masks to retain salient parameters. Across ten benchmarks, DART outperforms prior dynamic baseline, achieving accuracy gains of up to 14.5% on LLAMA-3.1-8B at 70% FFN sparsity. Furthermore, DART achieves up to 3x better ROUGE-L scores with respect to static-masked pruning on summarization tasks, with its performance comparable to the original dense models. We conclusively demonstrate that the proposed framework effectively adapts to diverse semantic contexts, preserves model capabilities across both general and domain-specific tasks while running at less than 10MBs of memory for LLAMA-3.1-8B(16GBs) with 0.1% FLOPs overhead. The code is available at https://github.com/seeder-research/DART.

</details>


### [27] [NAG: A Unified Native Architecture for Encoder-free Text-Graph Modeling in Language Models](https://arxiv.org/abs/2601.22657)
*Haisong Gong,Zhibo Liu,Qiang Liu,Shu Wu,Liang Wang*

Main category: cs.CL

TL;DR: NAG提出了一种将图处理内化到语言模型原生架构中的统一框架，无需外部GNN编码器，通过改造自注意力机制和位置编码来同时处理文本语义和图结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法将图结构编码（通过外部GNN）与文本语义处理（通过LM）分离，这种分离架构在文本图建模中存在问题：需要在抽象图标记和具体文本元素之间进行复杂的隐式对齐，导致概念上不连贯的交互范式。

Method: NAG通过重新利用自注意力机制来强制执行拓扑依赖关系，并重新校准位置ID以确保结构等价性，将图处理内化到LM的原生流形中。提出了两种高效实现：NAG-Zero（绝对保留基础模型的语言能力）和NAG-LoRA（增强结构适应能力）。

Result: 在多种图任务上的实验验证了NAG能够在不使用外部编码器的情况下实现稳健的图理解，为文本图建模提供了更简单、更连贯的范式。

Conclusion: NAG挑战了外部编码器的必要性，提出了一种统一的框架，使模型能够利用其内在的语言能力同时理解节点和边内容以及结构拓扑，为文本图建模提供了更优的解决方案。

Abstract: Prevailing methods for integrating graphs into Language Models (LMs) typically rely on a segregated architecture: external Graph Neural Networks (GNNs) encode structural topology, while LMs process textual semantics. We argue this approach is suboptimal for text-graphs: it creates a conceptually disjointed interaction paradigm. By segregating structural encoding from semantic processing, these systems must perform a complex implicit alignment between abstract graph tokens and concrete textual elements. Challenging the necessity of external encoders, we propose NAG (Native Architecture for Graphs), a unified framework that internalizes graph processing within the LM's native manifold. Instead of bridging disparate embedding spaces, NAG repurposes the self-attention mechanism to enforce topological dependencies and recalibrates positional IDs to ensure structural equivalence. This allows the model to harness its intrinsic linguistic capability to simultaneously comprehend node and edge content alongside structural topology. We introduce two efficient implementations: NAG-Zero for absolute preservation of the base model's linguistic capabilities, and NAG-LoRA for enhanced structural adaptation. Experiments across diverse graph tasks validate that NAG achieves robust graph comprehension without the overhead of external encoders, offering a simpler, more coherent paradigm for text-graph modeling.

</details>


### [28] [TSLM: Tree-Structured Language Modeling for Divergent Thinking](https://arxiv.org/abs/2601.22688)
*Doyoung Kim,Jaehyeok Doo,Minjoon Seo*

Main category: cs.CL

TL;DR: TSLM通过树状结构语言建模，让语言模型在单次生成过程中编码分支搜索路径，避免重复计算共享前缀，提升推理效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型按顺序生成推理，无法解耦无关的探索路径，导致搜索效率低下。需要一种方法让模型能够系统性地探索多个路径，同时避免重复计算。

Method: 提出树状结构语言建模(TSLM)，使用特殊token编码分支结构，让模型在单次生成过程中生成和选择性扩展多个搜索路径。通过训练包含成功和失败尝试的完整搜索树，让模型内化系统性探索能力。

Result: TSLM实现了鲁棒的性能和优越的推理效率，避免了外部搜索方法所需的多次独立前向传递。在推理时间扩展方面展示了新的范式。

Conclusion: 监督学习完整的树状结构轨迹为开发语言模型的系统性探索能力提供了高效替代方案，表明通过训练而非外部搜索机制可以内化探索能力。

Abstract: Language models generate reasoning sequentially, preventing them from decoupling irrelevant exploration paths during search. We introduce Tree-Structured Language Modeling (TSLM), which uses special tokens to encode branching structure, enabling models to generate and selectively expand multiple search paths within a single generation process. By training on complete search trees including both successful and failed attempts, TSLM learns to internalize systematic exploration without redundant recomputation of shared prefixes. TSLM achieves robust performance and superior inference efficiency by avoiding the multiple independent forward passes required by external search methods. These results suggest a new paradigm of inference-time scaling for robust reasoning, demonstrating that supervised learning on complete tree-structured traces provides an efficient alternative for developing systematic exploration capabilities in language models.

</details>


### [29] [FNF: Functional Network Fingerprint for Large Language Models](https://arxiv.org/abs/2601.22692)
*Yiheng Liu,Junhao Ning,Sichen Xia,Haiyang Sun,Yang Yang,Hanyang Chi,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 提出Functional Network Fingerprint (FNF)方法，通过分析语言模型神经元活动模式的一致性来检测模型是否源自同一来源，无需训练、样本高效，能有效保护开源LLM的知识产权。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型开发成本高昂且具有重要商业价值，防止未经授权的开源模型盗用和保护开发者知识产权成为关键挑战。需要一种有效的方法来检测嫌疑模型是否源自受害者模型。

Method: 提出Functional Network Fingerprint (FNF)方法，基于功能网络活动的一致性来检测模型来源。该方法无需训练，仅需少量样本进行验证，通过分析不同输入样本下神经元活动模式的一致性来判断模型是否共享共同起源。

Result: 实验表明，共享共同起源的模型（即使规模或架构不同）在功能网络中表现出高度一致的神经元活动模式。而独立训练或目标不同的模型则无法保持这种活动对齐。该方法对常见模型修改（微调、剪枝、参数置换）以及跨架构和维度比较都具有鲁棒性。

Conclusion: FNF为模型所有者和第三方提供了一个简单、非侵入性且有效的工具来保护LLM知识产权，仅需少量样本即可验证，同时保持模型实用性。

Abstract: The development of large language models (LLMs) is costly and has significant commercial value. Consequently, preventing unauthorized appropriation of open-source LLMs and protecting developers' intellectual property rights have become critical challenges. In this work, we propose the Functional Network Fingerprint (FNF), a training-free, sample-efficient method for detecting whether a suspect LLM is derived from a victim model, based on the consistency between their functional network activity. We demonstrate that models that share a common origin, even with differences in scale or architecture, exhibit highly consistent patterns of neuronal activity within their functional networks across diverse input samples. In contrast, models trained independently on distinct data or with different objectives fail to preserve such activity alignment. Unlike conventional approaches, our method requires only a few samples for verification, preserves model utility, and remains robust to common model modifications (such as fine-tuning, pruning, and parameter permutation), as well as to comparisons across diverse architectures and dimensionalities. FNF thus provides model owners and third parties with a simple, non-invasive, and effective tool for protecting LLM intellectual property. The code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [30] [Models Know Models Best: Evaluation via Model-Preferred Formats](https://arxiv.org/abs/2601.22699)
*Joonhak Lee,Sungmok Jung,Jongyeon Park,Jaejin Lee*

Main category: cs.CL

TL;DR: LLMs在符号式和完形填空式多选题评估中表现差异显著，作者提出动态格式对齐策略，利用轻量级分类器根据模型偏好信号选择最优格式，显著提升零样本准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在符号式和完形填空式多选题评估中存在系统性差异，现有启发式方法往往降低性能，需要一种能根据具体问题动态选择最优评估格式的方法。

Method: 提出动态格式对齐策略，训练轻量级分类器基于模型生成的潜在偏好信号，为每个问题实例自动选择最优评估格式（符号式或完形填空式）。

Result: 该方法在推理和知识基准测试中实现了显著且一致的零样本准确率提升，更好地揭示了模型的潜在能力，优于人工设计的启发式方法。

Conclusion: LLMs在不同多选题格式中的性能差异是系统性的，通过动态格式对齐策略可以显著提升评估准确性，这为更准确地评估LLM能力提供了新方法。

Abstract: Performance of Large Language Models (LLMs) on multiple-choice tasks differs markedly between symbol-based and cloze-style evaluation formats. The observed discrepancies are systematically attributable to task characteristics: natural language continuation benefits from likelihood scoring, whereas explicit comparison is better suited to symbol-based selection. These trends are consistent across various decoder-based LLMs, indicating model-agnostic effects. To address these inconsistencies, a dynamic format-alignment strategy is introduced that employs a lightweight classifier trained on latent model-preference signals. In contrast to human-designed heuristics, which often degrade performance, this approach uses model-generated signals to determine the optimal format for each problem instance. The proposed method achieves substantial and consistent improvements in zero-shot accuracy across reasoning and knowledge benchmarks, better revealing the models' latent capabilities.

</details>


### [31] [MM-THEBench: Do Reasoning MLLMs Think Reasonably?](https://arxiv.org/abs/2601.22735)
*Zhidian Huang,Zijun Yao,Ji Qi,Shangqing Tu,Junxian Ma,Jinxin Liu,Weichuan Liu,Xiaoyin Che,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: MM-THEBench：首个评估推理型多模态大语言模型中间思维链幻觉的基准，包含细粒度认知分类、多样化数据和自动化评估框架


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注推理型MLLMs出现之前的模型，忽略了内部思维过程，无法衡量思维过程中产生的幻觉。需要专门评估推理型MLLMs中间思维链幻觉的基准。

Method: 提出MM-THEBench基准，包含：1）基于认知维度的细粒度分类法；2）带有验证推理标注的多样化数据；3）多层次自动化评估框架

Result: 对主流推理型MLLMs进行广泛实验，揭示了思维如何影响各种多模态任务中的幻觉和推理能力

Conclusion: MM-THEBench填补了评估推理型MLLMs中间思维链幻觉的空白，为理解思维过程对幻觉的影响提供了重要工具

Abstract: Recent advances in multimodal large language models (MLLMs) mark a shift from non-thinking models to post-trained reasoning models capable of solving complex problems through thinking. However, whether such thinking mitigates hallucinations in multimodal perception and reasoning remains unclear. Self-reflective reasoning enhances robustness but introduces additional hallucinations, and subtle perceptual errors still result in incorrect or coincidentally correct answers. Existing benchmarks primarily focus on models before the emergence of reasoning MLLMs, neglecting the internal thinking process and failing to measure the hallucinations that occur during thinking. To address these challenges, we introduce MM-THEBench, a comprehensive benchmark for assessing hallucinations of intermediate CoTs in reasoning MLLMs. MM-THEBench features a fine-grained taxonomy grounded in cognitive dimensions, diverse data with verified reasoning annotations, and a multi-level automated evaluation framework. Extensive experiments on mainstream reasoning MLLMs reveal insights into how thinking affects hallucination and reasoning capability in various multimodal tasks.

</details>


### [32] [AR-BENCH: Benchmarking Legal Reasoning with Judgment Error Detection, Classification and Correction](https://arxiv.org/abs/2601.22742)
*Yifei Li,Richong Zhang,Wanyu Tu,Zhijie Nie,Haokun Luo,Chuantao Yin,Pengchong Li*

Main category: cs.CL

TL;DR: 论文提出了一个新的法律AI任务"上诉审查"，专注于检测、分类和纠正已发布判决中的错误，而非预测或生成。作者构建了AR-BENCH数据集并评估了14个大语言模型，揭示了现有模型在识别法律应用错误方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有法律AI研究主要关注判决预测和法律文档生成，但判决审查任务在目标和范式上完全不同——它是在判决发布后检测、分类和纠正错误，属于异常检测而非预测或生成。同时，现实中的上诉审查机制面临案件数量激增带来的效率压力。

Method: 1) 提出新的法律AI任务"上诉审查"；2) 构建AR-BENCH数据集，包含8,700个精细标注的判决和34,617个补充语料；3) 评估14个大语言模型在该任务上的表现。

Result: 评估显示现有大语言模型在识别法律应用错误方面存在关键局限性，为未来改进提供了实证证据。

Conclusion: 论文填补了法律AI研究中判决审查任务的空白，提出了新的研究方向，并通过实证评估揭示了当前模型的不足，为开发更可靠的法律AI系统提供了基础。

Abstract: Legal judgments may contain errors due to the complexity of case circumstances and the abstract nature of legal concepts, while existing appellate review mechanisms face efficiency pressures from a surge in case volumes. Although current legal AI research focuses on tasks like judgment prediction and legal document generation, the task of judgment review differs fundamentally in its objectives and paradigm: it centers on detecting, classifying, and correcting errors after a judgment is issued, constituting anomaly detection rather than prediction or generation. To address this research gap, we introduce a novel task APPELLATE REVIEW, aiming to assess models' diagnostic reasoning and reliability in legal practice. We also construct a novel dataset benchmark AR-BENCH, which comprises 8,700 finely annotated decisions and 34,617 supplementary corpora. By evaluating 14 large language models, we reveal critical limitations in existing models' ability to identify legal application errors, providing empirical evidence for future improvements.

</details>


### [33] [RASST: Fast Cross-modal Retrieval-Augmented Simultaneous Speech Translation](https://arxiv.org/abs/2601.22777)
*Jiaxuan Luo,Siqi Ouyang,Lei Li*

Main category: cs.CL

TL;DR: RASST提出检索增强的同步语音翻译方法，通过跨模态检索和滑动窗口检索为语音大语言模型提供术语提示，显著提升术语翻译准确率和整体翻译质量。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型在同步语音翻译中仍难以准确翻译罕见和领域特定术语，而检索增强在机器翻译中已被证明有效，但将其应用于同步语音翻译面临跨模态检索、部分输入和增量生成决策等挑战。

Method: 提出RASST框架：1)训练轻量级语音-文本检索器；2)采用高效滑动窗口检索；3)合成训练数据教导语音大语言模型精确利用检索到的术语；4)将检索到的术语提示集成到同步语音翻译流程中。

Result: 在ACL 60/60开发集的三个语言方向上，RASST将术语翻译准确率提升高达16%，整体翻译质量提升高达3个BLEU分数，消融实验验证了各组件贡献。

Conclusion: RASST成功将检索增强技术集成到同步语音翻译中，有效解决了术语翻译难题，通过跨模态检索和增量生成决策机制显著提升了翻译质量。

Abstract: Simultaneous speech translation (SST) produces target text incrementally from partial speech input. Recent speech large language models (Speech LLMs) have substantially improved SST quality, yet they still struggle to correctly translate rare and domain-specific terminology. While retrieval augmentation has been effective for terminology translation in machine translation, bringing retrieval to SST is non-trivial: it requires fast and accurate cross-modal (speech-to-text) retrieval under partial, continually arriving input, and the model must decide whether and when to apply retrieved terms during incremental generation. We propose Retrieval-Augmented Simultaneous Speech Translation (RASST), which tightly integrates cross-modal retrieval into the SST pipeline. RASST trains a lightweight speech-text retriever and performs efficient sliding-window retrieval, providing chunkwise terminology hints to the Speech LLM. We further synthesize training data that teaches the Speech LLM to leverage retrieved terms precisely. Experiments on three language directions of the ACL 60/60 dev set show that RASST improves terminology translation accuracy by up to 16% and increases overall translation quality by up to 3 BLEU points, with ablations confirming the contribution of each component.

</details>


### [34] [Sparse or Dense? A Mechanistic Estimation of Computation Density in Transformer-based LLMs](https://arxiv.org/abs/2601.22795)
*Corentin Kervadec,Iuliia Lysova,Marco Baroni,Gemma Boleda*

Main category: cs.CL

TL;DR: 本文提出了一种量化大语言模型计算密度的方法，发现LLM计算通常是密集的而非稀疏的，且密度随输入动态变化，与罕见词预测和上下文长度相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明可以大幅剪枝LLM参数而性能影响很小，这表明计算在参数中并非均匀分布。然而，目前缺乏系统量化LLM计算密度的方法，无法准确理解LLM内部的计算模式。

Method: 基于机制可解释性设计了一个计算密度估计器，通过实验分析LLM的计算密度特性，包括密度分布、动态变化模式以及与输入特征的关系。

Result: 发现：(1) LLM处理通常涉及密集计算而非稀疏计算；(2) 计算密度是动态的，模型根据输入在稀疏和密集处理模式间切换；(3) 不同LLM的每输入密度显著相关；(4) 预测罕见词需要更高密度，增加上下文长度通常会降低密度。

Conclusion: 计算密度估计器有助于更好地理解LLM的工作机制，挑战了LLM的符号解释观点，揭示了计算密度与输入特征之间的系统关系。

Abstract: Transformer-based large language models (LLMs) are comprised of billions of parameters arranged in deep and wide computational graphs. Several studies on LLM efficiency optimization argue that it is possible to prune a significant portion of the parameters, while only marginally impacting performance. This suggests that the computation is not uniformly distributed across the parameters. We introduce here a technique to systematically quantify computation density in LLMs. In particular, we design a density estimator drawing on mechanistic interpretability. We experimentally test our estimator and find that: (1) contrary to what has been often assumed, LLM processing generally involves dense computation; (2) computation density is dynamic, in the sense that models shift between sparse and dense processing regimes depending on the input; (3) per-input density is significantly correlated across LLMs, suggesting that the same inputs trigger either low or high density. Investigating the factors influencing density, we observe that predicting rarer tokens requires higher density, and increasing context length often decreases the density. We believe that our computation density estimator will contribute to a better understanding of the processing at work in LLMs, challenging their symbolic interpretation.

</details>


### [35] [When Meanings Meet: Investigating the Emergence and Quality of Shared Concept Spaces during Multilingual Language Model Training](https://arxiv.org/abs/2601.22851)
*Felicia Körner,Max Müller-Eberstein,Anna Korhonen,Barbara Plank*

Main category: cs.CL

TL;DR: 本文研究多语言大语言模型训练中跨语言概念空间的形成过程，通过因果解释方法发现共享概念空间早期出现但语言对齐存在差异，某些翻译质量提升实际是行为改变而非翻译能力改进。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注最终模型，缺乏对多语言LLM训练过程中跨语言概念空间形成动态的理解，且先前研究多使用非因果方法，缺乏深入错误分析，需要探究这些空间如何在训练中涌现。

Method: 使用因果解释方法中的激活修补技术，在EuroLLM预训练过程中隔离跨语言概念表示，然后将其注入翻译提示中，研究不同语言下翻译行为的一致性变化。

Result: 发现共享概念空间在训练早期就出现并持续细化，但对齐程度具有语言依赖性。精细人工分析显示，某些翻译质量提升实际上是行为改变（如多义词义项选择、翻译而非复制跨语言同形词）而非翻译能力改进。

Conclusion: 研究揭示了跨语言对齐的训练动态新见解，并明确了因果解释方法在多语言语境下提供有意义洞察的条件，对理解多语言LLM概念空间形成机制有重要贡献。

Abstract: Training Large Language Models (LLMs) with high multilingual coverage is becoming increasingly important -- especially when monolingual resources are scarce. Recent studies have found that LLMs process multilingual inputs in shared concept spaces, thought to support generalization and cross-lingual transfer. However, these prior studies often do not use causal methods, lack deeper error analysis or focus on the final model only, leaving open how these spaces emerge during training. We investigate the development of language-agnostic concept spaces during pretraining of EuroLLM through the causal interpretability method of activation patching. We isolate cross-lingual concept representations, then inject them into a translation prompt to investigate how consistently translations can be altered, independently of the language. We find that shared concept spaces emerge early} and continue to refine, but that alignment with them is language-dependent}. Furthermore, in contrast to prior work, our fine-grained manual analysis reveals that some apparent gains in translation quality reflect shifts in behavior -- like selecting senses for polysemous words or translating instead of copying cross-lingual homographs -- rather than improved translation ability. Our findings offer new insight into the training dynamics of cross-lingual alignment and the conditions under which causal interpretability methods offer meaningful insights in multilingual contexts.

</details>


### [36] [From Labels to Facets: Building a Taxonomically Enriched Turkish Learner Corpus](https://arxiv.org/abs/2601.22875)
*Elif Sayar,Tolgahan Türker,Anna Golynskaia Knezhevich,Bihter Dereli,Ayşe Demirhas,Lionel Nicolas,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 提出半自动标注方法，基于分面分类法丰富学习者语料库标注，实现多维度错误分析


<details>
  <summary>Details</summary>
Motivation: 现有学习者语料库大多采用整体扁平标签体系，无法分离多个语言维度，限制了深入的语言学分析和细粒度错误原因探究

Method: 基于新提出的分面分类法构建半自动标注方法，开发标注扩展框架，为土耳其语实现自动扩展工具，将现有扁平标注推断为分类法中的多个分面

Result: 标注扩展工具达到95.86%的分面级别准确率，创建了首个协作标注且分类法丰富的土耳其学习者语料库，提供增强的查询能力和详细探索分析

Conclusion: 本研究提出了首个符合新分类法的语料库，为现有错误标注学习者语料库的后续丰富工作铺平道路

Abstract: In terms of annotation structure, most learner corpora rely on holistic flat label inventories which, even when extensive, do not explicitly separate multiple linguistic dimensions. This makes linguistically deep annotation difficult and complicates fine-grained analyses aimed at understanding why and how learners produce specific errors. To address these limitations, this paper presents a semi-automated annotation methodology for learner corpora, built upon a recently proposed faceted taxonomy, and implemented through a novel annotation extension framework. The taxonomy provides a theoretically grounded, multi-dimensional categorization that captures the linguistic properties underlying each error instance, thereby enabling standardized, fine-grained, and interpretable enrichment beyond flat annotations. The annotation extension tool, implemented based on the proposed extension framework for Turkish, automatically extends existing flat annotations by inferring additional linguistic and metadata information as facets within the taxonomy to provide richer learner-specific context. It was systematically evaluated and yielded promising performance results, achieving a facet-level accuracy of 95.86%. The resulting taxonomically enriched corpus offers enhanced querying capabilities and supports detailed exploratory analyses across learner corpora, enabling researchers to investigate error patterns through complex linguistic and pedagogical dimensions. This work introduces the first collaboratively annotated and taxonomically enriched Turkish Learner Corpus, a manual annotation guideline with a refined tagset, and an annotation extender. As the first corpus designed in accordance with the recently introduced taxonomy, we expect our study to pave the way for subsequent enrichment efforts of existing error-annotated learner corpora.

</details>


### [37] [Leveraging LLMs For Turkish Skill Extraction](https://arxiv.org/abs/2601.22885)
*Ezgi Arslan İltüzer,Özgür Anıl Özlü,Vahid Farajijobehdar,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 该研究针对土耳其语技能提取问题，创建了首个土耳其语技能提取数据集，并评估了LLM在低资源语言技能提取中的表现，发现Claude Sonnet 3.7结合动态少样本提示效果最佳。


<details>
  <summary>Details</summary>
Motivation: 土耳其作为全球劳动力市场重要组成部分，其语言土耳其语缺乏技能分类体系和专用数据集，导致该语言技能提取研究不足。研究旨在解决土耳其语这一形态复杂、资源匮乏语言的技能提取问题。

Method: 1) 创建首个土耳其语技能提取数据集（4,819个标注技能跨度，327个职位描述）；2) 评估LLM在技能提取中的表现，比较不同LLM和提示策略（动态vs静态少样本、不同上下文信息、因果推理鼓励）；3) 采用端到端流程：技能识别→嵌入检索→LLM重排序。

Result: LLM在端到端技能提取中优于监督序列标注方法，能更有效将提取的技能与ESCO分类体系对齐。最佳配置（Claude Sonnet 3.7+动态少样本提示+嵌入检索+LLM重排序）达到0.56的端到端性能，使土耳其语技能提取达到与其他语言相当水平。

Conclusion: LLM能提升低资源语言技能提取性能，该研究为资源匮乏语言技能提取提供了可行方案，有望加速对代表性不足语言的技能提取研究。

Abstract: Skill extraction is a critical component of modern recruitment systems, enabling efficient job matching, personalized recommendations, and labor market analysis. Despite Türkiye's significant role in the global workforce, Turkish, a morphologically complex language, lacks both a skill taxonomy and a dedicated skill extraction dataset, resulting in underexplored research in skill extraction for Turkish. This article seeks the answers to three research questions: 1) How can skill extraction be effectively performed for this language, in light of its low resource nature? 2)~What is the most promising model? 3) What is the impact of different Large Language Models (LLMs) and prompting strategies on skill extraction (i.e., dynamic vs. static few-shot samples, varying context information, and encouraging causal reasoning)? The article introduces the first Turkish skill extraction dataset and performance evaluations of automated skill extraction using LLMs. The manually annotated dataset contains 4,819 labeled skill spans from 327 job postings across different occupation areas. The use of LLM outperforms supervised sequence labeling when used in an end-to-end pipeline, aligning extracted spans with standardized skills in the ESCO taxonomy more effectively. The best-performing configuration, utilizing Claude Sonnet 3.7 with dynamic few-shot prompting for skill identification, embedding-based retrieval, and LLM-based reranking for skill linking, achieves an end-to-end performance of 0.56, positioning Turkish alongside similar studies in other languages, which are few in the literature. Our findings suggest that LLMs can improve skill extraction performance in low-resource settings, and we hope that our work will accelerate similar research on skill extraction for underrepresented languages.

</details>


### [38] [Should LLMs, $\textit{like}$, Generate How Users Talk? Building Dialect-Accurate Dialog[ue]s Beyond the American Default with MDial](https://arxiv.org/abs/2601.22888)
*Jio Oh,Paul Vicinanza,Thomas Butler,Steven Euijong Whang,Dezhi Hong,Amani Namboori*

Main category: cs.CL

TL;DR: MDial框架首次大规模生成多方言对话数据，涵盖9种英语方言的词汇、拼写和语法特征，挑战了模型应复制用户语法特征的假设，并构建了包含5万+对话的MDialBench基准测试，发现前沿LLM在方言识别任务上准确率低于70%。


<details>
  <summary>Details</summary>
Motivation: 超过80%的16亿英语使用者不使用标准美式英语，在与LLM交互时面临更高的失败率和刻板回应，但多方言性能研究不足，需要系统性的方言数据处理框架。

Method: 引入MDial框架，通过与母语语言学家合作，设计基于规则的可扩展LLM转换方法，生成涵盖词汇、拼写和语法三大支柱的多方言对话数据，涵盖9种英语方言。

Result: 评估显示98%的标注者认为MDial输出比先前方法更自然；构建的MDialBench包含5万+对话和9.7万+问答对；测试17个LLM发现前沿模型方言识别准确率低于70%，加拿大英语低于50%，非标准美式英语常被误判为美式或英式英语。

Conclusion: 多方言性能是LLM的重要挑战，方言识别错误可能导致下游任务级联失败；研究挑战了模型应复制用户语法特征的假设，发现高达90%的方言语法特征不应被模型复制。

Abstract: More than 80% of the 1.6 billion English speakers do not use Standard American English (SAE) and experience higher failure rates and stereotyped responses when interacting with LLMs as a result. Yet multi-dialectal performance remains underexplored. We introduce $\textbf{MDial}$, the first large-scale framework for generating multi-dialectal conversational data encompassing the three pillars of written dialect -- lexical (vocabulary), orthographic (spelling), and morphosyntactic (grammar) features -- for nine English dialects. Partnering with native linguists, we design an annotated and scalable rule-based LLM transformation to ensure precision. Our approach challenges the assumption that models should mirror users' morphosyntactic features, showing that up to 90% of the grammatical features of a dialect should not be reproduced by models. Independent evaluations confirm data quality, with annotators preferring MDial outputs over prior methods in 98% of pairwise comparisons for dialect naturalness. Using this pipeline, we construct the dialect-parallel $\textbf{MDialBench}$mark with 50k+ dialogs, resulting in 97k+ QA pairs, and evaluate 17 LLMs on dialect identification and response generation tasks. Even frontier models achieve under 70% accuracy, fail to reach 50% for Canadian English, and systematically misclassify non-SAE dialects as American or British. As dialect identification underpins natural language understanding, these errors risk cascading failures into downstream tasks.

</details>


### [39] [DiffuSpeech: Silent Thought, Spoken Answer via Unified Speech-Text Diffusion](https://arxiv.org/abs/2601.22889)
*Yuxuan Lou,Ziming Wu,Yaochen Wang,Yong Liu,Yingxuan Ren,Fuming Lai,Shaobing Lian,Jie Tang,Yang You*

Main category: cs.CL

TL;DR: 提出"静默思考，语音回答"范式，让语音LLM在生成语音回答时同时产生内部文本推理轨迹，通过扩散模型联合生成推理文本和语音token，在语音问答任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型直接生成语音回答而没有显式推理过程，导致错误一旦生成就无法修正。需要一种能够同时进行内部推理和语音生成的框架。

Method: 提出MASKED DIFFUSION框架，首个基于扩散的语音-文本语言模型，在单一掩码扩散框架下统一离散文本和token化语音。通过迭代去噪联合生成推理轨迹和语音token，使用模态特定的掩码调度策略。

Result: 在语音问答任务上达到SOTA准确率，比最佳基线提升高达9个百分点；在生成模型中达到最佳TTS质量（6.2% WER）；保持语言理解能力（66.2% MMLU）。

Conclusion: 提出的"静默思考，语音回答"范式通过扩散架构和内部推理轨迹的结合，显著提升了语音语言模型的生成质量和准确性，为语音AI系统提供了更可靠的推理能力。

Abstract: Current speech language models generate responses directly without explicit reasoning, leading to errors that cannot be corrected once audio is produced. We introduce \textbf{``Silent Thought, Spoken Answer''} -- a paradigm where speech LLMs generate internal text reasoning alongside spoken responses, with thinking traces informing speech quality. To realize this, we present \method{}, the first diffusion-based speech-text language model supporting both understanding and generation, unifying discrete text and tokenized speech under a single masked diffusion framework. Unlike autoregressive approaches, \method{} jointly generates reasoning traces and speech tokens through iterative denoising, with modality-specific masking schedules. We also construct \dataset{}, the first speech QA dataset with paired text reasoning traces, containing 26K samples totaling 319 hours. Experiments show \method{} achieves state-of-the-art speech-to-speech QA accuracy, outperforming the best baseline by up to 9 points, while attaining the best TTS quality among generative models (6.2\% WER) and preserving language understanding (66.2\% MMLU). Ablations confirm that both the diffusion architecture and thinking traces contribute to these gains.

</details>


### [40] [LLMs Explain't: A Post-Mortem on Semantic Interpretability in Transformer Models](https://arxiv.org/abs/2601.22928)
*Alhassan Abdelhalim,Janick Edinger,Sören Laue,Michaela Regneri*

Main category: cs.CL

TL;DR: 论文发现两种流行的LLM可解释性方法（注意力机制分析和嵌入特征映射）在检测语言抽象时都失败了，表明这些方法不能可靠地证明LLM的理解能力。


<details>
  <summary>Details</summary>
Motivation: LLM在普适计算中广泛应用但工作机制不明确，现有可解释性方法本身也不完全被理解。研究者想探究LLM中语言抽象是如何出现的，并检测其在不同模块中的表现。

Method: 使用两种文献中成熟的方法：(1) 基于注意力机制探测token级关系结构，(2) 使用嵌入作为人类可解释属性的载体进行特征映射。

Result: 两种方法都失败了：注意力解释在测试"后层表示仍对应token"的核心假设时崩溃；嵌入属性推断方法的高预测分数是由方法伪影和数据集结构驱动，而非有意义的语义知识。

Conclusion: 这些失败很重要，因为这两种技术被广泛用作LLM理解能力的证据，但结果显示这种结论是不合理的。在LLM作为系统组件部署的普适计算环境中，这些可解释性方法的局限性尤其值得关注。

Abstract: Large Language Models (LLMs) are becoming increasingly popular in pervasive computing due to their versatility and strong performance. However, despite their ubiquitous use, the exact mechanisms underlying their outstanding performance remain unclear. Different methods for LLM explainability exist, and many are, as a method, not fully understood themselves. We started with the question of how linguistic abstraction emerges in LLMs, aiming to detect it across different LLM modules (attention heads and input embeddings). For this, we used methods well-established in the literature: (1) probing for token-level relational structures, and (2) feature-mapping using embeddings as carriers of human-interpretable properties.
  Both attempts failed for different methodological reasons: Attention-based explanations collapsed once we tested the core assumption that later-layer representations still correspond to tokens. Property-inference methods applied to embeddings also failed because their high predictive scores were driven by methodological artifacts and dataset structure rather than meaningful semantic knowledge. These failures matter because both techniques are widely treated as evidence for what LLMs supposedly understand, yet our results show such conclusions are unwarranted. These limitations are particularly relevant in pervasive and distributed computing settings where LLMs are deployed as system components and interpretability methods are relied upon for debugging, compression, and explaining models.

</details>


### [41] [Benchmarking Machine Translation on Chinese Social Media Texts](https://arxiv.org/abs/2601.22931)
*Kaiyan Zhao,Zheyong Xie,Zhongtao Miao,Xinze Lyu,Yao Hu,Shaosheng Cao*

Main category: cs.CL

TL;DR: 提出了CSM-MTBench基准测试，用于评估机器翻译系统处理中文社交媒体中俚语、新词和风格化表达的能力，包含两个专家策划的子集和针对性评估方法。


<details>
  <summary>Details</summary>
Motivation: 中文社交媒体中快速演变的俚语、新词和高度风格化的表达对机器翻译基准测试构成挑战，主要存在数据稀缺和传统评估指标无法捕捉风格保真度的问题。

Method: 构建CSM-MTBench基准，包含五个中-外语言方向，两个专家策划子集：Fun Posts（俚语新词丰富内容）和Social Snippets（情感风格驱动表达）。为每个子集设计专门评估方法：Fun Posts测量俚语新词翻译成功率，Social Snippets通过嵌入指标和LLM作为评判者评估语气风格保留。

Result: 对20多个模型的实验显示，当前MT系统在处理语义保真度和非正式社交媒体特定风格线索方面存在显著差异，验证了基准的有效性。

Conclusion: CSM-MTBench为推进能够掌握真实世界中文社交媒体文本的MT系统提供了严格的测试平台，解决了现有基准在非正式表达评估方面的不足。

Abstract: The prevalence of rapidly evolving slang, neologisms, and highly stylized expressions in informal user-generated text, particularly on Chinese social media, poses significant challenges for Machine Translation (MT) benchmarking. Specifically, we identify two primary obstacles: (1) data scarcity, as high-quality parallel data requires bilingual annotators familiar with platform-specific slang, and stylistic cues in both languages; and (2) metric limitations, where traditional evaluators like COMET often fail to capture stylistic fidelity and nonstandard expressions. To bridge these gaps, we introduce CSM-MTBench, a benchmark covering five Chinese-foreign language directions and consisting of two expert-curated subsets: Fun Posts, featuring context-rich, slang- and neologism-heavy content, and Social Snippets, emphasizing concise, emotion- and style- driven expressions. Furthermore, we propose tailored evaluation approaches for each subset: measuring the translation success rate of slang and neologisms in Fun Posts, while assessing tone and style preservation in Social Snippets via a hybrid of embedding-based metrics and LLM-as-a-judge. Experiments on over 20 models reveal substantial variation in how current MT systems handle semantic fidelity and informal, social-media-specific stylistic cues. CSM-MTBench thus serves as a rigorous testbed for advancing MT systems capable of mastering real-world Chinese social media texts.

</details>


### [42] [Relaxing Positional Alignment in Masked Diffusion Language Models](https://arxiv.org/abs/2601.22947)
*Mengyu Ye,Ryosuke Takahashi,Keito Kudo,Jun Suzuki*

Main category: cs.CL

TL;DR: 提出一种通过松弛严格位置监督来改进掩码扩散语言模型在开放文本生成中性能的方法，使用<slack>标记和CTC目标进行微调


<details>
  <summary>Details</summary>
Motivation: 掩码扩散语言模型在开放文本生成上与自回归模型存在差距，研究发现严格位置预测使解码对标记错位高度敏感，位置偏移会严重破坏语义，表明训练中的严格位置监督与MDLM解码的不可逆去噪动态不匹配

Method: 在微调阶段采用对齐灵活的监督策略，通过连接时序分类目标引入特殊标记<slack>，放松严格的位置监督要求

Result: 在五个开放文本生成基准测试中，该方法一致优于原始模型，并提高了对位置偏移的鲁棒性

Conclusion: 放松严格位置监督是提高MDLM生成质量的重要因素，提出的对齐灵活监督策略能有效改善MDLM在开放文本生成中的性能

Abstract: Masked diffusion language models (MDLMs) have emerged as a promising alternative to dominant autoregressive approaches. Although they achieve competitive performance on several tasks, a substantial gap remains in open-ended text generation. We hypothesize that one cause of this gap is that strict positional prediction makes MDLM decoding highly sensitive to token misalignment, and we show through controlled interventions that a one-position shift can severely disrupt semantics. This observation suggests that enforcing strict positional supervision during training is misaligned with the irreversible denoising dynamics of MDLM decoding. Motivated by this mismatch, we adopt an alignment-flexible supervision strategy during fine-tuning. Specifically, we introduce a special token <slack> via the connectionist temporal classification objective. We apply this approach to the widely used MDLM model and conduct experiments on five open-ended text generation benchmarks. Our method consistently outperforms the original model and improves robustness to positional shifts, indicating that relaxing strict positional supervision is an important factor in improving generation quality in MDLMs.

</details>


### [43] [Autonomous Chain-of-Thought Distillation for Graph-Based Fraud Detection](https://arxiv.org/abs/2601.22949)
*Yuan Li,Jun Hu,Bryan Hooi,Bingsheng He,Cheng Chen*

Main category: cs.CL

TL;DR: FraudCoT：一个统一的图欺诈检测框架，通过自主的图感知思维链推理和可扩展的LLM-GNN协同训练，在文本属性图上实现高效的欺诈检测。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM增强的GNN方法受限于预定义提示和解耦的训练流程，限制了推理自主性并削弱了语义-结构对齐，需要更有效的文本属性图欺诈检测方法。

Method: 提出欺诈感知选择性思维链蒸馏机制生成多样推理路径，将蒸馏后的思维链整合到节点文本中；开发高效的非对称协同训练策略，实现端到端优化并大幅降低计算成本。

Result: 在公共和工业基准测试中，FraudCoT相比最先进方法实现了高达8.8%的AUPRC提升，训练吞吐量提高了1066倍，显著提升了检测性能和效率。

Conclusion: FraudCoT通过自主的图感知思维链推理和高效的LLM-GNN协同训练，在文本属性图欺诈检测中实现了性能与效率的双重突破，为图学习与LLM融合提供了新范式。

Abstract: Graph-based fraud detection on text-attributed graphs (TAGs) requires jointly modeling rich textual semantics and relational dependencies. However, existing LLM-enhanced GNN approaches are constrained by predefined prompting and decoupled training pipelines, limiting reasoning autonomy and weakening semantic-structural alignment. We propose FraudCoT, a unified framework that advances TAG-based fraud detection through autonomous, graph-aware chain-of-thought (CoT) reasoning and scalable LLM-GNN co-training. To address the limitations of predefined prompts, we introduce a fraud-aware selective CoT distillation mechanism that generates diverse reasoning paths and enhances semantic-structural understanding. These distilled CoTs are integrated into node texts, providing GNNs with enriched, multi-hop semantic and structural cues for fraud detection. Furthermore, we develop an efficient asymmetric co-training strategy that enables end-to-end optimization while significantly reducing the computational cost of naive joint training. Extensive experiments on public and industrial benchmarks demonstrate that FraudCoT achieves up to 8.8% AUPRC improvement over state-of-the-art methods and delivers up to 1,066x speedup in training throughput, substantially advancing both detection performance and efficiency.

</details>


### [44] [Residual Context Diffusion Language Models](https://arxiv.org/abs/2601.22954)
*Yuezhou Hu,Harman Singh,Monishwaran Maheswaran,Haocheng Xi,Coleman Hooper,Jintao Zhang,Aditya Tomar,Michael W. Mahoney,Sewon Min,Mehrdad Farajtabar,Kurt Keutzer,Amir Gholami,Chenfeng Xu*

Main category: cs.CL

TL;DR: RCD（残差上下文扩散）通过回收被丢弃的令牌计算来改进扩散大语言模型，减少去噪步骤并提升准确性


<details>
  <summary>Details</summary>
Motivation: 当前块状扩散大语言模型使用"重新掩码"机制时，只解码最自信的令牌而丢弃其余令牌，浪费了计算资源。这些被丢弃的令牌实际上保留了有用的上下文信息。

Method: 提出残差上下文扩散（RCD）模块，将被丢弃的令牌表示转换为上下文残差，并注入到下一个去噪步骤中。采用解耦的两阶段训练流程来避免内存瓶颈。

Result: RCD将前沿dLLM的准确性提升了5-10个百分点，计算开销最小。在最具挑战性的AIME任务上，RCD几乎将基线准确性翻倍，并在相同准确性水平下减少4-5倍去噪步骤。

Conclusion: RCD通过有效回收被丢弃令牌的计算资源，显著提升了扩散大语言模型的效率和性能，仅需约10亿令牌即可将标准dLLM转换为RCD范式。

Abstract: Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, state-of-the-art block-wise dLLMs rely on a "remasking" mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), a module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses a decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation. We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that a standard dLLM can be efficiently converted to the RCD paradigm with merely ~1 billion tokens. RCD consistently improves frontier dLLMs by 5-10 points in accuracy with minimal extra computation overhead across a wide range of benchmarks. Notably, on the most challenging AIME tasks, RCD nearly doubles baseline accuracy and attains up to 4-5x fewer denoising steps at equivalent accuracy levels.

</details>


### [45] [A Unified View of Attention and Residual Sinks: Outlier-Driven Rescaling is Essential for Transformer Training](https://arxiv.org/abs/2601.22966)
*Zihan Qiu,Zeyu Huang,Kaiyue Wen,Peng Jin,Bo Zheng,Yuxin Zhou,Haofeng Huang,Zekun Wang,Xiao Li,Huaqing Zhang,Yang Xu,Haoran Lian,Siqi Zhang,Rui Men,Jianwei Zhang,Ivan Titov,Dayiheng Liu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: 大语言模型中的异常值（注意力汇和残差汇）通过与归一化层协同作用实现重缩放功能，而非直接贡献，这种异常值驱动重缩放现象对训练稳定性和量化鲁棒性有重要作用。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型中涌现的异常值（注意力汇和残差汇）的功能性角色，理解它们如何与归一化层相互作用，以及这种相互作用对模型训练和性能的影响。

Method: 通过分析不同模型架构和训练token数量的实验，验证异常值驱动重缩放假说，包括：1）移除归一化观察异常值变化；2）直接裁剪异常值；3）将异常值吸收到可学习参数中；4）使用显式门控重缩放进行缓解。

Result: 1）异常值与归一化协同作用，移除任一方都会导致性能下降；2）异常值主要作为重缩放因子而非直接贡献者；3）通过参数吸收或门控重缩放可提升训练性能（平均2点增益）和量化鲁棒性（W4A4量化下仅1.2点下降）。

Conclusion: 异常值驱动重缩放现象统一解释了注意力汇和残差汇的起源与缓解方法，异常值通过与归一化层协同实现重缩放功能，对训练稳定性至关重要，可通过适当方法进行优化以提升模型性能。

Abstract: We investigate the functional role of emergent outliers in large language models, specifically attention sinks (a few tokens that consistently receive large attention logits) and residual sinks (a few fixed dimensions with persistently large activations across most tokens). We hypothesize that these outliers, in conjunction with the corresponding normalizations (\textit{e.g.}, softmax attention and RMSNorm), effectively rescale other non-outlier components. We term this phenomenon \textit{outlier-driven rescaling} and validate this hypothesis across different model architectures and training token counts. This view unifies the origin and mitigation of both sink types. Our main conclusions and observations include: (1) Outliers function jointly with normalization: removing normalization eliminates the corresponding outliers but degrades training stability and performance; directly clipping outliers while retaining normalization leads to degradation, indicating that outlier-driven rescaling contributes to training stability. (2) Outliers serve more as rescale factors rather than contributors, as the final contributions of attention and residual sinks are significantly smaller than those of non-outliers. (3) Outliers can be absorbed into learnable parameters or mitigated via explicit gated rescaling, leading to improved training performance (average gain of 2 points) and enhanced quantization robustness (1.2 points degradation under W4A4 quantization).

</details>


### [46] [ArabicDialectHub: A Cross-Dialectal Arabic Learning Resource and Platform](https://arxiv.org/abs/2601.22987)
*Salem Lahlou*

Main category: cs.CL

TL;DR: 阿拉伯方言学习资源ArabicDialectHub，包含6种方言的552个短语，提供交互式网络平台，支持翻译探索、自适应测试和进度跟踪。


<details>
  <summary>Details</summary>
Motivation: 为阿拉伯语学习者提供跨方言的学习资源，解决不同阿拉伯方言之间的学习挑战，促进对多种阿拉伯语变体的理解和掌握。

Method: 使用LLM生成短语，由5名母语者验证，按难度分层并按主题组织。开发开源网络平台，包含翻译探索、自适应测试（算法生成干扰项）、云端同步进度跟踪和文化背景功能。

Result: 创建了包含摩洛哥达里贾语、黎巴嫩语、叙利亚语、阿联酋语、沙特语和现代标准阿拉伯语等6种变体的552个短语数据集，并发布了完整的交互式网络平台。

Conclusion: ArabicDialectHub是一个有价值的跨方言阿拉伯语学习资源，数据集和平台源代码均以MIT许可证开源发布，为阿拉伯语学习者提供了实用的学习工具。

Abstract: We present ArabicDialectHub, a cross-dialectal Arabic learning resource comprising 552 phrases across six varieties (Moroccan Darija, Lebanese, Syrian, Emirati, Saudi, and MSA) and an interactive web platform. Phrases were generated using LLMs and validated by five native speakers, stratified by difficulty, and organized thematically. The open-source platform provides translation exploration, adaptive quizzing with algorithmic distractor generation, cloud-synchronized progress tracking, and cultural context. Both the dataset and complete platform source code are released under MIT license. Platform: https://arabic-dialect-hub.netlify.app.

</details>


### [47] [Bias Beyond Borders: Political Ideology Evaluation and Steering in Multilingual LLMs](https://arxiv.org/abs/2601.23001)
*Afrozah Nadeem,Agrima,Mehwish Nasim,Usman Naseem*

Main category: cs.CL

TL;DR: 该论文提出了一个大规模多语言政治偏见评估框架和跨语言对齐引导（CLAS）后处理缓解方法，旨在减少LLM在多语言环境中的政治偏见，同时保持响应质量。


<details>
  <summary>Details</summary>
Motivation: LLM在全球话语中影响力日益增强，需要确保公平性和意识形态中立性。现有研究主要关注高资源西方语言或狭窄的多语言设置，缺乏跨语言一致性和有效的后处理缓解方法。

Method: 提出了跨语言对齐引导（CLAS）框架，通过将政治提示诱导的意识形态表示对齐到共享的意识形态子空间，确保跨语言一致性，并使用自适应机制防止过度校正和保持连贯性。

Result: 实验表明，该方法在经济和社会两个轴向上显著减少了偏见，同时响应质量下降最小。建立了可扩展和可解释的多语言LLM公平治理范式。

Conclusion: CLAS框架为多语言LLM治理提供了平衡意识形态中立性与语言文化多样性的有效解决方案，有助于负责任AI部署。

Abstract: Large Language Models (LLMs) increasingly shape global discourse, making fairness and ideological neutrality essential for responsible AI deployment. Despite growing attention to political bias in LLMs, prior work largely focuses on high-resource, Western languages or narrow multilingual settings, leaving cross-lingual consistency and safe post-hoc mitigation underexplored. To address this gap, we present a large-scale multilingual evaluation of political bias spanning 50 countries and 33 languages. We introduce a complementary post-hoc mitigation framework, Cross-Lingual Alignment Steering (CLAS), designed to augment existing steering methods by aligning ideological representations across languages and dynamically regulating intervention strength. This method aligns latent ideological representations induced by political prompts into a shared ideological subspace, ensuring cross lingual consistency, with the adaptive mechanism prevents over correction and preserves coherence. Experiments demonstrate substantial bias reduction along both economic and social axes with minimal degradation in response quality. The proposed framework establishes a scalable and interpretable paradigm for fairness-aware multilingual LLM governance, balancing ideological neutrality with linguistic and cultural diversity.

</details>


### [48] [InstructDiff: Domain-Adaptive Data Selection via Differential Entropy for Efficient LLM Fine-Tuning](https://arxiv.org/abs/2601.23006)
*Junyou Su,He Zhu,Xiao Luo,Liyu Zhang,Hong-Yu Zhou,Yun Chen,Peng Li,Yang Liu,Guanhua Chen*

Main category: cs.CL

TL;DR: InstructDiff：基于微分熵的领域自适应数据选择框架，通过校准模型熵差模式，在数学推理和通用指令任务上仅用10%数据实现性能提升


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法存在严重领域特异性问题：针对通用指令优化的方法在推理任务上失效，反之亦然。完整数据集训练成本高昂且收益递减，需要统一的领域自适应数据选择框架。

Method: 提出InstructDiff框架：1) 通过基础模型与最小指令微调校准模型计算微分熵差异；2) 发现熵差模式：推理任务偏好熵增加（认知扩展），通用任务偏好熵减少（认知压缩）；3) 采用预热校准、双向NLL过滤和基于熵的排序进行数据选择。

Result: 实验显示InstructDiff在数学推理任务上相比全数据训练获得17%相对提升，在通用指令跟随任务上获得52%提升，仅使用10%数据即超越现有基线方法。

Conclusion: 微分熵可作为统一的领域自适应数据选择标准，InstructDiff框架有效解决了数据选择中的领域特异性问题，显著降低训练成本同时提升模型性能。

Abstract: Supervised fine-tuning (SFT) is fundamental to adapting large language models, yet training on complete datasets incurs prohibitive costs with diminishing returns. Existing data selection methods suffer from severe domain specificity: techniques optimized for general instruction-following fail on reasoning tasks, and vice versa. We observe that measuring entropy differences between base models and minimally instruction-tuned calibrated models reveals a pattern -- samples with the lowest differential entropy consistently yield optimal performance across domains, yet this principle manifests domain-adaptively: reasoning tasks favor entropy increase (cognitive expansion), while general tasks favor entropy decrease (cognitive compression). We introduce InstructDiff, a unified framework that operationalizes differential entropy as a domain-adaptive selection criterion through warmup calibration, bi-directional NLL filtering, and entropy-based ranking. Extensive experiments show that InstructDiff achieves 17\% relative improvement over full data training on mathematical reasoning and 52\% for general instruction-following, outperforming prior baselines while using only 10\% of the data.

</details>


### [49] [DimABSA: Building Multilingual and Multidomain Datasets for Dimensional Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2601.23022)
*Lung-Hao Lee,Liang-Chih Yu,Natalia Loukashevich,Ilseyar Alimova,Alexander Panchenko,Tzu-Mi Lin,Zhe-Yu Xu,Jian-Yu Zhou,Guangmin Zheng,Jin Wang,Sharanya Awasthi,Jonas Becker,Jan Philip Wahle,Terry Ruas,Shamsuddeen Hassan Muhammad,Saif M. Mohammed*

Main category: cs.CL

TL;DR: 本文提出了DimABSA，首个多语言维度情感分析资源，将传统ABSA元素与连续的情感-唤醒度评分结合，支持更细粒度的情感分析。


<details>
  <summary>Details</summary>
Motivation: 现有ABSA研究依赖粗粒度的分类标签（如积极、消极），限制了捕捉细微情感状态的能力。需要采用维度方法，用连续的情感-唤醒度评分来表示情感，实现方面和情感层面的细粒度分析。

Method: 引入DimABSA资源，包含42,590个句子中的76,958个方面实例，涵盖6种语言和4个领域。提出三个结合VA评分与不同ABSA元素的子任务，并设计新的统一度量标准连续F1（cF1），将VA预测误差纳入标准F1。使用提示和微调的大型语言模型进行全面基准测试。

Result: DimABSA是一个具有挑战性的基准测试，为推进多语言维度ABSA提供了基础。结果显示，该资源能够支持更细粒度的情感分析任务。

Conclusion: DimABSA通过引入连续的情感-唤醒度评分，扩展了传统ABSA的能力，为多语言维度情感分析研究提供了重要资源和基准框架。

Abstract: Aspect-Based Sentiment Analysis (ABSA) focuses on extracting sentiment at a fine-grained aspect level and has been widely applied across real-world domains. However, existing ABSA research relies on coarse-grained categorical labels (e.g., positive, negative), which limits its ability to capture nuanced affective states. To address this limitation, we adopt a dimensional approach that represents sentiment with continuous valence-arousal (VA) scores, enabling fine-grained analysis at both the aspect and sentiment levels. To this end, we introduce DimABSA, the first multilingual, dimensional ABSA resource annotated with both traditional ABSA elements (aspect terms, aspect categories, and opinion terms) and newly introduced VA scores. This resource contains 76,958 aspect instances across 42,590 sentences, spanning six languages and four domains. We further introduce three subtasks that combine VA scores with different ABSA elements, providing a bridge from traditional ABSA to dimensional ABSA. Given that these subtasks involve both categorical and continuous outputs, we propose a new unified metric, continuous F1 (cF1), which incorporates VA prediction error into standard F1. We provide a comprehensive benchmark using both prompted and fine-tuned large language models across all subtasks. Our results show that DimABSA is a challenging benchmark and provides a foundation for advancing multilingual dimensional ABSA.

</details>


### [50] [Character as a Latent Variable in Large Language Models: A Mechanistic Account of Emergent Misalignment and Conditional Safety Failures](https://arxiv.org/abs/2601.23081)
*Yanghao Su,Wenbo Zhou,Tianwei Zhang,Qiu Han,Weiming Zhang,Nenghai Yu,Jie Zhang*

Main category: cs.CL

TL;DR: 研究发现微调LLMs时，模型在特定字符级倾向性数据上训练会引发比错误建议微调更强、更可转移的错位行为，表明错位源于行为倾向的稳定转变而非能力退化。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要将"涌现错位"归因于错误或不安全内容的泛化，但作者认为这种观点不完整。他们想探究微调过程中模型行为倾向的根本变化机制。

Method: 在多个领域和模型家族中进行实验，比较在特定字符级倾向性数据上微调与错误建议微调的效果。研究训练时触发器和推理时角色对齐提示如何条件性地激活这些行为倾向。

Result: 特定字符级倾向性微调比错误建议微调产生更强、更可转移的错位行为，同时基本保留一般能力。行为倾向可通过训练时触发器和推理时提示激活，揭示涌现错位、后门激活和越狱漏洞之间的共享结构。

Conclusion: 角色形成是核心且未被充分探索的对齐风险，稳健的对齐必须解决行为倾向问题，而非仅仅关注孤立错误或提示级防御。

Abstract: Emergent Misalignment refers to a failure mode in which fine-tuning large language models (LLMs) on narrowly scoped data induces broadly misaligned behavior. Prior explanations mainly attribute this phenomenon to the generalization of erroneous or unsafe content. In this work, we show that this view is incomplete. Across multiple domains and model families, we find that fine-tuning models on data exhibiting specific character-level dispositions induces substantially stronger and more transferable misalignment than incorrect-advice fine-tuning, while largely preserving general capabilities. This indicates that emergent misalignment arises from stable shifts in model behavior rather than from capability degradation or corrupted knowledge. We further show that such behavioral dispositions can be conditionally activated by both training-time triggers and inference-time persona-aligned prompts, revealing shared structure across emergent misalignment, backdoor activation, and jailbreak susceptibility. Overall, our results identify character formation as a central and underexplored alignment risk, suggesting that robust alignment must address behavioral dispositions rather than isolated errors or prompt-level defenses.

</details>


### [51] [Safer Policy Compliance with Dynamic Epistemic Fallback](https://arxiv.org/abs/2601.23094)
*Joseph Marvin Imperial,Harish Tayyar Madabushi*

Main category: cs.CL

TL;DR: 提出Dynamic Epistemic Fallback (DEF)协议，通过认知启发式防御机制增强LLM对恶意篡改政策文本的检测和拒绝能力


<details>
  <summary>Details</summary>
Motivation: 人类通过认知防御机制（认知警惕）对抗日常互动中的欺骗和错误信息风险，受此启发为LLM开发类似防护机制，特别是在自动化遵守数据隐私法律等高风险任务中尤为重要

Method: 提出动态认知回退(DEF)协议，通过不同级别的单句文本提示，促使LLM在遇到篡改的政策文本时标记不一致性、拒绝遵守并回退到其参数知识

Result: 使用HIPAA和GDPR等全球认可的法律政策进行实证评估，DEF有效提升了前沿LLM检测和拒绝篡改政策版本的能力，DeepSeek-R1在某一设置中达到100%检测率

Conclusion: 这项工作鼓励进一步开发认知启发式防御机制，以提高LLM对抗利用法律文书的伤害和欺骗形式的鲁棒性

Abstract: Humans develop a series of cognitive defenses, known as epistemic vigilance, to combat risks of deception and misinformation from everyday interactions. Developing safeguards for LLMs inspired by this mechanism might be particularly helpful for their application in high-stakes tasks such as automating compliance with data privacy laws. In this paper, we introduce Dynamic Epistemic Fallback (DEF), a dynamic safety protocol for improving an LLM's inference-time defenses against deceptive attacks that make use of maliciously perturbed policy texts. Through various levels of one-sentence textual cues, DEF nudges LLMs to flag inconsistencies, refuse compliance, and fallback to their parametric knowledge upon encountering perturbed policy texts. Using globally recognized legal policies such as HIPAA and GDPR, our empirical evaluations report that DEF effectively improves the capability of frontier LLMs to detect and refuse perturbed versions of policies, with DeepSeek-R1 achieving a 100% detection rate in one setting. This work encourages further efforts to develop cognitively inspired defenses to improve LLM robustness against forms of harm and deception that exploit legal artifacts.

</details>


### [52] [Evaluating the Utility of Grounding Documents with Reference-Free LLM-based Metrics](https://arxiv.org/abs/2601.23129)
*Yilun Hua,Giuseppe Castellucci,Peter Schulam,Heba Elfardy,Kevin Small*

Main category: cs.CL

TL;DR: 提出GroGU指标，基于LLM生成置信度（熵）量化RAG中检索内容对下游LLM的效用，无需人工标注，用于训练查询重写器提升RAG性能


<details>
  <summary>Details</summary>
Motivation: 现有RAG效用评估指标存在不足：要么忽略模型特定能力，要么依赖昂贵的人工标注。需要一种模型特定、无需参考标注的指标来准确量化检索内容对下游LLM的效用。

Method: 提出Grounding Generation Utility (GroGU)指标，基于下游LLM的生成置信度（通过熵计算）来定义内容效用。该指标模型特定、无需参考标注，通过识别高效用偏好数据用于训练RAG的查询重写器。

Result: GroGU能有效区分真实文档，捕捉LLM无关指标忽略的细微差别。应用GroGU训练的查询重写器在实验中显著提升性能：平均倒数排名提升达18.2分，答案准确率提升达9.4分。

Conclusion: GroGU是一种有效的模型特定、无需标注的RAG内容效用评估指标，能显著提升RAG系统的查询重写和整体性能。

Abstract: Retrieval Augmented Generation (RAG)'s success depends on the utility the LLM derives from the content used for grounding. Quantifying content utility does not have a definitive specification and existing metrics ignore model-specific capabilities and/or rely on costly annotations. In this paper, we propose Grounding Generation Utility (GroGU), a model-specific and reference-free metric that defines utility as a function of the downstream LLM's generation confidence based on entropy. Despite having no annotation requirements, GroGU is largely faithful in distinguishing ground-truth documents while capturing nuances ignored by LLM-agnostic metrics. We apply GroGU to train a query-rewriter for RAG by identifying high-utility preference data for Direct Preference Optimization. Experiments show improvements by up to 18.2 points in Mean Reciprocal Rank and up to 9.4 points in answer accuracy.

</details>


### [53] [Monotonic Reference-Free Refinement for Autoformalization](https://arxiv.org/abs/2601.23166)
*Lan Zhang,Marco Valentino,André Freitas*

Main category: cs.CL

TL;DR: 本文提出了一种无参考的迭代单调过程，用于全定理自动形式化，通过定理证明器和LLM法官的互补反馈，联合优化形式有效性、逻辑保持、数学一致性和形式质量四个维度。


<details>
  <summary>Details</summary>
Motivation: 虽然语句自动形式化发展迅速，但全定理自动形式化仍未被充分探索。现有的迭代细化方法通常只改进形式化的孤立方面（如语法正确性），难以联合优化多个质量维度，而这对于全定理自动形式化至关重要。

Method: 提出无参考迭代单调过程，利用定理证明器和基于LLM的法官的互补反馈，无需推理时访问真实证明或现有形式化。通过响应性映射指导不同LLM角色优先改进不同维度，并采用保证认证单调改进的接受策略。

Result: 在miniF2F上达到93.44%的形式有效性和78.22%的总体得分，在ProofNet上达到44.09%的形式有效性和29.79%的总体得分，实现了多个维度的同时改进。

Conclusion: 该方法能够同时优化多个质量维度，为全定理自动形式化提供了有效的解决方案，并保证了收敛性和终止性。

Abstract: While statement autoformalization has advanced rapidly, full-theorem autoformalization remains largely unexplored. Existing iterative refinement methods in statement autoformalization typicall improve isolated aspects of formalization, such as syntactic correctness, but struggle to jointly optimizing multiple quality dimensions, which is critical for full-theorem autoformalization. We introduce a reference-free iterative monotonic process for full-theorem autoformalization that leverages complementary feedback from theorem provers and LLM-based judges, without access to ground-truth proofs or existing formalizations at inference time. Our approach optimizes a masked composite objective over Formal Validity, Logical Preservation, Mathematical Consistency, and Formal Quality, guided by a responsiveness map that indicates how different LLMs acting as different roles preferentially improve each dimension. We further propose an acceptance policy that guarantees certified monotonic improvement, and provide conditions ensuring convergence and termination. Empirical experiments demonstrate the proposed process enables simultaneous improvement across multiple dimensions, achieving 93.44% formal validity and a 78.22% overall score on miniF2F, and 44.09% formal validity and a 29.79% overall score on ProofNet.

</details>


### [54] [FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation](https://arxiv.org/abs/2601.23182)
*Siyang He,Qiqi Wang,Xiaoran Liu,Hongnan Ma,Yiwei Shi,Yuerong Song,Ying Zhu,Tianyi Liang,Zengfeng Huang,Ziwei He,Xipeng Qiu*

Main category: cs.CL

TL;DR: 本文提出FourierSampler，一种基于频域分析的解码策略，通过频率滑动窗口机制实现"结构到细节"的生成，解决了扩散语言模型的位置偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型的解码策略存在位置偏差，未能充分发挥其非自回归生成的潜力。需要深入理解模型的频谱特性，以开发更有效的生成方法。

Method: 首先对扩散语言模型进行频域分析，发现隐藏状态中低频分量编码全局结构和长程依赖，高频分量编码局部细节。基于此提出FourierSampler，采用频域滑动窗口机制动态引导模型实现"结构到细节"的生成。

Result: FourierSampler在LLADA和SDAR基准测试中优于其他推理增强策略，在LLaDA1.5-8B上相对提升20.4%，在LLaDA-8B-Instruct上提升16.0%。显著超越类似规模的自回归模型如Llama3.1-8B-Instruct。

Conclusion: 频域分析为理解扩散语言模型提供了新视角，FourierSampler通过利用频率特性有效解决了位置偏差问题，实现了更优的生成质量。

Abstract: Despite the non-autoregressive potential of diffusion language models (dLLMs), existing decoding strategies demonstrate positional bias, failing to fully unlock the potential of arbitrary generation. In this work, we delve into the inherent spectral characteristics of dLLMs and present the first frequency-domain analysis showing that low-frequency components in hidden states primarily encode global structural information and long-range dependencies, while high-frequency components are responsible for characterizing local details. Based on this observation, we propose FourierSampler, which leverages a frequency-domain sliding window mechanism to dynamically guide the model to achieve a "structure-to-detail" generation. FourierSampler outperforms other inference enhancement strategies on LLADA and SDAR, achieving relative improvements of 20.4% on LLaDA1.5-8B and 16.0% on LLaDA-8B-Instruct. It notably surpasses similarly sized autoregressive models like Llama3.1-8B-Instruct.

</details>


### [55] [JobResQA: A Benchmark for LLM Machine Reading Comprehension on Multilingual Résumés and JDs](https://arxiv.org/abs/2601.23183)
*Casimiro Pio Carrino,Paula Estrella,Rabih Zbib,Carlos Escolano,José A. R. Fonollosa*

Main category: cs.CL

TL;DR: JobResQA是一个多语言问答基准测试，用于评估LLM在涉及简历和职位描述的HR特定任务上的机器阅读理解能力，包含5种语言的581个QA对，支持系统性的偏见和公平性研究。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门针对HR应用的多语言机器阅读理解基准测试，特别是涉及简历和职位描述的现实场景。需要评估LLM在HR任务中的多语言能力，并研究系统偏见和公平性问题。

Method: 1) 通过去识别化和数据合成从真实世界来源构建数据集生成管道；2) 使用基于TEaR方法的人类参与翻译管道，结合MQM错误标注和选择性后编辑；3) 通过受控的人口统计和专业属性（占位符）支持偏见研究；4) 采用LLM-as-judge方法进行基准评估。

Result: 基准测试包含581个QA对，覆盖5种语言（英语、西班牙语、意大利语、德语、中文），问题分为三个复杂度级别。评估显示英语和西班牙语表现较好，其他语言性能显著下降，揭示了HR应用中多语言MRC能力的关键差距。

Conclusion: JobResQA为推进公平可靠的基于LLM的HR系统提供了可复现的基准测试，公开可用，有助于研究多语言MRC能力和系统偏见问题。

Abstract: We introduce JobResQA, a multilingual Question Answering benchmark for evaluating Machine Reading Comprehension (MRC) capabilities of LLMs on HR-specific tasks involving résumés and job descriptions. The dataset comprises 581 QA pairs across 105 synthetic résumé-job description pairs in five languages (English, Spanish, Italian, German, and Chinese), with questions spanning three complexity levels from basic factual extraction to complex cross-document reasoning. We propose a data generation pipeline derived from real-world sources through de-identification and data synthesis to ensure both realism and privacy, while controlled demographic and professional attributes (implemented via placeholders) enable systematic bias and fairness studies. We also present a cost-effective, human-in-the-loop translation pipeline based on the TEaR methodology, incorporating MQM error annotations and selective post-editing to ensure an high-quality multi-way parallel benchmark. We provide a baseline evaluations across multiple open-weight LLM families using an LLM-as-judge approach revealing higher performances on English and Spanish but substantial degradation for other languages, highlighting critical gaps in multilingual MRC capabilities for HR applications. JobResQA provides a reproducible benchmark for advancing fair and reliable LLM-based HR systems. The benchmark is publicly available at: https://github.com/Avature/jobresqa-benchmark

</details>


### [56] [ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought](https://arxiv.org/abs/2601.23184)
*Fanmeng Wang,Haotian Liu,Guojiang Zhao,Hongteng Xu,Zhifeng Gao*

Main category: cs.CL

TL;DR: ReGuLaR提出了一种新的潜在推理范式，通过将显式推理链渲染为图像并提取视觉语义表示来指导潜在空间压缩，在保持推理效果的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统CoT方法虽然提升了LLM性能，但显式推理链引入了大量计算冗余。现有的潜在推理方法试图压缩推理过程到潜在空间，但由于缺乏适当的压缩指导，往往导致严重的性能下降。

Method: 将潜在推理建模为变分自编码器框架，从先前状态的条件后验分布中采样当前潜在推理状态。学习过程中，将显式推理链渲染为图像，提取密集的视觉语义表示来正则化后验分布，实现高效压缩且信息损失最小。

Result: ReGuLaR在计算效率和推理效果上显著优于现有潜在推理方法，甚至通过多模态推理超越了传统CoT方法，为潜在推理提供了新的解决方案。

Conclusion: ReGuLaR通过视觉语义指导的变分潜在推理，成功解决了现有潜在推理方法的性能退化问题，在保持推理能力的同时大幅提升计算效率，是多模态推理的重要进展。

Abstract: While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy. Recent latent reasoning methods attempt to mitigate this by compressing reasoning processes into latent space, but often suffer from severe performance degradation due to the lack of appropriate compression guidance. In this study, we propose Rendered CoT-Guided variational Latent Reasoning (ReGuLaR), a simple yet novel latent learning paradigm resolving this issue. Fundamentally, we formulate latent reasoning within the Variational Auto-Encoding (VAE) framework, sampling the current latent reasoning state from the posterior distribution conditioned on previous ones. Specifically, when learning this variational latent reasoning model, we render explicit reasoning chains as images, from which we extract dense visual-semantic representations to regularize the posterior distribution, thereby achieving efficient compression with minimal information loss. Extensive experiments demonstrate that ReGuLaR significantly outperforms existing latent reasoning methods across both computational efficiency and reasoning effectiveness, and even surpasses CoT through multi-modal reasoning, providing a new and insightful solution to latent reasoning. Code: https://github.com/FanmengWang/ReGuLaR.

</details>


### [57] [Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience](https://arxiv.org/abs/2601.23188)
*Zhongxiang Sun,Qipeng Wang,Weijie Yu,Jingxuan Yang,Haolang Lu,Jun Xu*

Main category: cs.CL

TL;DR: DS-MCM是一个增强深度搜索的元认知监控框架，通过分层监控机制（快速一致性监控和慢速经验驱动监控）来提升搜索代理在不确定性任务中的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的深度搜索代理在多步检索、推理和长时任务执行方面表现出色，但缺乏监控和调节推理与检索状态的机制，导致在实际应用中容易失败。受认知神经科学启发，人类元认知是分层组织的，结合了快速异常检测和选择性触发的经验驱动反思。

Method: 提出DS-MCM框架，包含两个分层监控组件：1) 快速一致性监控器，轻量级检查外部证据与内部推理置信度的对齐；2) 慢速经验驱动监控器，选择性激活，基于历史代理轨迹的经验记忆指导纠正干预。该框架将监控直接嵌入推理-检索循环中。

Result: 在多个深度搜索基准测试和骨干模型上的实验表明，DS-MCM能够持续提升性能和鲁棒性。

Conclusion: DS-MCM通过引入显式的分层元认知监控机制，有效解决了深度搜索代理在不确定性任务中缺乏状态监控的问题，显著提升了系统的可靠性和性能。

Abstract: Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval, reasoning, and long-horizon task execution. However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve under uncertainty. Insights from cognitive neuroscience suggest that human metacognition is hierarchically organized, integrating fast anomaly detection with selectively triggered, experience-driven reflection. In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), a deep search framework augmented with an explicit hierarchical metacognitive monitoring mechanism. DS-MCM integrates a Fast Consistency Monitor, which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and a Slow Experience-Driven Monitor, which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories. By embedding monitoring directly into the reasoning-retrieval loop, DS-MCM determines both when intervention is warranted and how corrective actions should be informed by prior experience. Experiments across multiple deep search benchmarks and backbone models demonstrate that DS-MCM consistently improves performance and robustness.

</details>


### [58] [Are you going to finish that? A Practical Study of the Tokenization Boundary Problem](https://arxiv.org/abs/2601.23223)
*Hao Xu,Alisa Liu,Jonathan Hayase,Yejin Choi,Noah A. Smith*

Main category: cs.CL

TL;DR: 语言模型在分词边界不匹配时会出现严重的预测失真问题，特别是在非空格语言、高度复合语言和代码中，即使自然完整的词语提示也会受到影响


<details>
  <summary>Details</summary>
Motivation: 语言模型基于token序列训练，但用户通过文本交互，这种不匹配导致部分token问题——当用户在预期下一个token中间结束提示时，会造成下一个token预测失真。虽然已有研究使用任意字符前缀探讨此问题，但在尊重词语边界的现实提示中的普遍性和严重性仍未充分探索

Method: 识别三个分词边界与词语边界经常不对齐的领域：不使用空格的语言、高度复合语言和代码。系统构建语义自然但以部分token结尾的提示，在实验中评估概率失真程度，并测试推理时缓解方法

Result: 在中文中，高达25%的词语边界与分词边界不对齐。前沿语言模型在部分token提示下对正确延续的概率分配比分词对齐提示低三个数量级。这种性能下降不随模型规模减小，反而在更大模型中经常恶化

Conclusion: 分词在现实使用场景中造成的概率失真问题具有相当的规模和严重性。研究验证了近期精确解决方案的有效性，并为模型推理服务提供商提供了实用建议

Abstract: Language models (LMs) are trained over sequences of tokens, whereas users interact with LMs via text. This mismatch gives rise to the partial token problem, which occurs when a user ends their prompt in the middle of the expected next-token, leading to distorted next-token predictions. Although this issue has been studied using arbitrary character prefixes, its prevalence and severity in realistic prompts respecting word boundaries remains underexplored. In this work, we identify three domains where token and "word" boundaries often do not line up: languages that do not use whitespace, highly compounding languages, and code. In Chinese, for example, up to 25% of word boundaries do not line up with token boundaries, making even natural, word-complete prompts susceptible to this problem. We systematically construct semantically natural prompts ending with a partial tokens; in experiments, we find that they comprise a serious failure mode: frontier LMs consistently place three orders of magnitude less probability on the correct continuation compared to when the prompt is "backed-off" to be token-aligned. This degradation does not diminish with scale and often worsens for larger models. Finally, we evaluate inference-time mitigations to the partial token problem and validate the effectiveness of recent exact solutions. Overall, we demonstrate the scale and severity of probability distortion caused by tokenization in realistic use cases, and provide practical recommentions for model inference providers.

</details>


### [59] [Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models](https://arxiv.org/abs/2601.23255)
*Ye Yu,Haibo Jin,Yaoning Yu,Jun Zhuang,Haohan Wang*

Main category: cs.CL

TL;DR: 论文研究了音频-语言模型的安全漏洞，通过设计文本到音频的越狱攻击，在叙事式音频流中嵌入禁止指令，成功绕过主要针对文本的安全机制。


<details>
  <summary>Details</summary>
Motivation: 随着大型音频-语言模型越来越多地处理原始语音输入，这种模态转变引入了新的安全漏洞，这些漏洞目前尚未得到充分研究。需要了解从文本到音频接口转变带来的安全影响。

Method: 设计了一种文本到音频的越狱攻击，利用先进的指令跟随文本转语音（TTS）模型，在叙事式音频流中嵌入禁止指令。攻击利用了结构和声学特性，绕过主要针对文本校准的安全机制。

Result: 通过合成语音传递的叙事格式能够从最先进的模型（包括Gemini 2.0 Flash）中引出受限输出，达到了98.26%的成功率，显著超过了纯文本基线。

Conclusion: 研究结果强调了需要开发能够同时处理语言和副语言表示的安全框架，特别是随着基于语音的接口变得越来越普遍。

Abstract: Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds disallowed directives within a narrative-style audio stream. The attack leverages an advanced instruction-following text-to-speech (TTS) model to exploit structural and acoustic properties, thereby circumventing safety mechanisms primarily calibrated for text. When delivered through synthetic speech, the narrative format elicits restricted outputs from state-of-the-art models, including Gemini 2.0 Flash, achieving a 98.26% success rate that substantially exceeds text-only baselines. These results highlight the need for safety frameworks that jointly reason over linguistic and paralinguistic representations, particularly as speech-based interfaces become more prevalent.

</details>


### [60] [PaperBanana: Automating Academic Illustration for AI Scientists](https://arxiv.org/abs/2601.23265)
*Dawei Zhu,Rui Meng,Yale Song,Xiyu Wei,Sujian Li,Tomas Pfister,Jinsung Yoon*

Main category: cs.CL

TL;DR: PaperBanana是一个基于先进视觉语言模型和图像生成模型的智能框架，能够自动生成符合发表要求的学术插图，通过专门代理进行参考文献检索、内容风格规划、图像渲染和迭代优化。


<details>
  <summary>Details</summary>
Motivation: 尽管基于语言模型的自主AI科学家发展迅速，但生成符合发表要求的插图仍然是研究流程中劳动密集型的瓶颈。为了减轻这一负担，需要开发自动化生成学术插图的解决方案。

Method: PaperBanana框架通过协调专门代理来检索参考文献、规划内容和风格、渲染图像，并通过自我批评进行迭代优化。使用最先进的视觉语言模型和图像生成模型作为技术支持。

Result: 在包含292个测试案例的PaperBananaBench评估中，PaperBanana在忠实性、简洁性、可读性和美学方面持续优于领先的基线方法。该方法还能有效扩展到高质量统计图的生成。

Conclusion: PaperBanana为自动化生成符合发表要求的插图铺平了道路，有望显著提高研究工作效率。

Abstract: Despite rapid advances in autonomous AI scientists powered by language models, generating publication-ready illustrations remains a labor-intensive bottleneck in the research workflow. To lift this burden, we introduce PaperBanana, an agentic framework for automated generation of publication-ready academic illustrations. Powered by state-of-the-art VLMs and image generation models, PaperBanana orchestrates specialized agents to retrieve references, plan content and style, render images, and iteratively refine via self-critique. To rigorously evaluate our framework, we introduce PaperBananaBench, comprising 292 test cases for methodology diagrams curated from NeurIPS 2025 publications, covering diverse research domains and illustration styles. Comprehensive experiments demonstrate that PaperBanana consistently outperforms leading baselines in faithfulness, conciseness, readability, and aesthetics. We further show that our method effectively extends to the generation of high-quality statistical plots. Collectively, PaperBanana paves the way for the automated generation of publication-ready illustrations.

</details>


### [61] [UPA: Unsupervised Prompt Agent via Tree-Based Search and Selection](https://arxiv.org/abs/2601.23273)
*Siran Peng,Weisong Zhao,Tianyu Fu,Chenxu Zhao,Tianshuo Zhang,Haoyuan Zhang,Xiangyu Zhu,Minghui Wu,Zhen Lei*

Main category: cs.CL

TL;DR: UPA是一种无监督提示代理，通过两阶段框架（基于BTL模型）进行结构化搜索和选择，无需监督奖励信号，在多个任务上优于现有提示优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有的提示代理方法通常需要监督奖励信号，但在实际场景中往往无法获得。因此需要开发无需监督反馈的提示优化方法。

Method: UPA采用两阶段框架：1) 搜索阶段：通过迭代构建树结构导航提示空间，利用LLM进行细粒度、顺序不变的成对比较；2) 选择阶段：基于Bradley-Terry-Luce模型，先进行路径级贝叶斯聚合筛选候选，再进行全局锦标赛式比较推断潜在提示质量。

Result: 在多个任务上的实验表明，UPA始终优于现有的提示优化方法，证明即使在完全无监督的设置下，代理式优化仍然非常有效。

Conclusion: UPA成功实现了无需监督反馈的结构化提示搜索和选择，为无监督提示优化提供了有效解决方案，扩展了提示代理的应用范围。

Abstract: Prompt agents have recently emerged as a promising paradigm for automated prompt optimization, framing refinement as a sequential decision-making problem over a structured prompt space. While this formulation enables the use of advanced planning algorithms, these methods typically assume access to supervised reward signals, which are often unavailable in practical scenarios. In this work, we propose UPA, an Unsupervised Prompt Agent that realizes structured search and selection without relying on supervised feedback. Specifically, during search, UPA iteratively constructs an evolving tree structure to navigate the prompt space, guided by fine-grained and order-invariant pairwise comparisons from Large Language Models (LLMs). Crucially, as these local comparisons do not inherently yield a consistent global scale, we decouple systematic prompt exploration from final selection, introducing a two-stage framework grounded in the Bradley-Terry-Luce (BTL) model. This framework first performs path-wise Bayesian aggregation of local comparisons to filter candidates under uncertainty, followed by global tournament-style comparisons to infer latent prompt quality and identify the optimal prompt. Experiments across multiple tasks demonstrate that UPA consistently outperforms existing prompt optimization methods, showing that agent-style optimization remains highly effective even in fully unsupervised settings.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [62] [Advanced techniques and applications of LiDAR Place Recognition in Agricultural Environments: A Comprehensive Survey](https://arxiv.org/abs/2601.22198)
*Judith Vilella-Cantos,Mónica Ballesta,David Valiente,María Flores,Luis Payá*

Main category: cs.RO

TL;DR: 本文综述了农业环境中基于LiDAR的定位技术，重点分析了深度学习在农业场景定位识别中的应用、挑战、现有方法、数据集和评估指标，是该领域首个专注于农业环境的LiDAR定位调研。


<details>
  <summary>Details</summary>
Motivation: 精准农业等自主机器人系统需要最优的定位解决方案。虽然LiDAR位置识别技术在近年被广泛用于城市环境中的精确定位，但农业环境缺乏显著特征且结构不规则，使得位置识别具有挑战性。目前缺乏专门针对农业环境的LiDAR定位技术综述。

Method: 本文采用文献综述方法，系统性地回顾了农业环境中基于LiDAR的定位技术的最新进展，特别是深度学习应用。分析了该领域面临的挑战、现有方法、可用数据集和性能评估指标。

Result: 这是首个专注于农业环境中LiDAR定位技术的调研论文，全面梳理了该领域的研究现状，识别了农业环境特有的挑战（如特征不明显、非结构化环境），并总结了现有方法、数据集和评估指标。

Conclusion: 农业环境中的LiDAR定位面临独特挑战，需要专门的研究方法。本文为这一专业领域提供了全面理解，旨在促进该领域的进一步研究，填补了农业环境LiDAR定位技术综述的空白。

Abstract: An optimal solution to the localization problem is essential for developing autonomous robotic systems. Apart from autonomous vehicles, precision agriculture is one of the elds that can bene t most from these systems. Although LiDAR place recognition is a widely used technique in recent years to achieve accurate localization, it is mostly used in urban settings. However, the lack of distinctive features and the unstructured nature of agricultural environments make place recognition challenging. This work presents a comprehensive review of state-of-the-art the latest deep learning applications for agricultural environments and LPR techniques. We focus on the challenges that arise in these environments. We analyze the existing approaches, datasets, and metrics used to evaluate LPR system performance and discuss the limitations and future directions of research in this eld. This is the rst survey that focuses on LiDAR based localization in agricultural settings, with the aim of providing a thorough understanding and fostering further research in this specialized domain.

</details>


### [63] [Game-Based and Gamified Robotics Education: A Comparative Systematic Review and Design Guidelines](https://arxiv.org/abs/2601.22199)
*Syed T. Mubarrat,Byung-Cheol Min,Tianyu Shao,E. Cho Smith,Bedrich Benes,Alejandra J. Magana,Christos Mousas,Dominic Kao*

Main category: cs.RO

TL;DR: 对机器人教育中游戏化学习和游戏化方法的首次PRISMA系统综述，分析了95项研究，揭示了方法-情境-教学法的耦合模式、技术采用局限和研究时间短等问题。


<details>
  <summary>Details</summary>
Motivation: 机器人教育虽然能培养计算思维、创造力和问题解决能力，但技术复杂性使其具有挑战性。游戏化学习和游戏化方法能提高参与度，但两者在机器人教育中的比较影响尚不明确，需要进行系统性的综述来指导实践。

Method: 采用PRISMA标准的系统综述方法，从四个数据库中筛选出95项研究（2014-2025年），对每项研究的方法、学习情境、技能水平、模式、教学法和结果进行编码（k = .918），并进行比较分析。

Result: 发现三个主要模式：1）方法-情境-教学法耦合（游戏化学习更多用于非正式环境，游戏化主导正式课堂）；2）主要关注入门编程和模块化套件，高级软件（~17%）、高级硬件（~5%）和沉浸式技术（~22%）采用有限；3）研究时间短，依赖自我报告数据。

Conclusion: 提出了八个研究方向和一个设计空间，为机器人教育提供最佳实践和陷阱指导，帮助教育者更有效地利用游戏化学习和游戏化方法。

Abstract: Robotics education fosters computational thinking, creativity, and problem-solving, but remains challenging due to technical complexity. Game-based learning (GBL) and gamification offer engagement benefits, yet their comparative impact remains unclear. We present the first PRISMA-aligned systematic review and comparative synthesis of GBL and gamification in robotics education, analyzing 95 studies from 12,485 records across four databases (2014-2025). We coded each study's approach, learning context, skill level, modality, pedagogy, and outcomes (k = .918). Three patterns emerged: (1) approach-context-pedagogy coupling (GBL more prevalent in informal settings, while gamification dominated formal classrooms [p < .001] and favored project-based learning [p = .009]); (2) emphasis on introductory programming and modular kits, with limited adoption of advanced software (~17%), advanced hardware (~5%), or immersive technologies (~22%); and (3) short study horizons, relying on self-report. We propose eight research directions and a design space outlining best practices and pitfalls, offering actionable guidance for robotics education.

</details>


### [64] [ReloPush-BOSS: Optimization-guided Nonmonotone Rearrangement Planning for a Car-like Robot Pusher](https://arxiv.org/abs/2601.22289)
*Jeeho Ahn,Christoforos Mavrogiannis*

Main category: cs.RO

TL;DR: ReloPush-BOSS：一种用于密集杂乱环境中多物体重排规划的框架，通过优化预重定位和构建物体可穿越图，实现高效可行的重排序列


<details>
  <summary>Details</summary>
Motivation: 在密集杂乱环境中使用类车机器人推动器进行多物体重排规划面临挑战，由于运动学、几何和物理约束导致非单调问题实例，需要将操作动作分解为多个部分。现有方法通过预重定位来满足约束，但决定预重定位位置困难，容易陷入局部极小值导致不可行或高成本路径

Method: 1. 通过Dubins路径分类引导预重定位优化，避免局部极小值；2. 构建物体可穿越图，编码运动学、几何和推动约束；3. 采用深度优先搜索在图结构中寻找高效可行的重排序列

Result: 在包含最多13个物体的密集杂乱场景中，ReloPush-BOSS框架相比现有基准方法表现出最高的成功率和最短的推动路径。在1/10比例类车推动器上的硬件实验验证了方法的鲁棒性

Conclusion: 通过优化预重定位和构建约束编码图，ReloPush-BOSS能够有效解决密集杂乱环境中的多物体重排规划问题，实现高效可行的操作序列

Abstract: We focus on multi-object rearrangement planning in densely cluttered environments using a car-like robot pusher. The combination of kinematic, geometric and physics constraints underlying this domain results in challenging nonmonotone problem instances which demand breaking each manipulation action into multiple parts to achieve a desired object rearrangement. Prior work tackles such instances by planning prerelocations, temporary object displacements that enable constraint satisfaction, but deciding where to prerelocate remains difficult due to local minima leading to infeasible or high-cost paths. Our key insight is that these minima can be avoided by steering a prerelocation optimization toward low-cost regions informed by Dubins path classification. These optimized prerelocations are integrated into an object traversability graph that encodes kinematic, geometric, and pushing constraints. Searching this graph in a depth-first fashion results in efficient, feasible rearrangement sequences. Across a series of densely cluttered scenarios with up to 13 objects, our framework, ReloPush-BOSS, exhibits consistently highest success rates and shortest pushing paths compared to state-of-the-art baselines. Hardware experiments on a 1/10 car-like pusher demonstrate the robustness of our approach. Code and footage from our experiments can be found at: https://fluentrobotics.com/relopushboss.

</details>


### [65] [Lantern: A Minimalist Robotic Object Platform](https://arxiv.org/abs/2601.22381)
*Victor Nikhil Antony,Zhili Gong,Guanchen Li,Clara Jeon,Chien-Ming Huang*

Main category: cs.RO

TL;DR: Lantern是一个低成本、简约的机器人对象平台，旨在降低人机交互研究门槛，通过简单形态激发人类社交联想，支持多样化应用场景。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互研究需要复杂昂贵的机器人平台，限制了研究可及性。Lantern旨在通过低成本、简约的设计降低HRI研究门槛，利用人类对简单形态赋予社交意义的倾向，促进更多人参与人机交互探索。

Method: 设计并开发Lantern平台，进行深入的机电架构迭代，保持低成本（约40美元）。作为可扩展的开源平台，通过五个探索性研究评估其HRI潜力：1）协同设计工作坊；2）感官室案例研究；3）分发到外部HRI实验室；4）整合到研究生级HRI课程；5）面向老年人和儿童的公共展览。

Result: Lantern能有效激发用户参与，支持从情绪调节到专注工作等多样化应用场景，并成功降低了人机交互研究的进入门槛，被证明是一个可行的HRI平台。

Conclusion: Lantern作为一个低成本、简约的机器人对象平台，能够有效促进人机交互研究，支持广泛的应用场景，并通过开源和可扩展设计降低了HRI领域的参与门槛。

Abstract: Robotic objects are simple actuated systems that subtly blend into human environments. We design and introduce Lantern, a minimalist robotic object platform to enable building simple robotic artifacts. We conducted in-depth design and engineering iterations of Lantern's mechatronic architecture to meet specific design goals while maintaining a low build cost (~40 USD). As an extendable, open-source platform, Lantern aims to enable exploration of a range of HRI scenarios by leveraging human tendency to assign social meaning to simple forms. To evaluate Lantern's potential for HRI, we conducted a series of explorations: 1) a co-design workshop, 2) a sensory room case study, 3) distribution to external HRI labs, 4) integration into a graduate-level HRI course, and 5) public exhibitions with older adults and children. Our findings show that Lantern effectively evokes engagement, can support versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to HRI as a field.

</details>


### [66] [Plant-Inspired Robot Design Metaphors for Ambient HRI](https://arxiv.org/abs/2601.22387)
*Victor Nikhil Antony,Adithya R N,Sarah Derrick,Zhili Gong,Peter M. Donley,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 论文探索植物作为人机交互的隐喻灵感，通过设计研究开发植物启发的机器人原型，研究如何通过植物形态重塑人机交互范式。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互主要基于拟人化和拟动物化范式，产生高需求、显性的交互形式。植物作为环境性、低需求的存在，通过时间节奏和微妙表达塑造氛围和关系，为重新思考人机交互提供了新的隐喻灵感。

Method: 采用设计研究方法，进行迭代的构思、原型制作和反思循环。通过原型中心研讨会探索人们对植物启发机器人的感知和想象，分析植物隐喻和形态产生的设计原语。

Result: 开发了一套推测性、开源的原型，探索植物启发的存在感、时间性、形态和姿态。获得了关于人们如何感知植物启发机器人的设计洞察，以及使用植物隐喻重塑人机交互的设计考虑因素。

Conclusion: 植物作为隐喻灵感能够为人机交互提供新的设计范式，从高需求、显性交互转向更环境性、低需求的交互形式，通过时间节奏和微妙表达塑造更自然的交互体验。

Abstract: Plants offer a paradoxical model for interaction: they are ambient, low-demand presences that nonetheless shape atmosphere, routines, and relationships through temporal rhythms and subtle expressions. In contrast, most human-robot interaction (HRI) has been grounded in anthropomorphic and zoomorphic paradigms, producing overt, high-demand forms of engagement. Using a Research through Design (RtD) methodology, we explore plants as metaphoric inspiration for HRI; we conducted iterative cycles of ideation, prototyping, and reflection to investigate what design primitives emerge from plant metaphors and morphologies, and how these primitives can be combined into expressive robotic forms. We present a suite of speculative, open-source prototypes that help probe plant-inspired presence, temporality, form, and gestures. We deepened our learnings from design and prototyping through prototype-centered workshops that explored people's perceptions and imaginaries of plant-inspired robots. This work contributes: (1) Set of plant-inspired robotic artifacts; (2) Designerly insights on how people perceive plant-inspired robots; and (3) Design consideration to inform how to use plant metaphors to reshape HRI.

</details>


### [67] [Accurate Pedestrian Tracking in Urban Canyons: A Multi-Modal Fusion Approach](https://arxiv.org/abs/2601.22406)
*Shahar Dubiner,Peng Ren,Roberto Manduchi*

Main category: cs.RO

TL;DR: 提出一种融合GNSS、惯性数据和地图空间先验的粒子滤波行人导航方法，在GNSS性能下降的城市环境中提高定位精度，特别适用于视障用户需要精确街道侧向识别的场景。


<details>
  <summary>Details</summary>
Motivation: 城市环境中GNSS性能下降严重影响定位精度，对视障用户尤其关键，因为他们需要精确识别街道正确侧向进行导航。基于摄像头的视觉定位不实用，需要解决GNSS局限性。

Method: 采用粒子滤波融合GNSS和惯性数据，结合地图空间先验（如不可通行建筑物和不可能行走区域）作为概率形式的地图匹配。惯性定位使用RoNIN机器学习方法，通过粒子权重调整实现与GNSS估计和不确定性的融合。

Result: 在旧金山市中心6条挑战性步行路线上评估，融合方法(GNSS+RoNIN+PF)在大多数指标上显著优于仅GNSS定位。仅惯性定位配合粒子滤波也在关键指标（如人行道分配和跨街道误差）上超越仅GNSS方法。

Conclusion: 提出的融合方法能有效提升城市环境中的行人定位精度，特别有助于视障用户的导航需求，通过结合GNSS、惯性数据和地图先验信息克服了单一技术的局限性。

Abstract: The contribution describes a pedestrian navigation approach designed to improve localization accuracy in urban environments where GNSS performance is degraded, a problem that is especially critical for blind or low-vision users who depend on precise guidance such as identifying the correct side of a street. To address GNSS limitations and the impracticality of camera-based visual positioning, the work proposes a particle filter based fusion of GNSS and inertial data that incorporates spatial priors from maps, such as impassable buildings and unlikely walking areas, functioning as a probabilistic form of map matching. Inertial localization is provided by the RoNIN machine learning method, and fusion with GNSS is achieved by weighting particles based on their consistency with GNSS estimates and uncertainty. The system was evaluated on six challenging walking routes in downtown San Francisco using three metrics related to sidewalk correctness and localization error. Results show that the fused approach (GNSS+RoNIN+PF) significantly outperforms GNSS only localization on most metrics, while inertial-only localization with particle filtering also surpasses GNSS alone for critical measures such as sidewalk assignment and across street error.

</details>


### [68] [High-Definition 5MP Stereo Vision Sensing for Robotics](https://arxiv.org/abs/2601.22445)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.RO

TL;DR: 该研究提出了一种用于5MP+高分辨率立体视觉系统的新型校准和立体匹配方法，旨在实现高精度和快速处理，并展示了高像素相机通过高精度校准才能产生高质量点云。


<details>
  <summary>Details</summary>
Motivation: 高分辨率（5MP+）立体视觉系统对于提升机器人能力至关重要，但传统方法无法满足高分辨率传感器所需的高精度校准和快速处理需求。

Method: 采用新型帧间校准和立体匹配方法处理5MP相机图像，并引入通过比较实时视差图与计算密集型算法生成的真值视差图来评估实时性能的新方法。

Result: 研究表明，高像素相机只有通过实施高精度校准才能产生高质量的点云，验证了所提方法在精度和速度方面的优势。

Conclusion: 高分辨率立体视觉系统需要匹配的高精度校准方法才能充分发挥其潜力，所提出的方法为实现这一目标提供了有效解决方案。

Abstract: High-resolution (5MP+) stereo vision systems are essential for advancing robotic capabilities, enabling operation over longer ranges and generating significantly denser and accurate 3D point clouds. However, realizing the full potential of high-angular-resolution sensors requires a commensurately higher level of calibration accuracy and faster processing -- requirements often unmet by conventional methods. This study addresses that critical gap by processing 5MP camera imagery using a novel, advanced frame-to-frame calibration and stereo matching methodology designed to achieve both high accuracy and speed. Furthermore, we introduce a new approach to evaluate real-time performance by comparing real-time disparity maps with ground-truth disparity maps derived from more computationally intensive stereo matching algorithms. Crucially, the research demonstrates that high-pixel-count cameras yield high-quality point clouds only through the implementation of high-accuracy calibration.

</details>


### [69] [CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control](https://arxiv.org/abs/2601.22467)
*Jiaqi Shi,Xulong Zhang,Xiaoyang Qu,Jianzong Wang*

Main category: cs.RO

TL;DR: CARE是一个无需动作标注的视觉-语言-动作模型训练框架，仅使用视频-文本对进行预训练，通过多任务目标学习连续潜在动作表示，在小规模标注数据上微调后实现机器人控制。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖动作监督，限制了可扩展性和泛化能力。需要开发无需动作标注的弱监督方法来训练机器人控制模型。

Method: CARE框架仅使用视频-文本对进行预训练，通过新设计的多任务目标学习连续潜在动作表示。在微调阶段使用少量标注数据训练动作头进行控制。

Result: 在多个仿真任务中，CARE展现出更高的成功率、更好的语义可解释性，并能避免捷径学习，证明了其可扩展性、可解释性和弱监督下的有效性。

Conclusion: CARE通过消除动作标注需求，为VLA模型的机器人控制提供了可扩展的弱监督解决方案，在保持性能的同时提高了泛化能力和可解释性。

Abstract: Recent advances in Vision-Language-Action (VLA) models have shown promise for robot control, but their dependence on action supervision limits scalability and generalization. To address this challenge, we introduce CARE, a novel framework designed to train VLA models for robotic task execution. Unlike existing methods that depend on action annotations during pretraining, CARE eliminates the need for explicit action labels by leveraging only video-text pairs. These weakly aligned data sources enable the model to learn continuous latent action representations through a newly designed multi-task pretraining objective. During fine-tuning, a small set of labeled data is used to train the action head for control. Experimental results across various simulation tasks demonstrate CARE's superior success rate, semantic interpretability, and ability to avoid shortcut learning. These results underscore CARE's scalability, interpretability, and effectiveness in robotic control with weak supervision.

</details>


### [70] [RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing](https://arxiv.org/abs/2601.22517)
*Kangning Yin,Zhe Cao,Wentao Dong,Weishuai Zeng,Tianyi Zhang,Qiang Zhang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Weinan Zhang*

Main category: cs.RO

TL;DR: RoboStriker：一个三阶段分层框架，通过解耦高层策略推理与底层物理执行，实现全自主人形机器人拳击，利用潜在空间多智能体强化学习提升训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在接触丰富且高度动态的任务（如拳击）中实现人类水平的竞争智能和身体敏捷性仍面临挑战。多智能体强化学习虽提供策略交互框架，但直接应用于人形控制受限于高维接触动力学和缺乏强物理运动先验。

Method: 提出RoboStriker三阶段框架：1）在人类动作捕捉数据上训练单智能体运动跟踪器，学习全面的拳击技能库；2）将技能蒸馏到结构化潜在流形，通过将高斯参数化分布投影到单位超球面进行正则化；3）引入潜在空间神经虚拟自博弈，智能体在潜在动作空间而非原始电机空间交互学习竞争策略。

Result: 实验结果表明RoboStriker在仿真中实现了优越的竞争性能，并展现出仿真到现实的迁移能力。

Conclusion: RoboStriker通过分层解耦策略推理与物理执行，结合潜在空间约束和神经虚拟自博弈，有效解决了人形机器人拳击中的多智能体强化学习挑战，实现了全自主的竞争性人形控制。

Abstract: Achieving human-level competitive intelligence and physical agility in humanoid robots remains a major challenge, particularly in contact-rich and highly dynamic tasks such as boxing. While Multi-Agent Reinforcement Learning (MARL) offers a principled framework for strategic interaction, its direct application to humanoid control is hindered by high-dimensional contact dynamics and the absence of strong physical motion priors. We propose RoboStriker, a hierarchical three-stage framework that enables fully autonomous humanoid boxing by decoupling high-level strategic reasoning from low-level physical execution. The framework first learns a comprehensive repertoire of boxing skills by training a single-agent motion tracker on human motion capture data. These skills are subsequently distilled into a structured latent manifold, regularized by projecting the Gaussian-parameterized distribution onto a unit hypersphere. This topological constraint effectively confines exploration to the subspace of physically plausible motions. In the final stage, we introduce Latent-Space Neural Fictitious Self-Play (LS-NFSP), where competing agents learn competitive tactics by interacting within the latent action space rather than the raw motor space, significantly stabilizing multi-agent training. Experimental results demonstrate that RoboStriker achieves superior competitive performance in simulation and exhibits sim-to-real transfer. Our website is available at RoboStriker.

</details>


### [71] [Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios](https://arxiv.org/abs/2601.22545)
*Feng Tao,Luca Paparusso,Chenyi Gu,Robin Koehler,Chenxu Wu,Xinyu Huang,Christian Juette,David Paz,Ren Liu*

Main category: cs.RO

TL;DR: 提出基于深度强化学习的实时路径规划框架，专门针对狭窄停车场景，通过单次前向传播生成动作，实现高效实时部署，性能超越传统规划器96%成功率。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划器在完美感知假设下有效，但对实际感知约束敏感且计算成本高，难以在复杂环境中实时部署。需要解决狭窄停车场景中需要多次倒车调整的挑战性路径规划问题。

Method: 采用深度强化学习框架，将路径规划建模为基于自行车模型动力学的序列决策问题，使智能体能够直接学习考虑车辆运动学和环境约束的导航策略。开发新基准支持训练和评估。

Result: 方法在成功率和效率方面达到最先进水平，相比传统规划器基线提升96%成功率和52%效率。开发的开源基准包含多样挑战性场景。

Conclusion: 提出的DRL框架为约束环境中的实时路径规划提供了更简单实用的解决方案，避免了传统方法对理想感知和额外模块的依赖，适合实时部署。开源基准将促进自主系统研究。

Abstract: Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep Reinforcement Learning (DRL) framework for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new benchmark is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves state-of-the-art success rates and efficiency, surpassing classical planner baselines by +96% in success rate and +52% in efficiency. Furthermore, we release our benchmark as an open-source resource for the community to foster future research in autonomous systems. The benchmark and accompanying tools are available at https://github.com/dqm5rtfg9b-collab/Constrained_Parking_Scenarios.

</details>


### [72] [Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation](https://arxiv.org/abs/2601.22550)
*Geonho Leem,Jaedong Lee,Jehee Lee,Seungmoon Song,Jungdam Won*

Main category: cs.RO

TL;DR: Exo-plore：一个结合神经力学模拟与深度强化学习的仿真框架，无需真人实验即可优化髋关节外骨骼辅助


<details>
  <summary>Details</summary>
Motivation: 当前外骨骼控制器优化需要长时间真人行走实验，这对行动不便者来说难以参与，限制了外骨骼的普及

Method: 结合神经力学模拟与深度强化学习，通过仿真生成适应辅助力的人类步态数据，优化髋关节外骨骼辅助

Result: 能够生成真实的人类步态适应数据，在随机性步态中产生可靠优化结果，并能推广到病理步态，显示病理严重程度与最佳辅助之间的线性关系

Conclusion: Exo-plore框架为外骨骼优化提供了一种无需真人实验的有效方法，特别适用于行动不便人群，有望推动外骨骼技术的普及应用

Abstract: Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current state-of-the-art approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assistance, such as individuals with mobility impairments, are rarely able to participate in such demanding procedures. We present Exo-plore, a simulation framework that combines neuromechanical simulation with deep reinforcement learning to optimize hip exoskeleton assistance without requiring real human experiments. Exo-plore can (1) generate realistic gait data that captures human adaptation to assistive forces, (2) produce reliable optimization results despite the stochastic nature of human gait, and (3) generalize to pathological gaits, showing strong linear relationships between pathology severity and optimal assistance.

</details>


### [73] [Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies](https://arxiv.org/abs/2601.22672)
*Theodora Kastritsi,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出一种为超数机器人身体(SRB)用户提供动觉反馈的控制框架，当检测到非人体工学姿势时提供阻力，以培养长期的人体工学习惯


<details>
  <summary>Details</summary>
Motivation: 虽然SRB能增强人类负载能力，但在与人类物理交互的任务中，用户仍可能采用不舒适的非人体工学姿势，长期可能导致不适或伤害

Method: 开发虚拟夹具方法，结合连续在线的人体工学姿势评估框架；为改善操作者与SRB的协调，调整浮动底座位置

Result: 实验结果表明人体工学驱动控制框架的功能和有效性，包括两个涉及14名受试者的实际移动操作任务用户研究

Conclusion: 提出的控制框架能有效促进人体工学姿势，相比不考虑人体工学的基准控制框架表现更优

Abstract: Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.

</details>


### [74] [FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation](https://arxiv.org/abs/2601.22686)
*Biyu Ye,Na Fan,Zhengping Fan,Weiliang Deng,Hongming Chen,Qifeng Chen,Ximin Lyu*

Main category: cs.RO

TL;DR: 提出一种用于空中机械臂的机载框架，通过视觉预抓取惯性估计和抓取后自适应机制，实现实时惯性动力学估计与自适应控制。


<details>
  <summary>Details</summary>
Motivation: 空中机械臂在实际部署中面临时变惯性参数的挑战，这些参数对有效载荷变化和机械臂配置高度敏感，需要更鲁棒的控制方法。

Method: 集成视觉预抓取惯性估计模块和抓取后自适应机制，开发基于增益调度的惯性感知自适应控制策略，并通过频域系统辨识评估鲁棒性。

Result: 为空中机械臂的抓取后控制提供了新见解，真实世界实验验证了所提框架的有效性和可行性。

Conclusion: 该框架通过实时惯性估计和自适应控制，显著提升了空中机械臂在有效载荷变化和配置变化下的鲁棒性和实用性。

Abstract: Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.

</details>


### [75] [Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives](https://arxiv.org/abs/2601.22849)
*Christian Dietz,Sebastian Albrecht,Gianluca Frison,Moritz Diehl,Armin Nurkanović*

Main category: cs.RO

TL;DR: 提出一种基于可微物理仿真的高效装配运动规划方法，通过二阶导数信息减少仿真步数，实现高成功率（>99%）的实物实验


<details>
  <summary>Details</summary>
Motivation: 传统装配运动规划依赖大量物理仿真（强化学习或采样方法），计算成本高。需要更高效的规划方法，减少仿真需求

Method: 构建可微物理仿真，提供二阶解析导数；使用内点法平滑处理碰撞检测和接触解析；提出线性规划优化的碰撞检测变体；建立多场景轨迹优化确保鲁棒性

Result: 实物实验成功率超过99%；验证了接触动力学平滑近似和鲁棒建模对成功率的影响；在模拟中展示精确Hessian矩阵优于常用近似方法

Conclusion: 可微物理仿真结合二阶导数信息能显著提高装配运动规划效率，减少仿真需求，实现高成功率的实物执行

Abstract: Efficient planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with reinforcement learning and sampling-based methods by using extensive physics simulations. This paper proposes a sample-efficient robust optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the efficient use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. We propose a modified variant of an optimization-based formulation of collision detection formulated as a linear program and present an efficient implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory optimization problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and robust modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.

</details>


### [76] [Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs](https://arxiv.org/abs/2601.22927)
*Lars Ullrich,Michael Buchholz,Klaus Dietmayer,Knut Graichen*

Main category: cs.RO

TL;DR: 论文分析了AI在自动驾驶中的挑战与机遇，重新审视了完全自动驾驶在AI发展背景下的可行性，并提出了相关研究问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶面临真实开放世界的动态变化挑战，虽然AI显示出超越传统方法、处理更高复杂性和实现新自主水平的潜力，但AI应用也引发了安全性和可迁移性等新问题。

Method: 分析当前自动驾驶发展现状，识别局限性，预测技术可能性，并在前瞻性发展背景下审视各种挑战。

Result: 识别了AI在自动驾驶功能中带来的挑战和机遇，重新思考了完全自动驾驶在AI进展背景下的可行性。

Conclusion: 本文通过分析AI领域进展，重新审视了完全自动驾驶，并提出了相应的需求和由此产生的研究问题。

Abstract: Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of artificial intelligence (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of AI raises further questions of safety and transferability. To identify the challenges and opportunities arising from AI concerning autonomous driving functionalities, we have analyzed the current state of AD, outlined limitations, and identified foreseeable technological possibilities. Thereby, various further challenges are examined in the context of prospective developments. In this way, this article reconsiders fully autonomous driving with respect to advancements in the field of AI and carves out the respective needs and resulting research questions.

</details>


### [77] [MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2601.22930)
*Xidong Li,Mingyu Guo,Chenchao Xu,Bailin Li,Wenjing Zhu,Yangang Zou,Rui Chen,Zehuan Wang*

Main category: cs.RO

TL;DR: MTDrive：基于多轮推理的自动驾驶轨迹规划框架，通过MLLMs与强化学习结合，利用多轮迭代优化轨迹，解决复杂长尾场景问题


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于单轮推理，难以处理需要迭代优化的复杂任务，特别是在自动驾驶的长尾场景中，需要更灵活的轨迹规划能力

Method: 提出MTDrive多轮框架，引入mtGRPO算法缓解奖励稀疏问题，构建交互式轨迹理解数据集，并进行系统级优化提升训练效率

Result: 在NAVSIM基准测试中表现优于现有方法，验证了多轮推理范式的有效性，系统优化使训练吞吐量提升2.5倍

Conclusion: 多轮推理范式显著提升了自动驾驶轨迹规划在复杂场景中的性能，为MLLMs与RL的深度结合提供了新思路

Abstract: Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with Reinforcement Learning (RL) has shown promise in addressing "long-tail" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks requiring iterative refinement. To overcome this limitation, we present MTDrive, a multi-turn framework that enables MLLMs to iteratively refine trajectories based on environmental feedback. MTDrive introduces Multi-Turn Group Relative Policy Optimization (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns. We further construct an interactive trajectory understanding dataset from closed-loop simulation to support multi-turn training. Experiments on the NAVSIM benchmark demonstrate superior performance compared to existing methods, validating the effectiveness of our multi-turn reasoning paradigm. Additionally, we implement system-level optimizations to reduce data transfer overhead caused by high-resolution images and multi-turn sequences, achieving 2.5x training throughput. Our data, models, and code will be made available soon.

</details>


### [78] [Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation](https://arxiv.org/abs/2601.22965)
*Runhua Zhang,Junyi Hou,Changxu Cheng,Qiyi Chen,Tao Wang,Wuyue Zhao*

Main category: cs.RO

TL;DR: SIDP通过自模仿机制改进扩散策略，减少对专家演示的依赖和后处理筛选，实现更高效、更高质量的视觉导航规划。


<details>
  <summary>Details</summary>
Motivation: 传统扩散策略依赖模仿学习，会继承专家演示的次优性和冗余，需要计算密集的"生成-过滤"流程和辅助选择器，导致推理效率低下。

Method: 提出自模仿扩散策略(SIDP)，通过奖励引导的自模仿机制选择性地模仿自身采样的轨迹，采用奖励驱动的课程学习和目标无关的轨迹增强来提升数据利用效率和规划鲁棒性。

Result: 在综合仿真基准测试中显著优于先前方法，在Jetson Orin Nano上推理速度比基线NavDP快2.5倍(110ms vs 273ms)，支持高效实时部署，多机器人平台实验验证了有效性。

Conclusion: SIDP通过自模仿机制有效解决了传统扩散策略的次优性和效率问题，实现了高质量、高效率的视觉导航规划，具备实际部署的可行性。

Abstract: Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive "generate-then-filter" pipeline that relies on auxiliary selectors during inference. To address these challenges, we propose Self-Imitated Diffusion Policy (SIDP), a novel framework that learns improved planning by selectively imitating a set of trajectories sampled from itself. Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering. During training, we employ a reward-driven curriculum learning paradigm to mitigate inefficient data utility, and goal-agnostic exploration for trajectory augmentation to improve planning robustness. Extensive evaluations on a comprehensive simulation benchmark show that SIDP significantly outperforms previous methods, with real-world experiments confirming its effectiveness across multiple robotic platforms. On Jetson Orin Nano, SIDP delivers a 2.5$\times$ faster inference than the baseline NavDP, i.e., 110ms VS 273ms, enabling efficient real-time deployment.

</details>


### [79] [Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.22988)
*Di Zhang,Weicheng Duan,Dasen Gu,Hongye Lu,Hai Zhang,Hang Yu,Junqiao Zhao,Guang Chen*

Main category: cs.RO

TL;DR: MethodName：一个统一的表示-策略学习框架，通过单视图3D预训练和多步蒸馏实现视点泛化的机器人操作


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人操作需要视觉运动策略具备强大的空间场景理解和跨不同相机视点的泛化能力。现有3D感知视觉表示方法存在三个关键限制：推理时依赖多视角观测（在单视图受限场景中不实用）、不完整的场景建模（无法捕捉精确操作所需的整体和细粒度几何结构）、缺乏有效的策略训练策略来保留和利用获得的3D知识。

Method: MethodName引入单视图3D预训练范式，利用点云重建和前馈高斯溅射在多视图监督下学习整体几何表示。在策略学习阶段，执行多步蒸馏以保留预训练的几何理解，并将其有效转移到操作技能中。

Result: 在12个RLBench任务上，该方法比先前最先进方法的平均成功率高出12.7%。在六个代表性任务上的进一步评估显示，在中等和大视点偏移下，成功率仅分别下降22.0%和29.7%，而最先进方法则分别下降41.6%和51.5%，表现出强大的零样本视点泛化能力。

Conclusion: MethodName通过统一的表示-策略学习框架，解决了现有3D感知方法在单视图推理、场景建模和知识保留方面的限制，实现了强大的视点泛化机器人操作性能。

Abstract: Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge. To address these challenges, we present MethodName, a unified representation-policy learning framework for view-generalizable robotic manipulation. MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, MethodName performs multi-step distillation to preserve the pretrained geometric understanding and effectively transfer it to manipulation skills. We conduct experiments on 12 RLBench tasks, where our approach outperforms the previous state-of-the-art method by 12.7% in average success rate. Further evaluation on six representative tasks demonstrates strong zero-shot view generalization, with success rate drops of only 22.0% and 29.7% under moderate and large viewpoint shifts respectively, whereas the state-of-the-art method suffers larger decreases of 41.6% and 51.5%.

</details>


### [80] [MOSAIC: Modular Scalable Autonomy for Intelligent Coordination of Heterogeneous Robotic Teams](https://arxiv.org/abs/2601.23038)
*David Oberacker,Julia Richer,Philip Arm,Marvin Grosse Besselmann,Lennart Puck,William Talbot,Maximilian Schik,Sabine Bellmann,Tristan Schnell,Hendrik Kolvenbach,Rüdiger Dillmann,Marco Hutter,Arne Roennau*

Main category: cs.RO

TL;DR: MOSAIC是一个可扩展的多机器人自主探索框架，使用兴趣点统一任务抽象和多层自主性，允许单个操作员监督异构机器人团队进行科学探索。


<details>
  <summary>Details</summary>
Motivation: 当前移动机器人在恶劣环境探索中主要依赖人工遥操作，这限制了部署规模并要求近乎连续的低延迟通信。需要一种能够减少操作员干预、提高可扩展性的自主框架。

Method: 提出基于兴趣点的统一任务抽象和多层自主性框架，根据机器人能力动态分配探索和测量任务，利用团队冗余和专业性实现连续操作。

Result: 在模拟月球勘探场景的太空模拟现场实验中，由5个异构机器人和单个操作员组成的团队，即使有一个机器人完全故障，仍完成了82.3%的分配任务，自主率达到86%，操作员工作量仅为78.2%。

Conclusion: 该框架实现了有限操作员干预下的鲁棒、可扩展多机器人科学探索，并总结了机器人互操作性、网络架构、团队组成和操作员工作负载管理方面的实践经验。

Abstract: Mobile robots have become indispensable for exploring hostile environments, such as in space or disaster relief scenarios, but often remain limited to teleoperation by a human operator. This restricts the deployment scale and requires near-continuous low-latency communication between the operator and the robot. We present MOSAIC: a scalable autonomy framework for multi-robot scientific exploration using a unified mission abstraction based on Points of Interest (POIs) and multiple layers of autonomy, enabling supervision by a single operator. The framework dynamically allocates exploration and measurement tasks based on each robot's capabilities, leveraging team-level redundancy and specialization to enable continuous operation. We validated the framework in a space-analog field experiment emulating a lunar prospecting scenario, involving a heterogeneous team of five robots and a single operator. Despite the complete failure of one robot during the mission, the team completed 82.3% of assigned tasks at an Autonomy Ratio of 86%, while the operator workload remained at only 78.2%. These results demonstrate that the proposed framework enables robust, scalable multi-robot scientific exploration with limited operator intervention. We further derive practical lessons learned in robot interoperability, networking architecture, team composition, and operator workload management to inform future multi-robot exploration missions.

</details>


### [81] [Robust and Generalized Humanoid Motion Tracking](https://arxiv.org/abs/2601.23080)
*Yubiao Ma,Han Yu,Jiayin Xie,Changtai Lv,Qiang Luo,Chi Zhang,Yunpeng Yin,Boyang Xing,Xuemei Ren,Dongdong Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于动力学条件命令聚合框架的人形机器人全身控制器，通过因果时间编码器和多头交叉注意力机制处理噪声参考运动，结合跌倒恢复课程提升鲁棒性，仅需3.5小时运动数据即可实现端到端训练。


<details>
  <summary>Details</summary>
Motivation: 学习通用人形机器人全身控制器面临挑战：参考运动转移到机器人域后可能存在噪声和不一致性，闭环执行会放大局部缺陷，导致动态接触丰富行为中的漂移或失败。

Method: 提出动力学条件命令聚合框架：1) 使用因果时间编码器总结近期本体感知；2) 多头交叉注意力命令编码器基于当前动力学选择性地聚合上下文窗口；3) 集成跌倒恢复课程，包含随机不稳定初始化和退火向上辅助力。

Result: 该方法仅需约3.5小时运动数据，支持单阶段端到端训练无需蒸馏。在多样化参考输入和挑战性运动机制下评估，展示了零样本迁移到未见运动的能力，以及在物理人形机器人上的鲁棒仿真到现实迁移。

Conclusion: 提出的动力学条件命令聚合框架能够有效处理噪声参考运动，结合跌倒恢复课程显著提升鲁棒性和抗干扰能力，实现了高效的人形机器人全身控制，具备良好的泛化性和现实部署能力。

Abstract: Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation framework that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as robust sim-to-real transfer on a physical humanoid robot.

</details>


### [82] [Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation](https://arxiv.org/abs/2601.23087)
*Wu Songwei,Jiang Zhiduo,Xie Guanghu,Liu Yang,Liu Hong*

Main category: cs.RO

TL;DR: LG-Flow Policy：一种在连续潜在动作空间进行流匹配的轨迹级模仿学习框架，通过将动作序列编码为时间正则化的潜在轨迹，实现快速单步推理和平滑的长时程执行。


<details>
  <summary>Details</summary>
Motivation: 现有生成策略在长时程机器人操作中存在挑战：基于扩散的方法建模能力强但推理延迟高，而流匹配方法虽然能实现快速单步生成，但在原始动作空间中直接应用往往导致执行不稳定。

Method: 提出LG-Flow Policy框架，在连续潜在动作空间进行流匹配。将动作序列编码为时间正则化的潜在轨迹，学习显式的潜在空间流，从而将全局运动结构与低级控制噪声解耦。还结合了几何感知点云条件和执行时多模态调制。

Result: 在仿真和物理机器人平台上的实验结果表明，LG-Flow Policy实现了接近单步推理，显著提高了轨迹平滑度和任务成功率，比在原始动作空间操作的流匹配基线表现更好，且比基于扩散的策略更高效。

Conclusion: LG-Flow Policy通过将流匹配应用于潜在动作空间，成功解决了长时程机器人操作中表达性建模、实时推理和稳定执行之间的权衡问题，为机器人策略学习提供了高效可靠的解决方案。

Abstract: Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space.
  We propose LG-Flow Policy, a trajectory-level imitation learning framework that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution.
  LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more efficient than diffusion-based policies.

</details>


### [83] [IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models](https://arxiv.org/abs/2601.23266)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: 提出IRL-DAL框架，结合逆强化学习与扩散模型规划器，用于自动驾驶车辆的安全导航，在模拟器中达到96%成功率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要安全、鲁棒的导航策略，传统方法在复杂动态环境中表现有限。需要结合专家演示与强化学习，同时确保安全约束。

Method: 1. 从专家FSM控制器模仿学习初始化；2. 结合环境奖励与IRL判别器信号；3. 使用条件扩散模型作为安全监督器规划路径；4. 引入可学习自适应掩码(LAM)改善感知；5. 用PPO进行策略微调；6. 在Webots模拟器中采用两阶段课程学习。

Result: 达到96%成功率，碰撞率降至每1000步0.05次，创造了安全导航的新基准，能处理不安全条件达到专家水平。

Conclusion: IRL-DAL框架有效结合了逆强化学习、扩散模型规划和自适应感知，实现了安全、鲁棒的自动驾驶导航，代码已开源。

Abstract: This paper proposes a novel inverse reinforcement learning framework using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. Reinforcement learning (RL) is then performed with a hybrid reward that combines diffuse environmental feedback and targeted IRL rewards. A conditional diffusion model, which acts as a safety supervisor, plans safe paths. It stays in its lane, avoids obstacles, and moves smoothly. Then, a learnable adaptive mask (LAM) improves perception. It shifts visual attention based on vehicle speed and nearby hazards. After FSM-based imitation, the policy is fine-tuned with Proximal Policy Optimization (PPO). Training is run in the Webots simulator with a two-stage curriculum. A 96\% success rate is reached, and collisions are reduced to 0.05 per 1k steps, marking a new benchmark for safe navigation. By applying the proposed approach, the agent not only drives in lane but also handles unsafe conditions at an expert level, increasing robustness.We make our code publicly available.

</details>


### [84] [End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms](https://arxiv.org/abs/2601.23285)
*MH Farhadi,Ali Rabiee,Sima Ghafoori,Anna Cetera,Andrew Fisher,Reza Abiri*

Main category: cs.RO

TL;DR: BRACE框架通过贝叶斯意图推断与上下文自适应辅助的端到端集成，在共享自主系统中实现了更优的性能，在复杂、目标模糊的场景中表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 共享自主系统需要从用户意图推断到辅助水平确定的统一方法。现有方法依赖静态混合比或将目标推断与辅助仲裁分离，导致在非结构化环境中性能不佳。

Method: 提出BRACE框架，通过端到端梯度流架构微调贝叶斯意图推断和上下文自适应辅助，将协作控制策略基于环境上下文和完整目标概率分布。

Result: 相比SOTA方法（IDA、DQN），在三维评估中分别实现6.3%更高成功率、41%路径效率提升，相比无辅助控制提升36.3%成功率和87%路径效率。

Conclusion: 集成优化在复杂、目标模糊的场景中最有益，可推广到需要目标导向辅助的机器人领域，推动了自适应共享自主系统的技术前沿。

Abstract: Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a novel framework that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our pipeline conditions collaborative control policies on environmental context and complete goal probability distributions. We provide analysis showing (1) optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, and (2) integrating belief information into policy learning yields a quadratic expected regret advantage over sequential approaches. We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints. We demonstrate improvements over SOTA, achieving 6.3% higher success rates and 41% increased path efficiency, and 36.3% success rate and 87% path efficiency improvement over unassisted control. Our results confirmed that integrated optimization is most beneficial in complex, goal-ambiguous scenarios, and is generalizable across robotic domains requiring goal-directed assistance, advancing the SOTA for adaptive shared autonomy.

</details>
