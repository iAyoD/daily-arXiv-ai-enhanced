<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 41]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Kilometer-Scale GNSS-Denied UAV Navigation via Heightmap Gradients: A Winning System from the SPRIN-D Challenge](https://arxiv.org/abs/2510.01348)
*Michal Werner,David Čapek,Tomáš Musil,Ondřej Franěk,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种在GNSS拒止环境下实现无人机长距离自主飞行的系统，通过LiDAR高度图匹配和粒子滤波来校正里程计漂移，在CPU硬件上实时运行，成功完成千米级飞行任务。


<details>
  <summary>Details</summary>
Motivation: 解决GNSS拒止环境下无人机长距离飞行的挑战：里程计集成会导致漂移，未知区域无法使用闭环检测，嵌入式平台计算能力有限。

Method: 集成感知、建图、规划和控制系统，采用轻量级漂移校正方法：通过梯度模板匹配将LiDAR局部高度图与先验地理数据高度图匹配，并在聚类粒子滤波中将证据与里程计融合。

Result: 在竞赛中成功执行了千米级飞行，覆盖城市、森林和开阔地带地形，相对于原始里程计显著减少了漂移，在仅使用CPU的硬件上实时运行。

Conclusion: 该系统为GNSS拒止环境下的无人机自主性设计提供了实用见解，证明了在有限计算资源下实现可靠长距离飞行的可行性。

Abstract: Reliable long-range flight of unmanned aerial vehicles (UAVs) in GNSS-denied
environments is challenging: integrating odometry leads to drift, loop closures
are unavailable in previously unseen areas and embedded platforms provide
limited computational power. We present a fully onboard UAV system developed
for the SPRIN-D Funke Fully Autonomous Flight Challenge, which required 9 km
long-range waypoint navigation below 25 m AGL (Above Ground Level) without GNSS
or prior dense mapping. The system integrates perception, mapping, planning,
and control with a lightweight drift-correction method that matches
LiDAR-derived local heightmaps to a prior geo-data heightmap via
gradient-template matching and fuses the evidence with odometry in a clustered
particle filter. Deployed during the competition, the system executed
kilometer-scale flights across urban, forest, and open-field terrain and
reduced drift substantially relative to raw odometry, while running in real
time on CPU-only hardware. We describe the system architecture, the
localization pipeline, and the competition evaluation, and we report practical
insights from field deployment that inform the design of GNSS-denied UAV
autonomy.

</details>


### [2] [Safe Motion Planning and Control Using Predictive and Adaptive Barrier Methods for Autonomous Surface Vessels](https://arxiv.org/abs/2510.01357)
*Alejandro Gonzalez-Garcia,Wei Xiao,Wei Wang,Alejandro Astudillo,Wilm Decré,Jan Swevers,Carlo Ratti,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种结合模型预测控制(MPC)和控制屏障函数(CBFs)的安全运动规划策略，用于自主船舶在狭窄内河水道的导航。通过时变膨胀椭圆障碍物表示，根据船舶与障碍物的相对位置和姿态自适应调整膨胀半径，减少控制器的保守性。


<details>
  <summary>Details</summary>
Motivation: 自主船舶在狭窄内河水道等挑战性空间中的安全运动规划至关重要，但传统方法通常计算量大或过于保守。

Method: 结合MPC和CBFs，使用时间变化的膨胀椭圆障碍物表示，根据相对位置和姿态自适应调整膨胀半径。MPC提供近似运动规划，高阶CBFs使用变化的膨胀半径确保船舶安全。

Result: 仿真和真实世界实验表明，该策略使全驱动自主机器人船舶能够实时导航狭窄空间，解决潜在死锁，同时确保安全。

Conclusion: 提出的自适应膨胀方法相比传统固定椭圆障碍物表示减少了保守性，实现了安全高效的自主船舶导航。

Abstract: Safe motion planning is essential for autonomous vessel operations,
especially in challenging spaces such as narrow inland waterways. However,
conventional motion planning approaches are often computationally intensive or
overly conservative. This paper proposes a safe motion planning strategy
combining Model Predictive Control (MPC) and Control Barrier Functions (CBFs).
We introduce a time-varying inflated ellipse obstacle representation, where the
inflation radius is adjusted depending on the relative position and attitude
between the vessel and the obstacle. The proposed adaptive inflation reduces
the conservativeness of the controller compared to traditional fixed-ellipsoid
obstacle formulations. The MPC solution provides an approximate motion plan,
and high-order CBFs ensure the vessel's safety using the varying inflation
radius. Simulation and real-world experiments demonstrate that the proposed
strategy enables the fully-actuated autonomous robot vessel to navigate through
narrow spaces in real time and resolve potential deadlocks, all while ensuring
safety.

</details>


### [3] [A Stochastic Framework for Continuous-Time State Estimation of Continuum Robots](https://arxiv.org/abs/2510.01381)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种基于因子图优化的连续时间随机状态估计框架，用于连续体机器人的状态估计，能够适应未建模的外部力和数据丢失。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人状态估计方法通常使用计算复杂的动态模型、简化的形状近似或仅限于准静态方法，这些方法对未建模的干扰很敏感。

Method: 基于连续时间运动学的因子图优化方法，使用高斯白噪声过程，结合简单机器人模型和高频传感。

Result: 能够估计机器人位姿、速度和应变的均值和协方差，可在时间或空间上连续插值，计算复杂度与时间呈线性关系。

Conclusion: 该方法在具有陀螺仪和位姿传感器的连续体机器人上验证了其在实际系统中的多功能性。

Abstract: State estimation techniques for continuum robots (CRs) typically involve
using computationally complex dynamic models, simplistic shape approximations,
or are limited to quasi-static methods. These limitations can be sensitive to
unmodelled disturbances acting on the robot. Inspired by a factor-graph
optimization paradigm, this work introduces a continuous-time stochastic state
estimation framework for continuum robots. We introduce factors based on
continuous-time kinematics that are corrupted by a white noise Gaussian process
(GP). By using a simple robot model paired with high-rate sensing, we show
adaptability to unmodelled external forces and data dropout. The result
contains an estimate of the mean and covariance for the robot's pose, velocity,
and strain, each of which can be interpolated continuously in time or space.
This same interpolation scheme can be used during estimation, allowing for
inclusion of measurements on states that are not explicitly estimated. Our
method's inherent sparsity leads to a linear solve complexity with respect to
time and interpolation queries in constant time. We demonstrate our method on a
CR with gyroscope and pose sensors, highlighting its versatility in real-world
systems.

</details>


### [4] [VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation](https://arxiv.org/abs/2510.01388)
*Arthur Zhang,Xiangyun Meng,Luca Calliari,Dong-Ki Kim,Shayegan Omidshafiei,Joydeep Biswas,Ali Agha,Amirreza Shaban*

Main category: cs.RO

TL;DR: VENTURA是一个视觉语言导航系统，通过微调互联网预训练的扩散模型进行路径规划，生成视觉路径掩码，再由轻量级策略执行轨迹，实现自然语言指令下的多样化机器人行为。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型在机器人导航任务中难以有效迁移的问题，因为动作空间差异和预训练目标不匹配阻碍了在机器人任务中的应用。

Method: 使用图像扩散模型生成路径掩码作为视觉规划，通过自监督跟踪模型和VLM增强的标注进行训练，避免人工像素级标注，由轻量级行为克隆策略将视觉规划转化为可执行轨迹。

Result: 在真实世界评估中，VENTURA在物体到达、障碍物避让和地形偏好任务上优于最先进的基础模型基线，成功率提高33%，碰撞减少54%，并能泛化到未见过的任务组合。

Conclusion: VENTURA展示了在开放世界环境中基于自然语言指令的机器人导航能力，具有组合泛化能力，为机器人导航提供了新的解决方案。

Abstract: Robots must adapt to diverse human instructions and operate safely in
unstructured, open-world environments. Recent Vision-Language models (VLMs)
offer strong priors for grounding language and perception, but remain difficult
to steer for navigation due to differences in action spaces and pretraining
objectives that hamper transferability to robotics tasks. Towards addressing
this, we introduce VENTURA, a vision-language navigation system that finetunes
internet-pretrained image diffusion models for path planning. Instead of
directly predicting low-level actions, VENTURA generates a path mask (i.e. a
visual plan) in image space that captures fine-grained, context-aware
navigation behaviors. A lightweight behavior-cloning policy grounds these
visual plans into executable trajectories, yielding an interface that follows
natural language instructions to generate diverse robot behaviors. To scale
training, we supervise on path masks derived from self-supervised tracking
models paired with VLM-augmented captions, avoiding manual pixel-level
annotation or highly engineered data collection setups. In extensive real-world
evaluations, VENTURA outperforms state-of-the-art foundation model baselines on
object reaching, obstacle avoidance, and terrain preference tasks, improving
success rates by 33% and reducing collisions by 54% across both seen and unseen
scenarios. Notably, we find that VENTURA generalizes to unseen combinations of
distinct tasks, revealing emergent compositional capabilities. Videos, code,
and additional materials: https://venturapath.github.io

</details>


### [5] [INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models](https://arxiv.org/abs/2510.01389)
*Ulas Berk Karli,Ziyao Shangguan,Tesca FItzgerald*

Main category: cs.RO

TL;DR: INSIGHT框架利用token级不确定性信号预测VLA模型何时需要请求人类帮助，通过训练紧凑的transformer分类器来映射不确定性序列到帮助触发信号。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型缺乏内省机制来预测失败并请求人类监督，需要开发能够主动识别不确定性的方法。

Method: 使用π₀-FAST作为基础模型，提取token级熵、对数概率以及Dirichlet估计的任意性和认知不确定性，训练transformer分类器来映射这些序列到帮助触发信号，探索强监督和弱监督两种监督机制。

Result: 强监督标签能够捕捉细粒度不确定性动态以实现可靠的帮助检测，弱监督标签虽然噪声较大但在训练和评估对齐时仍具有竞争力，建模token级不确定性信号的时间演化比静态序列级分数具有更强的预测能力。

Conclusion: 这是对VLA中基于不确定性的内省机制的首个系统评估，为主动学习和通过选择性人类干预实现实时错误缓解开辟了新途径。

Abstract: Recent Vision-Language-Action (VLA) models show strong generalization
capabilities, yet they lack introspective mechanisms for anticipating failures
and requesting help from a human supervisor. We present \textbf{INSIGHT}, a
learning framework for leveraging token-level uncertainty signals to predict
when a VLA should request help. Using $\pi_0$-FAST as the underlying model, we
extract per-token \emph{entropy}, \emph{log-probability}, and Dirichlet-based
estimates of \emph{aleatoric and epistemic uncertainty}, and train compact
transformer classifiers to map these sequences to help triggers. We explore
supervision regimes for strong or weak supervision, and extensively compare
them across in-distribution and out-of-distribution tasks. Our results show a
trade-off: strong labels enable models to capture fine-grained uncertainty
dynamics for reliable help detection, while weak labels, though noisier, still
support competitive introspection when training and evaluation are aligned,
offering a scalable path when dense annotation is impractical. Crucially, we
find that modeling the temporal evolution of token-level uncertainty signals
with transformers provides far greater predictive power than static
sequence-level scores. This study provides the first systematic evaluation of
uncertainty-based introspection in VLAs, opening future avenues for active
learning and for real-time error mitigation through selective human
intervention.

</details>


### [6] [Beyond Collision Cones: Dynamic Obstacle Avoidance for Nonholonomic Robots via Dynamic Parabolic Control Barrier Functions](https://arxiv.org/abs/2510.01402)
*Hun Kuk Park,Taekyung Kim,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出动态抛物线控制屏障函数(DPCBF)，通过动态调整抛物线边界来解决非完整机器人在密集动态环境中CBF方法保守性和不可行性问题


<details>
  <summary>Details</summary>
Motivation: 现有CBF方法在非完整机器人密集动态环境中过于保守，基于碰撞锥或速度障碍的约束只考虑相对速度角度，导致QP问题不可行

Method: 使用动态抛物线边界定义安全集，抛物线顶点和曲率根据障碍物距离和相对速度大小动态调整，创建限制更少的安全约束

Result: DPCBF控制器显著提高了导航成功率和QP可行性，在100个动态障碍物的密集环境中成功导航，而基于碰撞锥的方法因不可行性而失败

Conclusion: DPCBF方法有效解决了非完整机器人在密集动态环境中的安全导航问题，相比传统方法具有更好的性能和可行性

Abstract: Control Barrier Functions (CBFs) are a powerful tool for ensuring the safety
of autonomous systems, yet applying them to nonholonomic robots in cluttered,
dynamic environments remains an open challenge. State-of-the-art methods often
rely on collision-cone or velocity-obstacle constraints which, by only
considering the angle of the relative velocity, are inherently conservative and
can render the CBF-based quadratic program infeasible, particularly in dense
scenarios. To address this issue, we propose a Dynamic Parabolic Control
Barrier Function (DPCBF) that defines the safe set using a parabolic boundary.
The parabola's vertex and curvature dynamically adapt based on both the
distance to an obstacle and the magnitude of the relative velocity, creating a
less restrictive safety constraint. We prove that the proposed DPCBF is valid
for a kinematic bicycle model subject to input constraints. Extensive
comparative simulations demonstrate that our DPCBF-based controller
significantly enhances navigation success rates and QP feasibility compared to
baseline methods. Our approach successfully navigates through dense
environments with up to 100 dynamic obstacles, scenarios where collision
cone-based methods fail due to infeasibility.

</details>


### [7] [How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?](https://arxiv.org/abs/2510.01404)
*Lexi Foland,Thomas Cohn,Adam Wei,Nicholas Pfaff,Boyuan Chen,Russ Tedrake*

Main category: cs.RO

TL;DR: 该论文研究扩散策略在机器人模仿学习中学习运动学约束的能力，通过双手抓取放置任务分析数据集大小、质量和流形曲率对约束学习的影响。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散策略在机器人模仿学习中表现出色，但任务性能不能可靠反映策略精确学习训练数据中约束的能力，需要研究扩散策略如何发现这些约束流形。

Method: 通过双手抓取放置任务的案例研究，分析三个因素对训练策略的影响：数据集大小、数据集质量和流形曲率。

Result: 扩散策略学习到约束流形的粗略近似，数据集大小和质量的降低对学习产生负面影响，而流形曲率与约束满足和任务成功的关系不明确。硬件评估验证了结果在现实世界中的适用性。

Conclusion: 扩散策略能够学习运动学约束，但学习效果受数据集特征影响，需要进一步研究流形曲率的作用。

Abstract: Diffusion policies have shown impressive results in robot imitation learning,
even for tasks that require satisfaction of kinematic equality constraints.
However, task performance alone is not a reliable indicator of the policy's
ability to precisely learn constraints in the training data. To investigate, we
analyze how well diffusion policies discover these manifolds with a case study
on a bimanual pick-and-place task that encourages fulfillment of a kinematic
constraint for success. We study how three factors affect trained policies:
dataset size, dataset quality, and manifold curvature. Our experiments show
diffusion policies learn a coarse approximation of the constraint manifold with
learning affected negatively by decreases in both dataset size and quality. On
the other hand, the curvature of the constraint manifold showed inconclusive
correlations with both constraint satisfaction and task success. A hardware
evaluation verifies the applicability of our results in the real world. Project
website with additional results and visuals:
https://diffusion-learns-kinematic.github.io

</details>


### [8] [AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation](https://arxiv.org/abs/2510.01433)
*Anukriti Singh,Kasra Torshizi,Khuzema Habib,Kelin Yu,Ruohan Gao,Pratap Tokekar*

Main category: cs.RO

TL;DR: AFFORD2ACT是一个基于视觉的机器人学习框架，通过从文本提示和单张图像中提取语义2D关键点，构建轻量级策略，在多样化真实世界操作任务中实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 解决基于视觉的机器人学习中密集图像或点云输入计算量大、包含无关背景特征的问题，以及现有基于关键点的方法依赖手动启发式或任务耦合选择，限制了可扩展性和语义理解。

Method: 采用三阶段流程：1) 可操作性过滤；2) 类别级关键点构建；3) 基于transformer的策略学习，包含嵌入式门控机制来推理最相关的关键点，生成紧凑的38维状态策略。

Result: 在15分钟内完成训练，无需本体感知或密集表示即可实时良好运行，在未见过的物体、新类别、背景和干扰物上达到82%的成功率。

Conclusion: AFFORD2ACT在多样化真实世界操作任务中持续提高数据效率，为轻量级、语义理解的机器人学习提供了有效解决方案。

Abstract: Vision-based robot learning often relies on dense image or point-cloud
inputs, which are computationally heavy and entangle irrelevant background
features. Existing keypoint-based approaches can focus on manipulation-centric
features and be lightweight, but either depend on manual heuristics or
task-coupled selection, limiting scalability and semantic understanding. To
address this, we propose AFFORD2ACT, an affordance-guided framework that
distills a minimal set of semantic 2D keypoints from a text prompt and a single
image. AFFORD2ACT follows a three-stage pipeline: affordance filtering,
category-level keypoint construction, and transformer-based policy learning
with embedded gating to reason about the most relevant keypoints, yielding a
compact 38-dimensional state policy that can be trained in 15 minutes, which
performs well in real-time without proprioception or dense representations.
Across diverse real-world manipulation tasks, AFFORD2ACT consistently improves
data efficiency, achieving an 82% success rate on unseen objects, novel
categories, backgrounds, and distractors.

</details>


### [9] [Differentiable Skill Optimisation for Powder Manipulation in Laboratory Automation](https://arxiv.org/abs/2510.01438)
*Minglun Wei,Xintong Yang,Yu-Kun Lai,Ze Ji*

Main category: cs.RO

TL;DR: 提出了一种用于实验室粉末运输的轨迹优化框架，结合可微分物理模拟、低维技能空间参数化和课程学习策略，实现接触丰富的机器人轨迹端到端优化。


<details>
  <summary>Details</summary>
Motivation: 机器人自动化加速科学发现，但粉末精确操作仍具挑战性，特别是在需要精度和稳定性的运输任务中。

Method: 集成可微分物理模拟精确建模颗粒动力学，使用低维技能空间参数化降低优化复杂度，采用课程学习策略逐步提升长时域任务能力。

Result: 实验结果表明，与强化学习基线相比，所提方法实现了更高的任务成功率和稳定性。

Conclusion: 该框架能够在保持稳定性和收敛效率的同时，实现接触丰富机器人轨迹的端到端优化。

Abstract: Robotic automation is accelerating scientific discovery by reducing manual
effort in laboratory workflows. However, precise manipulation of powders
remains challenging, particularly in tasks such as transport that demand
accuracy and stability. We propose a trajectory optimisation framework for
powder transport in laboratory settings, which integrates differentiable
physics simulation for accurate modelling of granular dynamics, low-dimensional
skill-space parameterisation to reduce optimisation complexity, and a
curriculum-based strategy that progressively refines task competence over long
horizons. This formulation enables end-to-end optimisation of contact-rich
robot trajectories while maintaining stability and convergence efficiency.
Experimental results demonstrate that the proposed method achieves superior
task success rates and stability compared to the reinforcement learning
baseline.

</details>


### [10] [Touching the tumor boundary: A pilot study on ultrasound based virtual fixtures for breast-conserving surgery](https://arxiv.org/abs/2510.01452)
*Laura Connolly,Tamas Ungi,Adnan Munawar,Anton Deguet,Chris Yeung,Russell H. Taylor,Parvin Mousavi,Gabor Fichtinger Keyvan Hashtrudi-Zaad*

Main category: cs.RO

TL;DR: 开发了一种用于乳腺癌保乳手术的协作机器人引导系统，通过触觉反馈帮助外科医生定位肿瘤边界，在模拟手术中显示出改善切除边缘和降低手术难度的效果。


<details>
  <summary>Details</summary>
Motivation: 在保乳手术中，由于肿瘤具有高度移动性、不可触及性和不规则边界，准确定位肿瘤边界具有挑战性。需要一种能够帮助外科医生精确识别和切除肿瘤的技术。

Method: 将小型触觉机器人改装为电切刀，结合超声和电磁导航识别肿瘤边界，当手术工具与肿瘤边界碰撞时施加禁止区域虚拟约束。通过对比有无触觉引导的模拟切除实验进行评估。

Result: 虚拟约束引导改善了切除边缘，用户在使用触觉反馈时感觉任务的心理需求、挫败感和努力程度都较低。同时发现了一些对手术流程的意外影响。

Conclusion: 虚拟约束技术有助于在模拟保乳手术中定位肿瘤边界。未来将进行更广泛的用户研究来进一步验证结果并优化引导系统。

Abstract: Purpose: Delineating tumor boundaries during breast-conserving surgery is
challenging as tumors are often highly mobile, non-palpable, and have
irregularly shaped borders. To address these challenges, we introduce a
cooperative robotic guidance system that applies haptic feedback for tumor
localization. In this pilot study, we aim to assess if and how this system can
be successfully integrated into breast cancer care.
  Methods: A small haptic robot is retrofitted with an electrocautery blade to
operate as a cooperatively controlled surgical tool. Ultrasound and
electromagnetic navigation are used to identify the tumor boundaries and
position. A forbidden region virtual fixture is imposed when the surgical tool
collides with the tumor boundary. We conducted a study where users were asked
to resect tumors from breast simulants both with and without the haptic
guidance. We then assess the results of these simulated resections both
qualitatively and quantitatively.
  Results: Virtual fixture guidance is shown to improve resection margins. On
average, users find the task to be less mentally demanding, frustrating, and
effort intensive when haptic feedback is available. We also discovered some
unanticipated impacts on surgical workflow that will guide design adjustments
and training protocol moving forward.
  Conclusion: Our results suggest that virtual fixtures can help localize tumor
boundaries in simulated breast-conserving surgery. Future work will include an
extensive user study to further validate these results and fine-tune our
guidance system.

</details>


### [11] [VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs](https://arxiv.org/abs/2510.01483)
*Mohamad Al Mdfaa,Svetlana Lukina,Timur Akhtyamov,Arthur Nigmatzyanov,Dmitrii Nalberskii,Sergey Zagoruyko,Gonzalo Ferrer*

Main category: cs.RO

TL;DR: VL-KnG是一个视觉场景理解系统，通过构建时空知识图谱来解决视觉语言模型在机器人导航中的局限性，包括缺乏持久场景记忆、有限空间推理能力和实时应用扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在机器人导航中存在三个基本限制：缺乏持久场景记忆、空间推理能力有限、无法有效扩展到实时视频应用。需要一种能够持续跟踪物体身份、支持可解释空间推理且计算高效的方法。

Method: 采用分块处理视频序列的方法，利用现代视觉语言模型构建持久知识图谱，保持物体身份随时间的一致性，并通过可查询的图结构实现可解释的空间推理。

Result: 在真实世界差分驱动机器人上的部署显示，该方法达到77.27%的成功率和76.92%的答案准确率，与Gemini 2.5 Pro性能相当，同时提供基于知识图谱的可解释推理，并在定位、导航和规划等不同任务中实现计算高效的实时部署。

Conclusion: VL-KnG通过时空知识图谱构建有效解决了视觉语言模型在机器人导航中的关键限制，实现了可解释推理、计算高效性和实时部署能力，为机器人导航提供了新的解决方案。

Abstract: Vision-language models (VLMs) have shown potential for robot navigation but
encounter fundamental limitations: they lack persistent scene memory, offer
limited spatial reasoning, and do not scale effectively with video duration for
real-time application. We present VL-KnG, a Visual Scene Understanding system
that tackles these challenges using spatiotemporal knowledge graph construction
and computationally efficient query processing for navigation goal
identification. Our approach processes video sequences in chunks utilizing
modern VLMs, creates persistent knowledge graphs that maintain object identity
over time, and enables explainable spatial reasoning through queryable graph
structures. We also introduce WalkieKnowledge, a new benchmark with about 200
manually annotated questions across 8 diverse trajectories spanning
approximately 100 minutes of video data, enabling fair comparison between
structured approaches and general-purpose VLMs. Real-world deployment on a
differential drive robot demonstrates practical applicability, with our method
achieving 77.27% success rate and 76.92% answer accuracy, matching Gemini 2.5
Pro performance while providing explainable reasoning supported by the
knowledge graph, computational efficiency for real-time deployment across
different tasks, such as localization, navigation and planning. Code and
dataset will be released after acceptance.

</details>


### [12] [Pose Estimation of a Thruster-Driven Bioinspired Multi-Link Robot](https://arxiv.org/abs/2510.01485)
*Nicholas B. Andrews,Yanhao Yang,Sofya Akhetova,Kristi A. Morgansen,Ross L. Hatton*

Main category: cs.RO

TL;DR: 该研究展示了如何通过无迹卡尔曼滤波结合高斯过程残差学习，对具有非驱动关节、单陀螺仪感知的自由浮动仿生多连杆机器人进行位姿估计，证明了在多步态数据集上训练的滤波器与仅在前进步态数据集上训练的滤波器性能相当。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决自由浮动仿生多连杆机器人的位姿估计问题，该平台具有非驱动关节、最小化感知能力（每连杆仅一个陀螺仪）和欠驱动特性，需要开发可靠的位姿估计算法。

Method: 采用无迹卡尔曼滤波结合高斯过程残差学习来补偿非零均值、非高斯噪声，通过概念验证硬件实验和离线卡尔曼滤波分析进行验证。

Result: 实验表明机器人的位姿可以可靠估计，在多步态数据集上训练的滤波器与在更大前进步态数据集上训练的滤波器在相同测试轨迹上性能相当。

Conclusion: 研究揭示了步态输入空间的重叠性，可以利用这一特性减少训练数据需求，同时提高滤波器在多种步态间的泛化能力。

Abstract: This work demonstrates pose (position and shape) estimation for a
free-floating, bioinspired multi-link robot with unactuated joints,
link-mounted thrusters for control, and a single gyroscope per link, resulting
in an underactuated, minimally sensed platform. Through a proof-of-concept
hardware experiment and offline Kalman filter analysis, we show that the
robot's pose can be reliably estimated. State estimation is performed using an
unscented Kalman filter augmented with Gaussian process residual learning to
compensate for non-zero-mean, non-Gaussian noise. We further show that a filter
trained on a multi-gait dataset (forward, backward, left, right, and turning)
performs comparably to one trained on a larger forward-gait-only dataset when
both are evaluated on the same forward-gait test trajectory. These results
reveal overlap in the gait input space, which can be exploited to reduce
training data requirements while enhancing the filter's generalizability across
multiple gaits.

</details>


### [13] [Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments](https://arxiv.org/abs/2510.01519)
*Wei Han Chen,Yuchen Liu,Alexiy Buynitsky,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出分层规划方法解决机器人导航问题，高层用稀疏图捕捉全局连通性，低层用基于神经场的规划器解决Eikonal PDE，克服谱偏差和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：传统采样方法难以控制分辨率和扩展性，模仿学习方法需要大量演示数据，ANTFields方法受谱偏差和灾难性遗忘影响。

Method: 分层规划结构：高层使用稀疏图表示全局环境连通性，低层使用神经场规划器通过求解Eikonal PDE来导航局部障碍物。

Result: 在大规模环境中验证了框架的有效性，相比先前方法展现出更好的适应性和精度。

Conclusion: 该方法在复杂室内环境中具有在线探索、建图和实际导航的潜力，解决了现有方法的局限性。

Abstract: Robot navigation in large, complex, and unknown indoor environments is a
challenging problem. The existing approaches, such as traditional
sampling-based methods, struggle with resolution control and scalability, while
imitation learning-based methods require a large amount of demonstration data.
Active Neural Time Fields (ANTFields) have recently emerged as a promising
solution by using local observations to learn cost-to-go functions without
relying on demonstrations. Despite their potential, these methods are hampered
by challenges such as spectral bias and catastrophic forgetting, which diminish
their effectiveness in complex scenarios. To address these issues, our approach
decomposes the planning problem into a hierarchical structure. At the high
level, a sparse graph captures the environment's global connectivity, while at
the low level, a planner based on neural fields navigates local obstacles by
solving the Eikonal PDE. This physics-informed strategy overcomes common
pitfalls like spectral bias and neural field fitting difficulties, resulting in
a smooth and precise representation of the cost landscape. We validate our
framework in large-scale environments, demonstrating its enhanced adaptability
and precision compared to previous methods, and highlighting its potential for
online exploration, mapping, and real-world navigation.

</details>


### [14] [Real-time Multi-Plane Segmentation Based on GPU Accelerated High-Resolution 3D Voxel Mapping for Legged Robot Locomotion](https://arxiv.org/abs/2510.01592)
*Shun Niijima,Ryoichi Tsuzaki,Noriaki Takasugi,Masaya Kinoshita*

Main category: cs.RO

TL;DR: 提出了一种基于GPU加速高分辨率3D体素映射的实时多平面分割方法，用于腿式机器人运动，能够在30Hz更新率下实现快速准确的3D多平面分割。


<details>
  <summary>Details</summary>
Motivation: 现有在线平面映射方法难以平衡精度和计算效率：直接深度图像分割缺乏时间整合，高度图方法无法表示复杂3D结构，体素平面分割尚未用于实时应用。

Method: 开发了一个新颖框架，将基于顶点的连通分量标记与RANSAC平面检测和凸包相结合，利用GPU并行计算从高分辨率3D体素图中快速提取平面区域。

Result: 实验结果表明，即使在0.01米分辨率下，该方法也能以超过30Hz的更新率实现快速准确的3D多平面分割，使检测到的平面能够实时用于运动任务。

Conclusion: 在模拟环境和物理腿式机器人平台上的实验验证了该方法的有效性，确认了在考虑3D平面结构时的鲁棒运动性能。

Abstract: This paper proposes a real-time multi-plane segmentation method based on
GPU-accelerated high-resolution 3D voxel mapping for legged robot locomotion.
Existing online planar mapping approaches struggle to balance accuracy and
computational efficiency: direct depth image segmentation from specific sensors
suffers from poor temporal integration, height map-based methods cannot
represent complex 3D structures like overhangs, and voxel-based plane
segmentation remains unexplored for real-time applications. To address these
limitations, we develop a novel framework that integrates vertex-based
connected component labeling with random sample consensus based plane detection
and convex hull, leveraging GPU parallel computing to rapidly extract planar
regions from point clouds accumulated in high-resolution 3D voxel maps.
Experimental results demonstrate that the proposed method achieves fast and
accurate 3D multi-plane segmentation at over 30 Hz update rate even at a
resolution of 0.01 m, enabling the detected planes to be utilized in real time
for locomotion tasks. Furthermore, we validate the effectiveness of our
approach through experiments in both simulated environments and physical legged
robot platforms, confirming robust locomotion performance when considering 3D
planar structures.

</details>


### [15] [MiniBEE: A New Form Factor for Compact Bimanual Dexterity](https://arxiv.org/abs/2510.01603)
*Sharfin Islam,Zewen Chen,Zhanpeng He,Swapneel Bhatt,Andres Permuy,Brock Taylor,James Vickery,Pedro Piacenza,Cheng Zhang,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 提出MiniBEE系统，将两个低自由度机械臂耦合为紧凑的双手机器人末端执行器，支持穿戴式数据采集和标准机械臂部署，实现全工作空间的双手机器人操作。


<details>
  <summary>Details</summary>
Motivation: 传统双手机器人系统复杂且仅利用部分工作空间进行灵巧操作，需要更紧凑、轻量化的解决方案。

Method: 设计两个低自由度机械臂(3+自由度)耦合的紧凑系统，制定运动学灵巧度指标，支持穿戴式数据采集和标准机械臂部署两种模式。

Result: 开发出轻量化可穿戴系统，能够进行穿戴式演示数据采集，并通过模仿学习实现稳健的实时双手机器人操作。

Conclusion: MiniBEE系统通过紧凑设计扩展了双手机器人的灵巧工作空间，为穿戴式数据采集和机器人操作提供了有效解决方案。

Abstract: Bimanual robot manipulators can achieve impressive dexterity, but typically
rely on two full six- or seven- degree-of-freedom arms so that paired grippers
can coordinate effectively. This traditional framework increases system
complexity while only exploiting a fraction of the overall workspace for
dexterous interaction. We introduce the MiniBEE (Miniature Bimanual
End-effector), a compact system in which two reduced-mobility arms (3+ DOF
each) are coupled into a kinematic chain that preserves full relative
positioning between grippers. To guide our design, we formulate a kinematic
dexterity metric that enlarges the dexterous workspace while keeping the
mechanism lightweight and wearable. The resulting system supports two
complementary modes: (i) wearable kinesthetic data collection with self-tracked
gripper poses, and (ii) deployment on a standard robot arm, extending dexterity
across its entire workspace. We present kinematic analysis and design
optimization methods for maximizing dexterous range, and demonstrate an
end-to-end pipeline in which wearable demonstrations train imitation learning
policies that perform robust, real-world bimanual manipulation.

</details>


### [16] [ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations](https://arxiv.org/abs/2510.01607)
*Qiyuan Zeng,Chengmeng Li,Jude St. John,Zhongyi Zhou,Junjie Wen,Guorui Feng,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: ActiveUMI是一个便携式VR遥操作系统，通过捕捉操作者的主动自我中心感知来收集双手机器人操作数据，训练出的策略在复杂任务中表现优异且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决在真实世界中收集高质量机器人操作数据的问题，特别是复杂双手操作任务，需要一种便携且能捕捉人类主动感知的数据收集系统。

Method: 结合便携式VR遥操作套件和传感器化控制器，通过精确姿态对齐桥接人机运动学，引入沉浸式3D模型渲染、自包含可穿戴计算机和高效标定方法，并记录操作者的主动头部运动来学习视觉注意力与操作之间的联系。

Result: 在六个挑战性双手任务上评估，仅使用ActiveUMI数据训练的策略在分布内任务上平均成功率达到70%，在新物体和新环境中仍保持56%的成功率，表现出强泛化能力。

Conclusion: 便携式数据收集系统与学习的主动感知相结合，为创建可泛化且高能力的真实世界机器人策略提供了有效且可扩展的途径。

Abstract: We present ActiveUMI, a framework for a data collection system that transfers
in-the-wild human demonstrations to robots capable of complex bimanual
manipulation. ActiveUMI couples a portable VR teleoperation kit with sensorized
controllers that mirror the robot's end-effectors, bridging human-robot
kinematics via precise pose alignment. To ensure mobility and data quality, we
introduce several key techniques, including immersive 3D model rendering, a
self-contained wearable computer, and efficient calibration methods.
ActiveUMI's defining feature is its capture of active, egocentric perception.
By recording an operator's deliberate head movements via a head-mounted
display, our system learns the crucial link between visual attention and
manipulation. We evaluate ActiveUMI on six challenging bimanual tasks. Policies
trained exclusively on ActiveUMI data achieve an average success rate of 70\%
on in-distribution tasks and demonstrate strong generalization, retaining a
56\% success rate when tested on novel objects and in new environments. Our
results demonstrate that portable data collection systems, when coupled with
learned active perception, provide an effective and scalable pathway toward
creating generalizable and highly capable real-world robot policies.

</details>


### [17] [FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models](https://arxiv.org/abs/2510.01642)
*Zijun Lin,Jiafei Duan,Haoquan Fang,Dieter Fox,Ranjay Krishna,Cheston Tan,Bihan Wen*

Main category: cs.RO

TL;DR: FailSafe是一个用于机器人操作失败生成和恢复的系统，能够自动产生多样化的失败案例和可执行的恢复动作，通过微调LLaVa-OneVision-7B构建FailSafe-VLM，显著提升了VLA模型的失败检测和恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据集主要提供地面实况轨迹，无法帮助机器人从失败中恢复；少数处理失败检测的数据集通常只提供文本解释，难以直接在VLA模型中使用。

Method: 提出FailSafe系统，可在任何模拟器中无缝应用于任何操作任务，实现失败-动作数据的可扩展创建，并基于LLaVa-OneVision-7B构建FailSafe-VLM。

Result: FailSafe-VLM成功帮助机械臂检测和恢复潜在失败，在Maniskill多个任务中平均提升三个最先进VLA模型（pi0-FAST、OpenVLA、OpenVLA-OFT）性能达22.6%，并能泛化到不同空间配置、相机视角和机器人形态。

Conclusion: FailSafe系统有效解决了机器人操作中的失败恢复问题，显著提升了VLA模型的鲁棒性和泛化能力。

Abstract: Recent advances in robotic manipulation have integrated low-level robotic
control into Vision-Language Models (VLMs), extending them into
Vision-Language-Action (VLA) models. Although state-of-the-art VLAs achieve
strong performance in downstream robotic applications, supported by large-scale
crowd-sourced robot training data, they still inevitably encounter failures
during execution. Enabling robots to reason about and recover from
unpredictable and abrupt failures remains a critical challenge. Existing
robotic manipulation datasets, collected in either simulation or the real
world, primarily provide only ground-truth trajectories, leaving robots unable
to recover once failures occur. Moreover, the few datasets that address failure
detection typically offer only textual explanations, which are difficult to
utilize directly in VLA models. To address this gap, we introduce FailSafe, a
novel failure generation and recovery system that automatically produces
diverse failure cases paired with executable recovery actions. FailSafe can be
seamlessly applied to any manipulation task in any simulator, enabling scalable
creation of failure-action data. To demonstrate its effectiveness, we fine-tune
LLaVa-OneVision-7B (LLaVa-OV-7B) to build FailSafe-VLM. Experimental results
show that FailSafe-VLM successfully helps robotic arm detect and recover from
potential failures, improving the performance of three state-of-the-art VLA
models pi0-FAST, OpenVLA, OpenVLA-OFT) by up to 22.6% on average across several
tasks in Maniskill. Furthermore, FailSafe-VLM could generalize across different
spatial configurations, camera viewpoints, and robotic embodiments. We plan to
release the FailSafe code to the community.

</details>


### [18] [Statistical Uncertainty Learning for Robust Visual-Inertial State Estimation](https://arxiv.org/abs/2510.01648)
*Seungwon Choi,Donggyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: 提出了一种在线学习测量可靠性的统计框架，通过多视图几何一致性作为自监督，动态评估视觉惯性里程计中传感器测量的可靠性，相比固定不确定性参数的方法显著提升了跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设所有测量具有静态、均匀的不确定性，无法捕捉真实世界数据中的动态误差特性，限制了鲁棒视觉惯性里程计的性能。

Method: 利用多视图几何一致性作为自监督，从传感器数据和优化结果中在线学习测量可靠性评估，自适应地加权视觉测量。

Result: 在EuRoC数据集上评估，相比固定不确定性参数的基准方法，平均平移误差减少约24%，旋转误差减少约42%。

Conclusion: 该框架在实时运行的同时提高了精度和鲁棒性，源代码将公开以促进可复现性和进一步研究。

Abstract: A fundamental challenge in robust visual-inertial odometry (VIO) is to
dynamically assess the reliability of sensor measurements. This assessment is
crucial for properly weighting the contribution of each measurement to the
state estimate. Conventional methods often simplify this by assuming a static,
uniform uncertainty for all measurements. This heuristic, however, may be
limited in its ability to capture the dynamic error characteristics inherent in
real-world data. To improve this limitation, we present a statistical framework
that learns measurement reliability assessment online, directly from sensor
data and optimization results. Our approach leverages multi-view geometric
consistency as a form of self-supervision. This enables the system to infer
landmark uncertainty and adaptively weight visual measurements during
optimization. We evaluated our method on the public EuRoC dataset,
demonstrating improvements in tracking accuracy with average reductions of
approximately 24\% in translation error and 42\% in rotation error compared to
baseline methods with fixed uncertainty parameters. The resulting framework
operates in real time while showing enhanced accuracy and robustness. To
facilitate reproducibility and encourage further research, the source code will
be made publicly available.

</details>


### [19] [Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation](https://arxiv.org/abs/2510.01661)
*Yifei Simon Shao,Yuchen Zheng,Sunan Sun,Pratik Chaudhari,Vijay Kumar,Nadia Figueroa*

Main category: cs.RO

TL;DR: SymSkill是一个结合模仿学习和任务运动规划优势的统一学习框架，能够在动态环境中实现组合泛化和实时故障恢复。


<details>
  <summary>Details</summary>
Motivation: 解决多步操作在动态环境中的挑战：模仿学习缺乏组合泛化能力，而传统任务运动规划存在规划延迟问题，无法实时恢复故障。

Method: 从无标签、无分割的演示数据中联合学习谓词、操作符和技能；执行时使用符号规划器组合和重排序学习到的技能来实现符号目标，同时在运动和符号层面进行实时恢复。

Result: 在RoboCasa模拟中，SymSkill执行12个单步任务成功率85%，无需额外数据即可组合成最多需要6次技能重组的复杂多步计划；在真实Franka机器人上，仅用5分钟无标签演示数据就能通过目标规范执行多个任务。

Conclusion: SymSkill框架成功结合了模仿学习的反应性和任务运动规划的组合性，实现了在动态环境中的安全、不间断执行，并能从执行故障中稳健恢复。

Abstract: Multi-step manipulation in dynamic environments remains challenging. Two
major families of methods fail in distinct ways: (i) imitation learning (IL) is
reactive but lacks compositional generalization, as monolithic policies do not
decide which skill to reuse when scenes change; (ii) classical task-and-motion
planning (TAMP) offers compositionality but has prohibitive planning latency,
preventing real-time failure recovery. We introduce SymSkill, a unified
learning framework that combines the benefits of IL and TAMP, allowing
compositional generalization and failure recovery in real-time. Offline,
SymSkill jointly learns predicates, operators, and skills directly from
unlabeled and unsegmented demonstrations. At execution time, upon specifying a
conjunction of one or more learned predicates, SymSkill uses a symbolic planner
to compose and reorder learned skills to achieve the symbolic goals, while
performing recovery at both the motion and symbolic levels in real time.
Coupled with a compliant controller, SymSkill enables safe and uninterrupted
execution under human and environmental disturbances. In RoboCasa simulation,
SymSkill can execute 12 single-step tasks with 85% success rate. Without
additional data, it composes these skills into multi-step plans requiring up to
6 skill recompositions, recovering robustly from execution failures. On a real
Franka robot, we demonstrate SymSkill, learning from 5 minutes of unsegmented
and unlabeled play data, is capable of performing multiple tasks simply by goal
specifications. The source code and additional analysis can be found on
https://sites.google.com/view/symskill.

</details>


### [20] [Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances](https://arxiv.org/abs/2510.01675)
*Jaewoo Lee,Dongjae Lee,Jinwoo Lee,Hyungyu Lee,Yeonjoon Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种几何反步控制器，用于可变倾斜全向多旋翼飞行器，明确考虑了伺服和转子动力学，在快速机动和扰动恢复中表现优于不考虑执行器动态的基准方法。


<details>
  <summary>Details</summary>
Motivation: 现有执行器感知控制方法依赖于执行器输入与力矩之间的线性关系，无法捕捉可变倾斜角引起的非线性效应，这限制了在激进飞行或扰动恢复中的性能。

Method: 利用多旋翼刚体动力学与非线性执行器动力学之间的级联结构，设计几何反步控制器，并建立了整个系统的指数稳定性。

Result: 在快速平移跟踪、快速旋转跟踪和突然扰动恢复三个实验场景中，所提方法始终获得更好的跟踪性能，在基准方法发散和坠毁的情况下仍能保持稳定完成任务。

Conclusion: 该控制器能够有效处理执行器非线性动态，对模型参数不确定性具有鲁棒性，显著提升了可变倾斜全向多旋翼在激进飞行和扰动恢复中的性能。

Abstract: This work presents a geometric backstepping controller for a variable-tilt
omnidirectional multirotor that explicitly accounts for both servo and rotor
dynamics. Considering actuator dynamics is essential for more effective and
reliable operation, particularly during aggressive flight maneuvers or recovery
from sudden disturbances. While prior studies have investigated actuator-aware
control for conventional and fixed-tilt multirotors, these approaches rely on
linear relationships between actuator input and wrench, which cannot capture
the nonlinearities induced by variable tilt angles. In this work, we exploit
the cascade structure between the rigid-body dynamics of the multirotor and its
nonlinear actuator dynamics to design the proposed backstepping controller and
establish exponential stability of the overall system. Furthermore, we reveal
parametric uncertainty in the actuator model through experiments, and we
demonstrate that the proposed controller remains robust against such
uncertainty. The controller was compared against a baseline that does not
account for actuator dynamics across three experimental scenarios: fast
translational tracking, rapid rotational tracking, and recovery from sudden
disturbance. The proposed method consistently achieved better tracking
performance, and notably, while the baseline diverged and crashed during the
fastest translational trajectory tracking and the recovery experiment, the
proposed controller maintained stability and successfully completed the tasks,
thereby demonstrating its effectiveness.

</details>


### [21] [PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization](https://arxiv.org/abs/2510.01708)
*Zixing Lei,Zibo Zhou,Sheng Yin,Yueru Chen,Qingyao Xu,Weixin Li,Yunhong Wang,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: PolySim是一个多仿真器集成平台，通过同时在多个异构仿真器中训练人形机器人全身控制策略，减少仿真器归纳偏差，实现零样本从仿真到真实世界的部署。


<details>
  <summary>Details</summary>
Motivation: 解决仿真到真实世界的差距问题，这种差距源于单个仿真器的归纳偏差（假设和限制），导致跨仿真器和仿真-真实世界之间存在显著差异。

Method: 开发PolySim平台，在单个训练运行中同时启动来自不同仿真引擎的并行环境，实现动态层面的域随机化，联合训练策略以捕捉超越任何单个仿真器假设的通用动力学。

Result: 在仿真间评估中显著减少运动跟踪误差，在MuJoCo上比IsaacSim基线提高执行成功率52.8%；能够零样本部署到真实Unitree G1机器人上，无需额外微调。

Conclusion: PolySim通过多仿真器联合训练有效缓解了仿真器归纳偏差问题，实现了从仿真到真实世界的有效迁移，为人形机器人控制提供了更鲁棒的训练框架。

Abstract: Humanoid whole-body control (WBC) policies trained in simulation often suffer
from the sim-to-real gap, which fundamentally arises from simulator inductive
bias, the inherent assumptions and limitations of any single simulator. These
biases lead to nontrivial discrepancies both across simulators and between
simulation and the real world. To mitigate the effect of simulator inductive
bias, the key idea is to train policies jointly across multiple simulators,
encouraging the learned controller to capture dynamics that generalize beyond
any single simulator's assumptions. We thus introduce PolySim, a WBC training
platform that integrates multiple heterogeneous simulators. PolySim can launch
parallel environments from different engines simultaneously within a single
training run, thereby realizing dynamics-level domain randomization.
Theoretically, we show that PolySim yields a tighter upper bound on simulator
inductive bias than single-simulator training. In experiments, PolySim
substantially reduces motion-tracking error in sim-to-sim evaluations; for
example, on MuJoCo, it improves execution success by 52.8 over an IsaacSim
baseline. PolySim further enables zero-shot deployment on a real Unitree G1
without additional fine-tuning, showing effective transfer from simulation to
the real world. We will release the PolySim code upon acceptance of this work.

</details>


### [22] [Contrastive Representation Regularization for Vision-Language-Action Models](https://arxiv.org/abs/2510.01711)
*Taeyoung Kim,Jimin Lee,Myungkyu Koo,Dongyoung Kim,Kyungmin Lee,Changyeon Kim,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: 提出Robot State-aware Contrastive Loss (RS-CL)，一种简单有效的表示正则化方法，用于改善视觉-语言-动作模型在机器人操作中的表示质量，使其对机器人状态信号更敏感。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型虽然利用预训练视觉-语言模型的丰富表示，但这些表示对机器人信号（如控制动作和本体感觉状态）不够敏感，导致在机器人操作任务中表现欠佳。

Method: 引入RS-CL损失函数，使用机器人本体感觉状态之间的相对距离作为软监督，将表示与机器人状态更紧密地对齐，同时保持与标准VLA训练流程的兼容性。

Result: RS-CL显著提升了最先进VLA模型的性能：在RoboCasa-Kitchen的拾取放置任务中从30.8%提升到41.5%，在真实机器人操作任务中从45.0%提升到58.3%。

Conclusion: RS-CL是一种轻量级且有效的表示正则化方法，能够显著改善VLA模型在机器人操作任务中的表现，特别是在抓取和放置时的精确定位方面。

Abstract: Vision-Language-Action (VLA) models have shown its capabilities in robot
manipulation by leveraging rich representations from pre-trained
Vision-Language Models (VLMs). However, their representations arguably remain
suboptimal, lacking sensitivity to robotic signals such as control actions and
proprioceptive states. To address the issue, we introduce Robot State-aware
Contrastive Loss (RS-CL), a simple and effective representation regularization
for VLA models, designed to bridge the gap between VLM representations and
robotic signals. In particular, RS-CL aligns the representations more closely
with the robot's proprioceptive states, by using relative distances between the
states as soft supervision. Complementing the original action prediction
objective, RS-CL effectively enhances control-relevant representation learning,
while being lightweight and fully compatible with standard VLA training
pipeline. Our empirical results demonstrate that RS-CL substantially improves
the manipulation performance of state-of-the-art VLA models; it pushes the
prior art from 30.8% to 41.5% on pick-and-place tasks in RoboCasa-Kitchen,
through more accurate positioning during grasping and placing, and boosts
success rates from 45.0% to 58.3% on challenging real-robot manipulation tasks.

</details>


### [23] [Dual-Mode Magnetic Continuum Robot for Targeted Drug Delivery](https://arxiv.org/abs/2510.01761)
*Wendu Zhang,Heng Wang,Shuangyi Wang,Yuanrui Huang*

Main category: cs.RO

TL;DR: 提出了一种新型磁性连续体机器人设计，通过在导管壁内径向嵌入永磁体，实现单个外部永磁体独立控制弯曲或扭转运动，并开发了基于扭转剪切的双层阻塞机制用于按需药物释放。


<details>
  <summary>Details</summary>
Motivation: 传统轴向磁化设计的磁性连续体机器人主要限于弯曲运动，限制了变形能力。为了扩展变形能力，需要开发能够独立控制弯曲和扭转的新型设计。

Method: 采用径向嵌入永磁体的简单组装结构，结合基于物理的建模和有限元分析建立驱动原理，开发了利用扭转剪切实现按需药物释放的双层阻塞机制（外槽和内板）。

Result: 实验验证了在实际磁场下的解耦模式控制，并在体模干预实验中展示了从腔道跟随、弯曲接近目标到扭转激活释放的端到端操作。

Conclusion: 这种紧凑、无缆的平台结合了多功能变形与精确有效载荷输送，显示出在下一代定点治疗中的强大潜力。

Abstract: Magnetic continuum robots (MCRs) enable minimally invasive navigation through
tortuous anatomical channels, yet axially magnetized designs have largely been
limited to bending-only motion. To expand deformation capabilities, this paper
presents a simple assembly that embeds permanent magnets radially within the
catheter wall, allowing a single externally steered permanent magnet to
independently induce either bending or torsion. A physics-based formulation
together with finite-element analysis establishes the actuation principles, and
benchtop experiments validate decoupled mode control under practical fields.
Building on this, a dual-layer blockage mechanism consisting of outer grooves
and inner plates leverages torsional shear to achieve on-demand drug release.
Finally, an in-phantom intervention experiment demonstrates end-to-end
operation: lumen following by bending for target approach, followed by
twist-activated release at the site. The resulting compact, cable-free platform
combines versatile deformation with precise payload delivery, indicating strong
potential for next-generation, site-specific therapies.

</details>


### [24] [An Anytime, Scalable and Complete Algorithm for Embedding a Manufacturing Procedure in a Smart Factory](https://arxiv.org/abs/2510.01770)
*Christopher Leet,Aidan Sciortino,Sven Koenig*

Main category: cs.RO

TL;DR: TS-ACES是首个高度可扩展的智能工厂嵌入(SFE)问题解决方案，能够处理包含数百台机器的真实工业场景。


<details>
  <summary>Details</summary>
Motivation: 现代智能工厂可能包含数百台机器，但现有SFE求解器只能扩展到几十台机器，存在可扩展性差距。

Method: TS-ACES是基于交通系统的随时循环嵌入求解器，利用可编程运输系统来优化制造过程的嵌入。

Result: TS-ACES被证明是完备的，并且能够扩展到基于真实工业场景、包含超过一百台机器的SFE实例。

Conclusion: TS-ACES填补了智能工厂嵌入问题在大规模场景下的求解空白，为现代自动化工厂提供了实用的解决方案。

Abstract: Modern automated factories increasingly run manufacturing procedures using a
matrix of programmable machines, such as 3D printers, interconnected by a
programmable transport system, such as a fleet of tabletop robots. To embed a
manufacturing procedure into a smart factory, an operator must: (a) assign each
of its processes to a machine and (b) specify how agents should transport parts
between machines. The problem of embedding a manufacturing process into a smart
factory is termed the Smart Factory Embedding (SFE) problem. State-of-the-art
SFE solvers can only scale to factories containing a couple dozen machines.
Modern smart factories, however, may contain hundreds of machines. We fill this
hole by introducing the first highly scalable solution to the SFE, TS-ACES, the
Traffic System based Anytime Cyclic Embedding Solver. We show that TS-ACES is
complete and can scale to SFE instances based on real industrial scenarios with
more than a hundred machines.

</details>


### [25] [Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2510.01795)
*Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Nan Guan,Chun Jason Xue*

Main category: cs.RO

TL;DR: 提出Nav-EE框架，通过导航先验指导视觉语言模型在自动驾驶中的早期退出，在保持精度的同时显著降低推理延迟


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在自动驾驶中应用广泛，但高推理延迟阻碍实时部署。传统早期退出方法受限于任务依赖性，难以适应多样化场景

Method: 基于导航系统预知上下文（如路口、交通灯），离线预计算任务特定的退出层，在线根据导航先验动态应用早期退出

Result: 在CODA、Waymo和BOSCH数据集上，Nav-EE在保持与完整推理相当精度的同时，延迟降低高达63.9%。实车集成显示推理延迟从600ms降至300ms

Conclusion: 将导航预见性与早期退出相结合，为在自动驾驶系统中高效部署大模型提供了可行路径

Abstract: Vision-Language Models (VLMs) are increasingly applied in autonomous driving
for unified perception and reasoning, but high inference latency hinders
real-time deployment. Early-exit reduces latency by terminating inference at
intermediate layers, yet its task-dependent nature limits generalization across
diverse scenarios. We observe that this limitation aligns with autonomous
driving: navigation systems can anticipate upcoming contexts (e.g.,
intersections, traffic lights), indicating which tasks will be required. We
propose Nav-EE, a navigation-guided early-exit framework that precomputes
task-specific exit layers offline and dynamically applies them online based on
navigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EE
achieves accuracy comparable to full inference while reducing latency by up to
63.9%. Real-vehicle integration with Autoware Universe further demonstrates
reduced inference latency (600ms to 300ms), supporting faster decision-making
in complex scenarios. These results suggest that coupling navigation foresight
with early-exit offers a viable path toward efficient deployment of large
models in autonomous systems. Code and data are available at our anonymous
repository: https://anonymous.4open.science/r/Nav-EE-BBC4

</details>


### [26] [What Matters in RL-Based Methods for Object-Goal Navigation? An Empirical Study and A Unified Framework](https://arxiv.org/abs/2510.01830)
*Hongze Wang,Boyang Sun,Jiaxu Xing,Fan Yang,Marco Hutter,Dhruv Shah,Davide Scaramuzza,Marc Pollefeys*

Main category: cs.RO

TL;DR: 本文对基于强化学习的物体目标导航系统进行了大规模实证研究，发现感知质量和测试时策略是性能的关键驱动因素，而策略改进带来的增益有限。基于这些见解，作者提出了增强的模块化系统，在SPL指标上超越现有最佳方法6.6%。


<details>
  <summary>Details</summary>
Motivation: 物体目标导航是移动机器人在日常环境中部署的关键能力，但当前缺乏对强化学习方法中各个组件贡献的系统性分析，无法确定真正驱动性能的因素。

Method: 将模块化RL系统分解为感知、策略和测试时增强三个关键组件，通过大量受控实验隔离每个组件的贡献，并基于分析结果构建增强的模块化系统。

Result: 感知质量和测试时策略是性能的决定性驱动因素，策略改进仅带来边际增益。提出的增强系统在SPL指标上超越SotA方法6.6%，成功率提升2.7%。人类专家在相同条件下达到98%成功率。

Conclusion: 研究不仅设定了新的SotA性能标准，还为未来ObjectNav开发和评估提供了原则性指导，揭示了RL智能体与人类水平导航之间的差距。

Abstract: Object-Goal Navigation (ObjectNav) is a critical component toward deploying
mobile robots in everyday, uncontrolled environments such as homes, schools,
and workplaces. In this context, a robot must locate target objects in
previously unseen environments using only its onboard perception. Success
requires the integration of semantic understanding, spatial reasoning, and
long-horizon planning, which is a combination that remains extremely
challenging. While reinforcement learning (RL) has become the dominant
paradigm, progress has spanned a wide range of design choices, yet the field
still lacks a unifying analysis to determine which components truly drive
performance. In this work, we conduct a large-scale empirical study of modular
RL-based ObjectNav systems, decomposing them into three key components:
perception, policy, and test-time enhancement. Through extensive controlled
experiments, we isolate the contribution of each and uncover clear trends:
perception quality and test-time strategies are decisive drivers of
performance, whereas policy improvements with current methods yield only
marginal gains. Building on these insights, we propose practical design
guidelines and demonstrate an enhanced modular system that surpasses
State-of-the-Art (SotA) methods by 6.6% on SPL and by a 2.7% success rate. We
also introduce a human baseline under identical conditions, where experts
achieve an average 98% success, underscoring the gap between RL agents and
human-level navigation. Our study not only sets the SotA performance but also
provides principled guidance for future ObjectNav development and evaluation.

</details>


### [27] [Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots](https://arxiv.org/abs/2510.01843)
*Wanyue Li,Ji Ma,Minghao Lu,Peng Lu*

Main category: cs.RO

TL;DR: 该研究将无人机中成功的时空轨迹规划方法创新性地应用于双足机器人系统，自主生成满足目标踢球位置、速度和加速度约束的足部轨迹，同时优化摆动阶段持续时间，实现了高效可靠的机器人踢球控制。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人足球中在激烈踢球动作时保持系统稳定性并实现精确球轨迹控制的挑战。现有方法（位置控制或强化学习）存在显著局限性，MPC方法在足式机器人中虽流行但通常过度简化腿部摆动过程，限制了足部环境交互能力。

Method: 创新性地将无人机应用中成功的时空轨迹规划方法适配到双足机器人系统，自主生成满足目标踢球位置、速度和加速度约束的足部轨迹，同时优化摆动阶段持续时间。

Result: 优化的轨迹紧密模仿人类踢球行为，具有后摆动作特征。轨迹规划时间低于1毫秒，在足球门位于-90度到90度范围内时，任务完成准确率接近100%。

Conclusion: 所提出的时空轨迹规划方法在人形机器人踢球任务中表现出高效性和可靠性，能够生成类似人类踢球行为的轨迹，为机器人足球运动提供了有效的解决方案。

Abstract: Humanoid robot soccer presents several challenges, particularly in
maintaining system stability during aggressive kicking motions while achieving
precise ball trajectory control. Current solutions, whether traditional
position-based control methods or reinforcement learning (RL) approaches,
exhibit significant limitations. Model predictive control (MPC) is a prevalent
approach for ordinary quadruped and biped robots. While MPC has demonstrated
advantages in legged robots, existing studies often oversimplify the leg swing
progress, relying merely on simple trajectory interpolation methods. This
severely constrains the foot's environmental interaction capability, hindering
tasks such as ball kicking. This study innovatively adapts the spatial-temporal
trajectory planning method, which has been successful in drone applications, to
bipedal robotic systems. The proposed approach autonomously generates foot
trajectories that satisfy constraints on target kicking position, velocity, and
acceleration while simultaneously optimizing swing phase duration. Experimental
results demonstrate that the optimized trajectories closely mimic human kicking
behavior, featuring a backswing motion. Simulation and hardware experiments
confirm the algorithm's efficiency, with trajectory planning times under 1 ms,
and its reliability, achieving nearly 100 % task completion accuracy when the
soccer goal is within the range of -90{\deg} to 90{\deg}.

</details>


### [28] [GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics](https://arxiv.org/abs/2510.01848)
*Diram Tabaa,Gianni Di Caro*

Main category: cs.RO

TL;DR: GreenhouseSplat是一个从RGB图像生成逼真温室资产的框架和数据集，支持ROS仿真，用于农业机器人评估。


<details>
  <summary>Details</summary>
Motivation: 现有温室仿真方法依赖简单或合成资产，限制了仿真到现实的迁移。辐射场方法虽能实现逼真重建，但仅限于单个植物或实验室环境。

Method: 使用高斯泼溅辐射场方法，从廉价RGB图像直接生成逼真温室资产，集成到支持相机和LiDAR渲染的ROS仿真中。

Result: 提供了包含82株黄瓜植物的数据集，涵盖多种行配置，展示了在机器人评估中的实用性。

Conclusion: 这是迈向温室尺度辐射场仿真的第一步，为农业机器人研究提供了基础。

Abstract: Simulating greenhouse environments is critical for developing and evaluating
robotic systems for agriculture, yet existing approaches rely on simplistic or
synthetic assets that limit simulation-to-real transfer. Recent advances in
radiance field methods, such as Gaussian splatting, enable photorealistic
reconstruction but have so far been restricted to individual plants or
controlled laboratory conditions. In this work, we introduce GreenhouseSplat, a
framework and dataset for generating photorealistic greenhouse assets directly
from inexpensive RGB images. The resulting assets are integrated into a
ROS-based simulation with support for camera and LiDAR rendering, enabling
tasks such as localization with fiducial markers. We provide a dataset of 82
cucumber plants across multiple row configurations and demonstrate its utility
for robotics evaluation. GreenhouseSplat represents the first step toward
greenhouse-scale radiance-field simulation and offers a foundation for future
research in agricultural robotics.

</details>


### [29] [TACOS: Task Agnostic COordinator of a multi-drone System](https://arxiv.org/abs/2510.01869)
*Alessandro Nazzari,Roberto Rubinacci,Marco Lovera*

Main category: cs.RO

TL;DR: TACOS是一个基于大型语言模型的多无人机系统统一框架，通过自然语言接口实现高层任务控制，集成了一对多交互界面、智能协调器和自主执行代理。


<details>
  <summary>Details</summary>
Motivation: 解决单飞行员管理多无人机系统时面临的自主性需求变化问题，从直接控制到群体协调再到完全自主的群体行为，需要支持多种共享自主模式的灵活交互框架。

Method: TACOS框架集成三个关键能力：一对多自然语言交互界面、将用户意图转化为结构化任务计划的智能协调器、与现实世界交互执行计划的自主代理，通过LLM与可执行API库交互。

Result: 在真实多无人机系统中进行了演示，并通过消融研究评估了各模块的贡献。

Conclusion: TACOS通过语言模型实现了语义推理与实时多机器人协调的桥梁，为多无人机系统提供了直观的高层任务委托能力。

Abstract: When a single pilot is responsible for managing a multi-drone system, the
task demands varying levels of autonomy, from direct control of individual
UAVs, to group-level coordination, to fully autonomous swarm behaviors for
accomplishing high-level tasks. Enabling such flexible interaction requires a
framework that supports multiple modes of shared autonomy. As language models
continue to improve in reasoning and planning, they provide a natural
foundation for such systems, reducing pilot workload by enabling high-level
task delegation through intuitive, language-based interfaces. In this paper we
present TACOS (Task-Agnostic COordinator of a multi-drone System), a unified
framework that enables high-level natural language control of multi-UAV systems
through Large Language Models (LLMs). TACOS integrates three key capabilities
into a single architecture: a one-to-many natural language interface for
intuitive user interaction, an intelligent coordinator for translating user
intent into structured task plans, and an autonomous agent that executes plans
interacting with the real-world. TACOS allows a LLM to interact with a library
of executable APIs, bridging semantic reasoning with real-time multi-robot
coordination. We demonstrate the system in real-world multi-drone system and
conduct an ablation study to assess the contribution of each module.

</details>


### [30] [SPARC: Spine with Prismatic and Revolute Compliance for Quadruped Robot](https://arxiv.org/abs/2510.01984)
*Yue Wang*

Main category: cs.RO

TL;DR: SPARC是一个紧凑的开源3自由度脊柱模块，结合了旋转和线性运动，具有可编程任务空间阻抗，用于四足机器人。


<details>
  <summary>Details</summary>
Motivation: 为四足机器人提供系统研究脊柱柔顺性的便携平台，支持腿部运动中的脊柱柔顺性研究。

Method: 集成三个扭矩控制执行器、定制1kHz控制板和受保护电源单元，采用基于RNEA的计算加速度控制器和Stribeck摩擦补偿。

Result: 实验显示线性力-位移特性，水平刚度300-700N/m，相对误差≤1.5%；动态测试确认质量-弹簧-阻尼器响应。

Conclusion: SPARC为腿部运动中的脊柱柔顺性系统研究提供了便携平台，并将发布完整的硬件和固件资源。

Abstract: We present SPARC, a compact, open-source 3-DoF sagittal-plane spine module
that combines revolute (pitch) and prismatic (axial) motion with programmable
task-space impedance for quadruped robots. The system integrates three
torque-controlled actuators, a custom 1 kHz control board, and a protected
power unit in a 1.26 kg package, enabling closed-loop stiffness and damping
shaping along x, z, and theta. We develop an RNEA-based computed-acceleration
controller with smooth Stribeck friction compensation to render spring-damper
behavior without explicit inertia shaping. Bench experiments validate the
approach. Quasi-static push-pull tests show linear force-displacement
characteristics with commanded horizontal stiffness spanning 300-700 N/m and <=
1.5% relative error (R^2 >= 0.992, narrow 95% CIs). Dynamic
displace-and-release trials confirm mass-spring-damper responses over multiple
damping settings, with small, interpretable phase deviations due to
configuration-dependent inertia and low-speed friction effects. A task-space PD
controller produces roughly linear stiffness but with greater variability and
coupling sensitivity. SPARC provides a portable platform for systematic studies
of spine compliance in legged locomotion and will be released with complete
hardware and firmware resources.

</details>


### [31] [Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation](https://arxiv.org/abs/2510.01986)
*Varun Kotian,Vishrut Jain,Andrea Michelle Rios Lazcano,Daan Marinus Pool,Riender Happee,Barys Shyrokau*

Main category: cs.RO

TL;DR: 提出一种基于模型预测控制的运动提示算法，通过惩罚感官冲突和比力误差来同时优化驾驶模拟器的保真度和舒适度，显著降低晕动症


<details>
  <summary>Details</summary>
Motivation: 驾驶模拟器在研发中应用日益广泛，但由于运动缩放和视觉不匹配常导致晕动症，需要开发能同时保证保真度和舒适度的运动提示算法

Method: 使用模型预测控制开发运动提示算法，在成本函数中同时惩罚感官冲突和比力误差，进行人机回路实验比较四种运动设置

Result: 实验结果显示妥协方案将晕动症降低50%以上（平均MISC水平从3降至1.5），且保真度评分无显著下降，与模型预测一致

Conclusion: 提出的方法考虑了模拟器动力学和晕动症时间演化，在实现晕动症控制和比力重现方面取得重要进展，支持模拟器的更广泛应用

Abstract: Driving simulators are increasingly used in research and development.
However, simulators often cause motion sickness due to downscaled motion and
unscaled veridical visuals. In this paper, a motion cueing algorithm is
proposed that reduces motion sickness as predicted by the subjective vertical
conflict (SVC) model using model predictive control (MPC). Both sensory
conflict and specific force errors are penalised in the cost function, allowing
the algorithm to jointly optimise fidelity and comfort.
  Human-in-the-loop experiments were conducted to compare four simulator motion
settings: two variations of our MPC-based algorithm, one focused on pure
specific force tracking and the second compromising specific force tracking and
motion sickness minimisation, as well as reference adaptive washout and no
motion cases. The experiments were performed on a hexapod driving simulator
with participants exposed to passive driving.
  Experimental motion sickness results closely matched the sickness model
predictions. As predicted by the model, the no motion condition yielded the
lowest sickness levels. However, it was rated lowest in terms of fidelity. The
compromise solution reduced sickness by over 50% (average MISC level 3 to 1.5)
compared to adaptive washout and the algorithm focusing on specific force
tracking, without any significant reduction in fidelity rating.
  The proposed approach for developing MCA that takes into account both the
simulator dynamics and time evolution of motion sickness offers a significant
advancement in achieving an optimal control of motion sickness and specific
force recreation in driving simulators, supporting broader simulator use.

</details>


### [32] [EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2510.02080)
*Lingxiang Hu,Naima Ait Oufroukh,Fabien Bonardi,Raymond Ghandour*

Main category: cs.RO

TL;DR: EC3R-SLAM是一个无需相机标定的单目稠密SLAM框架，通过耦合跟踪模块和基于前馈3D重建的映射模块，实现了高精度定位建图、低延迟和低GPU内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的单目稠密SLAM方法存在高延迟、大GPU内存消耗和依赖相机标定的问题，限制了其实际应用。

Method: 结合稀疏特征点地图的跟踪模块和同时估计相机内参的前馈3D重建映射模块，并融入局部和全局闭环检测以确保多视角一致性。

Result: 在多个基准测试中达到与最先进方法相竞争的性能，同时速度更快、内存效率更高，能在笔记本电脑和Jetson Orin NX等资源受限平台上有效运行。

Conclusion: EC3R-SLAM框架具有实际机器人应用的潜力，通过消除相机标定需求并优化计算效率，实现了高性能的稠密SLAM。

Abstract: The application of monocular dense Simultaneous Localization and Mapping
(SLAM) is often hindered by high latency, large GPU memory consumption, and
reliance on camera calibration. To relax this constraint, we propose EC3R-SLAM,
a novel calibration-free monocular dense SLAM framework that jointly achieves
high localization and mapping accuracy, low latency, and low GPU memory
consumption. This enables the framework to achieve efficiency through the
coupling of a tracking module, which maintains a sparse map of feature points,
and a mapping module based on a feed-forward 3D reconstruction model that
simultaneously estimates camera intrinsics. In addition, both local and global
loop closures are incorporated to ensure mid-term and long-term data
association, enforcing multi-view consistency and thereby enhancing the overall
accuracy and robustness of the system. Experiments across multiple benchmarks
show that EC3R-SLAM achieves competitive performance compared to
state-of-the-art methods, while being faster and more memory-efficient.
Moreover, it runs effectively even on resource-constrained platforms such as
laptops and Jetson Orin NX, highlighting its potential for real-world robotics
applications.

</details>


### [33] [LangGrasp: Leveraging Fine-Tuned LLMs for Language Interactive Robot Grasping with Ambiguous Instructions](https://arxiv.org/abs/2510.02104)
*Yunhan Lin,Wenqi Wu,Zhijie Zhang,Huasong Min*

Main category: cs.RO

TL;DR: LangGrasp是一个语言交互式机器人抓取框架，通过微调的大语言模型处理包含隐含意图的模糊指令，实现从粗粒度物体级到细粒度部件级的精确抓取操作。


<details>
  <summary>Details</summary>
Motivation: 现有的语言驱动抓取方法难以完全处理包含隐含意图的模糊指令，需要开发能够理解语言指令中未明确表达但任务完成必需的关键操作和目标信息的方法。

Method: 集成微调的大语言模型利用其常识理解和环境感知能力推断隐含意图，设计基于2D部件分割指导的点云定位模块，实现场景中部分点云定位。

Result: 实验表明LangGrasp框架能准确解析模糊指令中的隐含意图，识别未明确表达但任务必需的关键操作和目标信息，通过整合环境信息动态选择最优抓取姿态。

Conclusion: 该框架实现了从物体级到部件级的高精度抓取，显著提升了机器人在非结构化环境中的适应性和任务执行效率。

Abstract: The existing language-driven grasping methods struggle to fully handle
ambiguous instructions containing implicit intents. To tackle this challenge,
we propose LangGrasp, a novel language-interactive robotic grasping framework.
The framework integrates fine-tuned large language models (LLMs) to leverage
their robust commonsense understanding and environmental perception
capabilities, thereby deducing implicit intents from linguistic instructions
and clarifying task requirements along with target manipulation objects.
Furthermore, our designed point cloud localization module, guided by 2D part
segmentation, enables partial point cloud localization in scenes, thereby
extending grasping operations from coarse-grained object-level to fine-grained
part-level manipulation. Experimental results show that the LangGrasp framework
accurately resolves implicit intents in ambiguous instructions, identifying
critical operations and target information that are unstated yet essential for
task completion. Additionally, it dynamically selects optimal grasping poses by
integrating environmental information. This enables high-precision grasping
from object-level to part-level manipulation, significantly enhancing the
adaptability and task execution efficiency of robots in unstructured
environments. More information and code are available here:
https://github.com/wu467/LangGrasp.

</details>


### [34] [Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control](https://arxiv.org/abs/2510.02129)
*Philip Reichenberg,Tim Laue*

Main category: cs.RO

TL;DR: 本文提出了NAO机器人的站立动作方案，通过解决关节位置执行误差问题，显著提高了站立成功率。该方法已被多个标准平台联盟团队采用。


<details>
  <summary>Details</summary>
Motivation: 人形机器人足球中，站立动作至关重要。无法自主站立的机器人会被暂时移出比赛。需要开发可靠的站立动作方案。

Method: 通过执行特殊动作释放卡住的肢体（如手臂），或使用其他关节补偿大误差，来解决关节位置执行误差问题。该方法自2019年起经过6年评估和改进。

Result: 显著提高了站立动作的整体成功率。分析多个比赛视频显示，采用该方法的其他团队也取得了相似的成功率。

Conclusion: 关节位置执行误差是站立失败的主要原因，通过针对性解决方案可以有效提高站立动作的可靠性。该方法在实践中得到了验证和广泛应用。

Abstract: Stand-up motions are an indispensable part of humanoid robot soccer. A robot
incapable of standing up by itself is removed from the game for some time. In
this paper, we present our stand-up motions for the NAO robot. Our approach
dates back to 2019 and has been evaluated and slightly expanded over the past
six years. We claim that the main reason for failed stand-up attempts are large
errors in the executed joint positions. By addressing such problems by either
executing special motions to free up stuck limbs such as the arms, or by
compensating large errors with other joints, we significantly increased the
overall success rate of our stand-up routine. The motions presented in this
paper are also used by several other teams in the Standard Platform League,
which thereby achieve similar success rates, as shown in an analysis of videos
from multiple tournaments.

</details>


### [35] [SCANS: A Soft Gripper with Curvature and Spectroscopy Sensors for In-Hand Material Differentiation](https://arxiv.org/abs/2510.02164)
*Nathaniel Hanson,Austin Allison,Charles DiMarzio,Taşkın Padır,Kristen L. Dorsey*

Main category: cs.RO

TL;DR: SCANS系统是一种无需电子元件、流体驱动的软体机械手，能够通过预接触包围或手持方式评估物体的光谱特性，具有比以往软体机器人更宽的光谱感知能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种多功能的光学传感软体机器人平台，扩展软体机器人的光谱感知能力，使其能够区分不同材质的物体。

Method: 进行材料分析以寻找适合光谱传感的软基底材料，评估预接触和手持性能，使用线性判别分析确定近红外波长对区分相似物体的重要性。

Result: 实验证明该系统能够对不同类别和尺寸的物体（金属、木材、塑料、有机物、纸张、泡沫）进行可解释的统计分离，物体间光谱角度差异显著。

Conclusion: 这些能力推进了光学作为软体机器人多功能传感模式的潜力，所有部件清单、组装指南和处理代码都已公开。

Abstract: We introduce the soft curvature and spectroscopy (SCANS) system: a versatile,
electronics-free, fluidically actuated soft manipulator capable of assessing
the spectral properties of objects either in hand or through pre-touch caging.
This platform offers a wider spectral sensing capability than previous soft
robotic counterparts. We perform a material analysis to explore optimal soft
substrates for spectral sensing, and evaluate both pre-touch and in-hand
performance. Experiments demonstrate explainable, statistical separation across
diverse object classes and sizes (metal, wood, plastic, organic, paper, foam),
with large spectral angle differences between items. Through linear
discriminant analysis, we show that sensitivity in the near-infrared
wavelengths is critical to distinguishing visually similar objects. These
capabilities advance the potential of optics as a multi-functional sensory
modality for soft robots. The complete parts list, assembly guidelines, and
processing code for the SCANS gripper are accessible at:
https://parses-lab.github.io/scans/.

</details>


### [36] [Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product-Process-Resource Asset Network](https://arxiv.org/abs/2510.02167)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 本文提出使用数字孪生技术优化电动汽车电池的拆解过程，通过扩展产品-过程-资源资产网络（PAN）为双向PAN（Bi-PAN），同时覆盖制造和再制造/回收阶段。


<details>
  <summary>Details</summary>
Motivation: 在循环经济背景下，制造商往往不共享相关数据，导致产品生命周期结束阶段的再制造和回收过程支持不足，影响可持续性和环境保护。

Method: 采用数字孪生技术，基于产品-过程-资源资产网络（PAN）范式，提出双向PAN（Bi-PAN）表示方法，将建模范围从制造阶段扩展到再制造/回收阶段。

Result: 通过电动汽车电池拆解用例证明，该方法能够灵活高效地解决不同类型电池的拆解挑战，减少生态影响并增强可持续性。

Conclusion: 数字孪生技术结合Bi-PAN表示能够有效支持循环经济中的产品拆解过程，为可持续制造和回收提供技术支撑。

Abstract: In the context of the circular economy, products in their end-of-life phase
should be either remanufactured or recycled. Both of these processes are
crucial for sustainability and environmental conservation. However,
manufacturers often do not support these processes enough by not sharing
relevant data. This paper proposes use of a digital twin technology, which is
capable to help optimizing the disassembly processes to reduce ecological
impact and enhance sustainability. The proposed approach is demonstrated
through a disassembly use-case of the product digital twin of an electric
vehicle battery. By utilizing product digital twins, challenges associated with
the disassembly of electric vehicle batteries can be solved flexibly and
efficiently for various battery types. As a backbone for the product digital
twin representation, the paper uses the paradigm of product-process-resource
asset networks (PAN). Such networks enable to model relevant relationships
across products, production resources, manufacturing processes, and specific
production operations that have to be done in the manufacturing phase of a
product. This paper introduces a Bi-Flow Product-Process-Resource Asset Network
(Bi-PAN) representation, which extends the PAN paradigm to cover not only the
manufacturing, but also the remanufacturing/recycling phase.

</details>


### [37] [DisCo-Layout: Disentangling and Coordinating Semantic and Physical Refinement in a Multi-Agent Framework for 3D Indoor Layout Synthesis](https://arxiv.org/abs/2510.02178)
*Jialin Gao,Donghao Zhou,Mingjian Liang,Lihao Liu,Chi-Wing Fu,Xiaowei Hu,Pheng-Ann Heng*

Main category: cs.RO

TL;DR: DisCo-Layout是一个解耦物理和语义精炼的3D室内布局合成框架，通过语义精炼工具和物理精炼工具分别处理抽象关系和具体空间问题，并采用多智能体协作实现智能布局生成。


<details>
  <summary>Details</summary>
Motivation: 传统方法由于固定数据集而泛化能力差，现有LLM和VLM方法虽然语义丰富但缺乏鲁棒灵活的精炼机制，导致布局质量不佳。

Method: 提出解耦协调框架：语义精炼工具修正抽象对象关系，物理精炼工具通过网格匹配算法解决具体空间问题；多智能体框架包括规划器、设计器和评估器进行协作精炼。

Result: 实验证明DisCo-Layout达到最先进性能，能生成真实、连贯且可泛化的3D室内布局。

Conclusion: DisCo-Layout通过解耦物理和语义精炼，实现了高质量的3D室内布局合成，代码将公开。

Abstract: 3D indoor layout synthesis is crucial for creating virtual environments.
Traditional methods struggle with generalization due to fixed datasets. While
recent LLM and VLM-based approaches offer improved semantic richness, they
often lack robust and flexible refinement, resulting in suboptimal layouts. We
develop DisCo-Layout, a novel framework that disentangles and coordinates
physical and semantic refinement. For independent refinement, our Semantic
Refinement Tool (SRT) corrects abstract object relationships, while the
Physical Refinement Tool (PRT) resolves concrete spatial issues via a
grid-matching algorithm. For collaborative refinement, a multi-agent framework
intelligently orchestrates these tools, featuring a planner for placement
rules, a designer for initial layouts, and an evaluator for assessment.
Experiments demonstrate DisCo-Layout's state-of-the-art performance, generating
realistic, coherent, and generalizable 3D indoor layouts. Our code will be
publicly available.

</details>


### [38] [Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0](https://arxiv.org/abs/2510.02248)
*Yan Miao,Ege Yuceel,Georgios Fainekos,Bardh Hoxha,Hideki Okamoto,Sayan Mitra*

Main category: cs.RO

TL;DR: FalconGym 2.0是一个基于高斯泼溅的逼真模拟框架，通过性能引导精炼算法训练视觉策略，在无人机导航中实现了优异的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉策略在航迹几何变化时性能下降，需要解决过拟合单一航迹的问题。

Method: 开发FalconGym 2.0模拟框架，提出性能引导精炼算法，在挑战性航迹上集中训练视觉策略。

Result: 训练出的单一视觉策略在三个未见航迹上实现100%成功率，在门姿态扰动下保持更高成功率，并能零样本迁移到真实四旋翼硬件，达到98.6%成功率。

Conclusion: FalconGym 2.0结合PGR算法能够训练出具有强大泛化能力和鲁棒性的视觉策略，支持零样本仿真到真实迁移。

Abstract: Visual policy design is crucial for aerial navigation. However,
state-of-the-art visual policies often overfit to a single track and their
performance degrades when track geometry changes. We develop FalconGym 2.0, a
photorealistic simulation framework built on Gaussian Splatting (GSplat) with
an Edit API that programmatically generates diverse static and dynamic tracks
in milliseconds. Leveraging FalconGym 2.0's editability, we propose a
Performance-Guided Refinement (PGR) algorithm, which concentrates visual
policy's training on challenging tracks while iteratively improving its
performance. Across two case studies (fixed-wing UAVs and quadrotors) with
distinct dynamics and environments, we show that a single visual policy trained
with PGR in FalconGym 2.0 outperforms state-of-the-art baselines in
generalization and robustness: it generalizes to three unseen tracks with 100%
success without per-track retraining and maintains higher success rates under
gate-pose perturbations. Finally, we demonstrate that the visual policy trained
with PGR in FalconGym 2.0 can be zero-shot sim-to-real transferred to a
quadrotor hardware, achieving a 98.6% success rate (69 / 70 gates) over 30
trials spanning two three-gate tracks and a moving-gate track.

</details>


### [39] [Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking](https://arxiv.org/abs/2510.02252)
*Joao Pedro Araujo,Yanjie Ze,Pei Xu,Jiajun Wu,C. Karen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种新的人形运动重定向方法GMR，通过系统评估重定向质量对策略性能的影响，解决了现有方法中存在的足部滑动、自穿透和物理不可行运动等问题。


<details>
  <summary>Details</summary>
Motivation: 当前人形运动跟踪策略面临人体与机器人之间的具身差距问题，现有重定向方法在参考轨迹中留下的伪影需要强化学习策略来修正，这通常需要大量的奖励工程和领域随机化。

Method: 提出了通用运动重定向(GMR)方法，并与PHC、ProtoMotions等开源重定向器以及Unitree的高质量闭源数据集进行比较，使用BeyondMimic进行策略训练以隔离重定向效果。

Result: 实验表明，大多数运动可以被跟踪，但重定向数据中的伪影显著降低了策略的鲁棒性，特别是在动态或长序列中。GMR在跟踪性能和源运动保真度方面始终优于现有开源方法。

Conclusion: GMR实现了接近闭源基线的感知保真度和策略成功率，证明了高质量重定向对于人形运动跟踪策略的重要性。

Abstract: Humanoid motion tracking policies are central to building teleoperation
pipelines and hierarchical controllers, yet they face a fundamental challenge:
the embodiment gap between humans and humanoid robots. Current approaches
address this gap by retargeting human motion data to humanoid embodiments and
then training reinforcement learning (RL) policies to imitate these reference
trajectories. However, artifacts introduced during retargeting, such as foot
sliding, self-penetration, and physically infeasible motion are often left in
the reference trajectories for the RL policy to correct. While prior work has
demonstrated motion tracking abilities, they often require extensive reward
engineering and domain randomization to succeed. In this paper, we
systematically evaluate how retargeting quality affects policy performance when
excessive reward tuning is suppressed. To address issues that we identify with
existing retargeting methods, we propose a new retargeting method, General
Motion Retargeting (GMR). We evaluate GMR alongside two open-source
retargeters, PHC and ProtoMotions, as well as with a high-quality closed-source
dataset from Unitree. Using BeyondMimic for policy training, we isolate
retargeting effects without reward tuning. Our experiments on a diverse subset
of the LAFAN1 dataset reveal that while most motions can be tracked, artifacts
in retargeted data significantly reduce policy robustness, particularly for
dynamic or long sequences. GMR consistently outperforms existing open-source
methods in both tracking performance and faithfulness to the source motion,
achieving perceptual fidelity and policy success rates close to the
closed-source baseline. Website:
https://jaraujo98.github.io/retargeting_matters. Code:
https://github.com/YanjieZe/GMR.

</details>


### [40] [Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning](https://arxiv.org/abs/2510.02268)
*Tianchong Jiang,Jingtian Ji,Xiangshan Tan,Jiading Fang,Anand Bhattad,Vitor Guizilini,Matthew R. Walter*

Main category: cs.RO

TL;DR: 通过显式地将策略与相机外参条件化，研究视角不变模仿学习。使用Plucker嵌入的像素光线，证明条件化外参显著提升了标准行为克隆策略在跨视角下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习策略在视角变化下的鲁棒性问题，避免策略依赖静态背景等视觉线索来推断相机姿态，从而在真实场景中实现更可靠的泛化。

Method: 使用Plucker嵌入表示像素光线，将相机外参作为条件输入到策略中。在RoboSuite和ManiSkill中设计了6个操作任务，包含固定和随机化场景变体，分离背景线索和相机姿态的影响。

Result: 无外参条件的策略在固定场景中会利用静态背景推断相机姿态，但在工作空间几何或相机位置变化时性能崩溃。条件化外参恢复了性能，实现了仅使用RGB的鲁棒控制。

Conclusion: 显式条件化相机外参是实现视角不变模仿学习的关键，能够显著提升策略在真实视角变化下的鲁棒性和泛化能力。

Abstract: We study view-invariant imitation learning by explicitly conditioning
policies on camera extrinsics. Using Plucker embeddings of per-pixel rays, we
show that conditioning on extrinsics significantly improves generalization
across viewpoints for standard behavior cloning policies, including ACT,
Diffusion Policy, and SmolVLA. To evaluate policy robustness under realistic
viewpoint shifts, we introduce six manipulation tasks in RoboSuite and
ManiSkill that pair "fixed" and "randomized" scene variants, decoupling
background cues from camera pose. Our analysis reveals that policies without
extrinsics often infer camera pose using visual cues from static backgrounds in
fixed scenes; this shortcut collapses when workspace geometry or camera
placement shifts. Conditioning on extrinsics restores performance and yields
robust RGB-only control without depth. We release the tasks, demonstrations,
and code at https://ripl.github.io/know_your_camera/ .

</details>


### [41] [ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation](https://arxiv.org/abs/2510.02298)
*Wenye Yu,Jun Lv,Zixi Ying,Yang Jin,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: ARMADA是一个多机器人部署和适应系统，通过FLOAT自主故障检测方法减少对人类监督的依赖，实现并行策略部署和高效领域数据收集。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在大规模真实世界数据上表现良好，但预训练策略在缺乏领域数据时性能较差，且人工收集演示数据成本高、质量不一。现有的人机交互系统需要全程人工监督，效率低下。

Method: 开发ARMADA系统，采用FLOAT自主在线故障检测方法，实现并行策略部署，仅在必要时请求人工干预，减少对人类监督的依赖。

Result: FLOAT故障检测准确率平均达到近95%，比现有最佳方法提升20%以上。ARMADA在多次策略部署和后训练中，成功率提高4倍以上，人工干预率降低2倍以上。

Conclusion: ARMADA系统通过FLOAT故障检测实现了更高效的机器人部署和适应，显著减少了人类监督需求，提高了领域数据收集效率。

Abstract: Imitation learning has shown promise in learning from large-scale real-world
datasets. However, pretrained policies usually perform poorly without
sufficient in-domain data. Besides, human-collected demonstrations entail
substantial labour and tend to encompass mixed-quality data and redundant
information. As a workaround, human-in-the-loop systems gather domain-specific
data for policy post-training, and exploit closed-loop policy feedback to offer
informative guidance, but usually require full-time human surveillance during
policy rollout. In this work, we devise ARMADA, a multi-robot deployment and
adaptation system with human-in-the-loop shared control, featuring an
autonomous online failure detection method named FLOAT. Thanks to FLOAT, ARMADA
enables paralleled policy rollout and requests human intervention only when
necessary, significantly reducing reliance on human supervision. Hence, ARMADA
enables efficient acquisition of in-domain data, and leads to more scalable
deployment and faster adaptation to new scenarios. We evaluate the performance
of ARMADA on four real-world tasks. FLOAT achieves nearly 95% accuracy on
average, surpassing prior state-of-the-art failure detection approaches by over
20%. Besides, ARMADA manifests more than 4$\times$ increase in success rate and
greater than 2$\times$ reduction in human intervention rate over multiple
rounds of policy rollout and post-training, compared to previous
human-in-the-loop learning methods.

</details>
