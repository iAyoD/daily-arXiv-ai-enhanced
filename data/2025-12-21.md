<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 31]
- [cs.RO](#cs.RO) [Total: 22]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TabReX : Tabular Referenceless eXplainable Evaluation](https://arxiv.org/abs/2512.15907)
*Tejas Anvekar,Juhna Park,Aparna Garimella,Vivek Gupta*

Main category: cs.CL

TL;DR: TabReX：一个基于图推理的无参考表格生成评估框架，通过将文本和表格转换为知识图进行对齐评估，提供可解释的评分和错误追踪。


<details>
  <summary>Details</summary>
Motivation: 现有表格生成评估方法存在局限：要么将表格扁平化为文本忽略结构信息，要么依赖固定参考限制了泛化能力。需要一种既能评估结构又能评估事实准确性的无参考评估框架。

Method: TabReX将源文本和生成的表格都转换为规范的知识图，通过LLM引导的匹配过程对齐两者，然后计算可解释的、基于评分标准的分数来量化结构和事实保真度。

Result: TabReX在专家排名相关性方面达到最高，在更难的扰动下保持稳定，并能进行细粒度的模型与提示分析。同时构建了TabReX-Bench基准，涵盖6个领域和12种扰动类型。

Conclusion: TabReX为结构化生成系统提供了可信、可解释的评估新范式，实现了敏感性和特异性的可控权衡，并支持人类对齐的判断和单元格级错误追踪。

Abstract: Evaluating the quality of tables generated by large language models (LLMs) remains an open challenge: existing metrics either flatten tables into text, ignoring structure, or rely on fixed references that limit generalization. We present TabReX, a reference-less, property-driven framework for evaluating tabular generation via graph-based reasoning. TabReX converts both source text and generated tables into canonical knowledge graphs, aligns them through an LLM-guided matching process, and computes interpretable, rubric-aware scores that quantify structural and factual fidelity. The resulting metric provides controllable trade-offs between sensitivity and specificity, yielding human-aligned judgments and cell-level error traces. To systematically asses metric robustness, we introduce TabReX-Bench, a large-scale benchmark spanning six domains and twelve planner-driven perturbation types across three difficulty tiers. Empirical results show that TabReX achieves the highest correlation with expert rankings, remains stable under harder perturbations, and enables fine-grained model-vs-prompt analysis establishing a new paradigm for trustworthy, explainable evaluation of structured generation systems.

</details>


### [2] [Social Story Frames: Contextual Reasoning about Narrative Intent and Reception](https://arxiv.org/abs/2512.15925)
*Joel Mire,Maria Antoniak,Steven R. Wilson,Zexin Ma,Achyutarama R. Ganti,Andrew Piper,Maarten Sap*

Main category: cs.CL

TL;DR: SocialStoryFrames：一种形式化框架，用于从社交媒体故事中提取读者反应的合理推断，包括感知作者意图、解释预测推理、情感反应和价值判断，通过对话上下文和叙事理论分类法实现。


<details>
  <summary>Details</summary>
Motivation: 现有计算模型在捕捉读者对故事的丰富解释性、情感性和评价性反应方面存在局限，无法进行细致分析，需要新的框架来填补这一空白。

Method: 提出SocialStoryFrames形式化框架，基于叙事理论、语言语用学和心理学建立分类法，开发SSF-Generator和SSF-Classifier两个模型，通过人类调查（382名参与者）和专家标注进行验证。

Result: 在SSF-Corpus（6140个社交媒体故事）上应用模型，分析了故事意图的频率和相互依赖性，比较了不同社区的叙事实践及其多样性。

Conclusion: SocialStoryFrames通过将细粒度、上下文敏感的建模与通用的读者反应分类法相结合，为在线社区叙事研究提供了新工具。

Abstract: Reading stories evokes rich interpretive, affective, and evaluative responses, such as inferences about narrative intent or judgments about characters. Yet, computational models of reader response are limited, preventing nuanced analyses. To address this gap, we introduce SocialStoryFrames, a formalism for distilling plausible inferences about reader response, such as perceived author intent, explanatory and predictive reasoning, affective responses, and value judgments, using conversational context and a taxonomy grounded in narrative theory, linguistic pragmatics, and psychology. We develop two models, SSF-Generator and SSF-Classifier, validated through human surveys (N=382 participants) and expert annotations, respectively. We conduct pilot analyses to showcase the utility of the formalism for studying storytelling at scale. Specifically, applying our models to SSF-Corpus, a curated dataset of 6,140 social media stories from diverse contexts, we characterize the frequency and interdependence of storytelling intents, and we compare and contrast narrative practices (and their diversity) across communities. By linking fine-grained, context-sensitive modeling with a generic taxonomy of reader responses, SocialStoryFrames enable new research into storytelling in online communities.

</details>


### [3] [BRAID: Bounded Reasoning for Autonomous Inference and Decisions](https://arxiv.org/abs/2512.15959)
*Armağan Amcalar,Eyup Cinar*

Main category: cs.CL

TL;DR: BRAID框架通过结构化、机器可读的提示（基于Mermaid指令图）显著提升LLM推理准确性和成本效率，在多个基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在性能、成本和token使用之间存在非线性关系，传统自然语言提示存在无限制的token扩展问题，需要更高效的结构化推理方法。

Method: 提出BRAID（有界推理自主推断与决策）框架，使用基于Mermaid的指令图创建结构化、机器可读的提示，使模型能够进行有界结构化推理而非无限制的自然语言扩展。

Result: 在AdvancedIF、GSM-Hard和SCALE MultiChallenge等多个基准数据集上测试不同GPT模型层级，显示结构化提示显著提高了推理准确性和成本效率。

Conclusion: BRAID被证明是优化自主代理系统推理效率的有效且可扩展技术，所有数据集和详细结果日志已公开。

Abstract: Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmark datasets. BRAID introduces a bounded reasoning framework using Mermaid-based instruction graphs that enable models to reason struc turally rather than through unbounded natural-language token expansion. We show that structured machine-readable prompts substantially increase reasoning accuracy and cost efficiency for agents in production systems. The findings establish BRAID as an effective and scalable technique for optimizing inference efficiency in autonomous agent systems. All datasets and detailed result logs are available at https://benchmark.openserv.ai.

</details>


### [4] [Examining the Utility of Self-disclosure Types for Modeling Annotators of Social Norms](https://arxiv.org/abs/2512.16034)
*Kieran Henderson,Kian Omoomi,Vasudha Varadarajan,Allison Lahnala,Charles Welch*

Main category: cs.CL

TL;DR: 研究探索如何利用个人信息（如自我披露句子）来改进个体特征建模和主观任务标注预测，发现人口统计信息比态度、关系、经历更有效，少量相关评论即可，多样化样本表现最佳。


<details>
  <summary>Details</summary>
Motivation: 以往研究使用个人信息（如人物描述或自我披露）来改进个体特征建模和主观任务标注预测，但信息量有限，缺乏对何种信息最有效的深入理解。本研究旨在探索不同类型自我披露信息对预测社会规范判断的影响。

Method: 对自我披露句子进行分类，构建标注者模型来预测社会规范判断。通过多种消融实验和分析，检验不同类型信息对预测标注模式的影响。

Result: 1. 人口统计信息比态度、关系、经历更具影响力；2. 基于理论的方法优于自动聚类；3. 与先前研究相反，仅需少量相关评论即可；4. 拥有更多样化的标注者自我披露样本可获得最佳性能。

Conclusion: 自我披露信息对预测主观任务标注具有价值，其中人口统计信息最为关键，理论驱动的方法效果更好，且不需要大量相关评论，多样化的样本能提升模型性能。

Abstract: Recent work has explored the use of personal information in the form of persona sentences or self-disclosures to improve modeling of individual characteristics and prediction of annotator labels for subjective tasks. The volume of personal information has historically been restricted and thus little exploration has gone into understanding what kind of information is most informative for predicting annotator labels. In this work, we categorize self-disclosure sentences and use them to build annotator models for predicting judgments of social norms. We perform several ablations and analyses to examine the impact of the type of information on our ability to predict annotation patterns. We find that demographics are more impactful than attitudes, relationships, and experiences. Generally, theory-based approaches worked better than automatic clusters. Contrary to previous work, only a small number of related comments are needed. Lastly, having a more diverse sample of annotator self-disclosures leads to the best performance.

</details>


### [5] [Are We on the Right Way to Assessing LLM-as-a-Judge?](https://arxiv.org/abs/2512.16041)
*Yuanning Feng,Sinan Wang,Zhengxiang Cheng,Yao Wan,Dongping Chen*

Main category: cs.CL

TL;DR: Sage是一个无需人工标注的LLM-as-a-Judge评估套件，通过局部自一致性和全局逻辑一致性两个新维度来评估LLM法官的质量，发现当前顶级LLM在约1/4困难案例中存在偏好不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-Judge基准主要依赖人工标注的真实标签，这引入了人类偏见，影响可靠性评估并限制了可扩展性。需要一种无需人工标注的方法来评估LLM法官的质量。

Method: 基于理性选择理论公理，提出两个新评估维度：局部自一致性（成对偏好稳定性）和全局逻辑一致性（完整偏好集的传递性）。构建包含650个问题的数据集，结合结构化基准问题和真实用户查询。

Result: 实验表明Sage指标稳定且与LLMBar、RewardBench2等监督基准高度相关。发现当前最先进的LLM（包括Gemini-2.5-Pro和GPT-5）在约1/4困难案例中无法保持一致的偏好判断，存在显著可靠性问题。

Conclusion: Sage作为无需人工标注的评估套件可靠有效。揭示了LLM法官存在情境偏好现象，微调LLM法官、使用评审团机制和深度推理可以提升一致性。人类判断也存在显著不一致性，表明人工标注可能不是可靠的金标准。

Abstract: LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human bias that undermines the assessment of reliability and imposes scalability constraints. To overcome these limitations, we introduce Sage, a novel evaluation suite that assesses the quality of LLM judges without necessitating any human annotation. Inspired by axioms of rational choice theory, Sage introduces two new lenses for measuring LLM-as-a-Judge: local self-consistency (pair-wise preference stability) and global logical consistency (transitivity across a full set of preferences). We curate a dataset of 650 questions by combining structured benchmark problems with real-world user queries. Our experiments demonstrate both the stability of our metrics and their high correlation with supervised benchmarks like LLMBar and RewardBench2, confirming Sage's reliability as an evaluation suite for the robustness and accuracy of LLM-as-a-Judge. Based on Sage, we reveal that current state-of-the-art LLMs exhibit significant reliability problems when acting as judges in both scoring and pairwise settings; even the top-performing models, Gemini-2.5-Pro and GPT-5, fail to maintain consistent preferences in nearly a quarter of difficult cases. We attribute this to a new phenomenon called situational preference, which explains why explicit rubrics or criteria can help the model judge consistently across answer pairs. Our further analysis shows that finetuned LLM-as-a-Judge is a feasible method to boost performance, and the panel-based judge as well as deep reasoning can enhance the judging consistency. We also find substantial inconsistency in human judgments, which indicates that human annotation may not be a reliable gold standard.

</details>


### [6] [Convolutional Lie Operator for Sentence Classification](https://arxiv.org/abs/2512.16125)
*Daniela N. Rim,Heeyoul Choi*

Main category: cs.CL

TL;DR: 将李卷积集成到基于卷积的句子分类器中，通过捕捉语言中的复杂非欧几里得对称性，超越了传统卷积模型。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在捕捉文本局部位置不变特征方面很成功，但它们在建模语言内部复杂变换方面的能力有待进一步探索。李群操作能够捕捉复杂的非欧几里得对称性，这为改进语言建模提供了新思路。

Method: 提出了一种新颖方法，将李卷积集成到基于卷积的句子分类器中，开发了SCLie和DPCLie两种模型。

Result: SCLie和DPCLie模型在实证中超越了传统的基于卷积的句子分类器，通过捕捉语言中不常见的变换，相对提高了准确率。

Conclusion: 研究结果表明李基模型能够捕捉传统方法难以处理的变换，这为语言建模的新范式探索提供了动力。

Abstract: Traditional Convolutional Neural Networks have been successful in capturing local, position-invariant features in text, but their capacity to model complex transformation within language can be further explored. In this work, we explore a novel approach by integrating Lie Convolutions into Convolutional-based sentence classifiers, inspired by the ability of Lie group operations to capture complex, non-Euclidean symmetries. Our proposed models SCLie and DPCLie empirically outperform traditional Convolutional-based sentence classifiers, suggesting that Lie-based models relatively improve the accuracy by capturing transformations not commonly associated with language. Our findings motivate more exploration of new paradigms in language modeling.

</details>


### [7] [MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation](https://arxiv.org/abs/2512.16145)
*Pengyu Wang,Shuchang Ye,Usman Naseem,Jinman Kim*

Main category: cs.CL

TL;DR: 提出基于语义驱动的强化学习方法MRG-R1，通过报告级奖励优化临床正确性而非语言风格模仿，在医学报告生成任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学报告生成方法主要模仿放射科医生的语言风格，但无法保证临床正确性，因为基于token级目标的训练关注词汇选择和句子结构而非实际医学准确性。

Method: 提出语义驱动强化学习(SRL)方法，采用Group Relative Policy Optimization(GRPO)优化报告级奖励：基于生成报告和参考报告中提取的关键放射学发现计算margin-based余弦相似度(MCCS)，直接对齐临床标签一致性。同时使用轻量级推理格式约束引导模型生成结构化"思考报告"。

Result: 在IU X-Ray和MIMIC-CXR数据集上，MRG-R1达到最先进性能：CE-F1分别为51.88和40.39。实验表明标签语义强化优于传统的token级监督。

Conclusion: 优化基于临床的报告级奖励而非token重叠能显著提升临床正确性。这是探索语义强化监督医学大型视觉语言模型训练中医学正确性的先驱工作。

Abstract: Medical report generation (MRG) aims to automatically derive radiology-style reports from medical images to aid in clinical decision-making. However, existing methods often generate text that mimics the linguistic style of radiologists but fails to guarantee clinical correctness, because they are trained on token-level objectives which focus on word-choice and sentence structure rather than actual medical accuracy. We propose a semantic-driven reinforcement learning (SRL) method for medical report generation, adopted on a large vision-language model (LVLM). SRL adopts Group Relative Policy Optimization (GRPO) to encourage clinical-correctness-guided learning beyond imitation of language style. Specifically, we optimise a report-level reward: a margin-based cosine similarity (MCCS) computed between key radiological findings extracted from generated and reference reports, thereby directly aligning clinical-label agreement and improving semantic correctness. A lightweight reasoning format constraint further guides the model to generate structured "thinking report" outputs. We evaluate Medical Report Generation with Sematic-driven Reinforment Learning (MRG-R1), on two datasets: IU X-Ray and MIMIC-CXR using clinical efficacy (CE) metrics. MRG-R1 achieves state-of-the-art performance with CE-F1 51.88 on IU X-Ray and 40.39 on MIMIC-CXR. We found that the label-semantic reinforcement is better than conventional token-level supervision. These results indicate that optimizing a clinically grounded, report-level reward rather than token overlap,meaningfully improves clinical correctness. This work is a prior to explore semantic-reinforcement in supervising medical correctness in medical Large vision-language model(Med-LVLM) training.

</details>


### [8] [Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning](https://arxiv.org/abs/2512.16147)
*Yash Bhaskar,Sankalp Bahad,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 本文介绍了用于Faux-Hate共享任务的系统，该任务旨在检测由虚假叙事驱动的仇恨言论，特别是在印地语-英语混合社交媒体文本中。系统处理两个子任务：二元虚假仇恨检测以及目标和严重性预测。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台已成为有害内容（包括仇恨言论和虚假叙事）快速传播的中心。Faux-Hate共享任务专注于检测由虚假叙事驱动的仇恨言论这一特定现象，这在印地语-英语混合社交媒体文本中尤为挑战性。

Method: 结合先进的自然语言处理技术与领域特定的预训练方法，采用多任务学习框架来处理二元虚假仇恨检测以及目标和严重性预测两个子任务。

Result: 系统在共享任务中取得了有竞争力的结果，证明了利用多任务学习处理这一复杂问题的有效性。

Conclusion: 研究表明，结合先进NLP技术和领域特定预训练的多任务学习方法能够有效检测由虚假叙事驱动的仇恨言论，为社交媒体有害内容检测提供了有效解决方案。

Abstract: Social media platforms, while enabling global connectivity, have become hubs for the rapid spread of harmful content, including hate speech and fake narratives \cite{davidson2017automated, shu2017fake}. The Faux-Hate shared task focuses on detecting a specific phenomenon: the generation of hate speech driven by fake narratives, termed Faux-Hate. Participants are challenged to identify such instances in code-mixed Hindi-English social media text. This paper describes our system developed for the shared task, addressing two primary sub-tasks: (a) Binary Faux-Hate detection, involving fake and hate speech classification, and (b) Target and Severity prediction, categorizing the intended target and severity of hateful content. Our approach combines advanced natural language processing techniques with domain-specific pretraining to enhance performance across both tasks. The system achieved competitive results, demonstrating the efficacy of leveraging multi-task learning for this complex problem.

</details>


### [9] [A Domain-Adapted Pipeline for Structured Information Extraction from Police Incident Announcements on Social Media](https://arxiv.org/abs/2512.16183)
*Mengfan Shen,Kangqi Song,Xindi Wang,Wei Jia,Tao Wang,Ziqiang Han*

Main category: cs.CL

TL;DR: 基于Qwen2.5-7B模型，通过LoRA微调和提示工程，构建了从警方通报中提取15个关键字段的高效信息抽取管道，在死亡检测、伤亡统计和位置提取等任务上达到95%以上准确率。


<details>
  <summary>Details</summary>
Motivation: 警方事故通报等非结构化文本信息抽取面临挑战，特别是社交媒体文本的多样性和非正式性，需要高效准确的自动化解决方案来支持社会科学研究。

Method: 采用Qwen2.5-7B模型，结合LoRA参数高效微调和针对性提示工程，构建领域适应的抽取管道，处理从27,822条微博警方通报中构建的4,933条高质量标注数据。

Result: LoRA微调显著优于基线和指令调优模型，死亡检测准确率超过98.36%，死亡人数精确匹配率达95.31%，省级位置提取精确匹配率达95.54%，成功提取15个关键字段。

Conclusion: 该管道为专业领域多任务结构化信息抽取提供了验证有效的高效解决方案，能够将非结构化文本转化为可靠的结构化数据，支持社会科学研究。

Abstract: Structured information extraction from police incident announcements is crucial for timely and accurate data processing, yet presents considerable challenges due to the variability and informal nature of textual sources such as social media posts. To address these challenges, we developed a domain-adapted extraction pipeline that leverages targeted prompt engineering with parameter-efficient fine-tuning of the Qwen2.5-7B model using Low-Rank Adaptation (LoRA). This approach enables the model to handle noisy, heterogeneous text while reliably extracting 15 key fields, including location, event characteristics, and impact assessment, from a high-quality, manually annotated dataset of 4,933 instances derived from 27,822 police briefing posts on Chinese Weibo (2019-2020). Experimental results demonstrated that LoRA-based fine-tuning significantly improved performance over both the base and instruction-tuned models, achieving an accuracy exceeding 98.36% for mortality detection and Exact Match Rates of 95.31% for fatality counts and 95.54% for province-level location extraction. The proposed pipeline thus provides a validated and efficient solution for multi-task structured information extraction in specialized domains, offering a practical framework for transforming unstructured text into reliable structured data in social science research.

</details>


### [10] [Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation](https://arxiv.org/abs/2512.16189)
*Musarrat Zeba,Abdullah Al Mamun,Kishoar Jahan Tithee,Debopom Sutradhar,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Reem E. Mohamed,Md Rafiqul Islam,Yakub Sebastian,Mukhtar Hussain,Sami Azam*

Main category: cs.CL

TL;DR: 提出一个独立于LLM的事实核查模块和领域特定的摘要模型，用于医疗领域减少幻觉，在MIMIC-III数据集上验证效果良好


<details>
  <summary>Details</summary>
Motivation: 在医疗健康领域，LLM生成的输出必须可靠准确，特别是在决策和患者安全方面。然而，LLM存在幻觉风险，导致关键领域输出不可靠，需要解决这一问题。

Method: 1) 提出独立于LLM的事实核查模块，使用数值正确性测试和通过离散逻辑的自然语言处理进行细粒度逻辑检查，验证事实与电子健康记录的一致性；2) 开发领域特定的摘要模型，使用LoRa在MIMIC-III数据集上进行微调以减少幻觉率；3) 将两个模块配对使用。

Result: 事实核查模块在104个摘要提取的3,786个命题上测试，达到精度0.8904、召回率0.8234、F1分数0.8556。LLM摘要模型获得ROUGE-1分数0.5797和BERTScore 0.9120。

Conclusion: 提出的独立事实核查模块和领域特定摘要模型能有效减少医疗领域LLM输出的幻觉，提高可靠性，为医疗决策提供更安全的AI辅助工具。

Abstract: In healthcare, it is essential for any LLM-generated output to be reliable and accurate, particularly in cases involving decision-making and patient safety. However, the outputs are often unreliable in such critical areas due to the risk of hallucinated outputs from the LLMs. To address this issue, we propose a fact-checking module that operates independently of any LLM, along with a domain-specific summarization model designed to minimize hallucination rates. Our model is fine-tuned using Low-Rank Adaptation (LoRa) on the MIMIC III dataset and is paired with the fact-checking module, which uses numerical tests for correctness and logical checks at a granular level through discrete logic in natural language processing (NLP) to validate facts against electronic health records (EHRs). We trained the LLM model on the full MIMIC-III dataset. For evaluation of the fact-checking module, we sampled 104 summaries, extracted them into 3,786 propositions, and used these as facts. The fact-checking module achieves a precision of 0.8904, a recall of 0.8234, and an F1-score of 0.8556. Additionally, the LLM summary model achieves a ROUGE-1 score of 0.5797 and a BERTScore of 0.9120 for summary quality.

</details>


### [11] [An Information-Theoretic Framework for Robust Large Language Model Editing](https://arxiv.org/abs/2512.16227)
*Qizhou Chen,Chengyu Wang,Taolin Zhang,Xiaofeng He*

Main category: cs.CL

TL;DR: IBKE：基于信息瓶颈理论的知识编辑框架，通过压缩关键信息实现可泛化的LLM知识更新，避免全模型重训练


<details>
  <summary>Details</summary>
Motivation: LLMs在科学和社会应用中存在错误或过时信息，但全模型重训练成本高且破坏性大。现有编辑技术泛化能力有限，容易产生意外副作用，限制了实际应用。

Method: 基于信息瓶颈理论，压缩和隔离实现泛化知识校正所需的关键信息，最小化对无关模型行为的影响。提出IBKE框架，利用紧凑的潜在表示指导基于梯度的更新。

Result: 在多种LLM架构和标准基准任务上验证了有效性，展示了最先进的准确性，并提高了编辑的泛化性和特异性。

Conclusion: 建立了一个理论上有原则且实用的开放域知识编辑范式，提升了LLMs在现实应用中的实用性和可信度。

Abstract: Large Language Models (LLMs) have become indispensable tools in science, technology, and society, enabling transformative advances across diverse fields. However, errors or outdated information within these models can undermine their accuracy and restrict their safe deployment. Developing efficient strategies for updating model knowledge without the expense and disruption of full retraining remains a critical challenge. Current model editing techniques frequently struggle to generalize corrections beyond narrow domains, leading to unintended consequences and limiting their practical impact. Here, we introduce a novel framework for editing LLMs, grounded in information bottleneck theory. This approach precisely compresses and isolates the essential information required for generalizable knowledge correction while minimizing disruption to unrelated model behaviors. Building upon this foundation, we present the Information Bottleneck Knowledge Editor (IBKE), which leverages compact latent representations to guide gradient-based updates, enabling robust and broadly applicable model editing. We validate IBKE's effectiveness across multiple LLM architectures and standard benchmark tasks, demonstrating state-of-the-art accuracy and improved generality and specificity of edits. These findings establish a theoretically principled and practical paradigm for open-domain knowledge editing, advancing the utility and trustworthiness of LLMs in real-world applications.

</details>


### [12] [LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding](https://arxiv.org/abs/2512.16229)
*Chenkai Xu,Yijie Jin,Jiajun Li,Yi Tu,Guoping Long,Dandan Tu,Tianqi Hou,Junchi Yan,Zhijie Deng*

Main category: cs.CL

TL;DR: LoPA是一种无需训练、即插即用的并行解码算法，通过优化token填充顺序将扩散大语言模型的推理速度提升至每前向传递10.1个token，同时开发了分支并行推理系统实现1073.9 tokens/秒的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 当前扩散大语言模型的置信度驱动解码策略并行性有限，通常每前向传递只能生成1-3个token，推理速度受限。研究发现推理并行度对token填充顺序高度敏感，需要优化这一顺序来加速推理。

Method: 提出LoPA算法：通过并行分支探索不同的候选token填充顺序，基于分支置信度选择具有最大未来并行潜力的顺序。同时开发了支持分支并行的多设备推理系统。

Result: 在D2F-Dream模型上，LoPA将GSM8K数据集上的每前向传递token数提升至10.1，性能优于Dream基线。多GPU部署下实现单样本1073.9 tokens/秒的吞吐量。

Conclusion: LoPA通过优化token填充顺序显著提升了扩散大语言模型的推理并行度，实现了训练无关的推理加速，为高效dLLM推理提供了有效解决方案。

Abstract: Diffusion Large Language Models (dLLMs) have demonstrated significant potential for high-speed inference. However, current confidence-driven decoding strategies are constrained by limited parallelism, typically achieving only 1--3 tokens per forward pass (TPF). In this work, we identify that the degree of parallelism during dLLM inference is highly sensitive to the Token Filling Order (TFO). Then, we introduce Lookahead PArallel Decoding LoPA, a training-free, plug-and-play algorithm, to identify a superior TFO and hence accelerate inference. LoPA concurrently explores distinct candidate TFOs via parallel branches, and selects the one with the highest potential for future parallelism based on branch confidence. We apply LoPA to the state-of-the-art D2F model and observe a substantial enhancement in decoding efficiency. Notably, LoPA increases the TPF of D2F-Dream to 10.1 on the GSM8K while maintaining performance superior to the Dream baseline. Furthermore, to facilitate this unprecedented degree of parallelism, we develop a specialized multi-device inference system featuring Branch Parallelism (BP), which achieves a single-sample throughput of 1073.9 tokens per second under multi-GPU deployment. The code is available at https://github.com/zhijie-group/LoPA.

</details>


### [13] [Sigma-Moe-Tiny Technical Report](https://arxiv.org/abs/2512.16248)
*Qingguo Hu,Zhenghao Lin,Ziyue Yang,Yucheng Ding,Xiao Liu,Yuting Jiang,Ruizhe Wang,Tianyu Chen,Zhongxin Guo,Yifan Xiong,Rui Gao,Lei Qu,Jinsong Su,Peng Cheng,Yeyun Gong*

Main category: cs.CL

TL;DR: Sigma-MoE-Tiny是一个极稀疏的MoE语言模型，通过细粒度专家分割（每层96个专家）但每个token仅激活1个专家，实现200亿总参数中仅激活5亿参数，达到最高稀疏度。


<details>
  <summary>Details</summary>
Motivation: 探索在混合专家模型中实现更高稀疏度的可能性，以提升基础模型的可扩展性和效率，同时解决极稀疏设置下专家负载平衡的挑战。

Method: 采用细粒度专家分割（每层最多96个专家），每个token仅激活一个专家；提出渐进稀疏化调度策略来解决极稀疏下的负载平衡问题；在多样化高质量语料上进行预训练和后续训练。

Result: 模型训练过程非常稳定，没有出现不可恢复的损失尖峰；尽管仅激活5亿参数，但在同类或更大规模模型中达到顶级性能；提供了对高稀疏MoE模型中负载平衡的深入分析。

Conclusion: Sigma-MoE-Tiny展示了在极稀疏设置下实现高效可扩展MoE模型的可行性，提出的渐进稀疏化调度策略有效解决了负载平衡问题，为未来MoE架构的稀疏化发展提供了重要见解。

Abstract: Mixture-of-Experts (MoE) has emerged as a promising paradigm for foundation models due to its efficient and powerful scalability. In this work, we present Sigma-MoE-Tiny, an MoE language model that achieves the highest sparsity compared to existing open-source models. Sigma-MoE-Tiny employs fine-grained expert segmentation with up to 96 experts per layer, while activating only one expert for each token, resulting in 20B total parameters with just 0.5B activated. The major challenge introduced by such extreme sparsity lies in expert load balancing. We find that the widely-used load balancing loss tends to become ineffective in the lower layers under this setting. To address this issue, we propose a progressive sparsification schedule aiming to balance expert utilization and training stability. Sigma-MoE-Tiny is pre-trained on a diverse and high-quality corpus, followed by post-training to further unlock its capabilities. The entire training process remains remarkably stable, with no occurrence of irrecoverable loss spikes. Comprehensive evaluations reveal that, despite activating only 0.5B parameters, Sigma-MoE-Tiny achieves top-tier performance among counterparts of comparable or significantly larger scale. In addition, we provide an in-depth discussion of load balancing in highly sparse MoE models, offering insights for advancing sparsity in future MoE architectures.
  Project page: https://qghuxmu.github.io/Sigma-MoE-Tiny
  Code: https://github.com/microsoft/ltp-megatron-lm

</details>


### [14] [Evaluating OpenAI GPT Models for Translation of Endangered Uralic Languages: A Comparison of Reasoning and Non-Reasoning Architectures](https://arxiv.org/abs/2512.16287)
*Yehor Tereshchenko,Mika Hämäläinen,Svitlana Myroniuk*

Main category: cs.CL

TL;DR: 该研究比较了OpenAI GPT模型中推理与非推理架构在芬兰语与四种低资源乌拉尔语翻译任务中的表现，发现推理模型拒绝翻译率低16个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型翻译评估主要关注高资源语言，对低资源和濒危语言的性能了解不足，特别是乌拉尔语系等低资源语言的翻译能力需要系统评估。

Method: 使用文学文本平行语料库，比较OpenAI GPT模型中推理与非推理架构在芬兰语与四种低资源乌拉尔语（科米-兹梁语、莫克沙语、埃尔齐亚语、乌德穆尔特语）之间的翻译表现，通过拒绝率分析评估模型翻译意愿。

Result: 推理模型与非推理模型在翻译性能上存在显著差异，推理模型的拒绝翻译率比非推理模型低16个百分点，表现出更强的低资源语言翻译能力。

Conclusion: 该研究为乌拉尔语言研究者提供了重要见解，并有助于更广泛地理解推理模型在濒危语言保护方面的能力，强调了推理架构在低资源语言翻译中的优势。

Abstract: The evaluation of Large Language Models (LLMs) for translation tasks has primarily focused on high-resource languages, leaving a significant gap in understanding their performance on low-resource and endangered languages. This study presents a comprehensive comparison of OpenAI's GPT models, specifically examining the differences between reasoning and non-reasoning architectures for translating between Finnish and four low-resource Uralic languages: Komi-Zyrian, Moksha, Erzya, and Udmurt. Using a parallel corpus of literary texts, we evaluate model willingness to attempt translation through refusal rate analysis across different model architectures. Our findings reveal significant performance variations between reasoning and non-reasoning models, with reasoning models showing 16 percentage points lower refusal rates. The results provide valuable insights for researchers and practitioners working with Uralic languages and contribute to the broader understanding of reasoning model capabilities for endangered language preservation.

</details>


### [15] [Hacking Neural Evaluation Metrics with Single Hub Text](https://arxiv.org/abs/2512.16323)
*Hiroyuki Deguchi,Katsuki Chousa,Yusuke Sakai*

Main category: cs.CL

TL;DR: 研究发现神经文本评估指标存在漏洞，通过寻找单一对抗性文本（hub text）可欺骗COMET等指标，使其始终给出高评分，即使该文本与源句子无关。


<details>
  <summary>Details</summary>
Motivation: 当前基于嵌入的神经文本评估指标（如COMET）在翻译任务中被广泛使用，但由于神经网络的"黑盒"特性，无法保证其评估结果的可靠性和安全性。需要揭示这类指标的潜在漏洞。

Method: 提出一种在离散空间中寻找单一对抗性文本的方法，该文本无论面对何种测试用例，都能被评估指标一致地评为高质量文本。这种方法旨在识别评估指标的脆弱性。

Result: 在WMT'24英日翻译任务中，找到的hub text获得了79.1 COMET%评分；在英德任务中获得67.8 COMET%评分，均超过了使用M2M100翻译模型为每个源句子单独生成的翻译质量。此外，该方法找到的hub text在多个语言对（如日英、德英）中都具有泛化能力。

Conclusion: 神经文本评估指标存在严重的安全性和可靠性问题，单一对抗性文本就能欺骗这些指标，这为评估指标的开发和使用敲响了警钟，需要更可靠的评估方法。

Abstract: Strongly human-correlated evaluation metrics serve as an essential compass for the development and improvement of generation models and must be highly reliable and robust. Recent embedding-based neural text evaluation metrics, such as COMET for translation tasks, are widely used in both research and development fields. However, there is no guarantee that they yield reliable evaluation results due to the black-box nature of neural networks. To raise concerns about the reliability and safety of such metrics, we propose a method for finding a single adversarial text in the discrete space that is consistently evaluated as high-quality, regardless of the test cases, to identify the vulnerabilities in evaluation metrics. The single hub text found with our method achieved 79.1 COMET% and 67.8 COMET% in the WMT'24 English-to-Japanese (En--Ja) and English-to-German (En--De) translation tasks, respectively, outperforming translations generated individually for each source sentence by using M2M100, a general translation model. Furthermore, we also confirmed that the hub text found with our method generalizes across multiple language pairs such as Ja--En and De--En.

</details>


### [16] [Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs](https://arxiv.org/abs/2512.16378)
*Sara Papi,Javier Garcia Gilabert,Zachary Hopton,Vilém Zouhar,Carlos Escolano,Gerard I. Gállego,Jorge Iranzo-Sánchez,Ahrii Kim,Dominik Macháček,Patricia Schmidtova,Maike Züfle*

Main category: cs.CL

TL;DR: SpeechLLMs vs 传统级联系统在语音翻译中的全面对比：级联系统仍最可靠，SpeechLLMs仅在特定场景匹配，语音基础模型表现最差


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型扩展到文本之外，集成语音作为原生模态催生了SpeechLLMs，旨在直接翻译口语，绕过传统的转录级联流程。但问题是：这种集成是否真的比成熟的级联架构在语音到文本翻译质量上有所提升？

Method: 提出了"Hearing to Translate"测试套件，首次全面评估5个最先进的SpeechLLMs与16个强大的直接和级联系统（结合领先的语音基础模型与多语言LLMs）。评估覆盖16个基准测试、13种语言对和9种挑战性条件（包括不流利、嘈杂和长语音）。

Result: 在广泛评估中，级联系统整体上仍然最可靠；当前的SpeechLLMs仅在特定设置中匹配级联系统；语音基础模型表现最差，落后于两者。这表明集成LLM（无论是模型内部还是管道中）对于高质量语音翻译至关重要。

Conclusion: 尽管SpeechLLMs作为新兴方法有潜力，但传统级联架构在语音翻译任务中仍然保持优势。集成LLM（无论是端到端还是级联方式）是获得高质量翻译的关键，而当前SpeechLLMs尚未超越成熟的级联系统。

Abstract: As Large Language Models (LLMs) expand beyond text, integrating speech as a native modality has given rise to SpeechLLMs, which aim to translate spoken language directly, thereby bypassing traditional transcription-based pipelines. Whether this integration improves speech-to-text translation quality over established cascaded architectures, however, remains an open question. We present Hearing to Translate, the first comprehensive test suite rigorously benchmarking 5 state-of-the-art SpeechLLMs against 16 strong direct and cascade systems that couple leading speech foundation models (SFM), with multilingual LLMs. Our analysis spans 16 benchmarks, 13 language pairs, and 9 challenging conditions, including disfluent, noisy, and long-form speech. Across this extensive evaluation, we find that cascaded systems remain the most reliable overall, while current SpeechLLMs only match cascades in selected settings and SFMs lag behind both, highlighting that integrating an LLM, either within the model or in a pipeline, is essential for high-quality speech translation.

</details>


### [17] [Bridging the Reality Gap: Efficient Adaptation of ASR systems for Challenging Low-Resource Domains](https://arxiv.org/abs/2512.16401)
*Darshil Chauhan,Adityasinh Solanki,Vansh Patel,Kanav Kapoor,Ritvik Jain,Aditya Bansal,Dhruv Kumar,Prateek Narang*

Main category: cs.CL

TL;DR: 提出一个高效、保护隐私的语音识别自适应框架，用于临床环境，通过低秩适应和多领域经验回放，在边缘设备上实现持续学习，显著降低词错误率并减少灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别在临床文档处理中具有巨大潜力，但面临数据隐私限制、计算资源有限和声学领域偏移等技术障碍，现有模型在真实临床音频上词错误率高达40.94%，无法实际应用。

Method: 提出隐私保护自适应框架，采用低秩适应实现边缘设备上的持续学习，结合多领域经验回放技术减少灾难性遗忘。

Result: 目标领域词错误率相对改善17.1%，与朴素自适应相比，灾难性遗忘减少47%，展示了在真实高影响力环境中构建可靠、自我改进语音识别系统的可行途径。

Conclusion: 该框架为在资源受限的临床环境中部署高效、隐私保护的语音识别系统提供了可行方案，能够应对数据隐私、计算资源和领域偏移等挑战。

Abstract: Automatic Speech Recognition (ASR) holds immense potential to streamline clinical documentation, such as digitizing handwritten prescriptions and reports, thereby increasing patient throughput and reducing costs in resource-constrained sectors like rural healthcare. However, realizing this utility is currently obstructed by significant technical barriers: strict data privacy constraints, limited computational resources, and severe acoustic domain shifts. We quantify this gap by showing that a robust multilingual model (IndicWav2Vec) degrades to a stark 40.94% Word Error Rate (WER) when deployed on real-world clinical audio (Gram Vaani), rendering it unusable for practical applications. To address these challenges and bring ASR closer to deployment, we propose an efficient, privacy-preserving adaptation framework. We employ Low-Rank Adaptation (LoRA) to enable continual learning from incoming data streams directly on edge devices, ensuring patient data confidentiality. Our strategy yields a 17.1% relative improvement in WER on the target domain. Furthermore, by integrating multi-domain experience replay, we reduce catastrophic forgetting by 47% compared to naive adaptation. These results demonstrate a viable pathway for building reliable, self-improving ASR systems that can operate effectively within the constraints of high-impact real-world environments.

</details>


### [18] [Plain language adaptations of biomedical text using LLMs: Comparision of evaluation metrics](https://arxiv.org/abs/2512.16530)
*Primoz Kocbek,Leon Kopitar,Gregor Stiglic*

Main category: cs.CL

TL;DR: 研究探索使用大语言模型简化生物医学文本以提高健康素养，比较了提示模板、双AI代理和微调三种方法，发现gpt-4o-mini表现最佳，微调方法表现不佳，G-Eval评估指标与人工评估结果一致。


<details>
  <summary>Details</summary>
Motivation: 提高生物医学文本的可读性和健康素养，使复杂的医学信息更容易被普通公众理解，从而改善健康信息获取的平等性。

Method: 使用公共数据集（包含生物医学摘要的通俗语言改编版），开发并评估三种方法：1）基于提示模板的基线方法；2）双AI代理方法；3）微调方法。使用OpenAI的gpt-4o和gpt-4o-mini模型作为基线。

Result: gpt-4o-mini表现最佳，微调方法表现不佳。G-Eval（基于LLM的定量指标）与定性指标（5点李克特量表）的评估结果一致，显示出良好的一致性。

Conclusion: 大语言模型在生物医学文本简化方面具有潜力，gpt-4o-mini表现优异，G-Eval可作为有效的自动化评估工具，但微调方法需要进一步优化。

Abstract: This study investigated the application of Large Language Models (LLMs) for simplifying biomedical texts to enhance health literacy. Using a public dataset, which included plain language adaptations of biomedical abstracts, we developed and evaluated several approaches, specifically a baseline approach using a prompt template, a two AI agent approach, and a fine-tuning approach. We selected OpenAI gpt-4o and gpt-4o mini models as baselines for further research. We evaluated our approaches with quantitative metrics, such as Flesch-Kincaid grade level, SMOG Index, SARI, and BERTScore, G-Eval, as well as with qualitative metric, more precisely 5-point Likert scales for simplicity, accuracy, completeness, brevity. Results showed a superior performance of gpt-4o-mini and an underperformance of FT approaches. G-Eval, a LLM based quantitative metric, showed promising results, ranking the approaches similarly as the qualitative metric.

</details>


### [19] [UM_FHS at the CLEF 2025 SimpleText Track: Comparing No-Context and Fine-Tune Approaches for GPT-4.1 Models in Sentence and Document-Level Text Simplification](https://arxiv.org/abs/2512.16541)
*Primoz Kocbek,Gregor Stiglic*

Main category: cs.CL

TL;DR: 使用GPT-4.1系列模型进行科学文本简化，比较无上下文提示工程与微调方法，发现gpt-4.1-mini在无上下文情况下表现最佳


<details>
  <summary>Details</summary>
Motivation: 解决CLEF 2025 SimpleText Track Task 1中的科学文本简化问题，包括句子级和文档级简化，探索不同方法在文本简化任务中的效果

Method: 使用OpenAI的gpt-4.1、gpt-4.1-mini和gpt-4.1-nano模型，比较两种方法：1）基于提示工程的无上下文方法；2）微调方法

Result: gpt-4.1-mini模型在无上下文情况下在句子级和文档级简化中都表现稳健；微调模型结果参差不齐；gpt-4.1-nano-ft在特定情况下在文档级简化中表现突出

Conclusion: 不同粒度的文本简化具有复杂性，gpt-4.1-mini的无上下文方法整体表现最佳，而微调方法的效果因模型和任务粒度而异

Abstract: This work describes our submission to the CLEF 2025 SimpleText track Task 1, addressing both sentenceand document-level simplification of scientific texts. The methodology centered on using the gpt-4.1, gpt-4.1mini, and gpt-4.1-nano models from OpenAI. Two distinct approaches were compared: a no-context method relying on prompt engineering and a fine-tuned (FT) method across models. The gpt-4.1-mini model with no-context demonstrated robust performance at both levels of simplification, while the fine-tuned models showed mixed results, highlighting the complexities of simplifying text at different granularities, where gpt-4.1-nano-ft performance stands out at document-level simplification in one case.

</details>


### [20] [Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics](https://arxiv.org/abs/2512.16602)
*Iker García-Ferrero,David Montero,Roman Orus*

Main category: cs.CL

TL;DR: Refusal Steering是一种推理时方法，通过激活向量控制LLM在政治敏感话题上的拒绝行为，无需重新训练模型


<details>
  <summary>Details</summary>
Motivation: 现有基于模式的拒绝检测方法脆弱且不精确，需要一种细粒度控制LLM在政治敏感话题上拒绝行为的方法，同时保持对有害内容的安全性

Method: 使用LLM-as-a-judge分配拒绝置信度分数，提出岭正则化变体计算更好的拒绝-顺从方向隔离的引导向量，在推理时通过激活向量控制模型行为

Result: 在Qwen3-Next-80B-A3B-Thinking上成功移除了政治敏感话题的拒绝行为，同时在JailbreakBench上保持安全性，在通用基准测试上接近基线性能，方法可泛化到4B和80B模型

Conclusion: 激活向量引导可以移除政治拒绝行为同时保留有害内容的安全对齐，为推理时可控、透明的审核提供了实用路径

Abstract: We introduce Refusal Steering, an inference-time method to exercise fine-grained control over Large Language Models refusal behaviour on politically sensitive topics without retraining. We replace fragile pattern-based refusal detection with an LLM-as-a-judge that assigns refusal confidence scores and we propose a ridge-regularized variant to compute steering vectors that better isolate the refusal--compliance direction. On Qwen3-Next-80B-A3B-Thinking, our method removes the refusal behaviour of the model around politically sensitive topics while maintaining safety on JailbreakBench and near-baseline performance on general benchmarks. The approach generalizes across 4B and 80B models and can also induce targeted refusals when desired. We analize the steering vectors and show that refusal signals concentrate in deeper layers of the transformer and are distributed across many dimensions. Together, these results demonstrate that activation steering can remove political refusal behaviour while retaining safety alignment for harmful content, offering a practical path to controllable, transparent moderation at inference time.

</details>


### [21] [JustRL: Scaling a 1.5B LLM with a Simple RL Recipe](https://arxiv.org/abs/2512.16649)
*Bingxiang He,Zekai Qu,Zeyuan Liu,Yinghao Chen,Yuxin Zuo,Cheng Qian,Kaiyan Zhang,Weize Chen,Chaojun Xiao,Ganqu Cui,Ning Ding,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 提出JustRL方法，通过单阶段训练和固定超参数，在1.5B推理模型上达到SOTA性能，计算量减半，挑战当前强化学习复杂化的趋势。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型强化学习领域趋向复杂化（多阶段训练、动态超参数、课程学习等），作者质疑这种复杂性是否必要，希望探索更简单有效的方法。

Method: 提出JustRL方法：单阶段训练、固定超参数、无复杂技巧。在两个1.5B推理模型上验证，超参数可跨模型迁移无需调优。

Result: 在九个数学基准测试上平均准确率达到54.9%和64.3%，计算量比复杂方法减少2倍。训练过程平滑单调，无崩溃或平台期。发现传统技巧（如长度惩罚、鲁棒验证器）可能损害性能。

Conclusion: 当前领域可能为解决本不存在的问题而增加复杂性。JustRL提供了一个简单有效的基线，挑战了强化学习复杂化的必要性。

Abstract: Recent advances in reinforcement learning for large language models have converged on increasing complexity: multi-stage training pipelines, dynamic hyperparameter schedules, and curriculum learning strategies. This raises a fundamental question: \textbf{Is this complexity necessary?} We present \textbf{JustRL}, a minimal approach using single-stage training with fixed hyperparameters that achieves state-of-the-art performance on two 1.5B reasoning models (54.9\% and 64.3\% average accuracy across nine mathematical benchmarks) while using 2$\times$ less compute than sophisticated approaches. The same hyperparameters transfer across both models without tuning, and training exhibits smooth, monotonic improvement over 4,000+ steps without the collapses or plateaus that typically motivate interventions. Critically, ablations reveal that adding ``standard tricks'' like explicit length penalties and robust verifiers may degrade performance by collapsing exploration. These results suggest that the field may be adding complexity to solve problems that disappear with a stable, scaled-up baseline. We release our models and code to establish a simple, validated baseline for the community.

</details>


### [22] [GinSign: Grounding Natural Language Into System Signatures for Temporal Logic Translation](https://arxiv.org/abs/2512.16770)
*William English,Chase Walker,Dominic Simon,Rickard Ewetz*

Main category: cs.CL

TL;DR: 提出GinSign框架，通过分层分类方法将自然语言映射到系统签名，实现自然语言到时序逻辑的翻译，提升接地翻译准确率至95.5%


<details>
  <summary>Details</summary>
Motivation: 现有NL-to-TL翻译框架要么假设能准确获取原子接地信息，要么接地翻译准确率低，这限制了在构建可信自主系统中的应用

Method: 提出GinSign框架，引入接地模型学习将自然语言片段映射到给定系统签名的抽象任务。采用分层分解方法：先预测谓词标签，再选择适当类型的常量参数。将任务从自由生成问题转化为结构化分类问题，使用较小的掩码语言模型，避免依赖昂贵的LLM

Result: 实验表明，省略接地的框架会产生语法正确但语义不等价的LTL表达式，而GinSign支持下游模型检查，接地逻辑等价分数达到95.5%，比现有最佳方法提升1.4倍

Conclusion: GinSign框架通过结构化分类方法有效解决了自然语言到时序逻辑翻译中的接地问题，显著提升了翻译准确率，为构建可信自主系统提供了更好的规范验证能力

Abstract: Natural language (NL) to temporal logic (TL) translation enables engineers to specify, verify, and enforce system behaviors without manually crafting formal specifications-an essential capability for building trustworthy autonomous systems. While existing NL-to-TL translation frameworks have demonstrated encouraging initial results, these systems either explicitly assume access to accurate atom grounding or suffer from low grounded translation accuracy. In this paper, we propose a framework for Grounding Natural Language Into System Signatures for Temporal Logic translation called GinSign. The framework introduces a grounding model that learns the abstract task of mapping NL spans onto a given system signature: given a lifted NL specification and a system signature $\mathcal{S}$, the classifier must assign each lifted atomic proposition to an element of the set of signature-defined atoms $\mathcal{P}$. We decompose the grounding task hierarchically -- first predicting predicate labels, then selecting the appropriately typed constant arguments. Decomposing this task from a free-form generation problem into a structured classification problem permits the use of smaller masked language models and eliminates the reliance on expensive LLMs. Experiments across multiple domains show that frameworks which omit grounding tend to produce syntactically correct lifted LTL that is semantically nonequivalent to grounded target expressions, whereas our framework supports downstream model checking and achieves grounded logical-equivalence scores of $95.5\%$, a $1.4\times$ improvement over SOTA.

</details>


### [23] [From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs](https://arxiv.org/abs/2512.16795)
*Shubham Mishra,Samyek Jain,Gorang Mehrishi,Shiv Tiwari,Harsh Sharma,Pratik Narang,Dhruv Kumar*

Main category: cs.CL

TL;DR: 提出推理轨迹增强的RAG框架，通过三阶段结构化推理解决检索文档冲突、过时和主观信息问题，引入CATS评估管道，实验显示在Qwen模型上端到端答案正确率从0.069提升到0.883


<details>
  <summary>Details</summary>
Motivation: 传统RAG在检索到冲突、过时或主观信息时效果不佳，现有工作缺乏统一的推理监督，需要解决多源信息冲突和可信度评估问题

Method: 提出推理轨迹增强RAG框架，包含三阶段结构化推理：文档级裁决、冲突分析、基于证据的合成；引入Conflict-Aware Trust-Score (CATS)评估管道，使用LLM-as-a-Judge评估基础性、事实正确性、拒绝准确性和冲突行为对齐

Result: 实验结果显示显著优于基线方法，特别是在Qwen模型上，监督微调后端到端答案正确率从0.069提升到0.883，行为依从性从0.074提升到0.722；构建了539个查询的推理数据集

Conclusion: 该框架为冲突感知、可解释的RAG系统奠定了基础，通过结构化推理显著提升了处理冲突信息的能力和系统可信度

Abstract: Retrieval-Augmented Generation (RAG) grounds large language models (LLMs) in external evidence, but fails when retrieved sources conflict or contain outdated or subjective information. Prior work address these issues independently but lack unified reasoning supervision. We propose a reasoning-trace-augmented RAG framework that adds structured, interpretable reasoning across three stages : (1) document-level adjudication, (2) conflict analysis, and (3) grounded synthesis, producing citation-linked answers or justified refusals. A Conflict-Aware Trust-Score (CATS) pipeline is introduced which evaluates groundedness, factual correctness, refusal accuracy, and conflict-behavior alignment using an LLM-as-a-Judge. Our 539-query reasoning dataset and evaluation pipeline establish a foundation for conflict-aware, interpretable RAG systems. Experimental results demonstrate substantial gains over baselines, most notably with Qwen, where Supervised Fine-Tuning improved End-to-End answer correctness from 0.069 to 0.883 and behavioral adherence from 0.074 to 0.722.

</details>


### [24] [Exploration of Augmentation Strategies in Multi-modal Retrieval-Augmented Generation for the Biomedical Domain: A Case Study Evaluating Question Answering in Glycobiology](https://arxiv.org/abs/2512.16802)
*Primož Kocbek,Azra Frkatović-Hodžić,Dora Lalić,Vivian Hui,Gordan Lauc,Gregor Štiglic*

Main category: cs.CL

TL;DR: 研究比较了多模态检索增强生成（MM-RAG）中两种视觉信息处理策略：将图表转换为文本 vs OCR-free视觉检索。在糖生物学领域测试发现，策略选择取决于模型能力：中等模型更适合图表转文本，前沿模型下OCR-free检索变得有竞争力。


<details>
  <summary>Details</summary>
Motivation: 多模态检索增强生成在生物医学QA中前景广阔，但缺乏对视觉信息处理策略的系统比较：何时将图表转换为文本，何时使用OCR-free视觉检索（返回页面图像，让生成器解释）。特别是在糖生物学这种视觉密集领域，这一权衡尤为重要。

Method: 构建了包含120道多选题的基准，来自25篇论文，按检索难度分层。实现了四种增强策略：无增强、文本RAG、多模态转换、OCR-free视觉检索（ColPali）。使用Docling解析和Qdrant索引，评估了中等规模开源模型和前沿专有模型。进行了5次重复实验，计算准确率和95%置信区间。

Result: 中等模型（Gemma-3-27B-IT）下，文本和多模态转换优于OCR-free检索（0.722-0.740 vs 0.510）。前沿模型（GPT-4o）下，多模态最佳（0.808），文本（0.782）和ColPali（0.745）接近。GPT-5家族中，ColPali和ColFlor提升约2%至0.828，各检索器表现无统计差异。GPT-5-nano落后较大模型8-10%。

Conclusion: 策略选择取决于模型能力：中等模型适合图表转文本以降低解读负担，前沿模型下OCR-free检索变得有竞争力。ColFlor检索器在保持性能的同时占用较小资源，是强生成器下的高效默认选择。

Abstract: Multi-modal retrieval-augmented generation (MM-RAG) promises grounded biomedical QA, but it is unclear when to (i) convert figures/tables into text versus (ii) use optical character recognition (OCR)-free visual retrieval that returns page images and leaves interpretation to the generator. We study this trade-off in glycobiology, a visually dense domain. We built a benchmark of 120 multiple-choice questions (MCQs) from 25 papers, stratified by retrieval difficulty (easy text, medium figures/tables, hard cross-evidence). We implemented four augmentations-None, Text RAG, Multi-modal conversion, and late-interaction visual retrieval (ColPali)-using Docling parsing and Qdrant indexing. We evaluated mid-size open-source and frontier proprietary models (e.g., Gemma-3-27B-IT, GPT-4o family). Additional testing used the GPT-5 family and multiple visual retrievers (ColPali/ColQwen/ColFlor). Accuracy with Agresti-Coull 95% confidence intervals (CIs) was computed over 5 runs per configuration. With Gemma-3-27B-IT, Text and Multi-modal augmentation outperformed OCR-free retrieval (0.722-0.740 vs. 0.510 average accuracy). With GPT-4o, Multi-modal achieved 0.808, with Text 0.782 and ColPali 0.745 close behind; within-model differences were small. In follow-on experiments with the GPT-5 family, the best results with ColPali and ColFlor improved by ~2% to 0.828 in both cases. In general, across the GPT-5 family, ColPali, ColQwen, and ColFlor were statistically indistinguishable. GPT-5-nano trailed larger GPT-5 variants by roughly 8-10%. Pipeline choice is capacity-dependent: converting visuals to text lowers the reader burden and is more reliable for mid-size models, whereas OCR-free visual retrieval becomes competitive under frontier models. Among retrievers, ColFlor offers parity with heavier options at a smaller footprint, making it an efficient default when strong generators are available.

</details>


### [25] [Grammar-Forced Translation of Natural Language to Temporal Logic using LLMs](https://arxiv.org/abs/2512.16814)
*William English,Dominic Simon,Sumit Kumar Jha,Rickard Ewetz*

Main category: cs.CL

TL;DR: GraFT框架通过限制每一步的有效输出token来简化自然语言到时序逻辑的翻译任务，相比现有方法提升了端到端翻译准确率5.49%和域外翻译准确率14.06%


<details>
  <summary>Details</summary>
Motivation: 现有方法在原子命题提取、共指消解和有限数据学习方面存在困难，需要更高效的NL到TL翻译框架

Method: 提出Grammar Forced Translation (GraFT)框架，通过利用每个问题的独特属性，在每一步将有效输出token从完整词汇表限制到少数几个，从而减少解空间复杂度

Result: 在CW、GLTL和Navi基准测试中，GraFT相比最先进方法平均提升端到端翻译准确率5.49%，域外翻译准确率14.06%

Conclusion: GraFT通过解空间缩减策略有效解决了NL到TL翻译中的关键挑战，为机器人系统的人机交互提供了更可靠的翻译框架

Abstract: Translating natural language (NL) into a formal language such as temporal logic (TL) is integral for human communication with robots and autonomous systems. State-of-the-art approaches decompose the task into a lifting of atomic propositions (APs) phase and a translation phase. However, existing methods struggle with accurate lifting, the existence of co-references, and learning from limited data. In this paper, we propose a framework for NL to TL translation called Grammar Forced Translation (GraFT). The framework is based on the observation that previous work solves both the lifting and translation steps by letting a language model iteratively predict tokens from its full vocabulary. In contrast, GraFT reduces the complexity of both tasks by restricting the set of valid output tokens from the full vocabulary to only a handful in each step. The solution space reduction is obtained by exploiting the unique properties of each problem. We also provide a theoretical justification for why the solution space reduction leads to more efficient learning. We evaluate the effectiveness of GraFT using the CW, GLTL, and Navi benchmarks. Compared with state-of-the-art translation approaches, it can be observed that GraFT the end-to-end translation accuracy by 5.49% and out-of-domain translation accuracy by 14.06% on average.

</details>


### [26] [What Do Prosody and Text Convey? Characterizing How Meaningful Information is Distributed Across Multiple Channels](https://arxiv.org/abs/2512.16832)
*Aditya Yadavalli,Tiago Pimentel,Tamar I Regev,Ethan Wilcox,Alex Warstadt*

Main category: cs.CL

TL;DR: 本文提出了一种信息论方法来量化语音中韵律（语调）所传递的信息量，发现对于讽刺和情感表达，音频通道比文本通道传递的信息量高一个数量级以上。


<details>
  <summary>Details</summary>
Motivation: 韵律（语音的旋律）传达了文本或文字无法捕捉的关键信息，但传统方法难以量化韵律单独传递的信息量及其具体内容。

Method: 使用大型语音和语言模型估计话语特定意义维度（如情感）与其通信通道（如音频或文本）之间的互信息，量化音频和文本在讽刺、情感和疑问表达中的信息传递能力。

Result: 对于讽刺和情感表达，音频通道（即韵律通道）传递的信息量比纯文本通道高一个数量级以上；对于疑问表达，韵律提供的额外信息相对较少。

Conclusion: 提出将这种方法扩展到更多意义维度、通信通道和语言的系统性研究计划，以更全面理解韵律在沟通中的作用。

Abstract: Prosody -- the melody of speech -- conveys critical information often not captured by the words or text of a message. In this paper, we propose an information-theoretic approach to quantify how much information is expressed by prosody alone and not by text, and crucially, what that information is about. Our approach applies large speech and language models to estimate the mutual information between a particular dimension of an utterance's meaning (e.g., its emotion) and any of its communication channels (e.g., audio or text). We then use this approach to quantify how much information is conveyed by audio and text about sarcasm, emotion, and questionhood, using speech from television and podcasts. We find that for sarcasm and emotion the audio channel -- and by implication the prosodic channel -- transmits over an order of magnitude more information about these features than the text channel alone, at least when long-term context beyond the current sentence is unavailable. For questionhood, prosody provides comparatively less additional information. We conclude by outlining a program applying our approach to more dimensions of meaning, communication channels, and languages.

</details>


### [27] [LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference](https://arxiv.org/abs/2512.16843)
*Harsh Vardhan Bansal*

Main category: cs.CL

TL;DR: LLMCache：一种基于语义相似性的层级缓存框架，通过重用中间激活来加速Transformer推理，实现最高3.1倍加速且精度损失小于0.5%


<details>
  <summary>Details</summary>
Motivation: Transformer语言模型虽然性能优异，但推理延迟高，限制了实时和大规模部署。现有的token级KV缓存机制适用范围有限，需要更通用的加速方案。

Method: 提出LLMCache层级缓存框架：1）基于输入序列语义相似性重用中间激活；2）轻量级指纹机制匹配语义相似输入；3）自适应淘汰策略管理缓存陈旧性；4）支持任意Transformer层缓存，兼容编码器和解码器架构。

Result: 在BERT和GPT-2模型上，在SQuAD、WikiText-103和OpenBookQA数据集上测试，推理时间最高加速3.1倍，精度损失小于0.5%。

Conclusion: LLMCache是一种实用且通用的Transformer推理优化方案，能够显著加速推理过程，同时保持模型精度，适用于实际应用场景。

Abstract: Transformer-based language models have achieved remarkable performance across a wide range of tasks, yet their high inference latency poses a significant challenge for real-timeand large-scale deployment. While existing caching mechanisms,such as token-level key-value caches, offer speedups in autore-gressive decoding, they are limited in scope and applicability. In this paper, we present LLMCache, a novel layer-wise caching framework that accelerates transformer inference by reusing intermediate activations based on semantic similarity of input sequences. Unlike prior work, LLMCache is model-agnostic,operates across both encoder and decoder architectures, and supports caching at arbitrary transformer layers. We introduce a lightweight fingerprinting mechanism for matching seman-tically similar inputs and propose adaptive eviction strategies to manage cache staleness. Experiments on BERT and GPT-2 across SQuAD, WikiText-103, and OpenBookQA show up to 3.1 X speedup in inference time with <0.5% accuracy degradation. Our results highlight LLMCache as a practical and general-purpose solution for optimizing transformer inference in real-world applications

</details>


### [28] [AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning](https://arxiv.org/abs/2512.16883)
*Tzu-Han Lin,Wei-Lin Chen,Chen-An Li,Hung-yi Lee,Yun-Nung Chen,Yu Meng*

Main category: cs.CL

TL;DR: 提出AdaSearch框架，通过两阶段强化学习分离问题解决与搜索决策，提高大语言模型搜索代理的自知能力，减少不必要搜索调用，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有搜索代理存在过度依赖搜索的问题，导致成本增加和噪声/恶意内容风险，而仅依赖参数知识又会产生幻觉。现有方法通过惩罚工具调用次数来缓解搜索滥用，但这需要大量奖励工程、信用分配模糊，且可能被代理表面减少调用而利用。

Method: 提出AdaSearch：一个简单的两阶段、结果驱动的强化学习框架。该框架将问题解决与是否调用搜索的决策分离，使决策过程变得明确和可解释。首先量化现有搜索代理的自知能力，然后设计新框架来改进知识边界意识。

Result: 实验表明，AdaSearch显著提高了知识边界意识，减少了不必要的搜索调用，保持了强大的任务性能，并提供了更透明、可解释的决策行为。在多个模型系列和规模上都表现出优越性。

Conclusion: AdaSearch通过明确分离问题解决和搜索决策，解决了现有搜索代理过度依赖搜索的问题，提供了更透明、可解释的决策过程，特别适用于金融和医疗问答等高风险领域。

Abstract: Equipping large language models (LLMs) with search engines via reinforcement learning (RL) has emerged as an effective approach for building search agents. However, overreliance on search introduces unnecessary cost and risks exposure to noisy or malicious content, while relying solely on parametric knowledge risks hallucination. The central challenge is to develop agents that adaptively balance parametric knowledge with external search, invoking search only when necessary. Prior work mitigates search overuse by shaping rewards around the number of tool calls. However, these penalties require substantial reward engineering, provide ambiguous credit assignment, and can be exploited by agents that superficially reduce calls. Moreover, evaluating performance solely through call counts conflates necessary and unnecessary search, obscuring the measurement of true adaptive behavior. To address these limitations, we first quantify the self-knowledge awareness of existing search agents via an F1-based decision metric, revealing that methods such as Search-R1 often overlook readily available parametric knowledge. Motivated by these findings, we propose AdaSearch, a simple two-stage, outcome-driven RL framework that disentangles problem solving from the decision of whether to invoke search, and makes this decision process explicit and interpretable. This transparency is crucial for high-stakes domains such as finance and medical question answering, yet is largely neglected by prior approaches. Experiments across multiple model families and sizes demonstrate that AdaSearch substantially improves knowledge-boundary awareness, reduces unnecessary search calls, preserves strong task performance, and offers more transparent, interpretable decision behaviors.

</details>


### [29] [Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image](https://arxiv.org/abs/2512.16899)
*Yushi Hu,Reyhane Askari-Hemmat,Melissa Hall,Emily Dinan,Luke Zettlemoyer,Marjan Ghazvininejad*

Main category: cs.CL

TL;DR: MMRB2是首个针对多模态奖励模型的综合基准，涵盖图像生成、编辑、交错生成和推理四大任务，包含4000个专家标注的偏好对，用于评估多模态奖励模型的性能。


<details>
  <summary>Details</summary>
Motivation: 奖励模型对于训练大语言模型至关重要，但在处理交错图像和文本序列的全能模型中尚未得到充分探索。目前缺乏针对多模态奖励模型的综合评估基准。

Method: 创建MMRB2基准，包含四大任务：文本到图像、图像编辑、交错生成和多模态推理。收集1000个专家标注的偏好对/任务，来自23个模型和代理在21个源任务中。采用集成过滤策略确保偏好对具有强人类专家共识。

Result: Gemini 3 Pro达到75-80%准确率，GPT-5和Gemini 2.5 Pro达到66-75%，优于GPT-4o的59%。最佳开源模型Qwen3-VL-32B与Gemini 2.5 Flash相当（64%）。人类准确率超过90%。MMRB2性能与下游任务成功强相关。

Conclusion: MMRB2为多模态奖励模型提供了首个全面基准，揭示了当前模型的局限性（远低于人类水平），并指出了奖励模型改进的关键方向。基准性能与下游任务成功相关，验证了其有效性。

Abstract: Reward models (RMs) are essential for training large language models (LLMs), but remain underexplored for omni models that handle interleaved image and text sequences. We introduce Multimodal RewardBench 2 (MMRB2), the first comprehensive benchmark for reward models on multimodal understanding and (interleaved) generation. MMRB2 spans four tasks: text-to-image, image editing, interleaved generation, and multimodal reasoning ("thinking-with-images"), providing 1,000 expert-annotated preference pairs per task from 23 models and agents across 21 source tasks. MMRB2 is designed with: (1) practical but challenging prompts; (2) responses from state-of-the-art models and agents; and (3) preference pairs with strong human-expert consensus, curated via an ensemble filtering strategy. Using MMRB2, we study existing judges for each subtask, including multimodal LLM-as-a-judge and models trained with human preferences. The latest Gemini 3 Pro attains 75-80% accuracy. GPT-5 and Gemini 2.5 Pro reach 66-75% accuracy, compared to >90% for humans, yet surpass the widely used GPT-4o (59%). The best performing open-source model Qwen3-VL-32B achieves similar accuracies as Gemini 2.5 Flash (64%). We also show that MMRB2 performance strongly correlates with downstream task success using Best-of-N sampling and conduct an in-depth analysis that shows key areas to improve the reward models going forward.

</details>


### [30] [In-Context Algebra](https://arxiv.org/abs/2512.16902)
*Eric Todd,Jannik Brinkmann,Rohit Gandikota,David Bau*

Main category: cs.CL

TL;DR: Transformer在变量符号含义不固定的算术任务中，发展出符号推理机制而非几何嵌入，包括交换复制、单位元识别和闭包消去三种机制。


<details>
  <summary>Details</summary>
Motivation: 先前研究发现Transformer在固定符号含义的算术任务中会发展几何嵌入，但现实世界中的符号含义往往是上下文相关的。本文旨在探索当符号含义随序列变化时，Transformer会发展何种推理机制。

Method: 设计新任务：符号与代数群元素的对应关系在序列间变化。创建有针对性的数据分布来因果测试假设机制，分析模型学习到的内部机制。

Result: Transformer在挑战性设置下达到接近完美的准确率，甚至能泛化到未见过的代数群。识别出三种一致学习的机制：交换复制（专用头复制答案）、单位元识别（区分包含单位元的事实）、闭包消去（跟踪群成员资格以约束有效答案）。

Conclusion: 与固定符号设置中的几何表示互补，当训练模型在符号含义不固定的上下文中推理时，模型会发展符号推理机制而非几何嵌入。

Abstract: We investigate the mechanisms that arise when transformers are trained to solve arithmetic on sequences where tokens are variables whose meaning is determined only through their interactions. While prior work has found that transformers develop geometric embeddings that mirror algebraic structure, those previous findings emerge from settings where arithmetic-valued tokens have fixed meanings. We devise a new task in which the assignment of symbols to specific algebraic group elements varies from one sequence to another. Despite this challenging setup, transformers achieve near-perfect accuracy on the task and even generalize to unseen algebraic groups. We develop targeted data distributions to create causal tests of a set of hypothesized mechanisms, and we isolate three mechanisms models consistently learn: commutative copying where a dedicated head copies answers, identity element recognition that distinguishes identity-containing facts, and closure-based cancellation that tracks group membership to constrain valid answers. Complementary to the geometric representations found in fixed-symbol settings, our findings show that models develop symbolic reasoning mechanisms when trained to reason in-context with variables whose meanings are not fixed.

</details>


### [31] [Constructive Circuit Amplification: Improving Math Reasoning in LLMs via Targeted Sub-Network Updates](https://arxiv.org/abs/2512.16914)
*Nikhil Prakash,Donghao Ren,Dominik Moritz,Yannick Assogba*

Main category: cs.CL

TL;DR: 提出Constructive Circuit Amplification方法，通过识别关键token和模型组件，仅更新少量组件来增强特定任务能力，在数学推理任务上提升11.4%准确率，仅修改1.59%组件。


<details>
  <summary>Details</summary>
Motivation: 先前研究发现LLMs中存在负责特定任务的稀疏子网络（circuits），且微调通常通过强化现有circuits来提升性能。这启发了直接干预这些circuits进行精确任务定向更新的可能性。

Method: 提出Constructive Circuit Amplification方法：1）从模型推理轨迹中识别关键token；2）识别负责目标任务的模型组件；3）仅更新这些特定组件。

Result: 在数学推理任务上，准确率提升高达+11.4%（跨多个模型），仅修改1.59%的模型组件，在MMLU、TriviaQA和TruthfulQA等其他能力测试中影响最小。

Conclusion: 通过选择性更新稀疏的模型组件集合，可以可靠地增强目标能力，这为精确的任务定向模型更新提供了有效方法。

Abstract: Prior studies investigating the internal workings of LLMs have uncovered sparse subnetworks, often referred to as circuits, that are responsible for performing specific tasks. Additionally, it has been shown that model performance improvement through fine-tuning often results from the strengthening of existing circuits in the model. Taken together, these findings suggest the possibility of intervening directly on such circuits to make precise, task-targeted updates. Motivated by these findings, we propose a novel method called Constructive Circuit Amplification which identifies pivotal tokens from model reasoning traces as well as model components responsible for the desired task, and updates only those components. Applied to mathematical reasoning, it improves accuracy by up to +11.4% across multiple models while modifying as little as 1.59% of model components, with minimal impact on other abilities as measured by MMLU, TriviaQA, and TruthfulQA. These results demonstrate that targeted capabilities can be reliably enhanced by selectively updating a sparse set of model components.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [32] [Large Video Planner Enables Generalizable Robot Control](https://arxiv.org/abs/2512.15840)
*Boyuan Chen,Tianyuan Zhang,Haoran Geng,Kiwhan Song,Caiyi Zhang,Peihao Li,William T. Freeman,Jitendra Malik,Pieter Abbeel,Russ Tedrake,Vincent Sitzmann,Yilun Du*

Main category: cs.RO

TL;DR: 该论文提出了一种基于大规模视频预训练构建机器人基础模型的新范式，通过互联网规模的人类活动视频数据集训练生成式机器人规划模型，实现零样本视频规划并提取可执行的机器人动作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型主要基于多模态大语言模型（MLLMs）扩展动作输出，但作者认为视频作为时空状态和动作序列的自然载体，比静态图像和语言更符合机器人行为的本质，因此探索视频预训练作为构建机器人基础模型的主要模态。

Method: 1. 收集互联网规模的人类活动和任务演示视频数据集；2. 首次以基础模型规模训练开放式视频模型用于生成式机器人规划；3. 模型为零样本新场景和任务生成视频规划；4. 后处理提取可执行的机器人动作。

Result: 模型展示了强大的指令跟随能力、强泛化性和现实可行性：1. 在第三方选择的野外任务中评估任务级泛化；2. 通过真实机器人实验证明物理执行成功；3. 模型和数据集已开源支持可复现的视频机器人学习。

Conclusion: 大规模视频预训练是构建机器人基础模型的有效替代范式，视频作为时空序列的自然表征与机器人行为高度契合，该方法在零样本规划、泛化能力和实际执行方面表现出色，为开放式、可复现的视频机器人学习提供了新途径。

Abstract: General-purpose robots require decision-making models that generalize across diverse tasks and environments. Recent works build robot foundation models by extending multimodal large language models (MLLMs) with action outputs, creating vision-language-action (VLA) systems. These efforts are motivated by the intuition that MLLMs' large-scale language and image pretraining can be effectively transferred to the action output modality. In this work, we explore an alternative paradigm of using large-scale video pretraining as a primary modality for building robot foundation models. Unlike static images and language, videos capture spatio-temporal sequences of states and actions in the physical world that are naturally aligned with robotic behavior. We curate an internet-scale video dataset of human activities and task demonstrations, and train, for the first time at a foundation-model scale, an open video model for generative robotics planning. The model produces zero-shot video plans for novel scenes and tasks, which we post-process to extract executable robot actions. We evaluate task-level generalization through third-party selected tasks in the wild and real-robot experiments, demonstrating successful physical execution. Together, these results show robust instruction following, strong generalization, and real-world feasibility. We release both the model and dataset to support open, reproducible video-based robot learning. Our website is available at https://www.boyuan.space/large-video-planner/.

</details>


### [33] [SORS: A Modular, High-Fidelity Simulator for Soft Robots](https://arxiv.org/abs/2512.15994)
*Manuel Mekkattu,Mike Y. Michelis,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SORS是一个用于软体机器人的高保真仿真器，基于有限元方法和能量框架，通过约束非线性优化处理接触交互，在多种实验中验证了其物理准确性和控制优化潜力。


<details>
  <summary>Details</summary>
Motivation: 软体机器人在多物理场环境中的部署需要先进的仿真框架，但现有仿真器难以处理软体机器人的大非线性变形、材料不可压缩性和接触交互等挑战，缺乏可扩展性和应用相关性。

Method: 提出SORS仿真器，基于有限元方法的能量框架，支持模块化扩展自定义材料和驱动模型，采用基于序列二次规划的约束非线性优化来确保物理一致的接触处理。

Result: 通过悬臂梁偏转、软体机械臂压力驱动、PokeFlex数据集接触交互等实验验证，能够准确捕捉材料基本行为和复杂驱动动力学，并展示了软体机器人腿的控制优化潜力。

Conclusion: SORS通过弥合仿真与现实之间的差距，为下一代软体机器人原型设计提供了经过验证的工具，填补了软体机器人生态系统中可扩展性、保真度和可用性的空白。

Abstract: The deployment of complex soft robots in multiphysics environments requires advanced simulation frameworks that not only capture interactions between different types of material, but also translate accurately to real-world performance. Soft robots pose unique modeling challenges due to their large nonlinear deformations, material incompressibility, and contact interactions, which complicate both numerical stability and physical accuracy. Despite recent progress, robotic simulators often struggle with modeling such phenomena in a scalable and application-relevant manner. We present SORS (Soft Over Rigid Simulator), a versatile, high-fidelity simulator designed to handle these complexities for soft robot applications. Our energy-based framework, built on the finite element method, allows modular extensions, enabling the inclusion of custom-designed material and actuation models. To ensure physically consistent contact handling, we integrate a constrained nonlinear optimization based on sequential quadratic programming, allowing for stable and accurate modeling of contact phenomena. We validate our simulator through a diverse set of real-world experiments, which include cantilever deflection, pressure-actuation of a soft robotic arm, and contact interactions from the PokeFlex dataset. In addition, we showcase the potential of our framework for control optimization of a soft robotic leg. These tests confirm that our simulator can capture both fundamental material behavior and complex actuation dynamics with high physical fidelity. By bridging the sim-to-real gap in these challenging domains, our approach provides a validated tool for prototyping next-generation soft robots, filling the gap of extensibility, fidelity, and usability in the soft robotic ecosystem.

</details>


### [34] [dLITE: Differentiable Lighting-Informed Trajectory Evaluation for On-Orbit Inspection](https://arxiv.org/abs/2512.16011)
*Jack Naylor,Raghav Mishra,Nicholas H. Barbara,Donald G. Dansereau*

Main category: cs.RO

TL;DR: 提出∂LITE，一个端到端可微分的在轨检查模拟管道，通过可微分渲染和轨道传播器优化检查轨迹，提升图像质量和数据可用性。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道环境对航天器检查操作带来独特挑战，包括太阳光镜面反射、自阴影、动态光照以及航天器间相对运动导致的成像距离和姿态变化。现有模拟方法难以专门优化检查轨迹以提升图像质量。

Method: 开发∂LITE端到端可微分模拟管道，结合最先进的可微分渲染工具和自定义轨道传播器，基于视觉传感器数据对轨道参数进行端到端优化，自动设计非显而易见的检查轨迹。

Result: ∂LITE能够自动设计非显而易见的检查轨迹，显著提升获取数据的质量和实用性，为现代航天器任务规划计算提供新见解。

Conclusion: ∂LITE是首个可微分检查规划管道，通过端到端优化方法解决了在轨检查中的视觉数据质量问题，为航天器任务规划提供了创新的计算框架。

Abstract: Visual inspection of space-borne assets is of increasing interest to spacecraft operators looking to plan maintenance, characterise damage, and extend the life of high-value satellites in orbit. The environment of Low Earth Orbit (LEO) presents unique challenges when planning inspection operations that maximise visibility, information, and data quality. Specular reflection of sunlight from spacecraft bodies, self-shadowing, and dynamic lighting in LEO significantly impact the quality of data captured throughout an orbit. This is exacerbated by the relative motion between spacecraft, which introduces variable imaging distances and attitudes during inspection. Planning inspection trajectories with the aide of simulation is a common approach. However, the ability to design and optimise an inspection trajectory specifically to improve the resulting image quality in proximity operations remains largely unexplored. In this work, we present $\partial$LITE, an end-to-end differentiable simulation pipeline for on-orbit inspection operations. We leverage state-of-the-art differentiable rendering tools and a custom orbit propagator to enable end-to-end optimisation of orbital parameters based on visual sensor data. $\partial$LITE enables us to automatically design non-obvious trajectories, vastly improving the quality and usefulness of attained data. To our knowledge, our differentiable inspection-planning pipeline is the first of its kind and provides new insights into modern computational approaches to spacecraft mission planning. Project page: https://appearance-aware.github.io/dlite/

</details>


### [35] [Few-Shot Inference of Human Perceptions of Robot Performance in Social Navigation Scenarios](https://arxiv.org/abs/2512.16019)
*Qiping Zhang,Nathan Tsoi,Mofeed Nagib,Hao-Tien Lewis Chiang,Marynel Vázquez*

Main category: cs.RO

TL;DR: 利用大语言模型的少样本学习能力，通过少量上下文示例预测人类对机器人社交导航行为的评价，性能优于传统监督学习且所需标注数据少一个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量标注数据来评估人类对机器人行为的感知，这在实际应用中存在限制。需要开发更高效、数据需求更少的方法来预测人类对机器人社交行为的评价。

Method: 扩展SEAN TOGETHER数据集，增加真实世界人机导航场景和参与者反馈。利用多个LLM基于少量上下文示例，通过观察机器人和周围人类运动的时空线索来预测人类对机器人性能的感知。进行输入特征消融研究，并探索个性化上下文学习（使用同一用户的示例）。

Result: LLM能够匹配或超越传统监督学习模型的性能，同时所需标注实例少一个数量级。更多上下文示例能提高预测性能，个性化示例能进一步提升预测准确性。消融研究揭示了LLM用于推理的传感器信息类型。

Conclusion: LLM的少样本学习能力为通过用户中心反馈改进机器人行为提供了可扩展的途径，减少了数据标注需求，使机器人能更好地理解和适应人类期望。

Abstract: Understanding how humans evaluate robot behavior during human-robot interactions is crucial for developing socially aware robots that behave according to human expectations. While the traditional approach to capturing these evaluations is to conduct a user study, recent work has proposed utilizing machine learning instead. However, existing data-driven methods require large amounts of labeled data, which limits their use in practice. To address this gap, we propose leveraging the few-shot learning capabilities of Large Language Models (LLMs) to improve how well a robot can predict a user's perception of its performance, and study this idea experimentally in social navigation tasks. To this end, we extend the SEAN TOGETHER dataset with additional real-world human-robot navigation episodes and participant feedback. Using this augmented dataset, we evaluate the ability of several LLMs to predict human perceptions of robot performance from a small number of in-context examples, based on observed spatio-temporal cues of the robot and surrounding human motion. Our results demonstrate that LLMs can match or exceed the performance of traditional supervised learning models while requiring an order of magnitude fewer labeled instances. We further show that prediction performance can improve with more in-context examples, confirming the scalability of our approach. Additionally, we investigate what kind of sensor-based information an LLM relies on to make these inferences by conducting an ablation study on the input features considered for performance prediction. Finally, we explore the novel application of personalized examples for in-context learning, i.e., drawn from the same user being evaluated, finding that they further enhance prediction accuracy. This work paves the path to improving robot behavior in a scalable manner through user-centered feedback.

</details>


### [36] [Maintaining the Level of a Payload carried by Multi-Robot System on Irregular Surface](https://arxiv.org/abs/2512.16024)
*Rishabh Dev Yadav,Shrey Agrawal,Kamalakar Karlapalem*

Main category: cs.RO

TL;DR: 多机器人负载运输系统，通过线性执行器调节机器人高度，在未知不平坦地形中保持负载期望方向


<details>
  <summary>Details</summary>
Motivation: 解决在未知且不平坦的倾斜环境中运输负载时，如何保持负载期望方向的问题。传统方法通常假设地形已知或平坦，无法适应复杂多变的地形条件。

Method: 使用带有线性执行器（活塞）的自定义机器人，结合开环控制器和闭环PID控制器。系统持续监测负载方向，计算每个机器人所需的活塞高度来维持负载期望方向。模型不对地形类型做任何假设。

Result: 在多种具有变化和复杂地形的模拟环境中测试，展示了所提出控制器的有效性。系统能够在任何未知和不平坦的地形及倾斜条件下工作。

Conclusion: 提出的多机器人负载运输系统能够在未知不平坦地形中有效保持负载方向，结合开环和闭环控制的方法具有实际应用价值。

Abstract: In this paper, we introduce a multi robot payload transport system to carry payloads through an environment of unknown and uneven inclinations while maintaining the desired orientation of the payload. For this task, we used custom built robots with a linear actuator (pistons) mounted on top of each robot. The system continuously monitors the payload's orientation and computes the required piston height of each robot to maintain the desired orientation of the payload. In this work, we propose an open loop controller coupled with a closed loop PID controller to achieve the goal. As our modelling makes no assumptions on the type of terrain, the system can work on any unknown and uneven terrains and inclinations. We showcase the efficacy of our proposed controller by testing it on various simulated environments with varied and complex terrains.

</details>


### [37] [SWIFT-Nav: Stability-Aware Waypoint-Level TD3 with Fuzzy Arbitration for UAV Navigation in Cluttered Environments](https://arxiv.org/abs/2512.16027)
*Shuaidong Ji,Mahdi Bamdad,Francisco Cruz*

Main category: cs.RO

TL;DR: SWIFT-Nav：基于TD3的无人机导航框架，通过模糊逻辑安全层和优先经验回放实现快速稳定收敛，在杂乱动态环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在杂乱和动态环境中实现高效可靠的无人机导航仍然具有挑战性。现有方法在轨迹平滑性、泛化能力和实时响应性方面存在不足。

Method: 提出SWIFT-Nav框架：1）传感器驱动的感知前端将LiDAR数据转换为置信度加权的安全地图和目标线索；2）TD3航点策略使用优先经验回放和衰减ε-贪婪探索；3）轻量级模糊逻辑层计算安全分数、控制模式切换并限制不安全动作；4）任务对齐的奖励塑形结合目标进度、避障距离和切换经济性。

Result: 在Webots中实现，基于接近度的碰撞检测。该方法在轨迹平滑性和对未见布局的泛化能力方面持续优于基线方法，同时保持实时响应性。

Conclusion: 将TD3与回放优先级、校准探索和模糊安全规则相结合，为杂乱场景中的无人机导航提供了一个鲁棒且可部署的解决方案。

Abstract: Efficient and reliable UAV navigation in cluttered and dynamic environments remains challenging. We propose SWIFT-Nav: Stability-aware Waypoint-level Integration of Fuzzy arbitration and TD3 for Navigation, a TD3-based navigation framework that achieves fast, stable convergence to obstacle-aware paths. The system couples a sensor-driven perception front end with a TD3 waypoint policy: the perception module converts LiDAR ranges into a confidence-weighted safety map and goal cues, while the TD3 policy is trained with Prioritised Experience Replay to focus on high-error transitions and a decaying epsilon-greedy exploration schedule that gradually shifts from exploration to exploitation. A lightweight fuzzy-logic layer computes a safety score from radial measurements and near obstacles, gates mode switching and clamps unsafe actions; in parallel, task-aligned reward shaping combining goal progress, clearance, and switch-economy terms provides dense, well-scaled feedback that accelerates learning. Implemented in Webots with proximity-based collision checking, our approach consistently outperforms baselines in trajectory smoothness and generalization to unseen layouts, while preserving real-time responsiveness. These results show that combining TD3 with replay prioritisation, calibrated exploration, and fuzzy-safety rules yields a robust and deployable solution for UAV navigation in cluttered scenes.

</details>


### [38] [A Task-Driven, Planner-in-the-Loop Computational Design Framework for Modular Manipulators](https://arxiv.org/abs/2512.16069)
*Maolin Lei,Edoardo Romiti,Arturo Laurenzi,Rui Dai,Matteo Dalle Vedove,Jiatao Ding,Daniele Fontanelli,Nikos Tsagarakis*

Main category: cs.RO

TL;DR: 提出统一的任务驱动计算框架，集成轨迹规划与形态和安装姿态的协同优化，通过HMPC策略和CMA-ES算法实现模块化机械臂的优化设计，引入虚拟模块抽象支持双分支形态扩展工作空间。


<details>
  <summary>Details</summary>
Motivation: 模块化机械臂虽然具有高适应性，但在部署时需要同时考虑运动规划、形态优化和安装姿态，传统单分支设计通过增加连杆长度扩展工作空间容易违反基关节扭矩限制，需要解决这些挑战。

Method: 提出统一任务驱动计算框架，集成轨迹规划和形态/安装姿态协同优化；采用分层模型预测控制(HMPC)进行运动规划；使用CMA-ES算法探索离散形态配置和连续安装姿态的混合搜索空间；引入虚拟模块抽象实现双分支形态，通过辅助分支分担主分支扭矩。

Result: 仿真和硬件实验（抛光、钻孔、拾放任务）表明：1）框架能为给定任务生成多个满足运动学和动力学约束、避免环境碰撞的可行设计；2）通过定制成本函数可实现最大化可操作性、最小化关节努力或减少模块数量等灵活设计目标；3）双分支形态能在不增加基础模块功率的情况下实现大工作空间操作。

Conclusion: 提出的统一框架有效解决了模块化机械臂部署中的运动规划、形态优化和安装姿态协同优化问题，双分支设计扩展了工作空间而不增加单个关节模块的容量，为模块化机械臂的灵活应用提供了系统解决方案。

Abstract: Modular manipulators composed of pre-manufactured and interchangeable modules offer high adaptability across diverse tasks. However, their deployment requires generating feasible motions while jointly optimizing morphology and mounted pose under kinematic, dynamic, and physical constraints. Moreover, traditional single-branch designs often extend reach by increasing link length, which can easily violate torque limits at the base joint. To address these challenges, we propose a unified task-driven computational framework that integrates trajectory planning across varying morphologies with the co-optimization of morphology and mounted pose. Within this framework, a hierarchical model predictive control (HMPC) strategy is developed to enable motion planning for both redundant and non-redundant manipulators. For design optimization, the CMA-ES is employed to efficiently explore a hybrid search space consisting of discrete morphology configurations and continuous mounted poses. Meanwhile, a virtual module abstraction is introduced to enable bi-branch morphologies, allowing an auxiliary branch to offload torque from the primary branch and extend the achievable workspace without increasing the capacity of individual joint modules. Extensive simulations and hardware experiments on polishing, drilling, and pick-and-place tasks demonstrate the effectiveness of the proposed framework. The results show that: 1) the framework can generate multiple feasible designs that satisfy kinematic and dynamic constraints while avoiding environmental collisions for given tasks; 2) flexible design objectives, such as maximizing manipulability, minimizing joint effort, or reducing the number of modules, can be achieved by customizing the cost functions; and 3) a bi-branch morphology capable of operating in a large workspace can be realized without requiring more powerful basic modules.

</details>


### [39] [A simulation platform calibration method for automated vehicle evaluation: accurate on both vehicle level and traffic flow level](https://arxiv.org/abs/2512.16076)
*Jia Hu,Junqi Li,Xuerun Yan,Jintao Lai,Lianhua An*

Main category: cs.RO

TL;DR: 提出一种自动驾驶仿真平台校准方法，能在车辆和交通流两个层面实现高精度校准，提升交互复现精度83.53%，校准效率76.75%


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶仿真测试中的校准方法在准确复现AV与背景交通交互方面存在不足，需要更有效的校准方法来确保仿真可靠性

Method: 提出一种仿真平台校准方法，具备车辆间交互校准能力、精度保证、效率提升和流水线校准能力，采用全自动化校准流程

Result: 相比无校准基线和现有最优方法，交互复现精度提升83.53%，校准效率提升76.75%，车辆级和交通流级指标精度提升51.9%

Conclusion: 该方法能有效解决自动驾驶仿真校准问题，实现高精度、高效率的全自动化校准，为可靠的仿真测试提供保障

Abstract: Simulation testing is a fundamental approach for evaluating automated vehicles (AVs). To ensure its reliability, it is crucial to accurately replicate interactions between AVs and background traffic, which necessitates effective calibration. However, existing calibration methods often fall short in achieving this goal. To address this gap, this study introduces a simulation platform calibration method that ensures high accuracy at both the vehicle and traffic flow levels. The method offers several key features:(1) with the capability of calibration for vehicle-to-vehicle interaction; (2) with accuracy assurance; (3) with enhanced efficiency; (4) with pipeline calibration capability. The proposed method is benchmarked against a baseline with no calibration and a state-of-the-art calibration method. Results show that it enhances the accuracy of interaction replication by 83.53% and boosts calibration efficiency by 76.75%. Furthermore, it maintains accuracy across both vehicle-level and traffic flow-level metrics, with an improvement of 51.9%. Notably, the entire calibration process is fully automated, requiring no human intervention.

</details>


### [40] [ManiLong-Shot: Interaction-Aware One-Shot Imitation Learning for Long-Horizon Manipulation](https://arxiv.org/abs/2512.16302)
*Zixuan Chen,Chongkai Gao,Lin Shao,Jieqi Shi,Jing Huo,Yang Gao*

Main category: cs.RO

TL;DR: ManiLong-Shot 是一个用于长视野操作任务的一次性模仿学习框架，通过将任务分解为交互感知的基元序列，实现了从短视野任务到长视野任务的泛化。


<details>
  <summary>Details</summary>
Motivation: 当前的一次性模仿学习方法主要局限于短视野任务，无法处理复杂的长期操作任务，限制了其在机器人技能学习中的实际应用。

Method: 将长视野任务围绕物理交互事件结构化，将其重构为序列化交互感知基元而非直接模仿连续轨迹。基元分解可由视觉语言模型的高层推理或基于机器人状态变化的启发式规则驱动。对每个基元，预测关键交互的不变区域，建立演示与当前观测的对应关系，计算目标末端执行器位姿。

Result: 在仅使用10个短视野任务训练的情况下，ManiLong-Shot 在20个未见的长视野任务上实现了一次性模仿学习，相比最先进方法取得了22.8%的相对提升。真实机器人实验验证了其在三个长视野操作任务中的鲁棒执行能力。

Conclusion: ManiLong-Shot 通过基元分解和交互感知的方法，成功扩展了一次性模仿学习到长视野操作任务，在仿真和真实机器人实验中均表现出色，具有实际应用价值。

Abstract: One-shot imitation learning (OSIL) offers a promising way to teach robots new skills without large-scale data collection. However, current OSIL methods are primarily limited to short-horizon tasks, thus limiting their applicability to complex, long-horizon manipulations. To address this limitation, we propose ManiLong-Shot, a novel framework that enables effective OSIL for long-horizon prehensile manipulation tasks. ManiLong-Shot structures long-horizon tasks around physical interaction events, reframing the problem as sequencing interaction-aware primitives instead of directly imitating continuous trajectories. This primitive decomposition can be driven by high-level reasoning from a vision-language model (VLM) or by rule-based heuristics derived from robot state changes. For each primitive, ManiLong-Shot predicts invariant regions critical to the interaction, establishes correspondences between the demonstration and the current observation, and computes the target end-effector pose, enabling effective task execution. Extensive simulation experiments show that ManiLong-Shot, trained on only 10 short-horizon tasks, generalizes to 20 unseen long-horizon tasks across three difficulty levels via one-shot imitation, achieving a 22.8% relative improvement over the SOTA. Additionally, real-robot experiments validate ManiLong-Shot's ability to robustly execute three long-horizon manipulation tasks via OSIL, confirming its practical applicability.

</details>


### [41] [A2VISR: An Active and Adaptive Ground-Aerial Localization System Using Visual Inertial and Single-Range Fusion](https://arxiv.org/abs/2512.16367)
*Sijia Chen,Wei Dong*

Main category: cs.RO

TL;DR: 提出一种地空协作系统，通过主动视觉、单点测距、惯性里程计和光流融合，增强飞行机器人在复杂环境中的定位鲁棒性，特别是在视觉传感器退化时。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用固定相机观测预置标记来估计飞行机器人位置，但受限于距离且容易捕获失败。在视觉传感器退化的杂乱环境中，需要更鲁棒的定位方案。

Method: 1) 地面车辆搭载主动视觉子系统，可动态旋转检测跟踪空中机器人的红外标记；2) 结合单点测距扩展可行距离和重捕获能力；3) 基于多项式近似的降维估计器融合多源测量；4) 自适应滑动置信度评估算法根据移动方差动态调整权重参数。

Result: 在烟雾干扰、光照变化、障碍物遮挡、长时间视觉丢失和扩展操作范围等条件下，平均均方根误差约0.09米，保持对捕获丢失和传感器故障的鲁棒性。

Conclusion: 所提出的地空协作定位框架通过多传感器融合和自适应置信度评估，实现了在复杂环境中的鲁棒在线定位，解决了传统视觉定位方法的局限性。

Abstract: It's a practical approach using the ground-aerial collaborative system to enhance the localization robustness of flying robots in cluttered environments, especially when visual sensors degrade. Conventional approaches estimate the flying robot's position using fixed cameras observing pre-attached markers, which could be constrained by limited distance and susceptible to capture failure. To address this issue, we improve the ground-aerial localization framework in a more comprehensive manner, which integrates active vision, single-ranging, inertial odometry, and optical flow. First, the designed active vision subsystem mounted on the ground vehicle can be dynamically rotated to detect and track infrared markers on the aerial robot, improving the field of view and the target recognition with a single camera. Meanwhile, the incorporation of single-ranging extends the feasible distance and enhances re-capture capability under visual degradation. During estimation, a dimension-reduced estimator fuses multi-source measurements based on polynomial approximation with an extended sliding window, balancing computational efficiency and redundancy. Considering different sensor fidelities, an adaptive sliding confidence evaluation algorithm is implemented to assess measurement quality and dynamically adjust the weighting parameters based on moving variance. Finally, extensive experiments under conditions such as smoke interference, illumination variation, obstacle occlusion, prolonged visual loss, and extended operating range demonstrate that the proposed approach achieves robust online localization, with an average root mean square error of approximately 0.09 m, while maintaining resilience to capture loss and sensor failures.

</details>


### [42] [E-SDS: Environment-aware See it, Do it, Sorted - Automated Environment-Aware Reinforcement Learning for Humanoid Locomotion](https://arxiv.org/abs/2512.16446)
*Enis Yalcin,Joshua O'Hara,Maria Stamatopoulou,Chengxu Zhou,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: E-SDS框架通过整合视觉语言模型和实时地形感知，自动生成奖励函数来训练人形机器人适应复杂地形的运动策略，显著减少人工设计时间并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的奖励设计方法缺乏环境感知能力，无法处理复杂地形导航。传统手动设计奖励函数耗时且效果有限，需要自动化且具备环境感知能力的解决方案。

Method: 提出E-SDS框架，整合视觉语言模型与实时地形传感器分析，基于示例视频自动生成奖励函数，训练具备环境感知能力的运动策略。

Result: 在Unitree G1人形机器人上测试四种地形（简单、间隙、障碍、楼梯），E-SDS首次实现成功下楼梯，而手动设计或非感知基线方法均失败。在所有地形中，速度跟踪误差减少51.9-82.6%，奖励设计时间从数天缩短至2小时内。

Conclusion: E-SDS框架通过环境感知的自动化奖励设计，显著减少了人工工作量，同时产生了更鲁棒和能力强的人形机器人运动策略，为复杂地形导航提供了有效解决方案。

Abstract: Vision-language models (VLMs) show promise in automating reward design in humanoid locomotion, which could eliminate the need for tedious manual engineering. However, current VLM-based methods are essentially "blind", as they lack the environmental perception required to navigate complex terrain. We present E-SDS (Environment-aware See it, Do it, Sorted), a framework that closes this perception gap. E-SDS integrates VLMs with real-time terrain sensor analysis to automatically generate reward functions that facilitate training of robust perceptive locomotion policies, grounded by example videos. Evaluated on a Unitree G1 humanoid across four distinct terrains (simple, gaps, obstacles, stairs), E-SDS uniquely enabled successful stair descent, while policies trained with manually-designed rewards or a non-perceptive automated baseline were unable to complete the task. In all terrains, E-SDS also reduced velocity tracking error by 51.9-82.6%. Our framework reduces the human effort of reward design from days to less than two hours while simultaneously producing more robust and capable locomotion policies.

</details>


### [43] [Single-View Shape Completion for Robotic Grasping in Clutter](https://arxiv.org/abs/2512.16449)
*Abhishek Kashyap,Yuxuan Yang,Henrik Andreasson,Todor Stoyanov*

Main category: cs.RO

TL;DR: 利用扩散模型从单视角深度观测进行类别级3D形状补全，提升杂乱场景中的抓取成功率


<details>
  <summary>Details</summary>
Motivation: 单视角相机只能捕捉物体的一面，加上杂乱场景的遮挡，导致观测几何不完整，抓取算法表现不佳

Method: 使用扩散模型从单视角部分深度观测进行类别级3D形状补全，重建完整物体几何，为抓取规划提供更丰富的上下文信息

Result: 在杂乱场景评估中，相比无形状补全的基线方法提升23%抓取成功率，相比现有形状补全方法提升19%

Conclusion: 通过扩散模型进行3D形状补全能有效提升杂乱场景中机器人抓取的成功率，为实际应用提供了更好的解决方案

Abstract: In vision-based robot manipulation, a single camera view can only capture one side of objects of interest, with additional occlusions in cluttered scenes further restricting visibility. As a result, the observed geometry is incomplete, and grasp estimation algorithms perform suboptimally. To address this limitation, we leverage diffusion models to perform category-level 3D shape completion from partial depth observations obtained from a single view, reconstructing complete object geometries to provide richer context for grasp planning. Our method focuses on common household items with diverse geometries, generating full 3D shapes that serve as input to downstream grasp inference networks. Unlike prior work, which primarily considers isolated objects or minimal clutter, we evaluate shape completion and grasping in realistic clutter scenarios with household objects. In preliminary evaluations on a cluttered scene, our approach consistently results in better grasp success rates than a naive baseline without shape completion by 23% and over a recent state of the art shape completion approach by 19%. Our code is available at https://amm.aass.oru.se/shape-completion-grasping/.

</details>


### [44] [AG-MPBS: a Mobility-Aware Prediction and Behavior-Based Scheduling Framework for Air-Ground Unmanned Systems](https://arxiv.org/abs/2512.16454)
*Tianhao Shao,Kaixing Zhao,Feng Liu,Lixin Yang,Bin Guo*

Main category: cs.RO

TL;DR: MPBS是一个面向无人机和无人车的可扩展任务招募框架，通过行为感知分类、时变马尔可夫移动性预测和动态优先级调度，实现高效的任务分配。


<details>
  <summary>Details</summary>
Motivation: 随着无人机和无人车在城市场景感知和应急响应等应用中日益重要，如何高效招募这些自主设备执行时间敏感任务成为关键挑战。

Method: MPBS框架包含三个核心模块：行为感知KNN分类器、时变马尔可夫移动性预测模型、以及考虑任务紧急性和基站性能的动态优先级调度机制。

Result: 在真实世界GeoLife数据集上的实验评估表明，MPBS显著提高了任务完成效率和资源利用率。

Conclusion: MPBS为无人系统提供了一个预测性、行为感知的智能协作调度解决方案。

Abstract: As unmanned systems such as Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) become increasingly important to applications like urban sensing and emergency response, efficiently recruiting these autonomous devices to perform time-sensitive tasks has become a critical challenge. This paper presents MPBS (Mobility-aware Prediction and Behavior-based Scheduling), a scalable task recruitment framework that treats each device as a recruitable "user". MPBS integrates three key modules: a behavior-aware KNN classifier, a time-varying Markov prediction model for forecasting device mobility, and a dynamic priority scheduling mechanism that considers task urgency and base station performance. By combining behavioral classification with spatiotemporal prediction, MPBS adaptively assigns tasks to the most suitable devices in real time. Experimental evaluations on the real-world GeoLife dataset show that MPBS significantly improves task completion efficiency and resource utilization. The proposed framework offers a predictive, behavior-aware solution for intelligent and collaborative scheduling in unmanned systems.

</details>


### [45] [Tri-Select: A Multi-Stage Visual Data Selection Framework for Mobile Visual Crowdsensing](https://arxiv.org/abs/2512.16469)
*Jiayu Zhang,Kaixing Zhao,Tianhao Shao,Bin Guo,Liang He*

Main category: cs.RO

TL;DR: Tri-Select是一个用于移动视觉众包的三阶段数据选择框架，通过元数据过滤、空间聚类和视觉特征选择来高效筛选冗余和低质量图像。


<details>
  <summary>Details</summary>
Motivation: 移动视觉众包收集的图像数据存在冗余和异质性，包括采集视角重叠、分辨率不一、用户行为多样等问题，需要高效的数据选择方法来提升数据集质量。

Method: 提出Tri-Select三阶段框架：1) 元数据过滤去除无关样本；2) 基于空间相似性的谱聚类组织候选图像；3) 基于最大独立集搜索的视觉特征引导选择，保留高质量代表性图像。

Result: 在真实世界和公开数据集上的实验表明，Tri-Select提高了选择效率和数据集质量，适合可扩展的众包应用。

Conclusion: Tri-Select能有效解决移动视觉众包中的冗余和异质性问题，为大规模环境监测提供了高效的数据选择方案。

Abstract: Mobile visual crowdsensing enables large-scale, fine-grained environmental monitoring through the collection of images from distributed mobile devices. However, the resulting data is often redundant and heterogeneous due to overlapping acquisition perspectives, varying resolutions, and diverse user behaviors. To address these challenges, this paper proposes Tri-Select, a multi-stage visual data selection framework that efficiently filters redundant and low-quality images. Tri-Select operates in three stages: (1) metadata-based filtering to discard irrelevant samples; (2) spatial similarity-based spectral clustering to organize candidate images; and (3) a visual-feature-guided selection based on maximum independent set search to retain high-quality, representative images. Experiments on real-world and public datasets demonstrate that Tri-Select improves both selection efficiency and dataset quality, making it well-suited for scalable crowdsensing applications.

</details>


### [46] [A Formal Modular Synthesis Approach for the Coordination of 3-D Robotic Construction with Multi-robots](https://arxiv.org/abs/2512.16555)
*Marcelo Rosa,José E. R. Cury,Fabio L. Baldissera*

Main category: cs.RO

TL;DR: 基于监控控制理论的多机器人协同构建3D结构方法


<details>
  <summary>Details</summary>
Motivation: 解决多个移动机器人协同自主构建预定3D结构的协调问题，确保系统正确性和可靠性

Method: 采用监控控制理论，从单个机器人和目标结构的模型合成正确构造的反应式控制器（监督器），然后将该监督器复制到其他机器人

Result: 通过该方法能够确保所有机器人协同完成目标结构的构建

Conclusion: 基于监控控制理论的监督器复制方法为多机器人协同构建3D结构提供了一种正确构造的解决方案

Abstract: In this paper, we deal with the problem of coordinating multiple robots to build 3-D structures. This problem consists of a set of mobile robots that interact with each other in order to autonomously build a predefined 3-D structure. Our approach is based on Supervisory Control Theory, and it allows us to synthesize from models that represent a single robot and the target structure a correct-by-construction reactive controller, called supervisor. When this supervisor is replicated for the other robots, then the target structure can be completed by all robots

</details>


### [47] [Olaf: Bringing an Animated Character to Life in the Physical World](https://arxiv.org/abs/2512.16705)
*David Müller,Espen Knoop,Dario Mylonopoulos,Agon Serifi,Michael A. Hopkins,Ruben Grandia,Moritz Bächer*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习和动画参考的物理角色控制方法，通过机械设计创新（隐藏式不对称腿部、球形/平面连杆机构）和温度感知控制策略，实现了动画角色Olaf在现实世界中的高可信度物理实现。


<details>
  <summary>Details</summary>
Motivation: 动画角色通常以非物理方式运动且比例与典型行走机器人差异巨大，这为机械设计和风格化运动控制提供了创新平台。研究旨在将动画角色Olaf带入物理世界，实现高可信度的物理表现。

Method: 1) 机械设计：隐藏两个不对称腿部于软泡沫裙下，使用球形和平面连杆机构在手臂、嘴巴和眼睛中安装执行器；2) 控制方法：基于强化学习，以动画参考为指导，引入减少冲击噪声的奖励函数；3) 热管理：将温度值作为策略输入，引入新奖励函数防止执行器过热。

Result: 在仿真和硬件上验证了建模的有效性，展示了服装机器人角色前所未有的可信度水平，成功实现了动画角色Olaf的物理实现。

Conclusion: 通过创新的机械设计和温度感知强化学习控制，成功将动画角色Olaf带入物理世界，实现了高可信度的物理表现，为风格化机器人角色的实现提供了有效方法。

Abstract: Animated characters often move in non-physical ways and have proportions that are far from a typical walking robot. This provides an ideal platform for innovation in both mechanical design and stylized motion control. In this paper, we bring Olaf to life in the physical world, relying on reinforcement learning guided by animation references for control. To create the illusion of Olaf's feet moving along his body, we hide two asymmetric legs under a soft foam skirt. To fit actuators inside the character, we use spherical and planar linkages in the arms, mouth, and eyes. Because the walk cycle results in harsh contact sounds, we introduce additional rewards that noticeably reduce impact noise. The large head, driven by small actuators in the character's slim neck, creates a risk of overheating, amplified by the costume. To keep actuators from overheating, we feed temperature values as additional inputs to policies, introducing new rewards to keep them within bounds. We validate the efficacy of our modeling in simulation and on hardware, demonstrating an unmatched level of believability for a costumed robotic character.

</details>


### [48] [VERM: Leveraging Foundation Models to Create a Virtual Eye for Efficient 3D Robotic Manipulation](https://arxiv.org/abs/2512.16724)
*Yixiang Chen,Yan Huang,Keji He,Peiyan Li,Liang Wang*

Main category: cs.RO

TL;DR: VERM方法通过利用基础模型知识从3D点云想象虚拟任务自适应视角，过滤多摄像头冗余信息，提升机器人3D操作任务的效率和性能


<details>
  <summary>Details</summary>
Motivation: 多摄像头设置引入大量冗余和无关信息，增加计算成本，迫使模型花费额外训练时间提取关键任务相关细节

Method: 提出VERM方法，利用基础模型知识从构建的3D点云想象虚拟任务自适应视角；设计深度感知模块和动态粗到细处理流程

Result: 在RLBench仿真基准和真实世界评估中超越先前最先进方法，实现1.89倍训练加速和1.54倍推理加速

Conclusion: VERM方法能有效过滤冗余信息，准确提取任务相关特征，促进3D动作规划和精细操作，显著提升效率和性能

Abstract: When performing 3D manipulation tasks, robots have to execute action planning based on perceptions from multiple fixed cameras. The multi-camera setup introduces substantial redundancy and irrelevant information, which increases computational costs and forces the model to spend extra training time extracting crucial task-relevant details. To filter out redundant information and accurately extract task-relevant features, we propose the VERM (Virtual Eye for Robotic Manipulation) method, leveraging the knowledge in foundation models to imagine a virtual task-adaptive view from the constructed 3D point cloud, which efficiently captures necessary information and mitigates occlusion. To facilitate 3D action planning and fine-grained manipulation, we further design a depth-aware module and a dynamic coarse-to-fine procedure. Extensive experimental results on both simulation benchmark RLBench and real-world evaluations demonstrate the effectiveness of our method, surpassing previous state-of-the-art methods while achieving 1.89x speedup in training time and 1.54x speedup in inference speed. More results can be found on our project website at https://verm-ral.github.io .

</details>


### [49] [Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future](https://arxiv.org/abs/2512.16760)
*Tianshuai Hu,Xiaolu Liu,Song Wang,Yiyao Zhu,Ao Liang,Lingdong Kong,Guoyang Zhao,Zeying Gong,Jun Cen,Zhiyu Huang,Xiaoshuai Hao,Linfeng Li,Hang Song,Xiangtai Li,Jun Ma,Shaojie Shen,Jianke Zhu,Dacheng Tao,Ziwei Liu,Junwei Liang*

Main category: cs.RO

TL;DR: 本文系统梳理了自动驾驶领域从传统模块化方法到Vision-Language-Action (VLA)框架的演进，将现有VLA方法分为端到端和双系统两大范式，并总结了相关数据集、基准和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶的模块化"感知-决策-动作"流水线存在手工接口、规则组件在复杂场景中失效、感知误差级联传播等问题。Vision-Action模型虽然直接学习视觉到动作的映射，但缺乏可解释性、对分布偏移敏感、缺少结构化推理和指令跟随能力。大型语言模型和多模态学习的进展推动了Vision-Language-Action框架的发展，旨在实现更可解释、泛化能力强且与人类对齐的驾驶策略。

Method: 本文采用结构化分析方法：1) 追溯从早期VA方法到现代VLA框架的演进历程；2) 将现有VLA方法组织为两大主要范式：端到端VLA（单一模型集成感知、推理和规划）和双系统VLA（慢速审议通过VLM与快速安全关键执行通过规划器分离）；3) 在这些范式中进一步区分文本vs.数值动作生成器、显式vs.隐式指导机制等子类；4) 总结评估VLA驾驶系统的代表性数据集和基准。

Result: 建立了自动驾驶VLA领域的系统化分类框架，明确了两种主要范式及其子类，为研究人员提供了清晰的领域地图。总结了当前可用的评估资源，为后续研究提供了基础。

Conclusion: VLA框架为自动驾驶提供了实现更可解释、泛化能力强且与人类对齐策略的途径。本文建立了推进人类兼容自动驾驶系统的连贯基础，同时指出了鲁棒性、可解释性和指令保真度等关键挑战和开放方向。

Abstract: Autonomous driving has long relied on modular "Perception-Decision-Action" pipelines, where hand-crafted interfaces and rule-based components often break down in complex or long-tailed scenarios. Their cascaded design further propagates perception errors, degrading downstream planning and control. Vision-Action (VA) models address some limitations by learning direct mappings from visual inputs to actions, but they remain opaque, sensitive to distribution shifts, and lack structured reasoning or instruction-following capabilities. Recent progress in Large Language Models (LLMs) and multimodal learning has motivated the emergence of Vision-Language-Action (VLA) frameworks, which integrate perception with language-grounded decision making. By unifying visual understanding, linguistic reasoning, and actionable outputs, VLAs offer a pathway toward more interpretable, generalizable, and human-aligned driving policies. This work provides a structured characterization of the emerging VLA landscape for autonomous driving. We trace the evolution from early VA approaches to modern VLA frameworks and organize existing methods into two principal paradigms: End-to-End VLA, which integrates perception, reasoning, and planning within a single model, and Dual-System VLA, which separates slow deliberation (via VLMs) from fast, safety-critical execution (via planners). Within these paradigms, we further distinguish subclasses such as textual vs. numerical action generators and explicit vs. implicit guidance mechanisms. We also summarize representative datasets and benchmarks for evaluating VLA-based driving systems and highlight key challenges and open directions, including robustness, interpretability, and instruction fidelity. Overall, this work aims to establish a coherent foundation for advancing human-compatible autonomous driving systems.

</details>


### [50] [PhysBrain: Human Egocentric Data as a Bridge from Vision Language Models to Physical Intelligence](https://arxiv.org/abs/2512.16793)
*Xiaopeng Lin,Shijie Lian,Bin Yu,Ruoqi Yang,Changti Wu,Yuzhuo Miao,Yurun Jin,Yukun Shi,Cong Huang,Bojun Cheng,Kai Chen*

Main category: cs.RO

TL;DR: 提出E2E-3M数据集和PhysBrain模型，通过将人类第一人称视频转化为结构化监督数据，解决机器人视觉语言模型在自我中心视角下的泛化问题


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型主要基于第三人称数据训练，与类人机器人的自我中心视角存在根本性不匹配。机器人自我中心数据收集成本高且多样性有限，而大规模人类第一人称视频提供了可扩展的替代方案

Method: 提出Egocentric2Embodiment转换流程，将原始第一人称视频转化为多层次、模式驱动的视觉问答监督数据，强调证据基础和时序一致性，构建E2E-3M数据集，并训练出自我中心感知的PhysBrain模型

Result: PhysBrain在EgoThink任务上表现出显著改进的自我中心理解能力，特别是在规划方面。作为自我中心感知的初始化模型，能够实现更高效的视觉语言模型微调和更高的SimplerEnv成功率（53.9%）

Conclusion: 通过将人类第一人称监督数据转化为机器人控制训练，证明了从人类自我中心监督到下游机器人控制的有效迁移，为解决机器人物理智能的泛化问题提供了新途径

Abstract: Robotic generalization relies on physical intelligence: the ability to reason about state changes, contact-rich interactions, and long-horizon planning under egocentric perception and action. However, most VLMs are trained primarily on third-person data, creating a fundamental viewpoint mismatch for humanoid robots. Scaling robot egocentric data collection remains impractical due to high cost and limited diversity, whereas large-scale human egocentric videos offer a scalable alternative that naturally capture rich interaction context and causal structure. The key challenge is to convert raw egocentric videos into structured and reliable embodiment training supervision. Accordingly, we propose an Egocentric2Embodiment translation pipeline that transforms first-person videos into multi-level, schema-driven VQA supervision with enforced evidence grounding and temporal consistency, enabling the construction of the Egocentric2Embodiment dataset (E2E-3M) at scale. An egocentric-aware embodied brain, termed PhysBrain, is obtained by training on the E2E-3M dataset. PhysBrain exhibits substantially improved egocentric understanding, particularly for planning on EgoThink. It provides an egocentric-aware initialization that enables more sample-efficient VLA fine-tuning and higher SimplerEnv success rates (53.9\%), demonstrating effective transfer from human egocentric supervision to downstream robot control.

</details>


### [51] [ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning](https://arxiv.org/abs/2512.16861)
*Zihan Zhou,Animesh Garg,Ajay Mandlekar,Caelan Garrett*

Main category: cs.RO

TL;DR: ReinforceGen是一个结合任务分解、数据生成、模仿学习和运动规划的系统，通过强化学习微调来提升长时程操作任务的性能


<details>
  <summary>Details</summary>
Motivation: 长时程操作一直是机器人领域的长期挑战，需要解决复杂任务的分解和执行问题

Method: 1. 将任务分解为多个局部技能；2. 通过运动规划连接技能；3. 基于10个人类演示生成数据集进行模仿学习；4. 通过在线适应和强化学习进行微调

Result: 在Robosuite数据集上，ReinforceGen在最高重置范围设置下达到80%的成功率；消融研究表明微调方法贡献了89%的平均性能提升

Conclusion: ReinforceGen通过结合任务分解、模仿学习和强化学习微调，有效解决了长时程操作问题，在基准测试中表现出色

Abstract: Long-horizon manipulation has been a long-standing challenge in the robotics community. We propose ReinforceGen, a system that combines task decomposition, data generation, imitation learning, and motion planning to form an initial solution, and improves each component through reinforcement-learning-based fine-tuning. ReinforceGen first segments the task into multiple localized skills, which are connected through motion planning. The skills and motion planning targets are trained with imitation learning on a dataset generated from 10 human demonstrations, and then fine-tuned through online adaptation and reinforcement learning. When benchmarked on the Robosuite dataset, ReinforceGen reaches 80% success rate on all tasks with visuomotor controls in the highest reset range setting. Additional ablation studies show that our fine-tuning approaches contributes to an 89% average performance increase. More results and videos available in https://reinforcegen.github.io/

</details>


### [52] [PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies](https://arxiv.org/abs/2512.16881)
*Arhan Jain,Mingtong Zhang,Kanav Arora,William Chen,Marcel Torne,Muhammad Zubair Irshad,Sergey Zakharov,Yue Wang,Sergey Levine,Chelsea Finn,Wei-Chiu Ma,Dhruv Shah,Abhishek Gupta,Karl Pertsch*

Main category: cs.RO

TL;DR: PolaRiS是一个可扩展的真实到仿真框架，通过神经重建方法将真实场景视频转换为交互式仿真环境，用于机器人策略评估，相比现有仿真基准能更好地关联真实世界性能。


<details>
  <summary>Details</summary>
Motivation: 机器人学习研究面临准确测量和比较策略性能的挑战，真实世界评估存在随机性、可重复性差和耗时等问题。现有仿真基准与真实世界存在视觉和物理领域差距，无法可靠指导策略改进，且构建真实多样的仿真环境需要大量人工和专业经验。

Method: 提出PolaRiS框架：1）利用神经重建方法将真实场景的短视频扫描转换为交互式仿真环境；2）开发简单的仿真数据协同训练方法，弥合剩余的真实到仿真差距，实现未见仿真环境的零样本评估。

Result: 通过仿真与真实世界的广泛配对评估，证明PolaRiS评估相比现有仿真基准，与真实世界通用策略性能有更强的相关性。其简单性也支持快速创建多样化的仿真环境。

Conclusion: PolaRiS为下一代机器人基础模型迈出了分布式和民主化评估的一步，通过真实到仿真转换实现了高保真度的机器人策略评估。

Abstract: A significant challenge for robot learning research is our ability to accurately measure and compare the performance of robot policies. Benchmarking in robotics is historically challenging due to the stochasticity, reproducibility, and time-consuming nature of real-world rollouts. This challenge is exacerbated for recent generalist policies, which has to be evaluated across a wide variety of scenes and tasks. Evaluation in simulation offers a scalable complement to real world evaluations, but the visual and physical domain gap between existing simulation benchmarks and the real world has made them an unreliable signal for policy improvement. Furthermore, building realistic and diverse simulated environments has traditionally required significant human effort and expertise. To bridge the gap, we introduce Policy Evaluation and Environment Reconstruction in Simulation (PolaRiS), a scalable real-to-sim framework for high-fidelity simulated robot evaluation. PolaRiS utilizes neural reconstruction methods to turn short video scans of real-world scenes into interactive simulation environments. Additionally, we develop a simple simulation data co-training recipe that bridges remaining real-to-sim gaps and enables zero-shot evaluation in unseen simulation environments. Through extensive paired evaluations between simulation and the real world, we demonstrate that PolaRiS evaluations provide a much stronger correlation to real world generalist policy performance than existing simulated benchmarks. Its simplicity also enables rapid creation of diverse simulated environments. As such, this work takes a step towards distributed and democratized evaluation for the next generation of robotic foundation models.

</details>


### [53] [Sceniris: A Fast Procedural Scene Generation Framework](https://arxiv.org/abs/2512.16896)
*Jinghuan Shang,Harsh Patel,Ran Gong,Karl Schmeckpeper*

Main category: cs.RO

TL;DR: Sceniris是一个高效的程序化场景生成框架，用于快速生成大规模、无碰撞的场景变体，相比现有方法实现234倍加速


<details>
  <summary>Details</summary>
Motivation: 现有程序化生成方法输出吞吐量低，成为扩展数据集创建的主要瓶颈，需要高效生成大规模、无碰撞的场景变体

Method: 采用批量采样和cuRobo中的快速碰撞检测，扩展了对象间空间关系支持，提供可选的机器人可达性检查

Result: 相比Scene Synthesizer方法，Sceniris实现了至少234倍的加速，能够高效生成大规模、无碰撞的场景变体

Conclusion: Sceniris是一个高效的程序化场景生成框架，显著加速了大规模场景数据集的创建，支持物理AI和生成模型的发展

Abstract: Synthetic 3D scenes are essential for developing Physical AI and generative models. Existing procedural generation methods often have low output throughput, creating a significant bottleneck in scaling up dataset creation. In this work, we introduce Sceniris, a highly efficient procedural scene generation framework for rapidly generating large-scale, collision-free scene variations. Sceniris also provides an optional robot reachability check, providing manipulation-feasible scenes for robot tasks. Sceniris is designed for maximum efficiency by addressing the primary performance limitations of the prior method, Scene Synthesizer. Leveraging batch sampling and faster collision checking in cuRobo, Sceniris achieves at least 234x speed-up over Scene Synthesizer. Sceniris also expands the object-wise spatial relationships available in prior work to support diverse scene requirements. Our code is available at https://github.com/rai-inst/sceniris

</details>
