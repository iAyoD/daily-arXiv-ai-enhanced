<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ERUPT: An Open Toolkit for Interfacing with Robot Motion Planners in Extended Reality](https://arxiv.org/abs/2510.02464)
*Isaac Ngui,Courtney McBeth,André Santos,Grace He,Katherine J. Mimnaugh,James D. Motes,Luciano Soares,Marco Morales,Nancy M. Amato*

Main category: cs.RO

TL;DR: ERUPT是一个扩展现实(XR)系统，用于交互式运动规划，允许用户在规划机器人路径时创建和动态重新配置环境。


<details>
  <summary>Details</summary>
Motivation: 传统机器人路径规划使用鼠标键盘在二维屏幕上操作，缺乏空间理解和自然交互能力。XR技术可以提供更好的空间感知和更自然的交互方式。

Method: 系统集成了MoveIt操纵规划框架，提供多种交互模式，允许用户在虚拟或增强现实中修改环境对象、与虚拟机器人交互，并可视化机器人运动路径。

Result: 用户可以在虚拟空间中安全地可视化机器人运动，确保期望行为并避免碰撞，然后将规划好的路径部署到真实世界的物理机器人上。

Conclusion: ERUPT系统通过XR技术显著改善了机器人运动规划的用户体验，提供了更直观、安全的规划环境，并实现了虚拟规划到物理部署的无缝衔接。

Abstract: We propose the Extended Reality Universal Planning Toolkit (ERUPT), an
extended reality (XR) system for interactive motion planning. Our system allows
users to create and dynamically reconfigure environments while they plan robot
paths. In immersive three-dimensional XR environments, users gain a greater
spatial understanding. XR also unlocks a broader range of natural interaction
capabilities, allowing users to grab and adjust objects in the environment
similarly to the real world, rather than using a mouse and keyboard with the
scene projected onto a two-dimensional computer screen. Our system integrates
with MoveIt, a manipulation planning framework, allowing users to send motion
planning requests and visualize the resulting robot paths in virtual or
augmented reality. We provide a broad range of interaction modalities, allowing
users to modify objects in the environment and interact with a virtual robot.
Our system allows operators to visualize robot motions, ensuring desired
behavior as it moves throughout the environment, without risk of collisions
within a virtual space, and to then deploy planned paths on physical robots in
the real world.

</details>


### [2] [SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting](https://arxiv.org/abs/2510.02469)
*Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang*

Main category: cs.RO

TL;DR: SIMSplat是一个基于语言对齐高斯泼溅的预测性驾驶场景编辑器，支持通过自然语言提示直观地操作驾驶场景，能够添加新物体和修改车辆、行人轨迹，并整合多智能体运动预测生成逼真的交互。


<details>
  <summary>Details</summary>
Motivation: 现有的驾驶场景编辑框架由于编辑能力有限，难以高效生成逼真场景。需要开发能够直观操作且支持精确灵活编辑的方法。

Method: 使用语言对齐的高斯泼溅技术重建驾驶场景，支持自然语言提示操作，提供详细的对象级编辑功能，包括添加新物体和修改轨迹，并整合多智能体运动预测进行路径优化。

Result: 在Waymo数据集上的实验表明，SIMSplat具有广泛的编辑能力和跨场景适应性。

Conclusion: SIMSplat通过语言对齐的高斯泼溅技术实现了直观、精确的驾驶场景编辑，能够生成逼真的交互场景，为驾驶模拟提供了有效的解决方案。

Abstract: Driving scene manipulation with sensor data is emerging as a promising
alternative to traditional virtual driving simulators. However, existing
frameworks struggle to generate realistic scenarios efficiently due to limited
editing capabilities. To address these challenges, we present SIMSplat, a
predictive driving scene editor with language-aligned Gaussian splatting. As a
language-controlled editor, SIMSplat enables intuitive manipulation using
natural language prompts. By aligning language with Gaussian-reconstructed
scenes, it further supports direct querying of road objects, allowing precise
and flexible editing. Our method provides detailed object-level editing,
including adding new objects and modifying the trajectories of both vehicles
and pedestrians, while also incorporating predictive path refinement through
multi-agent motion prediction to generate realistic interactions among all
agents in the scene. Experiments on the Waymo dataset demonstrate SIMSplat's
extensive editing capabilities and adaptability across a wide range of
scenarios. Project page: https://sungyeonparkk.github.io/simsplat/

</details>


### [3] [U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation](https://arxiv.org/abs/2510.02526)
*Anamika J H,Anujith Muraleedharan*

Main category: cs.RO

TL;DR: U-LAG是一个中执行目标重定向层，能够在感知延迟的情况下重新调整任务目标，保持底层控制器不变。通过UAR-PF不确定性感知重定向器处理感知滞后下的物体姿态分布，在Shift x Lag压力测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 机器人在变化环境中操作时，必须处理延迟、噪声或过时的感知数据，需要能够在执行过程中适应环境变化的目标重定向方法。

Method: 提出U-LAG框架，包括UAR-PF不确定性感知重定向器，维护物体姿态分布并选择最大化预期进度的目标。使用可插拔的重定向接口，在PyBullet/PandaGym中进行可复现的Shift x Lag压力测试。

Result: 在0-10厘米偏移和0-400毫秒延迟条件下，UAR-PF和ICP相比无重定向基线表现更优，实现更高成功率、更少末端执行器移动和更少中止，操作安全措施进一步提高了稳定性。

Conclusion: U-LAG提供了一种有效的目标重定向方法，能够优雅地处理感知延迟和环境变化，在多种操作任务中表现出良好的适应性。

Abstract: Robots manipulating in changing environments must act on percepts that are
late, noisy, or stale. We present U-LAG, a mid-execution goal-retargeting layer
that leaves the low-level controller unchanged while re-aiming task goals
(pre-contact, contact, post) as new observations arrive. Unlike motion
retargeting or generic visual servoing, U-LAG treats in-flight goal re-aiming
as a first-class, pluggable module between perception and control. Our main
technical contribution is UAR-PF, an uncertainty-aware retargeter that
maintains a distribution over object pose under sensing lag and selects goals
that maximize expected progress. We instantiate a reproducible Shift x Lag
stress test in PyBullet/PandaGym for pick, push, stacking, and peg insertion,
where the object undergoes abrupt in-plane shifts while synthetic perception
lag is injected during approach. Across 0-10 cm shifts and 0-400 ms lags,
UAR-PF and ICP degrade gracefully relative to a no-retarget baseline, achieving
higher success with modest end-effector travel and fewer aborts; simple
operational safeguards further improve stability. Contributions: (1) UAR-PF for
lag-adaptive, uncertainty-aware goal retargeting; (2) a pluggable retargeting
interface; and (3) a reproducible Shift x Lag benchmark with evaluation on
pick, push, stacking, and peg insertion.

</details>


### [4] [A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models](https://arxiv.org/abs/2510.02538)
*Yilin Wang,Shangzhe Li,Haoyi Niu,Zhiao Huang,Weitong Zhang,Hao Su*

Main category: cs.RO

TL;DR: 提出了一种利用机器人模拟器进行在线模仿学习的sim-to-real框架，通过世界模型结合在线预训练和离线微调，解决了离线模仿学习中数据覆盖不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的离线模仿学习方法在真实世界专家数据有限的情况下，面临数据覆盖不足和性能严重下降的问题。

Method: 基于世界模型的sim-to-real框架，结合在线模仿预训练和离线微调，利用在线交互缓解数据覆盖限制。

Result: 在sim-to-sim转移中成功率提高至少31.7%，在sim-to-real转移中提高至少23.3%，优于现有离线模仿学习基线。

Conclusion: 该方法通过在线交互有效缓解了离线模仿学习的数据覆盖限制，提高了鲁棒性和泛化能力，在领域转移中表现优异。

Abstract: We are interested in solving the problem of imitation learning with a limited
amount of real-world expert data. Existing offline imitation methods often
struggle with poor data coverage and severe performance degradation. We propose
a solution that leverages robot simulators to achieve online imitation
learning. Our sim-to-real framework is based on world models and combines
online imitation pretraining with offline finetuning. By leveraging online
interactions, our approach alleviates the data coverage limitations of offline
methods, leading to improved robustness and reduced performance degradation
during finetuning. It also enhances generalization during domain transfer. Our
empirical results demonstrate its effectiveness, improving success rates by at
least 31.7% in sim-to-sim transfer and 23.3% in sim-to-real transfer over
existing offline imitation learning baselines.

</details>


### [5] [Efficient Optimal Path Planning in Dynamic Environments Using Koopman MPC](https://arxiv.org/abs/2510.02584)
*Mohammad Abtahi,Navid Mojahed,Shima Nazari*

Main category: cs.RO

TL;DR: 基于Koopman算子的数据驱动模型预测控制框架，用于移动机器人在动态环境中的导航，通过双线性Koopman模型实现非线性最优控制问题的高效线性化。


<details>
  <summary>Details</summary>
Motivation: 传统Koopman方法仅关注系统动力学的线性化，而本文旨在为包含非线性机器人动力学和避障约束的最优路径规划问题寻找全局线性表示。

Method: 使用扩展动态模态分解从输入状态数据中识别线性和双线性Koopman实现，在提升空间中制定二次规划问题，并在MPC框架中确定最优机器人动作。

Result: 双线性Koopman模型能准确捕捉非线性状态-输入耦合和避障所需的二次项，而线性实现无法做到。该方法比在原始状态空间求解的非线性MPC快320倍。

Conclusion: 双线性Koopman实现具有将高度非线性最优控制问题线性化的潜力，同时保持与线性问题相似的计算效率。

Abstract: This paper presents a data-driven model predictive control framework for
mobile robots navigating in dynamic environments, leveraging Koopman operator
theory. Unlike the conventional Koopman-based approaches that focus on the
linearization of system dynamics only, our work focuses on finding a global
linear representation for the optimal path planning problem that includes both
the nonlinear robot dynamics and collision-avoidance constraints. We deploy
extended dynamic mode decomposition to identify linear and bilinear Koopman
realizations from input-state data. Our open-loop analysis demonstrates that
only the bilinear Koopman model can accurately capture nonlinear state-input
couplings and quadratic terms essential for collision avoidance, whereas linear
realizations fail to do so. We formulate a quadratic program for the robot path
planning in the presence of moving obstacles in the lifted space and determine
the optimal robot action in an MPC framework. Our approach is capable of
finding the safe optimal action 320 times faster than a nonlinear MPC
counterpart that solves the path planning problem in the original state space.
Our work highlights the potential of bilinear Koopman realizations for
linearization of highly nonlinear optimal control problems subject to nonlinear
state and input constraints to achieve computational efficiency similar to
linear problems.

</details>


### [6] [SubSense: VR-Haptic and Motor Feedback for Immersive Control in Subsea Telerobotics](https://arxiv.org/abs/2510.02594)
*Ruo Chen,David Blow,Adnan Abdullah,Md Jahidul Islam*

Main category: cs.RO

TL;DR: 提出SubSense框架，结合VR触觉反馈增强水下ROV远程操作，通过非侵入式反馈接口和VR平台提升操作者在复杂水下环境中的情境感知和任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统ROV远程操作依赖低分辨率2D摄像头，缺乏沉浸感和感官反馈，在复杂水下环境中降低了情境感知能力。

Method: 开发SubSense VR-触觉框架，包含与操作者手套配对的非侵入式反馈接口，提供触觉反馈和抓取状态，并集成端到端软件管理控制输入和通过VR平台显示沉浸式摄像头视图。

Result: 通过综合实验和用户研究验证系统有效性，相比传统远程操作界面，在精细操作任务中表现更佳。

Conclusion: 多感官反馈在沉浸式虚拟环境中具有显著提升远程情境感知和任务性能的潜力，为现场ROV操作提供更直观和易用的解决方案。

Abstract: This paper investigates the integration of haptic feedback and virtual
reality (VR) control interfaces to enhance teleoperation and telemanipulation
of underwater ROVs (remotely operated vehicles). Traditional ROV teleoperation
relies on low-resolution 2D camera feeds and lacks immersive and sensory
feedback, which diminishes situational awareness in complex subsea
environments. We propose SubSense -- a novel VR-Haptic framework incorporating
a non-invasive feedback interface to an otherwise 1-DOF (degree of freedom)
manipulator, which is paired with the teleoperator's glove to provide haptic
feedback and grasp status. Additionally, our framework integrates end-to-end
software for managing control inputs and displaying immersive camera views
through a VR platform. We validate the system through comprehensive experiments
and user studies, demonstrating its effectiveness over conventional
teleoperation interfaces, particularly for delicate manipulation tasks. Our
results highlight the potential of multisensory feedback in immersive virtual
environments to significantly improve remote situational awareness and mission
performance, offering more intuitive and accessible ROV operations in the
field.

</details>


### [7] [UMI-on-Air: Embodiment-Aware Guidance for Embodiment-Agnostic Visuomotor Policies](https://arxiv.org/abs/2510.02614)
*Harsh Gupta,Xiaofeng Guo,Huy Ha,Chuer Pan,Muqing Cao,Dongjae Lee,Sebastian Sherer,Shuran Song,Guanya Shi*

Main category: cs.RO

TL;DR: UMI-on-Air是一个框架，用于将手持夹爪收集的人类演示策略部署到受约束的机器人平台（如空中机械臂）。通过结合高层策略和低层特定控制器，实现动态可行的轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 解决从无约束人类演示到受约束机器人平台部署时的控制和动态不匹配问题，避免分布外行为和执行失败。

Method: 提出Embodiment-Aware Diffusion Policy (EADP)，在推理时将高层UMI策略与低层特定控制器耦合，通过控制器跟踪成本的梯度反馈引导扩散采样过程。

Result: 在多个长视野和高精度空中操作任务中，相比无引导扩散基线，显示出更高的成功率、效率和抗干扰鲁棒性。

Conclusion: 该方法为在不同（即使是高度受约束的）机器人平台上扩展通用操作技能提供了实用途径。

Abstract: We introduce UMI-on-Air, a framework for embodiment-aware deployment of
embodiment-agnostic manipulation policies. Our approach leverages diverse,
unconstrained human demonstrations collected with a handheld gripper (UMI) to
train generalizable visuomotor policies. A central challenge in transferring
these policies to constrained robotic embodiments-such as aerial
manipulators-is the mismatch in control and robot dynamics, which often leads
to out-of-distribution behaviors and poor execution. To address this, we
propose Embodiment-Aware Diffusion Policy (EADP), which couples a high-level
UMI policy with a low-level embodiment-specific controller at inference time.
By integrating gradient feedback from the controller's tracking cost into the
diffusion sampling process, our method steers trajectory generation towards
dynamically feasible modes tailored to the deployment embodiment. This enables
plug-and-play, embodiment-aware trajectory adaptation at test time. We validate
our approach on multiple long-horizon and high-precision aerial manipulation
tasks, showing improved success rates, efficiency, and robustness under
disturbances compared to unguided diffusion baselines. Finally, we demonstrate
deployment in previously unseen environments, using UMI demonstrations
collected in the wild, highlighting a practical pathway for scaling
generalizable manipulation skills across diverse-and even highly
constrained-embodiments. All code, data, and checkpoints will be publicly
released after acceptance. Result videos can be found at umi-on-air.github.io.

</details>


### [8] [RSV-SLAM: Toward Real-Time Semantic Visual SLAM in Indoor Dynamic Environments](https://arxiv.org/abs/2510.02616)
*Mobin Habibpour,Alireza Nemati,Ali Meghdari,Alireza Taheri,Shima Nazari*

Main category: cs.RO

TL;DR: 提出了一种针对动态环境的实时语义RGBD SLAM方法，通过深度学习语义信息检测移动物体，使用扩展卡尔曼滤波识别临时静止的动态物体，并生成网络填补动态物体区域，在TUM数据集上实现接近实时的竞争性定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉SLAM方法大多基于静态世界假设，在动态环境中表现不佳。需要开发能够有效处理动态物体的SLAM系统，特别是在社交机器人等应用场景中。

Method: 结合深度学习语义信息到SLAM系统，使用扩展卡尔曼滤波增强语义分割以识别临时静止的动态物体，实现生成网络填补动态物体区域，构建高度模块化的ROS平台框架。

Result: 在GTX1080上达到约22fps，在TUM数据集动态序列上的定位误差与最先进方法相当，同时保持接近实时的运行速度。

Conclusion: 该方法能够有效处理动态环境，在保持实时性能的同时提供准确的定位，源代码已公开。

Abstract: Simultaneous Localization and Mapping (SLAM) plays an important role in many
robotics fields, including social robots. Many of the available visual SLAM
methods are based on the assumption of a static world and struggle in dynamic
environments. In the current study, we introduce a real-time semantic RGBD SLAM
approach designed specifically for dynamic environments. Our proposed system
can effectively detect moving objects and maintain a static map to ensure
robust camera tracking. The key innovation of our approach is the incorporation
of deep learning-based semantic information into SLAM systems to mitigate the
impact of dynamic objects. Additionally, we enhance the semantic segmentation
process by integrating an Extended Kalman filter to identify dynamic objects
that may be temporarily idle. We have also implemented a generative network to
fill in the missing regions of input images belonging to dynamic objects. This
highly modular framework has been implemented on the ROS platform and can
achieve around 22 fps on a GTX1080. Benchmarking the developed pipeline on
dynamic sequences from the TUM dataset suggests that the proposed approach
delivers competitive localization error in comparison with the state-of-the-art
methods, all while operating in near real-time. The source code is publicly
available.

</details>


### [9] [Reachable Predictive Control: A Novel Control Algorithm for Nonlinear Systems with Unknown Dynamics and its Practical Applications](https://arxiv.org/abs/2510.02623)
*Taha Shafa,Yiming Meng,Melkior Ornik*

Main category: cs.RO

TL;DR: 提出一种无需系统动力学先验知识的算法，能够驱动系统跟踪分段线性轨迹，特别适用于系统动力学发生突变的关键故障场景。


<details>
  <summary>Details</summary>
Motivation: 针对系统动力学可能发生突变的关键故障场景，需要开发能够在不知道系统动力学的情况下仍能保证跟踪轨迹的算法。

Method: 算法首先施加小扰动局部学习当前状态附近的系统动力学，然后计算可证明可达的状态集合及其对应的最大增长率边界，最后合成控制动作将系统导航到保证可达的状态。

Result: 证明了即使不知道系统动力学，也能跟踪由分析证明可达的状态组成的一系列路径点。

Conclusion: 该算法能够在系统动力学未知的情况下，通过局部学习和可达性分析，实现分段线性轨迹的可靠跟踪。

Abstract: This paper proposes an algorithm capable of driving a system to follow a
piecewise linear trajectory without prior knowledge of the system dynamics.
Motivated by a critical failure scenario in which a system can experience an
abrupt change in its dynamics, we demonstrate that it is possible to follow a
set of waypoints comprised of states analytically proven to be reachable
despite not knowing the system dynamics. The proposed algorithm first applies
small perturbations to locally learn the system dynamics around the current
state, then computes the set of states that are provably reachable using the
locally learned dynamics and their corresponding maximum growth-rate bounds,
and finally synthesizes a control action that navigates the system to a
guaranteed reachable state.

</details>


### [10] [Multi-robot Rigid Formation Navigation via Synchronous Motion and Discrete-time Communication-Control Optimization](https://arxiv.org/abs/2510.02624)
*Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 提出了一种新颖的"hold-and-hit"通信控制框架，结合ROS平台实现多机器人刚性编队导航，能够有效应对无线网络延迟和数据包丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏能够在微处理器平台上通过无线网络执行复杂曲线路径多机器人编队导航的全面解决方案。

Method: 采用"hold-and-hit"通信控制框架与ROS平台集成，结合周期内优化方法，确保编队在非完整运动约束下精确跟踪曲线路径。

Result: 仿真和实验验证了方法的优越性：四机器人正方形编队沿S形路径导航时，间距误差在±0.069m内，角度误差在±19.15°内。

Conclusion: 提出的框架能够在挑战性场景下实现精确可靠的编队导航，优于现有方法。

Abstract: Rigid-formation navigation of multiple robots is essential for applications
such as cooperative transportation. This process involves a team of
collaborative robots maintaining a predefined geometric configuration, such as
a square, while in motion. For untethered collaborative motion, inter-robot
communication must be conducted through a wireless network. Notably, few
existing works offer a comprehensive solution for multi-robot formation
navigation executable on microprocessor platforms via wireless networks,
particularly for formations that must traverse complex curvilinear paths. To
address this gap, we introduce a novel "hold-and-hit" communication-control
framework designed to work seamlessly with the widely-used Robotic Operating
System (ROS) platform. The hold-and-hit framework synchronizes robot movements
in a manner robust against wireless network delays and packet loss. It operates
over discrete-time communication-control cycles, making it suitable for
implementation on contemporary microprocessors. Complementary to hold-and-hit,
we propose an intra-cycle optimization approach that enables rigid formations
to closely follow desired curvilinear paths, even under the nonholonomic
movement constraints inherent to most vehicular robots. The combination of
hold-and-hit and intra-cycle optimization ensures precise and reliable
navigation even in challenging scenarios. Simulations in a virtual environment
demonstrate the superiority of our method in maintaining a four-robot square
formation along an S-shaped path, outperforming two existing approaches.
Furthermore, real-world experiments validate the effectiveness of our
framework: the robots maintained an inter-distance error within $\pm 0.069m$
and an inter-angular orientation error within $\pm19.15^{\circ}$ while
navigating along an S-shaped path at a fixed linear velocity of $0.1 m/s$.

</details>


### [11] [A Trajectory Generator for High-Density Traffic and Diverse Agent-Interaction Scenarios](https://arxiv.org/abs/2510.02627)
*Ruining Yang,Yi Xu,Yixiao Chen,Yun Fu,Lili Su*

Main category: cs.RO

TL;DR: 提出了一种轨迹生成框架，通过结构化网格表示和基于行为的生成机制，增强场景密度和行为多样性，解决现有数据集中长尾分布问题。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹预测数据集存在明显的长尾分布问题，大多数样本来自低密度场景和简单直线驾驶行为，缺乏高密度场景和安全关键操作（如变道、超车、转弯）的充分表示，这阻碍了模型泛化并导致过于乐观的评估。

Method: 将连续道路环境转换为结构化网格表示，支持细粒度路径规划、显式冲突检测和多智能体协调。基于此表示，引入行为感知生成机制，结合基于规则的决策触发、Frenet-based轨迹平滑和动态可行性约束。

Result: 在Argoverse 1和Argoverse 2数据集上的大量实验表明，该方法显著提高了智能体密度和行为多样性，同时保持了运动真实性和场景级安全性。合成数据还使下游轨迹预测模型受益，在具有挑战性的高密度场景中提升了性能。

Conclusion: 提出的轨迹生成框架有效解决了轨迹预测数据集中的长尾分布问题，能够合成真实的高密度场景和复杂交互的罕见行为，为自动驾驶系统的安全评估和模型训练提供了更全面的数据支持。

Abstract: Accurate trajectory prediction is fundamental to autonomous driving, as it
underpins safe motion planning and collision avoidance in complex environments.
However, existing benchmark datasets suffer from a pronounced long-tail
distribution problem, with most samples drawn from low-density scenarios and
simple straight-driving behaviors. This underrepresentation of high-density
scenarios and safety critical maneuvers such as lane changes, overtaking and
turning is an obstacle to model generalization and leads to overly optimistic
evaluations. To address these challenges, we propose a novel trajectory
generation framework that simultaneously enhances scenarios density and
enriches behavioral diversity. Specifically, our approach converts continuous
road environments into a structured grid representation that supports
fine-grained path planning, explicit conflict detection, and multi-agent
coordination. Built upon this representation, we introduce behavior-aware
generation mechanisms that combine rule-based decision triggers with
Frenet-based trajectory smoothing and dynamic feasibility constraints. This
design allows us to synthesize realistic high-density scenarios and rare
behaviors with complex interactions that are often missing in real data.
Extensive experiments on the large-scale Argoverse 1 and Argoverse 2 datasets
demonstrate that our method significantly improves both agent density and
behavior diversity, while preserving motion realism and scenario-level safety.
Our synthetic data also benefits downstream trajectory prediction models and
enhances performance in challenging high-density scenarios.

</details>


### [12] [A $1000\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps](https://arxiv.org/abs/2510.02716)
*Junlin Zeng,Xin Zhang,Xiang Zhao,Yan Pan*

Main category: cs.RO

TL;DR: 本文提出iLLM-A*算法，通过优化A*搜索、增量学习生成高质量路径点、智能选择路径点等机制，相比LLM-A*实现了1000倍以上的加速、最高58.6%内存节省，并获得更短更稳定的路径。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法如A*、Dijkstra在大规模地图中搜索时间和内存消耗过高，而基于大语言模型的方法存在空间错觉和规划性能差的问题。LLM-A*虽然结合了LLM和A*，但在大规模地图中计算时间仍然很高。

Method: 设计iLLM-A*算法，包含三个核心机制：1) A*搜索优化 2) 增量学习方法让LLM生成高质量路径点 3) 智能选择适合A*规划的路径点

Result: 相比LLM-A*：1) 平均加速超过1000倍，极端情况下达2349.5倍 2) 最高节省58.6%内存 3) 路径长度更短且标准差更低

Conclusion: iLLM-A*通过精心设计的机制有效解决了LLM-A*的性能瓶颈，在大规模网格地图路径规划中实现了显著的性能提升。

Abstract: Path planning in grid maps, arising from various applications, has garnered
significant attention. Existing methods, such as A*, Dijkstra, and their
variants, work well for small-scale maps but fail to address large-scale ones
due to high search time and memory consumption. Recently, Large Language Models
(LLMs) have shown remarkable performance in path planning but still suffer from
spatial illusion and poor planning performance. Among all the works, LLM-A*
\cite{meng2024llm} leverages LLM to generate a series of waypoints and then
uses A* to plan the paths between the neighboring waypoints. In this way, the
complete path is constructed. However, LLM-A* still suffers from high
computational time for large-scale maps. To fill this gap, we conducted a deep
investigation into LLM-A* and found its bottleneck, resulting in limited
performance. Accordingly, we design an innovative LLM-enhanced algorithm, abbr.
as iLLM-A*. iLLM-A* includes 3 carefully designed mechanisms, including the
optimization of A*, an incremental learning method for LLM to generate
high-quality waypoints, and the selection of the appropriate waypoints for A*
for path planning. Finally, a comprehensive evaluation on various grid maps
shows that, compared with LLM-A*, iLLM-A* \textbf{1) achieves more than
$1000\times$ speedup on average, and up to $2349.5\times$ speedup in the
extreme case, 2) saves up to $58.6\%$ of the memory cost, 3) achieves both
obviously shorter path length and lower path length standard deviation.}

</details>


### [13] [Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4](https://arxiv.org/abs/2510.02728)
*Lingfeng Zhang,Erjia Xiao,Yuchen Zhang,Haoxiang Fu,Ruibin Hu,Yanbiao Ma,Wenbo Ding,Long Chen,Hangjun Ye,Xiaoshuai Hao*

Main category: cs.RO

TL;DR: 提出了一种两阶段检索优化方法CGRS，通过智能重排序增强基线粗排结果，在跨模态无人机导航任务中显著提升性能，获得挑战赛第二名。


<details>
  <summary>Details</summary>
Motivation: 解决当前基线方法在复杂空中场景中难以实现文本查询与视觉内容之间细粒度语义匹配的问题，特别是在自然语言引导的跨视角图像检索任务中。

Method: 首先使用基线模型获取前20个最相关图像的粗排结果，然后使用视觉语言模型为候选图像生成详细描述，最后通过多模态相似度计算框架进行细粒度重排序。

Result: 在所有关键指标（Recall@1、Recall@5、Recall@10）上相比基线方法实现了一致的5%提升，在RoboSense 2025 Track 4挑战赛中获得了第二名。

Conclusion: 该方法通过语义细化策略在真实机器人导航场景中具有实用价值，证明了在视觉内容和自然语言描述之间构建语义桥梁的有效性。

Abstract: Cross-modal drone navigation remains a challenging task in robotics,
requiring efficient retrieval of relevant images from large-scale databases
based on natural language descriptions. The RoboSense 2025 Track 4 challenge
addresses this challenge, focusing on robust, natural language-guided
cross-view image retrieval across multiple platforms (drones, satellites, and
ground cameras). Current baseline methods, while effective for initial
retrieval, often struggle to achieve fine-grained semantic matching between
text queries and visual content, especially in complex aerial scenes. To
address this challenge, we propose a two-stage retrieval refinement method:
Caption-Guided Retrieval System (CGRS) that enhances the baseline coarse
ranking through intelligent reranking. Our method first leverages a baseline
model to obtain an initial coarse ranking of the top 20 most relevant images
for each query. We then use Vision-Language-Model (VLM) to generate detailed
captions for these candidate images, capturing rich semantic descriptions of
their visual content. These generated captions are then used in a multimodal
similarity computation framework to perform fine-grained reranking of the
original text query, effectively building a semantic bridge between the visual
content and natural language descriptions. Our approach significantly improves
upon the baseline, achieving a consistent 5\% improvement across all key
metrics (Recall@1, Recall@5, and Recall@10). Our approach win TOP-2 in the
challenge, demonstrating the practical value of our semantic refinement
strategy in real-world robotic navigation scenarios.

</details>


### [14] [Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data](https://arxiv.org/abs/2510.02738)
*Tianyu Li,Yihan Li,Zizhe Zhang,Nadia Figueroa*

Main category: cs.RO

TL;DR: 提出一个基于单次人类演示生成力信息仿真数据的框架，结合顺应性策略提升从合成数据学习的视觉运动策略性能，在真实机器人任务中验证了可靠接触保持和新条件适应能力。


<details>
  <summary>Details</summary>
Motivation: 接触丰富的机器人操作任务需要显式处理顺应性和力，但大多数视觉运动策略忽略顺应性，导致过度接触力或脆弱行为。引入力信息可改善接触感知，但需要大量数据。

Method: 通过单次人类演示生成力信息仿真数据，结合顺应性策略来训练视觉运动策略。

Result: 在真实机器人任务（非抓取块翻转和双手物体移动）中验证，学习到的策略表现出可靠的接触保持和新条件适应能力。

Conclusion: 该框架能够有效利用仿真生成的数据提升视觉运动策略在接触丰富任务中的性能，减少对大量真实数据的依赖。

Abstract: While visuomotor policy has made advancements in recent years, contact-rich
tasks still remain a challenge. Robotic manipulation tasks that require
continuous contact demand explicit handling of compliance and force. However,
most visuomotor policies ignore compliance, overlooking the importance of
physical interaction with the real world, often leading to excessive contact
forces or fragile behavior under uncertainty. Introducing force information
into vision-based imitation learning could help improve awareness of contacts,
but could also require a lot of data to perform well. One remedy for data
scarcity is to generate data in simulation, yet computationally taxing
processes are required to generate data good enough not to suffer from the
Sim2Real gap. In this work, we introduce a framework for generating
force-informed data in simulation, instantiated by a single human
demonstration, and show how coupling with a compliant policy improves the
performance of a visuomotor policy learned from synthetic data. We validate our
approach on real-robot tasks, including non-prehensile block flipping and a
bi-manual object moving, where the learned policy exhibits reliable contact
maintenance and adaptation to novel conditions. Project Website:
https://flow-with-the-force-field.github.io/webpage/

</details>


### [15] [Work Zones challenge VLM Trajectory Planning: Toward Mitigation and Robust Autonomous Driving](https://arxiv.org/abs/2510.02803)
*Yifan Liao,Zhen Sun,Xiaoyun Qiu,Zixiao Zhao,Wenbing Tang,Xinlei He,Xinhu Zheng,Tianwei Zhang,Xinyi Huang,Xingshuo Han*

Main category: cs.RO

TL;DR: 本文首次系统研究视觉语言模型在工作区轨迹规划中的能力，发现主流VLMs在68%情况下生成错误轨迹，并提出REACT-Drive框架，通过检索增强生成技术显著提升规划精度和效率。


<details>
  <summary>Details</summary>
Motivation: 工作区具有不规则布局、临时交通控制和动态变化的几何结构等复杂特征，而现有视觉语言模型在此类环境中的轨迹规划能力尚未得到充分探索，存在明显的性能缺陷。

Method: 提出REACT-Drive框架，结合检索增强生成技术：首先通过子图挖掘和聚类分析识别常见失败模式，然后利用VLMs将先验失败案例转化为约束规则和可执行代码，最后通过RAG检索相似模式指导新场景的轨迹生成。

Result: 在ROADWork数据集上，REACT-Drive相比VLM基线平均位移误差减少约3倍，推理时间仅为0.58秒，远低于微调方法的17.90秒。在15个真实工作区场景的物理实验中验证了其强实用性。

Conclusion: REACT-Drive有效解决了VLMs在工作区轨迹规划中的失败问题，通过检索增强生成机制显著提升了规划精度和效率，为自动驾驶系统在复杂工作区环境中的安全部署提供了可行方案。

Abstract: Visual Language Models (VLMs), with powerful multimodal reasoning
capabilities, are gradually integrated into autonomous driving by several
automobile manufacturers to enhance planning capability in challenging
environments. However, the trajectory planning capability of VLMs in work
zones, which often include irregular layouts, temporary traffic control, and
dynamically changing geometric structures, is still unexplored. To bridge this
gap, we conduct the \textit{first} systematic study of VLMs for work zone
trajectory planning, revealing that mainstream VLMs fail to generate correct
trajectories in $68.0%$ of cases. To better understand these failures, we first
identify candidate patterns via subgraph mining and clustering analysis, and
then confirm the validity of $8$ common failure patterns through human
verification. Building on these findings, we propose REACT-Drive, a trajectory
planning framework that integrates VLMs with Retrieval-Augmented Generation
(RAG). Specifically, REACT-Drive leverages VLMs to convert prior failure cases
into constraint rules and executable trajectory planning code, while RAG
retrieves similar patterns in new scenarios to guide trajectory generation.
Experimental results on the ROADWork dataset show that REACT-Drive yields a
reduction of around $3\times$ in average displacement error relative to VLM
baselines under evaluation with Qwen2.5-VL. In addition, REACT-Drive yields the
lowest inference time ($0.58$s) compared with other methods such as fine-tuning
($17.90$s). We further conduct experiments using a real vehicle in 15 work zone
scenarios in the physical world, demonstrating the strong practicality of
REACT-Drive.

</details>


### [16] [Assist-as-needed Control for FES in Foot Drop Management](https://arxiv.org/abs/2510.02808)
*Andreas Christou,Elliot Lister,Georgia Andreopoulou,Don Mahad,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出了一种基于实时脚趾间隙的闭环FES控制器，能动态调整刺激强度，相比传统开环控制器在维持足够脚趾间隙的同时显著降低刺激强度。


<details>
  <summary>Details</summary>
Motivation: 传统开环FES控制器采用固定刺激强度，用户手动调整可能导致过度刺激（肌肉疲劳和不适）或刺激不足（背屈不足和跌倒风险增加）。

Method: 开发闭环FES控制器，根据实时脚趾间隙动态调整刺激强度，在健康参与者中诱导足下垂，比较闭环与开环控制器在不同步行条件（速度和地面倾斜度）下的效果。

Result: 闭环控制器在维持足够脚趾间隙的同时，显著降低刺激强度，且不影响髋、膝、踝关节角度。

Conclusion: 该方法不仅匹配现有系统的有效性，还具备减少肌肉疲劳、提高长期用户舒适度和依从性的潜力。

Abstract: Foot drop is commonly managed using Functional Electrical Stimulation (FES),
typically delivered via open-loop controllers with fixed stimulation
intensities. While users may manually adjust the intensity through external
controls, this approach risks overstimulation, leading to muscle fatigue and
discomfort, or understimulation, which compromises dorsiflexion and increases
fall risk. In this study, we propose a novel closed-loop FES controller that
dynamically adjusts the stimulation intensity based on real-time toe clearance,
providing "assistance as needed". We evaluate this system by inducing foot drop
in healthy participants and comparing the effects of the closed-loop controller
with a traditional open-loop controller across various walking conditions,
including different speeds and surface inclinations. Kinematic data reveal that
our closed-loop controller maintains adequate toe clearance without
significantly affecting the joint angles of the hips, the knees, and the
ankles, and while using significantly lower stimulation intensities compared to
the open-loop controller. These findings suggest that the proposed method not
only matches the effectiveness of existing systems but also offers the
potential for reduced muscle fatigue and improved long-term user comfort and
adherence.

</details>


### [17] [Action Deviation-Aware Inference for Low-Latency Wireless Robots](https://arxiv.org/abs/2510.02851)
*Jeyoung Park,Yeonsub Lim,Seungeun Oh,Jihong Park,Jinho Choi,Seong-Lyun Kim*

Main category: cs.RO

TL;DR: 提出了一种动作偏差感知的混合推理方法，通过选择性跳过服务器验证来降低延迟和传输开销，同时保持高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 6G分布式机器学习需要支持延迟敏感的AI应用，但行为克隆策略无法像文本生成那样并行验证多个草案，因为每个动作都依赖于前一个动作更新后的观察结果。

Method: 提出动作偏差感知混合推理，草案模型估计动作需要目标模型验证和修正的程度，选择性跳过服务器操作。推导路径偏差阈值来平衡传输率和推理性能。

Result: 减少上行传输和服务器操作40%，端到端延迟降低33.32%，任务成功率可达目标模型单独推理的97.03%。

Conclusion: 动作偏差感知混合推理能有效降低分布式推理的延迟和通信开销，同时保持接近目标模型的性能。

Abstract: To support latency-sensitive AI applications ranging from autonomous driving
to industrial robot manipulation, 6G envisions distributed ML, connecting
distributed computational resources in edge and cloud over hyper-reliable
low-latency communication (HRLLC). In this setting, speculative decoding can
facilitate collaborative inference of models distributively deployed: an
on-device draft model locally generates drafts and a remote server-based target
model verifies and corrects them, resulting lower latency. However, unlike
autoregressive text generation, behavior cloning policies, typically used for
embodied AI applications like robot manipulation and autonomous driving, cannot
parallelize verification and correction for multiple drafts as each action
depends on observation which needs to be updated by a previous action. To this
end, we propose Action Deviation-Aware Hybrid Inference, wherein the draft
model estimates an action's need for verification and correction by the target
model and selectively skips communication and computation for server
operations. Action deviation shows a strong correlation with action's rejection
probability by the target model, enabling selective skipping. We derive the
path deviation threshold that balances the transmission rate and the inference
performance, and we empirically show that action deviation-aware hybrid
inference reduces uplink transmission and server operation by 40%, while
lowering end-to-end latency by 33.32% relative to hybrid inference without
skipping and achieving task success rate up to 97.03% of that of target model
only inference.

</details>


### [18] [Novel UWB Synthetic Aperture Radar Imaging for Mobile Robot Mapping](https://arxiv.org/abs/2510.02874)
*Charith Premachandra,U-Xuan Tan*

Main category: cs.RO

TL;DR: 提出了一种移动机器人使用UWB雷达合成孔径成像来映射未知环境的流程，并在恶劣环境条件下评估了多种经典特征检测器用于闭环检测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的外感知传感器（如LiDAR和相机）在能见度差的环境中感知能力有限，而UWB雷达能够穿透恶劣环境条件，但单个扫描无法重建详细图像。

Method: 通过移动雷达沿机器人路径合成虚拟大孔径，生成高分辨率SAR图像，并评估SIFT、SURF、BRISK、AKAZE和ORB等特征检测器在UWB SAR图像上的闭环检测性能。

Result: 实验结果表明UWB SAR成像在高分辨率环境映射和闭环检测方面具有可行性和有效性。

Conclusion: UWB SAR成像能够为机器人感知系统提供更鲁棒和可靠的解决方案。

Abstract: Traditional exteroceptive sensors in mobile robots, such as LiDARs and
cameras often struggle to perceive the environment in poor visibility
conditions. Recently, radar technologies, such as ultra-wideband (UWB) have
emerged as potential alternatives due to their ability to see through adverse
environmental conditions (e.g. dust, smoke and rain). However, due to the small
apertures with low directivity, the UWB radars cannot reconstruct a detailed
image of its field of view (FOV) using a single scan. Hence, a virtual large
aperture is synthesized by moving the radar along a mobile robot path. The
resulting synthetic aperture radar (SAR) image is a high-definition
representation of the surrounding environment. Hence, this paper proposes a
pipeline for mobile robots to incorporate UWB radar-based SAR imaging to map an
unknown environment. Finally, we evaluated the performance of classical feature
detectors: SIFT, SURF, BRISK, AKAZE and ORB to identify loop closures using UWB
SAR images. The experiments were conducted emulating adverse environmental
conditions. The results demonstrate the viability and effectiveness of UWB SAR
imaging for high-resolution environmental mapping and loop closure detection
toward more robust and reliable robotic perception systems.

</details>


### [19] [Point Cloud-Based Control Barrier Functions for Model Predictive Control in Safety-Critical Navigation of Autonomous Mobile Robots](https://arxiv.org/abs/2510.02885)
*Faduo Liang,Yunfeng Yang,Shi-Lu Dai*

Main category: cs.RO

TL;DR: 提出了一种结合动态障碍物追踪和预测的安全关键运动规划算法，通过前向时间域地图和控制屏障函数实现自主机器人的安全导航。


<details>
  <summary>Details</summary>
Motivation: 为了解决自主移动机器人在复杂环境中安全避障的问题，特别是需要同时处理静态和动态障碍物的挑战。

Method: 集成实时动态障碍物追踪与建图系统，使用卡尔曼滤波预测动态点云运动状态，构建前向时间域地图，并结合控制屏障函数与非线性模型预测控制进行运动规划。

Result: 仿真和真实环境实验表明，该算法在复杂环境中表现优异，与两种基线方法相比，在安全性和鲁棒性方面具有显著优势。

Conclusion: 所提出的算法能够有效处理动态和静态障碍物，为自主机器人在复杂环境中的安全导航提供了可靠解决方案，代码已开源供机器人社区参考。

Abstract: In this work, we propose a novel motion planning algorithm to facilitate
safety-critical navigation for autonomous mobile robots. The proposed algorithm
integrates a real-time dynamic obstacle tracking and mapping system that
categorizes point clouds into dynamic and static components. For dynamic point
clouds, the Kalman filter is employed to estimate and predict their motion
states. Based on these predictions, we extrapolate the future states of dynamic
point clouds, which are subsequently merged with static point clouds to
construct the forward-time-domain (FTD) map. By combining control barrier
functions (CBFs) with nonlinear model predictive control, the proposed
algorithm enables the robot to effectively avoid both static and dynamic
obstacles. The CBF constraints are formulated based on risk points identified
through collision detection between the predicted future states and the FTD
map. Experimental results from both simulated and real-world scenarios
demonstrate the efficacy of the proposed algorithm in complex environments. In
simulation experiments, the proposed algorithm is compared with two baseline
approaches, showing superior performance in terms of safety and robustness in
obstacle avoidance. The source code is released for the reference of the
robotics community.

</details>


### [20] [Metrics vs Surveys: Can Quantitative Measures Replace Human Surveys in Social Robot Navigation? A Correlation Analysis](https://arxiv.org/abs/2510.02941)
*Stefano Trepella,Mauro Martini,Noé Pérez-Higueras,Andrea Ostuni,Fernando Caballero,Luis Merino,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 该研究探索社交导航中数值指标与人类中心评估之间的相关性，旨在找到能够替代昂贵人工调查的标准化定量评估方法。


<details>
  <summary>Details</summary>
Motivation: 社交导航评估复杂且成本高昂，人类中心评估可靠但资源密集，数值指标易于计算但缺乏标准化。研究旨在找到两者相关性以降低对人工调查的依赖。

Method: 通过分析数值指标与人类中心评估之间的关系，探索定量测量与人类感知之间的潜在相关性。

Result: 当前数值指标能够捕捉机器人导航行为的某些方面，但重要的主观因素仍然没有得到充分体现，需要开发新的指标。

Conclusion: 虽然现有指标部分有效，但需要开发新的数值指标来更好地反映人类对社交导航的主观评价，以实现更有效的标准化评估。

Abstract: Social, also called human-aware, navigation is a key challenge for the
integration of mobile robots into human environments. The evaluation of such
systems is complex, as factors such as comfort, safety, and legibility must be
considered. Human-centered assessments, typically conducted through surveys,
provide reliable insights but are costly, resource-intensive, and difficult to
reproduce or compare across systems. Alternatively, numerical social navigation
metrics are easy to compute and facilitate comparisons, yet the community lacks
consensus on a standard set of metrics.
  This work explores the relationship between numerical metrics and
human-centered evaluations to identify potential correlations. If specific
quantitative measures align with human perceptions, they could serve as
standardized evaluation tools, reducing the dependency on surveys. Our results
indicate that while current metrics capture some aspects of robot navigation
behavior, important subjective factors remain insufficiently represented and
new metrics are necessary.

</details>


### [21] [Single-Rod Brachiation Robot: Mechatronic Control Design and Validation of Prejump Phases](https://arxiv.org/abs/2510.02946)
*Juraj Lieskovský,Hijiri Akahane,Aoto Osawa,Jaroslav Bušek,Ikuo Mizuuchi,Tomáš Vyhlídal*

Main category: cs.RO

TL;DR: 本文提出了一种最小配置摆荡机器人的完整机电设计，采用单刚性杆和两端抓取器，通过曲柄滑块机构移动质心来控制运动，开发了最优和连续控制策略，并进行了仿真和实验验证。


<details>
  <summary>Details</summary>
Motivation: 设计一种简单可靠的摆荡机器人，能够通过控制质心位置实现摆动和旋转运动，为后续跳跃阶段积累能量。

Method: 使用单刚性杆和两端抓取器，通过曲柄滑块机构重新定位质心，基于非线性模型提出bang-bang最优控制和考虑扭矩限制的连续控制策略。

Result: 两种控制策略在仿真中得到验证，连续控制策略在STM32控制系统上实现，摆动和旋转运动均通过实验验证。

Conclusion: 提出的最小配置摆荡机器人设计可行，连续控制策略能够有效处理机构限制，为后续跳跃阶段成功积累能量。

Abstract: A complete mechatronic design of a minimal configuration brachiation robot is
presented. The robot consists of a single rigid rod with gripper mechanisms
attached to both ends. The grippers are used to hang the robot on a horizontal
bar on which it swings or rotates. The motion is imposed by repositioning the
robot's center of mass, which is performed using a crank-slide mechanism. Based
on a non-linear model, an optimal control strategy is proposed, for
repositioning the center of mass in a bang-bang manner. Consequently, utilizing
the concept of input-output linearization, a continuous control strategy is
proposed that takes into account the limited torque of the crank-slide
mechanism and its geometry. An increased attention is paid to energy
accumulation towards the subsequent jump stage of the brachiation. These two
strategies are validated and compared in simulations. The continuous control
strategy is then also implemented within a low-cost STM32-based control system,
and both the swing and rotation stages of the brachiation motion are
experimentally validated.

</details>


### [22] [YawSitter: Modeling and Controlling a Tail-Sitter UAV with Enhanced Yaw Control](https://arxiv.org/abs/2510.02968)
*Amir Habel,Fawad Mehboob,Jeffrin Sam,Clement Fortin,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 提出了一种新型的尾座式无人机侧向运动建模与控制策略，通过引入基于差动推力产生的侧滑力模型，实现了无滚转耦合的偏航控制侧向位置控制。


<details>
  <summary>Details</summary>
Motivation: 尾座式无人机在悬停状态下由于复杂的气动耦合和缺乏明确的侧向动力学模型，难以实现精确的侧向运动建模和解耦控制。

Method: 利用差动螺旋桨滑流效应在机身产生的侧滑力模型，采用YXZ欧拉旋转公式表示姿态并直接控制偏航轴，改善侧向动态行为并避免奇点。

Result: 在Unity环境中进行的轨迹跟踪仿真显示，在矩形和圆形路径上均表现稳定，平均绝对位置误差低，偏航偏差控制在5.688度以内。

Conclusion: 所提出的侧向力生成模型有效，为开发敏捷的悬停能力尾座式无人机奠定了基础。

Abstract: Achieving precise lateral motion modeling and decoupled control in hover
remains a significant challenge for tail-sitter Unmanned Aerial Vehicles
(UAVs), primarily due to complex aerodynamic couplings and the absence of
welldefined lateral dynamics. This paper presents a novel modeling and control
strategy that enhances yaw authority and lateral motion by introducing a
sideslip force model derived from differential propeller slipstream effects
acting on the fuselage under differential thrust. The resulting lateral force
along the body y-axis enables yaw-based lateral position control without
inducing roll coupling. The control framework employs a YXZ Euler rotation
formulation to accurately represent attitude and incorporate gravitational
components while directly controlling yaw in the yaxis, thereby improving
lateral dynamic behavior and avoiding singularities. The proposed approach is
validated through trajectory-tracking simulations conducted in a Unity-based
environment. Tests on both rectangular and circular paths in hover mode
demonstrate stable performance, with low mean absolute position errors and yaw
deviations constrained within 5.688 degrees. These results confirm the
effectiveness of the proposed lateral force generation model and provide a
foundation for the development of agile, hover-capable tail-sitter UAVs.

</details>


### [23] [AI-Enhanced Kinematic Modeling of Flexible Manipulators Using Multi-IMU Sensor Fusion](https://arxiv.org/abs/2510.02975)
*Amir Hossein Barjini,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种使用多个IMU估计柔性机械臂位置和姿态的新框架，通过PSO优化互补滤波器参数，并用RBFNN补偿残差误差，实现了高精度的运动估计。


<details>
  <summary>Details</summary>
Motivation: 柔性机械臂在垂直运动中的精确位置和姿态估计具有挑战性，需要解决低成本IMU的噪声和延迟问题，提高运动控制的准确性。

Method: 将柔性连杆建模为刚性段，使用互补滤波器融合加速度计和陀螺仪数据，PSO优化滤波器参数，RBFNN补偿位置和姿态的残差误差。

Result: 实验验证了方法的有效性，在y、z和θ方向上的RMSE分别为0.00021m、0.00041m和0.00024rad，达到了高精度估计。

Conclusion: 提出的智能多IMU运动估计方法能够有效估计柔性机械臂的位置和姿态，为柔性机械臂的精确控制提供了可行方案。

Abstract: This paper presents a novel framework for estimating the position and
orientation of flexible manipulators undergoing vertical motion using multiple
inertial measurement units (IMUs), optimized and calibrated with ground truth
data. The flexible links are modeled as a series of rigid segments, with joint
angles estimated from accelerometer and gyroscope measurements acquired by
cost-effective IMUs. A complementary filter is employed to fuse the
measurements, with its parameters optimized through particle swarm optimization
(PSO) to mitigate noise and delay. To further improve estimation accuracy,
residual errors in position and orientation are compensated using radial basis
function neural networks (RBFNN). Experimental results validate the
effectiveness of the proposed intelligent multi-IMU kinematic estimation
method, achieving root mean square errors (RMSE) of 0.00021~m, 0.00041~m, and
0.00024~rad for $y$, $z$, and $\theta$, respectively.

</details>


### [24] [Real-Time Nonlinear Model Predictive Control of Heavy-Duty Skid-Steered Mobile Platform for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.02976)
*Alvaro Paz,Pauli Mustalahti,Mohammad Dastranj,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种用于重型滑移转向移动平台轨迹跟踪的实时最优控制框架，采用多射击非线性模型预测控制方法，在速度和精度方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 在动态系统受到不确定性和干扰影响的情况下，需要准确实时的控制器来保证安全性和稳定性能。

Method: 采用多射击非线性模型预测控制框架，结合合适的算法和各种传感器读数，实现真正的实时高性能控制。

Result: 控制器在跟踪不同轨迹时表现出高度理想的速度和精度性能，相比现有文献中的非线性模型预测控制器有显著改进。

Conclusion: 该框架为重型滑移转向移动平台提供了高效准确的实时轨迹跟踪控制解决方案。

Abstract: This paper presents a framework for real-time optimal controlling of a
heavy-duty skid-steered mobile platform for trajectory tracking. The importance
of accurate real-time performance of the controller lies in safety
considerations of situations where the dynamic system under control is affected
by uncertainties and disturbances, and the controller should compensate for
such phenomena in order to provide stable performance. A multiple-shooting
nonlinear model-predictive control framework is proposed in this paper. This
framework benefits from suitable algorithm along with readings from various
sensors for genuine real-time performance with extremely high accuracy. The
controller is then tested for tracking different trajectories where it
demonstrates highly desirable performance in terms of both speed and accuracy.
This controller shows remarkable improvement when compared to existing
nonlinear model-predictive controllers in the literature that were implemented
on skid-steered mobile platforms.

</details>


### [25] [3D-CovDiffusion: 3D-Aware Diffusion Policy for Coverage Path Planning](https://arxiv.org/abs/2510.03011)
*Chenyuan Chen,Haoran Ding,Ran Ding,Tianyu Liu,Zewen He,Anqing Duan,Dezhen Song,Xiaodan Liang,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 提出了一种基于扩散模型的端到端轨迹生成框架，用于工业表面处理任务，显著提升了轨迹连续性、覆盖率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法受限于预定义函数形式，难以处理复杂多样的任务，泛化能力差，需要为不同场景手动重新设计或调参。扩散模型提供了更强大的表达能力。

Method: 使用扩散模型通过迭代去噪轨迹，结合精心学习的噪声调度和条件机制，确保平滑一致的运动并灵活适应任务上下文。

Result: 平均改进点向Chamfer距离98.2%，平滑度97.0%，表面覆盖率相比先前方法提高61%，能泛化到未见过的形状。

Conclusion: 该方法为工业表面处理任务提供了统一的端到端轨迹学习方案，无需类别特定模型。

Abstract: Diffusion models, as a class of deep generative models, have recently emerged
as powerful tools for robot skills by enabling stable training with reliable
convergence. In this paper, we present an end-to-end framework for generating
long, smooth trajectories that explicitly target high surface coverage across
various industrial tasks, including polishing, robotic painting, and spray
coating. The conventional methods are always fundamentally constrained by their
predefined functional forms, which limit the shapes of the trajectories they
can represent and make it difficult to handle complex and diverse tasks.
Moreover, their generalization is poor, often requiring manual redesign or
extensive parameter tuning when applied to new scenarios. These limitations
highlight the need for more expressive generative models, making
diffusion-based approaches a compelling choice for trajectory generation. By
iteratively denoising trajectories with carefully learned noise schedules and
conditioning mechanisms, diffusion models not only ensure smooth and consistent
motion but also flexibly adapt to the task context. In experiments, our method
improves trajectory continuity, maintains high coverage, and generalizes to
unseen shapes, paving the way for unified end-to-end trajectory learning across
industrial surface-processing tasks without category-specific models. On
average, our approach improves Point-wise Chamfer Distance by 98.2\% and
smoothness by 97.0\%, while increasing surface coverage by 61\% compared to
prior methods. The link to our code can be found
\href{https://anonymous.4open.science/r/spraydiffusion_ral-2FCE/README.md}{here}.

</details>


### [26] [HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton](https://arxiv.org/abs/2510.03022)
*Rui Zhong,Yizhe Sun,Junjie Wen,Jinming Li,Chuang Cheng,Wei Dai,Zhiwen Zeng,Huimin Lu,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: HumanoidExo系统通过将人类动作转换为全身人形机器人数据，解决了人形机器人策略学习中大规模多样化数据集获取困难的问题。


<details>
  <summary>Details</summary>
Motivation: 人形机器人策略学习面临的主要瓶颈是获取大规模多样化数据集，因为收集可靠的现实世界数据既困难又成本高昂。

Method: 开发了HumanoidExo系统，通过最小化人类演示者与机器人之间的体现差距，将人类动作转换为全身人形机器人数据。

Result: 在三个具有挑战性的现实世界任务中评估：桌面操作、结合站立-蹲下动作的操作以及全身操作。结果表明HumanoidExo能够使人形策略泛化到新环境，仅用5个真实机器人演示就能学习复杂的全身控制，甚至仅从HumanoidExo数据就能学习新技能（如行走）。

Conclusion: HumanoidExo是真实机器人数据的重要补充，显著提升了人形机器人在动态现实场景中的性能。

Abstract: A significant bottleneck in humanoid policy learning is the acquisition of
large-scale, diverse datasets, as collecting reliable real-world data remains
both difficult and cost-prohibitive. To address this limitation, we introduce
HumanoidExo, a novel system that transfers human motion to whole-body humanoid
data. HumanoidExo offers a high-efficiency solution that minimizes the
embodiment gap between the human demonstrator and the robot, thereby tackling
the scarcity of whole-body humanoid data. By facilitating the collection of
more voluminous and diverse datasets, our approach significantly enhances the
performance of humanoid robots in dynamic, real-world scenarios. We evaluated
our method across three challenging real-world tasks: table-top manipulation,
manipulation integrated with stand-squat motions, and whole-body manipulation.
Our results empirically demonstrate that HumanoidExo is a crucial addition to
real-robot data, as it enables the humanoid policy to generalize to novel
environments, learn complex whole-body control from only five real-robot
demonstrations, and even acquire new skills (i.e., walking) solely from
HumanoidExo data.

</details>


### [27] [Long-Term Human Motion Prediction Using Spatio-Temporal Maps of Dynamics](https://arxiv.org/abs/2510.03031)
*Yufei Zhu,Andrey Rudenko,Tomasz P. Kucner,Achim J. Lilienthal,Martin Magnusson*

Main category: cs.RO

TL;DR: 提出了一种基于动态地图(MoDs)的长期人体运动预测框架，通过利用环境动态特征来预测长达60秒的人体运动轨迹，并引入时间条件MoD来捕捉不同时段的运动模式变化。


<details>
  <summary>Details</summary>
Motivation: 长期人体运动预测对于自主机器人和车辆在与人类共享环境中的安全高效运行至关重要，准确的预测对运动规划、跟踪、人机交互和安全监控等应用具有重要意义。

Method: 提出MoD-informed LHMP框架，支持多种类型的动态地图，包含排序方法输出最可能的预测轨迹，并引入时间条件MoD来捕捉不同时间段的运动模式变化。

Result: 在两个真实世界数据集上的实验表明，MoD-informed方法优于基于学习的方法，平均位移误差提升高达50%，时间条件变体在所有方法中达到最高准确率。

Conclusion: 动态地图能够有效提升长期人体运动预测的准确性，时间条件MoD进一步增强了预测性能，为机器人应用提供了实用的解决方案。

Abstract: Long-term human motion prediction (LHMP) is important for the safe and
efficient operation of autonomous robots and vehicles in environments shared
with humans. Accurate predictions are important for applications including
motion planning, tracking, human-robot interaction, and safety monitoring. In
this paper, we exploit Maps of Dynamics (MoDs), which encode spatial or
spatio-temporal motion patterns as environment features, to achieve LHMP for
horizons of up to 60 seconds. We propose an MoD-informed LHMP framework that
supports various types of MoDs and includes a ranking method to output the most
likely predicted trajectory, improving practical utility in robotics. Further,
a time-conditioned MoD is introduced to capture motion patterns that vary
across different times of day. We evaluate MoD-LHMP instantiated with three
types of MoDs. Experiments on two real-world datasets show that MoD-informed
method outperforms learning-based ones, with up to 50\% improvement in average
displacement error, and the time-conditioned variant achieves the highest
accuracy overall. Project code is available at
https://github.com/test-bai-cpu/LHMP-with-MoDs.git

</details>


### [28] [Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot](https://arxiv.org/abs/2510.03081)
*Guiliang Liu,Bo Yue,Yi Jin Kim,Kui Jia*

Main category: cs.RO

TL;DR: 本文主张在人形机器人中采用协同设计方法，同时优化控制策略和物理结构，以实现真正的具身智能。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注固定机器人结构的控制策略优化，但人形机器人作为通用物理代理，需要同时具备智能控制和适应性形态才能在多样化现实环境中有效运作。

Method: 提出基于战略探索、Sim2Real迁移和元策略学习的实用协同设计方法，从方法论、应用驱动和社区导向三个角度分析协同设计的必要性。

Result: 确立了协同设计作为开发下一代智能和适应性人形代理的基石地位，并提出了从短期创新到长期目标的开放研究问题。

Conclusion: 协同设计是实现真正具身智能的关键路径，需要同时进化机器人的形态和行为，以在任务特定和资源受限的环境中优化性能。

Abstract: Humanoid robots, as general-purpose physical agents, must integrate both
intelligent control and adaptive morphology to operate effectively in diverse
real-world environments. While recent research has focused primarily on
optimizing control policies for fixed robot structures, this position paper
argues for evolving both control strategies and humanoid robots' physical
structure under a co-design mechanism. Inspired by biological evolution, this
approach enables robots to iteratively adapt both their form and behavior to
optimize performance within task-specific and resource-constrained contexts.
Despite its promise, co-design in humanoid robotics remains a relatively
underexplored domain, raising fundamental questions about its feasibility and
necessity in achieving true embodied intelligence. To address these challenges,
we propose practical co-design methodologies grounded in strategic exploration,
Sim2Real transfer, and meta-policy learning. We further argue for the essential
role of co-design by analyzing it from methodological, application-driven, and
community-oriented perspectives. Striving to guide and inspire future studies,
we present open research questions, spanning from short-term innovations to
long-term goals. This work positions co-design as a cornerstone for developing
the next generation of intelligent and adaptable humanoid agents.

</details>


### [29] [Whisker-based Tactile Flight for Tiny Drones](https://arxiv.org/abs/2510.03119)
*Chaoxiang Ye,Guido de Croon,Salua Hamaza*

Main category: cs.RO

TL;DR: 开发了一种仅重3.2克的胡须式触觉传感装置，使微型无人机能够在完全黑暗等恶劣环境中通过触觉感知进行导航和探索。


<details>
  <summary>Details</summary>
Motivation: 微型飞行机器人在搜救、安全检查和环境监测方面潜力巨大，但小尺寸限制了传统传感能力，特别是在光线差、烟雾、灰尘或反光障碍物环境中。受自然界启发，需要开发触觉感知系统来克服视觉限制。

Method: 使用基于气压计的胡须传感器检测障碍物位置，同时最小化对飞行稳定性的影响。开发了触觉深度估计方法，处理传感器噪声和漂移问题。系统在192KB RAM微控制器上完全自主运行。

Result: 触觉深度估计精度达到亚6毫米，使无人机能够仅通过触觉进行导航、沿障碍物轮廓飞行和探索受限空间，即使在完全黑暗中也能沿软硬表面飞行。系统在仿真和真实世界测试中得到验证。

Conclusion: 这种仿生方法重新定义了无视觉导航，为微型飞行器在极端环境中应用开辟了新可能性。

Abstract: Tiny flying robots hold great potential for search-and-rescue, safety
inspections, and environmental monitoring, but their small size limits
conventional sensing-especially with poor-lighting, smoke, dust or reflective
obstacles. Inspired by nature, we propose a lightweight, 3.2-gram,
whisker-based tactile sensing apparatus for tiny drones, enabling them to
navigate and explore through gentle physical interaction. Just as rats and
moles use whiskers to perceive surroundings, our system equips drones with
tactile perception in flight, allowing obstacle sensing even in pitch-dark
conditions. The apparatus uses barometer-based whisker sensors to detect
obstacle locations while minimising destabilisation. To address sensor noise
and drift, we develop a tactile depth estimation method achieving sub-6 mm
accuracy. This enables drones to navigate, contour obstacles, and explore
confined spaces solely through touch-even in total darkness along both soft and
rigid surfaces. Running fully onboard a 192-KB RAM microcontroller, the system
supports autonomous tactile flight and is validated in both simulation and
real-world tests. Our bio-inspired approach redefines vision-free navigation,
opening new possibilities for micro aerial vehicles in extreme environments.

</details>


### [30] [Learning Stability Certificate for Robotics in Real-World Environments](https://arxiv.org/abs/2510.03123)
*Zhe Shen*

Main category: cs.RO

TL;DR: 提出了一种从轨迹数据直接学习李雅普诺夫函数的新框架，无需系统动力学模型即可为自主系统提供稳定性认证


<details>
  <summary>Details</summary>
Motivation: 传统稳定性证书推导需要明确的系统动力学知识，对于复杂未知系统来说很困难。需要一种能够从数据直接学习稳定性证书的方法

Method: 使用神经网络参数化李雅普诺夫候选函数，通过Cholesky分解确保正定性，允许稳定性条件的受控违反以处理噪声数据

Result: 该框架能够提供数据驱动的稳定性保证，在动态真实环境中为机器人系统提供鲁棒的稳定性认证

Conclusion: 该方法无需访问内部控制算法，适用于系统行为不透明或专有的情况，为机器人系统安全提供了实用的稳定性认证工具

Abstract: Stability certificates play a critical role in ensuring the safety and
reliability of robotic systems. However, deriving these certificates for
complex, unknown systems has traditionally required explicit knowledge of
system dynamics, often making it a daunting task. This work introduces a novel
framework that learns a Lyapunov function directly from trajectory data,
enabling the certification of stability for autonomous systems without needing
detailed system models. By parameterizing the Lyapunov candidate using a neural
network and ensuring positive definiteness through Cholesky factorization, our
approach automatically identifies whether the system is stable under the given
trajectory. To address the challenges posed by noisy, real-world data, we allow
for controlled violations of the stability condition, focusing on maintaining
high confidence in the stability certification process. Our results demonstrate
that this framework can provide data-driven stability guarantees, offering a
robust method for certifying the safety of robotic systems in dynamic,
real-world environments. This approach works without access to the internal
control algorithms, making it applicable even in situations where system
behavior is opaque or proprietary. The tool for learning the stability proof is
open-sourced by this research: https://github.com/HansOersted/stability.

</details>


### [31] [MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning](https://arxiv.org/abs/2510.03142)
*Tianyu Xu,Jiawei Chen,Jiazhao Zhang,Wenyao Zhang,Zekun Qi,Minghan Li,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: 提出MM-Nav视觉语言动作模型，通过教师-学生方式从合成专家数据中学习多样化导航能力，在合成和真实环境中都表现出优异的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 视觉导航策略难以像激光雷达或深度图那样显式建模，需要智能模型和大规模数据，因此利用VLA模型的智能从合成专家数据中学习导航能力。

Method: 基于预训练大语言模型和视觉基础模型实现多视图VLA模型MM-Nav，从三个具有特权深度信息的RL专家收集数据，在三个定制环境中分别训练到达、挤压和避障能力，采用动态平衡训练比例的在线数据迭代训练。

Result: 在合成环境中展现出强大的泛化能力，学生VLA模型甚至超越了RL教师模型，体现了多种能力整合的协同效应，真实世界实验进一步验证了方法的有效性。

Conclusion: 通过VLA模型和合成专家数据的教师-学生训练框架，成功实现了多样化导航能力的有效学习，证明了该方法在视觉导航中的可行性和优越性。

Abstract: Visual navigation policy is widely regarded as a promising direction, as it
mimics humans by using egocentric visual observations for navigation. However,
optical information of visual observations is difficult to be explicitly
modeled like LiDAR point clouds or depth maps, which subsequently requires
intelligent models and large-scale data. To this end, we propose to leverage
the intelligence of the Vision-Language-Action (VLA) model to learn diverse
navigation capabilities from synthetic expert data in a teacher-student manner.
Specifically, we implement the VLA model, MM-Nav, as a multi-view VLA (with 360
observations) based on pretrained large language models and visual foundation
models. For large-scale navigation data, we collect expert data from three
reinforcement learning (RL) experts trained with privileged depth information
in three challenging tailor-made environments for different navigation
capabilities: reaching, squeezing, and avoiding. We iteratively train our VLA
model using data collected online from RL experts, where the training ratio is
dynamically balanced based on performance on individual capabilities. Through
extensive experiments in synthetic environments, we demonstrate that our model
achieves strong generalization capability. Moreover, we find that our student
VLA model outperforms the RL teachers, demonstrating the synergistic effect of
integrating multiple capabilities. Extensive real-world experiments further
confirm the effectiveness of our method.

</details>


### [32] [Optimal Smooth Coverage Trajectory Planning for Quadrotors in Cluttered Environment](https://arxiv.org/abs/2510.03169)
*Duanjiao Li,Yun Chen,Ying Zhang,Junwen Yao,Dongyue Huang,Jianguo Zhang,Ning Ding*

Main category: cs.RO

TL;DR: 提出了一种用于无人机在复杂环境中进行平滑覆盖轨迹规划的两阶段优化算法，结合遗传算法解决TSP问题和轨迹平滑优化。


<details>
  <summary>Details</summary>
Motivation: 针对无人机在电网等复杂环境中的覆盖应用需求，需要规划既能高效访问所有兴趣点又满足平滑性、避障等约束的轨迹。

Method: 采用两阶段方法：前端使用遗传算法求解TSP问题生成初始访问序列，后端通过非线性最小二乘问题优化轨迹平滑度、时间和避障约束。

Result: 数值仿真验证了算法的有效性，确保无人机能够在复杂环境中平滑覆盖所有兴趣点。

Conclusion: 该算法能够有效解决无人机在复杂环境中的平滑覆盖轨迹规划问题，满足实际应用需求。

Abstract: For typical applications of UAVs in power grid scenarios, we construct the
problem as planning UAV trajectories for coverage in cluttered environments. In
this paper, we propose an optimal smooth coverage trajectory planning
algorithm. The algorithm consists of two stages. In the front-end, a Genetic
Algorithm (GA) is employed to solve the Traveling Salesman Problem (TSP) for
Points of Interest (POIs), generating an initial sequence of optimized visiting
points. In the back-end, the sequence is further optimized by considering
trajectory smoothness, time consumption, and obstacle avoidance. This is
formulated as a nonlinear least squares problem and solved to produce a smooth
coverage trajectory that satisfies these constraints. Numerical simulations
validate the effectiveness of the proposed algorithm, ensuring UAVs can
smoothly cover all POIs in cluttered environments.

</details>


### [33] [Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning](https://arxiv.org/abs/2510.03182)
*Yilun Hao,Yongchao Chen,Chuchu Fan,Yang Zhang*

Main category: cs.RO

TL;DR: VLMFP是一个双VLM引导的框架，能够自主生成PDDL问题文件和领域文件，解决视觉语言模型在视觉规划中空间和长时推理的不足。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉规划中具有潜力，但在精确空间和长时推理方面存在困难；而PDDL规划器擅长形式化规划但无法处理视觉输入。现有方法需要人工预定义领域文件或持续环境访问，限制了自主性。

Method: 提出VLMFP框架，包含两个VLM：SimVLM基于规则描述模拟动作后果，GenVLM通过比较PDDL和SimVLM执行结果来生成和迭代优化PDDL文件。

Result: 在6个网格世界领域测试中，SimVLM在可见和未见外观下分别准确描述95.5%/82.6%场景，模拟85.5%/87.8%动作序列，判断82.4%/85.6%目标达成。VLMFP在可见和未见外观下对未见实例分别生成70.0%/54.1%的有效规划。

Conclusion: VLMFP实现了多层次的泛化能力：生成的PDDL领域文件适用于同一问题下的所有实例，VLM能够泛化到具有不同外观和规则的问题中。

Abstract: Vision Language Models (VLMs) show strong potential for visual planning but
struggle with precise spatial and long-horizon reasoning. In contrast, Planning
Domain Definition Language (PDDL) planners excel at long-horizon formal
planning, but cannot interpret visual inputs. Recent works combine these
complementary advantages by enabling VLMs to turn visual planning problems into
PDDL files for formal planning. However, while VLMs can generate PDDL problem
files satisfactorily, they struggle to accurately generate the PDDL domain
files, which describe all the planning rules. As a result, prior methods rely
on human experts to predefine domain files or on constant environment access
for refinement. We propose VLMFP, a Dual-VLM-guided framework that can
autonomously generate both PDDL problem and domain files for formal visual
planning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A
SimVLM that simulates action consequences based on input rule descriptions, and
a GenVLM that generates and iteratively refines PDDL files by comparing the
PDDL and SimVLM execution results. VLMFP unleashes multiple levels of
generalizability: The same generated PDDL domain file works for all the
different instances under the same problem, and VLMs generalize to different
problems with varied appearances and rules. We evaluate VLMFP with 6 grid-world
domains and test its generalization to unseen instances, appearance, and game
rules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,
simulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal
reaching for seen and unseen appearances, respectively. With the guidance of
SimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for
unseen instances in seen and unseen appearances, respectively. Project page:
https://sites.google.com/view/vlmfp.

</details>
