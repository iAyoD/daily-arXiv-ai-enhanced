<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes](https://arxiv.org/abs/2510.00154)
*Xinyi Liu,Mohammadreza Fani Sani,Zewei Zhou,Julius Wirbel,Bahram Zarrin,Roberto Galeazzi*

Main category: cs.RO

TL;DR: RoboPilot是一个双思维闭环机器人操作框架，通过快速和慢速思维的动态切换来平衡效率和准确性，在动态环境中实现复杂任务的适应性推理和执行。


<details>
  <summary>Details</summary>
Motivation: 当前自主机器人系统大多采用开环范式，缺乏推理和反馈机制，导致对环境变化的鲁棒性差和错误累积严重。

Method: RoboPilot利用原始动作进行结构化任务规划和灵活动作生成，引入反馈机制实现动态变化和执行错误的重新规划，并通过思维链推理增强高层任务规划和指导低层动作生成。

Result: 实验显示RoboPilot在任务成功率上比最先进基线方法高出25.9%，在工业机器人的真实世界部署进一步证明了其鲁棒性。

Conclusion: RoboPilot框架通过双思维闭环设计显著提升了机器人操作系统的鲁棒性和适应性，为复杂长时程任务执行提供了有效解决方案。

Abstract: Despite rapid progress in autonomous robotics, executing complex or
long-horizon tasks remains a fundamental challenge. Most current approaches
follow an open-loop paradigm with limited reasoning and no feedback, resulting
in poor robustness to environmental changes and severe error accumulation. We
present RoboPilot, a dual-thinking closed-loop framework for robotic
manipulation that supports adaptive reasoning for complex tasks in real-world
dynamic environments. RoboPilot leverages primitive actions for structured task
planning and flexible action generation, while introducing feedback to enable
replanning from dynamic changes and execution errors. Chain-of-Thought
reasoning further enhances high-level task planning and guides low-level action
generation. The system dynamically switches between fast and slow thinking to
balance efficiency and accuracy. To systematically evaluate the robustness of
RoboPilot in diverse robot manipulation scenarios, we introduce
RoboPilot-Bench, a benchmark spanning 21 tasks across 10 categories, including
infeasible-task recognition and failure recovery. Experiments show that
RoboPilot outperforms state-of-the-art baselines by 25.9\% in task success
rate, and the real-world deployment on an industrial robot further demonstrates
its robustness in real-world settings.

</details>


### [2] [A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream](https://arxiv.org/abs/2510.00182)
*Jorge Mendez-Mendez*

Main category: cs.RO

TL;DR: 本文评估了使用Gemini 2.5 Flash替代TAMP关键组件的16种算法，发现在机器人任务规划中，LLM的成功率较低、规划时间较长，且几何细节会增加任务规划错误。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在机器人复杂问题中的规划能力，特别是如何将LLM的语义知识与TAMP的形式推理相结合，以覆盖更广泛的机器人任务空间。

Method: 开发了16种使用Gemini 2.5 Flash替代TAMP关键组件的算法，在4,950个问题和三个领域进行零样本实验，比较不同LLM变体的性能。

Result: 基于Gemini的规划器比工程化对应方案成功率更低、规划时间更长；提供几何细节会增加任务规划错误；非推理LLM变体在多数情况下优于推理变体。

Conclusion: LLM在TAMP系统中的集成需要谨慎设计，非推理LLM变体可能更有效，因为TAMP系统可以指导LLM纠正错误。

Abstract: Using large language models (LLMs) to solve complex robotics problems
requires understanding their planning capabilities. Yet while we know that LLMs
can plan on some problems, the extent to which these planning capabilities
cover the space of robotics tasks is unclear. One promising direction is to
integrate the semantic knowledge of LLMs with the formal reasoning of task and
motion planning (TAMP). However, the myriad of choices for how to integrate
LLMs within TAMP complicates the design of such systems. We develop 16
algorithms that use Gemini 2.5 Flash to substitute key TAMP components. Our
zero-shot experiments across 4,950 problems and three domains reveal that the
Gemini-based planners exhibit lower success rates and higher planning times
than their engineered counterparts. We show that providing geometric details
increases the number of task-planning errors compared to pure PDDL
descriptions, and that (faster) non-reasoning LLM variants outperform (slower)
reasoning variants in most cases, since the TAMP system can direct the LLM to
correct its mistakes.

</details>


### [3] [A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements](https://arxiv.org/abs/2510.00188)
*Alireza Aliyari,Gholamreza Vossoughi*

Main category: cs.RO

TL;DR: 提出了一种混合NMPC-DNN-PI控制器，将非线性模型预测控制的DNN近似与PI控制器结合，应用于外骨骼机器人的下蹲运动控制，显著提高了鲁棒性并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统NMPC计算负载重，而纯DNN近似方法在遇到训练数据未覆盖的扰动或工况时缺乏鲁棒性，导致跟踪误差增大。

Method: 开发了包含三个主动关节（踝、膝、髋）的人机动力学模型，使用530多万训练样本训练DNN，并将NMPC-DNN输出与PI控制器结合形成混合控制器。

Result: 在DNN未见条件下，混合控制器的跟踪误差显著低于纯NMPC-DNN；外骨骼使用使人体关节扭矩大幅降低（踝30.9%、膝41.8%、髋29.7%）；计算成本比NMPC降低99.93%。

Conclusion: 混合NMPC-DNN-PI控制器在保持NMPC精度的同时，显著提高了鲁棒性和计算效率，成功应用于复杂的外骨骼机器人控制。

Abstract: Nonlinear Model Predictive Control (NMPC) is a precise controller, but its
heavy computational load often prevents application in robotic systems. Some
studies have attempted to approximate NMPC using deep neural networks
(NMPC-DNN). However, in the presence of unexpected disturbances or when
operating conditions differ from training data, this approach lacks robustness,
leading to large tracking errors. To address this issue, for the first time,
the NMPC-DNN output is combined with a PI controller (Hybrid NMPC-DNN-PI). The
proposed controller is validated by applying it to an exoskeleton robot during
squat movement, which has a complex dynamic model and has received limited
attention regarding robust nonlinear control design. A human-robot dynamic
model with three active joints (ankle, knee, hip) is developed, and more than
5.3 million training samples are used to train the DNN. The results show that,
under unseen conditions for the DNN, the tracking error in Hybrid NMPC-DNN-PI
is significantly lower compared to NMPC-DNN. Moreover, human joint torques are
greatly reduced with the use of the exoskeleton, with RMS values for the
studied case reduced by 30.9%, 41.8%, and 29.7% at the ankle, knee, and hip,
respectively. In addition, the computational cost of Hybrid NMPC-DNN-PI is
99.93% lower than that of NMPC.

</details>


### [4] [TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks](https://arxiv.org/abs/2510.00225)
*Yue Meng,Fei Chen,Chuchu Fan*

Main category: cs.RO

TL;DR: TGPO是一种解决通用信号时序逻辑任务的分层强化学习方法，通过将STL分解为定时子目标和不变约束，使用高层时间分配和低层策略学习，显著提升了复杂任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂长时程任务的策略学习挑战，特别是信号时序逻辑的非马尔可夫性和稀疏奖励问题，现有方法只能处理有限的STL片段或使用稀疏奖励。

Method: 提出TGPO分层框架：高层组件分配子目标时间，低层时间条件策略使用密集的阶段奖励学习；利用学习到的critic通过Metropolis-Hastings采样指导高层时间搜索。

Result: 在5个环境中测试，TGPO在任务成功率上比最佳基线平均提升31.6%，特别是在高维和长时程情况下表现显著优于现有方法。

Conclusion: TGPO能够有效解决通用STL任务，通过分层结构和密集奖励机制克服了传统RL方法在复杂时序任务中的局限性。

Abstract: Learning control policies for complex, long-horizon tasks is a central
challenge in robotics and autonomous systems. Signal Temporal Logic (STL)
offers a powerful and expressive language for specifying such tasks, but its
non-Markovian nature and inherent sparse reward make it difficult to be solved
via standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus
only on limited STL fragments or use STL robustness scores as sparse terminal
rewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization,
to solve general STL tasks. TGPO decomposes STL into timed subgoals and
invariant constraints and provides a hierarchical framework to tackle the
problem. The high-level component of TGPO proposes concrete time allocations
for these subgoals, and the low-level time-conditioned policy learns to achieve
the sequenced subgoals using a dense, stage-wise reward signal. During
inference, we sample various time allocations and select the most promising
assignment for the policy network to rollout the solution trajectory. To foster
efficient policy learning for complex STL with multiple subgoals, we leverage
the learned critic to guide the high-level temporal search via
Metropolis-Hastings sampling, focusing exploration on temporally feasible
solutions. We conduct experiments on five environments, ranging from
low-dimensional navigation to manipulation, drone, and quadrupedal locomotion.
Under a wide range of STL tasks, TGPO significantly outperforms
state-of-the-art baselines (especially for high-dimensional and long-horizon
cases), with an average of 31.6% improvement in task success rate compared to
the best baseline. The code will be available at
https://github.com/mengyuest/TGPO

</details>


### [5] [BC-MPPI: A Probabilistic Constraint Layer for Safe Model-Predictive Path-Integral Control](https://arxiv.org/abs/2510.00272)
*Odichimnma Ezeji,Michael Ziegltrum,Giulio Turrisi,Tommaso Belvedere,Valerio Modugno*

Main category: cs.RO

TL;DR: BC-MPPI是一种轻量级安全层，为MPPI控制添加概率约束保证，通过概率代理评估轨迹可行性，自动降低可能违反约束的轨迹权重，无需手动调整惩罚成本。


<details>
  <summary>Details</summary>
Motivation: MPPI控制虽然快速且无需梯度，但缺乏硬性约束保证，需要一种轻量级方法来确保安全性。

Method: 为每个状态和输入约束附加概率代理，在每次重规划时评估候选轨迹的可行性概率，该概率缩放轨迹权重，自动将采样分布推向安全子集。

Result: 在四旋翼无人机上测试，BC-MPPI在保持安全裕度的同时满足规定的违反概率，适用于静态和动态障碍物场景。

Conclusion: 该方法提供独立、版本可控的安全代理，运行时安全评分是单一标量，自然集成到可认证自主系统的验证-确认流程中。

Abstract: Model Predictive Path Integral (MPPI) control has recently emerged as a fast,
gradient-free alternative to model-predictive control in highly non-linear
robotic tasks, yet it offers no hard guarantees on constraint satisfaction. We
introduce Bayesian-Constraints MPPI (BC-MPPI), a lightweight safety layer that
attaches a probabilistic surrogate to every state and input constraint. At each
re-planning step the surrogate returns the probability that a candidate
trajectory is feasible; this joint probability scales the weight given to a
candidate, automatically down-weighting rollouts likely to collide or exceed
limits and pushing the sampling distribution toward the safe subset; no
hand-tuned penalty costs or explicit sample rejection required. We train the
surrogate from 1000 offline simulations and deploy the controller on a
quadrotor in MuJoCo with both static and moving obstacles. Across K in
[100,1500] rollouts BC-MPPI preserves safety margins while satisfying the
prescribed probability of violation. Because the surrogate is a stand-alone,
version-controlled artefact and the runtime safety score is a single scalar,
the approach integrates naturally with verification-and-validation pipelines
for certifiable autonomous systems.

</details>


### [6] [Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning](https://arxiv.org/abs/2510.00329)
*Sarmad Mehrdad,Maxime Sabbah,Vincent Bonnet,Ludovic Righetti*

Main category: cs.RO

TL;DR: 该论文应用最小观测逆强化学习(MO-IRL)建模人类手臂伸展运动，通过分段学习时变成本权重，显著减少了所需演示数据和收敛时间，在关节角度预测上取得了6.4-5.6度的RMSE，优于静态权重方法的10.4度。


<details>
  <summary>Details</summary>
Motivation: 研究人类运动控制中的动态成本结构，传统IRL方法需要大量演示数据且收敛慢，需要更高效的算法来揭示时变成本权重。

Method: 使用平面双连杆生物力学模型和高分辨率运动捕捉数据，将轨迹分段为多个阶段，学习七个候选成本函数的阶段特定组合，通过MO-IRL迭代优化成本权重。

Result: 每个姿势10次试验训练，六段和八段权重划分的平均关节角度RMSE分别为6.4度和5.6度，优于静态权重的10.4度；交叉验证和跨被试验证均显示约8度RMSE的稳健泛化能力。

Conclusion: MO-IRL能有效揭示人类运动控制中动态、被试独立的成本结构，学习到的权重在运动起始和终止阶段强调关节加速度最小化，符合生物运动的平滑性原则，具有人形机器人应用的潜力。

Abstract: This paper investigates the application of Minimal Observation Inverse
Reinforcement Learning (MO-IRL) to model and predict human arm-reaching
movements with time-varying cost weights. Using a planar two-link biomechanical
model and high-resolution motion-capture data from subjects performing a
pointing task, we segment each trajectory into multiple phases and learn
phase-specific combinations of seven candidate cost functions. MO-IRL
iteratively refines cost weights by scaling observed and generated trajectories
in the maximum entropy IRL formulation, greatly reducing the number of required
demonstrations and convergence time compared to classical IRL approaches.
Training on ten trials per posture yields average joint-angle Root Mean Squared
Errors (RMSE) of 6.4 deg and 5.6 deg for six- and eight-segment weight
divisions, respectively, versus 10.4 deg using a single static weight.
Cross-validation on remaining trials and, for the first time, inter-subject
validation on an unseen subject's 20 trials, demonstrates comparable predictive
accuracy, around 8 deg RMSE, indicating robust generalization. Learned weights
emphasize joint acceleration minimization during movement onset and
termination, aligning with smoothness principles observed in biological motion.
These results suggest that MO-IRL can efficiently uncover dynamic,
subject-independent cost structures underlying human motor control, with
potential applications for humanoid robots.

</details>


### [7] [DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts](https://arxiv.org/abs/2510.00358)
*Linjin He,Xinda Qi,Dong Chen,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 提出DiSA-IQL方法，通过惩罚不可靠的状态-动作对来缓解离线强化学习中的分布偏移问题，在软蛇机器人控制任务中优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 软蛇机器人控制面临高度非线性动力学挑战，现有方法依赖简化假设限制性能。在线DRL训练成本高且危险，离线RL存在分布偏移问题影响泛化能力。

Method: 扩展IQL方法，引入分布偏移感知机制，通过鲁棒性调制惩罚不可靠的状态-动作对来缓解分布偏移。

Result: 在目标到达任务中，DiSA-IQL在分布内和分布外评估中均优于BC、CQL和标准IQL，获得更高成功率、更平滑轨迹和更好鲁棒性。

Conclusion: DiSA-IQL有效解决了离线RL在软机器人控制中的分布偏移问题，代码开源支持可复现性和进一步研究。

Abstract: Soft snake robots offer remarkable flexibility and adaptability in complex
environments, yet their control remains challenging due to highly nonlinear
dynamics. Existing model-based and bio-inspired controllers rely on simplified
assumptions that limit performance. Deep reinforcement learning (DRL) has
recently emerged as a promising alternative, but online training is often
impractical because of costly and potentially damaging real-world interactions.
Offline RL provides a safer option by leveraging pre-collected datasets, but it
suffers from distribution shift, which degrades generalization to unseen
scenarios. To overcome this challenge, we propose DiSA-IQL
(Distribution-Shift-Aware Implicit Q-Learning), an extension of IQL that
incorporates robustness modulation by penalizing unreliable state-action pairs
to mitigate distribution shift. We evaluate DiSA-IQL on goal-reaching tasks
across two settings: in-distribution and out-of-distribution evaluation.
Simulation results show that DiSA-IQL consistently outperforms baseline models,
including Behavior Cloning (BC), Conservative Q-Learning (CQL), and vanilla
IQL, achieving higher success rates, smoother trajectories, and improved
robustness. The codes are open-sourced to support reproducibility and to
facilitate further research in offline RL for soft robot control.

</details>


### [8] [Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting](https://arxiv.org/abs/2510.00401)
*Shounak Sural,Charles Kekeh,Wenliang Liu,Federico Pecora,Mouhacine Benosman*

Main category: cs.RO

TL;DR: 提出了PINCoDE模型，一种基于神经控制微分方程的物理信息多机器人轨迹预测方法，能够在连续时间内结合物理约束进行长时程运动预测。


<details>
  <summary>Details</summary>
Motivation: 解决多自主机器人长时程运动预测的挑战，包括非线性交互、预测误差累积和连续时间动态演化，为旅行时间预测、规划引导和生成仿真等应用提供支持。

Method: 使用神经控制微分方程（CDEs）在连续时间内建模多机器人动力学，结合物理信息约束和偏差，模型可基于未来目标进行条件预测，无需额外参数即可从10个机器人扩展到100个机器人。

Result: 在1分钟预测时域内平均ADE低于0.5米，通过课程学习的渐进训练在4分钟时域内比解析模型减少2.7倍的位姿误差。

Conclusion: PINCoDE通过连续时间建模和物理约束的结合，有效解决了多机器人长时程轨迹预测问题，具有良好的可扩展性和预测精度。

Abstract: Long-horizon motion forecasting for multiple autonomous robots is challenging
due to non-linear agent interactions, compounding prediction errors, and
continuous-time evolution of dynamics. Learned dynamics of such a system can be
useful in various applications such as travel time prediction,
prediction-guided planning and generative simulation. In this work, we aim to
develop an efficient trajectory forecasting model conditioned on multi-agent
goals. Motivated by the recent success of physics-guided deep learning for
partially known dynamical systems, we develop a model based on neural
Controlled Differential Equations (CDEs) for long-horizon motion forecasting.
Unlike discrete-time methods such as RNNs and transformers, neural CDEs operate
in continuous time, allowing us to combine physics-informed constraints and
biases to jointly model multi-robot dynamics. Our approach, named PINCoDE
(Physics-Informed Neural Controlled Differential Equations), learns
differential equation parameters that can be used to predict the trajectories
of a multi-agent system starting from an initial condition. PINCoDE is
conditioned on future goals and enforces physics constraints for robot motion
over extended periods of time. We adopt a strategy that scales our model from
10 robots to 100 robots without the need for additional model parameters, while
producing predictions with an average ADE below 0.5 m for a 1-minute horizon.
Furthermore, progressive training with curriculum learning for our PINCoDE
model results in a 2.7X reduction of forecasted pose error over 4 minute
horizons compared to analytical models.

</details>


### [9] [VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators](https://arxiv.org/abs/2510.00406)
*Hengtao Li,Pengxiang Ding,Runze Suo,Yihao Wang,Zirui Ge,Dongyuan Zang,Kexian Yu,Mingyang Sun,Hongyin Zhang,Donglin Wang,Weihua Su*

Main category: cs.RO

TL;DR: VLA-RFT是一个基于世界模型的强化微调框架，通过数据驱动的可控模拟器来增强视觉-语言-动作模型的泛化性和鲁棒性，仅需不到400步微调就能超越监督基线。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型严重依赖模仿学习，容易产生累积错误且在分布偏移下鲁棒性差。强化学习可以缓解这些问题，但通常需要昂贵的真实世界交互或受限于仿真到真实的差距。

Method: 利用从真实交互数据训练的世界模型作为可控模拟器，预测基于动作的未来视觉观察，从而在策略rollout中获得密集的轨迹级奖励信号。

Result: 仅需不到400步微调就超越了强监督基线，比基于模拟器的强化学习更高效，在扰动条件下表现出强大的鲁棒性，保持稳定的任务执行。

Conclusion: 基于世界模型的强化微调是一种实用的后训练范式，能够有效增强VLA模型的泛化性和鲁棒性。

Abstract: Vision-Language-Action (VLA) models enable embodied decision-making but rely
heavily on imitation learning, leading to compounding errors and poor
robustness under distribution shift. Reinforcement learning (RL) can mitigate
these issues yet typically demands costly real-world interactions or suffers
from sim-to-real gaps. We introduce VLA-RFT, a reinforcement fine-tuning
framework that leverages a data-driven world model as a controllable simulator.
Trained from real interaction data, the simulator predicts future visual
observations conditioned on actions, allowing policy rollouts with dense,
trajectory-level rewards derived from goal-achieving references. This design
delivers an efficient and action-aligned learning signal, drastically lowering
sample requirements. With fewer than 400 fine-tuning steps, VLA-RFT surpasses
strong supervised baselines and achieves greater efficiency than
simulator-based RL. Moreover, it exhibits strong robustness under perturbed
conditions, sustaining stable task execution. Our results establish
world-model-based RFT as a practical post-training paradigm to enhance the
generalization and robustness of VLA models. For more details, please refer to
https://vla-rft.github.io/.

</details>


### [10] [Seeing through Uncertainty: Robust Task-Oriented Optimization in Visual Navigation](https://arxiv.org/abs/2510.00441)
*Yiyuan Pan,Yunzhe Xu,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: NeuRO是一个集成学习优化框架，将感知网络与下游任务级鲁棒优化紧密结合，通过部分输入凸神经网络和保形校准将视觉预测转化为凸不确定性集合，解决了数据稀缺下的视觉导航泛化问题。


<details>
  <summary>Details</summary>
Motivation: 视觉导航是具身AI的基础问题，但实际部署需要长时程规划能力来处理多目标任务。主要瓶颈是数据稀缺：从有限数据学习的策略容易过拟合且无法泛化到分布外场景。现有神经网络代理通常增加架构复杂度，但在小样本场景中适得其反。

Method: NeuRO框架：(i) 使用部分输入凸神经网络(PICNNs)和保形校准将噪声视觉预测转化为凸不确定性集合，直接参数化优化约束；(ii) 将部分可观测性下的规划重新表述为鲁棒优化问题，实现跨环境转移的不确定性感知策略。

Result: 在无序和顺序多目标导航任务上的广泛实验表明，NeuRO实现了最先进的性能，特别是在未见环境的泛化方面表现突出。

Conclusion: 这项工作为开发鲁棒、可泛化的自主智能体提供了重要进展。

Abstract: Visual navigation is a fundamental problem in embodied AI, yet practical
deployments demand long-horizon planning capabilities to address
multi-objective tasks. A major bottleneck is data scarcity: policies learned
from limited data often overfit and fail to generalize OOD. Existing neural
network-based agents typically increase architectural complexity that
paradoxically become counterproductive in the small-sample regime. This paper
introduce NeuRO, a integrated learning-to-optimize framework that tightly
couples perception networks with downstream task-level robust optimization.
Specifically, NeuRO addresses core difficulties in this integration: (i) it
transforms noisy visual predictions under data scarcity into convex uncertainty
sets using Partially Input Convex Neural Networks (PICNNs) with conformal
calibration, which directly parameterize the optimization constraints; and (ii)
it reformulates planning under partial observability as a robust optimization
problem, enabling uncertainty-aware policies that transfer across environments.
Extensive experiments on both unordered and sequential multi-object navigation
tasks demonstrate that NeuRO establishes SoTA performance, particularly in
generalization to unseen environments. Our work thus presents a significant
advancement for developing robust, generalizable autonomous agents.

</details>


### [11] [Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation](https://arxiv.org/abs/2510.00466)
*Run Su,Hao Fu,Shuai Zhou,Yingao Fu*

Main category: cs.RO

TL;DR: 提出了一种新颖的离线到在线微调强化学习算法，通过将Return-to-Go预测集成到因果Transformer架构中，解决机器人社交导航中的分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在机器人社交导航中存在局限性，包括行人行为的不确定性和训练期间环境交互有限，导致次优探索和离线训练与在线部署之间的分布偏移。

Method: 采用时空融合模型实时精确估计RTG值，联合编码时间行人运动模式和空间人群动态；构建混合离线-在线经验采样机制，稳定微调期间的政策更新。

Result: 在模拟社交导航环境中的广泛实验表明，与最先进的基线相比，该方法实现了更高的成功率和更低的碰撞率。

Conclusion: 该算法在增强导航策略的鲁棒性和适应性方面具有显著效果，为现实应用中更可靠和自适应的机器人导航系统铺平了道路。

Abstract: Offline reinforcement learning (RL) has emerged as a promising framework for
addressing robot social navigation challenges. However, inherent uncertainties
in pedestrian behavior and limited environmental interaction during training
often lead to suboptimal exploration and distributional shifts between offline
training and online deployment. To overcome these limitations, this paper
proposes a novel offline-to-online fine-tuning RL algorithm for robot social
navigation by integrating Return-to-Go (RTG) prediction into a causal
Transformer architecture. Our algorithm features a spatiotem-poral fusion model
designed to precisely estimate RTG values in real-time by jointly encoding
temporal pedestrian motion patterns and spatial crowd dynamics. This RTG
prediction framework mitigates distribution shift by aligning offline policy
training with online environmental interactions. Furthermore, a hybrid
offline-online experience sampling mechanism is built to stabilize policy
updates during fine-tuning, ensuring balanced integration of pre-trained
knowledge and real-time adaptation. Extensive experiments in simulated social
navigation environments demonstrate that our method achieves a higher success
rate and lower collision rate compared to state-of-the-art baselines. These
results underscore the efficacy of our algorithm in enhancing navigation policy
robustness and adaptability. This work paves the way for more reliable and
adaptive robotic navigation systems in real-world applications.

</details>


### [12] [From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment](https://arxiv.org/abs/2510.00491)
*Han Zhou,Jinjin Cao,Liyuan Ma,Xueji Fang,Guo-jun Qi*

Main category: cs.RO

TL;DR: Traj2Action是一个新框架，通过使用操作端点的3D轨迹作为统一中间表示，弥合人类与机器人之间的形态差距，实现从人类视频到机器人操作技能的迁移学习。


<details>
  <summary>Details</summary>
Motivation: 解决机器人多样化操作技能学习依赖昂贵遥操作演示的问题，利用可扩展的人类视频作为替代，但面临人类与机器人形态差异的挑战。

Method: 使用3D轨迹作为中间表示，首先生成粗略轨迹作为高层运动规划，然后在协同去噪框架中合成精确的机器人特定动作。

Result: 在Franka机器人上的真实世界实验显示，Traj2Action在短时和长时任务上分别比基线提升27%和22.25%，且随着人类数据规模扩大，机器人策略学习效果显著提升。

Conclusion: Traj2Action通过轨迹中间表示有效解决了人类-机器人形态差距问题，为从人类视频学习机器人操作技能提供了可行方案。

Abstract: Learning diverse manipulation skills for real-world robots is severely
bottlenecked by the reliance on costly and hard-to-scale teleoperated
demonstrations. While human videos offer a scalable alternative, effectively
transferring manipulation knowledge is fundamentally hindered by the
significant morphological gap between human and robotic embodiments. To address
this challenge and facilitate skill transfer from human to robot, we introduce
Traj2Action,a novel framework that bridges this embodiment gap by using the 3D
trajectory of the operational endpoint as a unified intermediate
representation, and then transfers the manipulation knowledge embedded in this
trajectory to the robot's actions. Our policy first learns to generate a coarse
trajectory, which forms an high-level motion plan by leveraging both human and
robot data. This plan then conditions the synthesis of precise, robot-specific
actions (e.g., orientation and gripper state) within a co-denoising framework.
Extensive real-world experiments on a Franka robot demonstrate that Traj2Action
boosts the performance by up to 27% and 22.25% over $\pi_0$ baseline on short-
and long-horizon real-world tasks, and achieves significant gains as human data
scales in robot policy learning. Our project website, featuring code and video
demonstrations, is available at
https://anonymous.4open.science/w/Traj2Action-4A45/.

</details>


### [13] [Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion](https://arxiv.org/abs/2510.00524)
*Baoshan Song,Penggao Yan,Xiao Xia,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 提出了一种两阶段异常值检测方法，用于GNSS-RTK/INS/里程计紧耦合系统，通过多普勒测量和预积分约束来检测和消除伪距异常值，提高复杂环境下的定位精度。


<details>
  <summary>Details</summary>
Motivation: 复杂环境中的GNSS定位面临非视距传播、多径效应和信号遮挡等挑战，这些因素会导致伪距测量出现大异常值，严重影响RTK定位性能和紧耦合导航系统的有效性。

Method: 采用两阶段异常值检测：第一阶段使用多普勒测量进行GNSS-only异常检测；第二阶段利用预积分IMU和里程计约束生成预测的双差伪距测量，进行更精细的异常识别和剔除。基于因子图优化的紧耦合GNSS-RTK/INS/里程计集成。

Result: 实验结果表明，两阶段检测框架显著降低了伪距异常值的影响，提高了定位精度和一致性。在深度城市峡谷测试中，异常值抑制方法将融合系统的RMSE从0.52米降低到0.30米，提升了42.3%。

Conclusion: 通过结合两种互补的检测阶段，系统对粗大伪距误差和卫星测量质量下降具有更强的鲁棒性，在复杂城市环境中实现了更可靠的GNSS定位性能。

Abstract: Reliable GNSS positioning in complex environments remains a critical
challenge due to non-line-of-sight (NLOS) propagation, multipath effects, and
frequent signal blockages. These effects can easily introduce large outliers
into the raw pseudo-range measurements, which significantly degrade the
performance of global navigation satellite system (GNSS) real-time kinematic
(RTK) positioning and limit the effectiveness of tightly coupled GNSS-based
integrated navigation system. To address this issue, we propose a two-stage
outlier detection method and apply the method in a tightly coupled GNSS-RTK,
inertial navigation system (INS), and odometer integration based on factor
graph optimization (FGO). In the first stage, Doppler measurements are employed
to detect pseudo-range outliers in a GNSS-only manner, since Doppler is less
sensitive to multipath and NLOS effects compared with pseudo-range, making it a
more stable reference for detecting sudden inconsistencies. In the second
stage, pre-integrated inertial measurement units (IMU) and odometer constraints
are used to generate predicted double-difference pseudo-range measurements,
which enable a more refined identification and rejection of remaining outliers.
By combining these two complementary stages, the system achieves improved
robustness against both gross pseudo-range errors and degraded satellite
measuring quality. The experimental results demonstrate that the two-stage
detection framework significantly reduces the impact of pseudo-range outliers,
and leads to improved positioning accuracy and consistency compared with
representative baseline approaches. In the deep urban canyon test, the outlier
mitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52
m to 0.30 m, with 42.3% improvement.

</details>


### [14] [GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks](https://arxiv.org/abs/2510.00573)
*Yen-Ling Tai,Yi-Ru Yang,Kuan-Ting Yu,Yu-Wei Chao,Yi-Ting Chen*

Main category: cs.RO

TL;DR: GRITS是一个基于引导扩散策略的机器人食物舀取框架，通过预测溢出概率来指导动作生成，显著减少食物溢出并保持任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习算法在处理多样化和动态变化的食物状态时表现不佳，容易导致食物溢出和可靠性降低，需要开发更有效的食物舀取方法。

Method: 设计溢出预测器估计当前观察和动作序列下的溢出概率，在模拟数据上训练，并在推理时作为可微分引导信号指导扩散采样过程生成更安全的轨迹。

Result: 在真实机器人平台上验证，在6种食物类别上训练，在10种未见类别上评估，达到82%任务成功率和4%溢出率，相比无引导基线溢出率降低40%以上。

Conclusion: GRITS框架通过引导扩散策略有效减少了食物舀取过程中的溢出问题，在多样食物类别上表现出良好的泛化能力和可靠性。

Abstract: Robotic food scooping is a critical manipulation skill for food preparation
and service robots. However, existing robot learning algorithms, especially
learn-from-demonstration methods, still struggle to handle diverse and dynamic
food states, which often results in spillage and reduced reliability. In this
work, we introduce GRITS: A Spillage-Aware Guided Diffusion Policy for Robot
Food Scooping Tasks. This framework leverages guided diffusion policy to
minimize food spillage during scooping and to ensure reliable transfer of food
items from the initial to the target location. Specifically, we design a
spillage predictor that estimates the probability of spillage given current
observation and action rollout. The predictor is trained on a simulated dataset
with food spillage scenarios, constructed from four primitive shapes (spheres,
cubes, cones, and cylinders) with varied physical properties such as mass,
friction, and particle size. At inference time, the predictor serves as a
differentiable guidance signal, steering the diffusion sampling process toward
safer trajectories while preserving task success. We validate GRITS on a
real-world robotic food scooping platform. GRITS is trained on six food
categories and evaluated on ten unseen categories with different shapes and
quantities. GRITS achieves an 82% task success rate and a 4% spillage rate,
reducing spillage by over 40% compared to baselines without guidance, thereby
demonstrating its effectiveness.

</details>


### [15] [Hybrid Training for Vision-Language-Action Models](https://arxiv.org/abs/2510.00600)
*Pietro Mazzaglia,Cansu Sancaktar,Markus Peschl,Daniel Dijkman*

Main category: cs.RO

TL;DR: 提出Hybrid Training (HyT)框架，让视觉语言动作模型在训练时学习思维链，但在推理时可以选择跳过思维生成直接输出动作，从而提升效率。


<details>
  <summary>Details</summary>
Motivation: 思维链(CoT)技术虽然能提升模型性能，但会显著增加推理时间，这在需要实时响应的机器人操作场景中严重影响可用性。

Method: HyT框架让模型在训练时学习思维链，但推理时可以条件性地选择是否生成思维，直接输出动作。

Result: 在模拟基准测试和真实世界实验中验证了方法的有效性。

Conclusion: HyT框架实现了性能提升与推理效率的平衡，支持推理时的灵活输出选择。

Abstract: Using Large Language Models to produce intermediate thoughts, a.k.a.
Chain-of-thought (CoT), before providing an answer has been a successful recipe
for solving complex language tasks. In robotics, similar embodied CoT
strategies, generating thoughts before actions, have also been shown to lead to
improved performance when using Vision-Language-Action models (VLAs). As these
techniques increase the length of the model's generated outputs to include the
thoughts, the inference time is negatively affected. Delaying an agent's
actions in real-world executions, as in robotic manipulation settings, strongly
affects the usability of a method, as tasks require long sequences of actions.
However, is the generation of long chains-of-thought a strong prerequisite for
achieving performance improvements? In this work, we explore the idea of Hybrid
Training (HyT), a framework that enables VLAs to learn from thoughts and
benefit from the associated performance gains, while enabling the possibility
to leave out CoT generation during inference. Furthermore, by learning to
conditionally predict a diverse set of outputs, HyT supports flexibility at
inference time, enabling the model to either predict actions directly, generate
thoughts or follow instructions. We evaluate the proposed method in a series of
simulated benchmarks and real-world experiments.

</details>


### [16] [What Did I Learn? Operational Competence Assessment for AI-Based Trajectory Planners](https://arxiv.org/abs/2510.00619)
*Michiel Braat,Maren Buermann,Marijke van Weperen,Jan-Pieter Paardekooper*

Main category: cs.RO

TL;DR: 提出一种基于知识图谱的方法来识别自动驾驶车辆未充分训练的场景，通过分析训练数据中特定子场景配置的覆盖率和复杂性来评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 确保机器学习在自动驾驶中的安全使用，需要识别模型未充分训练的场景，并提高数据集的可解释性。

Method: 将驾驶数据建模为知识图谱，表示场景中的实体及其关系，通过查询特定子场景配置来检查其在数据集中的出现情况。

Result: 在NuPlan数据集上应用该方法，成功建模知识图谱并分析特定驾驶场景的覆盖情况。

Conclusion: 该方法有助于监控基于数据集训练的机器学习模型的能力，对于在自动驾驶中部署可信AI至关重要。

Abstract: Automated driving functions increasingly rely on machine learning for tasks
like perception and trajectory planning, requiring large, relevant datasets.
The performance of these algorithms depends on how closely the training data
matches the task. To ensure reliable functioning, it is crucial to know what is
included in the dataset to assess the trained model's operational risk. We aim
to enhance the safe use of machine learning in automated driving by developing
a method to recognize situations that an automated vehicle has not been
sufficiently trained on. This method also improves explainability by describing
the dataset at a human-understandable level. We propose modeling driving data
as knowledge graphs, representing driving scenes with entities and their
relationships. These graphs are queried for specific sub-scene configurations
to check their occurrence in the dataset. We estimate a vehicle's competence in
a driving scene by considering the coverage and complexity of sub-scene
configurations in the training set. Higher complexity scenes require greater
coverage for high competence. We apply this method to the NuPlan dataset,
modeling it with knowledge graphs and analyzing the coverage of specific
driving scenes. This approach helps monitor the competence of machine learning
models trained on the dataset, which is essential for trustworthy AI to be
deployed in automated driving.

</details>


### [17] [Trajectory Based Observer Design: A Framework for Lightweight Sensor Fusion](https://arxiv.org/abs/2510.00630)
*Federico Oliva,Tom Shaked,Daniele Carnevale,Amir Degani*

Main category: cs.RO

TL;DR: 提出了一种基于轨迹的优化设计方法，用于设计非线性系统和多传感器设置的观测器，通过数值优化调整观测器参数。


<details>
  <summary>Details</summary>
Motivation: 高效的观测器设计和精确的传感器融合在状态估计中至关重要，需要一种轻量级、通用的方法来简化观测器设计过程。

Method: 使用预记录的测量轨迹，通过数值优化调整参数化观测器动态，结合经典观测器理论和移动水平估计器方法。

Result: 在陆地漫游车定位问题中测试，与扩展卡尔曼滤波器相比，位置估计精度相当，但方向估计显著改善。

Conclusion: TBOD方法提供了一种简单直接的调优程序，能够高效、模块化地处理通用传感器，是一种有效的传感器融合方法。

Abstract: Efficient observer design and accurate sensor fusion are key in state
estimation. This work proposes an optimization-based methodology, termed
Trajectory Based Optimization Design (TBOD), allowing the user to easily design
observers for general nonlinear systems and multi-sensor setups. Starting from
parametrized observer dynamics, the proposed method considers a finite set of
pre-recorded measurement trajectories from the nominal plant and exploits them
to tune the observer parameters through numerical optimization. This research
hinges on the classic observer's theory and Moving Horizon Estimators
methodology. Optimization is exploited to ease the observer's design, providing
the user with a lightweight, general-purpose sensor fusion methodology. TBOD's
main characteristics are the capability to handle general sensors efficiently
and in a modular way and, most importantly, its straightforward tuning
procedure. The TBOD's performance is tested on a terrestrial rover localization
problem, combining IMU and ranging sensors provided by Ultra Wide Band
antennas, and validated through a motion-capture system. Comparison with an
Extended Kalman Filter is also provided, matching its position estimation
accuracy and significantly improving in the orientation.

</details>


### [18] [Enabling High-Frequency Cross-Modality Visual Positioning Service for Accurate Drone Landing](https://arxiv.org/abs/2510.00646)
*Haoyang Wang,Xinyu Luo,Wenhua Ding,Jingao Xu,Xuecheng Chen,Ruiyang Duan,Jialong Chen,Haitao Zhang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: EV-Pose是一个基于事件相机的无人机视觉定位系统，通过时空特征引导的姿态估计和运动感知的层次融合优化，实现了高精度、低延迟的6自由度姿态跟踪，显著提升了无人机着陆精度。


<details>
  <summary>Details</summary>
Motivation: 传统GPS在城市场景中由于信号衰减和多径传播不可靠，现有视觉定位系统在无人机上部署时存在精度和效率限制，需要重新设计面向无人机的视觉定位服务。

Method: 引入时空特征引导的姿态估计模块提取时序距离场进行3D点云匹配；采用运动感知的层次融合优化方案，在事件过滤早期阶段和姿态优化后期阶段利用无人机运动信息。

Result: EV-Pose实现了1.34°的旋转精度和6.9mm的平移精度，跟踪延迟为10.08ms，比基线方法提升超过50%。

Conclusion: EV-Pose能够实现精确的无人机着陆，为无人机物流配送提供了可靠的姿态跟踪解决方案。

Abstract: After years of growth, drone-based delivery is transforming logistics. At its
core, real-time 6-DoF drone pose tracking enables precise flight control and
accurate drone landing. With the widespread availability of urban 3D maps, the
Visual Positioning Service (VPS), a mobile pose estimation system, has been
adapted to enhance drone pose tracking during the landing phase, as
conventional systems like GPS are unreliable in urban environments due to
signal attenuation and multi-path propagation. However, deploying the current
VPS on drones faces limitations in both estimation accuracy and efficiency. In
this work, we redesign drone-oriented VPS with the event camera and introduce
EV-Pose to enable accurate, high-frequency 6-DoF pose tracking for accurate
drone landing. EV-Pose introduces a spatio-temporal feature-instructed pose
estimation module that extracts a temporal distance field to enable 3D point
map matching for pose estimation; and a motion-aware hierarchical fusion and
optimization scheme to enhance the above estimation in accuracy and efficiency,
by utilizing drone motion in the \textit{early stage} of event filtering and
the \textit{later stage} of pose optimization. Evaluation shows that EV-Pose
achieves a rotation accuracy of 1.34$\degree$ and a translation accuracy of
6.9$mm$ with a tracking latency of 10.08$ms$, outperforming baselines by
$>$50\%, \tmcrevise{thus enabling accurate drone landings.} Demo:
https://ev-pose.github.io/

</details>


### [19] [Shared Object Manipulation with a Team of Collaborative Quadrupeds](https://arxiv.org/abs/2510.00682)
*Shengzhi Wang,Niels Dehio,Xuanqi Zeng,Xian Yang,Lingwei Zhang,Yun-Hui Liu,K. W. Samuel Au*

Main category: cs.RO

TL;DR: 将经典混合运动-力控制器扩展到腿式机械臂系统，实现多机器人协作搬运刚性物体


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在处理笨重物体方面具有优势，但现有研究多关注多机械臂系统，受限于工作空间约束

Method: 扩展经典混合运动-力控制器到腿式机械臂系统，采用力闭合抓取方式实现协作搬运

Result: 机器人能够灵活协调运动，实现高效稳定的物体协作搬运和运输，通过大量仿真和真实实验验证

Conclusion: 该方法成功实现了多腿式机械臂系统的协作搬运能力，克服了传统多机械臂系统的工作空间限制

Abstract: Utilizing teams of multiple robots is advantageous for handling bulky
objects. Many related works focus on multi-manipulator systems, which are
limited by workspace constraints. In this paper, we extend a classical hybrid
motion-force controller to a team of legged manipulator systems, enabling
collaborative loco-manipulation of rigid objects with a force-closed grasp. Our
novel approach allows the robots to flexibly coordinate their movements,
achieving efficient and stable object co-manipulation and transport, validated
through extensive simulations and real-world experiments.

</details>


### [20] [HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy](https://arxiv.org/abs/2510.00695)
*Myungkyu Koo,Daewon Choi,Taeyoung Kim,Kyungmin Lee,Changyeon Kim,Youngyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: HAMLET是一个可扩展框架，通过引入时刻令牌和轻量级记忆模块，使视觉-语言-动作模型能够利用历史上下文信息进行动作预测，显著提升了在需要历史依赖的长期任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型仅依赖当前观察而忽略历史上下文，但机器人操作任务本质上是历史依赖的，利用过去上下文可能带来益处。

Method: 提出时刻令牌紧凑编码每个时间步的感知信息，通过时间对比学习初始化表示；使用轻量级记忆模块整合过去时刻令牌为记忆特征，用于动作预测。

Result: 在GR00T N1.5上，HAMLET在历史依赖的真实世界任务中平均成功率76.4%，比基线提升47.2%；在RoboCasa Kitchen上从64.1%提升到66.4%，在LIBERO上从95.6%提升到97.7%。

Conclusion: HAMLET成功将最先进的VLA转化为历史感知策略，在需要历史上下文的任务上表现显著提升，证明了其有效性。

Abstract: Inherently, robotic manipulation tasks are history-dependent: leveraging past
context could be beneficial. However, most existing Vision-Language-Action
models (VLAs) have been designed without considering this aspect, i.e., they
rely solely on the current observation, ignoring preceding context. In this
paper, we propose HAMLET, a scalable framework to adapt VLAs to attend to the
historical context during action prediction. Specifically, we introduce moment
tokens that compactly encode perceptual information at each timestep. Their
representations are initialized with time-contrastive learning, allowing them
to better capture temporally distinctive aspects. Next, we employ a lightweight
memory module that integrates the moment tokens across past timesteps into
memory features, which are then leveraged for action prediction. Through
empirical evaluation, we show that HAMLET successfully transforms a
state-of-the-art VLA into a history-aware policy, especially demonstrating
significant improvements on long-horizon tasks that require historical context.
In particular, on top of GR00T N1.5, HAMLET achieves an average success rate of
76.4% on history-dependent real-world tasks, surpassing the baseline
performance by 47.2%. Furthermore, HAMLET pushes prior art performance from
64.1% to 66.4% on RoboCasa Kitchen (100-demo setup) and from 95.6% to 97.7% on
LIBERO, highlighting its effectiveness even under generic robot-manipulation
benchmarks.

</details>


### [21] [MultiPhysio-HRC: Multimodal Physiological Signals Dataset for industrial Human-Robot Collaboration](https://arxiv.org/abs/2510.00703)
*Andrea Bussolan,Stefano Baraldo,Oliver Avram,Pablo Urcola,Luis Montesano,Luca Maria Gambardella,Anna Valente*

Main category: cs.RO

TL;DR: MultiPhysio-HRC是一个多模态数据集，包含在真实人机协作场景中收集的生理、音频和面部数据，用于情感计算和人类感知机器人研究。


<details>
  <summary>Details</summary>
Motivation: 工业5.0中人机协作需要感知人类心理生理状态（如压力和认知负荷），以实现自适应和人类感知的机器人系统。

Method: 构建包含EEG、ECG、EDA、RESP、EMG、语音记录和面部动作单元的多模态数据集，结合受控认知任务、沉浸式虚拟现实体验和工业拆卸活动，并通过验证的心理自我评估问卷获得丰富的地面真实注释。

Result: 评估了压力和认知负荷分类的基线模型，展示了该数据集在情感计算和人类感知机器人研究中的潜力。

Conclusion: MultiPhysio-HRC数据集已公开可用，支持以人为中心的自动化、工作场所福祉和智能机器人系统的研究。

Abstract: Human-robot collaboration (HRC) is a key focus of Industry 5.0, aiming to
enhance worker productivity while ensuring well-being. The ability to perceive
human psycho-physical states, such as stress and cognitive load, is crucial for
adaptive and human-aware robotics. This paper introduces MultiPhysio-HRC, a
multimodal dataset containing physiological, audio, and facial data collected
during real-world HRC scenarios. The dataset includes electroencephalography
(EEG), electrocardiography (ECG), electrodermal activity (EDA), respiration
(RESP), electromyography (EMG), voice recordings, and facial action units. The
dataset integrates controlled cognitive tasks, immersive virtual reality
experiences, and industrial disassembly activities performed manually and with
robotic assistance, to capture a holistic view of the participants' mental
states. Rich ground truth annotations were obtained using validated
psychological self-assessment questionnaires. Baseline models were evaluated
for stress and cognitive load classification, demonstrating the dataset's
potential for affective computing and human-aware robotics research.
MultiPhysio-HRC is publicly available to support research in human-centered
automation, workplace well-being, and intelligent robotic systems.

</details>


### [22] [CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation](https://arxiv.org/abs/2510.00726)
*Giovanni Minelli,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 提出了一种跨状态转换注意力Transformer，通过状态转换注意力机制来建模状态演化模式，结合训练时的时序掩码，提升机器人操作策略对执行变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 监督学习训练的机器人操作策略在执行遇到训练数据中未明确覆盖的变化时表现不佳，现有注意力机制未能显式建模演示数据中的时序结构（如失败和恢复模式）。

Method: 使用状态转换注意力机制来调节标准注意力权重，基于学习到的状态演化模式；结合训练时的时序掩码，随机移除最近时间步的视觉信息以鼓励从历史上下文中进行时序推理。

Result: 在仿真评估中，STA在所有任务上都优于标准交叉注意力和时序建模方法（如TCN和LSTM网络），在精度关键任务上比交叉注意力提升超过2倍。

Conclusion: 提出的状态转换注意力机制能够有效提升机器人操作策略对执行变化的适应能力，通过显式建模状态演化模式实现更好的性能。

Abstract: Learning robotic manipulation policies through supervised learning from
demonstrations remains challenging when policies encounter execution variations
not explicitly covered during training. While incorporating historical context
through attention mechanisms can improve robustness, standard approaches
process all past states in a sequence without explicitly modeling the temporal
structure that demonstrations may include, such as failure and recovery
patterns. We propose a Cross-State Transition Attention Transformer that
employs a novel State Transition Attention (STA) mechanism to modulate standard
attention weights based on learned state evolution patterns, enabling policies
to better adapt their behavior based on execution history. Our approach
combines this structured attention with temporal masking during training, where
visual information is randomly removed from recent timesteps to encourage
temporal reasoning from historical context. Evaluation in simulation shows that
STA consistently outperforms standard cross-attention and temporal modeling
approaches like TCN and LSTM networks across all tasks, achieving more than 2x
improvement over cross-attention on precision-critical tasks.

</details>


### [23] [Tele-rehabilitation with online skill transfer and adaptation in $\mathbb{R}^3 \times \mathit{S}^3$](https://arxiv.org/abs/2510.00770)
*Tianle Ni,Xiao Chen,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种用于机器人辅助远程康复的远程教学框架，通过双边遥操作连接治疗师和患者端的机器人，使治疗师能够远程演示康复训练动作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够实现远程康复训练的系统，让治疗师可以远程指导患者进行康复训练，提高康复训练的可及性和个性化程度。

Method: 使用双边遥操作连接治疗师和患者端的机器人，采用6自由度动态运动基元在R³×S³空间中编码平移和旋转运动，支持治疗师引导和患者被动训练之间的平滑过渡。

Result: 使用7自由度机械臂进行的实验证明了该方法的可行性，展示了其在个性化和远程监督康复中的潜力。

Conclusion: 该框架为机器人辅助远程康复提供了一种有效的解决方案，能够实现准确的轨迹再现和自适应运动调整。

Abstract: This paper proposes a tele-teaching framework for the domain of
robot-assisted tele-rehabilitation. The system connects two robotic
manipulators on therapist and patient side via bilateral teleoperation,
enabling a therapist to remotely demonstrate rehabilitation exercises that are
executed by the patient-side robot. A 6-DoF Dynamical Movement Primitives
formulation is employed to jointly encode translational and rotational motions
in $\mathbb{R}^3 \times \mathit{S}^3$ space, ensuring accurate trajectory
reproduction. The framework supports smooth transitions between therapist-led
guidance and patient passive training, while allowing adaptive adjustment of
motion. Experiments with 7-DoF manipulators demonstrate the feasibility of the
approach, highlighting its potential for personalized and remotely supervised
rehabilitation.

</details>


### [24] [Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions](https://arxiv.org/abs/2510.00783)
*Thanh Nguyen Canh,Haolan Zhang,Xiem HoangVan,Nak Young Chong*

Main category: cs.RO

TL;DR: 本文是对语义SLAM领域的全面综述，涵盖了该领域20多年来的发展历程、最新进展和持续挑战，提出了统一的问题框架和模块化解决方案。


<details>
  <summary>Details</summary>
Motivation: 语义SLAM是机器人和计算机视觉领域的重要研究方向，但缺乏全面涵盖最新进展和持续挑战的综述文献。

Method: 通过深入探索视觉SLAM的演变，提出统一的问题公式化和模块化解决方案框架，将问题分解为视觉定位、语义特征提取、建图、数据关联和闭环优化等阶段。

Result: 提供了语义SLAM技术的最新技术状态分析，包括深度学习和大语言模型等替代方法的研究，以及当代SLAM数据集的综述。

Conclusion: 本研究为研究人员在复杂的语义SLAM领域中导航提供了全面资源，并讨论了潜在的未来研究方向。

Abstract: Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of
research within robotics and computer vision, focusing on the simultaneous
localization of robotic systems and associating semantic information to
construct the most accurate and complete comprehensive model of the surrounding
environment. Since the first foundational work in Semantic SLAM appeared more
than two decades ago, this field has received increasing attention across
various scientific communities. Despite its significance, the field lacks
comprehensive surveys encompassing recent advances and persistent challenges.
In response, this study provides a thorough examination of the state-of-the-art
of Semantic SLAM techniques, with the aim of illuminating current trends and
key obstacles. Beginning with an in-depth exploration of the evolution of
visual SLAM, this study outlines its strengths and unique characteristics,
while also critically assessing previous survey literature. Subsequently, a
unified problem formulation and evaluation of the modular solution framework is
proposed, which divides the problem into discrete stages, including visual
localization, semantic feature extraction, mapping, data association, and loop
closure optimization. Moreover, this study investigates alternative
methodologies such as deep learning and the utilization of large language
models, alongside a review of relevant research about contemporary SLAM
datasets. Concluding with a discussion on potential future research directions,
this study serves as a comprehensive resource for researchers seeking to
navigate the complex landscape of Semantic SLAM.

</details>


### [25] [RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator](https://arxiv.org/abs/2510.00814)
*Kai Tang,Dipankar Bhattacharya,Hang Xu,Fuyuki Tokuda,Norman C. Tien,Kazuhiro Kosuge*

Main category: cs.RO

TL;DR: 提出了首个随机到目标织物展平(RTFF)策略，采用混合模仿学习-视觉伺服(IL-VS)框架，通过基于模板的网格表示实现从随机褶皱状态到任意无褶皱目标状态的精确对齐。


<details>
  <summary>Details</summary>
Motivation: 解决织物生产中的机器人操作挑战，包括织物可变形性、无限自由度以及褶皱、折叠和机械臂遮挡等问题，实现可靠的织物展平和对齐。

Method: 采用混合IL-VS框架：IL学习使用显式织物模型进行粗对齐，VS确保精细对齐；提出基于模板的网格表示和RTFF-MACT Transformer策略。

Result: 在真实双臂遥操作系统上验证，展示了零样本对齐不同目标、高精度以及跨织物和尺度的强泛化能力。

Conclusion: RTFF策略成功解决了织物展平和对齐的挑战，为服装生产中的机器人操作提供了有效的解决方案。

Abstract: Robotic fabric manipulation in garment production for sewing, cutting, and
ironing requires reliable flattening and alignment, yet remains challenging due
to fabric deformability, effectively infinite degrees of freedom, and frequent
occlusions from wrinkles, folds, and the manipulator's End-Effector (EE) and
arm. To address these issues, this paper proposes the first Random-to-Target
Fabric Flattening (RTFF) policy, which aligns a random wrinkled fabric state to
an arbitrary wrinkle-free target state. The proposed policy adopts a hybrid
Imitation Learning-Visual Servoing (IL-VS) framework, where IL learns with
explicit fabric models for coarse alignment of the wrinkled fabric toward a
wrinkle-free state near the target, and VS ensures fine alignment to the
target. Central to this framework is a template-based mesh that offers precise
target state representation, wrinkle-aware geometry prediction, and consistent
vertex correspondence across RTFF manipulation steps, enabling robust
manipulation and seamless IL-VS switching. Leveraging the power of mesh, a
novel IL solution for RTFF-Mesh Action Chunking Transformer (MACT)-is then
proposed by conditioning the mesh information into a Transformer-based policy.
The RTFF policy is validated on a real dual-arm tele-operation system, showing
zero-shot alignment to different targets, high accuracy, and strong
generalization across fabrics and scales. Project website:
https://kaitang98.github.io/RTFF_Policy/

</details>


### [26] [Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell](https://arxiv.org/abs/2510.00933)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 提出了一种基于PPR建模范式的产品生命周期管理方法，重点关注将产品生命周期末端阶段的影响融入工程阶段，支持产品在整个生命周期中的维修、再制造和升级回收。


<details>
  <summary>Details</summary>
Motivation: 当前工业标准主要关注生产阶段而非完整产品生命周期，且侧重于生产过程而非产品本身。需要将产品生命周期末端阶段的影响融入工程阶段。

Method: 基于产品-过程-资源(PPR)建模范式，提出PoPAN模型作为产品的数字影子，封装在资产管理壳中，并使用AutomationML数据格式进行序列化。

Result: 开发了PoPAN模型，能够伴随产品整个生命周期，支持维修、再制造和升级回收活动，并在电动汽车电池拆卸用例中验证了模型的有效性。

Conclusion: 提出的PoPAN模型为复杂机电系统提供了完整的生命周期管理解决方案，特别关注可持续性和循环经济，支持产品在生命周期末端的价值回收。

Abstract: Current products, especially in the automotive sector, pose complex technical
systems having a multi-disciplinary mechatronic nature. Industrial standards
supporting system engineering and production typically (i) address the
production phase only, but do not cover the complete product life cycle, and
(ii) focus on production processes and resources rather than the products
themselves. The presented approach is motivated by incorporating impacts of
end-of-life phase of the product life cycle into the engineering phase. This
paper proposes a modelling approach coming up from the Product-Process-Resource
(PPR) modeling paradigm. It combines requirements on (i) respecting the product
structure as a basis for the model, and (ii) it incorporates repairing,
remanufacturing, or upcycling within cyber-physical production systems. The
proposed model called PoPAN should accompany the product during the entire life
cycle as a digital shadow encapsulated within the Asset Administration Shell of
a product. To facilitate the adoption of the proposed paradigm, the paper also
proposes serialization of the model in the AutomationML data format. The model
is demonstrated on a use-case for disassembling electric vehicle batteries to
support their remanufacturing for stationary battery applications.

</details>


### [27] [Non-submodular Visual Attention for Robot Navigation](https://arxiv.org/abs/2510.00942)
*Reza Vafaee,Kian Behzad,Milad Siami,Luca Carlone,Ali Jadbabaie*

Main category: cs.RO

TL;DR: 提出任务导向的计算框架，通过MSE目标函数和动态预测模型优化视觉惯性导航中的特征选择，开发四种多项式时间近似算法解决NP难问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在有限时间和能量资源下的视觉惯性导航挑战，提升导航效率和实时性能。

Method: 使用MSE非子模目标函数和简化动态预测模型进行特征选择，提出四种近似算法：经典贪心法、低秩贪心变体、随机贪心采样器和线性化选择器。

Result: 在标准基准和自定义控制感知平台上验证了理论结果，算法实现了强近似保证并支持实时部署。

Conclusion: 该框架通过高效特征选择和优化算法，显著提升了视觉惯性导航的实时性能和资源效率。

Abstract: This paper presents a task-oriented computational framework to enhance
Visual-Inertial Navigation (VIN) in robots, addressing challenges such as
limited time and energy resources. The framework strategically selects visual
features using a Mean Squared Error (MSE)-based, non-submodular objective
function and a simplified dynamic anticipation model. To address the
NP-hardness of this problem, we introduce four polynomial-time approximation
algorithms: a classic greedy method with constant-factor guarantees; a low-rank
greedy variant that significantly reduces computational complexity; a
randomized greedy sampler that balances efficiency and solution quality; and a
linearization-based selector based on a first-order Taylor expansion for
near-constant-time execution. We establish rigorous performance bounds by
leveraging submodularity ratios, curvature, and element-wise curvature
analyses. Extensive experiments on both standardized benchmarks and a custom
control-aware platform validate our theoretical results, demonstrating that
these methods achieve strong approximation guarantees while enabling real-time
deployment.

</details>


### [28] [ROSflight 2.0: Lean ROS 2-Based Autopilot for Unmanned Aerial Vehicles](https://arxiv.org/abs/2510.00995)
*Jacob Moore,Phil Tokumaru,Ian Reid,Brandon Sutherland,Joseph Ritchie,Gabe Snow,Tim McLain*

Main category: cs.RO

TL;DR: ROSflight是一个轻量级开源无人机自动驾驶系统，专为研究人员设计，通过模块化架构和ROS 2升级提升可用性，支持400Hz控制频率。


<details>
  <summary>Details</summary>
Motivation: 降低无人机研究门槛，加速从仿真到硬件实验的过渡，为先进空中机动性等研究领域提供支持。

Method: 从ROS 1迁移到ROS 2，改进模块化架构，优化硬件支持、底层执行器混控和仿真环境。

Result: 能够通过串行连接以400Hz频率控制多旋翼无人机，所有控制回路在配套计算机上闭环运行。

Conclusion: ROSflight的改进提升了系统可用性，能够有效加速无人机相关研究进展。

Abstract: ROSflight is a lean, open-source autopilot ecosystem for unmanned aerial
vehicles (UAVs). Designed by researchers for researchers, it is built to lower
the barrier to entry to UAV research and accelerate the transition from
simulation to hardware experiments by maintaining a lean (not full-featured),
well-documented, and modular codebase. This publication builds on previous
treatments and describes significant additions to the architecture that improve
the modularity and usability of ROSflight, including the transition from ROS 1
to ROS 2, supported hardware, low-level actuator mixing, and the simulation
environment. We believe that these changes improve the usability of ROSflight
and enable ROSflight to accelerate research in areas like advanced-air
mobility. Hardware results are provided, showing that ROSflight is able to
control a multirotor over a serial connection at 400 Hz while closing all
control loops on the companion computer.

</details>


### [29] [Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning](https://arxiv.org/abs/2510.01023)
*S. Satsevich,A. Bazhenov,S. Egorov,A. Erkhov,M. Gromakov,A. Fedoseev,D. Tsetserukou*

Main category: cs.RO

TL;DR: 提出了一种使用消费级HTC Vive Trackers 2.0的新型力反馈遥操作系统，通过实时压缩力数据传输提升操作成功率，为大规模模仿学习数据收集提供低成本解决方案。


<details>
  <summary>Details</summary>
Motivation: 开发一个低成本但有效的力反馈遥操作系统，用于提升操作任务成功率，并为大规模模仿学习数据收集提供经济可行的方案。

Method: 系统整合了定制控制器、UR3机械臂和配备定制手指的Robotiq夹爪，确保嵌入式力传感器上的均匀压力分布，实时传输压缩力数据到控制器。

Result: 实验结果表明，该系统提高了任务成功率，并为大规模模仿学习数据收集提供了低成本解决方案，同时保持了可负担性。

Conclusion: 该研究成功开发了一个基于消费级硬件的力反馈遥操作系统，在提升操作性能的同时保持了成本效益，为机器人模仿学习应用提供了实用工具。

Abstract: This paper presents a novel teleoperation system with force feedback,
utilizing consumer-grade HTC Vive Trackers 2.0. The system integrates a
custom-built controller, a UR3 robotic arm, and a Robotiq gripper equipped with
custom-designed fingers to ensure uniform pressure distribution on an embedded
force sensor. Real-time compression force data is transmitted to the
controller, enabling operators to perceive the gripping force applied to
objects. Experimental results demonstrate that the system enhances task success
rates and provides a low-cost solution for large-scale imitation learning data
collection without compromising affordability.

</details>


### [30] [ROSplane 2.0: A Fixed-Wing Autopilot for Research](https://arxiv.org/abs/2510.01041)
*Ian Reid,Joseph Ritchie,Jacob Moore,Brandon Sutherland,Gabe Snow,Phillip Tokumaru,Tim McLain*

Main category: cs.RO

TL;DR: ROSplane是一个专为研究人员设计的轻量级开源固定翼无人机自主系统，基于ROS 2构建，通过清晰的接口和易修改的框架加速无人机研究。


<details>
  <summary>Details</summary>
Motivation: 传统无人机研究需要将前沿技术集成到现有自动驾驶框架中，这个过程需要大量资源、时间和系统知识，开发ROSplane旨在降低研究门槛并加速研究进程。

Method: 采用ROS 2构建，提供清晰定义的接口和易于修改的框架，专注于轻量级、易于理解的代码和详细文档，增强模块化和气动建模流程。

Result: ROSplane能够快速集成低层或高层控制、路径规划或估计算法，显著减少了从仿真到真实世界测试的工作量，无需昂贵的系统辨识或计算流体动力学工具。

Conclusion: ROSplane的架构显著减少了集成新研究工具和方法所需的工作量，加速了硬件实验进程，为无人机研究提供了高效的研究平台。

Abstract: Unmanned aerial vehicle (UAV) research requires the integration of
cutting-edge technology into existing autopilot frameworks. This process can be
arduous, requiring extensive resources, time, and detailed knowledge of the
existing system. ROSplane is a lean, open-source fixed-wing autonomy stack
built by researchers for researchers. It is designed to accelerate research by
providing clearly defined interfaces with an easily modifiable framework.
Powered by ROS 2, ROSplane allows for rapid integration of low or high-level
control, path planning, or estimation algorithms. A focus on lean, easily
understood code and extensive documentation lowers the barrier to entry for
researchers. Recent developments to ROSplane improve its capacity to accelerate
UAV research, including the transition from ROS 1 to ROS 2, enhanced estimation
and control algorithms, increased modularity, and an improved aerodynamic
modeling pipeline. This aerodynamic modeling pipeline significantly reduces the
effort of transitioning from simulation to real-world testing without requiring
expensive system identification or computational fluid dynamics tools.
ROSplane's architecture reduces the effort required to integrate new research
tools and methods, expediting hardware experimentation.

</details>


### [31] [Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition](https://arxiv.org/abs/2510.01068)
*Jiahang Cao,Yize Huang,Hanzhong Guo,Rui Zhang,Mu Nan,Weijian Mai,Jiaxu Wang,Hao Cheng,Jingkai Sun,Gang Han,Wen Zhao,Qiang Zhang,Yijie Guo,Qihao Zheng,Chunfeng Song,Xiao Li,Ping Luo,Andrew F. Luo*

Main category: cs.RO

TL;DR: 提出了一种无需额外训练的策略组合方法GPC，通过组合多个预训练扩散模型的分布分数来提升机器人控制性能


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人控制中表现出色，但大规模交互数据获取成本高昂，需要不依赖额外训练的性能提升方法

Method: GPC方法：通过凸组合和测试时搜索组合多个预训练策略的分布分数，支持异构策略的即插即用组合

Result: 在Robomimic、PushT、RoboTwin等基准测试和真实机器人评估中，GPC持续提升性能和适应性

Conclusion: GPC是一种简单有效的控制性能提升方法，通过利用现有策略实现性能超越

Abstract: Diffusion-based models for robotic control, including vision-language-action
(VLA) and vision-action (VA) policies, have demonstrated significant
capabilities. Yet their advancement is constrained by the high cost of
acquiring large-scale interaction datasets. This work introduces an alternative
paradigm for enhancing policy performance without additional model training.
Perhaps surprisingly, we demonstrate that the composed policies can exceed the
performance of either parent policy. Our contribution is threefold. First, we
establish a theoretical foundation showing that the convex composition of
distributional scores from multiple diffusion models can yield a superior
one-step functional objective compared to any individual score. A
Gr\"onwall-type bound is then used to show that this single-step improvement
propagates through entire generation trajectories, leading to systemic
performance gains. Second, motivated by these results, we propose General
Policy Composition (GPC), a training-free method that enhances performance by
combining the distributional scores of multiple pre-trained policies via a
convex combination and test-time search. GPC is versatile, allowing for the
plug-and-play composition of heterogeneous policies, including VA and VLA
models, as well as those based on diffusion or flow-matching, irrespective of
their input visual modalities. Third, we provide extensive empirical
validation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside
real-world robotic evaluations, confirm that GPC consistently improves
performance and adaptability across a diverse set of tasks. Further analysis of
alternative composition operators and weighting strategies offers insights into
the mechanisms underlying the success of GPC. These results establish GPC as a
simple yet effective method for improving control performance by leveraging
existing policies.

</details>


### [32] [Real-Time Trajectory Generation and Hybrid Lyapunov-Based Control for Hopping Robots](https://arxiv.org/abs/2510.01138)
*Matthew Woodward*

Main category: cs.RO

TL;DR: 提出了一种实时、计算高效的轨迹生成方法和李雅普诺夫控制器，使跳跃机器人能够执行复杂空中轨迹并精确控制着陆姿态。


<details>
  <summary>Details</summary>
Motivation: 当前跳跃机器人无法直接控制空中轨迹或实现飞行转换，限制了跳跃系统的效率优势。需要开发能够生成和跟踪复杂轨迹的控制方法。

Method: 采用非线性阻力补偿的轨迹生成方法，结合李雅普诺夫稳定性理论设计控制器，实现从起飞到着陆的完整轨迹跟踪。

Result: 系统能够在水平和垂直表面上生成并跟踪复杂空中轨迹，同时严格控制着陆时的姿态，计算效率高且适用于各种尺寸的跳跃机器人。

Conclusion: 该方法为跳跃机器人提供了精确的轨迹控制能力，扩展了其应用范围，同时保持了计算效率，对四旋翼飞行器也具有通用性。

Abstract: The advent of rotor-based hopping robots has created very capable hopping
platforms with high agility and efficiency, and similar controllability, as
compared to their purely flying quadrotor counterparts. Advances in robot
performance have increased the hopping height to greater than 4 meters and
opened up the possibility for more complex aerial trajectories (i.e.,
behaviors). However, currently hopping robots do not directly control their
aerial trajectory or transition to flight, eliminating the efficiency benefits
of a hopping system. Here we show a real-time, computationally efficiency,
non-linear drag compensated, trajectory generation methodology and accompanying
Lyapunov-based controller. The combined system can create and follow complex
aerial trajectories from liftoff to touchdown on horizontal and vertical
surfaces, while maintaining strick control over the orientation at touchdown.
The computational efficiency provides broad applicability across all size
scales of hopping robots while maintaining applicability to quadrotors in
general.

</details>
