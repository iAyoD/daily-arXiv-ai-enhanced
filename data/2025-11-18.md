<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 86]
- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TimeStampEval: A Simple LLM Eval and a Little Fuzzy Matching Trick to Improve Search Accuracy](https://arxiv.org/abs/2511.11594)
*James McCammon*

Main category: cs.CL

TL;DR: 提出了TimeStampEval基准，用于从长文本转录中检索非逐字引用的精确时间戳。采用两阶段方法显著提高检索准确性，同时降低90%以上的推理成本。


<details>
  <summary>Details</summary>
Motivation: 解决传统模糊匹配在语义相同但语法不同的引用检索中的失败问题，特别是在对齐官方书面记录和语音转文字转录时。应用场景是自动化的长篇播客，将国会记录片段组装成AI主持的叙述。

Method: 两阶段方法：首先使用RapidFuzz进行预过滤，然后对短片段进行LLM验证。通过优化提示设计（将查询放在转录前、使用紧凑格式）和适度推理预算（600-850个token）来提高准确性。

Result: 在2800句（12万token）转录上的评估显示：提示设计比模型选择更重要，准确率提高3-20点，token数减少30-40%；适度推理预算将准确率从37%提升到77%（弱设置）和90%以上（强设置）；辅助模糊方法将模糊匹配准确率提高50点，延迟减半，每个正确结果的成本降低96%。

Conclusion: 该方法对转录长度、词汇漂移和领域变化具有鲁棒性，在10个转录（5万-90万token，1989-2025年）上保持95-100%的拒绝准确率，适用于非逐字时间戳检索任务。

Abstract: Traditional fuzzy matching often fails when searching for quotes that are semantically identical but syntactically different across documents-a common issue when aligning official written records with speech-to-text transcripts. We introduce TimeStampEval, a benchmark for retrieving precise millisecond timestamps from long transcripts given non-verbatim quotes. Our simple two-stage method dramatically improves retrieval accuracy while cutting inference costs by over 90%. The motivating use case is an automated long-form podcast that assembles Congressional Record clips into AI-hosted narration. The technical challenge: given a sentence-timestamped transcript and a target quote that may differ due to transcription or editorial drift, return exact start and end boundaries. Standard algorithms handle verbatim text but break under fuzzier variants. Evaluating six modern LLMs on a 2,800-sentence (120k-token) transcript revealed four key findings. (1) Prompt design matters more than model choice: placing the query before the transcript and using compact formatting improved accuracy by 3-20 points while reducing token count by 30-40%. (2) Off-by-one errors form a distinct category, showing models understand the task but misplace boundaries. (3) A modest reasoning budget (600-850 tokens) raises accuracy from 37% to 77% for weak setups and to above 90% for strong ones. (4) Our "Assisted Fuzzy" approach-RapidFuzz pre-filtering followed by LLM verification on short snippets-improves fuzzy match accuracy by up to 50 points while halving latency and reducing cost per correct result by up to 96%. Extended tests on ten transcripts (50k-900k tokens, 1989-2025) confirm robustness to transcript length, vocabulary drift, and domain change, maintaining 95-100% rejection accuracy for absent targets.

</details>


### [2] [MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling](https://arxiv.org/abs/2511.11793)
*MiroMind Team,Song Bai,Lidong Bing,Carson Chen,Guanzheng Chen,Yuntao Chen,Zhe Chen,Ziyi Chen,Jifeng Dai,Xuan Dong,Yue Deng,Yunjie Fu,Junqi Ge,Chenxia Han,Tammy Huang,Zhenhang Huang,Jerry Jiao,Shilei Jiang,Tianyu Jiao,Xiaoqi Jian,Lei Lei,Ruilin Li,Ryan Luo,Tiantong Li,Xiang Lin,Ziyuan Liu,Zhiqi Li,Jie Ni,Qiang Ren,Pax Sun,Shiqian Su,Chenxin Tao,Bin Wang,Hellen Wang,Haonan Wang,James Wang,Jin Wang,Jojo Wang,Letian Wang,Shizun Wang,Weizhi Wang,Zixuan Wang,Jinfan Xu,Sen Xing,Chenyu Yang,Hai Ye,Jiaheng Yu,Yue Yu,Muyan Zhong,Tianchen Zhao,Xizhou Zhu,Yanpeng Zhou,Yifan Zhang,Zhi Zhu*

Main category: cs.CL

TL;DR: MiroThinker v1.0是一个开源研究代理，通过交互式扩展作为模型性能提升的第三维度，能够在256K上下文窗口中执行多达600次工具调用，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅扩展模型规模或上下文长度，而MiroThinker探索在模型层面进行交互扩展，通过更深入和频繁的代理-环境交互来提升性能。

Method: 使用强化学习训练模型实现交互扩展，模型能够利用环境反馈和外部信息获取来纠正错误和优化轨迹，支持深度多轮推理。

Result: 72B变体在GAIA、HLE、BrowseComp和BrowseComp-ZH基准测试中分别达到81.9%、37.7%、47.1%和55.6%的准确率，超越先前开源代理并接近商业对应物。

Conclusion: 交互扩展展现出与模型规模和上下文长度类似的扩展行为，成为构建下一代开源研究代理的第三个关键维度。

Abstract: We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or context length, MiroThinker explores interaction scaling at the model level, systematically training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement. Unlike LLM test-time scaling, which operates in isolation and risks degradation with longer reasoning chains, interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories. Through reinforcement learning, the model achieves efficient interaction scaling: with a 256K context window, it can perform up to 600 tool calls per task, enabling sustained multi-turn reasoning and complex real-world research workflows. Across four representative benchmarks-GAIA, HLE, BrowseComp, and BrowseComp-ZH-the 72B variant achieves up to 81.9%, 37.7%, 47.1%, and 55.6% accuracy respectively, surpassing previous open-source agents and approaching commercial counterparts such as GPT-5-high. Our analysis reveals that MiroThinker benefits from interactive scaling consistently: research performance improves predictably as the model engages in deeper and more frequent agent-environment interactions, demonstrating that interaction depth exhibits scaling behaviors analogous to model size and context length. These findings establish interaction scaling as a third critical dimension for building next-generation open research agents, complementing model capacity and context windows.

</details>


### [3] [On the Notion that Language Models Reason](https://arxiv.org/abs/2511.11810)
*Bertram Højer*

Main category: cs.CL

TL;DR: 论文认为语言模型并非真正的推理者，而是统计模式匹配器，其推理式输出源于学习到的统计规律而非逻辑机制。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型是否真正具备推理能力，澄清当前NLP领域对"推理"概念的不一致使用。

Method: 将基于transformer的语言模型视为实现隐式有限阶马尔可夫核的系统，分析其信息处理和生成机制。

Result: 语言模型的推理式输出对应学习核中的统计规律性和近似统计不变性，而非显式逻辑机制。

Conclusion: 语言模型是统计模式匹配器而非真正推理者，这一区分对评估其认知不确定性至关重要。

Abstract: Language models (LMs) are said to be exhibiting reasoning, but what does this entail? We assess definitions of reasoning and how key papers in the field of natural language processing (NLP) use the notion and argue that the definitions provided are not consistent with how LMs are trained, process information, and generate new tokens. To illustrate this incommensurability we assume the view that transformer-based LMs implement an \textit{implicit} finite-order Markov kernel mapping contexts to conditional token distributions. In this view, reasoning-like outputs correspond to statistical regularities and approximate statistical invariances in the learned kernel rather than the implementation of explicit logical mechanisms. This view is illustrative of the claim that LMs are "statistical pattern matchers"" and not genuine reasoners and provides a perspective that clarifies why reasoning-like outputs arise in LMs without any guarantees of logical consistency. This distinction is fundamental to how epistemic uncertainty is evaluated in LMs. We invite a discussion on the importance of how the computational processes of the systems we build and analyze in NLP research are described.

</details>


### [4] [Scaling Open-Weight Large Language Models for Hydropower Regulatory Information Extraction: A Systematic Analysis](https://arxiv.org/abs/2511.11821)
*Hong-Jun Yoon,Faisal Ashraf,Thomas A. Ruggles,Debjani Singh*

Main category: cs.CL

TL;DR: 评估了7个开源大语言模型(0.6B-70B参数)在水电许可文档信息提取中的性能-资源权衡，发现14B参数是有效验证的阈值，小模型存在系统性幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决监管文档信息提取中性能与计算资源之间的关键权衡问题，为实际部署提供实证指导。

Method: 在水电许可文档上评估7个不同参数规模的开源模型，分析验证方法的有效性、性能表现和幻觉模式。

Result: 识别出14B参数阈值，消费级模型可达64% F1，小模型仅51%，大规模模型达77%但需企业基础设施；发现小模型完美召回率反而表明提取失败的系统性幻觉模式。

Conclusion: 建立了首个监管背景下开源信息提取的资源-性能映射，为模型选择提供证据基础，研究结果对水电合规有直接价值，参数缩放效应的见解可推广到其他信息提取任务。

Abstract: Information extraction from regulatory documents using large language models presents critical trade-offs between performance and computational resources. We evaluated seven open-weight models (0.6B-70B parameters) on hydropower licensing documentation to provide empirical deployment guidance.
  Our analysis identified a pronounced 14B parameter threshold where validation methods transition from ineffective (F1 $<$ 0.15) to viable (F1 = 0.64). Consumer-deployable models achieve 64\% F1 through appropriate validation, while smaller models plateau at 51\%. Large-scale models approach 77\% F1 but require enterprise infrastructure.
  We identified systematic hallucination patterns where perfect recall indicates extraction failure rather than success in smaller models. Our findings establish the first comprehensive resource-performance mapping for open-weight information extraction in regulatory contexts, enabling evidence-based model selection.
  These results provide immediate value for hydropower compliance while contributing insights into parameter scaling effects that generalize across information extraction tasks.

</details>


### [5] [Towards Autoformalization of LLM-generated Outputs for Requirement Verification](https://arxiv.org/abs/2511.11829)
*Mihir Gupte,Ramesh S*

Main category: cs.CL

TL;DR: 本文探索使用基于LLM的自动形式化方法来验证LLM生成的输出与自然语言需求的一致性，通过两个实验展示了该方法在一致性检查和逻辑验证方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在从自然语言生成结构化输出方面显示出潜力，但缺乏正式方法来验证这些输出的准确性。本文旨在填补这一空白。

Method: 使用基于LLM的自动形式化器对LLM生成的输出进行验证，通过两个实验：1）验证不同表述的自然语言需求的逻辑等价性；2）识别自然语言需求与LLM生成输出之间的逻辑不一致性。

Result: 在第一个实验中，自动形式化器成功识别出两个不同表述的自然语言需求在逻辑上是等价的；在第二个实验中，成功识别出给定自然语言需求与LLM生成输出之间的逻辑不一致性。

Conclusion: 虽然研究有限，但自动形式化在确保LLM生成输出的保真度和逻辑一致性方面具有显著潜力，为未来更广泛的研究奠定了基础。

Abstract: Autoformalization, the process of translating informal statements into formal logic, has gained renewed interest with the emergence of powerful Large Language Models (LLMs). While LLMs show promise in generating structured outputs from natural language (NL), such as Gherkin Scenarios from NL feature requirements, there's currently no formal method to verify if these outputs are accurate. This paper takes a preliminary step toward addressing this gap by exploring the use of a simple LLM-based autoformalizer to verify LLM-generated outputs against a small set of natural language requirements. We conducted two distinct experiments. In the first one, the autoformalizer successfully identified that two differently-worded NL requirements were logically equivalent, demonstrating the pipeline's potential for consistency checks. In the second, the autoformalizer was used to identify a logical inconsistency between a given NL requirement and an LLM-generated output, highlighting its utility as a formal verification tool. Our findings, while limited, suggest that autoformalization holds significant potential for ensuring the fidelity and logical consistency of LLM-generated outputs, laying a crucial foundation for future, more extensive studies into this novel application.

</details>


### [6] [Three Stage Narrative Analysis; Plot-Sentiment Breakdown, Structure Learning and Concept Detection](https://arxiv.org/abs/2511.11857)
*Taimur Khan,Ramoza Ahsan,Mohib Hameed*

Main category: cs.CL

TL;DR: 提出了一个分析电影剧本情感弧线的框架，通过自定义词典进行情感分析，并使用聚类方法对相似情感模式进行分组，帮助用户选择故事。


<details>
  <summary>Details</summary>
Motivation: 故事理解和分析是自然语言理解中的挑战领域，需要深度计算语义表示和句法处理。大量叙事数据需要自动化语义分析而非手动方法。

Method: 使用基于NRC-VAD数据集的Valence、Arousal和Dominance分数构建的自定义词典进行情感分析，应用LabMTsimple storylab模块，并使用Wards层次聚类技术对相似情感情节进行聚类。

Result: 在电影数据集上的实验评估表明，该分析结果对消费者和读者在选择叙事或故事时很有帮助。

Conclusion: 该框架能够提取叙事中传达的高层和低层概念，通过情感弧线分析和聚类技术为故事选择提供有价值的见解。

Abstract: Story understanding and analysis have long been challenging areas within Natural Language Understanding. Automated narrative analysis requires deep computational semantic representations along with syntactic processing. Moreover, the large volume of narrative data demands automated semantic analysis and computational learning rather than manual analytical approaches. In this paper, we propose a framework that analyzes the sentiment arcs of movie scripts and performs extended analysis related to the context of the characters involved. The framework enables the extraction of high-level and low-level concepts conveyed through the narrative. Using dictionary-based sentiment analysis, our approach applies a custom lexicon built with the LabMTsimple storylab module. The custom lexicon is based on the Valence, Arousal, and Dominance scores from the NRC-VAD dataset. Furthermore, the framework advances the analysis by clustering similar sentiment plots using Wards hierarchical clustering technique. Experimental evaluation on a movie dataset shows that the resulting analysis is helpful to consumers and readers when selecting a narrative or story.

</details>


### [7] [Identifying Imaging Follow-Up in Radiology Reports: A Comparative Analysis of Traditional ML and LLM Approaches](https://arxiv.org/abs/2511.11867)
*Namu Park,Giridhar Kaushik Ramachandran,Kevin Lybarger,Fei Xia,Ozlem Uzuner,Meliha Yetisgen,Martin Gunn*

Main category: cs.CL

TL;DR: 本文介绍了一个包含6,393份放射学报告的标注语料库，用于评估LLMs在放射学随访依从性检测任务中的表现，发现GPT-4o在优化提示下达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏专门用于评估LLMs在放射学任务表现的专业领域数据集，需要开发可靠的基准来比较传统机器学习方法与生成式LLMs的性能。

Method: 构建了6,393份放射学报告的标注语料库，系统比较了传统机器学习分类器（LR、SVM、Longformer）、完全微调的Llama3-8B-Instruct与生成式LLMs（GPT-4o、GPT-OSS-20B），后者在基础和优化两种提示设置下测试。

Result: GPT-4o（优化设置）表现最佳（F1=0.832），GPT-OSS-20B（优化设置）紧随其后（F1=0.828），LR和SVM也表现良好（F1=0.776和0.775），标注者间一致性高（F1=0.846）。

Conclusion: 虽然通过提示优化LLMs可以达到接近人类水平的一致性，但可解释且资源效率高的传统模型仍然是重要的基准方法。

Abstract: Large language models (LLMs) have shown considerable promise in clinical natural language processing, yet few domain-specific datasets exist to rigorously evaluate their performance on radiology tasks. In this work, we introduce an annotated corpus of 6,393 radiology reports from 586 patients, each labeled for follow-up imaging status, to support the development and benchmarking of follow-up adherence detection systems. Using this corpus, we systematically compared traditional machine-learning classifiers, including logistic regression (LR), support vector machines (SVM), Longformer, and a fully fine-tuned Llama3-8B-Instruct, with recent generative LLMs. To evaluate generative LLMs, we tested GPT-4o and the open-source GPT-OSS-20B under two configurations: a baseline (Base) and a task-optimized (Advanced) setting that focused inputs on metadata, recommendation sentences, and their surrounding context. A refined prompt for GPT-OSS-20B further improved reasoning accuracy. Performance was assessed using precision, recall, and F1 scores with 95% confidence intervals estimated via non-parametric bootstrapping. Inter-annotator agreement was high (F1 = 0.846). GPT-4o (Advanced) achieved the best performance (F1 = 0.832), followed closely by GPT-OSS-20B (Advanced; F1 = 0.828). LR and SVM also performed strongly (F1 = 0.776 and 0.775), underscoring that while LLMs approach human-level agreement through prompt optimization, interpretable and resource-efficient models remain valuable baselines.

</details>


### [8] [MedPT: A Massive Medical Question Answering Dataset for Brazilian-Portuguese Speakers](https://arxiv.org/abs/2511.11878)
*Fernanda Bufon Färber,Iago Alves Brito,Julia Soares Dollis,Pedro Schindler Freire Brasil Ribeiro,Rafael Teixeira Sousa,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: MedPT是首个针对巴西葡萄牙语的大规模真实世界医疗语料库，包含38.4万条真实的医患问答对，通过多阶段精心筛选和LLM增强标注，支持医疗专科路由等任务，旨在解决低资源语言医疗AI的公平性问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在医疗领域的发展主要集中于高资源语言，简单翻译无法捕捉特定临床和文化细微差别（如地方性疾病），这为其他语言群体创造了关键障碍。

Method: 构建包含384,095条真实医患问答对的语料库，采用混合定量-定性分析方法进行多阶段筛选，使用LLM驱动标注将问题分类为7种语义类型，并分析其主题广度和语言特性。

Result: 在医疗专科路由任务中，微调17亿参数模型在20类设置下达到94%的F1分数；错误分析显示误分类反映了真实的临床模糊性，证明了数据集的深层语义丰富性。

Conclusion: MedPT公开释放以促进葡萄牙语世界更公平、准确和文化敏感的医疗技术发展，展示了其在解决低资源语言医疗AI挑战方面的实用性。

Abstract: While large language models (LLMs) show transformative potential in healthcare, their development remains focused on high-resource languages, creating a critical barrier for others as simple translation fails to capture unique clinical and cultural nuances, such as endemic diseases. To address this, we introduce MedPT, the first large-scale, real-world corpus for Brazilian Portuguese, comprising 384,095 authentic question-answer pairs from patient-doctor interactions. The dataset underwent a meticulous multi-stage curation protocol, using a hybrid quantitative-qualitative analysis to filter noise and contextually enrich thousands of ambiguous queries. We further augmented the corpus via LLM-driven annotation, classifying questions into seven semantic types to capture user intent. Our analysis reveals its thematic breadth (3,200 topics) and unique linguistic properties, like the natural asymmetry in patient-doctor communication. To validate its utility, we benchmark a medical specialty routing task: fine-tuning a 1.7B parameter model achieves an outstanding 94\% F1-score on a 20-class setup. Furthermore, our qualitative error analysis shows misclassifications are not random but reflect genuine clinical ambiguities (e.g., between comorbid conditions), proving the dataset's deep semantic richness. We publicly release MedPT to foster the development of more equitable, accurate, and culturally-aware medical technologies for the Portuguese-speaking world.

</details>


### [9] [ClinStructor: AI-Powered Structuring of Unstructured Clinical Texts](https://arxiv.org/abs/2511.11883)
*Karthikeyan K,Raghuveer Thirukovalluru,David Carlson*

Main category: cs.CL

TL;DR: ClinStructor使用大语言模型将临床自由文本转换为结构化的问答对，以解决临床笔记中的偏见、泛化性和可解释性问题，在ICU死亡率预测任务中性能仅轻微下降2-3% AUC。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富信息但格式非结构化，存在无意偏见（如性别或种族偏见）、跨临床环境泛化性差以及可解释性差的问题。

Method: 利用大语言模型将临床自由文本转换为结构化的、任务特定的问答对，然后进行预测建模。

Result: 显著提高了透明度和可控性，在ICU死亡率预测任务中与直接微调相比，预测性能仅轻微下降（AUC下降2-3%）。

Conclusion: ClinStructor为在临床环境中构建可靠、可解释和可泛化的机器学习模型奠定了坚实基础。

Abstract: Clinical notes contain valuable, context-rich information, but their unstructured format introduces several challenges, including unintended biases (e.g., gender or racial bias), and poor generalization across clinical settings (e.g., models trained on one EHR system may perform poorly on another due to format differences) and poor interpretability. To address these issues, we present ClinStructor, a pipeline that leverages large language models (LLMs) to convert clinical free-text into structured, task-specific question-answer pairs prior to predictive modeling. Our method substantially enhances transparency and controllability and only leads to a modest reduction in predictive performance (a 2-3% drop in AUC), compared to direct fine-tuning, on the ICU mortality prediction task. ClinStructor lays a strong foundation for building reliable, interpretable, and generalizable machine learning models in clinical environments.

</details>


### [10] [Context-Emotion Aware Therapeutic Dialogue Generation: A Multi-component Reinforcement Learning Approach to Language Models for Mental Health Support](https://arxiv.org/abs/2511.11884)
*Eric Hua Qing Zhang,Julia Ive*

Main category: cs.CL

TL;DR: 本研究通过监督微调和强化学习技术增强GPT-2的心理治疗对话生成能力，在多指标评估中显示显著提升，特别是情感准确率达到99.34%。


<details>
  <summary>Details</summary>
Motivation: COVID-19加剧了心理健康服务的可及性挑战，虽然大语言模型提供24/7服务，但预训练模型缺乏情境和情感意识，需要改进以提供合适的治疗响应。

Method: 采用监督微调和强化学习技术，重构输入格式以同时处理情境信息和情感状态，使用多组件奖励函数使模型输出与专业治疗师响应和标注情感对齐。

Result: 强化学习在多个评估指标上优于基线GPT-2：BLEU(0.0111)、ROUGE-1(0.1397)、ROUGE-2(0.0213)、ROUGE-L(0.1317)、METEOR(0.0581)，情感准确率达到99.34%（基线为66.96%）。

Conclusion: 强化学习能有效开发治疗对话系统，作为治疗师的有价值辅助工具，同时保持必要的人类临床监督。

Abstract: Mental health illness represents a substantial global socioeconomic burden, with COVID-19 further exacerbating accessibility challenges and driving increased demand for telehealth mental health support. While large language models (LLMs) offer promising solutions through 24/7 availability and non-judgmental interactions, pre-trained models often lack the contextual and emotional awareness necessary for appropriate therapeutic responses. This paper investigated the application of supervised fine-tuning (SFT) and reinforcement learning (RL) techniques to enhance GPT-2's capacity for therapeutic dialogue generation. The methodology restructured input formats to enable simultaneous processing of contextual information and emotional states alongside user input, employing a multi-component reward function that aligned model outputs with professional therapist responses and annotated emotions. Results demonstrated improvements through reinforcement learning over baseline GPT-2 across multiple evaluation metrics: BLEU (0.0111), ROUGE-1 (0.1397), ROUGE-2 (0.0213), ROUGE-L (0.1317), and METEOR (0.0581). LLM evaluation confirmed high contextual relevance and professionalism, while reinforcement learning achieved 99.34% emotion accuracy compared to 66.96% for baseline GPT-2. These findings demonstrate reinforcement learning's effectiveness in developing therapeutic dialogue systems that can serve as valuable assistive tools for therapists while maintaining essential human clinical oversight.

</details>


### [11] [Additive Large Language Models for Semi-Structured Text](https://arxiv.org/abs/2511.11922)
*Karthikeyan K,Raghuveer Thirukovalluru,David Carlson*

Main category: cs.CL

TL;DR: CALM是一个可解释的临床文本分类框架，通过将预测分解为各个语义组件的贡献和，提供忠实解释，在保持性能的同时提高模型可信度。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在临床文本分类中预测不透明的问题，满足研究者和医生需要理解患者记录中哪些部分驱动风险信号的需求。

Method: 使用可加性大语言模型框架，将半结构化文本输入分解为语义组件，预测结果作为各组件贡献的加和，实现患者和群体层面的忠实解释。

Result: CALM在性能上与常规LLM分类器相当，同时提高了可信度，支持质量保证检查，并在模型开发和审计中揭示临床有意义的模式。

Conclusion: CALM框架为临床文本分类提供了可解释的解决方案，通过加性结构实现透明预测，促进模型在临床环境中的实际应用。

Abstract: Large Language Models have advanced clinical text classification, but their opaque predictions remain a critical barrier to practical adoption in research and clinical settings where investigators and physicians need to understand which parts of a patient's record drive risk signals. To address this challenge, we introduce \textbf{CALM}, short for \textbf{Classification with Additive Large Language Models}, an interpretable framework for semi-structured text where inputs are composed of semantically meaningful components, such as sections of an admission note or question-answer fields from an intake form. CALM predicts outcomes as the additive sum of each component's contribution, making these contributions part of the forward computation itself and enabling faithful explanations at both the patient and population level. The additive structure also enables clear visualizations, such as component-level risk curves similar to those used in generalized additive models, making the learned relationships easier to inspect and communicate. Although CALM expects semi-structured inputs, many clinical documents already have this form, and similar structure can often be automatically extracted from free-text notes. CALM achieves performance comparable to conventional LLM classifiers while improving trust, supporting quality-assurance checks, and revealing clinically meaningful patterns during model development and auditing.

</details>


### [12] [InData: Towards Secure Multi-Step, Tool-Based Data Analysis](https://arxiv.org/abs/2511.11933)
*Karthikeyan K,Raghuveer Thirukovalluru,Bhuwan Dhingra,David Edwin Carlson*

Main category: cs.CL

TL;DR: 提出InData数据集，用于评估LLM在多步骤工具推理方面的能力，发现当前LLM在复杂数据分析任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 解决LLM直接生成和执行代码访问敏感数据的安全风险，通过预定义安全工具进行间接数据交互。

Method: 引入InData数据集，包含三个难度级别的数据分析问题，评估15个开源LLM在多步骤工具推理中的表现。

Result: 大型模型在简单任务上准确率高（97.3%），但在困难任务上表现显著下降（69.6%），显示当前LLM缺乏稳健的多步骤工具推理能力。

Conclusion: InData为开发和评估具有更强多步骤工具使用能力的LLM迈出了重要一步，将公开发布数据集和代码。

Abstract: Large language model agents for data analysis typically generate and execute code directly on databases. However, when applied to sensitive data, this approach poses significant security risks. To address this issue, we propose a security-motivated alternative: restrict LLMs from direct code generation and data access, and require them to interact with data exclusively through a predefined set of secure, verified tools. Although recent tool-use benchmarks exist, they primarily target tool selection and simple execution rather than the compositional, multi-step reasoning needed for complex data analysis. To reduce this gap, we introduce Indirect Data Engagement (InData), a dataset designed to assess LLMs' multi-step tool-based reasoning ability. InData includes data analysis questions at three difficulty levels--Easy, Medium, and Hard--capturing increasing reasoning complexity. We benchmark 15 open-source LLMs on InData and find that while large models (e.g., gpt-oss-120b) achieve high accuracy on Easy tasks (97.3%), performance drops sharply on Hard tasks (69.6%). These results show that current LLMs still lack robust multi-step tool-based reasoning ability. With InData, we take a step toward enabling the development and evaluation of LLMs with stronger multi-step tool-use capabilities. We will publicly release the dataset and code.

</details>


### [13] [Improving LLM's Attachment to External Knowledge In Dialogue Generation Tasks Through Entity Anonymization](https://arxiv.org/abs/2511.11946)
*Hadi Sheikhi,Chenyang Huang,Osmar R. Zaïane*

Main category: cs.CL

TL;DR: LLM-KAT评估程序和实体匿名化技术，用于提升大语言模型在知识图谱对话生成中对外部知识的利用能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在知识图谱对话生成任务中过度依赖内部知识，即使提供了准确的知识图谱也难以有效利用外部知识

Method: 提出LLM-KAT评估方法来衡量知识附着度，并采用实体匿名化技术来鼓励模型更好地利用外部知识

Result: 在OpenDialKG数据集上的实验表明，该方法有效提升了LLM对外部知识的附着能力

Conclusion: 实体匿名化是一种简单有效的方法，能够显著改善大语言模型在知识图谱对话生成中对外部知识的利用

Abstract: Knowledge graph-based dialogue generation (KG-DG) is a challenging task requiring models to effectively incorporate external knowledge into conversational responses. While large language models (LLMs) have achieved impressive results across various NLP tasks, their ability to utilize external knowledge in KG-DG remains under-explored. We observe that LLMs often rely on internal knowledge, leading to detachment from provided knowledge graphs, even when they are given a flawlessly retrieved knowledge graph. First, we introduce LLM-KAT, an evaluation procedure for measuring knowledge attachment in generated responses. Second, we propose a simple yet effective entity anonymization technique to encourage LLMs to better leverage external knowledge. Experiments on the OpenDialKG dataset demonstrate that our approach improves LLMs' attachment on external knowledge.

</details>


### [14] [On the Entropy Calibration of Language Models](https://arxiv.org/abs/2511.11966)
*Steven Cao,Gregory Valiant,Percy Liang*

Main category: cs.CL

TL;DR: 本文研究了语言模型的熵校准问题，发现模型在生成过程中存在校准错误，且这种错误随规模扩大改善缓慢。理论分析表明校准改善速度取决于数据分布的幂律指数，实证研究显示从5亿到700亿参数的模型都表现出相似的错误累积率。


<details>
  <summary>Details</summary>
Motivation: 解决自回归模型中熵校准错误累积这一基本问题，探索模型规模扩大是否能改善校准，以及是否存在无需牺牲多样性的校准方法。

Method: 首先在简化理论设置中分析校准错误随数据集规模的缩放行为，然后实证测量从0.5B到70B参数的语言模型的校准错误。

Result: 发现校准错误的缩放指数接近0，意味着更大模型与更小模型以相似速率累积错误，这解释了为什么即使更大模型质量更高，我们仍使用相似程度的截断采样。

Conclusion: 理论上证明如果能够访问预测文本未来熵的黑盒模型，可以在不增加对数损失的情况下减少熵，从而可能实现无代价的校准。

Abstract: We study the problem of entropy calibration, which asks whether a language model's entropy over generations matches its log loss on human text. Past work found that models are miscalibrated, with entropy per step increasing (and text quality decreasing) as generations grow longer. This error accumulation is a fundamental problem in autoregressive models, and the standard solution is to truncate the distribution, which improves text quality at the cost of diversity. In this paper, we ask: is miscalibration likely to improve with scale, and is it theoretically possible to calibrate without tradeoffs? To build intuition, we first study a simplified theoretical setting to characterize the scaling behavior of miscalibration with respect to dataset size. We find that the scaling behavior depends on the power law exponent of the data distribution -- in particular, for a power law exponent close to 1, the scaling exponent is close to 0, meaning that miscalibration improves very slowly with scale. Next, we measure miscalibration empirically in language models ranging from 0.5B to 70B parameters. We find that the observed scaling behavior is similar to what is predicted by the simplified setting: our fitted scaling exponents for text are close to 0, meaning that larger models accumulate error at a similar rate as smaller ones. This scaling (or, lack thereof) provides one explanation for why we sample from larger models with similar amounts of truncation as smaller models, even though the larger models are of higher quality. However, truncation is not a satisfying solution because it comes at the cost of increased log loss. In theory, is it even possible to reduce entropy while preserving log loss? We prove that it is possible, if we assume access to a black box which can fit models to predict the future entropy of text.

</details>


### [15] [A Reasoning Paradigm for Named Entity Recognition](https://arxiv.org/abs/2511.11978)
*Hui Huang,Yanping Chen,Ruizhang Huang,Chuan Lin,Yongbin Qin*

Main category: cs.CL

TL;DR: 提出了ReasoningNER框架，通过显式推理机制改进NER任务，在零样本设置下性能超越GPT-4 12.3个百分点


<details>
  <summary>Details</summary>
Motivation: 现有生成式LLM在NER任务中依赖隐式模式匹配，缺乏可验证的推理机制，导致性能次优和泛化脆弱，特别是在零样本和低资源场景下

Method: 三阶段推理框架：1)生成NER导向的思维链数据集；2)使用CoT微调NER模型；3)通过综合奖励信号优化推理过程

Result: 在零样本设置下达到SOTA性能，F1分数比GPT-4高出12.3个百分点，展示了在推理导向信息提取研究中的巨大潜力

Conclusion: ReasoningNER框架通过将提取范式从隐式模式匹配转向显式推理，显著提升了NER任务的认知能力和性能

Abstract: Generative LLMs typically improve Named Entity Recognition (NER) performance through instruction tuning. They excel at generating entities by semantic pattern matching but lack an explicit, verifiable reasoning mechanism. This "cognitive shortcutting" leads to suboptimal performance and brittle generalization, especially in zero-shot and lowresource scenarios where reasoning from limited contextual cues is crucial. To address this issue, a reasoning framework is proposed for NER, which shifts the extraction paradigm from implicit pattern matching to explicit reasoning. This framework consists of three stages: Chain of Thought (CoT) generation, CoT tuning, and reasoning enhancement. First, a dataset annotated with NER-oriented CoTs is generated, which contain task-relevant reasoning chains. Then, they are used to tune the NER model to generate coherent rationales before deriving the final answer. Finally, a reasoning enhancement stage is implemented to optimize the reasoning process using a comprehensive reward signal. This stage ensures explicit and verifiable extractions. Experiments show that ReasoningNER demonstrates impressive cognitive ability in the NER task, achieving competitive performance. In zero-shot settings, it achieves state-of-the-art (SOTA) performance, outperforming GPT-4 by 12.3 percentage points on the F1 score. Analytical results also demonstrate its great potential to advance research in reasoningoriented information extraction. Our codes are available at https://github.com/HuiResearch/ReasoningIE.

</details>


### [16] [Critical or Compliant? The Double-Edged Sword of Reasoning in Chain-of-Thought Explanations](https://arxiv.org/abs/2511.12001)
*Eunkyu Park,Wesley Hanwen Deng,Vasudha Varadarajan,Mingxi Yan,Gunhee Kim,Maarten Sap,Motahhare Eslami*

Main category: cs.CL

TL;DR: 研究发现CoT解释在道德场景中具有双重作用：既能提高透明度，也可能因确认偏见而误导用户，特别是当解释语气自信时，用户会忽视推理错误而维持信任。


<details>
  <summary>Details</summary>
Motivation: 研究CoT解释在道德场景中的双重角色，探讨其如何既促进透明度又可能因确认偏见而误导用户，特别是关注推理错误和语气对用户信任和错误检测能力的影响。

Method: 在多模态道德场景中系统性地扰动推理链和操纵解释语气，分析视觉语言模型中的推理错误及其对用户信任和错误检测能力的影响。

Result: 发现两个关键效应：(1)用户常将信任等同于结果一致性，即使推理有缺陷也维持依赖；(2)自信语气会抑制错误检测但维持依赖，表明表达风格可以凌驾于正确性之上。

Conclusion: CoT解释既能澄清也能误导，强调NLP系统需要提供鼓励审慎和批判性思维而非盲目信任的解释。

Abstract: Explanations are often promoted as tools for transparency, but they can also foster confirmation bias; users may assume reasoning is correct whenever outputs appear acceptable. We study this double-edged role of Chain-of-Thought (CoT) explanations in multimodal moral scenarios by systematically perturbing reasoning chains and manipulating delivery tones. Specifically, we analyze reasoning errors in vision language models (VLMs) and how they impact user trust and the ability to detect errors. Our findings reveal two key effects: (1) users often equate trust with outcome agreement, sustaining reliance even when reasoning is flawed, and (2) the confident tone suppresses error detection while maintaining reliance, showing that delivery styles can override correctness. These results highlight how CoT explanations can simultaneously clarify and mislead, underscoring the need for NLP systems to provide explanations that encourage scrutiny and critical thinking rather than blind trust. All code will be released publicly.

</details>


### [17] [CURE: Cultural Understanding and Reasoning Evaluation - A Framework for "Thick" Culture Alignment Evaluation in LLMs](https://arxiv.org/abs/2511.12014)
*Truong Vo,Sanmi Koyejo*

Main category: cs.CL

TL;DR: 本文提出了一个评估大语言模型文化能力的厚评估框架，通过情境化基准测试和多维度指标，揭示了传统薄评估会高估模型文化能力且评估不稳定。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型文化能力评估方法局限于去情境化的正确性或强制选择判断，忽视了文化理解和推理的需求，无法准确评估模型在多元文化环境中的实际表现。

Method: 引入基于现实情境的基准测试，要求模型进行文化基础推理，并提出了四个补充指标（覆盖度、特异性、内涵和连贯性）来多维度评估响应质量。

Result: 实证分析显示，传统薄评估会系统性高估文化能力且评估方差大，而厚评估能揭示推理深度差异、减少方差，提供更稳定可解释的文化理解信号。

Conclusion: 厚评估方法比薄评估更适合评估大语言模型的文化能力，能提供更准确、稳定和可解释的评估结果。

Abstract: Large language models (LLMs) are increasingly deployed in culturally diverse environments, yet existing evaluations of cultural competence remain limited. Existing methods focus on de-contextualized correctness or forced-choice judgments, overlooking the need for cultural understanding and reasoning required for appropriate responses. To address this gap, we introduce a set of benchmarks that, instead of directly probing abstract norms or isolated statements, present models with realistic situational contexts that require culturally grounded reasoning. In addition to the standard Exact Match metric, we introduce four complementary metrics (Coverage, Specificity, Connotation, and Coherence) to capture different dimensions of model's response quality. Empirical analysis across frontier models reveals that thin evaluation systematically overestimates cultural competence and produces unstable assessments with high variance. In contrast, thick evaluation exposes differences in reasoning depth, reduces variance, and provides more stable, interpretable signals of cultural understanding.

</details>


### [18] [Exploring Parameter-Efficient Fine-Tuning and Backtranslation for the WMT 25 General Translation Task](https://arxiv.org/abs/2511.12109)
*Felipe Fujita,Hideyuki Takada*

Main category: cs.CL

TL;DR: 结合反向翻译和微调在小型日语语料库上显著提升神经机器翻译质量，即使训练数据有限也能获得优异表现。


<details>
  <summary>Details</summary>
Motivation: 探索在低资源语言对（英语→日语）中，如何通过结合反向翻译和微调技术来提升翻译质量，特别是在训练数据有限的情况下。

Method: 首先使用反向翻译从单语日语语料生成合成数据，然后在小规模真实平行数据集上进行微调，最后将两种方法结合使用。

Result: 从基线COMET=0.460开始，反向翻译提升至0.468，微调大幅提升至0.589，结合两种方法达到最佳性能COMET=0.597。

Conclusion: 反向翻译和针对性微调的协同使用能够显著提升低资源语言对的翻译质量，为有限训练数据场景提供了轻量级但强大的解决方案。

Abstract: In this paper, we explore the effectiveness of combining fine-tuning and backtranslation on a small Japanese corpus for neural machine translation. Starting from a baseline English{\textrightarrow}Japanese model (COMET = 0.460), we first apply backtranslation (BT) using synthetic data generated from monolingual Japanese corpora, yielding a modest increase (COMET = 0.468). Next, we fine-tune (FT) the model on a genuine small parallel dataset drawn from diverse Japanese news and literary corpora, achieving a substantial jump to COMET = 0.589 when using Mistral 7B. Finally, we integrate both backtranslation and fine-tuning{ -- }first augmenting the small dataset with BT generated examples, then adapting via FT{ -- }which further boosts performance to COMET = 0.597. These results demonstrate that, even with limited training data, the synergistic use of backtranslation and targeted fine-tuning on Japanese corpora can significantly enhance translation quality, outperforming each technique in isolation. This approach offers a lightweight yet powerful strategy for improving low-resource language pairs.

</details>


### [19] [LLMLagBench: Identifying Temporal Training Boundaries in Large Language Models](https://arxiv.org/abs/2511.12116)
*Piotr Pęzik,Konrad Kaczyński,Maria Szymańska,Filip Żarnecki,Zuzanna Deckert,Jakub Kwiatkowski,Wojciech Janowski*

Main category: cs.CL

TL;DR: LLMLagBench是一个评估LLM训练数据时间边界的基准测试，用于识别模型知识的最新时间界限，避免LLM在推理时混合过时信息。


<details>
  <summary>Details</summary>
Motivation: LLM在特定时间点前的文本数据上预训练，形成了严格的知识边界。当这个限制未知或被忽略时，LLM可能在推理任务中无意间将过时的时效性信息与一般知识混合，从而影响回答准确性。

Method: 引入LLMLagBench作为系统性方法，通过评估LLM对近期事件的知识来识别其训练数据的最早可能时间边界。将该基准应用于大量LLM评估，包括明确声明和未声明训练截止时间的模型。

Result: 通过人工验证和与公开的LLM预训练信息比较来评估基准的可靠性。

Conclusion: LLMLagBench提供了一种系统性的方法来识别LLM的知识时间边界，有助于理解模型的知识局限性并提高推理准确性。

Abstract: Large Language Models (LLMs) are pretrained on textual data up to a specific temporal cutoff. This creates a strict knowledge boundary beyond which models cannot provide accurate information without querying external sources. More subtly, when this limitation is unknown or ignored, LLMs may inadvertently blend outdated time-sensitive information with general knowledge during reasoning tasks, potentially compromising response accuracy. We introduce LLMLagBench, an LLM freshness benchmark, as a systematic approach for identifying the earliest probable temporal boundaries of an LLM's training data by evaluating its knowledge of recent events. We then apply this benchmark to evaluate a large set of LLMs, including models with both explicitly declared and undeclared training cutoffs. The reliability of the benchmark is assessed by manual validation and comparison with publicly released information about LLM pretraining.

</details>


### [20] [PRISM of Opinions: A Persona-Reasoned Multimodal Framework for User-centric Conversational Stance Detection](https://arxiv.org/abs/2511.12130)
*Bingbing Wang,Zhixin Bai,Zhengda Jin,Zihan Wang,Xintong Song,Jingjie Lin,Sixuan Li,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 提出了U-MStance数据集和PRISM模型，通过用户画像和多模态推理解决多模态对话立场检测中的伪多模态和用户同质性问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究存在伪多模态（仅源帖子包含视觉线索，评论被视为纯文本）和用户同质化（忽略个人特质对立场表达的影响）的局限性。

Method: PRISM模型：1）从历史帖子推导纵向用户画像；2）通过思维链对齐对话上下文中的文本和视觉线索；3）采用相互任务强化机制联合优化立场检测和立场感知响应生成。

Result: 在U-MStance数据集上的实验表明，PRISM相比强基线模型取得了显著提升。

Conclusion: 用户中心和上下文基础的多模态推理对于现实立场理解具有有效性。

Abstract: The rapid proliferation of multimodal social media content has driven research in Multimodal Conversational Stance Detection (MCSD), which aims to interpret users' attitudes toward specific targets within complex discussions. However, existing studies remain limited by: **1) pseudo-multimodality**, where visual cues appear only in source posts while comments are treated as text-only, misaligning with real-world multimodal interactions; and **2) user homogeneity**, where diverse users are treated uniformly, neglecting personal traits that shape stance expression. To address these issues, we introduce **U-MStance**, the first user-centric MCSD dataset, containing over 40k annotated comments across six real-world targets. We further propose **PRISM**, a **P**ersona-**R**easoned mult**I**modal **S**tance **M**odel for MCSD. PRISM first derives longitudinal user personas from historical posts and comments to capture individual traits, then aligns textual and visual cues within conversational context via Chain-of-Thought to bridge semantic and pragmatic gaps across modalities. Finally, a mutual task reinforcement mechanism is employed to jointly optimize stance detection and stance-aware response generation for bidirectional knowledge transfer. Experiments on U-MStance demonstrate that PRISM yields significant gains over strong baselines, underscoring the effectiveness of user-centric and context-grounded multimodal reasoning for realistic stance understanding.

</details>


### [21] [AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing](https://arxiv.org/abs/2511.12133)
*Qingyu Zhang,Chunlei Xin,Xuanang Chen,Yaojie Lu,Hongyu Lin,Xianpei Han,Le Sun,Qing Ye,Qianlong Xie,Xingxing Wang*

Main category: cs.CL

TL;DR: 提出了AI-Salesman框架，通过双阶段架构解决目标驱动说服对话中的多轮规划和事实忠实性问题，在真实数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 目标驱动说服对话（如电话销售）需要复杂多轮规划和严格事实忠实性，现有LLMs存在战略脆弱性和事实幻觉问题，且缺乏领域特定数据。

Method: 构建TeleSalesCorpus数据集，提出双阶段AI-Salesman框架：训练阶段使用贝叶斯监督强化学习从噪声对话中学习稳健销售策略；推理阶段使用动态大纲引导代理(DOGA)结合预建脚本库提供动态策略指导。

Result: 实验结果表明，AI-Salesman在自动指标和综合人工评估中均显著优于基线模型，在复杂说服场景中表现出色。

Conclusion: AI-Salesman框架有效解决了目标驱动说服对话中的关键挑战，通过数据驱动方法和动态策略指导实现了更好的性能。

Abstract: Goal-driven persuasive dialogue, exemplified by applications like telemarketing, requires sophisticated multi-turn planning and strict factual faithfulness, which remains a significant challenge for even state-of-the-art Large Language Models (LLMs). A lack of task-specific data often limits previous works, and direct LLM application suffers from strategic brittleness and factual hallucination. In this paper, we first construct and release TeleSalesCorpus, the first real-world-grounded dialogue dataset for this domain. We then propose AI-Salesman, a novel framework featuring a dual-stage architecture. For the training stage, we design a Bayesian-supervised reinforcement learning algorithm that learns robust sales strategies from noisy dialogues. For the inference stage, we introduce the Dynamic Outline-Guided Agent (DOGA), which leverages a pre-built script library to provide dynamic, turn-by-turn strategic guidance. Moreover, we design a comprehensive evaluation framework that combines fine-grained metrics for key sales skills with the LLM-as-a-Judge paradigm. Experimental results demonstrate that our proposed AI-Salesman significantly outperforms baseline models in both automatic metrics and comprehensive human evaluations, showcasing its effectiveness in complex persuasive scenarios.

</details>


### [22] [Seeing is Believing: Rich-Context Hallucination Detection for MLLMs via Backward Visual Grounding](https://arxiv.org/abs/2511.12140)
*Pinxue Guo,Chongruo Wu,Xinyu Zhou,Lingyi Hong,Zhaoyu Chen,Jinglun Li,Kaixun Jiang,Sen-ching Samson Cheung,Wei Zhang,Wenqiang Zhang*

Main category: cs.CL

TL;DR: VBackChecker是一个无需参考的幻觉检测框架，通过像素级Grounding LLM验证MLLM生成响应与视觉输入的一致性，在R^2-HalBench基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在严重的幻觉问题，需要准确检测以确保在实际应用中的可靠性。

Method: 基于"眼见为实"原则，使用具备推理和参考分割能力的像素级Grounding LLM来验证响应与视觉输入的一致性，并设计了R-Instruct指令调优数据生成流程。

Result: 在R^2-HalBench基准上超越现有复杂框架，性能媲美GPT-4o，在像素级定位任务中相比先前方法提升超过10%。

Conclusion: VBackChecker为MLLM幻觉检测提供了有效的参考免费解决方案，具有处理丰富上下文场景的能力和可解释性。

Abstract: Multimodal Large Language Models (MLLMs) have unlocked powerful cross-modal capabilities, but still significantly suffer from hallucinations. As such, accurate detection of hallucinations in MLLMs is imperative for ensuring their reliability in practical applications. To this end, guided by the principle of "Seeing is Believing", we introduce VBackChecker, a novel reference-free hallucination detection framework that verifies the consistency of MLLMgenerated responses with visual inputs, by leveraging a pixellevel Grounding LLM equipped with reasoning and referring segmentation capabilities. This reference-free framework not only effectively handles rich-context scenarios, but also offers interpretability. To facilitate this, an innovative pipeline is accordingly designed for generating instruction-tuning data (R-Instruct), featuring rich-context descriptions, grounding masks, and hard negative samples. We further establish R^2 -HalBench, a new hallucination benchmark for MLLMs, which, unlike previous benchmarks, encompasses real-world, rich-context descriptions from 18 MLLMs with high-quality annotations, spanning diverse object-, attribute, and relationship-level details. VBackChecker outperforms prior complex frameworks and achieves state-of-the-art performance on R^2 -HalBench, even rivaling GPT-4o's capabilities in hallucination detection. It also surpasses prior methods in the pixel-level grounding task, achieving over a 10% improvement. All codes, data, and models are available at https://github.com/PinxueGuo/VBackChecker.

</details>


### [23] [CriticSearch: Fine-Grained Credit Assignment for Search Agents via a Retrospective Critic](https://arxiv.org/abs/2511.12159)
*Yaocheng Zhang,Haohuan Huang,Zijun Song,Yuanheng Zhu,Qichao Zhang,Zijie Zhao,Dongbin Zhao*

Main category: cs.CL

TL;DR: CriticSearch是一个细粒度信用分配框架，通过回顾性批评机制提供密集的回合级反馈，解决搜索代理中稀疏奖励导致的低效探索和不稳定训练问题。


<details>
  <summary>Details</summary>
Motivation: 现有搜索代理管道依赖强化学习优化，但面临稀疏结果奖励问题，导致探索效率低和训练不稳定。

Method: 使用冻结的非对称批评LLM，基于完整轨迹和黄金答案的权限信息回顾性评估每个回合，将评估转化为稳定的密集奖励来指导策略改进。

Result: 在多样化多跳推理基准测试中，CriticSearch始终优于现有基线方法，实现更快的收敛、更好的训练稳定性和更高的性能。

Conclusion: CriticSearch通过密集的回合级反馈机制有效提升了搜索代理的训练效率和性能。

Abstract: Tool-Integrated Reasoning (TIR) with search engines enables large language models to iteratively retrieve up-to-date external knowledge, enhancing adaptability and generalization in complex question-answering tasks. However, existing search agent pipelines typically depend on reinforcement learning based optimization, which often suffers from sparse outcome rewards, leading to inefficient exploration and unstable training. We introduce CriticSearch, a fine-grained credit-assignment framework that supplies dense, turn-level feedback via a retrospective critic mechanism. During training, a frozen, asymmetric critique LLM retrospectively evaluates each turn using privileged information from the full trajectory and gold answers, converting these assessments into stable, dense rewards that guide policy improvement. Experimental results across diverse multi-hop reasoning benchmarks demonstrate that CriticSearch consistently outperforms existing baselines, achieving faster convergence, improved training stability, and higher performance.

</details>


### [24] [MME-RAG: Multi-Manager-Expert Retrieval-Augmented Generation for Fine-Grained Entity Recognition in Task-Oriented Dialogues](https://arxiv.org/abs/2511.12213)
*Liang Xue,Haoyu Liu,Yajun Tian,Xinyu Zhong,Yang Liu*

Main category: cs.CL

TL;DR: MME-RAG是一个多管理器-专家检索增强生成框架，通过将实体识别分解为类型级判断和跨度级提取两个协调阶段，解决了LLM在领域适应和检索可控性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在任务导向对话中的细粒度实体识别面临领域适应和检索可控性挑战，需要更精确和领域自适应的解决方案。

Method: 采用分层架构：轻量级管理器进行类型级判断，专业专家进行跨度级提取，每个专家配备KeyInfo检索器注入语义对齐的少样本示例。

Result: 在CrossNER、MIT-Movie、MIT-Restaurant和新构建的多领域客服数据集上，MME-RAG在大多数领域表现优于现有基线方法。

Conclusion: 分层分解和KeyInfo引导的检索是鲁棒性和跨领域泛化的关键驱动因素，MME-RAG为自适应对话理解提供了可扩展和可解释的解决方案。

Abstract: Fine-grained entity recognition is crucial for reasoning and decision-making in task-oriented dialogues, yet current large language models (LLMs) continue to face challenges in domain adaptation and retrieval controllability. We introduce MME-RAG, a Multi-Manager-Expert Retrieval-Augmented Generation framework that decomposes entity recognition into two coordinated stages: type-level judgment by lightweight managers and span-level extraction by specialized experts. Each expert is supported by a KeyInfo retriever that injects semantically aligned, few-shot exemplars during inference, enabling precise and domain-adaptive extraction without additional training. Experiments on CrossNER, MIT-Movie, MIT-Restaurant, and our newly constructed multi-domain customer-service dataset demonstrate that MME-RAG performs better than recent baselines in most domains. Ablation studies further show that both the hierarchical decomposition and KeyInfo-guided retrieval are key drivers of robustness and cross-domain generalization, establishing MME-RAG as a scalable and interpretable solution for adaptive dialogue understanding.

</details>


### [25] [Consistency Is the Key: Detecting Hallucinations in LLM Generated Text By Checking Inconsistencies About Key Facts](https://arxiv.org/abs/2511.12236)
*Raavi Gupta,Pranav Hari Panicker,Sumit Bhatia,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: CONFACTCHECK是一种高效的幻觉检测方法，无需外部知识库，通过检查生成文本中事实探针响应的一致性来检测LLM幻觉。


<details>
  <summary>Details</summary>
Motivation: LLM在文本生成时经常产生事实错误的幻觉，这在医疗、金融等领域存在严重风险。现有方法需要多次API调用，增加延迟和成本。

Method: 基于单LLM内部和跨不同LLM之间对生成文本中事实探针响应的一致性检查，无需外部知识库或模型权重访问。

Result: 在多个数据集上的评估显示，CONFACTCHECK能以更少资源高效检测幻觉事实，相比类似条件下的基线方法获得更高准确率。

Conclusion: CONFACTCHECK提供了一种资源高效、无需外部知识的幻觉检测解决方案，适用于API受限场景。

Abstract: Large language models (LLMs), despite their remarkable text generation capabilities, often hallucinate and generate text that is factually incorrect and not grounded in real-world knowledge. This poses serious risks in domains like healthcare, finance, and customer support. A typical way to use LLMs is via the APIs provided by LLM vendors where there is no access to model weights or options to fine-tune the model. Existing methods to detect hallucinations in such settings where the model access is restricted or constrained by resources typically require making multiple LLM API calls, increasing latency and API cost. We introduce CONFACTCHECK, an efficient hallucination detection approach that does not leverage any external knowledge base and works on the simple intuition that responses to factual probes within the generated text should be consistent within a single LLM and across different LLMs. Rigorous empirical evaluation on multiple datasets that cover both the generation of factual texts and the open generation shows that CONFACTCHECK can detect hallucinated facts efficiently using fewer resources and achieves higher accuracy scores compared to existing baselines that operate under similar conditions. Our code is available here.

</details>


### [26] [ViConBERT: Context-Gloss Aligned Vietnamese Word Embedding for Polysemous and Sense-Aware Representations](https://arxiv.org/abs/2511.12249)
*Khang T. Huynh,Dung H. Nguyen,Binh T. Nguyen*

Main category: cs.CL

TL;DR: 提出了ViConBERT框架，结合对比学习和基于词义解释的知识蒸馏来学习越南语上下文嵌入，并创建了ViConWSD数据集用于评估越南语语义理解。


<details>
  <summary>Details</summary>
Motivation: 越南语缺乏强大的语义理解模型和评估资源，而现有进展主要限于英语等高资源语言。

Method: 使用对比学习（SimCLR）和基于词义解释的知识蒸馏来学习越南语上下文嵌入，并构建大规模合成数据集ViConWSD。

Result: ViConBERT在WSD上F1=0.87，在ViCon上AP=0.88，在ViSim-400上Spearman's rho=0.60，表现优于基线模型。

Conclusion: ViConBERT能有效建模离散词义和分级语义关系，为越南语语义理解提供了有力工具。

Abstract: Recent advances in contextualized word embeddings have greatly improved semantic tasks such as Word Sense Disambiguation (WSD) and contextual similarity, but most progress has been limited to high-resource languages like English. Vietnamese, in contrast, still lacks robust models and evaluation resources for fine-grained semantic understanding. In this paper, we present ViConBERT, a novel framework for learning Vietnamese contextualized embeddings that integrates contrastive learning (SimCLR) and gloss-based distillation to better capture word meaning. We also introduce ViConWSD, the first large-scale synthetic dataset for evaluating semantic understanding in Vietnamese, covering both WSD and contextual similarity. Experimental results show that ViConBERT outperforms strong baselines on WSD (F1 = 0.87) and achieves competitive performance on ViCon (AP = 0.88) and ViSim-400 (Spearman's rho = 0.60), demonstrating its effectiveness in modeling both discrete senses and graded semantic relations. Our code, models, and data are available at https://github.com/tkhangg0910/ViConBERT

</details>


### [27] [Cmprsr: Abstractive Token-Level Question-Agnostic Prompt Compressor](https://arxiv.org/abs/2511.12281)
*Ivan Zakazov,Alexander Sharipov,Berke Argin,Oussama Gabouj,Kamel Charaf,Alexi Semiz,Lorenzo Drudi,Nicolas Baldwin,Robert West*

Main category: cs.CL

TL;DR: 提出使用小型LLM压缩大型LLM输入的新范式，开发了Cmprsr模型，在保持语义信息和控制压缩率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 降低使用黑盒大型语言模型的高成本，通过压缩输入来减少计算开销。

Method: 使用Textgrad优化压缩元提示，对Qwen3-4B进行SFT和GRPO联合训练，实现压缩率控制和下游任务性能最大化。

Result: Cmprsr在MeetingBank、LongBench和GSM8k数据集上优于抽取式和原始抽象压缩方法，能精确控制压缩率。

Conclusion: Cmprsr模型在成本-质量权衡方面提供了精细控制，具有良好的泛化能力。

Abstract: Motivated by the high costs of using black-box Large Language Models (LLMs), we introduce a novel prompt compression paradigm, under which we use smaller LLMs to compress inputs for the larger ones. We present the first comprehensive LLM-as-a-compressor benchmark spanning 25 open- and closed-source models, which reveals significant disparity in models' compression ability in terms of (i) preserving semantically important information (ii) following the user-provided compression rate (CR). We further improve the performance of gpt-4.1-mini, the best overall vanilla compressor, with Textgrad-based compression meta-prompt optimization. We also identify the most promising open-source vanilla LLM - Qwen3-4B - and post-train it with a combination of supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), pursuing the dual objective of CR adherence and maximizing the downstream task performance. We call the resulting model Cmprsr and demonstrate its superiority over both extractive and vanilla abstractive compression across the entire range of compression rates on lengthy inputs from MeetingBank and LongBench as well as short prompts from GSM8k. The latter highlights Cmprsr's generalizability across varying input lengths and domains. Moreover, Cmprsr closely follows the requested compression rate, offering fine control over the cost-quality trade-off.

</details>


### [28] [AugAbEx : Way Forward for Extractive Case Summarization](https://arxiv.org/abs/2511.12290)
*Purnima Bindal,Vikas Kumar,Sagar Rathore,Vasudha Bhatnagar*

Main category: cs.CL

TL;DR: 本文提出了一种利用现有抽象摘要生成对应提取式摘要的轻量级方法，旨在为法律案例摘要研究社区创建丰富的数据资源。


<details>
  <summary>Details</summary>
Motivation: 法律判决摘要对法律从业者造成沉重的认知负担，而深度学习方法生成的抽象摘要容易误判法律术语或忽略关键细节，因此需要提取式案例摘要器。

Method: 设计了一个轻量透明的流程，利用现有的抽象标准摘要创建对应的提取式标准版本，确保专家意见从原始抽象摘要传递到转换后的提取式摘要。

Result: 扩充了七个现有案例摘要数据集，包含抽象摘要和对应的提取式摘要，并通过结构、词汇和语义维度的广泛比较评估确保提取式摘要质量。

Conclusion: 承诺公开发布扩充的数据集，相信这一资源将推动法律文档自动摘要领域的发展。

Abstract: Summarization of legal judgments poses a heavy cognitive burden on law practitioners due to the complexity of the language, context-sensitive legal jargon, and the length of the document. Therefore, the automatic summarization of legal documents has attracted serious attention from natural language processing researchers. Since the abstractive summaries of legal documents generated by deep neural methods remain prone to the risk of misrepresenting nuanced legal jargon or overlooking key contextual details, we envisage a rising trend toward the use of extractive case summarizers.
  Given the high cost of human annotation for gold standard extractive summaries, we engineer a light and transparent pipeline that leverages existing abstractive gold standard summaries to create the corresponding extractive gold standard versions. The approach ensures that the experts` opinions ensconced in the original gold standard abstractive summaries are carried over to the transformed extractive summaries. We aim to augment seven existing case summarization datasets, which include abstractive summaries, by incorporating corresponding extractive summaries and create an enriched data resource for case summarization research community. To ensure the quality of the augmented extractive summaries, we perform an extensive comparative evaluation with the original abstractive gold standard summaries covering structural, lexical, and semantic dimensions. We also compare the domain-level information of the two summaries. We commit to release the augmented datasets in the public domain for use by the research community and believe that the resource will offer opportunities to advance the field of automatic summarization of legal documents.

</details>


### [29] [Do LLMs and Humans Find the Same Questions Difficult? A Case Study on Japanese Quiz Answering](https://arxiv.org/abs/2511.12300)
*Naoya Sugiura,Kosuke Yamada,Yasuhiro Ogawa,Katsuhiko Toyama,Ryohei Sasano*

Main category: cs.CL

TL;DR: 研究比较了LLMs和人类在抢答式问答中的表现差异，发现LLMs在维基百科未覆盖的问题和需要数值答案的问题上表现较差


<details>
  <summary>Details</summary>
Motivation: 探究对人类困难的问题是否对LLMs同样困难，比较LLMs和人类在抢答式问答中的表现差异

Method: 收集日本问答数据（包含问题、答案和人类正确率），在不同设置下让LLMs回答这些问题，从两个分析角度比较LLMs与人类的正确率

Result: 实验结果显示，相比人类，LLMs在维基百科未覆盖答案的问题上表现更差，且在需要数值答案的问题上也有困难

Conclusion: LLMs与人类在问题难度上存在差异，特别是在知识覆盖范围和数值推理方面表现出不同的能力特征

Abstract: LLMs have achieved performance that surpasses humans in many NLP tasks. However, it remains unclear whether problems that are difficult for humans are also difficult for LLMs. This study investigates how the difficulty of quizzes in a buzzer setting differs between LLMs and humans. Specifically, we first collect Japanese quiz data including questions, answers, and correct response rate of humans, then prompted LLMs to answer the quizzes under several settings, and compare their correct answer rate to that of humans from two analytical perspectives. The experimental results showed that, compared to humans, LLMs struggle more with quizzes whose correct answers are not covered by Wikipedia entries, and also have difficulty with questions that require numerical answers.

</details>


### [30] [Don't Think of the White Bear: Ironic Negation in Transformer Models Under Cognitive Load](https://arxiv.org/abs/2511.12381)
*Logan Mann,Nayan Saxena,Sarah Tandon,Chenhao Sun,Savar Toteja,Kevin Zhu*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型中的讽刺反弹现象——否定指令反而会增加被禁止概念的可及性。通过两个实验发现：否定后立即出现反弹，语义干扰会加剧反弹，而重复有助于抑制；极性分离程度与反弹持续性相关。


<details>
  <summary>Details</summary>
Motivation: 人类思维中存在讽刺反弹现象，即否定指令会增强被禁止概念的可及性。本研究旨在探究大型语言模型是否面临同样的挑战，以及这种反弹现象背后的机制。

Method: 进行两个实验：(1) 负载与内容实验：在否定指令后引入不同类型干扰文本（语义、句法、重复），测量反弹强度；(2) 极性分离实验：测试模型是否能区分概念的中性和负面框架，以及这种分离是否预测反弹持续性。还进行了电路追踪分析。

Result: 结果显示：否定后立即出现反弹，较长或语义干扰会加剧反弹，而重复有助于抑制；更强的极性分离与更持久的反弹相关。电路分析发现稀疏中间层注意力头放大被禁止标记，而早期层进行抑制。

Conclusion: 研究将讽刺反弹的认知预测与长上下文干扰的机制洞察联系起来，并发布了ReboundBench数据集（5000个系统变化的否定提示）以支持未来研究。

Abstract: Negation instructions such as 'do not mention $X$' can paradoxically increase the accessibility of $X$ in human thought, a phenomenon known as ironic rebound. Large language models (LLMs) face the same challenge: suppressing a concept requires internally activating it, which may prime rebound instead of avoidance. We investigated this tension with two experiments. \textbf{(1) Load \& content}: after a negation instruction, we vary distractor text (semantic, syntactic, repetition) and measure rebound strength. \textbf{(2) Polarity separation}: We test whether models distinguish neutral from negative framings of the same concept and whether this separation predicts rebound persistence. Results show that rebound consistently arises immediately after negation and intensifies with longer or semantic distractors, while repetition supports suppression. Stronger polarity separation correlates with more persistent rebound. Together, these findings, complemented by a circuit tracing analysis that identifies sparse middle-layer attention heads amplifying forbidden tokens while early layers suppress, link cognitive predictions of ironic rebound with mechanistic insights into long-context interference. To support future work, we release ReboundBench, a dataset of $5,000$ systematically varied negation prompts designed to probe rebound in LLMs.

</details>


### [31] [From Phonemes to Meaning: Evaluating Large Language Models on Tamil](https://arxiv.org/abs/2511.12387)
*Jeyarajalingam Varsha,Menan Velayuthan,Sumirtha Karunakaran,Rasan Nivethiga,Kengatharaiyer Sarveswaran*

Main category: cs.CL

TL;DR: ILAKKANAM是首个泰米尔语特定语言评估基准，包含820个来自斯里兰卡学校考试的问题，评估显示LLMs在泰米尔语中的语言能力有限，性能随复杂度增加而下降。


<details>
  <summary>Details</summary>
Motivation: 现有多语言基准多依赖英语翻译数据集，无法捕捉泰米尔语等低资源、形态丰富语言的语言和文化细微差别。

Method: 使用820个斯里兰卡学校泰米尔语考试问题构建基准，由训练有素的语言学家在五个语言类别和一个事实知识类别下进行标注，涵盖1-13年级以确保广泛的语言覆盖。

Result: Gemini 2.5表现最佳，开源模型落后；所有模型在低年级问题上表现良好，但随着语言复杂性增加明显下降；模型整体表现与识别语言类别能力无强相关性。

Conclusion: LLMs在泰米尔语中的表现可能由曝光驱动而非真正理解，需要更多针对低资源语言的语言基础工作。

Abstract: Large Language Models (LLMs) have shown strong generalization across tasks in high-resource languages; however, their linguistic competence in low-resource and morphologically rich languages such as Tamil remains largely unexplored. Existing multilingual benchmarks often rely on translated English datasets, failing to capture the linguistic and cultural nuances of the target language. To address this gap, we introduce ILAKKANAM, the first Tamil-specific linguistic evaluation benchmark manually curated using 820 questions from Sri Lankan school-level Tamil subject examination papers. Each question is annotated by trained linguists under five linguistic categories and a factual knowledge category, spanning Grades 1--13 to ensure broad linguistic coverage. We evaluate both closed-source and open-source LLMs using a standardized evaluation framework. Our results show that Gemini 2.5 achieves the highest overall performance, while open-source models lag behind, highlighting the gap in linguistic grounding. Category- and grade-wise analyses reveal that all models perform well on lower-grade questions but show a clear decline as linguistic complexity increases. Further, no strong correlation is observed between a model's overall performance and its ability to identify linguistic categories, suggesting that performance may be driven by exposure rather than genuine understanding.

</details>


### [32] [Probing Preference Representations: A Multi-Dimensional Evaluation and Analysis Method for Reward Models](https://arxiv.org/abs/2511.12464)
*Chenglong Wang,Yifu Huo,Yang Gan,Yongyu Mu,Qiaozhi He,Murun Yang,Bei Li,Chunliang Zhang,Tongran Liu,Anxiang Ma,Zhengtao Yu,Jingbo Zhu,Tong Xiao*

Main category: cs.CL

TL;DR: 提出了MRMBench基准和推理时探测方法，用于评估奖励模型在多维度偏好上的表现，发现该方法与LLM对齐性能强相关，揭示了奖励模型在多维度偏好捕捉上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型评估方法通常使用固定的成对排序测试集，但无法提供各个偏好维度的性能信息，需要更细粒度的评估方法来分析奖励模型在不同偏好维度上的表现。

Method: 构建了MRMBench基准，包含6个不同偏好维度的探测任务；提出了推理时探测方法，识别奖励预测中使用的维度并增强可解释性。

Result: MRMBench与大型语言模型的对齐性能强相关；奖励模型在多维度偏好捕捉上存在困难；推理时探测方法能可靠评估奖励预测置信度。

Conclusion: MRMBench是开发先进奖励模型的可靠参考；多目标优化在奖励建模中具有潜力；推理时探测方法能提升LLM对齐效果。

Abstract: Previous methods evaluate reward models by testing them on a fixed pairwise ranking test set, but they typically do not provide performance information on each preference dimension. In this work, we address the evaluation challenge of reward models by probing preference representations. To confirm the effectiveness of this evaluation method, we construct a Multi-dimensional Reward Model Benchmark (MRMBench), a collection of six probing tasks for different preference dimensions. We design it to favor and encourage reward models that better capture preferences across different dimensions. Furthermore, we introduce an analysis method, inference-time probing, which identifies the dimensions used during the reward prediction and enhances its interpretability. Through extensive experiments, we find that MRMBench strongly correlates with the alignment performance of large language models (LLMs), making it a reliable reference for developing advanced reward models. Our analysis of MRMBench evaluation results reveals that reward models often struggle to capture preferences across multiple dimensions, highlighting the potential of multi-objective optimization in reward modeling. Additionally, our findings show that the proposed inference-time probing method offers a reliable metric for assessing the confidence of reward predictions, which ultimately improves the alignment of LLMs.

</details>


### [33] [Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing](https://arxiv.org/abs/2511.12472)
*Mengying Wang,Chenhui Ma,Ao Jiao,Tuo Liang,Pengjun Lu,Shrinidhi Hegde,Yu Yin,Evren Gurkan-Cavusoglu,Yinghui Wu*

Main category: cs.CL

TL;DR: 提出SerenQA框架来评估LLM在科学知识图谱问答中发现意外洞察的能力，重点关注药物重定位任务中的相关性、新颖性和惊喜度。


<details>
  <summary>Details</summary>
Motivation: 现有KGQA系统通常返回高度相关但可预测的答案，缺乏发现惊喜和新型（"意外"）答案的能力。

Method: 提出SerenQA框架，包含基于相关性、新颖性和惊喜度的严格意外性指标，以及从临床知识图谱中提取的专家标注基准，专注于药物重定位。

Result: 实验表明，最先进的LLM在检索方面表现良好，但在识别真正令人惊讶和有价值的发现方面仍有困难。

Conclusion: 在发现真正令人惊讶和有价值的洞察方面仍有显著的改进空间，释放了精心策划的资源用于未来研究。

Abstract: Large Language Models (LLMs) have greatly advanced knowledge graph question answering (KGQA), yet existing systems are typically optimized for returning highly relevant but predictable answers. A missing yet desired capacity is to exploit LLMs to suggest surprise and novel ("serendipitious") answers. In this paper, we formally define the serendipity-aware KGQA task and propose the SerenQA framework to evaluate LLMs' ability to uncover unexpected insights in scientific KGQA tasks. SerenQA includes a rigorous serendipity metric based on relevance, novelty, and surprise, along with an expert-annotated benchmark derived from the Clinical Knowledge Graph, focused on drug repurposing. Additionally, it features a structured evaluation pipeline encompassing three subtasks: knowledge retrieval, subgraph reasoning, and serendipity exploration. Our experiments reveal that while state-of-the-art LLMs perform well on retrieval, they still struggle to identify genuinely surprising and valuable discoveries, underscoring a significant room for future improvements. Our curated resources and extended version are released at: https://cwru-db-group.github.io/serenQA.

</details>


### [34] [SGuard-v1: Safety Guardrail for Large Language Models](https://arxiv.org/abs/2511.12497)
*JoonHo Lee,HyeonMin Cho,Jaewoong Yun,Hyunjae Lee,JunKyu Lee,Juree Seok*

Main category: cs.CL

TL;DR: SGuard-v1是一个轻量级的大语言模型安全护栏系统，包含ContentFilter和JailbreakFilter两个专门模型，用于检测有害内容和筛选对抗性提示，支持12种语言，在保持轻量级的同时实现最先进的安全性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型在人类-AI对话设置中的安全风险，包括有害内容检测和对抗性提示攻击防护的需求。

Method: 基于2B参数的Granite-3.3-2B-Instruct模型，通过指令调优训练两个专门组件：ContentFilter用于识别安全风险，JailbreakFilter用于防御60种主要攻击类型，使用约140万训练实例。

Result: 在公共和专有安全基准测试中实现最先进的安全性能，同时保持轻量级部署，提供多类安全预测和二元置信度分数以提高可解释性。

Conclusion: SGuard-v1是一个有效的轻量级安全解决方案，通过Apache-2.0许可证发布，支持进一步研究和实际部署。

Abstract: We present SGuard-v1, a lightweight safety guardrail for Large Language Models (LLMs), which comprises two specialized models to detect harmful content and screen adversarial prompts in human-AI conversational settings. The first component, ContentFilter, is trained to identify safety risks in LLM prompts and responses in accordance with the MLCommons hazard taxonomy, a comprehensive framework for trust and safety assessment of AI. The second component, JailbreakFilter, is trained with a carefully designed curriculum over integrated datasets and findings from prior work on adversarial prompting, covering 60 major attack types while mitigating false-unsafe classification. SGuard-v1 is built on the 2B-parameter Granite-3.3-2B-Instruct model that supports 12 languages. We curate approximately 1.4 million training instances from both collected and synthesized data and perform instruction tuning on the base model, distributing the curated data across the two component according to their designated functions. Through extensive evaluation on public and proprietary safety benchmarks, SGuard-v1 achieves state-of-the-art safety performance while remaining lightweight, thereby reducing deployment overhead. SGuard-v1 also improves interpretability for downstream use by providing multi-class safety predictions and their binary confidence scores. We release the SGuard-v1 under the Apache-2.0 License to enable further research and practical deployment in AI safety.

</details>


### [35] [QA-Noun: Representing Nominal Semantics via Natural Language Question-Answer Pairs](https://arxiv.org/abs/2511.12504)
*Maria Tseytlin,Paul Roit,Omri Abend,Ido Dagan,Ayal Klein*

Main category: cs.CL

TL;DR: QA-Noun是一个基于问答的名词中心语义关系框架，通过9个问题模板捕捉名词的显式和隐式语义角色，与QA-SRL结合实现句子意义的细粒度分解。


<details>
  <summary>Details</summary>
Motivation: 现有的基于QA的语义方法主要关注谓词-论元关系，但忽视了名词中心的语义关系，需要补充名词语义表示框架。

Method: 定义9个问题模板覆盖名词的语法和上下文角色，构建超过2000个标注名词的数据集，并与QA-SRL集成形成统一语义分解框架。

Result: QA-Noun几乎完全覆盖AMR的名词论元，同时发现更多上下文隐含关系，与QA-SRL结合比FactScore和DecompScore等方法的粒度高出130%以上。

Conclusion: QA-Noun补充了基于QA的语义框架，形成了全面且可扩展的细粒度语义分解方法，适用于跨文本对齐任务。

Abstract: Decomposing sentences into fine-grained meaning units is increasingly used to model semantic alignment. While QA-based semantic approaches have shown effectiveness for representing predicate-argument relations, they have so far left noun-centered semantics largely unaddressed. We introduce QA-Noun, a QA-based framework for capturing noun-centered semantic relations. QA-Noun defines nine question templates that cover both explicit syntactical and implicit contextual roles for nouns, producing interpretable QA pairs that complement verbal QA-SRL. We release detailed guidelines, a dataset of over 2,000 annotated noun mentions, and a trained model integrated with QA-SRL to yield a unified decomposition of sentence meaning into individual, highly fine-grained, facts. Evaluation shows that QA-Noun achieves near-complete coverage of AMR's noun arguments while surfacing additional contextually implied relations, and that combining QA-Noun with QA-SRL yields over 130\% higher granularity than recent fact-based decomposition methods such as FactScore and DecompScore. QA-Noun thus complements the broader QA-based semantic framework, forming a comprehensive and scalable approach to fine-grained semantic decomposition for cross-text alignment.

</details>


### [36] [TAdaRAG: Task Adaptive Retrieval-Augmented Generation via On-the-Fly Knowledge Graph Construction](https://arxiv.org/abs/2511.12520)
*Jie Zhang,Bo Tang,Wanzi Shao,Wenqiang Wei,Jihao Zhao,Jianqing Zhu,Zhiyu li,Wen Xi,Zehao Lin,Feiyu Xiong,Yanchao Tan*

Main category: cs.CL

TL;DR: TAdaRAG是一个新颖的检索增强生成框架，通过任务自适应的知识图谱构建来解决传统RAG中信息截断和无关细节的问题，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法将外部知识截断成小块导致信息丢失，引发响应幻觉和推理链断裂，同时检索的非结构化知识包含无关细节，影响准确推理。

Method: 提出意图驱动的路由机制到领域特定提取模板，结合监督微调和基于强化学习的隐式提取机制，确保简洁、连贯且非冗余的知识整合。

Result: 在六个公共基准测试和一个真实业务基准(NowNewsQA)上，使用三个骨干模型进行评估，TAdaRAG在多个领域和长文本任务中优于现有方法。

Conclusion: TAdaRAG展示了强大的泛化能力和实际有效性，能够有效解决传统RAG的信息截断和无关细节问题。

Abstract: Retrieval-Augmented Generation (RAG) improves large language models by retrieving external knowledge, often truncated into smaller chunks due to the input context window, which leads to information loss, resulting in response hallucinations and broken reasoning chains. Moreover, traditional RAG retrieves unstructured knowledge, introducing irrelevant details that hinder accurate reasoning. To address these issues, we propose TAdaRAG, a novel RAG framework for on-the-fly task-adaptive knowledge graph construction from external sources. Specifically, we design an intent-driven routing mechanism to a domain-specific extraction template, followed by supervised fine-tuning and a reinforcement learning-based implicit extraction mechanism, ensuring concise, coherent, and non-redundant knowledge integration. Evaluations on six public benchmarks and a real-world business benchmark (NowNewsQA) across three backbone models demonstrate that TAdaRAG outperforms existing methods across diverse domains and long-text tasks, highlighting its strong generalization and practical effectiveness.

</details>


### [37] [Mitigating Length Bias in RLHF through a Causal Lens](https://arxiv.org/abs/2511.12573)
*Hyeonji Kim,Sujeong Oh,Sanghack Lee*

Main category: cs.CL

TL;DR: 提出一种因果框架来分析和缓解RLHF奖励模型中的长度偏差问题，通过反事实数据增强方法训练奖励模型，使其能够独立于冗长度评估内容质量。


<details>
  <summary>Details</summary>
Motivation: RLHF训练的奖励模型存在长度偏差，系统性地倾向于偏爱较长回答，将冗长度与质量混淆，这影响了模型输出的质量评估。

Method: 使用反事实数据增强方法，构建长度不同但内容相似的响应对，以及长度相似但内容不同的响应对，用这些数据训练奖励模型。

Result: 实证评估表明该方法减少了奖励分配中的长度偏差，使策略模型产生更简洁、内容聚焦的输出。

Conclusion: 所提出的方法有效减少了长度偏差，提高了RLHF流程中奖励建模的鲁棒性和内容敏感性。

Abstract: Reinforcement learning from human feedback (RLHF) is widely used to align large language models (LLMs) with human preferences. However, RLHF-trained reward models often exhibit length bias -- a systematic tendency to favor longer responses by conflating verbosity with quality. We propose a causal framework for analyzing and mitigating length bias in RLHF reward modeling. Central to our approach is a counterfactual data augmentation method that generates response pairs designed to isolate content quality from verbosity. These counterfactual examples are then used to train the reward model, enabling it to assess responses based on content quality independently of verbosity. Specifically, we construct (1) length-divergent pairs with similar content and (2) content-divergent pairs of similar length. Empirical evaluations show that our method reduces length bias in reward assignment and leads to more concise, content-focused outputs from the policy model. These findings demonstrate that the proposed approach effectively reduces length bias and improves the robustness and content sensitivity of reward modeling in RLHF pipelines.

</details>


### [38] [MMWOZ: Building Multimodal Agent for Task-oriented Dialogue](https://arxiv.org/abs/2511.12586)
*Pu-Hai Yang,Heyan Huang,Heng-Da Xu,Fanshu Sun,Xian-Ling Mao,Chaoxu Mu*

Main category: cs.CL

TL;DR: 提出了MMWOZ多模态对话数据集和MATE基线模型，旨在解决传统任务导向对话系统在现实GUI环境中的适用性问题


<details>
  <summary>Details</summary>
Motivation: 传统任务导向对话系统依赖定制后端API，而现实场景中广泛存在前端GUI且缺乏定制API，导致实际应用存在显著差距

Method: 1) 基于MultiWOZ 2.3扩展构建MMWOZ数据集，开发网页风格GUI；2) 设计自动化脚本将对话状态和系统动作转换为GUI操作指令；3) 收集网页快照和对应操作指令；4) 提出MATE多模态基线模型

Result: 成功构建了包含GUI操作的多模态对话数据集，并建立了相应的基线模型

Conclusion: MMWOZ数据集和MATE模型为构建实用的多模态任务导向对话系统提供了重要基础，弥合了传统系统与现实GUI环境之间的差距

Abstract: Task-oriented dialogue systems have garnered significant attention due to their conversational ability to accomplish goals, such as booking airline tickets for users. Traditionally, task-oriented dialogue systems are conceptualized as intelligent agents that interact with users using natural language and have access to customized back-end APIs. However, in real-world scenarios, the widespread presence of front-end Graphical User Interfaces (GUIs) and the absence of customized back-end APIs create a significant gap for traditional task-oriented dialogue systems in practical applications. In this paper, to bridge the gap, we collect MMWOZ, a new multimodal dialogue dataset that is extended from MultiWOZ 2.3 dataset. Specifically, we begin by developing a web-style GUI to serve as the front-end. Next, we devise an automated script to convert the dialogue states and system actions from the original dataset into operation instructions for the GUI. Lastly, we collect snapshots of the web pages along with their corresponding operation instructions. In addition, we propose a novel multimodal model called MATE (Multimodal Agent for Task-oriEnted dialogue) as the baseline model for the MMWOZ dataset. Furthermore, we conduct comprehensive experimental analysis using MATE to investigate the construction of a practical multimodal agent for task-oriented dialogue.

</details>


### [39] [Group-Aware Reinforcement Learning for Output Diversity in Large Language Models](https://arxiv.org/abs/2511.12596)
*Oron Anschel,Alon Shoshan,Adam Botach,Shunit Haviv Hakimi,Asaf Gendler,Emanuel Ben Baruch,Nadav Bhonker,Igor Kviatkovsky,Manoj Aggarwal,Gerard Medioni*

Main category: cs.CL

TL;DR: GAPO是一种基于GRPO的扩展方法，通过计算组级奖励来解决LLM的模式崩溃问题，提高生成响应的多样性而不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常出现模式崩溃，即使存在多个有效答案也重复生成相同的几个完成结果，这限制了在各种任务中的多样性。

Method: 引入组感知策略优化(GAPO)，作为GRPO的简单扩展，计算整个组的奖励，使模型能够从组级属性（如多样性和覆盖率）中学习。使用频率感知奖励函数鼓励对有效LLM完成结果的均匀采样。

Result: GAPO训练的模型产生有效且更多样化的响应，在开放提示下也能提高响应多样性，且在标准LLM基准测试（GSM8K、MATH、HumanEval、MMLU-Pro）上不损害准确性。

Conclusion: GAPO能够有效解决LLM的模式崩溃问题，提高生成响应的多样性，同时保持模型性能，具有很好的通用性。

Abstract: Large Language Models (LLMs) often suffer from mode collapse, repeatedly generating the same few completions even when many valid answers exist, limiting their diversity across a wide range of tasks. We introduce Group-Aware Policy Optimization (GAPO), a simple extension of the recent and popular Group Relative Policy Optimization (GRPO) that computes rewards over the group as a whole. GAPO enables learning from the group-level properties such as diversity and coverage. We demonstrate GAPO using a frequency-aware reward function that encourages uniform sampling over valid LLM completions, and show that GAPO-trained models produce valid and more diverse model responses. Beyond this setup, GAPO generalizes to open-ended prompts and improves response diversity without compromising accuracy on standard LLM benchmarks (GSM8K, MATH, HumanEval, MMLU-Pro). Our code will be made publicly available.

</details>


### [40] [Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data](https://arxiv.org/abs/2511.12609)
*Yunxin Li,Xinyu Chen,Shenyuan Jiang,Haoyuan Shi,Zhenyu Liu,Xuanyu Zhang,Nanhao Deng,Zhenran Xu,Yicheng Ma,Meishan Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: Uni-MoE 2.0是一个全开源的全模态大模型，基于Qwen2.5-7B架构构建，通过动态容量MoE设计、渐进式训练策略和精心策划的多模态数据匹配技术，在语言中心的多模态理解、推理和生成方面取得显著进展。


<details>
  <summary>Details</summary>
Motivation: 推动Lychee Uni-MoE系列在多模态能力上的发展，构建能够理解、推理和生成图像、文本、语音的全模态模型，解决现有模型在多模态对齐、训练稳定性和生成质量方面的挑战。

Method: 采用动态容量MoE框架，包含共享、路由和空专家；使用Omni-Modality 3D RoPE确保跨模态时空对齐；实施渐进式监督微调策略，结合平衡数据组合和迭代GSPO-DPO方法稳定强化学习训练。

Result: 在85个基准测试中表现优异，在76个基准中超过50个优于Qwen2.5-Omni（使用1.2T token训练），视频理解提升7%，全模态理解提升7%，视听推理提升4%，长语音处理WER降低4.2%，在低级图像处理和可控生成方面领先。

Conclusion: Uni-MoE 2.0通过创新的MoE架构和训练策略，在计算效率和能力之间取得平衡，实现了全模态理解、推理和生成的SOTA性能，证明了动态专家模型在多模态任务中的有效性。

Abstract: We present Uni-MoE 2.0 from the Lychee family. As a fully open-source omnimodal large model (OLM), it substantially advances Lychee's Uni-MoE series in language-centric multimodal understanding, reasoning, and generating. Based on the Qwen2.5-7B dense architecture, we build Uni-MoE-2.0-Omni from scratch through three core contributions: dynamic-capacity Mixture-of-Experts (MoE) design, a progressive training strategy enhanced with an iterative reinforcement strategy, and a carefully curated multimodal data matching technique. It is capable of omnimodal understanding, as well as generating images, text, and speech. Architecturally, our new MoE framework balances computational efficiency and capability for 10 cross-modal inputs using shared, routed, and null experts, while our Omni-Modality 3D RoPE ensures spatio-temporal cross-modality alignment in the self-attention layer. For training, following cross-modal pretraining, we use a progressive supervised fine-tuning strategy that activates modality-specific experts and is enhanced by balanced data composition and an iterative GSPO-DPO method to stabilise RL training and improve reasoning. Data-wise, the base model, trained on approximately 75B tokens of open-source multimodal data, is equipped with special speech and image generation tokens, allowing it to learn these generative tasks by conditioning its outputs on linguistic cues. Extensive evaluation across 85 benchmarks demonstrates that our model achieves SOTA or highly competitive performance against leading OLMs, surpassing Qwen2.5-Omni (trained with 1.2T tokens) on over 50 of 76 benchmarks. Key strengths include video understanding (+7% avg. of 8), omnimodallity understanding (+7% avg. of 4), and audiovisual reasoning (+4%). It also advances long-form speech processing (reducing WER by 4.2%) and leads in low-level image processing and controllable generation across 5 metrics.

</details>


### [41] [Knots: A Large-Scale Multi-Agent Enhanced Expert-Annotated Dataset and LLM Prompt Optimization for NOTAM Semantic Parsing](https://arxiv.org/abs/2511.12630)
*Maoqi Liu,Quan Fang,Yang Yang,Can Zhao,Kaiquan Cai*

Main category: cs.CL

TL;DR: 提出了NOTAM语义解析任务，构建了Knots数据集，通过多智能体协作框架增强标注质量，系统评估了多种提示工程和模型适应技术，显著提升了航空文本理解能力。


<details>
  <summary>Details</summary>
Motivation: NOTAMs作为关键飞行安全信息渠道，其复杂语言结构和隐含推理给自动解析带来挑战。现有研究主要关注分类和命名实体识别等表层任务，缺乏深度语义理解。

Method: 提出NOTAM语义解析任务，构建包含12,347条专家标注NOTAMs的Knots数据集，覆盖194个飞行情报区，采用多智能体协作框架进行全面的字段发现。

Result: 系统评估了广泛的提示工程策略和模型适应技术，在航空文本理解和处理方面取得了显著改进。实验结果表明所提方法的有效性。

Conclusion: 该研究为自动NOTAM分析系统提供了有价值的见解，证明了语义解析方法在航空领域文本处理中的有效性。

Abstract: Notice to Air Missions (NOTAMs) serve as a critical channel for disseminating key flight safety information, yet their complex linguistic structures and implicit reasoning pose significant challenges for automated parsing. Existing research mainly focuses on surface-level tasks such as classification and named entity recognition, lacking deep semantic understanding. To address this gap, we propose NOTAM semantic parsing, a task emphasizing semantic inference and the integration of aviation domain knowledge to produce structured, inference-rich outputs. To support this task, we construct Knots (Knowledge and NOTAM Semantics), a high-quality dataset of 12,347 expert-annotated NOTAMs covering 194 Flight Information Regions, enhanced through a multi-agent collaborative framework for comprehensive field discovery. We systematically evaluate a wide range of prompt-engineering strategies and model-adaptation techniques, achieving substantial improvements in aviation text understanding and processing. Our experimental results demonstrate the effectiveness of the proposed approach and offer valuable insights for automated NOTAM analysis systems. Our code is available at: https://github.com/Estrellajer/Knots.

</details>


### [42] [Reason-KE++: Aligning the Process, Not Just the Outcome, for Faithful LLM Knowledge Editing](https://arxiv.org/abs/2511.12661)
*Yuchen Wu,Liang Ding,Li Shen,Dacheng Tao*

Main category: cs.CL

TL;DR: Reason-KE++是一个SFT+RL框架，通过过程级忠实度对齐来解决LLM在复杂多跳推理任务中的事实幻觉问题，在MQUAKE-CF-3k上达到95.48%的新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有SFT方法（如Reason-KE）存在"忠实度差距"：它们优化格式模仿而非可靠推理，导致LLM的参数先验覆盖上下文事实，产生关键事实幻觉。

Method: 提出Reason-KE++框架，核心是阶段感知奖励机制，为中间推理步骤（如分解、子答案正确性）提供密集监督，避免天真结果导向RL的陷阱。

Result: 在MQUAKE-CF-3k上达到95.48%的准确率（提升+5.28%），而仅关注结果的RL方法会损害推理完整性（Hop准确率仅19.00%）。

Conclusion: 对于复杂任务，对齐推理过程对于构建可信赖的LLM至关重要，过程感知框架能有效解决核心的LLM对齐问题。

Abstract: Aligning Large Language Models (LLMs) to be faithful to new knowledge in complex, multi-hop reasoning tasks is a critical, yet unsolved, challenge. We find that SFT-based methods, e.g., Reason-KE, while state-of-the-art, suffer from a "faithfulness gap": they optimize for format mimicry rather than sound reasoning. This gap enables the LLM's powerful parametric priors to override new contextual facts, resulting in critical factual hallucinations (e.g., incorrectly reasoning "Houston" from "NASA" despite an explicit edit). To solve this core LLM alignment problem, we propose Reason-KE++, an SFT+RL framework that instills process-level faithfulness. Its core is a Stage-aware Reward mechanism that provides dense supervision for intermediate reasoning steps (e.g., Decomposition, Sub-answer Correctness). Crucially, we identify that naive outcome-only RL is a deceptive trap for LLM alignment: it collapses reasoning integrity (e.g., 19.00% Hop acc) while superficially boosting final accuracy. Our process-aware framework sets a new SOTA of 95.48% on MQUAKE-CF-3k (+5.28%), demonstrating that for complex tasks, aligning the reasoning process is essential for building trustworthy LLMs.

</details>


### [43] [Improving Direct Persian-English Speech-to-Speech Translation with Discrete Units and Synthetic Parallel Data](https://arxiv.org/abs/2511.12690)
*Sina Rashidi,Hossein Sameti*

Main category: cs.CL

TL;DR: 本文提出了一种用于波斯语到英语语音翻译的直接语音到语音翻译系统，通过自监督预训练、离散语音单元和合成并行数据来解决低资源语言对的训练数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 直接语音到语音翻译系统需要大量并行语音数据，但对于波斯语等低资源语言来说，这类数据非常稀缺，因此需要开发有效的方法来缓解数据不足问题。

Method: 系统包含三个组件：基于conformer的编码器、因果transformer解码器和基于单元的神经声码器。通过使用大语言模型翻译波斯语语音转录，并结合零样本文本到语音系统合成英语语音，构建了合成并行语料库。

Result: 在CVSS语料库的波斯语-英语部分，使用合成数据的模型相比直接基线在ASR BLEU指标上提升了4.6分，可用并行语音数据量增加了约6倍。

Conclusion: 结合自监督预训练、离散语音单元和合成并行数据的方法对于改善波斯语-英语等低资源语言对的直接语音到语音翻译是有效的。

Abstract: Direct speech-to-speech translation (S2ST), in which all components are trained jointly, is an attractive alternative to cascaded systems because it offers a simpler pipeline and lower inference latency. However, direct S2ST models require large amounts of parallel speech data in the source and target languages, which are rarely available for low-resource languages such as Persian. This paper presents a direct S2ST system for translating Persian speech into English speech, as well as a pipeline for synthetic parallel Persian-English speech generation. The model comprises three components: (1) a conformer-based encoder, initialized from self-supervised pre-training, maps source speech to high-level acoustic representations; (2) a causal transformer decoder with relative position multi-head attention translates these representations into discrete target speech units; (3) a unit-based neural vocoder generates waveforms from the predicted discrete units. To mitigate the data scarcity problem, we construct a new Persian-English parallel speech corpus by translating Persian speech transcriptions into English using a large language model and then synthesizing the corresponding English speech with a state-of-the-art zero-shot text-to-speech system. The resulting corpus increases the amount of available parallel speech by roughly a factor of six. On the Persian-English portion of the CVSS corpus, the proposed model achieves improvement of 4.6 ASR BLEU with the synthetic data over direct baselines. These results indicate that combining self-supervised pre-training, discrete speech units, and synthetic parallel data is effective for improving direct S2ST in low-resource language pairs such as Persian-English

</details>


### [44] [Evolve the Method, Not the Prompts: Evolutionary Synthesis of Jailbreak Attacks on LLMs](https://arxiv.org/abs/2511.12710)
*Yunhao Chen,Xin Wang,Juncheng Li,Yixu Wang,Jie Li,Yan Teng,Yingchun Wang,Xingjun Ma*

Main category: cs.CL

TL;DR: EvoSynth是一个自主的进化合成框架，通过多智能体系统自主设计、进化和执行基于代码的新型攻击算法，突破了现有自动化红队框架只能选择、组合或改进现有攻击策略的限制。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型自动化红队框架存在根本性限制：其越狱逻辑仅限于选择、组合或改进现有的攻击策略，这限制了其创造力，无法自主发明全新的攻击机制。

Method: 采用多智能体系统自主设计、进化和执行基于代码的攻击算法，并包含代码级自校正循环，能够根据失败情况迭代重写自身攻击逻辑。

Result: 在对抗高度鲁棒的模型（如Claude-Sonnet-4.5）时实现了85.5%的攻击成功率，并生成了比现有方法更多样化的攻击。

Conclusion: EvoSynth通过将范式从攻击规划转向进化合成，建立了新的最先进水平，为越狱方法的进化合成研究开辟了新方向。

Abstract: Automated red teaming frameworks for Large Language Models (LLMs) have become increasingly sophisticated, yet they share a fundamental limitation: their jailbreak logic is confined to selecting, combining, or refining pre-existing attack strategies. This binds their creativity and leaves them unable to autonomously invent entirely new attack mechanisms. To overcome this gap, we introduce \textbf{EvoSynth}, an autonomous framework that shifts the paradigm from attack planning to the evolutionary synthesis of jailbreak methods. Instead of refining prompts, EvoSynth employs a multi-agent system to autonomously engineer, evolve, and execute novel, code-based attack algorithms. Crucially, it features a code-level self-correction loop, allowing it to iteratively rewrite its own attack logic in response to failure. Through extensive experiments, we demonstrate that EvoSynth not only establishes a new state-of-the-art by achieving an 85.5\% Attack Success Rate (ASR) against highly robust models like Claude-Sonnet-4.5, but also generates attacks that are significantly more diverse than those from existing methods. We release our framework to facilitate future research in this new direction of evolutionary synthesis of jailbreak methods. Code is available at: https://github.com/dongdongunique/EvoSynth.

</details>


### [45] [Adaptive Focus Memory for Language Models](https://arxiv.org/abs/2511.12712)
*Christopher Cruz*

Main category: cs.CL

TL;DR: AFM是一种动态上下文管理器，通过语义相似度、时间衰减和重要性分类为历史消息分配三种保真度级别，在保持安全性能的同时将平均token使用量减少66%。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在多轮对话中固定上下文窗口和简单内存策略的瓶颈问题，避免静态摘要或仅关注最近消息导致安全关键信息丢失。

Method: AFM基于语义相似度、半衰期时间衰减权重和重要性分类，为每个历史消息分配FULL、COMPRESSED或PLACEHOLDER保真度级别，在严格token预算下按时间顺序打包消息。

Result: 在涉及花生过敏用户规划泰国旅行的安全导向基准测试中，AFM在短中长度对话中都能保留过敏信息，安全性能与简单重放相当，平均token使用量比基线减少66%。

Conclusion: AFM提供模块化Python实现，可在不牺牲安全性或事实连续性的情况下显著降低推理成本。

Abstract: Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, but their behavior is still bottlenecked by fixed context windows and naive memory strategies. Replaying the full conversation at every turn is simple but expensive, while static summarization or recency-only heuristics often erase safety-critical user details. We present Adaptive Focus Memory (AFM), a dynamic context manager that assigns each past message one of three fidelity levels -- FULL, COMPRESSED, or PLACEHOLDER -- based on semantic similarity to the current query, half-life recency weighting, and importance classification. AFM packs messages chronologically under a strict token budget, preferring high fidelity for the most relevant turns while aiming to preserve a cheap trace of the dialogue. In a safety-oriented benchmark involving a user with a severe peanut allergy planning a trip to Thailand, AFM retains the allergy across both short and medium-length conversations, matches the safety performance of naive replay, and cuts average token usage by 66% relative to a replay baseline. We release a modular Python implementation of AFM designed for OpenAI-compatible APIs and offline operation, enabling practitioners to reduce inference cost without sacrificing safety or factual continuity in the evaluated scenario.

</details>


### [46] [On the Brittleness of LLMs: A Journey around Set Membership](https://arxiv.org/abs/2511.12728)
*Lea Hergert,Gábor Berend,Mario Szegedy,Gyorgy Turan,Márk Jelasity*

Main category: cs.CL

TL;DR: LLMs在复杂推理任务中表现超人类，但在简单集合成员查询任务中却频繁失败，揭示了其推理能力的脆弱性和不可预测性。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在简单推理任务中的失败模式，以揭示其可靠性和可解释性的局限，通过简单任务实现大规模可控实验。

Method: 使用集合成员查询任务，系统评估提示措辞、语义结构、元素排序和模型选择等多个维度，进行大规模实证分析。

Result: LLMs在这一基本任务上的表现始终脆弱且不可预测，表明模型对集合概念的理解是碎片化和复杂的。

Conclusion: 通过简单问题实现的大规模实验能够全面映射和分析失败模式，这种方法对LLM评估具有普遍价值。

Abstract: Large language models (LLMs) achieve superhuman performance on complex reasoning tasks, yet often fail on much simpler problems, raising concerns about their reliability and interpretability. We investigate this paradox through a focused study with two key design features: simplicity, to expose basic failure modes, and scale, to enable comprehensive controlled experiments. We focus on set membership queries -- among the most fundamental forms of reasoning -- using tasks like ``Is apple an element of the set \{pear, plum, apple, raspberry\}?''. We conduct a systematic empirical evaluation across prompt phrasing, semantic structure, element ordering, and model choice. Our large-scale analysis reveals that LLM performance on this elementary task is consistently brittle, and unpredictable across all dimensions, suggesting that the models' ``understanding'' of the set concept is fragmented and convoluted at best. Our work demonstrates that the large-scale experiments enabled by the simplicity of the problem allow us to map and analyze the failure modes comprehensively, making this approach a valuable methodology for LLM evaluation in general.

</details>


### [47] [Evidence of Phase Transitions in Small Transformer-Based Language Models](https://arxiv.org/abs/2511.12768)
*Noah Hong,Tao Hong*

Main category: cs.CL

TL;DR: 研究发现语言模型训练中存在相变现象，即使在小规模transformer模型中也能观察到，这种相变在早期训练阶段出现，可通过词汇统计方法在原始训练空间中直接检测。


<details>
  <summary>Details</summary>
Motivation: 探索相变现象是否仅限于大型语言模型，能否在小模型中观察到，以及是否能在原始训练空间而非对数缩放后检测到这些相变。

Method: 训练小型GPT风格transformer模型，分析词汇使用演变，包括平均词长、正确与错误词汇数量、词汇多样性变化，并应用泊松和亚泊松统计量化词汇连接和重组。

Result: 在训练过程中发现明显的相变点，这些相变在标准损失或验证曲线中不明显，但通过词汇和统计方法变得可见。

Conclusion: 相变重组是语言模型训练的普遍特征，可在适度模型中观察到，在原始训练空间中直接检测，并在连贯性出现的早期阶段发生。

Abstract: Phase transitions have been proposed as the origin of emergent abilities in large language models (LLMs), where new capabilities appear abruptly once models surpass critical thresholds of scale. Prior work, such as that of Wei et al., demonstrated these phenomena under model and data scaling, with transitions revealed after applying a log scale to training compute. In this work, we ask three complementary questions: (1) Are phase transitions unique to large models, or can they also be observed in small transformer-based language models? (2) Can such transitions be detected directly in linear training space, rather than only after log rescaling? and (3) Can these transitions emerge at early stages of training? To investigate, we train a small GPT-style transformer on a character-level corpus and analyze the evolution of vocabulary usage throughout training. We track the average word length, the number of correct versus incorrect words, and shifts in vocabulary diversity. Building on these measures, we apply Poisson and sub-Poisson statistics to quantify how words connect and reorganize. This combined analysis reveals a distinct transition point during training. Notably, these transitions are not apparent in standard loss or validation curves, but become visible through our vocabulary- and statistics-based probes. Our findings suggest that phase-transition reorganizations are a general feature of language model training, observable even in modest models, detectable directly in linear training space, and occurring surprisingly early as coherence emerges. This perspective provides new insight into the nonlinear dynamics of language model training and underscores the importance of tailored metrics for uncovering phase transition behaviors

</details>


### [48] [LLM Reinforcement in Context](https://arxiv.org/abs/2511.12782)
*Thomas Rivasseau*

Main category: cs.CL

TL;DR: 提出使用中断机制作为增强大语言模型对齐性的方法，通过在用户输入中定期插入控制语句来防止越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐研究主要关注通过训练和提示来提高模型鲁棒性，但缺乏随用户输入长度扩展的对齐方法。研究发现LLM越狱概率随用户输入或对话长度增加而上升。

Method: 提出中断机制：在用户输入中每隔x个token插入控制语句，并可将此方法推广到思维链过程中以防止策略性行为。

Result: 该方法尚未在论文中报告具体实验结果，但提出了理论框架和概念验证。

Conclusion: 中断机制是一种有前景的解决方案，能够随用户输入长度扩展地增强LLM对齐性，防止越狱攻击和策略性行为。

Abstract: Current Large Language Model alignment research mostly focuses on improving model robustness against adversarial attacks and misbehavior by training on examples and prompting. Research has shown that LLM jailbreak probability increases with the size of the user input or conversation length. There is a lack of appropriate research into means of strengthening alignment which also scale with user input length. We propose interruptions as a possible solution to this problem. Interruptions are control sentences added to the user input approximately every x tokens for some arbitrary x. We suggest that this can be generalized to the Chain-of-Thought process to prevent scheming.

</details>


### [49] [Evaluating Autoformalization Robustness via Semantically Similar Paraphrasing](https://arxiv.org/abs/2511.12784)
*Hayden Moore,Asfahan Shah*

Main category: cs.CL

TL;DR: 评估大型语言模型在自动形式化任务中对语义相似但表达不同的自然语言输入的鲁棒性，发现模型输出对自然语言表述的微小变化敏感。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在自动形式化方面表现出色，但现有研究表明它们在文本到SQL任务中对语义保持的改写输入敏感。本文旨在验证这种敏感性是否也存在于自动形式化领域。

Method: 使用MiniF2F和ProofNet的Lean 4版本作为形式化基准，生成语义相似的改写自然语言陈述，并在两个现代LLMs上进行交叉评估，测量语义和编译有效性。

Result: 结果显示模型在改写输入上的性能存在变异性，自然语言陈述的微小变化会显著影响模型输出。

Conclusion: LLMs在自动形式化任务中对自然语言表述的变化敏感，这揭示了模型鲁棒性的局限性。

Abstract: Large Language Models (LLMs) have recently emerged as powerful tools for autoformalization. Despite their impressive performance, these models can still struggle to produce grounded and verifiable formalizations. Recent work in text-to-SQL, has revealed that LLMs can be sensitive to paraphrased natural language (NL) inputs, even when high degrees of semantic fidelity are preserved (Safarzadeh, Oroojlooyjadid, and Roth 2025). In this paper, we investigate this claim in the autoformalization domain. Specifically, we evaluate the robustness of LLMs generating formal proofs with semantically similar paraphrased NL statements by measuring semantic and compilation validity. Using the formal benchmarks MiniF2F (Zheng, Han, and Polu 2021) and Lean 4 version of ProofNet (Xin et al. 2024), and two modern LLMs, we generate paraphrased natural language statements and cross-evaluate these statements across both models. The results of this paper reveal performance variability across paraphrased inputs, demonstrating that minor shifts in NL statements can significantly impact model outputs.

</details>


### [50] [BioMedJImpact: A Comprehensive Dataset and LLM Pipeline for AI Engagement and Scientific Impact Analysis of Biomedical Journals](https://arxiv.org/abs/2511.12821)
*Ruiyu Wang,Yuzhang Xie,Xiao Hu,Carl Yang,Jiaying Lu*

Main category: cs.CL

TL;DR: BioMedJImpact是一个大规模生物医学期刊影响数据集，整合了文献计量指标、合作特征和基于LLM的AI参与度指标，用于分析合作强度和AI参与度如何共同影响科学影响力。


<details>
  <summary>Details</summary>
Motivation: 现有开放资源很少捕捉合作结构和AI研究如何共同塑造生物医学期刊声望，需要开发一个综合数据集来推进期刊层面的科学影响力和AI参与度分析。

Method: 从PubMed Central的174万篇文章构建数据集，整合文献计量指标、合作特征，并通过可复现的三阶段LLM流程提取AI参与度特征。

Result: 发现两个一致趋势：合作强度更高的期刊（特别是作者团队更大更多样化的）获得更高引用影响力；AI参与度日益成为期刊声望的强相关因素，尤其在四分位排名中。

Conclusion: BioMedJImpact既是捕捉生物医学与AI交叉的综合数据集，也是经过验证的方法框架，支持可扩展、内容感知的科学计量分析。

Abstract: Assessing journal impact is central to scholarly communication, yet existing open resources rarely capture how collaboration structures and artificial intelligence (AI) research jointly shape venue prestige in biomedicine. We present BioMedJImpact, a large-scale, biomedical-oriented dataset designed to advance journal-level analysis of scientific impact and AI engagement. Built from 1.74 million PubMed Central articles across 2,744 journals, BioMedJImpact integrates bibliometric indicators, collaboration features, and LLM-derived semantic indicators for AI engagement. Specifically, the AI engagement feature is extracted through a reproducible three-stage LLM pipeline that we propose. Using this dataset, we analyze how collaboration intensity and AI engagement jointly influence scientific impact across pre- and post-pandemic periods (2016-2019, 2020-2023). Two consistent trends emerge: journals with higher collaboration intensity, particularly those with larger and more diverse author teams, tend to achieve greater citation impact, and AI engagement has become an increasingly strong correlate of journal prestige, especially in quartile rankings. To further validate the three-stage LLM pipeline we proposed for deriving the AI engagement feature, we conduct human evaluation, confirming substantial agreement in AI relevance detection and consistent subfield classification. Together, these contributions demonstrate that BioMedJImpact serves as both a comprehensive dataset capturing the intersection of biomedicine and AI, and a validated methodological framework enabling scalable, content-aware scientometric analysis of scientific impact and innovation dynamics. Code is available at https://github.com/JonathanWry/BioMedJImpact.

</details>


### [51] [From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation](https://arxiv.org/abs/2511.12832)
*Niranjan Chebrolu,Gerard Christopher Yeo,Kokil Jaidka*

Main category: cs.CL

TL;DR: 通过目标激活工程引导LLaMA 3.1-8B展现更人性化的情感表达，使用归因修补识别关键干预位点，从对比文本对推导情感表达向量，显著增强情感特征。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然对话流畅度不断提升，但赋予其细腻、人性化的情感表达仍面临挑战。现有对齐技术往往只处理表面输出或需要大量微调。

Method: 采用归因修补识别因果影响组件，通过观察诊断对话任务中的激活模式找到关键干预位点；从对比文本对（积极vs消极情感示例）的激活差异推导情感表达向量。

Result: 将情感向量应用于新对话提示显著增强了情感特征：引导后的响应显示出更高的积极情感（如喜悦、信任）和更频繁的第一人称代词使用，表明更强的个人参与度。

Conclusion: 研究提供了一个精确且可解释的框架，为对话AI研究开辟了新方向。

Abstract: Large Language Models (LLMs) demonstrate increasing conversational fluency, yet instilling them with nuanced, human-like emotional expression remains a significant challenge. Current alignment techniques often address surface-level output or require extensive fine-tuning. This paper demonstrates that targeted activation engineering can steer LLaMA 3.1-8B to exhibit more human-like emotional nuances. We first employ attribution patching to identify causally influential components, to find a key intervention locus by observing activation patterns during diagnostic conversational tasks. We then derive emotional expression vectors from the difference in the activations generated by contrastive text pairs (positive vs. negative examples of target emotions). Applying these vectors to new conversational prompts significantly enhances emotional characteristics: steered responses show increased positive sentiment (e.g., joy, trust) and more frequent first-person pronoun usage, indicative of greater personal engagement. Our findings offer a precise and interpretable framework and new directions for the study of conversational AI.

</details>


### [52] [Quantifying consistency and accuracy of Latent Dirichlet Allocation](https://arxiv.org/abs/2511.12850)
*Saranzaya Magsarjav,Melissa Humphries,Jonathan Tuke,Lewis Mitchell*

Main category: cs.CL

TL;DR: 本文提出了一种新的稳定性度量方法来解决概率主题模型因随机性导致结果不一致的问题，通过生成具有真实主题的语料库来评估LDA模型的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 概率主题模型由于随机性在重复运行时会产生不同的结果，这种不稳定性影响了模型的可重复性、可靠性和解释性，引发了对主题模型是否真正捕捉到有意义主题的质疑。

Method: 定义了一个结合准确性和一致性的新稳定性度量，利用LDA的生成特性生成具有真实主题的语料库，并对这些语料库运行LDA 50次以评估输出变异性。

Result: 研究发现LDA能够正确确定文档中的基础主题数量，多次重复运行返回相似主题，表明LDA具有较好的内部一致性，但这些主题并非真实主题。

Conclusion: LDA在确定主题数量方面表现准确且具有内部一致性，但生成的主题与真实主题存在差异，这凸显了需要更好的稳定性评估方法来确保主题模型的可信度。

Abstract: Topic modelling in Natural Language Processing uncovers hidden topics in large, unlabelled text datasets. It is widely applied in fields such as information retrieval, content summarisation, and trend analysis across various disciplines. However, probabilistic topic models can produce different results when rerun due to their stochastic nature, leading to inconsistencies in latent topics. Factors like corpus shuffling, rare text removal, and document elimination contribute to these variations. This instability affects replicability, reliability, and interpretation, raising concerns about whether topic models capture meaningful topics or just noise. To address these problems, we defined a new stability measure that incorporates accuracy and consistency and uses the generative properties of LDA to generate a new corpus with ground truth. These generated corpora are run through LDA 50 times to determine the variability in the output. We show that LDA can correctly determine the underlying number of topics in the documents. We also find that LDA is more internally consistent, as the multiple reruns return similar topics; however, these topics are not the true topics.

</details>


### [53] [NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation](https://arxiv.org/abs/2511.12851)
*Kang Yin,Hye-Bin Shin*

Main category: cs.CL

TL;DR: NeuroLex是一个专门针对临床脑电图报告的轻量级领域自适应语言模型，在EEG报告文本上训练，能更好地理解EEG报告的语言特征和诊断模式。


<details>
  <summary>Details</summary>
Motivation: 通用语言模型无法充分捕捉临床EEG报告中领域特定的语言惯例，需要专门针对EEG报告语言特征进行优化的模型。

Method: 使用跨度损坏预训练和指令式微调（包括报告润色、段落摘要和术语问答），在哈佛EEG数据库的EEG报告文本上训练。

Result: 与同等规模的通用模型相比，NeuroLex实现了更低的困惑度、更高的提取和摘要准确性、更好的标签效率，以及对否定和事实幻觉的更强鲁棒性。

Conclusion: NeuroLex通过EEG感知的语言骨干网络，连接了生物医学文本建模和脑机接口应用，为可解释和语言驱动的神经解码提供了基础。

Abstract: Clinical electroencephalogram (EEG) reports encode domain-specific linguistic conventions that general-purpose language models (LMs) fail to capture. We introduce NeuroLex, a lightweight domain-adaptive language model trained purely on EEG report text from the Harvard Electroencephalography Database. Unlike existing biomedical LMs, NeuroLex is tailored to the linguistic and diagnostic characteristics of EEG reporting, enabling it to serve as both an independent textual model and a decoder backbone for multimodal EEG-language systems. Using span-corruption pretraining and instruction-style fine-tuning on report polishing, paragraph summarization, and terminology question answering, NeuroLex learns the syntax and reasoning patterns characteristic of EEG interpretation. Comprehensive evaluations show that it achieves lower perplexity, higher extraction and summarization accuracy, better label efficiency, and improved robustness to negation and factual hallucination compared with general models of the same scale. With an EEG-aware linguistic backbone, NeuroLex bridges biomedical text modeling and brain-computer interface applications, offering a foundation for interpretable and language-driven neural decoding.

</details>


### [54] [From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models](https://arxiv.org/abs/2511.12861)
*Wenxin Zhu,Andong Chen,Yuchen Song,Kehai Chen,Conghui Zhu,Ziyan Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: 本文系统综述了多模态思维链（MCoT）技术，分析了其背景动机、主流方法、评估指标、应用场景，并讨论了当前挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在感知任务中的显著成功，提升其复杂推理能力成为关键研究方向。现有模型存在推理路径不透明和泛化能力不足等问题，而思维链推理在语言模型中已证明能增强推理透明度和输出可解释性，有望在扩展到多模态领域后改善模型推理能力。

Method: 从三个方面介绍主流MCoT方法：思维链范式、后训练阶段和推理阶段，并分析其底层机制。

Result: 总结了现有的评估基准和指标，讨论了MCoT的应用场景。

Conclusion: 分析了MCoT当前面临的挑战，并对其未来研究方向进行了展望。

Abstract: With the remarkable success of Multimodal Large Language Models (MLLMs) in perception tasks, enhancing their complex reasoning capabilities has emerged as a critical research focus. Existing models still suffer from challenges such as opaque reasoning paths and insufficient generalization ability. Chain-of-Thought (CoT) reasoning, which has demonstrated significant efficacy in language models by enhancing reasoning transparency and output interpretability, holds promise for improving model reasoning capabilities when extended to the multimodal domain. This paper provides a systematic review centered on "Multimodal Chain-of-Thought" (MCoT). First, it analyzes the background and theoretical motivations for its inception from the perspectives of technical evolution and task demands. Then, it introduces mainstream MCoT methods from three aspects: CoT paradigms, the post-training stage, and the inference stage, while also analyzing their underlying mechanisms. Furthermore, the paper summarizes existing evaluation benchmarks and metrics, and discusses the application scenarios of MCoT. Finally, it analyzes the challenges currently facing MCoT and provides an outlook on its future research directions.

</details>


### [55] [Classification of Hope in Textual Data using Transformer-Based Models](https://arxiv.org/abs/2511.12874)
*Chukwuebuka Fortunate Ijezue,Tania-Amanda Fredrick Eneye,Maaz Amjad*

Main category: cs.CL

TL;DR: 本文比较了三种基于Transformer的架构（BERT、GPT-2、DeBERTa）在希望表达文本分类任务中的表现，发现BERT在准确性和计算效率方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 开发一个计算框架来分析文本中的希望表达，应用于心理健康和社交媒体分析领域。

Method: 使用BERT、GPT-2和DeBERTa三种Transformer架构进行二元分类（希望vs非希望）和多类分类（五个希望相关类别）的比较研究。

Result: BERT在二元分类中达到84.49%准确率，多类分类中达到72.03%准确率，且计算效率最高（443秒训练时间）。GPT-2表现最差（79.34%二元，71.29%多类），DeBERTa表现中等但计算成本最高（947秒多类训练）。

Conclusion: 对于专业化的情感检测任务，架构的适用性可能比模型规模更重要，BERT在希望表达分类中表现出最佳平衡。

Abstract: This paper presents a transformer-based approach for classifying hope expressions in text. We developed and compared three architectures (BERT, GPT-2, and DeBERTa) for both binary classification (Hope vs. Not Hope) and multiclass categorization (five hope-related categories). Our initial BERT implementation achieved 83.65% binary and 74.87% multiclass accuracy. In the extended comparison, BERT demonstrated superior performance (84.49% binary, 72.03% multiclass accuracy) while requiring significantly fewer computational resources (443s vs. 704s training time) than newer architectures. GPT-2 showed lowest overall accuracy (79.34% binary, 71.29% multiclass), while DeBERTa achieved moderate results (80.70% binary, 71.56% multiclass) but at substantially higher computational cost (947s for multiclass training). Error analysis revealed architecture-specific strengths in detecting nuanced hope expressions, with GPT-2 excelling at sarcasm detection (92.46% recall). This study provides a framework for computational analysis of hope, with applications in mental health and social media analysis, while demonstrating that architectural suitability may outweigh model size for specialized emotion detection tasks.

</details>


### [56] [Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy](https://arxiv.org/abs/2511.12920)
*Desheng Hu,Joachim Baumann,Aleksandra Urman,Elsa Lichtenegger,Robin Forsberg,Aniko Hannak,Christo Wilson*

Main category: cs.CL

TL;DR: 通过系统算法审计评估Google搜索中AI生成内容（AI概览和精选摘要）的质量，发现在婴儿护理和孕期相关查询中存在信息不一致、医疗安全措施缺失等问题。


<details>
  <summary>Details</summary>
Motivation: Google搜索越来越多地通过AI概览和精选摘要展示AI生成内容，用户依赖这些信息但无法控制其呈现方式，需要评估这些信息显示的质量和一致性。

Method: 对1,508个真实的婴儿护理和孕期相关查询进行系统算法审计，使用稳健的评估框架评估答案一致性、相关性、医疗安全措施存在性、来源类别和情感对齐等多个质量维度。

Result: AI概览和精选摘要之间存在33%的信息不一致；医疗安全措施严重缺失（AI概览仅11%，精选摘要仅7%）；健康网站是主要来源，但精选摘要也常链接商业来源。

Conclusion: 这些发现对公共卫生信息获取有重要影响，表明在AI介导的健康信息中需要更强的质量控制。该方法为审计高风险领域的AI系统提供了可转移的框架。

Abstract: Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.

</details>


### [57] [Visual Room 2.0: Seeing is Not Understanding for MLLMs](https://arxiv.org/abs/2511.12928)
*Haokun Li,Yazhou Zhang,Jizhi Ding,Qiuchi Li,Peng Zhang*

Main category: cs.CL

TL;DR: 该论文提出了视觉房间论证，认为多模态大语言模型可能精确描述视觉细节但无法理解底层情感和意图，即"看到不等于理解"。作者构建了Visual Room 2.0基准来评估MLLMs的感知-认知对齐，涵盖17个任务和2,100个问题。


<details>
  <summary>Details</summary>
Motivation: 扩展Searle的中文房间论证到多模态领域，质疑MLLMs是否真正理解所见内容。作者认为模型可能准确描述视觉细节但缺乏对情感和意图的理解能力。

Method: 构建了Visual Room 2.0基准，模拟人类感知和认知过程的三个层次（低、中、高），包含17个代表性任务。数据集包含350个多模态样本，每个样本有6个渐进式问题（共2,100个），涵盖从感知到认知的完整过程。

Result: 评估10个最先进的MLLMs发现：(1) MLLMs的感知能力比认知能力更强（8.0%差距）；(2) 认知似乎不因果依赖于基于感知的推理；(3) 认知能力随模型规模扩展，但感知能力在更大变体中并未一致提升。

Conclusion: 该工作将"看到≠理解"操作化为可测试的假设，为MLLMs从感知处理到认知推理提供了新范式。研究证实了感知和认知能力之间的差异，为理解MLLMs的局限性提供了重要见解。

Abstract: Can multi-modal large language models (MLLMs) truly understand what they can see? Extending Searle's Chinese Room into the multi-modal domain, this paper proposes the Visual Room argument: MLLMs may describe every visual detail precisely yet fail to comprehend the underlying emotions and intentions, namely seeing is not understanding. Building on this, we introduce \textit{Visual Room} 2.0, a hierarchical benchmark for evaluating perception-cognition alignment of MLLMs. We model human perceptive and cognitive processes across three levels: low, middle, and high, covering 17 representative tasks. The perception component ranges from attribute recognition to scene understanding, while the cognition component extends from textual entailment to causal and social reasoning. The dataset contains 350 multi-modal samples, each with six progressive questions (2,100 in total) spanning perception to cognition. Evaluating 10 state-of-the-art (SoTA) MLLMs, we highlight three key findings: (1) MLLMs exhibit stronger perceptual competence than cognitive ability (8.0\%$\uparrow$); (2) cognition appears not causally dependent on perception-based reasoning; and (3) cognition scales with model size, but perception does not consistently improve with larger variants. This work operationalizes Seeing $\ne$ Understanding as a testable hypothesis, offering a new paradigm from perceptual processing to cognitive reasoning in MLLMs. Our dataset is available at https://huggingface.co/datasets/LHK2003/PCBench.

</details>


### [58] [Fine-Tuned LLMs Know They Don't Know: A Parameter-Efficient Approach to Recovering Honesty](https://arxiv.org/abs/2511.12991)
*Zeyu Shi,Ziming Wang,Tianyu Chen,Shiqi Gao,Haoyi Zhou,Qingyun Sun,Jianxin Li*

Main category: cs.CL

TL;DR: HCNR方法通过识别和恢复关键表达神经元来修复SFT后LLM的诚实性，相比基线方法在数据效率和速度上有显著提升


<details>
  <summary>Details</summary>
Motivation: 监督微调(SFT)会严重损害LLM的诚实性，但现有恢复方法假设模型完全丧失了知识边界识别能力，而实际上这种能力仍然保留，只是表达这种意识的能力被抑制了

Method: 提出Honesty-Critical Neurons Restoration (HCNR)方法，识别并恢复关键表达神经元到预训练状态，同时通过Hessian引导的补偿机制与任务导向神经元协调

Result: 在四个QA任务和五个LLM家族上的实验表明，HCNR有效恢复了33.25%的受损诚实性，相比基线方法实现了至少2.23倍加速和超过10倍的数据减少

Conclusion: HCNR为可信赖LLM部署提供了实用解决方案，能够高效修复SFT对模型诚实性的损害

Abstract: The honesty of Large Language Models (LLMs) is increasingly important for safe deployment in high-stakes domains. However, this crucial trait is severely undermined by supervised fine-tuning (SFT), a common technique for model specialization. Existing recovery methods rely on data-intensive global parameter adjustments, implicitly assuming that SFT deeply corrupts the models' ability to recognize their knowledge boundaries. However, we observe that fine-tuned LLMs still preserve this ability; what is damaged is their capacity to faithfully express that awareness. Building on this, we propose Honesty-Critical Neurons Restoration (HCNR) to surgically repair this suppressed capacity. HCNR identifies and restores key expression-governing neurons to their pre-trained state while harmonizing them with task-oriented neurons via Hessian-guided compensation. Experiments on four QA tasks and five LLM families demonstrate that HCNR effectively recovers 33.25% of the compromised honesty while achieving at least 2.23x speedup with over 10x less data compared to baseline methods, offering a practical solution for trustworthy LLM deployment.

</details>


### [59] [AA-Omniscience: Evaluating Cross-Domain Knowledge Reliability in Large Language Models](https://arxiv.org/abs/2511.13029)
*Declan Jackson,William Keating,George Cameron,Micah Hill-Smith*

Main category: cs.CL

TL;DR: AA-Omniscience基准评估语言模型的事实回忆和知识校准能力，结果显示前沿模型在事实性和校准方面存在持续弱点，Claude 4.1 Opus表现最佳但得分仅为4.8。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估主要衡量通用能力，但在各领域可靠使用需要事实准确性和知识差距识别能力。

Method: 构建包含6,000个问题的基准，问题来自权威学术和行业资源，覆盖6个领域42个经济相关主题，测量全知指数(-100到100)。

Result: Claude 4.1 Opus得分最高(4.8)，是仅有的三个得分超过0的模型之一。不同领域表现差异显著，三个不同研究实验室的模型在六个领域各自领先。

Conclusion: 模型在知识重要任务中应根据用例需求而非通用性能进行选择，因为性能存在领域差异性。

Abstract: Existing language model evaluations primarily measure general capabilities, yet reliable use of these models across a range of domains demands factual accuracy and recognition of knowledge gaps. We introduce AA-Omniscience, a benchmark designed to measure both factual recall and knowledge calibration across 6,000 questions. Questions are derived from authoritative academic and industry sources, and cover 42 economically relevant topics within six different domains. The evaluation measures a model's Omniscience Index, a bounded metric (-100 to 100) measuring factual recall that jointly penalizes hallucinations and rewards abstention when uncertain, with 0 equating to a model that answers questions correctly as much as it does incorrectly. Among evaluated models, Claude 4.1 Opus attains the highest score (4.8), making it one of only three models to score above zero. These results reveal persistent factuality and calibration weaknesses across frontier models. Performance also varies by domain, with the models from three different research labs leading across the six domains. This performance variability suggests models should be chosen according to the demands of the use case rather than general performance for tasks where knowledge is important.

</details>


### [60] [How Good is BLI as an Alignment Measure: A Study in Word Embedding Paradigm](https://arxiv.org/abs/2511.13040)
*Kasun Wickramasinghe,Nisansa de Silva*

Main category: cs.CL

TL;DR: 本文探讨了多语言嵌入模型与对齐单语模型在双语词典归纳任务中的表现差异，分析了BLI作为评估指标的局限性，并提出基于词干的新BLI方法和词汇剪枝技术来更准确评估嵌入空间对齐程度。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言嵌入已成为主流选择，但需要验证其是否在所有方面都优于对齐单语模型，以及其更高的计算成本是否总是合理。研究旨在探索BLI作为评估指标的局限性，并比较不同嵌入对齐技术在高低资源语言环境下的表现。

Method: 使用双语词典归纳作为评估指标，比较传统嵌入对齐技术、新型多语言模型和组合对齐技术的性能。提出基于词干的BLI方法和词汇剪枝技术，分析语言家族对对齐效果的影响。

Result: 发现BLI在某些情况下不能真实反映对齐程度；组合嵌入对齐技术通常表现更好，但在低资源语言情况下多语言嵌入表现更优；提出的新方法能更准确评估嵌入空间对齐。

Conclusion: 多语言嵌入与对齐单语模型各有优势，需要根据具体场景选择；BLI作为评估指标存在局限性，需要改进方法；在低资源语言场景中多语言嵌入表现更佳。

Abstract: Sans a dwindling number of monolingual embedding studies originating predominantly from the low-resource domains, it is evident that multilingual embedding has become the de facto choice due to its adaptability to the usage of code-mixed languages, granting the ability to process multilingual documents in a language-agnostic manner, as well as removing the difficult task of aligning monolingual embeddings. But is this victory complete? Are the multilingual models better than aligned monolingual models in every aspect? Can the higher computational cost of multilingual models always be justified? Or is there a compromise between the two extremes? Bilingual Lexicon Induction is one of the most widely used metrics in terms of evaluating the degree of alignment between two embedding spaces. In this study, we explore the strengths and limitations of BLI as a measure to evaluate the degree of alignment of two embedding spaces. Further, we evaluate how well traditional embedding alignment techniques, novel multilingual models, and combined alignment techniques perform BLI tasks in the contexts of both high-resource and low-resource languages. In addition to that, we investigate the impact of the language families to which the pairs of languages belong. We identify that BLI does not measure the true degree of alignment in some cases and we propose solutions for them. We propose a novel stem-based BLI approach to evaluate two aligned embedding spaces that take into account the inflected nature of languages as opposed to the prevalent word-based BLI techniques. Further, we introduce a vocabulary pruning technique that is more informative in showing the degree of the alignment, especially performing BLI on multilingual embedding models. Often, combined embedding alignment techniques perform better while in certain cases multilingual embeddings perform better (mainly low-resource language cases).

</details>


### [61] [Spark-Prover-X1: Formal Theorem Proving Through Diverse Data Training](https://arxiv.org/abs/2511.13043)
*Xinyuan Zhou,Yi Lei,Xiaoyu Zhou,Jingyi Sun,Yu Zhu,Zhongyi Ye,Weitai Zhang,Quan Liu,Si Wei,Cong Liu*

Main category: cs.CL

TL;DR: Spark-Prover-X1是一个7B参数模型，通过三阶段训练框架提升轻量级LLM的形式推理能力，在定理证明任务上达到同类开源模型的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动定理证明中显示出潜力，但进展受到高质量形式语言数据稀缺的限制。

Method: 采用三阶段训练框架：1）在广泛数学语料上进行持续预训练，引入"思维链增强状态预测"任务；2）在专家迭代循环中进行监督微调；3）使用组相对策略优化针对最难问题进行强化训练。

Result: Spark-Prover-X1-7B在类似大小的开源模型中达到最先进性能，平均通过率37.0%（pass@32），在PutnamBench上解决27个问题，在CombiBench上达到24.0%。

Conclusion: 多样化的训练数据和逐步精炼的训练流水线为增强轻量级LLM的形式推理能力提供了有效路径。

Abstract: Large Language Models (LLMs) have shown significant promise in automated theorem proving, yet progress is often constrained by the scarcity of diverse and high-quality formal language data. To address this issue, we introduce Spark-Prover-X1, a 7B parameter model trained via an three-stage framework designed to unlock the reasoning potential of more accessible and moderately-sized LLMs. The first stage infuses deep knowledge through continuous pre-training on a broad mathematical corpus, enhanced by a suite of novel data tasks. Key innovation is a "CoT-augmented state prediction" task to achieve fine-grained reasoning. The second stage employs Supervised Fine-tuning (SFT) within an expert iteration loop to specialize both the Spark-Prover-X1-7B and Spark-Formalizer-X1-7B models. Finally, a targeted round of Group Relative Policy Optimization (GRPO) is applied to sharpen the prover's capabilities on the most challenging problems. To facilitate robust evaluation, particularly on problems from real-world examinations, we also introduce ExamFormal-Bench, a new benchmark dataset of 402 formal problems. Experimental results demonstrate that Spark-Prover-X1-7B achieves state-of-the-art performance among similarly-sized open-source models, attaining a 37.0\% average pass rate (pass@32). It shows exceptional performance on difficult competition benchmarks, notably solving 27 problems on PutnamBench (pass@32) and achieving 24.0\% on CombiBench (pass@32). Our work validates that this diverse training data and progressively refined training pipeline provides an effective path for enhancing the formal reasoning capabilities of lightweight LLMs. Both Spark-Prover-X1-7B and Spark-Formalizer-X1-7B, along with the ExamFormal-Bench dataset, are made publicly available at:https://www.modelscope.cn/organization/iflytek, https://gitcode.com/ifly_opensource.

</details>


### [62] [BeDiscovER: The Benchmark of Discourse Understanding in the Era of Reasoning Language Models](https://arxiv.org/abs/2511.13095)
*Chuyuan Li,Giuseppe Carenini*

Main category: cs.CL

TL;DR: BeDiscovER是一个评估现代大语言模型话语理解能力的综合基准测试套件，包含5个话语任务和52个数据集，覆盖词汇、句子和文档级别。评估发现前沿模型在时间推理的算术方面表现强劲，但在完整文档推理和某些语义话语现象上仍有困难。


<details>
  <summary>Details</summary>
Motivation: 随着推理语言模型的发展，需要建立一个全面评估模型话语层面知识的基准测试，涵盖传统任务和新型挑战，以系统评估现代LLMs的话语理解能力。

Method: 构建BeDiscovER基准套件，整合5个公开可用的话语任务（包括话语词典、句子级和文档级任务），共52个数据集。评估开源LLMs（Qwen3系列、DeepSeek-R1）和前沿模型（GPT-5-mini）在这些任务上的表现。

Result: 最先进的模型在时间推理的算术方面表现出色，但在完整文档推理和某些细微语义话语现象（如修辞关系识别）上存在困难。

Conclusion: 现代LLMs在话语理解方面取得了显著进展，但在复杂文档推理和细微语义理解方面仍需改进，BeDiscovER为系统评估模型话语能力提供了有效工具。

Abstract: We introduce BeDiscovER (Benchmark of Discourse Understanding in the Era of Reasoning Language Models), an up-to-date, comprehensive suite for evaluating the discourse-level knowledge of modern LLMs. BeDiscovER compiles 5 publicly available discourse tasks across discourse lexicon, (multi-)sentential, and documental levels, with in total 52 individual datasets. It covers both extensively studied tasks such as discourse parsing and temporal relation extraction, as well as some novel challenges such as discourse particle disambiguation (e.g., ``just''), and also aggregates a shared task on Discourse Relation Parsing and Treebanking for multilingual and multi-framework discourse relation classification. We evaluate open-source LLMs: Qwen3 series, DeepSeek-R1, and frontier model such as GPT-5-mini on BeDiscovER, and find that state-of-the-art models exhibit strong performance in arithmetic aspect of temporal reasoning, but they struggle with full document reasoning and some subtle semantic and discourse phenomena, such as rhetorical relation recognition.

</details>


### [63] [Evaluating the Ability of Large Language Models to Identify Adherence to CONSORT Reporting Guidelines in Randomized Controlled Trials: A Methodological Evaluation Study](https://arxiv.org/abs/2511.13107)
*Zhichao He,Mouxiao Bian,Jianhong Zhu,Jiayuan Chen,Yunqiu Wang,Wenxia Zhao,Tianbin Li,Bing Han,Jie Xu,Junyan Wu*

Main category: cs.CL

TL;DR: 本研究评估了当代大语言模型在零样本设置下识别随机对照试验对CONSORT 2010声明依从性的准确性。结果显示模型整体表现一般，能准确识别合规项目，但在识别不合规和不适用项目方面表现较差，目前尚不能替代人类专家进行试验质量评估。


<details>
  <summary>Details</summary>
Motivation: 手动验证CONSORT依从性是一个耗时费力的过程，成为同行评审和证据合成的重要瓶颈。本研究旨在系统评估当代LLMs在识别已发表RCTs对CONSORT 2010声明依从性方面的准确性和可靠性。

Method: 构建了包含150篇已发表RCTs的金标准数据集，涵盖不同医学专业。在零样本设置下评估LLMs性能，主要结果是三类分类任务的宏平均F1分数，辅以项目级性能指标和定性错误分析。

Result: 整体模型表现一般。表现最佳的模型Gemini-2.5-Flash和DeepSeek-R1分别获得0.634和0.282的宏F1分数和Cohen's Kappa系数，仅与专家共识达成一般一致性。模型在识别合规项目时准确率高（F1分数>0.850），但在识别不合规和不适用项目时表现差（F1分数很少超过0.400）。GPT-4o等知名模型表现不佳，宏F1分数仅为0.521。

Conclusion: LLMs作为CONSORT检查的初步筛选助手具有潜力，能够有效识别报告良好的项目。然而，目前它们无法可靠地检测报告遗漏或方法学缺陷，因此不适合替代人类专家进行试验质量的关键评估。

Abstract: The Consolidated Standards of Reporting Trials statement is the global benchmark for transparent and high-quality reporting of randomized controlled trials. Manual verification of CONSORT adherence is a laborious, time-intensive process that constitutes a significant bottleneck in peer review and evidence synthesis. This study aimed to systematically evaluate the accuracy and reliability of contemporary LLMs in identifying the adherence of published RCTs to the CONSORT 2010 statement under a zero-shot setting. We constructed a golden standard dataset of 150 published RCTs spanning diverse medical specialties. The primary outcome was the macro-averaged F1-score for the three-class classification task, supplemented by item-wise performance metrics and qualitative error analysis. Overall model performance was modest. The top-performing models, Gemini-2.5-Flash and DeepSeek-R1, achieved nearly identical macro F1 scores of 0.634 and Cohen's Kappa coefficients of 0.280 and 0.282, respectively, indicating only fair agreement with expert consensus. A striking performance disparity was observed across classes: while most models could identify compliant items with high accuracy (F1 score > 0.850), they struggled profoundly with identifying non-compliant and not applicable items, where F1 scores rarely exceeded 0.400. Notably, some high-profile models like GPT-4o underperformed, achieving a macro F1-score of only 0.521. LLMs show potential as preliminary screening assistants for CONSORT checks, capably identifying well-reported items. However, their current inability to reliably detect reporting omissions or methodological flaws makes them unsuitable for replacing human expertise in the critical appraisal of trial quality.

</details>


### [64] [Extracting Events Like Code: A Multi-Agent Programming Framework for Zero-Shot Event Extraction](https://arxiv.org/abs/2511.13118)
*Quanjiang Guo,Sijie Wang,Jinchuan Zhang,Ben Zhang,Zhao Kang,Ling Tian,Ke Yan*

Main category: cs.CL

TL;DR: Agent-Event-Coder (AEC) 是一个多智能体框架，将零样本事件抽取视为类似软件工程的代码生成过程，通过专门化的智能体协作实现更精确、完整的抽取结果。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在零样本事件抽取中面临的挑战：直接提示往往产生不完整或结构无效的输出，如错误分类的触发器、缺失参数和模式违规。

Method: 将事件抽取分解为检索、规划、编码和验证四个专门子任务，每个任务由专门的LLM智能体处理。事件模式表示为可执行的类定义，通过验证智能体实现确定性验证和精确反馈。

Result: 在五个不同领域和六个LLM上的实验表明，AEC始终优于先前的零样本基线方法。

Conclusion: 将事件抽取视为代码生成的方法能够使LLM在零样本设置下产生精确、完整且模式一致的抽取结果，展示了编程启发的多智能体框架的有效性。

Abstract: Zero-shot event extraction (ZSEE) remains a significant challenge for large language models (LLMs) due to the need for complex reasoning and domain-specific understanding. Direct prompting often yields incomplete or structurally invalid outputs--such as misclassified triggers, missing arguments, and schema violations. To address these limitations, we present Agent-Event-Coder (AEC), a novel multi-agent framework that treats event extraction like software engineering: as a structured, iterative code-generation process. AEC decomposes ZSEE into specialized subtasks--retrieval, planning, coding, and verification--each handled by a dedicated LLM agent. Event schemas are represented as executable class definitions, enabling deterministic validation and precise feedback via a verification agent. This programming-inspired approach allows for systematic disambiguation and schema enforcement through iterative refinement. By leveraging collaborative agent workflows, AEC enables LLMs to produce precise, complete, and schema-consistent extractions in zero-shot settings. Experiments across five diverse domains and six LLMs demonstrate that AEC consistently outperforms prior zero-shot baselines, showcasing the power of treating event extraction like code generation. The code and data are released on https://github.com/UESTC-GQJ/Agent-Event-Coder.

</details>


### [65] [A Comparative Analysis of Recurrent and Attention Architectures for Isolated Sign Language Recognition](https://arxiv.org/abs/2511.13126)
*Nigar Alishzade,Gulchin Abdullayeva*

Main category: cs.CL

TL;DR: 比较循环神经网络和注意力机制在孤立手语识别中的表现，发现基于注意力的Transformer模型在准确率上优于ConvLSTM，但ConvLSTM在计算效率上更有优势。


<details>
  <summary>Details</summary>
Motivation: 系统比较循环神经网络和注意力机制在手语识别任务中的性能差异，为不同应用场景下的模型选择提供指导。

Method: 在阿塞拜疆手语数据集(AzSLD)和美国手语数据集(WLASL)上实现并评估了ConvLSTM和Vanilla Transformer两种代表性模型。

Result: Vanilla Transformer在两个数据集上都优于ConvLSTM，在AzSLD上达到76.8%的Top-1准确率，在WLASL上达到88.3%。ConvLSTM计算效率更高但在小数据集上表现较差。

Conclusion: Transformer在整体准确率和说话者独立性方面表现更好，而ConvLSTM在计算效率和时序建模方面有优势，应根据应用需求和资源约束选择合适的架构。

Abstract: This study presents a systematic comparative analysis of recurrent and attention-based neural architectures for isolated sign language recognition. We implement and evaluate two representative models-ConvLSTM and Vanilla Transformer-on the Azerbaijani Sign Language Dataset (AzSLD) and the Word-Level American Sign Language (WLASL) dataset. Our results demonstrate that the attention-based Vanilla Transformer consistently outperforms the recurrent ConvLSTM in both Top-1 and Top-5 accuracy across datasets, achieving up to 76.8% Top-1 accuracy on AzSLD and 88.3% on WLASL. The ConvLSTM, while more computationally efficient, lags in recognition accuracy, particularly on smaller datasets. These findings highlight the complementary strengths of each paradigm: the Transformer excels in overall accuracy and signer independence, whereas the ConvLSTM offers advantages in computational efficiency and temporal modeling. The study provides a nuanced analysis of these trade-offs, offering guidance for architecture selection in sign language recognition systems depending on application requirements and resource constraints.

</details>


### [66] [Zero-Shot Grammar Competency Estimation Using Large Language Model Generated Pseudo Labels](https://arxiv.org/abs/2511.13152)
*Sourya Dipta Das,Shubham Kumar,Kuldeep Yadav*

Main category: cs.CL

TL;DR: 提出了一种零样本语法能力评估框架，利用无标签数据和大型语言模型，无需人工标注即可训练基于transformer的语法评分模型


<details>
  <summary>Details</summary>
Motivation: 口语语法评估面临自发、非结构化和不流畅的挑战，且需要大量专家标注，难以大规模创建数据

Method: 使用基于语法能力量表的提示词让LLM在无标签数据上生成预测作为伪标签，通过新颖的训练框架处理标签噪声来训练transformer模型

Result: 实验结果表明该方法能高精度估计语法能力分数，LLM选择对性能有重要影响，训练中干净与噪声样本比例影响稳定性和准确性

Conclusion: 该方法为可扩展、低资源的语法评估系统铺平了道路，具有鲁棒性和可解释性

Abstract: Grammar competency estimation is essential for assessing linguistic proficiency in both written and spoken language; however, the spoken modality presents additional challenges due to its spontaneous, unstructured, and disfluent nature. Developing accurate grammar scoring models further requires extensive expert annotation, making large-scale data creation impractical. To address these limitations, we propose a zero-shot grammar competency estimation framework that leverages unlabeled data and Large Language Models (LLMs) without relying on manual labels. During training, we employ LLM-generated predictions on unlabeled data by using grammar competency rubric-based prompts. These predictions, treated as pseudo labels, are utilized to train a transformer-based model through a novel training framework designed to handle label noise effectively. We show that the choice of LLM for pseudo-label generation critically affects model performance and that the ratio of clean-to-noisy samples during training strongly influences stability and accuracy. Finally, a qualitative analysis of error intensity and score prediction confirms the robustness and interpretability of our approach. Experimental results demonstrate the efficacy of our approach in estimating grammar competency scores with high accuracy, paving the way for scalable, low-resource grammar assessment systems.

</details>


### [67] [Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla ASR Transcripts: A Novel Corpus and Benchmarking Analysis](https://arxiv.org/abs/2511.13159)
*Zaara Zabeen Arpa,Sadnam Sakib Apurbo,Nazia Karim Khan Oishee,Ajwad Abrar*

Main category: cs.CL

TL;DR: 提出了首个孟加拉语ASR转录本中重复性口吃与形态重叠的区分数据集，通过LLM和微调方法建立了强基线，最佳模型达到84.78%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉语ASR转录本中词重复的歧义问题：区分重复性口吃（ASR错误/犹豫）和形态重叠（语法构造），避免标准口吃修正方法误删有效语言信息。

Method: 构建了首个20,000行手动标注的孟加拉语语料库，采用两种方法：1）多语言大语言模型的少样本提示；2）任务特定的编码器模型微调。

Result: LLM在少样本提示下达到82.68%准确率；微调方法更优，BanglaBERT模型达到最高84.78%准确率和0.677 F1分数。

Conclusion: 建立了强大的语言感知基线，为开发语义保留的孟加拉语文本规范化系统提供了重要数据基础。

Abstract: Automatic Speech Recognition (ASR) transcripts, especially in low-resource languages like Bangla, contain a critical ambiguity: word-word repetitions can be either Repetition Disfluency (unintentional ASR error/hesitation) or Morphological Reduplication (a deliberate grammatical construct). Standard disfluency correction fails by erroneously deleting valid linguistic information. To solve this, we introduce the first publicly available, 20,000-row Bangla corpus, manually annotated to explicitly distinguish between these two phenomena in noisy ASR transcripts. We benchmark this novel resource using two paradigms: state-of-the-art multilingual Large Language Models (LLMs) and task-specific fine-tuning of encoder models. LLMs achieve competitive performance (up to 82.68\% accuracy) with few-shot prompting. However, fine-tuning proves superior, with the language-specific BanglaBERT model achieving the highest accuracy of 84.78\% and an F1 score of 0.677. This establishes a strong, linguistically-informed baseline and provides essential data for developing sophisticated, semantic-preserving text normalization systems for Bangla.

</details>


### [68] [TCM-5CEval: Extended Deep Evaluation Benchmark for LLM's Comprehensive Clinical Research Competence in Traditional Chinese Medicine](https://arxiv.org/abs/2511.13169)
*Tianai Huang,Jiayuan Chen,Lu Lu,Pengcheng Chen,Tianbin Li,Bing Han,Wenchao Tang,Jie Xu,Ming Li*

Main category: cs.CL

TL;DR: TCM-5CEval是一个更细粒度的中医领域大语言模型评估基准，涵盖5个关键维度：核心知识、经典文献、临床决策、中药学和临床非药物治疗。评估发现模型在基础知识回忆方面表现良好，但在经典文本解释和推理稳定性方面存在显著弱点。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准在高度专业化和文化丰富的中医领域不够全面，需要更细致的评估工具来系统评估大语言模型在中医领域的真实能力。

Method: 构建TCM-5CEval基准，包含5个维度评估：TCM-Exam（核心知识）、TCM-LitQA（经典文献）、TCM-MRCD（临床决策）、TCM-CMM（中药学）、TCM-ClinNPT（临床非药物治疗）。对15个主流大语言模型进行全面评估，并使用排列一致性测试检测推理稳定性。

Result: 评估显示模型在基础知识回忆方面表现良好，但在经典文本解释方面存在困难。排列一致性测试发现所有模型都存在位置偏差敏感性，推理稳定性普遍不足。deepseek_r1和gemini_2_5_pro表现最佳。

Conclusion: TCM-5CEval为中医领域的大语言模型能力提供了更详细的诊断工具，揭示了模型在推理稳定性方面的根本弱点。该基准已上传至Medbench平台，促进标准化比较和进一步研究。

Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in general domains, yet their application in highly specialized and culturally-rich fields like Traditional Chinese Medicine (TCM) requires rigorous and nuanced evaluation. Building upon prior foundational work such as TCM-3CEval, which highlighted systemic knowledge gaps and the importance of cultural-contextual alignment, we introduce TCM-5CEval, a more granular and comprehensive benchmark. TCM-5CEval is designed to assess LLMs across five critical dimensions: (1) Core Knowledge (TCM-Exam), (2) Classical Literacy (TCM-LitQA), (3) Clinical Decision-making (TCM-MRCD), (4) Chinese Materia Medica (TCM-CMM), and (5) Clinical Non-pharmacological Therapy (TCM-ClinNPT). We conducted a thorough evaluation of fifteen prominent LLMs, revealing significant performance disparities and identifying top-performing models like deepseek\_r1 and gemini\_2\_5\_pro. Our findings show that while models exhibit proficiency in recalling foundational knowledge, they struggle with the interpretative complexities of classical texts. Critically, permutation-based consistency testing reveals widespread fragilities in model inference. All evaluated models, including the highest-scoring ones, displayed a substantial performance degradation when faced with varied question option ordering, indicating a pervasive sensitivity to positional bias and a lack of robust understanding. TCM-5CEval not only provides a more detailed diagnostic tool for LLM capabilities in TCM but aldso exposes fundamental weaknesses in their reasoning stability. To promote further research and standardized comparison, TCM-5CEval has been uploaded to the Medbench platform, joining its predecessor in the "In-depth Challenge for Comprehensive TCM Abilities" special track.

</details>


### [69] [Translation Entropy: A Statistical Framework for Evaluating Translation Systems](https://arxiv.org/abs/2511.13180)
*Ronit D. Gross,Yanir Harel,Ido Kanter*

Main category: cs.CL

TL;DR: 本文提出了一种量化估计翻译熵的方法，通过分析在保持翻译不变的情况下替换句子中单个标记的概率，来评估翻译器的性能。


<details>
  <summary>Details</summary>
Motivation: 在信息时代，翻译需求日益增长，但缺乏量化评估翻译器性能的客观方法，因为即使是单一语言的熵也未知。

Method: 给定翻译器，通过替换枢轴句中选定标记生成多个句子，统计翻译保持不变的概率，计算单个标记的熵，并平均所有枢轴标记得到整体翻译熵。

Result: 该方法能够量化排名多个公开翻译器，揭示互翻译熵的对称性，并发现替换两个标记时翻译退化度与两个标记退化度的乘积成正比。

Conclusion: 翻译熵是可测量的属性，为人工翻译器提供了客观基准测试方法，基于MarianMT、T5-Base和NLLB-200翻译器的结果验证了该方法的有效性。

Abstract: The translation of written language has been known since the 3rd century BC; however, its necessity has become increasingly common in the information age. Today, many translators exist, based on encoder-decoder deep architectures, nevertheless, no quantitative objective methods are available to assess their performance, likely because the entropy of even a single language remains unknown. This study presents a quantitative method for estimating translation entropy, with the following key finding. Given a translator, several sentences that differ by only one selected token of a given pivot sentence yield identical translations. Analyzing the statistics of this phenomenon across an ensemble of such sentences, consisting each of a pivot selected token, yields the probabilities of replacing this specific token with others while preserving the translation. These probabilities constitute the entropy of the selected token, and the average across all selected pivot tokens provides an estimate of the translator's overall translation entropy, which is enhanced along the decoder blocks. This entropic measure allows for the quantitative ranking of several publicly available translators and reveals whether mutual translation entropy is symmetric. Extending the proposed method to include the replacement of two tokens in a given pivot sentence demonstrates a multiplicative effect, where translation degeneracy is proportional to the product of the degeneracies of the two tokens. These findings establish translation entropy as a measurable property and objective benchmarking of artificial translators. Results are based on MarianMT, T5-Base and NLLB-200 translators.

</details>


### [70] [Evaluating Large Language Models for Diacritic Restoration in Romanian Texts: A Comparative Study](https://arxiv.org/abs/2511.13182)
*Mihai Dan Nadas,Laura Diosan*

Main category: cs.CL

TL;DR: 评估多种大型语言模型在罗马尼亚语变音符号恢复任务中的表现，发现GPT-4o等模型表现优异，而Llama系列模型表现波动较大。


<details>
  <summary>Details</summary>
Motivation: 自动变音符号恢复对于处理像罗马尼亚语这样具有丰富变音符号的语言至关重要，需要评估不同LLM在此任务上的性能。

Method: 使用综合语料库测试了包括GPT-3.5、GPT-4、GPT-4o、Gemini、Llama系列等在内的多种LLM，采用从零样本到复杂多样本的多种提示模板。

Result: GPT-4o等模型实现了高精度的变音符号恢复，始终超过中性回显基线，而Llama系列等模型表现出更大的变异性。

Conclusion: 模型架构、训练数据和提示设计对变音符号恢复性能有显著影响，为改进面向变音符号丰富语言的NLP工具指明了方向。

Abstract: Automatic diacritic restoration is crucial for text processing in languages with rich diacritical marks, such as Romanian. This study evaluates the performance of several large language models (LLMs) in restoring diacritics in Romanian texts. Using a comprehensive corpus, we tested models including OpenAI's GPT-3.5, GPT-4, GPT-4o, Google's Gemini 1.0 Pro, Meta's Llama 2 and Llama 3, MistralAI's Mixtral 8x7B Instruct, airoboros 70B, and OpenLLM-Ro's RoLlama 2 7B, under multiple prompt templates ranging from zero-shot to complex multi-shot instructions. Results show that models such as GPT-4o achieve high diacritic restoration accuracy, consistently surpassing a neutral echo baseline, while others, including Meta's Llama family, exhibit wider variability. These findings highlight the impact of model architecture, training data, and prompt design on diacritic restoration performance and outline promising directions for improving NLP tools for diacritic-rich languages.

</details>


### [71] [Seeing isn't Hearing: Benchmarking Vision Language Models at Interpreting Spectrograms](https://arxiv.org/abs/2511.13225)
*Tyler Loakman,Joseph James,Chenghua Lin*

Main category: cs.CL

TL;DR: 该研究评估了视觉语言模型在语音识别任务中的表现，发现即使是微调后的模型也难以准确解读语音的频谱图和波形图，表明需要特定的参数知识而不仅仅是配对样本。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和视觉语言模型的发展，研究者希望了解这些模型在融合视觉和语言模态任务中的能力，特别是能否像专业语音学家一样解读语音的频谱图和波形图。

Method: 创建了一个包含4000+英语单词的新数据集，通过多项选择任务测试VLMs从语音表示中预测正确音素或字素转录的能力，使用基于音素编辑距离的干扰项。

Result: 无论是零样本还是微调后的模型，其表现都很少超过随机水平，表明模型缺乏解读此类图形的特定参数知识。

Conclusion: 视觉语言模型需要专门的参数知识来正确解读语音的频谱图和波形图，仅靠配对样本训练是不够的。

Abstract: With the rise of Large Language Models (LLMs) and their vision-enabled counterparts (VLMs), numerous works have investigated their capabilities in tasks that fuse the modalities of vision and language. In this work, we benchmark the extent to which VLMs are able to act as highly-trained phoneticians, interpreting spectrograms and waveforms of speech. To do this, we synthesise a novel dataset containing 4k+ English words spoken in isolation alongside stylistically consistent spectrogram and waveform figures. We test the ability of VLMs to understand these representations of speech through a multiple-choice task whereby models must predict the correct phonemic or graphemic transcription of a spoken word when presented amongst 3 distractor transcriptions that have been selected based on their phonemic edit distance to the ground truth. We observe that both zero-shot and finetuned models rarely perform above chance, demonstrating the requirement for specific parametric knowledge of how to interpret such figures, rather than paired samples alone.

</details>


### [72] [Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance](https://arxiv.org/abs/2511.13254)
*Shalini Maiti,Amar Budhiraja,Bhavul Gauri,Gaurav Chaurasia,Anton Protopopov,Alexis Audran-Reiss,Michael Slater,Despoina Magka,Tatiana Shavrina,Roberta Raileanu,Yoram Bachrach*

Main category: cs.CL

TL;DR: SoCE是一种基于基准测试组合的模型融合方法，通过识别各弱相关类别中的专家模型，并使用非均匀加权平均而非均匀权重来最大化性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练资源密集且耗时，模型融合作为预训练和后训练技术可以在不进行昂贵重新训练的情况下提升性能。

Method: 利用基准类别间模型性能低相关性的观察，识别每个弱相关类别簇中的专家模型，并通过优化的加权平均而非均匀权重进行组合。

Result: 该方法在多个领域（包括多语言能力、工具调用和数学）提高了性能和鲁棒性，并在伯克利函数调用排行榜上取得了最先进的结果。

Conclusion: SoCE提供了一种原则性的模型融合方法，通过利用基准类别间的低相关性来识别和优化组合专家模型，从而显著提升模型性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, but their training remains resource- and time-intensive, requiring massive compute power and careful orchestration of training procedures. Model souping-the practice of averaging weights from multiple models of the same architecture-has emerged as a promising pre- and post-training technique that can enhance performance without expensive retraining. In this paper, we introduce Soup Of Category Experts (SoCE), a principled approach for model souping that utilizes benchmark composition to identify optimal model candidates and applies non-uniform weighted averaging to maximize performance. Contrary to previous uniform-averaging approaches, our method leverages the observation that benchmark categories often exhibit low inter-correlations in model performance. SoCE identifies "expert" models for each weakly-correlated category cluster and combines them using optimized weighted averaging rather than uniform weights. We demonstrate that the proposed method improves performance and robustness across multiple domains, including multilingual capabilities, tool calling, and math and achieves state-of-the-art results on the Berkeley Function Calling Leaderboard.

</details>


### [73] [RegionMarker: A Region-Triggered Semantic Watermarking Framework for Embedding-as-a-Service Copyright Protection](https://arxiv.org/abs/2511.13329)
*Shufan Yang,Zifeng Cheng,Zhiwei Jiang,Yafeng Yin,Cong Wang,Shiping Ge,Yuchen Fu,Qing Gu*

Main category: cs.CL

TL;DR: RegionMarker是一种区域触发语义水印框架，通过在低维空间中定义触发区域并向相关文本嵌入中注入水印，为Embedding-as-a-Service提供全面的版权保护。


<details>
  <summary>Details</summary>
Motivation: 现有的EaaS水印方法只能抵抗部分攻击，无法提供全面保护，存在模型提取攻击导致经济损失的风险。

Method: 使用秘密降维矩阵投影到子空间，随机选择触发区域，在整个触发区域嵌入水印，并将文本嵌入本身作为水印。

Result: 在多个数据集上的实验表明，RegionMarker能有效抵抗不同的攻击方法，包括水印移除、转述和维度扰动攻击。

Conclusion: RegionMarker框架能够全面保护EaaS的版权，抵抗多种攻击，为模型提供商提供有效的版权保护方案。

Abstract: Embedding-as-a-Service (EaaS) is an effective and convenient deployment solution for addressing various NLP tasks. Nevertheless, recent research has shown that EaaS is vulnerable to model extraction attacks, which could lead to significant economic losses for model providers. For copyright protection, existing methods inject watermark embeddings into text embeddings and use them to detect copyright infringement. However, current watermarking methods often resist only a subset of attacks and fail to provide \textit{comprehensive} protection. To this end, we present the region-triggered semantic watermarking framework called RegionMarker, which defines trigger regions within a low-dimensional space and injects watermarks into text embeddings associated with these regions. By utilizing a secret dimensionality reduction matrix to project onto this subspace and randomly selecting trigger regions, RegionMarker makes it difficult for watermark removal attacks to evade detection. Furthermore, by embedding watermarks across the entire trigger region and using the text embedding as the watermark, RegionMarker is resilient to both paraphrasing and dimension-perturbation attacks. Extensive experiments on various datasets show that RegionMarker is effective in resisting different attack methods, thereby protecting the copyright of EaaS.

</details>


### [74] [AHaSIS: Shared Task on Sentiment Analysis for Arabic Dialects](https://arxiv.org/abs/2511.13335)
*Maram Alharbi,Salmane Chafik,Saad Ezzini,Ruslan Mitkov,Tharindu Ranasinghe,Hansi Hettiarachchi*

Main category: cs.CL

TL;DR: 该论文介绍了阿拉伯酒店评论情感分析共享任务，使用包含沙特和摩洛哥方言的多方言数据集，最佳系统F1分数达0.81。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯世界酒店业日益依赖客户反馈来改进服务，需要先进的阿拉伯语情感分析工具，特别是针对方言的分析能力。

Method: 创建多方言数据集，将现代标准阿拉伯语的酒店评论翻译成沙特和摩洛哥方言，由母语者验证翻译准确性和情感保持。数据集包含538条平衡的情感评论。

Result: 超过40个团队注册参与，12个团队提交系统。最佳系统F1分数达到0.81，证明了跨阿拉伯方言情感分析的可行性。

Conclusion: 该资源支持开发方言感知的NLP系统，用于客户体验分析的实际应用，同时显示了跨阿拉伯方言情感分析的持续挑战。

Abstract: The hospitality industry in the Arab world increasingly relies on customer feedback to shape services, driving the need for advanced Arabic sentiment analysis tools. To address this challenge, the Sentiment Analysis on Arabic Dialects in the Hospitality Domain shared task focuses on Sentiment Detection in Arabic Dialects. This task leverages a multi-dialect, manually curated dataset derived from hotel reviews originally written in Modern Standard Arabic (MSA) and translated into Saudi and Moroccan (Darija) dialects. The dataset consists of 538 sentiment-balanced reviews spanning positive, neutral, and negative categories. Translations were validated by native speakers to ensure dialectal accuracy and sentiment preservation. This resource supports the development of dialect-aware NLP systems for real-world applications in customer experience analysis. More than 40 teams have registered for the shared task, with 12 submitting systems during the evaluation phase. The top-performing system achieved an F1 score of 0.81, demonstrating the feasibility and ongoing challenges of sentiment analysis across Arabic dialects.

</details>


### [75] [Donors and Recipients: On Asymmetric Transfer Across Tasks and Languages with Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2511.13368)
*Kajetan Dymkiewicz,Ivan Vulic,Helen Yannakoudakis,Eilam Shapira,Roi Reichart,Anna Korhonen*

Main category: cs.CL

TL;DR: 本文通过PEFT/LoRA研究揭示了LLM跨任务和跨语言迁移的模式：同任务跨语言迁移可靠为正，而异任务迁移常导致性能下降；同时发现了稳定的捐赠者-接收者结构。


<details>
  <summary>Details</summary>
Motivation: 理解LLM在一个任务或语言上的改进如何影响其他任务和语言及其组合，目前仍缺乏系统研究。

Method: 在多个开源LLM家族和规模上进行受控PEFT/LoRA研究，将任务和语言作为迁移轴，每个模型在单一任务-语言源上微调，测量在所有其他任务-语言目标对上的迁移效果。

Result: 发现两个一致模式：1）同任务跨语言迁移可靠为正，而异任务迁移常导致性能下降；2）跨语言和任务存在稳定的捐赠者-接收者结构。

Conclusion: 研究结果为风险感知微调和模型专业化提供了重要启示。

Abstract: Large language models (LLMs) perform strongly across tasks and languages, yet how improvements in one task or language affect other tasks and languages and their combinations remains poorly understood. We conduct a controlled PEFT/LoRA study across multiple open-weight LLM families and sizes, treating task and language as transfer axes while conditioning on model family and size; we fine-tune each model on a single task-language source and measure transfer as the percentage-point change versus its baseline score when evaluated on all other task-language target pairs. We decompose transfer into (i) Matched-Task (Cross-Language), (ii) Matched-Language (Cross-Task), and (iii) Cross-Task (Cross-Language) regimes. We uncover two consistent general patterns. First, a pronounced on-task vs. off-task asymmetry: Matched-Task (Cross-Language) transfer is reliably positive, whereas off-task transfer often incurs collateral degradation. Second, a stable donor-recipient structure across languages and tasks (hub donors vs. brittle recipients). We outline implications for risk-aware fine-tuning and model specialisation.

</details>


### [76] [Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts](https://arxiv.org/abs/2511.13381)
*Siyu Zhu,Mouxiao Bian,Yue Xie,Yongyu Tang,Zhikang Yu,Tianbin Li,Pengcheng Chen,Bing Han,Jie Xu,Xiaoyan Dong*

Main category: cs.CL

TL;DR: PEDIASBench评估框架显示，当前大语言模型在儿科医学中基础知识表现良好，但在复杂推理、动态诊疗决策和人文关怀方面存在局限，尚不能独立承担儿科诊疗工作，但在决策支持等方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在医学领域的快速发展，需要评估它们是否能在真实临床环境中作为合格的儿科医生发挥作用。

Method: 开发了PEDIASBench系统评估框架，从基础知识应用、动态诊疗能力、儿科医疗安全与伦理三个维度，评估12个代表性模型在19个儿科亚专业和211种典型疾病上的表现。

Result: 先进模型在基础知识上表现良好（Qwen3-235B-A22B在执照级问题上准确率超90%），但随着任务复杂度增加性能下降约15%；在动态诊疗场景中，DeepSeek-R1在病例推理中得分最高（平均0.58），但多数模型难以适应实时患者变化；在伦理安全任务中，Qwen2.5-72B表现最佳（准确率92.05%），但人文敏感性仍有限。

Conclusion: 当前儿科大语言模型受限于有限的动态决策能力和不成熟的人文关怀，未来应关注多模态整合和临床反馈-模型迭代循环，以增强安全性、可解释性和人机协作。虽然不能独立承担儿科诊疗，但在决策支持、医学教育和患者沟通方面具有前景。

Abstract: With the rapid rise of large language models (LLMs) in medicine, a key question is whether they can function as competent pediatricians in real-world clinical settings. We developed PEDIASBench, a systematic evaluation framework centered on a knowledge-system framework and tailored to realistic clinical environments. PEDIASBench assesses LLMs across three dimensions: application of basic knowledge, dynamic diagnosis and treatment capability, and pediatric medical safety and medical ethics. We evaluated 12 representative models released over the past two years, including GPT-4o, Qwen3-235B-A22B, and DeepSeek-V3, covering 19 pediatric subspecialties and 211 prototypical diseases. State-of-the-art models performed well on foundational knowledge, with Qwen3-235B-A22B achieving over 90% accuracy on licensing-level questions, but performance declined ~15% as task complexity increased, revealing limitations in complex reasoning. Multiple-choice assessments highlighted weaknesses in integrative reasoning and knowledge recall. In dynamic diagnosis and treatment scenarios, DeepSeek-R1 scored highest in case reasoning (mean 0.58), yet most models struggled to adapt to real-time patient changes. On pediatric medical ethics and safety tasks, Qwen2.5-72B performed best (accuracy 92.05%), though humanistic sensitivity remained limited. These findings indicate that pediatric LLMs are constrained by limited dynamic decision-making and underdeveloped humanistic care. Future development should focus on multimodal integration and a clinical feedback-model iteration loop to enhance safety, interpretability, and human-AI collaboration. While current LLMs cannot independently perform pediatric care, they hold promise for decision support, medical education, and patient communication, laying the groundwork for a safe, trustworthy, and collaborative intelligent pediatric healthcare system.

</details>


### [77] [Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction](https://arxiv.org/abs/2511.13410)
*Zhaopei Huang,Qifeng Dai,Guozheng Wu,Xiaopeng Wu,Kehan Chen,Chuan Yu,Xubin Li,Tiezheng Ge,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 提出了PAL-Bench基准和H²Memory记忆框架，用于评估和改进面向服务的个性化对话助手在长期交互中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着智能个人设备的普及，需要能够理解用户特定特征并定制响应的个性化对话助手，但现有方法往往忽视长期交互的复杂性。

Method: 开发了多步骤LLM合成管道创建PAL-Set中文数据集，并提出H²Memory层次异构记忆框架，结合检索增强生成来改进个性化响应生成。

Result: 在PAL-Bench和外部数据集上的综合实验证明了所提记忆框架的有效性。

Conclusion: PAL-Bench为评估服务导向助手的个性化能力提供了新基准，H²Memory框架显著提升了长期用户-代理交互中的个性化服务表现。

Abstract: With the rise of smart personal devices, service-oriented human-agent interactions have become increasingly prevalent. This trend highlights the need for personalized dialogue assistants that can understand user-specific traits to accurately interpret requirements and tailor responses to individual preferences. However, existing approaches often overlook the complexities of long-term interactions and fail to capture users' subjective characteristics. To address these gaps, we present PAL-Bench, a new benchmark designed to evaluate the personalization capabilities of service-oriented assistants in long-term user-agent interactions. In the absence of available real-world data, we develop a multi-step LLM-based synthesis pipeline, which is further verified and refined by human annotators. This process yields PAL-Set, the first Chinese dataset comprising multi-session user logs and dialogue histories, which serves as the foundation for PAL-Bench. Furthermore, to improve personalized service-oriented interactions, we propose H$^2$Memory, a hierarchical and heterogeneous memory framework that incorporates retrieval-augmented generation to improve personalized response generation. Comprehensive experiments on both our PAL-Bench and an external dataset demonstrate the effectiveness of the proposed memory framework.

</details>


### [78] [Non-Linear Scoring Model for Translation Quality Evaluation](https://arxiv.org/abs/2511.13467)
*Serge Gladkoff,Lifeng Han,Katerina Gasova*

Main category: cs.CL

TL;DR: 提出了一个基于对数函数的非线性翻译质量评估模型，解决了传统线性评分在不同文本长度下的偏差问题，使评估更符合人类感知。


<details>
  <summary>Details</summary>
Motivation: 传统基于MQM的线性评分方法在不同长度文本样本上存在偏差，短文本被过度惩罚而长文本被低估，与专家直觉不一致。

Method: 开发了双参数对数模型E(x) = a * ln(1 + b * x)，基于韦伯-费希纳定律和认知负荷理论，通过一维根查找步骤从两个容忍点进行校准。

Result: 实证数据显示可接受错误数量随样本大小呈对数增长而非线性增长，该模型提高了可解释性、公平性和评分者间信度。

Conclusion: 该非线性评分模型为翻译质量评估提供了更准确、可扩展的评估范式，并为AI驱动的文档级评估提供了更强的基础。

Abstract: Analytic Translation Quality Evaluation (TQE), based on Multidimensional Quality Metrics (MQM), traditionally uses a linear error-to-penalty scale calibrated to a reference sample of 1000-2000 words. However, linear extrapolation biases judgment on samples of different sizes, over-penalizing short samples and under-penalizing long ones, producing misalignment with expert intuition.
  Building on the Multi-Range framework, this paper presents a calibrated, non-linear scoring model that better reflects how human content consumers perceive translation quality across samples of varying length. Empirical data from three large-scale enterprise environments shows that acceptable error counts grow logarithmically, not linearly, with sample size.
  Psychophysical and cognitive evidence, including the Weber-Fechner law and Cognitive Load Theory, supports this premise by explaining why the perceptual impact of additional errors diminishes while the cognitive burden grows with scale. We propose a two-parameter model
  E(x) = a * ln(1 + b * x), a, b > 0,
  anchored to a reference tolerance and calibrated from two tolerance points using a one-dimensional root-finding step. The model yields an explicit interval within which the linear approximation stays within +/-20 percent relative error and integrates into existing evaluation workflows with only a dynamic tolerance function added.
  The approach improves interpretability, fairness, and inter-rater reliability across both human and AI-generated translations. By operationalizing a perceptually valid scoring paradigm, it advances translation quality evaluation toward more accurate and scalable assessment. The model also provides a stronger basis for AI-based document-level evaluation aligned with human judgment. Implementation considerations for CAT/LQA systems and implications for human and AI-generated text evaluation are discussed.

</details>


### [79] [Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns](https://arxiv.org/abs/2511.13481)
*Attapol T. Rutherford,Sirisak Chueykamhang,Thachaparn Bunditlurdruk,Nanthicha Angsuwichitkul*

Main category: cs.CL

TL;DR: 本文提出了一种基于方面情感分析(ABSA)的新方法，用于解码泰语财务年报中的模糊情感，并通过事件研究验证了分析结果对股票价格的实际影响。


<details>
  <summary>Details</summary>
Motivation: 财务文档中的情感理解对洞察市场行为至关重要，但这些报告常使用模糊语言来呈现积极或中性前景，即使实际情况可能不太乐观。

Method: 开发了针对泰语财务年报模糊情感标注的特定指南，标注了100多份财务报告，并在标注数据集上对各种文本分类模型进行基准测试。

Result: 在情感分类方面表现出色，事件研究表明市场反应受到报告中特定方面的选择性影响。

Conclusion: 研究结果强调了财务文本情感分析的复杂性，并凸显了解决模糊语言以准确评估市场情绪的重要性。

Abstract: Understanding sentiment in financial documents is crucial for gaining insights into market behavior. These reports often contain obfuscated language designed to present a positive or neutral outlook, even when underlying conditions may be less favorable. This paper presents a novel approach using Aspect-Based Sentiment Analysis (ABSA) to decode obfuscated sentiment in Thai financial annual reports. We develop specific guidelines for annotating obfuscated sentiment in these texts and annotate more than one hundred financial reports. We then benchmark various text classification models on this annotated dataset, demonstrating strong performance in sentiment classification. Additionally, we conduct an event study to evaluate the real-world implications of our sentiment analysis on stock prices. Our results suggest that market reactions are selectively influenced by specific aspects within the reports. Our findings underscore the complexity of sentiment analysis in financial texts and highlight the importance of addressing obfuscated language to accurately assess market sentiment.

</details>


### [80] [Applying Large Language Models to Characterize Public Narratives](https://arxiv.org/abs/2511.13505)
*Elinor Poole-Dayan,Daniel T Kessler,Hannah Chiou,Margaret Hughes,Emily S Lin,Marshall Ganz,Deb Roy*

Main category: cs.CL

TL;DR: 提出基于大语言模型的公共叙事自动化标注框架，在专家标注基准上达到接近人类专家水平的性能（平均F1分数0.80），并扩展到政治演讲分析。


<details>
  <summary>Details</summary>
Motivation: 公共叙事是领导力发展和公民动员的重要工具，但由于主观解释性和专家标注成本高，系统分析面临挑战。

Method: 开发基于大语言模型的计算框架，使用与领域专家共同制定的编码手册，评估LLM在公共叙事定性标注中的表现。

Result: LLM在8个叙事和14个代码上达到平均F1分数0.80，接近人类专家水平；扩展分析到22个故事和一组政治演讲。

Conclusion: 展示了LLM辅助标注在可扩展叙事分析中的潜力，为计算公民叙事研究指明了关键局限性和未来方向。

Abstract: Public Narratives (PNs) are key tools for leadership development and civic mobilization, yet their systematic analysis remains challenging due to their subjective interpretation and the high cost of expert annotation. In this work, we propose a novel computational framework that leverages large language models (LLMs) to automate the qualitative annotation of public narratives. Using a codebook we co-developed with subject-matter experts, we evaluate LLM performance against that of expert annotators. Our work reveals that LLMs can achieve near-human-expert performance, achieving an average F1 score of 0.80 across 8 narratives and 14 codes. We then extend our analysis to empirically explore how PN framework elements manifest across a larger dataset of 22 stories. Lastly, we extrapolate our analysis to a set of political speeches, establishing a novel lens in which to analyze political rhetoric in civic spaces. This study demonstrates the potential of LLM-assisted annotation for scalable narrative analysis and highlights key limitations and directions for future research in computational civic storytelling.

</details>


### [81] [Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets](https://arxiv.org/abs/2511.13529)
*Máté Gedeon,Piroska Zsófia Barta,Péter Mihajlik,Tekla Etelka Gráczi,Anna Kohári,Katalin Mády*

Main category: cs.CL

TL;DR: 为填补匈牙利语自发性和对话语音语料库的空白，研究者构建了两个新数据集BEA-Large和BEA-Dialogue，并建立了可复现的ASR基线模型，展示了对话ASR的持续挑战。


<details>
  <summary>Details</summary>
Motivation: 高资源语言的ASR发展受益于大量数据集，而匈牙利语等语言由于缺乏自发性和对话语料库而代表性不足，需要填补这一空白。

Method: 从匈牙利语音语料库BEA中构建两个新数据集：BEA-Large（255小时自发语音）和BEA-Dialogue（85小时自然对话），并使用公开可用的ASR模型建立可复现基线。

Result: 微调的Fast Conformer模型在自发语音上词错误率为14.18%，在重复语音上为4.8%；说话人日志错误率在13.05%-18.26%之间。

Conclusion: 对话ASR仍然面临困难，特别是由于不流畅、重叠和非正式语音模式。通过发布这些数据集和基线，旨在推进匈牙利语音技术并为其他语言开发自发性和对话基准提供方法论框架。

Abstract: The advancement of automatic speech recognition (ASR) has been largely enhanced by extensive datasets in high-resource languages, while languages such as Hungarian remain underrepresented due to limited spontaneous and conversational corpora. To address this gap, we introduce two new datasets -- BEA-Large and BEA-Dialogue -- constructed from the previously unprocessed portions of the Hungarian speech corpus named BEA. BEA-Large extends BEA-Base with 255 hours of spontaneous speech from 433 speakers, enriched with detailed segment-level metadata. BEA-Dialogue, comprising 85 hours of spontaneous conversations, is a Hungarian speech corpus featuring natural dialogues partitioned into speaker-independent subsets, supporting research in conversational ASR and speaker diarization. We establish reproducible baselines on these datasets using publicly available ASR models, with the fine-tuned Fast Conformer model achieving word error rates as low as 14.18\% on spontaneous and 4.8\% on repeated speech. Diarization experiments yield diarization error rates between 13.05\% and 18.26\%, providing reference points for future improvements. The results highlight the persistent difficulty of conversational ASR, particularly due to disfluencies, overlaps, and informal speech patterns. By releasing these datasets and baselines, we aim to advance Hungarian speech technology and offer a methodological framework for developing spontaneous and conversational benchmarks in other languages.

</details>


### [82] [Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation](https://arxiv.org/abs/2511.13590)
*Hao Wang,Yuanfeng Song,Xiaoming Yin,Xing Chen*

Main category: cs.CL

TL;DR: 提出了一种新的文本到SQL分类法，并基于该分类法创建了SQL-Synth数据集，该数据集比现有基准具有更好的多样性和覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到SQL数据集覆盖范围有限，无法捕捉真实世界应用的多样性，需要更全面的数据集来训练和评估模型。

Method: 开发了基于核心意图、语句类型、语法结构和关键动作的文本到SQL分类法，并利用该分类法与大型语言模型结合构建数据集合成管道。

Result: SQL-Synth数据集在多样性和覆盖范围上优于现有基准，现有LLMs在SQL-Synth上表现有限，但微调可以显著提高性能。

Conclusion: 提出的分类法具有重要潜力，能够全面分析数据集和不同LLMs的性能，并指导LLMs训练数据的构建。

Abstract: Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for text-to-SQL classification based on dimensions including core intents, statement types, syntax structures, and key actions. Using this taxonomy, we evaluate widely used public text-to-SQL datasets (e.g., Spider and Bird) and reveal limitations in their coverage and diversity. We then introduce a taxonomy-guided dataset synthesis pipeline, yielding a new dataset named SQL-Synth. This approach combines the taxonomy with Large Language Models (LLMs) to ensure the dataset reflects the breadth and complexity of real-world text-to-SQL applications. Extensive analysis and experimental results validate the effectiveness of our taxonomy, as SQL-Synth exhibits greater diversity and coverage compared to existing benchmarks. Moreover, we uncover that existing LLMs typically fall short in adequately capturing the full range of scenarios, resulting in limited performance on SQL-Synth. However, fine-tuning can substantially improve their performance in these scenarios. The proposed taxonomy has significant potential impact, as it not only enables comprehensive analysis of datasets and the performance of different LLMs, but also guides the construction of training data for LLMs.

</details>


### [83] [Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents](https://arxiv.org/abs/2511.13593)
*Piaohong Wang,Motong Tian,Jiaxian Li,Yuan Liang,Yuqing Wang,Qianben Chen,Tiannan Wang,Zhicong Lu,Jiawei Ma,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: O-Mem是一个基于主动用户画像的新型记忆框架，通过动态提取和更新用户特征与事件记录来提升个性化AI助手的长期交互能力，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的代理在复杂环境中维持长期交互时面临上下文一致性和动态个性化挑战，传统记忆系统依赖语义分组检索，可能忽略语义无关但关键的用户信息并引入检索噪声。

Method: 提出O-Mem框架，基于主动用户画像动态提取和更新用户特征及事件记录，支持人物属性和主题相关上下文的分层检索，实现更自适应和连贯的个性化响应。

Result: 在LoCoMo基准上达到51.76%，比之前的SOTA LangMem提升近3%；在PERSONAMEM上达到62.99%，比之前的SOTA A-Mem提升3.5%；同时提升了token和交互响应时间效率。

Conclusion: O-Mem为开发高效且类人的个性化AI助手开辟了有前景的方向。

Abstract: Recent advancements in LLM-powered agents have demonstrated significant potential in generating human-like responses; however, they continue to face challenges in maintaining long-term interactions within complex environments, primarily due to limitations in contextual consistency and dynamic personalization. Existing memory systems often depend on semantic grouping prior to retrieval, which can overlook semantically irrelevant yet critical user information and introduce retrieval noise. In this report, we propose the initial design of O-Mem, a novel memory framework based on active user profiling that dynamically extracts and updates user characteristics and event records from their proactive interactions with agents. O-Mem supports hierarchical retrieval of persona attributes and topic-related context, enabling more adaptive and coherent personalized responses. O-Mem achieves 51.76% on the public LoCoMo benchmark, a nearly 3% improvement upon LangMem,the previous state-of-the-art, and it achieves 62.99% on PERSONAMEM, a 3.5% improvement upon A-Mem,the previous state-of-the-art. O-Mem also boosts token and interaction response time efficiency compared to previous memory frameworks. Our work opens up promising directions for developing efficient and human-like personalized AI assistants in the future.

</details>


### [84] [Why is "Chicago" Predictive of Deceptive Reviews? Using LLMs to Discover Language Phenomena from Lexical Cues](https://arxiv.org/abs/2511.13658)
*Jiaming Qu,Mengtian Guo,Yue Wang*

Main category: cs.CL

TL;DR: 使用大语言模型将机器学习检测到的欺骗性评论特征转化为人类可理解的语言现象，帮助人们在没有检测分类器的情况下评估在线评论的可信度。


<details>
  <summary>Details</summary>
Motivation: 欺骗性评论误导消费者、损害企业利益并破坏在线市场信任。虽然机器学习分类器能有效检测欺骗性评论，但其学习到的区分特征往往难以被人理解。

Method: 利用大语言模型将机器学习学到的词汇线索转化为人类可理解的语言现象，这些现象基于实证数据，在相似领域具有通用性。

Result: 通过这种方法获得的语言现象比大语言模型先验知识或上下文学习获得的现象更具预测性，且基于实证数据。

Conclusion: 这些语言现象有潜力帮助人们在缺乏欺骗检测分类器的环境中批判性评估在线评论的可信度。

Abstract: Deceptive reviews mislead consumers, harm businesses, and undermine trust in online marketplaces. Machine learning classifiers can learn from large amounts of training examples to effectively distinguish deceptive reviews from genuine ones. However, the distinguishing features learned by these classifiers are often subtle, fragmented, and difficult for humans to interpret. In this work, we explore using large language models (LLMs) to translate machine-learned lexical cues into human-understandable language phenomena that can differentiate deceptive reviews from genuine ones. We show that language phenomena obtained in this manner are empirically grounded in data, generalizable across similar domains, and more predictive than phenomena either in LLMs' prior knowledge or obtained through in-context learning. These language phenomena have the potential to aid people in critically assessing the credibility of online reviews in environments where deception detection classifiers are unavailable.

</details>


### [85] [Crossing Borders: A Multimodal Challenge for Indian Poetry Translation and Image Generation](https://arxiv.org/abs/2511.13689)
*Sofia Jamil,Kotla Sai Charan,Sriparna Saha,Koustava Goswami,Joseph K J*

Main category: cs.CL

TL;DR: 提出了TAI框架，利用LLM和潜在扩散模型通过提示调优来翻译和生成印度诗歌图像，提升印度语言诗歌的全球可访问性。


<details>
  <summary>Details</summary>
Motivation: 印度诗歌具有语言复杂性和文化深度，但现有研究大多忽视印度语言诗歌，其多层含义和文化典故对非母语读者构成理解挑战。

Method: 使用TAI框架，包括：(1) 翻译模块采用几率比偏好对齐算法准确翻译形态丰富的诗歌；(2) 图像生成模块使用语义图捕捉标记、依赖关系和隐喻语义关系，创建诗歌的视觉表示。

Result: 综合实验评估显示TAI Diffusion在诗歌图像生成任务中优于强基线方法，并构建了包含21种低资源印度语言的1,570首诗歌的MorphoVerse数据集。

Conclusion: 通过解决诗歌翻译和视觉理解方面的空白，该工作旨在扩大可访问性并丰富读者的体验，支持联合国可持续发展目标。

Abstract: Indian poetry, known for its linguistic complexity and deep cultural resonance, has a rich and varied heritage spanning thousands of years. However, its layered meanings, cultural allusions, and sophisticated grammatical constructions often pose challenges for comprehension, especially for non-native speakers or readers unfamiliar with its context and language. Despite its cultural significance, existing works on poetry have largely overlooked Indian language poems. In this paper, we propose the Translation and Image Generation (TAI) framework, leveraging Large Language Models (LLMs) and Latent Diffusion Models through appropriate prompt tuning. Our framework supports the United Nations Sustainable Development Goals of Quality Education (SDG 4) and Reduced Inequalities (SDG 10) by enhancing the accessibility of culturally rich Indian-language poetry to a global audience. It includes (1) a translation module that uses an Odds Ratio Preference Alignment Algorithm to accurately translate morphologically rich poetry into English, and (2) an image generation module that employs a semantic graph to capture tokens, dependencies, and semantic relationships between metaphors and their meanings, to create visually meaningful representations of Indian poems. Our comprehensive experimental evaluation, including both human and quantitative assessments, demonstrates the superiority of TAI Diffusion in poem image generation tasks, outperforming strong baselines. To further address the scarcity of resources for Indian-language poetry, we introduce the Morphologically Rich Indian Language Poems MorphoVerse Dataset, comprising 1,570 poems across 21 low-resource Indian languages. By addressing the gap in poetry translation and visual comprehension, this work aims to broaden accessibility and enrich the reader's experience.

</details>


### [86] [Generalist Foundation Models Are Not Clinical Enough for Hospital Operations](https://arxiv.org/abs/2511.13703)
*Lavender Y. Jiang,Angelica Chen,Xu Han,Xujin Chris Liu,Radhika Dua,Kevin Eaton,Frederick Wolff,Robert Steele,Jeff Zhang,Anton Alyakin,Qingkai Pan,Yanbing Chen,Karl L. Sangwon,Daniel A. Alber,Jaden Stryker,Jin Vivian Lee,Yindalon Aphinyanaphongs,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: Lang1是一个专门针对医疗操作决策的模型系列，通过在EHR数据和互联网文本上预训练，在医疗任务上超越了通用模型，即使后者规模大70倍。


<details>
  <summary>Details</summary>
Motivation: 通用基础模型缺乏医疗操作决策所需的专业知识，而医院运营决策对患者流程、成本和质量至关重要。

Method: 开发Lang1模型系列(100M-7B参数)，在NYU Langone Health的800亿临床token和6270亿互联网token混合语料上预训练，并使用ReMedE基准进行零样本和微调评估。

Result: 微调后的Lang1-1B在AUROC上比微调通用模型提升3.64%-6.75%，比零样本模型提升1.66%-23.66%，且能有效迁移到外部医疗系统。

Conclusion: 医疗系统AI需要领域内预训练、监督微调和真实世界评估的结合，专业LLM在专业任务上可与通用模型竞争。

Abstract: Hospitals and healthcare systems rely on operational decisions that determine patient flow, cost, and quality of care. Despite strong performance on medical knowledge and conversational benchmarks, foundation models trained on general text may lack the specialized knowledge required for these operational decisions. We introduce Lang1, a family of models (100M-7B parameters) pretrained on a specialized corpus blending 80B clinical tokens from NYU Langone Health's EHRs and 627B tokens from the internet. To rigorously evaluate Lang1 in real-world settings, we developed the REalistic Medical Evaluation (ReMedE), a benchmark derived from 668,331 EHR notes that evaluates five critical tasks: 30-day readmission prediction, 30-day mortality prediction, length of stay, comorbidity coding, and predicting insurance claims denial. In zero-shot settings, both general-purpose and specialized models underperform on four of five tasks (36.6%-71.7% AUROC), with mortality prediction being an exception. After finetuning, Lang1-1B outperforms finetuned generalist models up to 70x larger and zero-shot models up to 671x larger, improving AUROC by 3.64%-6.75% and 1.66%-23.66% respectively. We also observed cross-task scaling with joint finetuning on multiple tasks leading to improvement on other tasks. Lang1-1B effectively transfers to out-of-distribution settings, including other clinical tasks and an external health system. Our findings suggest that predictive capabilities for hospital operations require explicit supervised finetuning, and that this finetuning process is made more efficient by in-domain pretraining on EHR. Our findings support the emerging view that specialized LLMs can compete with generalist models in specialized tasks, and show that effective healthcare systems AI requires the combination of in-domain pretraining, supervised finetuning, and real-world evaluation beyond proxy benchmarks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [87] [Hierarchical Federated Graph Attention Networks for Scalable and Resilient UAV Collision Avoidance](https://arxiv.org/abs/2511.11616)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.RO

TL;DR: 提出了一种分层框架来解决大规模多无人机系统中的实时性能、对抗弹性和隐私保护平衡问题，通过三层架构实现可扩展的碰撞避免。


<details>
  <summary>Details</summary>
Motivation: 现有框架存在计算复杂度高（O(n²)）且缺乏拜占庭容错的问题，需要在实时性能、对抗弹性和隐私保护之间找到平衡。

Method: 采用三层架构：本地层使用密集图注意力（延迟<10ms），区域层使用稀疏注意力（O(nk)复杂度）和异步联邦学习，全局层使用轻量级Hashgraph协议，并引入自适应差分隐私机制。

Result: 在500架无人机规模下，碰撞率<2.0%，95%百分位决策延迟<50ms，拜占庭容错f < n/3，隐私-效用权衡得到优化。

Conclusion: 该分层框架成功消除了传统方案中的权衡问题，实现了大规模多无人机系统的高效、安全和隐私保护。

Abstract: The real-time performance, adversarial resiliency, and privacy preservation are the most important metrics that need to be balanced to practice collision avoidance in large-scale multi-UAV (Unmanned Aerial Vehicle) systems. Current frameworks tend to prescribe monolithic solutions that are not only prohibitively computationally complex with a scaling cost of $O(n^2)$ but simply do not offer Byzantine fault tolerance. The proposed hierarchical framework presented in this paper tries to eliminate such trade-offs by stratifying a three-layered architecture. We spread the intelligence into three layers: an immediate collision avoiding local layer running on dense graph attention with latency of $<10 ms$, a regional layer using sparse attention with $O(nk)$ computational complexity and asynchronous federated learning with coordinate-wise trimmed mean aggregation, and lastly, a global layer using a lightweight Hashgraph-inspired protocol. We have proposed an adaptive differential privacy mechanism, wherein the noise level $(ε\in [0.1, 1.0])$ is dynamically reduced based on an evaluation of the measured real-time threat that in turn maximized the privacy-utility tradeoff. Through the use of Distributed Hash Table (DHT)-based lightweight audit logging instead of heavyweight blockchain consensus, the median cost of getting a $95^{th}$ percentile decision within 50ms is observed across all tested swarm sizes. This architecture provides a scalable scenario of 500 UAVs with a collision rate of $< 2.0\%$ and the Byzantine fault tolerance of $f < n/3$.

</details>


### [88] [Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding](https://arxiv.org/abs/2511.11634)
*Michikuni Eguchi,Takekazu Kitagishi,Yuichi Hiroi,Takefumi Hiraki*

Main category: cs.RO

TL;DR: 提出了一种基于机械臂的系统，用于从完整服装中收集触觉数据，通过模拟指尖滑动测量来创建带运动标签的多模态触觉数据库。


<details>
  <summary>Details</summary>
Motivation: 服装的触觉感受对穿着舒适度至关重要，需要系统性地收集滑动运动中的触觉数据来揭示影响舒适度的物理特性。

Method: 使用机械臂系统进行滑动测量，模拟指尖触摸，精确控制速度和方向，创建带运动标签的多模态触觉数据库。

Result: 机器学习评估显示，包含运动相关参数提高了音频和加速度数据的识别准确率，证明了运动相关标签在表征服装触觉感受方面的有效性。

Conclusion: 该系统提供了一种可扩展、非破坏性的服装触觉数据采集方法，为未来织物感知和再现研究做出贡献。

Abstract: The tactile sensation of clothing is critical to wearer comfort. To reveal physical properties that make clothing comfortable, systematic collection of tactile data during sliding motion is required. We propose a robotic arm-based system for collecting tactile data from intact garments. The system performs stroking measurements with a simulated fingertip while precisely controlling speed and direction, enabling creation of motion-labeled, multimodal tactile databases. Machine learning evaluation showed that including motion-related parameters improved identification accuracy for audio and acceleration data, demonstrating the efficacy of motion-related labels for characterizing clothing tactile sensation. This system provides a scalable, non-destructive method for capturing tactile data of clothing, contributing to future studies on fabric perception and reproduction.

</details>


### [89] [Image-based Morphological Characterization of Filamentous Biological Structures with Non-constant Curvature Shape Feature](https://arxiv.org/abs/2511.11639)
*Jie Fan,Francesco Visentin,Barbara Mazzolai,Emanuela Del Dottore*

Main category: cs.RO

TL;DR: 提出了一种基于图像的几何方法，使用3D分段回旋曲线模型来重建触须在机械刺激后的形状变化，揭示了触须顶端区域具有更高的响应性。


<details>
  <summary>Details</summary>
Motivation: 尽管攀援植物已被研究很长时间，但提取时间形状变化、触发事件和接触位置之间的关系仍然具有挑战性。需要建立这种关系来理解植物生物力学。

Method: 采用基于图像的几何方法，使用3D分段回旋曲线模型来重建触须在机械刺激后的配置。该方法相比深度学习方法具有数据需求少、计算成本低和可解释性的优势。

Result: 重建显示出高鲁棒性和可靠性，准确度R2 > 0.99。分析显示触须顶端段具有更高的响应性，可能对应于该区域更高的敏感性和组织灵活性。

Conclusion: 该研究为获得植物生物力学新见解提供了方法学，并为设计和开发受攀援植物启发的新型智能机器人系统奠定了基础。

Abstract: Tendrils coil their shape to anchor the plant to supporting structures, allowing vertical growth toward light. Although climbing plants have been studied for a long time, extracting information regarding the relationship between the temporal shape change, the event that triggers it, and the contact location is still challenging. To help build this relation, we propose an image-based method by which it is possible to analyze shape changes over time in tendrils when mechano-stimulated in different portions of their body. We employ a geometric approach using a 3D Piece-Wise Clothoid-based model to reconstruct the configuration taken by a tendril after mechanical rubbing. The reconstruction shows high robustness and reliability with an accuracy of R2 > 0.99. This method demonstrates distinct advantages over deep learning-based approaches, including reduced data requirements, lower computational costs, and interpretability. Our analysis reveals higher responsiveness in the apical segment of tendrils, which might correspond to higher sensitivity and tissue flexibility in that region of the organs. Our study provides a methodology for gaining new insights into plant biomechanics and offers a foundation for designing and developing novel intelligent robotic systems inspired by climbing plants.

</details>


### [90] [ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts](https://arxiv.org/abs/2511.11740)
*Haowen Jiang,Xinyu Huang,You Lu,Dingji Wang,Yuheng Cao,Chaofeng Sha,Bihuan Chen,Keyu Chen,Xin Peng*

Main category: cs.RO

TL;DR: 提出ExpertAD框架，通过混合专家架构提升自动驾驶系统性能，减少碰撞率20%和推理延迟25%，在复杂场景中展现强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统面临挑战：复杂场景语义信息丰富但可能模糊或嘈杂，多任务干扰影响规划效果，推理延迟增加安全风险。

Method: 采用混合专家架构，引入感知适配器增强任务关键特征，使用稀疏专家混合最小化任务干扰，实现高效规划。

Result: 相比现有方法，碰撞率降低20%，推理延迟减少25%，在罕见场景和未见城市环境中展现强泛化能力。

Conclusion: ExpertAD框架有效解决了自动驾驶系统中的语义模糊、任务干扰和延迟问题，提升了决策可靠性和安全性。

Abstract: Recent advancements in end-to-end autonomous driving systems (ADSs) underscore their potential for perception and planning capabilities. However, challenges remain. Complex driving scenarios contain rich semantic information, yet ambiguous or noisy semantics can compromise decision reliability, while interference between multiple driving tasks may hinder optimal planning. Furthermore, prolonged inference latency slows decision-making, increasing the risk of unsafe driving behaviors. To address these challenges, we propose ExpertAD, a novel framework that enhances the performance of ADS with Mixture of Experts (MoE) architecture. We introduce a Perception Adapter (PA) to amplify task-critical features, ensuring contextually relevant scene understanding, and a Mixture of Sparse Experts (MoSE) to minimize task interference during prediction, allowing for effective and efficient planning. Our experiments show that ExpertAD reduces average collision rates by up to 20% and inference latency by 25% compared to prior methods. We further evaluate its multi-skill planning capabilities in rare scenarios (e.g., accidents, yielding to emergency vehicles) and demonstrate strong generalization to unseen urban environments. Additionally, we present a case study that illustrates its decision-making process in complex driving scenarios.

</details>


### [91] [Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy: A Review](https://arxiv.org/abs/2511.11777)
*Vinit Mehta,Charu Sharma,Karthick Thiyagarajan*

Main category: cs.RO

TL;DR: 这篇综述论文分析了LLMs与3D视觉融合在机器人感知技术中的最新进展、应用和挑战，重点关注场景理解、文本到3D生成、物体定位和多模态集成等关键技术。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和机器人技术的快速发展，将大型语言模型与3D视觉相结合正在成为提升机器人感知能力的变革性方法，旨在弥合语言智能与空间感知之间的差距。

Method: 首先介绍LLMs和3D数据表示的基础原理，深入分析机器人关键的3D感知技术，然后探讨场景理解、文本到3D生成、物体定位和具身智能体等关键进展，包括零样本3D分割、动态场景合成和语言引导操作等前沿技术。

Result: 论文系统梳理了多模态LLMs如何整合3D数据与触觉、听觉和热输入，增强环境理解和机器人决策能力，并整理了专门针对3D-语言和视觉任务的基准数据集和评估指标。

Conclusion: 确定了关键挑战和未来研究方向，包括自适应模型架构、增强跨模态对齐和实时处理能力，为更智能、上下文感知和自主的机器人感知系统铺平道路。

Abstract: With the rapid advancement of artificial intelligence and robotics, the integration of Large Language Models (LLMs) with 3D vision is emerging as a transformative approach to enhancing robotic sensing technologies. This convergence enables machines to perceive, reason and interact with complex environments through natural language and spatial understanding, bridging the gap between linguistic intelligence and spatial perception. This review provides a comprehensive analysis of state-of-the-art methodologies, applications and challenges at the intersection of LLMs and 3D vision, with a focus on next-generation robotic sensing technologies. We first introduce the foundational principles of LLMs and 3D data representations, followed by an in-depth examination of 3D sensing technologies critical for robotics. The review then explores key advancements in scene understanding, text-to-3D generation, object grounding and embodied agents, highlighting cutting-edge techniques such as zero-shot 3D segmentation, dynamic scene synthesis and language-guided manipulation. Furthermore, we discuss multimodal LLMs that integrate 3D data with touch, auditory and thermal inputs, enhancing environmental comprehension and robotic decision-making. To support future research, we catalog benchmark datasets and evaluation metrics tailored for 3D-language and vision tasks. Finally, we identify key challenges and future research directions, including adaptive model architectures, enhanced cross-modal alignment and real-time processing capabilities, which pave the way for more intelligent, context-aware and autonomous robotic sensing systems.

</details>


### [92] [LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles](https://arxiv.org/abs/2511.11840)
*Shuangyu Xie,Kaiyuan Chen,Wenjing Chen,Chengyuan Qian,Christian Juette,Liu Ren,Dezhen Song,Ken Goldberg*

Main category: cs.RO

TL;DR: LAVQA是一个延迟感知的共享自治框架，通过视觉问答和时空风险可视化来应对自动驾驶中的网络延迟和人类响应时间问题，能够显著降低碰撞率


<details>
  <summary>Details</summary>
Motivation: 当不确定性较高时，自动驾驶车辆可能需要远程人类操作员提供高级指导，但无线网络延迟和人类响应时间会影响关键决策时机

Method: 提出LAVQA框架，整合视觉问答和时空风险可视化，使用LICOM（延迟诱导碰撞地图）动态表示时间延迟和空间不确定性

Result: 在CARLA模拟器中的闭环仿真表明，与不考虑延迟的基线方法相比，LAVQA能将碰撞率降低8倍以上

Conclusion: LAVQA通过延迟感知的共享自治方法有效解决了自动驾驶中延迟带来的安全问题，显著提升了系统安全性

Abstract: When uncertainty is high, self-driving vehicles may halt for safety and benefit from the access to remote human operators who can provide high-level guidance. This paradigm, known as {shared autonomy}, enables autonomous vehicle and remote human operators to jointly formulate appropriate responses. To address critical decision timing with variable latency due to wireless network delays and human response time, we present LAVQA, a latency-aware shared autonomy framework that integrates Visual Question Answering (VQA) and spatiotemporal risk visualization. LAVQA augments visual queries with Latency-Induced COllision Map (LICOM), a dynamically evolving map that represents both temporal latency and spatial uncertainty. It enables remote operator to observe as the vehicle safety regions vary over time in the presence of dynamic obstacles and delayed responses. Closed-loop simulations in CARLA, the de-facto standard for autonomous vehicle simulator, suggest that that LAVQA can reduce collision rates by over 8x compared to latency-agnostic baselines.

</details>


### [93] [Autonomous Underwater Cognitive System for Adaptive Navigation: A SLAM-Integrated Cognitive Architecture](https://arxiv.org/abs/2511.11845)
*K. A. I. N Jayarathne,R. M. N. M. Rathnayaka,D. P. S. S. Peiris*

Main category: cs.RO

TL;DR: 提出了一种集成SLAM与Soar认知架构的自主水下认知系统(AUCS)，通过多传感器数据融合和认知推理模块实现复杂海洋环境下的自适应导航。


<details>
  <summary>Details</summary>
Motivation: 解决深海探索中的迷失方向、通信中断和导航失败等挑战，提升水下自主航行器的安全性和可靠性。

Method: 融合SONAR、LiDAR、IMU和DVL等多传感器数据，结合Soar认知架构的感知、注意、规划和学习模块，实现语义理解、自适应传感器管理和基于记忆的学习。

Result: 系统能够区分动态和静态物体，减少错误闭环检测，增强长期地图一致性，展示了完整的感知-认知-行动-学习循环。

Conclusion: 为下一代认知潜水系统奠定了基础，提高了深海探索的安全性、可靠性和自主性。

Abstract: Deep-sea exploration poses significant challenges, including disorientation, communication loss, and navigational failures in dynamic underwater environments. This paper presents an Autonomous Underwater Cognitive System (AUCS) that integrates Simultaneous Localization and Mapping (SLAM) with a Soar-based cognitive architecture to enable adaptive navigation in complex oceanic conditions. The system fuses multi-sensor data from SONAR, LiDAR, IMU, and DVL with cognitive reasoning modules for perception, attention, planning, and learning. Unlike conventional SLAM systems, AUCS incorporates semantic understanding, adaptive sensor management, and memory-based learning to differentiate between dynamic and static objects, reducing false loop closures and enhancing long-term map consistency. The proposed architecture demonstrates a complete perception-cognition-action-learning loop, allowing autonomous underwater vehicles to sense, reason, and adapt intelligently. This work lays a foundation for next-generation cognitive submersible systems, improving safety, reliability, and autonomy in deep-sea exploration.

</details>


### [94] [MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy](https://arxiv.org/abs/2511.11931)
*Saida Liu,Nikolay Atanasov,Shumon Koga*

Main category: cs.RO

TL;DR: MATT-Diff是一种基于扩散策略的多模态主动目标跟踪控制方法，能够同时处理探索、专用跟踪和目标重捕获等多种行为模式，无需目标数量、状态或动态的先验知识。


<details>
  <summary>Details</summary>
Motivation: 有效的目标跟踪需要在探索未检测或丢失目标与跟踪已检测但不确定目标之间取得平衡，现有方法难以同时处理这些不同行为模式。

Method: 使用三种专家规划器生成演示数据集，设计基于视觉变换器的控制策略进行自我中心地图标记化，通过注意力机制整合可变目标估计，并作为扩散模型训练以生成多模态动作序列。

Result: 评估显示MATT-Diff在多种目标运动场景下优于专家和行为克隆基线方法，在目标跟踪方面表现出优越性能。

Conclusion: MATT-Diff通过扩散策略成功实现了多模态主动目标跟踪，验证了其在处理探索、跟踪和重捕获等复杂行为方面的优势。

Abstract: This paper proposes MATT-Diff: Multi-Modal Active Target Tracking by Diffusion Policy, a control policy that captures multiple behavioral modes - exploration, dedicated tracking, and target reacquisition - for active multi-target tracking. The policy enables agent control without prior knowledge of target numbers, states, or dynamics. Effective target tracking demands balancing exploration for undetected or lost targets with following the motion of detected but uncertain ones. We generate a demonstration dataset from three expert planners including frontier-based exploration, an uncertainty-based hybrid planner switching between frontier-based exploration and RRT* tracking based on target uncertainty, and a time-based hybrid planner switching between exploration and tracking based on target detection time. We design a control policy utilizing a vision transformer for egocentric map tokenization and an attention mechanism to integrate variable target estimates represented by Gaussian densities. Trained as a diffusion model, the policy learns to generate multi-modal action sequences through a denoising process. Evaluations demonstrate MATT-Diff's superior tracking performance against expert and behavior cloning baselines across multiple target motions, empirically validating its advantages in target tracking.

</details>


### [95] [Characterization and Evaluation of Screw-Based Locomotion Across Aquatic, Granular, and Transitional Media](https://arxiv.org/abs/2511.11958)
*Derek Chen,Zoe Samuels,Lizzie Peiros,Sujaan Mukherjee,Michael C. Yip*

Main category: cs.RO

TL;DR: 对螺旋推进系统在不同介质中的运动性能进行系统性研究，发现特定参数对性能有主导影响，并基于热沉设计优化思路提出了性能分类方法。


<details>
  <summary>Details</summary>
Motivation: 螺旋推进系统在实现水陆两栖机动性方面具有潜力，但在优化水、颗粒材料和过渡环境中的运动性能方面面临挑战。

Method: 采用原理优先方法分析螺旋性能，研究不同螺旋配置在干沙、湿沙、饱和沙和水等介质中的运动性能。

Result: 发现某些参数在不同介质中对性能有主导影响，基于热沉设计优化的衍生参数有助于在主导设计参数内对性能进行分类。

Conclusion: 研究结果为螺旋壳体设计和自适应运动策略提供了具体见解，可提升螺旋推进系统在多功能水陆两栖应用中的性能。

Abstract: Screw-based propulsion systems offer promising capabilities for amphibious mobility, yet face significant challenges in optimizing locomotion across water, granular materials, and transitional environments. This study presents a systematic investigation into the locomotion performance of various screw configurations in media such as dry sand, wet sand, saturated sand, and water. Through a principles-first approach to analyze screw performance, it was found that certain parameters are dominant in their impact on performance. Depending on the media, derived parameters inspired from optimizing heat sink design help categorize performance within the dominant design parameters. Our results provide specific insights into screw shell design and adaptive locomotion strategies to enhance the performance of screw-based propulsion systems for versatile amphibious applications.

</details>


### [96] [Bootstrapped LLM Semantics for Context-Aware Path Planning](https://arxiv.org/abs/2511.11967)
*Mani Amani,Behrad Beheshti,Reza Akhavian*

Main category: cs.RO

TL;DR: 该论文提出了一种将大语言模型转化为随机语义传感器的框架，通过LLM的危险判断来调制经典路径规划器，使机器人能够根据自然语言提示和语义信息安全高效地在人类中心环境中移动。


<details>
  <summary>Details</summary>
Motivation: 解决现有自然语言机器人控制主要关注任务选择而非执行安全性的问题，特别是在语义丰富的人类中心空间中如何安全高效地执行任务。

Method: 使用LLM生成多个危险判断，应用贝叶斯自举法近似每个类别的风险后验分布，基于后验统计创建势能成本来制定路径规划问题。

Result: 在模拟环境和BIM数字孪生中，该方法能够根据显式提示和隐式上下文信息自适应调整机器人移动方式，提供了定性和定量结果。

Conclusion: 该框架成功地将LLM转化为语义传感器，使机器人能够在复杂的人类中心环境中进行安全高效的路径规划。

Abstract: Prompting robots with natural language (NL) has largely been studied as what task to execute (goal selection, skill sequencing) rather than how to execute that task safely and efficiently in semantically rich, human-centric spaces. We address this gap with a framework that turns a large language model (LLM) into a stochastic semantic sensor whose outputs modulate a classical planner. Given a prompt and a semantic map, we draw multiple LLM "danger" judgments and apply a Bayesian bootstrap to approximate a posterior over per-class risk. Using statistics from the posterior, we create a potential cost to formulate a path planning problem. Across simulated environments and a BIM-backed digital twin, our method adapts how the robot moves in response to explicit prompts and implicit contextual information. We present qualitative and quantitative results.

</details>


### [97] [ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot](https://arxiv.org/abs/2511.11970)
*Sara Wickenhiser,Lizzie Peiros,Calvin Joyce,Peter Gavrilrov,Sujaan Mukherjee,Syler Sylvester,Junrong Zhou,Mandy Cheung,Jason Lim,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: ARCSnake V2是一个两栖螺旋推进蛇形机器人，结合了高机动性蛇形机器人和阿基米德螺旋推进的地形适应性，能在陆地、颗粒介质和水环境中实现螺旋、轮式和侧向滑行等多种运动模式。


<details>
  <summary>Details</summary>
Motivation: 传统轮式或腿式机器人在洞穴、海洋和行星表面等极端环境的地形多样性中移动困难，需要开发更适应多变地形的机器人平台。

Method: 采用水密封机械设计，结合串联螺旋和关节驱动，集成浮力控制系统，通过运动学匹配的手持控制器进行遥操作，支持多种运动模式的平滑切换。

Result: 实验验证了其水下机动性、通信鲁棒性和力调节驱动能力，展示了在多领域环境中的有效移动性能。

Conclusion: ARCSnake V2作为一个多域平台，在探索、搜救和环境监测等应用中具有广阔前景。

Abstract: Robotic exploration in extreme environments such as caves, oceans, and planetary surfaces pose significant challenges, particularly in locomotion across diverse terrains. Conventional wheeled or legged robots often struggle in these contexts due to surface variability. This paper presents ARCSnake V2, an amphibious, screw propelled, snake like robot designed for teleoperated or autonomous locomotion across land, granular media, and aquatic environments. ARCSnake V2 combines the high mobility of hyper redundant snake robots with the terrain versatility of Archimedean screw propulsion. Key contributions include a water sealed mechanical design with serially linked screw and joint actuation, an integrated buoyancy control system, and teleoperation via a kinematically matched handheld controller. The robots design and control architecture enable multiple locomotion modes screwing, wheeling, and sidewinding with smooth transitions between them. Extensive experiments validate its underwater maneuverability, communication robustness, and force regulated actuation. These capabilities position ARCSnake V2 as a versatile platform for exploration, search and rescue, and environmental monitoring in multi domain settings.

</details>


### [98] [SBAMP: Sampling Based Adaptive Motion Planning](https://arxiv.org/abs/2511.12022)
*Anh-Quan Pham,Kabir Ram Puri,Shreyas Raorane*

Main category: cs.RO

TL;DR: SBAMP结合RRT*全局路径规划和SEDS局部控制器，实现无需预训练数据的自适应运动规划，在动态环境中保持实时适应性和路径最优性。


<details>
  <summary>Details</summary>
Motivation: 传统采样方法如RRT*难以适应动态变化，而学习型动态系统如SEDS依赖预收集数据且泛化能力有限，需要一种能兼顾全局规划和实时适应的新方法。

Method: 集成RRT*进行全局路径规划，使用SEDS基的局部控制器进行连续自适应轨迹调整，无需预训练数据集，通过Lyapunov保证稳定性。

Result: 在模拟环境和RoboRacer平台上验证，SBAMP在动态障碍场景、扰动恢复和急转弯处理方面表现优异，实时适应性强且不牺牲全局路径最优性。

Conclusion: SBAMP为动态非结构化环境提供了可扩展的解决方案，成功结合了采样方法和学习型系统的优势。

Abstract: Autonomous robotic systems must navigate complex, dynamic environments in real time, often facing unpredictable obstacles and rapidly changing conditions. Traditional sampling-based methods, such as RRT*, excel at generating collision-free paths but struggle to adapt to sudden changes without extensive replanning. Conversely, learning-based dynamical systems, such as the Stable Estimator of Dynamical Systems (SEDS), offer smooth, adaptive trajectory tracking but typically rely on pre-collected demonstration data, limiting their generalization to novel scenarios. This paper introduces Sampling-Based Adaptive Motion Planning (SBAMP), a novel framework that overcomes these limitations by integrating RRT* for global path planning with a SEDS-based local controller for continuous, adaptive trajectory adjustment. Our approach requires no pre-trained datasets and ensures smooth transitions between planned waypoints, maintaining stability through Lyapunov-based guarantees. We validate SBAMP in both simulated environments and real hardware using the RoboRacer platform, demonstrating superior performance in dynamic obstacle scenarios, rapid recovery from perturbations, and robust handling of sharp turns. Experimental results highlight SBAMP's ability to adapt in real time without sacrificing global path optimality, providing a scalable solution for dynamic, unstructured environments.

</details>


### [99] [Decoupled Action Head: Confining Task Knowledge to Conditioning Layers](https://arxiv.org/abs/2511.12101)
*Jian Zhou,Sihao Lin,Shuai Fu,Qi WU*

Main category: cs.RO

TL;DR: 本文提出了一种解耦训练方法，利用低成本的运动学生成轨迹预训练通用动作头，然后通过特征调制适应新任务。该方法提高了训练效率，并揭示了动作生成主干在机器人操作中作用有限，进而提出了参数更少的DP-MLP模型。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法如Diffusion Policy受限于配对训练数据的稀缺性，且其内部机制理解不足，导致泛化能力有限和模型设计缺乏原则性指导。

Method: 提出解耦训练方法：使用运动学生成轨迹预训练通用动作头，然后冻结该动作头并通过特征调制适应新任务。基于动作主干作用有限的观察，进一步提出用简单MLP块替换U-Net主干的DP-MLP模型。

Result: 解耦训练在分布内和分布外场景均可行，DP-C实现41%训练加速。DP-MLP在正常训练下提速83.9%，解耦训练下提速89.1%，参数量从244M减少到4M。

Conclusion: 解耦训练方法有效提升训练效率，揭示了动作生成主干在机器人操作中作用有限，为更高效的模型设计提供了新思路。

Abstract: Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

</details>


### [100] [Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies](https://arxiv.org/abs/2511.12148)
*Advik Sinha,Akshay Arjun,Abhijit Das,Joyjit Mukherjee*

Main category: cs.RO

TL;DR: 使用NEAT算法为蛇形机器人开发资源高效的避障跟踪控制方案，通过进化神经网络生成动态步态参数，在密集障碍环境中实现高效路径跟踪。


<details>
  <summary>Details</summary>
Motivation: 在密集障碍环境中实现蛇形机器人的高效避障跟踪控制，同时保持计算资源效率，解决传统方法计算开销大的问题。

Method: 采用NEAT（增强拓扑神经进化）算法，以关节角度、连杆位置、头部位置和附近障碍物位置为输入，输出控制速度和航向的serpenoid步态频率和偏移角，通过LiDAR和传感器数据参数化奖励函数进行优化。

Result: 在PyBullet物理引擎仿真中验证，相比现有方法表现出优越性能，与最新的CBRL方法结果相当但计算开销显著降低。

Conclusion: 提出的NEAT框架在密集障碍环境中为蛇形机器人提供了计算高效的避障跟踪控制解决方案，特别适用于大型环境和多障碍场景。

Abstract: This work aims to develop a resource-efficient solution for obstacle-avoiding tracking control of a planar snake robot in a densely cluttered environment with obstacles. Particularly, Neuro-Evolution of Augmenting Topologies (NEAT) has been employed to generate dynamic gait parameters for the serpenoid gait function, which is implemented on the joint angles of the snake robot, thus controlling the robot on a desired dynamic path. NEAT is a single neural-network based evolutionary algorithm that is known to work extremely well when the input layer is of significantly higher dimension and the output layer is of a smaller size. For the planar snake robot, the input layer consists of the joint angles, link positions, head link position as well as obstacle positions in the vicinity. However, the output layer consists of only the frequency and offset angle of the serpenoid gait that control the speed and heading of the robot, respectively. Obstacle data from a LiDAR and the robot data from various sensors, along with the location of the end goal and time, are employed to parametrize a reward function that is maximized over iterations by selective propagation of superior neural networks. The implementation and experimental results showcase that the proposed approach is computationally efficient, especially for large environments with many obstacles. The proposed framework has been verified through a physics engine simulation study on PyBullet. The approach shows superior results to existing state-of-the-art methodologies and comparable results to the very recent CBRL approach with significantly lower computational overhead. The video of the simulation can be found here: https://sites.google.com/view/neatsnakerobot

</details>


### [101] [Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)](https://arxiv.org/abs/2511.12160)
*Wenbin Mai,Minghui Liwang,Xinlei Yi,Xiaoyu Xia,Seyyedali Hosseinalipour,Xianbin Wang*

Main category: cs.RO

TL;DR: 提出RE-DPG框架，将可达性分析与博弈论协调结合，解决多智能体在动态不确定环境中的运动规划问题，确保安全性、鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在动态不确定环境中复杂交互、随机扰动和模型不确定性带来的安全、鲁棒和可扩展运动规划挑战，特别是耦合决策的计算复杂性和主动安全保证需求。

Method: 采用可达性增强动态势博弈框架，将多智能体协调建模为动态势博弈，通过纳什均衡定义最优控制策略；开发邻域主导迭代最佳响应方案，基于迭代ε-最佳响应过程确保有限步收敛到ε-纳什均衡；集成多智能体前向可达集机制到成本函数中，显式建模不确定性传播并强制执行碰撞避免约束。

Result: 通过2D和3D环境的仿真和真实世界实验验证了RE-DPG在不同操作场景下的有效性。

Conclusion: RE-DPG框架成功整合了可达性分析与博弈论协调，为多智能体系统在动态不确定环境中提供了安全、可扩展的运动规划解决方案。

Abstract: Ensuring safe, robust, and scalable motion planning for multi-agent systems in dynamic and uncertain environments is a persistent challenge, driven by complex inter-agent interactions, stochastic disturbances, and model uncertainties. To overcome these challenges, particularly the computational complexity of coupled decision-making and the need for proactive safety guarantees, we propose a Reachability-Enhanced Dynamic Potential Game (RE-DPG) framework, which integrates game-theoretic coordination into reachability analysis. This approach formulates multi-agent coordination as a dynamic potential game, where the Nash equilibrium (NE) defines optimal control strategies across agents. To enable scalability and decentralized execution, we develop a Neighborhood-Dominated iterative Best Response (ND-iBR) scheme, built upon an iterated $\varepsilon$-BR (i$\varepsilon$-BR) process that guarantees finite-step convergence to an $\varepsilon$-NE. This allows agents to compute strategies based on local interactions while ensuring theoretical convergence guarantees. Furthermore, to ensure safety under uncertainty, we integrate a Multi-Agent Forward Reachable Set (MA-FRS) mechanism into the cost function, explicitly modeling uncertainty propagation and enforcing collision avoidance constraints. Through both simulations and real-world experiments in 2D and 3D environments, we validate the effectiveness of RE-DPG across diverse operational scenarios.

</details>


### [102] [Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance](https://arxiv.org/abs/2511.12184)
*Jun Huo,Kehan Xu,Chengyao Li,Yu Cao,Jie Zuo,Xinxing Chen,Jian Huang*

Main category: cs.RO

TL;DR: 本文针对超数机器人腿系统提出了一种混合位置/力阻抗控制器和可变阻抗控制方法，通过动态调整阻抗参数来适应内外干扰，提高人机交互安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在浮基机器人系统中，确保力控制的安全性至关重要。超数机器人腿系统作为典型的松散耦合浮基系统，特别容易受到强内部干扰的影响，需要解决浮基带来的挑战。

Method: 研究了松散耦合SRL的动力学模型，设计了混合位置/力阻抗控制器来适应动态扭矩输入。开发了高效的变阻抗控制方法，通过动态调整阻抗参数来改善刚柔切换，并设计了实时稳定性保证的阻抗参数生成网络。

Result: 仿真和实验验证了系统的有效性，系统能够在柔性状态下保持平滑信号转换，在刚性状态下提供强力支撑，实现了冲击缓解和高刚性支撑。

Conclusion: 该方法为人机交互中个体步态变化提供了实用解决方案，显著提升了人机系统的安全性和适应性。

Abstract: In human-robot systems, ensuring safety during force control in the presence of both internal and external disturbances is crucial. As a typical loosely coupled floating-base robot system, the supernumerary robotic leg (SRL) system is particularly susceptible to strong internal disturbances. To address the challenge posed by floating base, we investigated the dynamics model of the loosely coupled SRL and designed a hybrid position/force impedance controller to fit dynamic torque input. An efficient variable impedance control (VIC) method is developed to enhance human-robot interaction, particularly in scenarios involving external force disturbances. By dynamically adjusting impedance parameters, VIC improves the dynamic switching between rigidity and flexibility, so that it can adapt to unknown environmental disturbances in different states. An efficient real-time stability guaranteed impedance parameters generating network is specifically designed for the proposed SRL, to achieve shock mitigation and high rigidity supporting. Simulations and experiments validate the system's effectiveness, demonstrating its ability to maintain smooth signal transitions in flexible states while providing strong support forces in rigid states. This approach provides a practical solution for accommodating individual gait variations in interaction, and significantly advances the safety and adaptability of human-robot systems.

</details>


### [103] [Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization](https://arxiv.org/abs/2511.12186)
*Jun Huo,Jian Huang,Jie Zuo,Bo Yang,Zhongzheng Fu,Xi Li,Samer Mohammed*

Main category: cs.RO

TL;DR: 提出了一种用于超数机器人肢体(SRL)的多目标优化设计理论，整合抓取工作空间相似性、行走工作空间相似性、坐站转换支撑力和整体质量惯性，通过椭圆体量化方法和改进的萤火虫算法优化设计，实验显示抓取成功率提升7.2%，肌肉活动度显著降低。


<details>
  <summary>Details</summary>
Motivation: 设计通用SRL设备具有挑战性，需要满足上下肢不同功能需求的统一理论框架，以在康复和功能增强应用中发挥潜力。

Method: 开发多目标优化设计理论，使用椭圆体表示工作空间以减少计算复杂度，引入多子群修正萤火虫算法处理高维不规则帕累托前沿，优化后重新设计原型进行实验验证。

Result: 与优化前相比，平均抓取成功率提高7.2%，行走和坐站转换任务中的肌肉活动度分别降低12.7%和25.1%。

Conclusion: 所提出的设计理论为多功能SRL机构设计提供了高效选择，验证了优化方法的有效性。

Abstract: Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this paper, we propose a multi-objective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multi-subpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the pre-optimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multi-functional SRL mechanisms.

</details>


### [104] [Locally Optimal Solutions to Constraint Displacement Problems via Path-Obstacle Overlaps](https://arxiv.org/abs/2511.12203)
*Antony Thomas,Fulvio Mastrogiovanni,Marco Baglietto*

Main category: cs.RO

TL;DR: 提出了一种统一的方法来解决约束位移问题，通过两阶段过程计算局部最优的障碍物位移，使机器人能够找到可行路径。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在存在障碍物或约束的环境中寻找可行路径的问题，通过位移约束或障碍物来创造可行路径。

Method: 两阶段方法：第一阶段计算通过障碍物的轨迹并最小化目标函数；第二阶段位移障碍物使机器人轨迹可行且无碰撞。

Result: 成功演示了该方法在两类约束位移问题上的应用，提供了多个示例。

Conclusion: 该方法能够有效解决约束位移问题，为机器人路径规划提供了一种新的解决方案。

Abstract: We present a unified approach for constraint displacement problems in which a robot finds a feasible path by displacing constraints or obstacles. To this end, we propose a two stage process that returns locally optimal obstacle displacements to enable a feasible path for the robot. The first stage proceeds by computing a trajectory through the obstacles while minimizing an appropriate objective function. In the second stage, these obstacles are displaced to make the computed robot trajectory feasible, that is, collision-free. Several examples are provided that successfully demonstrate our approach on two distinct classes of constraint displacement problems.

</details>


### [105] [SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation](https://arxiv.org/abs/2511.12232)
*Lingfeng Zhang,Erjia Xiao,Xiaoshuai Hao,Haoxiang Fu,Zeying Gong,Long Chen,Xiaojun Liang,Renjing Xu,Hangjun Ye,Wenbo Ding*

Main category: cs.RO

TL;DR: 提出了SocialNav-Map，一种零样本社交导航框架，结合动态人类轨迹预测和占据地图，无需环境特定训练即可实现安全高效导航。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的方法需要2000+小时训练，且难以泛化到陌生环境，限制了实际应用。

Method: 将任务目标位置转换到地图坐标系，创建包含预测人类运动的动态占据地图，使用历史预测和方向预测两种互补方法进行人类轨迹预测。

Result: 在Social-HM3D和Social-MP3D数据集上显著优于最先进的RL方法，减少人类碰撞率超过10%，无需新环境训练。

Conclusion: 通过消除环境特定训练需求，SocialNav-Map实现了优越的导航性能，为在现实世界环境中部署社交导航系统铺平了道路。

Abstract: Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

</details>


### [106] [Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration](https://arxiv.org/abs/2511.12237)
*Alysson Ribeiro da Silva,Luiz Chaimowicz*

Main category: cs.RO

TL;DR: 提出了一个多机器人探索通信约束和间歇连接问题（MRE-CCIC）的解决方案，包括MILP规划生成器和RTUS跟踪机制，在Gazebo仿真中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人探索中通信受限环境下的调度问题，特别是在未知环境中无法预先获取环境信息的情况，改进之前工作中无法生成最优计划和缺乏实际轨迹跟踪机制的问题。

Method: 使用混合整数线性规划（MILP）生成集合点计划，并基于RTUS（未知场景集合点跟踪）机制制定策略来跟踪计划，考虑未知环境条件。

Result: 在Gazebo仿真的大规模环境中评估，结果表明该方法能够及时跟踪计划并高效完成任务。

Conclusion: 提出的MILP规划生成器和RTUS跟踪机制能够有效解决MRE-CCIC问题，为实际部署提供了可行的解决方案。

Abstract: Multi-Robot Exploration (MRE) systems with communication constraints have proven efficient in accomplishing a variety of tasks, including search-and-rescue, stealth, and military operations. While some works focus on opportunistic approaches for efficiency, others concentrate on pre-planned trajectories or scheduling for increased interpretability. However, scheduling usually requires knowledge of the environment beforehand, which prevents its deployment in several domains due to related uncertainties (e.g., underwater exploration). In our previous work, we proposed an intermittent communications framework for MRE under communication constraints that uses scheduled rendezvous events to mitigate such limitations. However, the system was unable to generate optimal plans and had no mechanisms to follow the plan considering realistic trajectories, which is not suited for real-world deployments. In this work, we further investigate the problem by formulating the Multi-Robot Exploration with Communication Constraints and Intermittent Connectivity (MRE-CCIC) problem. We propose a Mixed-Integer Linear Program (MILP) formulation to generate rendezvous plans and a policy to follow them based on the Rendezvous Tracking for Unknown Scenarios (RTUS) mechanism. The RTUS is a simple rule to allow robots to follow the assigned plan, considering unknown conditions. Finally, we evaluated our method in a large-scale environment configured in Gazebo simulations. The results suggest that our method can follow the plan promptly and accomplish the task efficiently. We provide an open-source implementation of both the MILP plan generator and the large-scale MRE-CCIC.

</details>


### [107] [SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty](https://arxiv.org/abs/2511.12361)
*Leroy D'Souza,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 提出SAC-MoE方法，在Soft Actor-Critic框架中使用混合专家模型和自适应路由器来处理具有不可观测参数和模式切换的混合动力系统，通过课程学习策略提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 混合动力系统存在不可观测的潜在参数和模式切换事件，传统基于模型的控制方法无法处理这种不确定性，而标准无模型强化学习方法无法应对突然的模式切换，导致泛化能力差。

Method: 将SAC框架中的行动者建模为混合专家模型，包含学习到的路由器自适应选择专家；开发基于课程学习的训练算法，优先在挑战性场景中收集数据。

Result: 在混合自主赛车和腿式机器人运动任务中的仿真研究表明，SAC-MoE在零样本泛化到未见环境方面优于基线方法（最高达6倍），课程学习策略在所有评估策略中持续提升性能。

Conclusion: SAC-MoE能有效处理混合动力系统中的潜在模式不确定性，可解释的MoE路由器能为不同潜在模式激活不同专家，具有优异的泛化性能。

Abstract: Hybrid dynamical systems result from the interaction of continuous-variable dynamics with discrete events and encompass various systems such as legged robots, vehicles and aircrafts. Challenges arise when the system's modes are characterized by unobservable (latent) parameters and the events that cause system dynamics to switch between different modes are also unobservable. Model-based control approaches typically do not account for such uncertainty in the hybrid dynamics, while standard model-free RL methods fail to account for abrupt mode switches, leading to poor generalization.
  To overcome this, we propose SAC-MoE which models the actor of the Soft Actor-Critic (SAC) framework as a Mixture-of-Experts (MoE) with a learned router that adaptively selects among learned experts. To further improve robustness, we develop a curriculum-based training algorithm to prioritize data collection in challenging settings, allowing better generalization to unseen modes and switching locations. Simulation studies in hybrid autonomous racing and legged locomotion tasks show that SAC-MoE outperforms baselines (up to 6x) in zero-shot generalization to unseen environments. Our curriculum strategy consistently improves performance across all evaluated policies. Qualitative analysis shows that the interpretable MoE router activates different experts for distinct latent modes.

</details>


### [108] [Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots](https://arxiv.org/abs/2511.12380)
*Nicholas Gunter,Heiko Kabutz,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 开发多层PVDF压电致动器，在脆性高力PZT堆栈和柔顺但低带宽软聚合物致动器之间建立独特设计空间，实现了大位移、高力和高频性能。


<details>
  <summary>Details</summary>
Motivation: 多层PVDF压电致动器是提升软微机器人系统性能的有前景方法，旨在填补脆性高力PZT堆栈与柔顺但低带宽软聚合物致动器之间的设计空白。

Method: 开发多层PVDF致动器，采用并行电压分布设计，研究层厚度和层数对性能的影响，并与第一原理模型进行验证。

Result: 致动器实现了>3mm自由偏转、>20mN阻塞力和≥500Hz频率，工作电压低至150V。集成到平面移动微机器人中，利用共振实现运动并具有抗大扰动鲁棒性。

Conclusion: 多层PVDF致动器在性能参数上表现出色，成功应用于微机器人系统，展示了其在软机器人集成中的潜力。

Abstract: Multilayer piezoelectric polyvinylidene fluoride (PVDF) actuators are a promising approach to enhance performance of soft microrobotic systems. In this work, we develop and characterize multilayer PVDF actuators with parallel voltage distribution across each layer, bridging a unique design space between brittle high-force PZT stacks and compliant but lower-bandwidth soft polymer actuators. We show the effects of layer thickness and number of layers in actuator performance and their agreement with a first principles model. By varying these parameters, we demonstrate actuators capable of >3 mm of free deflection, >20 mN of blocked force, and >=500 Hz, while operating at voltages as low as 150 volts. To illustrate their potential for robotic integration, we integrate our actuators into a planar, translating microrobot that leverages resonance to achieve locomotion with robustness to large perturbations.

</details>


### [109] [Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks](https://arxiv.org/abs/2511.12383)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 本文评估了MAML-TRPO在MetaWorld ML10基准测试中的表现，展示了元学习在机器人操作任务中的单次适应能力，但也揭示了泛化差距和任务间性能差异大的问题。


<details>
  <summary>Details</summary>
Motivation: 元学习算法能够使机器人系统在少量数据下快速适应新任务，这对于现实世界的机器人应用至关重要。

Method: 结合模型无关元学习(MAML)和信任域策略优化(TRPO)，在包含10个不同机器人操作任务的MetaWorld ML10基准上进行评估。

Result: MAML实现了有效的单次适应，在训练任务上达到21.0%的成功率，测试任务上达到13.2%的成功率，但存在泛化差距，且不同操作技能的成功率差异很大（0%到80%）。

Conclusion: 基于梯度的元学习在多样化机器人操作中既有前景也有局限性，未来需要在任务感知适应和结构化策略架构方面进一步研究。

Abstract: Meta-learning algorithms enable rapid adaptation to new tasks with minimal data, a critical capability for real-world robotic systems. This paper evaluates Model-Agnostic Meta-Learning (MAML) combined with Trust Region Policy Optimization (TRPO) on the MetaWorld ML10 benchmark, a challenging suite of ten diverse robotic manipulation tasks. We implement and analyze MAML-TRPO's ability to learn a universal initialization that facilitates few-shot adaptation across semantically different manipulation behaviors including pushing, picking, and drawer manipulation. Our experiments demonstrate that MAML achieves effective one-shot adaptation with clear performance improvements after a single gradient update, reaching final success rates of 21.0% on training tasks and 13.2% on held-out test tasks. However, we observe a generalization gap that emerges during meta-training, where performance on test tasks plateaus while training task performance continues to improve. Task-level analysis reveals high variance in adaptation effectiveness, with success rates ranging from 0% to 80% across different manipulation skills. These findings highlight both the promise and current limitations of gradient-based meta-learning for diverse robotic manipulation, and suggest directions for future work in task-aware adaptation and structured policy architectures.

</details>


### [110] [Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control](https://arxiv.org/abs/2511.12390)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 提出基于学习的神经遥操作框架，用强化学习训练的策略替代传统逆运动学+PD控制器，直接映射VR控制器输入到机器人关节命令，在Unitree G1人形机器人上实现了更低的跟踪误差、更平滑的运动和更好的力适应能力。


<details>
  <summary>Details</summary>
Motivation: 传统遥操作系统依赖逆运动学求解器和手动调整的PD控制器，难以处理外力干扰、适应不同用户，在动态条件下无法产生自然运动。

Method: 使用强化学习训练策略，在仿真环境中用基于逆运动学的遥操作演示进行初始化，然后通过力随机化和轨迹平滑度奖励进行微调，直接学习从VR控制器输入到机器人关节命令的映射。

Result: 在Unitree G1人形机器人上的实验显示，学习策略相比逆运动学基线实现了34%更低的跟踪误差、45%更平滑的运动和更优的力适应能力，同时保持实时性能（50Hz控制频率）。

Conclusion: 基于学习的方法能显著提升人形机器人遥操作系统的自然性和鲁棒性。

Abstract: Virtual reality (VR) teleoperation has emerged as a promising approach for controlling humanoid robots in complex manipulation tasks. However, traditional teleoperation systems rely on inverse kinematics (IK) solvers and hand-tuned PD controllers, which struggle to handle external forces, adapt to different users, and produce natural motions under dynamic conditions. In this work, we propose a learning-based neural teleoperation framework that replaces the conventional IK+PD pipeline with learned policies trained via reinforcement learning. Our approach learns to directly map VR controller inputs to robot joint commands while implicitly handling force disturbances, producing smooth trajectories, and adapting to user preferences. We train our policies in simulation using demonstrations collected from IK-based teleoperation as initialization, then fine-tune them with force randomization and trajectory smoothness rewards. Experiments on the Unitree G1 humanoid robot demonstrate that our learned policies achieve 34% lower tracking error, 45% smoother motions, and superior force adaptation compared to the IK baseline, while maintaining real-time performance (50Hz control frequency). We validate our approach on manipulation tasks including object pick-and-place, door opening, and bimanual coordination. These results suggest that learning-based approaches can significantly improve the naturalness and robustness of humanoid teleoperation systems.

</details>


### [111] [RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation](https://arxiv.org/abs/2511.12436)
*Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Yanbiao Ma,Yunfeng Diao,Ziyu Jia,Wenbo Ding,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: 提出了RoboAfford++数据集和RoboAfford-Eval基准，用于解决视觉语言模型在物体和空间可操作性学习方面的不足，显著提升了机器人在操作和导航中的可操作性推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型虽然擅长高级任务规划和场景理解，但在推断物理交互的可操作位置（如功能性抓取点和允许放置区域）方面存在困难，这源于训练数据中缺乏细粒度的物体和空间可操作性标注。

Method: 构建了包含869,987张图像和200万问答标注的RoboAfford++数据集，涵盖物体可操作性识别、物体可操作性预测和空间可操作性定位三个关键任务，并提出了包含338个样本的RoboAfford-Eval评估基准。

Result: 实验结果表明现有视觉语言模型在可操作性学习方面存在缺陷，而在RoboAfford++数据集上微调后，模型在物体和空间可操作性推理能力方面得到显著提升。

Conclusion: RoboAfford++数据集有效解决了视觉语言模型在细粒度可操作性推理方面的局限性，为机器人操作和导航提供了重要的数据支持。

Abstract: Robotic manipulation and navigation are fundamental capabilities of embodied intelligence, enabling effective robot interactions with the physical world. Achieving these capabilities requires a cohesive understanding of the environment, including object recognition to localize target objects, object affordances to identify potential interaction areas and spatial affordances to discern optimal areas for both object placement and robot movement. While Vision-Language Models (VLMs) excel at high-level task planning and scene understanding, they often struggle to infer actionable positions for physical interaction, such as functional grasping points and permissible placement regions. This limitation stems from the lack of fine-grained annotations for object and spatial affordances in their training datasets. To tackle this challenge, we introduce RoboAfford++, a generative AI-enhanced dataset for multimodal affordance learning for both robotic manipulation and navigation. Our dataset comprises 869,987 images paired with 2.0 million question answering (QA) annotations, covering three critical tasks: object affordance recognition to identify target objects based on attributes and spatial relationships, object affordance prediction to pinpoint functional parts for manipulation, and spatial affordance localization to identify free space for object placement and robot navigation. Complementing this dataset, we propose RoboAfford-Eval, a comprehensive benchmark for assessing affordance-aware prediction in real-world scenarios, featuring 338 meticulously annotated samples across the same three tasks. Extensive experimental results reveal the deficiencies of existing VLMs in affordance learning, while fine-tuning on the RoboAfford++ dataset significantly enhances their ability to reason about object and spatial affordances, validating the dataset's effectiveness.

</details>


### [112] [ClutterNav: Gradient-Guided Search for Efficient 3D Clutter Removal with Learned Costmaps](https://arxiv.org/abs/2511.12479)
*Navin Sriram Ravie,Keerthi Vasan M,Bijo Sebastian*

Main category: cs.RO

TL;DR: ClutterNav是一个用于密集杂物中目标物体检索的决策框架，通过强化学习和可移除性评估来最小化堆栈扰动并减少物体移除数量。


<details>
  <summary>Details</summary>
Motivation: 解决密集杂物中目标物体检索的挑战，传统基于规则的规划器计算开销大，端到端强化学习方法可解释性和泛化性差。

Method: 将问题建模为连续强化学习任务，使用从演示中训练的可移除性评估器估计移除成本，结合积分梯度评估周围物体对目标可访问性的影响。

Result: 在仿真和真实实验中验证，实现了实时、遮挡感知的决策，在部分可观测环境中表现出接近人类水平的策略序列。

Conclusion: ClutterNav无需预定义启发式规则，能有效平衡即时可移除性和长期目标暴露，实现高效的杂物清理策略。

Abstract: Dense clutter removal for target object retrieval presents a challenging problem, especially when targets are embedded deep within densely-packed configurations. It requires foresight to minimize overall changes to the clutter configuration while accessing target objects, avoiding stack destabilization and reducing the number of object removals required. Rule-based planners when applied to this problem, rely on rigid heuristics, leading to high computational overhead. End-to-end reinforcement learning approaches struggle with interpretability and generalizability over different conditions. To address these issues, we present ClutterNav, a novel decision-making framework that can identify the next best object to be removed so as to access a target object in a given clutter, while minimising stack disturbances. ClutterNav formulates the problem as a continuous reinforcement learning task, where each object removal dynamically updates the understanding of the scene. A removability critic, trained from demonstrations, estimates the cost of removing any given object based on geometric and spatial features. This learned cost is complemented by integrated gradients that assess how the presence or removal of surrounding objects influences the accessibility of the target. By dynamically prioritizing actions that balance immediate removability against long-term target exposure, ClutterNav achieves near human-like strategic sequencing, without predefined heuristics. The proposed approach is validated extensively in simulation and over real-world experiments. The results demonstrate real-time, occlusion-aware decision-making in partially observable environments.

</details>


### [113] [Botany Meets Robotics in Alpine Scree Monitoring](https://arxiv.org/abs/2511.12526)
*Davide De Benedittis,Giovanni Di Lorenzo,Franco Angelini,Barbara Valle,Marina Serena Borgatti,Paolo Remagnino,Marco Caccianiga,Manolo Garabini*

Main category: cs.RO

TL;DR: 本文提出了一种使用腿式机器人监测碎石栖息地的新方法，通过部署ANYmal C机器人在意大利阿尔卑斯山区进行植物物种检测和分类，提高了监测效率和频率。


<details>
  <summary>Details</summary>
Motivation: 碎石栖息地因高海拔特性面临气候变化严重威胁，传统监测方法需要专家在偏远危险地区进行实地考察，过程资源密集且耗时。

Method: 在意大利阿尔卑斯生物区部署ANYmal C腿式机器人进行两年实地考察，利用深度学习检测和分类关键植物物种，并与传统植物社会学调查相结合。

Result: 敏捷腿式机器人能够导航具有挑战性的地形，提高碎石监测的频率和效率，同时优化数据采集、存储和使用流程。

Conclusion: 这项研究为环境科学中的机器人应用开辟了新途径，为更全面和可持续的栖息地监测与保护方法奠定了基础。

Abstract: According to the European Union's Habitat Directive, habitat monitoring plays a critical role in response to the escalating problems posed by biodiversity loss and environmental degradation. Scree habitats, hosting unique and often endangered species, face severe threats from climate change due to their high-altitude nature. Traditionally, their monitoring has required highly skilled scientists to conduct extensive fieldwork in remote, potentially hazardous locations, making the process resource-intensive and time-consuming. This paper presents a novel approach for scree habitat monitoring using a legged robot to assist botanists in data collection and species identification. Specifically, we deployed the ANYmal C robot in the Italian Alpine bio-region in two field campaigns spanning two years and leveraged deep learning to detect and classify key plant species of interest. Our results demonstrate that agile legged robots can navigate challenging terrains and increase the frequency and efficiency of scree monitoring. When paired with traditional phytosociological surveys performed by botanists, this robotics-assisted protocol not only streamlines field operations but also enhances data acquisition, storage, and usage. The outcomes of this research contribute to the evolving landscape of robotics in environmental science, paving the way for a more comprehensive and sustainable approach to habitat monitoring and preservation.

</details>


### [114] [EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones](https://arxiv.org/abs/2511.12618)
*Jordan Leyva,Nahim J. Moran Vera,Yihan Xu,Adrien Durasno,Christopher U. Romero,Tendai Chimuka,Gabriel O. Huezo Ramirez,Ziqian Dong,Roberto Rojas-Cessa*

Main category: cs.RO

TL;DR: EcoFlight是一种能量高效的无人机路径规划算法，能在3D空间中避开障碍物找到能耗最低的飞行路径。


<details>
  <summary>Details</summary>
Motivation: 现有无人机路径规划方案很少考虑障碍物避让，而避障又是能量密集型操作，对点对点无人机飞行的效率至关重要。

Method: 基于无人机推进系统和飞行动力学建模能耗，在3D空间中寻找能耗最低的避障路径。

Result: 在各种障碍物密度下的仿真结果表明，EcoFlight始终找到比直接飞行和最短距离方案能耗更低的路径，特别是在高密度环境中表现更优。合适的飞行速度还能进一步提升节能效果。

Conclusion: EcoFlight算法能有效降低无人机在避障飞行中的能量消耗，为能量高效的无人机路径规划提供了可行方案。

Abstract: Obstacle avoidance path planning for uncrewed aerial vehicles (UAVs), or drones, is rarely addressed in most flight path planning schemes, despite obstacles being a realistic condition. Obstacle avoidance can also be energy-intensive, making it a critical factor in efficient point-to-point drone flights. To address these gaps, we propose EcoFlight, an energy-efficient pathfinding algorithm that determines the lowest-energy route in 3D space with obstacles. The algorithm models energy consumption based on the drone propulsion system and flight dynamics. We conduct extensive evaluations, comparing EcoFlight with direct-flight and shortest-distance schemes. The simulation results across various obstacle densities show that EcoFlight consistently finds paths with lower energy consumption than comparable algorithms, particularly in high-density environments. We also demonstrate that a suitable flying speed can further enhance energy savings.

</details>


### [115] [Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning](https://arxiv.org/abs/2511.12650)
*Arvind Kumar Mishra,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: 使用强化学习进行平面机械臂形态优化，验证了RL能够仅通过奖励反馈恢复已知解析最优解，并在无解析解的情况下有效解决高维形态优化问题。


<details>
  <summary>Details</summary>
Motivation: 大多数形态设计任务没有闭式解，网格搜索和启发式搜索在高维情况下计算成本高昂，需要探索强化学习作为可扩展的替代方案。

Method: 使用Yoshikawa可操作性指标，比较SAC、DDPG和PPO三种RL算法与网格搜索和黑盒优化器，在2R机械臂跟踪圆形路径的验证案例中，形态由单一参数phi表示，然后扩展到椭圆和矩形路径的完整形态向量(L1, L2, theta2)。

Result: 所有方法在验证案例中都收敛到解析解，证明无需提供解析结构即可数值恢复最优解。在无解析解的情况下，RL继续可靠收敛，而网格和黑盒方法需要更大的评估预算。

Conclusion: 强化学习对于恢复已知最优解和解决无解析解的形态优化问题都是有效的，特别是在高维情况下具有更好的可扩展性。

Abstract: In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
  Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

</details>


### [116] [Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL](https://arxiv.org/abs/2511.12755)
*Aleesha Khurram,Amir Moeini,Shangtong Zhang,Rohan Chandra*

Main category: cs.RO

TL;DR: 本文提出了一种基于上下文强化学习(ICRL)的推理时少样本提示驱动领域自适应方法，用于恶劣天气条件下的闭环自动驾驶，无需模型参数更新或额外数据收集。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统在领域自适应方面存在困难，特别是在恶劣天气条件下。现有的提示驱动领域自适应方法仅限于感知任务且需要专家少样本数据，限制了其实际应用。

Method: 采用上下文强化学习(ICRL)方法，在推理时使用一般轨迹进行少样本提示驱动领域自适应，无需更新模型参数或收集额外对抗性天气数据。

Result: 在CARLA模拟器上的实验表明，相比最先进的提示驱动领域自适应基线方法，ICRL在目标领域中产生了更安全、更高效和更舒适的驾驶策略。

Conclusion: ICRL方法成功将提示驱动领域自适应扩展到闭环驾驶任务，使用推理时观察到的一般轨迹，为自动驾驶领域自适应提供了更实用的解决方案。

Abstract: Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.

</details>


### [117] [DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation](https://arxiv.org/abs/2511.12778)
*Vignesh Rajagopal,Kasun Weerakoon Kulathun Mudiyanselage,Gershom Devake Seneviratne,Pon Aswin Sankaralingam,Mohamed Elnoor,Jing Liang,Rohan Chandra,Dinesh Manocha*

Main category: cs.RO

TL;DR: DR.Nav是一种用于自主导航的新方法，专注于死胡同检测和恢复，特别适用于非结构化环境。它通过RGB-LiDAR融合和贝叶斯推理生成实时的语义成本地图，显著提高了导航效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，机器人经常遇到死胡同、植被遮挡和阻塞路口等问题，传统导航方法无法有效处理这些情况，导致导航失败或效率低下。

Method: 采用跨模态RGB-LiDAR融合与基于注意力的过滤，通过贝叶斯推理持续更新每个单元的死亡概率和恢复点，将恢复感知风险明确纳入导航成本地图。

Result: 在密集室内外场景中，检测准确率提高83.33%，目标到达时间减少52.4%，优于DWA、MPPI和Nav2 DWB等先进规划器。

Conclusion: DR.Nav通过统一的死胡同预测和恢复策略，显著提升了自主导航在复杂环境中的鲁棒性和效率。

Abstract: We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions

</details>


### [118] [ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model](https://arxiv.org/abs/2511.12795)
*Boshu Lei,Wen Jiang,Kostas Daniilidis*

Main category: cs.RO

TL;DR: 提出了一种基于能量校准的抓取姿态生成模型和主动视角选择方法，用于在密集杂乱环境中进行机器人抓取。该方法通过校准能量模型捕获SE(3)流形上的多模态抓取分布，并基于信息增益选择最佳视角。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在密集杂乱环境中的抓取问题。现有方法要么忽视了抓取分布在信息增益估计中的重要性，要么依赖于抓取分布的投影而忽略了SE(3)流形上的结构。

Method: 使用校准的能量模型生成抓取姿态，该模型捕获SE(3)流形上的多模态抓取分布，并将能量水平校准到抓取成功率。通过从校准分布中估计信息增益来选择下一个最佳视角。

Result: 在模拟环境和真实机器人设置上的实验表明，与先前最先进模型相比，该方法能够在有限视角预算下成功抓取杂乱环境中的物体。

Conclusion: 所提出的方法能够有效解决密集杂乱环境中的机器人抓取问题，模拟环境可作为未来主动抓取研究的可复现平台。

Abstract: Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.

</details>


### [119] [Structured Imitation Learning of Interactive Policies through Inverse Games](https://arxiv.org/abs/2511.12848)
*Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出了一种结合生成式单智能体策略学习和博弈论结构的模仿学习框架，用于学习交互式策略，在5智能体社交导航任务中仅用50个演示就取得了显著效果


<details>
  <summary>Details</summary>
Motivation: 在无显式通信的共享空间中协调人类行为的交互式策略模仿学习具有挑战性，因为多智能体交互的行为复杂性远高于非交互任务

Method: 两阶段学习：首先使用标准模仿学习从多智能体演示中学习个体行为模式，然后通过求解逆博弈问题结构化学习智能体间依赖关系

Result: 在合成5智能体社交导航任务中，该方法显著优于非交互策略，仅用50个演示就达到了与真实交互策略相当的性能

Conclusion: 结构化模仿学习在交互式场景中具有巨大潜力

Abstract: Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.

</details>


### [120] [Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos](https://arxiv.org/abs/2511.12882)
*Taiyi Su,Jian Zhu,Yaxuan Li,Chong Ma,Zitai Huang,Yichen Zhu,Hanli Wang,Yi Xu*

Main category: cs.RO

TL;DR: MTV-World是一个具身世界模型，通过多视角轨迹视频控制实现精确的视觉运动预测，解决了现有模型在将低级动作转换为精确机器人运动时的物理不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有具身世界模型难以准确地将低级动作（如关节位置）转换为预测帧中的精确机器人运动，导致与现实世界物理交互不一致。

Method: 使用通过相机内外参和笛卡尔空间变换获得的轨迹视频作为控制信号，引入多视角框架补偿空间信息损失，基于多视角轨迹视频预测未来帧。

Result: 在复杂双臂场景中实现了精确的控制执行和准确的物理交互建模。

Conclusion: MTV-World通过多视角轨迹视频控制方法，有效解决了具身世界模型中的物理一致性问题，实现了精确的机器人运动控制和物理交互建模。

Abstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

</details>


### [121] [Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction](https://arxiv.org/abs/2511.12896)
*Jun Huo,Hongge Ru,Bo Yang,Xingjian Chen,Xi Li,Jian Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于16通道气压计的软气室型六轴力/力矩传感器，采用刚性-柔性分层结构实现有效的解耦方法，将六轴解耦问题简化为两个三轴解耦问题。


<details>
  <summary>Details</summary>
Motivation: 开发软性且精确的六轴传感器具有挑战性，因为交叉轴耦合会导致校准问题和精度下降。需要实现完整的六自由度力测量能力。

Method: 使用硅橡胶制成的超弹性气室，内置16通道气压计。提出基于刚性-柔性分层结构的解耦方法，将六轴解耦简化为两个三轴解耦问题。通过有限元模型仿真和实验验证。

Result: 原型传感器测量范围为50N力和1Nm扭矩，平均偏差4.9%、重复性2.7%、非线性5.8%、迟滞6.7%。在静态负载响应、动态负载响应和动态响应特性方面表现出令人满意的传感性能。

Conclusion: 该软气室六轴力/力矩传感器在保持柔软性的同时，展现出良好的传感性能，验证了所提方法的有效性。

Abstract: Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\%$, 2.7$\%$, 5.8$\%$ and 6.7$\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.

</details>


### [122] [TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints](https://arxiv.org/abs/2511.12910)
*Yong Li,Yujun Huang,Yi Chen,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了TOPP-DWR算法，为差速驱动轮式机器人提供系统实用的时间最优路径参数化方法，考虑了角速度、关节速度、线速度和加速度约束


<details>
  <summary>Details</summary>
Motivation: 现有移动机器人时间最优路径参数化研究通常忽略角速度和关节速度约束，导致实际应用中控制性能下降

Method: 采用非均匀B样条表示任务空间初始轨迹，将角速度、关节速度、线速度和加速度约束统一表示为线速度约束，通过引入松弛变量将问题重构为二阶锥规划

Result: 对比实验验证了方法的优越性，定量性能指标显示TOPP-DWR能在满足所有约束条件下实现时间最优路径参数化

Conclusion: 现场自主导航实验验证了TOPP-DWR在实际应用中的实用性

Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.

</details>


### [123] [DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping](https://arxiv.org/abs/2511.12912)
*Yingting Zhou,Wenbo Cui,Weiheng Liu,Guixing Chen,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: DiffuDepGrasp是一个零样本sim2real框架，通过扩散深度生成器合成带有传感器噪声的仿真深度图，实现高效部署的抓取策略迁移。


<details>
  <summary>Details</summary>
Motivation: 解决仿真到真实世界策略迁移中的数据效率问题和部署复杂性，克服深度图传感器伪影（如空洞和噪声）造成的sim2real差距。

Method: 使用扩散深度生成器，包含扩散深度模块（利用时间几何先验训练条件扩散模型）和噪声嫁接模块（保持度量精度注入感知伪影），仅需原始深度输入进行部署。

Result: 在12个物体抓取任务中达到95.7%的平均成功率，实现零样本迁移并对未见物体具有强泛化能力。

Conclusion: DiffuDepGrasp通过仿真专属策略训练和扩散模型噪声合成，有效解决了sim2real迁移中的数据效率和部署复杂度问题。

Abstract: Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.

</details>


### [124] [GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving](https://arxiv.org/abs/2511.12941)
*Chunyong Hu,Qi Luo,Jianyun Xu,Song Wang,Qiang Li,Sheng Yang*

Main category: cs.RO

TL;DR: GUIDE是一个基于3D高斯的新型自动驾驶感知框架，通过高斯到体素投影实现实例级障碍物检测和占用预测，相比传统3D边界框方法能更好地处理不规则形状物体，在nuScenes数据集上实现了21.61的实例占用mAP，比现有方法提升50%。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶感知方法主要依赖3D边界框来表示障碍物，但这种方法无法准确捕捉现实世界中不规则形状物体的复杂性，限制了决策系统的有效性。

Method: 采用3D高斯进行实例检测和占用预测，使用稀疏表示策略和Gaussian-to-Voxel Splatting技术，在避免密集体素网格计算负担的同时提供细粒度的实例级占用数据，并具备强大的跟踪能力。

Result: 在nuScenes数据集上的实验验证显示，GUIDE实现了21.61的实例占用mAP，比现有方法提升50%，同时具备竞争力的跟踪性能。

Conclusion: GUIDE为自动驾驶感知系统设立了新基准，有效结合了精度和计算效率，能更好地应对现实驾驶环境的复杂性。

Abstract: In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.

</details>


### [125] [SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models](https://arxiv.org/abs/2511.12972)
*Siddarth Narasimhan,Matthew Lisondra,Haitong Wang,Goldie Nejat*

Main category: cs.RO

TL;DR: SplatSearch是一个解决实例图像目标导航(IIN)问题的新架构，利用稀疏视图3D高斯泼溅重建和扩散模型完成渲染图像，通过新颖的边界探索策略提高导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决实例图像目标导航问题中的挑战：参考图像视角任意且机器人必须在稀疏视图场景重建下操作。

Method: 使用稀疏在线3D高斯泼溅重建渲染候选对象的多视角图像，利用多视角扩散模型补全缺失区域，实现与目标图像的鲁棒特征匹配，并引入基于语义和视觉相关性的边界探索策略。

Result: 在真实感家庭和真实世界环境中的广泛实验验证了SplatSearch在成功率和成功路径长度方面优于当前最先进方法。

Conclusion: SplatSearch通过结合3D高斯泼溅重建、扩散模型补全和语义边界探索，有效解决了实例图像目标导航问题，表现出优越性能。

Abstract: The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.

</details>


### [126] [CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner](https://arxiv.org/abs/2511.12984)
*Miryeong Park,Dongjin Cho,Sanghyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 提出一个集成框架，结合安全路径生成、自适应置信度更新和置信度感知探索策略，用于行星探索机器人在不确定地形中的导航和建图。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂地形（如陨石坑）附近的高程估计不确定性方面存在不足，未考虑不确定性降低的探索策略，且未能解决高程不确定性对导航安全和地图质量的影响。

Method: 使用基于卡尔曼滤波的高程估计方法生成地形可穿越性和置信度评分，将其整合到基于图的探索规划器（GBP）中，优先探索可穿越的低置信度区域。

Result: 在模拟月球实验中，相比基线GBP实现了69%的不确定性降低，任务成功率从0%提升到100%。

Conclusion: 该方法显著提高了探索安全性和地图可靠性，在行星探索任务中具有重要应用价值。

Abstract: Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.

</details>


### [127] [APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation](https://arxiv.org/abs/2511.13042)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种用于A*等图搜索规划器的通用后处理算法APP，通过双向顶点缩减和路径扰动来缩短路径长度、减少不必要的转向，提高路径平滑度


<details>
  <summary>Details</summary>
Motivation: A*等图搜索规划器生成的路径通常不是最短路径，且存在不必要的转向和锯齿模式，这与人类直觉中在开阔空间应走直线路径的期望不符

Method: 基于代价地图开发APP算法：1）双向顶点缩减算法处理路径和环境的不对称性；2）在顶点缩减过程中采用彻底捷径策略；3）迭代路径扰动算法局部减少不必要的转向

Result: 对比实验表明APP在规划时间、路径长度和减少不必要转向方面优于现有方法，现场导航实验验证了实用性

Conclusion: APP算法能有效改进A*等规划器的路径质量，生成更短、更平滑的路径，减少不必要的转向

Abstract: Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.

</details>


### [128] [Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments](https://arxiv.org/abs/2511.13048)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种用于半结构化环境中清洁机器人全局路径规划的新方法，通过构建单向道路网络表示交通约束，采用混合策略保证规划结果，允许在起点和终点处穿越道路以缩短路径，并使用双层势能图处理复杂交叉口情况。


<details>
  <summary>Details</summary>
Motivation: 现有全局路径规划方法存在局限性：自由空间方法忽视交通规则约束导致频繁重新规划和碰撞风险增加，而结构化环境方法严格遵守道路网络可能导致路径过长影响导航效率。需要一种能平衡路径长度和道路网络一致性的方法。

Method: 构建单向道路网络表示半结构化环境中的交通约束，提出混合策略保证规划结果，允许在起点和终点处穿越道路以缩短路径，特别设计了双层势能图来处理复杂交叉口情况。

Result: 对比实验验证了该方法的有效性，定量实验结果显示，与现有最先进方法相比，该方法在路径长度和道路网络一致性之间实现了更好的平衡。

Conclusion: 该方法为半结构化环境中的全局路径规划提供了一种通用且系统化的解决方案，能够有效平衡路径长度和交通规则约束，提高清洁机器人的导航效率。

Abstract: Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.

</details>


### [129] [Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers](https://arxiv.org/abs/2511.13071)
*Michal Levin,Itzik Klein*

Main category: cs.RO

TL;DR: 提出一种无需传感器定向和旋转的模型无关学习型加速度计偏置校准方法，在静止条件下实现快速实用的现场部署。


<details>
  <summary>Details</summary>
Motivation: 低成本MEMS加速度计在导航、机器人等领域广泛应用，但其性能常受偏置误差影响。传统校准方法需要加速度计调平或复杂的定向相关程序，限制了实际应用。

Method: 基于学习的模型无关校准方法，在静止条件下估计加速度计偏置，无需传感器定向知识和旋转操作。

Result: 在13.39小时六加速度计数据集上的实验验证表明，该方法比传统技术误差降低52%以上。

Conclusion: 该工作推动了无定向场景下的精确校准方法发展，提高了低成本惯性传感器在科学和工业应用中的可靠性，消除了调平校准的需求。

Abstract: Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.

</details>


### [130] [ResAlignNet: A Data-Driven Approach for INS/DVL Alignment](https://arxiv.org/abs/2511.13096)
*Guy Damari,Itzik Klein*

Main category: cs.RO

TL;DR: ResAlignNet是一种基于1D ResNet-18架构的数据驱动方法，将INS和DVL传感器对准问题转化为深度神经网络优化，无需外部定位辅助或复杂机动，仅需25秒数据即可在0.8°精度内完成对准。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的INS-DVL对准方法存在收敛时间长、依赖预设运动模式和外部辅助传感器的问题，严重限制了水下自主航行器的操作灵活性。

Method: 使用1D ResNet-18架构，将传感器对准问题转化为深度神经网络优化，支持Sim2Real迁移学习，可在合成数据上训练并在实际传感器测量中部署。

Result: 在Snapir自主水下航行器上的实验验证表明，ResAlignNet仅需25秒数据收集即可实现0.8°以内的对准精度，相比标准速度方法收敛时间减少65%。

Conclusion: 该轨迹无关解决方案消除了运动模式要求，无需冗长的任务前程序即可立即部署航行器，通过鲁棒的传感器无关对准推进了水下导航能力。

Abstract: Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.

</details>


### [131] [Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing](https://arxiv.org/abs/2511.13100)
*Xuecheng Chen,Jingao Xu,Wenhua Ding,Haoyang Wang,Xinyu Luo,Ruiyang Duan,Jialong Chen,Xueqian Wang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 提出了一种基于事件相机的无人机感知系统EventPro，通过精确估计螺旋桨转速来显著提升无人机感知性能，在真实无人机配送场景中实现了3ms的感知延迟和0.23%的转速估计误差。


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用的普及，从地面进行非接触式无人机感知变得至关重要。传统方法在感知性能上存在局限，需要更精确的无人机状态监测方案。

Method: 系统包含两个核心组件：Count Every Rotation通过减轻事件相机对环境噪声的超高灵敏度，实现准确、实时的螺旋桨转速估计；Every Rotation Counts利用这些转速推断无人机的内外动态。

Result: 在真实无人机配送场景评估中，系统实现了3ms的感知延迟和0.23%的转速估计误差，能够以96.5%的精度推断无人机飞行指令，与其他感知模态结合时可将无人机跟踪精度提升22%以上。

Conclusion: 专注于螺旋桨转速能够显著提升无人机感知性能，基于事件相机的解决方案在实时性、准确性和鲁棒性方面表现出色，为无人机监测提供了有效的新方法。

Abstract: As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \sysname. \sysname features two components: \textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\%. Additionally, \sysname infers drone flight commands with 96.5\% precision and improves drone tracking accuracy by over 22\% when combined with other sensing modalities. \textit{ Demo: {\color{blue}https://eventpro25.github.io/EventPro/.} }

</details>


### [132] [Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design](https://arxiv.org/abs/2511.13120)
*Trevor Exley,Anderson Brazil Nardin,Petr Trunin,Diana Cafiso,Lucia Beccai*

Main category: cs.RO

TL;DR: 本文介绍了用于软体机器人的单体单元(MU)，这是一种集成了气动驱动、柔性晶格外壳和光学波导传感的3D打印构建模块。通过参数化设计框架和实验均质化方法，建立了从驱动器腔室尺寸到晶格单元尺寸的确定性规则，并通过有限元仿真优化传感器布局，在保持机械性能的同时实现嵌入式传感。


<details>
  <summary>Details</summary>
Motivation: 开发一种集驱动、结构和传感于一体的软体机器人构建模块，解决软体机器人中驱动、传感和结构集成困难的问题，实现可重复制造和可扩展设计。

Method: 1. 设计集成了气动驱动、柔性晶格外壳和光学波导传感的单体单元；2. 建立参数化设计框架，将驱动器腔室尺寸与晶格单元尺寸关联；3. 通过实验均质化获得有效材料属性用于有限元仿真；4. 将传感器布局作为离散优化问题处理，从晶格节点导出的候选波导路径中选择最小化机械响应偏差的配置。

Result: 优化后的模型被制造并实验表征，验证了在保持机械性能的同时实现嵌入式传感。该方法进一步扩展到缩放单元和双指夹持器，证明了MU概念的通用性。

Conclusion: 该方法通过结合可重复的协同设计规则和基于仿真的传感器集成，推进了单体软体机器人的设计。

Abstract: This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.

</details>


### [133] [Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control](https://arxiv.org/abs/2511.13188)
*Osama Al Sheikh Ali,Sotiris Koutsoftas,Ze Zhang,Knut Akesson,Emmanuel Dean*

Main category: cs.RO

TL;DR: 提出了一种集成导航框架，将环境表示、轨迹生成和模型预测控制统一起来，使用四叉树方法从占据地图生成结构化无碰撞区域作为安全走廊和MPC约束。


<details>
  <summary>Details</summary>
Motivation: 为自主移动机器人开发一个统一的导航框架，避免直接编码障碍物，实现高效可靠的导航。

Method: 采用四叉树方法生成轴对齐的无碰撞区域，构建连通图，结合轨迹生成和B样条平滑，将安全区域提取作为MPC的线性约束。

Result: 实验结果显示在复杂环境中相比基线方法具有一致的优越性能。

Conclusion: 该集成框架能够实现高效可靠的自主导航，无需直接处理障碍物编码。

Abstract: This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.

</details>


### [134] [PIGEON: VLM-Driven Object Navigation via Points of Interest Selection](https://arxiv.org/abs/2511.13207)
*Cheng Peng,Zhenzhe Zhang,Cheng Chi,Xiaobao Wei,Yanhao Zhang,Heng Wang,Pengwei Wang,Zhongyuan Wang,Jing Liu,Shanghang Zhang*

Main category: cs.RO

TL;DR: PIGEON是一个用于未知环境中物体导航的框架，通过兴趣点引导探索，结合视觉语言模型和强化学习，实现高频智能决策。


<details>
  <summary>Details</summary>
Motivation: 现有方法在决策频率与智能性之间难以平衡，导致决策缺乏前瞻性或动作不连续，需要一种既能高频决策又具备语义理解能力的导航方法。

Method: 使用PIGEON-VL视觉语言模型选择探索过程中形成的兴趣点，然后由低级规划器输出动作；同时基于兴趣点决策生成可验证奖励的强化学习数据。

Result: 在经典物体导航基准测试中，零样本迁移方法达到最先进性能，RLVR进一步增强了模型的语义引导能力，实现实时导航中的深度推理。

Conclusion: PIGEON框架成功平衡了决策频率与智能性，通过兴趣点引导和语义记忆实现了高效且智能的物体导航。

Abstract: Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

</details>


### [135] [GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry](https://arxiv.org/abs/2511.13216)
*Chiyun Noh,Sangwoo Jung,Hanjun Kim,Yafei Hu,Laura Herlant,Ayoung Kim*

Main category: cs.RO

TL;DR: GaRLILEO是一个重力对齐的连续时间雷达-腿-惯性里程计框架，通过解耦IMU速度并构建连续时间自速度样条，结合雷达多普勒和腿部运动学信息，提高腿式机器人在挑战性地形上的垂直位姿估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于腿部运动学和惯性传感的里程计方法存在无法抑制的垂直漂移问题，特别是在楼梯、斜坡等复杂地形上。现有方法虽然引入了激光雷达或相机等外部传感器，但在特征稀疏或重复场景中性能下降，且容易受到IMU加速度双重积分误差的影响。

Method: GaRLILEO通过构建基于SoC雷达多普勒和腿部运动学信息的连续时间自速度样条，将速度从IMU中解耦出来，实现无缝传感器融合。同时采用新颖的软S2约束重力因子可靠地捕捉准确的重力向量，提高垂直位姿精度。

Result: 在自收集的真实世界室内外轨迹数据集上评估，GaRLILEO展示了最先进的精度，特别是在楼梯和斜坡上的垂直里程计估计方面表现优异。

Conclusion: GaRLILEO框架有效解决了腿式机器人在挑战性地形上的垂直漂移问题，无需依赖激光雷达或相机，为腿式机器人里程计和SLAM研究提供了新的解决方案。

Abstract: Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO

</details>


### [136] [EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation](https://arxiv.org/abs/2511.13312)
*Jonas Bode,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 提出了一种结合视觉和文本输入的扩散模型视觉运动策略，用于生成精确的机器人轨迹，在CALVIN数据集上验证了其在操作任务和长时域任务序列中的性能提升。


<details>
  <summary>Details</summary>
Motivation: 让机器人在人类环境中执行任务需要强大的自然语言理解和物理任务应用能力，本文旨在利用扩散模型的能力来提升机器人的操作性能。

Method: 在视觉运动策略框架中整合扩散模型，结合视觉和文本输入生成机器人轨迹，使用参考演示进行训练，并采用图像生成中的扩散模型技术进行改进。

Result: 在CALVIN数据集上的评估显示，该方法在各种操作任务上性能提升，并且在执行多个任务序列时提高了长时域成功率。

Conclusion: 该方法强化了扩散模型在机器人操作中的实用性，为通用多任务操作做出了贡献。

Abstract: Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.

</details>


### [137] [ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning](https://arxiv.org/abs/2511.13327)
*Juntao Jian,Yi-Lin Wei,Chengjie Mou,Yuhao Lin,Xing Zhu,Yujun Shen,Wei-Shi Zheng,Ruizhen Hu*

Main category: cs.RO

TL;DR: 提出ZeroDexGrasp框架，通过多模态大语言模型和抓取优化的零样本方法，实现面向任务的灵巧抓取合成，无需依赖昂贵的标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖标注数据，难以在多样化物体和任务指令间泛化，需要开发零样本的语义对齐方法。

Method: 使用基于提示的多阶段语义推理推断初始抓取配置和物体接触信息，然后通过接触引导的抓取优化来细化姿势，确保物理可行性和任务对齐。

Result: 实验结果表明，该方法能够在未见过的物体类别和复杂任务需求上实现高质量的零样本灵巧抓取。

Conclusion: ZeroDexGrasp推动了更通用和智能的机器人抓取技术的发展。

Abstract: Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

</details>


### [138] [Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness](https://arxiv.org/abs/2511.13459)
*Bingkun Huang,Yuhe Gong,Zewen Yang,Tianyu Ren,Luis Figueredo*

Main category: cs.RO

TL;DR: 提出了一种基于任务空间和能量安全的强化学习框架，结合PPO和运动基元来处理接触丰富的机器人操作任务，确保安全交互。


<details>
  <summary>Details</summary>
Motivation: 传统基于MDP的强化学习方法在机器人关节空间中应用，对3D环境感知有限，且忽视了任务空间中接触丰富信息的安全性和鲁棒性问题。

Method: 结合近端策略优化(PPO)和运动基元生成可靠的任务空间轨迹，并融入能量感知的笛卡尔阻抗控制器目标以确保安全交互。

Result: 实验表明该框架在3D环境中各种表面上的任务处理优于现有方法，实现了高成功率、平滑轨迹和能量安全交互。

Conclusion: 所提出的任务空间能量安全框架在接触丰富的操作任务中表现出色，为机器人安全交互提供了有效解决方案。

Abstract: Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

</details>


### [139] [Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety](https://arxiv.org/abs/2511.13530)
*Vesna Poprcova,Iulia Lefter,Matthias Wieser,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 本文提出了一个用于收集社交焦虑多模态数据集的协议，该数据集包含与Furhat社交机器人交互时的同步音频、视频和生理记录，旨在支持社交焦虑的稳健多模态检测研究。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种普遍存在的状况，影响人际互动和社交功能。目前缺乏反映社交焦虑的多模态数据集，限制了相关研究和应用的进展。

Method: 设计了一个多模态数据集收集协议，从至少70名参与者中获取同步的音频、视频和生理记录，参与者根据社交焦虑水平分组，在受控实验条件下与Furhat社交机器人进行约10分钟的Wizard-of-Oz角色扮演交互。

Result: 将构建一个包含多模态数据和上下文信息的丰富数据集，为研究提供支持。

Conclusion: 这项工作可以为情感自适应人机交互研究做出贡献，通过提供支持社交焦虑稳健多模态检测的数据集。

Abstract: Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

</details>


### [140] [OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving](https://arxiv.org/abs/2511.13707)
*Xiaoyu Liang,Ziang Liu,Kelvin Lin,Edward Gu,Ruolin Ye,Tam Nguyen,Cynthia Hsu,Zhanxin Wu,Xiaoman Yang,Christy Sum Yu Cheung,Harold Soh,Katherine Dimitropoulou,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: OpenRoboCare是一个用于机器人护理的多模态数据集，包含职业治疗师执行日常生活活动任务的专家演示，涵盖RGB-D视频、姿态跟踪、眼动追踪、任务注释和触觉感知五种模态。


<details>
  <summary>Details</summary>
Motivation: 护理任务涉及复杂的人机物理交互，需要精确的遮挡感知、安全的物理接触和长期规划，但目前缺乏大规模、多样化且由专家驱动的真实世界护理数据集。

Method: 收集了21名职业治疗师在两个人体模型上执行15项日常生活活动任务的数据，涵盖五种模态：RGB-D视频、姿态跟踪、眼动追踪、任务和动作注释、触觉感知。

Result: 数据集提供了关于护理人员运动、注意力、施力和任务执行策略的丰富多模态洞察，并对现有机器人感知和人类活动识别方法提出了挑战。

Conclusion: OpenRoboCare填补了机器人护理领域的数据空白，为开发安全自适应的辅助机器人提供了重要资源，同时揭示了专家护理原则和策略以提升机器人效率和任务可行性。

Abstract: We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.

</details>


### [141] [From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands](https://arxiv.org/abs/2511.13710)
*Jianglong Ye,Lai Wei,Guangqi Jiang,Changwei Jing,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种联合优化多指灵巧手控制策略和硬件设计的框架，通过轻量化的指尖几何修改实现了既能进行强力抓取又能进行精确操作的单系统解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前机器人手设计存在关键限制：难以在单一系统中同时实现稳定的强力抓取和精确的精细操作。多指手擅长强力抓取，但精确操作任务仍主要使用平行夹爪。

Method: 1. 引入轻量级指尖几何修改，将其表示为接触平面；2. 联合优化指尖几何参数和相应控制策略；3. 控制策略在强力操作和精确操作间动态切换，将精确控制简化为平行拇指-食指运动；4. 利用大规模仿真和可微分神经物理替代模型优化指尖几何。

Result: 在未见物体的sim-to-real精确抓取中达到82.5%的零样本成功率，在涉及面包捏取的真实世界挑战性任务中达到93.3%的成功率。

Conclusion: 该协同设计框架能显著增强多指手的精细操作能力，同时不削弱其强力抓取能力，成功解决了机器人手设计中的关键限制。

Abstract: Human grasps can be roughly categorized into two types: power grasps and precision grasps. Precision grasping enables tool use and is believed to have influenced human evolution. Today's multi-fingered robotic hands are effective in power grasps, but for tasks requiring precision, parallel grippers are still more widely adopted. This contrast highlights a key limitation in current robotic hand design: the difficulty of achieving both stable power grasps and precise, fine-grained manipulation within a single, versatile system. In this work, we bridge this gap by jointly optimizing the control and hardware design of a multi-fingered dexterous hand, enabling both power and precision manipulation. Rather than redesigning the entire hand, we introduce a lightweight fingertip geometry modification, represent it as a contact plane, and jointly optimize its parameters along with the corresponding control. Our control strategy dynamically switches between power and precision manipulation and simplifies precision control into parallel thumb-index motions, which proves robust for sim-to-real transfer. On the design side, we leverage large-scale simulation to optimize the fingertip geometry using a differentiable neural-physics surrogate model. We validate our approach through extensive experiments in both sim-to-real and real-to-real settings. Our method achieves an 82.5% zero-shot success rate on unseen objects in sim-to-real precision grasping, and a 93.3% success rate in challenging real-world tasks involving bread pinching. These results demonstrate that our co-design framework can significantly enhance the fine-grained manipulation ability of multi-fingered hands without reducing their ability for power grasps. Our project page is at https://jianglongye.com/power-to-precision

</details>
