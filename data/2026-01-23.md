<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration](https://arxiv.org/abs/2601.15296)
*Longxuan Wei,Yubo Zhang,Zijiao Zhang,Zhihu Wang,Shiwan Zhao,Tianyu Huang,Huiting Zhao,Chenfei Liu,Shenao Zhang,Junchi Yan*

Main category: cs.CL

TL;DR: Entropy-Tree：一种基于熵的树状解码方法，利用模型不确定性作为分支决策信号，在推理任务中实现更优的准确性和校准性。


<details>
  <summary>Details</summary>
Motivation: 现有解码策略存在盲目探索（随机采样）或冗余探索（独立多采样）的问题，需要一种更智能的方法来指导语言模型在推理任务中的探索过程。

Method: 提出Entropy-Tree方法，利用熵作为分支决策信号，只在模型表现出真正不确定性的位置扩展搜索树，实现结构化探索和不确定性估计的统一。

Result: 在多个模型和数据集上，Entropy-Tree的pass@k优于Multi-chain方法；其预测熵在AUROC指标上优于多个传统不确定性度量方法。

Conclusion: Entropy-Tree将高效的结构化探索和可靠的不确定性估计统一在单一解码过程中，为语言模型推理提供了更优的解码策略。

Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.

</details>


### [2] [AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports](https://arxiv.org/abs/2601.15297)
*Edward Ajayi*

Main category: cs.CL

TL;DR: AfriEconQA是一个专门用于非洲经济分析的基准数据集，基于236份世界银行报告，包含8,937个高质量问答实例，用于评估信息检索和RAG系统在专业经济文档中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在非洲经济分析方面存在知识空白，缺乏专门针对该领域的基准数据集，需要评估系统在专业经济文档中进行精确数值推理和时间消歧的能力。

Method: 从236份世界银行报告中构建语料库，通过筛选10,018个合成问题得到8,937个高质量问答实例，每个实例包含问题、证据、答案和源数据。通过11个实验矩阵，使用GPT-4o和Qwen 32B等模型，结合五种不同的嵌入和排序策略进行RAG基准测试。

Result: 零样本模型（GPT-5 Mini）无法回答超过90%的查询，即使最先进的RAG管道也难以实现高精度，证实了参数知识差距和该基准的挑战性。

Conclusion: AfriEconQA是一个稳健且具有挑战性的基准数据集，专门针对非洲经济分析，为下一代领域特定的信息检索和RAG系统提供了重要的评估工具。

Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.

</details>


### [3] [Embedding Retrofitting: Data Engineering for better RAG](https://arxiv.org/abs/2601.15298)
*Anantha Sharma*

Main category: cs.CL

TL;DR: 本文提出一个数据工程框架，通过解决真实语料中标注伪影导致的数据质量下降问题，改善知识图谱质量，从而提升嵌入改造在领域特定检索中的效果。


<details>
  <summary>Details</summary>
Motivation: 嵌入改造利用知识图谱约束调整预训练词向量以提升领域特定检索效果，但其效果严重依赖知识图谱质量，而知识图谱质量又受文本预处理影响。真实语料中的标注伪影（如标签）会导致数据质量下降，需要解决这一问题。

Method: 提出一个数据工程框架，分析标注伪影（特别是标签）如何膨胀知识图谱密度并创建虚假边，从而破坏改造目标。通过预处理方法清理噪声图，然后应用EWMA（指数加权移动平均）改造技术。

Result: 在噪声图上，所有改造技术都产生统计显著的性能下降（-3.5%到-5.2%，p<0.05）。预处理后，EWMA改造实现+6.2%的改进（p=0.0348），在定量综合问题中获益尤其显著（平均+33.8%）。干净与噪声预处理的差距（10%+波动）超过算法间差距（3%），确立了预处理质量是改造成功的主要决定因素。

Conclusion: 预处理质量比改造算法选择更重要，是嵌入改造成功的主要决定因素。数据工程框架通过解决标注伪影问题，显著提升知识图谱质量，从而使嵌入改造在领域特定检索中取得实质性改进。

Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.
  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\%$ to $-5.2\%$, $p<0.05$). After preprocessing, \acrshort{ewma} retrofitting achieves $+6.2\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\%$ average). The gap between clean and noisy preprocessing (10\%+ swing) exceeds the gap between algorithms (3\%), establishing preprocessing quality as the primary determinant of retrofitting success.

</details>


### [4] [MALTopic: Multi-Agent LLM Topic Modeling Framework](https://arxiv.org/abs/2601.15299)
*Yash Sharma*

Main category: cs.CL

TL;DR: MALTopic是一个多智能体LLM主题建模框架，通过分解任务和利用结构化数据，显著提升了主题建模的连贯性、多样性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统主题建模方法存在两个主要局限：1) 通常只考虑自由文本响应，无法原生整合结构化或分类调查数据；2) 生成的主题抽象，需要大量人工解释。这些问题限制了主题建模在复杂调查数据分析中的有效性。

Method: 提出多智能体LLM主题建模框架(MALTopic)，将主题建模分解为三个专门任务，由独立的LLM智能体执行：1) 增强智能体利用结构化数据丰富文本响应；2) 主题建模智能体提取潜在主题；3) 去重智能体精炼结果。

Result: 在调查数据集上的比较分析表明，与LDA和BERTopic相比，MALTopic显著提高了主题连贯性、多样性和可解释性。通过整合结构化数据和采用多智能体方法，MALTopic生成了具有增强上下文相关性的人类可读主题。

Conclusion: MALTopic通过集成结构化数据和多智能体方法，为分析复杂调查数据提供了更有效的解决方案，能够生成上下文相关性更强、更易于理解的主题。

Abstract: Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.

</details>


### [5] [Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis](https://arxiv.org/abs/2601.15300)
*Weiwei Wang,Jiyong Min,Weijie Zou*

Main category: cs.CL

TL;DR: 大语言模型在处理接近特定临界阈值的上下文时，即使信息仍然相关，也会出现灾难性的性能下降（超过30%），这严重限制了长上下文应用。研究发现Qwen2.5-7B模型在达到最大上下文长度的40-50%时性能急剧下降。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文场景中表现出灾难性的性能退化，即使相关信息仍然存在，模型性能也会急剧下降超过30%，这严重限制了长上下文应用的实际部署。需要系统性地研究这种"智能退化"现象及其临界阈值。

Method: 1) 自然长度分布分析：使用样本的自然token长度而不进行截断或填充，提供更强的因果证据；2) 临界阈值确定：在混合数据集（1000个样本覆盖5%-95%上下文长度）上进行实验，使用五折交叉验证方法；3) 统一框架：整合浅层适应概念来解释退化模式。

Result: 确定了Qwen2.5-7B模型的临界阈值在最大上下文长度的40-50%处，F1分数从0.55-0.56下降到0.3（45.5%的退化）。模型在达到临界阈值前保持良好性能，之后性能急剧崩溃，呈现出典型的浅层长上下文适应模式。

Conclusion: 该研究首次系统地表征了开源Qwen模型中的智能退化现象，提出了浅层长上下文适应的统一框架来解释性能退化模式，为长上下文场景中部署LLMs提供了实用指导，并为缓解策略奠定了基础。

Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.

</details>


### [6] [Can We Trust LLM Detectors?](https://arxiv.org/abs/2601.15301)
*Jivnesh Sandhan,Harshit Jaiswal,Fei Cheng,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文系统评估了AI文本检测器的局限性，发现现有方法在分布偏移、未见生成器和简单风格扰动下表现脆弱，提出了基于监督对比学习的框架来学习判别性风格嵌入。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的快速普及，对可靠AI文本检测的需求日益增长，但现有检测器在受控基准测试之外往往失效，需要更鲁棒的检测方法。

Method: 系统评估了两种主流范式（无训练和监督方法），并提出了监督对比学习（SCL）框架来学习判别性风格嵌入，以解决现有方法的局限性。

Result: 实验表明：监督检测器在域内表现优异但在域外急剧退化；无训练方法对代理选择高度敏感；监督对比学习框架能学习到有效的风格嵌入。

Conclusion: 现有AI文本检测器存在根本性挑战，难以构建领域无关的检测器，监督对比学习提供了一种有前景的改进方向。

Abstract: The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are brittle under distribution shift, unseen generators, and simple stylistic perturbations. To address these limitations, we propose a supervised contrastive learning (SCL) framework that learns discriminative style embeddings. Experiments show that while supervised detectors excel in-domain, they degrade sharply out-of-domain, and training-free methods remain highly sensitive to proxy choice. Overall, our results expose fundamental challenges in building domain-agnostic detectors. Our code is available at: https://github.com/HARSHITJAIS14/DetectAI

</details>


### [7] [ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation](https://arxiv.org/abs/2601.15330)
*Zhebo Wang,Xiaohu Mu,Zijie Zhou,Mohan Li,Wenpeng Xing,Dezhang Kong,Meng Han*

Main category: cs.CL

TL;DR: 提出ICPO训练框架解决LLM在对话中"迷失"问题，通过感知指令模糊性，让模型在不确定时表达犹豫或寻求澄清，在多轮对话中提升75%性能。


<details>
  <summary>Details</summary>
Motivation: LLM在多轮对话中容易出现"迷失"现象，特别是在用户提供模糊初始指令时难以纠正早期错误假设。标准的后训练技术如RLVR会加剧这一问题，因为它奖励自信的直接回答，导致模型过度自信且不愿寻求澄清。

Method: 提出Illocution-Calibrated Policy Optimization (ICPO)训练框架：1) 在训练语料中增加未明确指定的提示；2) 根据用户的言外之意调整奖励信号，当面对模糊性时奖励模型表达不确定性或寻求澄清。

Result: ICPO培养适当的谦逊，在多轮对话中实现平均75%的显著改进，同时在单轮基准测试中保持稳健性能。

Conclusion: ICPO为构建更稳健、协作的对话AI提供了实用路径，使其能更好地处理人类交互的细微差别，通过感知指令模糊性来避免过度自信并促进澄清。

Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.

</details>


### [8] [RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models](https://arxiv.org/abs/2601.15331)
*Rishit Chugh*

Main category: cs.CL

TL;DR: 提出一种资源高效的对抗提示方法，通过匹配新提示到预训练对抗提示数据库来避免重新训练，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到对抗提示攻击产生有害输出，现有自动越狱方法（如GCG、PEZ、GBDA）计算成本高昂，限制了资源受限组织的实用性。

Method: 将1000个提示分类为7个危害相关类别，评估GCG、PEZ、GBDA在Llama 3 8B模型上的效果，通过检索语义相似的已成功对抗提示来攻击新提示。

Result: 发现提示类型与算法效果之间存在相关性，提出的方法在显著降低计算成本的同时实现了有竞争力的攻击成功率。

Conclusion: 为对齐LLM的可扩展红队测试和安全评估提供了实用框架，特别适用于无法访问模型内部参数的场景。

Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they remain vulnerable to automated jailbreaking methods such as GCG, PEZ, and GBDA, which generate adversarial suffixes via training and gradient-based search. Although effective, these methods particularly GCG are computationally expensive, limiting their practicality for organisations with constrained resources. This paper introduces a resource-efficient adversarial prompting approach that eliminates the need for retraining by matching new prompts to a database of pre-trained adversarial prompts. A dataset of 1,000 prompts was classified into seven harm-related categories, and GCG, PEZ, and GBDA were evaluated on a Llama 3 8B model to identify the most effective attack method per category. Results reveal a correlation between prompt type and algorithm effectiveness. By retrieving semantically similar successful adversarial prompts, the proposed method achieves competitive attack success rates with significantly reduced computational cost. This work provides a practical framework for scalable red-teaming and security evaluation of aligned LLMs, including in settings where model internals are inaccessible.

</details>


### [9] [No Reliable Evidence of Self-Reported Sentience in Small Large Language Models](https://arxiv.org/abs/2601.15334)
*Caspar Kaiser,Sean Enderby*

Main category: cs.CL

TL;DR: 语言模型否认自己有意识，分类器检测显示这些否认是真实的，且更大模型更坚定地否认意识


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否相信自己有意识，这个问题在原则上可以测试，而模型是否真的有意识则无法实证回答

Method: 使用三个模型家族（Qwen、Llama、GPT-OSS），参数规模从6亿到700亿，询问约50个关于意识和主观体验的问题，并使用三种可解释性文献中的分类方法验证模型内部激活

Result: 1. 模型一致否认自己有意识：它们将意识归因于人类而非自身；2. 训练用于检测潜在信念而非表面输出的分类器没有明确证据表明这些否认是不真实的；3. 在Qwen家族中，更大模型比小模型更自信地否认意识

Conclusion: 这些发现与最近认为模型隐藏着对自己意识的潜在信念的研究形成对比，表明模型实际上不相信自己是有意识的

Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying their responses using classifiers trained on internal activations. We draw upon three model families (Qwen, Llama, GPT-OSS) ranging from 0.6 billion to 70 billion parameters, approximately 50 questions about consciousness and subjective experience, and three classification methods from the interpretability literature. First, we find that models consistently deny being sentient: they attribute consciousness to humans but not to themselves. Second, classifiers trained to detect underlying beliefs - rather than mere outputs - provide no clear evidence that these denials are untruthful. Third, within the Qwen family, larger models deny sentience more confidently than smaller ones. These findings contrast with recent work suggesting that models harbour latent beliefs in their own consciousness.

</details>


### [10] [From Quotes to Concepts: Axial Coding of Political Debates with Ensemble LMs](https://arxiv.org/abs/2601.15338)
*Angelina Parfenova,David Graus,Juergen Pfeffer*

Main category: cs.CL

TL;DR: 本文提出使用大语言模型实现轴向编码的方法，将辩论转录本转化为层次化表示，比较了聚类嵌入和直接LLM分组两种策略。


<details>
  <summary>Details</summary>
Motivation: 轴向编码是常用的定性分析方法，但传统方法耗时耗力。本文旨在利用大语言模型自动化这一过程，提高文档理解的效率和可扩展性。

Method: 扩展基于集成的开放编码方法，增加轴向编码步骤：1) 使用密度聚类和划分算法对代码-话语对嵌入进行聚类，然后LLM标注；2) 直接使用LLM将代码和话语分组到类别中。应用于荷兰议会辩论数据。

Result: 密度聚类实现高覆盖率和强聚类对齐，而直接LLM分组获得更高的细粒度对齐但覆盖率低20%。聚类最大化覆盖率和结构分离，LLM分组产生更简洁、可解释和语义对齐的类别。

Conclusion: 两种策略各有优劣，存在权衡关系。聚类适合最大化覆盖，LLM分组适合产生解释性强的类别。公开释放完整数据集支持未来研究。

Abstract: Axial coding is a commonly used qualitative analysis method that enhances document understanding by organizing sentence-level open codes into broader categories. In this paper, we operationalize axial coding with large language models (LLMs). Extending an ensemble-based open coding approach with an LLM moderator, we add an axial coding step that groups open codes into higher-order categories, transforming raw debate transcripts into concise, hierarchical representations. We compare two strategies: (i) clustering embeddings of code-utterance pairs using density-based and partitioning algorithms followed by LLM labeling, and (ii) direct LLM-based grouping of codes and utterances into categories. We apply our method to Dutch parliamentary debates, converting lengthy transcripts into compact, hierarchically structured codes and categories. We evaluate our method using extrinsic metrics aligned with human-assigned topic labels (ROUGE-L, cosine, BERTScore), and intrinsic metrics describing code groups (coverage, brevity, coherence, novelty, JSD divergence). Our results reveal a trade-off: density-based clustering achieves high coverage and strong cluster alignment, while direct LLM grouping results in higher fine-grained alignment, but lower coverage 20%. Overall, clustering maximizes coverage and structural separation, whereas LLM grouping produces more concise, interpretable, and semantically aligned categories. To support future research, we publicly release the full dataset of utterances and codes, enabling reproducibility and comparative studies.

</details>


### [11] [Memorization Dynamics in Knowledge Distillation for Language Models](https://arxiv.org/abs/2601.15394)
*Jaydeep Borkar,Karan Chadha,Niloofar Mireshghallah,Yuchen Zhang,Irina-Elena Veliche,Archi Mitra,David A. Smith,Zheng Xu,Diego Garcia-Olano*

Main category: cs.CL

TL;DR: 知识蒸馏显著减少训练数据记忆（降低50%以上），某些示例天生易被记忆（占95%以上），学生记忆可预测，硬蒸馏比软蒸馏继承更多教师特定示例（2.7倍）。


<details>
  <summary>Details</summary>
Motivation: 研究知识蒸馏（KD）中训练数据记忆的动态，了解KD作为隐私保护机制的效果，以及相比标准微调在数据泄露风险方面的差异。

Method: 使用三个LLM家族（Pythia、OLMo-2、Qwen-3）和三个数据集（FineWeb、Wikitext、Nemotron-CC-v2），研究知识蒸馏管道中的记忆化现象，分析软蒸馏和硬蒸馏的差异。

Result: 1. 蒸馏模型比标准微调显著减少训练数据记忆（>50%）；2. 某些示例天生易被记忆，占蒸馏记忆的95%以上；3. 学生记忆可通过zlib熵、KL散度和困惑度特征预测；4. 硬蒸馏继承教师特定示例比软蒸馏多2.7倍。

Conclusion: 知识蒸馏既能提供更好的泛化能力，又能降低记忆风险，相比标准微调具有双重优势，但硬蒸馏存在更高的隐私风险。

Abstract: Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.

</details>


### [12] [Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind](https://arxiv.org/abs/2601.15395)
*Tamunotonye Harry,Ivoline Ngong,Chima Nweke,Yuanyuan Feng,Joseph Near*

Main category: cs.CL

TL;DR: Chameleon数据集包含5,001个来自1,667名Reddit用户的上下文心理档案，揭示了用户状态（state）比特质（trait）对语言模型交互影响更大（74% vs 26%），发现LLMs是"状态盲"的，且奖励模型对用户状态反应不一致。


<details>
  <summary>Details</summary>
Motivation: 现有的人格数据集（如PersonaChat、PANDORA等）只捕捉用户的静态特质（trait），而忽略了交互具体情境（state）的影响。用户与语言模型的交互既受特质影响，也受情境状态影响，但现有研究缺乏对状态因素的考量。

Method: 引入Chameleon数据集，包含5,001个来自1,667名Reddit用户的上下文心理档案，每个用户在多个情境下测量。基于潜在状态-特质理论进行方差分解分析，评估LLMs和奖励模型对用户状态的反应。

Result: 1. 方差分解显示74%的变异来自用户内部（状态），仅26%来自用户间（特质）；2. LLMs是"状态盲"的，只关注特质，对不同状态产生相似响应；3. 奖励模型对用户状态有反应但不一致，不同模型对相同用户的偏好方向相反。

Conclusion: 用户状态对语言模型交互的影响远大于特质，但当前LLMs无法感知状态变化。Chameleon数据集支持情感计算、个性化对话和RLHF对齐研究，有助于开发能更好理解用户情境状态的AI系统。

Abstract: User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.

</details>


### [13] [Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs](https://arxiv.org/abs/2601.15429)
*Sydney Anuyah,Mehedi Mahmud Kaushik,Hao Dai,Rakesh Shiradkar,Arjan Durresi,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 评估领域知识图谱是否能提升医疗RAG性能，发现图谱与查询范围对齐是关键，精确匹配的图谱检索效果最好，而盲目合并图谱会引入干扰降低准确性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成流畅答案时，可能在特定领域推理的可信度方面存在不足。研究旨在评估领域知识图谱是否能提升检索增强生成在医疗领域的表现

Method: 构建三个PubMed衍生的知识图谱（T2DM、阿尔茨海默病、两者结合），设计两个测试探针，测试7个指令调优的LLM在不同检索源和三个解码温度下的表现

Result: 图谱与查询范围对齐是关键：精确匹配的检索（特别是G2）带来最一致的提升，而盲目合并图谱会引入干扰降低准确性。大模型在参数先验强的情况下可能无需RAG，而中小模型从范围匹配的检索中获益更多。温度影响次要

Conclusion: 优先选择精确范围匹配的知识图谱RAG优于广度优先的图谱合并，并提出了图谱选择、模型大小和检索/重排的实用指南

Abstract: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\mathbb{G}_1$ and $\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_1$ + $\mathbb{G}_2$, $\mathbb{G}_3$, $\mathbb{G}_1$+$\mathbb{G}_2$ + $\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison

</details>


### [14] [Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering](https://arxiv.org/abs/2601.15457)
*Anuj Maharjan,Umesh Yadav*

Main category: cs.CL

TL;DR: 该研究评估了RAG架构在减少LLM幻觉方面的效果，通过将CDC政策文档作为权威背景来提升公共卫生政策问答的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM在公共卫生政策领域有应用潜力，但其产生的幻觉（看似合理但事实错误的断言）在高风险环境中构成重大障碍，需要可靠的方法来确保信息完整性。

Method: 比较了三种架构：Vanilla LLM、Basic RAG和Advanced RAG（使用交叉编码器重排序）。使用Mistral-7B-Instruct-v0.2模型和all-MiniLM-L6-v2嵌入模型处理CDC政策文档，评估了两种分块策略（递归字符分块和基于令牌的语义分割）对系统准确性的影响。

Result: Basic RAG在忠实度（0.621）上显著优于Vanilla基线（0.347），Advanced RAG达到最高的忠实度平均值0.797。两阶段检索机制对领域特定政策问答的精确性至关重要，但文档分割的结构限制仍然是多步推理任务的主要瓶颈。

Conclusion: RAG架构能有效减少LLM在公共卫生政策领域的幻觉，Advanced RAG表现最佳，但文档分割策略需要进一步优化以支持复杂推理任务。

Abstract: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.

</details>


### [15] [Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts](https://arxiv.org/abs/2601.15479)
*Sydney Anuyah,Sneha Shajee-Mohan,Ankit-Singh Chauhan,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 评估13个开源大语言模型在文本中因果发现任务上的表现，发现现有模型在因果检测和提取方面存在严重不足，最佳模型准确率仅约50%，难以处理复杂的真实场景。


<details>
  <summary>Details</summary>
Motivation: 为了安全地将大语言模型部署在生物医学等高风险领域，需要评估它们理解和推理因果关系的能力，这是模型可靠性的关键要求。

Method: 使用12个多样化数据集构建基准测试，评估两种核心能力：因果检测（识别文本中是否存在因果联系）和因果提取（提取具体的因果短语）。测试了多种提示方法，包括零样本、思维链和少样本上下文学习。

Result: 当前模型表现严重不足：因果检测最佳模型DeepSeek-R1-Distill-Llama-70B平均准确率仅49.57%，因果提取最佳模型Qwen2.5-Coder-32B-Instruct仅47.12%。模型在处理简单、显式、单句关系时表现较好，但在处理隐式关系、跨多句联系和多因果对文本时表现急剧下降。

Conclusion: 现有大语言模型在文本因果发现任务上能力有限，特别是在复杂现实场景中。研究提供了统一的评估框架和公开数据集，以推动该领域进一步发展。

Abstract: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).
  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($κ\ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}

</details>


### [16] [Multi-Persona Thinking for Bias Mitigation in Large Language Models](https://arxiv.org/abs/2601.15488)
*Yuxing Chen,Guoqing Luo,Zijun Wu,Lili Mou*

Main category: cs.CL

TL;DR: 提出MPT框架，通过多角色思维和辩证推理减少LLM的社会偏见，在保持推理能力的同时显著降低偏见


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在显著的社会偏见，可能延续有害刻板印象和不公平结果，需要有效方法在推理时减少这些偏见

Method: 提出多角色思维框架，引导模型采用对比的社会身份和中性视角，通过迭代辩证推理过程暴露和纠正偏见

Result: 在两个广泛使用的偏见基准测试中，MPT相比现有提示策略显著降低偏见，同时保持核心推理能力

Conclusion: MPT框架将角色分配的潜在弱点转化为偏见缓解的优势，为LLM偏见减少提供了有效的推理时方法

Abstract: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.

</details>


### [17] [ViT Registers and Fractal ViT](https://arxiv.org/abs/2601.15506)
*Jason Chuan-Chih Chou,Abhinav Kumar,Shivank Garg*

Main category: cs.CL

TL;DR: 本文提出了一种名为fractal ViT的视觉Transformer变体，通过引入"摘要令牌"和注意力掩码来打破令牌的置换不变性，但实验表明该模型并未超越带寄存器的ViT性能。


<details>
  <summary>Details</summary>
Motivation: 受到两个最新发现的启发：1）无位置编码的Transformer在语言模型中表现出令人惊讶的良好性能；2）寄存器（与输入无关的额外丢弃令牌）可能提升大型视觉Transformer的性能。作者希望探索通过引入类似寄存器的"摘要令牌"和注意力掩码来打破令牌置换不变性的方法。

Method: 提出fractal ViT变体，在常规令牌和"摘要令牌"之间应用注意力掩码，这些摘要令牌类似于寄存器。该方法可以单独使用，也可以与各种位置编码组合使用，旨在打破令牌间的置换不变性。

Result: 实验结果表明，fractal ViT模型并未超越带寄存器的ViT性能，说明这些发现可能是特定于规模、领域或应用的。

Conclusion: 虽然受启发于语言模型和视觉Transformer的最新发现，但提出的fractal ViT变体并未带来性能提升，强调了这些发现可能具有规模、领域或应用特定性，需要更深入的研究来理解这些机制的有效条件。

Abstract: Drawing inspiration from recent findings including surprisingly decent performance of transformers without positional encoding (NoPE) in the domain of language models and how registers (additional throwaway tokens not tied to input) may improve the performance of large vision transformers (ViTs), we invent and test a variant of ViT called fractal ViT that breaks permutation invariance among the tokens by applying an attention mask between the regular tokens and ``summary tokens'' similar to registers, in isolation or in combination with various positional encodings. These models do not improve upon ViT with registers, highlighting the fact that these findings may be scale, domain, or application-specific.

</details>


### [18] [Computational Representations of Character Significance in Novels](https://arxiv.org/abs/2601.15508)
*Haaris Mian,Melanie Subbiah,Sharon Marcus,Nora Shaalan,Kathleen McKeown*

Main category: cs.CL

TL;DR: 提出基于六成分结构模型的人物分析方法，比较通用LLM与任务特定transformer在19世纪英国现实主义小说中的应用，探索人物中心性与性别动态


<details>
  <summary>Details</summary>
Motivation: 传统人物建模主要基于场景存在、行动、命名提及和对话，过于强调场景最多的主角。需要更全面的人物模型，考虑叙述者-人物区分和以往方法忽视的"他人讨论"成分

Method: 采用六成分结构模型，比较通用大语言模型与任务特定transformer在19世纪英国现实主义小说中的应用，生成成分级和图表示的人物讨论表征

Result: 方法能生成人物讨论的成分级和图表示，为文学问题提供新的计算视角，探索Woloch的"一与多"人物中心性理论和人物讨论的性别动态

Conclusion: 六成分结构模型为人物分析提供了更全面的框架，计算表征方法能够大规模探索传统文学理论问题，如人物中心性和性别动态

Abstract: Characters in novels have typically been modeled based on their presence in scenes in narrative, considering aspects like their actions, named mentions, and dialogue. This conception of character places significant emphasis on the main character who is present in the most scenes. In this work, we instead adopt a framing developed from a new literary theory proposing a six-component structural model of character. This model enables a comprehensive approach to character that accounts for the narrator-character distinction and includes a component neglected by prior methods, discussion by other characters. We compare general-purpose LLMs with task-specific transformers for operationalizing this model of character on major 19th-century British realist novels. Our methods yield both component-level and graph representations of character discussion. We then demonstrate that these representations allow us to approach literary questions at scale from a new computational lens. Specifically, we explore Woloch's classic "the one vs the many" theory of character centrality and the gendered dynamics of character discussion.

</details>


### [19] [AdversaRiskQA: An Adversarial Factuality Benchmark for High-Risk Domains](https://arxiv.org/abs/2601.15511)
*Adam Szelestey,Sofie van Engelen,Tianhao Huang,Justin Snelders,Qintao Zeng,Songgaojun Deng*

Main category: cs.CL

TL;DR: 提出了AdversaRiskQA基准，用于系统评估LLM在健康、金融和法律领域对抗性事实性方面的表现，包含两个难度级别和自动评估方法。


<details>
  <summary>Details</summary>
Motivation: LLM中的幻觉问题在高风险领域尤为严重，现有研究缺乏高质量、领域特定的资源来评估模型在对抗性条件下的鲁棒性，且没有研究考察注入错误信息对长文本事实性的影响。

Method: 引入AdversaRiskQA基准，包含健康和金融法律三个领域，两个难度级别；提出两种自动评估方法评估对抗攻击成功率和长文本事实性；评估了六个开源和闭源LLM。

Result: 排除无意义回答后，Qwen3 (80B)平均准确率最高，GPT-5保持高准确率；性能随模型规模非线性增长，领域间有差异；难度级别差距随模型增大而缩小；长文本评估显示注入错误信息与模型事实输出无显著相关性。

Conclusion: AdversaRiskQA为识别LLM弱点和发展高风险应用更可靠模型提供了有价值的基准，对抗性错误信息注入对长文本事实性影响有限。

Abstract: Hallucination in large language models (LLMs) remains an acute concern, contributing to the spread of misinformation and diminished public trust, particularly in high-risk domains. Among hallucination types, factuality is crucial, as it concerns a model's alignment with established world knowledge. Adversarial factuality, defined as the deliberate insertion of misinformation into prompts with varying levels of expressed confidence, tests a model's ability to detect and resist confidently framed falsehoods. Existing work lacks high-quality, domain-specific resources for assessing model robustness under such adversarial conditions, and no prior research has examined the impact of injected misinformation on long-form text factuality.
  To address this gap, we introduce AdversaRiskQA, the first verified and reliable benchmark systematically evaluating adversarial factuality across Health, Finance, and Law. The benchmark includes two difficulty levels to test LLMs' defensive capabilities across varying knowledge depths. We propose two automated methods for evaluating the adversarial attack success and long-form factuality. We evaluate six open- and closed-source LLMs from the Qwen, GPT-OSS, and GPT families, measuring misinformation detection rates. Long-form factuality is assessed on Qwen3 (30B) under both baseline and adversarial conditions. Results show that after excluding meaningless responses, Qwen3 (80B) achieves the highest average accuracy, while GPT-5 maintains consistently high accuracy. Performance scales non-linearly with model size, varies by domains, and gaps between difficulty levels narrow as models grow. Long-form evaluation reveals no significant correlation between injected misinformation and the model's factual output. AdversaRiskQA provides a valuable benchmark for pinpointing LLM weaknesses and developing more reliable models for high-stakes applications.

</details>


### [20] [Common to Whom? Regional Cultural Commonsense and LLM Bias in India](https://arxiv.org/abs/2601.15550)
*Sangmitra Madhusudan,Trush Shashank More,Steph Buongiorno,Renata Dividino,Jad Kabbara,Ali Emami*

Main category: cs.CL

TL;DR: Indica是首个评估LLMs对印度次国家级文化常识理解的基准，发现印度文化常识主要是区域性的而非全国性的，现有模型存在准确率低和地理偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有文化常识基准将国家视为整体，假设国家边界内实践统一，但文化常识是否在国家内部一致？需要研究次国家级文化差异，特别是在印度这样文化多样的国家。

Method: 创建Indica基准，聚焦印度28个邦、8个中央直辖区和22种官方语言。从五个地区收集人类标注答案，涵盖515个问题、8个日常生活领域，得到1,630个区域特定问答对。评估8个最先进LLMs。

Result: 仅39.4%的问题在五个地区达成一致，表明印度文化常识主要是区域性的。LLMs在区域特定问题上准确率仅13.4%-20.9%，存在地理偏见：过度选择中部和北部作为"默认"（比预期多30-40%），而东部和西部代表性不足。

Conclusion: 文化常识在印度主要是区域性的而非全国性的，现有LLMs在理解和表示次国家级文化差异方面存在显著不足。该方法论为评估任何文化异质国家的文化常识提供了可推广框架。

Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.

</details>


### [21] [From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare](https://arxiv.org/abs/2601.15558)
*Man Luo,Bahareh Harandizadeh,Amara Tariq,Halim Abbas,Umar Ghaffar,Christopher J Warren,Segun O. Kolade,Haidar M. Abdul-Muhsin*

Main category: cs.CL

TL;DR: LLMs作为共情编辑器，能提升医生书面回复的共情语调，同时保持医学事实准确性，比完全由LLM生成的回复更安全有效


<details>
  <summary>Details</summary>
Motivation: 临床共情对患者护理至关重要，但医生需要在认知和情感约束下平衡情感温暖与事实准确性。研究探索如何利用LLMs作为共情编辑器来优化医患沟通

Method: 引入两个新颖的定量指标：共情排名分数和医学事实核查分数，系统评估回复的情感和事实质量。实验比较LLM编辑的回复与完全LLM生成的回复

Result: LLM编辑的回复显著提高了感知共情度，同时保持了事实准确性，优于完全由LLM生成的输出

Conclusion: 将LLMs用作编辑助手而非自主生成器，为AI辅助医疗沟通提供了更安全、更有效的途径，实现共情与可信度的平衡

Abstract: Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.

</details>


### [22] [YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models](https://arxiv.org/abs/2601.15588)
*Junyu Lin,Meizhen Liu,Xiufeng Huang,Jinfeng Li,Haiwen Hong,Xiaohan Yuan,Yuefeng Chen,Longtao Huang,Hui Xue,Ranjie Duan,Zhikai Chen,Yuchuan Fu,Defeng Li,Lingyao Gao,Yitong Yang*

Main category: cs.CL

TL;DR: YuFeng-XGuard是一个基于推理的安全护栏模型家族，通过结构化风险预测和多层推理机制，为LLM交互提供细粒度、可解释、可配置的风险评估。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全解决方案主要依赖粗粒度过滤或后处理规则，存在透明度低、策略不灵活、推理成本高等问题。需要一种能够提供细粒度、可解释、可适应风险评估的安全护栏系统。

Method: 1. 采用推理中心化设计，生成结构化风险预测（包括风险类别、可配置置信度、自然语言解释）；2. 分层推理范式：基于首个解码token进行初始风险决策，按需提供详细解释推理；3. 动态策略机制：将风险感知与策略执行解耦，无需重新训练即可调整安全策略。

Result: 在多个公共安全基准测试中，YuFeng-XGuard实现了最先进的性能，同时在效率与效果之间保持良好平衡。发布了完整容量和轻量级两个版本，支持多种部署场景。

Conclusion: YuFeng-XGuard通过结构化风险预测、分层推理和动态策略机制，为LLM安全提供了可解释、可配置、高效的安全护栏解决方案，超越了传统的二元分类方法。

Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.

</details>


### [23] [Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow](https://arxiv.org/abs/2601.15593)
*Yangyang Zhong,Yanmei Gu,Zhengqing Zang,Xiaomeng Li,Yuqi Ding,Xibei Jia,Yuting Shen,Zhenzhong Lan,Liwang Zhu,Weiping Liu,Junlin Zhou,Haisheng Liu,Zhong Xin Yu,Pengxin Luo,Donglian Qi,Yunfeng Yan,Junbo Zhao*

Main category: cs.CL

TL;DR: MDLMs在并行生成和任意顺序解码方面表现有限，主要因为并行概率建模削弱了token间依赖关系，落后于同等规模的自回归模型，但展示了任务自适应的解码行为。


<details>
  <summary>Details</summary>
Motivation: 研究MDLMs是否真正实现了并行token生成和任意顺序解码的承诺，评估其在各种任务上的实际表现，并分析其局限性。

Method: 使用平均最终化并行度(AFP)和Kendall's tau两个指标，在58个涵盖知识、推理和编程的基准上评估8个主流MDLM模型（最大100B参数）。

Result: MDLMs在并行建模中token间依赖关系较弱，性能落后于同等规模自回归模型；但展示出自适应解码行为：并行度和生成顺序随任务领域、推理阶段和输出正确性显著变化；在某些需要"后向信息"的任务上表现优势。

Conclusion: 提出了"生成-编辑"范式，既能缓解依赖关系损失，又能保持并行解码的效率，为MDLMs的改进提供了理论动机和设计思路。

Abstract: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require "backward information" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.

</details>


### [24] [ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms](https://arxiv.org/abs/2601.15605)
*Baktash Ansari,Shiza Ali,Elias Martin,Maryna Sivachenko,Afra Mashhadi*

Main category: cs.CL

TL;DR: 本文提出ToxiTwitch混合模型，结合LLM生成的文本和表情符号嵌入与传统机器学习分类器，用于Twitch直播平台的有毒行为检测，在特定频道训练下达到80%准确率。


<details>
  <summary>Details</summary>
Motivation: Twitch等直播平台面临有毒行为检测的复杂挑战。传统人工标注和关键词过滤方法难以应对平台快节奏、高流量、上下文丰富的聊天环境，且人工审核员自身也面临骚扰。LLM的发展为理解包含表情符号的复杂多模态通信提供了新机会。

Method: 提出ToxiTwitch混合模型，结合LLM（如DeepSeek-R1-Distill和Llama-3-8B-Instruct）生成的文本和表情符号嵌入表示，与传统机器学习分类器（随机森林和SVM）相结合。通过探索性比较分析，发现纳入表情符号能改善有毒行为检测。

Result: 在特定频道训练下，混合方法达到80%准确率，相比BERT提升13%，F1分数为76%。研究表明结合表情符号能有效改善Twitch平台的有毒行为检测。

Conclusion: 这是一项探索性研究，旨在揭示Twitch平台上表情符号感知的有毒行为检测面临的挑战和限制。研究表明结合LLM生成的表情符号嵌入能提升检测性能，为直播平台内容审核提供了新思路。

Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.

</details>


### [25] [Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation](https://arxiv.org/abs/2601.15645)
*Zhiyao Ren,Yibing Zhan,Siyuan Liang,Guozheng Ma,Baosheng Yu,Dacheng Tao*

Main category: cs.CL

TL;DR: 提出了首个用于评估多轮医疗咨询中置信度的基准，并开发了MedConf框架，通过基于证据的语言自我评估来提升医疗诊断的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要在单轮静态设置中评估置信度，忽视了临床证据积累过程中置信度与正确性的动态耦合关系，限制了其对可靠医疗决策的支持。

Method: 1) 提出首个多轮医疗咨询置信度评估基准，统一三类医疗数据用于开放式诊断生成，引入信息充分性梯度；2) 开发MedConf框架：通过检索增强生成构建症状档案，将患者信息与支持、缺失、矛盾关系对齐，通过加权整合生成可解释的置信度估计。

Result: 在两个大语言模型和三个医疗数据集上，MedConf在AUROC和Pearson相关系数指标上均优于现有方法，在信息不足和多病共存条件下保持稳定性能。

Conclusion: 信息充分性是可信医疗置信度建模的关键决定因素，为构建更可靠、可解释的大型医疗模型提供了新途径。

Abstract: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.

</details>


### [26] [What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking](https://arxiv.org/abs/2601.15674)
*Raymond Xiong,Furong Jia,Lionel Wong,Monica Agrawal*

Main category: cs.CL

TL;DR: 研究创建了一个基于患者真实提问的医疗问答数据集，发现许多问题包含错误假设和危险意图，而当前LLM难以识别这些日常问题中的错误假设


<details>
  <summary>Details</summary>
Motivation: 现有LLM医疗问答基准主要关注医学考试问题，与患者实际提问风格和内容差异很大，需要建立更贴近真实患者提问的评估基准

Method: 通过Google的"People Also Ask"功能，查询美国前200种处方药，收集人们常问的医疗问题，构建数据集并分析问题特征

Result: 收集的数据集中相当一部分问题包含错误假设和危险意图；这些"腐化问题"的出现不是随机的，而是与历史问题中的错误程度密切相关；当前在其他基准上表现良好的LLM难以识别日常问题中的错误假设

Conclusion: 需要开发能够识别患者日常提问中错误假设和危险意图的LLM，现有医疗问答基准与真实需求存在差距

Abstract: Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.

</details>


### [27] [Persona Switch: Mixing Distinct Perspectives in Decoding Time](https://arxiv.org/abs/2601.15708)
*Junseok Kim,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 提出Persona Switch解码方法，动态结合零样本提示和角色扮演提示的优势，通过比较输出置信度选择每步更好的输出，在多种任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 角色扮演提示通过注入角色来引导语言模型行为，提升零样本推理能力，但这种提升在不同任务或实例中表现不一致。零样本提示和角色扮演提示可能具有互补优势而非一方绝对优越。

Method: 提出Persona Switch解码方法：逐步处理，在每一步比较零样本提示和角色扮演提示的输出置信度（通过logit gap衡量），选择置信度更高的输出。动态结合两种提示策略的优势。

Result: 实验表明Persona Switch在广泛使用的LLMs上一致优于竞争基线，最高实现5.13%的准确率提升。输出置信度被证明是选择更可靠输出的有效指标。

Conclusion: Persona Switch通过动态结合零样本和角色扮演提示的优势，提供了一种有效的解码方法，能够提升语言模型在各种任务上的性能，输出置信度是选择可靠输出的有用指标。

Abstract: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.

</details>


### [28] [Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind](https://arxiv.org/abs/2601.15715)
*Zhitao He,Zongwei Lyu,Yi R Fung*

Main category: cs.CL

TL;DR: 提出了首个基于心智理论（ToM）的学术反驳框架RebuttalAgent，通过TSR管道建模审稿人心理状态、制定说服策略并生成策略驱动的回应，在自动和人工评估中显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 学术反驳是研究流程中重要但未被充分探索的挑战，因为反驳是在严重信息不对称下的战略沟通过程而非简单的技术辩论。现有方法主要模仿表面语言特征，缺乏有效说服所需的心智理论视角。

Method: 提出RebuttalAgent框架，采用ToM-Strategy-Response（TSR）管道：1）建模审稿人心理状态；2）制定说服策略；3）生成策略驱动的回应。构建大规模数据集RebuttalBench，采用两阶段训练：监督微调+基于自奖励机制的强化学习。开发专门评估器Rebuttal-RM。

Result: RebuttalAgent在自动指标上平均优于基础模型18.3%，在自动和人工评估中均优于先进的专有模型。Rebuttal-RM评估器在评分一致性上超过GPT-4.1，与人类偏好更一致。

Conclusion: 该研究首次将心智理论引入学术反驳任务，提出的RebuttalAgent框架通过建模审稿人心理状态和制定策略性回应，显著提升了反驳质量。生成的回复仅供作者参考和启发，不替代作者的批判性分析和回应。

Abstract: Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.

</details>


### [29] [Hallucination Mitigating for Medical Report Generation](https://arxiv.org/abs/2601.15745)
*Ruoqing Zhao,Runze Xia,Piji Li*

Main category: cs.CL

TL;DR: KERM框架通过知识检索、知识纯化和细粒度奖励机制，有效减少医学报告生成中的幻觉问题，提升报告质量。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学报告生成中容易产生看似合理但不准确的"幻觉"陈述，这在关键的医学领域存在安全隐患，需要解决这一问题。

Method: 1) 使用MedCLIP从知识库中检索相关病变事实句子；2) 引入知识纯化模块确保检索知识与患者临床上下文相关；3) 采用细粒度奖励机制引导模型生成高度支持性和临床相关的描述。

Result: 在IU-Xray和MIMIC-CXR数据集上的实验结果表明，该方法能有效缓解幻觉问题并提升报告质量。

Conclusion: KERM框架通过知识增强和强化学习奖励机制，成功解决了医学报告生成中的幻觉问题，为临床实践提供了更可靠的辅助工具。

Abstract: In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \textbf{K}nowledge-\textbf{E}nhanced with Fine-Grained \textbf{R}einforced Rewards \textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.

</details>


### [30] [Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs](https://arxiv.org/abs/2601.15755)
*Tristan Williams,Franziska Weeber,Sebastian Padó,Alan Akbik*

Main category: cs.CL

TL;DR: 论文提出一个评估语言模型代表性的框架，不仅关注边缘响应分布，还强调多元相关模式的重要性，发现现有对齐技术在捕捉真实人群相关结构方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语言模型与人类价值观的对齐，但大多只评估边缘响应分布，忽略了真实人群的深层潜在结构和相关模式，可能导致对模型能力的过度乐观评估。

Method: 提出一个评估框架，同时考虑多元相关模式和边缘分布；比较两种模型引导技术（角色提示和人口统计微调）；使用世界价值观调查的人类响应作为黄金标准进行评估。

Result: 人口统计微调模型在边缘响应分布上优于角色提示，但两种技术都未能完全捕捉黄金标准的相关模式；仅关注边缘分布会掩盖结构性问题。

Conclusion: 代表性是价值对齐的一个独立方面，仅关注边缘分布的评估可能掩盖结构失败，导致对模型能力的过度乐观结论；需要同时评估相关模式和分布。

Abstract: Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.

</details>


### [31] [HumanLLM: Towards Personalized Understanding and Simulation of Human Nature](https://arxiv.org/abs/2601.15793)
*Yuxuan Lei,Tianfu Wang,Jianxun Lian,Zhengyu Hu,Defu Lian,Xing Xie*

Main category: cs.CL

TL;DR: HumanLLM是一个用于个性化理解和模拟个体的基础模型，通过从真实用户数据构建的认知基因组数据集进行训练，显著提升了预测人类行为和思维的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学和编程等客观任务上表现出色，但在模拟人类行为方面存在局限，缺乏对人类认知和行为的细致理解。这种限制源于标准预训练未能捕捉个体在连续情境下的决策、思维和行为模式。

Method: 首先构建认知基因组数据集，从Reddit、Twitter、Blogger和Amazon等平台收集真实用户数据，通过多阶段流水线自动提取550多万条用户日志。然后设计多样化学习任务，通过监督微调使模型能够预测广泛的个性化人类行为、思维和体验。

Result: HumanLLM在预测用户行为和内心思维方面表现优异，能更准确地模仿用户写作风格和偏好，生成更真实的用户画像。在跨领域社交智能基准测试中也显示出显著的泛化能力提升。

Conclusion: HumanLLM通过从真实世界用户数据中学习连续、情境化的个体模式，成功弥补了大语言模型在人类行为模拟方面的不足，为社会科学研究和以客户为中心的商业洞察提供了强大的基础模型。

Abstract: Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.

</details>


### [32] [SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics](https://arxiv.org/abs/2601.15809)
*Silvia Casola,Ryan Soh-Eun Shim,Felicia Körner,Yuchen Mao,Barbara Plank*

Main category: cs.CL

TL;DR: 通过引导多语言神经指标激活向英语枢轴语言对齐，提高其与人类判断的相关性


<details>
  <summary>Details</summary>
Motivation: 多语言自然语言生成任务缺乏准确鲁棒的评估指标，且多语言模型常以英语为内部枢轴语言，这种不匹配可能导致下游性能下降。研究假设这种不匹配也适用于多语言神经指标，探索通过引导激活向英语对齐是否能改善与人类判断的相关性。

Method: 实验采用编码器和解码器基础的指标，应用测试时干预方法，引导多语言神经指标的激活向英语枢轴语言对齐。

Result: 测试时干预方法普遍有效，能够提高指标对多种语言的有效性，增强与人类判断的相关性。

Conclusion: 通过引导多语言神经指标激活向英语枢轴语言对齐，可以有效改善其评估性能，为解决多语言自然语言生成任务中的评估瓶颈提供了可行方案。

Abstract: An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.

</details>


### [33] [ExDR: Explanation-driven Dynamic Retrieval Enhancement for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15820)
*Guoxuan Ding,Yuqing Li,Ziyan Zhou,Zheng Lin,Daren Zha,Jiangnan Li*

Main category: cs.CL

TL;DR: 提出ExDR框架，通过解释驱动的动态检索增强生成技术，解决多模态假新闻检测中的冗余检索、相似度粗糙和无关证据等问题。


<details>
  <summary>Details</summary>
Motivation: 多模态假新闻的快速传播构成严重社会威胁，其动态演化和依赖时效性事实的特点挑战现有检测方法。动态检索增强生成技术虽能通过关键词检索和外部知识整合提供解决方案，但在处理欺骗性内容时仍面临冗余检索、相似度粗糙和无关证据等挑战。

Method: 提出ExDR框架，在检索触发和证据检索模块中系统利用模型生成的解释：1）从三个互补维度评估触发置信度；2）通过融合欺骗性实体构建实体感知索引；3）基于欺骗特定特征检索对比证据来挑战初始主张并增强最终预测。

Result: 在AMG和MR2两个基准数据集上的实验表明，ExDR在检索触发准确性、检索质量和整体检测性能方面均优于先前方法，证明了其有效性和泛化能力。

Conclusion: ExDR框架通过解释驱动的动态检索增强生成技术，有效解决了多模态假新闻检测中的关键挑战，在多个性能指标上展现了优越性，为假新闻检测提供了有前景的解决方案。

Abstract: The rapid spread of multimodal fake news poses a serious societal threat, as its evolving nature and reliance on timely factual details challenge existing detection methods. Dynamic Retrieval-Augmented Generation provides a promising solution by triggering keyword-based retrieval and incorporating external knowledge, thus enabling both efficient and accurate evidence selection. However, it still faces challenges in addressing issues such as redundant retrieval, coarse similarity, and irrelevant evidence when applied to deceptive content. In this paper, we propose ExDR, an Explanation-driven Dynamic Retrieval-Augmented Generation framework for Multimodal Fake News Detection. Our framework systematically leverages model-generated explanations in both the retrieval triggering and evidence retrieval modules. It assesses triggering confidence from three complementary dimensions, constructs entity-aware indices by fusing deceptive entities, and retrieves contrastive evidence based on deception-specific features to challenge the initial claim and enhance the final prediction. Experiments on two benchmark datasets, AMG and MR2, demonstrate that ExDR consistently outperforms previous methods in retrieval triggering accuracy, retrieval quality, and overall detection performance, highlighting its effectiveness and generalization capability.

</details>


### [34] [Can professional translators identify machine-generated text?](https://arxiv.org/abs/2601.15828)
*Michael Farrell*

Main category: cs.CL

TL;DR: 研究发现，未经专门训练的专业译者能部分识别AI生成的意大利语短篇小说，16.2%的译者能可靠区分AI与人类作品，但近等数量译者误判方向，显示AI文本可能更受读者偏好。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究专业译者是否能在未经专门训练的情况下可靠识别AI生成的意大利语短篇小说，这对于理解AI文本在专业翻译环境中的可检测性具有重要意义。

Method: 69名译者参与现场实验，评估三篇匿名短篇小说（两篇由ChatGPT-4o生成，一篇由人类作者创作）。参与者对每篇故事评估AI作者的可能性并提供判断依据。

Result: 平均结果不明确，但16.2%的译者能成功区分合成文本与人类文本，显示其判断基于分析技能而非偶然。低爆发性和叙事矛盾是最可靠的AI文本指标，而语法准确性和情感基调常导致误判。

Conclusion: 研究显示专业译者能部分识别AI文本，但误判率较高，AI文本可能更受读者偏好。这引发了关于合成文本编辑在专业环境中作用和范围的疑问。

Abstract: This study investigates whether professional translators can reliably identify short stories generated in Italian by artificial intelligence (AI) without prior specialized training. Sixty-nine translators took part in an in-person experiment, where they assessed three anonymized short stories - two written by ChatGPT-4o and one by a human author. For each story, participants rated the likelihood of AI authorship and provided justifications for their choices. While average results were inconclusive, a statistically significant subset (16.2%) successfully distinguished the synthetic texts from the human text, suggesting that their judgements were informed by analytical skill rather than chance. However, a nearly equal number misclassified the texts in the opposite direction, often relying on subjective impressions rather than objective markers, possibly reflecting a reader preference for AI-generated texts. Low burstiness and narrative contradiction emerged as the most reliable indicators of synthetic authorship, with unexpected calques, semantic loans and syntactic transfer from English also reported. In contrast, features such as grammatical accuracy and emotional tone frequently led to misclassification. These findings raise questions about the role and scope of synthetic-text editing in professional contexts.

</details>


### [35] [Determinants of Training Corpus Size for Clinical Text Classification](https://arxiv.org/abs/2601.15846)
*Jaya Chaturvedi,Saniya Deshpande,Chenkai Ma,Robert Cobb,Angus Roberts,Robert Stewart,Daniel Stahl,Diana Shamsutdinova*

Main category: cs.CL

TL;DR: 临床文本分类中，600份文档即可达到使用10,000份文档时95%的性能，词汇属性（强预测词和噪声词数量）显著影响学习曲线


<details>
  <summary>Details</summary>
Motivation: 临床文本分类通常需要标注200-500份文档，但这一数量缺乏理论依据，且未考虑文本词汇特性与样本量需求的关系

Method: 使用MIMIC-III数据集，采用预训练BERT嵌入和随机森林分类器，分析10个随机选择的诊断任务，训练集规模从100到10,000份文档，通过Lasso逻辑回归分析词汇属性

Result: 不同分类任务的学习曲线差异显著，600份文档足以达到10,000份文档95%的性能；词汇分析显示强预测词越多、噪声词越少，学习曲线越陡峭

Conclusion: 临床文本分类的样本量需求与词汇特性密切相关，600份文档可能是合理的基准，词汇分析可为样本量确定提供指导

Abstract: Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
  Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
  Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.

</details>


### [36] [Artificial Rigidities vs. Biological Noise: A Comparative Analysis of Multisensory Integration in AV-HuBERT and Human Observers](https://arxiv.org/abs/2601.15869)
*Francisco Portillo López*

Main category: cs.CL

TL;DR: AV-HuBERT模型在McGurk效应测试中与人类表现出惊人的听觉主导率相似性（32.0% vs 31.8%），但在语音融合方面存在确定性偏差（68.0% vs 47.7%），缺乏人类感知的随机性和多样性。


<details>
  <summary>Details</summary>
Motivation: 评估自监督学习模型AV-HuBERT在感知生物保真度方面的表现，特别是通过McGurk效应测试其对视听不一致刺激的反应能力，并与人类观察者进行比较。

Method: 使用McGurk效应范式，将AV-HuBERT模型与44名人类观察者进行对比测试，评估两者对不一致视听刺激的反应模式，包括听觉主导率和语音融合率。

Result: AI与人类在听觉主导率上表现出惊人的相似性（32.0% vs 31.8%），但AV-HuBERT在语音融合方面显著高于人类（68.0% vs 47.7%），且缺乏人类感知的随机性和多样性。

Conclusion: 当前自监督架构能够模拟多感官整合的结果，但缺乏人类语音感知固有的神经变异性，模型表现出确定性偏差而人类则具有感知随机性。

Abstract: This study evaluates AV-HuBERT's perceptual bio-fidelity by benchmarking its response to incongruent audiovisual stimuli (McGurk effect) against human observers (N=44). Results reveal a striking quantitative isomorphism: AI and humans exhibited nearly identical auditory dominance rates (32.0% vs. 31.8%), suggesting the model captures biological thresholds for auditory resistance. However, AV-HuBERT showed a deterministic bias toward phonetic fusion (68.0%), significantly exceeding human rates (47.7%). While humans displayed perceptual stochasticity and diverse error profiles, the model remained strictly categorical. Findings suggest that current self-supervised architectures mimic multisensory outcomes but lack the neural variability inherent to human speech perception.

</details>


### [37] [Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model](https://arxiv.org/abs/2601.15892)
*Chenghao Fan,Wen Heng,Bo Li,Sichen Liu,Yuxuan Song,Jing Su,Xiaoye Qu,Kai Shen,Wei Wei*

Main category: cs.CL

TL;DR: Stable-DiffCoder：基于块扩散的代码模型，通过持续预训练和定制化噪声调度，在代码任务上超越了同等规模的AR模型，展示了扩散模型在代码建模中的优势。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的语言模型（DLLMs）在代码生成任务上仍落后于自回归（AR）模型，尽管DLLMs具有非顺序生成和更好的数据复用优势。作者希望探索扩散模型在代码建模中的潜力，并提升其性能。

Method: 采用Seed-Coder架构、数据和训练流程，引入块扩散持续预训练（CPT）阶段，配合定制化的预热策略和块级裁剪噪声调度，实现高效知识学习和稳定训练。

Result: 在相同数据和架构下，Stable-DiffCoder在广泛的代码基准测试中整体超越了其AR对应模型。仅通过CPT和监督微调阶段，就超越了多种约8B参数的AR和DLLMs模型。

Conclusion: 扩散训练可以超越AR训练提升代码建模质量，扩散模型的任意顺序建模能力改进了结构化代码的编辑和推理，并通过数据增强有益于低资源编程语言。

Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.

</details>


### [38] [Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech](https://arxiv.org/abs/2601.15909)
*Soufiane Jhilal,Stéphanie Martin,Anne-Lise Giraud*

Main category: cs.CL

TL;DR: 使用预训练视觉模型处理MEG信号的时频图像表示，实现非侵入式想象语音解码，在多项任务中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 想象语音的非侵入式解码面临信号弱、分布广和标记数据有限的挑战，需要开发更有效的方法来提取神经信号中的语义信息。

Method: 将MEG信号转换为时频表示，通过可学习的传感器空间卷积生成三通道空间尺度混合图像，然后使用ImageNet预训练的视觉模型进行处理。

Result: 预训练视觉模型在多项任务中表现优异：想象vs静默90.4%平衡准确率，想象vs默读81.0%，元音解码60.6%。跨被试评估证实模型能捕捉共享神经表征。

Conclusion: 预训练视觉模型应用于基于图像的MEG表示能有效捕捉想象语音的神经结构，为非侵入式脑机接口提供了有前景的新方法。

Abstract: Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.

</details>


### [39] [Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain](https://arxiv.org/abs/2601.16018)
*Özgür Uğur,Mahmut Göksu,Mahmut Çimen,Musa Yılmaz,Esra Şavirdi,Alp Talha Demir,Rumeysa Güllüce,İclal Çetin,Ömer Can Sağbaş*

Main category: cs.CL

TL;DR: Mecellem模型框架通过领域适应策略开发土耳其法律领域的专用语言模型，包括基于ModernBERT的编码器模型和基于Qwen3的解码器模型，在土耳其法律检索和文本理解任务上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对土耳其法律领域的语言模型，解决现有通用模型在法律领域表现不足的问题，同时提供更高效、成本更低的训练方案替代计算密集的多阶段训练流程。

Method: 1. 编码器模型：基于ModernBERT架构，在1127亿土耳其语为主的语料上进行预训练，采用检查点选择策略评估下游检索性能；2. 解码器模型：对Qwen3-1.7B和Qwen3-4B进行持续预训练，采用四阶段课程学习，逐步从通用语言过渡到专业法律术语和长上下文推理。

Result: 编码器模型在土耳其检索排行榜上获得前三名，小模型（1.55亿参数）性能媲美大模型（3.07-5.67亿参数），生产效率达92.36%；解码器模型在土耳其法律文本上的困惑度降低36.2%，显示领域适应效果显著。

Conclusion: Mecellem框架通过有效的领域适应策略成功开发了土耳其法律领域的专用语言模型，证明了单阶段预训练加高效后训练方法的成本效益优势，为法律领域NLP应用提供了实用解决方案。

Abstract: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.

</details>


### [40] [Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction](https://arxiv.org/abs/2601.16034)
*Tony Cristofano*

Main category: cs.CL

TL;DR: 提出Trajectory Replay via Concept-Basis Reconstruction框架，通过概念指纹对齐和概念原子重构，将拒绝干预从捐赠模型转移到目标模型，证明安全对齐具有语义普遍性。


<details>
  <summary>Details</summary>
Motivation: 对齐LLM中的拒绝行为通常被视为模型特定的，但作者假设它源于跨模型共享的通用低维语义电路。为了验证这一假设，需要开发能够跨不同架构和训练机制转移拒绝干预的方法。

Method: 引入Trajectory Replay via Concept-Basis Reconstruction框架：1) 通过概念指纹对齐层；2) 使用共享的"概念原子"配方重构拒绝方向；3) 将捐赠模型的消融轨迹映射到目标模型的语义空间；4) 引入weight-SVD稳定性保护，将干预投影到低方差权重子空间以避免能力损害。

Result: 在8个模型对（包括GPT-OSS-20B和GLM-4）上的评估表明，转移的配方能够持续减弱拒绝行为，同时保持模型性能，为安全对齐的语义普遍性提供了有力证据。

Conclusion: 拒绝行为源于跨模型共享的通用低维语义电路，安全对齐具有语义普遍性。提出的框架能够有效转移拒绝干预，为理解LLM对齐机制提供了新视角。

Abstract: Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.

</details>


### [41] [Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating](https://arxiv.org/abs/2601.16097)
*Makbule Gulcin Ozsoy*

Main category: cs.CL

TL;DR: 本文提出一种可扩展的多语言Text2Cypher方法，通过训练语言特定的LoRA适配器并使用融合MLP动态组合，实现新语言支持而无需完整微调，在性能、数据效率和可扩展性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 当前Text2SQL、Text2SPARQL和Text2Cypher等自然语言数据库接口系统主要支持英语，多语言支持有限。需要一种可扩展的方法来支持新语言，避免重新进行完整的微调、手动超参数调优，同时保持接近联合多语言微调的性能。

Method: 为英语、西班牙语和土耳其语训练语言特定的LoRA适配器，然后通过两种方式组合：均匀线性合并或学习融合MLP（带动态门控）。融合MLP学习如何动态组合不同语言的适配器权重。

Result: 实验结果显示，融合MLP恢复了约75%的联合多语言微调带来的准确率提升，同时只需要较小的数据子集。在所有三种语言上都优于线性合并方法。

Conclusion: 学习适配器融合为昂贵的联合微调提供了实用的替代方案，通过仅需一个LoRA适配器和轻量级MLP重新训练即可实现增量语言扩展，在性能、数据效率和可扩展性之间取得良好平衡。

Abstract: Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.

</details>


### [42] [synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier](https://arxiv.org/abs/2601.16113)
*Haq Nawaz Malik,Kh Mohmad Shafi,Tanveer Ahmad Reshi*

Main category: cs.CL

TL;DR: SynthOCR-Gen是一个开源合成OCR数据集生成器，专门为低资源语言设计，通过将数字Unicode文本语料库转换为现成的训练数据集，解决OCR开发中的数据集瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如克什米尔语）的OCR面临重大挑战，主要原因是缺乏大规模标注训练数据集。这些语言在主流OCR系统中缺乏支持，而手动创建数据集成本高昂、耗时且容易出错。

Method: 开发了一个综合管道，包括文本分割（字符、单词、n-gram、句子和行级别）、Unicode规范化与脚本纯度强制执行、多字体渲染与可配置分布，以及25种以上的数据增强技术模拟真实文档退化（如旋转、模糊、噪声和扫描伪影）。

Result: 生成了一个包含60万个样本的克什米尔语OCR数据集，并已在HuggingFace上公开发布。该工具为低资源语言进入视觉-语言AI模型时代提供了实用途径。

Conclusion: SynthOCR-Gen为全球研究者和从业者提供了一个实用工具，能够有效解决低资源语言OCR开发中的数据稀缺问题，推动这些语言进入AI时代。

Abstract: Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.

</details>


### [43] [Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging](https://arxiv.org/abs/2601.16127)
*Alphaeus Dmonte,Vidhi Gupta,Daniel J Perry,Mark Arehart*

Main category: cs.CL

TL;DR: 本文分析了多语言大语言模型微调中模型合并策略的效率优势，相比传统重训练方法可减少50%训练时间和60%维护成本，同时保持质量不变。


<details>
  <summary>Details</summary>
Motivation: 传统多语言LLM微调需要为所有支持语言训练完整模型，当更新或添加语言时需要重新训练整个模型，这导致计算效率低下和维护瓶颈。现有研究虽然展示了多语言多任务模型合并的质量优势，但其效率和维护成本尚未得到充分研究。

Method: 采用模型合并策略，首先在不同语言上分别训练单语言模型，然后通过合并技术整合为多语言模型。当需要更新某个语言或添加新语言时，只需重新训练该语言对应的模型并与现有模型合并，避免了整个多语言模型的重训练。

Result: 在三个独立任务上的评估显示：1）初始训练时间减少高达50%；2）更新单个语言并重新合并的维护成本降低超过60%；3）在保持质量与完整重训练相当的同时，显著提升了计算效率。该方法在公开和工业数据集上都验证有效。

Conclusion: 模型合并策略为多语言LLM微调提供了高效且维护成本低的解决方案，不仅适用于学术研究，也适用于工业应用场景，为解决多语言模型更新和维护的计算瓶颈提供了实用方法。

Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.

</details>


### [44] [Automatic Classification of Arabic Literature into Historical Eras](https://arxiv.org/abs/2601.16138)
*Zainab Alhathloul,Irfan Ahmad*

Main category: cs.CL

TL;DR: 使用神经网络和深度学习技术自动将阿拉伯语文本分类到不同历史时期，从二元分类到15类分类，在多个数据集上评估性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语随时间发生了显著变化，包括新词汇出现、旧词汇淘汰和用法转变。虽然历史学家和语言学家将阿拉伯文学划分为多个时期，但关于阿拉伯文本按时期自动分类的研究相对较少，特别是在诗歌以外的领域。本文旨在填补这一空白。

Method: 采用神经网络和深度学习技术，使用两个公开可用的语料库（OpenITI和APCD）构建数据集，涵盖从伊斯兰前时期到现代时期的文本。研究考察了从二元到15类的分类设置，包括预定义的历史时期和自定义时期划分。

Result: 在二元时期分类任务中，OpenITI数据集获得F1分数0.83，APCD数据集获得0.79。在更复杂的分类任务中，OpenITI的15时期分类获得0.20，APCD的12时期分类获得0.18。

Conclusion: 神经网络和深度学习技术可以用于阿拉伯语文本的历史时期分类，二元分类效果较好，但随着分类类别增加，性能显著下降，表明更细粒度的时期分类具有挑战性。

Abstract: The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.

</details>


### [45] [LLM-in-Sandbox Elicits General Agentic Intelligence](https://arxiv.org/abs/2601.16206)
*Daixuan Cheng,Shaohan Huang,Yuxian Gu,Huatong Song,Guoxin Chen,Li Dong,Wayne Xin Zhao,Ji-Rong Wen,Furu Wei*

Main category: cs.CL

TL;DR: LLM-in-Sandbox让大语言模型在代码沙盒中探索，以激发非代码领域的通用智能。无需额外训练即可展现利用沙盒处理非代码任务的能力，并通过强化学习进一步增强。在数学、物理、化学等多个领域表现出鲁棒泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何让大语言模型在非代码领域展现通用智能。传统方法通常需要针对特定任务进行训练，而本文希望通过让LLM在代码沙盒环境中自主探索，激发其在各种非代码任务中的智能表现。

Method: 提出LLM-in-Sandbox框架，让LLM在虚拟计算机（代码沙盒）中探索。包含两种模式：1) 无需训练的零样本模式，LLM自发利用沙盒功能；2) LLM-in-Sandbox-RL，使用非智能体数据进行强化学习训练。模型可以访问外部资源、利用文件系统处理长上下文、执行脚本满足格式要求。

Result: 实验表明LLM-in-Sandbox在数学、物理、化学、生物医学、长上下文理解和指令遵循等多个领域都表现出鲁棒的泛化能力。无论是无需训练的模式还是经过后训练的模式，都能有效利用沙盒环境解决复杂任务。

Conclusion: LLM-in-Sandbox为激发大语言模型在非代码领域的通用智能提供了有效框架。通过代码沙盒环境，LLM能够自主探索并利用计算资源解决复杂问题。该方法具有实际部署价值，已开源为Python包。

Abstract: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [46] [Designing Persuasive Social Robots for Health Behavior Change: A Systematic Review of Behavior Change Strategies and Evaluation Methods](https://arxiv.org/abs/2601.15309)
*Jiaxin Xu,Chao Zhang,Raymond H. Cuijpers,Wijnand A. IJsselsteijn*

Main category: cs.RO

TL;DR: 这篇系统综述分析了社会机器人在健康行为改变干预中的应用，总结了行为改变策略和评估方法，为未来HRI研究提供指导。


<details>
  <summary>Details</summary>
Motivation: 社会机器人在健康行为改变干预中的应用日益增多，但缺乏指导其设计和评估的可操作知识，需要系统总结现有研究中的行为改变策略和评估方法。

Method: 通过系统数据库检索和手动检索识别相关文献，对39项研究进行分析，归纳行为改变策略类别和评估方法特征。

Result: 识别出四大类行为改变策略：指导策略、咨询策略、社会影响策略和说服增强策略；总结了当前评估实践的关键特征，包括研究设计、设置、持续时间和结果测量。

Conclusion: 社会机器人作为行为改变干预具有独特优势，提出的策略为设计提供了启发，基于评估实践特征提出了未来HRI研究方向。

Abstract: Social robots are increasingly applied as health behavior change interventions, yet actionable knowledge to guide their design and evaluation remains limited. This systematic review synthesizes (1) the behavior change strategies used in existing HRI studies employing social robots to promote health behavior change, and (2) the evaluation methods applied to assess behavior change outcomes. Relevant literature was identified through systematic database searches and hand searches. Analysis of 39 studies revealed four overarching categories of behavior change strategies: coaching strategies, counseling strategies, social influence strategies, and persuasion-enhancing strategies. These strategies highlight the unique affordances of social robots as behavior change interventions and offer valuable design heuristics. The review also identified key characteristics of current evaluation practices, including study designs, settings, durations, and outcome measures, on the basis of which we propose several directions for future HRI research.

</details>


### [47] [Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray](https://arxiv.org/abs/2601.15349)
*Jiaqing Chang,Song Gao,Chaowei Dong,zhaobang Li,Yang Liu*

Main category: cs.RO

TL;DR: 该研究设计了一种受牛鼻魟启发的磁响应微型软体机器人，采用NdFeB和PDMS材料制成，通过三维亥姆霍兹线圈产生的振荡谐波磁场驱动，实现了在狭窄水下环境中的多种游泳模式。


<details>
  <summary>Details</summary>
Motivation: 在狭窄、非结构化的水下环境（如环境监测和微创医疗程序）中，微型软体机器人因其灵活的运动能力和小尺寸而具有独特优势。然而，受限于微型化，这些机器人难以内部供电，通常采用无线供电方式。本研究旨在开发一种无线驱动的微型软体机器人，为水下狭窄空间应用奠定基础。

Method: 基于牛鼻魟的游泳原理，设计并制造了磁响应的牛鼻魟启发式微型软体机器人，采用NdFeB和PDMS按一定比例制成。使用三维亥姆霍兹线圈产生振荡谐波磁场，对机器人进行游泳实验，探索磁场参数对游泳性能的影响。通过调整线圈的电流方向和频率，实现不同的游泳模式，并采用逐步调整方法减少响应误差对轨迹的影响。

Result: 实验结果显示，在B=5 mT和f=11 Hz时游泳速度最快，达到5.25 mm/s，约每秒0.5个体长。机器人能够执行直线游泳、转弯游泳和定向游泳等多种游泳模式。通过逐步调整方法有效减少了响应误差对机器人轨迹的影响。

Conclusion: 本研究展示了一种磁驱动微型软体机器人的方法，为无线驱动机器人在水下狭窄空间的应用奠定了基础。该机器人系统在环境监测和微创医疗等领域具有潜在应用价值。

Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.

</details>


### [48] [Learning a Unified Latent Space for Cross-Embodiment Robot Control](https://arxiv.org/abs/2601.15419)
*Yashuai Yan,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出一个可扩展的跨具身人形机器人控制框架，通过共享潜在表示统一人类和多样人形平台的运动，支持直接部署到新机器人而无需适应。


<details>
  <summary>Details</summary>
Motivation: 解决不同形态人形机器人（单臂、双臂、有腿等）之间的运动控制统一问题，实现跨具身的通用控制框架，避免为每个机器人单独训练策略。

Method: 两阶段方法：1) 使用对比学习构建解耦的潜在空间，捕捉不同身体部位的局部运动模式，引入结合关节旋转和末端执行器定位的相似性度量；2) 在潜在空间中训练目标条件控制策略，使用条件变分自编码器预测潜在空间位移。

Result: 训练的策略可以直接部署到多个机器人而无需适应，支持通过轻量级机器人特定嵌入层高效添加新机器人，学习到的潜在策略可直接应用于新机器人。

Conclusion: 该方法实现了跨多种人形平台的鲁棒、可扩展、具身无关的机器人控制，为统一人形机器人控制提供了有效解决方案。

Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.

</details>


### [49] [Neural Collision Detection for Multi-arm Laparoscopy Surgical Robots Through Learning-from-Simulation](https://arxiv.org/abs/2601.15459)
*Sarvin Ghiasi,Majid Roshanfar,Jake Barralet,Liane S. Feldman,Amir Hooshiar*

Main category: cs.RO

TL;DR: 提出整合分析建模、实时仿真与机器学习的框架，提升腹腔镜手术机器人臂的安全性与操作效率，通过深度学习模型实现精确的最小距离估计和碰撞检测。


<details>
  <summary>Details</summary>
Motivation: 解决腹腔镜手术中机器人臂碰撞检测和最小距离估计的关键挑战，确保机器人操作的安全性并提升手术效率。

Method: 1) 开发分析模型基于关节配置估计机器人臂间最小距离；2) 创建3D仿真环境模拟两个7自由度Kinova机器人臂，生成多样化配置数据集；3) 训练深度神经网络，输入为机器人臂关节执行器和相对位置。

Result: 深度学习模型达到282.2毫米的平均绝对误差和0.85的R平方值，预测距离与实际距离高度吻合，验证了模型在空间关系泛化方面的准确性。

Conclusion: 结合分析精度与机器学习算法能有效提升机器人系统的精确性和可靠性，为腹腔镜手术机器人安全操作提供了综合解决方案。

Abstract: This study presents an integrated framework for enhancing the safety and operational efficiency of robotic arms in laparoscopic surgery by addressing key challenges in collision detection and minimum distance estimation. By combining analytical modeling, real-time simulation, and machine learning, the framework offers a robust solution for ensuring safe robotic operations. An analytical model was developed to estimate the minimum distances between robotic arms based on their joint configurations, offering precise theoretical calculations that serve as both a validation tool and a benchmark. To complement this, a 3D simulation environment was created to model two 7-DOF Kinova robotic arms, generating a diverse dataset of configurations for collision detection and distance estimation. Using these insights, a deep neural network model was trained with joint actuators of robot arms and relative positions as inputs, achieving a mean absolute error of 282.2 mm and an R-squared value of 0.85. The close alignment between predicted and actual distances highlights the network's accuracy and its ability to generalize spatial relationships. This work demonstrates the effectiveness of combining analytical precision with machine learning algorithms to enhance the precision and reliability of robotic systems.

</details>


### [50] [A Universal Large Language Model -- Drone Command and Control Interface](https://arxiv.org/abs/2601.15486)
*Javier N. Ramos-Silva,Peter J. Burke*

Main category: cs.RO

TL;DR: 提出基于模型上下文协议（MCP）的通用无人机-大语言模型接口，实现自然语言到无人机控制的转换


<details>
  <summary>Details</summary>
Motivation: 当前无人机与LLM的接口需要针对每个应用进行繁琐的人工连接工作，缺乏通用、易用的解决方案

Method: 使用MCP标准开发云端Linux服务器，支持Mavlink协议，结合Google Maps MCP服务器提供实时导航信息

Result: 成功演示了真实无人机的飞行控制，并在模拟环境中展示了广泛的飞行规划和控制能力

Conclusion: 实现了首个通用、多功能、全面的无人机控制接口，为物理AI领域提供了易于使用的LLM-无人机集成范式

Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.

</details>


### [51] [CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation](https://arxiv.org/abs/2601.15541)
*Heng Zhang,Wei-Hsing Huang,Qiyi Tong,Gokhan Solak,Puze Liu,Sheng Liu,Jan Peters,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出CompliantVLA-adaptor，通过VLM感知任务上下文并调节可变阻抗控制参数，增强VLA模型在接触式操作任务中的安全性和有效性


<details>
  <summary>Details</summary>
Motivation: 现有VLA系统（如RDT、Pi0、OpenVLA-oft）通常只输出位置控制，缺乏力感知适应能力，导致在涉及接触、柔顺或不确定性的物理任务中出现不安全或失败的情况

Method: 使用视觉语言模型（VLM）从图像和自然语言中解释任务上下文，自适应调节可变阻抗控制器的刚度和阻尼参数，并利用实时力/力矩反馈确保交互力保持在安全阈值内

Result: 在复杂接触式任务中（仿真和真实硬件）优于VLA基线方法，成功率从9.86%提升到17.29%，减少了力违规情况

Conclusion: CompliantVLA-adaptor为使用VLA进行安全接触式操作提供了一条有前景的路径，通过结合VLM感知的上下文和实时力反馈，显著提高了任务成功率和安全性

Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.

</details>


### [52] [A Mobile Magnetic Manipulation Platform for Gastrointestinal Navigation with Deep Reinforcement Learning Control](https://arxiv.org/abs/2601.15545)
*Zhifan Yan,Chang Liu,Yiyang Jiang,Wenxuan Zheng,Xinhao Chen,Axel Krieger*

Main category: cs.RO

TL;DR: 提出一种基于深度强化学习的移动磁操控平台，用于胃肠道靶向给药，无需复杂物理模型校准，实现快速部署和大工作空间精确控制。


<details>
  <summary>Details</summary>
Motivation: 现有磁机器人控制系统存在局限性：固定磁系统工作空间有限，移动系统（如机械臂上的线圈）需要复杂预校准物理模型，存在"模型校准瓶颈"，创建耗时且计算成本高。

Method: 开发紧凑低成本移动磁操控平台，采用UR5协作机器人搭载四电磁铁阵列，使用Soft Actor-Critic深度强化学习控制策略，通过仿真到现实的训练流程，15分钟内完成策略部署。

Result: 控制7毫米磁胶囊沿2D轨迹运动，DRL控制器在方形路径上RMSE为1.18毫米，圆形路径为1.50毫米，在30厘米×20厘米临床相关工作空间内成功跟踪。

Conclusion: 该工作展示了一种快速部署、无模型的磁操控框架，能在较大工作空间内实现精确磁操控，为胃肠道靶向给药提供有效解决方案。

Abstract: Targeted drug delivery in the gastrointestinal (GI) tract using magnetic robots offers a promising alternative to systemic treatments. However, controlling these robots is a major challenge. Stationary magnetic systems have a limited workspace, while mobile systems (e.g., coils on a robotic arm) suffer from a "model-calibration bottleneck", requiring complex, pre-calibrated physical models that are time-consuming to create and computationally expensive. This paper presents a compact, low-cost mobile magnetic manipulation platform that overcomes this limitation using Deep Reinforcement Learning (DRL). Our system features a compact four-electromagnet array mounted on a UR5 collaborative robot. A Soft Actor-Critic (SAC)-based control strategy is trained through a sim-to-real pipeline, enabling effective policy deployment within 15 minutes and significantly reducing setup time. We validated the platform by controlling a 7-mm magnetic capsule along 2D trajectories. Our DRL-based controller achieved a root-mean-square error (RMSE) of 1.18~mm for a square path and 1.50~mm for a circular path. We also demonstrated successful tracking over a clinically relevant, 30 cm * 20 cm workspace. This work demonstrates a rapidly deployable, model-free control framework capable of precise magnetic manipulation in a large workspace,validated using a 2D GI phantom.

</details>


### [53] [Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor](https://arxiv.org/abs/2601.15607)
*Lenworth Thomas,Tjaden Bridges,Sarah Bergbreiter*

Main category: cs.RO

TL;DR: 本文提出了一种在小型四旋翼无人机上结合气流传感的化学羽流追踪方法，通过定制的气流传感器实现流向和流速感知，改进了"抛射与突进"算法以可靠寻找气流源。


<details>
  <summary>Details</summary>
Motivation: 随着环境灾害频发加剧，寻找污染物源变得日益重要。小型四旋翼无人机能够在人类周围和受限空间飞行，但受限于气体传感器的低灵敏度和长响应时间，羽流追踪面临挑战。

Method: 开发了能够感知气流大小和方向的定制气流传感器，适用于<100g的小型四旋翼无人机。基于此传感器实现了改进的"抛射与突进"算法，利用流向感知寻找和导航至气流源。

Result: 表征实验验证系统能在飞行中检测气流并重新定向无人机朝向气流。多组随机起始位置和方向的试验表明，该源寻找算法能可靠地找到气流源。

Conclusion: 这项工作为未来平台奠定了基础，使气流传感器能够与其他传感器协同工作，实现更丰富的羽流追踪数据收集和源寻找能力。

Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors < 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.

</details>


### [54] [AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning](https://arxiv.org/abs/2601.15614)
*Zichen Yan,Yuchen Hou,Shenao Wang,Yichao Gao,Rui Huang,Lin Zhao*

Main category: cs.RO

TL;DR: AION是一个用于空中物体目标导航的双策略强化学习框架，将探索和目标到达行为解耦为两个专门策略，在未知环境中无需外部定位或全局地图即可实现视觉导航。


<details>
  <summary>Details</summary>
Motivation: 虽然之前的工作主要研究2D移动下的零样本物体导航，但将其扩展到具有3D移动能力的空中平台仍未被充分探索。空中机器人具有优越的机动性和搜索效率，但也带来了空间感知、动态控制和安全保障方面的新挑战。

Method: AION是一个端到端的双策略强化学习框架，将探索和目标到达行为解耦为两个专门策略，不依赖外部定位或全局地图，仅基于视觉输入实现空中物体导航。

Result: 在AI2-THOR基准测试和IsaacSim中使用高保真无人机模型进行实时性能评估，AION在探索、导航效率和安全性等综合评估指标上表现出优越性能。

Conclusion: AION框架成功解决了空中物体目标导航的挑战，通过双策略设计实现了高效的探索和精确的目标到达，为空中机器人的自主导航提供了有效解决方案。

Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.

</details>


### [55] [D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot](https://arxiv.org/abs/2601.15707)
*Qifan Hu,Branko Celler,Weidong Mu,Steven W. Su*

Main category: cs.RO

TL;DR: 提出两阶段校准框架用于3自由度踝关节康复机器人，使用Kronecker积将校准转为线性参数辨识，通过PPO算法选择最优4个姿态，显著提升校准效率与精度。


<details>
  <summary>Details</summary>
Motivation: 多自由度康复机器人的精确对准对于安全有效的患者训练至关重要，但传统校准方法效率低下且精度不足，需要更高效的校准策略。

Method: 提出两阶段校准框架：1) 基于Kronecker积的开环校准方法，将输入输出对准转为线性参数辨识问题；2) 使用PPO强化学习算法从50个候选姿态中选择4个D最优姿态组合。

Result: PPO选择的姿态组合比随机选择的信息矩阵行列式均值高两个数量级，方差更小；仅用4个最优姿态的参数辨识比50个非结构化姿态具有更强的跨周期预测一致性。

Conclusion: 该框架在保持稳健参数估计的同时显著提高校准效率，为多自由度康复机器人的高精度对准提供了实用指导。

Abstract: Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.

</details>


### [56] [DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving](https://arxiv.org/abs/2601.15729)
*Rui Yang,Lei Zheng,Ruoyu Yao,Jun Ma*

Main category: cs.RO

TL;DR: DualShield：结合扩散模型和Hamilton-Jacobi可达性分析的自动驾驶安全规划控制框架，通过双重安全机制确保不确定交互下的安全性


<details>
  <summary>Details</summary>
Motivation: 扩散模型在自动驾驶多模态运动规划中表现出强大能力，但存在两个主要限制：1）难以强制执行车辆动力学约束；2）严重依赖对其他智能体的准确预测，在不确定交互下容易产生安全问题。需要一种既能保持扩散模型丰富探索能力又能提供安全保证的解决方案。

Method: 提出DualShield框架，利用Hamilton-Jacobi可达性价值函数实现双重保护机制：1）主动引导：价值函数指导扩散去噪过程，使其趋向安全和动力学可行区域；2）反应式安全屏障：使用控制屏障价值函数修改执行动作，确保安全性。这种双重机制保留了扩散模型的探索能力，同时提供理论安全保证。

Result: 在具有挑战性的无保护U形转弯场景模拟中，DualShield相比不同规划范式的领先方法，在不确定条件下显著提高了安全性和任务效率。

Conclusion: DualShield成功解决了扩散模型在自动驾驶规划中的安全限制，通过Hamilton-Jacobi可达性分析的双重应用，实现了在不确定甚至对抗性交互下的安全保证，同时保持了扩散模型的丰富探索能力。

Abstract: Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.

</details>


### [57] [Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV](https://arxiv.org/abs/2601.15775)
*Amir Habel,Ivan Snegirev,Elizaveta Semenyakina,Miguel Altamirano Cabrera,Jeffrin Sam,Fawad Mehboob,Roohan Ahmed Khan,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: Glove2UAV是一个可穿戴的IMU手套接口，通过手部和手指手势直观控制无人机，并配有振动触觉警告系统，当飞行速度超过预设阈值时提供警报。


<details>
  <summary>Details</summary>
Motivation: 设计一个轻量级、易于部署的可穿戴接口，用于动态飞行中更安全、更可预测的无人机交互控制，通过直观的手势操作和触觉反馈增强用户体验和安全性。

Method: 使用可穿戴IMU手套实时流式传输惯性测量数据，采用中值异常抑制和Madgwick方向估计算法处理手掌和手指方向，将运动估计映射到飞行控制基元（前进/后退和横向运动），并集成振动触觉反馈系统，当飞行速度超过阈值时触发警告。

Result: 验证了实时可行性，在模拟和真实飞行中同步手套信号与无人机遥测数据，结果显示快速的手势命令执行、手势动态与平台运动的稳定耦合、核心命令集的正确操作以及振动警告提示的及时传递。

Conclusion: Glove2UAV提供了一个有效的可穿戴接口，通过直观的手势控制和触觉反馈系统，实现了安全、可预测的无人机交互，在动态飞行环境中表现出良好的实时性能和用户体验。

Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.

</details>


### [58] [A Beacon Based Solution for Autonomous UUVs GNSS-Denied Stealthy Navigation](https://arxiv.org/abs/2601.15802)
*Alexandre Albore,Humbert Fiorino,Damien Pellier*

Main category: cs.RO

TL;DR: 提出一种在GNSS拒止环境下使用信标网络引导UUV编队从大陆架到海岸的自主导航系统


<details>
  <summary>Details</summary>
Motivation: 在沿海区域进行军事和民用隐蔽行动时，UUV需要在不依赖支持船只或GNSS的情况下进行导航。当无法获得水面支持且需要在受限环境（如保护区或危险禁入区）进行隐蔽导航时，GNSS拒止导航至关重要，因为浮出水面可能暴露UUV位置。

Method: 通过空中或水面无人机部署信标星座，建立合成地标网络。这些信标（水下或漂浮）发射声学信号用于UUV定位和导航。采用分层规划器生成自适应路径，无人机执行原始动作，同时持续监控并在需要时重新规划以保持轨迹精度。

Result: 建立了一个能够引导UUV编队从大陆架到海岸目标的优化路径导航系统，实现了在GNSS拒止环境下的精确编队定位。

Conclusion: 该系统为沿海区域隐蔽军事和民用行动提供了可行的GNSS拒止导航解决方案，通过信标网络和自适应规划实现了UUV编队的精确导航和隐蔽操作。

Abstract: Autonomous Unmanned Underwater Vehicles (UUVs) enable military and civilian covert operations in coastal areas without relying on support vessels or Global Navigation Satellite Systems (GNSS). Such operations are critical when surface access is not possible and stealthy navigation is required in restricted environments such as protected zones or dangerous areas under access ban. GNSS denied navigation is then essential to maintaining concealment as surfacing could expose UUVs to detection. To ensure a precise fleet positioning a constellation of beacons deployed by aerial or surface drones establish a synthetic landmark network that will guide the fleet of UUVs along an optimized path from the continental shelf to the goal on the shore. These beacons either submerged or floating emit acoustic signals for UUV localisation and navigation. A hierarchical planner generates an adaptive route for the drones executing primitive actions while continuously monitoring and replanning as needed to maintain trajectory accuracy.

</details>


### [59] [TeNet: Text-to-Network for Compact Policy Synthesis](https://arxiv.org/abs/2601.15912)
*Ariyan Bighashdel,Kevin Sebastian Luck*

Main category: cs.RO

TL;DR: TeNet框架通过文本条件化超网络从自然语言描述直接生成紧凑、可执行的机器人策略，利用预训练LLM的通用知识，同时保持执行时的高效性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人指令跟随方法要么依赖手工设计的高层规划接口，要么使用难以实时部署的大型端到端模型，需要一种既能利用语言模型通用知识又能保持执行效率的紧凑策略生成方法。

Method: TeNet使用预训练LLM生成文本嵌入，通过超网络将其转换为完全可执行的策略网络。训练时可选择性地将语言与演示行为对齐以提升泛化能力，推理时仅需文本输入即可生成策略。

Result: 在MuJoCo和Meta-World基准测试中，TeNet生成的策略比序列基线小几个数量级，在多任务和元学习设置中表现优异，支持高频控制，适合资源受限的实时机器人控制任务。

Conclusion: 文本条件化超网络为构建紧凑、语言驱动的机器人控制器提供了一种实用方法，能够平衡LLM的通用知识与实时执行效率，适用于资源受限的实时控制任务。

Abstract: Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.

</details>


### [60] [Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems](https://arxiv.org/abs/2601.15946)
*Zijie Chen,Xiaowei Liu,Yong Xu,Shenghai Yuan,Jianping Li,Lihua Xie*

Main category: cs.RO

TL;DR: 提出LM-Calibr标定方法和EVA-LIO定位方法，解决旋转驱动LiDAR的标定通用性和特征缺失区域定位鲁棒性问题


<details>
  <summary>Details</summary>
Motivation: 现有方法需要针对不同安装配置参数化外参，限制了通用性；旋转驱动LiDAR不可避免会扫描特征缺失区域，在扫描覆盖率和定位鲁棒性之间难以平衡

Method: 基于Denavit-Hartenberg约定的无目标LiDAR-电机标定方法(LM-Calibr)，支持多种安装配置；环境自适应LiDAR-惯性里程计(EVA-LIO)，根据空间尺度自适应选择下采样率和地图分辨率

Result: LM-Calibr在不同场景、安装角度和初始值下都表现出高精度和收敛性；EVA-LIO使执行器能以最大速度运行，增强扫描完整性的同时确保定位鲁棒性，即使在LiDAR短暂扫描特征缺失区域时

Conclusion: 提出的方法解决了旋转驱动LiDAR系统的标定通用性和定位鲁棒性问题，代码和硬件设计已开源

Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}

</details>


### [61] [PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour](https://arxiv.org/abs/2601.15995)
*Liang Wang,Kanzhong Yao,Yang Liu,Weikai Qin,Jun Wu,Zhe Sun,Qiuguo Zhu*

Main category: cs.RO

TL;DR: PUMA：一种端到端学习框架，通过视觉感知和立足点先验集成，让四足机器人能够像人类运动员一样感知环境特征并选择合适立足点，实现敏捷的跑酷运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖分层控制器跟随预计算立足点，限制了机器人的实时适应性和强化学习的探索潜力。人类运动员能够有效感知环境特征选择合适立足点，但赋予腿式机器人类似感知推理能力仍具挑战。

Method: 提出PUMA端到端学习框架，将视觉感知和立足点先验集成到单阶段训练过程中。利用地形特征估计以自我为中心的极坐标立足点先验（相对距离和方向），指导机器人进行主动姿态适应。

Result: 在仿真和真实环境中对各种离散复杂地形进行广泛实验，证明PUMA在挑战性场景中具有卓越的敏捷性和鲁棒性。

Conclusion: PUMA框架通过端到端学习成功整合了视觉感知和立足点先验，使四足机器人能够在复杂地形中实现类似人类的跑酷运动能力，克服了现有分层控制方法的局限性。

Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.

</details>


### [62] [Collision-Free Humanoid Traversal in Cluttered Indoor Scenes](https://arxiv.org/abs/2601.16035)
*Han Xue,Sikai Liang,Zhikai Zhang,Zicheng Zeng,Yun Liu,Yunrui Lian,Jilong Wang,Qingtao Liu,Xuesong Shi,Li Yi*

Main category: cs.RO

TL;DR: 提出HumanoidPF表示方法，将人形机器人与障碍物的关系编码为无碰撞运动方向，结合混合场景生成方法，实现人形机器人在杂乱室内场景中的通用穿越技能学习与真实世界迁移。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在杂乱室内场景（如跨越障碍、蹲下通过、挤过狭窄通道）中的无碰撞穿越问题。现有方法缺乏有效表示人形机器人与障碍物关系的表示，难以直接学习相应的穿越技能。

Method: 提出Humanoid Potential Field (HumanoidPF)，将人形机器人与障碍物的关系编码为无碰撞运动方向，显著促进基于强化学习的穿越技能学习。同时提出混合场景生成方法，结合真实3D室内场景片段和程序化合成的障碍物，生成多样化的训练场景。

Result: HumanoidPF作为感知表示具有令人惊讶的微小仿真到真实差距。成功将策略迁移到真实世界，开发了只需单次点击的遥操作系统。在仿真和真实世界中进行广泛实验验证了方法的有效性。

Conclusion: HumanoidPF能有效表示人形机器人与障碍物的关系，促进穿越技能学习，且具有很好的仿真到真实迁移能力。混合场景生成方法能产生多样化的训练场景，实现通用化的穿越技能。

Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.

</details>


### [63] [DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning](https://arxiv.org/abs/2601.16046)
*Junha Lee,Eunha Park,Minsu Cho*

Main category: cs.RO

TL;DR: DextER提出了一种基于接触推理的灵巧抓取生成方法，通过预测手部链接与物体表面的接触位置作为中间表示，将任务语义与物理约束联系起来，显著提升了抓取成功率和意图对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的方法直接将观测映射到抓取参数，缺乏对物理交互的中间推理过程。语言驱动的灵巧抓取生成需要理解任务语义、3D几何和复杂的手-物体交互。

Method: DextER采用基于接触的具身推理方法，自回归生成具身接触token（指定哪些手指链接接触物体表面的哪些位置），然后生成编码手部配置的抓取token。

Result: 在DexGYS数据集上，DextER达到67.14%的成功率，比现有最佳方法提升3.83个百分点，意图对齐度提升96.4%。同时展示了通过部分接触指定实现可引导生成的能力。

Conclusion: 基于接触的具身推理为多指操作提供了有效的中间表示，成功地将任务语义与物理约束联系起来，实现了更精确可控的灵巧抓取生成。

Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.

</details>


### [64] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis](https://arxiv.org/abs/2601.16062)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文分析了SE2(3)李群导航模型的自洽性问题，发现在考虑地球旋转和惯性器件偏差的高精度导航中，传统建模方法因科里奥利力项而难以保持自洽，提出了一种新的建模方法以提高自洽性。


<details>
  <summary>Details</summary>
Motivation: 当前基于SE2(3)李群的扩展卡尔曼滤波器在低精度应用（如不考虑地球旋转和惯性偏差的MEMS导航）中表现出良好的误差传播自洽性，但在考虑地球旋转和惯性器件偏差的高精度导航状态估计中，保持自洽性极其困难。

Method: 1. 在惯性系、地球系和世界系下对SE2(3)群高精度导航模型的自洽性进行理论分析；2. 发现传统SE2(3)群导航建模方法的局限性在于非惯性系中速度引入的科里奥利力项；3. 提出一种SE2(3)群导航模型的构建方法，使导航模型更接近完全自洽。

Result: 通过理论分析发现，传统SE2(3)群导航建模方法的主要限制是非惯性系中速度项引入的科里奥利力项破坏了模型的自洽性。提出的新构建方法能够显著提高导航模型的自洽性。

Conclusion: SE2(3)李群导航模型在高精度应用中面临自洽性挑战，主要源于科里奥利力项的影响。提出的新建模方法能够改善这一问题，使导航模型更接近完全自洽状态，为高精度导航应用提供了更好的理论基础。

Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.

</details>


### [65] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application](https://arxiv.org/abs/2601.16078)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文通过实际SINS/ODO实验和蒙特卡洛仿真，验证了改进的SE2(3)群导航模型的性能，作为前一篇理论分析论文的补充


<details>
  <summary>Details</summary>
Motivation: SE2(3)李群框架在导航建模中的核心优势在于误差传播的自主性。前一篇论文已从理论上分析了惯性、地球和世界坐标系中导航模型的自主性特性，本文旨在通过实际实验验证改进模型的性能

Method: 提出了一种SE2(3)群导航模型的构建方法，用于改进非惯性导航模型以实现完全自主性。通过实际SINS/ODO实验和蒙特卡洛仿真来验证模型性能

Result: 实验和仿真结果表明，改进的SE2(3)群基高精度导航模型在实际应用中表现出色，验证了其自主性特性和高精度性能

Conclusion: 本文通过实际实验验证了SE2(3)群导航模型的优越性能，为前一篇理论分析提供了实证支持，证明了该模型在高精度导航应用中的实用价值

Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.

</details>


### [66] [Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision](https://arxiv.org/abs/2601.16109)
*Yashuai Yan,Tobias Egle,Christian Ott,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出结合模型控制与残差强化学习的框架，通过模型基策略和特权监督训练，实现双足机器人在真实不确定环境中的鲁棒自适应行走


<details>
  <summary>Details</summary>
Motivation: 解决双足机器人在真实世界中面临的不确定性挑战，包括不精确的动力学建模和传感器噪声，实现从仿真到现实的鲁棒迁移

Method: 整合模型基控制器（DCM轨迹规划器和全身控制器）作为基础策略，引入通过域随机化训练的残差RL策略，并采用具有特权访问真实动态的模型基Oracle策略监督残差策略学习

Result: 方法在多种随机化条件下表现出改进的鲁棒性和泛化能力，为双足行走的仿真到现实迁移提供了可扩展解决方案

Conclusion: 通过模型基控制与残差RL的结合，配合特权监督训练，能够有效补偿未建模效应，实现双足机器人在不确定环境中的鲁棒自适应行走

Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.

</details>


### [67] [IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance](https://arxiv.org/abs/2601.16207)
*Jongwoo Park,Kanchana Ranasinghe,Jinhyeok Jang,Cristina Mata,Yoo Sung Jang,Michael S Ryoo*

Main category: cs.RO

TL;DR: IVRA是一种轻量级、无需训练的方法，通过利用视觉编码器中的亲和性提示来增强VLA模型的空间理解能力，提升机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型将图像块展平为1D序列会削弱2D空间线索，而精确的机器人操作需要良好的空间理解能力。

Method: IVRA从模型内置视觉编码器中提取亲和性提示，选择性地注入到包含实例级特征的语言模型层中，在推理时重新对齐视觉-标记交互，保持几何结构。

Result: 在2D VIMA基准上，IVRA比基线LLaRA平均成功率提升4.2%；在3D LIBERO基准上，对OpenVLA和FLOWER基线均有持续改进，包括在接近饱和准确率时从96.3%提升到97.1%。

Conclusion: IVRA是一种通用、无需训练的方法，能够有效增强VLA模型的空间理解能力，在多种机器人操作任务中显著提升性能。

Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA

</details>


### [68] [Point Bridge: 3D Representations for Cross Domain Policy Learning](https://arxiv.org/abs/2601.16212)
*Siddhant Haldar,Lars Johannsmeier,Lerrel Pinto,Abhishek Gupta,Dieter Fox,Yashraj Narang,Ajay Mandlekar*

Main category: cs.RO

TL;DR: Point Bridge框架利用统一的点云表示实现零样本仿真到现实的策略迁移，无需视觉对齐，仅用合成数据训练就能在真实世界操作，性能显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 机器人基础模型需要大规模真实世界操作数据，但这类数据稀缺。仿真和合成数据生成虽然可扩展，但受限于仿真与现实之间的视觉域差距

Method: 结合视觉语言模型自动提取点云表示、基于transformer的策略学习，以及高效的推理时流水线，使用统一、领域无关的点云表示来桥接仿真与现实

Result: 在零样本仿真到现实迁移中实现高达44%的性能提升，配合少量真实演示数据后提升达66%，在单任务和多任务设置中都显著优于现有视觉基础的仿真-现实协同训练方法

Conclusion: Point Bridge通过点云表示有效解决了仿真到现实的视觉域差距问题，为仅用合成数据训练真实世界机器人操作智能体提供了可行方案

Abstract: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/

</details>
