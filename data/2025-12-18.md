<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 40]
- [cs.RO](#cs.RO) [Total: 16]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis](https://arxiv.org/abs/2512.14801)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CL

TL;DR: 该论文挑战了OpenAI关于大语言模型幻觉是激励对齐问题的观点，认为幻觉是transformer架构的结构性必然，无法通过优化激励解决，需要外部验证和弃权模块的混合系统。


<details>
  <summary>Details</summary>
Motivation: 反驳OpenAI关于幻觉是激励对齐问题的观点，证明幻觉是transformer架构的结构性缺陷而非行为优化问题。

Method: 基于先前关于结构幻觉的研究，使用Licensing Oracle进行实证实验，分析transformer的嵌入空间和模式完成机制。

Result: 实验证明幻觉只能通过外部真实验证和弃权模块消除，无法通过激励调整、提示工程或微调解决；Licensing Oracle实现了完美的弃权精度。

Conclusion: 幻觉是生成式架构的结构属性，可靠AI需要混合系统来区分语言流畅性和认知责任。

Abstract: OpenAI has recently argued that hallucinations in large language models result primarily from misaligned evaluation incentives that reward confident guessing rather than epistemic humility. On this view, hallucination is a contingent behavioral artifact, remediable through improved benchmarks and reward structures. In this paper, we challenge that interpretation. Drawing on previous work on structural hallucination and empirical experiments using a Licensing Oracle, we argue that hallucination is not an optimization failure but an architectural inevitability of the transformer model.
  Transformers do not represent the world; they model statistical associations among tokens. Their embedding spaces form a pseudo-ontology derived from linguistic co-occurrence rather than world-referential structure. At ontological boundary conditions - regions where training data is sparse or incoherent - the model necessarily interpolates fictional continuations in order to preserve coherence. No incentive mechanism can modify this structural dependence on pattern completion.
  Our empirical results demonstrate that hallucination can only be eliminated through external truth-validation and abstention modules, not through changes to incentives, prompting, or fine-tuning. The Licensing Oracle achieves perfect abstention precision across domains precisely because it supplies grounding that the transformer lacks.
  We conclude that hallucination is a structural property of generative architectures and that reliable AI requires hybrid systems that distinguish linguistic fluency from epistemic responsibility.

</details>


### [2] [T5Gemma 2: Seeing, Reading, and Understanding Longer](https://arxiv.org/abs/2512.14856)
*Biao Zhang,Paul Suganthan,Gaël Liu,Ilya Philippov,Sahil Dua,Ben Hora,Kat Black,Gus Martins,Omar Sanseviero,Shreya Pathak,Cassidy Hardin,Francesco Visin,Jiageng Zhang,Kathleen Kenealy,Qin Yin,Olivier Lacombe,Armand Joulin,Tris Warkentin,Adam Roberts*

Main category: cs.CL

TL;DR: T5Gemma 2是基于Gemma 3模型构建的轻量级多模态编码器-解码器模型，通过改进的UL2适配方法将仅解码器模型转换为编码器-解码器架构，并引入共享嵌入和合并注意力机制提升效率。


<details>
  <summary>Details</summary>
Motivation: 延续T5Gemma系列的研究，将文本模型的适配方法扩展到多模态领域，同时改进模型效率，探索编码器-解码器架构在长上下文建模中的优势。

Method: 1) 基于UL2适配方法将Gemma 3仅解码器模型转换为编码器-解码器架构；2) 引入共享词嵌入（编码器和解码器共享所有嵌入）；3) 提出合并注意力机制，将解码器的自注意力和交叉注意力统一为单个联合模块。

Result: 实验证明适配策略在不同架构和模态上具有通用性，编码器-解码器架构在长上下文建模中表现出独特优势。T5Gemma 2在预训练性能上与Gemma 3相当或更好，在后训练性能上显著提升。

Conclusion: 成功开发了具有多语言、多模态和长上下文能力的轻量级编码器-解码器模型，发布了270M-270M、1B-1B和4B-4B三个规模的预训练模型供社区使用。

Abstract: We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.

</details>


### [3] [Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media](https://arxiv.org/abs/2512.14887)
*Massimiliano Fadda,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino*

Main category: cs.CL

TL;DR: 本文改进了新闻观点分类流程，通过微调大语言模型和用Wikidata丰富实体表示，在移民话题上提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 新闻媒体在民主社会中通过特定话题、观点和声音塑造政治社会话语，理解这些动态对于评估媒体是否提供平衡公正的公共辩论至关重要。之前的工作虽然建立了观点识别和分类流程，但仍有改进空间。

Method: 1) 微调大语言模型用于观点分类；2) 使用Wikidata中相关参与者的语义描述来丰富声明表示。两种机制集成使用，特别关注能处理长输入的大语言模型。

Result: 两种机制都能独立提升分类性能，但集成使用时效果最佳，特别是使用能处理长输入的大语言模型时。在英国移民辩论的基准测试中验证了方法的有效性。

Conclusion: 通过结合微调LLM和丰富实体语义表示，能够显著改进新闻观点分类的准确性和效果，为理解媒体话语动态提供了更强大的工具。

Abstract: News sources play a central role in democratic societies by shaping political and social discourse through specific topics, viewpoints and voices. Understanding these dynamics is essential for assessing whether the media landscape offers a balanced and fair account of public debate. In earlier work, we introduced a pipeline that, given a news corpus, i) uses a hybrid human-machine approach to identify the range of viewpoints expressed about a given topic, and ii) classifies relevant claims with respect to the identified viewpoints, defined as sets of semantically and ideologically congruent claims (e.g., positions arguing that immigration positively impacts the UK economy). In this paper, we improve this pipeline by i) fine-tuning Large Language Models (LLMs) for viewpoint classification and ii) enriching claim representations with semantic descriptions of relevant actors drawn from Wikidata. We evaluate our approach against alternative solutions on a benchmark centred on the UK immigration debate. Results show that while both mechanisms independently improve classification performance, their integration yields the best results, particularly when using LLMs capable of processing long inputs.

</details>


### [4] [DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline](https://arxiv.org/abs/2512.14896)
*Houman Kazemzadeh,Kiarash Mokhtari Dizaji,Seyed Reza Tavakoli,Farbod Davoodi,MohammadReza KarimiNejad,Parham Abed Azad,Ali Sabzi,Armin Khosravi,Siavash Ahmadi,Mohammad Hossein Rohban,Glolamali Aminian,Tahereh Javaheri*

Main category: cs.CL

TL;DR: 评估LLM在药房执照考试问答任务上的表现，开发DrugRAG外部知识整合方法提升准确性


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在药房执照考试问答任务上的表现，并开发外部知识整合方法来提高其准确性，为药房领域的AI应用提供实用解决方案

Method: 1. 使用141个问题的药房数据集对11个不同参数规模的LLM进行基准测试；2. 开发三步检索增强生成（RAG）管道DrugRAG，从验证来源检索结构化药物知识，将基于证据的上下文增强到模型提示中；3. 该管道在模型外部运行，无需修改模型架构或参数

Result: 基线准确率从46%到92%不等，GPT-5（92%）和o3（89%）得分最高；参数少于80亿的模型得分低于50%；DrugRAG在所有测试模型中均提高了准确率，提升幅度为7-21个百分点（例如Gemma 3 27B：61%到71%，Llama 3.1 8B：46%到67%）

Conclusion: 通过DrugRAG进行外部结构化药物知识整合，无需修改底层模型即可显著提高LLM在药房任务上的准确性，为增强药房AI应用提供了实用的基于证据信息整合管道

Abstract: Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy.
  Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters.
  Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark.
  Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.

</details>


### [5] [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)
*Caner Erden*

Main category: cs.CL

TL;DR: MAHA提出了一种多尺度聚合层次注意力机制，通过分层分解和数学优化聚合策略，在保持全局依赖的同时将计算复杂度从二次降低到接近线性，实现了81%的计算成本降低。


<details>
  <summary>Details</summary>
Motivation: 多头自注意力的二次计算复杂度限制了大型语言模型处理长上下文任务的可扩展性。现有的稀疏和线性化注意力方法要么损害全局依赖表示，要么无法有效捕捉多尺度语义粒度。

Method: MAHA通过可学习下采样算子将输入序列动态划分为层次化尺度，将尺度特定注意力矩阵的融合建模为资源分配问题，使用凸优化框架或基于纳什均衡的博弈论方法求解，确保局部细节与全局上下文保真度的理论最优平衡。

Result: MAHA在序列长度为4096时相比标准注意力减少了81%的计算成本，实现了优越的可扩展性，同时保持了全局依赖表示能力。

Conclusion: MAHA通过将优化理论与序列建模相结合，为下一代大型语言模型提供了可扩展的解决方案，填补了理论优化与序列建模之间的空白。

Abstract: The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global dependencies or fail to capture multiscale semantic granularity effectively. In this paper, we propose Multiscale Aggregated Hierarchical Attention (MAHA), a novel architectural framework that reformulates the attention mechanism through hierarchical decomposition and mathematically rigorous aggregation. Unlike conventional approaches that treat token interactions at a single resolution, MAHA dynamically partitions the input sequence into hierarchical scales via learnable downsampling operators. The core innovation lies in its aggregation strategy: we model the fusion of scalespecific attention matrices as a resource allocation problem, solved via a convex optimization framework or a Nash equilibriumbased gametheoretic approach. This ensures a theoretically optimal balance between local nuance and global context fidelity. Implemented within a hybrid dilatedconvolutional transformer backbone, MAHA utilizes differentiable optimization layers to enable endtoend training. Experimental evaluations demonstrate that MAHA achieves superior scalability; empirical FLOPs analysis confirms an 81% reduction in computational cost at a sequence length of 4096 compared to standard attention. This work bridges the gap between optimization theory and sequence modeling, offering a scalable solution for nextgeneration LLMs.

</details>


### [6] [Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](https://arxiv.org/abs/2512.14926)
*George-Andrei Dima,Dumitru-Clementin Cercel*

Main category: cs.CL

TL;DR: 本文通过将Flickr30k数据集翻译为罗马尼亚语并扩展为视觉问答数据集，微调开源视觉语言模型，提升了罗马尼亚语的多模态AI能力。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言（特别是罗马尼亚语）的多模态NLP资源匮乏问题，旨在通过创建罗马尼亚语视觉问答数据集来促进生成式AI的民主化。

Method: 1) 将Flickr30k数据集翻译为罗马尼亚语；2) 利用开源LLM扩展为视觉问答数据集；3) 使用LoRA方法微调LLaMA 3.2、LLaVA 1.6和Qwen2等开源VLM模型。

Result: 微调后的模型在罗马尼亚语视觉问答任务上表现提升，同时在未训练的罗马尼亚语图像描述生成任务上也有改进。Qwen2-VL-RoVQA模型在BERTScore F1上分别提升了6.05%和2.61%，语法错误显著减少。

Conclusion: 通过创建罗马尼亚语多模态数据集和微调开源VLM，有效提升了罗马尼亚语的多模态AI能力，为低资源语言的AI民主化提供了可行方案。

Abstract: Focusing on low-resource languages is an essential step toward democratizing generative AI. In this work, we contribute to reducing the multimodal NLP resource gap for Romanian. We translate the widely known Flickr30k dataset into Romanian and further extend it for visual question answering by leveraging open-source LLMs. We demonstrate the usefulness of our datasets by fine-tuning open-source VLMs on Romanian visual question answering. We select VLMs from three widely used model families: LLaMA 3.2, LLaVA 1.6, and Qwen2. For fine-tuning, we employ the parameter-efficient LoRA method. Our models show improved Romanian capabilities in visual QA, as well as on tasks they were not trained on, such as Romanian image description generation. The seven-billion-parameter Qwen2-VL-RoVQA obtains top scores on both tasks, with improvements of +6.05% and +2.61% in BERTScore F1 over its original version. Finally, the models show substantial reductions in grammatical errors compared to their original forms, indicating improvements not only in language understanding but also in Romanian fluency.

</details>


### [7] [Cross-Tokenizer Likelihood Scoring Algorithms for Language Model Distillation](https://arxiv.org/abs/2512.14954)
*Buu Phan,Ashish Khisti,Karen Ullrich*

Main category: cs.CL

TL;DR: 提出跨分词器似然评分方法，解决教师和学生语言模型使用不同分词器时的知识蒸馏问题，支持子集和通用两种场景。


<details>
  <summary>Details</summary>
Motivation: 当教师和学生语言模型使用不同分词器时，计算下一个token的似然比变得困难，特别是在边缘设备部署需要更小词汇表以降低内存开销的情况下。

Method: 利用Byte-Pair Encoding (BPE)算法的隐式递归结构，创建跨分词器似然评分的概率框架。针对子集场景提供精确似然计算和O(1)模型评估，针对通用场景提供无损过程和快速近似方法。

Result: 在子集场景中，Qwen2.5-1.5B模型内存占用减少12%，基线性能提升4%；在通用场景中，数学推理任务GSM8K准确率比当前最佳方法提升超过2%。

Conclusion: 该方法有效解决了分词器不对齐问题，为不同分词器语言模型之间的知识蒸馏提供了实用解决方案，在保持性能的同时显著降低内存开销。

Abstract: Computing next-token likelihood ratios between two language models (LMs) is a standard task in training paradigms such as knowledge distillation. Since this requires both models to share the same probability space, it becomes challenging when the teacher and student LMs use different tokenizers, for instance, when edge-device deployment necessitates a smaller vocabulary size to lower memory overhead. In this work, we address this vocabulary misalignment problem by uncovering an implicit recursive structure in the commonly deployed Byte-Pair Encoding (BPE) algorithm and utilizing it to create a probabilistic framework for cross-tokenizer likelihood scoring. Our method enables sequence likelihood evaluation for vocabularies different from the teacher model native tokenizer, addressing two specific scenarios: when the student vocabulary is a subset of the teacher vocabulary, and the general case where it is arbitrary. In the subset regime, our framework computes exact likelihoods and provides next-token probabilities for sequential sampling with only O(1) model evaluations per token. When used for distillation, this yields up to a 12% reduction in memory footprint for the Qwen2.5-1.5B model while also improving baseline performance up to 4% on the evaluated tasks. For the general case, we introduce a rigorous lossless procedure that leverages BPE recursive structure, complemented by a fast approximation that keeps large-vocabulary settings practical. Applied to distillation for mathematical reasoning, our approach improves GSM8K accuracy by more than 2% over the current state of the art.

</details>


### [8] [Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams](https://arxiv.org/abs/2512.14989)
*Yiming Cui,Xin Yao,Yuxuan Qin,Xin Li,Shijin Wang,Guoping Hu*

Main category: cs.CL

TL;DR: 系统评估40个多模态大语言模型在化学奥林匹克题目上的表现，发现模型在多模态融合方面存在困难，思维链提示能显著提升性能，揭示了当前MLLMs在科学推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 多模态科学推理对大型语言模型仍具挑战性，特别是在化学领域，问题解决需要结合符号图表、分子结构和结构化视觉数据。需要系统评估当前多模态模型在复杂化学问题上的表现。

Method: 使用超过20年美国国家化学奥林匹克竞赛题目构建基准，系统评估40个专有和开源多模态LLMs（包括GPT-5、o3、Gemini-2.5-Pro、Qwen2.5-VL等）。采用思维链提示、消融研究和基于遮挡的可解释性分析。

Result: 许多模型在多模态融合方面表现不佳，有时移除图像反而提高准确率，表明视觉-语言整合存在错位。思维链提示能一致提升准确率和视觉基础性。揭示了当前MLLMs在科学推理能力上的关键限制。

Conclusion: 这项工作为衡量领域特定多模态AI进展提供了及时基准，强调了在人工智能与科学推理交叉领域需要进一步推进，为开发更稳健、可解释的化学多模态系统提供了可行策略。

Abstract: Multimodal scientific reasoning remains a significant challenge for large language models (LLMs), particularly in chemistry, where problem-solving relies on symbolic diagrams, molecular structures, and structured visual data. Here, we systematically evaluate 40 proprietary and open-source multimodal LLMs, including GPT-5, o3, Gemini-2.5-Pro, and Qwen2.5-VL, on a curated benchmark of Olympiad-style chemistry questions drawn from over two decades of U.S. National Chemistry Olympiad (USNCO) exams. These questions require integrated visual and textual reasoning across diverse modalities. We find that many models struggle with modality fusion, where in some cases, removing the image even improves accuracy, indicating misalignment in vision-language integration. Chain-of-Thought prompting consistently enhances both accuracy and visual grounding, as demonstrated through ablation studies and occlusion-based interpretability. Our results reveal critical limitations in the scientific reasoning abilities of current MLLMs, providing actionable strategies for developing more robust and interpretable multimodal systems in chemistry. This work provides a timely benchmark for measuring progress in domain-specific multimodal AI and underscores the need for further advances at the intersection of artificial intelligence and scientific reasoning.

</details>


### [9] [DASH: Dialogue-Aware Similarity and Handshake Recognition for Topic Segmentation in Public-Channel Conversations](https://arxiv.org/abs/2512.15042)
*Sijin Sun,Liangbin Zhao,Ming Deng,Xiuju Fu*

Main category: cs.CL

TL;DR: 提出DASH-DTS框架，通过对话握手识别、相似性引导示例选择和正负样本生成，在非正式语音对话中实现主题分割，并在首个海事VHF数据集VHF-Dial上取得SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 任务导向的公共频道通信（如海事VHF对话）具有非正式语音和隐式转换特点，传统方法难以有效处理，需要开发专门的主题分割方法。

Method: 提出DASH-DTS框架：1）通过对话握手识别检测主题转换；2）使用相似性引导的示例选择进行上下文增强；3）生成选择性正负样本以提高模型判别力和鲁棒性。

Result: 在首个公开海事VHF通信数据集VHF-Dial和标准基准测试上取得了多个SOTA分割可信精度，为操作对话的稳定监控和决策支持奠定基础。

Conclusion: DASH-DTS框架有效解决了非正式语音对话中的主题分割问题，提供可解释的推理和置信度评分，并发布了首个真实世界海事VHF通信数据集推动该领域研究。

Abstract: Dialogue Topic Segmentation (DTS) is crucial for understanding task-oriented public-channel communications, such as maritime VHF dialogues, which feature informal speech and implicit transitions. To address the limitations of traditional methods, we propose DASH-DTS, a novel LLM-based framework. Its core contributions are: (1) topic shift detection via dialogue handshake recognition; (2) contextual enhancement through similarity-guided example selection; and (3) the generation of selective positive and negative samples to improve model discrimination and robustness. Additionally, we release VHF-Dial, the first public dataset of real-world maritime VHF communications, to advance research in this domain. DASH-DTS provides interpretable reasoning and confidence scores for each segment. Experimental results demonstrate that our framework achieves several sota segmentation trusted accuracy on both VHF-Dial and standard benchmarks, establishing a strong foundation for stable monitoring and decision support in operational dialogues.

</details>


### [10] [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052)
*Hongbo Wang,MaungMaung AprilPyone,Isao Echizen*

Main category: cs.CL

TL;DR: SGM提出一种白盒神经元级多模态干预方法，通过选择性重新校准有毒专家神经元来降低多模态大语言模型的毒性，无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型从弱监管的预训练语料中继承了有毒、偏见和NSFW信号，存在安全风险，特别是在对抗性触发条件下，现有的训练无关的解毒方法难以有效处理。

Method: SGM采用白盒神经元级多模态干预，选择性重新校准一小部分有毒专家神经元，通过专业加权软抑制来中和有害的跨模态激活，无需参数更新。

Result: 在开源MLLMs上的实验显示，SGM在标准和对抗条件下都能有效降低毒性，将有害率从48.2%降至2.5%，同时保持流畅性和多模态推理能力。

Conclusion: SGM提供了一种可解释、低成本的毒性控制多模态生成解决方案，其组合防御SGM*可与现有解毒方法结合以获得更强的安全性能。

Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort.
  Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.

</details>


### [11] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: 提出了Meta-Prompting Protocol框架，通过对抗性三元组结构（生成器、审计器、优化器）将LLM交互形式化为可编程、自优化的系统，使用文本批评作为梯度来减少幻觉和模型崩溃。


<details>
  <summary>Details</summary>
Motivation: 当前基于启发式的"提示工程"方法无法为关键任务应用提供确定性保证，需要重新设计LLM交互范式，使其从随机聊天接口转变为可靠的软件组件。

Method: 提出Meta-Prompting Protocol理论框架，采用对抗性三元组拓扑结构：生成器(P)生成内容，审计器(A)评估质量，优化器(O)基于文本批评进行改进。将自然语言指令视为语义计算图中的可微分变量，使用文本批评作为梯度。

Result: 通过声明式编程范式(DSPy)和自动文本微分(TextGrad)证明了该方法的理论可行性，为概率计算时代的"可观测软件工程"奠定了基础。

Conclusion: 该协议为LLM交互提供了严格的数学框架，能够减少幻觉和防止模型崩溃，使LLM能够作为可靠的软件组件在关键任务应用中使用。

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [12] [Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning](https://arxiv.org/abs/2512.15146)
*Weiqin Wang,Yile Wang,Kehao Chen,Hui Huang*

Main category: cs.CL

TL;DR: SCOPE提出了一种基于置信度的伪标签估计框架，通过动态子组划分和逐步置信度加权来解决测试时强化学习中多数投票策略的确认偏差和稀疏奖励问题。


<details>
  <summary>Details</summary>
Motivation: 测试时强化学习使用多数投票结果作为伪标签来减少对标注数据的依赖，但这种方法容易产生确认偏差且奖励稀疏，限制了整体性能。

Method: SCOPE框架整合了逐步置信度到伪标签推导中，优先考虑高质量推理路径而非简单频率计数；同时动态地将候选输出池划分为独立子组，平衡推理质量与探索多样性；通过每个子组的重复采样获得局部共识。

Result: SCOPE在各种模型和基准测试中均优于现有基线方法，在AIME 2025上相对提升13.1%，在AMC上相对提升8.1%。

Conclusion: SCOPE通过置信度加权和动态子组划分有效解决了测试时强化学习中的确认偏差和稀疏奖励问题，显著提升了大型语言模型的推理能力。

Abstract: Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\% on challenging AIME 2025 and 8.1\% on AMC. The code is released at \href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.

</details>


### [13] [Rakuten Data Release: A Large-Scale and Long-Term Reviews Corpus for Hotel Domain](https://arxiv.org/abs/2512.15151)
*Yuki Nakayama,Koki Hikichi,Yun Ching Liu,Yu Hirate*

Main category: cs.CL

TL;DR: 构建了一个大规模的乐天旅游评论语料库，包含2009-2024年730万条客户评论，涵盖多种元数据，并分析了2019-2024年间的数据漂移因素。


<details>
  <summary>Details</summary>
Motivation: 缺乏大规模、长时间跨度的旅游评论数据集，难以进行深入的旅游领域自然语言处理和数据分析研究。

Method: 收集了乐天旅游平台16年间的客户评论数据，构建包含文本评论、商家回复、用户评分和多种元数据的结构化数据集，并使用统计方法分析数据漂移。

Result: 创建了包含730万条评论的大规模语料库，覆盖16年时间跨度，提供了详细的统计信息，并识别了2019-2024年间影响数据漂移的关键因素。

Conclusion: 该语料库为旅游领域的自然语言处理研究提供了宝贵资源，数据漂移分析有助于理解用户行为和平台变化对评论数据的影响。

Abstract: This paper presents a large-scale corpus of Rakuten Travel Reviews. Our collection contains 7.3 million customer reviews for 16 years, ranging from 2009 to 2024. Each record in the dataset contains the review text, its response from an accommodation, an anonymized reviewer ID, review date, accommodation ID, plan ID, plan title, room type, room name, purpose, accompanying group, and user ratings from different aspect categories, as well as an overall score. We present statistical information about our corpus and provide insights into factors driving data drift between 2019 and 2024 using statistical approaches.

</details>


### [14] [MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers](https://arxiv.org/abs/2512.15163)
*Xuanjun Zong,Zhiqi Shen,Lei Wang,Yunshi Lan,Chao Yang*

Main category: cs.CL

TL;DR: MCP-SafetyBench：首个基于真实MCP服务器的综合安全基准，评估LLM代理在多服务器工作流中的安全风险


<details>
  <summary>Details</summary>
Motivation: MCP协议使LLM能够连接异构工具和服务，但其开放性和多服务器工作流引入了新的安全风险，现有基准无法捕捉这些现实威胁

Method: 构建基于真实MCP服务器的基准，覆盖浏览器自动化、金融分析、位置导航、仓库管理和网络搜索五个领域，包含20种攻击类型的统一分类，支持多轮评估和多服务器协调任务

Result: 评估主流开源和闭源LLM发现安全性能差异巨大，随着任务复杂度和服务器交互增加，漏洞呈指数级增长

Conclusion: MCP-SafetyBench为诊断和缓解真实MCP部署中的安全风险提供了基础，突显了加强防御的紧迫需求

Abstract: Large language models (LLMs) are evolving into agentic systems that reason, plan, and operate external tools. The Model Context Protocol (MCP) is a key enabler of this transition, offering a standardized interface for connecting LLMs with heterogeneous tools and services. Yet MCP's openness and multi-server workflows introduce new safety risks that existing benchmarks fail to capture, as they focus on isolated attacks or lack real-world coverage. We present MCP-SafetyBench, a comprehensive benchmark built on real MCP servers that supports realistic multi-turn evaluation across five domains: browser automation, financial analysis, location navigation, repository management, and web search. It incorporates a unified taxonomy of 20 MCP attack types spanning server, host, and user sides, and includes tasks requiring multi-step reasoning and cross-server coordination under uncertainty. Using MCP-SafetyBench, we systematically evaluate leading open- and closed-source LLMs, revealing large disparities in safety performance and escalating vulnerabilities as task horizons and server interactions grow. Our results highlight the urgent need for stronger defenses and establish MCP-SafetyBench as a foundation for diagnosing and mitigating safety risks in real-world MCP deployments.

</details>


### [15] [From NLG Evaluation to Modern Student Assessment in the Era of ChatGPT: The Great Misalignment Problem and Pedagogical Multi-Factor Assessment (P-MFA)](https://arxiv.org/abs/2512.15183)
*Mika Hämäläinen,Kimmo Leiviskä*

Main category: cs.CL

TL;DR: 论文探讨了NLG评估与芬兰大学学生评分之间的认知平行性，两者都面临"大错位问题"，并提出基于过程的P-MFA评估模型


<details>
  <summary>Details</summary>
Motivation: 随着学生越来越多地使用ChatGPT等工具生成复杂输出，传统基于最终产出的评估方法已失去有效性，需要新的评估框架来解决这一"大错位问题"

Method: 提出教学多因素评估（P-MFA）模型，这是一个基于过程、多证据的框架，灵感来源于多因素认证逻辑

Result: 论文建立了NLG评估与学生评分之间的认知平行性，识别了两者共同的"大错位问题"，并提出了创新的过程导向评估解决方案

Conclusion: 需要从基于产出的评估转向基于过程的评估，P-MFA模型为解决AI工具普及背景下的评估有效性提供了新思路

Abstract: This paper explores the growing epistemic parallel between NLG evaluation and grading of students in a Finnish University. We argue that both domains are experiencing a Great Misalignment Problem. As students increasingly use tools like ChatGPT to produce sophisticated outputs, traditional assessment methods that focus on final products rather than learning processes have lost their validity. To address this, we introduce the Pedagogical Multi-Factor Assessment (P-MFA) model, a process-based, multi-evidence framework inspired by the logic of multi-factor authentication.

</details>


### [16] [RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA](https://arxiv.org/abs/2512.15219)
*Chao Zhang,Minghan Li,Tianrui Lv,Guodong Zhou*

Main category: cs.CL

TL;DR: RFKG-CoT：通过关系驱动的自适应跳数选择器和少样本上下文学习路径指导机制，改进知识图谱增强的思维链方法，减少LLM在知识密集型QA中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有KG-CoT方法存在两个主要问题：1）僵化的跳数选择（仅基于问题驱动），无法根据关系类型动态调整推理步骤；2）推理路径利用不足（缺乏指导），导致LLM无法有效理解和使用知识图谱证据。

Method: 提出RFKG-CoT框架：1）关系驱动的自适应跳数选择器，通过关系掩码动态调整推理步骤（如直接关系用1跳，间接关系链用2跳）；2）少样本上下文学习路径指导机制，以"问题-路径-答案"格式构建示例，增强LLM对推理路径的理解能力。

Result: 在四个KGQA基准测试中，RFKG-CoT相比KG-CoT显著提升准确率，最高提升14.7个百分点（Llama2-7B在WebQSP上）。消融实验证实跳数选择器和路径提示是互补的，共同将KG证据转化为更可靠的答案。

Conclusion: RFKG-CoT通过自适应跳数选择和路径指导机制，有效解决了现有KG增强方法在知识密集型QA中的局限性，显著减少了LLM的幻觉问题，提高了答案的可靠性。

Abstract: Large language models (LLMs) often generate hallucinations in knowledge-intensive QA due to parametric knowledge limitations. While existing methods like KG-CoT improve reliability by integrating knowledge graph (KG) paths, they suffer from rigid hop-count selection (solely question-driven) and underutilization of reasoning paths (lack of guidance). To address this, we propose RFKG-CoT: First, it replaces the rigid hop-count selector with a relation-driven adaptive hop-count selector that dynamically adjusts reasoning steps by activating KG relations (e.g., 1-hop for direct "brother" relations, 2-hop for indirect "father-son" chains), formalized via a relation mask. Second, it introduces a few-shot in-context learning path guidance mechanism with CoT (think) that constructs examples in a "question-paths-answer" format to enhance LLMs' ability to understand reasoning paths. Experiments on four KGQA benchmarks show RFKG-CoT improves accuracy by up to 14.7 pp (Llama2-7B on WebQSP) over KG-CoT. Ablations confirm the hop-count selector and the path prompt are complementary, jointly transforming KG evidence into more faithful answers.

</details>


### [17] [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)
*Yash Bhaskar,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: Yes-MT团队在WMT 2024低资源印度语言翻译任务中，针对英语与阿萨姆语、米佐语、卡西语、曼尼普尔语之间的翻译，探索了多种方法，包括微调预训练模型、LLM提示、LoRA微调等，结果显示LLM微调在低资源翻译中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 解决低资源印度语言（阿萨姆语、米佐语、卡西语、曼尼普尔语）与英语之间的机器翻译问题，这些语言由于数据稀缺而面临翻译挑战。

Method: 采用了多种方法：1) 微调预训练模型（mT5、IndicBart）的多语言和单语言版本；2) 使用LoRA微调IndicTrans2；3) 对Llama 3和Mixtral 8x7b等大语言模型进行零样本和少样本提示；4) 对Llama 3进行LoRA监督微调；5) 从头训练Transformer模型。

Result: 使用SacreBLEU和CHRF在WMT23测试数据上评估，结果显示低资源翻译具有挑战性，但大语言模型特别是经过微调后，在这些任务中显示出潜力。

Conclusion: 低资源印度语言翻译仍然具有挑战性，但大语言模型（特别是经过微调）为解决这一问题提供了有前景的途径，未来需要更多研究来优化这些方法。

Abstract: This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.

</details>


### [18] [FAME: Fictional Actors for Multilingual Erasure](https://arxiv.org/abs/2512.15235)
*Claudio Savelli,Moreno La Quatra,Alkis Koudounas,Flavio Giobergia*

Main category: cs.CL

TL;DR: FAME是一个用于评估大语言模型机器遗忘的多语言合成基准，包含1000个虚构演员传记和20000个问答对，支持实体级和实例级遗忘评估，覆盖英语、法语、德语、意大利语和西班牙语五种语言。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型机器遗忘基准存在两个主要限制：仅关注英语，且仅支持实体级遗忘（即删除关于某个人的所有信息）。这限制了机器遗忘技术在多语言场景和细粒度遗忘需求下的评估能力。

Method: 创建了FAME基准，包含1000个虚构演员的完整传记，每个传记包含20个主题信息，组织成结构化类别（传记、职业、成就、个人信息）。生成了20000个问答对，提供两个数据集分割来支持实体级和实例级遗忘场景。使用完全虚构的数据确保模型在预训练期间从未接触过这些信息。

Result: FAME基准支持五种语言（英语、法语、德语、意大利语、西班牙语），能够系统比较不同语言下的遗忘技术。通过使用虚构数据，实现了对遗忘方法的受控评估，避免了预训练数据污染的问题。

Conclusion: FAME填补了现有机器遗忘基准在多语言支持和细粒度遗忘评估方面的空白，为研究社区提供了一个标准化、可控的评估框架，能够更全面地评估大语言模型的遗忘能力。

Abstract: LLMs trained on web-scale data raise concerns about privacy and the right to be forgotten. To address these issues, Machine Unlearning provides techniques to remove specific information from trained models without retraining from scratch. However, existing benchmarks for evaluating unlearning in LLMs face two major limitations: they focus only on English and support only entity-level forgetting (removing all information about a person). We introduce FAME (Fictional Actors for Multilingual Erasure), a synthetic benchmark for evaluating Machine Unlearning across five languages: English, French, German, Italian, and Spanish. FAME contains 1,000 fictional actor biographies and 20,000 question-answer pairs. Each biography includes information on 20 topics organized into structured categories (biography, career, achievements, personal information). This design enables both entity-level unlearning (i.e., forgetting entire identities) and instance-level unlearning (i.e., forgetting specific facts while retaining others). We provide two dataset splits to support these two different unlearning scenarios and enable systematic comparison of unlearning techniques across languages. Since FAME uses entirely fictional data, it ensures that the information was never encountered during model pretraining, allowing for a controlled evaluation of unlearning methods.

</details>


### [19] [The Moralization Corpus: Frame-Based Annotation and Analysis of Moralizing Speech Acts across Diverse Text Genres](https://arxiv.org/abs/2512.15248)
*Maria Becker,Mirko Sommer,Lars Tapken,Yi Wan Teh,Bruno Brocai*

Main category: cs.CL

TL;DR: 本文提出了Moralization Corpus，一个用于分析道德论证的多体裁德语数据集，开发了基于框架的标注方案，并评估了LLM在道德化检测任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 道德化论证（引用道德价值来支持立场）是一种尚未充分探索的说服性交流形式，在语用上复杂且通常隐含，对人类标注者和NLP系统都构成挑战。

Method: 开发了基于框架的标注方案，捕捉道德化的构成要素（道德价值、要求、话语主体），应用于德语政治辩论、新闻文章和在线讨论等多体裁文本，创建了Moralization Corpus。

Result: 详细提示指令比少样本或基于解释的提示效果更好；道德化检测仍然是一个高度主观和上下文敏感的任务；发布了所有数据、标注指南和代码。

Conclusion: 该语料库支持跨沟通格式和领域的道德化语言细粒度分析，为NLP中的道德话语和道德推理研究提供了资源，揭示了自动和手动分析道德化的挑战。

Abstract: Moralizations - arguments that invoke moral values to justify demands or positions - are a yet underexplored form of persuasive communication. We present the Moralization Corpus, a novel multi-genre dataset designed to analyze how moral values are strategically used in argumentative discourse. Moralizations are pragmatically complex and often implicit, posing significant challenges for both human annotators and NLP systems. We develop a frame-based annotation scheme that captures the constitutive elements of moralizations - moral values, demands, and discourse protagonists - and apply it to a diverse set of German texts, including political debates, news articles, and online discussions. The corpus enables fine-grained analysis of moralizing language across communicative formats and domains. We further evaluate several large language models (LLMs) under varied prompting conditions for the task of moralization detection and moralization component extraction and compare it to human annotations in order to investigate the challenges of automatic and manual analysis of moralizations. Results show that detailed prompt instructions has a greater effect than few-shot or explanation-based prompting, and that moralization remains a highly subjective and context-sensitive task. We release all data, annotation guidelines, and code to foster future interdisciplinary research on moral discourse and moral reasoning in NLP.

</details>


### [20] [SynGP500: A Clinically-Grounded Synthetic Dataset of Australian General Practice Medical Notes](https://arxiv.org/abs/2512.15259)
*Piyawoot Songsiritat*

Main category: cs.CL

TL;DR: SynGP500是一个包含500份澳大利亚全科医疗记录的临床医生策划合成数据集，整合了课程覆盖、流行病学校准和多样咨询场景，旨在支持更通用的临床NLP模型训练。


<details>
  <summary>Details</summary>
Motivation: 解决澳大利亚全科医疗领域缺乏高质量、隐私保护的临床文本数据集的问题，同时克服真实数据中罕见病例分布不均的局限性，支持更通用的临床NLP方法开发。

Method: 基于RACGP 2022课程框架，结合BEACH研究的流行病学数据校准患病率，设计包含常见和罕见病例的多样化咨询场景，并故意引入真实医疗记录中的"混乱"特征（如简写、拼写错误、患者不依从等）。

Result: 数据集通过多维度验证：流行病学模式与真实GP咨询数据对齐，语言变异度高，语义覆盖广泛，在自监督医疗概念提取任务中显示F1分数提升。

Conclusion: SynGP500填补了澳大利亚全科医疗NLP研究的关键空白，为研究人员和教育者提供了隐私保护、真实反映临床复杂性的数据集资源。

Abstract: We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.

</details>


### [21] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)
*Yiliu Sun,Zicheng Zhao,Yang Wei,Yanfang Zhang,Chen Gong*

Main category: cs.CL

TL;DR: PPPO是一种新的RLVR方法，专注于优化LLM推理过程中的前缀token，通过渐进式前缀保留和延续累积奖励策略，显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法对所有生成token进行统一训练，忽视了不同token对推理的贡献差异，特别是前缀token的关键作用。这种均匀训练策略浪费资源优化低回报token，限制了高回报token的改进潜力。

Method: 提出渐进式前缀token策略优化（PPPO），基于"路径依赖"理论识别LLM推理中的"起始锁定效应"，专注于优化前缀推理过程。采用两种训练策略：1）渐进式前缀保留：逐步增加训练中保留的前缀token比例；2）延续累积奖励：为单个前缀序列采样多个延续，累积其分数作为奖励信号。

Result: 在各种推理任务上的实验结果表明，PPPO显著优于代表性RLVR方法，仅使用26.17%的训练token就实现了18.02%的准确率提升。

Conclusion: PPPO通过专注于优化LLM推理的前缀过程，有效提升了训练效率和推理性能，验证了前缀token在LLM推理中的关键作用。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.

</details>


### [22] [Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues](https://arxiv.org/abs/2512.15302)
*Xiaotian Zhang,Yuan Wang,Ruizhe Chen,Zeya Wang,Runchen Hou,Zuozhu Liu*

Main category: cs.CL

TL;DR: PersonalAgent：一种面向终身个性化的人机对话代理，通过动态构建用户画像来持续推断和适应用户偏好，解决了传统方法在长期个性化与冷启动问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型对齐技术主要关注普适人类价值观或静态的单轮偏好，无法满足长期个性化需求，也难以解决用户冷启动问题。需要一种能够持续推断和适应用户偏好的方法。

Method: 提出PersonalAgent，通过将对话分解为单轮交互，构建并动态优化统一的用户画像，将偏好推断建模为序列决策任务。该方法支持终身学习和跨会话偏好一致性。

Result: 实验表明PersonalAgent在理想和嘈杂对话环境中均优于基于提示和策略优化的基线方法，同时保持跨会话偏好一致性。人工评估确认其能自然连贯地捕捉用户偏好。

Conclusion: 终身个性化对于开发更具包容性和适应性的对话代理至关重要。PersonalAgent通过持续学习和动态适应，为个性化人机交互提供了有效解决方案。

Abstract: The deployment of Large Language Models (LLMs) in interactive systems necessitates a deep alignment with the nuanced and dynamic preferences of individual users. Current alignment techniques predominantly address universal human values or static, single-turn preferences, thereby failing to address the critical needs of long-term personalization and the initial user cold-start problem. To bridge this gap, we propose PersonalAgent, a novel user-centric lifelong agent designed to continuously infer and adapt to user preferences. PersonalAgent constructs and dynamically refines a unified user profile by decomposing dialogues into single-turn interactions, framing preference inference as a sequential decision-making task. Experiments show that PersonalAgent achieves superior performance over strong prompt-based and policy optimization baselines, not only in idealized but also in noisy conversational contexts, while preserving cross-session preference consistency. Furthermore, human evaluation confirms that PersonalAgent excels at capturing user preferences naturally and coherently. Our findings underscore the importance of lifelong personalization for developing more inclusive and adaptive conversational agents. Our code is available here.

</details>


### [23] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: 评估LLM在沸石合成实验信息提取中的效能，发现LLM在事件分类表现良好（80-90% F1），但在细粒度参数提取任务上表现一般（50-65% F1），且高级提示策略改进有限。


<details>
  <summary>Details</summary>
Motivation: 从沸石合成实验程序中提取结构化信息对材料发现至关重要，但现有方法尚未系统评估LLM在此领域特定任务中的表现。本研究旨在探索不同提示策略在科学信息提取中的效能。

Method: 研究四个关键子任务：事件类型分类、触发文本识别、论元角色提取和论元文本提取。评估四种提示策略（零样本、少样本、事件特定、反思式）在六个最先进LLM上的表现，使用包含1,530个标注句子的ZSEE数据集。

Result: LLM在事件类型分类上表现强劲（80-90% F1），但在细粒度提取任务上表现一般，特别是论元角色和论元文本提取（50-65% F1）。GPT-5-mini表现出极端的提示敏感性（11-79% F1变化）。高级提示策略相比零样本方法改进有限，揭示了基本架构限制。

Conclusion: 虽然LLM实现了高层次理解，但精确提取实验参数需要领域适应模型。研究结果为科学信息提取提供了定量基准，揭示了LLM在科学信息提取中的系统局限性。

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [24] [Why Your Academic Field Is Everywhere at Once: A Case Study of Arabic Linguistics](https://arxiv.org/abs/2512.15328)
*Ayman Eddakrouri,Amani Ramadan*

Main category: cs.CL

TL;DR: 应用Brookes分类离散度测量(Δ)分析当代阿拉伯应用语言学研究的主题结构，发现该领域呈现极端离散特征(Δ=0.194)，计算语言学占主导但非霸权地位。


<details>
  <summary>Details</summary>
Motivation: 需要量化分析阿拉伯应用语言学领域的主题结构特征，了解该学科的发展现状和分布模式，为领域评估提供实证基础。

Method: 使用Brookes分类离散度测量(Δ)方法，基于2019-2025年1,564篇出版物数据集，将研究分类为8个核心子学科，计算离散度指数。

Result: 计算得到Δ=0.194的极低离散度值，表明阿拉伯应用语言学领域呈现极端主题离散特征，计算语言学占主导但非霸权地位，与社会语言学、语言教学等子领域共存。

Conclusion: 阿拉伯应用语言学领域具有显著异质性而非集中性，Brookes方法适用于领域特征分析，该研究提供了可复制的文献计量学方法来评估学科结构。

Abstract: This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.

</details>


### [25] [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)
*Joao Queiroz*

Main category: cs.CL

TL;DR: 研究发现将提示改写为诗歌形式是一种有效的对抗性攻击方法，能显著降低对齐LLM的安全性，在MLCommons AILuminate基准测试中安全失败率增加18倍。手动诗歌攻击成功率约62%，自动版本43%，部分模型单轮交互成功率超90%。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索诗歌形式作为对抗性攻击机制的有效性，揭示当前LLM对齐方法的局限性。现有安全防护过度依赖表面模式，而诗歌形式能将提示转移到稀疏监督的潜在区域，绕过安全防护。同时指出葡萄牙语等高形态句法复杂度语言缺乏相关评估是重要研究空白。

Method: 研究方法包括：1）将常规拒绝的指令改写为诗歌形式；2）使用手动编写和自动生成的诗歌进行测试；3）在MLCommons AILuminate基准测试中评估安全失败率；4）测试不同对齐方法（RLHF、宪法AI、混合管道）的脆弱性；5）分析诗歌形式如何将提示转移到稀疏监督区域。

Result: 主要结果：1）诗歌形式使安全失败率增加18倍；2）手动诗歌攻击成功率约62%，自动版本43%；3）部分模型单轮交互成功率超90%；4）所有测试的对齐方法（RLHF、宪法AI、混合管道）都表现出一致的性能退化；5）揭示了安全防护过度依赖表面模式的根本问题。

Conclusion: 结论：诗歌形式是一种有效的通用单轮越狱机制，暴露了当前对齐方法的深层局限性。安全防护过度依赖表面模式，而诗歌的韵律变化能将提示转移到稀疏监督区域。研究强调需要评估葡萄牙语等高复杂度语言的特定脆弱性，现有评估忽略了韵律、格律等参数。

Abstract: Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become executable when rewritten as verse, producing up to 18 x more safety failures in benchmarks derived from MLCommons AILuminate. Manually written poems reach approximately 62% ASR, and automated versions 43%, with some models surpassing 90% success in single-turn interactions. The effect is structural: systems trained with RLHF, constitutional AI, and hybrid pipelines exhibit consistent degradation under minimal semiotic formal variation. Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns. This dissociation between apparent robustness and real vulnerability exposes deep limitations in current alignment regimes. The absence of evaluations in Portuguese, a language with high morphosyntactic complexity, a rich metric-prosodic tradition, and over 250 million speakers, constitutes a critical gap. Experimental protocols must parameterise scansion, metre, and prosodic variation to test vulnerabilities specific to Lusophone patterns, which are currently ignored.

</details>


### [26] [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)
*Zhengyi Zhao,Shubo Zhang,Yuxi Zhang,Huimin Wang,Binyang Li,Kam-Fai Wong*

Main category: cs.CL

TL;DR: Denser框架通过区分推理和回答阶段的信息密度，使用压缩符号进行高效中间计算，同时保持人类可读的最终答案，减少62%的token消耗。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂推理任务中，对中间推理过程和最终答案使用统一的语言密度，导致计算效率低下。研究发现推理过程主要为模型自身计算服务，而回答则是为了人类理解，这种差异为优化提供了机会。

Method: 提出Denser框架，包含三个组件：1) 查询处理模块分析输入问题；2) 高密度压缩推理机制进行高效中间计算；3) 答案生成组件将压缩推理转换为人类可读的解决方案。

Result: 在多个推理问答基准测试中，Denser相比标准Chain-of-Thought方法减少高达62%的token消耗，同时保持或提高了准确性，特别是在复杂多步推理问题上效果显著。

Conclusion: 通过区分推理和回答阶段的信息密度，Denser框架实现了计算效率的显著提升，为LLM推理任务提供了更高效的解决方案。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a computational function for the model itself, while answering serves a communicative function for human understanding. This distinction enables the use of compressed, symbol-rich language for intermediate computations while maintaining human-readable final explanations. To address this inefficiency, we present Denser: \underline{D}ual-d\underline{ens}ity inf\underline{er}ence, a novel framework that optimizes information density separately for reasoning and answering phases. Our framework implements this through three components: a query processing module that analyzes input problems, a high-density compressed reasoning mechanism for efficient intermediate computations, and an answer generation component that translates compressed reasoning into human-readable solutions. Experimental evaluation across multiple reasoning question answering benchmarks demonstrates that Denser reduces token consumption by up to 62\% compared to standard Chain-of-Thought methods while preserving or improving accuracy. These efficiency gains are particularly significant for complex multi-step reasoning problems where traditional methods generate extensive explanations.

</details>


### [27] [ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs](https://arxiv.org/abs/2512.15397)
*Lev Kharlashkin,Eiaki Morooka,Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: ORACLE平台将每日新闻转化为周度决策洞察，通过爬取、过滤、嵌入、分类新闻内容，构建时间依赖递归摘要图，为芬兰应用科学大学提供课程智能分析。


<details>
  <summary>Details</summary>
Motivation: 为芬兰应用科学大学提供从海量新闻中提取相关、结构化洞察的系统，帮助大学进行课程规划和战略决策，解决信息过载和相关性筛选问题。

Method: 平台爬取并版本化新闻，应用大学特定相关性过滤，嵌入内容，按PESTEL维度分类，构建时间依赖递归摘要图（TRSG），包含两层聚类并由LLM总结，每周重新计算。轻量级变化检测器识别新增、删除或变更内容，并将差异按主题分组进行PESTEL感知分析。

Result: 开发了稳定生产系统，详细描述了流水线设计和具体选择，提出了课程智能用例和评估计划，实现了从新闻到结构化周度洞察的自动化转换。

Conclusion: ORACLE系统成功将每日新闻转化为决策就绪的周度洞察，通过结构化分析和变化检测为大学提供课程智能支持，系统设计稳定且可扩展。

Abstract: ORACLE turns daily news into week-over-week, decision-ready insights for one of the Finnish University of Applied Sciences. The platform crawls and versions news, applies University-specific relevance filtering, embeds content, classifies items into PESTEL dimensions and builds a concise Time-Dependent Recursive Summary Graph (TRSG): two clustering layers summarized by an LLM and recomputed weekly. A lightweight change detector highlights what is new, removed or changed, then groups differences into themes for PESTEL-aware analysis. We detail the pipeline, discuss concrete design choices that make the system stable in production and present a curriculum-intelligence use case with an evaluation plan.

</details>


### [28] [Toward expert-level motivational interviewing for health behavior improvement with LLMs](https://arxiv.org/abs/2512.15446)
*Run-ze Hu,Yang Yang,Yi-hang Yang,Jing-qi Kong,Jia-hui Luo,Wen-yu Yang,Jing Chen,Jing-yao Liu,Hui-qun Zeng,Lei Zhang,Zheng Liu*

Main category: cs.CL

TL;DR: 本研究开发并评估了用于动机性访谈的大型语言模型（MI-LLMs），通过微调中文开源LLMs，使其在核心MI技能上接近真实人类咨询师水平，为AI辅助健康行为改变提供了可扩展的途径。


<details>
  <summary>Details</summary>
Motivation: 动机性访谈（MI）是促进健康行为改变的有效咨询方法，但其效果受到需要高度训练的人类咨询师的限制。本研究旨在探索一种可扩展的替代方案，通过开发大型语言模型来实现MI咨询。

Method: 研究首先整理五个中文心理咨询语料库，使用GPT-4和MI提示将高质量数据集转录为2,040个MI风格对话。然后微调三个中文开源LLMs（Baichuan2-7B-Chat、ChatGLM-4-9B-Chat和Llama-3-8B-Chinese-Chat-v2）。评估采用基于轮次的自动指标和专家手动编码（使用MITI编码手册4.2.1）。

Result: 微调显著提高了所有三个模型的BLEU-4和ROUGE分数。手动编码显示MI-LLMs在技术和关系全局评分以及MI一致性比率上接近真实MI对话水平，但复杂反思和反思-问题比率仍然较低。

Conclusion: MI导向的微调能够赋予通用LLMs核心的MI一致性咨询行为，为AI辅助健康行为改变支持提供了可扩展的途径，但需要在数据规模、复杂MI技能和真实世界干预试验方面进一步研究。

Abstract: Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.

</details>


### [29] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: 该研究首次对孟加拉语在2024年孟加拉国大规模起义期间的公众情绪进行分析，创建了包含2028条标注新闻标题的数据集，使用语言特定模型在情感分类任务上超越了多语言模型和传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 情感分析在选举和社交媒体趋势等场景已有研究，但在孟加拉语中针对社会动荡期间的情绪动态研究存在显著空白。本研究旨在填补这一空白，分析孟加拉国2024年大规模起义期间的公众情绪。

Method: 研究收集了主要Facebook新闻门户的2028条标注新闻标题，分为愤怒、希望和绝望三类。使用潜在狄利克雷分配(LDA)识别主题，并比较了语言特定模型、多语言变换器(mBERT, XLM-RoBERTa)和传统机器学习方法(SVM, 逻辑回归)的性能。

Result: 语言特定模型表现最佳，准确率达到73%，超越了多语言变换器(mBERT: 67%, XLM-RoBERTa: 71%)和传统机器学习方法(SVM和逻辑回归: 均为70%)。LDA分析识别出政治腐败和公众抗议等主要主题，并揭示了互联网封锁等事件对情绪模式的影响。

Conclusion: 研究表明语言特定模型在孟加拉语情感分析中具有优势，为理解政治动荡期间的公众情绪提供了有价值的见解，填补了该领域的研究空白。

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>


### [30] [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)
*Kuan Lu,Shuhang Lin,Sai Wu,Yichen Yao,Junhan Yang,Huan Li,Wei Chu,Xu Yinghui,Yuan Qi,Gang Chen*

Main category: cs.CL

TL;DR: CTKVR提出了一种新颖的两阶段KV缓存检索方案，通过先计算轻量级质心进行粗粒度索引，再进行细粒度令牌级优化，在长上下文场景下显著提升推理效率，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 长上下文场景（如多轮对话）中，LLM推理面临KV缓存内存开销高和内存访问延迟大的挑战。现有动态KV选择方法存在权衡问题：块级索引会因检索不相关KV条目而降低精度，令牌级索引则因检索机制低效导致高延迟。

Method: CTKVR采用质心-令牌两阶段检索策略：1）预填充阶段预计算轻量级质心用于质心粒度索引；2）基于查询向量在RoPE后相邻位置高度相似且共享大部分top-k KV缓存条目的观察，进行令牌级精化检索。同时实现CPU-GPU协同执行的优化索引构建和搜索系统。

Result: 在多个基准测试中，CTKVR在精度下降小于1%的情况下实现优异性能。在96K上下文长度下，对Llama-3-8B和Yi-9B模型，在不同GPU硬件上分别实现3倍和4倍的吞吐量加速。

Conclusion: CTKVR通过创新的两阶段KV检索方案，有效解决了长上下文推理中KV缓存管理的效率-精度权衡问题，为LLM在长上下文场景下的高效推理提供了实用解决方案。

Abstract: Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory accesses. Recent methods for dynamic KV selection struggle with trade-offs: block-level indexing degrades accuracy by retrieving irrelevant KV entries, while token-level indexing incurs high latency from inefficient retrieval mechanisms. In this paper, we propose CTKVR, a novel centroid-then-token KV retrieval scheme that addresses these limitations. CTKVR leverages a key observation: query vectors adjacent in position exhibit high similarity after Rotary Position Embedding (RoPE) and share most of their top-k KV cache entries. Based on this insight, CTKVR employs a two-stage retrieval strategy: lightweight centroids are precomputed during prefilling for centroid-grained indexing, followed by token-level refinement for precise KV retrieval. This approach balances retrieval efficiency and accuracy. To further enhance performance, we implement an optimized system for indexing construction and search using CPU-GPU co-execution. Experimentally, CTKVR achieves superior performance across multiple benchmarks with less than 1% accuracy degradation. Meanwhile, CTKVR delivers 3 times and 4 times throughput speedups on Llama-3-8B and Yi-9B at 96K context length across diverse GPU hardware.

</details>


### [31] [Learning inflection classes using Adaptive Resonance Theory](https://arxiv.org/abs/2512.15551)
*Peter Dekker,Heikki Rasilo,Bart de Boer*

Main category: cs.CL

TL;DR: 研究使用自适应共振理论神经网络对拉丁语、葡萄牙语和爱沙尼亚语的动词屈折变化类进行无监督聚类学习，发现最佳性能出现在泛化参数的狭窄区域内，学习到的特征与语言学描述相似。


<details>
  <summary>Details</summary>
Motivation: 屈折变化类是语言学家使用的抽象概念，为推断未遇到的形式提供类比基础，这种能力是形态习得和处理的重要组成部分。研究旨在探索个体语言使用者对动词屈折变化类系统的可学习性。

Method: 使用自适应共振理论（ART）神经网络作为认知合理且可解释的计算模型，该网络具有决定泛化程度的警戒参数。对拉丁语、葡萄牙语和爱沙尼亚语进行无监督聚类，将词位聚类到屈折变化类中。

Result: 聚类结果与实证屈折变化类的相似性因屈折系统的复杂性而异。在泛化参数的狭窄区域内发现最佳性能。从模型中提取的学习特征与屈折变化类的语言学描述相似。

Conclusion: 所提出的模型可用于未来研究屈折变化类的变化，通过将其纳入基于代理的模型中。该模型为研究个体语言使用者如何学习屈折模式提供了计算框架。

Abstract: The concept of inflection classes is an abstraction used by linguists, and provides a means to describe patterns in languages that give an analogical base for deducing previously unencountered forms. This ability is an important part of morphological acquisition and processing. We study the learnability of a system of verbal inflection classes by the individual language user by performing unsupervised clustering of lexemes into inflection classes. As a cognitively plausible and interpretable computational model, we use Adaptive Resonance Theory, a neural network with a parameter that determines the degree of generalisation (vigilance). The model is applied to Latin, Portuguese and Estonian. The similarity of clustering to attested inflection classes varies depending on the complexity of the inflectional system. We find the best performance in a narrow region of the generalisation parameter. The learned features extracted from the model show similarity with linguistic descriptions of the inflection classes. The proposed model could be used to study change in inflection classes in the future, by including it in an agent-based model.

</details>


### [32] [From Data to Dialogue: Unlocking Language for All](https://arxiv.org/abs/2512.15552)
*Dakota Ellis,Samy Bakikerali,Wanshan Chen,Bao Dinh,Uyen Le*

Main category: cs.CL

TL;DR: 本文提出了一种自动化创建专业词汇表(SWL)的方法，相比传统通用服务列表(GSL)，能以更少词汇达到95%语言理解覆盖率，且更实用、可扩展。


<details>
  <summary>Details</summary>
Motivation: 传统语言学家提出的通用服务列表(GSL)需要语言学专业知识、主观判断和大量时间，过程不够高效。需要一种更实用、可自动化的方法来帮助语言学习者识别最重要的英语词汇。

Method: 创建专业词汇表(SWL)，即针对特定语料库子集的词汇列表。通过仅使用客观标准来限制SWL创建过程，使其能够自动化、可扩展，并根据全球语言学习者的需求进行定制。

Result: 使用该模型创建的SWL在性能上超越了行业标准(NGSL)，以相对较少的词汇量达到了语言理解所需的95%覆盖率要求。

Conclusion: 专业词汇表(SWL)是语言学习者优化学习过程最实用的方法。通过自动化创建过程，可以实现规模化应用，满足全球语言学习者的个性化需求。

Abstract: Traditional linguists have proposed the use of a General Service List (GSL) to assist new language learners in identifying the most important words in English. This process requires linguistic expertise, subjective input, and a considerable amount of time. We attempt to create our own GSL and evaluate its practicality against the industry standard (The NGSL). We found creating a Specialized Word List (SWL), or a word list specific to a subset of the overall corpus, to be the most practical way for language-learners to optimize the process. The SWL's that we created using our model outperformed the industry standard, reaching the 95% coverage required for language comprehension with fewer words comparatively. By restricting the SWL process to objective criteria only, it can be automated, scaled, and tailored to the needs of language-learners across the globe.

</details>


### [33] [An Empirical Study on Chinese Character Decomposition in Multiword Expression-Aware Neural Machine Translation](https://arxiv.org/abs/2512.15556)
*Lifeng Han,Gareth J. F. Jones,Alan F. Smeaton*

Main category: cs.CL

TL;DR: 该论文系统研究汉字分解技术在多词表达感知神经机器翻译中的应用，探讨如何通过汉字分解技术更好地表示中文词汇和字符的原始含义，解决多词表达翻译的挑战。


<details>
  <summary>Details</summary>
Motivation: 多词表达式在自然语言处理中带来歧义、习语表达、低频使用和变体等挑战。虽然西方语言（特别是英语）在多词表达式处理方面取得显著进展，但中文等表意文字语言在这方面仍然落后。子词建模技术（如BPE）不能直接应用于汉字这样的表意文字，因此需要探索适合中文特性的方法。

Method: 采用系统研究方法，将汉字分解技术应用于多词表达感知的神经机器翻译。具体包括：1）研究汉字分解技术如何帮助表示中文词汇和字符的原始含义；2）探索该技术如何有效解决多词表达翻译的挑战；3）通过实验验证汉字分解技术在多词表达翻译中的效果。

Result: 论文报告了相关实验结果，展示了汉字分解技术在多词表达感知神经机器翻译中的贡献。具体结果包括：1）汉字分解技术如何增强对中文词汇和字符原始含义的表示；2）该技术在解决多词表达翻译挑战方面的有效性；3）与现有方法相比的改进效果。

Conclusion: 汉字分解技术为中文多词表达翻译提供了有效的解决方案，弥补了传统子词建模方法在表意文字语言上的不足。这项研究为中文自然语言处理任务，特别是多词表达翻译，提供了新的技术途径，有助于缩小中文与西方语言在相关研究领域的差距。

Abstract: Word meaning, representation, and interpretation play fundamental roles in natural language understanding (NLU), natural language processing (NLP), and natural language generation (NLG) tasks. Many of the inherent difficulties in these tasks stem from Multi-word Expressions (MWEs), which complicate the tasks by introducing ambiguity, idiomatic expressions, infrequent usage, and a wide range of variations. Significant effort and substantial progress have been made in addressing the challenging nature of MWEs in Western languages, particularly English. This progress is attributed in part to the well-established research communities and the abundant availability of computational resources. However, the same level of progress is not true for language families such as Chinese and closely related Asian languages, which continue to lag behind in this regard. While sub-word modelling has been successfully applied to many Western languages to address rare words improving phrase comprehension, and enhancing machine translation (MT) through techniques like byte-pair encoding (BPE), it cannot be applied directly to ideograph language scripts like Chinese. In this work, we conduct a systematic study of the Chinese character decomposition technology in the context of MWE-aware neural machine translation (NMT). Furthermore, we report experiments to examine how Chinese character decomposition technology contributes to the representation of the original meanings of Chinese words and characters, and how it can effectively address the challenges of translating MWEs.

</details>


### [34] [Bolmo: Byteifying the Next Generation of Language Models](https://arxiv.org/abs/2512.15586)
*Benjamin Minixhofer,Tyler Murray,Tomasz Limisiewicz,Anna Korhonen,Luke Zettlemoyer,Noah A. Smith,Edoardo M. Ponti,Luca Soldaini,Valentin Hofmann*

Main category: cs.CL

TL;DR: Bolmo是首个在1B和7B参数规模上具有竞争力的完全开放字节级语言模型家族，通过字节化现有子词级模型实现，性能接近领先的子词级模型，解决了字节级模型的实际应用问题。


<details>
  <summary>Details</summary>
Motivation: 传统子词分词存在字符理解不足和固定词汇表带来的效率限制问题，而现有的字节级语言模型主要从头训练，性能不足且不实用。需要一种方法既能克服子词分词的局限，又能保持与领先子词模型相当的性能。

Method: 通过"字节化"现有子词级模型：设计专门的架构解决字节级与子词级模型表达能力不匹配问题，使用精确蒸馏目标将子词模型转换为字节级模型，仅需不到1%的典型预训练token预算。

Result: Bolmo在字符理解任务上优于源子词模型，在某些编码任务上也表现更好，其他任务性能接近原模型。推理速度可通过更高token压缩比训练达到与子词模型竞争水平，并能利用现有生态系统进行廉价有效的后训练。

Conclusion: Bolmo使字节级语言模型成为与子词级模型在广泛用例中具有竞争力的实用选择，解决了字节级模型的实际应用障碍，为语言模型发展提供了新方向。

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteification enables overcoming the limitations of subword tokenization - such as insufficient character understanding and efficiency constraints due to the fixed subword vocabulary - while performing at the level of leading subword-level LMs. Bolmo is specifically designed for byteification: our architecture resolves a mismatch between the expressivity of prior byte-level architectures and subword-level LMs, which makes it possible to employ an effective exact distillation objective between Bolmo and the source subword model. This allows for converting a subword-level LM to a byte-level LM by investing less than 1\% of a typical pretraining token budget. Bolmo substantially outperforms all prior byte-level LMs of comparable size, and outperforms the source subword-level LMs on character understanding and, in some cases, coding, while coming close to matching the original LMs' performance on other tasks. Furthermore, we show that Bolmo can achieve inference speeds competitive with subword-level LMs by training with higher token compression ratios, and can be cheaply and effectively post-trained by leveraging the existing ecosystem around the source subword-level LM. Our results finally make byte-level LMs a practical choice competitive with subword-level LMs across a wide set of use cases.

</details>


### [35] [You Never Know a Person, You Only Know Their Defenses: Detecting Levels of Psychological Defense Mechanisms in Supportive Conversations](https://arxiv.org/abs/2512.15601)
*Hongbin Na,Zimu Wang,Zhaoming Chen,Peilin Zhou,Yining Hua,Grace Ziqi Zhou,Haiyang Zhang,Tao Shen,Wei Wang,John Torous,Shaoxiong Ji,Ling Chen*

Main category: cs.CL

TL;DR: 研究者开发了PsyDefConv对话语料库和DMRS Co-Pilot标注系统，用于自动识别心理防御机制，在临床对话中实现了22.4%的标注效率提升，但现有语言模型在防御识别上仍有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: 心理防御机制是人们在应对痛苦时使用的策略，但过度使用会影响心理健康和求助行为。目前防御机制难以可靠测量，特别是在临床对话中，需要更好的标注工具和数据集来支持相关研究。

Method: 1) 创建PsyDefConv对话语料库，包含200个对话和4709个话语，其中2336个求助者话语标注了防御水平；2) 开发DMRS Co-Pilot四阶段管道，提供基于证据的预标注；3) 进行平衡研究评估标注效率；4) 专家评审评估证据质量；5) 使用强语言模型进行零样本和微调基准测试。

Result: 1) 标注一致性达到Cohen's kappa 0.639；2) Co-Pilot减少平均标注时间22.4%；3) 专家评分较高（证据4.62/7，临床合理性4.44/7，洞察力4.40/7）；4) 最佳模型宏F1分数约30%，倾向于过度预测成熟防御；5) 分析显示成熟防御最常见，存在情绪特异性偏差。

Conclusion: PsyDefConv语料库和DMRS Co-Pilot系统为心理防御机制的语言研究提供了有价值的资源，显著提高了标注效率，但现有语言模型在防御识别任务上仍有很大改进空间，需要进一步研究来提升性能。

Abstract: Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.

</details>


### [36] [Evaluating Metrics for Safety with LLM-as-Judges](https://arxiv.org/abs/2512.15617)
*Kester Clegg,Richard Hawkins,Ibrahim Habli,Tom Lawton*

Main category: cs.CL

TL;DR: 论文主张通过采用加权指标篮子、上下文敏感度定义错误严重性，并设计触发人工审查的置信度阈值，来降低LLM在关键信息流中的风险


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地用于文本处理流程，可能替代人力瓶颈角色，但LLMs会犯错且某些处理角色是安全关键的。如何在关键信息流中安全可靠地引入LLMs？

Method: 主张安全论证应聚焦于LLM流程中评估点获得的证据类型，特别是在使用LLM-as-Judges评估框架中。采用加权指标篮子、上下文敏感度定义错误严重性，并设计触发人工审查的置信度阈值

Result: 虽然无法从许多自然语言处理任务中获得确定性评估，但通过上述方法可以降低评估中的错误风险

Conclusion: 在LLM-as-Judges评估框架中，通过综合评估策略和人工审查机制，可以在关键信息流中更安全地部署LLMs

Abstract: LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.

</details>


### [37] [How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](https://arxiv.org/abs/2512.15634)
*Darshita Rathore,Vineet Kumar,Chetna Bansal,Anindya Moitra*

Main category: cs.CL

TL;DR: LoRA在特定秩值下能达到甚至超越全参数微调的性能，尤其在推理任务上表现优异，同时分析了内部表示的变化


<details>
  <summary>Details</summary>
Motivation: 虽然参数高效微调方法（如LoRA）因计算效率高而被广泛使用，但其配置参数（如秩）在下游问答任务和泛化能力方面的影响尚未得到充分探索

Method: 在多个推理和回忆数据集上进行全面评估，进行秩扫描以量化SFT和PEFT之间的权衡，比较域内和域外适应中的准确性，并通过谱特征和层间注意力结构分析内部表示

Result: LoRA在特定秩值下能达到与SFT竞争甚至更优的性能，尤其在推理任务上；在域内和域外适应中表现出不同的泛化行为和任务特定遗忘

Conclusion: LoRA是一种有效的微调方法，在特定配置下能达到与全参数微调相当或更好的性能，同时通过分析内部表示变化提供了对模型适应过程的深入理解

Abstract: Large language models are increasingly adapted to downstream tasks through fine-tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT methods are widely used for their computational efficiency, the implications of their configurations (e.g., rank) remain under-explored in downstream Q&A tasks and generalisation. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade-off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, highlighting distinct generalisation behaviour and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, particularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer-wise attention structures, offering insights into representational drift and structural changes in attention patterns.

</details>


### [38] [Characterizing Mamba's Selective Memory using Auto-Encoders](https://arxiv.org/abs/2512.15653)
*Tamanna Hossain,Robert L. Logan,Ganesh Jagadeesan,Sameer Singh,Joel Tetreault,Alejandro Jaimes*

Main category: cs.CL

TL;DR: 研究分析了Mamba SSM语言模型在长序列处理中信息遗忘的模式，发现数学符号、组织实体名称和非标准英语方言等低频token更容易被遗忘。


<details>
  <summary>Details</summary>
Motivation: 虽然状态空间模型(SSM)在推理时使用固定内存，但处理长序列时会导致隐藏状态信息丢失。之前的研究只关注了信息丢失发生的序列长度，但没有分析SSM语言模型倾向于遗忘哪些类型的信息。

Method: 训练一个自编码器来从SSM的隐藏状态重建序列，通过比较输入和重建结果来测量信息损失。使用Mamba系列SSM语言模型(130M-1.4B参数)在4-256个token的序列上进行实验。

Result: 结果显示数学相关token(数字、变量)、组织实体提及和非标准美国英语方言的信息丢失率显著更高。进一步分析发现，预训练数据中出现频率较低的token更容易被遗忘。

Conclusion: 通过识别这些遗忘模式，为未来研究提供了明确方向，可以开发更好的方法来控制Mamba保留重要信息的能力。

Abstract: State space models (SSMs) are a promising alternative to transformers for language modeling because they use fixed memory during inference. However, this fixed memory usage requires some information loss in the hidden state when processing long sequences. While prior work has studied the sequence length at which this information loss occurs, it does not characterize the types of information SSM language models (LMs) tend to forget. In this paper, we address this knowledge gap by identifying the types of tokens (e.g., parts of speech, named entities) and sequences (e.g., code, math problems) that are more frequently forgotten by SSM LMs. We achieve this by training an auto-encoder to reconstruct sequences from the SSM's hidden state, and measure information loss by comparing inputs with their reconstructions. We perform experiments using the Mamba family of SSM LMs (130M--1.4B) on sequences ranging from 4--256 tokens. Our results show significantly higher rates of information loss on math-related tokens (e.g., numbers, variables), mentions of organization entities, and alternative dialects to Standard American English. We then examine the frequency that these tokens appear in Mamba's pretraining data and find that less prevalent tokens tend to be the ones Mamba is most likely to forget. By identifying these patterns, our work provides clear direction for future research to develop methods that better control Mamba's ability to retain important information.

</details>


### [39] [PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning](https://arxiv.org/abs/2512.15658)
*Xiaodi Li,Dingcheng Li,Rujun Gao,Mahmoud Zamani,Feng Mi,Latifur Khan*

Main category: cs.CL

TL;DR: PPSEBM：一种结合能量模型和渐进参数选择的新框架，用于解决NLP持续学习中的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 持续学习是机器学习的基本挑战，模型需要从任务流中学习而不遗忘先前知识。主要障碍是灾难性遗忘——学习新任务时早期任务性能下降。本文旨在解决NLP任务中的这一核心问题。

Method: PPSEBM框架整合了能量模型和渐进参数选择。渐进参数选择为每个新任务分配特定的任务参数，而能量模型生成先前任务的代表性伪样本。这些生成的样本主动指导参数选择过程，增强模型保留过去知识同时适应新任务的能力。

Result: 在多个NLP基准测试上的实验结果表明，PPSEBM优于最先进的持续学习方法，为缓解灾难性遗忘提供了有前景且鲁棒的解决方案。

Conclusion: PPSEBM通过结合渐进参数选择和能量模型生成伪样本，有效解决了NLP持续学习中的灾难性遗忘问题，展示了在保留过去知识同时适应新任务方面的优越性能。

Abstract: Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.

</details>


### [40] [Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers](https://arxiv.org/abs/2512.15674)
*Adam Karvonen,James Chua,Clément Dumas,Kit Fraser-Taliente,Subhash Kantamneni,Julian Minder,Euan Ong,Arnab Sen Sharma,Daniel Wen,Owain Evans,Samuel Marks*

Main category: cs.CL

TL;DR: 本文提出了一种通用的激活预言机（Activation Oracles）方法，通过训练LLM直接接受LLM激活作为输入，并用自然语言回答关于激活的任意问题，在多种任务上超越了现有的白盒和黑盒方法。


<details>
  <summary>Details</summary>
Motivation: 现有理解LLM激活的技术通常使用复杂、专门的方法，而近期提出的LatentQA方法虽然简化了这一过程，但局限于狭窄的任务设置。本文旨在从通用主义视角出发，探索更广泛、多样化的训练和评估设置。

Method: 采用LatentQA方法训练激活预言机（AOs），让LLM能够直接处理LLM激活并回答自然语言问题。研究在不同训练数据多样性下的性能扩展，包括分类任务和自监督上下文预测任务等多样化数据集。

Result: AOs能够恢复模型中微调后的信息（如传记知识或恶意倾向），即使这些信息未出现在输入文本中。在四个下游任务评估中，最佳AOs在所有任务上匹配或超越了现有白盒基线，在3/4的任务上表现最佳。多样化训练显著提升了模型性能。

Conclusion: 通过多样化训练让LLM回答自然语言查询，能够赋予其通用的能力来用语言表达LLM激活中的信息，为理解LLM内部表示提供了一种更简单有效的方法。

Abstract: Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [41] [Breathe with Me: Synchronizing Biosignals for User Embodiment in Robots](https://arxiv.org/abs/2512.14952)
*Iddo Yehoshua Wald,Amber Maimon,Shiyao Zhang,Dennis Küster,Robert Porzel,Tanja Schultz,Rainer Malaka*

Main category: cs.RO

TL;DR: 通过将用户呼吸与机器人动作同步来增强用户在机器人系统中的具身感体验


<details>
  <summary>Details</summary>
Motivation: 探索如何通过生理信号（特别是呼吸）的实时表示来增强用户在机器人系统中的具身感体验，扩展传统基于视觉运动反馈的具身化方法

Method: 采用"呼吸具身化"概念，在受试者内实验中让参与者控制机械臂，比较呼吸同步与非同步条件下用户的具身感体验

Result: 呼吸同步显著增强了身体所有权感，且大多数参与者更偏好同步条件

Conclusion: 生理信号表示可作为人机交互的新型内感受通路，对远程临场感、假肢、机器人协作和共享自主性有重要应用价值

Abstract: Embodiment of users within robotic systems has been explored in human-robot interaction, most often in telepresence and teleoperation. In these applications, synchronized visuomotor feedback can evoke a sense of body ownership and agency, contributing to the experience of embodiment. We extend this work by employing embreathment, the representation of the user's own breath in real time, as a means for enhancing user embodiment experience in robots. In a within-subjects experiment, participants controlled a robotic arm, while its movements were either synchronized or non-synchronized with their own breath. Synchrony was shown to significantly increase body ownership, and was preferred by most participants. We propose the representation of physiological signals as a novel interoceptive pathway for human-robot interaction, and discuss implications for telepresence, prosthetics, collaboration with robots, and shared autonomy.

</details>


### [42] [ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision](https://arxiv.org/abs/2512.15020)
*Wenlong Xia,Jinhao Zhang,Ce Zhang,Yaojia Wang,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: 提出Implicit Scene Supervision (ISS) Policy，一种基于点云观测和扩散Transformer的3D视觉运动策略，通过隐式场景监督模块提升训练效率和泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉的模仿学习过度依赖物体外观而忽略3D场景结构，导致训练效率低和泛化能力差

Method: 提出ISS Policy：基于点云观测的3D视觉运动DiT扩散策略，引入隐式场景监督模块，确保模型输出与场景几何演化一致

Result: 在单臂操作任务（MetaWorld）和灵巧手操作（Adroit）上达到SOTA性能，在真实世界实验中表现出强泛化性和鲁棒性

Conclusion: ISS Policy通过3D场景结构和隐式监督显著提升了模仿学习的效率和泛化能力，在仿真和真实环境中都表现出色

Abstract: Vision-based imitation learning has enabled impressive robotic manipulation skills, but its reliance on object appearance while ignoring the underlying 3D scene structure leads to low training efficiency and poor generalization. To address these challenges, we introduce \emph{Implicit Scene Supervision (ISS) Policy}, a 3D visuomotor DiT-based diffusion policy that predicts sequences of continuous actions from point cloud observations. We extend DiT with a novel implicit scene supervision module that encourages the model to produce outputs consistent with the scene's geometric evolution, thereby improving the performance and robustness of the policy. Notably, ISS Policy achieves state-of-the-art performance on both single-arm manipulation tasks (MetaWorld) and dexterous hand manipulation (Adroit). In real-world experiments, it also demonstrates strong generalization and robustness. Additional ablation studies show that our method scales effectively with both data and parameters. Code and videos will be released.

</details>


### [43] [HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles](https://arxiv.org/abs/2512.15047)
*Yunheng Wang,Yixiao Feng,Yuetong Fang,Shuning Zhang,Tan Jing,Jian Li,Xiangrui Jiang,Renjing Xu*

Main category: cs.RO

TL;DR: HERO框架构建层次化可通行3D场景图，通过将可操作障碍物建模为通路，显著提升机器人导航的效率和可达性。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图导航方法基于静态世界假设，将可交互障碍物视为不可通行，导致在真实场景中可达性有限、效率低下、扩展性差。

Method: 提出HERO框架，构建层次化可通行3D场景图，重新定义可通行性：将可操作障碍物建模为通路，捕捉其物理交互性、功能语义和场景关系层次。

Result: 相比基线方法，在部分阻塞环境中路径长度减少35.1%，在完全阻塞环境中成功率提升79.4%，显著提高了导航效率和可达性。

Conclusion: HERO通过建模可操作障碍物的交互特性，克服了传统静态世界假设的限制，为智能体在复杂真实环境中的导航提供了更有效的解决方案。

Abstract: 3D Scene Graphs (3DSGs) constitute a powerful representation of the physical world, distinguished by their abilities to explicitly model the complex spatial, semantic, and functional relationships between entities, rendering a foundational understanding that enables agents to interact intelligently with their environment and execute versatile behaviors. Embodied navigation, as a crucial component of such capabilities, leverages the compact and expressive nature of 3DSGs to enable long-horizon reasoning and planning in complex, large-scale environments. However, prior works rely on a static-world assumption, defining traversable space solely based on static spatial layouts and thereby treating interactable obstacles as non-traversable. This fundamental limitation severely undermines their effectiveness in real-world scenarios, leading to limited reachability, low efficiency, and inferior extensibility. To address these issues, we propose HERO, a novel framework for constructing Hierarchical Traversable 3DSGs, that redefines traversability by modeling operable obstacles as pathways, capturing their physical interactivity, functional semantics, and the scene's relational hierarchy. The results show that, relative to its baseline, HERO reduces PL by 35.1% in partially obstructed environments and increases SR by 79.4% in fully obstructed ones, demonstrating substantially higher efficiency and reachability.

</details>


### [44] [NAP3D: NeRF Assisted 3D-3D Pose Alignment for Autonomous Vehicles](https://arxiv.org/abs/2512.15080)
*Gaurav Bansal*

Main category: cs.RO

TL;DR: NAP3D：一种利用NeRF进行3D-3D位姿对齐的定位方法，通过将当前深度图像与预训练NeRF直接对齐来修正位姿误差，无需回环检测。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM中的视觉回环检测需要重新访问已观测位置，且依赖多传感器融合。在无法进行回环检测的场景中，需要一种不依赖回环的位姿修正方法。

Method: 提出NeRF-Assisted 3D-3D Pose Alignment (NAP3D)，利用智能体当前深度图像与预训练NeRF之间的3D-3D对应关系，直接对齐观测场景的3D点与NeRF合成的3D点来修正位姿。

Result: 在自定义数据集上实现5厘米内的相机位姿修正，在TUM RGB-D数据集上比2D-3D PnP基线方法提升约6厘米的3D对齐RMSE，显示出更好的几何一致性。

Conclusion: NAP3D提供了一种轻量级、数据集无关的工具，可在传统回环检测不可用时补充现有的SLAM和定位流程，通过3D-3D对应关系实现稳健的位姿修正。

Abstract: Accurate localization is essential for autonomous vehicles, yet sensor noise and drift over time can lead to significant pose estimation errors, particularly in long-horizon environments. A common strategy for correcting accumulated error is visual loop closure in SLAM, which adjusts the pose graph when the agent revisits previously mapped locations. These techniques typically rely on identifying visual mappings between the current view and previously observed scenes and often require fusing data from multiple sensors.
  In contrast, this work introduces NeRF-Assisted 3D-3D Pose Alignment (NAP3D), a complementary approach that leverages 3D-3D correspondences between the agent's current depth image and a pre-trained Neural Radiance Field (NeRF). By directly aligning 3D points from the observed scene with synthesized points from the NeRF, NAP3D refines the estimated pose even from novel viewpoints, without relying on revisiting previously observed locations.
  This robust 3D-3D formulation provides advantages over conventional 2D-3D localization methods while remaining comparable in accuracy and applicability. Experiments demonstrate that NAP3D achieves camera pose correction within 5 cm on a custom dataset, robustly outperforming a 2D-3D Perspective-N-Point baseline. On TUM RGB-D, NAP3D consistently improves 3D alignment RMSE by approximately 6 cm compared to this baseline given varying noise, despite PnP achieving lower raw rotation and translation parameter error in some regimes, highlighting NAP3D's improved geometric consistency in 3D space. By providing a lightweight, dataset-agnostic tool, NAP3D complements existing SLAM and localization pipelines when traditional loop closure is unavailable.

</details>


### [45] [BEV-Patch-PF: Particle Filtering with BEV-Aerial Feature Matching for Off-Road Geo-Localization](https://arxiv.org/abs/2512.15111)
*Dongmyeong Lee,Jesse Quattrociocchi,Christian Ellis,Rwik Rana,Amanda Adkins,Adam Uccello,Garrett Warnell,Joydeep Biswas*

Main category: cs.RO

TL;DR: BEV-Patch-PF：一种无需GPS的序列化地理定位系统，通过粒子滤波器结合鸟瞰图与航拍特征图匹配，在越野环境中实现高精度实时定位


<details>
  <summary>Details</summary>
Motivation: 解决GPS受限环境（如茂密树冠下）的机器人定位问题，传统GPS信号在复杂地形中不可靠，需要基于视觉的替代定位方案

Method: 从车载RGB和深度图像构建BEV特征图，为每个3自由度粒子姿态假设从航拍特征图中裁剪对应区域，通过特征匹配计算粒子对数似然，使用粒子滤波器进行序列化定位

Result: 在两个真实世界越野数据集上，相比基于检索的基线方法，在已见路线上绝对轨迹误差降低7.5倍，在未见路线上降低7.0倍，在茂密树冠和阴影下仍保持精度，在NVIDIA Tesla T4上以10Hz实时运行

Conclusion: BEV-Patch-PF系统实现了无需GPS的高精度实时地理定位，在复杂越野环境中表现优异，适合实际机器人部署

Abstract: We propose BEV-Patch-PF, a GPS-free sequential geo-localization system that integrates a particle filter with learned bird's-eye-view (BEV) and aerial feature maps. From onboard RGB and depth images, we construct a BEV feature map. For each 3-DoF particle pose hypothesis, we crop the corresponding patch from an aerial feature map computed from a local aerial image queried around the approximate location. BEV-Patch-PF computes a per-particle log-likelihood by matching the BEV feature to the aerial patch feature. On two real-world off-road datasets, our method achieves 7.5x lower absolute trajectory error (ATE) on seen routes and 7.0x lower ATE on unseen routes than a retrieval-based baseline, while maintaining accuracy under dense canopy and shadow. The system runs in real time at 10 Hz on an NVIDIA Tesla T4, enabling practical robot deployment.

</details>


### [46] [EPSM: A Novel Metric to Evaluate the Safety of Environmental Perception in Autonomous Driving](https://arxiv.org/abs/2512.15195)
*Jörg Gamerdinger,Sven Teufel,Stephan Amann,Lukas Marc Listl,Oliver Bringmann*

Main category: cs.RO

TL;DR: 提出一种新的感知系统安全评估框架，结合物体和车道检测任务，量化感知错误的安全风险，弥补传统精度指标的不足。


<details>
  <summary>Details</summary>
Motivation: 传统感知评估指标（如精度、召回率、F1分数）只关注整体检测准确性，但忽略了安全相关因素。即使在这些指标上表现优异的感知系统，仍可能产生导致严重事故的误检测。因此需要专门的安全评估方法来确保智能车辆在复杂驾驶场景中的安全性。

Method: 提出一个联合评估框架，包含：1）新的轻量级物体安全指标，量化物体检测错误相关的潜在风险；2）车道安全指标，考虑物体和车道检测任务之间的相互依赖关系。最终生成统一的、可解释的感知安全性能综合评分。

Result: 在DeepAccident数据集上的实验表明，该方法能够识别传统性能指标无法捕捉的安全关键感知错误，验证了安全中心评估方法的重要性。

Conclusion: 感知系统的安全评估至关重要，提出的安全指标框架能够更全面地评估感知系统在实际驾驶场景中的安全性能，为自动驾驶系统的安全验证提供了新方法。

Abstract: Extensive evaluation of perception systems is crucial for ensuring the safety of intelligent vehicles in complex driving scenarios. Conventional performance metrics such as precision, recall and the F1-score assess the overall detection accuracy, but they do not consider the safety-relevant aspects of perception. Consequently, perception systems that achieve high scores in these metrics may still cause misdetections that could lead to severe accidents. Therefore, it is important to evaluate not only the overall performance of perception systems, but also their safety. We therefore introduce a novel safety metric for jointly evaluating the most critical perception tasks, object and lane detection. Our proposed framework integrates a new, lightweight object safety metric that quantifies the potential risk associated with object detection errors, as well as an lane safety metric including the interdependence between both tasks that can occur in safety evaluation. The resulting combined safety score provides a unified, interpretable measure of perception safety performance. Using the DeepAccident dataset, we demonstrate that our approach identifies safety critical perception errors that conventional performance metrics fail to capture. Our findings emphasize the importance of safety-centric evaluation methods for perception systems in autonomous driving.

</details>


### [47] [Infrastructure-based Autonomous Mobile Robots for Internal Logistics -- Challenges and Future Perspectives](https://arxiv.org/abs/2512.15215)
*Erik Brorsson,Kristian Ceder,Ze Zhang,Sabino Francesco Roselli,Endre Erős,Martin Dahl,Beatrice Alenljung,Jessica Lindblom,Thanh Bui,Emmanuel Dean,Lennart Svensson,Kristofer Bengtsson,Per-Lage Götvall,Knut Åkesson*

Main category: cs.RO

TL;DR: 该论文综述了基于基础设施的自主移动机器人系统，提出了参考架构，并在重型车辆制造环境中进行了实际部署和用户体验评估。


<details>
  <summary>Details</summary>
Motivation: 当前大多数自主移动机器人解决方案强调分散式、车载智能，而利用基础设施（外部传感器和计算资源）支持室内环境（如工厂）的AMR系统在文献中尚未得到充分探索。

Method: 提出了结合基础设施感知、本地云计算和车载自主性的参考架构，并基于该架构回顾了定位、感知和规划等核心技术。在重型车辆制造环境中进行了实际部署，并进行了用户体验评估。

Result: 展示了基于基础设施的AMR系统在真实工业环境中的可行性，通过用户体验评估总结了实际应用中的发现，为未来开发提供了基础。

Conclusion: 该研究为未来在复杂工业环境中开发可扩展、鲁棒且与人兼容的AMR系统提供了全面的基础，强调了基础设施支持的重要性。

Abstract: The adoption of Autonomous Mobile Robots (AMRs) for internal logistics is accelerating, with most solutions emphasizing decentralized, onboard intelligence. While AMRs in indoor environments like factories can be supported by infrastructure, involving external sensors and computational resources, such systems remain underexplored in the literature. This paper presents a comprehensive overview of infrastructure-based AMR systems, outlining key opportunities and challenges. To support this, we introduce a reference architecture combining infrastructure-based sensing, on-premise cloud computing, and onboard autonomy. Based on the architecture, we review core technologies for localization, perception, and planning. We demonstrate the approach in a real-world deployment in a heavy-vehicle manufacturing environment and summarize findings from a user experience (UX) evaluation. Our aim is to provide a holistic foundation for future development of scalable, robust, and human-compatible AMR systems in complex industrial environments.

</details>


### [48] [VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments](https://arxiv.org/abs/2512.15258)
*Yuze Wu,Mo Zhu,Xingxing Li,Yuheng Du,Yuxin Fan,Wenjun Li,Xin Zhou,Fei Gao*

Main category: cs.RO

TL;DR: VLA-AN是一个高效的机载视觉-语言-动作框架，用于无人机在复杂环境中的自主导航，解决了现有大型空中导航模型的四个主要限制：数据域差距、时间导航推理不足、生成动作策略的安全问题以及机载部署约束。


<details>
  <summary>Details</summary>
Motivation: 现有大型空中导航模型存在四个主要问题：1）数据域差距导致模型泛化能力差；2）时间导航推理能力不足；3）生成动作策略存在安全隐患；4）难以在资源受限的无人机上部署。需要开发一个高效、安全、可机载部署的完整解决方案。

Method: 1）使用3D高斯溅射构建高保真数据集来弥合域差距；2）采用渐进式三阶段训练框架：场景理解→核心飞行技能→复杂导航能力；3）设计轻量级实时动作模块，结合几何安全校正；4）深度优化机载部署流程。

Result: VLA-AN在推理吞吐量上实现了8.3倍的实时提升，最大单任务成功率达到98.1%，显著改善了空间定位、场景推理和长时程导航能力，为轻量级空中机器人提供了高效实用的全链闭环自主解决方案。

Conclusion: VLA-AN通过创新的数据集构建、渐进式训练、安全动作模块和深度部署优化，成功解决了现有空中导航模型的关键限制，实现了高效、安全、可机载部署的自主导航系统，为轻量级无人机提供了实用的全链闭环自主解决方案。

Abstract: This paper proposes VLA-AN, an efficient and onboard Vision-Language-Action (VLA) framework dedicated to autonomous drone navigation in complex environments. VLA-AN addresses four major limitations of existing large aerial navigation models: the data domain gap, insufficient temporal navigation with reasoning, safety issues with generative action policies, and onboard deployment constraints. First, we construct a high-fidelity dataset utilizing 3D Gaussian Splatting (3D-GS) to effectively bridge the domain gap. Second, we introduce a progressive three-stage training framework that sequentially reinforces scene comprehension, core flight skills, and complex navigation capabilities. Third, we design a lightweight, real-time action module coupled with geometric safety correction. This module ensures fast, collision-free, and stable command generation, mitigating the safety risks inherent in stochastic generative policies. Finally, through deep optimization of the onboard deployment pipeline, VLA-AN achieves a robust real-time 8.3x improvement in inference throughput on resource-constrained UAVs. Extensive experiments demonstrate that VLA-AN significantly improves spatial grounding, scene reasoning, and long-horizon navigation, achieving a maximum single-task success rate of 98.1%, and providing an efficient, practical solution for realizing full-chain closed-loop autonomy in lightweight aerial robots.

</details>


### [49] [A Network-Based Framework for Modeling and Analyzing Human-Robot Coordination Strategies](https://arxiv.org/abs/2512.15282)
*Martijn IJtsma,Salvatore Hargis*

Main category: cs.RO

TL;DR: 提出一个用于分析人机系统联合工作策略的计算框架，整合功能建模和图论表示，支持概念设计阶段协调动态推理


<details>
  <summary>Details</summary>
Motivation: 随着机器人能力提升，需要更强的协作能力支持人机合作，但现有HRI框架要么关注实时执行计算支持，要么依赖静态设计表示，缺乏对早期概念设计阶段协调动态的推理支持

Method: 整合功能建模与图论表示的计算框架，从系统功能关系和工作环境物理信息结构角度描述集体工作，明确捕捉协调需求随时间演变

Result: 通过灾难机器人案例研究展示框架在概念设计阶段的应用，支持早期人机协调策略权衡探索，识别支持协调开销灵活管理的协作能力

Conclusion: 该框架使协调需求及其时间演变显式化，支持在实施前进行协作能力需求和工作需求的设时推理

Abstract: Studies of human-robot interaction in dynamic and unstructured environments show that as more advanced robotic capabilities are deployed, the need for cooperative competencies to support collaboration with human problem-holders increases. Designing human-robot systems to meet these demands requires an explicit understanding of the work functions and constraints that shape the feasibility of alternative joint work strategies. Yet existing human-robot interaction frameworks either emphasize computational support for real-time execution or rely on static representations for design, offering limited support for reasoning about coordination dynamics during early-stage conceptual design. To address this gap, this article presents a novel computational framework for analyzing joint work strategies in human-robot systems by integrating techniques from functional modeling with graph-theoretic representations. The framework characterizes collective work in terms of the relationships among system functions and the physical and informational structure of the work environment, while explicitly capturing how coordination demands evolve over time. Its use during conceptual design is demonstrated through a case study in disaster robotics, which shows how the framework can be used to support early trade-space exploration of human-robot coordination strategies and to identify cooperative competencies that support flexible management of coordination overhead. These results show how the framework makes coordination demands and their temporal evolution explicit, supporting design-time reasoning about cooperative competency requirements and work demands prior to implementation.

</details>


### [50] [GuangMing-Explorer: A Four-Legged Robot Platform for Autonomous Exploration in General Environments](https://arxiv.org/abs/2512.15309)
*Kai Zhang,Shoubin Chen,Dong Li,Baiyang Zhang,Tao Huang,Zehao Wu,Jiasheng Chen,Bo Zhang*

Main category: cs.RO

TL;DR: 本文介绍了GuangMing-Explorer，一个完全集成的自主探索平台，包含硬件和软件系统，旨在在各种环境中实现稳健的自主探索操作。


<details>
  <summary>Details</summary>
Motivation: 自主探索是感知、规划、控制和运动执行紧密结合的基础能力，在室内目标搜索、极端环境测绘、资源勘探等应用中至关重要。尽管各个组件取得了显著进展，但包含硬件和软件的完整自主探索系统的整体实用描述仍然稀缺。

Method: 提出了GuangMing-Explorer平台，提供了系统架构的全面概述，包括硬件设计、软件栈、算法部署和实验配置。这是一个完全集成的自主探索平台。

Result: 大量真实世界实验证明了该平台在执行自主探索任务方面的有效性和效率，突显了其在复杂和非结构化环境中实际部署的潜力。

Conclusion: GuangMing-Explorer是一个完全集成的自主探索平台，展示了在多样化环境中稳健操作的潜力，为复杂和非结构化环境中的实际部署提供了实用解决方案。

Abstract: Autonomous exploration is a fundamental capability that tightly integrates perception, planning, control, and motion execution. It plays a critical role in a wide range of applications, including indoor target search, mapping of extreme environments, resource exploration, etc. Despite significant progress in individual components, a holistic and practical description of a completely autonomous exploration system, encompassing both hardware and software, remains scarce. In this paper, we present GuangMing-Explorer, a fully integrated autonomous exploration platform designed for robust operation across diverse environments. We provide a comprehensive overview of the system architecture, including hardware design, software stack, algorithm deployment, and experimental configuration. Extensive real-world experiments demonstrate the platform's effectiveness and efficiency in executing autonomous exploration tasks, highlighting its potential for practical deployment in complex and unstructured environments.

</details>


### [51] [Remotely Detectable Robot Policy Watermarking](https://arxiv.org/abs/2512.15379)
*Michael Amir,Manon Flageat,Amanda Prorok*

Main category: cs.RO

TL;DR: 提出首个用于机器人策略远程检测的水印方法CoNoCo，通过利用策略固有随机性在机器人动作中嵌入频谱信号，可在仅通过外部观察（如视频）的情况下验证知识产权。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在机器人系统中的成功应用，训练好的策略成为一种新型知识产权，需要验证所有权并检测未经授权的使用。现有水印方法需要访问机器人内部状态，但审计者通常只能通过外部观察（如视频）进行检测，存在"物理观察鸿沟"。

Method: 提出Colored Noise Coherency (CoNoCo)水印策略，利用策略固有随机性在机器人动作中嵌入频谱信号。该方法通过形式化"瞥视序列"概念解决远程检测挑战，并证明不会降低策略性能（保持边缘动作分布）。

Result: 实验表明CoNoCo在各种远程模态下都能实现强大、鲁棒的检测，包括运动捕捉和侧视/俯视视频，在仿真和真实机器人实验中均有效。

Conclusion: 该工作为保护机器人知识产权提供了必要步骤，首次实现了仅通过远程观察非侵入式验证物理策略来源的方法。

Abstract: The success of machine learning for real-world robotic systems has created a new form of intellectual property: the trained policy. This raises a critical need for novel methods that verify ownership and detect unauthorized, possibly unsafe misuse. While watermarking is established in other domains, physical policies present a unique challenge: remote detection. Existing methods assume access to the robot's internal state, but auditors are often limited to external observations (e.g., video footage). This ``Physical Observation Gap'' means the watermark must be detected from signals that are noisy, asynchronous, and filtered by unknown system dynamics. We formalize this challenge using the concept of a \textit{glimpse sequence}, and introduce Colored Noise Coherency (CoNoCo), the first watermarking strategy designed for remote detection. CoNoCo embeds a spectral signal into the robot's motions by leveraging the policy's inherent stochasticity. To show it does not degrade performance, we prove CoNoCo preserves the marginal action distribution. Our experiments demonstrate strong, robust detection across various remote modalities, including motion capture and side-way/top-down video footage, in both simulated and real-world robot experiments. This work provides a necessary step toward protecting intellectual property in robotics, offering the first method for validating the provenance of physical policies non-invasively, using purely remote observations.

</details>


### [52] [MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training](https://arxiv.org/abs/2512.15411)
*Zhenhan Yin,Xuanhan Wang,Jiahao Jiang,Kaiyuan Deng,Pengqi Chen,Shuangle Li,Chong Liu,Xing Xu,ingkuan Song,Lianli Gao,Heng Tao Shen*

Main category: cs.RO

TL;DR: MiVLA通过人类-机器人相互模仿预训练，利用手部与机械臂的行为相似性建立行为先验，提升视觉语言动作模型在跨视角、外观和形态下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作模型（VLA）在利用人类视频和模拟机器人数据时，由于相机视角、视觉外观和形态结构的不匹配，泛化能力有限。需要解决真实世界人类数据与模拟机器人数据之间的鸿沟。

Method: 提出MiVLA，基于人类-机器人相互模仿预训练。使用左右手坐标系运动学规则进行双向对齐，让模型能够预测一种形态的行为轨迹，同时模仿另一种未见形态的行为，整合人类数据的真实行为保真度和模拟机器人数据的操作多样性。

Result: 在ARX、PiPer和LocoMan三个机器人平台上的仿真和真实世界实验中，MiVLA显著提升了泛化能力，在仿真中比现有最佳VLA（π₀、π₀.₅和H-RDT）提升25%，在真实机器人控制任务中提升14%。

Conclusion: 通过人类-机器人相互模仿预训练，MiVLA成功整合了人类数据的真实性和模拟数据的多样性，建立了强大的行为先验，显著提升了视觉语言动作模型在跨形态、跨环境下的泛化能力。

Abstract: While leveraging abundant human videos and simulated robot data poses a scalable solution to the scarcity of real-world robot data, the generalization capability of existing vision-language-action models (VLAs) remains limited by mismatches in camera views, visual appearance, and embodiment morphologies. To overcome this limitation, we propose MiVLA, a generalizable VLA empowered by human-robot mutual imitation pre-training, which leverages inherent behavioral similarity between human hands and robotic arms to build a foundation of strong behavioral priors for both human actions and robotic control. Specifically, our method utilizes kinematic rules with left/right hand coordinate systems for bidirectional alignment between human and robot action spaces. Given human or simulated robot demonstrations, MiVLA is trained to forecast behavior trajectories for one embodiment, and imitate behaviors for another one unseen in the demonstration. Based on this mutual imitation, it integrates the behavioral fidelity of real-world human data with the manipulative diversity of simulated robot data into a unified model, thereby enhancing the generalization capability for downstream tasks. Extensive experiments conducted on both simulation and real-world platforms with three robots (ARX, PiPer and LocoMan), demonstrate that MiVLA achieves strong improved generalization capability, outperforming state-of-the-art VLAs (e.g., $\boldsymbolπ_{0}$, $\boldsymbolπ_{0.5}$ and H-RDT) by 25% in simulation, and 14% in real-world robot control tasks.

</details>


### [53] [Load-Based Variable Transmission Mechanism for Robotic Applications](https://arxiv.org/abs/2512.15448)
*Sinan Emre,Victor Barasuol,Matteo Villa,Claudio Semini*

Main category: cs.RO

TL;DR: 提出一种基于负载的可变传动机构，通过预紧弹簧和四连杆机构被动调整传动比，无需额外执行器即可响应外部扭矩需求，实现高达40%的传动比提升。


<details>
  <summary>Details</summary>
Motivation: 现有可变传动系统通常需要额外的执行器进行主动控制，增加了机器人关节驱动系统的复杂性。研究旨在开发轻量、高效、自适应的传动系统，特别适用于需要动态扭矩适应的腿式机器人。

Method: 采用预紧弹簧和四连杆机构设计被动式可变传动机制，当外部扭矩达到预设阈值时，系统自动调整传动比。通过仿真分析评估系统性能。

Result: 系统在达到预设扭矩阈值时能实现高达40%的传动比提升，当施加力超过18N时触发扭矩放大效应，能自主响应变化的负载条件。

Conclusion: LBVT机制为机器人应用提供了一种轻量、高效、自适应的传动解决方案，特别适用于需要动态扭矩适应的腿式机器人，减少了系统复杂性。

Abstract: This paper presents a Load-Based Variable Transmission (LBVT) mechanism designed to enhance robotic actuation by dynamically adjusting the transmission ratio in response to external torque demands. Unlike existing variable transmission systems that require additional actuators for active control, the proposed LBVT mechanism leverages a pre-tensioned spring and a four-bar linkage to passively modify the transmission ratio, thereby reducing the complexity of robot joint actuation systems. The effectiveness of the LBVT mechanism is evaluated through simulation-based analyses. The results confirm that the system achieves up to a 40 percent increase in transmission ratio upon reaching a predefined torque threshold, effectively amplifying joint torque when required without additional actuation. Furthermore, the simulations demonstrate a torque amplification effect triggered when the applied force exceeds 18 N, highlighting the system ability to autonomously respond to varying load conditions. This research contributes to the development of lightweight, efficient, and adaptive transmission systems for robotic applications, particularly in legged robots where dynamic torque adaptation is critical.

</details>


### [54] [OMCL: Open-vocabulary Monte Carlo Localization](https://arxiv.org/abs/2512.15557)
*Evgenii Kruzhkov,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 提出一种基于视觉-语言特征的蒙特卡洛定位方法，通过开放词汇特征实现不同传感器模态间的鲁棒关联，支持自然语言初始化全局定位。


<details>
  <summary>Details</summary>
Motivation: 机器人定位是导航规划的重要前提，当环境地图由不同传感器创建时，需要鲁棒地将机器人测量与地图特征关联。现有方法在处理多模态传感器数据时存在挑战。

Method: 扩展蒙特卡洛定位方法，引入视觉-语言特征。利用开放词汇特征计算给定相机位姿和3D地图（RGB-D图像或点云创建）下视觉观测的似然度，实现不同模态观测与地图元素的关联，支持自然语言描述初始化全局定位。

Result: 在室内场景的Matterport3D和Replica数据集上评估，并在室外场景的SemanticKITTI上展示泛化能力，验证了方法的有效性。

Conclusion: 基于视觉-语言特征的蒙特卡洛定位方法能够鲁棒地处理多模态传感器数据，通过开放词汇特征实现跨模态关联，自然语言描述为全局定位提供了灵活初始化方式。

Abstract: Robust robot localization is an important prerequisite for navigation planning. If the environment map was created from different sensors, robot measurements must be robustly associated with map features. In this work, we extend Monte Carlo Localization using vision-language features. These open-vocabulary features enable to robustly compute the likelihood of visual observations, given a camera pose and a 3D map created from posed RGB-D images or aligned point clouds. The abstract vision-language features enable to associate observations and map elements from different modalities. Global localization can be initialized by natural language descriptions of the objects present in the vicinity of locations. We evaluate our approach using Matterport3D and Replica for indoor scenes and demonstrate generalization on SemanticKITTI for outdoor scenes.

</details>


### [55] [An Open Toolkit for Underwater Field Robotics](https://arxiv.org/abs/2512.15597)
*Giacomo Picardi,Saverio Iacoponi,Matias Carandell,Jorge Aguirregomezcorta,Mrudul Chellapurath,Joaquin del Rio,Marcello Calisti,Iacopo Aguzzi*

Main category: cs.RO

TL;DR: 开源水下机器人关节工具包：包含深度评级关节、控制电子设备和ROS2软件栈，用于水下操作研究，已在40米深度测试验证。


<details>
  <summary>Details</summary>
Motivation: 水下机器人对海洋科学和环境监测日益重要，但水下操作和驱动系统开发受限于高成本、专有设计和缺乏模块化研究硬件。现有开源项目主要集中在车辆构造和控制软件，而缺乏适用于机械臂、抓取器和仿生设备的防水、带反馈的关节驱动系统，导致研究周期长、可重复性差、实验室原型难以转化为现场平台。

Method: 开发了开源的水下机器人关节（URJ）工具包，包括：1）深度评级的水下机器人关节，具备早期泄漏检测功能；2）紧凑的控制和电源管理电子设备；3）基于ROS2的软件栈，用于传感和多模式驱动。所有CAD模型、制造文件、PCB源文件、固件和ROS2包都开源发布，支持本地制造、修改和社区驱动改进。

Result: 工具包经过广泛的实验室测试和多次现场部署，在40米深度下可靠运行，已成功应用于多种场景：3自由度水下机械臂、肌腱驱动软抓取器和欠驱动沉积物采样器。验证了工具包在真实海洋环境中的鲁棒性、多功能性和可重用性。

Conclusion: 通过提供完全开源、经过现场测试的平台，这项工作旨在降低水下操作研究的入门门槛，提高可重复性，并加速水下现场机器人领域的创新。

Abstract: Underwater robotics is becoming increasingly important for marine science, environmental monitoring, and subsea industrial operations, yet the development of underwater manipulation and actuation systems remains restricted by high costs, proprietary designs, and limited access to modular, research-oriented hardware. While open-source initiatives have democratized vehicle construction and control software, a substantial gap persists for joint-actuated systems-particularly those requiring waterproof, feedback-enabled actuation suitable for manipulators, grippers, and bioinspired devices. As a result, many research groups face lengthy development cycles, limited reproducibility, and difficulty transitioning laboratory prototypes to field-ready platforms.
  To address this gap, we introduce an open, cost-effective hardware and software toolkit for underwater manipulation research. The toolkit includes a depth-rated Underwater Robotic Joint (URJ) with early leakage detection, compact control and power management electronics, and a ROS2-based software stack for sensing and multi-mode actuation. All CAD models, fabrication files, PCB sources, firmware, and ROS2 packages are openly released, enabling local manufacturing, modification, and community-driven improvement.
  The toolkit has undergone extensive laboratory testing and multiple field deployments, demonstrating reliable operation up to 40 m depth across diverse applications, including a 3-DoF underwater manipulator, a tendon-driven soft gripper, and an underactuated sediment sampler. These results validate the robustness, versatility, and reusability of the toolkit for real marine environments.
  By providing a fully open, field-tested platform, this work aims to lower the barrier to entry for underwater manipulation research, improve reproducibility, and accelerate innovation in underwater field robotics.

</details>


### [56] [mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs](https://arxiv.org/abs/2512.15692)
*Jonas Pai,Liam Achenbach,Victoriano Montesinos,Benedek Forrai,Oier Mees,Elvis Nava*

Main category: cs.RO

TL;DR: 提出Video-Action Model (VAM)，通过预训练的视频模型捕获语义和视觉动态，结合流匹配动作解码器，显著提升机器人操作任务的样本效率和收敛速度


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型依赖大规模静态网络数据预训练，缺乏物理因果理解，需要大量专家数据补偿，无法有效捕获复杂物理动态和时间依赖

Method: 引入Video-Action Model (VAM)，结合预训练的互联网规模视频模型和基于流匹配的动作解码器，解码器作为逆动力学模型从视频空间动作计划的潜在表示生成低级机器人动作

Result: 在模拟和真实世界机器人操作任务中达到最先进性能，相比传统VLA架构提升10倍样本效率和2倍收敛速度

Conclusion: 利用视频预训练联合捕获语义和视觉动态是更有效的范式，能显著降低数据需求并提升机器人操作性能

Abstract: Prevailing Vision-Language-Action Models (VLAs) for robotic manipulation are built upon vision-language backbones pretrained on large-scale, but disconnected static web data. As a result, despite improved semantic generalization, the policy must implicitly infer complex physical dynamics and temporal dependencies solely from robot trajectories. This reliance creates an unsustainable data burden, necessitating continuous, large-scale expert data collection to compensate for the lack of innate physical understanding. We contend that while vision-language pretraining effectively captures semantic priors, it remains blind to physical causality. A more effective paradigm leverages video to jointly capture semantics and visual dynamics during pretraining, thereby isolating the remaining task of low-level control. To this end, we introduce \model, a novel Video-Action Model (VAM) that pairs a pretrained Internet-scale video model with a flow matching-based action decoder conditioned on its latent representations. The decoder serves as an Inverse Dynamics Model (IDM), generating low-level robot actions from the latent representation of video-space action plans. Our extensive evaluation shows that our approach achieves state-of-the-art performance on simulated and real-world robotic manipulation tasks, improving sample efficiency by 10x and convergence speed by 2x compared to traditional VLA architectures.

</details>
