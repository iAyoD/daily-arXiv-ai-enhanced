<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 78]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks](https://arxiv.org/abs/2510.09786)
*Yuang Lu,Song Wang,Xiao Han,Xuri Zhang,Yucong Wu,Zhicheng He*

Main category: cs.RO

TL;DR: 提出CFG-DP框架，通过集成无分类器指导与条件/无条件模型来增强扩散策略，解决时序任务中的局部最优和重复动作问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略和动作分块变换器方法缺乏时序上下文，导致局部最优陷阱和过多重复动作，难以处理时序顺序任务。

Method: 引入无分类器指导的扩散策略框架，利用时间步输入跟踪任务进度，通过指导因子动态调整动作预测，平衡时序一致性和动作精度。

Result: 在仿人机器人上的真实实验显示高成功率和最小化重复动作，模型能够有效终止动作，不同组件和参数调整对性能有显著影响。

Conclusion: 该框架显著提升了时序机器人任务的确定性控制和执行可靠性。

Abstract: Temporal sequential tasks challenge humanoid robots, as existing Diffusion
Policy (DP) and Action Chunking with Transformers (ACT) methods often lack
temporal context, resulting in local optima traps and excessive repetitive
actions. To address these issues, this paper introduces a Classifier-Free
Guidance-Based Diffusion Policy (CFG-DP), a novel framework to enhance DP by
integrating Classifier-Free Guidance (CFG) with conditional and unconditional
models. Specifically, CFG leverages timestep inputs to track task progression
and ensure precise cycle termination. It dynamically adjusts action predictions
based on task phase, using a guidance factor tuned to balance temporal
coherence and action accuracy. Real-world experiments on a humanoid robot
demonstrate high success rates and minimal repetitive actions. Furthermore, we
assessed the model's ability to terminate actions and examined how different
components and parameter adjustments affect its performance. This framework
significantly enhances deterministic control and execution reliability for
sequential robotic tasks.

</details>


### [2] [Cross-Sensor Touch Generation](https://arxiv.org/abs/2510.09817)
*Samanta Rodriguez,Yiming Dou,Miquel Oller,Andrew Owens,Nima Fazeli*

Main category: cs.RO

TL;DR: 提出了两种跨传感器触觉图像生成方法：Touch2Touch（端到端方法，需要配对数据）和T2D2（通过中间深度表示，无需配对数据），用于解决不同触觉传感器间的模型通用性问题。


<details>
  <summary>Details</summary>
Motivation: 当前触觉传感器形状和尺寸各异，导致大多数模型只能针对特定传感器设计，难以开发通用触觉表示。

Method: 1. Touch2Touch：端到端方法，利用配对数据进行跨传感器图像生成；2. T2D2：构建中间深度表示，无需配对数据即可实现跨传感器触觉生成。

Result: 两种方法都能通过跨传感器触觉生成过程，使特定传感器模型能够在多个传感器上使用，并在手内姿态估计和行为克隆等下游任务中验证了有效性。

Conclusion: 这些模型为传感器转换提供了灵活解决方案，可根据数据可用性和应用需求选择合适方法，成功实现了在一个传感器上训练的模型迁移到另一个传感器。

Abstract: Today's visuo-tactile sensors come in many shapes and sizes, making it
challenging to develop general-purpose tactile representations. This is because
most models are tied to a specific sensor design. To address this challenge, we
propose two approaches to cross-sensor image generation. The first is an
end-to-end method that leverages paired data (Touch2Touch). The second method
builds an intermediate depth representation and does not require paired data
(T2D2: Touch-to-Depth-to-Touch). Both methods enable the use of sensor-specific
models across multiple sensors via the cross-sensor touch generation process.
Together, these models offer flexible solutions for sensor translation,
depending on data availability and application needs. We demonstrate their
effectiveness on downstream tasks such as in-hand pose estimation and behavior
cloning, successfully transferring models trained on one sensor to another.
Project page: https://samantabelen.github.io/cross_sensor_touch_generation.

</details>


### [3] [VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping](https://arxiv.org/abs/2510.09962)
*Yicheng He,Jingwen Yu,Guangcheng Chen,Hong Zhang*

Main category: cs.RO

TL;DR: VG-Mapping是一个基于3D高斯泼溅的在线地图构建系统，专门针对半静态场景，通过混合表示和变化感知密度控制策略来高效更新变化区域。


<details>
  <summary>Details</summary>
Motivation: 在机器人重复遍历同一空间时，及时更新环境变化对地图质量至关重要。现有3DGS方法在准确高效更新变化区域方面存在挑战。

Method: 提出混合表示方法，将3DGS与TSDF体素地图结合来识别变化区域，并采用变化感知密度控制策略来插入或删除高斯基元。

Result: 实验结果表明，该方法在半静态场景中显著提高了渲染质量和地图更新效率。

Conclusion: VG-Mapping为半静态环境下的在线地图构建提供了有效的解决方案，并发布了相关数据集和代码。

Abstract: Maintaining an up-to-date map that accurately reflects recent changes in the
environment is crucial, especially for robots that repeatedly traverse the same
space. Failing to promptly update the changed regions can degrade map quality,
resulting in poor localization, inefficient operations, and even lost robots.
3D Gaussian Splatting (3DGS) has recently seen widespread adoption in online
map reconstruction due to its dense, differentiable, and photorealistic
properties, yet accurately and efficiently updating the regions of change
remains a challenge. In this paper, we propose VG-Mapping, a novel online
3DGS-based mapping system tailored for such semi-static scenes. Our approach
introduces a hybrid representation that augments 3DGS with a TSDF-based voxel
map to efficiently identify changed regions in a scene, along with a
variation-aware density control strategy that inserts or deletes Gaussian
primitives in regions undergoing change. Furthermore, to address the absence of
public benchmarks for this task, we construct a RGB-D dataset comprising both
synthetic and real-world semi-static environments. Experimental results
demonstrate that our method substantially improves the rendering quality and
map update efficiency in semi-static scenes. The code and dataset are available
at https://github.com/heyicheng-never/VG-Mapping.

</details>


### [4] [LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots](https://arxiv.org/abs/2510.09963)
*Chaoran Wang,Jingyuan Sun,Yanhui Zhang,Mingyu Zhang,Changju Wu*

Main category: cs.RO

TL;DR: 提出基于大语言模型的自动行为树构建框架，用于异构多机器人系统在动态环境中的自适应协作


<details>
  <summary>Details</summary>
Motivation: 传统机器人功能固定，无法有效应对任务失败或环境变化。需要结合LLMs的推理能力和BTs的模块化特性，提高多机器人系统的适应性和鲁棒性

Method: 框架包含四个互联模块：任务初始化、任务分配、BT更新和失败节点检测。机器人执行时tick行为树，遇到失败节点时可本地扩展树或调用虚拟协调器重新分配子任务

Result: 在3个模拟场景60个任务和真实咖啡厅环境中验证，方法在任务成功率、鲁棒性和可扩展性方面均优于基线方法

Conclusion: 该框架能有效支持异构机器人在复杂场景中的长期协作执行

Abstract: We introduce a novel framework for automatic behavior tree (BT) construction
in heterogeneous multi-robot systems, designed to address the challenges of
adaptability and robustness in dynamic environments. Traditional robots are
limited by fixed functional attributes and cannot efficiently reconfigure their
strategies in response to task failures or environmental changes. To overcome
this limitation, we leverage large language models (LLMs) to generate and
extend BTs dynamically, combining the reasoning and generalization power of
LLMs with the modularity and recovery capability of BTs. The proposed framework
consists of four interconnected modules task initialization, task assignment,
BT update, and failure node detection which operate in a closed loop. Robots
tick their BTs during execution, and upon encountering a failure node, they can
either extend the tree locally or invoke a centralized virtual coordinator
(Alex) to reassign subtasks and synchronize BTs across peers. This design
enables long-term cooperative execution in heterogeneous teams. We validate the
framework on 60 tasks across three simulated scenarios and in a real-world cafe
environment with a robotic arm and a wheeled-legged robot. Results show that
our method consistently outperforms baseline approaches in task success rate,
robustness, and scalability, demonstrating its effectiveness for multi-robot
collaboration in complex scenarios.

</details>


### [5] [FORM: Fixed-Lag Odometry with Reparative Mapping utilizing Rotating LiDAR Sensors](https://arxiv.org/abs/2510.09966)
*Easton R. Potokar,Taylor Pool,Daniel McGann,Michael Kaess*

Main category: cs.RO

TL;DR: 提出了FORM方法，一种LiDAR里程计方法，通过密集连接的因子图进行平滑处理，同时使用单一迭代地图进行匹配，实现实时性能和局部地图的主动校正。


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR里程计方法大多基于子地图，会将姿态估计误差传播到固定子地图中，导致轨迹抖动和未来配准性能下降。需要一种既能实时运行又能主动校正局部地图的方法。

Method: 使用密集连接的因子图进行平滑处理，同时采用单一迭代地图进行匹配，允许在姿态估计进一步细化时主动校正局部地图。

Result: 在多种数据集上的评估显示，FORM方法相比现有最先进的LiDAR里程计方法具有鲁棒性、准确性、实时性，并能提供平滑的轨迹估计。

Conclusion: FORM方法通过结合因子图平滑和单一迭代地图，成功解决了传统子地图方法的误差传播问题，实现了实时性能下的高质量LiDAR里程计估计。

Abstract: Light Detection and Ranging (LiDAR) sensors have become a de-facto sensor for
many robot state estimation tasks, spurring development of many LiDAR Odometry
(LO) methods in recent years. While some smoothing-based LO methods have been
proposed, most require matching against multiple scans, resulting in
sub-real-time performance. Due to this, most prior works estimate a single
state at a time and are ``submap''-based. This architecture propagates any
error in pose estimation to the fixed submap and can cause jittery trajectories
and degrade future registrations. We propose Fixed-Lag Odometry with Reparative
Mapping (FORM), a LO method that performs smoothing over a densely connected
factor graph while utilizing a single iterative map for matching. This allows
for both real-time performance and active correction of the local map as pose
estimates are further refined. We evaluate on a wide variety of datasets to
show that FORM is robust, accurate, real-time, and provides smooth trajectory
estimates when compared to prior state-of-the-art LO methods.

</details>


### [6] [ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots](https://arxiv.org/abs/2510.09980)
*Jingyuan Sun,Hongyu Ji,Zihan Qu,Chaoran Wang,Mingyu Zhang*

Main category: cs.RO

TL;DR: 提出了ATRos强化学习框架，用于轮腿机器人的混合行走-驱动运动，无需预定义步态模式，通过协调轮子和腿部运动提高地形适应性和能量效率。


<details>
  <summary>Details</summary>
Motivation: 轮腿机器人结合了腿式运动的敏捷性和轮式运动的高效性，但混合运动的全身体控制仍然具有挑战性。

Method: 使用强化学习技术构建预测策略网络，从本体感觉信息估计外部环境状态，然后通过演员-评论家网络生成最优关节命令。

Result: 在平坦地面、楼梯和草地等多种地形上的仿真和真实实验验证了框架的可行性，在未见地形上表现出鲁棒性能。

Conclusion: 该混合运动框架展示了良好的泛化能力，能够适应各种未知地形。

Abstract: Hybrid locomotion of wheeled-legged robots has recently attracted increasing
attention due to their advantages of combining the agility of legged locomotion
and the efficiency of wheeled motion. But along with expanded performance, the
whole-body control of wheeled-legged robots remains challenging for hybrid
locomotion. In this paper, we present ATRos, a reinforcement learning
(RL)-based hybrid locomotion framework to achieve hybrid walking-driving
motions on the wheeled-legged robot. Without giving predefined gait patterns,
our planner aims to intelligently coordinate simultaneous wheel and leg
movements, thereby achieving improved terrain adaptability and improved energy
efficiency. Based on RL techniques, our approach constructs a prediction policy
network that could estimate external environmental states from proprioceptive
sensory information, and the outputs are then fed into an actor critic network
to produce optimal joint commands. The feasibility of the proposed framework is
validated through both simulations and real-world experiments across diverse
terrains, including flat ground, stairs, and grassy surfaces. The hybrid
locomotion framework shows robust performance over various unseen terrains,
highlighting its generalization capability.

</details>


### [7] [Hybrid Robotic Meta-gripper for Tomato Harvesting: Analysis of Auxetic Structures with Lattice Orientation Variations](https://arxiv.org/abs/2510.10016)
*Shahid Ansari,Vivek Gupta,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 开发了一种用于番茄采摘的混合夹持器，结合刚性外框和软性拉胀内部晶格结构，研究拉胀晶格取向对抓取性能的影响。


<details>
  <summary>Details</summary>
Motivation: 农业自动化需求增长，水果蔬菜处理仍依赖人工导致效率低下和采后损失，软体机器人技术为解决选择性采摘问题提供了可行方案。

Method: 采用六指3D笼式效应设计，结合实验验证、2D数字图像相关技术和非线性有限元分析，评估0°、30°、45°、60°四种拉胀晶格取向的抓取性能。

Result: 晶格取向显著影响夹持器的柔顺性、接触力和能量效率，不同配置各有优势，为优化机器人夹持器性能提供了新思路。

Conclusion: 通过定制拉胀几何结构优化软硬混合夹持器性能，为精准农业自动化策略提供新见解，同时减少作物损伤。

Abstract: The agricultural sector is rapidly evolving to meet growing global food
demands, yet tasks like fruit and vegetable handling remain labor-intensive,
causing inefficiencies and post-harvest losses. Automation, particularly
selective harvesting, offers a viable solution, with soft robotics emerging as
a key enabler. This study introduces a novel hybrid gripper for tomato
harvesting, incorporating a rigid outer frame with a soft auxetic internal
lattice. The six-finger, 3D caging-effect design enables gentle yet secure
grasping in unstructured environments. Uniquely, the work investigates the
effect of auxetic lattice orientation on grasping conformability, combining
experimental validation with 2D Digital Image Correlation (DIC) and nonlinear
finite element analysis (FEA). Auxetic configurations with unit cell
inclinations of 0 deg, 30 deg, 45 deg, and 60 deg are evaluated, and their
grasping forces, deformation responses, and motor torque requirements are
systematically compared. Results demonstrate that lattice orientation strongly
influences compliance, contact forces, and energy efficiency, with distinct
advantages across configurations. This comparative framework highlights the
novelty of tailoring auxetic geometries to optimize robotic gripper
performance. The findings provide new insights into soft-rigid hybrid gripper
design, advancing automation strategies for precision agriculture while
minimizing crop damage.

</details>


### [8] [LOMORO: Long-term Monitoring of Dynamic Targets with Minimum Robotic Fleet under Resource Constraints](https://arxiv.org/abs/2510.10046)
*Mingke Lu,Shuaikang Wang,Meng Guo*

Main category: cs.RO

TL;DR: LOMORO是一个在线多机器人协作目标监控系统，通过资源感知的任务协调和在线适应算法，确保所有目标的监控间隔有明确上界，所有机器人的资源水平有下界，同时最小化活跃机器人数量。


<details>
  <summary>Details</summary>
Motivation: 长期监控动态目标对人类操作员来说很繁琐，对单个机器人不可行。现有方法要么部署所有可用机器人而不最小化机群规模，要么忽视电池和内存等资源约束。

Method: 包含三个核心组件：(I)在资源和监控间隔约束下建模多机器人任务分配问题；(II)资源感知任务协调算法，通过Martin算法在高层动态目标分配和低层多目标路由间迭代；(III)针对不可预测目标行为和机器人故障的在线适应算法。

Result: 通过大规模仿真验证，在不同道路网络、机器人速度、充电速率和监控间隔下，与多个基线方法相比表现出色。

Conclusion: LOMORO系统能够有效协调多机器人协作监控动态目标，确保监控质量和资源安全，同时优化机群规模。

Abstract: Long-term monitoring of numerous dynamic targets can be tedious for a human
operator and infeasible for a single robot, e.g., to monitor wild flocks,
detect intruders, search and rescue. Fleets of autonomous robots can be
effective by acting collaboratively and concurrently. However, the online
coordination is challenging due to the unknown behaviors of the targets and the
limited perception of each robot. Existing work often deploys all robots
available without minimizing the fleet size, or neglects the constraints on
their resources such as battery and memory. This work proposes an online
coordination scheme called LOMORO for collaborative target monitoring, path
routing and resource charging. It includes three core components: (I) the
modeling of multi-robot task assignment problem under the constraints on
resources and monitoring intervals; (II) the resource-aware task coordination
algorithm iterates between the high-level assignment of dynamic targets and the
low-level multi-objective routing via the Martin's algorithm; (III) the online
adaptation algorithm in case of unpredictable target behaviors and robot
failures. It ensures the explicitly upper-bounded monitoring intervals for all
targets and the lower-bounded resource levels for all robots, while minimizing
the average number of active robots. The proposed methods are validated
extensively via large-scale simulations against several baselines, under
different road networks, robot velocities, charging rates and monitoring
intervals.

</details>


### [9] [Ionospheric and Plasmaspheric Delay Characterization for Lunar Terrestrial GNSS Receivers with Global Core Plasma Model](https://arxiv.org/abs/2510.10059)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: 该论文分析了月球GNSS导航中的电离层和等离子体层延迟误差，使用GCPM模型和光线追踪算法模拟不同条件下的延迟情况，发现延迟可达100米以上，为月球导航算法设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 虽然月球GNSS导航已被验证，但未建模的电离层和等离子体层延迟仍是主要误差源，特别是在独特信号几何和长传播路径下。

Method: 使用全球核心等离子体模型(GCPM)和低成本光线追踪算法，模拟GNSS信号在月球轨道和南极接收时的群延迟和路径弯曲延迟。

Result: 平均群延迟约为1米，但在高太阳活动期间低高度射线路径可超过100米；弯曲延迟较小但对低高度路径不可忽略。

Conclusion: 研究结果为利用地面GNSS信号的鲁棒定位和定时算法设计提供了重要信息。

Abstract: Recent advancements in lunar positioning, navigation, and timing (PNT) have
demonstrated that terrestrial GNSS signals, including weak sidelobe
transmissions, can be exploited for lunar spacecraft positioning and timing.
While GNSS-based navigation at the Moon has been validated recently, unmodeled
ionospheric and plasmaspheric delays remain a significant error source,
particularly given the unique signal geometry and extended propagation paths.
This paper characterizes these delays using the Global Core Plasma Model (GCPM)
and a custom low-cost ray-tracing algorithm that iteratively solves for bent
signal paths. We simulate first-, second-, and third-order group delays, as
well as excess path length from ray bending, for GNSS signals received at both
lunar orbit and the lunar south pole under varying solar and geomagnetic
conditions. Results show that mean group delays are typically on the order of 1
m, but can exceed 100 m for low-altitude ray paths during high solar activity,
while bending delays are generally smaller but non-negligible for low-altitude
ray paths. We also quantify the influence of signal frequency, geomagnetic
$K_p$ index, and solar R12 index. These findings inform the design of robust
positioning and timing algorithms that utilize terrestrial GNSS signals.

</details>


### [10] [Beyond ADE and FDE: A Comprehensive Evaluation Framework for Safety-Critical Prediction in Multi-Agent Autonomous Driving Scenarios](https://arxiv.org/abs/2510.10086)
*Feifei Liu,Haozhe Wang,Zejun Wei,Qirong Lu,Yiyang Wen,Xiaoyu Tang,Jingyan Jiang,Zhijian He*

Main category: cs.RO

TL;DR: 提出新的自动驾驶预测模型测试框架，通过场景结构、地图上下文、智能体密度和空间分布等维度评估预测性能，揭示传统指标无法发现的模型脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶预测模型评估主要依赖ADE和FDE等简单指标，无法捕捉复杂交互和安全关键场景中的细微行为差异，缺乏对多智能体交互鲁棒性的系统测试。

Method: 开发新型测试框架，基于多样化的场景结构、地图上下文、智能体密度和空间分布来评估预测性能，量化智能体邻近度对轨迹预测的影响。

Result: 通过实证分析发现当前最先进预测模型的关键脆弱性，识别出传统指标无法暴露的场景特定失败案例，证明了智能体邻近度对预测性能的差异化影响。

Conclusion: 该框架为严格的、安全驱动的预测验证奠定了基础，有助于识别易失败的极端案例，推动开发鲁棒且可认证的自动驾驶预测系统。

Abstract: Current evaluation methods for autonomous driving prediction models rely
heavily on simplistic metrics such as Average Displacement Error (ADE) and
Final Displacement Error (FDE). While these metrics offer basic performance
assessments, they fail to capture the nuanced behavior of prediction modules
under complex, interactive, and safety-critical driving scenarios. For
instance, existing benchmarks do not distinguish the influence of nearby versus
distant agents, nor systematically test model robustness across varying
multi-agent interactions. This paper addresses this critical gap by proposing a
novel testing framework that evaluates prediction performance under diverse
scene structures, saying, map context, agent density and spatial distribution.
Through extensive empirical analysis, we quantify the differential impact of
agent proximity on target trajectory prediction and identify scenario-specific
failure cases that are not exposed by traditional metrics. Our findings
highlight key vulnerabilities in current state-of-the-art prediction models and
demonstrate the importance of scenario-aware evaluation. The proposed framework
lays the groundwork for rigorous, safety-driven prediction validation,
contributing significantly to the identification of failure-prone corner cases
and the development of robust, certifiable prediction systems for autonomous
vehicles.

</details>


### [11] [Ctrl-World: A Controllable Generative World Model for Robot Manipulation](https://arxiv.org/abs/2510.10125)
*Yanjiang Guo,Lucy Xiaoyang Shi,Jianyu Chen,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出了一个可控多视角世界模型，用于评估和改进通用机器人策略的指令跟随能力，无需真实世界部署即可准确评估策略性能，并通过想象空间合成成功轨迹来改进策略。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略评估和改进需要大量真实世界部署和专家标注数据，过程缓慢、成本高且难以扩展。世界模型提供了一种可扩展的替代方案，但现有方法无法处理通用策略的多步骤交互需求。

Method: 开发了可控多视角世界模型，采用位姿条件记忆检索机制保持长时一致性，通过帧级动作条件实现精确动作控制。在DROID数据集（95k轨迹，564场景）上训练。

Result: 模型能在新场景和新相机布局下生成时空一致的轨迹超过20秒，无需真实机器人部署即可准确评估策略性能，通过监督微调可将策略成功率提高44.7%。

Conclusion: 该方法为通用机器人策略的评估和改进提供了一种高效、可扩展的解决方案，显著减少了真实世界部署的需求。

Abstract: Generalist robot policies can now perform a wide range of manipulation
skills, but evaluating and improving their ability with unfamiliar objects and
instructions remains a significant challenge. Rigorous evaluation requires a
large number of real-world rollouts, while systematic improvement demands
additional corrective data with expert labels. Both of these processes are
slow, costly, and difficult to scale. World models offer a promising, scalable
alternative by enabling policies to rollout within imagination space. However,
a key challenge is building a controllable world model that can handle
multi-step interactions with generalist robot policies. This requires a world
model compatible with modern generalist policies by supporting multi-view
prediction, fine-grained action control, and consistent long-horizon
interactions, which is not achieved by previous works. In this paper, we make a
step forward by introducing a controllable multi-view world model that can be
used to evaluate and improve the instruction-following ability of generalist
robot policies. Our model maintains long-horizon consistency with a
pose-conditioned memory retrieval mechanism and achieves precise action control
through frame-level action conditioning. Trained on the DROID dataset (95k
trajectories, 564 scenes), our model generates spatially and temporally
consistent trajectories under novel scenarios and new camera placements for
over 20 seconds. We show that our method can accurately rank policy performance
without real-world robot rollouts. Moreover, by synthesizing successful
trajectories in imagination and using them for supervised fine-tuning, our
approach can improve policy success by 44.7\%.

</details>


### [12] [CompassNav: Steering From Path Imitation To Decision Understanding In Navigation](https://arxiv.org/abs/2510.10154)
*LinFeng Li,Jian Zhao,Yuan Xie,Xin Tan,Xuelong Li*

Main category: cs.RO

TL;DR: 提出从路径模仿转向决策理解的新范式，通过Compass-Data-22k数据集和gap-aware混合奖励函数，训练智能体发展内部"指南针"来评估所有可能移动的相对质量，在导航基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前大型视觉语言模型的导航训练主要依赖模仿专家轨迹，这种方法将复杂导航任务简化为单一正确路径的序列复制，限制了智能体的探索和泛化能力。

Method: 1) 引入Compass-Data-22k数据集，其RFT子集通过A*测地距离标注所有可行动作；2) 设计gap-aware混合奖励函数，根据决策确定性动态调整反馈；3) 采用SFT-then-RFT训练流程。

Result: 7B参数的CompassNav智能体在目标导航基准测试中达到新的最先进水平，超越了更大的专有模型，并在物理机器人上实现了鲁棒的现实世界目标导航。

Conclusion: 从路径模仿转向决策理解的范式转变使智能体能够发展内部"指南针"，通过评估所有可能移动的相对质量来不断感知目标方向，从而实现更好的导航性能。

Abstract: The dominant paradigm for training Large Vision-Language Models (LVLMs) in
navigation relies on imitating expert trajectories. This approach reduces the
complex navigation task to a sequence-to-sequence replication of a single
correct path, fundamentally limiting the agent's ability to explore and
generalize. In this work, we argue for and introduce a new paradigm: a shift
from Path Imitation to Decision Understanding. The goal of this paradigm is to
build agents that do not just follow, but truly understand how to navigate. We
materialize this through two core contributions: first, we introduce
Compass-Data-22k, a novel 22k-trajectory dataset.Its Reinforcement Fine-Tuning
(RFT) subset provides a panoramic view of the decision landscape by annotating
all feasible actions with A* geodesic distances. Second, we design a novel
gap-aware hybrid reward function that dynamically adapts its feedback to
decision certainty, shifting between decisive signals for optimal actions and
nuanced scores to encourage exploration. Integrated into an SFT-then-RFT
recipe, our CompassNav agent is trained not to memorize static routes, but to
develop an internal ``compass'' that constantly intuits the direction to the
goal by evaluating the relative quality of all possible moves. This approach
enables our 7B agent to set a new state-of-the-art on Goal navigation
benchmarks, outperforming even larger proprietary models, and achieve robust
real-world goal navigation on a physical robot.

</details>


### [13] [Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback](https://arxiv.org/abs/2510.10181)
*Shaokai Wu,Yanbiao Ji,Qiuchang Li,Zhiyi Zhang,Qichen He,Wenyuan Xie,Guodong Zhang,Bayram Bayramli,Yue Ding,Hongtao Lu*

Main category: cs.RO

TL;DR: Dejavu框架通过经验反馈网络和记忆检索机制，让已部署的具身智能体能够在固定权重的情况下从执行经验中学习，提升任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决具身智能体在真实环境部署后无法获取新知识来提升任务性能的根本限制。

Method: 使用经验反馈网络(EFN)和增强的冻结视觉-语言-动作策略，通过检索执行记忆，采用基于语义相似度奖励的强化学习来确保预测动作与过去成功行为一致。

Result: 在多种具身任务实验中，EFN显著提高了适应性、鲁棒性和成功率，优于冻结基线方法。

Conclusion: 为具身智能体在部署后持续优化行为提供了一条有前景的路径。

Abstract: Embodied agents face a fundamental limitation: once deployed in real-world
environments to perform specific tasks, they are unable to acquire new useful
knowledge to enhance task performance. In this paper, we propose a general
post-deployment learning framework called Dejavu, which employs an Experience
Feedback Network (EFN) and augments the frozen Vision-Language-Action (VLA)
policy with retrieved execution memories. EFN automatically identifies
contextually successful prior action experiences and conditions action
prediction on this retrieved guidance. We adopt reinforcement learning with
semantic similarity rewards on EFN to ensure that the predicted actions align
with past successful behaviors under current observations. During deployment,
EFN continually enriches its memory with new trajectories, enabling the agent
to exhibit "learning from experience" despite fixed weights. Experiments across
diverse embodied tasks show that EFN significantly improves adaptability,
robustness, and success rates over frozen baselines. These results highlight a
promising path toward embodied agents that continually refine their behavior
after deployment.

</details>


### [14] [It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots](https://arxiv.org/abs/2510.10206)
*Zuhong Liu,Junhao Ge,Minhao Xiong,Jiahao Gu,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: Harmanoid是一个双人形机器人运动模仿框架，专门解决多机器人交互中的协调问题，通过接触感知的运动重定向和交互驱动的运动控制器，实现物理真实的交互动作模仿。


<details>
  <summary>Details</summary>
Motivation: 现有单人形机器人方法存在孤立问题，忽略了代理间动态交互，导致接触错位、相互穿透和不真实的运动。需要开发能够处理多人形机器人协调交互的框架。

Method: 包含两个关键组件：(1) 接触感知的运动重定向，通过将SMPL接触与机器人顶点对齐来恢复身体间协调；(2) 交互驱动的运动控制器，利用交互特定奖励来强制执行协调的关键点和物理合理的接触。

Result: 实验表明Harmanoid显著改善了交互运动模仿效果，超越了在类似场景中大多失败的现有单人形机器人框架。

Conclusion: 通过显式建模代理间接触和交互感知动态，Harmanoid能够捕捉单人形框架固有忽略的人形机器人之间的耦合行为，实现了更真实的多人形机器人交互。

Abstract: The true promise of humanoid robotics lies beyond single-agent autonomy: two
or more humanoids must engage in physically grounded, socially meaningful
whole-body interactions that echo the richness of human social interaction.
However, single-humanoid methods suffer from the isolation issue, ignoring
inter-agent dynamics and causing misaligned contacts, interpenetrations, and
unrealistic motions. To address this, we present Harmanoid , a dual-humanoid
motion imitation framework that transfers interacting human motions to two
robots while preserving both kinematic fidelity and physical realism. Harmanoid
comprises two key components: (i) contact-aware motion retargeting, which
restores inter-body coordination by aligning SMPL contacts with robot vertices,
and (ii) interaction-driven motion controller, which leverages
interaction-specific rewards to enforce coordinated keypoints and physically
plausible contacts. By explicitly modeling inter-agent contacts and
interaction-aware dynamics, Harmanoid captures the coupled behaviors between
humanoids that single-humanoid frameworks inherently overlook. Experiments
demonstrate that Harmanoid significantly improves interactive motion imitation,
surpassing existing single-humanoid frameworks that largely fail in such
scenarios.

</details>


### [15] [UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction](https://arxiv.org/abs/2510.10217)
*Hyogo Hiruma,Hiroshi Ito,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 提出UF-RNN模型，通过前瞻模块进行内部多轨迹模拟，在不确定性环境下实现鲁棒适应，在开门任务中相比传统随机RNN基线获得更高成功率


<details>
  <summary>Details</summary>
Motivation: 解决机器人在不确定状态环境（如模糊物体属性或不可预测交互）中操作的问题，传统模仿学习方法依赖成功示例而忽略不确定性最显著时的失败场景

Method: UF-RNN结合标准时间序列预测与主动"前瞻"模块，该模块执行多个未来轨迹的内部模拟并优化隐藏状态以最小化预测方差，使模型能在高不确定性下有选择地探索动作

Result: 在仿真和真实机器人开门任务中验证，即使没有显式失败演示，模型通过利用潜在空间中的自诱导混沌动力学表现出鲁棒适应性，前瞻模块引导的混沌特性在环境模糊时激发探索行为

Conclusion: 将不确定性驱动的前瞻整合到模仿学习流程中能显著增强机器人处理不可预测现实条件的能力

Abstract: Training robots to operate effectively in environments with uncertain states,
such as ambiguous object properties or unpredictable interactions, remains a
longstanding challenge in robotics. Imitation learning methods typically rely
on successful examples and often neglect failure scenarios where uncertainty is
most pronounced. To address this limitation, we propose the Uncertainty-driven
Foresight Recurrent Neural Network (UF-RNN), a model that combines standard
time-series prediction with an active "Foresight" module. This module performs
internal simulations of multiple future trajectories and refines the hidden
state to minimize predicted variance, enabling the model to selectively explore
actions under high uncertainty. We evaluate UF-RNN on a door-opening task in
both simulation and a real-robot setting, demonstrating that, despite the
absence of explicit failure demonstrations, the model exhibits robust
adaptation by leveraging self-induced chaotic dynamics in its latent space.
When guided by the Foresight module, these chaotic properties stimulate
exploratory behaviors precisely when the environment is ambiguous, yielding
improved success rates compared to conventional stochastic RNN baselines. These
findings suggest that integrating uncertainty-driven foresight into imitation
learning pipelines can significantly enhance a robot's ability to handle
unpredictable real-world conditions.

</details>


### [16] [A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots](https://arxiv.org/abs/2510.10221)
*Hyogo Hiruma,Hiroshi Ito,Hiroki Mori,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 该研究提出A^3 RNN注意力模型，通过双向架构整合自上而下和自下而上的视觉注意力机制，探索在机器人学习中两者如何相互适应形成结构化注意力行为。


<details>
  <summary>Details</summary>
Motivation: 理解结构化、类人的注意力行为如何通过自上而下和自下而上机制的相互适应随时间发展形成，探索感知与内部预测交互在注意力自组织中的重要性。

Method: 提出A^3 RNN注意力模型，采用双向注意力架构整合预测性TD信号和显著性BU线索，在机器人操作任务中使用模仿学习进行评估。

Result: 注意力行为在训练过程中从显著性驱动的探索演变为预测驱动的定向。BU注意力最初引导TD过程，随着学习进展，TD注意力稳定并重塑显著性感知。模型展现出比基线更连贯和可解释的注意力模式。

Conclusion: 发展机制有助于稳健注意力的形成，注意力轨迹反映了认知科学和自由能框架的原则，强调了感知与内部预测交互在自组织注意力中的重要性。

Abstract: This study investigates the developmental interaction between top-down (TD)
and bottom-up (BU) visual attention in robotic learning. Our goal is to
understand how structured, human-like attentional behavior emerges through the
mutual adaptation of TD and BU mechanisms over time. To this end, we propose a
novel attention model $A^3 RNN$ that integrates predictive TD signals and
saliency-based BU cues through a bi-directional attention architecture.
  We evaluate our model in robotic manipulation tasks using imitation learning.
Experimental results show that attention behaviors evolve throughout training,
from saliency-driven exploration to prediction-driven direction. Initially, BU
attention highlights visually salient regions, which guide TD processes, while
as learning progresses, TD attention stabilizes and begins to reshape what is
perceived as salient. This trajectory reflects principles from cognitive
science and the free-energy framework, suggesting the importance of
self-organizing attention through interaction between perception and internal
prediction. Although not explicitly optimized for stability, our model exhibits
more coherent and interpretable attention patterns than baselines, supporting
the idea that developmental mechanisms contribute to robust attention
formation.

</details>


### [17] [Integration of the TIAGo Robot into Isaac Sim with Mecanum Drive Modeling and Learned S-Curve Velocity Profiles](https://arxiv.org/abs/2510.10273)
*Vincent Schoenbach,Marvin Wiedemann,Raphael Memmesheimer,Malte Mosbach,Sven Behnke*

Main category: cs.RO

TL;DR: 本文在Isaac Sim中引入了PAL Robotics TIAGo++ Omni机器人的仿真模型，重点校准了其全向驱动动力学，并提供了两种控制模型：物理精确模型和轻量级速度模型。


<details>
  <summary>Details</summary>
Motivation: TIAGo++ Omni是一款多功能移动机械臂，具有全向移动能力，但此前在Isaac Sim中没有可用模型。为了支持基于学习的方法研究，需要提供精确的仿真模型。

Method: 开发了两种全向驱动控制模型：物理精确模型和轻量级速度模型，并引入了基于学习的校准方法来近似真实机器人的S形速度曲线。

Result: 成功在Isaac Sim中集成了TIAGo++ Omni机器人模型，能够准确模拟真实机器人的行为，特别是全向驱动动力学。

Conclusion: 该仿真模型使研究人员能够在多样化环境中进行实验和执行高效的基于学习的控制，代码已在GitHub上公开提供。

Abstract: Efficient physics simulation has significantly accelerated research progress
in robotics applications such as grasping and assembly. The advent of
GPU-accelerated simulation frameworks like Isaac Sim has particularly empowered
learning-based methods, enabling them to tackle increasingly complex tasks. The
PAL Robotics TIAGo++ Omni is a versatile mobile manipulator equipped with a
mecanum-wheeled base, allowing omnidirectional movement and a wide range of
task capabilities. However, until now, no model of the robot has been available
in Isaac Sim. In this paper, we introduce such a model, calibrated to
approximate the behavior of the real robot, with a focus on its omnidirectional
drive dynamics. We present two control models for the omnidirectional drive: a
physically accurate model that replicates real-world wheel dynamics and a
lightweight velocity-based model optimized for learning-based applications.
With these models, we introduce a learning-based calibration approach to
approximate the real robot's S-shaped velocity profile using minimal trajectory
data recordings. This simulation should allow researchers to experiment with
the robot and perform efficient learning-based control in diverse environments.
We provide the integration publicly at https://github.com/AIS-Bonn/tiago_isaac.

</details>


### [18] [X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model](https://arxiv.org/abs/2510.10274)
*Jinliang Zheng,Jianxiong Li,Zhihao Wang,Dongxiu Liu,Xirui Kang,Yuchun Feng,Yinan Zheng,Jiayin Zou,Yilun Chen,Jia Zeng,Ya-Qin Zhang,Jiangmiao Pang,Jingjing Liu,Tai Wang,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 提出X-VLA模型，通过软提示方法在异构机器人数据集上进行训练，实现跨具身智能，在6个仿真和3个真实机器人上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决通用视觉-语言-动作模型在多样化机器人平台上有效训练的问题，利用异构机器人数据源的丰富性。

Method: 采用软提示方法，为每个数据源引入可学习的嵌入作为具身特定提示，基于流匹配的VLA架构，仅使用软提示的标准Transformer编码器。

Result: 0.9B参数的X-VLA在6个仿真和3个真实机器人上同时实现SOTA性能，在灵活性、跨具身适应等方面表现优异。

Conclusion: 软提示方法能有效利用跨具身特征，X-VLA架构兼具可扩展性和简洁性，为通用机器人学习提供有效解决方案。

Abstract: Successful generalist Vision-Language-Action (VLA) models rely on effective
training across diverse robotic platforms with large-scale, cross-embodiment,
heterogeneous datasets. To facilitate and leverage the heterogeneity in rich,
diverse robotic data sources, we propose a novel Soft Prompt approach with
minimally added parameters, by infusing prompt learning concepts into
cross-embodiment robot learning and introducing separate sets of learnable
embeddings for each distinct data source. These embeddings serve as
embodiment-specific prompts, which in unity empower VLA models with effective
exploitation of varying cross-embodiment features. Our new X-VLA, a neat
flow-matching-based VLA architecture, relies exclusively on soft-prompted
standard Transformer encoders, enjoying both scalability and simplicity.
Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B
instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep
of benchmarks, demonstrating superior results on a wide axes of capabilities,
from flexible dexterity to quick adaptation across embodiments, environments,
and tasks. Website: https://thu-air-dream.github.io/X-VLA/

</details>


### [19] [Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework](https://arxiv.org/abs/2510.10332)
*Kohio Deflesselle,Mélodie Daniel,Aly Magassouba,Miguel Aranda,Olivier Ly*

Main category: cs.RO

TL;DR: 基于Soft Actor-Critic的深度强化学习框架，用于双阿克曼转向移动机器人的安全精确操控，在复杂环境中实现高效避障导航。


<details>
  <summary>Details</summary>
Motivation: 双阿克曼转向移动机器人面临强运动学约束，传统规划器在复杂环境中表现脆弱，需要更鲁棒的导航方法。

Method: 采用Soft Actor-Critic强化学习框架，结合Hindsight Experience Replay和CrossQ覆盖技术，鼓励高效机动同时避免障碍物。

Result: 在重型四轮转向漫游车仿真中，学习策略能鲁棒地达到97%的目标位置，同时成功避开障碍物。

Conclusion: 该框架不依赖手工轨迹或专家演示，为复杂运动学约束的机器人提供了有效的自主导航解决方案。

Abstract: We present a deep reinforcement learning framework based on Soft Actor-Critic
(SAC) for safe and precise maneuvering of double-Ackermann-steering mobile
robots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as
differential-drive robots, DASMRs face strong kinematic constraints that make
classical planners brittle in cluttered environments. Our framework leverages
the Hindsight Experience Replay (HER) and the CrossQ overlay to encourage
maneuvering efficiency while avoiding obstacles. Simulation results with a
heavy four-wheel-steering rover show that the learned policy can robustly reach
up to 97% of target positions while avoiding obstacles. Our framework does not
rely on handcrafted trajectories or expert demonstrations.

</details>


### [20] [Rise of the Robochemist](https://arxiv.org/abs/2510.10337)
*Jihong Zhu,Kefeng Huang,Jonathon Pipe,Chris Horbaczewsky,Andy Tyrrell,Ian J. S. Fairlamb*

Main category: cs.RO

TL;DR: 本文提出了"robochemist"（机器人化学家）概念，将机器人技术和人工智能整合到化学研究中，实现实验设计、执行和分析的自主化，作为人类化学家的补充合作伙伴。


<details>
  <summary>Details</summary>
Motivation: 传统化学研究依赖人工操作，过程耗时且效率有限。通过引入机器人技术和AI，旨在提高实验的适应性、可重复性和安全性，加速化学发现和创新。

Method: 整合移动机械臂、先进感知技术、远程操作和数据驱动协议，构建能够自主执行化学实验的机器人系统。

Result: robochemist能够更高效地探索化学空间，在药物研发、材料科学和可持续制造等领域加速创新。

Conclusion: 化学的未来在于人类直觉与机器人精度、AI洞察力的共生合作关系，robochemist将作为补充伙伴而非完全替代人类化学家。

Abstract: Chemistry, a long-standing discipline, has historically relied on manual and
often time-consuming processes. While some automation exists, the field is now
on the cusp of a significant evolution driven by the integration of robotics
and artificial intelligence (AI), giving rise to the concept of the
robochemist: a new paradigm where autonomous systems assist in designing,
executing, and analyzing experiments. Robochemists integrate mobile
manipulators, advanced perception, teleoperation, and data-driven protocols to
execute experiments with greater adaptability, reproducibility, and safety.
Rather than a fully automated replacement for human chemists, we envisioned the
robochemist as a complementary partner that works collaboratively to enhance
discovery, enabling a more efficient exploration of chemical space and
accelerating innovation in pharmaceuticals, materials science, and sustainable
manufacturing. This article traces the technologies, applications, and
challenges that define this transformation, highlighting both the opportunities
and the responsibilities that accompany the emergence of the robochemist.
Ultimately, the future of chemistry is argued to lie in a symbiotic partnership
where human intuition and expertise is amplified by robotic precision and
AI-driven insight.

</details>


### [21] [sqrtVINS: Robust and Ultrafast Square-Root Filter-based 3D Motion Tracking](https://arxiv.org/abs/2510.10346)
*Yuxiang Peng,Chuchu Chen,Kejian Wu,Guoquan Huang*

Main category: cs.RO

TL;DR: 开发了首个基于平方根滤波的视觉惯性导航系统sqrtVINS，具有超快速度、数值稳定性和动态初始化能力，在32位单精度浮点数下运行速度是SOTA方法的两倍。


<details>
  <summary>Details</summary>
Motivation: 嵌入式机器人系统资源受限且数值不稳定，平方根协方差滤波器能提供数值稳定性、高效内存使用和保证正半定性，但传统SRF因协方差矩阵三角结构破坏而效率低下。

Method: 提出基于Cholesky分解的SRF更新方法，充分利用系统结构保持三角结构；设计快速鲁棒的动态初始化方法，先恢复最小状态而不进行3D特征三角化，然后通过迭代SRF更新优化完整状态。

Result: 在32位单精度浮点数下实现卓越的数值稳定性，运行速度是SOTA方法的两倍；在移动工作站和Jetson Nano上测试，即使在100ms窗口和最小条件下也能实现高成功率的初始化。

Conclusion: sqrtVINS在各种场景下展现出强大的效率、鲁棒性和可靠性，开源实现支持未来研究和应用。

Abstract: In this paper, we develop and open-source, for the first time, a square-root
filter (SRF)-based visual-inertial navigation system (VINS), termed sqrtVINS,
which is ultra-fast, numerically stable, and capable of dynamic initialization
even under extreme conditions (i.e., extremely small time window). Despite
recent advancements in VINS, resource constraints and numerical instability on
embedded (robotic) systems with limited precision remain critical challenges. A
square-root covariance-based filter offers a promising solution by providing
numerical stability, efficient memory usage, and guaranteed positive
semi-definiteness. However, canonical SRFs suffer from inefficiencies caused by
disruptions in the triangular structure of the covariance matrix during
updates. The proposed method significantly improves VINS efficiency with a
novel Cholesky decomposition (LLT)-based SRF update, by fully exploiting the
system structure to preserve the structure. Moreover, we design a fast, robust,
dynamic initialization method, which first recovers the minimal states without
triangulating 3D features and then efficiently performs iterative SRF update to
refine the full states, enabling seamless VINS operation. The proposed
LLT-based SRF is extensively verified through numerical studies, demonstrating
superior numerical stability and achieving robust efficient performance on
32-bit single-precision floats, operating at twice the speed of
state-of-the-art (SOTA) methods. Our initialization method, tested on both
mobile workstations and Jetson Nano computers, achieving a high success rate of
initialization even within a 100 ms window under minimal conditions. Finally,
the proposed sqrtVINS is extensively validated across diverse scenarios,
demonstrating strong efficiency, robustness, and reliability. The full
open-source implementation is released to support future research and
applications.

</details>


### [22] [Learning to Throw-Flip](https://arxiv.org/abs/2510.10357)
*Yang Liu,Bruno Da Costa,Aude Billard*

Main category: cs.RO

TL;DR: 提出了一种让机器人精确"抛掷翻转"物体到目标位置和方向的方法，通过解耦寄生旋转和结合物理模型与回归学习，显著扩展了可行着陆姿态的范围。


<details>
  <summary>Details</summary>
Motivation: 传统机器人抛掷主要关注物体落地位置而忽略最终方向，且由于寄生旋转导致着陆姿态受限且不可控。

Method: 基于冲量-动量原理设计抛掷动作族来解耦寄生旋转，结合自由飞行的物理模型和回归学习方法处理未建模效应。

Result: 真实机器人实验表明，该方法能在数十次试验内学会将物体抛掷翻转至(±5cm, ±45度)精度内的目标姿态，相比端到端学习方法样本复杂度降低40%，重用过往知识可加速学习70%。

Conclusion: 该方法成功实现了机器人对物体位置和方向的精确抛掷控制，通过物理模型与数据驱动方法的结合显著提高了学习效率和性能。

Abstract: Dynamic manipulation, such as robot tossing or throwing objects, has recently
gained attention as a novel paradigm to speed up logistic operations. However,
the focus has predominantly been on the object's landing location, irrespective
of its final orientation. In this work, we present a method enabling a robot to
accurately "throw-flip" objects to a desired landing pose (position and
orientation). Conventionally, objects thrown by revolute robots suffer from
parasitic rotation, resulting in highly restricted and uncontrollable landing
poses. Our approach is based on two key design choices: first, leveraging the
impulse-momentum principle, we design a family of throwing motions that
effectively decouple the parasitic rotation, significantly expanding the
feasible set of landing poses. Second, we combine a physics-based model of free
flight with regression-based learning methods to account for unmodeled effects.
Real robot experiments demonstrate that our framework can learn to throw-flip
objects to a pose target within ($\pm$5 cm, $\pm$45 degrees) threshold in
dozens of trials. Thanks to data assimilation, incorporating projectile
dynamics reduces sample complexity by an average of 40% when throw-flipping to
unseen poses compared to end-to-end learning methods. Additionally, we show
that past knowledge on in-hand object spinning can be effectively reused,
accelerating learning by 70% when throwing a new object with a Center of Mass
(CoM) shift. A video summarizing the proposed method and the hardware
experiments is available at https://youtu.be/txYc9b1oflU.

</details>


### [23] [RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning](https://arxiv.org/abs/2510.10379)
*Rohan Gupta,Trevor Asbery,Zain Merchant,Abrar Anwar,Jesse Thomason*

Main category: cs.RO

TL;DR: RobotFleet是一个开源的多机器人任务规划和调度框架，利用LLM实现异构机器人舰队完成多个任务，通过容器化部署简化舰队扩展和管理。


<details>
  <summary>Details</summary>
Motivation: 协调异构机器人舰队实现多个目标在多机器人系统中具有挑战性，需要简化舰队扩展和管理的解决方案。

Method: 提供规划、调度和执行的抽象层，使用容器化服务部署机器人，维护共享声明式世界状态和双向通信，利用LLM进行开放世界推理。

Result: 开发了RobotFleet框架，降低了构建可扩展多机器人系统的门槛，实现了异构机器人舰队的任务规划和调度能力。

Conclusion: RobotFleet通过模块化自主堆栈各层和使用LLM，为构建可扩展的多机器人系统提供了有效解决方案。

Abstract: Coordinating heterogeneous robot fleets to achieve multiple goals is
challenging in multi-robot systems. We introduce an open-source and extensible
framework for centralized multi-robot task planning and scheduling that
leverages LLMs to enable fleets of heterogeneous robots to accomplish multiple
tasks. RobotFleet provides abstractions for planning, scheduling, and execution
across robots deployed as containerized services to simplify fleet scaling and
management. The framework maintains a shared declarative world state and
two-way communication for task execution and replanning. By modularizing each
layer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet
lowers the barrier to building scalable multi-robot systems. The code can be
found here: https://github.com/therohangupta/robot-fleet.

</details>


### [24] [MicroRoboScope: A Portable and Integrated Mechatronic Platform for Magnetic and Acoustic Microrobotic Experimentation](https://arxiv.org/abs/2510.10392)
*Max Sokolich,Yanda Yang,Subrahmanyam Cherukumilli,Fatma Ceren Kirmizitas,Sambeeta Das*

Main category: cs.RO

TL;DR: MicroRoboScope是一个便携、紧凑、多功能的微机器人实验平台，支持磁性和声学微机器人的实时闭环控制。


<details>
  <summary>Details</summary>
Motivation: 降低微机器人实验的门槛，为生物医学、组织工程和机器人学的研究、教育和转化应用创造新机会。

Method: 将嵌入式计算机、显微镜、电源和控制电路集成到单一低成本设备中，使用Python和Arduino C++开发定制控制软件处理视频采集、机器人跟踪和控制信号生成。

Result: 开发出具有多模态驱动、易用性和便携性的集成平台，适用于专业研究实验室以及教育和推广环境。

Conclusion: 该系统通过降低微机器人实验的进入门槛，为生物医学、组织工程和机器人学领域的研究、教育和转化应用开辟了新机遇。

Abstract: This paper presents MicroRoboScope, a portable, compact, and versatile
microrobotic experimentation platform designed for real-time, closed-loop
control of both magnetic and acoustic microrobots. The system integrates an
embedded computer, microscope, power supplies, and control circuitry into a
single, low-cost and fully integrated apparatus. Custom control software
developed in Python and Arduino C++ handles live video acquisition, microrobot
tracking, and generation of control signals for electromagnetic coils and
acoustic transducers. The platform's multi-modal actuation, accessibility, and
portability make it suitable not only for specialized research laboratories but
also for educational and outreach settings. By lowering the barrier to entry
for microrobotic experimentation, this system enables new opportunities for
research, education, and translational applications in biomedicine, tissue
engineering, and robotics.

</details>


### [25] [Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty](https://arxiv.org/abs/2510.10421)
*Junbin Yuan,Brady Moon,Muqing Cao,Sebastian Scherer*

Main category: cs.RO

TL;DR: 提出了一种用于无人机多目标跟踪的分层规划器，通过将任务分解为单目标搜索子任务，使用MDP框架和树基算法解决，在模拟中显著降低了11-70%的不确定性。


<details>
  <summary>Details</summary>
Motivation: 单机器人系统在广阔空间跟踪多个动态目标时，视野外的目标不确定性会累积，现有方法因规划视野短和假设小环境导致跟踪性能差和目标丢失。

Method: 分层规划方法，包含低层覆盖规划器搜索目标在演化信念区域，估计子任务成功概率，将主动目标跟踪转化为MDP问题并用树基算法求解子任务序列。

Result: 在模拟验证中，相比现有方法，提出的规划器在不同环境下将最终不确定性降低了11-70%。

Conclusion: 该分层规划器通过结合运动模型和不确定性传播，有效解决了大规模场景下的多动态目标跟踪问题，显著提升了跟踪性能。

Abstract: Achieving persistent tracking of multiple dynamic targets over a large
spatial area poses significant challenges for a single-robot system with
constrained sensing capabilities. As the robot moves to track different
targets, the ones outside the field of view accumulate uncertainty, making them
progressively harder to track. An effective path planning algorithm must manage
uncertainty over a long horizon and account for the risk of permanently losing
track of targets that remain unseen for too long. However, most existing
approaches rely on short planning horizons and assume small, bounded
environments, resulting in poor tracking performance and target loss in
large-scale scenarios. In this paper, we present a hierarchical planner for
tracking multiple moving targets with an aerial vehicle. To address the
challenge of tracking non-static targets, our method incorporates motion models
and uncertainty propagation during path execution, allowing for more informed
decision-making. We decompose the multi-target tracking task into sub-tasks of
single target search and detection, and our proposed pipeline consists a novel
low-level coverage planner that enables searching for a target in an evolving
belief area, and an estimation method to assess the likelihood of success for
each sub-task, making it possible to convert the active target tracking task to
a Markov decision process (MDP) that we solve with a tree-based algorithm to
determine the sequence of sub-tasks. We validate our approach in simulation,
demonstrating its effectiveness compared to existing planners for active target
tracking tasks, and our proposed planner outperforms existing approaches,
achieving a reduction of 11-70% in final uncertainty across different
environments.

</details>


### [26] [Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds](https://arxiv.org/abs/2510.10455)
*Jiayu Ding,Xulin Chen,Garrett E. Katz,Zhenyu Gan*

Main category: cs.RO

TL;DR: 提出基于对称性的强化学习框架，自动生成四足机器人的多种步态，无需人工调整脚部轨迹参数。


<details>
  <summary>Details</summary>
Motivation: 传统四足机器人步态生成需要专家手动调整大量参数，如触地/抬腿时机和腿部约束，过程繁琐且不灵活。

Method: 利用动态腿式系统的内在对称性和速度-周期关系，设计对称性引导的奖励函数，包含时间、形态和时间反转对称性。

Result: 在Unitree Go2机器人上实现，在仿真和硬件测试中表现出稳健性能，能平滑切换小跑、跳跃、半跳跃和疾驰等多种步态。

Conclusion: 该方法显著提高了步态适应性，无需大量奖励调整或显式脚部位置控制，证明了对称性在机器人步态设计中的关键作用。

Abstract: Quadrupedal robots exhibit a wide range of viable gaits, but generating
specific footfall sequences often requires laborious expert tuning of numerous
variables, such as touch-down and lift-off events and holonomic constraints for
each leg. This paper presents a unified reinforcement learning framework for
generating versatile quadrupedal gaits by leveraging the intrinsic symmetries
and velocity-period relationship of dynamic legged systems. We propose a
symmetry-guided reward function design that incorporates temporal,
morphological, and time-reversal symmetries. By focusing on preserved
symmetries and natural dynamics, our approach eliminates the need for
predefined trajectories, enabling smooth transitions between diverse locomotion
patterns such as trotting, bounding, half-bounding, and galloping. Implemented
on the Unitree Go2 robot, our method demonstrates robust performance across a
range of speeds in both simulations and hardware tests, significantly improving
gait adaptability without extensive reward tuning or explicit foot placement
control. This work provides insights into dynamic locomotion strategies and
underscores the crucial role of symmetries in robotic gait design.

</details>


### [27] [Galilean Symmetry in Robotics](https://arxiv.org/abs/2510.10468)
*Robert Mahony,Jonathan Kelly,Stephan Weiss*

Main category: cs.RO

TL;DR: 本文为机器人学领域提供了伽利略对称性的专业阐述，利用机器人社区熟悉的刚体变换和位姿表示方法，展示了伽利略矩阵李群在机器人问题中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 伽利略对称性是牛顿物理学中惯性运动的自然对称性，但在机器人学领域缺乏类似刚体对称性的系统处理。作者旨在填补这一空白，为机器人社区提供专门针对伽利略对称性的阐述。

Method: 使用伽利略矩阵李群描述两种不同的位姿表示：使用惯性速度的伽利略框架和使用坐标速度的扩展位姿。通过三个机器人问题示例展示该方法的实用性。

Result: 成功将伽利略矩阵李群代数应用于三个机器人问题：旋转地球上方的惯性导航、机械臂运动学以及时间不确定性下的传感器数据融合，获得了重要见解。

Conclusion: 机器人社区现在正是时候重新发现和扩展这一经典材料，并将其应用于现代问题，从而从中获益。

Abstract: Galilean symmetry is the natural symmetry of inertial motion that underpins
Newtonian physics. Although rigid-body symmetry is one of the most established
and fundamental tools in robotics, there appears to be no comparable treatment
of Galilean symmetry for a robotics audience. In this paper, we present a
robotics-tailored exposition of Galilean symmetry that leverages the
community's familiarity with and understanding of rigid-body transformations
and pose representations. Our approach contrasts with common treatments in the
physics literature that introduce Galilean symmetry as a stepping stone to
Einstein's relativity. A key insight is that the Galilean matrix Lie group can
be used to describe two different pose representations, Galilean frames, that
use inertial velocity in the state definition, and extended poses, that use
coordinate velocity. We provide three examples where applying the Galilean
matrix Lie-group algebra to robotics problems is straightforward and yields
significant insights: inertial navigation above the rotating Earth, manipulator
kinematics, and sensor data fusion under temporal uncertainty. We believe that
the time is right for the robotics community to benefit from rediscovering and
extending this classical material and applying it to modern problems.

</details>


### [28] [SuperEx: Enhancing Indoor Mapping and Exploration using Non-Line-of-Sight Perception](https://arxiv.org/abs/2510.10506)
*Kush Garg,Akshat Dave*

Main category: cs.RO

TL;DR: SuperEx框架将非视距(NLOS)感知集成到机器人探索中，利用单光子LiDAR观察盲区，通过物理和数据驱动方法重建隐藏结构，在低覆盖率下提升12%的建图精度。


<details>
  <summary>Details</summary>
Motivation: 当前机器人感知局限于视距范围，被遮挡区域需要物理遍历才能发现，导致探索效率低下。NLOS感知可以让机器人看到盲区，提高未知室内环境探索效率。

Method: 集成NLOS感知到建图-探索循环中：(1)从时间直方图中剔除空NLOS区域；(2)通过两步物理和数据驱动方法重建被遮挡结构，利用结构规律性。

Result: 在复杂仿真地图和真实KTH Floorplan数据集上评估，在<30%覆盖率下建图精度提升12%，探索效率优于视距基线方法。

Conclusion: SuperEx为超越直接可见性的可靠建图开辟了新路径，证明了NLOS感知在机器人探索中的实用价值。

Abstract: Efficient exploration and mapping in unknown indoor environments is a
fundamental challenge, with high stakes in time-critical settings. In current
systems, robot perception remains confined to line-of-sight; occluded regions
remain unknown until physically traversed, leading to inefficient exploration
when layouts deviate from prior assumptions. In this work, we bring
non-line-of-sight (NLOS) sensing to robotic exploration. We leverage
single-photon LiDARs, which capture time-of-flight histograms that encode the
presence of hidden objects - allowing robots to look around blind corners.
Recent single-photon LiDARs have become practical and portable, enabling
deployment beyond controlled lab settings. Prior NLOS works target 3D
reconstruction in static, lab-based scenarios, and initial efforts toward
NLOS-aided navigation consider simplified geometries. We introduce SuperEx, a
framework that integrates NLOS sensing directly into the mapping-exploration
loop. SuperEx augments global map prediction with beyond-line-of-sight cues by
(i) carving empty NLOS regions from timing histograms and (ii) reconstructing
occupied structure via a two-step physics-based and data-driven approach that
leverages structural regularities. Evaluations on complex simulated maps and
the real-world KTH Floorplan dataset show a 12% gain in mapping accuracy under
< 30% coverage and improved exploration efficiency compared to line-of-sight
baselines, opening a path to reliable mapping beyond direct visibility.

</details>


### [29] [Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control](https://arxiv.org/abs/2510.10516)
*Kanishkha Jaisankar,Xiaoyang Jiang,Feifan Liao,Jeethu Sreenivas Amuthan*

Main category: cs.RO

TL;DR: 提出了一种结合群体编码脉冲神经网络(SNN)和深度强化学习(DRL)的新框架，在保持控制性能的同时实现高达96.10%的能耗节省


<details>
  <summary>Details</summary>
Motivation: 解决机器人高维连续控制任务中能效和性能的平衡问题，传统DRL方法计算需求大、能耗高，限制了在资源受限环境中的部署

Method: 使用群体编码脉冲演员网络(PopSAN)，将高维观测编码为神经元群体活动，通过基于梯度的更新实现最优策略学习，结合SNN的事件驱动异步计算和DRL的鲁棒策略优化能力

Result: 在Isaac Gym平台的PixMC基准测试中，Franka机械臂实验显示相比传统人工神经网络(ANN)节省96.10%能耗，同时保持相当的控制性能，表现出稳健的手指位置跟踪和稳定的目标高度维持

Conclusion: 群体编码SNN为资源受限应用中的能效高性能机器人控制提供了有前景的解决方案，为实际机器人系统的可扩展部署铺平了道路

Abstract: Energy-efficient and high-performance motor control remains a critical
challenge in robotics, particularly for high-dimensional continuous control
tasks with limited onboard resources. While Deep Reinforcement Learning (DRL)
has achieved remarkable results, its computational demands and energy
consumption limit deployment in resource-constrained environments. This paper
introduces a novel framework combining population-coded Spiking Neural Networks
(SNNs) with DRL to address these challenges. Our approach leverages the
event-driven, asynchronous computation of SNNs alongside the robust policy
optimization capabilities of DRL, achieving a balance between energy efficiency
and control performance. Central to this framework is the Population-coded
Spiking Actor Network (PopSAN), which encodes high-dimensional observations
into neuronal population activities and enables optimal policy learning through
gradient-based updates. We evaluate our method on the Isaac Gym platform using
the PixMC benchmark with complex robotic manipulation tasks. Experimental
results on the Franka robotic arm demonstrate that our approach achieves energy
savings of up to 96.10% compared to traditional Artificial Neural Networks
(ANNs) while maintaining comparable control performance. The trained SNN
policies exhibit robust finger position tracking with minimal deviation from
commanded trajectories and stable target height maintenance during
pick-and-place operations. These results position population-coded SNNs as a
promising solution for energy-efficient, high-performance robotic control in
resource-constrained applications, paving the way for scalable deployment in
real-world robotics systems.

</details>


### [30] [Decoupled Scaling 4ch Bilateral Control on the Cartesian coordinate by 6-DoF Manipulator using Rotation Matrix](https://arxiv.org/abs/2510.10545)
*Koki Yamane,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 提出了一种4通道笛卡尔坐标系双边控制方法，通过解耦各维度实现期望动力学，不受缩放因子影响


<details>
  <summary>Details</summary>
Motivation: 四通道双边控制能通过同步两个机械臂的位置和力来实现带力反馈的远程控制，在接触密集型任务中显著改善操作性。笛卡尔坐标系下的4通道双边控制特别适合不同结构的机械臂，并能通过调整控制参数实现直观操作

Method: 在笛卡尔坐标系中实现4通道双边控制，通过解耦每个维度来实现期望的动力学特性，该方法不受缩放因子的影响

Result: 该方法能够实现期望的动力学特性，为不同结构的机械臂提供了合适的双边控制方案

Conclusion: 提出的4通道笛卡尔坐标系双边控制方法能够有效实现远程控制的力反馈和操作性调整，特别适用于接触密集型任务

Abstract: Four-channel bilateral control is a method for achieving remote control with
force feedback and adjustment operability by synchronizing the positions and
forces of two manipulators. This is expected to significantly improve the
operability of the remote control in contact-rich tasks. Among these, 4-channel
bilateral control on the Cartesian coordinate system is advantageous owing to
its suitability for manipulators with different structures and because it
allows the dynamics in the Cartesian coordinate system to be adjusted by
adjusting the control parameters, thus achieving intuitive operability for
humans. This paper proposes a 4-channel bilateral control method that achieves
the desired dynamics by decoupling each dimension in the Cartesian coordinate
system regardless of the scaling factor.

</details>


### [31] [Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving](https://arxiv.org/abs/2510.10567)
*Alexander Langmann,Yevhenii Tokarev,Mattia Piccinini,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 提出使用强化学习作为高层行为选择器，动态切换底层轨迹规划器的成本函数参数，解决了自动驾驶赛车中静态规划器在安全性和竞争力之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 基于采样的轨迹规划器在自动驾驶赛车中广泛使用，但其行为通常由手动调优的静态权重成本函数控制，这在不同场景下需要战术妥协，无法达到最优性能。

Method: 使用强化学习智能体作为高层行为选择器，在运行时动态切换底层分析性轨迹规划器的成本函数参数，实现自适应行为切换。

Result: 在自动驾驶赛车模拟环境中，RL规划器实现了0%的碰撞率，同时将超车时间减少高达60%，能够动态在激进和保守行为之间切换，实现静态配置无法达到的交互机动。

Conclusion: 将强化学习作为高层选择器集成，解决了自动驾驶赛车规划器中安全性和竞争力之间的固有权衡，为更广泛的自动驾驶应用提供了自适应且可解释的运动规划路径。

Abstract: Sampling-based trajectory planners are widely used for agile autonomous
driving due to their ability to generate fast, smooth, and kinodynamically
feasible trajectories. However, their behavior is often governed by a cost
function with manually tuned, static weights, which forces a tactical
compromise that is suboptimal across the wide range of scenarios encountered in
a race. To address this shortcoming, we propose using a Reinforcement Learning
(RL) agent as a high-level behavioral selector that dynamically switches the
cost function parameters of an analytical, low-level trajectory planner during
runtime. We show the effectiveness of our approach in simulation in an
autonomous racing environment where our RL-based planner achieved 0% collision
rate while reducing overtaking time by up to 60% compared to state-of-the-art
static planners. Our new agent now dynamically switches between aggressive and
conservative behaviors, enabling interactive maneuvers unattainable with static
configurations. These results demonstrate that integrating reinforcement
learning as a high-level selector resolves the inherent trade-off between
safety and competitiveness in autonomous racing planners. The proposed
methodology offers a pathway toward adaptive yet interpretable motion planning
for broader autonomous driving applications.

</details>


### [32] [Fast Vision in the Dark: A Case for Single-Photon Imaging in Planetary Navigation](https://arxiv.org/abs/2510.10597)
*David Rodríguez-Martínez,C. J. Pérez del Pulgar*

Main category: cs.RO

TL;DR: 提出使用SPAD相机作为替代被动传感技术，用于行星导航，特别针对高纬度月球区域等感知挑战环境。


<details>
  <summary>Details</summary>
Motivation: 传统CCD或CMOS相机在复杂光照条件和运动下存在限制，影响移动行星机器人的探测范围和可访问性。

Method: 利用单光子雪崩二极管相机的独特成像能力，评估其在代表性光照条件下的性能，并详细说明其工作原理和性能特征。

Result: 首次全面评估单光子成像技术作为机器人探测任务的替代传感方案，特别针对月球高纬度区域。

Conclusion: SPAD相机能够解决即将到来的月球探测任务中的关键感知挑战，在复杂光照条件下具有优势。

Abstract: Improving robotic navigation is critical for extending exploration range and
enhancing operational efficiency. Vision-based navigation relying on
traditional CCD or CMOS cameras faces major challenges when complex
illumination conditions are paired with motion, limiting the range and
accessibility of mobile planetary robots. In this study, we propose a novel
approach to planetary navigation that leverages the unique imaging capabilities
of Single-Photon Avalanche Diode (SPAD) cameras. We present the first
comprehensive evaluation of single-photon imaging as an alternative passive
sensing technology for robotic exploration missions targeting perceptually
challenging locations, with a special emphasis on high-latitude lunar regions.
We detail the operating principles and performance characteristics of SPAD
cameras, assess their advantages and limitations in addressing key perception
challenges of upcoming exploration missions to the Moon, and benchmark their
performance under representative illumination conditions.

</details>


### [33] [SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams](https://arxiv.org/abs/2510.10602)
*Zhuoheng Gao,Jiyao Zhang,Zhiyong Xie,Hao Dong,Zhaofei Yu,Rongmei Chen,Guozhang Chen,Tiejun Huang*

Main category: cs.RO

TL;DR: SpikeGrasp是一个神经启发的6-DoF抓取检测框架，直接处理来自立体脉冲相机的原始异步事件，无需重建点云，在杂乱和无纹理场景中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 大多数机器人抓取系统依赖将传感器数据转换为显式3D点云，这在生物智能中不存在。本文探索一种根本不同的神经启发范式，模仿生物视觉运动通路。

Method: 引入SpikeGrasp框架，处理立体脉冲相机的原始异步事件，使用循环脉冲神经网络迭代优化抓取假设，无需重建点云。构建大规模合成基准数据集进行验证。

Result: 实验表明SpikeGrasp超越传统基于点云的基线方法，特别是在杂乱和无纹理场景中，并展现出显著的数据效率。

Conclusion: 通过验证这种端到端神经启发方法的可行性，SpikeGrasp为未来能够实现自然界中流畅高效操作的系统铺平了道路，特别适用于动态物体。

Abstract: Most robotic grasping systems rely on converting sensor data into explicit 3D
point clouds, which is a computational step not found in biological
intelligence. This paper explores a fundamentally different, neuro-inspired
paradigm for 6-DoF grasp detection. We introduce SpikeGrasp, a framework that
mimics the biological visuomotor pathway, processing raw, asynchronous events
from stereo spike cameras, similarly to retinas, to directly infer grasp poses.
Our model fuses these stereo spike streams and uses a recurrent spiking neural
network, analogous to high-level visual processing, to iteratively refine grasp
hypotheses without ever reconstructing a point cloud. To validate this
approach, we built a large-scale synthetic benchmark dataset. Experiments show
that SpikeGrasp surpasses traditional point-cloud-based baselines, especially
in cluttered and textureless scenes, and demonstrates remarkable data
efficiency. By establishing the viability of this end-to-end, neuro-inspired
approach, SpikeGrasp paves the way for future systems capable of the fluid and
efficient manipulation seen in nature, particularly for dynamic objects.

</details>


### [34] [High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting](https://arxiv.org/abs/2510.10637)
*Haoyu Zhao,Cheng Zeng,Linghao Zhuang,Yaxi Zhao,Shengke Xue,Hao Wang,Xingyue Zhao,Zhongyu Li,Kehan Li,Siteng Huang,Mingxiu Chen,Xin Li,Deli Zhao,Hua Zou*

Main category: cs.RO

TL;DR: RoboSimGS是一个Real2Sim2Real框架，通过多模态大语言模型自动化创建物理可信的仿真环境，实现零样本的仿真到真实世界迁移。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中真实世界数据收集成本高、仿真数据难以泛化到真实世界的问题，弥合仿真与现实之间的差距。

Method: 使用3D高斯溅射重建场景外观，网格基元处理交互对象物理模拟，多模态大语言模型自动推断物体物理属性和运动结构。

Result: 在RoboSimGS生成的数据上训练的策略实现了成功的零样本仿真到真实迁移，并能显著提升现有方法的性能和泛化能力。

Conclusion: RoboSimGS是弥合仿真与现实差距的强大可扩展解决方案，为机器人学习提供了高效的仿真数据生成方法。

Abstract: The scalability of robotic learning is fundamentally bottlenecked by the
significant cost and labor of real-world data collection. While simulated data
offers a scalable alternative, it often fails to generalize to the real world
due to significant gaps in visual appearance, physical properties, and object
interactions. To address this, we propose RoboSimGS, a novel Real2Sim2Real
framework that converts multi-view real-world images into scalable,
high-fidelity, and physically interactive simulation environments for robotic
manipulation. Our approach reconstructs scenes using a hybrid representation:
3D Gaussian Splatting (3DGS) captures the photorealistic appearance of the
environment, while mesh primitives for interactive objects ensure accurate
physics simulation. Crucially, we pioneer the use of a Multi-modal Large
Language Model (MLLM) to automate the creation of physically plausible,
articulated assets. The MLLM analyzes visual data to infer not only physical
properties (e.g., density, stiffness) but also complex kinematic structures
(e.g., hinges, sliding rails) of objects. We demonstrate that policies trained
entirely on data generated by RoboSimGS achieve successful zero-shot
sim-to-real transfer across a diverse set of real-world manipulation tasks.
Furthermore, data from RoboSimGS significantly enhances the performance and
generalization capabilities of SOTA methods. Our results validate RoboSimGS as
a powerful and scalable solution for bridging the sim-to-real gap.

</details>


### [35] [UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning](https://arxiv.org/abs/2510.10642)
*Jianke Zhang,Yucheng Hu,Yanjiang Guo,Xiaoyu Chen,Yichen Liu,Wenna Chen,Chaochao Lu,Jianyu Chen*

Main category: cs.RO

TL;DR: UniCoD是一个机器人策略学习框架，通过在大规模互联网教学视频上预训练，结合视觉语言理解和视觉生成能力，在仿真和真实世界任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有通用机器人策略要么基于视觉语言理解模型，要么基于生成模型，但语义理解和视觉动态建模对具身机器人都至关重要。需要结合理解和生成的优势来提升机器人策略学习。

Method: 在超过100万互联网教学视频上预训练，学习高维视觉特征的动态建模，然后在机器人具身数据上微调，将预测表示映射到动作标记。

Result: 在仿真环境和真实世界分布外任务中分别比基线方法提升9%和12%。

Conclusion: 结合理解和生成的大规模预训练能够有效提升机器人策略的通用性和性能。

Abstract: Building generalist robot policies that can handle diverse tasks in
open-ended environments is a central challenge in robotics. To leverage
knowledge from large-scale pretraining, prior work has typically built
generalist policies either on top of vision-language understanding models
(VLMs) or generative models. However, both semantic understanding from
vision-language pretraining and visual dynamics modeling from visual-generation
pretraining are crucial for embodied robots. Recent unified models of
generation and understanding have demonstrated strong capabilities in both
comprehension and generation through large-scale pretraining. We posit that
robotic policy learning can likewise benefit from the combined strengths of
understanding, planning and continuous future representation learning. Building
on this insight, we introduce UniCoD, which acquires the ability to dynamically
model high-dimensional visual features through pretraining on over 1M
internet-scale instructional manipulation videos. Subsequently, UniCoD is
fine-tuned on data collected from the robot embodiment, enabling the learning
of mappings from predictive representations to action tokens. Extensive
experiments show our approach consistently outperforms baseline methods in
terms of 9\% and 12\% across simulation environments and real-world
out-of-distribution tasks.

</details>


### [36] [Deployment and Development of a Cognitive Teleoreactive Framework for Deep Sea Autonomy](https://arxiv.org/abs/2510.10716)
*Christopher Thierauf*

Main category: cs.RO

TL;DR: DINOS-R是一种新的AUV任务规划与执行软件，融合了符号决策和机器学习技术，已在Sentry AUV上测试成功


<details>
  <summary>Details</summary>
Motivation: 替代传统的MC架构，统一符号决策和机器学习方法，提高AUV在不同海洋学平台上的现场适应性

Method: 基于Python3构建的模块化、可扩展架构，支持声明式任务规范和实时任务规划与硬编码计划的同时使用

Result: 在Sentry AUV和多种模拟场景中成功演示了系统功能

Conclusion: DINOS-R为海洋学和机器人算法研究提供了可扩展的基础，未来工作将继续完善

Abstract: A new AUV mission planning and execution software has been tested on AUV
Sentry. Dubbed DINOS-R, it draws inspiration from cognitive architectures and
AUV control systems to replace the legacy MC architecture. Unlike these
existing architectures, however, DINOS-R is built from the ground-up to unify
symbolic decision making (for understandable, repeatable, provable behavior)
with machine learning techniques and reactive behaviors, for field-readiness
across oceanographic platforms. Implemented primarily in Python3, DINOS-R is
extensible, modular, and reusable, with an emphasis on non-expert use as well
as growth for future research in oceanography and robot algorithms. Mission
specification is flexible, and can be specified declaratively. Behavior
specification is similarly flexible, supporting simultaneous use of real-time
task planning and hard-coded user specified plans. These features were
demonstrated in the field on Sentry, in addition to a variety of simulated
cases. These results are discussed, and future work is outlined.

</details>


### [37] [Controllable Generative Trajectory Prediction via Weak Preference Alignment](https://arxiv.org/abs/2510.10731)
*Yongxi Cao,Julian F. Schumann,Jens Kober,Joni Pajarinen,Arkady Zgonnikov*

Main category: cs.RO

TL;DR: PrefCVAE是一个增强的条件变分自编码器框架，通过弱标记的偏好对为潜在变量注入语义属性，实现可控的多样化轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 现有深度生成模型在自动驾驶轨迹预测中缺乏可控多样化生成方案，而随机多样化轨迹对安全规划不够有用。

Method: 提出PrefCVAE框架，使用弱标记偏好对将语义属性（如平均速度）编码到潜在变量中，实现可控的多样化预测。

Result: PrefCVAE在不降低基线准确性的情况下，实现了可控且语义有意义的预测，证明了偏好监督作为增强采样生成模型的有效方法。

Conclusion: 偏好监督是增强基于采样的生成模型的一种经济有效的方式，能够为自动驾驶安全规划提供更有用的可控多样化轨迹预测。

Abstract: Deep generative models such as conditional variational autoencoders (CVAEs)
have shown great promise for predicting trajectories of surrounding agents in
autonomous vehicle planning. State-of-the-art models have achieved remarkable
accuracy in such prediction tasks. Besides accuracy, diversity is also crucial
for safe planning because human behaviors are inherently uncertain and
multimodal. However, existing methods generally lack a scheme to generate
controllably diverse trajectories, which is arguably more useful than randomly
diversified trajectories, to the end of safe planning. To address this, we
propose PrefCVAE, an augmented CVAE framework that uses weakly labeled
preference pairs to imbue latent variables with semantic attributes. Using
average velocity as an example attribute, we demonstrate that PrefCVAE enables
controllable, semantically meaningful predictions without degrading baseline
accuracy. Our results show the effectiveness of preference supervision as a
cost-effective way to enhance sampling-based generative models.

</details>


### [38] [Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning](https://arxiv.org/abs/2510.10759)
*Arthicha Srisuchinnawong,Poramate Manoonpong*

Main category: cs.RO

TL;DR: 提出了ROGER方法，通过在线自适应调整奖励权重增益来解决机器人运动学习中的约束违反问题，在真实四足机器人上实现了近乎零约束违反和更高的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有机器人运动学习技术严重依赖离线选择适当的奖励权重增益，无法在训练过程中保证约束满足（即避免约束违反）。

Method: ROGER方法通过基于在具体交互过程中收到的惩罚来在线自适应调整奖励权重增益。当学习接近约束阈值时，正奖励与负奖励增益的比率会自动降低以避免违反；在安全状态下则会增加比率以优先考虑性能。

Result: 在60公斤四足机器人上，ROGER在多次学习试验中实现了近乎零约束违反，比同类最先进技术获得高达50%更多的主要奖励。在MuJoCo连续运动基准测试中，性能相当或高达100%更高，扭矩使用和方向偏差减少60%。真实世界四足机器人在1小时内从零开始学习运动且没有任何跌倒。

Conclusion: 这项工作为满足约束的真实世界持续机器人运动学习做出了贡献，并简化了奖励权重增益调优，可能促进物理机器人和在真实世界中学习的机器人的发展。

Abstract: Existing robot locomotion learning techniques rely heavily on the offline
selection of proper reward weighting gains and cannot guarantee constraint
satisfaction (i.e., constraint violation) during training. Thus, this work aims
to address both issues by proposing Reward-Oriented Gains via Embodied
Regulation (ROGER), which adapts reward-weighting gains online based on
penalties received throughout the embodied interaction process. The ratio
between the positive reward (primary reward) and negative reward (penalty)
gains is automatically reduced as the learning approaches the constraint
thresholds to avoid violation. Conversely, the ratio is increased when learning
is in safe states to prioritize performance. With a 60-kg quadruped robot,
ROGER achieved near-zero constraint violation throughout multiple learning
trials. It also achieved up to 50% more primary reward than the equivalent
state-of-the-art techniques. In MuJoCo continuous locomotion benchmarks,
including a single-leg hopper, ROGER exhibited comparable or up to 100% higher
performance and 60% less torque usage and orientation deviation compared to
those trained with the default reward function. Finally, real-world locomotion
learning of a physical quadruped robot was achieved from scratch within one
hour without any falls. Therefore, this work contributes to
constraint-satisfying real-world continual robot locomotion learning and
simplifies reward weighting gain tuning, potentially facilitating the
development of physical robots and those that learn in the real world.

</details>


### [39] [Real2USD: Scene Representations in Universal Scene Description Language](https://arxiv.org/abs/2510.10778)
*Christopher D. Hsu,Pratik Chaudhari*

Main category: cs.RO

TL;DR: 该论文提出使用通用场景描述语言（USD）作为LLM机器人任务的统一场景表示，通过Real to USD系统将真实环境转换为USD格式，并利用LLM进行场景理解和规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法针对特定任务，缺乏通用性。USD作为XML格式的场景图，既适合LLM理解又足够丰富，能支持各种机器人任务。

Method: 开发Real to USD系统，使用四足机器人搭载LiDAR和RGB相机构建室内环境的USD表示，然后利用Google Gemini解析USD进行场景理解、推理和规划。

Result: 成功在具有玻璃等挑战性环境的室内场景中构建了USD表示，并展示了LLM能够理解场景、进行复杂推理和规划。在模拟仓库和医院环境中也验证了系统性能。

Conclusion: USD是连接LLM与机器人任务的通用有效表示，为LLM在机器人领域的应用提供了新途径。

Abstract: Large Language Models (LLMs) can help robots reason about abstract task
specifications. This requires augmenting classical representations of the
environment used by robots with natural language-based priors. There are a
number of existing approaches to doing so, but they are tailored to specific
tasks, e.g., visual-language models for navigation, language-guided neural
radiance fields for mapping, etc. This paper argues that the Universal Scene
Description (USD) language is an effective and general representation of
geometric, photometric and semantic information in the environment for
LLM-based robotics tasks. Our argument is simple: a USD is an XML-based scene
graph, readable by LLMs and humans alike, and rich enough to support
essentially any task -- Pixar developed this language to store assets, scenes
and even movies. We demonstrate a ``Real to USD'' system using a Unitree Go2
quadruped robot carrying LiDAR and a RGB camera that (i) builds an explicit USD
representation of indoor environments with diverse objects and challenging
settings with lots of glass, and (ii) parses the USD using Google's Gemini to
demonstrate scene understanding, complex inferences, and planning. We also
study different aspects of this system in simulated warehouse and hospital
settings using Nvidia's Issac Sim. Code is available at
https://github.com/grasp-lyrl/Real2USD .

</details>


### [40] [Two-Layer Voronoi Coverage Control for Hybrid Aerial-Ground Robot Teams in Emergency Response: Implementation and Analysis](https://arxiv.org/abs/2510.10781)
*Douglas Hutchings,Luai Abuelsamen,Karthik Rajgopal*

Main category: cs.RO

TL;DR: 提出了一种双层Voronoi覆盖控制方法，用于协调混合空中-地面机器人团队在危险材料应急响应场景中的部署，解决了异构机器人能力、集群初始部署和时间紧迫等挑战。


<details>
  <summary>Details</summary>
Motivation: 传统Voronoi覆盖控制在应急场景中存在三个关键限制：异构机器人能力差异大、集群初始部署配置、以及紧急时间约束需要快速响应而非渐进收敛。

Method: 采用解耦的双层架构，分别优化空中和地面机器人定位，空中机器人通过空投将地面传感器部署到高优先级位置，包括有界Voronoi单元计算、重要性加权质心高效数值积分技术和防困控制策略。

Result: 仿真结果显示响应时间减少88%，在25秒内达到目标传感器覆盖（初始传感器损失18.5%），而纯地面部署需要220秒。

Conclusion: 该方法显著提高了混合机器人团队在紧急响应场景中的部署效率和响应速度。

Abstract: We present a comprehensive two-layer Voronoi coverage control approach for
coordinating hybrid aerial-ground robot teams in hazardous material emergency
response scenarios. Traditional Voronoi coverage control methods face three
critical limitations in emergency contexts: heterogeneous agent capabilities
with vastly different velocities, clustered initial deployment configurations,
and urgent time constraints requiring rapid response rather than eventual
convergence. Our method addresses these challenges through a decoupled
two-layer architecture that separately optimizes aerial and ground robot
positioning, with aerial agents delivering ground sensors via airdrop to
high-priority locations. We provide detailed implementation of bounded Voronoi
cell computation, efficient numerical integration techniques for
importance-weighted centroids, and robust control strategies that prevent agent
trapping. Simulation results demonstrate an 88% reduction in response time,
achieving target sensor coverage (18.5% of initial sensor loss) in 25 seconds
compared to 220 seconds for ground-only deployment. Complete implementation
code is available at https://github.com/dHutchings/ME292B.

</details>


### [41] [Representing Data in Robotic Tactile Perception -- A Review](https://arxiv.org/abs/2510.10804)
*Alessandro Albini,Mohsen Kaboli,Giorgio Cannata,Perla Maiolino*

Main category: cs.RO

TL;DR: 这篇论文是关于机器人触觉感知中数据表示方法的综述研究，分析了触觉信息如何通过不同数据结构进行编码，并提出了选择合适表示的指导原则。


<details>
  <summary>Details</summary>
Motivation: 机器人触觉感知需要将传感器数据转换为适合高级计算的数据结构，这一转换过程直接影响任务执行效果。现有研究多采用计算机视觉等领域的技术，但缺乏对数据表示方法的系统性分析。

Method: 通过文献综述方法，分析先前研究如何处理触觉信息表示问题，研究硬件、表示方法和高级计算方法之间的关系，识别出六种常用的数据结构。

Result: 识别出文献中常用的六种触觉数据表示结构，并提供了根据操作条件（可用硬件、所需触觉信息、具体任务）选择合适表示的讨论和指导原则。

Conclusion: 触觉数据表示是触觉感知流程中的关键环节，需要根据具体应用场景选择合适的表示方法，本文为此提供了系统性的分析框架和实用指南。

Abstract: Robotic tactile perception is a complex process involving several
computational steps performed at different levels. Tactile information is
shaped by the interplay of robot actions, the mechanical properties of its
body, and the software that processes the data. In this respect, high-level
computation, required to process and extract information, is commonly performed
by adapting existing techniques from other domains, such as computer vision,
which expects input data to be properly structured. Therefore, it is necessary
to transform tactile sensor data to match a specific data structure. This
operation directly affects the tactile information encoded and, as a
consequence, the task execution. This survey aims to address this specific
aspect of the tactile perception pipeline, namely Data Representation. The
paper first clearly defines its contributions to the perception pipeline and
then reviews how previous studies have dealt with the problem of representing
tactile information, investigating the relationships among hardware,
representations, and high-level computation methods. The analysis has led to
the identification of six structures commonly used in the literature to
represent data. The manuscript provides discussions and guidelines for properly
selecting a representation depending on operating conditions, including the
available hardware, the tactile information required to be encoded, and the
task at hand.

</details>


### [42] [Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots](https://arxiv.org/abs/2510.10843)
*Jared Grinberg,Yanran Ding*

Main category: cs.RO

TL;DR: 提出了一种使用分布式关节扭矩传感器和单个髋部安装的力-扭矩传感器来检测和定位机器人腿部接触的方法，通过广义动量观测器框架实现高精度接触力与位置估计。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖复杂的摩擦模型或基于电机电流的扭矩估计，精度有限。需要一种更直接、准确的接触检测和定位方法，以提升机器人腿部与环境的交互能力。

Method: 设计了低成本应变片式关节扭矩传感器，安装在每个关节上提供直接扭矩测量；采用广义动量观测器框架结合单个髋部FT传感器，通过仿真和硬件实验验证接触力与位置的恢复能力。

Result: 仿真验证了框架能准确恢复大腿和小腿连杆上的接触力和位置；扭矩传感器校准后达到96.4%的平均精度；硬件实验显示亚厘米级接触定位精度和低于0.2 N的力误差。

Conclusion: 该方法通过分布式关节扭矩传感器和广义动量观测器，实现了高精度的接触检测和定位，为机器人腿部与环境的安全交互提供了有效解决方案。

Abstract: This paper presents a method for detecting and localizing contact along robot
legs using distributed joint torque sensors and a single hip-mounted
force-torque (FT) sensor using a generalized momentum-based observer framework.
We designed a low-cost strain-gauge-based joint torque sensor that can be
installed on every joint to provide direct torque measurements, eliminating the
need for complex friction models and providing more accurate torque readings
than estimation based on motor current. Simulation studies on a floating-based
2-DoF robot leg verified that the proposed framework accurately recovers
contact force and location along the thigh and shin links. Through a
calibration procedure, our torque sensor achieved an average 96.4% accuracy
relative to ground truth measurements. Building upon the torque sensor, we
performed hardware experiments on a 2-DoF manipulator, which showed
sub-centimeter contact localization accuracy and force errors below 0.2 N.

</details>


### [43] [Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion](https://arxiv.org/abs/2510.10851)
*Tingxuan Leng,Yushi Wang,Tinglong Zheng,Changsheng Luo,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出了一种偏好条件多目标强化学习框架，用于平衡人形机器人运动中的命令跟踪和外部力顺应性，实现了可部署的偏好调节人形运动控制。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法主要强调鲁棒性，导致策略抵抗外部力而缺乏顺应性，这对本质上不稳定的人形机器人尤其具有挑战性。需要平衡命令跟踪和外部力顺应性。

Method: 使用偏好条件多目标RL框架，通过速度阻力因子建模外部力，采用编码器-解码器结构从可部署观测中推断特权特征，集成刚性命令跟随和顺应行为。

Result: 在仿真和真实人形机器人实验中验证，该框架不仅提高了适应性和收敛性，还实现了可部署的偏好条件人形运动。

Conclusion: 该工作成功解决了人形机器人运动中命令跟踪与外部力顺应性的平衡问题，为实际部署提供了有效的解决方案。

Abstract: Humanoid locomotion requires not only accurate command tracking for
navigation but also compliant responses to external forces during human
interaction. Despite significant progress, existing RL approaches mainly
emphasize robustness, yielding policies that resist external forces but lack
compliance-particularly challenging for inherently unstable humanoids. In this
work, we address this by formulating humanoid locomotion as a multi-objective
optimization problem that balances command tracking and external force
compliance. We introduce a preference-conditioned multi-objective RL (MORL)
framework that integrates rigid command following and compliant behaviors
within a single omnidirectional locomotion policy. External forces are modeled
via velocity-resistance factor for consistent reward design, and training
leverages an encoder-decoder structure that infers task-relevant privileged
features from deployable observations. We validate our approach in both
simulation and real-world experiments on a humanoid robot. Experimental results
indicate that our framework not only improves adaptability and convergence over
standard pipelines, but also realizes deployable preference-conditioned
humanoid locomotion.

</details>


### [44] [GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments](https://arxiv.org/abs/2510.10865)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: GRIP是一个用于机器人导航的统一模块化框架，包含三个变体：GRIP-L（轻量级）、GRIP-F（完整版）和GRIP-R（现实世界版），通过语义占据网格、多跳锚链和LLM自省等技术，在动态杂乱环境中实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在动态、杂乱和语义复杂环境中因依赖静态先验或有限内存而导致的适应性问题，特别是在部分可观测性和语义模糊性下的导航挑战。

Method: 集成动态2D网格构建、开放词汇对象接地、共现感知符号规划，以及使用行为克隆、D*搜索和网格条件控制的混合策略执行。

Result: 在AI2-THOR和RoboTHOR基准测试中，GRIP在长时程任务上实现了高达9.6%的成功率提升和超过2倍的路径效率改进（SPL和SAE）。

Conclusion: GRIP作为一个鲁棒、可扩展和可解释的框架，成功连接了仿真和现实世界导航，在传感器噪声和环境变化下展现出良好的泛化能力。

Abstract: Robots navigating dynamic, cluttered, and semantically complex environments
must integrate perception, symbolic reasoning, and spatial planning to
generalize across diverse layouts and object categories. Existing methods often
rely on static priors or limited memory, constraining adaptability under
partial observability and semantic ambiguity. We present GRIP, Grid-based Relay
with Intermediate Planning, a unified, modular framework with three scalable
variants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic
occupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and
LLM-based introspection; and GRIP-R (Real-World), enabling physical robot
deployment under perceptual uncertainty. GRIP integrates dynamic 2D grid
construction, open-vocabulary object grounding, co-occurrence-aware symbolic
planning, and hybrid policy execution using behavioral cloning, D* search, and
grid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks
show that GRIP achieves up to 9.6% higher success rates and over $2\times$
improvement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative
analyses reveal interpretable symbolic plans in ambiguous scenes. Real-world
deployment on a Jetbot further validates GRIP's generalization under sensor
noise and environmental variation. These results position GRIP as a robust,
scalable, and explainable framework bridging simulation and real-world
navigation.

</details>


### [45] [QuayPoints: A Reasoning Framework to Bridge the Information Gap Between Global and Local Planning in Autonomous Racing](https://arxiv.org/abs/2510.10886)
*Yashom Dighe,Youngjin Kim,Karthik Dantu*

Main category: cs.RO

TL;DR: 该论文提出了一种名为QuayPoints的框架，通过将全局规划器的时间最优性信息传递给局部规划器，帮助自动驾驶赛车在偏离最优赛道线时做出更明智的决策。


<details>
  <summary>Details</summary>
Motivation: 标准自动驾驶流水线中，全局规划器的优化信息在传递到局部规划器时被简化为稀疏的路径点，导致局部规划器在决策时缺乏足够的全局上下文，特别是在需要偏离最优赛道线进行超车等策略性操作时。

Method: 引入QuayPoints框架，识别并传递关键区域信息给局部规划器，这些区域是偏离最优赛道线会显著影响时间最优性的位置。

Result: 将QuayPoints集成到现有规划器中，在四个不同赛道上测试，能够持续超越以自我车辆速度75%行驶的对手。

Conclusion: QuayPoints框架有效保留了全局知识，使局部规划器能够在偏离最优赛道线时做出更明智的全局决策，提升了自动驾驶赛车的性能。

Abstract: Autonomous racing requires tight integration between perception, planning and
control to minimize latency as well as timely decision making. A standard
autonomy pipeline comprising a global planner, local planner, and controller
loses information as the higher-level racing context is sequentially propagated
downstream into specific task-oriented context. In particular, the global
planner's understanding of optimality is typically reduced to a sparse set of
waypoints, leaving the local planner to make reactive decisions with limited
context. This paper investigates whether additional global insights,
specifically time-optimality information, can be meaningfully passed to the
local planner to improve downstream decisions. We introduce a framework that
preserves essential global knowledge and conveys it to the local planner
through QuayPoints regions where deviations from the optimal raceline result in
significant compromises to optimality. QuayPoints enable local planners to make
more informed global decisions when deviating from the raceline, such as during
strategic overtaking. To demonstrate this, we integrate QuayPoints into an
existing planner and show that it consistently overtakes opponents traveling at
up to 75% of the ego vehicle's speed across four distinct race tracks.

</details>


### [46] [An Adaptive Transition Framework for Game-Theoretic Based Takeover](https://arxiv.org/abs/2510.10893)
*Dikshant Shehmar,Matthew E. Taylor,Ehsan Hashemi*

Main category: cs.RO

TL;DR: 提出基于驾驶员实时跟踪能力的自适应控制权转移策略，通过合作微分博弈建模共享控制，减少轨迹偏差和驾驶员控制负担。


<details>
  <summary>Details</summary>
Motivation: 现有固定时间转移策略无法适应驾驶员实时性能变化，OOTL情况降低驾驶员准备度并增加反应时间。

Method: 将共享控制建模为合作微分游戏，通过时变目标函数调节控制权，引入驾驶员特定状态跟踪矩阵，基于累积轨迹误差评估多种转移策略。

Result: 在ISO标准换道场景中，自适应转移相比传统策略减少轨迹偏差和驾驶员控制负担，实时调整控制权提高车辆稳定性。

Conclusion: 基于驾驶员实时跟踪能力的自适应控制权转移策略能更自然地完成接管，提高系统性能和驾驶员体验。

Abstract: The transition of control from autonomous systems to human drivers is
critical in automated driving systems, particularly due to the out-of-the-loop
(OOTL) circumstances that reduce driver readiness and increase reaction times.
Existing takeover strategies are based on fixed time-based transitions, which
fail to account for real-time driver performance variations. This paper
proposes an adaptive transition strategy that dynamically adjusts the control
authority based on both the time and tracking ability of the driver trajectory.
Shared control is modeled as a cooperative differential game, where control
authority is modulated through time-varying objective functions instead of
blending control torques directly. To ensure a more natural takeover, a
driver-specific state-tracking matrix is introduced, allowing the transition to
align with individual control preferences. Multiple transition strategies are
evaluated using a cumulative trajectory error metric. Human-in-the-loop control
scenarios of the standardized ISO lane change maneuvers demonstrate that
adaptive transitions reduce trajectory deviations and driver control effort
compared to conventional strategies. Experiments also confirm that continuously
adjusting control authority based on real-time deviations enhances vehicle
stability while reducing driver effort during takeover.

</details>


### [47] [Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey](https://arxiv.org/abs/2510.10903)
*Shuanghao Bai,Wenxuan Song,Jiayi Chen,Yuheng Ji,Zhide Zhong,Jin Yang,Han Zhao,Wanqi Zhou,Wei Zhao,Zhe Li,Pengxiang Ding,Cheng Chi,Haoang Li,Chang Xu,Xiaolong Zheng,Donglin Wang,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 这篇论文是关于机器人操作的综合综述，涵盖了背景知识、基准数据集、方法分类以及实际应用，提供了比以往调查更广的范围和更深的见解。


<details>
  <summary>Details</summary>
Motivation: 机器人操作是具身智能的核心挑战之一，需要将感知、规划和控制无缝集成，以在多样化和非结构化环境中实现交互。现有调查在范围和深度上存在不足，因此需要提供一个更全面和结构化的参考。

Method: 提出了一个统一的方法分类法，将高层规划扩展为语言、代码、运动、功能性和3D表示，同时基于训练范式（如输入建模、潜在学习和策略学习）引入了新的低层学习控制分类法。还首次提供了关键瓶颈的专门分类法，重点关注数据收集、利用和泛化。

Result: 提供了一个全面的机器人操作综述，包括基础背景、任务组织的基准和数据集、方法分类以及实际应用回顾。相比之前的调查，本工作提供了更广的范围和更深的见解。

Conclusion: 本调查为新手提供了易于理解的路线图，为有经验的研究人员提供了结构化参考。所有相关资源，包括研究论文、开源数据集和项目，都在GitHub上为社区整理。

Abstract: Embodied intelligence has witnessed remarkable progress in recent years,
driven by advances in computer vision, natural language processing, and the
rise of large-scale multimodal models. Among its core challenges, robot
manipulation stands out as a fundamental yet intricate problem, requiring the
seamless integration of perception, planning, and control to enable interaction
within diverse and unstructured environments. This survey presents a
comprehensive overview of robotic manipulation, encompassing foundational
background, task-organized benchmarks and datasets, and a unified taxonomy of
existing methods. We extend the classical division between high-level planning
and low-level control by broadening high-level planning to include language,
code, motion, affordance, and 3D representations, while introducing a new
taxonomy of low-level learning-based control grounded in training paradigms
such as input modeling, latent learning, and policy learning. Furthermore, we
provide the first dedicated taxonomy of key bottlenecks, focusing on data
collection, utilization, and generalization, and conclude with an extensive
review of real-world applications. Compared with prior surveys, our work offers
both a broader scope and deeper insight, serving as an accessible roadmap for
newcomers and a structured reference for experienced researchers. All related
resources, including research papers, open-source datasets, and projects, are
curated for the community at
https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation.

</details>


### [48] [More than A Point: Capturing Uncertainty with Adaptive Affordance Heatmaps for Spatial Grounding in Robotic Tasks](https://arxiv.org/abs/2510.10912)
*Xinyu Shao,Yanzhe Tang,Pengwei Xie,Kaiwen Zhou,Yuzheng Zhuang,Xingyue Quan,Jianye Hao,Long Zeng,Xiu Li*

Main category: cs.RO

TL;DR: RoboMAP是一个语言引导机器人框架，使用连续自适应affordance热图表示空间目标，解决了离散点表示对感知噪声和语义模糊的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现有语言引导机器人系统将空间推理简化为离散点表示，对感知噪声和语义模糊非常脆弱。需要更鲁棒的空间表示方法来提高任务成功率。

Method: 提出RoboMAP框架，使用连续自适应affordance热图来表示空间目标，这种密集表示能捕捉空间grounding的不确定性，为下游策略提供更丰富信息。

Result: 在大多数grounding基准测试中超越之前的最先进方法，速度提升高达50倍，真实世界操作任务成功率达到82%，在模拟和物理实验中表现出鲁棒性能，并具有强大的零样本导航泛化能力。

Conclusion: RoboMAP通过连续affordance热图表示显著提高了语言引导机器人系统的鲁棒性和性能，在多个基准测试和真实场景中展现出优越表现。

Abstract: Many language-guided robotic systems rely on collapsing spatial reasoning
into discrete points, making them brittle to perceptual noise and semantic
ambiguity. To address this challenge, we propose RoboMAP, a framework that
represents spatial targets as continuous, adaptive affordance heatmaps. This
dense representation captures the uncertainty in spatial grounding and provides
richer information for downstream policies, thereby significantly enhancing
task success and interpretability. RoboMAP surpasses the previous
state-of-the-art on a majority of grounding benchmarks with up to a 50x speed
improvement, and achieves an 82\% success rate in real-world manipulation.
Across extensive simulated and physical experiments, it demonstrates robust
performance and shows strong zero-shot generalization to navigation. More
details and videos can be found at https://robo-map.github.io.

</details>


### [49] [Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2510.10960)
*Dong Hu,Fenqing Hu,Lidong Yang,Chao Huang*

Main category: cs.RO

TL;DR: 提出了一种新颖的博弈论风险塑造强化学习框架GTR2L，用于解决自动驾驶在动态复杂交通环境中的安全问题，通过多级博弈论世界模型和自适应风险建模显著提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在自动驾驶中难以平衡安全性、效率和适应性，主要关注奖励最大化而缺乏明确的风险建模和安全约束，无法有效应对动态复杂交通环境中的意外风险。

Method: GTR2L框架包含：1）多级博弈论世界模型，联合预测周围车辆的交互行为和风险；2）基于预测不确定性的自适应滚动时域；3）不确定性感知屏障机制，灵活调节安全边界；4）专门的风险建模方法，显式捕捉认知和随机不确定性。

Result: 在多样化和安全关键交通场景中的广泛评估表明，GTR2L在成功率、碰撞和违规减少以及驾驶效率方面显著优于最先进的基线方法，包括人类驾驶员。

Conclusion: GTR2L框架通过结合博弈论、风险建模和自适应机制，有效解决了自动驾驶中的安全挑战，为复杂动态环境下的安全决策提供了有前景的解决方案。

Abstract: Ensuring safety in autonomous driving (AD) remains a significant challenge,
especially in highly dynamic and complex traffic environments where diverse
agents interact and unexpected hazards frequently emerge. Traditional
reinforcement learning (RL) methods often struggle to balance safety,
efficiency, and adaptability, as they primarily focus on reward maximization
without explicitly modeling risk or safety constraints. To address these
limitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L)
framework for safe AD. GTR2L incorporates a multi-level game-theoretic world
model that jointly predicts the interactive behaviors of surrounding vehicles
and their associated risks, along with an adaptive rollout horizon that adjusts
dynamically based on predictive uncertainty. Furthermore, an uncertainty-aware
barrier mechanism enables flexible modulation of safety boundaries. A dedicated
risk modeling approach is also proposed, explicitly capturing both epistemic
and aleatoric uncertainty to guide constrained policy optimization and enhance
decision-making in complex environments. Extensive evaluations across diverse
and safety-critical traffic scenarios show that GTR2L significantly outperforms
state-of-the-art baselines, including human drivers, in terms of success rate,
collision and violation reduction, and driving efficiency. The code is
available at https://github.com/DanielHu197/GTR2L.

</details>


### [50] [RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model](https://arxiv.org/abs/2510.10975)
*Mingtong Dai,Lingbo Liu,Yongjie Bai,Yang Liu,Zhouxia Wang,Rui SU,Chunjie Chen,Liang Lin,Xinyu Wu*

Main category: cs.RO

TL;DR: RoVer是一个无需修改模型架构或权重的测试时扩展框架，通过机器人过程奖励模型评估候选动作可靠性并指导动作空间探索，将计算资源转化为更好的决策能力。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型性能提升依赖大规模训练数据和模型扩展的问题，这种方法在机器人领域成本过高且受限于数据收集成本。

Method: 使用机器人过程奖励模型为候选动作分配标量过程奖励，预测动作空间方向进行扩展/优化；在推理时并行生成多个候选动作，沿PRM预测方向扩展，用PRM评分选择最优动作；通过缓存共享感知特征来分摊感知成本。

Result: 实现了测试时扩展的好处而无需额外训练开销，将可用计算资源转化为更好的动作决策能力。

Conclusion: RoVer提供了一个通用、即插即用的测试时扩展框架，通过联合提供标量过程奖励和动作空间方向的PRM，以及利用共享感知缓存的高效方向引导采样策略，实现了可扩展的候选生成和选择。

Abstract: Vision-Language-Action (VLA) models have become a prominent paradigm for
embodied intelligence, yet further performance improvements typically rely on
scaling up training data and model size -- an approach that is prohibitively
expensive for robotics and fundamentally limited by data collection costs.We
address this limitation with $\mathbf{RoVer}$, an embodied test-time scaling
framework that uses a $\mathbf{Ro}$bot Process Reward Model (PRM) as a
Test-Time $\mathbf{Ver}$ifier to enhance the capabilities of existing VLA
models without modifying their architectures or weights. Specifically, RoVer
(i) assigns scalar-based process rewards to evaluate the reliability of
candidate actions, and (ii) predicts an action-space direction for candidate
expansion/refinement. During inference, RoVer generates multiple candidate
actions concurrently from the base policy, expands them along PRM-predicted
directions, and then scores all candidates with PRM to select the optimal
action for execution. Notably, by caching shared perception features, it can
amortize perception cost and evaluate more candidates under the same test-time
computational budget. Essentially, our approach effectively transforms
available computing resources into better action decision-making, realizing the
benefits of test-time scaling without extra training overhead. Our
contributions are threefold: (1) a general, plug-and-play test-time scaling
framework for VLAs; (2) a PRM that jointly provides scalar process rewards and
an action-space direction to guide exploration; and (3) an efficient
direction-guided sampling strategy that leverages a shared perception cache to
enable scalable candidate generation and selection during inference.

</details>


### [51] [AMO-HEAD: Adaptive MARG-Only Heading Estimation for UAVs under Magnetic Disturbances](https://arxiv.org/abs/2510.10979)
*Qizhi Guo,Siyuan Yang,Junning Lyu,Jianjun Sun,Defu Lin,Shaoming He*

Main category: cs.RO

TL;DR: 提出AMO-HEAD方法，使用自适应EKF框架结合惯性传感器和磁传感器，在磁干扰环境下为无人机提供鲁棒的航向估计


<details>
  <summary>Details</summary>
Motivation: 室内环境中的磁干扰会显著降低无人机航向估计精度，需要开发能在磁干扰环境下可靠工作的航向估计算法

Method: 基于扩展卡尔曼滤波的轻量级框架，集成陀螺仪角速度测量传播四元数状态，使用加速度计和磁力计数据进行校正，引入自适应过程噪声协方差和磁偏差检测缩放因子

Result: 在真实室内环境中的实验表明，该方法在磁干扰条件下能提供精确的航向估计

Conclusion: AMO-HEAD方法有效解决了无人机在磁干扰环境下的航向估计问题，具有实际应用价值

Abstract: Accurate and robust heading estimation is crucial for unmanned aerial
vehicles (UAVs) when conducting indoor inspection tasks. However, the cluttered
nature of indoor environments often introduces severe magnetic disturbances,
which can significantly degrade heading accuracy. To address this challenge,
this paper presents an Adaptive MARG-Only Heading (AMO-HEAD) estimation
approach for UAVs operating in magnetically disturbed environments. AMO-HEAD is
a lightweight and computationally efficient Extended Kalman Filter (EKF)
framework that leverages inertial and magnetic sensors to achieve reliable
heading estimation. In the proposed approach, gyroscope angular rate
measurements are integrated to propagate the quaternion state, which is
subsequently corrected using accelerometer and magnetometer data. The corrected
quaternion is then used to compute the UAV's heading. An adaptive process noise
covariance method is introduced to model and compensate for gyroscope
measurement noise, bias drift, and discretization errors arising from the Euler
method integration. To mitigate the effects of external magnetic disturbances,
a scaling factor is applied based on real-time magnetic deviation detection. A
theoretical observability analysis of the proposed AMO-HEAD is performed using
the Lie derivative. Extensive experiments were conducted in real world indoor
environments with customized UAV platforms. The results demonstrate the
effectiveness of the proposed algorithm in providing precise heading estimation
under magnetically disturbed conditions.

</details>


### [52] [Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces](https://arxiv.org/abs/2510.11014)
*Subhransu S. Bhattacharjee,Hao Lu,Dylan Campbell,Rahul Shome*

Main category: cs.RO

TL;DR: 提出了一种基于采样的流程，利用大规模预训练生成模型为零样本规划提供概率先验，能够从部分观测中恢复完整的RGB-D点云样本，包含占据和目标语义信息。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测环境下规划需要先验知识，但实践中难以获取。生成模型能够提供捕捉环境不确定性和空间语义关系的概率先验。

Method: 基于采样的流程，利用预训练生成模型，从部分观测中恢复完整的RGB-D点云样本，包含占据和目标语义信息，可直接用于配置空间规划。

Result: 在Matterport3D基准测试中，该方法恢复了与真实情况一致的常识性空间语义，生成了多样化、干净的3D点云，可用于运动规划。

Conclusion: 生成模型作为机器人规划中丰富的先验知识来源具有很大潜力，能够有效处理未观测区域的占据和目标位置不确定性。

Abstract: Priors are vital for planning under partial observability, yet difficult to
obtain in practice. We present a sampling-based pipeline that leverages
large-scale pretrained generative models to produce probabilistic priors
capturing environmental uncertainty and spatio-semantic relationships in a
zero-shot manner. Conditioned on partial observations, the pipeline recovers
complete RGB-D point cloud samples with occupancy and target semantics,
formulated to be directly useful in configuration-space planning. We establish
a Matterport3D benchmark of rooms partially visible through doorways, where a
robot must navigate to an unobserved target object. Effective priors for this
setting must represent both occupancy and target-location uncertainty in
unobserved regions. Experiments show that our approach recovers commonsense
spatial semantics consistent with ground truth, yielding diverse, clean 3D
point clouds usable in motion planning, highlight the promise of generative
models as a rich source of priors for robotic planning.

</details>


### [53] [Refinery: Active Fine-tuning and Deployment-time Optimization for Contact-Rich Policies](https://arxiv.org/abs/2510.11019)
*Bingjie Tang,Iretiayo Akinola,Jie Xu,Bowen Wen,Dieter Fox,Gaurav S. Sukhatme,Fabio Ramos,Abhishek Gupta,Yashraj Narang*

Main category: cs.RO

TL;DR: Refinery框架通过贝叶斯优化微调策略和高斯混合模型采样，将机器人装配任务的模拟学习成功率从约80%提升到91.51%，并能成功串联策略完成8个零件的长时程装配。


<details>
  <summary>Details</summary>
Motivation: 模拟学习的策略在接触密集型任务中成功率约80%，但无法满足工业标准且策略串联非常脆弱，主要限制在于不同初始条件下策略性能的高方差。

Method: 提出Refinery框架：1）使用贝叶斯优化指导策略微调；2）部署时使用高斯混合模型采样选择最大化执行成功率的初始化条件。

Result: 在机器人装配任务的模拟学习中，比最先进方法平均成功率提高10.98%，达到91.51%的模拟成功率，并在真实世界中表现相当；能成功串联策略完成8个零件的多部件装配。

Conclusion: Refinery框架有效弥补了模拟学习与工业标准之间的性能差距，提高了策略在不同初始条件下的鲁棒性，并支持无需显式多步训练的长时程策略串联。

Abstract: Simulation-based learning has enabled policies for precise, contact-rich
tasks (e.g., robotic assembly) to reach high success rates (~80%) under high
levels of observation noise and control error. Although such performance may be
sufficient for research applications, it falls short of industry standards and
makes policy chaining exceptionally brittle. A key limitation is the high
variance in individual policy performance across diverse initial conditions. We
introduce Refinery, an effective framework that bridges this performance gap,
robustifying policy performance across initial conditions. We propose Bayesian
Optimization-guided fine-tuning to improve individual policies, and Gaussian
Mixture Model-based sampling during deployment to select initializations that
maximize execution success. Using Refinery, we improve mean success rates by
10.98% over state-of-the-art methods in simulation-based learning for robotic
assembly, reaching 91.51% in simulation and comparable performance in the real
world. Furthermore, we demonstrate that these fine-tuned policies can be
chained to accomplish long-horizon, multi-part
assembly$\unicode{x2013}$successfully assembling up to 8 parts without
requiring explicit multi-step training.

</details>


### [54] [XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation](https://arxiv.org/abs/2510.11036)
*Yeonseo Lee,Jungwook Mun,Hyosup Shin,Guebin Hwang,Junhee Nam,Taeyeop Lee,Sungho Jo*

Main category: cs.RO

TL;DR: XGrasp是一个实时抓取检测框架，能够处理多种夹爪配置，通过两阶段架构和对比学习实现零样本泛化到未见过的夹爪。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法通常只针对单一夹爪类型设计，限制了在需要多样化末端执行器的实际场景中的适用性。

Method: 采用分层两阶段架构：第一阶段使用抓取点预测器识别最佳抓取位置，第二阶段使用角度-宽度预测器细化抓取参数，并通过对比学习实现零样本泛化。

Result: 实验结果显示在各种夹爪类型上具有竞争力的抓取成功率，同时相比现有方法在推理速度上有显著提升。

Conclusion: XGrasp提供了一个模块化框架，能够有效处理多种夹爪配置，并为未来视觉-语言能力集成提供了途径。

Abstract: Most robotic grasping methods are typically designed for single gripper
types, which limits their applicability in real-world scenarios requiring
diverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp
detection framework that efficiently handles multiple gripper configurations.
The proposed method addresses data scarcity by systematically augmenting
existing datasets with multi-gripper annotations. XGrasp employs a hierarchical
two-stage architecture. In the first stage, a Grasp Point Predictor (GPP)
identifies optimal locations using global scene information and gripper
specifications. In the second stage, an Angle-Width Predictor (AWP) refines the
grasp angle and width using local features. Contrastive learning in the AWP
module enables zero-shot generalization to unseen grippers by learning
fundamental grasping characteristics. The modular framework integrates
seamlessly with vision foundation models, providing pathways for future
vision-language capabilities. The experimental results demonstrate competitive
grasp success rates across various gripper types, while achieving substantial
improvements in inference speed compared to existing gripper-aware methods.
Project page: https://sites.google.com/view/xgrasp

</details>


### [55] [Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy](https://arxiv.org/abs/2510.11041)
*Shiyao Zhang,Liwei Deng,Shuyu Zhang,Weijie Yuan,Hong Zhang*

Main category: cs.RO

TL;DR: 提出基于深度强化学习的自主协同规划框架，解决多车辆交互中的感知、规划和通信不确定性，使用SAC算法和GRU网络学习最优时变动作，在CARLA仿真中验证性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有自主协同规划策略无法充分处理感知、规划和通信等多种不确定性，需要开发更有效的解决方案来提高多车辆交互的效率和安全性。

Method: 采用软演员-评论家算法结合门控循环单元，学习在规划、通信和感知不确定性下具有不完美状态信息的最优时变动作，在CARLA仿真平台验证实时动作。

Result: 提出的DRLACP框架能够有效学习和执行协同规划，在不同场景下具有不完美自动驾驶车辆状态信息时，性能优于其他基线方法。

Conclusion: 基于深度强化学习的自主协同规划框架成功解决了多车辆交互中的多种不确定性问题，为智能交通系统提供了有效的协同运动规划方案。

Abstract: In future intelligent transportation systems, autonomous cooperative planning
(ACP), becomes a promising technique to increase the effectiveness and security
of multi-vehicle interactions. However, multiple uncertainties cannot be fully
addressed for existing ACP strategies, e.g. perception, planning, and
communication uncertainties. To address these, a novel deep reinforcement
learning-based autonomous cooperative planning (DRLACP) framework is proposed
to tackle various uncertainties on cooperative motion planning schemes.
Specifically, the soft actor-critic (SAC) with the implementation of gate
recurrent units (GRUs) is adopted to learn the deterministic optimal
time-varying actions with imperfect state information occurred by planning,
communication, and perception uncertainties. In addition, the real-time actions
of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act
(CARLA) simulation platform. Evaluation results show that the proposed DRLACP
learns and performs cooperative planning effectively, which outperforms other
baseline methods under different scenarios with imperfect AV state information.

</details>


### [56] [PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System](https://arxiv.org/abs/2510.11072)
*Huayi Wang,Wentao Zhang,Runyi Yu,Tao Huang,Junli Ren,Feiyu Jia,Zirui Wang,Xiaojie Niu,Xiao Chen,Jiahe Chen,Qifeng Chen,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: PhysHSI是一个物理世界人形机器人-场景交互系统，通过仿真训练和现实部署实现自然的人形机器人交互行为。


<details>
  <summary>Details</summary>
Motivation: 将人形机器人部署到现实环境中进行物体搬运、坐椅子等交互任务，需要可泛化的自然动作和鲁棒的场景感知能力，但现有方法难以统一这些能力。

Method: 采用仿真训练管道和现实部署系统：仿真中使用基于对抗运动先验的策略学习来模仿自然的人形-场景交互数据；现实部署中引入粗到细的物体定位模块，结合LiDAR和相机输入。

Result: 在四个代表性交互任务（搬运箱子、坐下、躺下、站起）中，仿真和现实环境均表现出高成功率、强泛化能力和自然运动模式。

Conclusion: PhysHSI系统成功实现了人形机器人在物理世界中的自主交互任务，展示了自然行为和鲁棒场景感知的统一能力。

Abstract: Deploying humanoid robots to interact with real-world environments--such as
carrying objects or sitting on chairs--requires generalizable, lifelike motions
and robust scene perception. Although prior approaches have advanced each
capability individually, combining them in a unified system is still an ongoing
challenge. In this work, we present a physical-world humanoid-scene interaction
system, PhysHSI, that enables humanoids to autonomously perform diverse
interaction tasks while maintaining natural and lifelike behaviors. PhysHSI
comprises a simulation training pipeline and a real-world deployment system. In
simulation, we adopt adversarial motion prior-based policy learning to imitate
natural humanoid-scene interaction data across diverse scenarios, achieving
both generalization and lifelike behaviors. For real-world deployment, we
introduce a coarse-to-fine object localization module that combines LiDAR and
camera inputs to provide continuous and robust scene perception. We validate
PhysHSI on four representative interactive tasks--box carrying, sitting, lying,
and standing up--in both simulation and real-world settings, demonstrating
consistently high success rates, strong generalization across diverse task
goals, and natural motion patterns.

</details>


### [57] [Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling](https://arxiv.org/abs/2510.11083)
*Tianyi Tan,Yinan Zheng,Ruiming Liang,Zexu Wang,Kexin Zheng,Jinliang Zheng,Jianxiong Li,Xianyuan Zhan,Jingjing Liu*

Main category: cs.RO

TL;DR: Flow Planner是一个用于自动驾驶规划的模型，通过轨迹标记化、时空融合架构和流匹配技术，有效解决复杂交互驾驶行为建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的自动驾驶规划方法在建模复杂交互行为方面存在不足，简单堆叠Transformer块缺乏专门的交互建模机制，且交互驾驶数据稀缺导致模仿学习方法难以捕捉高价值交互行为。

Method: 1）细粒度轨迹标记化，将轨迹分解为重叠段以降低建模复杂度；2）精心设计的架构实现规划与场景信息的时空高效融合；3）结合流匹配和无分类器引导的多模态行为生成，在推理时动态重加权智能体交互。

Result: 在大规模nuPlan数据集和具有挑战性的interPlan数据集上，Flow Planner在基于学习的方法中达到了最先进的性能，并能有效建模复杂驾驶场景中的交互行为。

Conclusion: Flow Planner通过数据建模、模型架构和学习方案的协同创新，成功解决了自动驾驶规划中复杂交互行为建模的挑战，为交互场景理解提供了关键提升。

Abstract: Modeling interactive driving behaviors in complex scenarios remains a
fundamental challenge for autonomous driving planning. Learning-based
approaches attempt to address this challenge with advanced generative models,
removing the dependency on over-engineered architectures for representation
fusion. However, brute-force implementation by simply stacking transformer
blocks lacks a dedicated mechanism for modeling interactive behaviors that are
common in real driving scenarios. The scarcity of interactive driving data
further exacerbates this problem, leaving conventional imitation learning
methods ill-equipped to capture high-value interactive behaviors. We propose
Flow Planner, which tackles these problems through coordinated innovations in
data modeling, model architecture, and learning scheme. Specifically, we first
introduce fine-grained trajectory tokenization, which decomposes the trajectory
into overlapping segments to decrease the complexity of whole trajectory
modeling. With a sophisticatedly designed architecture, we achieve efficient
temporal and spatial fusion of planning and scene information, to better
capture interactive behaviors. In addition, the framework incorporates flow
matching with classifier-free guidance for multi-modal behavior generation,
which dynamically reweights agent interactions during inference to maintain
coherent response strategies, providing a critical boost for interactive
scenario understanding. Experimental results on the large-scale nuPlan dataset
and challenging interactive interPlan dataset demonstrate that Flow Planner
achieves state-of-the-art performance among learning-based approaches while
effectively modeling interactive behaviors in complex driving scenarios.

</details>


### [58] [Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami-Inspired Pneumatic Actuator for Knee Rehabilitation](https://arxiv.org/abs/2510.11094)
*Junxiang Wang,Han Zhang,Zehao Wang,Huaiyuan Chen,Pu Wang,Weidong Chen*

Main category: cs.RO

TL;DR: 基于折纸启发的气动执行器设计软体外骨骼，使用深度Koopman网络建模人机交互动力学，结合模型预测控制实现膝关节康复训练，相比传统PID控制表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统刚性外骨骼笨重且穿戴不便，需要额外合规控制保证安全；软体外骨骼穿戴舒适且具有内在合规性，但其复杂非线性人机交互动力学给控制带来挑战。

Method: 设计基于折纸气动执行器的膝关节康复外骨骼，使用深度Koopman网络建模人机交互动力学（输入为EMG信号和PWM占空比），并基于Koopman模型采用模型预测控制进行实时康复训练。

Result: 集成EMG信号的Koopman模型显著提高了模型精度，个性化模型优于非个性化模型，控制框架在被动和主动训练模式下均优于传统PID控制。

Conclusion: 该方法为软康复机器人提供了新的控制框架，结合EMG信号和个性化建模能有效提升康复训练效果。

Abstract: Effective rehabilitation methods are essential for the recovery of lower limb
dysfunction caused by stroke. Nowadays, robotic exoskeletons have shown great
potentials in rehabilitation. Nevertheless, traditional rigid exoskeletons are
usually heavy and need a lot of work to help the patients to put them on.
Moreover, it also requires extra compliance control to guarantee the safety. In
contrast, soft exoskeletons are easy and comfortable to wear and have intrinsic
compliance, but their complex nonlinear human-robot interaction dynamics would
pose significant challenges for control. In this work, based on the pneumatic
actuators inspired by origami, we design a rehabilitation exoskeleton for knee
that is easy and comfortable to wear. To guarantee the control performance and
enable a nice human-robot interaction, we first use Deep Koopman Network to
model the human-robot interaction dynamics. In particular, by viewing the
electromyography (EMG) signals and the duty cycle of the PWM wave that controls
the pneumatic robot's valves and pump as the inputs, the linear Koopman model
accurately captures the complex human-robot interaction dynamics. Next, based
on the obtained Koopman model, we further use Model Predictive Control (MPC) to
control the soft robot and help the user to do rehabilitation training in
real-time. The goal of the rehabilitation training is to track a given
reference signal shown on the screen. Experiments show that by integrating the
EMG signals into the Koopman model, we have improved the model accuracy to
great extent. In addition, a personalized Koopman model trained from the
individual's own data performs better than the non-personalized model.
Consequently, our control framework outperforms the traditional PID control in
both passive and active training modes. Hence the proposed method provides a
new control framework for soft rehabilitation robots.

</details>


### [59] [A Primer on SO(3) Action Representations in Deep Reinforcement Learning](https://arxiv.org/abs/2510.11103)
*Martin Schuck,Sherif Samy,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文系统评估了SO(3)旋转表示在强化学习中的表现，发现局部切空间表示在多种算法中表现最稳定可靠。


<details>
  <summary>Details</summary>
Motivation: 机器人控制任务需要处理SO(3)旋转，但SO(3)没有全局平滑的最小参数化，不同表示方法各有优缺点，其在强化学习中的影响尚不明确。

Method: 在三种连续控制算法(PPO、SAC、TD3)下，系统评估了欧拉角、四元数、旋转矩阵和李代数坐标等SO(3)表示方法，比较了它们在密集和稀疏奖励下的表现。

Result: 表示方法引入的几何特性显著影响探索和优化过程，局部切空间表示在各种算法中表现最稳定可靠。

Conclusion: 提出了简单实用的旋转动作选择和使用指南，强调表示诱导的几何特性对强化学习性能有重要影响。

Abstract: Many robotic control tasks require policies to act on orientations, yet the
geometry of SO(3) makes this nontrivial. Because SO(3) admits no global,
smooth, minimal parameterization, common representations such as Euler angles,
quaternions, rotation matrices, and Lie algebra coordinates introduce distinct
constraints and failure modes. While these trade-offs are well studied for
supervised learning, their implications for actions in reinforcement learning
remain unclear. We systematically evaluate SO(3) action representations across
three standard continuous control algorithms, PPO, SAC, and TD3, under dense
and sparse rewards. We compare how representations shape exploration, interact
with entropy regularization, and affect training stability through empirical
studies and analyze the implications of different projections for obtaining
valid rotations from Euclidean network outputs. Across a suite of robotics
benchmarks, we quantify the practical impact of these choices and distill
simple, implementation-ready guidelines for selecting and using rotation
actions. Our results highlight that representation-induced geometry strongly
influences exploration and optimization and show that representing actions as
tangent vectors in the local frame yields the most reliable results across
algorithms.

</details>


### [60] [DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation](https://arxiv.org/abs/2510.11258)
*Yuhui Fu,Feiyang Xie,Chaoyi Xu,Jing Xiong,Haoqi Yuan,Zongqing Lu*

Main category: cs.RO

TL;DR: DemoHLM框架通过分层架构实现人形机器人的移动操作，结合底层全身控制器和基于视觉反馈的高层操作策略，能够从单个仿真演示中学习并在真实机器人上实现泛化。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人的移动操作研究不足，通常依赖硬编码任务定义或昂贵的真实世界数据收集，限制了自主性和泛化能力。

Method: 采用分层架构：底层通用全身控制器提供全方位移动能力，高层操作策略通过仿真数据生成和模仿学习获得，利用闭环视觉反馈控制全身控制器。

Result: 实验显示合成数据量与策略性能呈正相关，在Unitree G1机器人上的真实实验验证了框架的仿真到现实迁移能力，在10个移动操作任务中表现出鲁棒性能。

Conclusion: DemoHLM框架能够从单个仿真演示中学习人形机器人的移动操作，并成功迁移到真实机器人，展示了数据效率和泛化能力。

Abstract: Loco-manipulation is a fundamental challenge for humanoid robots to achieve
versatile interactions in human environments. Although recent studies have made
significant progress in humanoid whole-body control, loco-manipulation remains
underexplored and often relies on hard-coded task definitions or costly
real-world data collection, which limits autonomy and generalization. We
present DemoHLM, a framework for humanoid loco-manipulation that enables
generalizable loco-manipulation on a real humanoid robot from a single
demonstration in simulation. DemoHLM adopts a hierarchy that integrates a
low-level universal whole-body controller with high-level manipulation policies
for multiple tasks. The whole-body controller maps whole-body motion commands
to joint torques and provides omnidirectional mobility for the humanoid robot.
The manipulation policies, learned in simulation via our data generation and
imitation learning pipeline, command the whole-body controller with closed-loop
visual feedback to execute challenging loco-manipulation tasks. Experiments
show a positive correlation between the amount of synthetic data and policy
performance, underscoring the effectiveness of our data generation pipeline and
the data efficiency of our approach. Real-world experiments on a Unitree G1
robot equipped with an RGB-D camera validate the sim-to-real transferability of
DemoHLM, demonstrating robust performance under spatial variations across ten
loco-manipulation tasks.

</details>


### [61] [Rotor-Failure-Aware Quadrotors Flight in Unknown Environments](https://arxiv.org/abs/2510.11306)
*Xiaobin Zhou,Miao Wang,Chengao Li,Can Cui,Ruibin Zhang,Yongchao Wang,Chao Xu,Fei Gao*

Main category: cs.RO

TL;DR: 提出了一种转子故障感知的四旋翼导航系统，通过快速故障检测与诊断、非线性模型预测控制和时空联合优化规划，实现了在未知复杂环境中转子故障下的自主飞行。


<details>
  <summary>Details</summary>
Motivation: 四旋翼转子故障会导致高速旋转和振动，给未知环境中的自主飞行带来重大挑战。现有方法主要依赖容错控制和预定义轨迹跟踪，尚未实现在未知复杂环境中的在线故障检测诊断、轨迹规划和容错控制。

Method: 1. 基于复合故障检测诊断的非线性模型预测控制器，结合电机动力学确保快速故障检测和飞行稳定性；2. 转子故障感知规划器，利用故障检测诊断结果进行时空联合优化；3. 配备四个抗扭矩板的激光雷达四旋翼平台，确保高速旋转下的可靠感知。

Result: 与最先进方法的广泛基准测试表明，该方法在处理转子故障（包括螺旋桨卸载和电机停机）方面具有优越性能。实验首次证明该方法能够在杂乱房间和未知森林等挑战性环境中实现转子故障下的自主四旋翼飞行。

Conclusion: 该研究首次实现了在未知复杂环境中转子故障四旋翼的在线故障检测诊断、轨迹规划和容错控制，为故障情况下的自主飞行提供了完整解决方案。

Abstract: Rotor failures in quadrotors may result in high-speed rotation and vibration
due to rotor imbalance, which introduces significant challenges for autonomous
flight in unknown environments. The mainstream approaches against rotor
failures rely on fault-tolerant control (FTC) and predefined trajectory
tracking. To the best of our knowledge, online failure detection and diagnosis
(FDD), trajectory planning, and FTC of the post-failure quadrotors in unknown
and complex environments have not yet been achieved. This paper presents a
rotor-failure-aware quadrotor navigation system designed to mitigate the
impacts of rotor imbalance. First, a composite FDD-based nonlinear model
predictive controller (NMPC), incorporating motor dynamics, is designed to
ensure fast failure detection and flight stability. Second, a
rotor-failure-aware planner is designed to leverage FDD results and
spatial-temporal joint optimization, while a LiDAR-based quadrotor platform
with four anti-torque plates is designed to enable reliable perception under
high-speed rotation. Lastly, extensive benchmarks against state-of-the-art
methods highlight the superior performance of the proposed approach in
addressing rotor failures, including propeller unloading and motor stoppage.
The experimental results demonstrate, for the first time, that our approach
enables autonomous quadrotor flight with rotor failures in challenging
environments, including cluttered rooms and unknown forests.

</details>


### [62] [Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments](https://arxiv.org/abs/2510.11308)
*Weixi Situ,Hanjing Ye,Jianwei Peng,Yu Zhan,Hong Zhang*

Main category: cs.RO

TL;DR: 提出了一种自适应轨迹采样方法，结合预测感知的MPPI控制器，解决机器人跟随中复杂遮挡问题，在平滑性、安全性、鲁棒性和人机舒适度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人跟随在动态拥挤环境中因频繁遮挡导致的挑战，现有方法依赖固定点跟随或稀疏候选点选择，无法充分处理移动障碍物造成的复杂遮挡。

Method: 在社交感知区域内生成密集候选点，使用多目标成本函数评估，基于最优点估计相对于目标预测运动的跟随轨迹，并设计预测感知的MPPI控制器同时跟踪轨迹和主动避障。

Result: 在平滑性、安全性、鲁棒性和人机舒适度方面优于最先进的基线方法，并在真实移动机器人场景中验证了有效性。

Conclusion: 该方法能够有效处理复杂遮挡问题，提升机器人跟随性能，在真实环境中具有实用价值。

Abstract: Robot person following (RPF) is a core capability in human-robot interaction,
enabling robots to assist users in daily activities, collaborative work, and
other service scenarios. However, achieving practical RPF remains challenging
due to frequent occlusions, particularly in dynamic and crowded environments.
Existing approaches often rely on fixed-point following or sparse
candidate-point selection with oversimplified heuristics, which cannot
adequately handle complex occlusions caused by moving obstacles such as
pedestrians. To address these limitations, we propose an adaptive trajectory
sampling method that generates dense candidate points within socially aware
zones and evaluates them using a multi-objective cost function. Based on the
optimal point, a person-following trajectory is estimated relative to the
predicted motion of the target. We further design a prediction-aware model
predictive path integral (MPPI) controller that simultaneously tracks this
trajectory and proactively avoids collisions using predicted pedestrian
motions. Extensive experiments show that our method outperforms
state-of-the-art baselines in smoothness, safety, robustness, and human
comfort, with its effectiveness further demonstrated on a mobile robot in
real-world scenarios.

</details>


### [63] [HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data](https://arxiv.org/abs/2510.11321)
*Ruizhe Liu,Pei Zhou,Qian Luo,Li Sun,Jun Cen,Yibing Song,Yanchao Yang*

Main category: cs.RO

TL;DR: 提出了一种自监督的层次化操作概念学习框架，通过跨模态关联和多时间尺度抽象来捕捉操作中的不变模式，无需人工标注即可学习可迁移的操作概念。


<details>
  <summary>Details</summary>
Motivation: 机器人操作需要能够捕捉环境和任务间不变交互模式的表征，以实现有效的泛化能力。

Method: 结合跨模态关联网络识别跨感官模态的持久模式，以及多时间尺度预测器在时间尺度上层次化组织表征。

Result: 在仿真基准和真实世界部署中，概念增强的策略表现出显著性能提升，学习到的概念类似于人类可解释的操作基元。

Conclusion: 该工作推进了操作表征学习的理解，并为增强机器人在复杂场景中的性能提供了实用方法。

Abstract: Effective generalization in robotic manipulation requires representations
that capture invariant patterns of interaction across environments and tasks.
We present a self-supervised framework for learning hierarchical manipulation
concepts that encode these invariant patterns through cross-modal sensory
correlations and multi-level temporal abstractions without requiring human
annotation. Our approach combines a cross-modal correlation network that
identifies persistent patterns across sensory modalities with a multi-horizon
predictor that organizes representations hierarchically across temporal scales.
Manipulation concepts learned through this dual structure enable policies to
focus on transferable relational patterns while maintaining awareness of both
immediate actions and longer-term goals. Empirical evaluation across simulated
benchmarks and real-world deployments demonstrates significant performance
improvements with our concept-enhanced policies. Analysis reveals that the
learned concepts resemble human-interpretable manipulation primitives despite
receiving no semantic supervision. This work advances both the understanding of
representation learning for manipulation and provides a practical approach to
enhancing robotic performance in complex scenarios.

</details>


### [64] [Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots](https://arxiv.org/abs/2510.11401)
*Jiayang Wu,Jiongye Li,Shibowen Zhang,Zhicheng He,Zaijin Wang,Xiaokun Leng,Hangxin Liu,Jingwen Zhang,Jiayi Wang,Song-Chun Zhu,Yao Su*

Main category: cs.RO

TL;DR: 提出了一种人形机器人检查任务框架，结合分层规划、时间最优站位生成和集成MPC，实现高效率、毫米级精度的工业操作。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在复杂工业环境中执行检查任务时面临的高维规划计算复杂性和精度控制挑战。

Method: 采用分层规划策略（IK和MIP）、时间最优站位选择的MIP公式、以及带简化运动学和单步位置校正的MPC系统。

Result: 在Kuavo 4Pro平台上验证，显示低时间成本和高成功率，能够高效精确执行多位置工业任务。

Conclusion: 该框架成功实现了人形机器人在工业检查任务中的高效率毫米级精度操作，为复杂工业应用提供了可行解决方案。

Abstract: This paper proposes a novel framework for humanoid robots to execute
inspection tasks with high efficiency and millimeter-level precision. The
approach combines hierarchical planning, time-optimal standing position
generation, and integrated \ac{mpc} to achieve high speed and precision. A
hierarchical planning strategy, leveraging \ac{ik} and \ac{mip}, reduces
computational complexity by decoupling the high-dimensional planning problem. A
novel MIP formulation optimizes standing position selection and trajectory
length, minimizing task completion time. Furthermore, an MPC system with
simplified kinematics and single-step position correction ensures
millimeter-level end-effector tracking accuracy. Validated through simulations
and experiments on the Kuavo 4Pro humanoid platform, the framework demonstrates
low time cost and a high success rate in multi-location tasks, enabling
efficient and precise execution of complex industrial operations.

</details>


### [65] [A Modular AIoT Framework for Low-Latency Real-Time Robotic Teleoperation in Smart Cities](https://arxiv.org/abs/2510.11421)
*Shih-Chieh Sun,Yun-Cheng Tsai*

Main category: cs.RO

TL;DR: 本文提出了一种AI驱动的物联网机器人遥操作系统，用于智能城市应用中的实时远程操作和智能视觉监控，采用Flutter移动界面、MQTT控制和WebRTC视频流，实现低延迟响应。


<details>
  <summary>Details</summary>
Motivation: 为智能城市场景（如远程基础设施检查、公共设备维护）开发一个模块化、实时AI感知和适应性通信的遥操作系统，克服传统平台的局限性。

Method: 集成Flutter跨平台移动界面、MQTT控制信号传输、WebRTC视频流（通过LiveKit框架），部署YOLOv11-nano模型进行轻量级目标检测，使用ESP8266执行器和Arduino Mega2560控制器协调多轴机械臂运动，后端托管在DigitalOcean上。

Result: 在本地和国际VPN场景（香港、日本、比利时）下，执行器响应时间低至0.2秒，总视频延迟低于1.2秒，即使在高速延迟网络中也能保持低延迟双协议设计的响应闭环交互和稳健性能。

Conclusion: 该系统在分布式环境中表现出模块化部署、实时AI感知和适应性通信策略的优势，适用于智能城市应用。未来将专注于边缘设备部署、自适应路由和与城市级物联网网络的集成，以增强弹性和可扩展性。

Abstract: This paper presents an AI-driven IoT robotic teleoperation system designed
for real-time remote manipulation and intelligent visual monitoring, tailored
for smart city applications. The architecture integrates a Flutter-based
cross-platform mobile interface with MQTT-based control signaling and WebRTC
video streaming via the LiveKit framework. A YOLOv11-nano model is deployed for
lightweight object detection, enabling real-time perception with annotated
visual overlays delivered to the user interface. Control commands are
transmitted via MQTT to an ESP8266-based actuator node, which coordinates
multi-axis robotic arm motion through an Arduino Mega2560 controller. The
backend infrastructure is hosted on DigitalOcean, ensuring scalable cloud
orchestration and stable global communication. Latency evaluations conducted
under both local and international VPN scenarios (including Hong Kong, Japan,
and Belgium) demonstrate actuator response times as low as 0.2 seconds and
total video latency under 1.2 seconds, even across high-latency networks. This
low-latency dual-protocol design ensures responsive closed-loop interaction and
robust performance in distributed environments. Unlike conventional
teleoperation platforms, the proposed system emphasizes modular deployment,
real-time AI sensing, and adaptable communication strategies, making it
well-suited for smart city scenarios such as remote infrastructure inspection,
public equipment servicing, and urban automation. Future enhancements will
focus on edge-device deployment, adaptive routing, and integration with
city-scale IoT networks to enhance resilience and scalability.

</details>


### [66] [A Faster and More Reliable Middleware for Autonomous Driving Systems](https://arxiv.org/abs/2510.11448)
*Yuankai He,Hanlin Chen,Weisong Shi*

Main category: cs.RO

TL;DR: SIM是一种用于自动驾驶车辆内部通信的共享内存传输方案，通过在ROS 2旁边运行，显著降低了数据传输延迟，提高了控制频率，缩短了紧急制动距离。


<details>
  <summary>Details</summary>
Motivation: 高速自动驾驶车辆需要快速控制循环和严格受限的感知到执行延迟。ROS 2及其DDS传输在共享计算单元时引入显著的序列化、复制和发现开销，缩小了可用时间预算。

Method: 设计Sensor-in-Memory (SIM)共享内存传输，保持传感器数据的原生内存布局，使用无锁有界双缓冲区优先保证数据新鲜度，仅需四行代码即可集成到ROS 2节点中。

Result: 在NVIDIA Jetson Orin Nano上，SIM相比ROS 2零拷贝传输降低延迟达98%，平均延迟降低约95%，尾部延迟降低约96%。在Level 4车辆测试中，定位频率从7.5 Hz提升至9.5 Hz，感知到决策平均延迟从521.91 ms降至290.26 ms，40 mph时紧急制动距离减少4.14米。

Conclusion: SIM为自动驾驶车辆提供了一种高效的数据传输方案，在数据新鲜度和低延迟优先于保证完整性的场景下表现优异，显著提升了系统性能和安全性能。

Abstract: Ensuring safety in high-speed autonomous vehicles requires rapid control
loops and tightly bounded delays from perception to actuation. Many open-source
autonomy systems rely on ROS 2 middleware; when multiple sensor and control
nodes share one compute unit, ROS 2 and its DDS transports add significant
(de)serialization, copying, and discovery overheads, shrinking the available
time budget. We present Sensor-in-Memory (SIM), a shared-memory transport
designed for intra-host pipelines in autonomous vehicles. SIM keeps sensor data
in native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double
buffers that overwrite old data to prioritize freshness, and integrates into
ROS 2 nodes with four lines of code. Unlike traditional middleware, SIM
operates beside ROS 2 and is optimized for applications where data freshness
and minimal latency outweigh guaranteed completeness. SIM provides sequence
numbers, a writer heartbeat, and optional checksums to ensure ordering,
liveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces
data-transport latency by up to 98% compared to ROS 2 zero-copy transports such
as FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows
95th/99th-percentile tail latencies by around 96%. In tests on a
production-ready Level 4 vehicle running Autoware.Universe, SIM increased
localization frequency from 7.5 Hz to 9.5 Hz. Applied across all
latency-critical modules, SIM cut average perception-to-decision latency from
521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h)
on dry concrete by 13.6 ft (4.14 m).

</details>


### [67] [Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.11474)
*Ardian Selmonaj,Giacomo Del Rio,Adrian Schneider,Alessandro Antonucci*

Main category: cs.RO

TL;DR: 提出了一种分层多智能体强化学习框架，用于解决3D空战环境中的任务目标达成问题，通过分层决策和多种训练技术提升学习效率和战斗性能。


<details>
  <summary>Details</summary>
Motivation: 由于不完全态势感知和非线性飞行动力学，在真实空战模拟中实现任务目标极具挑战性。

Method: 结合异构智能体动力学、课程学习、联盟博弈和新适应的训练算法，将决策过程组织为两个抽象层次：低层策略学习精确控制机动，高层策略基于任务目标发出战术指令。

Result: 实证结果表明，该分层方法在复杂空战场景中提高了学习效率和战斗性能。

Conclusion: 分层多智能体强化学习框架有效解决了复杂空战环境中的挑战，提升了智能体的决策能力和任务执行效果。

Abstract: Achieving mission objectives in a realistic simulation of aerial combat is
highly challenging due to imperfect situational awareness and nonlinear flight
dynamics. In this work, we introduce a novel 3D multi-agent air combat
environment and a Hierarchical Multi-Agent Reinforcement Learning framework to
tackle these challenges. Our approach combines heterogeneous agent dynamics,
curriculum learning, league-play, and a newly adapted training algorithm. To
this end, the decision-making process is organized into two abstraction levels:
low-level policies learn precise control maneuvers, while high-level policies
issue tactical commands based on mission objectives. Empirical results show
that our hierarchical approach improves both learning efficiency and combat
performance in complex dogfight scenarios.

</details>


### [68] [Constraint-Aware Reinforcement Learning via Adaptive Action Scaling](https://arxiv.org/abs/2510.11491)
*Murad Dawood,Usama Ahmed Siddiquie,Shahram Khorshidi,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出了一种模块化的成本感知调节器，通过预测约束违规来缩放智能体动作，保持探索性而非覆盖策略，在安全强化学习中实现了最先进的回报-成本比。


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法要么使用单一策略联合优化奖励和安全性，导致目标冲突不稳定；要么使用需要先验系统知识的外部安全过滤器覆盖动作，限制了探索能力。

Method: 开发模块化成本感知调节器，基于预测的约束违规来平滑缩放智能体动作，避免动作退化抑制，与SAC、TD3等离策略RL方法无缝集成。

Result: 在Safety Gym运动任务上实现了最先进的回报-成本比，约束违规减少高达126倍，同时回报提高超过一个数量级。

Conclusion: 模块化调节器方法通过平滑动作调制而非动作覆盖，有效解决了安全强化学习中探索与安全的平衡问题，显著提升了性能。

Abstract: Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that
arise from exploration during training by reducing constraint violations while
maintaining task performance. Existing approaches typically rely on a single
policy to jointly optimize reward and safety, which can cause instability due
to conflicting objectives, or they use external safety filters that override
actions and require prior system knowledge. In this paper, we propose a modular
cost-aware regulator that scales the agent's actions based on predicted
constraint violations, preserving exploration through smooth action modulation
rather than overriding the policy. The regulator is trained to minimize
constraint violations while avoiding degenerate suppression of actions. Our
approach integrates seamlessly with off-policy RL methods such as SAC and TD3,
and achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion
tasks with sparse costs, reducing constraint violations by up to 126 times
while increasing returns by over an order of magnitude compared to prior
methods.

</details>


### [69] [DQ-NMPC: Dual-Quaternion NMPC for Quadrotor Flight](https://arxiv.org/abs/2510.11525)
*Luis F. Recalde,Dhruv Agrawal,Jon Arrizabalaga,Guanrui Li*

Main category: cs.RO

TL;DR: 提出基于对偶四元数(DQ-NMPC)的新型非线性模型预测控制框架，用于解决四旋翼无人机在敏捷飞行中的精确控制问题，相比传统方法显著提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 四旋翼无人机在复杂动态环境中具有巨大应用潜力，但由于其欠驱动特性和平移与旋转动力学的强耦合，实现精确控制仍然是一个重大挑战。

Method: 使用对偶四元数表示四旋翼动力学和姿态误差，在双四元数流形上构建紧凑且全局非奇异的公式，捕捉四旋翼的耦合动力学特性。

Result: 仿真和真实世界实验验证显示，相比传统NMPC方法，位置和姿态误差分别减少高达56.11%和56.77%，数值条件更好，能处理激进轨迹，在13.66 m/s速度和4.2 g加速度下仍能稳定控制。

Conclusion: DQ-NMPC框架通过双四元数表示有效解决了四旋翼的耦合控制问题，显著提升了敏捷飞行的跟踪性能和控制鲁棒性。

Abstract: MAVs have great potential to assist humans in complex tasks, with
applications ranging from logistics to emergency response. Their agility makes
them ideal for operations in complex and dynamic environments. However,
achieving precise control in agile flights remains a significant challenge,
particularly due to the underactuated nature of quadrotors and the strong
coupling between their translational and rotational dynamics. In this work, we
propose a novel NMPC framework based on dual-quaternions (DQ-NMPC) for
quadrotor flight. By representing both quadrotor dynamics and the pose error
directly on the dual-quaternion manifold, our approach enables a compact and
globally non-singular formulation that captures the quadrotor coupled dynamics.
We validate our approach through simulations and real-world experiments,
demonstrating better numerical conditioning and significantly improved tracking
performance, with reductions in position and orientation errors of up to 56.11%
and 56.77%, compared to a conventional baseline NMPC method. Furthermore, our
controller successfully handles aggressive trajectories, reaching maximum
speeds up to 13.66 m/s and accelerations reaching 4.2 g within confined space
conditions of dimensions 11m x 4.5m x 3.65m under which the baseline controller
fails.

</details>


### [70] [IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy](https://arxiv.org/abs/2510.11534)
*Enli Lin,Ziyuan Yang,Qiujing Lu,Jianming Hu,Shuo Feng*

Main category: cs.RO

TL;DR: 提出了IntersectioNDE模拟器，专门用于复杂城市交叉路口场景，通过交互解耦策略解决高密度异构交通模拟的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模拟器难以建模城市交叉路口的密集异构交互，特别是在中国等国家的复杂交通环境中，存在模式崩溃和长期模拟不稳定的问题。

Method: 基于City Crossings Dataset，提出交互解耦策略(IDS)，通过从智能体子集学习组合动态，实现边缘到联合的模拟，并集成到场景感知Transformer网络中。

Result: 在CiCross数据集上的实验表明，IntersectioNDE在模拟保真度、稳定性和复制复杂分布级城市交通动态方面优于基线方法。

Conclusion: IntersectioNDE能够有效模拟城市交叉路口的密集异构交通交互，显著提升了模拟的鲁棒性和长期稳定性。

Abstract: Realistic traffic simulation is critical for ensuring the safety and
reliability of autonomous vehicles (AVs), especially in complex and diverse
urban traffic environments. However, existing data-driven simulators face two
key challenges: a limited focus on modeling dense, heterogeneous interactions
at urban intersections - which are prevalent, crucial, and practically
significant in countries like China, featuring diverse agents including
motorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and
the inherent difficulty in robustly learning high-dimensional joint
distributions for such high-density scenes, often leading to mode collapse and
long-term simulation instability. We introduce City Crossings Dataset
(CiCross), a large-scale dataset collected from a real-world urban
intersection, uniquely capturing dense, heterogeneous multi-agent interactions,
particularly with a substantial proportion of MVs, NMVs and pedestrians. Based
on this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving
Environment), a data-driven simulator tailored for complex urban intersection
scenarios. Its core component is the Interaction Decoupling Strategy (IDS), a
training paradigm that learns compositional dynamics from agent subsets,
enabling the marginal-to-joint simulation. Integrated into a scene-aware
Transformer network with specialized training techniques, IDS significantly
enhances simulation robustness and long-term stability for modeling
heterogeneous interactions. Experiments on CiCross show that IntersectioNDE
outperforms baseline methods in simulation fidelity, stability, and its ability
to replicate complex, distribution-level urban traffic dynamics.

</details>


### [71] [Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization](https://arxiv.org/abs/2510.11539)
*Denglin Cheng,Jiarong Kang,Xiaobin Xiong*

Main category: cs.RO

TL;DR: 提出了一种双层优化框架，联合校准协方差矩阵和运动学参数，通过估计器内环方式提高机器人状态估计的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决在动态不确定环境中，腿式和空中机器人状态估计的关键挑战——过程噪声和测量噪声协方差通常未知或需要手动调整的问题。

Method: 采用双层优化框架：上层将噪声协方差和模型参数作为优化变量，下层执行全信息估计器。通过估计器的微分实现轨迹级目标的直接优化。

Result: 在四足机器人和人形机器人上验证，相比手动调优基线，估计精度和不确定性校准显著提升。

Conclusion: 该方法将状态估计、传感器和运动学校准统一到一个原则性的数据驱动框架中，适用于各种机器人平台。

Abstract: Accurate state estimation is critical for legged and aerial robots operating
in dynamic, uncertain environments. A key challenge lies in specifying process
and measurement noise covariances, which are typically unknown or manually
tuned. In this work, we introduce a bi-level optimization framework that
jointly calibrates covariance matrices and kinematic parameters in an
estimator-in-the-loop manner. The upper level treats noise covariances and
model parameters as optimization variables, while the lower level executes a
full-information estimator. Differentiating through the estimator allows direct
optimization of trajectory-level objectives, resulting in accurate and
consistent state estimates. We validate our approach on quadrupedal and
humanoid robots, demonstrating significantly improved estimation accuracy and
uncertainty calibration compared to hand-tuned baselines. Our method unifies
state estimation, sensor, and kinematics calibration into a principled,
data-driven framework applicable across diverse robotic platforms.

</details>


### [72] [NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning](https://arxiv.org/abs/2510.11542)
*Neil C. Janwani,Varun Madabushi,Maegan Tucker*

Main category: cs.RO

TL;DR: NaviGait是一个分层框架，结合轨迹优化的结构和强化学习的适应性，用于稳健直观的双足运动控制。它利用离线优化的步态库，通过插值生成连续参考运动，并通过策略提供关节级和速度命令残差修正来稳定参考轨迹。


<details>
  <summary>Details</summary>
Motivation: 强化学习在双足运动控制中虽然强大，但奖励函数设计复杂且不直观；而离线轨迹优化方法虽然可调性和可解释性强，但对现实世界扰动脆弱。需要结合两者优势。

Method: 分层框架：高层使用轨迹优化生成步态库并插值产生参考运动；低层使用强化学习策略提供关节和速度的残差修正来稳定和调制参考轨迹。

Result: 相比传统和基于模仿的强化学习，NaviGait训练更快，产生的运动最接近原始参考轨迹，且奖励设计大大简化。

Conclusion: 通过解耦高层运动生成和低层修正，NaviGait为实现动态稳健运动提供了更可扩展和泛化的方法。

Abstract: Reinforcement learning (RL) has emerged as a powerful method to learn robust
control policies for bipedal locomotion. Yet, it can be difficult to tune
desired robot behaviors due to unintuitive and complex reward design. In
comparison, offline trajectory optimization methods, like Hybrid Zero Dynamics,
offer more tuneable, interpretable, and mathematically grounded motion plans
for high-dimensional legged systems. However, these methods often remain
brittle to real-world disturbances like external perturbations.
  In this work, we present NaviGait, a hierarchical framework that combines the
structure of trajectory optimization with the adaptability of RL for robust and
intuitive locomotion control. NaviGait leverages a library of offline-optimized
gaits and smoothly interpolates between them to produce continuous reference
motions in response to high-level commands. The policy provides both
joint-level and velocity command residual corrections to modulate and stabilize
the reference trajectories in the gait library. One notable advantage of
NaviGait is that it dramatically simplifies reward design by encoding rich
motion priors from trajectory optimization, reducing the need for finely tuned
shaping terms and enabling more stable and interpretable learning. Our
experimental results demonstrate that NaviGait enables faster training compared
to conventional and imitation-based RL, and produces motions that remain
closest to the original reference. Overall, by decoupling high-level motion
generation from low-level correction, NaviGait offers a more scalable and
generalizable approach for achieving dynamic and robust locomotion.

</details>


### [73] [Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education](https://arxiv.org/abs/2510.11552)
*Gregoire Passault,Clement Gaspard,Olivier Ly*

Main category: cs.RO

TL;DR: 开发了一款带有外部跟踪系统的教育用全向机器人套件，解决了现有机器人套件局限于自我中心感知的问题，使学生能够接触更高级的机器人学概念。


<details>
  <summary>Details</summary>
Motivation: 当前教育机器人套件大多局限于机器人的自我中心感知，难以让学生接触到涉及坐标系、导航等更高级的机器人学问题。

Method: 设计了一款全向教育机器人套件，配备外部跟踪系统，减轻了嵌入式系统的负担，同时支持探索高级机器人学概念。

Result: 该套件使得学生能够接触和学习原本难以达到的高级机器人学方面，如坐标系统和导航等。

Conclusion: 通过引入外部跟踪系统的全向机器人套件，成功扩展了教育机器人的应用范围，使学生能够探索更复杂的机器人学问题。

Abstract: Recent developments of low cost off-the-shelf programmable components, their
modularity, and also rapid prototyping made educational robotics flourish, as
it is accessible in most schools today. They allow to illustrate and embody
theoretical problems in practical and tangible applications, and gather
multidisciplinary skills. They also give a rich natural context for
project-oriented pedagogy. However, most current robot kits all are limited to
egocentric aspect of the robots perception. This makes it difficult to access
more high-level problems involving e.g. coordinates or navigation. In this
paper we introduce an educational holonomous robot kit that comes with an
external tracking system, which lightens the constraint on embedded systems,
but allows in the same time to discover high-level aspects of robotics,
otherwise unreachable.

</details>


### [74] [SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy](https://arxiv.org/abs/2510.11566)
*Kuanning Wang,Yongchong Gu,Yuqian Fu,Zeyu Shangguan,Sicheng He,Xiangyang Xue,Yanwei Fu,Daniel Seita*

Main category: cs.RO

TL;DR: SCOOP'D是一个使用模拟演示和扩散策略的机器人舀取方法，能够在真实世界中实现零样本部署，在465次试验中表现优于所有基线方法。


<details>
  <summary>Details</summary>
Motivation: 开发通用的自主机器人舀取策略具有挑战性，因为需要理解复杂的工具-物体交互，特别是涉及颗粒介质或液体等可变形物体的操作。

Method: 使用OmniGibson模拟器收集基于特权状态信息的舀取演示，然后通过扩散生成策略来模仿这些演示，仅使用观察输入。

Result: 在零样本部署中，该方法在465次多样化场景试验中表现出色，包括不同难度级别的物体（Level 1和Level 2），显著优于所有基线和消融实验。

Conclusion: SCOOP'D是通过模拟演示和扩散策略获取机器人舀取技能的有前景方法，能够直接应用于真实世界场景。

Abstract: Scooping items with tools such as spoons and ladles is common in daily life,
ranging from assistive feeding to retrieving items from environmental disaster
sites. However, developing a general and autonomous robotic scooping policy is
challenging since it requires reasoning about complex tool-object interactions.
Furthermore, scooping often involves manipulating deformable objects, such as
granular media or liquids, which is challenging due to their
infinite-dimensional configuration spaces and complex dynamics. We propose a
method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA
Omniverse) to collect scooping demonstrations using algorithmic procedures that
rely on privileged state information. Then, we use generative policies via
diffusion to imitate demonstrations from observational input. We directly apply
the learned policy in diverse real-world scenarios, testing its performance on
various item quantities, item characteristics, and container types. In
zero-shot deployment, our method demonstrates promising results across 465
trials in diverse scenarios, including objects of different difficulty levels
that we categorize as "Level 1" and "Level 2." SCOOP'D outperforms all
baselines and ablations, suggesting that this is a promising approach to
acquiring robotic scooping skills. Project page is at
https://scoopdiff.github.io/.

</details>


### [75] [Calibrated Dynamic Modeling for Force and Payload Estimation in Hydraulic Machinery](https://arxiv.org/abs/2510.11574)
*Lennart Werner,Pol Eyschen,Sean Costello,Pierluigi Micarelli,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种用于液压挖掘机的高精度、可改造的二维力和有效载荷估计算法，无需额外操作要求，通过动态模型识别实现末端执行器作用力和铲斗有效载荷的实时估计。


<details>
  <summary>Details</summary>
Motivation: 准确估计液压挖掘机末端执行器作用力是实现重型机械高级自动化的关键，能改善精确的平整和挖掘操作。

Method: 基于优化的有效载荷估计方法，通过识别动态模型，利用压力和惯性测量在线估计力和有效载荷，无需机器特定动态特性的先验知识。

Result: 在标准25吨挖掘机上，在线力测量的方向精度为13度，幅度精度为383N；有效载荷估计的全量程精度达到1%，在两个不同类型和重量等级的挖掘机平台上验证了方法的准确性和泛化能力。

Conclusion: 该方法在准确性和精度上优于传统的准静态方法和商业可用系统，具有高精度、可改造性和最小校准要求的特点。

Abstract: Accurate real-time estimation of end effector interaction forces in hydraulic
excavators is a key enabler for advanced automation in heavy machinery.
Accurate knowledge of these forces allows improved, precise grading and digging
maneuvers. To address these challenges, we introduce a high-accuracy,
retrofittable 2D force- and payload estimation algorithm that does not impose
additional requirements on the operator regarding trajectory, acceleration or
the use of the slew joint. The approach is designed for retrofittability,
requires minimal calibration and no prior knowledge of machine-specific dynamic
characteristics. Specifically, we propose a method for identifying a dynamic
model, necessary to estimate both end effector interaction forces and bucket
payload during normal operation. Our optimization-based payload estimation
achieves a full-scale payload accuracy of 1%. On a standard 25 t excavator, the
online force measurement from pressure and inertial measurements achieves a
direction accuracy of 13 degree and a magnitude accuracy of 383 N. The method's
accuracy and generalization capability are validated on two excavator platforms
of different type and weight classes. We benchmark our payload estimation
against a classical quasistatic method and a commercially available system. Our
system outperforms both in accuracy and precision.

</details>


### [76] [ManiAgent: An Agentic Framework for General Robotic Manipulation](https://arxiv.org/abs/2510.11660)
*Yi Yang,Kefan Gu,Yuqing Wen,Hebei Li,Yucheng Zhao,Tiancai Wang,Xudong Liu*

Main category: cs.RO

TL;DR: ManiAgent是一个用于通用操作任务的智能体架构，通过多智能体协作实现从任务描述到机器人操作动作的端到端输出，在复杂推理和长时程任务规划方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决Vision-Language-Action模型在复杂推理和长时程任务规划中因数据稀缺和模型容量限制导致的性能不足问题。

Method: 采用多智能体架构，通过智能体间通信进行环境感知、子任务分解和动作生成，从而高效处理复杂操作场景。

Result: 在SimplerEnv基准测试中达到86.8%的成功率，在真实世界拾取放置任务中达到95.8%的成功率，能够高效收集数据训练出与人工标注数据集性能相当的VLA模型。

Conclusion: ManiAgent通过多智能体协作有效提升了机器人操作任务的性能，为复杂操作场景提供了高效的解决方案。

Abstract: While Vision-Language-Action (VLA) models have demonstrated impressive
capabilities in robotic manipulation, their performance in complex reasoning
and long-horizon task planning is limited by data scarcity and model capacity.
To address this, we introduce ManiAgent, an agentic architecture for general
manipulation tasks that achieves end-to-end output from task descriptions and
environmental inputs to robotic manipulation actions. In this framework,
multiple agents involve inter-agent communication to perform environmental
perception, sub-task decomposition and action generation, enabling efficient
handling of complex manipulation scenarios. Evaluations show ManiAgent achieves
an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world
pick-and-place tasks, enabling efficient data collection that yields VLA models
with performance comparable to those trained on human-annotated datasets.The
project webpage is available at https://yi-yang929.github.io/ManiAgent/.

</details>


### [77] [Ego-Vision World Model for Humanoid Contact Planning](https://arxiv.org/abs/2510.11682)
*Hang Liu,Yuman Gao,Sangli Teng,Yufeng Chi,Yakun Sophia Shao,Zhongyu Li,Maani Ghaffari,Koushil Sreenath*

Main category: cs.RO

TL;DR: 提出结合学习世界模型与采样MPC的框架，用于人形机器人接触感知规划，支持多任务且数据效率高


<details>
  <summary>Details</summary>
Motivation: 让人形机器人能够利用物理接触而非仅避免碰撞，在非结构化环境中实现自主性

Method: 使用无演示离线数据集训练学习世界模型，结合采样MPC在压缩潜在空间预测未来结果，采用学习替代值函数处理稀疏接触奖励和传感器噪声

Result: 在物理人形机器人上实现实时接触规划，支持墙面支撑、阻挡物体、穿越限高拱门等多任务，数据效率和泛化能力优于在线强化学习

Conclusion: 该框架实现了鲁棒的实时接触规划，在真实人形机器人上验证了有效性

Abstract: Enabling humanoid robots to exploit physical contact, rather than simply
avoid collisions, is crucial for autonomy in unstructured environments.
Traditional optimization-based planners struggle with contact complexity, while
on-policy reinforcement learning (RL) is sample-inefficient and has limited
multi-task ability. We propose a framework combining a learned world model with
sampling-based Model Predictive Control (MPC), trained on a demonstration-free
offline dataset to predict future outcomes in a compressed latent space. To
address sparse contact rewards and sensor noise, the MPC uses a learned
surrogate value function for dense, robust planning. Our single, scalable model
supports contact-aware tasks, including wall support after perturbation,
blocking incoming objects, and traversing height-limited arches, with improved
data efficiency and multi-task capability over on-policy RL. Deployed on a
physical humanoid, our system achieves robust, real-time contact planning from
proprioception and ego-centric depth images. Website:
https://ego-vcp.github.io/

</details>


### [78] [Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation](https://arxiv.org/abs/2510.11689)
*Maggie Wang,Stephen Tian,Aiden Swann,Ola Shorinwa,Jiajun Wu,Mac Schwager*

Main category: cs.RO

TL;DR: Phys2Real是一个从真实到模拟再到真实的强化学习管道，通过视觉语言模型推断物理参数并结合交互式自适应，解决了模拟到真实转移的挑战。


<details>
  <summary>Details</summary>
Motivation: 直接在真实世界中学习机器人操作策略成本高昂且耗时，而仿真训练的强化学习策略虽然可扩展，但有效的模拟到真实转移仍然困难，特别是需要精确动力学的任务。

Method: Phys2Real包含三个核心组件：(1) 使用3D高斯泼溅进行高保真几何重建；(2) VLM推断的物理参数先验分布；(3) 从交互数据中在线估计物理参数。通过集成不确定性量化来融合VLM预测和在线估计。

Result: 在具有不同质心的T形块平面推动任务和具有偏心质量分布的锤子推动任务中，Phys2Real相比域随机化基线有显著改进：底部加重T形块成功率100% vs 79%，挑战性顶部加重T形块成功率57% vs 23%，锤子推动任务平均完成时间快15%。

Conclusion: 消融研究表明VLM和交互信息的结合对于成功至关重要。该方法通过将策略建立在可解释的物理参数上，有效解决了模拟到真实转移的挑战。

Abstract: Learning robotic manipulation policies directly in the real world can be
expensive and time-consuming. While reinforcement learning (RL) policies
trained in simulation present a scalable alternative, effective sim-to-real
transfer remains challenging, particularly for tasks that require precise
dynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL
pipeline that combines vision-language model (VLM)-inferred physical parameter
estimates with interactive adaptation through uncertainty-aware fusion. Our
approach consists of three core components: (1) high-fidelity geometric
reconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions
over physical parameters, and (3) online physical parameter estimation from
interaction data. Phys2Real conditions policies on interpretable physical
parameters, refining VLM predictions with online estimates via ensemble-based
uncertainty quantification. On planar pushing tasks of a T-block with varying
center of mass (CoM) and a hammer with an off-center mass distribution,
Phys2Real achieves substantial improvements over a domain randomization
baseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23%
in the challenging top-weighted T-block, and 15% faster average task completion
for hammer pushing. Ablation studies indicate that the combination of VLM and
interaction information is essential for success. Project website:
https://phys2real.github.io/ .

</details>
