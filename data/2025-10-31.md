<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Debate2Create: Robot Co-design via Large Language Model Debates](https://arxiv.org/abs/2510.25850)
*Kevin Qiu,Marek Cygan*

Main category: cs.RO

TL;DR: D2C框架使用LLM代理进行结构化辩论，共同优化机器人形态和控制，通过多轮辩论迭代改进设计，在四足机器人运动基准上比默认设计移动距离增加73%。


<details>
  <summary>Details</summary>
Motivation: 自动化机器人形态和控制的协同设计面临巨大设计空间和紧密耦合的挑战，需要新的方法来解决这一长期难题。

Method: 设计代理提出形态修改，控制代理设计奖励函数，多元评审团在模拟中评估设计-控制对并提供反馈，通过迭代辩论逐步改进提案。

Result: D2C产生了多样化和专业化的形态，无需显式多样性目标；在四足机器人运动基准上，发现的设计比默认设计移动距离增加73%。

Conclusion: 基于LLM的结构化辩论结合物理基础反馈，是自动化机器人设计的有前景的新范式。

Abstract: Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.

</details>


### [2] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 开发基于泊松方程和拉普拉斯引导场的风险感知安全过滤器，用于机器人导航系统，通过数学建模环境语义理解和风险等级来保证安全。


<details>
  <summary>Details</summary>
Motivation: 机器人系统在现实环境中导航需要语义理解环境以确定安全动作，需要开发能够感知风险的安全表示方法。

Method: 采用两步法：通过泊松方程求解狄利克雷问题生成安全函数，通过拉普拉斯方程求解狄利克雷问题合成安全引导场，结合两者构建风险感知安全过滤器。

Result: 在仿真中验证了该方法能够根据环境特征的先验风险知识生成风险感知的安全行为，保证安全的同时优先避开高风险障碍物。

Conclusion: 提出的风险感知安全过滤器能够有效结合环境语义理解和风险等级，为机器人导航提供数学上严谨的安全保障。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a representation --
specifically, the goal is to develop safety filters that are risk-aware. To
this end, we take a two step approach: encoding an understanding of the
environment via Poisson's equation, and associated risk via Laplace guidance
fields. That is, we first solve a Dirichlet problem for Poisson's equation to
generate a safety function that encodes system safety as its 0-superlevel set.
We then separately solve a Dirichlet problem for Laplace's equation to
synthesize a safe \textit{guidance field} that encodes variable levels of
caution around obstacles -- by enforcing a tunable flux boundary condition. The
safety function and guidance fields are then combined to define a safety
constraint and used to synthesize a risk-aware safety filter which, given a
semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [3] [Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces](https://arxiv.org/abs/2510.25965)
*Luoyan Zhong,Heather Jin Hee Kim,Dylan P. Losey,Cara M. Nunez*

Main category: cs.RO

TL;DR: 开发了一种用于电阻式触觉传感器的曲率感知校准模型，通过在无负载条件下使用神经网络预测局部曲率，显著提高了在曲面上的力测量精度和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有柔性触觉传感器主要在平面上校准，但在实际应用中安装在曲面几何体上时精度和一致性会下降，限制了其在实际应用中的可靠性。

Method: 开发了曲率感知校准模型，使用多层感知机神经网络从无负载时的基线传感器输出预测局部曲率，并在五种不同曲率的日常物体上验证。

Result: 神经网络预测曲率的R2分数达到0.91，曲率感知校准在所有表面上保持一致的力精度，而平面校准会随着曲率增加而低估力值。

Conclusion: 曲率感知建模提高了柔性触觉传感器的精度、一致性和可靠性，使其能够在实际应用中提供可靠的性能。

Abstract: Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.

</details>


### [4] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 提出了一种新的基于欧拉轴角的姿态控制方法，相比传统的四元数控制方法，能保证闭环系统存在唯一的平衡点，并在大角度误差时提供更好的比例控制效果。


<details>
  <summary>Details</summary>
Motivation: 传统的四元数姿态控制方法存在两个问题：1) 不能保证闭环系统存在唯一的平衡点；2) 当绕姿态误差欧拉轴的旋转误差超过π弧度时，比例控制效果会随着系统状态远离稳定平衡点而减弱。

Method: 开发了一种新的姿态控制律，更有效地利用姿态误差欧拉轴角信息，通过构建严格的Lyapunov函数来证明闭环旋转系统的唯一平衡点是一致渐近稳定的。

Result: 通过数值模拟和数十次实时翻滚恢复机动实验验证了方法的有效性。与高性能四元数控制器相比，提出的轴角方法在稳定时间方面表现出更优越的飞行性能。

Conclusion: 提出的基于欧拉轴角的姿态控制方法在保证唯一闭环平衡点的同时，提供了更灵活的比例控制能力，并在实际应用中表现出比传统四元数方法更优越的性能。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [5] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: DARTS是一个基于无人机和AI的实时交通事件检测系统，通过无人机的高机动性和热成像技术实现自适应监控，使用轻量级深度学习框架进行实时车辆轨迹提取和事件检测，在真实道路测试中比传统方法提前12分钟检测到追尾事故。


<details>
  <summary>Details</summary>
Motivation: 传统交通事件检测方法存在检测与验证分离、灵活性有限、需要密集基础设施等问题，限制了系统的适应性和可扩展性。需要开发更灵活、集成的实时检测系统来减少事故相关的伤亡和拥堵。

Method: 整合无人机的高机动性和空中视角进行自适应监控，使用热成像技术提升低能见度性能和隐私保护，采用轻量级深度学习框架进行实时车辆轨迹提取和事件检测。

Result: 在自收集数据集上达到99%的检测准确率，在佛罗里达州75号州际公路实地测试中，比当地交通管理中心提前12分钟检测到追尾事故，并能监控事故引发的拥堵传播。

Conclusion: DARTS展示了更灵活、集成的实时交通事件检测系统的潜力，具有显著提高现代交通管理运营效率和响应能力的意义，特别是在偏远地区和资源受限环境中的可扩展性和成本效益。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [6] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 使用微型无人机群合作定位放射性材料，通过轻量级康普顿相机实时融合测量数据，实现辐射源定位和追踪


<details>
  <summary>Details</summary>
Motivation: 利用轻量级康普顿相机（仅40克）在微型无人机上的应用，实现团队协作的辐射检测新方法

Method: 采用单探测器康普顿相机作为辐射探测器，融合测量数据实时估计辐射源位置，通过动态反馈控制无人机运动，保持紧密协作的蜂群状态

Result: 能够从极其稀疏的测量中实时定位辐射源，并能追踪移动的辐射源

Conclusion: 该方法为微型无人机群协作辐射检测开辟了新途径，实现了高效灵敏的辐射源定位和追踪

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [7] [Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods](https://arxiv.org/abs/2510.26040)
*Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams*

Main category: cs.RO

TL;DR: 本文提出了一种新型的自主赛车和超车智能体，能够在模拟和现实中可靠地导航赛道并超越对手，在F1Tenth竞赛中实现了87%的超车成功率。


<details>
  <summary>Details</summary>
Motivation: 当前自主轮对轮赛车和超车技术仍然严重受限，现有算法难以安全可靠地完成超车动作，而可靠的超车能力对于安全的自主轮对轮赛车至关重要。

Method: 开发了一种能够学习可靠导航和超车的新型赛车智能体，在F1Tenth平台上进行训练，并在真实车辆上部署，与运行不同竞争算法的对手进行对抗。

Result: 该智能体在与对手的训练中实现了87%的超车成功率，而仅接受赛车训练的智能体只有56%的超车成功率，表明对抗训练能够实现有意识的超车行为。

Conclusion: 通过与对手进行训练，该智能体能够实现有目的的超车行为，显著提高了超车成功率，为自主轮对轮赛车提供了有效的解决方案。

Abstract: While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.

</details>


### [8] [Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion](https://arxiv.org/abs/2510.26067)
*Chi Zhang,Mingrui Li,Wenzhe Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于图神经网络的强化学习框架，用于控制张拉整体机器人的运动，该框架通过捕捉机器人组件的耦合关系，实现了比传统方法更快更稳定的学习效果。


<details>
  <summary>Details</summary>
Motivation: 张拉整体机器人具有高弹性和可部署性，但由于其欠驱动和高度耦合的动力学特性，运动控制面临重大挑战。

Method: 将图神经网络集成到Soft Actor-Critic算法中，将机器人的物理拓扑表示为图结构，从而捕捉组件间的耦合关系。

Result: 在3杆张拉整体机器人上验证了三种基本运动模式，表现出优异的样本效率、对噪声和刚度变化的鲁棒性，以及改进的轨迹精度。学习到的策略无需微调即可从仿真直接迁移到硬件。

Conclusion: 结果表明将结构先验知识融入强化学习对张拉整体机器人控制具有显著优势。

Abstract: Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.

</details>


### [9] [I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship](https://arxiv.org/abs/2510.26080)
*Fan Yang,Renkai Ma,Yaxin Hu,Michael Rodgers,Lingyao Li*

Main category: cs.RO

TL;DR: 研究探讨社交机器人（如Moxie）服务终止对儿童情感伤害的责任归属问题，发现责任被视为机器人公司、父母、开发者和政府共同承担，但责任分配因政治意识形态和父母身份而异。


<details>
  <summary>Details</summary>
Motivation: 社交机器人与儿童建立强烈情感纽带后突然终止服务会造成显著困扰和痛苦，这引发了当儿童情感纽带被破坏时谁应承担责任这一复杂问题。

Method: 以Moxie关闭为案例研究，通过对72名美国参与者进行定性调查。

Result: 研究发现责任被视为共同承担，但责任归属因政治意识形态和父母身份而不同；参与者对机器人服务是否应继续持高度两极分化观点。

Conclusion: 研究提出了基于实证的共享责任框架，详细说明了责任如何分配和争议，为减轻机器人服务终止造成的情感伤害提供了具体设计和政策启示。

Abstract: Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.

</details>


### [10] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究表明机器人拟人化程度对保护性反应的影响不是线性的，中等拟人化机器人引发最强的愤怒反应，道德推理随拟人化程度增加从技术评估转向对施虐者品德的谴责。


<details>
  <summary>Details</summary>
Motivation: 研究不同拟人化程度如何影响人们对机器人受虐的保护性反应，将CASA理论和恐怖谷理论扩展到道德领域。

Method: 邀请201名参与者观看低、中、高三种拟人化程度机器人受虐视频，结合自我报告问卷、生理数据分析和定性反思进行三角验证。

Result: 中等拟人化机器人引发最强的生理愤怒表达和最高诡异感；自我报告的愤怒和愧疚感在中等和高拟人化机器人中显著更高；道德推理随拟人化程度增加而转变。

Conclusion: 恐怖谷现象不会削弱道德关注，反而会增强保护性冲动，这对机器人设计、政策和未来法律框架具有重要意义。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [11] [Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights](https://arxiv.org/abs/2510.26132)
*Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文讨论了将具身智能作为微型机器人设计原则，特别是通过协同设计方法将物理结构和行为功能同时开发，使智能行为从结构动力学和物理交互中涌现。


<details>
  <summary>Details</summary>
Motivation: 传统机器人架构将感知、计算和执行解耦，而具身智能方法通过整合身体形态、材料特性和环境交互来生成智能行为，特别是在微型机器人领域。

Method: 采用协同设计方法，同时开发物理结构和行为功能，将反馈回路、决策逻辑、传感机制和智能驱动策略嵌入到机器人系统的物理属性中。

Result: 开发了一系列微型机器人平台（Bee++、RoBeetle、SMALLBug等），展示了从结构动力学和物理交互中涌现的智能行为，为毫米到厘米级机器人提供了可扩展和鲁棒的替代方案。

Conclusion: 协同设计不仅是约束条件下的经验优化方法，更是实现具身智能的推动者，为微型机器人提供了超越传统控制方法的优势。

Abstract: The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.

</details>


### [12] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一个基于混合状态树的动力学TAMP框架，将符号和数值状态统一表示，通过视觉语言模型引导搜索，显著提高了长时域规划的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有TAMP方法在长时域问题中因过度运动采样而成本高昂，LLM缺乏3D空间推理能力且无法保证几何或动力学可行性。

Method: 使用混合状态树统一表示符号和数值状态，通过现成运动规划器和物理模拟器验证动力学约束，VLM基于状态视觉渲染引导TAMP解决方案探索和回溯搜索。

Result: 在模拟和真实世界实验中，相比传统和基于LLM的TAMP规划器，平均成功率提高了32.14%-1166.67%，复杂问题规划时间减少。

Conclusion: 该框架通过VLM引导和混合状态表示，有效解决了长时域TAMP问题，显著提升了规划性能和效率。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [13] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 提出自适应轨迹优化算法，通过分段保守碰撞检测和姿态修正，解决移动机器人在狭窄通道中的轨迹规划问题，显著提高成功率和规划速度。


<details>
  <summary>Details</summary>
Motivation: 传统方法在狭窄通道环境中经常失败或生成次优路径，需要解决移动机器人在复杂环境中的安全轨迹规划挑战。

Method: 采用两阶段方法：1) 分段保守碰撞检测，递归细分风险轨迹段消除碰撞风险；2) 基于穿透方向和线搜索的姿态修正，确保每个姿态无碰撞且远离障碍物。

Result: 仿真结果显示，相比最先进方法，成功率提高1.69倍，规划时间加快3.79倍；真实实验验证机器人能安全通过狭窄通道并保持快速规划性能。

Conclusion: 所提自适应轨迹优化算法能有效解决狭窄通道中的轨迹规划问题，显著提升规划成功率和效率。

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [14] [Self-localization on a 3D map by fusing global and local features from a monocular camera](https://arxiv.org/abs/2510.26170)
*Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki*

Main category: cs.RO

TL;DR: 提出结合CNN和Vision Transformer的新方法，在动态障碍物存在时显著提升3D地图上的单目相机自定位精度


<details>
  <summary>Details</summary>
Motivation: 基于相机的自定位通常使用CNN提取局部特征，但在动态障碍物（如行人）存在时效果不佳

Method: 将CNN与Vision Transformer结合，CNN提取局部特征，Vision Transformer提取全局特征（图像块间的关系）

Result: 在CG数据集上，动态障碍物存在时的精度提升率是无动态障碍物时的1.5倍；在公共数据集上自定位误差比SOTA减少20.1%；机器人平均定位误差7.51cm

Conclusion: CNN与Vision Transformer的结合能有效提升动态障碍物环境下的自定位精度

Abstract: Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.

</details>


### [15] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: PHUMA是一个基于物理约束的人形机器人运动数据集，通过大规模人类视频和物理约束重定向技术，解决了现有方法中的物理伪影问题，在运动模仿任务中表现优于Humanoid-X和AMASS。


<details>
  <summary>Details</summary>
Motivation: 现有运动模仿方法依赖稀缺昂贵的运动捕捉数据集，而基于互联网视频的方法存在物理伪影问题，限制了方法的可扩展性和多样性。

Method: 利用大规模人类视频，通过数据筛选和物理约束重定向技术，强制关节限制、确保地面接触、消除脚部滑动，生成物理可靠的大规模运动数据。

Result: 在未见运动模仿和骨盆引导路径跟随两种条件下，PHUMA训练的策略均优于Humanoid-X和AMASS，在多样化运动模仿方面取得显著提升。

Conclusion: PHUMA通过物理约束的数据处理方法，成功解决了运动模仿中的物理伪影问题，为大规模人形机器人运动学习提供了可靠的数据基础。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [16] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: 提出了Thor人形机器人框架，通过力自适应躯干倾斜奖励函数和解耦强化学习架构，显著提升了人形机器人在接触丰富环境中的力交互能力。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在服务、工业和救援应用中需要保持全身稳定性，同时与环境进行密集接触交互，但实现人类水平的自适应响应仍面临挑战。

Method: 基于机器人受力分析设计力自适应躯干倾斜(FAT2)奖励函数；采用解耦强化学习架构，将上半身、腰部和下半身分开控制但共享全局观测并联合更新参数。

Result: 在Unitree G1机器人上部署后，向后移动时峰值拉力达167.7N(约G1体重的48%)，向前移动时145.5N，分别比最佳基线提升68.9%和74.7%；能拉动130N负载架和单手打开60N防火门。

Conclusion: Thor框架有效增强了人形机器人的力交互能力，在接触丰富环境中表现出色。

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [17] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: AgriGS-SLAM是一个用于果园环境的视觉-LiDAR SLAM框架，结合了直接LiDAR里程计、闭环检测和多相机3D高斯泼溅渲染，能够在季节性变化和遮挡条件下实现实时3D场景理解。


<details>
  <summary>Details</summary>
Motivation: 果园环境中的自主机器人需要实时3D场景理解，但面临重复行几何、季节性外观变化和风驱动树叶运动等挑战。

Method: 耦合直接LiDAR里程计和闭环检测与多相机3D高斯泼溅渲染，通过批量栅格化互补视角恢复遮挡下的果园结构，使用统一的梯度驱动地图生命周期管理，并通过概率LiDAR深度一致性项指导位姿优化。

Result: 在苹果和梨园多个季节的测试中，相比现有3DGS-SLAM基线方法，AgriGS-SLAM提供了更清晰、更稳定的重建和更平滑的轨迹，同时保持实时性能。

Conclusion: 该方法在果园监测中表现优异，也可应用于其他需要鲁棒多模态感知的户外领域。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [18] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文基于共形几何代数提出了多臂机器人系统的协作任务空间理论框架，通过几何基元的相似变换将复杂系统抽象为单臂系统，并推导了相应的雅可比矩阵，便于集成到经典控制方法中。


<details>
  <summary>Details</summary>
Motivation: 人类环境中的许多任务需要多个运动链的协作行为，但协调高自由度系统的运动建模困难。

Method: 使用共形几何代数定义协作几何基元，通过相似变换抽象复杂系统，推导解析和几何雅可比矩阵，集成到操作空间控制中。

Result: 在双手机器人、仿人机器人和多指手的实验中验证了方法，展示了在期望几何基元到达和遥操作中的有效性。

Conclusion: 该工作为协作操作控制框架奠定了理论基础，几何基元自然嵌入零空间结构，可用于引入次级控制目标。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [19] [Towards Reinforcement Learning Based Log Loading Automation](https://arxiv.org/abs/2510.26363)
*Ilya Kurinov,Miroslav Ivanov,Grzegorz Orzechowski,Aki Mikkola*

Main category: cs.RO

TL;DR: 该研究使用强化学习代理来自动化林业集材机的原木装载过程，从抓取扩展到完整的装载操作，在模拟环境中实现了94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 林业集材机操作对操作员来说具有挑战性且身心疲惫，部分自动化可以减轻操作员压力。

Method: 在NVIDIA Isaac Gym中开发了拖车式林业集材机模拟模型和虚拟环境，使用强化学习代理和课程学习方法训练自动化装载过程。

Result: 训练出的代理能够从随机位置抓取原木并运输到车厢，最佳代理的成功率达到94%。

Conclusion: 该训练代理是朝着在林业集材机自动化中应用强化学习代理的重要一步。

Abstract: Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.

</details>


### [20] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: Hi-ORS是一种有效的后训练方法，通过拒绝采样实现训练稳定性和高鲁棒性，在真实世界任务中仅需1.5小时训练即可超越RL和IL基线方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习训练视觉语言动作模型时存在价值估计不准确和中间步骤监督稀疏的问题，而模仿学习虽然易于训练但性能通常较差。

Method: 采用拒绝采样过滤负奖励样本来稳定价值估计，使用奖励加权的监督训练目标提供密集的中间步骤监督，并开发异步推理训练框架支持在线人工校正。

Result: 在三个真实世界任务和两种实体上，Hi-ORS仅用1.5小时真实世界训练就掌握了接触丰富的操作，在效果和效率上都显著优于RL和IL基线方法。

Conclusion: Hi-ORS方法成功解决了VLA模型微调中的稳定性问题，训练出的策略表现出强大的测试时扩展性，能够可靠执行复杂的错误恢复行为以获得更好性能。

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [21] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了RoboOS-NeXT框架，通过统一的时空-具身记忆(STEM)实现多机器人系统的终身适应、可扩展协调和鲁棒调度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限的个体记忆，无法实现长期学习、异构团队扩展或故障恢复，需要统一的记忆表示。

Method: 核心是STEM记忆，整合空间场景几何、时间事件历史和具身配置文件；采用大脑-小脑框架，高层大脑模型进行全局规划，低层控制器本地执行。

Result: 在餐厅、超市和家庭等复杂协调任务中，RoboOS-NeXT在异构具身系统上表现出优越性能。

Conclusion: 该框架通过认知、记忆和执行的闭环，实现了动态任务分配、容错协作和一致状态同步，验证了其终身、可扩展和鲁棒多机器人协作的有效性。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [22] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 提出了一种扩展机器人逆运动学求解器的新框架，使机器人能够学习使用不同长度工具的顺序动作库，并在仿真和现实场景中实现技能迁移。


<details>
  <summary>Details</summary>
Motivation: 传统机器人对自身运动学理解有限，局限于预设任务，无法有效利用工具。需要解决工具使用的四个关键要素：理解期望结果、选择合适工具、确定最佳工具方向、执行精确操作。

Method: 扩展机器人逆运动学求解器，集成仿真学习的动作轨迹与工具，使机器人能够获取使用不同长度工具的顺序动作库。

Result: 扩展逆运动学求解器误差小于1cm；训练策略在仿真中平均误差为8cm；使用两种不同长度工具时性能几乎无差异。

Conclusion: 该研究展示了在工具使用四个基本方面探索的潜在进展，使机器人能够掌握跨不同任务的复杂工具操作艺术。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [23] [FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles](https://arxiv.org/abs/2510.26588)
*Gang Li,Chunlei Zhai,Teng Wang,Shaun Li,Shangsong Jiang,Xiangwei Zhu*

Main category: cs.RO

TL;DR: FLYINGTRUST是一个用于四旋翼无人机视觉导航算法的高保真可配置基准测试框架，通过系统评估平台动力学和场景结构对导航鲁棒性的联合影响。


<details>
  <summary>Details</summary>
Motivation: 四旋翼无人机的视觉导航算法在不同平台和场景间性能差异大，增加了现场部署的成本和风险，需要系统化的早期评估方法。

Method: 使用最大推重比和轴间最大角加速度两个物理可解释指标建模平台能力，结合多样化场景库和异构平台集，采用标准化评估协议和综合评分方法。

Result: 发现导航成功率可预测地依赖于平台能力和场景几何结构，不同算法在评估条件下表现出不同的偏好和失效模式。

Conclusion: 算法设计、评估和选择必须同时考虑平台能力和场景结构，未来需要开发在多样化平台和场景下保持鲁棒性的方法。

Abstract: Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.

</details>


### [24] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种用于连续体机器人连续时间状态估计的滑动窗口滤波器，在提高滤波器精度的同时实现在线运行，且速度快于实时。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人状态估计方法在精度和计算效率之间难以平衡。滑动窗口方法局限于简化离散时间近似且缺乏随机表示，而随机滤波器方法受限于测量速度。连续时间估计方法目前仅限于离线操作。

Method: 开发了一种专门为连续体机器人设计的随机滑动窗口滤波器，用于连续时间状态估计。

Result: 该方法在提高滤波器精度的同时，使连续时间方法能够在线运行，且速度快于实时。

Conclusion: 这是首个专门为连续体机器人设计的随机滑动窗口滤波器，为该领域未来研究提供了有前景的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [25] [REALMS2 -- Resilient Exploration And Lunar Mapping System 2 -- A Comprehensive Approach](https://arxiv.org/abs/2510.26638)
*Dave van der Meer,Loïck P. Chovet,Gabriel M. Garcia,Abhishek Bera,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: REALMS2是一个基于ROS 2的多机器人系统框架，用于行星勘探和地图绘制，采用vSLAM技术和网状网络，在ESA-ESRIC挑战赛中成功绘制了约60%的区域。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在太空勘探中的挑战，特别是针对异质多机器人探索任务在恶劣外星环境中的通信延迟和中断问题。

Method: 使用ROS 2框架，集成视觉SLAM技术进行地图生成，采用网状网络建立鲁棒的ad hoc网络，通过单一GUI控制所有漫游车。

Result: 在ESA-ESRIC挑战赛的第二次实地测试中，使用三个同质漫游车成功绘制了约60%的区域，有效处理了通信延迟和中断。

Conclusion: REALMS2系统证明了其在行星勘探任务中的有效性，能够应对恶劣外星环境的挑战，为未来太空资源勘探提供了可行的技术方案。

Abstract: The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.

</details>


### [26] [Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments](https://arxiv.org/abs/2510.26646)
*Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai*

Main category: cs.RO

TL;DR: 提出分层路径规划与控制框架，结合高层DQN进行离散子目标选择和底层TD3控制器进行连续驱动，在动态和部分可观测环境中实现改进的路径规划性能。


<details>
  <summary>Details</summary>
Motivation: 解决单一算法在复杂环境中路径规划的局限性，通过分层结构结合离散决策和连续控制，提高在动态和部分可观测环境中的规划成功率和样本效率。

Method: 使用高层Deep Q-Network进行行为选择和子目标决策，底层Twin Delayed Deep Deterministic Policy Gradient执行平滑速度控制，结合LiDAR安全门和奖励塑造方案（方向、距离、避障、动作平滑性等）。

Result: 在ROS + Gazebo平台上验证，相比单一算法基准（单独DQN或TD3）和基于规则的规划器，实现了更高的成功率、更好的样本效率，对未见障碍物配置具有更好的泛化能力，并减少了突变的控制变化。

Conclusion: 分层框架有效结合了离散决策和连续控制的优势，在复杂环境中提供了更鲁棒和高效的路径规划解决方案，代码和评估脚本已开源。

Abstract: This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.

</details>


### [27] [Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems](https://arxiv.org/abs/2510.26656)
*Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 提出了三种启发式LFI变体（EDGE、MODE、CENTRE）来解决支持集错误设定问题，通过在推理过程中自适应调整支持集来提高参数推断和策略学习的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统LFI方法假设固定的采样支持集，但错误设定的支持集会导致次优且虚假确定的后验分布，影响机器人学习性能。

Method: 开发了三种启发式LFI变体，通过解释后验模式在推理步骤中的移动来动态调整支持集，并与后验推理集成。

Result: 在随机动态基准测试中验证了方法的有效性，在可变形线性物体操作任务中实现了更精细的长度和刚度分类，并提升了基于模拟的策略学习性能。

Conclusion: 提出的启发式支持集自适应方法能够解决LFI中的支持集错误设定问题，提高参数推断精度和策略学习的鲁棒性。

Abstract: In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.

</details>


### [28] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: 提出混合一致性策略(HCP)，通过结合随机前缀和一致性跳跃，在保持多模态行为的同时显著加速扩散策略的推理速度


<details>
  <summary>Details</summary>
Motivation: 解决基于扩散的模仿学习方法在快速采样和强多模态之间难以兼顾的问题

Method: HCP先运行短随机前缀到自适应切换时间，然后应用一步一致性跳跃生成最终动作，采用时变一致性蒸馏结合轨迹一致性目标和去噪匹配目标

Result: 在仿真和真实机器人上，HCP仅需25步SDE加一次跳跃即可接近80步DDPM教师模型的精度和模态覆盖度，同时显著降低延迟

Conclusion: 多模态不需要慢推理，切换时间实现了模态保持与速度的解耦，为机器人策略提供了实用的精度效率权衡

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [29] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 提出了一种在单张消费级GPU上实现30Hz帧率和480Hz轨迹频率的π0级多视角VLA实时推理方法，使大型VLA模型能够完成动态实时任务。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言动作模型在实时机器人控制中的高延迟问题，实现之前被认为无法达到的动态实时任务。

Method: 引入一系列策略消除模型推理中的开销，包括优化推理流程和提出完整的流式推理框架。

Result: 在抓取下落笔的任务中，采用该策略的π0策略实现了100%的成功率。

Conclusion: 证明了通过优化推理策略，大型VLA模型能够在消费级硬件上实现实时性能，为实时机器人控制提供了可行方案。

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>
