<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Configuration-Dependent Robot Kinematics Model and Calibration](https://arxiv.org/abs/2510.19962)
*Chen-Lung Lu,Honglu He,Agung Julius,John T. Wen*

Main category: cs.RO

TL;DR: 提出了一种基于局部POE模型和傅里叶基函数插值的配置依赖运动学校准框架，显著提高工业机器人在整个工作空间中的定位精度，最大定位误差降低50%以上。


<details>
  <summary>Details</summary>
Motivation: 准确的运动学模型对机器人精确定位至关重要，但非几何因素会导致配置依赖的模型差异，需要开发能在整个工作空间中提高精度的校准方法。

Method: 使用局部POE模型在多个配置点进行识别，通过傅里叶基函数插值构建全局模型，参数化基于肩部和肘部关节角度，实现高效训练。

Result: 在两个6自由度工业机器人上验证，最大定位误差降低超过50%，达到冷喷涂制造所需的亚毫米精度，配置依赖差异较大的机器人获益更多。

Conclusion: 该方法在训练效率和精度方面优于神经网络和自编码器方法，双机器人协作任务验证了其实际应用价值和可重复性。

Abstract: Accurate robot kinematics is essential for precise tool placement in
articulated robots, but non-geometric factors can introduce
configuration-dependent model discrepancies. This paper presents a
configuration-dependent kinematic calibration framework for improving accuracy
across the entire workspace. Local Product-of-Exponential (POE) models,
selected for their parameterization continuity, are identified at multiple
configurations and interpolated into a global model. Inspired by joint gravity
load expressions, we employ Fourier basis function interpolation parameterized
by the shoulder and elbow joint angles, achieving accuracy comparable to neural
network and autoencoder methods but with substantially higher training
efficiency. Validation on two 6-DoF industrial robots shows that the proposed
approach reduces the maximum positioning error by over 50%, meeting the
sub-millimeter accuracy required for cold spray manufacturing. Robots with
larger configuration-dependent discrepancies benefit even more. A dual-robot
collaborative task demonstrates the framework's practical applicability and
repeatability.

</details>


### [2] [Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC](https://arxiv.org/abs/2510.19974)
*Hien Bui,Yufeiyang Gao,Haoran Yang,Eric Cui,Siddhant Mody,Brian Acosta,Thomas Stephen Felix,Bibit Bianchini,Michael Posa*

Main category: cs.RO

TL;DR: 提出了C3+算法，一种改进的接触隐式模型预测控制方法，能够在多物体平面推动任务中实现实时性能，成功率达到98%。


<details>
  <summary>Details</summary>
Motivation: 解决非抓取式操作中物体物理属性未知和接触丰富交互复杂性的核心挑战，扩展CI-MPC方法在多样化物体几何和多物体场景中的应用能力。

Method: 引入共识互补控制增强版(C3+)，集成物体扫描、网格重建和硬件执行的完整流程，相比前代C3显著提升求解速度。

Result: 在33个物体上达到98%成功率，单物体任务平均耗时约0.5分钟，多物体任务(2-4个)耗时1.6-5.3分钟，实现实时性能。

Conclusion: C3+算法有效解决了先前CI-MPC方法难以处理的多物体接触推理挑战，展示了在复杂非抓取操作任务中的强大能力。

Abstract: Non-prehensile manipulation of diverse objects remains a core challenge in
robotics, driven by unknown physical properties and the complexity of
contact-rich interactions. Recent advances in contact-implicit model predictive
control (CI-MPC), with contact reasoning embedded directly in the trajectory
optimization, have shown promise in tackling the task efficiently and robustly,
yet demonstrations have been limited to narrowly curated examples. In this
work, we showcase the broader capabilities of CI-MPC through precise planar
pushing tasks over a wide range of object geometries, including multi-object
domains. These scenarios demand reasoning over numerous inter-object and
object-environment contacts to strategically manipulate and de-clutter the
environment, challenges that were intractable for prior CI-MPC methods. To
achieve this, we introduce Consensus Complementarity Control Plus (C3+), an
enhanced CI-MPC algorithm integrated into a complete pipeline spanning object
scanning, mesh reconstruction, and hardware execution. Compared to its
predecessor C3, C3+ achieves substantially faster solve times, enabling
real-time performance even in multi-object pushing tasks. On hardware, our
system achieves overall 98% success rate across 33 objects, reaching pose goals
within tight tolerances. The average time-to-goal is approximately 0.5, 1.6,
3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project
page: https://dairlab.github.io/push-anything.

</details>


### [3] [Simultaneous learning of state-to-state minimum-time planning and control](https://arxiv.org/abs/2510.20008)
*Swati Dantu,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出基于强化学习的框架，学习无人机任意状态间的最小时间飞行策略，结合敏捷飞行和稳定悬停，并通过课程学习实现泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统无人机竞速方法虽能实现高速敏捷飞行，但受限于预设轨道布局，缺乏在现实世界中任意状态间飞行的泛化能力。

Method: 使用点质量模型轨迹作为代理奖励来近似最优飞行目标，采用课程学习高效扩展训练过程并实现泛化，结合强化学习同时学习状态间最小时间规划与控制。

Result: 仿真实验验证方法有效性，优于非线性模型预测控制跟踪点质量模型轨迹；真实环境实验证明策略在户外环境中的鲁棒性，能在小型ARM单板计算机上运行。

Conclusion: 所提框架成功学习到通用最小时间飞行策略，实现任意状态间飞行，平衡敏捷性与稳定性，并在真实环境中展示良好泛化能力和计算效率。

Abstract: This paper tackles the challenge of learning a generalizable minimum-time
flight policy for UAVs, capable of navigating between arbitrary start and goal
states while balancing agile flight and stable hovering. Traditional
approaches, particularly in autonomous drone racing, achieve impressive speeds
and agility but are constrained to predefined track layouts, limiting
real-world applicability. To address this, we propose a reinforcement
learning-based framework that simultaneously learns state-to-state minimum-time
planning and control and generalizes to arbitrary state-to-state flights. Our
approach leverages Point Mass Model (PMM) trajectories as proxy rewards to
approximate the true optimal flight objective and employs curriculum learning
to scale the training process efficiently and to achieve generalization. We
validate our method through simulation experiments, comparing it against
Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories
and conducting ablation studies to assess the impact of curriculum learning.
Finally, real-world experiments confirm the robustness of our learned policy in
outdoor environments, demonstrating its ability to generalize and operate on a
small ARM-based single-board computer.

</details>


### [4] [Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review](https://arxiv.org/abs/2510.20070)
*Sourabh Karmakar,Apurva Patel,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了基于Stewart平台的并联运动学机器人的逆向运动学校准方法，分析了外部仪器、约束条件和自校准三种主要方法，重点关注提高平台位置和方向精度的技术。


<details>
  <summary>Details</summary>
Motivation: 并联运动学机器人在医疗、工程、航天等精密应用领域具有重要价值，需要达到微米和纳米级的运动控制精度。为确保机器人的精度高于应用要求，必须进行适当的校准。

Method: 采用逆向运动学校准方法，分析了外部仪器校准、约束条件校准和自校准三种主要技术路径，通过文献综述比较了这些方法的效果和特点。

Result: 研究发现研究人员主要关注提高平台位置和方向精度，考虑单一或多重误差源，主要涉及结构误差，部分考虑环境因素，但校准都在无负载条件下进行。

Conclusion: 本研究旨在理解该领域当前技术水平，为其他研究人员在特定领域的进一步探索提供参考和扩展空间。

Abstract: Stewart platform-based Parallel Kinematic (PKM) Machines have been
extensively studied by researchers due to their inherent finer control
characteristics. This has opened its potential deployment opportunities in
versatile critical applications like the medical field, engineering machines,
space research, electronic chip manufacturing, automobile manufacturing, etc.
All these precise, complicated, and repeatable motion applications require
micro and nano-scale movement control in 3D space; a 6-DOF PKM can take this
challenge smartly. For this, the PKM must be more accurate than the desired
application accuracy level and thus proper calibration for a PKM robot is
essential. Forward kinematics-based calibration for such hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To analyze different techniques, an external instrument-based,
constraint-based, and auto or self-calibration-based approaches have been used
for calibration. This survey has been done by reviewing these key
methodologies, their outcome, and important points related to inverse
kinematic-based PKM calibrations in general. It is observed in this study that
the researchers focused on improving the accuracy of the platform position and
orientation considering the errors contributed by a single source or multiple
sources. The error sources considered are mainly structural, in some cases,
environmental factors are also considered, however, these calibrations are done
under no-load conditions. This study aims to understand the current state of
the art in this field and to expand the scope for other researchers in further
exploration in a specific area.

</details>


### [5] [Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts](https://arxiv.org/abs/2510.20079)
*Travis A. Roberts,Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 设计并制造了一台用于聚合物FDM工艺研究的3D打印机，该平台具有闭环位置反馈、温度控制、环境监测和原位摄影测量功能，特别关注了加热床旋转机制的设计。


<details>
  <summary>Details</summary>
Motivation: 商用和消费级3D打印机缺乏研究所需的灵活性和控制精度，无法满足重复实验的需求。

Method: 开发了一个开源研究平台，集成了闭环位置反馈、温度控制、环境监测系统，并设计了加热床旋转机制以支持摄影测量重建。

Result: 成功构建了一个能够精确控制和监测FDM工艺参数的研究平台，支持通过摄影测量进行几何缺陷分析。

Conclusion: 该平台为聚合物FDM工艺研究提供了可重复实验的基础设施，特别在过程参数与几何缺陷关联分析方面具有优势。

Abstract: Additive manufacturing, or 3D printing, is a complex process that creates
free-form geometric objects by sequentially placing material to construct an
object, usually in a layer-by-layer process. One of the most widely used
methods is Fused Deposition Modeling (FDM). FDM is used in many of the
consumer-grade polymer 3D printers available today. While consumer grade
machines are cheap and plentiful, they lack many of the features desired in a
machine used for research purposes and are often closed-source platforms.
Commercial-grade models are more expensive and are also usually closed-source
platforms that do not offer flexibility for modifications often needed for
research. The authors designed and fabricated a machine to be used as a test
bed for research in the field of polymer FDM processes. The goal was to create
a platform that tightly controls and/or monitors the FDM build parameters so
that experiments can be repeated with a known accuracy. The platform offers
closed loop position feedback, control of the hot end and bed temperature, and
monitoring of environment temperature and humidity. Additionally, the platform
is equipped with cameras and a mechanism for in-situ photogrammetry, creating a
geometric record of the printing throughout the printing process. Through
photogrammetry, backtracking and linking process parameters to observable
geometric defects can be achieved. This paper focuses on the design of a novel
mechanism for spinning the heated bed to allow for photogrammetric
reconstruction of the printed part using a minimal number of cameras, as
implemented on this platform.

</details>


### [6] [PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation](https://arxiv.org/abs/2510.20161)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: 提出了一种基于路径的Transformer模型，通过3网格表示和约束掩码解码来生成精确的机器人轨迹，在53,755条轨迹上训练，达到89.44%的步进准确率和99.99%的合法路径，在真实机器人测试中实现86.7%的端到端成功率。


<details>
  <summary>Details</summary>
Motivation: 传统序列模型忽略运动结构，导致机器人轨迹规划产生无效或低效执行，需要一种能够同时考虑任务图、动作顺序和运动约束的方法。

Method: 使用基于路径的Transformer，采用3网格（位置/内容/时间）表示法编码机器人运动，结合约束掩码解码确保网格相邻移动和工作空间边界，同时推理任务图和动作顺序。

Result: 在53,755条轨迹数据集上训练，达到89.44%步进准确率、93.32%精确率、89.44%召回率和90.40% F1分数，99.99%路径构造合法；在xArm Lite 6机器人上实现97.5%到达成功率和92.5%抓取成功率，在60个语言指定任务中达到86.7%端到端成功率。

Conclusion: 路径结构表示使Transformer能够生成准确、可靠且可解释的机器人轨迹，桥接了基于图的规划和基于序列的学习，为通用操作和仿真到现实的迁移提供了实用基础。

Abstract: Robotic arms require precise, task-aware trajectory planning, yet sequence
models that ignore motion structure often yield invalid or inefficient
executions. We present a Path-based Transformer that encodes robot motion with
a 3-grid (where/what/when) representation and constraint-masked decoding,
enforcing lattice-adjacent moves and workspace bounds while reasoning over task
graphs and action order. Trained on 53,755 trajectories (80% train / 20%
validation), the model aligns closely with ground truth -- 89.44% stepwise
accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of
paths legal by construction. Compiled to motor primitives on an xArm Lite 6
with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick
success in controlled tests, and 86.7% end-to-end success across 60
language-specified tasks in cluttered scenes, absorbing slips and occlusions
via local re-grounding without global re-planning. These results show that
path-structured representations enable Transformers to generate accurate,
reliable, and interpretable robot trajectories, bridging graph-based planning
and sequence-based learning and providing a practical foundation for
general-purpose manipulation and sim-to-real transfer.

</details>


### [7] [Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment](https://arxiv.org/abs/2510.20174)
*Yong Um,Young-Ha Shin,Joon-Ha Kim,Soonpyo Kwon,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出一种针对四足磁吸附爬壁机器人的强化学习框架，通过物理建模和课程学习解决磁脚附着不确定性问题，实现稳健的垂直表面爬行。


<details>
  <summary>Details</summary>
Motivation: 磁吸附爬壁机器人面临部分接触、气隙敏感性和概率性附着失败等不确定性，传统控制方法假设完美附着，在实际应用中容易失效。

Method: 采用三阶段课程学习：1) 在平坦地面学习爬行步态；2) 逐渐旋转重力矢量并激活吸附模型；3) 注入随机附着失败以训练滑移恢复能力。

Result: 学习策略在仿真中实现高成功率、强吸附保持和快速脱离恢复，优于假设完美附着的MPC基线。硬件实验验证了在钢表面的稳健垂直爬行。

Conclusion: 结合课程学习和真实吸附建模为磁吸附爬壁机器人提供了在复杂环境中具有弹性的仿真到现实框架。

Abstract: We present a reinforcement learning framework for quadrupedal wall-climbing
locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A
physics-based adhesion model of a quadrupedal magnetic climbing robot is
incorporated into simulation to capture partial contact, air-gap sensitivity,
and probabilistic attachment failures. To stabilize learning and enable
reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait
on flat ground without adhesion, (2) gradually rotate the gravity vector to
vertical while activating the adhesion model, and (3) inject stochastic
adhesion failures to encourage slip recovery. The learned policy achieves a
high success rate, strong adhesion retention, and rapid recovery from
detachment in simulation under degraded adhesion. Compared with a model
predictive control (MPC) baseline that assumes perfect adhesion, our controller
maintains locomotion when attachment is intermittently lost. Hardware
experiments with the untethered robot further confirm robust vertical crawling
on steel surfaces, maintaining stability despite transient misalignment and
incomplete attachment. These results show that combining curriculum learning
with realistic adhesion modeling provides a resilient sim-to-real framework for
magnetic climbing robots in complex environments.

</details>


### [8] [A Contact-Driven Framework for Manipulating in the Blind](https://arxiv.org/abs/2510.20177)
*Muhammad Suhail Saleem,Lai Yuan,Maxim Likhachev*

Main category: cs.RO

TL;DR: 提出了一个在视觉受限环境中利用接触反馈和结构先验进行机器人操作的完整框架，包含接触检测定位、占用估计和规划三个模块，在模拟和真实环境中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在视觉受限环境（如遮挡、光线差）中的操作问题，利用接触反馈和结构先验来感知环境并导航。

Method: 框架包含三个耦合组件：基于关节扭矩传感的接触检测定位模块、利用接触历史构建占用地图并预测未探索区域的占用估计模块、考虑噪声的规划模块。

Result: 在模拟和真实UR10e机械臂上测试了两个家庭任务（操作厨房水槽下的阀门、从杂乱货架取物），任务完成时间相比基线最多减少2倍，各模块均有贡献。

Conclusion: 该框架能可靠解决视觉受限环境中的操作任务，通过整合接触反馈和结构先验实现了高效操作。

Abstract: Robots often face manipulation tasks in environments where vision is
inadequate due to clutter, occlusions, or poor lighting--for example, reaching
a shutoff valve at the back of a sink cabinet or locating a light switch above
a crowded shelf. In such settings, robots, much like humans, must rely on
contact feedback to distinguish free from occupied space and navigate around
obstacles. Many of these environments often exhibit strong structural
priors--for instance, pipes often span across sink cabinets--that can be
exploited to anticipate unseen structure and avoid unnecessary collisions. We
present a theoretically complete and empirically efficient framework for
manipulation in the blind that integrates contact feedback with structural
priors to enable robust operation in unknown environments. The framework
comprises three tightly coupled components: (i) a contact detection and
localization module that utilizes joint torque sensing with a contact particle
filter to detect and localize contacts, (ii) an occupancy estimation module
that uses the history of contact observations to build a partial occupancy map
of the workspace and extrapolate it into unexplored regions with learned
predictors, and (iii) a planning module that accounts for the fact that contact
localization estimates and occupancy predictions can be noisy, computing paths
that avoid collisions and complete tasks efficiently without eliminating
feasible solutions. We evaluate the system in simulation and in the real world
on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
under a kitchen sink surrounded by pipes and (ii) retrieving a target object
from a cluttered shelf. Results show that the framework reliably solves these
tasks, achieving up to a 2x reduction in task completion time compared to
baselines, with ablations confirming the contribution of each module.

</details>


### [9] [NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof](https://arxiv.org/abs/2510.20231)
*Yuta Takahashi,Atsuki Ochi,Yoichi Tomioka,Shin-Ichiro Sakai*

Main category: cs.RO

TL;DR: 该研究通过实验验证了基于学习辅助磁场相互作用的大规模卫星群控制原理，使用磁力矩器实现长期编队保持，解决了多卫星控制中的非线性挑战。


<details>
  <summary>Details</summary>
Motivation: 解决多卫星编队控制中的四个基本挑战：非完整约束、欠驱动、可扩展性和计算成本，特别是当卫星数量超过三个时的高非线性问题。

Method: 采用学习辅助的时间积分电流控制方法，设计两轴线圈和基于气浮平台的地面实验装置，开发NODA-MMH算法进行基于模型的功率最优群控制。

Result: 实验验证了学习辅助时间积分电流控制的两个关键方面：增强平均系统动态的可控性（具有理论保证的误差界限）和分散式电流管理。

Conclusion: 该研究为磁驱动卫星群的长期编队维护问题提供了有效的解决方案，通过学习交互模型实现了功率最优的群控制。

Abstract: This study experimentally validates the principle of large-scale satellite
swarm control through learning-aided magnetic field interactions generated by
satellite-mounted magnetorquers. This actuation presents a promising solution
for the long-term formation maintenance of multiple satellites and has
primarily been demonstrated in ground-based testbeds for two-satellite position
control. However, as the number of satellites increases beyond three,
fundamental challenges coupled with the high nonlinearity arise: 1)
nonholonomic constraints, 2) underactuation, 3) scalability, and 4)
computational cost. Previous studies have shown that time-integrated current
control theoretically solves these problems, where the average actuator outputs
align with the desired command, and a learning-based technique further enhances
their performance. Through multiple experiments, we validate critical aspects
of learning-aided time-integrated current control: (1) enhanced controllability
of the averaged system dynamics, with a theoretically guaranteed error bound,
and (2) decentralized current management. We design two-axis coils and a
ground-based experimental setup utilizing an air-bearing platform, enabling a
mathematical replication of orbital dynamics. Based on the effectiveness of the
learned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole
Allocation for certified learned Model-based Magnetically swarm control
Harness) for model-based power-optimal swarm control. This study complements
our tutorial paper on magnetically actuated swarms for the long-term formation
maintenance problem.

</details>


### [10] [Kinaema: a recurrent sequence model for memory and pose in motion](https://arxiv.org/abs/2510.20261)
*Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf*

Main category: cs.RO

TL;DR: Kinaema模型通过隐式潜在记忆实现机器人空间定位，能够在连续操作中利用先前观察信息进行高效导航


<details>
  <summary>Details</summary>
Motivation: 解决机器人在连续操作中如何利用先前观察信息来优化定位效率的问题，特别是在大规模场景中的空间感知能力

Method: 提出Kinaema模型，使用Transformer以循环方式更新隐式潜在记忆，压缩传感器观测历史为紧凑表示，不显式存储观测历史

Result: 模型在Mem-Nav任务中保持有用的场景表示，能够导航到实际任务开始前观察到的目标位置，计算效率优于传统基于观测历史注意力的Transformer

Conclusion: Kinaema通过隐式记忆机制实现了高效的空间定位和导航，突破了传统方法在上下文长度上的限制

Abstract: One key aspect of spatially aware robots is the ability to "find their
bearings", ie. to correctly situate themselves in previously seen spaces. In
this work, we focus on this particular scenario of continuous robotics
operations, where information observed before an actual episode start is
exploited to optimize efficiency. We introduce a new model, Kinaema, and agent,
capable of integrating a stream of visual observations while moving in a
potentially large scene, and upon request, processing a query image and
predicting the relative position of the shown space with respect to its current
position. Our model does not explicitly store an observation history, therefore
does not have hard constraints on context length. It maintains an implicit
latent memory, which is updated by a transformer in a recurrent way,
compressing the history of sensor readings into a compact representation. We
evaluate the impact of this model in a new downstream task we call "Mem-Nav".
We show that our large-capacity recurrent model maintains a useful
representation of the scene, navigates to goals observed before the actual
episode start, and is computationally efficient, in particular compared to
classical transformers with attention over an observation history.

</details>


### [11] [MemER: Scaling Up Memory for Robot Control via Experience Retrieval](https://arxiv.org/abs/2510.20328)
*Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出MemER分层策略框架，让机器人策略具备记忆能力，通过高层策略选择相关关键帧，结合近期帧生成指令给底层策略执行，在需要分钟级记忆的长时程操作任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 人类依赖记忆执行任务，但大多数机器人策略缺乏这种能力。直接使用长观测历史计算昂贵且脆弱，而简单采样历史会导致信息冗余或无关

Method: 分层策略框架：高层策略训练用于选择和跟踪历史相关关键帧，使用选定关键帧和最新帧生成文本指令给底层VLA模型执行

Result: 在三个需要分钟级记忆的真实世界长时程机器人操作任务中，MemER方法优于先前方法

Conclusion: 该设计兼容现有VLA模型，使系统能够高效推理长时程依赖关系，通过最小语言标注的演示进行微调

Abstract: Humans routinely rely on memory to perform tasks, yet most robot policies
lack this capability; our goal is to endow robot policies with the same
ability. Naively conditioning on long observation histories is computationally
expensive and brittle under covariate shift, while indiscriminate subsampling
of history leads to irrelevant or redundant information. We propose a
hierarchical policy framework, where the high-level policy is trained to select
and track previous relevant keyframes from its experience. The high-level
policy uses selected keyframes and the most recent frames when generating text
instructions for a low-level policy to execute. This design is compatible with
existing vision-language-action (VLA) models and enables the system to
efficiently reason over long-horizon dependencies. In our experiments, we
finetune Qwen2.5-VL-7B-Instruct and $\pi_{0.5}$ as the high-level and low-level
policies respectively, using demonstrations supplemented with minimal language
annotations. Our approach, MemER, outperforms prior methods on three real-world
long-horizon robotic manipulation tasks that require minutes of memory. Videos
and code can be found at https://jen-pan.github.io/memer/.

</details>


### [12] [Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking](https://arxiv.org/abs/2510.20335)
*Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren*

Main category: cs.RO

TL;DR: 提出Dino-Diffusion Parking (DDP)方法，结合视觉基础模型和扩散规划，实现领域无关的自动驾驶停车系统，在分布偏移下保持高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有端到端停车方法在领域偏移（如天气和光照变化）下的鲁棒性不足，需要一种不依赖额外数据的通用解决方案。

Method: 整合视觉基础模型进行通用感知，使用扩散模型进行运动规划，在CARLA中训练并在对抗性设置中进行零样本迁移。

Result: 在所有测试的分布外场景中，停车成功率均超过90%，在3D高斯泼溅重建的真实停车场环境中显示出有前景的仿真到真实迁移能力。

Conclusion: DDP方法通过结合视觉基础模型和扩散规划，显著提升了跨领域停车性能，为自动驾驶停车系统提供了鲁棒且通用的解决方案。

Abstract: Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

</details>


### [13] [Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots](https://arxiv.org/abs/2510.20347)
*Ashutosh Mishra,Shreya Santra,Elian Neppel,Edoardo M. Rossi Lombardi,Shamistan Karimov,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种去中心化强化学习方案，让模块化机器人的每个模块学习自己的策略，实现零样本泛化到未见过的配置，在仿真和月球模拟现场测试中验证了自主运动、转向和重构的可行性。


<details>
  <summary>Details</summary>
Motivation: 模块化可重构机器人适合特定任务的空间操作，但形态组合增长阻碍了统一控制，需要解决模块化机器人的控制泛化问题。

Method: 采用去中心化强化学习方案：轮式模块使用SAC算法进行运动控制，7自由度肢体模块使用PPO算法进行转向和操作，实现零样本泛化到未见配置。

Result: 仿真中转向策略平均绝对误差3.63度，操作策略成功率84.6%，轮式策略相比基线减少95.4%电机扭矩且保持99.6%成功率。月球模拟现场测试验证了自主运动、转向和重构对齐的零样本集成。

Conclusion: 系统在策略执行中平滑切换同步、并行和顺序模式，无空闲状态或控制冲突，表明该方法对模块化月球机器人具有可扩展性、可重用性和鲁棒性。

Abstract: Modular reconfigurable robots suit task-specific space operations, but the
combinatorial growth of morphologies hinders unified control. We propose a
decentralized reinforcement learning (Dec-RL) scheme where each module learns
its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and
7-DoF limbs use Proximal Policy Optimization (PPO) for steering and
manipulation, enabling zero-shot generalization to unseen configurations. In
simulation, the steering policy achieved a mean absolute error of 3.63{\deg}
between desired and induced angles; the manipulation policy plateaued at 84.6 %
success on a target-offset criterion; and the wheel policy cut average motor
torque by 95.4 % relative to baseline while maintaining 99.6 % success.
Lunar-analogue field tests validated zero-shot integration for autonomous
locomotion, steering, and preliminary alignment for reconfiguration. The system
transitioned smoothly among synchronous, parallel, and sequential modes for
Policy Execution, without idle states or control conflicts, indicating a
scalable, reusable, and robust approach for modular lunar robots.

</details>


### [14] [NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control](https://arxiv.org/abs/2510.20390)
*Yijiong Lin,Bowen Deng,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: NeuralTouch是一个多模态框架，结合神经描述场(NDF)和触觉传感，通过轻柔物理交互实现准确、可泛化的抓取。


<details>
  <summary>Details</summary>
Motivation: NDF单独使用时由于相机标定不完美、点云不完整和物体变化性会产生不准确的抓取姿态，而现有触觉方法通常局限于简单的预定义接触几何形状。

Method: 利用NDF隐式表示目标接触几何，训练深度强化学习策略使用触觉反馈来优化抓取，该策略以神经描述符为条件，无需显式指定接触类型。

Result: 在仿真中的消融研究和零样本迁移到真实世界操作任务（如孔轴装配和瓶盖开启）中验证，无需额外微调。

Conclusion: NeuralTouch显著提高了抓取准确性和鲁棒性，为精确、接触丰富的机器人操作提供了一个通用框架。

Abstract: Grasping accuracy is a critical prerequisite for precise object manipulation,
often requiring careful alignment between the robot hand and object. Neural
Descriptor Fields (NDF) offer a promising vision-based method to generate
grasping poses that generalize across object categories. However, NDF alone can
produce inaccurate poses due to imperfect camera calibration, incomplete point
clouds, and object variability. Meanwhile, tactile sensing enables more precise
contact, but existing approaches typically learn policies limited to simple,
predefined contact geometries. In this work, we introduce NeuralTouch, a
multimodal framework that integrates NDF and tactile sensing to enable
accurate, generalizable grasping through gentle physical interaction. Our
approach leverages NDF to implicitly represent the target contact geometry,
from which a deep reinforcement learning (RL) policy is trained to refine the
grasp using tactile feedback. This policy is conditioned on the neural
descriptors and does not require explicit specification of contact types. We
validate NeuralTouch through ablation studies in simulation and zero-shot
transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle
lid opening--without additional fine-tuning. Results show that NeuralTouch
significantly improves grasping accuracy and robustness over baseline methods,
offering a general framework for precise, contact-rich robotic manipulation.

</details>


### [15] [PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning](https://arxiv.org/abs/2510.20406)
*Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann*

Main category: cs.RO

TL;DR: PointMapPolicy是一种新颖的扩散策略方法，通过在结构化点网格上调节而不进行下采样，结合点云和RGB数据，在机器人操作任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前点云方法难以捕捉细粒度细节，而RGB方法缺乏几何感知能力，限制了机器人操作的精度和泛化能力。需要结合两种感知模态的优势。

Method: 提出PointMapPolicy方法，在结构化点网格上调节扩散策略而不下采样，使用xLSTM作为骨干网络，有效融合点图和RGB数据进行多模态感知。

Result: 在RoboCasa和CALVIN基准测试以及真实机器人评估中，该方法在多样化操作任务上实现了最先进的性能。

Conclusion: PointMapPolicy通过结构化点网格和RGB数据的有效融合，显著提升了机器人操作的感知能力和任务性能。

Abstract: Robotic manipulation systems benefit from complementary sensing modalities,
where each provides unique environmental information. Point clouds capture
detailed geometric structure, while RGB images provide rich semantic context.
Current point cloud methods struggle to capture fine-grained detail, especially
for complex tasks, which RGB methods lack geometric awareness, which hinders
their precision and generalization. We introduce PointMapPolicy, a novel
approach that conditions diffusion policies on structured grids of points
without downsampling. The resulting data type makes it easier to extract shape
and spatial relationships from observations, and can be transformed between
reference frames. Yet due to their structure in a regular grid, we enable the
use of established computer vision techniques directly to 3D data. Using xLSTM
as a backbone, our model efficiently fuses the point maps with RGB data for
enhanced multi-modal perception. Through extensive experiments on the RoboCasa
and CALVIN benchmarks and real robot evaluations, we demonstrate that our
method achieves state-of-the-art performance across diverse manipulation tasks.
The overview and demos are available on our project page:
https://point-map.github.io/Point-Map/

</details>


### [16] [MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control](https://arxiv.org/abs/2510.20407)
*Kohei Nishi,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: 提出了一种基于混合现实的水下机器人手臂遥操作系统MR-UBi，通过双边控制和反应扭矩指示器，整合视觉和触觉反馈，提高了水下遥操作的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决水下机器人手臂遥操作中缺乏有效扭矩反馈的问题，提高操作精度和用户体验。

Method: 使用混合现实头戴显示器(MR-HMD)叠加颜色和长度编码的扭矩条作为反应扭矩指示器(RTI)，结合双边控制实现视觉和触觉反馈的整合。

Result: 与双边控制基线相比，MR-UBi显著提高了抓取扭矩控制精度，增加了在最佳扭矩范围内的时间，减少了低和高抓取扭矩范围，在提升和拾放任务中表现更好。主观评估显示更高的可用性(SUS)和更低的工作负荷(NASA-TLX)。

Conclusion: MR-UBi通过整合视觉和触觉反馈，实现了更稳定、准确和用户友好的水下机器人手臂遥操作。

Abstract: We present a mixed reality-based underwater robot arm teleoperation system
with a reaction torque indicator via bilateral control (MR-UBi). The reaction
torque indicator (RTI) overlays a color and length-coded torque bar in the
MR-HMD, enabling seamless integration of visual and haptic feedback during
underwater robot arm teleoperation. User studies with sixteen participants
compared MR-UBi against a bilateral-control baseline. MR-UBi significantly
improved grasping-torque control accuracy, increasing the time within the
optimal torque range and reducing both low and high grasping torque range
during lift and pick-and-place tasks with objects of different stiffness.
Subjective evaluations further showed higher usability (SUS) and lower workload
(NASA--TLX). Overall, the results confirm that \textit{MR-UBi} enables more
stable, accurate, and user-friendly underwater robot-arm teleoperation through
the integration of visual and haptic feedback. For additional material, please
check: https://mertcookimg.github.io/mr-ubi

</details>


### [17] [Robot Path and Trajectory Planning Considering a Spatially Fixed TCP](https://arxiv.org/abs/2510.20473)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller,Ronald Naderer*

Main category: cs.RO

TL;DR: 提出了一种在工作空间坐标系中规划轨迹的方法，使用固定工具中心点(TCP)，同时考虑零件上的加工路径，适用于移动零件比移动工具更容易的场景。


<details>
  <summary>Details</summary>
Motivation: 当移动零件比移动工具更容易时，需要一种能够规划固定TCP轨迹的方法，同时考虑零件加工路径。

Method: 使用B样条表示机器人路径，确保路径连续性和平滑轨迹，在计算机器人轨迹时考虑规定的方向和TCP速度。

Result: 该方法在工业机器人移动任意定义零件的真实系统上得到了验证。

Conclusion: 基于B样条的轨迹规划方法能够生成平滑的机器人轨迹，适用于固定TCP的加工场景。

Abstract: This paper presents a method for planning a trajectory in workspace
coordinates using a spatially fixed tool center point (TCP), while taking into
account the processing path on a part. This approach is beneficial if it is
easier to move the part rather than moving the tool. Whether a mathematical
description that defines the shape to be processed or single points from a
design program are used, the robot path is finally represented using B-splines.
The use of splines enables the path to be continuous with a desired degree,
which finally leads to a smooth robot trajectory. While calculating the robot
trajectory through prescribed orientation, additionally a given velocity at the
TCP has to be considered. The procedure was validated on a real system using an
industrial robot moving an arbitrary defined part.

</details>


### [18] [Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections](https://arxiv.org/abs/2510.20480)
*Václav Pritzl,Xianjia Yu,Tomi Westerlund,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种新颖的自适应多模态多机器人协同定位方法，使用因子图融合异步的视觉惯性里程计、激光雷达惯性里程计和3D机器人间检测，在传感器退化的GNSS拒绝环境中显著提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒绝环境中，单个机器人携带所有传感器会增加尺寸、重量和功耗需求。将传感器分布在多个机器人上可增强部署性，但带来了融合异步多模态数据的挑战。

Method: 使用因子图公式以松耦合方式融合异步VIO、LIO和3D机器人间检测。提出基于插值的因子融合非同步测量，基于近似扫描匹配Hessian评估LIO退化，并提出按连续VIO输出的Wasserstein距离比例加权里程计数据。

Result: 在真实世界数据上的广泛评估表明，该方法在各种传感器退化情况下显著提高了定位精度。

Conclusion: 所提出的方法能够适应变化的条件，利用可靠数据辅助受传感器退化影响的机器人，在存在各种传感器退化的情况下提供显著的定位精度改进。

Abstract: Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

</details>


### [19] [Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty](https://arxiv.org/abs/2510.20483)
*Victor Vantilborgh,Hrishikesh Sathyanarayan,Guillaume Crevecoeur,Ian Abraham,Tom Lefebvre*

Main category: cs.RO

TL;DR: 该论文提出两种方法来解决机器人操作任务中的未知动力学问题，通过在线参数适应和主动探索来提高模型控制精度。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作任务中未知动力学（如负载不确定性）的问题，需要主动探索和在线参数适应来实现准确的基于模型的控制。

Method: 1. 将问题构建为包含参数不确定性的闭环最优控制问题；2. 预定义包含显式适应机制的反馈策略结构；3. 提出两种参考轨迹生成方法：基于鲁棒最优控制的方法和基于最优性损失最小化的方法。

Result: 两种方法都能自然地考虑Fisher信息，同时追求最优任务执行。在拾取-放置操作任务中表现出更快速、更准确的任务性能和系统辨识能力。

Conclusion: 在考虑控制的同时设计参考轨迹，能够实现更快速准确的任务性能、系统辨识，并确保稳定高效的控制。

Abstract: This work addresses the problem of robot manipulation tasks under unknown
dynamics, such as pick-and-place tasks under payload uncertainty, where active
exploration and(/for) online parameter adaptation during task execution are
essential to enable accurate model-based control. The problem is framed as dual
control seeking a closed-loop optimal control problem that accounts for
parameter uncertainty. We simplify the dual control problem by pre-defining the
structure of the feedback policy to include an explicit adaptation mechanism.
Then we propose two methods for reference trajectory generation. The first
directly embeds parameter uncertainty in robust optimal control methods that
minimize the expected task cost. The second method considers minimizing the
so-called optimality loss, which measures the sensitivity of parameter-relevant
information with respect to task performance. We observe that both approaches
reason over the Fisher information as a natural side effect of their
formulations, simultaneously pursuing optimal task execution. We demonstrate
the effectiveness of our approaches for a pick-and-place manipulation task. We
show that designing the reference trajectories whilst taking into account the
control enables faster and more accurate task performance and system
identification while ensuring stable and efficient control.

</details>


### [20] [Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators](https://arxiv.org/abs/2510.20490)
*Thomas Kordik,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文研究如何通过优化轨迹和串联弹性驱动器刚度来最小化执行拾取放置任务的并联机器人的能量消耗。


<details>
  <summary>Details</summary>
Motivation: 工业机器人执行拾取放置任务时通常长时间运行，因此最小化能耗具有重要意义。串联弹性驱动器通过激发特征运动来利用振荡特性，可能实现能量优化。

Method: 推导SEA驱动并联机器人的动态模型，建立能量最小化的最优控制问题，同时优化操作轨迹和SEA刚度，并在两个并联机器人应用上进行测试。

Result: 该方法在两个并联机器人应用中验证了有效性，证实了能量减少的假设。

Conclusion: 通过同时优化轨迹和弹性驱动器刚度，可以有效降低执行拾取放置任务的并联机器人的能量消耗。

Abstract: A major field of industrial robot applications deals with repetitive tasks
that alternate between operating points. For these so-called pick-and-place
operations, parallel kinematic manipulators (PKM) are frequently employed.
These tasks tend to automatically run for a long period of time and therefore
minimizing energy consumption is always of interest. Recent research addresses
this topic by the use of elastic elements and particularly series elastic
actuators (SEA). This paper explores the possibilities of minimizing energy
consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea
is to excite eigenmotions that result from the actuator springs and exploit
their oscillating characteristics. To this end, a prescribed cyclic
pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is
derived. Subsequently, an energy minimizing optimal control problem is
formulated where operating trajectories as well as SEA stiffnesses are
optimized simultaneously. Here, optimizing the actuator stiffness does not
account for variable stiffness actuators. It serves as a tool for the design
and dimensioning process. The hypothesis on energy reduction is tested on two
(parallel) robot applications where redundant actuation is also addressed. The
results confirm the validity of this approach.

</details>


### [21] [A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator](https://arxiv.org/abs/2510.20496)
*Tobias Marauli,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种基于最大化路径速度的时间最优路径跟踪方法，避免了传统方法在零路径速度时的奇异性问题，能够高效生成平滑轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统时间最优路径跟踪方法在最小化旅行时间时，会在零路径速度处产生奇异性，导致计算复杂且难以生成平滑轨迹。

Method: 采用最大化路径速度的方法，将问题重新表述为线性优化变量问题，实现数值高效计算。

Result: 该方法能够避免奇异性问题，同时保持低计算复杂度，实现平滑轨迹规划。

Conclusion: 基于最大化路径速度的方法为时间最优路径跟踪提供了一种计算高效且平滑的解决方案。

Abstract: In this paper the computational challenges of time-optimal path following are
addressed. The standard approach is to minimize the travel time, which
inevitably leads to singularities at zero path speed, when reformulating the
optimization problem in terms of a path parameter. Thus, smooth trajectory
generation while maintaining a low computational effort is quite challenging,
since the singularities have to be taken into account. To this end, a different
approach is presented in this paper. This approach is based on maximizing the
path speed along a prescribed path. Furthermore, the approach is capable of
planning smooth trajectories numerically efficient. Moreover, the discrete
reformulation of the underlying problem is linear in optimization variables.

</details>


### [22] [RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping](https://arxiv.org/abs/2510.20529)
*Constantine Frost,Chad Council,Margaret McGuinness,Nathaniel Hanson*

Main category: cs.RO

TL;DR: 提出了RubbleSim，一个开源、可重构的模拟器，用于在结构坍塌事故中进行逼真的空隙空间探索，以解决真实数据获取困难的问题。


<details>
  <summary>Details</summary>
Motivation: 由于法律约束和机构所有权问题，真实坍塌事故中的空隙空间数据难以获取，而训练用的工程废墟堆也不愿公开其专有训练场信息。

Method: 使用Unity开发多操作系统支持的模拟器，采用基于物理的方法构建随机废墟堆，允许快速迭代模拟世界并保留绝对真实数据。

Result: 应用最先进的结构从运动算法，展示了在模拟空隙空间中具有挑战性的视觉条件下感知性能如何下降。

Conclusion: RubbleSim为研究坍塌空隙空间探索提供了一个可行的替代方案，解决了真实数据获取的障碍。

Abstract: Despite well-reported instances of robots being used in disaster response,
there is scant published data on the internal composition of the void spaces
within structural collapse incidents. Data collected during these incidents is
mired in legal constraints, as ownership is often tied to the responding
agencies, with little hope of public release for research. While engineered
rubble piles are used for training, these sites are also reluctant to release
information about their proprietary training grounds. To overcome this access
challenge, we present RubbleSim -- an open-source, reconfigurable simulator for
photorealistic void space exploration. The design of the simulation assets is
directly informed by visits to numerous training rubble sites at differing
levels of complexity. The simulator is implemented in Unity with
multi-operating system support. The simulation uses a physics-based approach to
build stochastic rubble piles, allowing for rapid iteration between simulation
worlds while retaining absolute knowledge of the ground truth. Using RubbleSim,
we apply a state-of-the-art structure-from-motion algorithm to illustrate how
perception performance degrades under challenging visual conditions inside the
emulated void spaces. Pre-built binaries and source code to implement are
available online: https://github.com/mit-ll/rubble_pile_simulator.

</details>


### [23] [C-NAV: Towards Self-Evolving Continual Object Navigation in Open World](https://arxiv.org/abs/2510.20685)
*Ming-Ming Yu,Fei Zhu,Wenzhuo Liu,Yirong Yang,Qunbo Wang,Wenjun Wu,Jing Liu*

Main category: cs.RO

TL;DR: 提出了C-Nav框架，用于解决持续目标导航问题，通过双路径抗遗忘机制和自适应采样策略，在避免灾难性遗忘的同时降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态轨迹和固定对象类别，忽略了现实世界中需要持续适应变化场景的需求，因此需要开发能够持续学习新对象类别导航技能而不遗忘已学知识的智能体。

Method: C-Nav框架包含：(1)双路径抗遗忘机制：特征蒸馏将多模态输入对齐到一致表示空间确保表示一致性，特征重放在动作解码器中保留时间特征确保策略一致性；(2)自适应采样策略选择多样化和信息丰富的经验，减少冗余并最小化内存开销。

Result: 在多种模型架构上的广泛实验表明，C-Nav始终优于现有方法，即使与保留完整轨迹的基线相比也能实现更优性能，同时显著降低内存需求。

Conclusion: C-Nav框架有效解决了持续目标导航中的灾难性遗忘问题，通过创新的抗遗忘机制和采样策略实现了高性能和低内存消耗的平衡。

Abstract: Embodied agents are expected to perform object navigation in dynamic,
open-world environments. However, existing approaches typically rely on static
trajectories and a fixed set of object categories during training, overlooking
the real-world requirement for continual adaptation to evolving scenarios. To
facilitate related studies, we introduce the continual object navigation
benchmark, which requires agents to acquire navigation skills for new object
categories while avoiding catastrophic forgetting of previously learned
knowledge. To tackle this challenge, we propose C-Nav, a continual visual
navigation framework that integrates two key innovations: (1) A dual-path
anti-forgetting mechanism, which comprises feature distillation that aligns
multi-modal inputs into a consistent representation space to ensure
representation consistency, and feature replay that retains temporal features
within the action decoder to ensure policy consistency. (2) An adaptive
sampling strategy that selects diverse and informative experiences, thereby
reducing redundancy and minimizing memory overhead. Extensive experiments
across multiple model architectures demonstrate that C-Nav consistently
outperforms existing approaches, achieving superior performance even compared
to baselines with full trajectory retention, while significantly lowering
memory requirements. The code will be publicly available at
https://bigtree765.github.io/C-Nav-project.

</details>


### [24] [Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning](https://arxiv.org/abs/2510.20706)
*Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出了一种结合MPPI和Dreamer模块的优化框架，用于四足机器人在连续步态空间中的实时步态自适应，显著降低能耗并保持精确跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决模型自由强化学习中策略收敛到单一步态导致性能次优的问题，以及传统MPC无法适应变化环境的局限性。

Method: 在每个时间步使用MPPI联合优化动作和步态变量，结合学习的Dreamer奖励函数（促进速度跟踪、能效、稳定性和平滑过渡）和值函数作为终端奖励。

Result: 在Unitree Go1仿真中，在不同目标速度下平均能耗降低高达36.48%，同时保持精确跟踪和适应性步态。

Conclusion: 该框架成功实现了四足机器人的自适应和最优步态策略，在能耗和性能方面均有显著提升。

Abstract: Model-free reinforcement learning (RL) has enabled adaptable and agile
quadruped locomotion; however, policies often converge to a single gait,
leading to suboptimal performance. Traditionally, Model Predictive Control
(MPC) has been extensively used to obtain task-specific optimal policies but
lacks the ability to adapt to varying environments. To address these
limitations, we propose an optimization framework for real-time gait adaptation
in a continuous gait space, combining the Model Predictive Path Integral (MPPI)
algorithm with a Dreamer module to produce adaptive and optimal policies for
quadruped locomotion. At each time step, MPPI jointly optimizes the actions and
gait variables using a learned Dreamer reward that promotes velocity tracking,
energy efficiency, stability, and smooth transitions, while penalizing abrupt
gait changes. A learned value function is incorporated as terminal reward,
extending the formulation to an infinite-horizon planner. We evaluate our
framework in simulation on the Unitree Go1, demonstrating an average reduction
of up to 36.48\% in energy consumption across varying target speeds, while
maintaining accurate tracking and adaptive, task-appropriate gaits.

</details>


### [25] [FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation](https://arxiv.org/abs/2510.20774)
*Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu*

Main category: cs.RO

TL;DR: FieldGen是一个场引导的数据生成框架，通过分解操作任务为预操作和精细操作两个阶段，结合人类演示的关键信息和自动生成的多样化轨迹，实现大规模、多样化且高质量的真实世界数据收集。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据收集方法难以平衡规模、多样性和质量。仿真方法可扩展但存在仿真到现实的差距，遥操作方法质量高但多样性有限且人力成本高。

Method: 将操作任务分解为预操作阶段（允许轨迹多样性）和精细操作阶段（需要专家精度）。人类演示捕捉关键接触和姿态信息，然后通过吸引场自动生成多样化的轨迹，收敛到成功配置。

Result: 使用FieldGen训练的策略相比基于遥操作的基线方法，实现了更高的成功率和改进的稳定性，同时显著减少了长期真实世界数据收集的人力投入。

Conclusion: FieldGen框架成功解决了机器人操作数据收集中规模、多样性和质量的平衡问题，通过解耦设计和自动轨迹生成，实现了高效的数据收集和策略学习。

Abstract: Large-scale and diverse datasets are vital for training robust robotic
manipulation policies, yet existing data collection methods struggle to balance
scale, diversity, and quality. Simulation offers scalability but suffers from
sim-to-real gaps, while teleoperation yields high-quality demonstrations with
limited diversity and high labor cost. We introduce FieldGen, a field-guided
data generation framework that enables scalable, diverse, and high-quality
real-world data collection with minimal human supervision. FieldGen decomposes
manipulation into two stages: a pre-manipulation phase, allowing trajectory
diversity, and a fine manipulation phase requiring expert precision. Human
demonstrations capture key contact and pose information, after which an
attraction field automatically generates diverse trajectories converging to
successful configurations. This decoupled design combines scalable trajectory
diversity with precise supervision. Moreover, FieldGen-Reward augments
generated data with reward annotations to further enhance policy learning.
Experiments demonstrate that policies trained with FieldGen achieve higher
success rates and improved stability compared to teleoperation-based baselines,
while significantly reducing human effort in long-term real-world data
collection. Webpage is available at https://fieldgen.github.io/.

</details>


### [26] [The Reality Gap in Robotics: Challenges, Solutions, and Best Practices](https://arxiv.org/abs/2510.20808)
*Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos*

Main category: cs.RO

TL;DR: 这篇论文是关于机器人学中仿真到现实转移问题的综述，探讨了仿真与现实环境之间的差异（现实差距）以及克服这些差距的各种技术方法。


<details>
  <summary>Details</summary>
Motivation: 机器学习在机器人领域的应用日益广泛，但仿真环境与现实世界之间存在显著差异（现实差距），这阻碍了仿真训练系统在现实中的成功部署。理解并解决这一差距是机器人学面临的关键挑战。

Method: 论文采用综述研究方法，系统分析了仿真到现实转移领域的现状，包括领域随机化、现实到仿真转移、状态和动作抽象、仿真-现实协同训练等多种技术方法。

Result: 研究表明，通过上述技术方法，许多研究工作已经成功克服了现实差距，在运动、导航和操作等多个机器人平台上取得了有前景的结果。

Conclusion: 尽管已有进展，但现实差距问题仍然存在挑战，需要更深入地理解其根本原因和解决方案。论文为仿真到现实转移领域提供了全面的概览和分析框架。

Abstract: Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.

</details>


### [27] [GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation](https://arxiv.org/abs/2510.20813)
*Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: GSWorld是一个结合3D高斯泼溅和物理引擎的机器人操作模拟器，通过GSDF格式实现逼真渲染，支持多种应用如零样本sim2real策略学习和可复现评估。


<details>
  <summary>Details</summary>
Motivation: 开发一个逼真的机器人操作模拟器，实现从真实机器人数据学习策略的可复现评估，以及无需真实机器人的sim2real策略训练。

Method: 提出GSDF（高斯场景描述文件）格式，将高斯-网格表示与机器人URDF和其他对象结合，构建包含3种机器人形态和40多个物体的数据库。

Result: 展示了五个应用：零样本sim2real像素到动作策略学习、自动化DAgger数据收集、可复现基准测试、虚拟遥操作数据收集和零样本sim2real视觉强化学习。

Conclusion: GSWorld为机器人操作提供了一个强大且逼真的模拟平台，实现了从真实数据学习到sim2real策略训练的闭环开发流程。

Abstract: This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.

</details>


### [28] [VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation](https://arxiv.org/abs/2510.20818)
*Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta*

Main category: cs.RO

TL;DR: VAMOS是一个分层视觉语言导航系统，通过将语义规划与具体化接地分离，实现了跨不同机器人平台（轮式和腿式）的通用导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中学习策略在不同环境中泛化的问题，同时适应特定机器人的物理约束和能力差异。

Method: 使用分层VLA架构：通用规划器从多样化开放世界数据学习，专门化affordance模型在低成本模拟中学习机器人物理约束，通过图像空间路径提案和评估实现分离。

Result: 在室内和复杂室外导航中比最先进的模型和端到端学习方法获得更高成功率，支持跨具体化导航，单机器人可靠性提升3倍。

Conclusion: 分层设计是关键，专门化模型实现了具体化接地，使单一高层规划器能够部署在物理特性不同的轮式和腿式机器人上。

Abstract: A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/

</details>
