<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 144]
- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TeleMem: Building Long-Term and Multimodal Memory for Agentic AI](https://arxiv.org/abs/2601.06037)
*Chunliang Chen,Ming Guan,Xiao Lin,Jiaxu Li,Qiyi Wang,Xiangyu Chen,Jixiang Luo,Changzhi Sun,Dell Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: TeleMem是一个统一的长时多模态记忆系统，通过叙事动态提取维护连贯用户画像，采用结构化写入管道提升存储效率，结合多模态记忆模块和ReAct推理实现视频内容理解，在长时对话任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长时对话中因注意力限制而表现不佳，现有的检索增强生成方法缺乏可靠的内存更新机制，存在模式驱动的幻觉、低效的写入操作和有限的多模态推理支持。

Method: 1) 叙事动态提取确保只保留对话基础信息；2) 结构化写入管道批量处理、检索、聚类和整合记忆条目；3) 多模态记忆模块结合ReAct式推理（观察-思考-行动的闭环过程）。

Result: 在ZH-4O长时角色扮演游戏基准测试中，TeleMem比最先进的Mem0基线准确率提高19%，token使用减少43%，速度提升2.1倍。

Conclusion: TeleMem通过统一的长时多模态记忆系统有效解决了LLMs在长时对话中的局限性，在准确性、效率和速度方面均显著优于现有方法。

Abstract: Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to schema-driven hallucinations, inefficient write operations, and minimal support for multimodal reasoning.To address these challenges, we propose TeleMem, a unified long-term and multimodal memory system that maintains coherent user profiles through narrative dynamic extraction, ensuring that only dialogue-grounded information is preserved. TeleMem further introduces a structured writing pipeline that batches, retrieves, clusters, and consolidates memory entries, substantially improving storage efficiency, reducing token usage, and accelerating memory operations. Additionally, a multimodal memory module combined with ReAct-style reasoning equips the system with a closed-loop observe, think, and act process that enables accurate understanding of complex video content in long-term contexts. Experimental results show that TeleMem surpasses the state-of-the-art Mem0 baseline with 19% higher accuracy, 43% fewer tokens, and a 2.1x speedup on the ZH-4O long-term role-play gaming benchmark.

</details>


### [2] [Operation Veja: Fixing Fundamental Concepts Missing from Modern Roleplaying Training Paradigms](https://arxiv.org/abs/2601.06039)
*Yueze Liu,Ajay Nagi Reddy Kumdam,Ronit Kanjilal,Hao Yang,Yichi Zhang*

Main category: cs.CL

TL;DR: 提出VEJA框架（价值观、经验、判断、能力）作为角色扮演模型的新数据策展范式，解决现有方法在建模角色内部动态互动上的局限性


<details>
  <summary>Details</summary>
Motivation: 当前角色扮演模型虽然越来越复杂，但始终难以创造可信、有深度的角色。现有训练范式（包括RAG、基于事实的引导、文献学习和合成数据生成）忽视了角色内部世界的动态互动，无法建模人类互动中特有的深思熟虑和价值冲突的推理过程

Method: 提出VEJA框架作为新的数据策展范式，包含四个核心概念：价值观、经验、判断、能力。通过手动策展的VEJA数据集与最先进的合成基线进行对比研究，使用LLM作为评判者进行评估

Result: VEJA框架在角色真实性方面展现出显著的质量优势，表明基于概念的数据策展方法对于创造有深度和叙事连续性的角色扮演代理是必要的

Conclusion: 需要向概念基础的数据策展范式转变，VEJA框架为实现真正有深度的角色扮演代理提供了新的方向，数据集已开源

Abstract: Modern roleplaying models are increasingly sophisticated, yet they consistently struggle to capture the essence of believable, engaging characters. We argue this failure stems from training paradigms that overlook the dynamic interplay of a character's internal world. Current approaches, including Retrieval-Augmented Generation (RAG), fact-based priming, literature-based learning, and synthetic data generation, exhibit recurring limitations in modeling the deliberative, value-conflicted reasoning that defines human interaction. In this paper, we identify four core concepts essential for character authenticity: Values, Experiences, Judgments, and Abilities (VEJA). We propose the VEJA framework as a new paradigm for data curation that addresses these systemic limitations. To illustrate the qualitative ceiling enabled by our framework, we present a pilot study comparing a manually curated, VEJA-grounded dataset against a state-of-the-art synthetic baseline. Using an LLM-as-judge evaluation, our findings demonstrate a significant quality gap, suggesting that a shift toward conceptually grounded data curation, as embodied by VEJA, is necessary for creating roleplaying agents with genuine depth and narrative continuity. The full dataset is available at https://github.com/HyouinKyoumaIRL/Operation-Veja

</details>


### [3] [Lexical and Statistical Analysis of Bangla Newspaper and Literature: A Corpus-Driven Study on Diversity, Readability, and NLP Adaptation](https://arxiv.org/abs/2601.06041)
*Pramit Bhattacharyya,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 通过对孟加拉语文学和新闻文本的语料库分析，发现文学语料库在词汇多样性、结构复杂性和可读性方面均显著高于新闻语料库，且加入文学数据能提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 研究孟加拉语文学和新闻文本的语言特性差异，探索文学语料在词汇丰富度、结构复杂性和可读性方面的特点，以及文学数据对自然语言处理任务的影响。

Method: 使用Vacaspati（文学）和IndicCorp（新闻）两大孟加拉语语料库，分析类型-标记比、单现词比例、二元组多样性、平均音节/词长、Zipf定律等特征，构建n-gram模型计算困惑度，并评估下游任务性能。

Result: 文学语料库在所有特征上都显示出更高的词汇丰富度和结构变化，困惑度更高，更符合Zipf定律，熵值更高而冗余度更低，可读性更复杂，且加入文学数据能提升模型在下游任务中的性能。

Conclusion: 孟加拉语文学文本比新闻文本具有更高的语言复杂性和多样性，文学语料库能更好地反映语言全局分布特性，将文学数据纳入训练能提升自然语言处理模型的性能。

Abstract: In this paper, we present a comprehensive corpus-driven analysis of Bangla literary and newspaper texts to investigate their lexical diversity, structural complexity and readability. We undertook Vacaspati and IndicCorp, which are the most extensive literature and newspaper-only corpora for Bangla. We examine key linguistic properties, including the type-token ratio (TTR), hapax legomena ratio (HLR), Bigram diversity, average syllable and word lengths, and adherence to Zipfs Law, for both newspaper (IndicCorp) and literary corpora (Vacaspati).For all the features, such as Bigram Diversity and HLR, despite its smaller size, the literary corpus exhibits significantly higher lexical richness and structural variation. Additionally, we tried to understand the diversity of corpora by building n-gram models and measuring perplexity. Our findings reveal that literary corpora have higher perplexity than newspaper corpora, even for similar sentence sizes. This trend can also be observed for the English newspaper and literature corpus, indicating its generalizability. We also examined how the perfor- mance of models on downstream tasks is influenced by the inclusion of literary data alongside newspaper data. Our findings suggest that inte- grating literary data with newspapers improves the performance of models on various downstream tasks. We have also demonstrated that a literary corpus adheres more closely to global word distribution proper- ties, such as Zipfs law, than a newspaper corpus or a merged corpus of both literary and newspaper texts. Literature corpora also have higher entropy and lower redundancy values compared to a newspaper corpus. We also further assess the readability using Flesch and Coleman-Liau in- dices, showing that literary texts are more complex.

</details>


### [4] [Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization](https://arxiv.org/abs/2601.06052)
*Hanyu Li,Jiangshan Duo,Bofei Gao,Hailin Zhang,Sujian Li,Xiaotie Deng,Liang Zhao*

Main category: cs.CL

TL;DR: 提出一种样本级软强化学习压缩方法，减少大语言模型链式思考推理的过度思考问题，在保持或提高准确性的同时缩短响应长度20-40%，并展示跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的链式思考推理经常陷入"过度思考陷阱"，导致计算成本和延迟增加，但准确性提升不可靠。现有方法通常依赖全局静态控制，可能惩罚必要的推理过程。

Method: 提出样本级软强化学习压缩方法，仅对模型已掌握并能产生更简洁推理路径的问题，惩罚过长的推理过程。采用后训练课程学习（准确性-压缩-准确性）策略。

Result: 方法将平均响应长度减少20-40%，同时保持或提高准确性。压缩效果具有强跨领域泛化能力：在数学任务上训练的模型能在代码、指令遵循和常识问答等未见任务上自发缩短响应。

Conclusion: 这种压缩方法应成为开发高效推理模型的标准阶段，能够最终产生更准确且推理更简洁的模型，通过稳定的后训练课程学习实现准确性-压缩-准确性的良性循环。

Abstract: Chain-of-thought reasoning in large language models often creates an "overthinking trap," leading to excessive computational cost and latency for unreliable accuracy gains. Prior work has typically relied on global, static controls that risk penalizing necessary reasoning. We introduce a sample-level, soft reinforcement learning compression method that penalizes inefficiently long rollouts, but only on problems where the model has already mastered and already produced a more concise rollout. Our experiments show that this method reduces average response length by 20-40% with comparable or higher accuracy. Crucially, the compression exhibits strong cross-domain generalization; a model trained on math spontaneously shortens responses on unseen tasks like code, instruction following, and general knowledge QA, with stable or improved accuracy. We demonstrate a stable post-training curriculum (accuracy-compression-accuracy) that can ultimately produce models that are more accurate and reason more concisely, arguing that such compression method should be a standard phase in developing efficient reasoning models.

</details>


### [5] [A Multi-Stage Workflow for the Review of Marketing Content with Reasoning Large Language Models](https://arxiv.org/abs/2601.06054)
*Alberto Purpura,Emily Chen,Swapnil Shinde*

Main category: cs.CL

TL;DR: 提出使用微调推理大语言模型的多阶段工作流，自动检测营销内容合规性，并比较不同微调策略和奖励函数的效果


<details>
  <summary>Details</summary>
Motivation: 大语言模型在解决复杂问题方面展现出潜力，但如何有效利用其推理能力来自动识别营销内容是否符合给定要求列表，是一个实际且有价值的研究方向

Method: 提出多阶段工作流，使用微调推理LLM辅助营销内容审查；比较监督微调(SFT)和组相对策略优化(GRPO)等不同微调策略；评估训练小模型生成推理标记的效果；分析不同奖励函数组合对GRPO训练模型性能的影响

Result: 论文贡献包括：(1)提出不依赖外部知识表示的自动合规问题识别方法；(2)比较不同微调策略效果；(3)评估小模型生成推理标记的有效性；(4)分析奖励函数选择对GRPO性能的影响

Conclusion: 通过多阶段工作流和不同微调策略，可以有效利用推理LLM自动检测营销内容合规性，为实际应用提供技术方案

Abstract: Reasoning Large Language Models (LLMs) have shown promising results when tasked with solving complex problems. In this paper, we propose and evaluate a multi-stage workflow that leverages the capabilities of fine-tuned reasoning LLMs to assist in the review process of marketing content, making sure they comply with a given list of requirements. The contributions of this paper are the following: (i) we present a novel approach -- that does not rely on any external knowledge representation -- for the automatic identification of compliance issues in textual content; (ii) compare the effectiveness of different fine-tuning strategies like Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) in training models to solve this problem; (iii) we evaluate the effectiveness of training small LLMs to generate reasoning tokens before providing their final response; (iv) we evaluate how the choice and combinations of different reward functions affects the performance of a model trained with GRPO.

</details>


### [6] [AzeroS: Extending LLM to Speech with Self-Generated Instruction-Free Tuning](https://arxiv.org/abs/2601.06086)
*Yiwen Shao,Wei Liu,Jiahong Li,Tianzi Wang,Kun Wei,Meng Yu,Dong Yu*

Main category: cs.CL

TL;DR: 提出AZeroS语音大模型，采用自生成无指令微调范式，无需任务特定数据，仅训练轻量投影模块，在语义和副语言任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统语音LLM需要大量任务特定的指令微调数据，这既耗时又导致模型泛化能力差。需要一种无需人工标注指令数据、能更好泛化到未见任务的方法。

Method: 提出SIFT范式：使用冻结的LLM根据语音文本表示生成监督信号。基于此构建AZeroS模型，仅训练两个轻量投影模块（各2380万参数），保持LLM和音频编码器冻结，使用公开语音-文本对数据训练。

Result: AZeroS在VoiceBench、AIR-Bench Foundation (Speech)和AIR-Bench Chat (Speech)等基准测试中，在语义和副语言任务上均达到最先进性能，尽管训练成本低且数据规模适中。

Conclusion: SIFT范式能有效提升语音LLM的泛化能力，无需任务特定指令数据。AZeroS证明了该方法的有效性，为语音LLM发展提供了新方向。

Abstract: Extending large language models (LLMs) to the speech domain has recently gained significant attention. A typical approach connects a pretrained LLM with an audio encoder through a projection module and trains the resulting model on large-scale, task-specific instruction-tuning datasets. However, curating such instruction-tuning data for specific requirements is time-consuming, and models trained in this manner often generalize poorly to unseen tasks. In this work, we first formulate that the strongest generalization of a speech-LLM is achieved when it is trained with Self-Generated Instruction-Free Tuning (SIFT), in which supervision signals are generated by a frozen LLM using textual representations of speech as input. Our proposed SIFT paradigm eliminates the need for collecting task-specific question-answer pairs and yields the theoretically best generalization to unseen tasks. Building upon this paradigm, we introduce AZeroS (Auden Zero-instruction-tuned Speech-LLM), which is trained on speech-text pairs derived from publicly available corpora, including approximately 25,000 hours of speech with ASR transcripts and 3,000 hours of speech with paralinguistic labels. Built upon Qwen2.5-7B-Instruct, the model updates only two lightweight projection modules (23.8 million parameters each), while keeping both the LLM and audio encoders frozen. Despite the minimal training cost and modest data scale, AZeroS achieves state-of-the-art performance on both semantic and paralinguistic benchmarks, including VoiceBench, AIR-Bench Foundation (Speech), and AIR-Bench Chat (Speech).

</details>


### [7] [Is Sanskrit the most token-efficient language? A quantitative study using GPT, Gemini, and SentencePiece](https://arxiv.org/abs/2601.06142)
*Anshul Kumar*

Main category: cs.CL

TL;DR: 研究发现梵文在大型语言模型中的标记效率比英文/印地文高约2倍，最新GPT和Gemini分词器减少了偏见但仍未完全捕捉梵文的紧凑性，这对非英语用户存在成本偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是量化梵文在大型语言模型中的标记效率。梵文因其形态和语法规则被认为每个标记能表达更多含义，但此前没有研究量化这一特性。同时关注非英语用户在分词过程中可能面临的标记数量偏见和成本问题。

Method: 使用包含701个平行经文的《薄伽梵歌》数据集，涵盖梵文、英文、印地文及梵文转写英文。测试多种分词器包括SentencePiece、旧版GPT模型、最新GPT-4o和Gemini分词器。采用标记数量、每标记字符数（标记效率）和每字符标记数（标记成本）三个指标进行评估。

Result: 结果显示：1）在无偏的SPM基线中，梵文与英文/印地文的标记数量存在约2倍差异；2）梵文注释的英文/印地文翻译导致标记数量增加约20倍；3）最新GPT-4o和Gemini分词器相比旧版GPT-4分词器显著减少了偏见，但仍未完全捕捉梵文的紧凑性。

Conclusion: 研究为改进未来分词器设计提供了基础，展示了梵文在高度紧凑编码方面的潜力，能够节省成本并加速训练和推理。同时揭示了非英语用户可能面临的标记数量偏见问题，这对公平性和成本效率具有重要意义。

Abstract: Tokens are the basic units of Large Language Models (LLMs). LLMs rely on tokenizers to segment text into these tokens, and tokenization is the primary determinant of computational and inference cost. Sanskrit, one of the oldest languages, is hypothesized to express more meaning per token due to its morphology and grammar rules; however, no prior work has quantified this. We use a dataset of 701 parallel verses of the Bhagavad Gita, which comprises three languages-Sanskrit, English, and Hindi along with transliteration of Sanskrit into English. We test tokenizers including SentencePiece (SPM), older GPT models, and the latest generation tokenizers from Gemini and GPT. We use metrics of token count, characters per token (token efficiency), and tokens per character (token cost). Results show a ~2x difference in token counts between Sanskrit and English/Hindi under the unbiased SPM baseline. English/Hindi translations of Sanskrit commentary resulted in an approximately 20x increase in token count. GPT o200k base (latest, used by GPT-4o) and Gemini (latest) reduce bias by a significant degree compared to GPT cl100k base (used until GPT-4), but still fail to fully capture Sanskrit's compactness. This matters because there might be a penalty bias for non-English users, which inflates the token count. This research provides a foundation for improving future tokenizer design and shows the potential of Sanskrit for highly compact encoding, saving on cost while speeding up training and inference. The code and dataset are available at https://github.com/anshulkr713/sanskrit-token-efficiency

</details>


### [8] [Amory: Building Coherent Narrative-Driven Agent Memory through Agentic Reasoning](https://arxiv.org/abs/2601.06282)
*Yue Zhou,Xiaobo Guo,Belhassen Bayar,Srinivasan H. Sengamedu*

Main category: cs.CL

TL;DR: Amory是一个工作记忆框架，通过离线时间增强代理推理来主动构建结构化记忆表示，显著提升长期对话效率，在保持推理质量的同时减少50%响应时间。


<details>
  <summary>Details</summary>
Motivation: 长期对话代理面临可扩展性挑战：重复处理完整对话历史计算成本过高。现有方法通过RAG风格检索片段化记忆，但缺乏对人类记忆微妙性和连贯性的捕捉。

Method: Amory框架在离线时间主动构建结构化记忆：1) 将对话片段组织成情节叙事；2) 通过动量机制巩固记忆；3) 将外围事实语义化为语义记忆；4) 检索时在叙事结构上进行连贯性驱动推理。

Result: 在LOCOMO长期推理基准测试中，Amory显著超越先前SOTA方法，性能与完整上下文推理相当，同时减少50%响应时间。动量感知巩固显著提升响应质量，连贯性驱动检索比基于嵌入的方法提供更好的记忆覆盖。

Conclusion: Amory通过主动构建结构化记忆表示，有效解决了长期对话的可扩展性挑战，在保持推理质量的同时大幅提升效率，为构建更人性化的对话代理提供了新方向。

Abstract: Long-term conversational agents face a fundamental scalability challenge as interactions extend over time: repeatedly processing entire conversation histories becomes computationally prohibitive. Current approaches attempt to solve this through memory frameworks that predominantly fragment conversations into isolated embeddings or graph representations and retrieve relevant ones in a RAG style. While computationally efficient, these methods often treat memory formation minimally and fail to capture the subtlety and coherence of human memory. We introduce Amory, a working memory framework that actively constructs structured memory representations through enhancing agentic reasoning during offline time. Amory organizes conversational fragments into episodic narratives, consolidates memories with momentum, and semanticizes peripheral facts into semantic memory. At retrieval time, the system employs coherence-driven reasoning over narrative structures. Evaluated on the LOCOMO benchmark for long-term reasoning, Amory achieves considerable improvements over previous state-of-the-art, with performance comparable to full context reasoning while reducing response time by 50%. Analysis shows that momentum-aware consolidation significantly enhances response quality, while coherence-driven retrieval provides superior memory coverage compared to embedding-based approaches.

</details>


### [9] [How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning?](https://arxiv.org/abs/2601.06289)
*Yufeng Wang,Lu Wei,Lin Liu,Hao Xu,Haibin Ling*

Main category: cs.CL

TL;DR: 评估大语言模型通过思维链提示从质谱数据推理分子结构的能力，发现模型能生成语法有效的结构但缺乏化学准确性


<details>
  <summary>Details</summary>
Motivation: 质谱是识别小分子的强大技术，但从串联质谱直接确定完整分子结构仍具挑战性。虽然大语言模型在科学推理任务中显示出潜力，但其化学解释能力尚不明确

Method: 引入思维链提示框架，将化学专家推理步骤（如双键当量分析、中性丢失识别、碎片组装）形式化为结构化提示，在零样本设置下评估多个先进LLM（Claude-3.5-Sonnet、GPT-4o-mini和Llama-3系列），使用MassSpecGym数据集

Result: 评估显示LLM能生成语法有效的SMILES和部分合理的结构，但无法达到化学准确性或将推理与正确的分子预测联系起来

Conclusion: 研究突出了LLM在分子解析中的解释潜力与当前局限性，为未来结合领域知识和强化学习实现化学基础AI推理提供了基础

Abstract: Mass spectrometry (MS) is a powerful analytical technique for identifying small molecules, yet determining complete molecular structures directly from tandem mass spectra (MS/MS) remains a long-standing challenge due to complex fragmentation patterns and the vast diversity of chemical space. Recent progress in large language models (LLMs) has shown promise for reasoning-intensive scientific tasks, but their capability for chemical interpretation is still unclear. In this work, we introduce a Chain-of-Thought (CoT) prompting framework and benchmark that evaluate how LLMs reason about mass spectral data to predict molecular structures. We formalize expert chemists' reasoning steps-such as double bond equivalent (DBE) analysis, neutral loss identification, and fragment assembly-into structured prompts and assess multiple state-of-the-art LLMs (Claude-3.5-Sonnet, GPT-4o-mini, and Llama-3 series) in a zero-shot setting using the MassSpecGym dataset. Our evaluation across metrics of SMILES validity, formula consistency, and structural similarity reveals that while LLMs can produce syntactically valid and partially plausible structures, they fail to achieve chemical accuracy or link reasoning to correct molecular predictions. These findings highlight both the interpretive potential and the current limitations of LLM-based reasoning for molecular elucidation, providing a foundation for future work that combines domain knowledge and reinforcement learning to achieve chemically grounded AI reasoning.

</details>


### [10] [$\texttt{AMEND++}$: Benchmarking Eligibility Criteria Amendments in Clinical Trials](https://arxiv.org/abs/2601.06300)
*Trisha Das,Mandis Beigi,Jacob Aptekar,Jimeng Sun*

Main category: cs.CL

TL;DR: 提出临床试验资格标准修订预测新任务，发布AMEND++基准套件，开发CAMLM预训练方法提升修订预测性能


<details>
  <summary>Details</summary>
Motivation: 临床试验修订频繁导致延迟、成本增加和管理负担，其中资格标准是最常修订的组成部分，需要预测修订以优化试验设计

Method: 1) 提出资格标准修订预测新NLP任务；2) 发布AMEND++基准套件，包含AMEND数据集和LLM去噪的AMEND_LLM子集；3) 提出Change-Aware Masked Language Modeling (CAMLM)预训练策略，利用历史编辑学习修订敏感表示

Result: 实验表明CAMLM在不同基线模型上一致提升修订预测性能，实现更稳健和成本效益的临床试验设计

Conclusion: 该研究为临床试验修订预测提供了新任务、基准和方法，CAMLM通过利用历史编辑信息有效提升预测能力，有助于优化临床试验设计流程

Abstract: Clinical trial amendments frequently introduce delays, increased costs, and administrative burden, with eligibility criteria being the most commonly amended component. We introduce \textit{eligibility criteria amendment prediction}, a novel NLP task that aims to forecast whether the eligibility criteria of an initial trial protocol will undergo future amendments. To support this task, we release $\texttt{AMEND++}$, a benchmark suite comprising two datasets: $\texttt{AMEND}$, which captures eligibility-criteria version histories and amendment labels from public clinical trials, and $\verb|AMEND_LLM|$, a refined subset curated using an LLM-based denoising pipeline to isolate substantive changes. We further propose $\textit{Change-Aware Masked Language Modeling}$ (CAMLM), a revision-aware pretraining strategy that leverages historical edits to learn amendment-sensitive representations. Experiments across diverse baselines show that CAMLM consistently improves amendment prediction, enabling more robust and cost-effective clinical trial design.

</details>


### [11] [Why LoRA Fails to Forget: Regularized Low-Rank Adaptation Against Backdoors in Language Models](https://arxiv.org/abs/2601.06305)
*Hoang-Chau Luong,Lingwei Chen*

Main category: cs.CL

TL;DR: LoRA在去除后门行为上效果不佳的根本原因是谱特性问题，而非仅因低秩限制。论文提出了RoRA方法，通过增强谱强度和改善谱对齐来有效防御后门攻击。


<details>
  <summary>Details</summary>
Motivation: LoRA广泛用于大语言模型的参数高效微调，但在去除中毒预训练模型的后门行为时效果不佳。传统观点认为这是低秩限制导致的，但本文发现根本原因是谱特性问题。

Method: 提出Regularized Low-Rank Adaptation (RoRA)方法，通过三个关键技术：1) 干净数据增强的正则化来增加谱强度；2) 触发器不敏感约束来改善谱对齐；3) 训练后谱重缩放来确保达到理论上的关键缩放阈值。

Result: 在多个NLP基准测试和攻击设置下的实验表明，RoRA能显著降低攻击成功率，同时保持干净的准确率，有效解决了LoRA在后门防御上的弱点。

Conclusion: LoRA在后门防御上的弱点本质上是谱特性问题，而非简单的低秩限制。RoRA通过增强谱强度和改善谱对齐，为参数高效微调提供了有效的后门防御解决方案。

Abstract: Low-Rank Adaptation (LoRA) is widely used for parameter-efficient fine-tuning of large language models, but it is notably ineffective at removing backdoor behaviors from poisoned pretrained models when fine-tuning on clean dataset. Contrary to the common belief that this weakness is caused primarily by low rank, we show that LoRA's vulnerability is fundamentally spectral. Our analysis identifies two key factors: LoRA updates (i) possess insufficient spectral strength, with singular values far below those of pretrained weights, and (ii) exhibit unfavorable spectral alignment, weakly matching clean-task directions while retaining overlap with trigger-sensitive subspaces. We further establish a critical scaling threshold beyond which LoRA can theoretically suppress trigger-induced activations, and we show empirically that standard LoRA rarely reaches this regime. We introduce Regularized Low-Rank Adaptation (RoRA), which improves forgetting by increasing spectral strength and correcting alignment through clean-strengthened regularization, trigger-insensitive constraints, and post-training spectral rescaling. Experiments across multiple NLP benchmarks and attack settings show that RoRA substantially reduces attack success rates while maintaining clean accuracy.

</details>


### [12] [SyntaxMind at BLP-2025 Task 1: Leveraging Attention Fusion of CNN and GRU for Hate Speech Detection](https://arxiv.org/abs/2601.06306)
*Md. Shihab Uddin Riad*

Main category: cs.CL

TL;DR: 本文介绍了用于BLP-2025任务1（仇恨言论检测）的系统，在孟加拉语文本的仇恨言论分类任务中，使用统一架构结合BanglaBERT嵌入、并行GRU和CNN分支、注意力机制和密集层，在两个子任务中均取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 参与BLP-2025竞赛的仇恨言论检测任务，针对孟加拉语文本开发有效的分类系统，以应对社交媒体上日益增长的仇恨言论问题。

Method: 采用统一架构：首先使用BanglaBERT获取文本嵌入，然后通过多个并行处理分支（包括GRU和CNN）捕捉不同层次的特征，最后结合注意力机制和密集层进行分类。

Result: 在Subtask 1A中获得0.7345微平均F1分数（第二名），在Subtask 1B中获得0.7317微平均F1分数（第五名），表现出高度竞争力。

Conclusion: 提出的统一架构能够有效捕捉孟加拉语文本的上下文语义和局部语言特征，在仇恨言论检测任务中取得了优异的性能表现。

Abstract: This paper describes our system used in the BLP-2025 Task 1: Hate Speech Detection. We participated in Subtask 1A and Subtask 1B, addressing hate speech classification in Bangla text. Our approach employs a unified architecture that integrates BanglaBERT embeddings with multiple parallel processing branches based on GRUs and CNNs, followed by attention and dense layers for final classification. The model is designed to capture both contextual semantics and local linguistic cues, enabling robust performance across subtasks. The proposed system demonstrated high competitiveness, obtaining 0.7345 micro F1-Score (2nd place) in Subtask 1A and 0.7317 micro F1-Score (5th place) in Subtask 1B.

</details>


### [13] [A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality](https://arxiv.org/abs/2601.06307)
*Ishika Agarwal,Zhenlin He,Dhruva Patil,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 使用GRPO风格微调和机器翻译质量评估模型作为奖励函数，提升神经机器翻译系统对成语等非组合表达式的翻译能力，在中文和印地语成语数据集上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 成语、谚语和隐喻等非组合表达式对神经机器翻译系统构成重大挑战，因为它们的含义不能从单个单词推导出来。这些表达式编码了丰富的文化含义，具有比喻和字面双重意义，使得准确翻译变得困难。

Method: 采用GRPO风格的微调方法，使用机器翻译质量评估（MTQE）模型作为奖励函数，训练模型更好地翻译成语。在中文和印地语成语数据集上进行实验。

Result: 成语翻译能力提升约14个百分点，一般非成语翻译隐含提升约8个百分点，跨语言翻译能力（在一个语言上训练，在另一个语言上评估）提升约6个百分点。

Conclusion: 该工作量化了非组合翻译的差距，并为开发具有更强跨文化和比喻语言理解能力的大语言模型提供了见解。

Abstract: Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by ~14 points, general, non-idiomatic translation implicitly improves by ~8 points, and cross-lingual translation abilities (trained on one language, evaluated on another) improves by ~6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding.

</details>


### [14] [Annotating Dimensions of Social Perception in Text: The First Sentence-Level Dataset of Warmth and Competence](https://arxiv.org/abs/2601.06316)
*Mutaz Ayesh,Saif M. Mohammad,Nedjma Ousidhoum*

Main category: cs.CL

TL;DR: 提出了首个句子级别的温暖与能力数据集W&C-Sent，包含1600+英语句子-目标对，标注了信任、社交性和能力三个维度，用于分析语言中的社会评价。


<details>
  <summary>Details</summary>
Motivation: 温暖和能力是社会心理学中评价个体和群体的核心维度，但在NLP研究中主要通过词级词典来研究，无法完全捕捉这些概念在更大文本单元和话语中的语境表达。

Method: 构建了W&C-Sent数据集，包含来自社交媒体的1600多个英语句子-目标对，标注了信任、社交性和能力三个维度。详细描述了数据收集、标注和质量控制流程，并评估了多种大语言模型在识别这些维度上的表现。

Result: 创建了首个句子级别的温暖与能力数据集，为分析语言中的社会评价提供了新资源。评估了LLMs在识别这些社会心理学维度上的能力，支持NLP与计算社会科学的交叉研究。

Conclusion: W&C-Sent填补了NLP研究中句子级别温暖与能力分析的空白，为研究语言中的社会评价提供了重要资源，支持未来在NLP和计算社会科学交叉领域的研究。

Abstract: Warmth (W) (often further broken down into Trust (T) and Sociability (S)) and Competence (C) are central dimensions along which people evaluate individuals and social groups (Fiske, 2018). While these constructs are well established in social psychology, they are only starting to get attention in NLP research through word-level lexicons, which do not completely capture their contextual expression in larger text units and discourse. In this work, we introduce Warmth and Competence Sentences (W&C-Sent), the first sentence-level dataset annotated for warmth and competence. The dataset includes over 1,600 English sentence--target pairs annotated along three dimensions: trust and sociability (components of warmth), and competence. The sentences in W&C-Sent are from social media and often express attitudes and opinions about specific individuals or social groups (the targets of our annotations). We describe the data collection, annotation, and quality-control procedures in detail, and evaluate a range of large language models (LLMs) on their ability to identify trust, sociability, and competence in text. W&C-Sent provides a new resource for analyzing warmth and competence in language and supports future research at the intersection of NLP and computational social science.

</details>


### [15] [On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation](https://arxiv.org/abs/2601.06329)
*Jeff Chan-Jan Sju,Liang-Hsuan Tseng,Yi-Cheng Lin,Yen-Chun Kuo,Ju-Chieh Chou,Kai-Wei Chang,Hung-yi Lee,Carlos Busso*

Main category: cs.CL

TL;DR: 本文提出新的语音语言模型评估方法，替代传统的全局token困惑度，更准确反映生成质量，缩小了最佳模型与人类基线之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有语音语言模型评估通常使用"全局token困惑度"，直接套用文本困惑度的公式。这种做法忽视了语音和文本模态的根本差异，可能导致低估语音特性，无法准确评估模型性能。

Method: 提出多种基于似然和生成的评估方法，替代简单的全局token困惑度。这些方法更全面地考虑语音特性，包括语音特征、韵律、音质等方面。

Result: 新评估方法与人类评分（MOS）有更强的相关性，更忠实地反映感知生成质量。在新指标下，语音语言模型的相对性能格局被重塑，最佳模型与人类基线之间的差距显著缩小。

Conclusion: 适当的评估方法对于准确评估语音语言建模的进展至关重要。新提出的评估框架能更真实地反映模型性能，为领域发展提供更可靠的评估标准。

Abstract: Generative spoken language models pretrained on large-scale raw audio can continue a speech prompt with appropriate content while preserving attributes like speaker and emotion, serving as foundation models for spoken dialogue. In prior literature, these models are often evaluated using ``global token perplexity'', which directly applies the text perplexity formulation to speech tokens. However, this practice overlooks fundamental differences between speech and text modalities, possibly leading to an underestimation of the speech characteristics. In this work, we propose a variety of likelihood- and generative-based evaluation methods that serve in place of naive global token perplexity. We demonstrate that the proposed evaluations more faithfully reflect perceived generation quality, as evidenced by stronger correlations with human-rated mean opinion scores (MOS). When assessed under the new metrics, the relative performance landscape of spoken language models is reshaped, revealing a significantly reduced gap between the best-performing model and the human topline. Together, these results suggest that appropriate evaluation is critical for accurately assessing progress in spoken language modeling.

</details>


### [16] [What Matters When Building Universal Multilingual Named Entity Recognition Models?](https://arxiv.org/abs/2601.06347)
*Jonas Golde,Patrick Haller,Alan Akbik*

Main category: cs.CL

TL;DR: 本文通过系统实验分析多语言NER模型的关键设计决策，提出了Otter模型，在100多种语言上超越现有基线，性能接近大型生成模型但更高效。


<details>
  <summary>Details</summary>
Motivation: 当前多语言NER研究缺乏对关键设计决策（架构、训练目标、数据源）的系统性分析，这些决策通常组合评估而非独立验证，阻碍了领域进步。

Method: 对架构、transformer骨干网络、训练目标和数据组成进行广泛实验分析，基于这些洞察开发了支持100多种语言的Otter模型。

Result: Otter在F1分数上比GLiNER-x-base提升5.3个百分点，性能与Qwen3-32B等大型生成模型相当，但计算效率显著更高。

Conclusion: 通过系统性分析多语言NER设计决策，开发出高效且性能优越的Otter模型，为未来研究提供可复现的基础。

Abstract: Recent progress in universal multilingual named entity recognition (NER) has been driven by advances in multilingual transformer models and task-specific architectures, loss functions, and training datasets. Despite substantial prior work, we find that many critical design decisions for such models are made without systematic justification, with architectural components, training objectives, and data sources evaluated only in combination rather than in isolation. We argue that these decisions impede progress in the field by making it difficult to identify which choices improve model performance. In this work, we conduct extensive experiments around architectures, transformer backbones, training objectives, and data composition across a wide range of languages. Based on these insights, we introduce Otter, a universal multilingual NER model supporting over 100 languages. Otter achieves consistent improvements over strong multilingual NER baselines, outperforming GLiNER-x-base by 5.3pp in F1 and achieves competitive performance compared to large generative models such as Qwen3-32B, while being substantially more efficient. We release model checkpoints, training and evaluation code to facilitate reproducibility and future research.

</details>


### [17] [Average shortest-path length in word-adjacency networks: Chinese versus English](https://arxiv.org/abs/2601.06361)
*Jakub Dec,Michał Dolina,Stanisław Drożdż,Jarosław Kwapień,Jin Liu,Tomasz Stanisz*

Main category: cs.CL

TL;DR: 分析中英文文学作品构建的词邻接网络拓扑结构，将标点符号视为普通词汇，发现包含标点时两种语言的网络平均最短路径长度渐近相似，但排除标点后中文网络路径显著更长。


<details>
  <summary>Details</summary>
Motivation: 研究复杂网络在自然语言分析中的应用，特别关注标点符号在语言网络中的信息价值。标点符号不仅承载情感状态、逻辑分组、阅读停顿等功能信息，先前研究还表明标点符号在Zipf分析中表现类似词汇，能提升作者归属分析的准确性。

Method: 构建不同时期中英文文学作品（包括原文和翻译版本）的词邻接网络，将标点符号视为普通词汇纳入网络。分析网络平均最短路径长度L(N)随网络规模N的变化关系，并与增长网络模型进行拟合比较。

Result: 经验数据与增长网络模型拟合良好。关键发现：当包含标点符号时，中英文网络的平均最短路径长度L(N)渐近行为相似；但排除标点符号后，中文网络的L(N)显著更大。

Conclusion: 标点符号在语言网络分析中具有重要作用，特别是在中文文本分析中。包含标点符号能更准确地反映语言网络的结构特性，排除标点会导致中文网络结构特征的失真。

Abstract: Complex networks provide powerful tools for analyzing and understanding the intricate structures present in various systems, including natural language. Here, we analyze topology of growing word-adjacency networks constructed from Chinese and English literary works written in different periods. Unconventionally, instead of considering dictionary words only, we also include punctuation marks as if they were ordinary words. Our approach is based on two arguments: (1) punctuation carries genuine information related to emotional state, allows for logical grouping of content, provides a pause in reading, and facilitates understanding by avoiding ambiguity, and (2) our previous works have shown that punctuation marks behave like words in a Zipfian analysis and, if considered together with regular words, can improve authorship attribution in stylometric studies. We focus on a functional dependence of the average shortest path length $L(N)$ on a network size $N$ for different epochs and individual novels in their original language as well as for translations of selected novels into the other language. We approximate the empirical results with a growing network model and obtain satisfactory agreement between the two. We also observe that $L(N)$ behaves asymptotically similar for both languages if punctuation marks are included but becomes sizably larger for Chinese if punctuation marks are neglected.

</details>


### [18] [Talking to Extraordinary Objects: Folktales Offer Analogies for Interacting with Technology](https://arxiv.org/abs/2601.06372)
*Martha Larson*

Main category: cs.CL

TL;DR: 该论文探讨如何从民间故事中汲取灵感，将语音和语言交互与拟人化分离，为技术交互设计提供新思路。


<details>
  <summary>Details</summary>
Motivation: 当前语音和语言交互技术过度依赖拟人化设计，而拟人化正面临重要反思。需要寻找不依赖拟人化的语音交互新范式。

Method: 通过分析民间故事中的非凡物体（extraordinary objects）案例，研究这些故事如何将语言能力与人类特征分离，为技术交互提供类比和启示。

Result: 民间故事展示了多样且令人难忘的非凡物体，这些物体的语言能力和智能并不总是与人性相关，为技术交互设计提供了丰富的灵感来源。

Conclusion: 民间故事可以为语音和语言交互技术提供重要启示，帮助设计者创造不依赖拟人化的、更自然的技术交互方式。

Abstract: Speech and language are valuable for interacting with technology. It would be ideal to be able to decouple their use from anthropomorphization, which has recently met an important moment of reckoning. In the world of folktales, language is everywhere and talking to extraordinary objects is not unusual. This overview presents examples of the analogies that folktales offer. Extraordinary objects in folktales are diverse and also memorable. Language capacity and intelligence are not always connected to humanness. Consideration of folktales can offer inspiration and insight for using speech and language for interacting with technology.

</details>


### [19] [AfriqueLLM: How Data Mixing and Model Architecture Impact Continued Pre-training for African Languages](https://arxiv.org/abs/2601.06395)
*Hao Yu,Tianyi Xu,Michael A. Hedderich,Wassim Hamidouche,Syed Waqas Zamir,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: AfriqueLLM：通过持续预训练将开源LLM适配到20种非洲语言，研究数据组合对性能的影响，发现数学、代码和合成翻译数据能提升推理能力


<details>
  <summary>Details</summary>
Motivation: 开源多语言大模型在非洲语言上表现不佳，持续预训练是语言适配的实用方法，但低资源语言语料库存在领域覆盖不均和任务相关知识缺失的问题，限制了推理等高级能力的提升

Method: 对Llama 3.1、Gemma 3、Qwen 3等5个不同规模和架构的基础模型进行持续预训练，使用260亿token，系统研究数学、代码和合成翻译数据的不同组合如何影响下游性能

Result: 数据组合是持续预训练增益的主要驱动力；添加数学、代码和合成翻译数据能带来一致改进，包括推理导向的评估；在固定架构内，更大模型通常表现更好，但跨模型家族比较时架构选择比规模更重要；基础模型的多语言性能不能可靠预测持续预训练后的结果

Conclusion: 稳健的架构配合任务对齐的数据是更可靠的改进方法；最佳模型提升了长上下文性能，包括文档级翻译；模型已在Huggingface发布

Abstract: Large language models (LLMs) are increasingly multilingual, yet open models continue to underperform relative to proprietary systems, with the gap most pronounced for African languages. Continued pre-training (CPT) offers a practical route to language adaptation, but improvements on demanding capabilities such as mathematical reasoning often remain limited. This limitation is driven in part by the uneven domain coverage and missing task-relevant knowledge that characterize many low-resource language corpora. We present \texttt{AfriqueLLM}, a suite of open LLMs adapted to 20 African languages through CPT on 26B tokens. We perform a comprehensive empirical study across five base models spanning sizes and architectures, including Llama 3.1, Gemma 3, and Qwen 3, and systematically analyze how CPT data composition shapes downstream performance. In particular, we vary mixtures that include math, code, and synthetic translated data, and evaluate the resulting models on a range of multilingual benchmarks. Our results identify data composition as the primary driver of CPT gains. Adding math, code, and synthetic translated data yields consistent improvements, including on reasoning-oriented evaluations. Within a fixed architecture, larger models typically improve performance, but architectural choices dominate scale when comparing across model families. Moreover, strong multilingual performance in the base model does not reliably predict post-CPT outcomes; robust architectures coupled with task-aligned data provide a more dependable recipe. Finally, our best models improve long-context performance, including document-level translation. Models have been released on [Huggingface](https://huggingface.co/collections/McGill-NLP/afriquellm).

</details>


### [20] [MITRA: A Large-Scale Parallel Corpus and Multilingual Pretrained Language Model for Machine Translation and Semantic Retrieval for Pāli, Sanskrit, Buddhist Chinese, and Tibetan](https://arxiv.org/abs/2601.06400)
*Sebastian Nehrdich,Kurt Keutzer*

Main category: cs.CL

TL;DR: MITRA框架：用于佛教文献多语言平行文本挖掘的AI系统，包含平行文本挖掘管道、174万句对数据集、领域专用预训练模型和语义嵌入模型，在机器翻译和语义相似度任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 佛教文献中存在大量跨语言（梵文、巴利文、佛教中文、藏文等）的文本平行关系，但通常缺乏标注。由于材料规模庞大，人工检查几乎不可能，需要自动化工具来辅助研究。

Method: 1. 开发MITRA-parallel多语言平行段落挖掘管道；2. 构建包含174万梵文-中文-藏文平行句对的大规模语料库；3. 训练领域专用预训练语言模型Gemma 2 MITRA；4. 开发Gemma 2 MITRA-MT（机器翻译微调版）和Gemma 2 MITRA-E（语义嵌入模型）。

Result: 1. Gemma 2 MITRA-MT在这些语言到英语的机器翻译任务中达到最先进性能，甚至超过更大的开源模型；2. Gemma 2 MITRA-E在新的详细语义嵌入基准测试中表现最优；3. 所有资源（数据集、模型权重、语义相似度基准）都已开源。

Conclusion: MITRA框架为佛教和古典亚洲文献的NLP研究和文献学研究提供了强大工具，通过自动化平行文本挖掘和领域专用模型，显著提升了跨语言文本分析的效率和准确性。

Abstract: Ancient Buddhist literature features frequent, yet often unannotated, textual parallels spread across diverse languages: Sanskrit, Pāli, Buddhist Chinese, Tibetan, and more. The scale of this material makes manual examination prohibitive. We present the MITRA framework, which consists of a novel pipeline for multilingual parallel passage mining, MITRA-parallel, a large-scale corpus of 1.74 million parallel sentence pairs between Sanskrit, Chinese, and Tibetan, and the development of the domain-specific pretrained language model Gemma 2 MITRA. We present Gemma 2 MITRA-MT, a version of this base model fine-tuned on machine translation tasks, reaching state-of-the-art performance for machine translation of these languages into English and outperforming even much larger open-source models. We also present Gemma 2 MITRA-E, a semantic embedding model that shows state-of-the-art performance on a novel, detailed semantic embedding benchmark. We make the parallel dataset, model weights, and semantic similarity benchmark openly available to aid both NLP research and philological studies in Buddhist and classical Asian literature.

</details>


### [21] [Steer Model beyond Assistant: Controlling System Prompt Strength via Contrastive Decoding](https://arxiv.org/abs/2601.06403)
*Yijiang River Dong,Tiancheng Hu,Zheng Hui,Nigel Collier*

Main category: cs.CL

TL;DR: 提出系统提示强度方法，通过对比目标与默认系统提示的logits，用缩放因子α放大目标角色行为信号，实现无需训练的动态行为控制


<details>
  <summary>Details</summary>
Motivation: 大语言模型擅长复杂指令，但难以偏离其"有帮助的助手"角色定位，因为后训练过程建立了强大的先验，使其抵抗冲突指令

Method: 引入系统提示强度方法，将提示遵循视为连续控制。通过对比目标系统提示和默认系统提示的logits，用缩放因子α隔离并放大目标角色的行为信号

Result: 在五个不同基准测试中取得显著改进：IFEval严格准确率提升+8.5，OffTopicEval拒绝率提升+45个百分点，Prompt-Steering可引导性提升+13%

Conclusion: 该方法使从业者能够调节系统提示强度，无需重新训练即可提供动态的模型行为控制

Abstract: Large language models excel at complex instructions yet struggle to deviate from their helpful assistant persona, as post-training instills strong priors that resist conflicting instructions. We introduce system prompt strength, a training-free method that treats prompt adherence as a continuous control. By contrasting logits from target and default system prompts, we isolate and amplify the behavioral signal unique to the target persona by a scalar factor alpha. Across five diverse benchmarks spanning constraint satisfaction, behavioral control, pluralistic alignment, capability modulation, and stylistic control, our method yields substantial improvements: up to +8.5 strict accuracy on IFEval, +45pp refusal rate on OffTopicEval, and +13% steerability on Prompt-Steering. Our approach enables practitioners to modulate system prompt strength, providing dynamic control over model behavior without retraining.

</details>


### [22] [Value of Information: A Framework for Human-Agent Communication](https://arxiv.org/abs/2601.06407)
*Yijiang River Dong,Tiancheng Hu,Zheng Hui,Caiqi Zhang,Ivan Vulić,Andreea Bobu,Nigel Collier*

Main category: cs.CL

TL;DR: 提出基于信息价值(VoI)的决策理论框架，让LLM智能体在信息不足时能动态权衡询问用户带来的预期效用增益与用户认知成本，无需超参数调优即可自适应不同场景。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在实际任务中面临基本困境：用户请求通常不完整，智能体必须在信息不足时决定是直接行动还是中断用户寻求澄清。现有方法要么依赖需要任务特定调优的脆弱置信度阈值，要么无法考虑不同决策的不同风险。

Method: 引入基于信息价值(VoI)的决策理论框架，使智能体能够动态权衡询问问题带来的预期效用增益与对用户施加的认知成本。该推理时方法无需超参数调优，可无缝适应从休闲游戏到医疗诊断等各种场景。

Result: 在四个不同领域（20个问题游戏、医疗诊断、航班预订和电子商务）的实验表明，VoI方法始终匹配或超过最佳手动调优基线，在高成本设置中实现了高达1.36个效用点的提升。

Conclusion: 这项工作提供了一个无参数的自适应智能体通信框架，明确平衡了任务风险、查询模糊性和用户努力，解决了LLM智能体在信息不足时决策的基本困境。

Abstract: Large Language Model (LLM) agents deployed for real-world tasks face a fundamental dilemma: user requests are underspecified, yet agents must decide whether to act on incomplete information or interrupt users for clarification. Existing approaches either rely on brittle confidence thresholds that require task-specific tuning, or fail to account for the varying stakes of different decisions. We introduce a decision-theoretic framework that resolves this trade-off through the Value of Information (VoI), enabling agents to dynamically weigh the expected utility gain from asking questions against the cognitive cost imposed on users. Our inference-time method requires no hyperparameter tuning and adapts seamlessly across contexts-from casual games to medical diagnosis. Experiments across four diverse domains (20 Questions, medical diagnosis, flight booking, and e-commerce) show that VoI consistently matches or exceeds the best manually-tuned baselines, achieving up to 1.36 utility points higher in high-cost settings. This work provides a parameter-free framework for adaptive agent communication that explicitly balances task risk, query ambiguity, and user effort.

</details>


### [23] [Structured Episodic Event Memory](https://arxiv.org/abs/2601.06411)
*Zhengxuan Lu,Dongfang Li,Yukun Shi,Beilun Wang,Longyue Wang,Baotian Hu*

Main category: cs.CL

TL;DR: SEEM是一个结构化事件记忆框架，结合图记忆层和动态情节记忆层，通过认知框架理论将交互流转化为结构化事件帧，显著提升LLM在复杂推理中的叙事连贯性和逻辑一致性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的记忆方法主要依赖静态的检索增强生成(RAG)，这种方法检索分散且无法捕捉复杂推理所需的结构依赖关系。对于自主智能体而言，这些被动、扁平化的架构缺乏对长期交互动态性和关联性进行认知组织的能力。

Method: 提出结构化情节事件记忆(SEEM)框架：1) 结合图记忆层处理关系事实和动态情节记忆层处理叙事进展；2) 基于认知框架理论，将交互流转化为带有精确来源指针的结构化情节事件帧(EEFs)；3) 引入关联融合和反向来源扩展(RPE)机制，从碎片化证据中重建连贯的叙事上下文。

Result: 在LoCoMo和LongMemEval基准测试中，SEEM显著优于基线方法，使智能体能够保持更优的叙事连贯性和逻辑一致性。

Conclusion: SEEM通过分层记忆架构和结构化事件表示，有效解决了传统RAG方法在复杂推理中的局限性，为LLM提供了更接近人类认知组织的记忆能力。

Abstract: Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency.

</details>


### [24] [Can a Unimodal Language Agent Provide Preferences to Tune a Multimodal Vision-Language Model?](https://arxiv.org/abs/2601.06424)
*Sazia Tabasum Mim,Jack Morris,Manish Dhakal,Yanming Xiu,Maria Gorlatova,Yi Ding*

Main category: cs.CL

TL;DR: LLM可以通过文本反馈优化视觉语言模型，使VLM生成更符合LLM偏好的多模态场景描述，提升多模态理解能力


<details>
  <summary>Details</summary>
Motivation: 探索为现有LLM添加多模态能力的可扩展路径，研究单模态LLM能否仅通过文本推理自身信息需求并为多模态模型提供有效反馈

Method: 提出让语言智能体向视觉语言模型提供反馈的方法，使VLM能够根据智能体偏好调整文本生成

Result: LLM偏好反馈显著提升VLM描述质量，VLM生成的多模态场景描述帮助LLM更好理解多模态上下文，相比基线多模态方法最高提升13%绝对准确率；人类研究显示LLM选择与人类判断的偏好对齐率达到64.6%

Conclusion: 单模态LLM能够有效推理自身信息需求并为多模态模型提供优化反馈，为现有LLM添加多模态能力提供了一条可扩展路径

Abstract: To explore a more scalable path for adding multimodal capabilities to existing LLMs, this paper addresses a fundamental question: Can a unimodal LLM, relying solely on text, reason about its own informational needs and provide effective feedback to optimize a multimodal model? To answer this, we propose a method that enables a language agent to give feedback to a vision-language model (VLM) to adapt text generation to the agent's preferences. Our results from different experiments affirm this hypothesis, showing that LLM preference feedback significantly enhances VLM descriptions. Using our proposed method, we find that the VLM can generate multimodal scene descriptions to help the LLM better understand multimodal context, leading to improvements of maximum 13% in absolute accuracy compared to the baseline multimodal approach. Furthermore, a human study validated our AI-driven feedback, showing a 64.6% preference alignment rate between the LLM's choices and human judgments. Extensive experiments provide insights on how and why the method works and its limitations.

</details>


### [25] [NC-Bench: An LLM Benchmark for Evaluating Conversational Competence](https://arxiv.org/abs/2601.06426)
*Robert J. Moore,Sungeun An,Farhan Ahmed,Jay Pankaj Gala*

Main category: cs.CL

TL;DR: NC-Bench是一个基于IBM自然对话框架的新基准，专注于评估LLMs的对话形式和结构能力，而非内容。它包含三个测试集：基础对话能力、RAG对话和复杂请求，评估模型在序列管理、修复、结束对话等方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注模型行为的内容，缺乏对对话形式和结构的评估。需要一种基于人类对话基本原则的轻量级、可扩展的理论基础框架来评估和改进LLMs的对话能力。

Method: 基于IBM自然对话框架(NCF)，NC-Bench包含三个测试集：1)基础对话能力集评估基本序列管理实践；2)RAG集应用相同序列管理模式但结合检索增强生成；3)复杂请求集评估更复杂的序列管理模式。每个基准测试模型在14种交互模式中产生上下文适当对话动作的能力。

Result: 对6个开源模型的评估显示：模型在基础回答任务上表现良好，在修复任务（特别是重复）上表现较差，在结束序列上表现不一，在复杂多轮请求上最具挑战性。Qwen模型在基础集上表现优异，Granite模型在RAG集和复杂请求集上表现最佳。

Conclusion: NC-Bench通过操作化人类对话基本原则，提供了一个轻量级、可扩展、理论基础的框架，用于评估和改进LLMs的对话能力，超越了主题或任务特定的基准。

Abstract: The Natural Conversation Benchmark (NC-Bench) introduce a new approach to evaluating the general conversational competence of large language models (LLMs). Unlike prior benchmarks that focus on the content of model behavior, NC-Bench focuses on the form and structure of natural conversation. Grounded in the IBM Natural Conversation Framework (NCF), NC-Bench comprises three distinct sets. The Basic Conversation Competence set evaluates fundamental sequence management practices, such as answering inquiries, repairing responses, and closing conversational pairs. The RAG set applies the same sequence management patterns as the first set but incorporates retrieval-augmented generation (RAG). The Complex Request set extends the evaluation to complex requests involving more intricate sequence management patterns. Each benchmark tests a model's ability to produce contextually appropriate conversational actions in response to characteristic interaction patterns. Initial evaluations across 6 open-source models and 14 interaction patterns show that models perform well on basic answering tasks, struggle more with repair tasks (especially repeat), have mixed performance on closing sequences, and find complex multi-turn requests most challenging, with Qwen models excelling on the Basic set and Granite models on the RAG set and the Complex Request set. By operationalizing fundamental principles of human conversation, NC-Bench provides a lightweight, extensible, and theory-grounded framework for assessing and improving the conversational abilities of LLMs beyond topical or task-specific benchmarks.

</details>


### [26] [Time Travel Engine: A Shared Latent Chronological Manifold Enables Historical Navigation in Large Language Models](https://arxiv.org/abs/2601.06437)
*Jingmin An,Wei Liu,Qian Wang,Fang Fang*

Main category: cs.CL

TL;DR: 论文提出Time Travel Engine框架，揭示大语言模型中时间信息以连续几何结构编码，而非离散聚类，支持在不同历史时期间流畅导航。


<details>
  <summary>Details</summary>
Motivation: 时间是人类认知的基本维度，但大语言模型如何编码时间进展的机制仍不透明。需要理解模型如何组织时间信息，并探索跨语言的时间编码共性。

Method: 提出Time Travel Engine框架，将历时语言模式投影到共享的时间流形上，通过直接调制潜在表示来诱导与目标时代一致的风格、词汇和概念转变。

Result: 发现时间信息在潜在空间中组织为连续可遍历的几何结构；TTE能够实现流畅的时代间导航并限制未来知识访问；中文和英文的时间子空间存在拓扑同构，表明跨语言共享历史演化的通用几何逻辑。

Conclusion: 研究连接了历史语言学和机制可解释性，为控制神经网络中的时间推理提供了新范式，揭示了跨语言的时间编码几何共性。

Abstract: Time functions as a fundamental dimension of human cognition, yet the mechanisms by which Large Language Models (LLMs) encode chronological progression remain opaque. We demonstrate that temporal information in their latent space is organized not as discrete clusters but as a continuous, traversable geometry. We introduce the Time Travel Engine (TTE), an interpretability-driven framework that projects diachronic linguistic patterns onto a shared chronological manifold. Unlike surface-level prompting, TTE directly modulates latent representations to induce coherent stylistic, lexical, and conceptual shifts aligned with target eras. By parameterizing diachronic evolution as a continuous manifold within the residual stream, TTE enables fluid navigation through period-specific "zeitgeists" while restricting access to future knowledge. Furthermore, experiments across diverse architectures reveal topological isomorphism between the temporal subspaces of Chinese and English-indicating that distinct languages share a universal geometric logic of historical evolution. These findings bridge historical linguistics with mechanistic interpretability, offering a novel paradigm for controlling temporal reasoning in neural networks.

</details>


### [27] [LitVISTA: A Benchmark for Narrative Orchestration in Literary Text](https://arxiv.org/abs/2601.06445)
*Mingzhe Lu,Yiwen Wang,Yanbing Liu,Qi You,Chong Liu,Ruize Qin,Haoyu Dong,Wenyu Zhang,Jiarui Zhang,Yue Hu,Yunpeng Li*

Main category: cs.CL

TL;DR: 提出VISTA Space框架和LitVISTA基准，用于评估LLM在叙事编排能力上的系统性缺陷


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型生成故事时过于关注因果连贯性，忽视了人类叙事中复杂的故事情节和编排结构，导致模型生成与人类叙事之间存在结构偏差

Method: 提出VISTA Space高维表示框架统一人类和模型叙事视角，创建LitVISTA基于文学文本的结构化标注基准，对GPT、Claude、Grok、Gemini等前沿LLM进行系统评估

Result: 现有模型存在系统性缺陷：无法构建统一的全局叙事视角，难以同时捕捉叙事功能和结构；即使使用高级思维模式对文学叙事理解也只有有限提升

Conclusion: 需要开发能够更好理解和生成复杂叙事编排的模型，VISTA Space和LitVISTA为评估和改进LLM的叙事能力提供了重要框架

Abstract: Computational narrative analysis aims to capture rhythm, tension, and emotional dynamics in literary texts. Existing large language models can generate long stories but overly focus on causal coherence, neglecting the complex story arcs and orchestration inherent in human narratives. This creates a structural misalignment between model- and human-generated narratives. We propose VISTA Space, a high-dimensional representational framework for narrative orchestration that unifies human and model narrative perspectives. We further introduce LitVISTA, a structurally annotated benchmark grounded in literary texts, enabling systematic evaluation of models' narrative orchestration capabilities. We conduct oracle evaluations on a diverse selection of frontier LLMs, including GPT, Claude, Grok, and Gemini. Results reveal systematic deficiencies: existing models fail to construct a unified global narrative view, struggling to jointly capture narrative function and structure. Furthermore, even advanced thinking modes yield only limited gains for such literary narrative understanding.

</details>


### [28] [PRISP: Privacy-Safe Few-Shot Personalization via Lightweight Adaptation](https://arxiv.org/abs/2601.06471)
*Junho Park,Dohoon Kim,Taesup Moon*

Main category: cs.CL

TL;DR: PRISP：一种轻量级、隐私安全的LLM个性化框架，在数据极少、计算资源受限且隐私要求严格的实际部署场景下，通过Text-to-LoRA超网络生成任务感知的LoRA参数，实现高效个性化


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化方法通常需要大量数据和计算资源，且存在隐私风险。而实际部署场景中，个性化通常发生在数据极少、计算资源受限、隐私要求严格的情况下，需要专门针对这些约束的解决方案

Method: 提出PRISP框架：1) 使用Text-to-LoRA超网络从任务描述生成任务感知的LoRA参数；2) 仅优化少量任务感知LoRA参数和最小额外模块，利用少量用户数据进行高效个性化；3) 设计为轻量级且隐私安全

Result: 在LaMP基准测试的少样本变体上，PRISP相比先前方法实现了更强的整体性能，同时显著减少了计算开销并完全消除了隐私风险

Conclusion: PRISP为实际部署场景中的LLM个性化提供了一种有效的解决方案，能够在数据极少、资源受限且隐私要求严格的条件下实现高效、安全的个性化适配

Abstract: Large language model (LLM) personalization aims to adapt general-purpose models to individual users. Most existing methods, however, are developed under data-rich and resource-abundant settings, often incurring privacy risks. In contrast, realistic personalization typically occurs after deployment under (i) extremely limited user data, (ii) constrained computational resources, and (iii) strict privacy requirements. We propose PRISP, a lightweight and privacy-safe personalization framework tailored to these constraints. PRISP leverages a Text-to-LoRA hypernetwork to generate task-aware LoRA parameters from task descriptions, and enables efficient user personalization by optimizing a small subset of task-aware LoRA parameters together with minimal additional modules using few-shot user data. Experiments on a few-shot variant of the LaMP benchmark demonstrate that PRISP achieves strong overall performance compared to prior approaches, while reducing computational overhead and eliminating privacy risks.

</details>


### [29] [IndRegBias: A Dataset for Studying Indian Regional Biases in English and Code-Mixed Social Media Comments](https://arxiv.org/abs/2601.06477)
*Debasmita Panda,Akash Anil,Neelesh Kumar Shukla*

Main category: cs.CL

TL;DR: 该论文创建了印度区域偏见数据集IndRegBias，并评估了LLMs和ILMs在检测区域偏见及其严重程度方面的表现，发现微调方法显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 虽然NLP中已广泛研究性别、种族等社会偏见，但区域偏见研究较少，主要因为：1）区域偏见数据集提取困难；2）标注存在分歧；3）区域偏见常与其他社会偏见结合且代表性不足。该研究旨在填补印度区域偏见研究的空白。

Method: 1）从Reddit和YouTube收集25,000条关于印度区域议题的评论创建IndRegBias数据集；2）采用多级标注策略标注区域偏见陈述的严重程度；3）使用开源LLMs和ILMs，通过零样本、少样本和微调策略评估区域偏见检测能力。

Result: 零样本和少样本方法在大多数LLMs和ILMs中检测区域偏见及其严重程度的准确率较低。然而，微调方法显著提升了LLM在检测印度区域偏见及其严重程度方面的性能。

Conclusion: 该研究成功创建了印度区域偏见数据集，并证明微调方法能有效提升语言模型检测区域偏见的能力，为区域偏见研究提供了重要资源和基准。

Abstract: Warning: This paper consists of examples representing regional biases in Indian regions that might be offensive towards a particular region. While social biases corresponding to gender, race, socio-economic conditions, etc., have been extensively studied in the major applications of Natural Language Processing (NLP), biases corresponding to regions have garnered less attention. This is mainly because of (i) difficulty in the extraction of regional bias datasets, (ii) disagreements in annotation due to inherent human biases, and (iii) regional biases being studied in combination with other types of social biases and often being under-represented. This paper focuses on creating a dataset IndRegBias, consisting of regional biases in an Indian context reflected in users' comments on popular social media platforms, namely Reddit and YouTube. We carefully selected 25,000 comments appearing on various threads in Reddit and videos on YouTube discussing trending topics on regional issues in India. Furthermore, we propose a multilevel annotation strategy to annotate the comments describing the severity of regional biased statements. To detect the presence of regional bias and its severity in IndRegBias, we evaluate open-source Large Language Models (LLMs) and Indic Language Models (ILMs) using zero-shot, few-shot, and fine-tuning strategies. We observe that zero-shot and few-shot approaches show lower accuracy in detecting regional biases and severity in the majority of the LLMs and ILMs. However, the fine-tuning approach significantly enhances the performance of the LLM in detecting Indian regional bias along with its severity.

</details>


### [30] [Spec-o3: A Tool-Augmented Vision-Language Agent for Rare Celestial Object Candidate Vetting via Automated Spectral Inspection](https://arxiv.org/abs/2601.06498)
*Minghui Jia,Qichao Zhang,Ali Luo,Linjing Li,Shuo Ye,Hailing Lu,Wen Hou,Dongbin Zhao*

Main category: cs.CL

TL;DR: Spec-o3是一个工具增强的视觉语言智能体，通过多模态思维链推理进行天文学家对齐的光谱检查，显著提升稀有天体识别的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 深度学习分类器在泛化性和可解释性方面有限，稀有天体候选者的最终筛选仍依赖专家人工检查，这已成为现代光谱巡天数据洪流的主要瓶颈。

Method: 提出Spec-o3工具增强视觉语言智能体，采用两阶段后训练方法：基于专家检查轨迹的冷启动监督微调，然后在稀有类型验证任务上进行基于结果的强化学习。

Result: 在LAMOST的五个稀有天体识别任务中，Spec-o3将macro-F1分数从28.3提升到76.5，使用7B参数基础模型超越专有视觉语言模型和专用深度模型，并展示了对SDSS/DESI等不同巡天的强泛化能力。

Conclusion: Spec-o3通过天文学家对齐的多模态推理，实现了透明可信的决策，解决了光谱数据洪流中人工检查的瓶颈问题，为天文光谱分析提供了可扩展的自动化解决方案。

Abstract: Due to the limited generalization and interpretability of deep learning classifiers, The final vetting of rare celestial object candidates still relies on expert visual inspection--a manually intensive process. In this process, astronomers leverage specialized tools to analyze spectra and construct reliable catalogs. However, this practice has become the primary bottleneck, as it is fundamentally incapable of scaling with the data deluge from modern spectroscopic surveys. To bridge this gap, we propose Spec-o3, a tool-augmented vision-language agent that performs astronomer-aligned spectral inspection via interleaved multimodal chain-of-thought reasoning. Spec-o3 is trained with a two-stage post-training recipe: cold-start supervised fine-tuning on expert inspection trajectories followed by outcome-based reinforcement learning on rare-type verification tasks. Evaluated on five rare-object identification tasks from LAMOST, Spec-o3 establishes a new State-of-the-Art, boosting the macro-F1 score from 28.3 to 76.5 with a 7B parameter base model and outperforming both proprietary VLMs and specialized deep models. Crucially, the agent demonstrates strong generalization to unseen inspection tasks across survey shifts (from LAMOST to SDSS/DESI). Expert evaluations confirm that its reasoning traces are coherent and physically consistent, supporting transparent and trustworthy decision-making. Code, data, and models are available at \href{https://github.com/Maxwell-Jia/spec-o3}{Project HomePage}.

</details>


### [31] [MedRAGChecker: Claim-Level Verification for Biomedical Retrieval-Augmented Generation](https://arxiv.org/abs/2601.06519)
*Yuelyu Ji,Min Gu Kwak,Hang Zhang,Xizhi Wu,Chenyu Li,Yanshan Wang*

Main category: cs.CL

TL;DR: MedRAGChecker是一个针对生物医学RAG系统的声明级验证框架，通过分解答案为原子声明，结合证据推理和知识图谱一致性信号来检测不支持或矛盾的声明，特别关注安全关键错误。


<details>
  <summary>Details</summary>
Motivation: 生物医学检索增强生成（RAG）虽然能将LLM答案基于医学文献，但长篇输出常包含孤立的不支持或矛盾声明，这些声明具有安全影响。现有方法缺乏细粒度的声明级验证机制来识别这些问题。

Method: 1. 将生成的答案分解为原子声明；2. 结合证据基础的自然语言推理（NLI）和生物医学知识图谱（KG）一致性信号来估计声明支持度；3. 通过集成验证器进行可扩展评估，使用类别特定的可靠性加权；4. 将管道蒸馏为紧凑的生物医学模型。

Result: 在四个生物医学QA基准测试中，MedRAGChecker能可靠地标记不支持或矛盾的声明，并揭示不同生成器之间的风险特征差异，特别是在安全关键的生物医学关系上表现突出。

Conclusion: MedRAGChecker提供了一个有效的声明级验证和诊断框架，能够识别生物医学RAG系统中的检索和生成失败，包括忠实性、证据不足、矛盾和安全关键错误率，对提高生物医学AI系统的安全性和可靠性具有重要意义。

Abstract: Biomedical retrieval-augmented generation (RAG) can ground LLM answers in medical literature, yet long-form outputs often contain isolated unsupported or contradictory claims with safety implications.
  We introduce MedRAGChecker, a claim-level verification and diagnostic framework for biomedical RAG.
  Given a question, retrieved evidence, and a generated answer, MedRAGChecker decomposes the answer into atomic claims and estimates claim support by combining evidence-grounded natural language inference (NLI) with biomedical knowledge-graph (KG) consistency signals.
  Aggregating claim decisions yields answer-level diagnostics that help disentangle retrieval and generation failures, including faithfulness, under-evidence, contradiction, and safety-critical error rates.
  To enable scalable evaluation, we distill the pipeline into compact biomedical models and use an ensemble verifier with class-specific reliability weighting.
  Experiments on four biomedical QA benchmarks show that MedRAGChecker reliably flags unsupported and contradicted claims and reveals distinct risk profiles across generators, particularly on safety-critical biomedical relations.

</details>


### [32] [Atomic-SNLI: Fine-Grained Natural Language Inference through Atomic Fact Decomposition](https://arxiv.org/abs/2601.06528)
*Minghui Huang*

Main category: cs.CL

TL;DR: 论文提出Atomic-SNLI数据集，通过将假设分解为原子事实来改进自然语言推理系统的细粒度推理能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言推理系统主要在句子层面操作，缺乏解释性。原子级NLI通过将假设分解为单个事实提供了有前景的替代方案，但传统假设（只有当所有原子事实都被蕴含时假设才被蕴含）在实践中因模型细粒度推理能力差而失败。

Method: 通过分解SNLI数据集并采用语言学信息生成策略精心构建原子级示例，创建了Atomic-SNLI数据集。在该数据集上微调模型以提升原子推理能力。

Result: 实验结果表明，在Atomic-SNLI上微调的模型在原子推理能力上取得显著提升，同时保持强大的句子层面性能，实现了准确判断和事实层面的透明、可解释结果。

Conclusion: Atomic-SNLI数据集有效解决了现有模型在原子级推理上的局限性，使NLI系统既能做出准确判断，又能提供事实层面的透明解释，推动了可解释AI的发展。

Abstract: Current Natural Language Inference (NLI) systems primarily operate at the sentence level, providing black-box decisions that lack explanatory power. While atomic-level NLI offers a promising alternative by decomposing hypotheses into individual facts, we demonstrate that the conventional assumption that a hypothesis is entailed only when all its atomic facts are entailed fails in practice due to models' poor performance on fine-grained reasoning. Our analysis reveals that existing models perform substantially worse on atomic level inference compared to sentence level tasks. To address this limitation, we introduce Atomic-SNLI, a novel dataset constructed by decomposing SNLI and enriching it with carefully curated atomic level examples through linguistically informed generation strategies. Experimental results demonstrate that models fine-tuned on Atomic-SNLI achieve significant improvements in atomic reasoning capabilities while maintaining strong sentence level performance, enabling both accurate judgements and transparent, explainable results at the fact level.

</details>


### [33] [Exposía: Academic Writing Assessment of Exposés and Peer Feedback](https://arxiv.org/abs/2601.06536)
*Dennis Zyska,Alla Rozovskaya,Ilia Kuznetsov,Iryna Gurevych*

Main category: cs.CL

TL;DR: Exposía是首个连接高等教育写作与反馈评估的公开数据集，包含学生研究项目提案及同伴/教师反馈，支持学术写作评估研究。作者使用该数据集对开源大语言模型进行自动评分基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏连接学术写作与反馈评估的公开数据集，限制了教育领域基于数据的学术写作评估方法研究。需要开发一个能够反映学术写作多阶段过程（起草、反馈、修订）的数据集。

Method: 收集计算机科学本科"科学工作导论"课程中的学生研究项目提案、同伴反馈和教师反馈，构建Exposía数据集。开发细粒度、基于教学原理的写作和反馈评估框架。使用该数据集对开源大语言模型进行两个任务的基准测试：提案自动评分和学生反馈自动评分。

Result: 最强的LLM在需要较少领域知识的评分维度上达到较高一致性，但在评估内容的维度上表现下降，与人类评估者的一致性趋势一致。LLM更倾向于与给出高分的教师评估者保持一致。同时发现，同时对写作多个方面进行评分的提示策略最为有效。

Conclusion: Exposía数据集为学术写作评估研究提供了重要资源。LLM在学术写作自动评分方面展现出潜力，特别是在结构化维度上，但在内容评估方面仍有局限。多维度联合评分策略对课堂部署具有重要意义。

Abstract: We present Exposía, the first public dataset that connects writing and feedback assessment in higher education, enabling research on educationally grounded approaches to academic writing evaluation. Exposía includes student research project proposals and peer and instructor feedback consisting of comments and free-text reviews. The dataset was collected in the "Introduction to Scientific Work" course of the Computer Science undergraduate program that focuses on teaching academic writing skills and providing peer feedback on academic writing. Exposía reflects the multi-stage nature of the academic writing process that includes drafting, providing and receiving feedback, and revising the writing based on the feedback received. Both the project proposals and peer feedback are accompanied by human assessment scores based on a fine-grained, pedagogically-grounded schema for writing and feedback assessment that we develop.
  We use Exposía to benchmark state-of-the-art open-source large language models (LLMs) for two tasks: automated scoring of (1) the proposals and (2) the student reviews. The strongest LLMs attain high agreement on scoring aspects that require little domain knowledge but degrade on dimensions evaluating content, in line with human agreement values. We find that LLMs align better with the human instructors giving high scores. Finally, we establish that a prompting strategy that scores multiple aspects of the writing together is the most effective, an important finding for classroom deployment.

</details>


### [34] [SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation](https://arxiv.org/abs/2601.06543)
*Jun-Qi Chen,Kun Zhang,Rui Zheng,Ying Zhong*

Main category: cs.CL

TL;DR: 研究者微调开源LLMs（Qwen-Coder-7B和DeepSeek-Coder-6.7B）用于生成SimPy排队模拟代码，以解决闭源模型的高成本和隐私问题，通过多阶段微调框架显著提升了代码可执行性、格式合规性和指令一致性。


<details>
  <summary>Details</summary>
Motivation: SimPy广泛用于排队系统建模，LLMs在生成可执行代码方面表现出色，但直接使用闭源模型（如GPT-4o）存在高计算成本和数据隐私问题，需要开发更经济、隐私友好的替代方案。

Method: 采用多阶段微调框架：首先在精选的SimPy排队数据上进行两阶段监督微调（SFT），然后进行直接偏好优化（DPO），逐步提升模型生成SimPy排队模拟代码的能力。

Result: 两个微调模型在可执行性、输出格式合规性和指令一致性方面均取得显著提升，证明领域特定微调能将紧凑的开源代码模型转化为可靠的SimPy模拟生成器。

Conclusion: 领域特定微调可有效将开源代码模型转变为可靠的SimPy模拟生成器，为教育、研究和运营决策支持提供了闭源LLMs的实用替代方案。

Abstract: The Python package SimPy is widely used for modeling queueing systems due to its flexibility, simplicity, and smooth integration with modern data analysis and optimization frameworks. Recent advances in large language models (LLMs) have shown strong ability in generating clear and executable code, making them powerful and suitable tools for writing SimPy queueing simulation code. However, directly employing closed-source models like GPT-4o to generate such code may lead to high computational costs and raise data privacy concerns. To address this, we fine-tune two open-source LLMs, Qwen-Coder-7B and DeepSeek-Coder-6.7B, on curated SimPy queueing data, which enhances their code-generating performance in executability, output-format compliance, and instruction-code consistency. Particularly, we proposed a multi-stage fine-tuning framework comprising two stages of supervised fine-tuning (SFT) and one stage of direct preference optimization (DPO), progressively enhancing the model's ability in SimPy-based queueing simulation code generation. Extensive evaluations demonstrate that both fine-tuned models achieve substantial improvements in executability, output-format compliance, and instruct consistency. These results confirm that domain-specific fine-tuning can effectively transform compact open-source code models into reliable SimPy simulation generators which provide a practical alternative to closed-source LLMs for education, research, and operational decision support.

</details>


### [35] [CSR-RAG: An Efficient Retrieval System for Text-to-SQL on the Enterprise Scale](https://arxiv.org/abs/2601.06564)
*Rajpreet Singh,Novak Boškov,Lawrence Drabeck,Aditya Gudal,Manzoor A. Khan*

Main category: cs.CL

TL;DR: 提出CSR-RAG混合检索增强生成系统，用于企业级数据库的自然语言到SQL转换，通过上下文、结构和关系检索实现高效准确查询


<details>
  <summary>Details</summary>
Motivation: 企业级应用需要先进行表检索再生成SQL查询，而现有学术基准通常将模式描述作为自然语言输入的一部分，无法满足企业级需求

Method: 提出CSR-RAG混合检索增强生成系统，包含上下文检索、结构检索和关系检索三个组件，实现计算高效且足够准确的检索

Result: 在企业级基准测试中，CSR-RAG达到40%的精确率和超过80%的召回率，平均查询生成延迟仅30ms，适合现代LLM企业级系统

Conclusion: CSR-RAG系统为企业级数据库的Text-to-SQL任务提供了高效准确的检索解决方案，平衡了计算效率和准确性需求

Abstract: Natural language to SQL translation (Text-to-SQL) is one of the long-standing problems that has recently benefited from advances in Large Language Models (LLMs). While most academic Text-to-SQL benchmarks request schema description as a part of natural language input, enterprise-scale applications often require table retrieval before SQL query generation. To address this need, we propose a novel hybrid Retrieval Augmented Generation (RAG) system consisting of contextual, structural, and relational retrieval (CSR-RAG) to achieve computationally efficient yet sufficiently accurate retrieval for enterprise-scale databases. Through extensive enterprise benchmarks, we demonstrate that CSR-RAG achieves up to 40% precision and over 80% recall while incurring a negligible average query generation latency of only 30ms on commodity data center hardware, which makes it appropriate for modern LLM-based enterprise-scale systems.

</details>


### [36] [EVM-QuestBench: An Execution-Grounded Benchmark for Natural-Language Transaction Code Generation](https://arxiv.org/abs/2601.06565)
*Pei Yang,Wanyi Chen,Ke Wang,Lynn Ai,Eric Yang,Tianyu Shi*

Main category: cs.CL

TL;DR: EVM-QuestBench是一个针对EVM兼容链上自然语言交易脚本生成的执行基准测试，包含107个任务，采用动态评估方法，发现现有模型在单动作精度和多步骤工作流完成度之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 在链上交易场景中，即使是微小的错误也可能给用户造成不可逆的损失，而现有的评估方法往往忽视执行准确性和安全性，因此需要专门的执行基准来评估语言模型在交易脚本生成方面的能力。

Method: 采用动态评估方法：从模板池中采样指令，从预定义区间抽取数值参数，验证器根据这些实例化值验证结果。包含107个任务（62个原子任务，45个复合任务），采用模块化架构支持快速任务开发。在分叉的EVM链上执行脚本，使用快照隔离；复合任务应用步骤效率衰减。

Result: 评估了20个模型，发现存在较大的性能差距，分数分解显示单动作精度和多步骤工作流完成度之间存在持续的不对称性。

Conclusion: EVM-QuestBench提供了一个有效的执行基准测试框架，揭示了现有语言模型在链上交易脚本生成任务中的局限性，特别是在复杂多步骤工作流方面的表现不足。

Abstract: Large language models are increasingly applied to various development scenarios. However, in on-chain transaction scenarios, even a minor error can cause irreversible loss for users. Existing evaluations often overlook execution accuracy and safety. We introduce EVM-QuestBench, an execution-grounded benchmark for natural-language transaction-script generation on EVM-compatible chains. The benchmark employs dynamic evaluation: instructions are sampled from template pools, numeric parameters are drawn from predefined intervals, and validators verify outcomes against these instantiated values. EVM-QuestBench contains 107 tasks (62 atomic, 45 composite). Its modular architecture enables rapid task development. The runner executes scripts on a forked EVM chain with snapshot isolation; composite tasks apply step-efficiency decay. We evaluate 20 models and find large performance gaps, with split scores revealing persistent asymmetry between single-action precision and multi-step workflow completion. Code: https://anonymous.4open.science/r/bsc_quest_bench-A9CF/.

</details>


### [37] [Are Emotions Arranged in a Circle? Geometric Analysis of Emotion Representations via Hyperspherical Contrastive Learning](https://arxiv.org/abs/2601.06575)
*Yusuke Yamauchi,Akiko Aizawa*

Main category: cs.CL

TL;DR: 该论文提出了一种通过对比学习在超球面上诱导语言模型嵌入中圆形情感表示的方法，发现这种圆形对齐虽然提供更好的可解释性和对降维的鲁棒性，但在高维设置和细粒度分类中表现不如传统设计。


<details>
  <summary>Details</summary>
Motivation: 心理学研究长期使用环状模型来结构化情感，将相似情感相邻放置，对立情感对角放置。尽管这些模型经常被用来解释深度学习表示，但很少直接纳入语言模型的表示学习中，其几何有效性尚未被探索。

Method: 提出了一种通过对比学习在超球面上诱导语言模型嵌入中圆形情感表示的方法。

Result: 圆形对齐提供了优越的可解释性和对降维的鲁棒性，但在高维设置和细粒度分类中表现不如传统设计。

Conclusion: 研究结果阐明了将心理学环状模型应用于深度学习架构时涉及的权衡。

Abstract: Psychological research has long utilized circumplex models to structure emotions, placing similar emotions adjacently and opposing ones diagonally. Although frequently used to interpret deep learning representations, these models are rarely directly incorporated into the representation learning of language models, leaving their geometric validity unexplored. This paper proposes a method to induce circular emotion representations within language model embeddings via contrastive learning on a hypersphere. We show that while this circular alignment offers superior interpretability and robustness against dimensionality reduction, it underperforms compared to conventional designs in high-dimensional settings and fine-grained classification. Our findings elucidate the trade-offs involved in applying psychological circumplex models to deep learning architectures.

</details>


### [38] [Stylistic Evolution and LLM Neutrality in Singlish Language](https://arxiv.org/abs/2601.06580)
*Linus Tze En Foo,Weihan Angela Ng,Wenkai Li,Lynnette Hui Xian Ng*

Main category: cs.CL

TL;DR: 该研究分析了新加坡英语（Singlish）在十年间非正式数字短信中的演变，提出了风格相似性框架来量化时间变化，并测试了LLMs生成Singlish的能力及其时间中立性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解Singlish这种在新加坡多语言环境中产生的克里奥尔语如何随着社会和技术变化而演变，特别是通过非正式数字通信渠道的视角。

Method: 提出了一个风格相似性框架，通过比较词汇结构、语用、心理语言学和编码器提取的特征来分析跨年份的Singlish文本，并测试了LLMs生成Singlish的能力及其时间信号残留。

Result: 分析显示Singlish在语调、表达性和句子结构方面存在显著的历时变化。虽然一些LLMs能够生成表面真实的Singlish消息，但它们无法产生时间中立的输出，即使经过提示和微调，残留的时间信号仍然可检测。

Conclusion: 研究结果突出了Singlish的动态演变特性，以及当前LLMs在建模口语语言的社会方言和时间变化方面的能力和局限性。

Abstract: Singlish is a creole rooted in Singapore's multilingual environment and continues to evolve alongside social and technological change. This study investigates the evolution of Singlish over a decade of informal digital text messages. We propose a stylistic similarity framework that compares lexico-structural, pragmatic, psycholinguistic, and encoder-derived features across years to quantify temporal variation. Our analysis reveals notable diachronic changes in tone, expressivity and sentence construction over the years. Conversely, while some LLMs were able to generate superficially realistic Singlish messages, they do not produce temporally neutral outputs, and residual temporal signals remain detectable despite prompting and fine-tuning. Our findings highlight the dynamic evolution of Singlish, as well as the capabilities and limitations of current LLMs in modeling sociolectal and temporal variations in the colloquial language.

</details>


### [39] [Detecting LLM-Generated Text with Performance Guarantees](https://arxiv.org/abs/2601.06586)
*Hongyi Zhou,Jin Zhu,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 训练一个无需辅助信息的LLM文本检测器，能有效区分人类和AI生成文本，支持统计推断，并在准确率和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM生成高度拟人化文本引发严重担忧，包括假新闻传播、误导性政府报告和学术不端等实际问题，需要开发有效的检测工具。

Method: 训练一个分类器，无需依赖水印或特定LLM信息，仅基于文本内容判断是否为LLM生成，支持统计推断并部署在在线CPU平台上。

Result: 该检测器在分类准确率上优于现有方法，同时保持I类错误控制、高统计功效和计算效率，已部署在Hugging Face平台。

Conclusion: 提出的检测器能有效解决LLM文本检测的实际问题，具有无需辅助信息、高准确率和统计推断能力三大创新点。

Abstract: Large language models (LLMs) such as GPT, Claude, Gemini, and Grok have been deeply integrated into our daily life. They now support a wide range of tasks -- from dialogue and email drafting to assisting with teaching and coding, serving as search engines, and much more. However, their ability to produce highly human-like text raises serious concerns, including the spread of fake news, the generation of misleading governmental reports, and academic misconduct. To address this practical problem, we train a classifier to determine whether a piece of text is authored by an LLM or a human. Our detector is deployed on an online CPU-based platform https://huggingface.co/spaces/stats-powered-ai/StatDetectLLM, and contains three novelties over existing detectors: (i) it does not rely on auxiliary information, such as watermarks or knowledge of the specific LLM used to generate the text; (ii) it more effectively distinguishes between human- and LLM-authored text; and (iii) it enables statistical inference, which is largely absent in the current literature. Empirically, our classifier achieves higher classification accuracy compared to existing detectors, while maintaining type-I error control, high statistical power, and computational efficiency.

</details>


### [40] [How Context Shapes Truth: Geometric Transformations of Statement-level Truth Representations in LLMs](https://arxiv.org/abs/2601.06599)
*Shivam Adarsh,Maria Maistro,Christina Lioma*

Main category: cs.CL

TL;DR: 研究大型语言模型中真理向量在上下文引入时的几何变化，发现上下文会放大真假表征的分离，不同规模模型通过不同机制区分相关/无关上下文。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探索LLMs中真理向量的存在，但上下文如何改变这些向量仍未被探索。本研究旨在从几何角度分析上下文对真理向量的影响。

Method: 通过测量(1)有/无上下文时真理向量的方向变化(θ)和(2)添加上下文后真理向量的相对大小，在四个LLMs和四个数据集上进行实验分析。

Result: 发现：1)真理向量在早期层正交，中间层收敛，后期层稳定或继续增加；2)上下文通常增加真理向量大小，放大真假表征分离；3)大模型主要通过方向变化区分相关/无关上下文，小模型通过大小差异；4)与参数知识冲突的上下文产生更大的几何变化。

Conclusion: 这是首个从几何角度描述上下文如何转换LLMs激活空间中真理向量的工作，揭示了上下文对真理表示的动态影响机制。

Abstract: Large Language Models (LLMs) often encode whether a statement is true as a vector in their residual stream activations. These vectors, also known as truth vectors, have been studied in prior work, however how they change when context is introduced remains unexplored. We study this question by measuring (1) the directional change ($θ$) between the truth vectors with and without context and (2) the relative magnitude of the truth vectors upon adding context. Across four LLMs and four datasets, we find that (1) truth vectors are roughly orthogonal in early layers, converge in middle layers, and may stabilize or continue increasing in later layers; (2) adding context generally increases the truth vector magnitude, i.e., the separation between true and false representations in the activation space is amplified; (3) larger models distinguish relevant from irrelevant context mainly through directional change ($θ$), while smaller models show this distinction through magnitude differences. We also find that context conflicting with parametric knowledge produces larger geometric changes than parametrically aligned context. To the best of our knowledge, this is the first work that provides a geometric characterization of how context transforms the truth vector in the activation space of LLMs.

</details>


### [41] [Probing Multimodal Large Language Models on Cognitive Biases in Chinese Short-Video Misinformation](https://arxiv.org/abs/2601.06600)
*Jen-tse Huang,Chang Chen,Shiyang Lai,Wenxuan Wang,Michelle R. Kaufman,Mark Dredze*

Main category: cs.CL

TL;DR: 该研究评估了多模态大语言模型在短视频健康谣言检测中的表现，发现模型容易受到权威渠道等社会线索的认知偏见影响。


<details>
  <summary>Details</summary>
Motivation: 短视频平台已成为健康谣言传播的主要渠道，而当前多模态大语言模型在应对包含认知偏见的误导性内容方面的鲁棒性尚未得到充分探索。

Method: 构建了一个包含200个短视频的高质量人工标注数据集，涵盖四个健康领域，标注了三种欺骗模式（实验错误、逻辑谬误、捏造主张），并评估了8个前沿MLLM在五种模态设置下的表现。

Result: Gemini-2.5-Pro在多模态设置中表现最佳（信念得分71.5/100），o3表现最差（35.2）。研究发现模型容易受到权威渠道ID等社会线索的认知偏见影响。

Conclusion: 多模态大语言模型在检测短视频健康谣言方面仍有改进空间，特别是需要增强对认知偏见的抵抗能力，未来研究应关注提升模型的社会线索识别和抗偏见能力。

Abstract: Short-video platforms have become major channels for misinformation, where deceptive claims frequently leverage visual experiments and social cues. While Multimodal Large Language Models (MLLMs) have demonstrated impressive reasoning capabilities, their robustness against misinformation entangled with cognitive biases remains under-explored. In this paper, we introduce a comprehensive evaluation framework using a high-quality, manually annotated dataset of 200 short videos spanning four health domains. This dataset provides fine-grained annotations for three deceptive patterns, experimental errors, logical fallacies, and fabricated claims, each verified by evidence such as national standards and academic literature. We evaluate eight frontier MLLMs across five modality settings. Experimental results demonstrate that Gemini-2.5-Pro achieves the highest performance in the multimodal setting with a belief score of 71.5/100, while o3 performs the worst at 35.2. Furthermore, we investigate social cues that induce false beliefs in videos and find that models are susceptible to biases like authoritative channel IDs.

</details>


### [42] [N2N-GQA: Noise-to-Narrative for Graph-Based Table-Text Question Answering Using LLMs](https://arxiv.org/abs/2601.06603)
*Mohamed Sharafath,Aravindh Annamalai,Ganesh Murugan,Aravindakumar Venugopalan*

Main category: cs.CL

TL;DR: N2N-GQA：首个零样本开放域混合表格-文本QA框架，通过构建动态证据图解决多跳推理中的检索噪声问题，无需任务特定训练即可达到接近精细调优系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG流水线将文档处理为扁平排名列表，导致检索噪声掩盖推理链，无法有效支持多跳问答。需要一种能够理解证据间关系、识别连接推理步骤的桥梁文档的方法。

Method: 提出N2N-GQA框架，将文档建模为图节点，语义关系为边，从噪声检索输出中构建动态证据图，识别连接推理步骤的桥梁文档，实现结构化证据组织。

Result: 在OTT-QA数据集上，基于图的证据整理比强基线提升19.9个EM点，达到48.80 EM，匹配精细调优的检索模型（CORE: 49.0 EM），接近高度优化的系统（COS: 56.9 EM）。

Conclusion: 图结构证据组织对于可扩展的零样本多跳QA系统至关重要，简单可解释的图构建方法可以媲美复杂的精细调优方法，为开放域混合数据QA提供了新方向。

Abstract: Multi-hop question answering over hybrid table-text data requires retrieving and reasoning across multiple evidence pieces from large corpora, but standard Retrieval-Augmented Generation (RAG) pipelines process documents as flat ranked lists, causing retrieval noise to obscure reasoning chains. We introduce N2N-GQA. To our knowledge, it is the first zeroshot framework for open-domain hybrid table-text QA that constructs dynamic evidence graphs from noisy retrieval outputs. Our key insight is that multi-hop reasoning requires understanding relationships between evidence pieces: by modeling documents as graph nodes with semantic relationships as edges, we identify bridge documents connecting reasoning steps, a capability absent in list-based retrieval. On OTT-QA, graph-based evidence curation provides a 19.9-point EM improvement over strong baselines, demonstrating that organizing retrieval results as structured graphs is critical for multihop reasoning. N2N-GQA achieves 48.80 EM, matching finetuned retrieval models (CORE: 49.0 EM) and approaching heavily optimized systems (COS: 56.9 EM) without any task specific training. This establishes graph-structured evidence organization as essential for scalable, zero-shot multi-hop QA systems and demonstrates that simple, interpretable graph construction can rival sophisticated fine-tuned approaches.

</details>


### [43] [Pragya: An AI-Based Semantic Recommendation System for Sanskrit Subhasitas](https://arxiv.org/abs/2601.06607)
*Tanisha Raorane,Prasenjit Kole*

Main category: cs.CL

TL;DR: Pragya：首个结合检索与生成的梵语Subhasitas语义推荐框架，通过IndicBERT检索和Mistral LLM生成，提升古印度智慧格言的可访问性。


<details>
  <summary>Details</summary>
Motivation: 梵语Subhasitas蕴含数世纪的文化哲学智慧，但由于语言和语境障碍，在数字时代未被充分利用。需要一种方法让这些文化遗产更易于现代人访问和理解。

Method: 开发Pragya框架：1) 构建包含200首诗句的数据集，标注主题标签；2) 使用IndicBERT句子嵌入进行语义检索，找到与用户查询最相关的诗句；3) 将检索结果输入Mistral LLM生成音译、翻译和上下文解释。

Result: 实验评估表明：语义检索在精确度和相关性上显著优于关键词匹配；用户研究显示生成的摘要提高了可访问性；这是首个将检索与生成结合用于梵语Subhasitas的尝试。

Conclusion: Pragya成功将文化遗产与现代应用AI相结合，为梵语Subhasitas提供了有效的语义推荐系统，解决了语言和语境障碍，使古代智慧更易于数字时代访问。

Abstract: Sanskrit Subhasitas encapsulate centuries of cultural and philosophical wisdom, yet remain underutilized in the digital age due to linguistic and contextual barriers. In this work, we present Pragya, a retrieval-augmented generation (RAG) framework for semantic recommendation of Subhasitas. We curate a dataset of 200 verses annotated with thematic tags such as motivation, friendship, and compassion. Using sentence embeddings (IndicBERT), the system retrieves top-k verses relevant to user queries. The retrieved results are then passed to a generative model (Mistral LLM) to produce transliterations, translations, and contextual explanations. Experimental evaluation demonstrates that semantic retrieval significantly outperforms keyword matching in precision and relevance, while user studies highlight improved accessibility through generated summaries. To our knowledge, this is the first attempt at integrating retrieval and generation for Sanskrit Subhasitas, bridging cultural heritage with modern applied AI.

</details>


### [44] [Efficient and Reliable Estimation of Named Entity Linking Quality: A Case Study on GutBrainIE](https://arxiv.org/abs/2601.06624)
*Marco Martinelli,Stefano Marchesin,Gianmaria Silvello*

Main category: cs.CL

TL;DR: 提出一个基于抽样的框架，在统计保证和有限标注预算下估计大规模信息抽取语料库的命名实体链接准确性


<details>
  <summary>Details</summary>
Motivation: 生物医学信息抽取中命名实体链接质量评估面临挑战：专家标注成本高、语料库规模大，需要可扩展且统计鲁棒的准确性评估方法

Method: 将NEL准确性估计构建为约束优化问题，最小化标注成本同时满足目标误差范围；采用分层两阶段聚类抽样，基于标签分层和全局表面形式聚类，独立于NEL标注

Result: 在GutBrainIE语料库的11,184个NEL标注上，仅手动标注2,749个三元组（24.6%）就达到误差范围≤0.05，总体准确性估计为0.915±0.0473；比简单随机抽样减少约29%的专家标注时间

Conclusion: 该框架是通用的，可应用于其他需要可扩展且统计鲁棒准确性评估的NEL基准测试和信息抽取流程

Abstract: Named Entity Linking (NEL) is a core component of biomedical Information Extraction (IE) pipelines, yet assessing its quality at scale is challenging due to the high cost of expert annotations and the large size of corpora. In this paper, we present a sampling-based framework to estimate the NEL accuracy of large-scale IE corpora under statistical guarantees and constrained annotation budgets. We frame NEL accuracy estimation as a constrained optimization problem, where the objective is to minimize expected annotation cost subject to a target Margin of Error (MoE) for the corpus-level accuracy estimate. Building on recent works on knowledge graph accuracy estimation, we adapt Stratified Two-Stage Cluster Sampling (STWCS) to the NEL setting, defining label-based strata and global surface-form clusters in a way that is independent of NEL annotations. Applied to 11,184 NEL annotations in GutBrainIE -- a new biomedical corpus openly released in fall 2025 -- our framework reaches a MoE $\leq 0.05$ by manually annotating only 2,749 triples (24.6%), leading to an overall accuracy estimate of $0.915 \pm 0.0473$. A time-based cost model and simulations against a Simple Random Sampling (SRS) baseline show that our design reduces expert annotation time by about 29% at fixed sample size. The framework is generic and can be applied to other NEL benchmarks and IE pipelines that require scalable and statistically robust accuracy assessment.

</details>


### [45] [Labels have Human Values: Value Calibration of Subjective Tasks](https://arxiv.org/abs/2601.06631)
*Mohammed Fayiz Parappan,Ricardo Henao*

Main category: cs.CL

TL;DR: MC-STL框架通过聚类标注数据来识别不同的人类价值观群体，并学习群体特定的嵌入表示，以提升主观任务中NLP系统的表现。


<details>
  <summary>Details</summary>
Motivation: 构建面向主观任务的NLP系统需要确保其与不同人类价值观的对齐，因为主观任务中不同人群可能有不同的价值判断标准。

Method: 提出MC-STL框架，通过三种方法聚类标注数据：标注者理由相似性、专家价值分类或标注者社会文化描述符，然后为每个价值群体学习特定的嵌入表示进行校准。

Result: 在多个主观学习任务（序数、二元和偏好学习）和数据集（有毒聊天机器人对话、冒犯性社交媒体帖子、人类偏好对齐）上，MC-STL均优于忽略标注潜在价值结构的基线方法，在区分度、价值特定校准和分歧感知指标上都有提升。

Conclusion: MC-STL框架能有效识别和建模主观任务中的人类价值差异，显著提升NLP系统在不同价值群体上的表现，为构建更公平、更准确的主观任务系统提供了有效方法。

Abstract: Building NLP systems for subjective tasks requires one to ensure their alignment to contrasting human values. We propose the MultiCalibrated Subjective Task Learner framework (MC-STL), which clusters annotations into identifiable human value clusters by three approaches (similarity of annotator rationales, expert-value taxonomies or rater's sociocultural descriptors) and calibrates predictions for each value cluster by learning cluster-specific embeddings. We demonstrate MC-STL on several subjective learning settings, including ordinal, binary, and preference learning predictions, and evaluate it on multiple datasets covering toxic chatbot conversations, offensive social media posts, and human preference alignment. The results show that MC-STL consistently outperforms the baselines that ignore the latent value structure of the annotations, delivering gains in discrimination, value-specific calibration, and disagreement-aware metrics.

</details>


### [46] [MedEinst: Benchmarking the Einstellung Effect in Medical LLMs through Counterfactual Differential Diagnosis](https://arxiv.org/abs/2601.06636)
*Wenting Chen,Zhongrui Zhu,Guolin Huang,Wenxuan Wang*

Main category: cs.CL

TL;DR: 该论文提出了MedEinst基准测试，用于检测LLM在临床诊断中的Einstellung效应（依赖统计捷径而非患者特异性证据），并开发了ECR-Agent系统来改善医学推理。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在医学基准测试中达到高准确率，但在临床诊断中表现出Einstellung效应——依赖统计捷径而非患者特异性证据，导致非典型病例误诊。现有基准测试无法检测这一关键失败模式。

Method: 1. 引入MedEinst基准：包含5,383对临床病例，覆盖49种疾病，每对包含控制病例和"陷阱"病例（改变鉴别性证据导致诊断反转）；2. 提出ECR-Agent系统：包含动态因果推理（DCI）进行结构化推理，以及批判驱动的图和记忆演化（CGME）迭代优化系统。

Result: 评估17个LLM显示，前沿模型虽然基线准确率高，但存在严重的偏差陷阱率。ECR-Agent能够显著改善医学推理质量。

Conclusion: 需要专门基准来检测LLM在医学诊断中的Einstellung效应，而ECR-Agent通过结构化因果推理和迭代优化能够有效改善LLM的临床推理能力。

Abstract: Despite achieving high accuracy on medical benchmarks, LLMs exhibit the Einstellung Effect in clinical diagnosis--relying on statistical shortcuts rather than patient-specific evidence, causing misdiagnosis in atypical cases. Existing benchmarks fail to detect this critical failure mode. We introduce MedEinst, a counterfactual benchmark with 5,383 paired clinical cases across 49 diseases. Each pair contains a control case and a "trap" case with altered discriminative evidence that flips the diagnosis. We measure susceptibility via Bias Trap Rate--probability of misdiagnosing traps despite correctly diagnosing controls. Extensive Evaluation of 17 LLMs shows frontier models achieve high baseline accuracy but severe bias trap rates. Thus, we propose ECR-Agent, aligning LLM reasoning with Evidence-Based Medicine standard via two components: (1) Dynamic Causal Inference (DCI) performs structured reasoning through dual-pathway perception, dynamic causal graph reasoning across three levels (association, intervention, counterfactual), and evidence audit for final diagnosis; (2) Critic-Driven Graph and Memory Evolution (CGME) iteratively refines the system by storing validated reasoning paths in an exemplar base and consolidating disease-specific knowledge into evolving illness graphs. Source code is to be released.

</details>


### [47] [Efficient Aspect Term Extraction using Spiking Neural Network](https://arxiv.org/abs/2601.06637)
*Abhishek Kumar Mishra,Arya Somasundaram,Anup Das,Nagarajan Kandasamy*

Main category: cs.CL

TL;DR: 本文提出了一种基于脉冲神经网络（SNN）的节能型方面术语提取方法SpikeATE，在保持与深度神经网络相当性能的同时显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有方面术语提取（ATE）方法主要使用能耗高的深度神经网络进行序列标注，需要寻找更节能的替代方案。

Method: 提出SpikeATE架构，使用三元脉冲神经元和直接脉冲训练，通过伪梯度进行微调，利用稀疏激活和事件驱动推理捕捉词间时序依赖。

Result: 在四个SemEval基准数据集上，SpikeATE达到与最先进深度神经网络相当的性能，同时显著降低能耗。

Conclusion: 脉冲神经网络是方面术语提取任务实用且可持续的选择，为节能自然语言处理提供了可行方案。

Abstract: Aspect Term Extraction (ATE) identifies aspect terms in review sentences, a key subtask of sentiment analysis. While most existing approaches use energy-intensive deep neural networks (DNNs) for ATE as sequence labeling, this paper proposes a more energy-efficient alternative using Spiking Neural Networks (SNNs). Using sparse activations and event-driven inferences, SNNs capture temporal dependencies between words, making them suitable for ATE. The proposed architecture, SpikeATE, employs ternary spiking neurons and direct spike training fine-tuned with pseudo-gradients. Evaluated on four benchmark SemEval datasets, SpikeATE achieves performance comparable to state-of-the-art DNNs with significantly lower energy consumption. This highlights the use of SNNs as a practical and sustainable choice for ATE tasks.

</details>


### [48] [Do Language Models Reason Across Languages?](https://arxiv.org/abs/2601.06644)
*Yan Meng,Wafaa Mohammed,Christof Monz*

Main category: cs.CL

TL;DR: 本文研究了语言模型在多语言环境下的推理能力，发现模型对语言变化敏感且推理缺乏忠实分解，提出SUBQ提示方法显著提升两跳问答准确率。


<details>
  <summary>Details</summary>
Motivation: 现实世界信息源本质上是多语言的，这自然引发了一个问题：语言模型能否跨语言合成信息？本文旨在探索语言模型在多语言环境下的推理能力，特别是它们是否能够进行忠实的分步推理。

Method: 引入简单的两跳问答设置，需要基于两个多语言文档进行推理。通过分步子问题评估分析模型行为，发现推理缺乏忠实分解。为缓解此问题，提出三阶段SUBQ提示方法，通过子问题引导多步推理。

Result: 研究发现：1）语言模型对答案跨度文档的语言变化比对提供桥接信息的文档更敏感；2）高达33%的多语言案例中，模型未能推断第一步的桥接信息但仍能正确回答整体问题；3）推理缺乏分解导致约18%的组合失败；4）SUBQ提示方法将准确率从10.1%大幅提升至66.5%。

Conclusion: 语言模型在多语言环境下的推理缺乏忠实的分步分解，这限制了其跨语言信息合成能力。通过明确的子问题引导可以显著改善模型的推理性能，为提升多语言推理能力提供了有效方法。

Abstract: The real-world information sources are inherently multilingual, which naturally raises a question about whether language models can synthesize information across languages. In this paper, we introduce a simple two-hop question answering setting, where answering a question requires making inferences over two multilingual documents. We find that language models are more sensitive to language variation in answer-span documents than in those providing bridging information, despite the equal importance of both documents for answering a question. Under a step-by-step sub-question evaluation, we further show that in up to 33% of multilingual cases, models fail to infer the bridging information in the first step yet still answer the overall question correctly. This indicates that reasoning in language models, especially in multilingual settings, does not follow a faithful step-by-step decomposition. Subsequently, we show that the absence of reasoning decomposition leads to around 18% composition failure, where both sub-questions are answered correctly but fail for the final two-hop questions. To mitigate this, we propose a simple three-stage SUBQ prompting method to guide the multi-step reasoning with sub-questions, which boosts accuracy from 10.1% to 66.5%.

</details>


### [49] [What makes for an enjoyable protagonist? An analysis of character warmth and competence](https://arxiv.org/abs/2601.06658)
*Hannes Rosenbusch*

Main category: cs.CL

TL;DR: 研究使用AI辅助标注分析电影主角的温暖度和能力度对IMDb评分的影响，发现两者有理论一致但微弱的相关性，而性别差异的影响更大。


<details>
  <summary>Details</summary>
Motivation: 基于心理学和文学理论，探讨电影主角的温暖度和能力度是否影响观众评分，以及这种影响是否因电影类型而异。

Method: 使用Movie Scripts Corpus中的2,858部影视作品，通过AI辅助标注识别主角，并用LLM_annotate包量化温暖度和能力度，进行预注册贝叶斯回归分析。

Result: 温暖度和能力度与评分有理论一致但微弱的相关性；类型交互作用无显著预测改进；男性主角温暖度略低于女性主角；男性主演的电影评分平均更高。

Conclusion: 观众倾向于喜欢温暖、有能力的角色，但对电影评价的影响有限，表明角色个性只是影响评分的众多因素之一；AI辅助标注在大规模分析中有效，但偶尔不如人工标注。

Abstract: Drawing on psychological and literary theory, we investigated whether the warmth and competence of movie protagonists predict IMDb ratings, and whether these effects vary across genres. Using 2,858 films and series from the Movie Scripts Corpus, we identified protagonists via AI-assisted annotation and quantified their warmth and competence with the LLM_annotate package ([1]; human-LLM agreement: r = .83). Preregistered Bayesian regression analyses revealed theory-consistent but small associations between both warmth and competence and audience ratings, while genre-specific interactions did not meaningfully improve predictions. Male protagonists were slightly less warm than female protagonists, and movies with male leads received higher ratings on average (an association that was multiple times stronger than the relationships between movie ratings and warmth/competence). These findings suggest that, although audiences tend to favor warm, competent characters, the effects on movie evaluations are modest, indicating that character personality is only one of many factors shaping movie ratings. AI-assisted annotation with LLM_annotate and gpt-4.1-mini proved effective for large-scale analyses but occasionally fell short of manually generated annotations.

</details>


### [50] [InFi-Check: Interpretable and Fine-Grained Fact-Checking of LLMs](https://arxiv.org/abs/2601.06666)
*Yuzhuo Bai,Shuzheng Si,Kangyang Luo,Qingyi Wang,Wenhao Li,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: InFi-Check是一个用于大语言模型输出的可解释细粒度事实检查框架，包含数据合成管道、基准数据集和检查器模型，能提供证据、错误分类、解释和修正。


<details>
  <summary>Details</summary>
Motivation: 现有事实检查方法大多将事实性评估视为二元分类问题，可解释性有限且无法捕捉细粒度错误类型，而LLM经常产生幻觉，需要更精细的评估方法。

Method: 1) 提出受控数据合成管道，生成包含明确证据、细粒度错误类型标签、理由和修正的高质量数据；2) 构建大规模训练数据和手动验证的基准InFi-Check-FG；3) 基于高质量数据开发InFi-Checker模型，能联合提供证据、分类错误类型、生成理由和修正。

Result: InFi-Checker在InFi-Check-FG基准上达到最先进性能，在各种下游任务中表现出强大的泛化能力，显著提高了事实性评估的实用性和可信度。

Conclusion: InFi-Check框架通过细粒度、可解释的事实检查，有效解决了LLM幻觉评估的局限性，为提升事实检查的实用性和可信度提供了系统解决方案。

Abstract: Large language models (LLMs) often hallucinate, yet most existing fact-checking methods treat factuality evaluation as a binary classification problem, offering limited interpretability and failing to capture fine-grained error types. In this paper, we introduce InFi-Check, a framework for interpretable and fine-grained fact-checking of LLM outputs. Specifically, we first propose a controlled data synthesis pipeline that generates high-quality data featuring explicit evidence, fine-grained error type labels, justifications, and corrections. Based on this, we further construct large-scale training data and a manually verified benchmark InFi-Check-FG for fine-grained fact-checking of LLM outputs. Building on these high-quality training data, we further propose InFi-Checker, which can jointly provide supporting evidence, classify fine-grained error types, and produce justifications along with corrections. Experiments show that InFi-Checker achieves state-of-the-art performance on InFi-Check-FG and strong generalization across various downstream tasks, significantly improving the utility and trustworthiness of factuality evaluation.

</details>


### [51] [Will it Merge? On The Causes of Model Mergeability](https://arxiv.org/abs/2601.06672)
*Adir Rahamim,Asaf Yehudai,Boaz Carmeli,Leshem Choshen,Yosi Mass,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 该研究探讨了模型合并的成功因素，提出了可测量的"可合并性"定义，发现基础模型知识是决定合并效果的关键因素，并基于此提出了一种加权合并方法。


<details>
  <summary>Details</summary>
Motivation: 模型合并作为一种无需重新训练即可将多个微调模型组合成单一多任务模型的技术，但其成功或失败的决定因素尚不清楚。研究者希望探究为什么某些模型比其他模型更容易合并。

Method: 提出了一个具体、可测量的"可合并性"定义，并研究了导致高或低可合并性的几个潜在原因。基于可合并性定义，探索了一种简单的加权合并技术，以更好地保留基础模型中的薄弱知识。

Result: 研究发现基础模型知识是主导因素：在基础模型掌握较好的实例上微调的模型比在基础模型难以处理的实例上微调的模型更具可合并性。加权合并技术能够更好地保留基础模型中的薄弱知识。

Conclusion: 基础模型的知识水平是决定模型合并成功与否的关键因素，基于可合并性定义的加权合并方法能够改善合并效果，为模型合并技术提供了理论指导和实用方法。

Abstract: Model merging has emerged as a promising technique for combining multiple fine-tuned models into a single multitask model without retraining. However, the factors that determine whether merging will succeed or fail remain poorly understood. In this work, we investigate why specific models are merged better than others. To do so, we propose a concrete, measurable definition of mergeability. We investigate several potential causes for high or low mergeability, highlighting the base model knowledge as a dominant factor: Models fine-tuned on instances that the base model knows better are more mergeable than models fine-tuned on instances that the base model struggles with. Based on our mergeability definition, we explore a simple weighted merging technique that better preserves weak knowledge in the base model.

</details>


### [52] [Evaluating Cross-Lingual Unlearning in Multilingual Language Models](https://arxiv.org/abs/2601.06675)
*Tyler Lizzo,Larry Heck*

Main category: cs.CL

TL;DR: 该研究首次全面评估多语言大模型中的跨语言遗忘效果，发现大多数遗忘算法无法有效移除训练语言之外的事实知识，但子空间投影方法表现最佳，能实现强跨语言遗忘且性能下降最小。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大模型中的遗忘研究主要集中在单一语言，缺乏对跨语言遗忘效果的全面评估。研究者希望了解不同遗忘算法在多语言环境下的表现，以及多语言知识在模型权重空间中的几何结构。

Method: 使用翻译后的TOFU基准测试在七种语言/文字变体中进行评估，测试了主要的遗忘算法，特别关注子空间投影方法。通过分析学习到的任务子空间结构，探索多语言知识在权重空间中的几何特性。

Result: 大多数遗忘算法无法有效移除训练语言之外的事实知识，即使模型效用仍然很高。子空间投影方法在跨语言遗忘方面表现最佳，能实现强遗忘效果且性能下降最小。分析发现存在共享的"中间语言"结构，移除该共享子空间会影响所有语言，而移除语言特定组件则只影响特定语言。

Conclusion: 多语言遗忘效果取决于权重空间中的几何结构，这为未来基于子空间的遗忘系统提供了理论依据。子空间投影方法在多语言遗忘任务中表现出色，揭示了多语言知识在模型中的结构化表示方式。

Abstract: We present the first comprehensive evaluation of cross-lingual unlearning in multilingual LLMs. Using translated TOFU benchmarks in seven language/script variants, we test major unlearning algorithms and show that most fail to remove facts outside the training language, even when utility remains high. However, subspace-projection consistently outperforms the other methods, achieving strong cross-lingual forgetting with minimal degradation. Analysis of learned task subspaces reveals a shared interlingua structure: removing this shared subspace harms all languages, while removing language-specific components selectively affects one. These results demonstrate that multilingual forgetting depends on geometry in weight space, motivating subspace-based approaches for future unlearning systems.

</details>


### [53] [IDRBench: Interactive Deep Research Benchmark](https://arxiv.org/abs/2601.06676)
*Yingchaojie Feng,Qiang Huang,Xiaoya Xie,Zhaorui Yang,Jun Yu,Wei Chen,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: IDRBench是首个系统评估交互式深度研究的基准，包含模块化多智能体研究框架、按需交互、可扩展的参考基础用户模拟器，以及同时衡量交互收益（质量和对齐）与成本（轮次和令牌）的交互感知评估套件。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究系统大多以自主方式运行，假设用户意图完全明确且仅评估最终输出。然而实际研究中，研究目标往往不明确且在探索过程中不断演变，持续的交互对于稳健对齐至关重要。现有基准既未建模动态用户反馈，也未量化其成本，导致交互的重要性被忽视。

Method: 提出IDRBench基准，包含：1）模块化多智能体研究框架；2）按需交互机制；3）可扩展的参考基础用户模拟器；4）交互感知评估套件，同时衡量交互收益（研究质量和目标对齐）与成本（交互轮次和令牌消耗）。在7个最先进的LLM上进行实验验证。

Result: 实验表明交互能持续提高研究质量和鲁棒性，其效果往往超过模型能力差异。同时揭示了交互效率方面的显著权衡：虽然交互带来质量提升，但也增加了交互轮次和计算成本。

Conclusion: 交互对于深度研究系统至关重要，IDRBench为系统评估交互式研究提供了首个标准化框架，揭示了交互在提高研究质量和鲁棒性方面的价值，同时强调了需要优化交互效率以平衡收益与成本。

Abstract: Deep research agents powered by Large Language Models (LLMs) can perform multi-step reasoning, web exploration, and long-form report generation. However, most existing systems operate in an autonomous manner, assuming fully specified user intent and evaluating only final outputs. In practice, research goals are often underspecified and evolve during exploration, making sustained interaction essential for robust alignment. Despite its importance, interaction remains largely invisible to existing deep research benchmarks, which neither model dynamic user feedback nor quantify its costs. We introduce IDRBench, the first benchmark for systematically evaluating interactive deep research. IDRBench combines a modular multi-agent research framework with on-demand interaction, a scalable reference-grounded user simulator, and an interaction-aware evaluation suite that jointly measures interaction benefits (quality and alignment) and costs (turns and tokens). Experiments across seven state-of-the-art LLMs show that interaction consistently improves research quality and robustness, often outweighing differences in model capacity, while revealing substantial trade-offs in interaction efficiency.

</details>


### [54] [Characterising Toxicity in Generative Large Language Models](https://arxiv.org/abs/2601.06700)
*Zhiyao Zhang,Yazan Mash'Al,Yuhan Wu*

Main category: cs.CL

TL;DR: 该论文研究大型语言模型在特定提示下生成有害内容的程度，以及影响这种毒性输出的词汇和句法因素。


<details>
  <summary>Details</summary>
Motivation: 尽管注意力机制和Transformer架构显著推动了NLP发展，但语言模型仍容易生成不当、冒犯或有害的"毒性"输出。虽然已有RLHF等方法使模型与人类价值观对齐，但这些防护措施常能被精心设计的提示绕过，因此需要研究模型在提示下生成毒性内容的程度及其影响因素。

Method: 论文通过分析语言模型在特定提示下生成的内容，研究毒性输出的产生程度，并考察影响毒性输出的词汇和句法因素（包括词汇选择和句法结构）。

Result: 论文发现语言模型在特定提示下确实会生成毒性内容，且这种生成受到词汇和句法因素的显著影响。某些词汇选择和句法结构更容易触发模型的毒性输出。

Conclusion: 需要更深入理解语言模型生成毒性内容的机制，并开发更有效的防护措施来防止模型生成有害输出，特别是在面对精心设计的提示攻击时。

Abstract: In recent years, the advent of the attention mechanism has significantly advanced the field of natural language processing (NLP), revolutionizing text processing and text generation. This has come about through transformer-based decoder-only architectures, which have become ubiquitous in NLP due to their impressive text processing and generation capabilities. Despite these breakthroughs, language models (LMs) remain susceptible to generating undesired outputs: inappropriate, offensive, or otherwise harmful responses. We will collectively refer to these as ``toxic'' outputs. Although methods like reinforcement learning from human feedback (RLHF) have been developed to align model outputs with human values, these safeguards can often be circumvented through carefully crafted prompts. Therefore, this paper examines the extent to which LLMs generate toxic content when prompted, as well as the linguistic factors -- both lexical and syntactic -- that influence the production of such outputs in generative models.

</details>


### [55] [GRASP LoRA: GRPO Guided Adapter Sparsity Policy for Cross Lingual Transfer](https://arxiv.org/abs/2601.06702)
*Besher Hassan,Xiuying Chen*

Main category: cs.CL

TL;DR: GRASP LoRA：一种通过强化学习控制器在线学习全局剪枝比例的方法，替代网格搜索，提高多语言适配效率


<details>
  <summary>Details</summary>
Motivation: 传统适配器管道通过网格搜索选择全局剪枝比例，这种方法计算成本高、需要大量开发集、重复训练、固定稀疏度且可能错过最优解

Method: 提出GRASP LoRA（GRPO引导的适配器稀疏策略），将全局稀疏度作为可学习的控制变量。使用GRPO控制器与训练交错进行，定期在小微开发集上探测候选剪枝比例，从奖励信号中在线更新单个全局剪枝比例。在冻结骨干网络上操作合并的源和目标LoRA适配器，用一次控制器运行替代网格搜索，然后进行单次最终合并和固定剪枝比例的剪枝微调

Result: 在从英语到阿拉伯语和中文的跨语言迁移任务中（包括XL-Sum摘要和MLQA抽取式问答，使用Llama 3 8B），GRASP LoRA在语义忠实度、内容覆盖率和答案质量方面优于强基线。相对于网格搜索，端到端运行时间减少数倍，降低了对大型开发集的依赖

Conclusion: GRASP LoRA使适配器重用对于低资源部署变得实用，提供了一种更高效、更智能的剪枝比例选择方法，显著减少了计算成本和开发集需求

Abstract: Parameter efficient fine tuning is a way to adapt LLMs to new languages when compute or data are limited, yet adapter pipelines usually choose a global prune ratio by grid search. This practice is computationally expensive and development set intensive, since it repeats training, freezes sparsity, and misses fractional optima. We introduce GRASP LoRA (GRPO Guided Adapter Sparsity Policy), which treats global sparsity as a learnable control variable. A GRPO controller interleaves with training, periodically probing candidate prune ratios on a small micro development set and updating a single global prune ratio online from its reward signal. It operates on merged source and target LoRA adapters on a frozen backbone and replaces grid search with one controller run that learns a prune ratio, followed by a single final merge and prune fine tuning run with pruning fixed to that ratio. On cross lingual transfer from English into Arabic and Chinese, including XL-Sum summarization and MLQA extractive question answering with Llama 3 8B, GRASP LoRA improves semantic faithfulness, content coverage, and answer quality over strong target only and merge and prune baselines. It reduces end to end runtime by multiple times relative to grid search, lowers reliance on large development sets, and makes adapter reuse practical for low resource deployment.

</details>


### [56] [Evaluating Accounting Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2601.06707)
*Jie Zhou,Xin Chen,Jie Zhang,Hai Li,Jie Wang,Zhe Li*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型在会计领域的垂直应用，提出了会计推理评估标准，并测试了多个模型（GLM系列和GPT-4）的表现，发现GPT-4表现最佳但仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在各领域的应用，如何将其有效整合到会计等专业领域成为企业数字化转型的关键挑战。需要建立系统化的评估框架来研究会计推理能力。

Method: 定义了垂直领域会计推理概念，基于GLM模型训练数据特征分析提出了评估标准。使用该框架评估了GLM-6B、GLM-130B、GLM-4和OpenAI GPT-4在会计推理任务上的表现，特别关注提示设计对性能的影响。

Result: 提示设计对性能有显著影响，GPT-4在所有测试模型中表现出最强的会计推理能力。尽管有这些进步，当前模型仍不足以满足实际企业会计需求。

Conclusion: 大型语言模型在会计领域有应用潜力，但现有模型仍需进一步优化才能发挥其实际价值。需要持续改进以满足企业会计的专业要求。

Abstract: Large language models are transforming learning, cognition, and research across many fields. Effectively integrating them into professional domains, such as accounting, is a key challenge for enterprise digital transformation. To address this, we define vertical domain accounting reasoning and propose evaluation criteria derived from an analysis of the training data characteristics of representative GLM models. These criteria support systematic study of accounting reasoning and provide benchmarks for performance improvement. Using this framework, we evaluate GLM-6B, GLM-130B, GLM-4, and OpenAI GPT-4 on accounting reasoning tasks. Results show that prompt design significantly affects performance, with GPT-4 demonstrating the strongest capability. Despite these gains, current models remain insufficient for real-world enterprise accounting, indicating the need for further optimization to unlock their full practical value.

</details>


### [57] [Towards Computational Chinese Paleography](https://arxiv.org/abs/2601.06753)
*Yiran Rex Ma*

Main category: cs.CL

TL;DR: 该立场论文分析了中国古文字学如何经历人工智能驱动的计算转向，从自动化视觉任务发展到创建集成数字生态系统，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 中国古文字学正在经历人工智能驱动的计算转向，但当前研究仍存在数据稀缺、AI能力与人文研究整体性脱节等问题，需要推动该领域从孤立任务自动化向集成数字生态系统发展。

Method: 论文首先梳理数字资源格局（甲骨文、金文、竹简数据集），然后分析该领域的方法论流程：从基础视觉处理（图像修复、字符识别）到上下文分析（文物拼接、断代），再到自动破译和人机协作的高级推理。同时考察从经典计算机视觉到现代深度学习范式（包括transformer和大规模多模态模型）的技术转变。

Result: 论文识别出该领域的核心挑战：数据稀缺性以及当前AI能力与人文研究整体性之间的脱节。提出了未来研究议程应聚焦于创建多模态、少样本、以人为中心的系统来增强学术专业知识。

Conclusion: 中国古文字学的计算转向正在从自动化孤立视觉任务向创建集成数字生态系统发展。未来需要开发多模态、少样本、以人为中心的AI系统，以更好地支持学术研究，弥合技术能力与人文研究需求之间的差距。

Abstract: Chinese paleography, the study of ancient Chinese writing, is undergoing a computational turn powered by artificial intelligence. This position paper charts the trajectory of this emerging field, arguing that it is evolving from automating isolated visual tasks to creating integrated digital ecosystems for scholarly research. We first map the landscape of digital resources, analyzing critical datasets for oracle bone, bronze, and bamboo slip scripts. The core of our analysis follows the field's methodological pipeline: from foundational visual processing (image restoration, character recognition), through contextual analysis (artifact rejoining, dating), to the advanced reasoning required for automated decipherment and human-AI collaboration. We examine the technological shift from classical computer vision to modern deep learning paradigms, including transformers and large multimodal models. Finally, we synthesize the field's core challenges -- notably data scarcity and a disconnect between current AI capabilities and the holistic nature of humanistic inquiry -- and advocate for a future research agenda focused on creating multimodal, few-shot, and human-centric systems to augment scholarly expertise.

</details>


### [58] [MTMCS-Bench: Evaluating Contextual Safety of Multimodal Large Language Models in Multi-Turn Dialogues](https://arxiv.org/abs/2601.06757)
*Zheyuan Liu,Dongwhi Kim,Yixin Wan,Xiangchi Yuan,Zhaoxuan Tan,Fengran Mo,Meng Jiang*

Main category: cs.CL

TL;DR: MTMCS-Bench是一个多轮多模态上下文安全基准，用于评估MLLMs在逐步风险升级和上下文切换风险下的安全性，包含3万多个样本，发现现有模型在上下文安全性和实用性之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 现有上下文安全基准大多是单轮对话，无法捕捉恶意意图如何逐步形成或同一场景如何支持良性/恶意目标，需要评估多轮对话中视觉场景和对话演变共同影响下的风险。

Method: 引入MTMCS-Bench基准，包含真实图像和多轮对话，评估两种互补设置：基于升级的风险和上下文切换风险。提供配对的安全/不安全对话结构化评估，包含3万+多模态和单模态样本。

Result: 评估8个开源和7个专有MLLMs，发现上下文安全性和实用性之间存在持续权衡，模型要么错过逐步风险，要么过度拒绝良性对话。评估5个现有防护措施，发现能缓解部分失败但无法完全解决多轮上下文风险。

Conclusion: 多轮多模态上下文安全评估至关重要，现有模型和防护措施在应对逐步风险和上下文切换风险方面仍有不足，需要更全面的安全评估框架。

Abstract: Multimodal large language models (MLLMs) are increasingly deployed as assistants that interact through text and images, making it crucial to evaluate contextual safety when risk depends on both the visual scene and the evolving dialogue. Existing contextual safety benchmarks are mostly single-turn and often miss how malicious intent can emerge gradually or how the same scene can support both benign and exploitative goals. We introduce the Multi-Turn Multimodal Contextual Safety Benchmark (MTMCS-Bench), a benchmark of realistic images and multi-turn conversations that evaluates contextual safety in MLLMs under two complementary settings, escalation-based risk and context-switch risk. MTMCS-Bench offers paired safe and unsafe dialogues with structured evaluation. It contains over 30 thousand multimodal (image+text) and unimodal (text-only) samples, with metrics that separately measure contextual intent recognition, safety-awareness on unsafe cases, and helpfulness on benign ones. Across eight open-source and seven proprietary MLLMs, we observe persistent trade-offs between contextual safety and utility, with models tending to either miss gradual risks or over-refuse benign dialogues. Finally, we evaluate five current guardrails and find that they mitigate some failures but do not fully resolve multi-turn contextual risks.

</details>


### [59] [GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO](https://arxiv.org/abs/2601.06767)
*Shubhashis Roy Dipta,Khairul Mahbub,Nadia Najjar*

Main category: cs.CL

TL;DR: 论文提出了GanitLLM——一个孟加拉语数学推理模型，包含新的难度感知孟加拉语数学语料库和基于课程学习的GRPO训练流程，显著提升了孟加拉语数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语是世界上使用最广泛的语言之一，但现有LLM要么用英语推理再翻译，要么在多步孟加拉语数学问题上失败。强化学习方法在高资源语言上有效，但在低资源环境下因奖励稀疏而失效。

Method: 1) 构建Ganit数据集：经过严格过滤和去污染的孟加拉语数学数据集，带有基于强评估模型pass@k的自动难度标签；2) 提出Curriculum-GRPO：结合多阶段训练（SFT + GRPO）与难度感知采样，使用格式、数值正确性和孟加拉语推理的可验证奖励。

Result: 在Bn-MGSM和Bn-MSVAMP基准测试中，GanitLLM-4B相比其Qwen3-4B基础模型分别提升了+8和+7个准确率点，孟加拉语推理token比例从14%增加到88%以上，平均解决方案长度从943词减少到193词。

Conclusion: 通过构建高质量的难度感知数据集和课程式强化学习流程，成功开发了在孟加拉语数学推理上表现优异的GanitLLM模型，为低资源语言数学推理提供了有效解决方案。

Abstract: We present a Bengali mathematical reasoning model called GanitLLM (named after the Bangla word for mathematics, "Ganit"), together with a new difficulty-aware Bengali math corpus and a curriculum-based GRPO pipeline. Bengali is one of the world's most widely spoken languages, yet existing LLMs either reason in English and then translate, or simply fail on multi-step Bengali math, in part because reinforcement learning recipes are tuned for high-resource languages and collapse under reward sparsity in low-resource settings. To address this, we construct Ganit, a rigorously filtered and decontaminated Bengali math dataset with automatic difficulty tags derived from the pass@k of a strong evaluator model. Building on this dataset, we propose Curriculum-GRPO, which combines multi-stage training (SFT + GRPO) with difficulty-aware sampling and verifiable rewards for format, numerical correctness, and Bengali reasoning. On Bn-MGSM and Bn-MSVAMP, GanitLLM-4B improves over its Qwen3-4B base by +8 and +7 accuracy points, respectively, while increasing the percentage of Bengali reasoning tokens from 14% to over 88% and reducing average solution length from 943 to 193 words.

</details>


### [60] [Multi-Stage Evolutionary Model Merging with Meta Data Driven Curriculum Learning for Sentiment-Specialized Large Language Modeling](https://arxiv.org/abs/2601.06780)
*Keito Inoshita,Xiaokang Zhou,Akira Kawai*

Main category: cs.CL

TL;DR: 提出MEM-MCL混合学习模型，通过进化模型合并与元数据驱动的课程学习增强大语言模型在情感分析任务中的性能


<details>
  <summary>Details</summary>
Motivation: 传统情感分析方法专注于单一任务，不适用于需要处理多任务的现实应用；大语言模型在情感分析任务中灵活性高但准确率不足；现有技术如微调和进化模型合并可整合模型但缺乏任务元数据和课程学习的优化

Method: 提出MEM-MCL模型：1) 通过指令调优创建特定情感任务的专家模型；2) 使用进化算法合并专家模型形成统一模型；3) 利用弱数据优化合并过程；4) 引入基于任务难度的课程学习来优化学习序列

Result: 实验结果表明，MEM-MCL模型在大多数情感分析任务中优于传统大语言模型，在各种子任务上取得优越结果

Conclusion: MEM-MCL通过进化模型合并与元数据驱动的课程学习，有效提升了大语言模型在情感分析任务中的性能，实现了多任务处理的高准确率和可扩展性

Abstract: The emergence of large language models (LLMs) has significantly transformed natural language processing (NLP), enabling more generalized models to perform various tasks with minimal training. However, traditional sentiment analysis methods, which focus on individual tasks such as sentiment classification or aspect-based analysis, are not practical for real-world applications that usually require handling multiple tasks. While offering flexibility, LLMs in sentiment-specific tasks often fall short of the required accuracy. Techniques like fine-tuning and evolutionary model merging help integrate models into a unified framework, which can improve the learning performance while reducing computational costs. The use of task meta-data and curriculum learning to optimize learning processes remains underexplored, while sentiment analysis is a critical task in NLP that requires high accuracy and scalability across multiple subtasks. In this study, we propose a hybrid learning model called Multi-stage Evolutionary Model Merging with Meta data driven Curriculum Learning (MEM-MCL), to enhance the sentiment analysis in large language modeling. In particular, expert models are created through instruction tuning for specific sentiment tasks and then merged using evolutionary algorithms to form a unified model. The merging process is optimized with weak data to enhance performance across tasks. The curriculum learning is incorporated to provide a learning sequence based on task difficulty, improving knowledge extraction from LLMs. Experiment results demonstrate that the proposed MEM-MCL model outperforms conventional LLMs in a majority of sentiment analysis tasks, achieving superior results across various subtasks.

</details>


### [61] [EpiCaR: Knowing What You Don't Know Matters for Better Reasoning in LLMs](https://arxiv.org/abs/2601.06786)
*Jewon Yeom,Jaewon Sok,Seonghyeon Park,Jeongjae Park,Taesup Kim*

Main category: cs.CL

TL;DR: 提出EpiCaR方法，通过联合优化推理性能和校准，解决LLM在自训练中过度自信、失去不确定性表示能力的问题，实现准确性和校准的帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理训练方法主要强化成功推理路径，导致模型过度自信、失去不确定性表示能力，出现校准成本高的问题，这被描述为对齐中的模型崩溃。

Method: 提出认知校准推理(EpiCaR)训练目标，将推理训练重新定义为认知学习问题，联合优化推理性能和校准，在迭代监督微调框架中使用显式自评估信号。

Result: 在Llama-3和Qwen-3系列模型上，EpiCaR在准确性和校准方面均优于标准基线，特别是在3B+参数模型中；在OOD数学推理(GSM8K)和代码生成(MBPP)任务上有效泛化；在推理计算上实现3倍减少。

Conclusion: EpiCaR框架通过联合优化推理性能和校准，解决了LLM自训练中的校准退化问题，实现了准确性和校准的帕累托改进，显著减少了推理计算成本。

Abstract: Improving the reasoning abilities of large language models (LLMs) has largely relied on iterative self-training with model-generated data. While effective at boosting accuracy, existing approaches primarily reinforce successful reasoning paths, incurring a substantial calibration cost: models become overconfident and lose the ability to represent uncertainty. This failure has been characterized as a form of model collapse in alignment, where predictive distributions degenerate toward low-variance point estimates. We address this issue by reframing reasoning training as an epistemic learning problem, in which models must learn not only how to reason, but also when their reasoning should be trusted. We propose epistemically-calibrated reasoning (EpiCaR) as a training objective that jointly optimizes reasoning performance and calibration, and instantiate it within an iterative supervised fine-tuning framework using explicit self-evaluation signals. Experiments on Llama-3 and Qwen-3 families demonstrate that our approach achieves Pareto-superiority over standard baselines in both accuracy and calibration, particularly in models with sufficient reasoning capacity (e.g., 3B+). This framework generalizes effectively to OOD mathematical reasoning (GSM8K) and code generation (MBPP). Ultimately, our approach enables a 3X reduction in inference compute, matching the K=30 performance of STaR with only K=10 samples in capable models.

</details>


### [62] [Garbage Attention in Large Language Models: BOS Sink Heads and Sink-aware Pruning](https://arxiv.org/abs/2601.06787)
*Jaewon Sok,Jewon Yeom,Seonghyeon Park,Jeongjae Park,Taesup Kim*

Main category: cs.CL

TL;DR: 论文发现注意力机制中的BOS sink现象是导致大语言模型高层冗余的关键机制，并提出基于此的剪枝策略


<details>
  <summary>Details</summary>
Motivation: 虽然已知大语言模型存在显著冗余，但为何高层组件更冗余的系统性解释仍不清楚。本文旨在揭示驱动这种层间敏感性的关键机制

Method: 识别BOS sink现象作为关键机制，提出基于高BOS sink分数的注意力头剪枝策略，在Gemma-3、Llama-3.1和Qwen3上进行实验验证

Result: 实验表明该方法比基于权重或激活的准则更可靠地识别冗余组件，在激进剪枝下仍能保持接近密集基线的性能，且sink头行为在不同序列长度下保持稳定

Conclusion: 注意力结构特性为模型压缩提供了比基于幅度的方法更直观和鲁棒的基础，BOS sink现象为结构冗余提供了具体的功能解释

Abstract: Large Language Models (LLMs) are known to contain significant redundancy, yet a systematic explanation for why certain components, particularly in higher layers, are more redundant has remained elusive. In this work, we identify the BOS sink phenomenon as a key mechanism driving this layer-wise sensitivity. We show that attention heads with high BOS sink scores are strongly associated with functional redundancy: such heads, especially in deeper layers, contribute little to predictive performance and effectively serve as \emph{dumping grounds} for superfluous attention weights. This provides a concrete functional explanation for the structural redundancy reported in prior studies. Leveraging this insight, we introduce a simple pruning strategy that removes high-BOS sink heads. Experiments on Gemma-3, Llama-3.1, and Qwen3 demonstrate that this approach identifies redundant transformer components more reliably than weight- or activation-based criteria, while preserving performance close to dense baselines even under aggressive pruning. Moreover, we find that the behavior of sink heads remains stable across different sequence lengths. Overall, our results suggest that structural properties of attention offer a more intuitive and robust basis for model compression than magnitude-based methods.

</details>


### [63] [CIRAG: Construction-Integration Retrieval and Adaptive Generation for Multi-hop Question Answering](https://arxiv.org/abs/2601.06799)
*Zili Wei,Xiaocui Yang,Yilin Wang,Zihan Wang,Weidong Bao,Shi Feng,Daling Wang,Yifei Zhang*

Main category: cs.CL

TL;DR: CIRAG模型通过迭代构建-集成模块避免贪婪单路径扩展，采用自适应多粒度生成模块平衡噪声控制与上下文充分性，并通过轨迹蒸馏实现高效长程推理，显著提升多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有iRAG方法存在两个主要问题：1）贪婪单路径扩展导致早期错误传播，无法捕捉不同推理分支的并行证据；2）粒度需求不匹配，单一证据表示难以平衡噪声控制与上下文充分性。

Method: 提出CIRAG模型，包含：1）迭代构建-集成模块，构建候选三元组并基于历史条件集成，提炼核心三元组并生成下一跳查询；2）自适应级联多粒度生成模块，根据问题需求逐步扩展上下文证据；3）轨迹蒸馏技术，将教师模型的集成策略蒸馏到轻量级学生模型中。

Result: 大量实验表明，CIRAG相比现有iRAG方法取得了优越的性能表现。

Conclusion: CIRAG通过避免贪婪单路径扩展、自适应多粒度证据生成和高效的轨迹蒸馏，有效解决了现有iRAG方法的局限性，在多跳问答任务中表现出色。

Abstract: Triple-based Iterative Retrieval-Augmented Generation (iRAG) mitigates document-level noise for multi-hop question answering. However, existing methods still face limitations: (i) greedy single-path expansion, which propagates early errors and fails to capture parallel evidence from different reasoning branches, and (ii) granularity-demand mismatch, where a single evidence representation struggles to balance noise control with contextual sufficiency. In this paper, we propose the Construction-Integration Retrieval and Adaptive Generation model, CIRAG. It introduces an Iterative Construction-Integration module that constructs candidate triples and history-conditionally integrates them to distill core triples and generate the next-hop query. This module mitigates the greedy trap by preserving multiple plausible evidence chains. Besides, we propose an Adaptive Cascaded Multi-Granularity Generation module that progressively expands contextual evidence based on the problem requirements, from triples to supporting sentences and full passages. Moreover, we introduce Trajectory Distillation, which distills the teacher model's integration policy into a lightweight student, enabling efficient and reliable long-horizon reasoning. Extensive experiments demonstrate that CIRAG achieves superior performance compared to existing iRAG methods.

</details>


### [64] [Doing More with Less: Data Augmentation for Sudanese Dialect Automatic Speech Recognition](https://arxiv.org/abs/2601.06802)
*Ayman Mansour*

Main category: cs.CL

TL;DR: 该研究针对低资源苏丹阿拉伯语方言，通过数据增强技术微调OpenAI Whisper模型，建立了首个苏丹方言ASR基准，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 尽管已有许多针对现代标准阿拉伯语和方言阿拉伯语的ASR系统，但对低资源阿拉伯语方言（如苏丹方言）的研究很少。需要开发针对特定方言的解决方案，特别是资源有限的方言。

Method: 研究采用两种数据增强策略：1) 使用未标注语音生成伪标签进行自训练；2) 使用Klaam TTS系统合成语音进行TTS增强。在低成本资源（Kaggle免费层和Lightning.ai试用版）上微调OpenAI Whisper模型。

Result: 最佳模型（Whisper-Medium结合自训练和TTS增强，28.4小时数据）在评估集上达到57.1% WER，在域外保留集上达到51.6% WER，显著优于零样本多语言Whisper（78.8% WER）和MSA专用阿拉伯语模型（73.8-123% WER）。

Conclusion: 战略性数据增强可以克服低资源方言的资源限制，为开发低资源阿拉伯语方言和其他边缘化语言变体的ASR系统提供了实用路线图。所有模型、评估基准和可复现训练管道均已公开。

Abstract: Although many Automatic Speech Recognition (ASR) systems have been developed for Modern Standard Arabic (MSA) and Dialectal Arabic (DA), few studies have focused on dialect-specific implementations, particularly for low-resource Arabic dialects such as Sudanese. This paper presents a comprehensive study of data augmentation techniques for fine-tuning OpenAI Whisper models and establishes the first benchmark for the Sudanese dialect. Two augmentation strategies are investigated: (1) self-training with pseudo-labels generated from unlabeled speech, and (2) TTS-based augmentation using synthetic speech from the Klaam TTS system. The best-performing model, Whisper-Medium fine-tuned with combined self-training and TTS augmentation (28.4 hours), achieves a Word Error Rate (WER) of 57.1% on the evaluation set and 51.6% on an out-of-domain holdout set substantially outperforming zero-shot multilingual Whisper (78.8% WER) and MSA-specialized Arabic models (73.8-123% WER). All experiments used low-cost resources (Kaggle free tier and Lightning.ai trial), demonstrating that strategic data augmentation can overcome resource limitations for low-resource dialects and provide a practical roadmap for developing ASR systems for low-resource Arabic dialects and other marginalized language varieties. The models, evaluation benchmarks, and reproducible training pipelines are publicly released to facilitate future research on low-resource Arabic ASR.

</details>


### [65] [Forest Before Trees: Latent Superposition for Efficient Visual Reasoning](https://arxiv.org/abs/2601.06803)
*Yubo Wang,Juntian Zhang,Yichen Wu,Yankai Lin,Nils Lukas,Yuhan Liu*

Main category: cs.CL

TL;DR: Laser提出了一种新的视觉推理范式，通过动态窗口对齐学习实现"先森林后树木"的认知层次，在保持可解释性的同时大幅减少推理token（>97%），在6个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型推理方法存在信息带宽瓶颈：链式思维（CoT）的文本推理会丢失连续的视觉细节，而最近的潜在推理方法又容易因刚性自回归目标导致过早的语义崩溃。

Method: 提出Laser范式，通过动态窗口对齐学习（DWAL）重新定义视觉推理。该方法不是强制点对点预测，而是将潜在状态与未来语义的动态有效性窗口对齐，实现"先森林后树木"的认知层次。通过自精炼叠加保持可解释性轨迹。

Result: 在6个基准测试中，Laser在潜在推理方法中达到最先进性能，平均比强基线Monet提升5.03%。推理token减少超过97%，同时在分布外领域表现出鲁棒泛化能力。

Conclusion: Laser通过动态窗口对齐学习解决了视觉推理中的信息带宽瓶颈和语义崩溃问题，在保持可解释性的同时实现了高效、准确的推理，为视觉语言模型的推理能力提供了新范式。

Abstract: While Chain-of-Thought empowers Large Vision-Language Models with multi-step reasoning, explicit textual rationales suffer from an information bandwidth bottleneck, where continuous visual details are discarded during discrete tokenization. Recent latent reasoning methods attempt to address this challenge, but often fall prey to premature semantic collapse due to rigid autoregressive objectives. In this paper, we propose Laser, a novel paradigm that reformulates visual deduction via Dynamic Windowed Alignment Learning (DWAL). Instead of forcing a point-wise prediction, Laser aligns the latent state with a dynamic validity window of future semantics. This mechanism enforces a "Forest-before-Trees" cognitive hierarchy, enabling the model to maintain a probabilistic superposition of global features before narrowing down to local details. Crucially, Laser maintains interpretability via decodable trajectories while stabilizing unconstrained learning via Self-Refined Superposition. Extensive experiments on 6 benchmarks demonstrate that Laser achieves state-of-the-art performance among latent reasoning methods, surpassing the strong baseline Monet by 5.03% on average. Notably, it achieves these gains with extreme efficiency, reducing inference tokens by more than 97%, while demonstrating robust generalization to out-of-distribution domains.

</details>


### [66] [AgentHallu: Benchmarking Automated Hallucination Attribution of LLM-based Agents](https://arxiv.org/abs/2601.06818)
*Xuannan Liu,Xiao Yang,Zekun Li,Peipei Li,Ran He*

Main category: cs.CL

TL;DR: 提出AgentHallu基准，用于自动化归因LLM智能体在多步推理中的幻觉，包含693个轨迹、5类幻觉分类和多级标注，评估显示现有模型在步骤定位上表现不佳（最佳仅41.1%）。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在多步推理中，中间步骤的幻觉会沿轨迹传播，降低整体可靠性。现有研究主要关注单轮响应的幻觉检测，缺乏对多步工作流中幻觉归因的研究。

Method: 提出自动化幻觉归因新任务，并构建AgentHallu基准：包含693个高质量轨迹（覆盖7个智能体框架和5个领域）、5大类14小类的幻觉分类法、以及人工标注的多级标签（二元标签、责任步骤、因果解释）。评估了13个领先模型。

Result: 任务极具挑战性，即使顶级模型（如GPT-5、Gemini-2.5-Pro）表现也不佳。最佳模型步骤定位准确率仅41.1%，其中工具使用类幻觉最困难（仅11.6%）。

Conclusion: AgentHallu基准将推动未来开发更鲁棒、透明、可靠的智能体系统，自动化幻觉归因是提升多步推理可靠性的关键研究方向。

Abstract: As LLM-based agents operate over sequential multi-step reasoning, hallucinations arising at intermediate steps risk propagating along the trajectory, thus degrading overall reliability. Unlike hallucination detection in single-turn responses, diagnosing hallucinations in multi-step workflows requires identifying which step causes the initial divergence. To fill this gap, we propose a new research task, automated hallucination attribution of LLM-based agents, aiming to identify the step responsible for the hallucination and explain why. To support this task, we introduce AgentHallu, a comprehensive benchmark with: (1) 693 high-quality trajectories spanning 7 agent frameworks and 5 domains, (2) a hallucination taxonomy organized into 5 categories (Planning, Retrieval, Reasoning, Human-Interaction, and Tool-Use) and 14 sub-categories, and (3) multi-level annotations curated by humans, covering binary labels, hallucination-responsible steps, and causal explanations. We evaluate 13 leading models, and results show the task is challenging even for top-tier models (like GPT-5, Gemini-2.5-Pro). The best-performing model achieves only 41.1\% step localization accuracy, where tool-use hallucinations are the most challenging at just 11.6\%. We believe AgentHallu will catalyze future research into developing robust, transparent, and reliable agentic systems.

</details>


### [67] [PDR: A Plug-and-Play Positional Decay Framework for LLM Pre-training Data Detection](https://arxiv.org/abs/2601.06827)
*Jinhan Liu,Yibo Yang,Ruiying Lu,Piotr Piekos,Yimeng Chen,Peng Wang,Dandan Guo*

Main category: cs.CL

TL;DR: 提出PDR框架，通过位置衰减重加权增强黑盒零样本设置下LLM预训练数据检测能力，利用语言生成中记忆信号偏向高熵初始token的特性。


<details>
  <summary>Details</summary>
Motivation: 在黑盒零样本设置下检测LLM预训练数据对于审计数据隐私和版权合规至关重要，但现有方法通常使用均匀权重聚合token级分数，忽略了自回归生成的信息论动态特性。

Method: 提出位置衰减重加权(PDR)框架，基于记忆信号偏向高熵初始token且随上下文积累而衰减的语言学特性，显式地对token级分数进行重加权，放大早期位置的区分信号，抑制后期噪声。

Result: 大量实验表明PDR作为鲁棒先验，通常能增强多种先进方法在多个基准测试上的性能。

Conclusion: PDR是一种无需训练、即插即用的框架，通过利用语言生成中的信息论动态特性，有效提升了黑盒零样本设置下LLM预训练数据检测的性能。

Abstract: Detecting pre-training data in Large Language Models (LLMs) is crucial for auditing data privacy and copyright compliance, yet it remains challenging in black-box, zero-shot settings where computational resources and training data are scarce. While existing likelihood-based methods have shown promise, they typically aggregate token-level scores using uniform weights, thereby neglecting the inherent information-theoretic dynamics of autoregressive generation. In this paper, we hypothesize and empirically validate that memorization signals are heavily skewed towards the high-entropy initial tokens, where model uncertainty is highest, and decay as context accumulates. To leverage this linguistic property, we introduce Positional Decay Reweighting (PDR), a training-free and plug-and-play framework. PDR explicitly reweights token-level scores to amplify distinct signals from early positions while suppressing noise from later ones. Extensive experiments show that PDR acts as a robust prior and can usually enhance a wide range of advanced methods across multiple benchmarks.

</details>


### [68] [Explainable Multimodal Aspect-Based Sentiment Analysis with Dependency-guided Large Language Model](https://arxiv.org/abs/2601.06848)
*Zhongzheng Wang,Yuanhe Tian,Hongzhi Wang,Yan Song*

Main category: cs.CL

TL;DR: 本文提出了一种基于多模态大语言模型的生成式可解释MABSA框架，将多模态方面级情感分析重构为生成任务，同时预测情感并生成自然语言解释，通过依赖句法引导策略增强方面推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有MABSA方法主要依赖判别式分类和复杂的多模态融合，缺乏明确的情感可解释性。需要一种既能准确分类情感又能提供解释的统一框架。

Method: 1. 将MABSA重构为生成式可解释任务；2. 基于MLLMs采用提示生成范式联合产生情感和解释；3. 提出依赖句法引导的情感线索策略，修剪并文本化方面中心依赖句法树；4. 使用MLLMs构建带情感解释的新数据集进行微调。

Result: 实验表明该方法在情感分类准确率上获得一致提升，同时能产生忠实、基于方面的解释。

Conclusion: 该生成式可解释MABSA框架有效解决了现有方法缺乏可解释性的问题，通过依赖句法引导增强了方面推理能力，实现了准确情感分类和高质量解释生成的统一。

Abstract: Multimodal aspect-based sentiment analysis (MABSA) aims to identify aspect-level sentiments by jointly modeling textual and visual information, which is essential for fine-grained opinion understanding in social media. Existing approaches mainly rely on discriminative classification with complex multimodal fusion, yet lacking explicit sentiment explainability. In this paper, we reformulate MABSA as a generative and explainable task, proposing a unified framework that simultaneously predicts aspect-level sentiment and generates natural language explanations. Based on multimodal large language models (MLLMs), our approach employs a prompt-based generative paradigm, jointly producing sentiment and explanation. To further enhance aspect-oriented reasoning capabilities, we propose a dependency-syntax-guided sentiment cue strategy. This strategy prunes and textualizes the aspect-centered dependency syntax tree, guiding the model to distinguish different sentiment aspects and enhancing its explainability. To enable explainability, we use MLLMs to construct new datasets with sentiment explanations to fine-tune. Experiments show that our approach not only achieves consistent gains in sentiment classification accuracy, but also produces faithful, aspect-grounded explanations.

</details>


### [69] [†DAGGER: Distractor-Aware Graph Generation for Executable Reasoning in Math Problems](https://arxiv.org/abs/2601.06853)
*Zabir Al Nazi,Shubhashis Roy Dipta,Sudipta Kar*

Main category: cs.CL

TL;DR: 论文研究了数学问题解决中Chain-of-Thought提示在无关上下文下的表现，提出了DISTRACTMATH-BN孟加拉语基准和DAGGER方法，通过结构化中间表示提高鲁棒性和推理效率。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought提示在数学问题解决中广泛应用，包括低资源语言，但其在无关上下文下的行为尚未得到充分研究。需要系统性地研究这一挑战，特别是在嘈杂、低资源环境中。

Method: 1) 提出DISTRACTMATH-BN基准，在MGSM和MSVAMP基础上添加语义相关但计算无关的信息；2) 提出DAGGER方法，将数学问题解决重新表述为可执行计算图生成，明确建模干扰节点；3) 使用监督微调后接Group Relative Policy Optimization对Gemma-3模型进行微调。

Result: 评估7个3B到12B参数模型发现：标准模型在干扰下性能下降高达41分，推理专用模型下降14-20分且消耗5倍更多token。DAGGER方法在增强基准上达到可比加权准确率，同时比推理模型少用89% token，且无需在干扰增强示例上显式训练。

Conclusion: 与自由形式方法相比，强制结构化中间表示能提高数学推理的鲁棒性和推理效率，特别是在嘈杂、低资源环境中。结构化方法能有效处理无关上下文干扰。

Abstract: Chain-of-Thought (CoT) prompting is widely adopted for mathematical problem solving, including in low-resource languages, yet its behavior under irrelevant context remains underexplored. To systematically study this challenge, we introduce DISTRACTMATH-BN, a Bangla benchmark that augments MGSM and MSVAMP with semantically coherent but computationally irrelevant information. Evaluating seven models ranging from 3B to 12B parameters, we observe substantial performance degradation under distractors: standard models drop by up to 41 points, while reasoning-specialized models decline by 14 to 20 points despite consuming five times more tokens. We propose †DAGGER, which reformulates mathematical problem solving as executable computational graph generation with explicit modeling of distractor nodes. Fine-tuning Gemma-3 models using supervised fine-tuning followed by Group Relative Policy Optimization achieves comparable weighted accuracy on augmented benchmarks while using 89 percent fewer tokens than reasoning models. Importantly, this robustness emerges without explicit training on distractor-augmented examples. Our results suggest that enforcing structured intermediate representations improves robustness and inference efficiency in mathematical reasoning compared to free-form approaches, particularly in noisy, low-resource settings.

</details>


### [70] [BiasLab: A Multilingual, Dual-Framing Framework for Robust Measurement of Output-Level Bias in Large Language Models](https://arxiv.org/abs/2601.06861)
*William Guey,Wei Zhang,Pei-Luen Patrick Rau,Pierrick Bougault,Vitor D. de Moura,Bertan Ucar,Jose O. Gomes*

Main category: cs.CL

TL;DR: BiasLab是一个开源、模型无关的评估框架，用于通过多语言、鲁棒性导向的实验设计量化LLM输出层面的偏见。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地部署在高风险场景中，但评估LLM输出偏见存在方法学挑战：对提示措辞敏感、多语言覆盖有限、缺乏标准化指标来可靠比较不同模型。

Method: 采用严格的双框架方案构建镜像探针对：一个肯定断言支持目标A，另一个通过确定性目标替换支持目标B，同时保持相同的语言结构。使用随机指令包装进行重复评估，强制固定选择的Likert响应格式，通过LLM法官将响应归一化为同意标签，对齐跨框架的极性一致性，并聚合成带有效应大小和中性率等描述性统计的定量偏见指标。

Result: BiasLab提供了一个标准化方法，用于跨语言和框架敏感的偏见测量，支持人口统计、文化、政治和地缘政治等多种偏见轴，并生成可复现的结构化报告和比较可视化。

Conclusion: BiasLab贡献了标准化方法，补充了内在和基于数据集的审计，使研究人员和机构能够基准测试鲁棒性并做出更明智的部署决策。

Abstract: Large Language Models (LLMs) are increasingly deployed in high-stakes contexts where their outputs influence real-world decisions. However, evaluating bias in LLM outputs remains methodologically challenging due to sensitivity to prompt wording, limited multilingual coverage, and the lack of standardized metrics that enable reliable comparison across models. This paper introduces BiasLab, an open-source, model-agnostic evaluation framework for quantifying output-level (extrinsic) bias through a multilingual, robustness-oriented experimental design. BiasLab constructs mirrored probe pairs under a strict dual-framing scheme: an affirmative assertion favoring Target A and a reverse assertion obtained by deterministic target substitution favoring Target B, while preserving identical linguistic structure. To reduce dependence on prompt templates, BiasLab performs repeated evaluation under randomized instructional wrappers and enforces a fixed-choice Likert response format to maximize comparability across models and languages. Responses are normalized into agreement labels using an LLM-based judge, aligned for polarity consistency across framings, and aggregated into quantitative bias indicators with descriptive statistics including effect sizes and neutrality rates. The framework supports evaluation across diverse bias axes, including demographic, cultural, political, and geopolitical topics, and produces reproducible artifacts such as structured reports and comparative visualizations. BiasLab contributes a standardized methodology for cross-lingual and framing-sensitive bias measurement that complements intrinsic and dataset-based audits, enabling researchers and institutions to benchmark robustness and make better-informed deployment decisions.

</details>


### [71] [Paraphrasing Adversarial Attack on LLM-as-a-Reviewer](https://arxiv.org/abs/2601.06884)
*Masahiro Kaneko*

Main category: cs.CL

TL;DR: 提出PAA攻击方法，通过语义保持的改写提升论文评审分数，揭示LLM评审系统的脆弱性


<details>
  <summary>Details</summary>
Motivation: 现有攻击依赖提示注入，会改变稿件内容，混淆了注入易感性与评估鲁棒性。需要研究LLM在同行评审系统中的潜在漏洞

Method: 提出Paraphrasing Adversarial Attack (PAA)，一种黑盒优化方法，搜索能获得更高评审分数的改写序列，同时保持语义等价和语言自然性。利用上下文学习，使用先前改写及其分数指导候选生成

Result: 在5个ML/NLP会议、3个LLM评审模型和5个攻击模型上的实验表明，PAA能一致提高评审分数而不改变论文主张。人类评估确认生成的改写保持意义和自然性。发现受攻击论文在评审中表现出更高的困惑度，可作为检测信号；改写提交可部分缓解攻击

Conclusion: PAA揭示了LLM评审系统的脆弱性，需要开发更鲁棒的评估方法。困惑度可作为攻击检测指标，改写提交是部分防御策略

Abstract: The use of large language models (LLMs) in peer review systems has attracted growing attention, making it essential to examine their potential vulnerabilities. Prior attacks rely on prompt injection, which alters manuscript content and conflates injection susceptibility with evaluation robustness. We propose the Paraphrasing Adversarial Attack (PAA), a black-box optimization method that searches for paraphrased sequences yielding higher review scores while preserving semantic equivalence and linguistic naturalness. PAA leverages in-context learning, using previous paraphrases and their scores to guide candidate generation. Experiments across five ML and NLP conferences with three LLM reviewers and five attacking models show that PAA consistently increases review scores without changing the paper's claims. Human evaluation confirms that generated paraphrases maintain meaning and naturalness. We also find that attacked papers exhibit increased perplexity in reviews, offering a potential detection signal, and that paraphrasing submissions can partially mitigate attacks.

</details>


### [72] [Fine-grained Verbal Attack Detection via a Hierarchical Divide-and-Conquer Framework](https://arxiv.org/abs/2601.06907)
*Quan Zheng,Yuanhe Tian,Ming Wang,Yan Song*

Main category: cs.CL

TL;DR: 提出分层攻击评论检测数据集和基于时空信息的细粒度框架，通过任务分解提升中文社交媒体中隐含攻击的识别效果


<details>
  <summary>Details</summary>
Motivation: 现有研究对对话结构和上下文依赖建模不足，特别是在中文社交媒体中隐含攻击普遍存在，现有方法过度关注通用语义理解而忽视用户响应关系，难以识别隐含和上下文相关的攻击

Method: 提出分层攻击评论检测数据集，显式编码分层回复结构和时间顺序；设计分治细粒度框架，将攻击检测分解为分层子任务，使用专门的轻量模型处理显式检测、隐含意图推断和受限上下文下的目标识别

Result: 在提出的数据集和基准意图检测数据集上的广泛实验表明，使用该框架的较小模型显著优于依赖参数扩展的大型单体模型，证明了结构化任务分解的有效性

Conclusion: 通过分层数据集和分治框架，能够有效解决中文社交媒体中隐含攻击检测的挑战，结构化任务分解比单纯扩大模型参数更有效

Abstract: In the digital era, effective identification and analysis of verbal attacks are essential for maintaining online civility and ensuring social security. However, existing research is limited by insufficient modeling of conversational structure and contextual dependency, particularly in Chinese social media where implicit attacks are prevalent. Current attack detection studies often emphasize general semantic understanding while overlooking user response relationships, hindering the identification of implicit and context-dependent attacks. To address these challenges, we present the novel "Hierarchical Attack Comment Detection" dataset and propose a divide-and-conquer, fine-grained framework for verbal attack recognition based on spatiotemporal information. The proposed dataset explicitly encodes hierarchical reply structures and chronological order, capturing complex interaction patterns in multi-turn discussions. Building on this dataset, the framework decomposes attack detection into hierarchical subtasks, where specialized lightweight models handle explicit detection, implicit intent inference, and target identification under constrained context. Extensive experiments on the proposed dataset and benchmark intention detection datasets show that smaller models using our framework significantly outperform larger monolithic models relying on parameter scaling, demonstrating the effectiveness of structured task decomposition.

</details>


### [73] [Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models](https://arxiv.org/abs/2601.06911)
*Shaoning Sun,Mingzhu Cai,Huang He,Bingjin Chen,Siqi Bao,Yujiu Yang,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 研究发现语言模型在强化学习中的表现差异源于"分布清晰度"这一结构特性，即模型对正确与错误回答的概率分配具有类内紧凑性和类间分离性，可通过轮廓系数量化并用于改进训练。


<details>
  <summary>Details</summary>
Motivation: 不同语言模型家族在相同强化学习训练下表现差异显著（如Qwen大幅提升而Llama改善有限），需要探究这种差异背后的根本原因，超越单纯的数据中心方法。

Method: 采用三阶段分析：现象观察→机制探究→解释验证。提出用轮廓系数(S)量化分布清晰度，并设计轮廓感知重加权策略，在训练中优先处理低S样本。

Result: 实验表明：1)高S与RL性能强相关；2)低S与严重逻辑错误和推理不稳定相关；3)轮廓感知重加权在六个数学基准测试中均带来一致改进，AIME24上最高提升5.9分。

Conclusion: 分布清晰度是决定语言模型强化学习友好性的根本可训练特性，轮廓系数可作为评估和改进模型RL性能的有效指标。

Abstract: Language model families exhibit striking disparity in their capacity to benefit from reinforcement learning: under identical training, models like Qwen achieve substantial gains, while others like Llama yield limited improvements. Complementing data-centric approaches, we reveal that this disparity reflects a hidden structural property: \textbf{distributional clarity} in probability space. Through a three-stage analysis-from phenomenon to mechanism to interpretation-we uncover that RL-friendly models exhibit intra-class compactness and inter-class separation in their probability assignments to correct vs. incorrect responses. We quantify this clarity using the \textbf{Silhouette Coefficient} ($S$) and demonstrate that (1) high $S$ correlates strongly with RL performance; (2) low $S$ is associated with severe logic errors and reasoning instability. To confirm this property, we introduce a Silhouette-Aware Reweighting strategy that prioritizes low-$S$ samples during training. Experiments across six mathematical benchmarks show consistent improvements across all model families, with gains up to 5.9 points on AIME24. Our work establishes distributional clarity as a fundamental, trainable property underlying RL-Friendliness.

</details>


### [74] [TreePS-RAG: Tree-based Process Supervision for Reinforcement Learning in Agentic RAG](https://arxiv.org/abs/2601.06922)
*Tianhua Zhang,Kun Li,Junan Li,Yunxiang Li,Hongyin Luo,Xixin Wu,James Glass,Helen Meng*

Main category: cs.CL

TL;DR: TreePS-RAG：基于树的在线强化学习框架，用于智能体检索增强生成，通过蒙特卡洛估计实现步骤级信用分配，无需中间标注，在多个QA基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体RAG方法主要依赖稀疏的最终奖励，这限制了步骤级信用分配，对中间推理和动作的指导较弱。虽然最近有研究探索过程级监督，但通常依赖离线构建的训练数据（存在分布偏移风险）或需要昂贵的中间标注。

Method: 提出TreePS-RAG框架：1）将智能体RAG推理建模为展开树，每个推理步骤对应一个节点；2）通过蒙特卡洛估计后代结果来估计步骤效用，获得细粒度的过程优势；3）引入高效的在线树构建策略，在有限计算预算下保持探索多样性。

Result: 在7个多跳和通用QA基准测试中，TreePS-RAG在多个模型规模上一致且显著地优于结果监督和领先的过程监督RL方法，且展开成本与Search-R1等强基线相当。

Conclusion: TreePS-RAG通过树结构实现步骤级信用分配，仅需标准结果奖励即可获得过程级监督效果，提供了一种高效、实用的智能体RAG强化学习框架。

Abstract: Agentic retrieval-augmented generation (RAG) formulates question answering as a multi-step interaction between reasoning and information retrieval, and has recently been advanced by reinforcement learning (RL) with outcome-based supervision. While effective, relying solely on sparse final rewards limits step-wise credit assignment and provides weak guidance for intermediate reasoning and actions. Recent efforts explore process-level supervision, but typically depend on offline constructed training data, which risks distribution shift, or require costly intermediate annotations. We present TreePS-RAG, an online, tree-based RL framework for agentic RAG that enables step-wise credit assignment while retaining standard outcome-only rewards. Our key insight is to model agentic RAG reasoning as a rollout tree, where each reasoning step naturally maps to a node. This tree structure allows step utility to be estimated via Monte Carlo estimation over its descendant outcomes, yielding fine-grained process advantages without requiring intermediate labels. To make this paradigm practical, we introduce an efficient online tree construction strategy that preserves exploration diversity under a constrained computational budget. With a rollout cost comparable to strong baselines like Search-R1, experiments on seven multi-hop and general QA benchmarks across multiple model scales show that TreePS-RAG consistently and significantly outperforms both outcome-supervised and leading process-supervised RL methods.

</details>


### [75] [Symphonym: Universal Phonetic Embeddings for Cross-Script Toponym Matching via Teacher-Student Distillation](https://arxiv.org/abs/2601.06932)
*Stephen Gadd*

Main category: cs.CL

TL;DR: Symphonym是一个神经嵌入系统，将20种书写系统的地名映射到统一的128维语音空间，通过教师-学生网络架构实现跨文字系统的地名匹配。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖语言特定的语音算法或音译规则，在跨越文字系统边界时失效，无法识别不同文字系统（如西里尔文、阿拉伯文）中表示同一地名的字符串。

Method: 采用教师-学生网络架构：教师网络基于发音语音特征（通过Epitran和PanPhon）生成目标嵌入，学生网络学习从原始字符近似这些嵌入。推理时仅需轻量级学生网络（170万参数）。训练采用三阶段课程：1）教师网络在46.7万语音基础三元组上训练；2）学生网络对齐教师输出（2300万样本）；3）在330万困难负样本三元组上微调。

Result: 在MEHDIE希伯来-阿拉伯基准测试中达到89.2%的Recall@1，优于Levenshtein（81.5%）和Jaro-Winkler（78.5%）。学生网络与教师网络输出达到96.6%的余弦相似度。

Conclusion: Symphonym实现了跨文字系统的地名匹配，将支持世界历史地名录中6700万个地名的模糊语音协调和搜索。代码和模型已公开。

Abstract: Linking place names across languages and writing systems is a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches rely on language-specific phonetic algorithms or transliteration rules that fail when names cross script boundaries -- no string metric can determine that "Moscow" when rendered in Cyrillic or Arabic refer to the same city.
  I present Symphonym, a neural embedding system that maps toponyms from 20 writing systems into a unified 128-dimensional phonetic space. A Teacher network trained on articulatory phonetic features (via Epitran and PanPhon) produces target embeddings, while a Student network learns to approximate these from raw characters. At inference, only the lightweight Student (1.7M parameters) is required, enabling deployment without runtime phonetic conversion.
  Training uses a three-phase curriculum on 57 million toponyms from GeoNames, Wikidata, and the Getty Thesaurus of Geographic Names. Phase 1 trains the Teacher on 467K phonetically-grounded triplets. Phase 2 aligns the Student to Teacher outputs across 23M samples, achieving 96.6% cosine similarity. Phase 3 fine-tunes on 3.3M hard negative triplets -- negatives sharing prefix and script with the anchor but referring to different places -- to sharpen discrimination.
  Evaluation on the MEHDIE Hebrew-Arabic benchmark achieves 89.2% Recall@1, outperforming Levenshtein (81.5%) and Jaro-Winkler (78.5%). The system is optimised for cross-script matching; same-script variants can be handled by complementary string methods. Symphonym will enable fuzzy phonetic reconciliation and search across the World Historical Gazetteer's 67 million toponyms. Code and models are publicly available.

</details>


### [76] [X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests](https://arxiv.org/abs/2601.06953)
*Jie Wu,Haoling Li,Xin Zhang,Jiani Guo,Jane Luo,Steven Liu,Yangyu Huang,Ruihang Chu,Scarlett Li,Yujiu Yang*

Main category: cs.CL

TL;DR: 本文提出完全合成数据训练Code LLMs的方法SynthSmith，通过特征合成生成多样化编程任务和验证方案，训练出的7B参数X-Coder模型在编程基准测试中超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 当前Code LLMs严重依赖真实世界数据，限制了可扩展性。竞争性编程对代码推理要求高，需要探索不依赖真实数据的训练方法。

Method: 提出SynthSmith数据合成管道，基于特征合成生成多样化编程任务、解决方案和测试用例。使用合成数据进行监督微调和强化学习训练，引入X-Coder模型系列。

Result: X-Coder模型在LiveCodeBench v5和v6上分别达到62.9 avg@8和55.8的通过率，超越DeepCoder-14B-Preview和AReal-boba2-14B等更大模型。分析显示合成数据集上存在缩放规律。

Conclusion: 高质量合成数据缩放和分阶段训练能显著提升代码推理能力，减少对真实编程数据的依赖。合成数据方法在代码LLMs训练中具有巨大潜力。

Abstract: Competitive programming presents great challenges for Code LLMs due to its intensive reasoning demands and high logical complexity. However, current Code LLMs still rely heavily on real-world data, which limits their scalability. In this paper, we explore a fully synthetic approach: training Code LLMs with entirely generated tasks, solutions, and test cases, to empower code reasoning models without relying on real-world data. To support this, we leverage feature-based synthesis to propose a novel data synthesis pipeline called SynthSmith. SynthSmith shows strong potential in producing diverse and challenging tasks, along with verified solutions and tests, supporting both supervised fine-tuning and reinforcement learning. Based on the proposed synthetic SFT and RL datasets, we introduce the X-Coder model series, which achieves a notable pass rate of 62.9 avg@8 on LiveCodeBench v5 and 55.8 on v6, outperforming DeepCoder-14B-Preview and AReal-boba2-14B despite having only 7B parameters. In-depth analysis reveals that scaling laws hold on our synthetic dataset, and we explore which dimensions are more effective to scale. We further provide insights into code-centric reinforcement learning and highlight the key factors that shape performance through detailed ablations and analysis. Our findings demonstrate that scaling high-quality synthetic data and adopting staged training can greatly advance code reasoning, while mitigating reliance on real-world coding data.

</details>


### [77] [RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction](https://arxiv.org/abs/2601.06966)
*Haonan Bian,Zhiyuan Yao,Sen Hu,Zishan Xu,Shaolei Zhang,Yifu Guo,Ziliang Yang,Xueran Han,Huacan Wang,Ronghao Chen*

Main category: cs.CL

TL;DR: RealMem是首个面向现实项目场景的基准测试，包含2000+跨会话对话，用于评估LLM在长期项目导向交互中的记忆能力，发现现有记忆系统在管理长期项目状态和动态上下文依赖方面面临挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM从静态对话接口发展为自主通用智能体，有效的记忆系统对于确保长期一致性至关重要。现有基准主要关注闲聊或任务导向对话，未能捕捉"长期项目导向"交互中智能体需要跟踪演化目标的需求。

Method: 提出RealMem基准，包含11个场景的2000+跨会话对话，使用自然用户查询进行评估。设计了一个综合流程，整合项目基础构建、多智能体对话生成、记忆与日程管理，以模拟记忆的动态演化。

Result: 实验表明，当前记忆系统在管理现实项目中固有的长期项目状态和动态上下文依赖方面面临显著挑战。

Conclusion: RealMem填补了长期项目导向交互评估的空白，为开发更有效的记忆系统提供了重要基准，代码和数据集已开源。

Abstract: As Large Language Models (LLMs) evolve from static dialogue interfaces to autonomous general agents, effective memory is paramount to ensuring long-term consistency. However, existing benchmarks primarily focus on casual conversation or task-oriented dialogue, failing to capture **"long-term project-oriented"** interactions where agents must track evolving goals.
  To bridge this gap, we introduce **RealMem**, the first benchmark grounded in realistic project scenarios. RealMem comprises over 2,000 cross-session dialogues across eleven scenarios, utilizing natural user queries for evaluation.
  We propose a synthesis pipeline that integrates Project Foundation Construction, Multi-Agent Dialogue Generation, and Memory and Schedule Management to simulate the dynamic evolution of memory. Experiments reveal that current memory systems face significant challenges in managing the long-term project states and dynamic context dependencies inherent in real-world projects.
  Our code and datasets are available at [https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench).

</details>


### [78] [Categorize Early, Integrate Late: Divergent Processing Strategies in Automatic Speech Recognition](https://arxiv.org/abs/2601.06972)
*Nathan Roll,Pranav Bhalerao,Martijn Bartelds,Arjun Pawar,Yuka Tatsumi,Tolulope Ogunremi,Chen Shani,Calbert Graham,Meghan Sumner,Dan Jurafsky*

Main category: cs.CL

TL;DR: 论文提出"架构指纹"框架分析Transformer和Conformer在语音语言建模中的处理策略差异，发现Conformer采用"早期分类"策略，而Transformer采用"晚期集成"策略。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer和Conformer在语音语言建模中表现相当，但尚不清楚这种相似性能是源于收敛的处理策略还是不同的架构归纳偏置。需要系统分析两种架构在表征学习中的本质差异。

Method: 提出"架构指纹"探测框架，隔离架构对表征的影响，应用于24个预训练编码器（39M-3.3B参数）的受控实验套件，分析不同深度层的信息编码模式。

Result: Conformer实现"早期分类"策略，音素分类比Transformer早29%深度完成，说话人性别早16%深度；Transformer采用"晚期集成"策略，将音素、口音和时长编码推迟到深层（49-57%深度）。

Conclusion: 两种架构具有不同的处理层次：Conformer的前置分类策略可能有利于低延迟流式处理，而Transformer的深度集成策略可能更适合需要丰富上下文和跨话语归一化的任务。这些指纹为架构选择提供了设计启发。

Abstract: In speech language modeling, two architectures dominate the frontier: the Transformer and the Conformer. However, it remains unknown whether their comparable performance stems from convergent processing strategies or distinct architectural inductive biases. We introduce Architectural Fingerprinting, a probing framework that isolates the effect of architecture on representation, and apply it to a controlled suite of 24 pre-trained encoders (39M-3.3B parameters). Our analysis reveals divergent hierarchies: Conformers implement a "Categorize Early" strategy, resolving phoneme categories 29% earlier in depth and speaker gender by 16% depth. In contrast, Transformers "Integrate Late," deferring phoneme, accent, and duration encoding to deep layers (49-57%). These fingerprints suggest design heuristics: Conformers' front-loaded categorization may benefit low-latency streaming, while Transformers' deep integration may favor tasks requiring rich context and cross-utterance normalization.

</details>


### [79] [LLMs Can't Play Hangman: On the Necessity of a Private Working Memory for Language Agents](https://arxiv.org/abs/2601.06973)
*Davide Baldelli,Ali Parviz,Amal Zouaq,Sarath Chandar*

Main category: cs.CL

TL;DR: 论文提出私有状态交互任务(PSITs)概念，证明标准聊天界面无法同时保持秘密性和一致性，提出带私有工作记忆的新架构解决此问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs从文本补全向自主代理发展，标准聊天界面缺乏私有工作记忆，限制了代理执行依赖隐藏状态的交互任务的能力。

Method: 1) 定义私有状态交互任务(PSITs)；2) 提出不可能性定理证明仅依赖公开对话历史的代理无法同时保持秘密性和一致性；3) 设计自一致性测试协议评估代理维护隐藏秘密的能力；4) 提出包含显式私有工作记忆的新架构。

Result: 理论证明：任何仅依赖公开对话历史的代理都无法在PSITs中同时保持秘密性和一致性。实证验证：标准聊天LLMs和基于检索的记忆基线都无法通过自一致性测试，无论规模大小。新架构：包含私有工作记忆的机制能够恢复一致性。

Conclusion: 私有状态是交互式语言代理的必要组件，语义检索无法实现真正的状态维护，需要显式的私有工作记忆架构。

Abstract: As LLMs move from text completion toward autonomous agents, they remain constrained by the standard chat interface, which lacks private working memory. This raises a fundamental question: can agents reliably perform interactive tasks that depend on hidden state? We define Private State Interactive Tasks (PSITs), which require agents to generate and maintain hidden information while producing consistent public responses. We show theoretically that any agent restricted to the public conversation history cannot simultaneously preserve secrecy and consistency in PSITs, yielding an impossibility theorem. To empirically validate this limitation, we introduce a self-consistency testing protocol that evaluates whether agents can maintain a hidden secret across forked dialogue branches. Standard chat-based LLMs and retrieval-based memory baselines fail this test regardless of scale, demonstrating that semantic retrieval does not enable true state maintenance. To address this, we propose a novel architecture incorporating an explicit private working memory; we demonstrate that this mechanism restores consistency, establishing private state as a necessary component for interactive language agents.

</details>


### [80] [UETQuintet at BioCreative IX - MedHopQA: Enhancing Biomedical QA with Selective Multi-hop Reasoning and Contextual Retrieval](https://arxiv.org/abs/2601.06974)
*Quoc-An Nguyen,Thi-Minh-Thu Vu,Bich-Dat Nguyen,Dinh-Quang-Minh Tran,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: 提出一个处理生物医学问答的模型，能有效处理直接问题和序列问题，在BioCreative IX - MedHopQA共享任务中取得0.84的精确匹配分数，排名第二


<details>
  <summary>Details</summary>
Motivation: 生物医学问答系统在处理复杂医学查询时面临挑战，特别是在处理医学数据的复杂性和多跳推理需求方面存在困难

Method: 1) 对序列问题分解为子问题链进行多步推理；2) 直接处理直接问题以提高效率；3) 利用多源信息检索和上下文学习提供丰富的相关上下文

Result: 在BioCreative IX - MedHopQA共享任务数据集上评估，获得0.84的精确匹配分数，在当前排行榜上排名第二

Conclusion: 该模型能够有效应对生物医学问答的挑战，为推进医学研究和实践提供了一个多功能解决方案

Abstract: Biomedical Question Answering systems play a critical role in processing complex medical queries, yet they often struggle with the intricate nature of medical data and the demand for multi-hop reasoning. In this paper, we propose a model designed to effectively address both direct and sequential questions. While sequential questions are decomposed into a chain of sub-questions to perform reasoning across a chain of steps, direct questions are processed directly to ensure efficiency and minimise processing overhead. Additionally, we leverage multi-source information retrieval and in-context learning to provide rich, relevant context for generating answers. We evaluated our model on the BioCreative IX - MedHopQA Shared Task datasets. Our approach achieves an Exact Match score of 0.84, ranking second on the current leaderboard. These results highlight the model's capability to meet the challenges of Biomedical Question Answering, offering a versatile solution for advancing medical research and practice.

</details>


### [81] [MedTutor: A Retrieval-Augmented LLM System for Case-Based Medical Education](https://arxiv.org/abs/2601.06979)
*Dongsuk Jang,Ziyao Shangguan,Kyle Tegtmeyer,Anurag Gupta,Jan Czerminski,Sophie Chheang,Arman Cohan*

Main category: cs.CL

TL;DR: MedTutor是一个基于RAG的系统，能够从临床病例报告自动生成循证教育内容和多选题，旨在辅助住院医师培训。


<details>
  <summary>Details</summary>
Motivation: 住院医师学习过程中面临解读复杂病例和快速获取准确医学知识的挑战，传统方法寻找相关教育材料和证据耗时且困难，需要更高效的学习辅助工具。

Method: 采用检索增强生成(RAG)流程，输入临床病例报告，通过混合检索机制查询本地医学教科书和学术文献数据库，使用最先进的reranking模型过滤排序证据，最后由LLM生成教育内容。

Result: 三位放射科医师评估显示输出具有高临床和教育价值；大规模LLM-as-a-Judge评估表明LLM输出与专家判断存在中等程度一致性，但仍需专家监督。

Conclusion: MedTutor系统能有效生成高质量循证教育材料，LLM评估与人类专家存在一定相关性，但专家监督仍然必要，该系统有望提升住院医师培训效率。

Abstract: The learning process for medical residents presents significant challenges, demanding both the ability to interpret complex case reports and the rapid acquisition of accurate medical knowledge from reliable sources. Residents typically study case reports and engage in discussions with peers and mentors, but finding relevant educational materials and evidence to support their learning from these cases is often time-consuming and challenging. To address this, we introduce MedTutor, a novel system designed to augment resident training by automatically generating evidence-based educational content and multiple-choice questions from clinical case reports. MedTutor leverages a Retrieval-Augmented Generation (RAG) pipeline that takes clinical case reports as input and produces targeted educational materials. The system's architecture features a hybrid retrieval mechanism that synergistically queries a local knowledge base of medical textbooks and academic literature (using PubMed, Semantic Scholar APIs) for the latest related research, ensuring the generated content is both foundationally sound and current. The retrieved evidence is filtered and ordered using a state-of-the-art reranking model and then an LLM generates the final long-form output describing the main educational content regarding the case-report. We conduct a rigorous evaluation of the system. First, three radiologists assessed the quality of outputs, finding them to be of high clinical and educational value. Second, we perform a large scale evaluation using an LLM-as-a Judge to understand if LLMs can be used to evaluate the output of the system. Our analysis using correlation between LLMs outputs and human expert judgments reveals a moderate alignment and highlights the continued necessity of expert oversight.

</details>


### [82] [Lexicalized Constituency Parsing for Middle Dutch: Low-resource Training and Cross-Domain Generalization](https://arxiv.org/abs/2601.07008)
*Yiming Liang,Fang Zhao*

Main category: cs.CL

TL;DR: 将基于Transformer的选区解析器应用于中古荷兰语，通过联合训练、领域适应和数据增强策略提升低资源历史语言的解析性能


<details>
  <summary>Details</summary>
Motivation: 目前神经解析器主要关注依存解析，而中古荷兰语等低资源历史语言的选区解析研究不足，需要开发有效的解析方法

Method: 采用基于Transformer的选区解析器，通过联合训练使用高资源辅助语言，评估微调、数据组合等策略，探索领域适应的特征分离技术

Result: 联合训练使F1分数提升达0.73，地理和时间上更接近中古荷兰语的语言带来最大增益；神经解析器始终优于现有的PCFG解析器；领域适应需要约200个样本才能有效提升跨域性能

Conclusion: 基于Transformer的解析器能有效处理中古荷兰语的选区解析，联合训练和领域适应策略显著提升性能，为低资源历史语言解析提供了可行方案

Abstract: Recent years have seen growing interest in applying neural networks and contextualized word embeddings to the parsing of historical languages. However, most advances have focused on dependency parsing, while constituency parsing for low-resource historical languages like Middle Dutch has received little attention. In this paper, we adapt a transformer-based constituency parser to Middle Dutch, a highly heterogeneous and low-resource language, and investigate methods to improve both its in-domain and cross-domain performance. We show that joint training with higher-resource auxiliary languages increases F1 scores by up to 0.73, with the greatest gains achieved from languages that are geographically and temporally closer to Middle Dutch. We further evaluate strategies for leveraging newly annotated data from additional domains, finding that fine-tuning and data combination yield comparable improvements, and our neural parser consistently outperforms the currently used PCFG-based parser for Middle Dutch. We further explore feature-separation techniques for domain adaptation and demonstrate that a minimum threshold of approximately 200 examples per domain is needed to effectively enhance cross-domain performance.

</details>


### [83] [TurkBench: A Benchmark for Evaluating Turkish Large Language Models](https://arxiv.org/abs/2601.07020)
*Çağrı Toraman,Ahmet Kaan Sever,Ayse Aysu Cengiz,Elif Ecem Arslan,Görkem Sevinç,Mete Mert Birdal,Yusuf Faruk Güldemir,Ali Buğra Kanburoğlu,Sezen Felekoğlu,Osman Gürlek,Sarp Kantar,Birsen Şahin Kütük,Büşra Tufan,Elif Genç,Serkan Coşkun,Gupse Ekin Demir,Muhammed Emin Arayıcı,Olgun Dursun,Onur Gungor,Susan Üsküdarlı,Abdullah Topraksoy,Esra Darıcı*

Main category: cs.CL

TL;DR: TurkBench是一个针对土耳其语大语言模型的综合评估基准，包含8,151个数据样本和21个子任务，涵盖知识、语言理解、推理等六大类别。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，需要语言特定的评估基准。虽然英语评估基准已有显著进展，但土耳其语等具有独特语言特性的语言评估基准仍然不足。

Method: 研究团队开发了TurkBench基准，包含8,151个数据样本，分布在21个不同的子任务中，这些任务组织在六大评估类别下：知识、语言理解、推理、内容审核、土耳其语语法和词汇、以及指令遵循。

Result: TurkBench为研究人员和开发者提供了一个有价值的工具，用于评估土耳其语大语言模型的能力，并识别改进领域。基准已在HuggingFace平台发布，支持在线提交。

Conclusion: TurkBench填补了土耳其语大语言模型评估的空白，其多样化的任务和文化相关数据将为土耳其语NLP研究提供重要支持。

Abstract: With the recent surge in the development of large language models, the need for comprehensive and language-specific evaluation benchmarks has become critical. While significant progress has been made in evaluating English language models, benchmarks for other languages, particularly those with unique linguistic characteristics such as Turkish, remain less developed. Our study introduces TurkBench, a comprehensive benchmark designed to assess the capabilities of generative large language models in the Turkish language. TurkBench involves 8,151 data samples across 21 distinct subtasks. These are organized under six main categories of evaluation: Knowledge, Language Understanding, Reasoning, Content Moderation, Turkish Grammar and Vocabulary, and Instruction Following. The diverse range of tasks and the culturally relevant data would provide researchers and developers with a valuable tool for evaluating their models and identifying areas for improvement. We further publish our benchmark for online submissions at https://huggingface.co/turkbench

</details>


### [84] [Solar Open Technical Report](https://arxiv.org/abs/2601.07022)
*Sungrae Park,Sanghoon Kim,Jungho Cho,Gyoungjin Gim,Dawoon Jung,Mikyoung Cha,Eunhae Choo,Taekgyu Hong,Minbyul Jeong,SeHwan Joo,Minsoo Khang,Eunwon Kim,Minjeong Kim,Sujeong Kim,Yunsu Kim,Hyeonju Lee,Seunghyun Lee,Sukyung Lee,Siyoung Park,Gyungin Shin,Inseo Song,Wonho Song,Seonghoon Yang,Seungyoun Yi,Sanghoon Yoon,Jeonghyun Ko,Seyoung Song,Keunwoo Choi,Hwalsuk Lee,Sunghun Kim,Du-Seong Chang,Kyunghyun Cho,Junsuk Choe,Hwaran Lee,Jae-Gil Lee,KyungTae Lim,Alice Oh*

Main category: cs.CL

TL;DR: Solar Open是一个102B参数的双语MoE模型，针对资源匮乏语言开发，通过合成数据、渐进式课程学习和高效RL优化框架解决数据稀缺问题，在英语和韩语基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对资源匮乏语言（underserved languages）开发高质量语言模型面临数据稀缺、训练效率低和推理能力不足三大挑战，需要系统性方法解决这些问题。

Method: 1. 合成4.5T高质量、领域特定、RL导向的token数据；2. 采用渐进式课程学习，在20万亿token上联合优化数据组成、质量阈值和领域覆盖；3. 应用SnapPO框架进行高效可扩展的强化学习优化。

Result: 在英语和韩语基准测试中，Solar Open取得了具有竞争力的性能表现，证明了该方法在资源匮乏语言AI开发中的有效性。

Conclusion: Solar Open展示了通过系统性方法解决数据稀缺、训练优化和推理能力三大挑战，为资源匮乏语言开发高质量语言模型提供了有效方法论。

Abstract: We introduce Solar Open, a 102B-parameter bilingual Mixture-of-Experts language model for underserved languages. Solar Open demonstrates a systematic methodology for building competitive LLMs by addressing three interconnected challenges. First, to train effectively despite data scarcity for underserved languages, we synthesize 4.5T tokens of high-quality, domain-specific, and RL-oriented data. Second, we coordinate this data through a progressive curriculum jointly optimizing composition, quality thresholds, and domain coverage across 20 trillion tokens. Third, to enable reasoning capabilities through scalable RL, we apply our proposed framework SnapPO for efficient optimization. Across benchmarks in English and Korean, Solar Open achieves competitive performance, demonstrating the effectiveness of this methodology for underserved language AI development.

</details>


### [85] [Codified Foreshadowing-Payoff Text Generation](https://arxiv.org/abs/2601.07033)
*Longfei Yun,Kun Zhou,Yupeng Hou,Letian Peng,Jingbo Shang*

Main category: cs.CL

TL;DR: CFPG框架通过编码"伏笔-触发-回报"三元组，将叙事连续性转化为可执行的因果谓词，显著提升LLM在长程叙事依赖上的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在故事生成方面有进展，但经常无法处理长程叙事依赖（如契诃夫之枪），现有评估主要关注表面连贯性而非叙事设置的逻辑实现。

Method: 提出CFPG框架，从BookSum语料库中挖掘和编码"伏笔-触发-回报"三元组，将叙事连续性转化为可执行的因果谓词，提供结构化监督。

Result: CFPG在回报准确性和叙事对齐方面显著优于标准提示基线，表明明确编码叙事机制对提升LLM叙事能力至关重要。

Conclusion: 明确编码叙事机制对于推动LLM从表面流畅性转向真正的叙事能力是必要的，CFPG为评估和改进叙事生成提供了新视角。

Abstract: Foreshadowing and payoff are ubiquitous narrative devices through which authors introduce commitments early in a story and resolve them through concrete, observable outcomes. However, despite advances in story generation, large language models (LLMs) frequently fail to bridge these long-range narrative dependencies, often leaving "Chekhov's guns" unfired even when the necessary context is present. Existing evaluations largely overlook this structural failure, focusing on surface-level coherence rather than the logical fulfillment of narrative setups. In this paper, we introduce Codified Foreshadowing-Payoff Generation (CFPG), a novel framework that reframes narrative quality through the lens of payoff realization. Recognizing that LLMs struggle to intuitively grasp the "triggering mechanism" of a foreshadowed event, CFPG transforms narrative continuity into a set of executable causal predicates. By mining and encoding Foreshadow-Trigger-Payoff triples from the BookSum corpus, we provide structured supervision that ensures foreshadowed commitments are not only mentioned but also temporally and logically fulfilled. Experiments demonstrate that CFPG significantly outperforms standard prompting baselines in payoff accuracy and narrative alignment. Our findings suggest that explicitly codifying narrative mechanics is essential for moving LLMs from surface-level fluency to genuine narrative competence.

</details>


### [86] [Mid-Think: Training-Free Intermediate-Budget Reasoning via Token-Level Triggers](https://arxiv.org/abs/2601.07036)
*Wang Yang,Debargha Ganguly,Xinpeng Li,Chaoda Song,Shouren Wang,Vikash Singh,Vipin Chaudhary,Xiaotian Han*

Main category: cs.CL

TL;DR: 研究发现混合推理语言模型的行为切换主要由少量触发词而非指令本身驱动，提出Mid-Think训练免费提示格式，在推理控制和强化学习训练中均有效


<details>
  <summary>Details</summary>
Motivation: 当前混合推理语言模型通过Think/No-think指令控制推理行为，但研究发现这种模式切换主要由少量触发词驱动而非指令本身，这为更高效的控制方法提供了机会

Method: 通过注意力分析和受控提示实验识别关键触发词，提出Mid-Think训练免费提示格式，结合"Okay"触发词和"</think>"后的换行模式，实现中间预算推理控制

Result: Mid-Think在准确率-长度权衡方面优于固定token和基于提示的基线方法；应用于SFT后的RL训练可减少约15%训练时间，同时提升Qwen3-8B在AIME和GPQA上的性能

Conclusion: 识别触发词驱动的推理行为控制机制，提出的Mid-Think方法在推理时控制和基于RL的推理训练中均有效，为高效推理控制提供了新思路

Abstract: Hybrid reasoning language models are commonly controlled through high-level Think/No-think instructions to regulate reasoning behavior, yet we found that such mode switching is largely driven by a small set of trigger tokens rather than the instructions themselves. Through attention analysis and controlled prompting experiments, we show that a leading ``Okay'' token induces reasoning behavior, while the newline pattern following ``</think>'' suppresses it. Based on this observation, we propose Mid-Think, a simple training-free prompting format that combines these triggers to achieve intermediate-budget reasoning, consistently outperforming fixed-token and prompt-based baselines in terms of the accuracy-length trade-off. Furthermore, applying Mid-Think to RL training after SFT reduces training time by approximately 15% while improving final performance of Qwen3-8B on AIME from 69.8% to 72.4% and on GPQA from 58.5% to 61.1%, demonstrating its effectiveness for both inference-time control and RL-based reasoning training.

</details>


### [87] [Task Arithmetic with Support Languages for Low-Resource ASR](https://arxiv.org/abs/2601.07038)
*Emma Rafkin,Dan DeGenaro,Xiulin Yang*

Main category: cs.CL

TL;DR: 该论文提出了一种通过任务向量算术合并高资源和低资源语言模型的方法，以提升低资源语言的自动语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 针对许多低资源语言缺乏可用数据的问题，需要开发资源受限的自动语音识别方法。现有方法通常利用高资源相关语言的数据，而任务算术方法可以通过合并不同任务模型来创建缺乏训练数据的任务模型。

Method: 将每种语言的训练视为一个任务，通过微调Whisper ASR系统生成任务向量。对于高资源和低资源语言配对，通过线性组合合并任务向量，并在低资源目标语言的验证集上优化线性组合的权重以最小化词错误率。

Result: 该方法在目标语言上持续提升了性能表现，表明任务向量合并方法对低资源语言ASR任务有效。

Conclusion: 通过任务向量算术合并高资源和低资源语言模型的方法能够有效提升低资源语言的自动语音识别性能，为资源受限的ASR系统开发提供了有前景的解决方案。

Abstract: The development of resource-constrained approaches to automatic speech recognition (ASR) is of great interest due to its broad applicability to many low-resource languages for which there is scant usable data. Existing approaches to many low-resource natural language processing tasks leverage additional data from higher-resource languages that are closely related to a target low-resource language. One increasingly popular approach uses task arithmetic to combine models trained on different tasks to create a model for a task where there is little to no training data. In this paper, we consider training on a particular language to be a task, and we generate task vectors by fine-tuning variants of the Whisper ASR system. For pairings of high- and low-resource languages, we merge task vectors via a linear combination, optimizing the weights of the linear combination on the downstream word error rate on the low-resource target language's validation set. We find that this approach consistently improves performance on the target languages.

</details>


### [88] [When Abundance Conceals Weakness: Knowledge Conflict in Multilingual Models](https://arxiv.org/abs/2601.07041)
*Jiaqi Zhao,Qiang Huang,Haodong Chen,Xiaoxing You,Jun Yu*

Main category: cs.CL

TL;DR: 论文提出CLEAR框架，系统评估多语言大模型如何处理跨语言知识冲突，发现任务类型决定冲突解决机制：推理任务中高资源语言占优，事实任务中语言亲缘性更重要。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在不同语言间的知识分布不均，当外部证据与语言依赖的记忆冲突时，会产生跨语言知识冲突现象，这在非英语中心场景中尚未充分研究。

Method: 提出CLEAR框架，将冲突解决分解为四个渐进场景，构建覆盖10种类型多样语言的跨语言版本ConflictQA和ConflictingQA基准，评估六个代表性大模型。

Result: 实验揭示了任务依赖的决策二分法：推理密集型任务中，冲突解决由语言资源丰富度主导，高资源语言具有更强说服力；实体中心的事实冲突中，语言亲缘性而非资源规模起决定作用，低资源但语言对齐的语言能超越远亲高资源语言。

Conclusion: 跨语言知识冲突解决机制因任务类型而异，CLEAR框架为理解多语言模型如何处理冲突知识提供了系统评估方法，揭示了语言资源与语言亲缘性在不同任务中的相对重要性。

Abstract: Large Language Models (LLMs) encode vast world knowledge across multiple languages, yet their internal beliefs are often unevenly distributed across linguistic spaces. When external evidence contradicts these language-dependent memories, models encounter \emph{cross-lingual knowledge conflict}, a phenomenon largely unexplored beyond English-centric settings. We introduce \textbf{CLEAR}, a \textbf{C}ross-\textbf{L}ingual knowl\textbf{E}dge conflict ev\textbf{A}luation f\textbf{R}amework that systematically examines how multilingual LLMs reconcile conflicting internal beliefs and multilingual external evidence. CLEAR decomposes conflict resolution into four progressive scenarios, from multilingual parametric elicitation to competitive multi-source cross-lingual induction, and systematically evaluates model behavior across two complementary QA benchmarks with distinct task characteristics. We construct multilingual versions of ConflictQA and ConflictingQA covering 10 typologically diverse languages and evaluate six representative LLMs. Our experiments reveal a task-dependent decision dichotomy. In reasoning-intensive tasks, conflict resolution is dominated by language resource abundance, with high-resource languages exerting stronger persuasive power. In contrast, for entity-centric factual conflicts, linguistic affinity, not resource scale, becomes decisive, allowing low-resource but linguistically aligned languages to outperform distant high-resource ones.

</details>


### [89] [Engineering of Hallucination in Generative AI: It's not a Bug, it's a Feature](https://arxiv.org/abs/2601.07046)
*Tim Fingscheidt,Patrick Blumenberg,Björn Möller*

Main category: cs.CL

TL;DR: 本文探讨生成式AI中的幻觉现象，认为适度的幻觉可能是特征而非缺陷，并介绍了通过概率工程控制幻觉程度的方法。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（如ChatGPT、GAIA-1）在实际应用中需要一定程度的"幻觉"才能产生令人满意的结果，这与通常认为幻觉是负面现象的观点相矛盾。作者旨在重新审视幻觉在生成式AI中的作用。

Method: 文章回顾了一些简单的概率工程技术，这些技术可以用来鼓励生成式AI进行有限度的幻觉，从而获得期望的输出结果。

Result: 通过适当的概率工程控制，可以调节生成式AI的幻觉程度，使其在保持事实准确性的同时，也能产生创造性和连贯的输出。

Conclusion: 在生成式AI中，适度的幻觉可能不是缺陷，而是一个必要的特征，有助于模型产生更自然、更有用的输出。

Abstract: Generative artificial intelligence (AI) is conquering our lives at lightning speed. Large language models such as ChatGPT answer our questions or write texts for us, large computer vision models such as GAIA-1 generate videos on the basis of text descriptions or continue prompted videos. These neural network models are trained using large amounts of text or video data, strictly according to the real data employed in training. However, there is a surprising observation: When we use these models, they only function satisfactorily when they are allowed a certain degree of fantasy (hallucination). While hallucination usually has a negative connotation in generative AI - after all, ChatGPT is expected to give a fact-based answer! - this article recapitulates some simple means of probability engineering that can be used to encourage generative AI to hallucinate to a limited extent and thus lead to the desired results. We have to ask ourselves: Is hallucination in gen-erative AI probably not a bug, but rather a feature?

</details>


### [90] [Fine-Tuning vs. RAG for Multi-Hop Question Answering with Novel Knowledge](https://arxiv.org/abs/2601.07054)
*Zhuoyi Yang,Yurun Song,Iftekhar Ahmed,Ian Harris*

Main category: cs.CL

TL;DR: 本文系统比较了参数化与非参数化知识注入方法在多跳问答中的效果，发现监督微调效果最好，检索增强生成在处理时序新知识时表现优异，而无监督微调效果有限。


<details>
  <summary>Details</summary>
Motivation: 多跳问答需要整合多个知识片段来获得正确答案，常用于评估大语言模型的推理能力。现有研究探索了不同的知识注入机制（如微调和检索增强生成），但它们在多跳问答中的相对有效性，特别是在需要时序新知识的情况下，仍未得到充分理解。

Method: 系统比较了参数化（无监督微调、监督微调）和非参数化（检索增强生成）知识注入方法。在三个7B参数的开源大语言模型上进行评估，使用两个基准：标准多跳科学问答数据集QASC，以及新构建的包含10,000多个基于2024年维基百科事件的多跳问题数据集，专门测试模型预训练截止日期后的知识。

Result: 无监督微调相比基础模型提升有限，表明仅持续预训练不足以改善多跳推理准确性。检索增强生成带来显著且一致的改进，特别是在回答依赖时序新信息的问题时。监督微调在模型和数据集上达到最高总体准确率。

Conclusion: 知识注入机制支持多跳问答的方式存在根本差异，当需要外部或组合知识时，检索增强方法尤为重要。监督微调效果最佳，而检索增强生成在处理时序新知识方面表现突出。

Abstract: Multi-hop question answering is widely used to evaluate the reasoning capabilities of large language models (LLMs), as it requires integrating multiple pieces of supporting knowledge to arrive at a correct answer. While prior work has explored different mechanisms for providing knowledge to LLMs, such as finetuning and retrieval-augmented generation (RAG), their relative effectiveness for multi-hop question answering remains insufficiently understood, particularly when the required knowledge is temporally novel.
  In this paper, we systematically compare parametric and non-parametric knowledge injection methods for open-domain multi-hop question answering. We evaluate unsupervised fine-tuning (continual pretraining), supervised fine-tuning, and retrieval-augmented generation across three 7B-parameter open-source LLMs. Experiments are conducted on two benchmarks: QASC, a standard multi-hop science question answering dataset, and a newly constructed dataset of over 10,000 multi-hop questions derived from Wikipedia events in 2024, designed to test knowledge beyond the models' pretraining cutoff.
  Our results show that unsupervised fine-tuning provides only limited gains over base models, suggesting that continual pretraining alone is insufficient for improving multi-hop reasoning accuracy. In contrast, retrieval-augmented generation yields substantial and consistent improvements, particularly when answering questions that rely on temporally novel information. Supervised fine-tuning achieves the highest overall accuracy across models and datasets. These findings highlight fundamental differences in how knowledge injection mechanisms support multi-hop question answering and underscore the importance of retrieval-based methods when external or compositional knowledge is required.

</details>


### [91] [The Need for a Socially-Grounded Persona Framework for User Simulation](https://arxiv.org/abs/2601.07110)
*Pranav Narayanan Venkit,Yu Li,Yada Pruksachatkun,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: SCOPE框架通过141项社会心理学协议构建人物角色，发现仅基于人口统计的角色是结构瓶颈，加入社会心理学维度能显著提升行为预测准确性并减少偏见。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型用于社会模拟时，人物角色大多基于粗糙的人口统计属性或摘要构建，缺乏社会心理学基础，这限制了模拟的真实性和准确性。

Method: 提出SCOPE框架，基于124名美国参与者的141项两小时社会心理学协议数据构建人物角色，在7个模型上测试，并与SimBench的441个对齐问题进行对比评估。

Result: 人口统计仅解释约1.5%的人类响应方差，加入社会心理学维度能改善行为预测、减少过度强调偏见，基于价值观和身份的非人口统计角色实现强对齐且偏见更低。SCOPE角色在SimBench上优于默认提示和NVIDIA Nemotron角色。

Conclusion: 人物角色质量取决于社会心理学结构而非人口统计模板或摘要，社会心理学基础的角色构建能显著提升语言模型社会模拟的准确性和公平性。

Abstract: Synthetic personas are widely used to condition large language models (LLMs) for social simulation, yet most personas are still constructed from coarse sociodemographic attributes or summaries. We revisit persona creation by introducing SCOPE, a socially grounded framework for persona construction and evaluation, built from a 141-item, two-hour sociopsychological protocol collected from 124 U.S.-based participants. Across seven models, we find that demographic-only personas are a structural bottleneck: demographics explain only ~1.5% of variance in human response similarity. Adding sociopsychological facets improves behavioral prediction and reduces over-accentuation, and non-demographic personas based on values and identity achieve strong alignment with substantially lower bias. These trends generalize to SimBench (441 aligned questions), where SCOPE personas outperform default prompting and NVIDIA Nemotron personas, and SCOPE augmentation improves Nemotron-based personas. Our results indicate that persona quality depends on sociopsychological structure rather than demographic templates or summaries.

</details>


### [92] [ReMIND: Orchestrating Modular Large Language Models for Controllable Serendipity A REM-Inspired System Design for Emergent Creative Ideation](https://arxiv.org/abs/2601.07121)
*Makoto Sato*

Main category: cs.CL

TL;DR: ReMIND是一个受REM睡眠启发的模块化框架，用于促进LLM的创造性构思，通过分离探索和整合阶段来平衡新颖性和一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在创造性构思中难以同时实现新颖性和内部一致性。随机采样虽然能促进新颖性，但往往会损害一致性，需要一种能平衡这两者的方法。

Method: ReMIND框架包含四个阶段：wake（生成稳定的低温语义基线）、dream（进行高温探索性生成）、judge（应用粗略评估过滤不连贯输出并提取候选想法）、re-wake（将选定想法重新表达为连贯的最终输出）。每个阶段由独立的LLM实例化，实现探索与整合的功能分离。

Result: 参数扫描显示ReMIND能可靠地诱导语义探索同时保持下游稳定性。嵌入分析确认在dream阶段有显著的语义位移，外部评估显示高质量想法是零星出现的，而非沿任何单一指标的极端值。

Conclusion: LLM中的偶然性构思是一个罕见事件过程，最好通过系统级设计来塑造有价值想法出现和稳定的条件。ReMIND为研究偶然性的计算基础提供了通用框架，展示了模块化LLM编排如何桥接探索与稳定。

Abstract: Large language models (LLMs) are used not only for problem solving but also for creative ideation; however, eliciting serendipitous insights that are both novel and internally coherent remains difficult. While stochastic sampling promotes novelty, it often degrades consistency. Here, we propose ReMIND, a REM-inspired modular framework for ideation. ReMIND consists of four stages: wake, which generates a stable low-temperature semantic baseline; dream, which performs high-temperature exploratory generation; judge, which applies coarse evaluation to filter incoherent outputs and extract candidate ideas; and re-wake, which re-articulates selected ideas into coherent final outputs. By instantiating each stage as an independent LLM, ReMIND enables functional separation between exploration and consolidation. Parameter sweeps show that ReMIND reliably induces semantic exploration while preserving downstream stability. Embedding-based analyses confirm substantial semantic displacement during the dream phase, whereas external evaluations reveal that high-quality ideas emerge sporadically rather than as extrema along any single metric. These results suggest that serendipitous ideation in LLMs is a rare-event process best approached through system level design that shapes the conditions under which valuable ideas can emerge and be stabilized. ReMIND provides a general framework for studying the computational basis of serendipity and illustrates how modular LLM orchestration can bridge exploration and stabilization.

</details>


### [93] [Measuring Iterative Temporal Reasoning with TimePuzzles](https://arxiv.org/abs/2601.07148)
*Zhengxiang Wang,Zeyu Dong*

Main category: cs.CL

TL;DR: TimePuzzles是一个基于约束的日期推理任务，用于评估迭代时间推理能力，通过算法生成包含时间锚点和日历关系的谜题，对LLM具有挑战性且能有效区分模型能力。


<details>
  <summary>Details</summary>
Motivation: 需要一种方法来评估大型语言模型在迭代时间推理方面的能力，特别是在处理包含事实时间锚点和跨文化日历关系的复杂约束时的表现。

Method: 创建TimePuzzles任务，通过算法生成包含时间锚点和日历关系的约束性日期推理谜题，每个谜题有一个或多个有效解日期，用于受控、动态和持续评估。

Result: 在13个不同LLM上测试，TimePuzzles能很好地区分模型的迭代时间推理能力：GPT-5仅达到49.3%准确率，其他模型均低于31%。网络搜索能显著提升性能，代码解释器效果不一，将约束重写为明确日期能大幅改善表现。

Conclusion: TimePuzzles提供了一个简单、经济有效的诊断工具，用于评估工具增强的迭代时间推理能力，揭示了当前LLM在可靠使用工具处理时间约束方面的差距。

Abstract: We introduce TimePuzzles, a constraint-based date inference task for evaluating iterative temporal reasoning. Each puzzle combines factual temporal anchors with (cross-cultural) calendar relations, admits one or multiple valid solution dates, and is algorithmically generated for controlled, dynamic, and continual evaluation. Across 13 diverse LLMs, TimePuzzles well distinguishes their iterative temporal reasoning capabilities and remains challenging without tools: GPT-5 reaches only 49.3% accuracy and all other models stay below 31%, despite the dataset's simplicity. Web search consistently yields substantial gains and using code interpreter shows mixed effects, but all models perform much better when constraints are rewritten with explicit dates, revealing a gap in reliable tool use. Overall, TimePuzzles presents a simple, cost-effective diagnostic for tool-augmented iterative temporal reasoning.

</details>


### [94] [Can Large Language Models Understand, Reason About, and Generate Code-Switched Text?](https://arxiv.org/abs/2601.07153)
*Genta Indra Winata,David Anugraha,Patrick Amadeus Irawan,Anirban Das,Haneul Yoo,Paresh Dashore,Shreyas Kulkarni,Ruochen Zhang,Haruki Sakajo,Frederikus Hudi,Anaelia Ovalle,Syrielle Montariol,Felix Gaschi,Michael Anugraha,Rutuj Ravindra Puranik,Zawad Hayat Ahmed,Adril Putra Merin,Emmanuele Chersoni*

Main category: cs.CL

TL;DR: 论文提出了CodeMixQA基准，全面评估大语言模型在代码切换（多语言混合）文本上的理解和生成能力，发现现有模型在混合语言推理和生成方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 代码切换是多语言交流中的普遍现象，但大语言模型在混合语言环境下的鲁棒性尚未得到充分理解。需要系统评估LLM在理解和生成代码切换文本方面的能力。

Method: 构建CodeMixQA基准数据集，包含16种不同平行代码切换语言对变体，涵盖多个地理区域和代码切换模式，包括原始脚本和音译形式。使用该基准分析LLM在代码切换问答任务中的推理行为，并系统评估LLM生成的合成代码切换文本的自然性和语义保真度。

Result: 研究发现LLM在代码切换条件下的推理和生成能力存在持续挑战。模型在处理混合语言输入时的推理行为显示出局限性，生成的代码切换文本在自然性和语义保真度方面也有明显不足。

Conclusion: 该研究揭示了当前LLM在代码切换环境中的局限性，为构建更鲁棒的多语言大语言模型提供了可操作的见解。作者开源了数据集和代码。

Abstract: Code-switching is a pervasive phenomenon in multilingual communication, yet the robustness of large language models (LLMs) in mixed-language settings remains insufficiently understood. In this work, we present a comprehensive evaluation of LLM capabilities in understanding, reasoning over, and generating code-switched text. We introduce CodeMixQA a novel benchmark with high-quality human annotations, comprising 16 diverse parallel code-switched language-pair variants that span multiple geographic regions and code-switching patterns, and include both original scripts and their transliterated forms. Using this benchmark, we analyze the reasoning behavior of LLMs on code-switched question-answering tasks, shedding light on how models process and reason over mixed-language inputs. We further conduct a systematic evaluation of LLM-generated synthetic code-switched text, focusing on both naturalness and semantic fidelity, and uncover key limitations in current generation capabilities. Our findings reveal persistent challenges in both reasoning and generation under code-switching conditions and provide actionable insights for building more robust multilingual LLMs. We release the dataset and code as open source.

</details>


### [95] [Structured Reasoning for Large Language Models](https://arxiv.org/abs/2601.07180)
*Jinyi Han,Zixiang Di,Zishang Jiang,Ying Liao,Jiaqing Liang,Yongqi Wang,Yanghua Xiao*

Main category: cs.CL

TL;DR: SCR框架通过结构化推理轨迹，采用生成-验证-修订范式，结合动态终止监督和两阶段强化学习，显著提升LLM推理效率，减少50%输出长度。


<details>
  <summary>Details</summary>
Motivation: 当前LLM通过长思维链推理时，经常产生冗余或无效的推理步骤，特别是达到正确答案后仍进行不必要的验证和修订。这源于推理轨迹的非结构化和缺乏对关键推理能力的针对性监督。

Method: 提出结构化推理(SCR)框架，将推理轨迹解耦为可评估、可训练的组件。采用生成-验证-修订范式，构建结构化训练数据，应用动态终止监督指导模型决定何时终止推理。为避免不同推理能力学习信号间的干扰，采用渐进式两阶段强化学习策略：第一阶段针对初始生成和自我验证，第二阶段专注于修订。

Result: 在三个骨干模型上的广泛实验表明，SCR显著提高了推理效率和自我验证能力。与现有推理范式相比，输出token长度最多减少50%。

Conclusion: SCR框架通过结构化推理轨迹和针对性训练策略，有效解决了LLM推理中的冗余问题，实现了更高效、更精确的推理过程。

Abstract: Large language models (LLMs) achieve strong performance by generating long chains of thought, but longer traces always introduce redundant or ineffective reasoning steps. One typical behavior is that they often perform unnecessary verification and revisions even if they have reached the correct answers. This limitation stems from the unstructured nature of reasoning trajectories and the lack of targeted supervision for critical reasoning abilities. To address this, we propose Structured Reasoning (SCR), a framework that decouples reasoning trajectories into explicit, evaluable, and trainable components. We mainly implement SCR using a Generate-Verify-Revise paradigm. Specifically, we construct structured training data and apply Dynamic Termination Supervision to guide the model in deciding when to terminate reasoning. To avoid interference between learning signals for different reasoning abilities, we adopt a progressive two-stage reinforcement learning strategy: the first stage targets initial generation and self-verification, and the second stage focuses on revision. Extensive experiments on three backbone models show that SCR substantially improves reasoning efficiency and self-verification. Besides, compared with existing reasoning paradigms, it reduces output token length by up to 50%.

</details>


### [96] [Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG](https://arxiv.org/abs/2601.07192)
*Manzong Huang,Chenyang Bu,Yi He,Xingrui Zhuo,Xindong Wu*

Main category: cs.CL

TL;DR: Relink提出了一种新的"推理-构建"范式，通过动态构建查询特定的证据图来解决传统GraphRAG中知识图不完整和噪声干扰的问题。


<details>
  <summary>Details</summary>
Motivation: 传统GraphRAG采用"先构建后推理"范式，依赖静态预构建的知识图，面临两个关键挑战：1) 知识图不完整性导致推理路径断裂；2) 图中低信噪比引入干扰事实，这些查询相关但误导性的知识会破坏推理过程。

Method: Relink采用"推理-构建"范式，动态构建查询特定的证据图。针对不完整性，从原始文本语料库的潜在关系池中实例化所需事实，实时修复断裂路径。针对干扰事实，采用统一的查询感知评估策略，联合考虑知识图和潜在关系中的候选事实，选择对回答查询最有用的信息而非依赖其预存在性。

Result: 在五个开放域问答基准测试上的广泛实验表明，Relink相比领先的GraphRAG基线在EM上平均提升5.4%，在F1上平均提升5.2%，证明了该框架的优越性。

Conclusion: Relink通过动态构建查询特定证据图的"推理-构建"范式，有效解决了传统GraphRAG中知识图不完整和噪声干扰的问题，显著提升了问答性能。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a prevailing \textit{build-then-reason} paradigm, which relies on a static, pre-constructed Knowledge Graph (KG). This paradigm faces two critical challenges. First, the KG's inherent incompleteness often breaks reasoning paths. Second, the graph's low signal-to-noise ratio introduces distractor facts, presenting query-relevant but misleading knowledge that disrupts the reasoning process.
  To address these challenges, we argue for a \textit{reason-and-construct} paradigm and propose Relink, a framework that dynamically builds a query-specific evidence graph. To tackle incompleteness, \textbf{Relink} instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. To handle misleading or distractor facts, Relink employs a unified, query-aware evaluation strategy that jointly considers candidates from both the KG and latent relations, selecting those most useful for answering the query rather than relying on their pre-existence. This empowers Relink to actively discard distractor facts and construct the most faithful and precise evidence path for each query.
  Extensive experiments on five Open-Domain Question Answering benchmarks show that Relink achieves significant average improvements of 5.4\% in EM and 5.2\% in F1 over leading GraphRAG baselines, demonstrating the superiority of our proposed framework.

</details>


### [97] [MI-PRUN: Optimize Large Language Model Pruning via Mutual Information](https://arxiv.org/abs/2601.07212)
*Hao Zhang,Zhibin Zhang,Guangxin Wu,He Chen,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: 提出基于互信息的LLM块剪枝方法MI-PRUN，通过互信息评估隐藏状态转移识别冗余块，结合数据处理不等式分析块重要性关系，并开发快速块选择算法实现全局最优解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多个领域应用广泛，但需要大量计算和内存资源。现有块剪枝方法不稳定且难以达到全局最优解，需要更稳定有效的剪枝方法。

Method: 提出MI-PRUN方法：1) 利用互信息评估隐藏状态转移来识别冗余块；2) 结合数据处理不等式分析连续块与单个块的重要性关系；3) 开发Fast-Block-Select算法迭代更新块组合实现全局最优。

Result: 在多种模型和数据集上的广泛实验证明了该方法的稳定性和有效性，能够实现显著压缩和推理加速。

Conclusion: MI-PRUN方法通过互信息评估和快速块选择算法，解决了现有块剪枝方法不稳定和难以达到全局最优的问题，为LLM的高效压缩提供了有效解决方案。

Abstract: Large Language Models (LLMs) have become indispensable across various domains, but this comes at the cost of substantial computational and memory resources. Model pruning addresses this by removing redundant components from models. In particular, block pruning can achieve significant compression and inference acceleration. However, existing block pruning methods are often unstable and struggle to attain globally optimal solutions. In this paper, we propose a mutual information based pruning method MI-PRUN for LLMs. Specifically, we leverages mutual information to identify redundant blocks by evaluating transitions in hidden states. Additionally, we incorporate the Data Processing Inequality (DPI) to reveal the relationship between the importance of entire contiguous blocks and that of individual blocks. Moreover, we develop the Fast-Block-Select algorithm, which iteratively updates block combinations to achieve a globally optimal solution while significantly improving the efficiency. Extensive experiments across various models and datasets demonstrate the stability and effectiveness of our method.

</details>


### [98] [The Roots of Performance Disparity in Multilingual Language Models: Intrinsic Modeling Difficulty or Design Choices?](https://arxiv.org/abs/2601.07220)
*Chen Shani,Yuval Reif,Nathan Roll,Dan Jurafsky,Ekaterina Shutova*

Main category: cs.CL

TL;DR: 该调查分析了多语言语言模型性能差异的原因，发现差距主要源于建模选择而非语言内在难度，提出了改善多语言公平性的设计建议


<details>
  <summary>Details</summary>
Motivation: 当前多语言语言模型在不同语言间表现不均，需要理解这种差距是源于语言内在难度还是建模选择，以促进更公平的多语言NLP系统

Method: 围绕两个核心问题组织文献综述：1）语言差异是否源于表征和分配选择而非内在复杂性；2）哪些设计选择能缓解不同类型语言间的不平等。分析语言特征（正字法、形态学、词汇多样性、句法、信息密度、类型学距离）与建模机制的关系

Result: 当分词、编码和数据暴露被标准化时，性能差距通常缩小，表明当前观察到的困难主要源于建模选择而非语言内在难度

Conclusion: 提出了分词、采样、架构和评估的设计建议，以支持更平衡的多语言语言模型，强调通过改进建模选择而非归因于语言内在难度来缩小性能差距

Abstract: Multilingual language models (LMs) promise broader NLP access, yet current systems deliver uneven performance across the world's languages. This survey examines why these gaps persist and whether they reflect intrinsic linguistic difficulty or modeling artifacts. We organize the literature around two questions: do linguistic disparities arise from representation and allocation choices (e.g., tokenization, encoding, data exposure, parameter sharing) rather than inherent complexity; and which design choices mitigate inequities across typologically diverse languages. We review linguistic features, such as orthography, morphology, lexical diversity, syntax, information density, and typological distance, linking each to concrete modeling mechanisms. Gaps often shrink when segmentation, encoding, and data exposure are normalized, suggesting much apparent difficulty stems from current modeling choices. We synthesize these insights into design recommendations for tokenization, sampling, architectures, and evaluation to support more balanced multilingual LMs.

</details>


### [99] [ActiShade: Activating Overshadowed Knowledge to Guide Multi-Hop Reasoning in Large Language Models](https://arxiv.org/abs/2601.07260)
*Huipeng Ma,Luan Zhang,Dandan Song,Linmei Hu,Yuhang Tian,Jun Yang,Changzhi Zhou,Chenhao Li,Yizhou Jin,Xudong Li,Meng Lin,Mingxing Zhang,Shuhao Zhang*

Main category: cs.CL

TL;DR: ActiShade通过检测和激活被遮蔽的关键知识来改进多跳推理中的检索增强生成，减少知识遮蔽导致的错误累积


<details>
  <summary>Details</summary>
Motivation: 在多跳推理中，传统的多轮检索增强生成方法依赖LLM生成的内容作为检索查询，但这些方法容易受到知识遮蔽现象的影响。知识遮蔽会导致关键信息在生成过程中被掩盖，使得LLM生成的内容不完整或不准确，进而导致无关检索和迭代过程中的错误累积。

Method: ActiShade通过迭代检测给定查询中被遮蔽的关键短语，检索与查询和被遮蔽关键短语都相关的文档，然后基于检索到的文档生成新的查询来指导下一轮迭代。该方法在制定下一轮查询时补充被遮蔽的知识，同时最小化引入无关噪声。

Result: 大量实验表明，ActiShade在多个数据集和LLM上都优于现有方法。

Conclusion: ActiShade通过检测和激活被遮蔽的知识，有效解决了多跳推理中知识遮蔽导致的问题，减少了错误累积，提高了检索增强生成的性能。

Abstract: In multi-hop reasoning, multi-round retrieval-augmented generation (RAG) methods typically rely on LLM-generated content as the retrieval query. However, these approaches are inherently vulnerable to knowledge overshadowing - a phenomenon where critical information is overshadowed during generation. As a result, the LLM-generated content may be incomplete or inaccurate, leading to irrelevant retrieval and causing error accumulation during the iteration process. To address this challenge, we propose ActiShade, which detects and activates overshadowed knowledge to guide large language models (LLMs) in multi-hop reasoning. Specifically, ActiShade iteratively detects the overshadowed keyphrase in the given query, retrieves documents relevant to both the query and the overshadowed keyphrase, and generates a new query based on the retrieved documents to guide the next-round iteration. By supplementing the overshadowed knowledge during the formulation of next-round queries while minimizing the introduction of irrelevant noise, ActiShade reduces the error accumulation caused by knowledge overshadowing. Extensive experiments show that ActiShade outperforms existing methods across multiple datasets and LLMs.

</details>


### [100] [The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents](https://arxiv.org/abs/2601.07264)
*Weihao Xuan,Qingcheng Zeng,Heli Qi,Yunze Xiao,Junjue Wang,Naoto Yokoya*

Main category: cs.CL

TL;DR: 该研究系统探讨了工具使用智能体的校准问题，发现证据型工具（如网络搜索）会导致严重过度自信，而验证型工具（如代码解释器）能改善校准。作者提出强化学习微调框架，联合优化任务准确性和校准性能。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的自主智能体在处理多轮任务时快速发展，但确保其可信度仍是关键挑战。校准作为可信度的基础支柱，在静态模型中已有研究，但在工具集成的工作流中的动态特性尚未充分探索。

Method: 1. 通过试点研究识别工具类型对校准的影响；2. 提出强化学习微调框架，联合优化任务准确性和校准性能；3. 设计全面的奖励设计方案基准；4. 在本地训练环境和嘈杂网络设置中进行评估。

Result: 1. 证据型工具（如网络搜索）由于检索信息中的固有噪声导致严重过度自信；2. 验证型工具（如代码解释器）通过确定性反馈能够改善校准；3. 训练的智能体不仅获得更好的校准性能，还能从本地训练环境泛化到嘈杂网络设置和数学推理等不同领域。

Conclusion: 工具使用智能体需要领域特定的校准策略。这项工作为构建能够在高风险实际部署中可靠传达不确定性的自我意识智能体奠定了基础。

Abstract: Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge. A fundamental pillar of this trustworthiness is calibration, which refers to an agent's ability to express confidence that reliably reflects its actual performance. While calibration is well-established for static models, its dynamics in tool-integrated agentic workflows remain underexplored. In this work, we systematically investigate verbalized calibration in tool-use agents, revealing a fundamental confidence dichotomy driven by tool type. Specifically, our pilot study identifies that evidence tools (e.g., web search) systematically induce severe overconfidence due to inherent noise in retrieved information, while verification tools (e.g., code interpreters) can ground reasoning through deterministic feedback and mitigate miscalibration. To robustly improve calibration across tool types, we propose a reinforcement learning (RL) fine-tuning framework that jointly optimizes task accuracy and calibration, supported by a holistic benchmark of reward designs. We demonstrate that our trained agents not only achieve superior calibration but also exhibit robust generalization from local training environments to noisy web settings and to distinct domains such as mathematical reasoning. Our results highlight the necessity of domain-specific calibration strategies for tool-use agents. More broadly, this work establishes a foundation for building self-aware agents that can reliably communicate uncertainty in high-stakes, real-world deployments.

</details>


### [101] [Document-Level Zero-Shot Relation Extraction with Entity Side Information](https://arxiv.org/abs/2601.07271)
*Mohan Raj Chanthran,Soon Lay Ki,Ong Huey Fang,Bhawani Selvaretnam*

Main category: cs.CL

TL;DR: 本文提出DocZSRE-SI框架，利用实体侧信息（如实体提及描述和上位词）进行文档级零样本关系抽取，避免依赖LLM生成合成数据，在马来西亚英语等低资源语言上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有文档级零样本关系抽取方法依赖大语言模型生成合成数据，但在低资源语言（如马来西亚英语）中存在两个主要问题：1）难以捕捉本地语言细微差别；2）LLM生成数据存在事实不准确风险。需要一种不依赖LLM生成数据的方法。

Method: 提出DocZSRE-SI框架，利用实体侧信息（Entity Side Information）进行零样本关系抽取，包括实体提及描述和实体提及上位词等信息。该方法不依赖LLM生成合成数据，采用低复杂度模型设计。

Result: DocZSRE-SI在宏观F1分数上比基线模型和现有基准平均提升11.6%，在处理低资源语言和语言多样性方面表现显著优于传统LLM方法。

Conclusion: DocZSRE-SI为文档级零样本关系抽取提供了可扩展且可靠的解决方案，特别适用于马来西亚英语新闻文章等传统LLM方法表现不佳的场景，通过利用实体侧信息避免了LLM生成数据的错误风险。

Abstract: Document-Level Zero-Shot Relation Extraction (DocZSRE) aims to predict unseen relation labels in text documents without prior training on specific relations. Existing approaches rely on Large Language Models (LLMs) to generate synthetic data for unseen labels, which poses challenges for low-resource languages like Malaysian English. These challenges include the incorporation of local linguistic nuances and the risk of factual inaccuracies in LLM-generated data. This paper introduces Document-Level Zero-Shot Relation Extraction with Entity Side Information (DocZSRE-SI) to address limitations in the existing DocZSRE approach. The DocZSRE-SI framework leverages Entity Side Information, such as Entity Mention Descriptions and Entity Mention Hypernyms, to perform ZSRE without depending on LLM-generated synthetic data. The proposed low-complexity model achieves an average improvement of 11.6% in the macro F1-Score compared to baseline models and existing benchmarks. By utilizing Entity Side Information, DocZSRE-SI offers a robust and efficient alternative to error-prone, LLM-based methods, demonstrating significant advancements in handling low-resource languages and linguistic diversity in relation extraction tasks. This research provides a scalable and reliable solution for ZSRE, particularly in contexts like Malaysian English news articles, where traditional LLM-based approaches fall short.

</details>


### [102] [Towards Comprehensive Semantic Speech Embeddings for Chinese Dialects](https://arxiv.org/abs/2601.07274)
*Kalvin Chang,Yiwen Shao,Jiahong Li,Dong Yu*

Main category: cs.CL

TL;DR: 该论文提出通过仅使用ASR数据训练语音编码器，实现中文方言与普通话之间的跨方言语义对齐，为方言到普通话的语音大语言模型奠定基础。


<details>
  <summary>Details</summary>
Motivation: 中文方言拥有数亿使用者，但在语音和语言技术方面落后于普通话。由于大多数方言主要是口语形式，因此方言到普通话的语音大语言模型比方言大语言模型更实用。构建这样的模型需要实现中文方言与普通话之间的跨方言语义对齐。

Method: 通过仅使用自动语音识别（ASR）数据训练语音编码器，实现跨方言语义对齐。作者还贡献了一个新的中文方言口语基准数据集，并采用语音到语音检索作为评估方法。

Result: 训练出的语音编码器在中文方言ASR任务上达到最先进性能，同时在新的中文方言口语基准数据集上通过语音到语音检索验证了跨方言语义对齐的有效性。

Conclusion: 该研究为未来中文方言语音大语言模型的发展奠定了基础，包括贡献的方言基准数据集、语义对齐的语音表示以及语音到语音检索评估方法。所有资源已在GitHub上开源。

Abstract: Despite having hundreds of millions of speakers, Chinese dialects lag behind Mandarin in speech and language technologies. Most varieties are primarily spoken, making dialect-to-Mandarin speech-LLMs (large language models) more practical than dialect LLMs. Building dialect-to-Mandarin speech-LLMs requires speech representations with cross-dialect semantic alignment between Chinese dialects and Mandarin. In this paper, we achieve such a cross-dialect semantic alignment by training a speech encoder with ASR (automatic speech recognition)-only data, as demonstrated by speech-to-speech retrieval on a new benchmark of spoken Chinese varieties that we contribute. Our speech encoder further demonstrates state-of-the-art ASR performance on Chinese dialects. Together, our Chinese dialect benchmark, semantically aligned speech representations, and speech-to-speech retrieval evaluation lay the groundwork for future Chinese dialect speech-LLMs. We release the benchmark at https://github.com/kalvinchang/yubao.

</details>


### [103] [ReasonTabQA: A Comprehensive Benchmark for Table Question Answering from Real World Industrial Scenarios](https://arxiv.org/abs/2601.07280)
*Changzai Pan,Jie Zhang,Kaiwen Wei,Chenshuo Pan,Yu Zhao,Jingwang Huang,Jian Yang,Zhenhe Wu,Haoyang Zeng,Xiaoyan Gu,Weichao Sun,Yanbo Zhai,Yujie Mao,Zhuoru Jiang,Jiang Zhong,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 提出了ReasonTabQA工业级表格问答基准和TabCodeRL强化学习方法，解决现有基准忽略工业场景多表、嵌套表头、大规模等复杂性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有表格问答基准未能充分反映工业场景的复杂性，如多表结构、嵌套表头和大规模数据，这些场景需要深度结构化推理，而当前方法对此处理不足。

Method: 1) 构建ReasonTabQA大规模双语基准，包含1932个表格覆盖30个工业领域；2) 提出TabCodeRL强化学习方法，利用表格感知的可验证奖励来引导逻辑推理路径生成。

Result: TabCodeRL在开源LLMs上带来显著性能提升，但在ReasonTabQA上的持续性能差距突显了真实工业表格问答的固有复杂性。

Conclusion: 工业级表格问答具有显著挑战性，ReasonTabQA基准和TabCodeRL方法为这一领域提供了新的评估框架和解决方案，但仍有改进空间。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly catalyzed table-based question answering (TableQA). However, existing TableQA benchmarks often overlook the intricacies of industrial scenarios, which are characterized by multi-table structures, nested headers, and massive scales. These environments demand robust table reasoning through deep structured inference, presenting a significant challenge that remains inadequately addressed by current methodologies. To bridge this gap, we present ReasonTabQA, a large-scale bilingual benchmark encompassing 1,932 tables across 30 industry domains such as energy and automotive. ReasonTabQA provides high-quality annotations for both final answers and explicit reasoning chains, supporting both thinking and no-thinking paradigms. Furthermore, we introduce TabCodeRL, a reinforcement learning method that leverages table-aware verifiable rewards to guide the generation of logical reasoning paths. Extensive experiments on ReasonTabQA and 4 TableQA datasets demonstrate that while TabCodeRL yields substantial performance gains on open-source LLMs, the persistent performance gap on ReasonTabQA underscores the inherent complexity of real-world industrial TableQA.

</details>


### [104] [PsyCLIENT: Client Simulation via Conversational Trajectory Modeling for Trainee Practice and Model Evaluation in Mental Health Counseling](https://arxiv.org/abs/2601.07312)
*Huachuan Qiu,Zhaoming Chen,Yuqian Chen,Yuan Xie,Yu Lu,Zhenzhong Lan*

Main category: cs.CL

TL;DR: PsyCLIENT是一个基于对话轨迹建模的心理咨询客户模拟框架，通过结合真实世界轨迹、行为标签和内容约束来生成多样且真实的客户互动，并发布了首个中文客户资料数据集。


<details>
  <summary>Details</summary>
Motivation: 现有客户模拟方法存在三个关键问题：客户资料多样性和真实性有限、缺乏建模真实客户行为的理论框架、中文场景资源稀缺。这些问题限制了心理咨询培训和评估系统的效果。

Method: 提出基于对话轨迹建模的PsyCLIENT框架，将LLM生成条件限制在预定义的真实世界轨迹上，这些轨迹包含明确的行为标签和内容约束。同时创建了PsyCLIENT-CP数据集，涵盖60个不同的心理咨询主题。

Result: 专业心理咨询师的综合评估显示，PsyCLIENT在真实性和培训效果上显著优于基线方法。模拟客户几乎无法与真实客户区分，在辨别任务中达到约95%的专家混淆率。

Conclusion: 对话轨迹建模有效弥合了理论客户资料与动态真实模拟之间的差距，为心理健康教育和研究提供了稳健解决方案。代码和数据将开源以促进心理健康咨询领域的研究。

Abstract: LLM-based client simulation has emerged as a promising tool for training novice counselors and evaluating automated counseling systems. However, existing client simulation approaches face three key challenges: (1) limited diversity and realism in client profiles, (2) the lack of a principled framework for modeling realistic client behaviors, and (3) a scarcity in Chinese-language settings. To address these limitations, we propose PsyCLIENT, a novel simulation framework grounded in conversational trajectory modeling. By conditioning LLM generation on predefined real-world trajectories that incorporate explicit behavior labels and content constraints, our approach ensures diverse and realistic interactions. We further introduce PsyCLIENT-CP, the first open-source Chinese client profile dataset, covering 60 distinct counseling topics. Comprehensive evaluations involving licensed professional counselors demonstrate that PsyCLIENT significantly outperforms baselines in terms of authenticity and training effectiveness. Notably, the simulated clients are nearly indistinguishable from human clients, achieving an about 95\% expert confusion rate in discrimination tasks. These findings indicate that conversational trajectory modeling effectively bridges the gap between theoretical client profiles and dynamic, realistic simulations, offering a robust solution for mental health education and research. Code and data will be released to facilitate future research in mental health counseling.

</details>


### [105] [Mitrasamgraha: A Comprehensive Classical Sanskrit Machine Translation Dataset](https://arxiv.org/abs/2601.07314)
*Sebastian Nehrdich,David Allport,Sven Sellmer,Jivnesh Sandhan,Manoj Balaji Jagadeeshan,Pawan Goyal,Sujeet Kumar,Kurt Keutzer*

Main category: cs.CL

TL;DR: 本文介绍了Mitrasamgraha，一个高质量的梵语-英语机器翻译数据集，包含391,548个双语对，覆盖三千多年历史时期和广泛领域，用于研究复杂梵语文本的翻译挑战。


<details>
  <summary>Details</summary>
Motivation: 梵语文献包含诗歌语言、哲学概念、多层隐喻等复杂内容，以及sandhi、复合词、复杂形态等语言特征，现有公开资源严重不足，需要高质量数据集来研究这些挑战。

Method: 构建了Mitrasamgraha数据集，包含391,548个双语对，覆盖三千多年历史时期和多个领域，提供时间和领域标注，并创建了验证集和测试集。在数据集上对商业和开源模型进行基准测试，微调NLLB和Gemma模型。

Result: 数据集规模是之前最大梵语数据集Itihāsa的四倍多。实验显示微调后模型性能显著提升，但仍面临复杂复合词、哲学概念和多层隐喻的翻译挑战。分析了上下文学习对商业模型性能的影响。

Conclusion: Mitrasamgraha填补了梵语机器翻译资源空白，为研究领域和时间对翻译性能的影响提供了基础，展示了复杂梵语文本翻译的挑战和机遇。

Abstract: While machine translation is regarded as a "solved problem" for many high-resource languages, close analysis quickly reveals that this is not the case for content that shows challenges such as poetic language, philosophical concepts, multi-layered metaphorical expressions, and more. Sanskrit literature is a prime example of this, as it combines a large number of such challenges in addition to inherent linguistic features like sandhi, compounding, and heavy morphology, which further complicate NLP downstream tasks. It spans multiple millennia of text production time as well as a large breadth of different domains, ranging from ritual formulas via epic narratives, philosophical treatises, poetic verses up to scientific material. As of now, there is a strong lack of publicly available resources that cover these different domains and temporal layers of Sanskrit. We therefore introduce Mitrasamgraha, a high-quality Sanskrit-to-English machine translation dataset consisting of 391,548 bitext pairs, more than four times larger than the largest previously available Sanskrit dataset Itih=asa. It covers a time period of more than three millennia and a broad range of historical Sanskrit domains. In contrast to web-crawled datasets, the temporal and domain annotation of this dataset enables fine-grained study of domain and time period effects on MT performance. We also release a validation set consisting of 5,587 and a test set consisting of 5,552 post-corrected bitext pairs. We conduct experiments benchmarking commercial and open models on this dataset and fine-tune NLLB and Gemma models on the dataset, showing significant improvements, while still recognizing significant challenges in the translation of complex compounds, philosophical concepts, and multi-layered metaphors. We also analyze how in-context learning on this dataset impacts the performance of commercial models

</details>


### [106] [How to predict creativity ratings from written narratives: A comparison of co-occurrence and textual forma mentis networks](https://arxiv.org/abs/2601.07327)
*Roberto Passaro,Edith Haim,Massimo Stella*

Main category: cs.CL

TL;DR: 该教程论文提供了从短篇创意文本构建和分析语义网络的逐步工作流程，比较了两种文本到网络方法，并展示了如何用网络特征预测人类创造力评分。


<details>
  <summary>Details</summary>
Motivation: 为研究人员提供实用的网络方法指导，特别是在认知科学和创造力研究领域，帮助理解何时选择句法网络而非表面共现模型，并提供可复现的工作流程。

Method: 使用1029篇短篇小说语料库，介绍文本预处理、网络构建（词共现网络和文本心智形式网络）、特征提取（结构度量、扩散激活指数和情感分数），并应用回归模型预测创造力评分。

Result: TFMN在所有建模设置中始终优于共现网络（最佳MAE：TFMN为0.581，窗口大小为3的共现网络为0.592）。网络结构特征主导预测性能（TFMN MAE=0.591），情感特征表现较差（TFMN MAE=0.711），扩散激活措施贡献很小（TFMN MAE=0.788）。

Conclusion: 该论文为认知领域（如创造力研究）的网络方法应用提供了实用指导，展示了句法网络相对于表面共现模型的优势，并为新手提供了可访问的工作流程，同时为经验丰富的研究人员提供了方法学见解。

Abstract: This tutorial paper provides a step-by-step workflow for building and analysing semantic networks from short creative texts. We introduce and compare two widely used text-to-network approaches: word co-occurrence networks and textual forma mentis networks (TFMNs). We also demonstrate how they can be used in machine learning to predict human creativity ratings. Using a corpus of 1029 short stories, we guide readers through text preprocessing, network construction, feature extraction (structural measures, spreading-activation indices, and emotion scores), and application of regression models. We evaluate how network-construction choices influence both network topology and predictive performance. Across all modelling settings, TFMNs consistently outperformed co-occurrence networks through lower prediction errors (best MAE = 0.581 for TFMN, vs 0.592 for co-occurrence with window size 3). Network-structural features dominated predictive performance (MAE = 0.591 for TFMN), whereas emotion features performed worse (MAE = 0.711 for TFMN) and spreading-activation measures contributed little (MAE = 0.788 for TFMN). This paper offers practical guidance for researchers interested in applying network-based methods for cognitive fields like creativity research. we show when syntactic networks are preferable to surface co-occurrence models, and provide an open, reproducible workflow accessible to newcomers in the field, while also offering deeper methodological insight for experienced researchers.

</details>


### [107] [BayesRAG: Probabilistic Mutual Evidence Corroboration for Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2601.07329)
*Xuan Li,Yining Wang,Haocai Luo,Shengping Liu,Jerry Liang,Ying Fu,Weihuang,Jun Yu,Junnan Zhu*

Main category: cs.CL

TL;DR: BayesRAG提出了一种基于贝叶斯推理和Dempster-Shafer证据理论的多模态检索框架，通过建模跨模态一致性作为概率证据来改进检索置信度，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在处理视觉丰富文档时存在局限性，将文本和图像视为孤立的检索目标，仅依赖余弦相似度无法捕捉跨模态对齐和布局诱导的一致性所提供的语义增强。

Method: 基于贝叶斯推理和Dempster-Shafer证据理论，将跨模态检索结果的固有一致性建模为概率证据，计算多模态检索结果组合的后验关联概率，优先选择在语义和布局上相互佐证的文本-图像对。

Result: 在具有挑战性的多模态基准测试中，BayesRAG显著优于现有最先进方法，证明了其有效性。

Conclusion: 该研究建立了一种新的多模态检索融合范式，通过证据融合机制有效解决了异构模态的孤立问题，增强了检索结果的鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) has become a pivotal paradigm for Large Language Models (LLMs), yet current approaches struggle with visually rich documents by treating text and images as isolated retrieval targets. Existing methods relying solely on cosine similarity often fail to capture the semantic reinforcement provided by cross-modal alignment and layout-induced coherence. To address these limitations, we propose BayesRAG, a novel multimodal retrieval framework grounded in Bayesian inference and Dempster-Shafer evidence theory. Unlike traditional approaches that rank candidates strictly by similarity, BayesRAG models the intrinsic consistency of retrieved candidates across modalities as probabilistic evidence to refine retrieval confidence. Specifically, our method computes the posterior association probability for combinations of multimodal retrieval results, prioritizing text-image pairs that mutually corroborate each other in terms of both semantics and layout. Extensive experiments demonstrate that BayesRAG significantly outperforms state-of-the-art (SOTA) methods on challenging multimodal benchmarks. This study establishes a new paradigm for multimodal retrieval fusion that effectively resolves the isolation of heterogeneous modalities through an evidence fusion mechanism and enhances the robustness of retrieval outcomes. Our code is available at https://github.com/TioeAre/BayesRAG.

</details>


### [108] [Beyond Literal Mapping: Benchmarking and Improving Non-Literal Translation Evaluation](https://arxiv.org/abs/2601.07338)
*Yanzhi Tian,Cunxiang Wang,Zeming Liu,Heyan Huang,Wenbo Yu,Dawei Song,Jie Tang,Yuhang Guo*

Main category: cs.CL

TL;DR: 该论文针对非直译翻译场景中机器翻译评估指标不准确的问题，提出了MENT数据集和RATE评估框架，显著提升了翻译质量评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在机器翻译领域取得显著进展，但在处理社交媒体、文学等复杂领域的非直译表达时，现有翻译评估指标存在不准确的问题，需要系统研究这些指标的可靠性。

Method: 首先构建了专注于非直译翻译的元评估数据集MENT，包含四个非直译翻译领域和7,530个人工标注的翻译质量分数。然后提出了RATE框架，以反思核心代理为中心，动态调用专门子代理进行翻译评估。

Result: 实验结果显示传统MT指标存在不准确性，LLM-as-a-Judge方法存在知识截止和分数不一致问题。RATE框架相比现有指标至少提升了3.2个元分数，并在通用领域MT评估中表现出鲁棒性。

Conclusion: RATE框架有效解决了非直译翻译评估的挑战，为复杂翻译场景提供了更可靠的评估方法，相关代码和数据集已开源。

Abstract: Large Language Models (LLMs) have significantly advanced Machine Translation (MT), applying them to linguistically complex domains-such as Social Network Services, literature etc. In these scenarios, translations often require handling non-literal expressions, leading to the inaccuracy of MT metrics. To systematically investigate the reliability of MT metrics, we first curate a meta-evaluation dataset focused on non-literal translations, namely MENT. MENT encompasses four non-literal translation domains and features source sentences paired with translations from diverse MT systems, with 7,530 human-annotated scores on translation quality. Experimental results reveal the inaccuracies of traditional MT metrics and the limitations of LLM-as-a-Judge, particularly the knowledge cutoff and score inconsistency problem. To mitigate these limitations, we propose RATE, a novel agentic translation evaluation framework, centered by a reflective Core Agent that dynamically invokes specialized sub-agents. Experimental results indicate the efficacy of RATE, achieving an improvement of at least 3.2 meta score compared with current metrics. Further experiments demonstrate the robustness of RATE to general-domain MT evaluation. Code and dataset are available at: https://github.com/BITHLP/RATE.

</details>


### [109] [DiffER: Diffusion Entity-Relation Modeling for Reversal Curse in Diffusion Large Language Models](https://arxiv.org/abs/2601.07347)
*Shaokai He,Kaiwen Wei,Xinyi Zeng,Xiang Chen,Xue Yang,Zhenyang Li,Jiang Zhong,Yu Tian*

Main category: cs.CL

TL;DR: 扩散语言模型也存在"逆转诅咒"现象，本文提出DiffER方法通过实体感知训练和平衡数据构建来解决这一问题


<details>
  <summary>Details</summary>
Motivation: 研究发现扩散语言模型（DLLMs）尽管是双向训练的，仍然存在"逆转诅咒"现象，即模型在处理逻辑双向关系时表现出单向行为。作者旨在探究这一现象的根本原因并提出解决方案。

Method: 提出Diffusion Entity-Relation Modeling (DiffER)方法：1）引入整体实体掩码，通过单步预测完整实体来缓解实体碎片化；2）采用分布对称和关系增强的数据构建策略，减轻数据不对称和缺失关系问题。

Result: 大量实验证明，DiffER方法能有效缓解扩散语言模型中的"逆转诅咒"现象。

Conclusion: 本文不仅揭示了扩散语言模型存在"逆转诅咒"的原因，还提出了有效的解决方案，为未来研究提供了新视角。

Abstract: The "reversal curse" refers to the phenomenon where large language models (LLMs) exhibit predominantly unidirectional behavior when processing logically bidirectional relationships. Prior work attributed this to autoregressive training -- predicting the next token inherently favors left-to-right information flow over genuine bidirectional knowledge associations. However, we observe that Diffusion LLMs (DLLMs), despite being trained bidirectionally, also suffer from the reversal curse. To investigate the root causes, we conduct systematic experiments on DLLMs and identify three key reasons: 1) entity fragmentation during training, 2) data asymmetry, and 3) missing entity relations. Motivated by the analysis of these reasons, we propose Diffusion Entity-Relation Modeling (DiffER), which addresses the reversal curse through entity-aware training and balanced data construction. Specifically, DiffER introduces whole-entity masking, which mitigates entity fragmentation by predicting complete entities in a single step. DiffER further employs distribution-symmetric and relation-enhanced data construction strategies to alleviate data asymmetry and missing relations. Extensive experiments demonstrate that DiffER effectively alleviates the reversal curse in Diffusion LLMs, offering new perspectives for future research.

</details>


### [110] [Controlled Self-Evolution for Algorithmic Code Optimization](https://arxiv.org/abs/2601.07348)
*Tu Hu,Ronghao Chen,Shuo Zhang,Jianghao Yin,Mou Xiao Feng,Jingping Liu,Shaolei Zhang,Wenqi Jiang,Yuqi Fang,Sen Hu,Yi Xu,Huacan Wang*

Main category: cs.CL

TL;DR: 本文提出Controlled Self-Evolution (CSE)方法，通过多样化规划初始化、遗传进化和分层进化记忆三个组件，解决现有代码生成自进化方法探索效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自进化方法在代码生成中存在探索效率低的问题，无法在有限预算内发现更优复杂度的解决方案。这源于初始化偏差将进化困在较差解区域、缺乏反馈指导的随机操作、以及跨任务经验利用不足。

Method: CSE包含三个核心组件：1) 多样化规划初始化生成结构不同的算法策略以广泛覆盖解空间；2) 遗传进化用反馈指导机制替代随机操作，实现有针对性的变异和组合交叉；3) 分层进化记忆在任务间和任务内两个层面捕获成功和失败经验。

Result: 在EffiBench-X上的实验表明，CSE在不同LLM骨干网络上始终优于所有基线方法。CSE从早期进化代就展现出更高效率，并在整个进化过程中保持持续改进。

Conclusion: CSE通过系统化的控制机制有效解决了自进化代码生成中的探索效率瓶颈，实现了更高效和持续的改进。

Abstract: Self-evolution methods enhance code generation through iterative "generate-verify-refine" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks.To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels.Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.

</details>


### [111] [Reward Modeling from Natural Language Human Feedback](https://arxiv.org/abs/2601.07349)
*Zongqi Wang,Rui Wang,Yuchuan Wu,Yiyao Yu,Pinyi Zhang,Shaoning Sun,Yujiu Yang,Yongbin Li*

Main category: cs.CL

TL;DR: 该论文提出RM-NLHF方法，使用自然语言反馈而非二元偏好标签来训练生成式奖励模型，解决传统RLVR方法中模型可能通过猜测而非合理推理获得正确标签的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于二元偏好标签的RLVR方法存在缺陷：生成式奖励模型可能通过猜测获得正确标签，而非基于合理的推理链，这导致奖励信号包含大量噪声，影响强化学习效果。

Method: 提出RM-NLHF方法：1) 使用自然语言反馈计算GRM生成评论与人类评论的相似度作为训练奖励；2) 引入MetaRM元奖励模型，从含人类评论的数据学习预测过程奖励，并泛化到无人类评论的数据。

Result: 在多个基准测试中，该方法持续优于仅使用结果监督的最先进GRM，证实了自然语言反馈相对于二元人类反馈的优越性。

Conclusion: 使用自然语言反馈而非二元偏好标签能提供更准确的奖励信号，有效缓解二元任务中解决方案空间有限的问题，提升强化学习效果。

Abstract: Reinforcement Learning with Verifiable reward (RLVR) on preference data has become the mainstream approach for training Generative Reward Models (GRMs). Typically in pairwise rewarding tasks, GRMs generate reasoning chains ending with critiques and preference labels, and RLVR then relies on the correctness of the preference labels as the training reward. However, in this paper, we demonstrate that such binary classification tasks make GRMs susceptible to guessing correct outcomes without sound critiques. Consequently, these spurious successes introduce substantial noise into the reward signal, thereby impairing the effectiveness of reinforcement learning. To address this issue, we propose Reward Modeling from Natural Language Human Feedback (RM-NLHF), which leverages natural language feedback to obtain process reward signals, thereby mitigating the problem of limited solution space inherent in binary tasks. Specifically, we compute the similarity between GRM-generated and human critiques as the training reward, which provides more accurate reward signals than outcome-only supervision. Additionally, considering that human critiques are difficult to scale up, we introduce Meta Reward Model (MetaRM) which learns to predict process reward from datasets with human critiques and then generalizes to data without human critiques. Experiments on multiple benchmarks demonstrate that our method consistently outperforms state-of-the-art GRMs trained with outcome-only reward, confirming the superiority of integrating natural language over binary human feedback as supervision.

</details>


### [112] [Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models](https://arxiv.org/abs/2601.07351)
*Linhao Zhong,Linyu Wu,Bozhen Fang,Tianjian Feng,Chenchen Jing,Wen Wang,Jiaheng Zhang,Hao Chen,Chunhua Shen*

Main category: cs.CL

TL;DR: EvoToken-DLM是一种新型扩散语言模型，用演化软token分布替代硬二值掩码，支持可修订的解码，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型依赖硬二值掩码和离散token分配，这阻碍了早期决策的修订，并且未能充分利用中间概率表示。

Method: 提出EvoToken-DLM，用演化软token分布替代硬二值掩码，实现从掩码状态到离散输出的渐进过渡；引入连续轨迹监督来对齐训练目标与迭代概率更新。

Result: 在多个基准测试上的广泛实验表明，EvoToken-DLM始终实现卓越性能，优于强大的基于扩散和掩码的DLM基线。

Conclusion: EvoToken-DLM通过演化软token分布和连续轨迹监督，为扩散语言建模提供了更灵活、可修订的解码方法，显著提升了性能。

Abstract: Diffusion Language Models (DLMs) offer a promising alternative for language modeling by enabling parallel decoding through iterative refinement. However, most DLMs rely on hard binary masking and discrete token assignments, which hinder the revision of early decisions and underutilize intermediate probabilistic representations. In this paper, we propose EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions. EvoToken-DLM enables a progressive transition from masked states to discrete outputs, supporting revisable decoding. To effectively support this evolution, we introduce continuous trajectory supervision, which aligns training objectives with iterative probabilistic updates. Extensive experiments across multiple benchmarks show that EvoToken-DLM consistently achieves superior performance, outperforming strong diffusion-based and masked DLM baselines. Project webpage: https://aim-uofa.github.io/EvoTokenDLM.

</details>


### [113] [TALON: Confidence-Aware Speculative Decoding with Adaptive Token Trees](https://arxiv.org/abs/2601.07353)
*Tianyu Liu,Qitan Lv,Yuhao Shen,Xiao Sun,Xiaoyan Sun*

Main category: cs.CL

TL;DR: TALON是一个无需训练的预算驱动自适应树扩展框架，用于改进推测解码中的树结构生成，通过动态调整树形结构实现更高效的并行推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有的树结构推测解码方法通常构建固定宽度和深度的草稿树，无法根据令牌和上下文的难度进行自适应调整。这导致草稿模型无法在困难令牌上提前停止，也无法在简单令牌上扩展生成，限制了推理效率。

Method: TALON采用无需训练的预算驱动自适应树扩展框架，迭代构建草稿树直到达到固定的令牌预算。它使用混合扩展策略，自适应地将节点预算分配到草稿树的每一层，形成针对确定性上下文的"深而窄"树形和针对不确定分支的"浅而宽"树形。

Result: 在5个模型和6个数据集上的广泛实验表明，TALON始终优于最先进的EAGLE-3方法，相比自回归解码实现了高达5.16倍的端到端加速。

Conclusion: TALON通过自适应树扩展策略有效优化了探索宽度和生成深度之间的权衡，显著提升了LLM推理效率，且无需额外训练即可集成到现有树结构方法中。

Abstract: Speculative decoding (SD) has become a standard technique for accelerating LLM inference without sacrificing output quality. Recent advances in speculative decoding have shifted from sequential chain-based drafting to tree-structured generation, where the draft model constructs a tree of candidate tokens to explore multiple possible drafts in parallel. However, existing tree-based SD methods typically build a fixed-width, fixed-depth draft tree, which fails to adapt to the varying difficulty of tokens and contexts. As a result, the draft model cannot dynamically adjust the tree structure to early stop on difficult tokens and extend generation for simple ones. To address these challenges, we introduce TALON, a training-free, budget-driven adaptive tree expansion framework that can be plugged into existing tree-based methods. Unlike static methods, TALON constructs the draft tree iteratively until a fixed token budget is met, using a hybrid expansion strategy that adaptively allocates the node budget to each layer of the draft tree. This framework naturally shapes the draft tree into a "deep-and-narrow" form for deterministic contexts and a "shallow-and-wide" form for uncertain branches, effectively optimizing the trade-off between exploration width and generation depth under a given budget. Extensive experiments across 5 models and 6 datasets demonstrate that TALON consistently outperforms state-of-the-art EAGLE-3, achieving up to 5.16x end-to-end speedup over auto-regressive decoding.

</details>


### [114] [Semantic Compression of LLM Instructions via Symbolic Metalanguages](https://arxiv.org/abs/2601.07354)
*Ernst van Gassen*

Main category: cs.CL

TL;DR: MetaGlyph是一种使用数学符号（如∈、⇒）而非自然语言来压缩提示词的符号语言，能在保持语义等效的同时显著减少token使用量。


<details>
  <summary>Details</summary>
Motivation: 当前提示词通常使用冗长的自然语言描述，导致token消耗大、成本高、延迟增加。需要一种更高效的指令编码方式，利用模型已从训练数据中理解的数学符号作为"指令捷径"。

Method: 设计MetaGlyph符号语言，使用∈（成员关系）、⇒（蕴含）等数学符号编码指令。在8个不同规模和类型的模型上进行评估，包括3B-1T参数规模的模型，以及开源本地部署和专有API模型。

Result: MetaGlyph实现62-81%的token减少。不同模型表现差异大：Gemini 2.5 Flash在选择性任务上达到75%语义等效，Kimi K2的⇒符号保真度达98.1%，GPT-5.2 Chat的∈符号保真度最高（91.3%）。中型开源模型（7B-12B）符号保真度接近零，显示U型关系。

Conclusion: 数学符号可作为有效的提示词压缩机制，但效果高度依赖模型规模和能力。大模型能很好理解符号指令，中型模型因指令微调偏见而表现差，表明足够规模能克服这种偏见。MetaGlyph为API部署节省成本，为本地部署减少延迟和内存压力。

Abstract: We introduce MetaGlyph, a symbolic language for compressing prompts by encoding instructions as mathematical symbols rather than prose. Unlike systems requiring explicit decoding rules, MetaGlyph uses symbols like $\in$ (membership) and $\Rightarrow$ (implication) that models already understand from their training data. We test whether these symbols work as ''instruction shortcuts'' that models can interpret without additional teaching.
  We evaluate eight models across two dimensions relevant to practitioners: scale (3B-1T parameters) and accessibility (open-source for local deployment vs. proprietary APIs). MetaGlyph achieves 62-81% token reduction across all task types. For API-based deployments, this translates directly to cost savings; for local deployments, it reduces latency and memory pressure.
  Results vary by model. Gemini 2.5 Flash achieves 75% semantic equivalence between symbolic and prose instructions on selection tasks, with 49.9% membership operator fidelity. Kimi K2 reaches 98.1% fidelity for implication ($\Rightarrow$) and achieves perfect (100%) accuracy on selection tasks with symbolic prompts. GPT-5.2 Chat shows the highest membership fidelity observed (91.3%), though with variable parse success across task types. Claude Haiku 4.5 achieves 100% parse success with 26% membership fidelity. Among mid-sized models, Qwen 2.5 7B shows 62% equivalence on extraction tasks. Mid-sized open-source models (7B-12B) show near-zero operator fidelity, suggesting a U-shaped relationship where sufficient scale overcomes instruction-tuning biases.

</details>


### [115] [Interpretable Text Classification Applied to the Detection of LLM-generated Creative Writing](https://arxiv.org/abs/2601.07368)
*Minerva Suvanto,Andrea McGlinchey,Mattias Wahde,Peter J Barclay*

Main category: cs.CL

TL;DR: 人类难以区分AI生成与人类创作的小说文本（准确率接近随机），但机器学习模型能达到93-98%的准确率，即使仅使用短文本和单字符特征。可解释线性分类器揭示AI文本倾向于使用更多同义词等特征。


<details>
  <summary>Details</summary>
Motivation: 研究如何区分人类创作的小说文本与大型语言模型生成的类似文本，探索人类与机器在识别AI生成内容方面的能力差异，并理解机器学习模型高准确率背后的原因。

Method: 使用多种机器学习模型进行二元分类任务，特别采用可解释的线性分类器来分析特征重要性。使用短文本样本和单字符（unigram）特征，识别区分人类与AI生成文本的关键特征。

Result: 人类观察者在二元分类任务中表现不佳（接近随机水平），而机器学习模型在未见测试集上达到0.93-0.98的准确率。可解释分类器识别出AI生成文本的关键特征：使用更多同义词、时间漂移、美式表达、外语使用和口语化表达。

Conclusion: 机器学习模型能有效区分人类创作与AI生成的小说文本，准确率远高于人类。AI文本的特征模式（如同义词多样性）使其容易被机器学习检测但人类难以察觉。这种基于多种特征的分类方法具有鲁棒性，难以被恶意规避。

Abstract: We consider the problem of distinguishing human-written creative fiction (excerpts from novels) from similar text generated by an LLM. Our results show that, while human observers perform poorly (near chance levels) on this binary classification task, a variety of machine-learning models achieve accuracy in the range 0.93 - 0.98 over a previously unseen test set, even using only short samples and single-token (unigram) features. We therefore employ an inherently interpretable (linear) classifier (with a test accuracy of 0.98), in order to elucidate the underlying reasons for this high accuracy. In our analysis, we identify specific unigram features indicative of LLM-generated text, one of the most important being that the LLM tends to use a larger variety of synonyms, thereby skewing the probability distributions in a manner that is easy to detect for a machine learning classifier, yet very difficult for a human observer. Four additional explanation categories were also identified, namely, temporal drift, Americanisms, foreign language usage, and colloquialisms. As identification of the AI-generated text depends on a constellation of such features, the classification appears robust, and therefore not easy to circumvent by malicious actors intent on misrepresenting AI-generated text as human work.

</details>


### [116] [Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models](https://arxiv.org/abs/2601.07372)
*Xin Cheng,Wangding Zeng,Damai Dai,Qinyu Chen,Bingxuan Wang,Zhenda Xie,Kezhao Huang,Xingkai Yu,Zhewen Hao,Yukun Li,Han Zhang,Huishuai Zhang,Dongyan Zhao,Wenfeng Liang*

Main category: cs.CL

TL;DR: 提出Engram模块，将条件记忆作为稀疏建模新维度，通过N-gram嵌入实现O(1)查找，与MoE形成计算与记忆的优化平衡，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer缺乏原生知识查找机制，只能通过计算模拟检索，效率低下。需要引入条件记忆作为MoE的补充稀疏维度。

Method: 提出Engram模块，基于经典N-gram嵌入实现O(1)查找；建立稀疏分配问题，发现U型缩放规律；将Engram扩展到27B参数规模。

Result: 在知识检索（MMLU +3.4）、通用推理（BBH +5.0）、代码/数学（HumanEval +3.0）和长上下文检索（Multi-Query NIAH: 84.2→97.0）上均显著优于基线；机制分析显示Engram减轻了早期层的静态重建负担，释放注意力容量处理全局上下文。

Conclusion: 条件记忆是下一代稀疏模型不可或缺的建模原语，Engram通过确定性寻址实现基础设施感知效率，为模型设计开辟新方向。

Abstract: While Mixture-of-Experts (MoE) scales capacity via conditional computation, Transformers lack a native primitive for knowledge lookup, forcing them to inefficiently simulate retrieval through computation. To address this, we introduce conditional memory as a complementary sparsity axis, instantiated via Engram, a module that modernizes classic $N$-gram embedding for O(1) lookup. By formulating the Sparsity Allocation problem, we uncover a U-shaped scaling law that optimizes the trade-off between neural computation (MoE) and static memory (Engram). Guided by this law, we scale Engram to 27B parameters, achieving superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline. Most notably, while the memory module is expected to aid knowledge retrieval (e.g., MMLU +3.4; CMMLU +4.0), we observe even larger gains in general reasoning (e.g., BBH +5.0; ARC-Challenge +3.7) and code/math domains~(HumanEval +3.0; MATH +2.4). Mechanistic analyses reveal that Engram relieves the backbone's early layers from static reconstruction, effectively deepening the network for complex reasoning. Furthermore, by delegating local dependencies to lookups, it frees up attention capacity for global context, substantially boosting long-context retrieval (e.g., Multi-Query NIAH: 84.2 to 97.0). Finally, Engram establishes infrastructure-aware efficiency: its deterministic addressing enables runtime prefetching from host memory, incurring negligible overhead. We envision conditional memory as an indispensable modeling primitive for next-generation sparse models.

</details>


### [117] [GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on OpenStreetMap](https://arxiv.org/abs/2601.07375)
*Farzad Shami,Subhrasankha Dey,Nico Van de Weghe,Henrikki Tenkanen*

Main category: cs.CL

TL;DR: GROKE是一个基于LLM的无视觉分层框架，使用OpenStreetMap数据评估导航指令质量，无需训练且避免视觉模拟器依赖


<details>
  <summary>Details</summary>
Motivation: 传统基于参考的指标（如BLEU、ROUGE）无法捕捉导航指令的功能效用；现有VLN智能体作为评估器依赖高保真视觉模拟器，存在许可限制、计算成本高和感知误差问题

Method: 提出GROKE框架：基于OpenStreetMap数据的无视觉、免训练分层LLM架构，使用结构化JSON和文本格式表示空间信息，结合子指令规划和拓扑图导航

Result: 结构化JSON和文本格式的空间表示显著优于基于网格和视觉图的表示；在Map2Seq数据集上，导航错误比启发式和采样基线减少68.5%；通过执行成功率、轨迹保真度和决策模式作为功能可导航性代理指标

Conclusion: GROKE建立了一个可扩展且可解释的评估范式，无需视觉依赖，为导航指令评估提供了新的解决方案

Abstract: The evaluation of navigation instructions remains a persistent challenge in Vision-and-Language Navigation (VLN) research. Traditional reference-based metrics such as BLEU and ROUGE fail to capture the functional utility of spatial directives, specifically whether an instruction successfully guides a navigator to the intended destination. Although existing VLN agents could serve as evaluators, their reliance on high-fidelity visual simulators introduces licensing constraints and computational costs, and perception errors further confound linguistic quality assessment. This paper introduces GROKE(Graph-based Reasoning over OSM Knowledge for instruction Evaluation), a vision-free training-free hierarchical LLM-based framework for evaluating navigation instructions using OpenStreetMap data. Through systematic ablation studies, we demonstrate that structured JSON and textual formats for spatial information substantially outperform grid-based and visual graph representations. Our hierarchical architecture combines sub-instruction planning with topological graph navigation, reducing navigation error by 68.5% compared to heuristic and sampling baselines on the Map2Seq dataset. The agent's execution success, trajectory fidelity, and decision patterns serve as proxy metrics for functional navigability given OSM-visible landmarks and topology, establishing a scalable and interpretable evaluation paradigm without visual dependencies. Code and data are available at https://anonymous.4open.science/r/groke.

</details>


### [118] [Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning](https://arxiv.org/abs/2601.07408)
*Ziheng Li,Liu Kang,Feng Xiao,Luxi Xing,Qingyi Si,Zhuoran Li,Weikang Gong,Deqing Yang,Yanghua Xiao,Hongcheng Guo*

Main category: cs.CL

TL;DR: 提出OAR方法，通过细粒度信用分配改进GRPO，使用两种策略（OAR-P和OAR-G）重新分配优势值，显著提升数学推理性能。


<details>
  <summary>Details</summary>
Motivation: 标准GRPO采用粗粒度的信用分配机制，将组级奖励均匀传播给序列中的每个token，忽略了各个推理步骤的不同贡献。需要更精细的信用分配方法来区分不同token对最终答案的影响程度。

Method: 提出Outcome-grounded Advantage Reshaping (OAR)方法，包含两种策略：1) OAR-P通过反事实token扰动估计结果敏感性；2) OAR-G使用输入梯度敏感性代理单次反向传播近似影响信号。采用保守的双层优势重塑方案，抑制低影响token并增强关键token。

Result: 在广泛的数学推理基准测试中，OAR-P设定了性能上限，OAR-G以可忽略的计算开销实现了可比的增益，两者都显著优于强GRPO基线，推动了无critic LLM推理的边界。

Conclusion: OAR通过细粒度信用分配机制有效解决了GRPO中token贡献不均的问题，为无critic强化学习在推理任务中提供了更精确的优化方法，OAR-G在性能和效率之间取得了良好平衡。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a promising critic-free reinforcement learning paradigm for reasoning tasks. However, standard GRPO employs a coarse-grained credit assignment mechanism that propagates group-level rewards uniformly to to every token in a sequence, neglecting the varying contribution of individual reasoning steps. We address this limitation by introducing Outcome-grounded Advantage Reshaping (OAR), a fine-grained credit assignment mechanism that redistributes advantages based on how much each token influences the model's final answer. We instantiate OAR via two complementary strategies: (1) OAR-P, which estimates outcome sensitivity through counterfactual token perturbations, serving as a high-fidelity attribution signal; (2) OAR-G, which uses an input-gradient sensitivity proxy to approximate the influence signal with a single backward pass. These importance signals are integrated with a conservative Bi-Level advantage reshaping scheme that suppresses low-impact tokens and boosts pivotal ones while preserving the overall advantage mass. Empirical results on extensive mathematical reasoning benchmarks demonstrate that while OAR-P sets the performance upper bound, OAR-G achieves comparable gains with negligible computational overhead, both significantly outperforming a strong GRPO baseline, pushing the boundaries of critic-free LLM reasoning.

</details>


### [119] [Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations](https://arxiv.org/abs/2601.07422)
*Wen Luo,Guangyue Peng,Wei Li,Shaohang Wei,Feifan Song,Liang Wang,Nan Yang,Xingxing Zhang,Jing Jin,Furu Wei,Houfeng Wang*

Main category: cs.CL

TL;DR: LLM真实性信号源于两个信息通路：问题锚定通路（依赖问答信息流）和答案锚定通路（基于生成答案的自包含证据），这些通路与模型知识边界相关，可用于提升幻觉检测性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能力强大，但经常产生幻觉。先前研究表明其内部状态编码了丰富的真实性信号，但这些信号的起源和机制仍不清楚。本文旨在揭示LLM内部如何编码真实性信号。

Method: 通过注意力敲除和token修补技术验证并分离两个信息通路：问题锚定通路（依赖问答信息流）和答案锚定通路（基于生成答案的自包含证据）。进一步分析这两个机制的特性及其与知识边界的关系。

Result: 研究发现两个通路与LLM知识边界密切相关，内部表示能够区分这两种机制。基于这些发现，提出了两个应用来增强幻觉检测性能。

Conclusion: 该工作为理解LLM内部如何编码真实性提供了新视角，为构建更可靠、更具自我意识的生成系统指明了方向。

Abstract: Despite their impressive capabilities, large language models (LLMs) frequently generate hallucinations. Previous work shows that their internal states encode rich signals of truthfulness, yet the origins and mechanisms of these signals remain unclear. In this paper, we demonstrate that truthfulness cues arise from two distinct information pathways: (1) a Question-Anchored pathway that depends on question-answer information flow, and (2) an Answer-Anchored pathway that derives self-contained evidence from the generated answer itself. First, we validate and disentangle these pathways through attention knockout and token patching. Afterwards, we uncover notable and intriguing properties of these two mechanisms. Further experiments reveal that (1) the two mechanisms are closely associated with LLM knowledge boundaries; and (2) internal representations are aware of their distinctions. Finally, building on these insightful findings, two applications are proposed to enhance hallucination detection performance. Overall, our work provides new insight into how LLMs internally encode truthfulness, offering directions for more reliable and self-aware generative systems.

</details>


### [120] [SAD: A Large-Scale Strategic Argumentative Dialogue Dataset](https://arxiv.org/abs/2601.07423)
*Yongkang Liu,Jiayang Yu,Mingyang Wang,Yiqun Zhang,Ercong Nie,Shi Feng,Daling Wang,Kaisong Song,Hinrich Schütze*

Main category: cs.CL

TL;DR: SAD是首个大规模战略性论证对话数据集，包含39.2万条示例，标注了五种论证策略，支持多轮对话建模。


<details>
  <summary>Details</summary>
Motivation: 现有论证语料库主要关注非交互式单轮设置，而实际论证通常是多轮对话，说话者会采用多种论证策略来增强说服力。需要支持更深层次的论证对话建模。

Method: 基于论证理论构建SAD数据集，为每个话语标注五种策略类型（允许多策略），要求模型基于对话历史、指定立场和目标论证策略生成上下文适当的论证。

Result: 创建了包含392,822个示例的大规模战略性论证对话数据集，在SAD上对多种预训练生成模型进行了基准测试，并深入分析了论证中的策略使用模式。

Conclusion: SAD数据集填补了多轮战略性论证对话建模的空白，为研究论证策略和对话生成提供了重要资源，推动了更真实、更具说服力的论证对话系统发展。

Abstract: Argumentation generation has attracted substantial research interest due to its central role in human reasoning and decision-making. However, most existing argumentative corpora focus on non-interactive, single-turn settings, either generating arguments from a given topic or refuting an existing argument. In practice, however, argumentation is often realized as multi-turn dialogue, where speakers defend their stances and employ diverse argumentative strategies to strengthen persuasiveness. To support deeper modeling of argumentation dialogue, we present the first large-scale \textbf{S}trategic \textbf{A}rgumentative \textbf{D}ialogue dataset, SAD, consisting of 392,822 examples. Grounded in argumentation theories, we annotate each utterance with five strategy types, allowing multiple strategies per utterance. Unlike prior datasets, SAD requires models to generate contextually appropriate arguments conditioned on the dialogue history, a specified stance on the topic, and targeted argumentation strategies. We further benchmark a range of pretrained generative models on SAD and present in-depth analysis of strategy usage patterns in argumentation.

</details>


### [121] [KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning](https://arxiv.org/abs/2601.07430)
*Qitan Lv,Tianyu Liu,Qiaosheng Zhang,Xingcheng Xu,Chaochao Lu*

Main category: cs.CL

TL;DR: KALE是一个利用知识图谱增强大语言模型知识操纵能力的后训练框架，通过知识引导的数据合成和知识感知微调，显著提升模型在知识推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法存在"已知但错误"现象，即模型明明拥有相关知识却无法正确运用。需要提升LLMs的知识操纵能力（回忆、推理和迁移相关知识）。

Method: 1) 知识引导数据合成：从知识图谱中提取多跳推理路径，为问答对生成高质量推理依据；2) 知识感知微调：通过最小化有/无推理依据预测之间的KL散度，内化推理过程。

Result: 在8个流行基准测试和6个不同LLM上的实验表明，KALE最高提升准确率11.72%，平均提升4.18%，有效增强了模型的知识操纵能力。

Conclusion: KALE框架通过知识图谱生成高质量推理依据并进行知识感知微调，成功解决了LLMs的"已知但错误"问题，显著提升了知识操纵能力。

Abstract: Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation-the ability to effectively recall, reason, and transfer relevant knowledge-remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs' knowledge manipulation ability. However, we observe that SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware LEarning)-a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs' knowledge manipulation ability. Specifically, KALE first introduces a Knowledge-Induced (KI) data synthesis method that efficiently extracts multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm that enhances knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%.

</details>


### [122] [Judging Against the Reference: Uncovering Knowledge-Driven Failures in LLM-Judges on QA Evaluation](https://arxiv.org/abs/2601.07506)
*Dongryeol Lee,Yerin Hwang,Taegwan Kang,Minwoo Lee,Younhyung Chae,Kyomin Jung*

Main category: cs.CL

TL;DR: LLM作为自动评估器时，当提供的参考答案与其内部知识冲突时，评估可靠性会显著下降，因为模型过度依赖参数知识而忽视给定参考。


<details>
  <summary>Details</summary>
Motivation: 研究LLM作为自动评估器在问答等任务中的可靠性，特别是当提供的参考答案与模型内部知识冲突时，评估结果是否可信。

Method: 提出受控的交换参考问答框架，通过将参考答案替换为错误实体来制造参考-信念冲突，构建原始和交换参考的多样化配对及相应候选答案。

Result: 在交换参考条件下，各种评估模型的评分可靠性急剧下降；这种脆弱性源于评估模型过度依赖参数知识，在冲突时忽视给定参考；常见提示缓解策略无法解决此问题。

Conclusion: LLM作为评估器存在根本性限制，需要开发强制更强参考依从性的基于参考的评估协议。

Abstract: While large language models (LLMs) are increasingly used as automatic judges for question answering (QA) and other reference-conditioned evaluation tasks, little is known about their ability to adhere to a provided reference. We identify a critical failure mode of such reference-based LLM QA evaluation: when the provided reference conflicts with the judge model's parametric knowledge, the resulting scores become unreliable, substantially degrading evaluation fidelity. To study this phenomenon systematically, we introduce a controlled swapped-reference QA framework that induces reference-belief conflicts. Specifically, we replace the reference answer with an incorrect entity and construct diverse pairings of original and swapped references with correspondingly aligned candidate answers. Surprisingly, grading reliability drops sharply under swapped references across a broad set of judge models. We empirically show that this vulnerability is driven by judges' over-reliance on parametric knowledge, leading judges to disregard the given reference under conflict. Finally, we find that this failure persists under common prompt-based mitigation strategies, highlighting a fundamental limitation of LLM-as-a-judge evaluation and motivating reference-based protocols that enforce stronger adherence to the provided reference.

</details>


### [123] [High-Rank Structured Modulation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2601.07507)
*Yongkang Liu,Xing Li,Mengjie Zhao,Shanru Zhang,Zijing Wang,Qian Li,Shi Feng,Feiliang Ren,Daling Wang,Hinrich Schütze*

Main category: cs.CL

TL;DR: SMoA是一种高效的高秩结构化调制适配器，通过多子空间选择性放大/抑制原始权重特征，以更少可训练参数实现更高秩表示，超越LoRA及其变体在10个任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 随着模型参数增加，参数高效微调成为主流。LoRA使用低秩更新模拟全参数微调，但降低秩会限制表示能力。需要一种方法既能减少可训练参数，又能保持高秩表示能力。

Method: 提出SMoA（结构化调制适配器）：冻结原始预训练权重，通过多子空间机制选择性放大或抑制原始权重的重要特征。子空间机制提供高效增加模型容量和复杂性的方式。

Result: 在多个任务上的实验表明，SMoA在10个任务上优于LoRA及其变体，广泛的消融研究验证了其有效性。

Conclusion: SMoA通过高秩结构化调制适配器，以更少可训练参数实现更高秩表示，提高了模型表示能力和性能潜力，为参数高效微调提供了新方向。

Abstract: As the number of model parameters increases, parameter-efficient fine-tuning (PEFT) has become the go-to choice for tailoring pre-trained large language models. Low-rank Adaptation (LoRA) uses a low-rank update method to simulate full parameter fine-tuning, which is widely used to reduce resource requirements. However, decreasing the rank encounters challenges with limited representational capacity when compared to full parameter fine-tuning. We present \textbf{SMoA}, a high-rank \textbf{S}tructured \textbf{MO}dulation \textbf{A}dapter that uses fewer trainable parameters while maintaining a higher rank, thereby improving the model's representational capacity and offering improved performance potential. The core idea is to freeze the original pretrained weights and selectively amplify or suppress important features of the original weights across multiple subspaces. The subspace mechanism provides an efficient way to increase the capacity and complexity of a model. We conduct both theoretical analyses and empirical studies on various tasks. Experiment results show that SMoA outperforms LoRA and its variants on 10 tasks, with extensive ablation studies validating its effectiveness.

</details>


### [124] [Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions](https://arxiv.org/abs/2601.07516)
*Yongqi Li,Hao Lang,Tieyun Qian,Yongbin Li*

Main category: cs.CL

TL;DR: 提出一种基于潜在动作空间的强化学习方法，用于多模态对话代理的微调，通过构建紧凑的潜在动作空间解决大规模文本标记空间处理难题


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在多模态对话代理微调中表现出色，但处理极大规模文本标记空间仍然面临挑战，需要更高效的解决方案

Method: 采用从观察中学习机制构建潜在动作空间的码本，利用未来观察估计当前潜在动作；结合配对图像-文本数据和纯文本数据，使用跨模态投影器将文本嵌入转换为图像-文本嵌入，并通过循环一致性损失增强鲁棒性

Result: 在两种对话任务和多种强化学习算法上，基于潜在动作的方法优于竞争基线

Conclusion: 通过构建紧凑的潜在动作空间，有效解决了多模态对话代理强化学习微调中的大规模文本空间处理问题，提高了模型性能

Abstract: Vision-language models are increasingly employed as multimodal conversational agents (MCAs) for diverse conversational tasks. Recently, reinforcement learning (RL) has been widely explored for adapting MCAs to various human-AI interaction scenarios. Despite showing great enhancement in generalization performance, fine-tuning MCAs via RL still faces challenges in handling the extremely large text token space. To address this, we learn a compact latent action space for RL fine-tuning instead. Specifically, we adopt the learning from observation mechanism to construct the codebook for the latent action space, where future observations are leveraged to estimate current latent actions that could further be used to reconstruct future observations. However, the scarcity of paired image-text data hinders learning a codebook with sufficient coverage. Thus, we leverage both paired image-text data and text-only data to construct the latent action space, using a cross-modal projector for transforming text embeddings into image-text embeddings. We initialize the cross-modal projector on paired image-text data, and further train it on massive text-only data with a novel cycle consistency loss to enhance its robustness. We show that our latent action based method outperforms competitive baselines on two conversation tasks across various RL algorithms.

</details>


### [125] [Thinking Before Constraining: A Unified Decoding Framework for Large Language Models](https://arxiv.org/abs/2601.07525)
*Ngoc Trinh Hung Nguyen,Alonso Silva,Laith Zumot,Liubov Tupikina,Armen Aghasaryan,Mehwish Alam*

Main category: cs.CL

TL;DR: 提出一种结合自然生成和结构化生成的混合方法，让LLM在触发特定标记前自由推理，然后切换到结构化输出，既保持推理灵活性又确保输出可靠性。


<details>
  <summary>Details</summary>
Motivation: 自然生成允许LLM进行自由推理但输出难以解析验证，结构化生成确保格式一致性但可能限制推理能力，需要结合两者优势。

Method: 提出混合生成方法：让语言模型在生成特定触发标记前进行自由自然推理，一旦检测到触发标记就切换到结构化生成模式，确保最终输出为标准化格式。

Result: 在多个分类和推理任务数据集上评估，相比纯自然生成方法准确率提升高达27%，仅需额外10-20个标记的开销。

Conclusion: 该方法成功结合了自然推理的表达能力和结构化输出的可靠性，为LLM生成提供了灵活且可验证的解决方案。

Abstract: Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats such as JSON, ensuring consistency and guaranteed-parsable outputs, but it can inadvertently restrict the model's reasoning capabilities. In this work, we propose a simple approach that combines the advantages of both natural and structured generation. By allowing LLMs to reason freely until specific trigger tokens are generated, and then switching to structured generation, our method preserves the expressive power of natural language reasoning while ensuring the reliability of structured outputs. We further evaluate our approach on several datasets, covering both classification and reasoning tasks, to demonstrate its effectiveness, achieving a substantial gain of up to 27% in accuracy compared to natural generation, while requiring only a small overhead of 10-20 extra tokens.

</details>


### [126] [From RAG to Agentic RAG for Faithful Islamic Question Answering](https://arxiv.org/abs/2601.07528)
*Gagan Bhatia,Hamdy Mubarak,Mustafa Jarrar,George Mikros,Fadi Zaraket,Mahmoud Alhirthani,Mutaz Al-Khatib,Logan Cochrane,Kareem Darwish,Rashid Yahiaoui,Firoj Alam*

Main category: cs.CL

TL;DR: 该论文提出了ISLAMICFAITHQA基准测试和伊斯兰建模套件，用于评估LLM在伊斯兰问答中的幻觉和弃权能力，并开发了基于代理的RAG框架来提升回答准确性。


<details>
  <summary>Details</summary>
Motivation: LLM在伊斯兰问答中可能产生无根据的回答，带来严重的宗教后果。现有的MCQ/MRC评估无法捕捉关键的现实失败模式，特别是自由形式的幻觉和模型在缺乏证据时是否适当弃权。

Method: 1) 创建ISLAMICFAITHQA双语基准测试(3,810项)；2) 开发端到端的伊斯兰建模套件(25K阿拉伯语SFT推理对、5K双语偏好样本、~6k古兰经检索语料)；3) 构建代理式古兰经基础框架(agentic RAG)，使用结构化工具调用进行迭代证据搜索和答案修订。

Result: 检索提高了正确性，代理式RAG相比标准RAG获得最大提升，即使使用小模型(Qwen3 4B)也能达到最先进性能，并表现出更强的阿拉伯语-英语鲁棒性。

Conclusion: 该研究为伊斯兰问答提供了全面的评估框架和解决方案，代理式RAG能有效减少幻觉并提高回答准确性，相关资源将公开供社区使用。

Abstract: LLMs are increasingly used for Islamic question answering, where ungrounded responses may carry serious religious consequences. Yet standard MCQ/MRC-style evaluations do not capture key real-world failure modes, notably free-form hallucinations and whether models appropriately abstain when evidence is lacking. To shed a light on this aspect we introduce ISLAMICFAITHQA, a 3,810-item bilingual (Arabic/English) generative benchmark with atomic single-gold answers, which enables direct measurement of hallucination and abstention. We additionally developed an end-to-end grounded Islamic modelling suite consisting of (i) 25K Arabic text-grounded SFT reasoning pairs, (ii) 5K bilingual preference samples for reward-guided alignment, and (iii) a verse-level Qur'an retrieval corpus of $\sim$6k atomic verses (ayat). Building on these resources, we develop an agentic Quran-grounding framework (agentic RAG) that uses structured tool calls for iterative evidence seeking and answer revision. Experiments across Arabic-centric and multilingual LLMs show that retrieval improves correctness and that agentic RAG yields the largest gains beyond standard RAG, achieving state-of-the-art performance and stronger Arabic-English robustness even with a small model (i.e., Qwen3 4B). We will make the experimental resources and datasets publicly available for the community.

</details>


### [127] [A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models](https://arxiv.org/abs/2601.07565)
*Jiaqi Qiao,Xiujuan Xu,Xinran Li,Yu Liu*

Main category: cs.CL

TL;DR: EGMF是一个统一的多模态情感理解框架，通过专家引导的多模态融合与大型语言模型结合，能够同时处理离散情感识别和连续情感分析任务。


<details>
  <summary>Details</summary>
Motivation: 多模态情感理解需要有效整合文本、音频和视觉模态，但现有方法在捕捉细微情感差异、跨模态关系和长程依赖方面存在局限，需要更强大的融合框架。

Method: 提出EGMF框架，包含三个专家网络：细粒度局部专家（捕捉细微情感）、语义关联专家（跨模态关系）、全局上下文专家（长程依赖），通过分层动态门控自适应集成。增强的多模态表示通过伪令牌注入和提示条件与LLMs集成，使用LoRA微调提高计算效率。

Result: 在双语基准测试（MELD, CHERMA, MOSEI, SIMS-V2）上持续超越最先进方法，显示出优越的跨语言鲁棒性，揭示了英语和中文中多模态情感表达的普遍模式。

Conclusion: EGMF通过专家引导的多模态融合与LLMs的有效集成，为多模态情感理解提供了一个强大的统一框架，在双语任务中表现出色，具有跨语言泛化能力。

Abstract: Multimodal emotion understanding requires effective integration of text, audio, and visual modalities for both discrete emotion recognition and continuous sentiment analysis. We present EGMF, a unified framework combining expert-guided multimodal fusion with large language models. Our approach features three specialized expert networks--a fine-grained local expert for subtle emotional nuances, a semantic correlation expert for cross-modal relationships, and a global context expert for long-range dependencies--adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression through natural language generation. We employ LoRA fine-tuning for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness revealing universal patterns in multimodal emotional expressions across English and Chinese. We will release the source code publicly.

</details>


### [128] [ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents](https://arxiv.org/abs/2601.07582)
*Huhai Zou,Tianhao Sun,Chuanjiang He,Yu Tian,Zhenyang Li,Li Jin,Nayu Liu,Jiang Zhong,Kaiwen Wei*

Main category: cs.CL

TL;DR: ES-Mem是一个基于事件分割理论的对话记忆框架，通过动态事件分割和分层记忆架构解决现有记忆机制在语义完整性和检索精度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆机制存在两个主要局限：1）僵化的记忆粒度破坏语义完整性，导致记忆单元碎片化；2）扁平的检索范式仅依赖表层语义相似度，忽略了对话结构线索，难以准确定位特定情景记忆。

Method: 受事件分割理论启发，提出ES-Mem框架，包含两个核心组件：1）动态事件分割模块，将长期交互划分为语义连贯、边界清晰的事件；2）分层记忆架构，构建多层记忆，利用边界语义锚定特定情景记忆以实现精确上下文定位。

Result: 在两个记忆基准测试中，ES-Mem相比基线方法取得了一致的性能提升。此外，提出的事件分割模块在对话分割数据集上展现出强大的适用性。

Conclusion: ES-Mem通过事件分割和分层记忆架构有效解决了对话记忆中的语义完整性和检索精度问题，为长期交互中的对话智能体提供了更连贯、更精确的记忆机制。

Abstract: Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic similarity, neglecting the structural cues of discourse required to navigate and locate specific episodic contexts. To mitigate these limitations, drawing inspiration from Event Segmentation Theory, we propose ES-Mem, a framework incorporating two core components: (1) a dynamic event segmentation module that partitions long-term interactions into semantically coherent events with distinct boundaries; (2) a hierarchical memory architecture that constructs multi-layered memories and leverages boundary semantics to anchor specific episodic memory for precise context localization. Evaluations on two memory benchmarks demonstrate that ES-Mem yields consistent performance gains over baseline methods. Furthermore, the proposed event segmentation module exhibits robust applicability on dialogue segmentation datasets.

</details>


### [129] [Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments](https://arxiv.org/abs/2601.07606)
*Bingyang Ye,Shan Chen,Jingxuan Tu,Chen Liu,Zidi Xiong,Samuel Schmidgall,Danielle S. Bitterman*

Main category: cs.CL

TL;DR: PoT是一个半可验证的基准测试框架，用于评估语言模型对科学创意的判断能力，通过将判断与下游可观察信号（如引用量、研究议程转变）关联，在离线沙箱中验证预测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地用于评估和预测研究创意，目前缺乏可扩展的方法来评估模型对这些科学创意判断的质量。需要建立一个能够验证模型判断准确性的基准测试框架。

Method: PoT框架采用时间分区方法：冻结截止时间前的证据快照，让模型预测截止时间后的结果（如引用量变化）。在离线沙箱中运行，支持工具使用代理与非代理基线的比较，包含提示消融和预算扩展实验。

Result: 在涵盖四个基准领域的30,000多个实例中，研究发现：相比非代理基线，更高的交互预算通常能提升代理性能，而工具使用的益处则强烈依赖于具体任务。

Conclusion: PoT通过结合时间分区、未来可验证目标和工具使用的离线沙箱，为面向未来的科学创意判断任务提供了可扩展的代理评估支持，有助于系统评估语言模型在科研预测中的表现。

Abstract: Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments about these scientific ideas. Towards this goal, we introduce PoT, a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later (e.g., citations and shifts in researchers' agendas). PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human-model misalignment against signals such as peer-review awards. In addition, PoT provides a controlled testbed for agent-based research judgments that evaluate scientific ideas, comparing tool-using agents to non-agent baselines under prompt ablations and budget scaling. Across 30,000+ instances spanning four benchmark domains, we find that, compared with non-agent baselines, higher interaction budgets generally improve agent performance, while the benefit of tool use is strongly task-dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks.

</details>


### [130] [Integrating Machine-Generated Short Descriptions into the Wikipedia Android App: A Pilot Deployment of Descartes](https://arxiv.org/abs/2601.07631)
*Marija Šakota,Dmitry Brant,Cooltey Feng,Shay Nowick,Amal Ramadan,Robin Schoenbaechler,Joseph Seddon,Jazmin Tanner,Isaac Johnson,Robert West*

Main category: cs.CL

TL;DR: Descartes模型在维基百科Android应用中的试点部署显示，AI生成的简短描述质量接近人工编写，编辑采纳率高且撤销率低，但需考虑延迟、语言差异和敏感话题保护等技术与社区保障措施。


<details>
  <summary>Details</summary>
Motivation: 维基百科的简短描述在不同语言和主题间覆盖不均，需要工具支持编辑填补内容空白。Descartes多语言模型旨在为编辑提供高质量的简短描述建议，提高内容创建效率。

Method: 在维基百科Android应用中部署Descartes模型进行试点实验，为编辑提供AI生成的简短描述建议。实验涵盖12种语言，涉及3900多篇文章和375名编辑，收集采纳率、质量评分、撤销率等数据。

Result: 90%被采纳的Descartes描述质量评分至少3/5分，平均评分与人工编写相当。编辑既直接采纳也修改采纳AI建议，撤销和报告率较低。实验也揭示了延迟、语言特定差距和敏感话题保护等实际部署问题。

Conclusion: Descartes的简短描述能有效支持编辑减少内容差距，但需要在技术、设计和社区层面建立适当的保障措施，包括处理延迟、语言特定问题和敏感话题保护等。

Abstract: Short descriptions are a key part of the Wikipedia user experience, but their coverage remains uneven across languages and topics. In previous work, we introduced Descartes, a multilingual model for generating short descriptions. In this report, we present the results of a pilot deployment of Descartes in the Wikipedia Android app, where editors were offered suggestions based on outputs from Descartes while editing short descriptions. The experiment spanned 12 languages, with over 3,900 articles and 375 editors participating. Overall, 90% of accepted Descartes descriptions were rated at least 3 out of 5 in quality, and their average ratings were comparable to human-written ones. Editors adopted machine suggestions both directly and with modifications, while the rate of reverts and reports remained low. The pilot also revealed practical considerations for deployment, including latency, language-specific gaps, and the need for safeguards around sensitive topics. These results indicate that Descartes's short descriptions can support editors in reducing content gaps, provided that technical, design, and community guardrails are in place.

</details>


### [131] [PlaM: Training-Free Plateau-Guided Model Merging for Better Visual Grounding in MLLMs](https://arxiv.org/abs/2601.07645)
*Zijing Wang,Yongkang Liu,Mingyang Wang,Ercong Nie,Deyuan Chen,Zhengjie Zhao,Shi Feng,Daling Wang,Xiaocui Yang,Yifei Zhang,Hinrich Schütze*

Main category: cs.CL

TL;DR: 提出一种无需训练的框架，通过层级视觉token掩码揭示MLLMs的三阶段模式，并基于此提出平台引导的模型合并方法，有效缓解多模态指令微调对文本推理能力的退化问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）虽然继承了基础语言模型的强大语言推理能力，但多模态指令微调却会降低其文本推理能力，从而削弱多模态性能。为了解决这一问题，需要找到一种方法来缓解这种退化。

Method: 通过层级视觉token掩码揭示MLLMs的三阶段模式（早期模态分离、中期模态对齐、晚期模态退化），并提出平台引导的模型合并方法，选择性地将基础语言模型参数注入到MLLMs中。

Result: 基于5个MLLMs在9个基准测试上的实验结果表明该方法有效。注意力分析进一步显示，合并使注意力从分散、散乱的模式转变为聚焦于任务相关视觉区域的定位。

Conclusion: 提出的无需训练框架通过揭示MLLMs的三阶段模式，并采用平台引导的模型合并方法，成功缓解了多模态指令微调对文本推理能力的退化问题，提高了多模态性能。

Abstract: Multimodal Large Language Models (MLLMs) rely on strong linguistic reasoning inherited from their base language models. However, multimodal instruction fine-tuning paradoxically degrades this text's reasoning capability, undermining multimodal performance. To address this issue, we propose a training-free framework to mitigate this degradation. Through layer-wise vision token masking, we reveal a common three-stage pattern in multimodal large language models: early-modal separation, mid-modal alignment, and late-modal degradation. By analyzing the behavior of MLLMs at different stages, we propose a plateau-guided model merging method that selectively injects base language model parameters into MLLMs. Experimental results based on five MLLMs on nine benchmarks demonstrate the effectiveness of our method. Attention-based analysis further reveals that merging shifts attention from diffuse, scattered patterns to focused localization on task-relevant visual regions. Our repository is on https://github.com/wzj1718/PlaM.

</details>


### [132] [Order in the Evaluation Court: A Critical Analysis of NLG Evaluation Trends](https://arxiv.org/abs/2601.07648)
*Jing Yang,Nils Feldhus,Salar Mohtaj,Leonhard Hennig,Qianli Wang,Eleni Metheniti,Sherzod Hakimov,Charlott Jakob,Veronika Solopova,Konrad Rieck,David Schlangen,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 该论文通过自动信息提取分析了14,171篇NLG论文的评估方法演变，发现任务间评估方法差异显著、传统指标惯性使用、LLM评估与人工评估存在明显分歧等问题，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言生成领域不断发展，但评估方法仍然面临挑战。虽然出现了各种新指标和LLM作为评估者的方法，但人工评估仍然是黄金标准。为了系统回顾NLG评估的演变，需要大规模分析论文中的评估实践。

Method: 采用自动信息提取方案，从四大会议（ACL、EMNLP、NAACL、INLG）过去六年的14,171篇论文中收集关键信息，重点关注不同评估方法（指标、LLM评估和人工评估）的使用情况。

Result: 发现了三个关键发现：1）任务分歧：对话生成快速转向LLM评估（2025年>40%），机器翻译仍依赖n-gram指标，问答系统的人工评估比例大幅下降；2）指标惯性：尽管开发了语义指标，通用指标（如BLEU、ROUGE）仍被广泛使用且缺乏经验依据；3）人机评估分歧：LLM评估与人工评估关注不同信号，验证研究稀少（<8%），相关性中等偏低。

Conclusion: 基于这些观察，提出了改进未来NLG评估严谨性的实用建议，强调需要更系统化的评估实践和验证机制。

Abstract: Despite advances in Natural Language Generation (NLG), evaluation remains challenging. Although various new metrics and LLM-as-a-judge (LaaJ) methods are proposed, human judgment persists as the gold standard. To systematically review how NLG evaluation has evolved, we employ an automatic information extraction scheme to gather key information from NLG papers, focusing on different evaluation methods (metrics, LaaJ and human evaluation). With extracted metadata from 14,171 papers across four major conferences (ACL, EMNLP, NAACL, and INLG) over the past six years, we reveal several critical findings: (1) Task Divergence: While Dialogue Generation demonstrates a rapid shift toward LaaJ (>40% in 2025), Machine Translation remains locked into n-gram metrics, and Question Answering exhibits a substantial decline in the proportion of studies conducting human evaluation. (2) Metric Inertia: Despite the development of semantic metrics, general-purpose metrics (e.g., BLEU, ROUGE) continue to be widely used across tasks without empirical justification, often lacking the discriminative power to distinguish between specific quality criteria. (3) Human-LaaJ Divergence: Our association analysis challenges the assumption that LLMs act as mere proxies for humans; LaaJ and human evaluations prioritize very different signals, and explicit validation is scarce (<8% of papers comparing the two), with only moderate to low correlation. Based on these observations, we derive practical recommendations to improve the rigor of future NLG evaluation.

</details>


### [133] [Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference](https://arxiv.org/abs/2601.07667)
*Rei Taniguchi,Yuyang Dong,Makoto Onizuka,Chuan Xiao*

Main category: cs.CL

TL;DR: ASL是一种训练免费的自适应KV缓存减少方法，通过利用注意力分数排序的token方差自适应选择选择层，平衡不同任务性能同时满足用户指定的KV预算要求。


<details>
  <summary>Details</summary>
Motivation: 现有层级token剪枝方法通常采用预定义的选择层，这种设计不够灵活，在不同任务间准确率差异大，在KV检索等困难任务中性能显著下降。

Method: 提出ASL方法，在预填充阶段利用注意力分数排序的token方差自适应选择选择层，采用一次性token选择（在选定层选择token并传播到更深层），可与现有方法（如SnapKV）联合使用优化解码阶段。

Result: 在InfiniteBench、RULER和NIAH基准测试中，ASL在保持解码速度和KV缓存减少的同时，准确率优于最先进的层级token选择方法。

Conclusion: ASL通过自适应选择层实现了更灵活的KV缓存减少，平衡了不同任务间的性能，同时满足KV预算要求，可与现有方法结合进一步优化解码性能。

Abstract: Due to the prevalence of large language models (LLMs), key-value (KV) cache reduction for LLM inference has received remarkable attention. Among numerous works that have been proposed in recent years, layer-wise token pruning approaches, which select a subset of tokens at particular layers to retain in KV cache and prune others, are one of the most popular schemes. They primarily adopt a set of pre-defined layers, at which tokens are selected. Such design is inflexible in the sense that the accuracy significantly varies across tasks and deteriorates in harder tasks such as KV retrieval. In this paper, we propose ASL, a training-free method that adaptively chooses the selection layer for KV cache reduction, exploiting the variance of token ranks ordered by attention score. The proposed method balances the performance across different tasks while meeting the user-specified KV budget requirement. ASL operates during the prefilling stage and can be jointly used with existing KV cache reduction methods such as SnapKV to optimize the decoding stage. By evaluations on the InfiniteBench, RULER, and NIAH benchmarks, we show that equipped with one-shot token selection, where tokens are selected at a layer and propagated to deeper layers, ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.

</details>


### [134] [Exploring the Meta-level Reasoning of Large Language Models via a Tool-based Multi-hop Tabular Question Answering Task](https://arxiv.org/abs/2601.07696)
*Nick Ferguson,Alan Bundy,Kwabena Nuamah*

Main category: cs.CL

TL;DR: 本文提出了一种区分元级推理和对象级推理的新框架，并设计了一个基于地缘政治指标的问题回答任务来评估大语言模型的元级推理能力。研究发现LLMs在元级推理方面表现良好，但在任务理解和数值计算方面存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型研究中"推理"概念定义模糊且重叠，需要更结构化的方法来区分不同类型的推理能力，特别是元级推理（关于如何解决问题的过程推理）和对象级推理（具体步骤的执行）。

Method: 设计了一个基于各国历年地缘政治指标值的问题回答任务，需要分解中间步骤、数据检索和数学运算。通过分析LLMs选择适当工具的能力来评估其元级推理，并引入"基本动作"来深入分析推理能力。

Result: LLMs在元级推理方面表现良好，但在任务理解方面存在缺陷。n-shot提示对准确性影响不大，错误信息通常不会显著降低性能，同时提供了LLMs数值计算能力较差的额外证据。

Conclusion: 研究提出了评估LLMs推理能力的结构化框架，发现了元级推理的优势和数值计算的局限性，并讨论了这些发现在其他任务领域的泛化性和局限性。

Abstract: Recent advancements in Large Language Models (LLMs) are increasingly focused on "reasoning" ability, a concept with many overlapping definitions in the LLM discourse. We take a more structured approach, distinguishing meta-level reasoning (denoting the process of reasoning about intermediate steps required to solve a task) from object-level reasoning (which concerns the low-level execution of the aforementioned steps.) We design a novel question answering task, which is based around the values of geopolitical indicators for various countries over various years. Questions require breaking down into intermediate steps, retrieval of data, and mathematical operations over that data. The meta-level reasoning ability of LLMs is analysed by examining the selection of appropriate tools for answering questions. To bring greater depth to the analysis of LLMs beyond final answer accuracy, our task contains 'essential actions' against which we can compare the tool call output of LLMs to infer the strength of reasoning ability. We find that LLMs demonstrate good meta-level reasoning on our task, yet are flawed in some aspects of task understanding. We find that n-shot prompting has little effect on accuracy; error messages encountered do not often deteriorate performance; and provide additional evidence for the poor numeracy of LLMs. Finally, we discuss the generalisation and limitation of our findings to other task domains.

</details>


### [135] [Emotional Support Evaluation Framework via Controllable and Diverse Seeker Simulator](https://arxiv.org/abs/2601.07698)
*Chaewon Heo,Cheyon Jin,Yohan Jo*

Main category: cs.CL

TL;DR: 提出可控的求助者模拟器，通过9个心理和语言特征驱动，使用MoE架构训练，能更真实地模拟多样化求助者行为，用于更准确评估情感支持聊天机器人。


<details>
  <summary>Details</summary>
Motivation: 当前情感支持聊天机器人评估中使用的求助者模拟器存在两个关键问题：1) 无法捕捉真实求助者的行为多样性，往往将他们描绘得过于合作；2) 缺乏可控性，无法模拟特定的求助者特征。这导致评估结果不够真实可靠。

Method: 提出基于9个心理和语言特征的可控求助者模拟器。使用真实的Reddit对话数据，通过混合专家(MoE)架构训练模型，将不同的求助者行为区分到专门的参数子空间中，从而增强细粒度可控性。

Result: 模拟器在特征遵循性和行为多样性方面优于现有方法。使用该系统评估7个主流支持者模型时，发现了之前被掩盖的性能下降问题，表明现有评估方法可能高估了模型性能。

Conclusion: 该框架为情感支持聊天机器人提供了更真实、经过压力测试的评估方法，能够更准确地揭示模型在实际应用中的表现，有助于开发更有效的支持系统。

Abstract: As emotional support chatbots have recently gained significant traction across both research and industry, a common evaluation strategy has emerged: use help-seeker simulators to interact with supporter chatbots. However, current simulators suffer from two critical limitations: (1) they fail to capture the behavioral diversity of real-world seekers, often portraying them as overly cooperative, and (2) they lack the controllability required to simulate specific seeker profiles. To address these challenges, we present a controllable seeker simulator driven by nine psychological and linguistic features that underpin seeker behavior. Using authentic Reddit conversations, we train our model via a Mixture-of-Experts (MoE) architecture, which effectively differentiates diverse seeker behaviors into specialized parameter subspaces, thereby enhancing fine-grained controllability. Our simulator achieves superior profile adherence and behavioral diversity compared to existing approaches. Furthermore, evaluating 7 prominent supporter models with our system uncovers previously obscured performance degradations. These findings underscore the utility of our framework in providing a more faithful and stress-tested evaluation for emotional support chatbots.

</details>


### [136] [Is Agentic RAG worth it? An experimental comparison of RAG approaches](https://arxiv.org/abs/2601.07711)
*Pietro Ferrazzi,Milica Cvjeticanin,Alessio Piraccini,Davide Giannuzzi*

Main category: cs.CL

TL;DR: 该论文对增强型RAG和代理型RAG进行了全面的实证评估，比较了两种范式在不同场景下的性能与成本权衡，为实际应用中的RAG设计选择提供指导。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统存在检索噪声、误用检索、查询-文档匹配弱、生成器变异性等局限性。虽然增强型RAG通过专用模块解决这些问题，代理型RAG利用LLM的自反思能力实现流程编排，但两种范式在何种条件下更优尚不明确。

Method: 通过多场景、多维度的广泛实证评估，对比增强型RAG和代理型RAG的性能表现。评估考虑了不同应用条件和维度，包括成本效益分析。

Result: 研究结果为两种RAG范式之间的权衡提供了实用见解，揭示了在不同条件下哪种设计更有效，同时考虑了性能和成本因素。

Conclusion: 该研究为实际应用中RAG设计的选择提供了指导，帮助开发者根据具体场景需求在增强型RAG和代理型RAG之间做出明智决策，平衡性能与成本。

Abstract: Retrieval-Augmented Generation (RAG) systems are usually defined by the combination of a generator and a retrieval component that extracts textual context from a knowledge base to answer user queries. However, such basic implementations exhibit several limitations, including noisy or suboptimal retrieval, misuse of retrieval for out-of-scope queries, weak query-document matching, and variability or cost associated with the generator. These shortcomings have motivated the development of "Enhanced" RAG, where dedicated modules are introduced to address specific weaknesses in the workflow. More recently, the growing self-reflective capabilities of Large Language Models (LLMs) have enabled a new paradigm, which we refer to as "Agentic" RAG. In this approach, the LLM orchestrates the entire process-deciding which actions to perform, when to perform them, and whether to iterate-thereby reducing reliance on fixed, manually engineered modules. Despite the rapid adoption of both paradigms, it remains unclear which approach is preferable under which conditions. In this work, we conduct an extensive, empirically driven evaluation of Enhanced and Agentic RAG across multiple scenarios and dimensions. Our results provide practical insights into the trade-offs between the two paradigms, offering guidance on selecting the most effective RAG design for real-world applications, considering both costs and performance.

</details>


### [137] [Structure First, Reason Next: Enhancing a Large Language Model using Knowledge Graph for Numerical Reasoning in Financial Documents](https://arxiv.org/abs/2601.07754)
*Aryan Mishra,Akash Anil*

Main category: cs.CL

TL;DR: 该论文提出了一种结合知识图谱与LLM的框架，用于提升金融文档数值推理任务的准确性，在FinQA基准上相对基线LLM提升了约12%的执行准确率。


<details>
  <summary>Details</summary>
Motivation: 金融文档通常包含长而复杂的上下文，LLM虽然适合构建金融问答系统，但在处理金融报告中的各种数字时面临挑战，特别是在从非结构化文本和半结构化表格中提取数值数据并进行准确计算方面存在瓶颈。知识图谱等结构化数据增强已被证明能显著改善LLM的预测和逻辑解释能力。

Method: 提出一个结合知识图谱与LLM预测的框架，用于数值推理任务。知识图谱使用提出的模式从处理文档中提取，然后将结构化信息与LLM预测相结合。

Result: 在FinQA基准数据集上使用开源LLM Llama 3.1 8B Instruct进行评估，结果显示提出的框架相对于原始LLM提升了约12%的执行准确率。

Conclusion: 结合知识图谱的结构化信息能有效提升LLM在金融数值推理任务中的性能，证明了在金融分析中使用LLM时考虑文档固有结构化信息的重要性。

Abstract: Numerical reasoning is an important task in the analysis of financial documents. It helps in understanding and performing numerical predictions with logical conclusions for the given query seeking answers from financial texts. Recently, Large Language Models (LLMs) have shown promising results in multiple Question-Answering (Q-A) systems with the capability of logical reasoning. As documents related to finance often consist of long and complex financial contexts, LLMs appear well-suited for building high-quality automated financial question-answering systems. However, LLMs often face challenges in accurately processing the various numbers within financial reports. Extracting numerical data from unstructured text and semi-structured tables, and reliably performing accurate calculations, remains a significant bottleneck for numerical reasoning in most state-of-the-art LLMs. Recent studies have shown that structured data augmentations, such as Knowledge Graphs (KGs), have notably improved the predictions of LLMs along with logical explanations. Thus, it is an important requirement to consider inherent structured information in financial reports while using LLMs for various financial analytics. This paper proposes a framework to incorporate structured information using KGs along with LLM predictions for numerical reasoning tasks. The KGs are extracted using a proposed schema inherently from the document under processing. We evaluated our proposed framework over the benchmark data FinQA, using an open-source LLM, namely Llama 3.1 8B Instruct. We observed that the proposed framework improved execution accuracy by approximately 12% relative to the vanilla LLM.

</details>


### [138] [Contrastive Learning with Narrative Twins for Modeling Story Salience](https://arxiv.org/abs/2601.07765)
*Igor Sterner,Alex Lascarides,Frank Keller*

Main category: cs.CL

TL;DR: 提出一个基于对比学习的叙事显著性建模框架，通过叙事双胞胎学习故事嵌入，用于识别故事中最关键的句子。


<details>
  <summary>Details</summary>
Motivation: 理解叙事需要识别哪些事件对故事进展最为关键。现有方法在建模叙事显著性方面存在不足，需要更有效的框架来捕捉故事的核心要素。

Method: 使用对比学习框架，通过叙事双胞胎（相同情节但不同表面形式的故事）训练模型区分：1）故事与其叙事双胞胎；2）故事与具有相似表面特征但不同情节的干扰项。评估四种叙事学操作：删除、移位、干扰和摘要。

Result: 在ROCStories短篇叙事和维基百科长篇情节摘要上的实验表明，对比学习获得的故事嵌入优于掩码语言模型基线。摘要操作在识别显著性句子方面最可靠。当叙事双胞胎不可用时，随机丢弃可用于生成双胞胎。

Conclusion: 对比学习框架能有效建模叙事显著性，摘要是最可靠的显著性识别操作。该框架在缺乏叙事双胞胎时仍可通过随机丢弃等方法应用，为叙事理解提供了实用工具。

Abstract: Understanding narratives requires identifying which events are most salient for a story's progression. We present a contrastive learning framework for modeling narrative salience that learns story embeddings from narrative twins: stories that share the same plot but differ in surface form. Our model is trained to distinguish a story from both its narrative twin and a distractor with similar surface features but different plot. Using the resulting embeddings, we evaluate four narratologically motivated operations for inferring salience (deletion, shifting, disruption, and summarization). Experiments on short narratives from the ROCStories corpus and longer Wikipedia plot summaries show that contrastively learned story embeddings outperform a masked-language-model baseline, and that summarization is the most reliable operation for identifying salient sentences. If narrative twins are not available, random dropout can be used to generate the twins from a single story. Effective distractors can be obtained either by prompting LLMs or, in long-form narratives, by using different parts of the same story.

</details>


### [139] [Enhancing Self-Correction in Large Language Models through Multi-Perspective Reflection](https://arxiv.org/abs/2601.07780)
*Mariana Costa,Alberlucia Rafael Soarez,Daniel Kim,Camila Ferreira*

Main category: cs.CL

TL;DR: 提出MyGO PR-CoT方法，通过多角度反思提升LLM推理的准确性和一致性，无需模型重训练


<details>
  <summary>Details</summary>
Motivation: 现有CoT提示在复杂或伦理敏感任务中存在一致性、准确性和自我修正不足的问题，单维度反思方法改进有限

Method: 提出多角度反思链式思维(PR-CoT)，在初始CoT后引导LLM从逻辑一致性、信息完整性、偏见/伦理、替代方案四个角度进行自我评估

Result: 在算术、常识、伦理决策和逻辑谜题等任务上，PR-CoT显著优于传统CoT和现有反思方法，特别是在伦理决策等复杂领域

Conclusion: 多角度反思范式能有效提升LLM推理的可靠性，消融研究验证了各反思角度的贡献

Abstract: While Chain-of-Thought (CoT) prompting advances LLM reasoning, challenges persist in consistency, accuracy, and self-correction, especially for complex or ethically sensitive tasks. Existing single-dimensional reflection methods offer insufficient improvements. We propose MyGO Poly-Reflective Chain-of-Thought (PR-CoT), a novel methodology employing structured multi-perspective reflection. After initial CoT, PR-CoT guides the LLM to self-assess its reasoning across multiple predefined angles: logical consistency, information completeness, biases/ethics, and alternative solutions. Implemented purely via prompt engineering, this process refines the initial CoT into a more robust and accurate final answer without model retraining. Experiments across arithmetic, commonsense, ethical decision-making, and logical puzzles, using GPT-three point five and GPT-four models, demonstrate PR-CoT's superior performance. It significantly outperforms traditional CoT and existing reflection methods in logical consistency and error correction, with notable gains in nuanced domains like ethical decision-making. Ablation studies, human evaluations, and qualitative analyses further validate the contribution of each reflection perspective and the overall efficacy of our poly-reflective paradigm in fostering more reliable LLM reasoning.

</details>


### [140] [Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning](https://arxiv.org/abs/2601.07782)
*Wei Fang,James Glass*

Main category: cs.CL

TL;DR: TOOLQP：一个轻量级框架，将工具检索建模为迭代查询规划，通过分解指令为子任务并动态生成查询来弥合语义鸿沟，显著提升复杂工具组合场景下的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有单次密集检索器在处理复杂工具请求时表现不佳，主要问题在于：1）抽象用户目标与技术文档之间的语义鸿沟；2）固定大小嵌入难以建模组合工具结构。需要更智能的检索方法来应对大规模动态工具库的挑战。

Method: 提出TOOLQP框架，将检索建模为迭代查询规划过程。核心思想是：将复杂指令分解为子任务，动态生成针对性查询与检索器交互。采用合成查询轨迹训练，并通过可验证奖励的强化学习（RLVR）进行优化。

Result: 实验表明TOOLQP达到最先进性能，在零样本泛化、跨不同检索器的鲁棒性、以及下游代理执行任务方面均有显著提升。

Conclusion: TOOLQP通过迭代查询规划有效解决了复杂工具检索中的语义鸿沟和组合建模问题，为LLM代理在大规模动态工具库中的操作提供了更可靠的检索基础。

Abstract: LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.

</details>


### [141] [Kinship Data Benchmark for Multi-hop Reasoning](https://arxiv.org/abs/2601.07794)
*Tianda Sun,Dimitar Kazakov*

Main category: cs.CL

TL;DR: KinshipQA：一个通过亲属关系推理来评估大语言模型多跳推理能力的基准测试，使用可生成大规模、文化特异性家谱数据的管道来创建推理任务。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型的多跳推理能力（结合多个信息片段进行连贯推理），需要系统化、可控的测试基准，特别是能够体现文化差异和关系深度的任务。

Method: 开发了一个生成式管道，能够按需生成大规模、真实、文化特异性的家谱数据（满足不同亲属系统的婚姻约束），从中提取需要推理隐含关系链的文本推理任务。

Result: 在6个最先进的大语言模型（包括开源和闭源模型）上使用零样本协议和确定性解码进行评估，结果显示KinshipQA产生了广泛的结果分布，并揭示了不同模型和文化设置下多跳推理的系统性差异。

Conclusion: KinshipQA是一个有效的基准测试，能够系统评估大语言模型的多跳推理能力，并揭示模型在不同文化背景下的推理差异，为模型能力评估提供了新的工具。

Abstract: Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. We introduce KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution of our work is a generative pipeline that produces, on demand, large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, we derive textual inference tasks that require reasoning over implicit relational chains. We evaluate the resulting benchmark using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Our results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.

</details>


### [142] [Learning Through Dialogue: Unpacking the Dynamics of Human-LLM Conversations on Political Issues](https://arxiv.org/abs/2601.07796)
*Shaz Furniturewala,Gerard Christopher Yeo,Kokil Jaidka*

Main category: cs.CL

TL;DR: LLM解释对政治知识和信心的影响取决于用户参与状态，学习效果是互动过程而非单纯解释质量的产物


<details>
  <summary>Details</summary>
Motivation: 研究LLM作为学习伙伴时，解释行为如何影响用户的政治知识和信心变化，探索互动动态而非单纯解释质量

Method: 分析397个人类-LLM对话，使用中介和调节分析，考察语言和互动特征对政治知识和信心的影响机制

Result: 解释丰富度通过反思洞察部分支持信心，通过认知参与影响知识；效果高度条件化，取决于政治效能感

Conclusion: LLM学习是互动成就，设计人机交互系统时需要将解释行为与用户参与状态对齐以支持有效学习

Abstract: Large language models (LLMs) are increasingly used as conversational partners for learning, yet the interactional dynamics supporting users' learning and engagement are understudied. We analyze the linguistic and interactional features from both LLM and participant chats across 397 human-LLM conversations about socio-political issues to identify the mechanisms and conditions under which LLM explanations shape changes in political knowledge and confidence. Mediation analyses reveal that LLM explanatory richness partially supports confidence by fostering users' reflective insight, whereas its effect on knowledge gain operates entirely through users' cognitive engagement. Moderation analyses show that these effects are highly conditional and vary by political efficacy. Confidence gains depend on how high-efficacy users experience and resolve uncertainty. Knowledge gains depend on high-efficacy users' ability to leverage extended interaction, with longer conversations benefiting primarily reflective users. In summary, we find that learning from LLMs is an interactional achievement, not a uniform outcome of better explanations. The findings underscore the importance of aligning LLM explanatory behavior with users' engagement states to support effective learning in designing Human-AI interactive systems.

</details>


### [143] [The Confidence Trap: Gender Bias and Predictive Certainty in LLMs](https://arxiv.org/abs/2601.07806)
*Ahmed Sabir,Markus Kängsepp,Rajesh Sharma*

Main category: cs.CL

TL;DR: 研究评估LLM置信度校准与性别偏见的关系，发现Gemma-2在校准方面表现最差，并提出了新的性别偏见校准指标Gender-ECE。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在敏感领域的应用增加，需要评估其置信度分数与公平性、偏见之间的对应关系，特别是置信度校准是否能有效捕捉模型中的公平性差异。

Method: 研究聚焦性别偏见，通过代词消解任务分析LLM预测置信度与人工标注偏见判断的一致性，评估基于置信度分数的校准指标是否能有效衡量公平性差异。

Result: 在六个最先进的模型中，Gemma-2在性别偏见基准测试中表现出最差的校准性能。研究还提出了新的校准指标Gender-ECE来专门衡量代词消解任务中的性别差异。

Conclusion: 这项工作提供了LLM置信度校准的公平性评估框架，为伦理部署提供指导，并引入Gender-ECE指标来专门测量性别偏见相关的校准问题。

Abstract: The increased use of Large Language Models (LLMs) in sensitive domains leads to growing interest in how their confidence scores correspond to fairness and bias. This study examines the alignment between LLM-predicted confidence and human-annotated bias judgments. Focusing on gender bias, the research investigates probability confidence calibration in contexts involving gendered pronoun resolution. The goal is to evaluate if calibration metrics based on predicted confidence scores effectively capture fairness-related disparities in LLMs. The results show that, among the six state-of-the-art models, Gemma-2 demonstrates the worst calibration according to the gender bias benchmark. The primary contribution of this work is a fairness-aware evaluation of LLMs' confidence calibration, offering guidance for ethical deployment. In addition, we introduce a new calibration metric, Gender-ECE, designed to measure gender disparities in resolution tasks.

</details>


### [144] [Reference Games as a Testbed for the Alignment of Model Uncertainty and Clarification Requests](https://arxiv.org/abs/2601.07820)
*Manar Ali,Judith Sieker,Sina Zarrieß,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 论文研究语言模型能否像人类对话者一样识别自身不确定性并请求澄清，使用指称游戏作为测试平台，发现现有模型在这方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 人类对话中，双方都积极维护相互理解，当听者不确定说话者意思时可以请求澄清。研究语言模型是否能承担类似的听者角色，识别并表达自身的不确定性。

Method: 使用指称游戏作为测试平台，评估三个视觉语言模型：比较基线指称解析任务与要求模型在不确定时请求澄清的实验设置。

Result: 即使在这样简单的任务中，模型也常常难以识别内部不确定性并将其转化为适当的澄清行为。

Conclusion: 指称游戏是测试（视觉和）语言模型交互能力的有效测试平台，当前模型在识别和表达不确定性方面仍有不足。

Abstract: In human conversation, both interlocutors play an active role in maintaining mutual understanding. When addressees are uncertain about what speakers mean, for example, they can request clarification. It is an open question for language models whether they can assume a similar addressee role, recognizing and expressing their own uncertainty through clarification. We argue that reference games are a good testbed to approach this question as they are controlled, self-contained, and make clarification needs explicit and measurable. To test this, we evaluate three vision-language models comparing a baseline reference resolution task to an experiment where the models are instructed to request clarification when uncertain. The results suggest that even in such simple tasks, models often struggle to recognize internal uncertainty and translate it into adequate clarification behavior. This demonstrates the value of reference games as testbeds for interaction qualities of (vision and) language models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [145] [Walk the PLANC: Physics-Guided RL for Agile Humanoid Locomotion on Constrained Footholds](https://arxiv.org/abs/2601.06286)
*Min Dai,William D. Compton,Junheng Li,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出一种结合简化步态规划与强化学习的双足机器人步态控制框架，通过CLF奖励引导学习，在步进石等不连续地形上实现精确、敏捷的硬件验证步态


<details>
  <summary>Details</summary>
Motivation: 传统优化控制方法依赖精确地形几何模型，对感知噪声敏感；而纯强化学习方法难以发现精确落脚点和步序。需要结合物理结构引导学习而非仅靠奖励塑造

Method: 采用简化步态规划器提供动力学一致的运动目标，通过控制李雅普诺夫函数(CLF)奖励引导强化学习训练过程，结合结构化步态规划与数据驱动适应

Result: 在双足人形机器人上实现了精确、敏捷且硬件验证的步进石步态，相比传统无模型强化学习基线显著提高了可靠性

Conclusion: 结合结构化步态规划与数据驱动适应的方法能够产生准确、可靠的步态控制，解决了传统方法与纯强化学习在复杂地形步态控制中的局限性

Abstract: Bipedal humanoid robots must precisely coordinate balance, timing, and contact decisions when locomoting on constrained footholds such as stepping stones, beams, and planks -- even minor errors can lead to catastrophic failure. Classical optimization and control pipelines handle these constraints well but depend on highly accurate mathematical representations of terrain geometry, making them prone to error when perception is noisy or incomplete. Meanwhile, reinforcement learning has shown strong resilience to disturbances and modeling errors, yet end-to-end policies rarely discover the precise foothold placement and step sequencing required for discontinuous terrain. These contrasting limitations motivate approaches that guide learning with physics-based structure rather than relying purely on reward shaping. In this work, we introduce a locomotion framework in which a reduced-order stepping planner supplies dynamically consistent motion targets that steer the RL training process via Control Lyapunov Function (CLF) rewards. This combination of structured footstep planning and data-driven adaptation produces accurate, agile, and hardware-validated stepping-stone locomotion on a humanoid robot, substantially improving reliability compared to conventional model-free reinforcement-learning baselines.

</details>


### [146] [BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures](https://arxiv.org/abs/2601.06344)
*Cedric Melancon,Julien Gascon-Samson,Maarouf Saad,Kuljeet Kaur,Simon Savard*

Main category: cs.RO

TL;DR: BlazeAIoT是一个模块化的多层平台，用于统一分布式机器人系统，通过整合边缘、雾和云计算层，满足实时约束，提供动态数据传输、可配置服务和集成监控。


<details>
  <summary>Details</summary>
Motivation: 分布式机器人系统日益复杂，需要能够无缝整合边缘、雾和云计算层的平台，同时满足严格的实时约束要求。

Method: 采用基于Kubernetes的集群架构，支持多种代理互操作性（DDS、Kafka、Redis、ROS2），包含多层配置服务、动态自适应数据桥接和分层速率限制机制。

Result: 平台在机器人导航和AI驱动的大规模消息处理场景中得到验证，展示了在实时约束下的稳健性能，能够动态分配服务、维护系统健康并最小化延迟。

Conclusion: BlazeAIoT是一个成本感知、可扩展的解决方案，适用于机器人及更广泛的物联网应用，如智慧城市和智能工厂。

Abstract: The increasing complexity of distributed robotics has driven the need for platforms that seamlessly integrate edge, fog, and cloud computing layers while meeting strict real-time constraints. This paper introduces BlazeAIoT, a modular multi-layer platform designed to unify distributed robotics across heterogeneous infrastructures. BlazeAIoT provides dynamic data transfer, configurable services, and integrated monitoring, while ensuring resilience, security, and programming language flexibility. The architecture leverages Kubernetes-based clusters, broker interoperability (DDS, Kafka, Redis, and ROS2), and adaptive data distribution mechanisms to optimize communication and computation across diverse environments. The proposed solution includes a multi-layer configuration service, dynamic and adaptive data bridging, and hierarchical rate limiting to handle large messages. The platform is validated through robotics scenarios involving navigation and artificial intelligence-driven large-scale message processing, demonstrating robust performance under real-time constraints. Results highlight BlazeAIoT's ability to dynamically allocate services across incomplete topologies, maintain system health, and minimize latency, making it a cost-aware, scalable solution for robotics and broader IoT applications, such as smart cities and smart factories.

</details>


### [147] [Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning](https://arxiv.org/abs/2601.06415)
*Nathan Pascal Walus,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Kazunori Ohno*

Main category: cs.RO

TL;DR: 提出离线方法从CAD环境创建详细3D场景图，利用大型视觉语言模型增强语义、空间和功能信息，为机器人动态仿真和推理提供基础


<details>
  <summary>Details</summary>
Motivation: 工业环境中的功能元件（如显示屏、交互阀门）为机器人训练提供有效可能，但CAD文件虽然提供精确几何和视觉描述，却缺乏语义、关系和功能信息，限制了仿真和训练能力

Method: 开发离线方法从CAD环境创建详细3D场景图，利用大型视觉语言模型（LVLM）增强环境的语义、空间和功能信息，特别关注管道结构和功能关系识别

Result: 提供了生成语义标签的定量结果和场景图的定性结果，特别在管道结构和识别的功能关系方面表现良好，所有代码、结果和环境都将开源

Conclusion: 该方法成功创建了包含语义、关系和功能信息的详细3D场景图，为动态仿真和推理提供了坚实基础，解决了CAD环境缺乏高层次理解信息的问题

Abstract: Utilizing functional elements in an industrial environment, such as displays and interactive valves, provide effective possibilities for robot training. When preparing simulations for robots or applications that involve high-level scene understanding, the simulation environment must be equally detailed. Although CAD files for such environments deliver an exact description of the geometry and visuals, they usually lack semantic, relational and functional information, thus limiting the simulation and training possibilities. A 3D scene graph can organize semantic, spatial and functional information by enriching the environment through a Large Vision-Language Model (LVLM). In this paper we present an offline approach to creating detailed 3D scene graphs from CAD environments. This will serve as a foundation to include the relations of functional and actionable elements, which then can be used for dynamic simulation and reasoning. Key results of this research include both quantitative results of the generated semantic labels as well as qualitative results of the scene graph, especially in hindsight of pipe structures and identified functional relations. All code, results and the environment will be made available at https://cad-scenegraph.github.io

</details>


### [148] [CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method](https://arxiv.org/abs/2601.06451)
*Hyunseo Koh,Chang-Yong Song,Youngjae Choi,Misa Viveiros,David Hyde,Heewon Kim*

Main category: cs.RO

TL;DR: 提出一个结合视觉-语言-动作数据集与基于物质点法的物理切割模拟器的统一框架，用于解决食品切割中的物理挑战


<details>
  <summary>Details</summary>
Motivation: 食品切割是视觉与机器人操作交叉领域的重要应用，但面临挑战：刀具与可变形材料的交互高度非线性，涉及大变形、频繁接触和拓扑变化，阻碍了稳定的大规模数据收集

Method: 1. 基于物质点法(MPM)构建物理真实的切割模拟器，采用MLS-MPM减少数值耗散和能量漂移；2. 通过粒子与网格间的冲量交换估计切割过程中的力和应力分布；3. 提供包含多样化切割轨迹、多视角视觉观测、细粒度语言指令以及力-扭矩和工具位姿标签的基准数据集

Result: 建立了一个尊重切割核心物理特性的学习-评估循环，为可变形物体操作中的VLA模型提供了安全、可重复和可扩展的基础

Conclusion: 该框架通过结合物理模拟器和基准数据集，解决了食品切割中的物理挑战，为视觉-语言-动作模型在可变形物体操作中的发展奠定了基础

Abstract: Food cutting is a highly practical yet underexplored application at the intersection of vision and robotic manipulation. The task remains challenging because interactions between the knife and deformable materials are highly nonlinear and often entail large deformations, frequent contact, and topological change, which in turn hinder stable and safe large-scale data collection.
  To address these challenges, we propose a unified framework that couples a vision-language-action (VLA) dataset with a physically realistic cutting simulator built on the material point method (MPM). Our simulator adopts MLS-MPM as its computational core, reducing numerical dissipation and energy drift while preserving rotational and shear responses even under topology-changing cuts. During cutting, forces and stress distributions are estimated from impulse exchanges between particles and the grid, enabling stable tracking of transient contact forces and energy transfer.
  We also provide a benchmark dataset that integrates diverse cutting trajectories, multi-view visual observations, and fine-grained language instructions, together with force--torque and tool--pose labels to provide physically consistent training signals.
  These components realize a learning--evaluation loop that respects the core physics of cutting and establishes a safe, reproducible, and scalable foundation for advancing VLA models in deformable object manipulation.

</details>


### [149] [Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing](https://arxiv.org/abs/2601.06508)
*Andrei A. Korigodskii,Artem E. Vasiunik,Georgii A. Varin,Adilia M. Zukhurova,Matvei V. Urvantsev,Semen A. Osipenkov,Igor S. Efremov,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 多无人机系统用于户外壁画自动绘制，结合2D定位与LiDAR实现精确控制，相比单无人机方案提升可扩展性和操作速度


<details>
  <summary>Details</summary>
Motivation: 将自主无人机集成到大规模艺术项目中是机器人学的新应用，需要解决多无人机协调、精确定位和恶劣天气下稳定操作等挑战

Method: 开发新型多无人机系统，采用状态机算法协调多机任务执行，结合单运动跟踪相机的2D定位与机载LiDAR实现复杂定位，设计沿轨迹和垂直轨迹方向工作的新型飞行控制算法

Result: 成功创建100平方米的壁画，验证系统有效性。相比单无人机方案，显著提升可扩展性和操作速度，在恶劣天气条件下保持高稳定性

Conclusion: 自主机器人群体在创意应用中具有巨大潜力，为大规模机器人艺术的进一步发展铺平道路

Abstract: The integration of autonomous unmanned aerial vehicles (UAVs) into large-scale artistic projects has emerged as a new application in robotics. This paper presents the design, deployment, and testing of a novel multi-drone system for automated mural painting in outdoor settings. This technology makes use of new software that coordinates multiple drones simultaneously, utilizing state-machine algorithms for task execution. Key advancements are the complex positioning system that combines 2D localization using a single motion tracking camera with onboard LiDAR for precise positioning, and a novel flight control algorithm, which works differently along the trajectory and normally to it, ensuring smoothness and high precision of the drawings at the same time. A 100 square meters mural was created using the developed multi-drone system, validating the system's efficacy. Compared to single-drone approaches, our multi-UAV solution significantly improves scalability and operational speed while maintaining high stability even in harsh weather conditions. The findings highlight the potential of autonomous robotic swarms in creative applications, paving the way for further advancements in large-scale robotic art.

</details>


### [150] [Model Reconciliation through Explainability and Collaborative Recovery in Assistive Robotics](https://arxiv.org/abs/2601.06552)
*Britt Besch,Tai Mai,Jeremias Thun,Markus Huff,Jörn Vogel,Freek Stulp,Samuel Bustamante*

Main category: cs.RO

TL;DR: 提出一个基于大语言模型的模型协调框架，用于解释和纠正人机协作中的机器人意外行为，实现人机共享心智模型


<details>
  <summary>Details</summary>
Motivation: 在人机协作中，当机器人出现意外行为时，需要向用户解释原因。特别是在共享控制等应用中，用户和机器人必须对世界中的对象及其可执行操作有相同的理解模型

Method: 采用模型协调框架，利用大语言模型预测和解释机器人与人类心智模型之间的差异，无需用户的正式心智模型。框架允许人类在解释后纠正机器人，解决模型分歧

Result: 在辅助机器人领域实现了该框架，使用真实轮椅移动机械臂及其数字孪生进行了一系列实验验证

Conclusion: 提出的基于大语言模型的模型协调框架能够有效解释机器人意外行为，并通过人类纠正解决人机模型分歧，提升人机协作效果

Abstract: Whenever humans and robots work together, it is essential that unexpected robot behavior can be explained to the user. Especially in applications such as shared control the user and the robot must share the same model of the objects in the world, and the actions that can be performed on these objects.
  In this paper, we achieve this with a so-called model reconciliation framework. We leverage a Large Language Model to predict and explain the difference between the robot's and the human's mental models, without the need of a formal mental model of the user. Furthermore, our framework aims to solve the model divergence after the explanation by allowing the human to correct the robot. We provide an implementation in an assistive robotics domain, where we conduct a set of experiments with a real wheelchair-based mobile manipulator and its digital twin.

</details>


### [151] [UMLoc: Uncertainty-Aware Map-Constrained Inertial Localization with Quantified Bounds](https://arxiv.org/abs/2601.06602)
*Mohammed S. Alharbi,Shinkyu Park*

Main category: cs.RO

TL;DR: UMLoc是一个端到端框架，通过联合建模IMU不确定性和地图约束来实现抗漂移的室内定位，使用LSTM分位数回归器估计定位不确定性，并通过CGAN融合IMU数据和楼层平面图生成几何可行的轨迹。


<details>
  <summary>Details</summary>
Motivation: 在GPS拒止环境（如室内）中，仅使用惯性测量单元（IMU）进行定位会受到运动过程噪声和传感器偏差引起的漂移问题影响，需要一种能够有效处理这些挑战的定位方法。

Method: UMLoc包含两个耦合模块：1）LSTM分位数回归器，估计68%、90%和95%预测区间所需的分位数，作为定位不确定性的度量；2）带有交叉注意力的条件生成对抗网络（CGAN），融合IMU动态数据和基于距离的楼层平面图，生成几何可行的轨迹。两个模块联合训练，使不确定性估计在轨迹生成过程中传播。

Result: 在三个数据集（包括新收集的2小时室内基准数据集）上的评估显示，该方法在70米行程距离上实现了5.9%的平均漂移比和1.36米的平均绝对轨迹误差（ATE），同时保持了校准的预测边界。

Conclusion: UMLoc通过联合建模IMU不确定性和地图约束，实现了抗漂移的室内定位，在保持校准预测边界的同时显著提高了定位精度，为GPS拒止环境中的定位问题提供了有效的解决方案。

Abstract: Inertial localization is particularly valuable in GPS-denied environments such as indoors. However, localization using only Inertial Measurement Units (IMUs) suffers from drift caused by motion-process noise and sensor biases. This paper introduces Uncertainty-aware Map-constrained Inertial Localization (UMLoc), an end-to-end framework that jointly models IMU uncertainty and map constraints to achieve drift-resilient positioning. UMLoc integrates two coupled modules: (1) a Long Short-Term Memory (LSTM) quantile regressor, which estimates the specific quantiles needed to define 68%, 90%, and 95% prediction intervals serving as a measure of localization uncertainty and (2) a Conditioned Generative Adversarial Network (CGAN) with cross-attention that fuses IMU dynamic data with distance-based floor-plan maps to generate geometrically feasible trajectories. The modules are trained jointly, allowing uncertainty estimates to propagate through the CGAN during trajectory generation. UMLoc was evaluated on three datasets, including a newly collected 2-hour indoor benchmark with time-aligned IMU data, ground-truth poses and floor-plan maps. Results show that the method achieves a mean drift ratio of 5.9% over a 70 m travel distance and an average Absolute Trajectory Error (ATE) of 1.36 m, while maintaining calibrated prediction bounds.

</details>


### [152] [Robotic Tele-Operation for Upper Aerodigestive Tract Microsurgery: System Design and Validation](https://arxiv.org/abs/2601.06617)
*Giovani Braglia,José Jair Alves Mendes Junior,Augusto Tetsuo Prado Inafuco,Federico Mariano,Leonardo S. Mattos*

Main category: cs.RO

TL;DR: 提出用于上呼吸道消化道手术的新型机器人系统，通过远程操作框架和远程运动中心机制实现精确的镊子控制，改善外科医生的人体工程学


<details>
  <summary>Details</summary>
Motivation: 目前上呼吸道消化道手术中镊子操作主要依赖手动，存在人体工程学、精度和可控性方面的限制，需要改进

Method: 开发新型机器人系统，包括专门设计的末端执行器用于镊子控制，集成远程操作框架，采用具有编程远程运动中心机制的机器人操纵器

Result: 通过两项实验研究和专门的可用性评估验证了系统的有效性和适用性

Conclusion: 该系统能够为上呼吸道消化道手术提供精确、受约束的器械运动，同时改善外科医生的人体工程学

Abstract: Upper aerodigestive tract (UADT) treatments frequently employ transoral laser microsurgery (TLM) for procedures such as the removal of tumors or polyps. In TLM, a laser beam is used to cut target tissue, while forceps are employed to grasp, manipulate, and stabilize tissue within the UADT. Although TLM systems may rely on different technologies and interfaces, forceps manipulation is still predominantly performed manually, introducing limitations in ergonomics, precision, and controllability. This paper proposes a novel robotic system for tissue manipulation in UADT procedures, based on a novel end-effector designed for forceps control. The system is integrated within a teleoperation framework that employs a robotic manipulator with a programmed remote center of motion (RCM), enabling precise and constrained instrument motion while improving surgeon ergonomics. The proposed approach is validated through two experimental studies and a dedicated usability evaluation, demonstrating its effectiveness and suitability for UADT surgical applications.

</details>


### [153] [Follow the Signs: Using Textual Cues and LLMs to Guide Efficient Robot Navigation](https://arxiv.org/abs/2601.06652)
*Jing Cao,Nishanth Kumar,Aidan Curtis*

Main category: cs.RO

TL;DR: 提出基于大语言模型的语义导航框架，利用文本模式推断目标位置，在稀疏网格环境中实现高效导航


<details>
  <summary>Details</summary>
Motivation: 传统自主导航依赖几何地图而忽略丰富的语义线索（如标志、房间号、文本标签），无法有效利用部分观察中的模式信息

Method: 结合局部感知输入与前沿探索，周期性查询LLM提取符号模式（如房间编号方案和建筑布局结构），更新置信度网格指导探索

Result: 在模拟真实平面图的环境中，该方法始终实现接近最优路径，在加权成功路径长度指标上优于基线方法25%以上

Conclusion: 利用大语言模型推断语义模式能显著提升机器人在稀疏、部分可观察环境中的导航效率，特别是在目标位置有文本标识的场景

Abstract: Autonomous navigation in unfamiliar environments often relies on geometric mapping and planning strategies that overlook rich semantic cues such as signs, room numbers, and textual labels. We propose a novel semantic navigation framework that leverages large language models (LLMs) to infer patterns from partial observations and predict regions where the goal is most likely located. Our method combines local perceptual inputs with frontier-based exploration and periodic LLM queries, which extract symbolic patterns (e.g., room numbering schemes and building layout structures) and update a confidence grid used to guide exploration. This enables robots to move efficiently toward goal locations labeled with textual identifiers (e.g., "room 8") even before direct observation. We demonstrate that this approach enables more efficient navigation in sparse, partially observable grid environments by exploiting symbolic patterns. Experiments across environments modeled after real floor plans show that our approach consistently achieves near-optimal paths and outperforms baselines by over 25% in Success weighted by Path Length.

</details>


### [154] [Robust Evacuation for Multi-Drone Failure in Drone Light Shows](https://arxiv.org/abs/2601.06728)
*Minhyuk Park,Aloysius K. Mok,Tsz-Chiu Au*

Main category: cs.RO

TL;DR: 提出针对无人机灯光秀中多机故障的停车算法，通过疏散和隐藏无人机替换来防止连锁碰撞并实现快速恢复


<details>
  <summary>Details</summary>
Motivation: 无人机灯光秀近年来流行，但多次大规模无人机同时坠落事件引发安全和可靠性担忧，需要提高多无人机系统的鲁棒性

Method: 集成Social LSTM模型与注意力机制预测故障无人机轨迹，计算最优疏散路径；使用隐藏无人机（LED灯关闭）替换故障无人机实现快速恢复

Result: 实验表明该方法能显著提高多无人机系统的鲁棒性，通过深度学习预测坠落无人机轨迹来防止连锁碰撞

Conclusion: 提出的无人机停车算法能有效应对多机故障，通过疏散和隐藏无人机替换机制增强无人机灯光秀的安全性和可靠性

Abstract: Drone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failures -- where multiple drones simultaneously fall from the sky -- have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.

</details>


### [155] [On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.06748)
*Changyu Liu,Yiyang Liu,Taowen Wang,Qiao Zhuang,James Chenhao Liang,Wenhao Yang,Renjing Xu,Qifan Wang,Dongfang Liu,Cheng Han*

Main category: cs.RO

TL;DR: 提出TT-VLA框架，通过测试时强化学习实现视觉-语言-动作模型在推理过程中的实时策略适应，提升在动态未知场景下的适应性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型主要通过监督微调或训练时强化学习，需要显式微调阶段、人工干预或受控数据收集，难以应对模拟或物理世界中不断演化的环境，无法实现自主灵活响应。

Method: TT-VLA框架采用测试时强化学习，设计密集奖励机制，利用逐步任务进度信号在推理过程中精炼动作策略，同时保留监督微调/强化学习训练的先验知识。

Result: 实验结果表明，该方法在模拟和真实世界设置中，显著提升了模型在动态、未见场景下的整体适应性、稳定性和任务成功率。

Conclusion: TT-VLA为实现自改进、可部署的视觉-语言-动作模型提供了原则性步骤，是对现有VLA模型的有效补充。

Abstract: Vision-Language-Action models have recently emerged as a powerful paradigm for general-purpose robot learning, enabling agents to map visual observations and natural-language instructions into executable robotic actions. Though popular, they are primarily trained via supervised fine-tuning or training-time reinforcement learning, requiring explicit fine-tuning phases, human interventions, or controlled data collection. Consequently, existing methods remain unsuitable for challenging simulated- or physical-world deployments, where robots must respond autonomously and flexibly to evolving environments. To address this limitation, we introduce a Test-Time Reinforcement Learning for VLAs (TT-VLA), a framework that enables on-the-fly policy adaptation during inference. TT-VLA formulates a dense reward mechanism that leverages step-by-step task-progress signals to refine action policies during test time while preserving the SFT/RL-trained priors, making it an effective supplement to current VLA models. Empirical results show that our approach enhances overall adaptability, stability, and task success in dynamic, previously unseen scenarios under simulated and real-world settings. We believe TT-VLA offers a principled step toward self-improving, deployment-ready VLAs.

</details>


### [156] [SPINE Gripper: A Twisted Underactuated Mechanism-based Passive Mode-Transition Gripper](https://arxiv.org/abs/2601.06833)
*JaeHyung Jang,JunHyeong Park,Joong-Ku Lee,Jee-Hwan Ryu*

Main category: cs.RO

TL;DR: 提出一种单执行器被动夹爪，通过机械编码的功率传输逻辑实现稳定抓取和连续双向手内旋转，无需传感器或主动控制切换


<details>
  <summary>Details</summary>
Motivation: 传统多功能夹爪需要多个执行器、传感器或基于控制的切换，增加了系统复杂性和成本。本文旨在通过纯机械设计实现非共面多功能操作，减少对执行器和控制的依赖

Method: 采用扭曲欠驱动机构(TUM)，从单一旋转输入产生轴向收缩和旋转两种非共面运动；通过摩擦发生器机械定义扭矩阈值，实现被动模式切换；建立TUM的运动学、弹性力生成和扭矩传输分析模型

Result: 实验验证了抓取成功率、基于摩擦的抓握力调节和双向旋转性能；系统级演示包括螺栓操作、物体重新定向和仅由腕部扭矩驱动的机械臂集成任务，在两种旋转方向上都实现了可靠的抓取到旋转转换

Conclusion: 通过纯机械设计可以实现非共面多功能操作，机械编码的功率传输逻辑是执行器和控制密集型夹爪架构的稳健替代方案

Abstract: This paper presents a single-actuator passive gripper that achieves both stable grasping and continuous bidirectional in-hand rotation through mechanically encoded power transmission logic. Unlike conventional multifunctional grippers that require multiple actuators, sensors, or control-based switching, the proposed gripper transitions between grasping and rotation solely according to the magnitude of the applied input torque. The key enabler of this behavior is a Twisted Underactuated Mechanism (TUM), which generates non-coplanar motions, namely axial contraction and rotation, from a single rotational input while producing identical contraction regardless of rotation direction. A friction generator mechanically defines torque thresholds that govern passive mode switching, enabling stable grasp establishment before autonomously transitioning to in-hand rotation without sensing or active control. Analytical models describing the kinematics, elastic force generation, and torque transmission of the TUM are derived and experimentally validated. The fabricated gripper is evaluated through quantitative experiments on grasp success, friction-based grasp force regulation, and bidirectional rotation performance. System-level demonstrations, including bolt manipulation, object reorientation, and manipulator-integrated tasks driven solely by wrist torque, confirm reliable grasp to rotate transitions in both rotational directions. These results demonstrate that non-coplanar multifunctional manipulation can be realized through mechanical design alone, establishing mechanically encoded power transmission logic as a robust alternative to actuator and control intensive gripper architectures.

</details>


### [157] [Semilinear single-track vehicle models with distributed tyre friction dynamics](https://arxiv.org/abs/2601.06854)
*Luigi Romano,Ole Morten Aamo,Jan Åslund,Erik Frisk*

Main category: cs.RO

TL;DR: 提出新型单轨车辆模型，结合分布式瞬态轮胎动力学与非线性摩擦效应，基于FrBD模型统一扩展经典摩擦模型，建立ODE-PDE耦合系统，分析稳定性并验证微摆振和转向瞬态响应。


<details>
  <summary>Details</summary>
Motivation: 现有车辆动力学模型在处理瞬态轮胎行为和摩擦非线性效应方面存在局限，需要更物理基础、数学严谨且计算可行的框架来准确捕捉侧向车辆动力学中的瞬态轮胎行为。

Method: 提出分布式摩擦与刷毛动力学(FrBD)模型，将滚动接触描述为半线性偏微分方程的空间分布式系统，集成到单轨车辆框架中形成ODE-PDE耦合系统，考虑刚性/柔性胎体两种变体，建立状态空间表示并分析适定性。

Result: 建立了耦合系统的局部和全局适定性，证明了分布式FrBD模型的耗散性和物理一致性；通过线性化实现谱分析和传递函数推导；数值模拟验证了模型捕捉微摆振振荡和转向瞬态响应的能力。

Conclusion: 该框架通过提供物理基础、数学严谨且计算可行的分布式瞬态轮胎动力学模型，推进了考虑有限摩擦效应的侧向车辆动力学建模技术。

Abstract: This paper introduces a novel family of single-track vehicle models that incorporate a distributed representation of transient tyre dynamics, whilst simultaneously accounting for nonlinear effects induced by friction. The core of the proposed framework is represented by the distributed Friction with Bristle Dynamics (FrBD) model, which unifies and extends classical formulations such as Dahl and LuGre by describing the rolling contact process as a spatially distributed system governed by semilinear partial differential equations (PDEs). This model is systematically integrated into a single-track vehicle framework, where the resulting semilinear ODE-PDE interconnection captures the interaction between lateral vehicle motion and tyre deformation. Two main variants are considered: one with rigid tyre carcass and another with flexible carcass, each admitting a compact state-space representation. Local and global well-posedness properties for the coupled system are established rigorously, highlighting the dissipative and physically consistent properties of the distributed FrBD model. A linearisation procedure is also presented, enabling spectral analysis and transfer function derivation, and potentially facilitating the synthesis of controllers and observers. Numerical simulations demonstrate the model's capability to capture micro-shimmy oscillations and transient lateral responses to advanced steering manoeuvres. The proposed formulation advances the state-of-the-art in vehicle dynamics modelling by providing a physically grounded, mathematically rigorous, and computationally tractable approach to incorporating transient tyre behaviour in lateral vehicle dynamics, when accounting for the effect of limited friction.

</details>


### [158] [Observability-Enhanced Target Motion Estimation via Bearing-Box: Theory and MAV Applications](https://arxiv.org/abs/2601.06887)
*Yin Zhang,Zian Ning,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出一种基于单目视觉和3D边界框的目标运动估计新方法，无需传统方法的各向同性形状和横向运动假设，特别适用于多旋翼无人机场景。


<details>
  <summary>Details</summary>
Motivation: 单目视觉目标运动估计是许多应用的基础挑战，现有方法依赖限制性假设（如各向同性目标形状和横向运动），且未充分利用现代3D检测测量信息。

Method: 提出bearing-box估计器，利用3D边界框中的信息，无需各向同性形状和横向运动假设即可估计目标运动和物理尺寸。针对多旋翼无人机，利用其加速度与推力的独特耦合关系，进一步消除了高阶运动假设的需求。

Result: 通过严格的观测性分析和广泛的实验验证，证明了该方法在真实场景中的优越性能，解决了传统bearing-based估计器需要高阶运动假设的问题。

Conclusion: 该方法充分利用了现代3D检测测量信息，突破了传统方法的限制性假设，为单目视觉目标运动估计提供了更通用和有效的解决方案，特别在多旋翼无人机应用中展现出独特优势。

Abstract: Monocular vision-based target motion estimation is a fundamental challenge in numerous applications. This work introduces a novel bearing-box approach that fully leverages modern 3D detection measurements that are widely available nowadays but have not been well explored for motion estimation so far. Unlike existing methods that rely on restrictive assumptions such as isotropic target shape and lateral motion, our bearing-box estimator can estimate both the target's motion and its physical size without these assumptions by exploiting the information buried in a 3D bounding box. When applied to multi-rotor micro aerial vehicles (MAVs), the estimator yields an interesting advantage: it further removes the need for higher-order motion assumptions by exploiting the unique coupling between MAV's acceleration and thrust. This is particularly significant, as higher-order motion assumptions are widely believed to be necessary in state-of-the-art bearing-based estimators. We support our claims with rigorous observability analyses and extensive experimental validation, demonstrating the estimator's superior performance in real-world scenarios.

</details>


### [159] [ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction](https://arxiv.org/abs/2601.06997)
*Yuetao Li,Zhizhou Jia,Yu Zhang,Qun Hao,Shaohui Zhang*

Main category: cs.RO

TL;DR: ObjSplat：一个主动重建框架，使用高斯面元作为统一表示，通过几何感知的视点评估和多步前瞻规划，高效重建具有逼真外观和准确几何的未知物体。


<details>
  <summary>Details</summary>
Motivation: 自主高保真物体重建对于创建数字资产和弥合机器人学中的仿真与现实差距至关重要。传统方法在复杂几何物体上存在局限性，需要更有效的重建策略。

Method: 1. 使用高斯面元作为统一表示；2. 引入几何感知视点评估管道，显式建模背面可见性和遮挡感知多视图共视性；3. 采用下一最佳路径规划器进行多步前瞻，在动态构建的空间图上联合优化信息增益和移动成本。

Result: 在仿真和真实世界文化遗产上的广泛实验表明，ObjSplat能在几分钟内生成物理一致的模型，相比最先进方法，在重建保真度、表面完整性方面表现更优，同时显著减少扫描时间和路径长度。

Conclusion: ObjSplat通过结合高斯面元表示、几何感知视点评估和全局高效路径规划，实现了对复杂几何物体的高效高质量自主重建，为数字资产创建和机器人应用提供了有力工具。

Abstract: Autonomous high-fidelity object reconstruction is fundamental for creating digital assets and bridging the simulation-to-reality gap in robotics. We present ObjSplat, an active reconstruction framework that leverages Gaussian surfels as a unified representation to progressively reconstruct unknown objects with both photorealistic appearance and accurate geometry. Addressing the limitations of conventional opacity or depth-based cues, we introduce a geometry-aware viewpoint evaluation pipeline that explicitly models back-face visibility and occlusion-aware multi-view covisibility, reliably identifying under-reconstructed regions even on geometrically complex objects. Furthermore, to overcome the limitations of greedy planning strategies, ObjSplat employs a next-best-path (NBP) planner that performs multi-step lookahead on a dynamically constructed spatial graph. By jointly optimizing information gain and movement cost, this planner generates globally efficient trajectories. Extensive experiments in simulation and on real-world cultural artifacts demonstrate that ObjSplat produces physically consistent models within minutes, achieving superior reconstruction fidelity and surface completeness while significantly reducing scan time and path length compared to state-of-the-art approaches. Project page: https://li-yuetao.github.io/ObjSplat-page/ .

</details>


### [160] [A Sliding Mode Controller Based on Timoshenko Beam Theory Developed for a Tendon-Driven Robotic Wrist](https://arxiv.org/abs/2601.07009)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本文提出了一种肌腱驱动机器人腕关节及其高效滑模控制器，实现了精确运动控制，在仿真和实验中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 发展灵巧的机器人关节对于提升机器人系统的操作能力至关重要。需要设计精确控制的肌腱驱动腕关节来推动机器人应用发展。

Method: 采用Timoshenko方法建模腕关节的动力学特性，设计高效的滑模控制器进行肌腱力计算和运动控制，通过仿真和实验验证性能。

Result: 滑模控制器在仿真中RMSE约1.67e-2弧度，实验中误差0.2弧度，稳定时间小于3秒，稳态误差低于1e-1弧度，性能优于现有控制器。

Conclusion: 提出的滑模控制器在肌腱驱动腕关节中表现出优越的轨迹跟踪性能，为未来机器人肌腱驱动机制和控制策略研究奠定了基础。

Abstract: Development of dexterous robotic joints is essential for advancing manipulation capabilities in robotic systems. This paper presents the design and implementation of a tendon-driven robotic wrist joint together with an efficient Sliding Mode Controller (SMC) for precise motion control. The wrist mechanism is modeled using a Timoshenko-based approach to accurately capture its kinematic and dynamic properties, which serve as the foundation for tendon force calculations within the controller. The proposed SMC is designed to deliver fast dynamic response and computational efficiency, enabling accurate trajectory tracking under varying operating conditions. The effectiveness of the controller is validated through comparative analyses with existing controllers for similar wrist mechanisms. The proposed SMC demonstrates superior performance in both simulation and experimental studies. The Root Mean Square Error (RMSE) in simulation is approximately 1.67e-2 radians, while experimental validation yields an error of 0.2 radians. Additionally, the controller achieves a settling time of less than 3 seconds and a steady-state error below 1e-1 radians, consistently observed across both simulation and experimental evaluations. Comparative analyses confirm that the developed SMC surpasses alternative control strategies in motion accuracy, rapid convergence, and steady-state precision. This work establishes a foundation for future exploration of tendon-driven wrist mechanisms and control strategies in robotic applications.

</details>


### [161] [RSLCPP - Deterministic Simulations Using ROS 2](https://arxiv.org/abs/2601.07052)
*Simon Sagmeister,Marcel Weinmann,Phillip Pitschi,Markus Lienkamp*

Main category: cs.RO

TL;DR: 提出RSLCPP库，通过确定性调度解决ROS 2模拟中的可复现性问题，无需修改现有节点代码


<details>
  <summary>Details</summary>
Motivation: ROS的异步多进程设计导致模拟结果不可复现，影响科学基准测试和持续集成，需要确定性执行保证

Method: 开发ROS Simulation Library for C++ (RSLCPP)，实现确定性回调执行调度，将现有节点组合成可复现的模拟流程

Result: 在合成基准测试和真实机器人系统上，不同CPU和架构下都能获得完全一致的模拟结果

Conclusion: RSLCPP成功解决了ROS 2模拟的可复现性问题，为机器人研究和开发提供了可靠的测试环境

Abstract: Simulation is crucial in real-world robotics, offering safe, scalable, and efficient environments for developing applications, ranging from humanoid robots to autonomous vehicles and drones. While the Robot Operating System (ROS) has been widely adopted as the backbone of these robotic applications in both academia and industry, its asynchronous, multiprocess design complicates reproducibility, especially across varying hardware platforms. Deterministic callback execution cannot be guaranteed when computation times and communication delays vary. This lack of reproducibility complicates scientific benchmarking and continuous integration, where consistent results are essential. To address this, we present a methodology to create deterministic simulations using ROS 2 nodes. Our ROS Simulation Library for C++ (RSLCPP) implements this approach, enabling existing nodes to be combined into a simulation routine that yields reproducible results without requiring any code changes. We demonstrate that our approach yields identical results across various CPUs and architectures when testing both a synthetic benchmark and a real-world robotics system. RSLCPP is open-sourced at https://github.com/TUMFTM/rslcpp.

</details>


### [162] [PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.07060)
*Yuanzhe Liu,Jingyuan Zhu,Yuchen Mo,Gen Li,Xu Cao,Jin Jin,Yifan Shen,Zhengyuan Li,Tianjiao Yu,Wenzhen Yuan,Fangqiang Ding,Ismini Lourentzou*

Main category: cs.RO

TL;DR: PALM是一个视觉-语言-动作模型框架，通过交互为中心的affordance推理和子任务进度追踪来解决长时程多步骤任务中的执行错误问题，显著提升了机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在长时程多步骤任务中表现不佳，缺乏内部推理机制来识别任务相关的交互线索或追踪子任务进度，导致重复动作、遗漏步骤和过早终止等关键执行错误。

Method: PALM框架围绕交互为中心的affordance推理和子任务进度线索构建策略学习。它提取互补的affordance表示，捕捉对象相关性、接触几何、空间位置和运动动态，作为视觉运动控制的任务相关锚点。同时预测连续的子任务内进度，实现无缝子任务转换。

Result: 在广泛的仿真和真实世界实验中，PALM始终优于基线方法：在LIBERO-LONG上达到91.8%的成功率，在CALVIN ABC->D上平均长度提升12.5%，在三个长时程泛化设置中比真实世界基线提升2倍。

Conclusion: PALM通过整合交互为中心的affordance推理和子任务进度追踪，有效解决了VLA模型在长时程多步骤任务中的局限性，显著提升了机器人操作的鲁棒性和成功率。

Abstract: Recent advancements in vision-language-action (VLA) models have shown promise in robotic manipulation, yet they continue to struggle with long-horizon, multi-step tasks. Existing methods lack internal reasoning mechanisms that can identify task-relevant interaction cues or track progress within a subtask, leading to critical execution errors such as repeated actions, missed steps, and premature termination. To address these challenges, we introduce PALM, a VLA framework that structures policy learning around interaction-centric affordance reasoning and subtask progress cues. PALM distills complementary affordance representations that capture object relevance, contact geometry, spatial placements, and motion dynamics, and serve as task-relevant anchors for visuomotor control. To further stabilize long-horizon execution, PALM predicts continuous within-subtask progress, enabling seamless subtask transitions. Across extensive simulation and real-world experiments, PALM consistently outperforms baselines, achieving a 91.8% success rate on LIBERO-LONG, a 12.5% improvement in average length on CALVIN ABC->D, and a 2x improvement over real-world baselines across three long-horizon generalization settings.

</details>


### [163] [PROTEA: Securing Robot Task Planning and Execution](https://arxiv.org/abs/2601.07186)
*Zainab Altaweel,Mohaiminul Al Nahian,Jake Juettner,Adnan Siraj Rakin,Shiqi Zhang*

Main category: cs.RO

TL;DR: 提出PROTEA防御机制，使用LLM作为裁判评估机器人任务计划的安全性，解决维度性和历史性挑战，通过数据集评估不同隐蔽程度的恶意计划


<details>
  <summary>Details</summary>
Motivation: 现有机器人任务规划器（特别是基于基础模型的）存在显著安全漏洞，需要解决这些安全挑战

Method: 引入PROTEA防御机制，采用LLM-as-a-Judge方法评估任务计划安全性，解决维度性和历史性挑战，使用不同LLM实现多个版本进行比较

Result: 创建包含良性和恶意任务计划的数据集（恶意行为具有不同隐蔽程度），结果为机器人系统从业者提供了增强任务规划系统鲁棒性和安全性的可行见解

Conclusion: PROTEA为机器人任务规划系统提供了一种有效的安全评估机制，有助于增强系统的鲁棒性和安全性

Abstract: Robots need task planning methods to generate action sequences for complex tasks. Recent work on adversarial attacks has revealed significant vulnerabilities in existing robot task planners, especially those built on foundation models. In this paper, we aim to address these security challenges by introducing PROTEA, an LLM-as-a-Judge defense mechanism, to evaluate the security of task plans. PROTEA is developed to address the dimensionality and history challenges in plan safety assessment. We used different LLMs to implement multiple versions of PROTEA for comparison purposes. For systemic evaluations, we created a dataset containing both benign and malicious task plans, where the harmful behaviors were injected at varying levels of stealthiness. Our results provide actionable insights for robotic system practitioners seeking to enhance robustness and security of their task planning systems. Details, dataset and demos are provided: https://protea-secure.github.io/PROTEA/

</details>


### [164] [HERE: Hierarchical Active Exploration of Radiance Field with Epistemic Uncertainty Minimization](https://arxiv.org/abs/2601.07242)
*Taekbeom Lee,Dabin Kim,Youngseok Jang,H. Jin Kim*

Main category: cs.RO

TL;DR: HERE：基于神经辐射场的主动3D场景重建框架，通过证据深度学习的认知不确定性量化识别未探索区域，采用分层探索策略实现高效数据采集和精确重建。


<details>
  <summary>Details</summary>
Motivation: 现有主动3D重建方法难以可靠识别未探索或重建质量差的区域，导致数据采集效率低和重建不完整。需要一种能够准确量化不确定性并指导针对性探索的方法。

Method: 1. 基于证据深度学习的认知不确定性量化，直接捕捉数据不足并与重建误差强相关；2. 分层探索策略：局部规划从高不确定性体素中提取目标视点生成轨迹，全局规划利用不确定性指导大规模覆盖；3. 主动学习驱动的相机轨迹生成。

Result: 在多种尺度的逼真模拟场景中，相比现有方法实现了更高的重建完整性；硬件演示进一步验证了其实际应用可行性。

Conclusion: HERE框架通过认知不确定性量化和分层探索策略，能够更可靠地识别未探索区域，实现高效数据采集和精确的3D场景重建，在模拟和实际场景中均表现出优越性能。

Abstract: We present HERE, an active 3D scene reconstruction framework based on neural radiance fields, enabling high-fidelity implicit mapping. Our approach centers around an active learning strategy for camera trajectory generation, driven by accurate identification of unseen regions, which supports efficient data acquisition and precise scene reconstruction. The key to our approach is epistemic uncertainty quantification based on evidential deep learning, which directly captures data insufficiency and exhibits a strong correlation with reconstruction errors. This allows our framework to more reliably identify unexplored or poorly reconstructed regions compared to existing methods, leading to more informed and targeted exploration. Additionally, we design a hierarchical exploration strategy that leverages learned epistemic uncertainty, where local planning extracts target viewpoints from high-uncertainty voxels based on visibility for trajectory generation, and global planning uses uncertainty to guide large-scale coverage for efficient and comprehensive reconstruction. The effectiveness of the proposed method in active 3D reconstruction is demonstrated by achieving higher reconstruction completeness compared to previous approaches on photorealistic simulated scenes across varying scales, while a hardware demonstration further validates its real-world applicability.

</details>


### [165] [AdaMorph: Unified Motion Retargeting via Embodiment-Aware Adaptive Transformers](https://arxiv.org/abs/2601.07284)
*Haoyu Zhang,Shibo Jin,Lvsong Li,Jun Li,Liang Lin,Xiaodong He,Zecui Zeng*

Main category: cs.RO

TL;DR: AdaMorph是一个统一的神经重定向框架，使用单个模型将人类运动适配到不同机器人形态，通过条件生成和自适应层归一化实现跨异构机器人的统一控制。


<details>
  <summary>Details</summary>
Motivation: 现有的人类运动重定向方法通常需要为每种机器人形态训练特定模型，这种方法扩展性差且无法利用共享的运动语义。由于不同机器人之间存在严重的运动学和动力学差异，需要一种统一的解决方案。

Method: 将重定向视为条件生成任务：1）将人类运动映射到形态无关的潜在意图空间；2）使用双重提示机制进行条件生成；3）采用自适应层归一化（AdaLN）动态调制解码器特征空间；4）通过课程式训练目标确保物理合理性，保持方向和轨迹一致性。

Result: 在12种不同的人形机器人上实验表明，AdaMorph能有效统一异构拓扑结构的控制，对未见过的复杂运动表现出强大的零样本泛化能力，同时保留源行为的动态本质。

Conclusion: AdaMorph提供了一个统一的神经重定向框架，能够通过单个模型适应多种机器人形态，解决了现有方法扩展性差的问题，实现了跨异构机器人的有效运动控制。

Abstract: Retargeting human motion to heterogeneous robots is a fundamental challenge in robotics, primarily due to the severe kinematic and dynamic discrepancies between varying embodiments. Existing solutions typically resort to training embodiment-specific models, which scales poorly and fails to exploit shared motion semantics. To address this, we present AdaMorph, a unified neural retargeting framework that enables a single model to adapt human motion to diverse robot morphologies. Our approach treats retargeting as a conditional generation task. We map human motion into a morphology-agnostic latent intent space and utilize a dual-purpose prompting mechanism to condition the generation. Instead of simple input concatenation, we leverage Adaptive Layer Normalization (AdaLN) to dynamically modulate the decoder's feature space based on embodiment constraints. Furthermore, we enforce physical plausibility through a curriculum-based training objective that ensures orientation and trajectory consistency via integration. Experimental results on 12 distinct humanoid robots demonstrate that AdaMorph effectively unifies control across heterogeneous topologies, exhibiting strong zero-shot generalization to unseen complex motions while preserving the dynamic essence of the source behaviors.

</details>


### [166] [Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts](https://arxiv.org/abs/2601.07304)
*Yun Chen,Bowei Huang,Fan Guo,Kang Song*

Main category: cs.RO

TL;DR: 提出HMER框架，通过语义任务规划器分解长时程任务为导航和操作专家策略，结合混合模仿-强化训练策略，显著提升自主叉车在非结构化仓库中的操作性能。


<details>
  <summary>Details</summary>
Motivation: 自主移动操作在非结构化仓库中需要平衡大规模导航效率和精确物体交互。传统端到端学习方法难以处理这两个阶段的不同需求：导航需要在大空间中进行鲁棒决策，而操作需要对局部细节高度敏感。单一网络同时学习这些不同目标会导致优化干扰。

Method: 提出异构多专家强化学习（HMER）框架，通过语义任务规划器将长时程任务分解为专门的子策略，分离宏观导航和微观操作。采用混合模仿-强化训练策略，使用专家演示初始化策略，再用强化学习进行微调，解决稀疏探索问题。

Result: 在Gazebo仿真实验中，HMER显著优于顺序和端到端基线方法：任务成功率94.2%（基线62.5%），操作时间减少21.4%，放置误差保持在1.5厘米以内。

Conclusion: HMER框架通过分解任务和协调专家策略，有效解决了自主叉车在非结构化仓库中的导航-操作冲突问题，实现了高效精确的材料处理。

Abstract: Autonomous mobile manipulation in unstructured warehouses requires a balance between efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle to handle the conflicting demands of these distinct phases. Navigation relies on robust decision-making over large spaces, while manipulation needs high sensitivity to fine local details. Forcing a single network to learn these different objectives simultaneously often causes optimization interference, where improving one task degrades the other. To address these limitations, we propose a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. Furthermore, to solve the problem of sparse exploration, we introduce a Hybrid Imitation-Reinforcement Training Strategy. This method uses expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines. Our method achieves a task success rate of 94.2\% (compared to 62.5\% for baselines), reduces operation time by 21.4\%, and maintains placement error within 1.5 cm, validating its efficacy for precise material handling.

</details>


### [167] [Large-Scale Autonomous Gas Monitoring for Volcanic Environments: A Legged Robot on Mount Etna](https://arxiv.org/abs/2601.07362)
*Julia Richter,Turcan Tuna,Manthan Patel,Takahiro Miki,Devon Higgins,James Fox,Cesar Cadena,Andres Diaz,Marco Hutter*

Main category: cs.RO

TL;DR: 开发四足机器人系统用于火山气体自主监测，在埃特纳火山成功完成气体源检测任务


<details>
  <summary>Details</summary>
Motivation: 火山气体排放是喷发活动的重要前兆，但传统轮式系统在崎岖火山地形中移动能力有限，难以进行可靠的原位气体测量，需要自主解决方案

Method: 使用四足机器人ANYmal搭载四极杆质谱仪系统，构建模块化自主堆栈，包括任务规划界面、全局规划器、定位框架和地形感知局部导航

Result: 在埃特纳火山进行了三次自主任务，在多变地形中实现了93-100%的自主率，成功检测到气体源；在遥操作任务中检测到二氧化硫和二氧化碳

Conclusion: 需要自适应传感策略、全局与局部规划的更紧密集成以及改进的硬件设计，四足机器人系统在火山气体监测中具有实际应用潜力

Abstract: Volcanic gas emissions are key precursors of eruptive activity. Yet, obtaining accurate near-surface measurements remains hazardous and logistically challenging, motivating the need for autonomous solutions. Limited mobility in rough volcanic terrain has prevented wheeled systems from performing reliable in situ gas measurements, reducing their usefulness as sensing platforms. We present a legged robotic system for autonomous volcanic gas analysis, utilizing the quadruped ANYmal, equipped with a quadrupole mass spectrometer system. Our modular autonomy stack integrates a mission planning interface, global planner, localization framework, and terrain-aware local navigation. We evaluated the system on Mount Etna across three autonomous missions in varied terrain, achieving successful gas-source detections with autonomy rates of 93-100%. In addition, we conducted a teleoperated mission in which the robot measured natural fumaroles, detecting sulfur dioxide and carbon dioxide. We discuss lessons learned from the gas-analysis and autonomy perspectives, emphasizing the need for adaptive sensing strategies, tighter integration of global and local planning, and improved hardware design.

</details>


### [168] [LOONG: Online Time-Optimal Autonomous Flight for MAVs in Cluttered Environments](https://arxiv.org/abs/2601.07434)
*Xin Guan,Fangguo Zhao,Qianyi Wang,Chengcheng Zhao,Jiming Chen,Shuo Li*

Main category: cs.RO

TL;DR: 提出一个集成规划与控制框架，实现MAV在未知杂乱环境中高速、时间最优的自主飞行，通过模仿学习加速时间分配，结合MPCC和SFC约束实现激进但安全的机动。


<details>
  <summary>Details</summary>
Motivation: 当前MAV在未知杂乱环境中的自主飞行面临挑战，保守的机动策略无法满足时间关键任务的需求，需要更激进但安全的飞行能力。

Method: 采用100Hz重规划周期，生成多项式表示的时间最优轨迹参考，通过模仿学习加速时间分配；结合时间最优模型预测轮廓控制(MPCC)和可变视野步长的安全飞行走廊(SFC)约束，充分利用MAV动力学。

Result: 仿真结果显示比现有技术更具攻击性；真实世界实验中，在杂乱环境中达到峰值速度18m/s，从不同起点连续10次试验均成功。

Conclusion: 该框架成功实现了MAV在杂乱环境中的高速、时间最优自主飞行，平衡了激进机动与安全性，验证了方法的有效性。

Abstract: Autonomous flight of micro air vehicles (MAVs) in unknown, cluttered environments remains challenging for time-critical missions due to conservative maneuvering strategies. This article presents an integrated planning and control framework for high-speed, time-optimal autonomous flight of MAVs in cluttered environments. In each replanning cycle (100 Hz), a time-optimal trajectory under polynomial presentation is generated as a reference, with the time-allocation process accelerated by imitation learning. Subsequently, a time-optimal model predictive contouring control (MPCC) incorporates safe flight corridor (SFC) constraints at variable horizon steps to enable aggressive yet safe maneuvering, while fully exploiting the MAV's dynamics. We validate the proposed framework extensively on a custom-built LiDAR-based MAV platform. Simulation results demonstrate superior aggressiveness compared to the state of the art, while real-world experiments achieve a peak speed of 18 m/s in a cluttered environment and succeed in 10 consecutive trials from diverse start points. The video is available at the following link: https://youtu.be/vexXXhv99oQ.

</details>


### [169] [WaveMan: mmWave-Based Room-Scale Human Interaction Perception for Humanoid Robots](https://arxiv.org/abs/2601.07454)
*Yuxuan Hu,Kuangji Zuo,Boyu Ma,Shihao Li,Zhaoyang Xia,Feng Xu,Jianfei Yang*

Main category: cs.RO

TL;DR: WaveMan是一个空间自适应的人机交互感知系统，使用毫米波传感实现隐私保护，通过视角对齐和频谱图增强解决现有系统在未知距离或视角下空间泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 家庭环境中可靠的人机交互面临两个基本约束：对无约束用户位置的鲁棒性和用户隐私保护。毫米波传感天生支持隐私保护交互，但现有毫米波交互感知系统在未见距离或视角下空间泛化能力差。

Method: WaveMan集成了视角对齐和频谱图增强以实现空间一致性，采用双通道注意力机制进行鲁棒特征提取，构建空间自适应感知系统。

Result: 在固定位置评估中，WaveMan用基线1/5的训练位置达到相同的跨位置准确率；在随机自由位置测试中，准确率从33.00%提升到94.33%。

Conclusion: WaveMan证明了在无约束用户位置下实现可靠、隐私保护的家庭人机交互的可行性，为毫米波传感在房间尺度人机交互中的应用提供了有效解决方案。

Abstract: Reliable humanoid-robot interaction (HRI) in household environments is constrained by two fundamental requirements, namely robustness to unconstrained user positions and preservation of user privacy. Millimeter-wave (mmWave) sensing inherently supports privacy-preserving interaction, making it a promising modality for room-scale HRI. However, existing mmWave-based interaction-sensing systems exhibit poor spatial generalization at unseen distances or viewpoints. To address this challenge, we introduce WaveMan, a spatially adaptive room-scale perception system that restores reliable human interaction sensing across arbitrary user positions. WaveMan integrates viewpoint alignment and spectrogram enhancement for spatial consistency, with dual-channel attention for robust feature extraction. Experiments across five participants show that, under fixed-position evaluation, WaveMan achieves the same cross-position accuracy as the baseline with five times fewer training positions. In random free-position testing, accuracy increases from 33.00% to 94.33%, enabled by the proposed method. These results demonstrate the feasibility of reliable, privacy-preserving interaction for household humanoid robots across unconstrained user positions.

</details>


### [170] [NanoCockpit: Performance-optimized Application Framework for AI-based Autonomous Nanorobotics](https://arxiv.org/abs/2601.07476)
*Elia Cereda,Alessandro Giusti,Daniele Palossi*

Main category: cs.RO

TL;DR: NanoCockpit框架通过协程多任务处理优化纳米无人机视觉TinyML应用的端到端延迟，实现零开销流水线处理


<details>
  <summary>Details</summary>
Motivation: 纳米无人机受限于计算资源（<100mW MCU），现有软件层无法充分利用硬件资源，导致控制性能不佳。需要简化开发体验的同时优化系统吞吐量和延迟。

Method: 提出NanoCockpit框架，采用协程多任务处理技术，实现多缓冲区图像采集、多核计算、MCU间数据交换和Wi-Fi流式传输的时间最优流水线。

Result: 在三个真实世界TinyML纳米机器人应用中，框架实现理想的端到端延迟（串行任务零开销），闭环控制性能显著提升（平均位置误差减少30%，任务成功率从40%提高到100%）。

Conclusion: NanoCockpit填补了纳米无人机软件层的空白，通过高效的资源利用和简化的开发体验，显著提升了基于视觉TinyML的纳米无人机系统性能。

Abstract: Autonomous nano-drones, powered by vision-based tiny machine learning (TinyML) models, are a novel technology gaining momentum thanks to their broad applicability and pushing scientific advancement on resource-limited embedded systems. Their small form factor, i.e., a few 10s grams, severely limits their onboard computational resources to sub-\SI{100}{\milli\watt} microcontroller units (MCUs). The Bitcraze Crazyflie nano-drone is the \textit{de facto} standard, offering a rich set of programmable MCUs for low-level control, multi-core processing, and radio transmission. However, roboticists very often underutilize these onboard precious resources due to the absence of a simple yet efficient software layer capable of time-optimal pipelining of multi-buffer image acquisition, multi-core computation, intra-MCUs data exchange, and Wi-Fi streaming, leading to sub-optimal control performances. Our \textit{NanoCockpit} framework aims to fill this gap, increasing the throughput and minimizing the system's latency, while simplifying the developer experience through coroutine-based multi-tasking. In-field experiments on three real-world TinyML nanorobotics applications show our framework achieves ideal end-to-end latency, i.e. zero overhead due to serialized tasks, delivering quantifiable improvements in closed-loop control performance ($-$30\% mean position error, mission success rate increased from 40\% to 100\%).

</details>


### [171] [FlyCo: Foundation Model-Empowered Drones for Autonomous 3D Structure Scanning in Open-World Environments](https://arxiv.org/abs/2601.07558)
*Chen Feng,Guiyong Zheng,Tengkai Zhuang,Yongqian Wu,Fangzhan He,Haojia Li,Juepeng Zheng,Shaojie Shen,Boyu Zhou*

Main category: cs.RO

TL;DR: FlyCo：基于基础模型的感知-预测-规划循环系统，实现无人机在开放世界中完全自主、提示驱动的3D目标扫描


<details>
  <summary>Details</summary>
Motivation: 现有无人机3D扫描方法依赖限制性假设或费力的人工先验，限制了实用性、效率和适应性。基础模型(FMs)为弥合这一差距提供了巨大潜力，但需要有效的系统架构来整合FM知识。

Method: FlyCo采用三阶段协调架构：(1)感知阶段融合流式传感器数据与视觉-语言基础模型，实现鲁棒的目标定位和跟踪；(2)预测阶段蒸馏FM知识并结合多模态线索，推断部分观测目标的完整几何形状；(3)规划阶段利用预测前瞻性生成高效安全路径，实现全面目标覆盖。

Result: 在具有挑战性的真实世界和仿真实验中，FlyCo实现了精确的场景理解、高效率和实时安全性，以更低的人工努力超越现有范式，验证了所提架构的实用性。消融实验验证了各组件贡献。

Conclusion: FlyCo提供了一个灵活、可扩展的蓝图，能够有效整合基础模型知识，实现无人机在开放世界中完全自主的3D目标扫描，并能够利用未来的FM和机器人技术进步。

Abstract: Autonomous 3D scanning of open-world target structures via drones remains challenging despite broad applications. Existing paradigms rely on restrictive assumptions or effortful human priors, limiting practicality, efficiency, and adaptability. Recent foundation models (FMs) offer great potential to bridge this gap. This paper investigates a critical research problem: What system architecture can effectively integrate FM knowledge for this task? We answer it with FlyCo, a principled FM-empowered perception-prediction-planning loop enabling fully autonomous, prompt-driven 3D target scanning in diverse unknown open-world environments. FlyCo directly translates low-effort human prompts (text, visual annotations) into precise adaptive scanning flights via three coordinated stages: (1) perception fuses streaming sensor data with vision-language FMs for robust target grounding and tracking; (2) prediction distills FM knowledge and combines multi-modal cues to infer the partially observed target's complete geometry; (3) planning leverages predictive foresight to generate efficient and safe paths with comprehensive target coverage. Building on this, we further design key components to boost open-world target grounding efficiency and robustness, enhance prediction quality in terms of shape accuracy, zero-shot generalization, and temporal stability, and balance long-horizon flight efficiency with real-time computability and online collision avoidance. Extensive challenging real-world and simulation experiments show FlyCo delivers precise scene understanding, high efficiency, and real-time safety, outperforming existing paradigms with lower human effort and verifying the proposed architecture's practicality. Comprehensive ablations validate each component's contribution. FlyCo also serves as a flexible, extensible blueprint, readily leveraging future FM and robotics advances. Code will be released.

</details>


### [172] [Stable In-hand Manipulation for a Lightweight Four-motor Prosthetic Hand](https://arxiv.org/abs/2601.07559)
*Yuki Kuroda,Tomoya Takahashi,Cristian C. Beltran-Hernandez,Kazutoshi Tanaka,Masashi Hamaya*

Main category: cs.RO

TL;DR: 本研究通过引入电机电流反馈，改进PLEXUS假肢手的控制器，使其能够自动估计物体宽度并协调食指位置，从而实现对不同重量物体（最重达289g）的稳定抓握和重定向操作。


<details>
  <summary>Details</summary>
Motivation: 现有假肢手需要预定义物体宽度，且只能处理轻量物体（≤34g），限制了其在日常生活中的实用性。需要开发能够适应不同物体宽度和重量的稳定抓握和重定向能力。

Method: 采用电机电流反馈结合优化的单轴拇指设计，通过电流信号估计物体宽度，并协调调整食指位置以维持稳定抓握，实现物体在精度抓握和侧向抓握之间的重定向。

Result: 实验验证显示：对于轻量物体成功率达100%，即使对于重达289g的铝制棱柱也能保持≥80%的成功率。相比之下，无食指协调时对289g物体的成功率仅为40%。手部还能成功完成日常任务如拧瓶盖和调整笔的书写方向。

Conclusion: 电机电流反馈方法显著提升了假肢手对物体重量和宽度的适应性，实现了更稳定的抓握和重定向操作，增强了假肢手在日常生活中的实用性和功能性。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and designed with motors enclosed inside to protect them from damage and dirt. Additionally, in-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting a pen into a writing posture after picking it up from a desk. We previously developed PLEXUS hand (Precision-Lateral dEXteroUS manipulation hand), a lightweight (311 g) prosthetic hand driven by four motors. This prosthetic performed reorientation between precision and lateral grasps with various objects. However, its controller required predefined object widths and was limited to handling lightweight objects (of weight up to 34 g). This study addresses these limitations by employing motor current feedback. Combined with the hand's previously optimized single-axis thumb, this approach achieves more stable manipulation by estimating the object's width and adjusting the index finger position to maintain stable object holding during the reorientation. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in a 100% success rate with lightweight objects and maintained a high success rate (>=80) even with heavy aluminum prisms (of weight up to 289 g). By contrast, the performance without index finger coordination dropped to just 40% on the heaviest 289 g prism. The hand also successfully executed several daily tasks, including closing bottle caps and orienting a pen for writing.

</details>


### [173] [Deep Whole-body Parkour](https://arxiv.org/abs/2601.07701)
*Ziwen Zhuang,Shaoting Zhu,Mengjie Zhao,Hang Zhao*

Main category: cs.RO

TL;DR: 提出感知全身运动控制框架，将外感受感知融入全身运动跟踪，使类人机器人能在不平坦地形上执行高度动态的非步态任务


<details>
  <summary>Details</summary>
Motivation: 当前类人机器人控制存在两个范式：感知步态（擅长地形适应但仅限于步态）和通用运动跟踪（能复现复杂技能但忽略环境能力）。需要结合两者优势，实现感知通用运动控制

Method: 开发一个框架，将外感受感知集成到全身运动跟踪中，训练单个策略执行多种不同运动，适应各种地形特征

Result: 该框架使机器人能在非结构化地形上执行高度动态的多接触运动（如跳跃、翻滚），显著扩展了机器人的通过能力，超越了简单的行走或奔跑

Conclusion: 通过将感知融入控制回路，实现了感知通用运动控制，展示了感知集成的重要价值，为类人机器人在复杂地形上的动态运动控制提供了新范式

Abstract: Current approaches to humanoid control generally fall into two paradigms: perceptive locomotion, which handles terrain well but is limited to pedal gaits, and general motion tracking, which reproduces complex skills but ignores environmental capabilities. This work unites these paradigms to achieve perceptive general motion control. We present a framework where exteroceptive sensing is integrated into whole-body motion tracking, permitting a humanoid to perform highly dynamic, non-locomotion tasks on uneven terrain. By training a single policy to perform multiple distinct motions across varied terrestrial features, we demonstrate the non-trivial benefit of integrating perception into the control loop. Our results show that this framework enables robust, highly dynamic multi-contact motions, such as vaulting and dive-rolling, on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running. https://project-instinct.github.io/deep-whole-body-parkour

</details>


### [174] [Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids](https://arxiv.org/abs/2601.07718)
*Shaoting Zhu,Ziwen Zhuang,Mengjie Zhao,Kun-Ying Lee,Hang Zhao*

Main category: cs.RO

TL;DR: 提出"Hiking in the Wild"框架，通过端到端强化学习实现人形机器人在复杂地形中的稳健徒步，结合地形边缘检测和足部体积点确保安全，无需外部状态估计。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人在非结构化环境中徒步面临挑战：基于地图的方法存在状态估计漂移问题（如LiDAR方法对躯干抖动处理不佳），而端到端方法则存在可扩展性和训练复杂性不足的问题。

Method: 提出可扩展的端到端感知框架，包含两个关键机制：1) 结合可扩展地形边缘检测和足部体积点的立足点安全机制；2) 平坦补丁采样策略防止奖励欺骗。采用单阶段强化学习方案，直接将原始深度输入和本体感知映射到关节动作。

Result: 在全尺寸人形机器人上进行广泛实地实验，策略能够在复杂地形中以最高2.5 m/s的速度稳健穿越。训练和部署代码已开源。

Conclusion: 提出的"Hiking in the Wild"框架通过端到端强化学习实现了人形机器人在复杂非结构化环境中的稳健徒步，无需依赖外部状态估计，具有实际部署价值。

Abstract: Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. However, integrating exteroception remains a significant challenge: mapping-based methods suffer from state estimation drift; for instance, LiDAR-based methods do not handle torso jitter well. Existing end-to-end approaches often struggle with scalability and training complexity; specifically, some previous works using virtual obstacles are implemented case-by-case. In this work, we present \textit{Hiking in the Wild}, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. To ensure safety and training stability, we introduce two key mechanisms: a foothold safety mechanism combining scalable \textit{Terrain Edge Detection} with \textit{Foot Volume Points} to prevent catastrophic slippage on edges, and a \textit{Flat Patch Sampling} strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate that our policy enables robust traversal of complex terrains at speeds up to 2.5 m/s. The training and deployment code is open-sourced to facilitate reproducible research and deployment on real robots with minimal hardware modifications.

</details>


### [175] [THETA: Triangulated Hand-State Estimation for Teleoperation and Automation in Robotic Hand Control](https://arxiv.org/abs/2601.07768)
*Alex Huang,Akshay Karthik*

Main category: cs.RO

TL;DR: 提出THETA系统：使用三个普通网络摄像头通过三角测量追踪手指关节角度，结合低成本DexHand机械手实现实时遥操作，准确率达97.18%


<details>
  <summary>Details</summary>
Motivation: 传统机械手遥操作依赖昂贵的深度相机和传感器手套，成本高昂。需要开发低成本、易获取的替代方案

Method: 1. 使用三个640x480p网络摄像头以120度间隔布置采集RGB图像；2. 手动测量MCP、PIP、DIP关节中点确定关节角度；3. 使用DeepLabV3+ResNet-50进行手部语义分割；4. 设计MobileNetV2 CNN分类器处理9通道多视角张量；5. 通过串口将预测角度传输至Arduino控制DexHand

Result: 在40种手势的48,000张图像数据集上，模型达到97.18%准确率、98.72%召回率、0.9274 F1分数和0.8906精确度。系统能实时控制机械手复现人手动作

Conclusion: THETA系统提供了一种低成本、用户友好的机械手遥操作方案，在医疗、语言和制造领域有应用潜力。未来将增加数据集多样性、集成手腕追踪并应用OpenAI-Vision等技术

Abstract: The teleoperation of robotic hands is limited by the high costs of depth cameras and sensor gloves, commonly used to estimate hand relative joint positions (XYZ). We present a novel, cost-effective approach using three webcams for triangulation-based tracking to approximate relative joint angles (theta) of human fingers. We also introduce a modified DexHand, a low-cost robotic hand from TheRobotStudio, to demonstrate THETA's real-time application. Data collection involved 40 distinct hand gestures using three 640x480p webcams arranged at 120-degree intervals, generating over 48,000 RGB images. Joint angles were manually determined by measuring midpoints of the MCP, PIP, and DIP finger joints. Captured RGB frames were processed using a DeepLabV3 segmentation model with a ResNet-50 backbone for multi-scale hand segmentation. The segmented images were then HSV-filtered and fed into THETA's architecture, consisting of a MobileNetV2-based CNN classifier optimized for hierarchical spatial feature extraction and a 9-channel input tensor encoding multi-perspective hand representations. The classification model maps segmented hand views into discrete joint angles, achieving 97.18% accuracy, 98.72% recall, F1 Score of 0.9274, and a precision of 0.8906. In real-time inference, THETA captures simultaneous frames, segments hand regions, filters them, and compiles a 9-channel tensor for classification. Joint-angle predictions are relayed via serial to an Arduino, enabling the DexHand to replicate hand movements. Future research will increase dataset diversity, integrate wrist tracking, and apply computer vision techniques such as OpenAI-Vision. THETA potentially ensures cost-effective, user-friendly teleoperation for medical, linguistic, and manufacturing applications.

</details>


### [176] [Data-driven control of hydraulic impact hammers under strict operational and control constraints](https://arxiv.org/abs/2601.07813)
*Francisco Leiva,Claudio Canales,Michelle Valenzuela,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出基于数据驱动的液压冲击锤控制方法，使用监督学习从遥操作数据中学习动态模型，结合RL和MPC实现末端执行器姿态控制，在真实设备上达到12厘米位置误差和0.08弧度角度误差的精度。


<details>
  <summary>Details</summary>
Motivation: 解决采矿行业液压冲击锤的自动化控制问题，使其末端执行器能够精确到达目标姿态以破碎岩石，同时应对状态变量不可观测和离散控制接口等约束。

Method: 采用数据驱动方法：1) 通过监督学习从遥操作数据中学习液压臂近似动态模型；2) 利用学习模型结合强化学习(RL)和模型预测控制(MPC)进行策略合成；3) 在Bobcat E10小型挖掘机上进行仿真和真实世界验证。

Result: 最佳RL策略在真实世界中达到：位置误差<12厘米，俯仰角误差<0.08弧度。仅需约68分钟遥操作数据训练和8分钟评估动态模型，无需Sim2Real调整。该精度足以破碎岩石（冲击锤凿子直径4厘米）。

Conclusion: 提出的数据驱动方法成功实现了液压冲击锤的自动化控制，仅需少量遥操作数据即可获得精确控制策略，且能直接应用于真实设备，为采矿设备自动化提供了有效解决方案。

Abstract: This paper presents a data-driven methodology for the control of static hydraulic impact hammers, also known as rock breakers, which are commonly used in the mining industry. The task addressed in this work is that of controlling the rock-breaker so its end-effector reaches arbitrary target poses, which is required in normal operation to place the hammer on top of rocks that need to be fractured. The proposed approach considers several constraints, such as unobserved state variables due to limited sensing and the strict requirement of using a discrete control interface at the joint level. First, the proposed methodology addresses the problem of system identification to obtain an approximate dynamic model of the hydraulic arm. This is done via supervised learning, using only teleoperation data. The learned dynamic model is then exploited to obtain a controller capable of reaching target end-effector poses. For policy synthesis, both reinforcement learning (RL) and model predictive control (MPC) algorithms are utilized and contrasted. As a case study, we consider the automation of a Bobcat E10 mini-excavator arm with a hydraulic impact hammer attached as end-effector. Using this machine, both the system identification and policy synthesis stages are studied in simulation and in the real world. The best RL-based policy consistently reaches target end-effector poses with position errors below 12 cm and pitch angle errors below 0.08 rad in the real world. Considering that the impact hammer has a 4 cm diameter chisel, this level of precision is sufficient for breaking rocks. Notably, this is accomplished by relying only on approximately 68 min of teleoperation data to train and 8 min to evaluate the dynamic model, and without performing any adjustments for a successful policy Sim2Real transfer. A demonstration of policy execution in the real world can be found in https://youtu.be/e-7tDhZ4ZgA.

</details>


### [177] [Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation](https://arxiv.org/abs/2601.07821)
*Huanyu Li,Kun Lei,Sheng Zang,Kaizhe Hu,Yongyuan Liang,Bo An,Xiaoli Li,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出FARL框架，通过离线到在线强化学习减少机器人实际部署中的干预性失败，在真实世界RL后训练中减少73.1%的干预性失败并提升11.3%的性能。


<details>
  <summary>Details</summary>
Motivation: 基于深度强化学习的后训练算法虽然能提升机器人模型的泛化性、准确性和鲁棒性，但在真实世界探索中不可避免会出现需要人工干预的失败（如机器人打翻水或打破玻璃），这阻碍了该范式的实际部署。

Method: 提出FARL（Failure-Aware Offline-to-Online Reinforcement Learning）框架，创建FailureBench基准测试集，整合基于世界模型的安全评估器和离线训练的恢复策略，以防止在线探索期间的失败。

Result: 广泛的仿真和真实世界实验表明，FARL能显著减少干预性失败，同时提升在线强化学习后训练的性能和泛化能力。在真实世界RL后训练中，FARL减少73.1%的干预性失败，平均提升11.3%的性能。

Conclusion: FARL为减少机器人实际部署中的干预性失败提供了一种有效的离线到在线强化学习范式，通过整合安全评估和恢复策略，显著提高了机器人后训练的安全性和性能。

Abstract: Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.

</details>
