<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Women's Health Benchmark for Large Language Models](https://arxiv.org/abs/2512.17028)
*Victoria-Elisabeth Gruber,Razvan Marinescu,Diego Fajardo,Amin H. Nassar,Christopher Arkfeld,Alexandria Ludlow,Shama Patel,Mehrnoosh Samaei,Valerie Klug,Anna Huber,Marcel Gühner,Albert Botta i Orfila,Irene Lagoja,Kimya Tarr,Haleigh Larson,Mary Beth Howard*

Main category: cs.CL

TL;DR: 论文提出了首个专门评估大语言模型在女性健康领域表现的基准测试WHB，发现当前模型在女性健康问题上失败率约60%，存在显著的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型成为数百万人获取健康信息的主要来源，其在女性健康领域的准确性尚未得到充分检验。需要建立专门基准来评估LLMs在女性健康方面的表现，揭示潜在风险。

Method: 构建了包含96个经过严格验证的模型测试题的女性健康基准(WHB)，涵盖5个医学专科、3种查询类型和8种错误类型。评估了13个最先进的LLMs。

Result: 当前模型在女性健康基准上的失败率约为60%，表现因专科和错误类型差异显著。所有模型普遍在"错过紧急情况"指标上表现不佳，而GPT-5等新模型在避免不适当建议方面有显著改进。

Conclusion: AI聊天机器人目前尚不能提供可靠的女性健康建议，需要进一步改进以确保安全性和准确性，特别是在紧急情况识别和专科知识方面。

Abstract: As large language models (LLMs) become primary sources of health information for millions, their accuracy in women's health remains critically unexamined. We introduce the Women's Health Benchmark (WHB), the first benchmark evaluating LLM performance specifically in women's health. Our benchmark comprises 96 rigorously validated model stumps covering five medical specialties (obstetrics and gynecology, emergency medicine, primary care, oncology, and neurology), three query types (patient query, clinician query, and evidence/policy query), and eight error types (dosage/medication errors, missing critical information, outdated guidelines/treatment recommendations, incorrect treatment advice, incorrect factual information, missing/incorrect differential diagnosis, missed urgency, and inappropriate recommendations). We evaluated 13 state-of-the-art LLMs and revealed alarming gaps: current models show approximately 60\% failure rates on the women's health benchmark, with performance varying dramatically across specialties and error types. Notably, models universally struggle with "missed urgency" indicators, while newer models like GPT-5 show significant improvements in avoiding inappropriate recommendations. Our findings underscore that AI chatbots are not yet fully able of providing reliable advice in women's health.

</details>


### [2] [Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL](https://arxiv.org/abs/2512.17053)
*Khushboo Thaker,Yony Bresler*

Main category: cs.CL

TL;DR: Struct-SQL：一个基于结构化推理的知识蒸馏框架，通过查询执行计划作为形式化蓝图，让小语言模型在Text-to-SQL任务上性能显著提升


<details>
  <summary>Details</summary>
Motivation: 企业级Text-to-SQL系统面临成本、安全性和性能的三难困境：需要在昂贵的大型专有LLM和性能较低的小型SLM之间做出选择。现有方法通过非结构化思维链进行知识蒸馏存在固有模糊性，而Text-to-SQL任务需要明确精确的逻辑步骤。

Method: 提出Struct-SQL知识蒸馏框架，使用查询执行计划作为形式化蓝图来推导结构化推理，训练小型语言模型模拟大型LLM的能力。采用结构化思维链而非传统非结构化思维链进行蒸馏。

Result: 使用结构化CoT蒸馏的SLM相比非结构化CoT蒸馏基线实现了8.1%的绝对性能提升。详细错误分析显示，性能提升的关键因素是语法错误显著减少。

Conclusion: 使用结构化逻辑蓝图教导模型进行推理，对于SLM中可靠的SQL生成是有益的。结构化推理表示提供了更清晰、更可靠的教学信号，特别适合需要精确逻辑步骤的Text-to-SQL任务。

Abstract: Deploying accurate Text-to-SQL systems at the enterprise level faces a difficult trilemma involving cost, security and performance. Current solutions force enterprises to choose between expensive, proprietary Large Language Models (LLMs) and low-performing Small Language Models (SLMs). Efforts to improve SLMs often rely on distilling reasoning from large LLMs using unstructured Chain-of-Thought (CoT) traces, a process that remains inherently ambiguous. Instead, we hypothesize that a formal, structured reasoning representation provides a clearer, more reliable teaching signal, as the Text-to-SQL task requires explicit and precise logical steps. To evaluate this hypothesis, we propose Struct-SQL, a novel Knowledge Distillation (KD) framework that trains an SLM to emulate a powerful large LLM. Consequently, we adopt a query execution plan as a formal blueprint to derive this structured reasoning. Our SLM, distilled with structured CoT, achieves an absolute improvement of 8.1% over an unstructured CoT distillation baseline. A detailed error analysis reveals that a key factor in this gain is a marked reduction in syntactic errors. This demonstrates that teaching a model to reason using a structured logical blueprint is beneficial for reliable SQL generation in SLMs.

</details>


### [3] [XLM: A Python package for non-autoregressive language models](https://arxiv.org/abs/2512.17065)
*Dhruvesh Patel,Durga Prasad Maram,Sai Sreenivas Chintha,Benjamin Rozonoyer,Andrew McCallum*

Main category: cs.CL

TL;DR: XLM是一个用于快速实现小型非自回归语言模型的Python包，旨在解决当前非自回归方法实现分散、难以系统比较的问题，同时提供预训练模型供研究社区使用。


<details>
  <summary>Details</summary>
Motivation: 当前非自回归语言模型实现分散且多为定制化，缺乏标准训练和推理库，导致难以系统比较不同方法，且每个模型都需要自己的数据处理、损失函数和预测逻辑，组件复用困难。

Method: 开发XLM Python包，提供统一的框架来快速实现小型非自回归语言模型，通过配套的xlm-models包提供预训练模型，代码开源在GitHub上。

Result: 成功创建了XLM包，为研究社区提供了实现非自回归语言模型的标准化工具和预训练模型资源，解决了实现分散和比较困难的问题。

Conclusion: XLM包为非自回归语言模型研究提供了实用的工具支持，促进了该领域方法的系统比较和组件复用，有助于推动非自回归文本生成研究的发展。

Abstract: In recent years, there has been a resurgence of interest in non-autoregressive text generation in the context of general language modeling. Unlike the well-established autoregressive language modeling paradigm, which has a plethora of standard training and inference libraries, implementations of non-autoregressive language modeling have largely been bespoke making it difficult to perform systematic comparisons of different methods. Moreover, each non-autoregressive language model typically requires it own data collation, loss, and prediction logic, making it challenging to reuse common components. In this work, we present the XLM python package, which is designed to make implementing small non-autoregressive language models faster with a secondary goal of providing a suite of small pre-trained models (through a companion xlm-models package) that can be used by the research community. The code is available at https://github.com/dhruvdcoder/xlm-core.

</details>


### [4] [Perturb Your Data: Paraphrase-Guided Training Data Watermarking](https://arxiv.org/abs/2512.17075)
*Pranav Shetty,Mirazul Haque,Petr Babkin,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: SPECTRA是一种用于检测LLM训练数据的数字水印方法，即使水印数据仅占训练语料的0.001%也能可靠检测，通过对比嫌疑模型和评分模型的token概率来实现检测。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在从互联网抓取的大规模文本语料上进行训练，训练数据检测对于执行版权和数据许可变得至关重要。需要一种能够在数据发布前部署、可扩展且能在大规模LLM训练中存活的水印方法。

Method: SPECTRA通过使用LLM对文本进行释义，并根据一个独立的评分模型为每个释义分配分数。选择与原始文本分数密切匹配的释义，以避免引入分布偏移。检测时，比较嫌疑模型的token概率与评分模型的token概率。

Result: SPECTRA在检测用于训练的数据与未用于训练的数据时，实现了超过九个数量级的一致p值差距，优于所有测试的基线方法。

Conclusion: SPECTRA为数据所有者提供了一种可扩展的、在发布前部署的水印方法，即使在大规模LLM训练中也能存活，有效解决了训练数据检测的版权和数据许可问题。

Abstract: Training data detection is critical for enforcing copyright and data licensing, as Large Language Models (LLM) are trained on massive text corpora scraped from the internet. We present SPECTRA, a watermarking approach that makes training data reliably detectable even when it comprises less than 0.001% of the training corpus. SPECTRA works by paraphrasing text using an LLM and assigning a score based on how likely each paraphrase is, according to a separate scoring model. A paraphrase is chosen so that its score closely matches that of the original text, to avoid introducing any distribution shifts. To test whether a suspect model has been trained on the watermarked data, we compare its token probabilities against those of the scoring model. We demonstrate that SPECTRA achieves a consistent p-value gap of over nine orders of magnitude when detecting data used for training versus data not used for training, which is greater than all baselines tested. SPECTRA equips data owners with a scalable, deploy-before-release watermark that survives even large-scale LLM training.

</details>


### [5] [When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation](https://arxiv.org/abs/2512.17083)
*Michael H. Coen*

Main category: cs.CL

TL;DR: 对话主题分割评估存在缺陷：传统F1指标依赖稀疏标注，导致性能差异主要源于标注粒度不匹配而非模型质量。论文提出将边界密度和段落连贯性作为主要评估标准，并引入窗口容忍F1，认为主题分割应视为选择适当粒度而非预测单一正确边界。


<details>
  <summary>Details</summary>
Motivation: 对话主题分割对摘要、检索、记忆管理和对话连续性至关重要，但现有评估实践仍以严格边界匹配和F1指标为主。随着LLM系统依赖分割管理超出固定上下文窗口的对话历史，传统评估方法无法反映实际需求，且性能差异可能源于评估伪影而非模型改进。

Method: 引入新的评估目标：将边界密度和段落连贯性作为主要标准，辅以窗口容忍F1。在八个对话数据集（任务导向、开放域、会议风格、合成交互）上评估多种结构不同的分割策略，分离边界评分与边界选择，分析标注粒度不匹配的影响。

Result: 跨数据集实证显示：报告的性能差异主要由标注粒度不匹配和稀疏边界标签驱动，而非模型质量。观察到高段落连贯性但相对于稀疏标签的极端过分割，导致精确匹配F1分数误导性偏低。许多报告的改进源于评估伪影而非边界检测改进。

Conclusion: 主题分割应理解为选择适当粒度而非预测单一正确边界集。通过明确分离边界评分与边界选择来操作化这一观点，提出更合理的评估框架，强调边界密度和连贯性作为主要标准，窗口容忍F1作为辅助指标。

Abstract: Dialogue topic segmentation supports summarization, retrieval, memory management, and conversational continuity. Despite decades of prior work, evaluation practice in dialogue topic segmentation remains dominated by strict boundary matching and F1-based metrics, even as modern LLM-based conversational systems increasingly rely on segmentation to manage conversation history beyond the model's fixed context window, where unstructured context accumulation degrades efficiency and coherence.
  This paper introduces an evaluation objective for dialogue topic segmentation that treats boundary density and segment coherence as primary criteria, alongside window-tolerant F1 (W-F1). Through extensive cross-dataset empirical evaluation, we show that reported performance differences across dialogue segmentation benchmarks are driven not by model quality, but by annotation granularity mismatches and sparse boundary labels. This indicates that many reported improvements arise from evaluation artifacts rather than improved boundary detection.
  We evaluated multiple, structurally distinct dialogue segmentation strategies across eight dialogue datasets spanning task-oriented, open-domain, meeting-style, and synthetic interactions. Across these settings, we observe high segment coherence combined with extreme oversegmentation relative to sparse labels, producing misleadingly low exact-match F1 scores. We show that topic segmentation is best understood as selecting an appropriate granularity rather than predicting a single correct boundary set. We operationalize this view by explicitly separating boundary scoring from boundary selection.

</details>


### [6] [Data Augmentation Supporting a Conversational Agent Designed for Smoking Cessation Support Groups](https://arxiv.org/abs/2512.17092)
*Salar Hashemitaheri,Ian Harris*

Main category: cs.CL

TL;DR: 本研究提出兩層數據增強策略（合成與真實數據）來改善戒菸線上支持群組對話代理的意圖分類性能，解決數據稀缺問題。


<details>
  <summary>Details</summary>
Motivation: 戒菸線上支持群組面臨用戶參與度低和污名化問題，對話代理可提升參與度，但高質量訓練數據不足限制了意圖分類器的性能。

Method: 採用兩層數據增強：1) 合成數據增強：微調開源LLM識別低F1分數意圖，使用GPT模型生成高質量合成帖子；2) 真實數據增強：從相關線上支持環境爬取真實帖子。所有新數據都經過人工審核驗證質量。

Result: 合成帖子平均87%被評為高質量，真實帖子73%通過驗證。增強後的數據集使意圖分類器的F1分數提升32%，合成和真實數據增強帶來相似的性能改善。

Conclusion: 該數據增強框架有效解決了數據稀缺問題，顯著提升了對話代理的意圖分類性能，為類似領域提供了可複製的解決方案。

Abstract: Online support groups for smoking cessation are economical and accessible, yet they often face challenges with low user engagement and stigma. The use of an automatic conversational agent would improve engagement by ensuring that all user comments receive a timely response.). We address the challenge of insufficient high-quality data by employing a two-level data augmentation strategy: synthetic data augmentation and real data augmentation. First, we fine-tuned an open source LLM to classify posts from our existing smoking cessation support groups and identify intents with low F1 (precision+recall) scores. Then, for these intents, we generate additional synthetic data using prompt engineering with the GPT model, with an average of 87\% of the generated synthetic posts deemed high quality by human annotators. Overall, the synthetic augmentation process resulted in 43\% of the original posts being selected for augmentation, followed by 140\% synthetic expansion of these posts. Additionally, we scraped more than 10,000 real posts from a related online support context, of which 73\% were validated as good quality by human annotators. Each synthetic or scraped post underwent rigorous validation involving human reviewers to ensure quality and relevance. The validated new data, combined with the original support group posts, formed an augmented dataset used to retrain the intent classifier. Performance evaluation of the retrained model demonstrated a 32\% improvement in F1, confirming the effectiveness of our data augmentation approach. Synthetic and real post augmentation led to similar performance improvements. This study provides a replicable framework for enhancing conversational agent performance in domains where data scarcity is a critical issue.

</details>


### [7] [Enhancing Long Document Long Form Summarisation with Self-Planning](https://arxiv.org/abs/2512.17179)
*Xiaotang Du,Rohit Saxena,Laura Perez-Beltrachini,Pasquale Minervini,Ivan Titov*

Main category: cs.CL

TL;DR: 提出一种基于高亮引导的长文本摘要生成方法，利用句子级信息作为内容规划，提升摘要的可追溯性和忠实度


<details>
  <summary>Details</summary>
Motivation: 传统长文本摘要方法在信息密集文档中难以保证事实一致性和可追溯性，需要一种能更好保留重要细节并提高摘要忠实度的新方法

Method: 采用高亮引导生成框架，使用自规划方法识别重要内容作为内容规划，然后基于该规划生成摘要。探索了端到端和两阶段两种变体，发现两阶段流水线在长而信息密集的文档上表现更好

Result: 在长文本摘要数据集上的实验表明，该方法持续改善事实一致性，同时保持相关性和整体质量。在GovReport数据集上，最佳方法将ROUGE-L提高了4.1分，SummaC分数提升了约35%

Conclusion: 高亮引导的摘要生成有助于保留重要细节，产生更准确和富有洞察力的跨领域摘要，两阶段方法在长而信息密集的文档中表现更优

Abstract: We introduce a novel approach for long context summarisation, highlight-guided generation, that leverages sentence-level information as a content plan to improve the traceability and faithfulness of generated summaries. Our framework applies self-planning methods to identify important content and then generates a summary conditioned on the plan. We explore both an end-to-end and two-stage variants of the approach, finding that the two-stage pipeline performs better on long and information-dense documents. Experiments on long-form summarisation datasets demonstrate that our method consistently improves factual consistency while preserving relevance and overall quality. On GovReport, our best approach has improved ROUGE-L by 4.1 points and achieves about 35% gains in SummaC scores. Qualitative analysis shows that highlight-guided summarisation helps preserve important details, leading to more accurate and insightful summaries across domains.

</details>


### [8] [Mindscape-Aware Retrieval Augmented Generation for Improved Long Context Understanding](https://arxiv.org/abs/2512.17220)
*Yuqing Li,Jiangnan Li,Zheng Lin,Ziyan Zhou,Junjie Wu,Weiping Wang,Jie Zhou,Mo Yu*

Main category: cs.CL

TL;DR: MiA-RAG为RAG系统引入全局语义感知，通过构建心智景观来指导检索和生成，在长文本任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 人类理解长文本时依赖全局语义表征，而当前RAG系统缺乏这种全局指导，因此在长上下文任务中表现不佳。

Method: 通过分层摘要构建心智景观，并以此全局语义表征来指导检索器的查询嵌入和生成器的推理过程。

Result: 在多种长上下文和双语基准测试中持续超越基线方法，能够将局部细节与连贯的全局表征对齐。

Conclusion: MiA-RAG通过引入全局语义感知，使RAG系统具备更接近人类的长期上下文检索和推理能力。

Abstract: Humans understand long and complex texts by relying on a holistic semantic representation of the content. This global view helps organize prior knowledge, interpret new information, and integrate evidence dispersed across a document, as revealed by the Mindscape-Aware Capability of humans in psychology. Current Retrieval-Augmented Generation (RAG) systems lack such guidance and therefore struggle with long-context tasks. In this paper, we propose Mindscape-Aware RAG (MiA-RAG), the first approach that equips LLM-based RAG systems with explicit global context awareness. MiA-RAG builds a mindscape through hierarchical summarization and conditions both retrieval and generation on this global semantic representation. This enables the retriever to form enriched query embeddings and the generator to reason over retrieved evidence within a coherent global context. We evaluate MiA-RAG across diverse long-context and bilingual benchmarks for evidence-based understanding and global sense-making. It consistently surpasses baselines, and further analysis shows that it aligns local details with a coherent global representation, enabling more human-like long-context retrieval and reasoning.

</details>


### [9] [Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition](https://arxiv.org/abs/2512.17247)
*Zahra Rahmani,Hossein Sameti*

Main category: cs.CL

TL;DR: 提出一个结合多假设和噪声感知建模的鲁棒波斯语ASR纠错框架，通过引入误差级别噪声(ELN)表示来量化噪声引起的语言失真，显著降低在噪声环境下的词错误率。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别系统在噪声环境下性能显著下降，特别是对于波斯语等低资源语言。即使是Whisper等最先进模型在不同信噪比下也难以保持准确性，需要开发鲁棒的噪声感知纠错方法。

Method: 使用噪声波斯语音生成5个最佳假设，引入误差级别噪声(ELN)表示来捕捉假设间的语义和词级分歧。评估三种模型：基础LLaMA-2-7B、仅文本微调变体、以及集成句子和词级ELN嵌入的噪声条件模型。

Result: 在混合噪声测试集上，提出的微调+ELN模型将词错误率从原始Whisper的31.10%降至24.84%，显著优于仅文本微调基线的30.79%。原始LLaMA-2-7B模型将WER增加至64.58%，表明其无法独立纠正波斯语错误。

Conclusion: 结合多假设和噪声感知嵌入的方法对噪声环境下的鲁棒波斯语ASR有效，ELN条件建模显著提高了纠错性能，为现实世界噪声场景提供了实用解决方案。

Abstract: Automatic Speech Recognition (ASR) systems suffer significant performance degradation in noisy environments, a challenge that is especially severe for low-resource languages such as Persian. Even state-of-the-art models such as Whisper struggle to maintain accuracy under varying signal-to-noise ratios (SNRs). This study presents a robust noise-sensitive ASR error correction framework that combines multiple hypotheses and noise-aware modeling. Using noisy Persian speech, we generate 5-best hypotheses from a modified Whisper-large decoder. Error Level Noise (ELN) is introduced as a representation that captures semantic- and token-level disagreement across hypotheses, quantifying the linguistic distortions caused by noise. ELN thus provides a direct measure of noise-induced uncertainty, enabling the LLM to reason about the reliability of each hypothesis during correction. Three models are evaluated: (1) a base LLaMA-2-7B model without fine-tuning, (2) a fine-tuned variant trained on text-only hypotheses, and (3) a noise-conditioned model integrating ELN embeddings at both sentence and word levels. Experimental results demonstrate that the ELN-conditioned model achieves substantial reductions in Word Error Rate (WER). Specifically, on the challenging Mixed Noise test set, the proposed Fine-tuned + ELN (Ours) model reduces the WER from a baseline of 31.10\% (Raw Whisper) to 24.84\%, significantly surpassing the Fine-tuned (No ELN) text-only baseline of 30.79\%, whereas the original LLaMA-2-7B model increased the WER to 64.58\%, demonstrating that it is unable to correct Persian errors on its own. This confirms the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust Persian ASR in noisy real-world scenarios.

</details>


### [10] [Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience](https://arxiv.org/abs/2512.17260)
*Jiangjie Chen,Wenxiang Chen,Jiacheng Du,Jinyi Hu,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Wenlei Shi,Zhihong Wang,Mingxuan Wang,Chenrui Wei,Shufa Wei,Huajian Xin,Fan Yang,Weihao Gao,Zheng Yuan,Tianyang Zhan,Zeyu Zheng,Tianxi Zhou,Thomas Hanwen Zhu*

Main category: cs.CL

TL;DR: Seed-Prover 1.5是一个通过大规模智能体强化学习训练的形式定理证明模型，结合高效测试时扩展工作流，显著提升了形式定理证明的能力和效率，在多个数学竞赛基准测试中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在生成严格数学证明方面取得进展，但在形式语言（如Lean）中进行定理证明仍然具有挑战性且计算成本高昂，特别是在处理本科及以上级别的问题时。需要开发更高效的形式定理证明方法。

Method: 1. 通过大规模智能体强化学习训练Seed-Prover 1.5模型，通过与Lean等工具持续交互积累经验；2. 开发高效的测试时扩展工作流，利用自然语言证明的最新进展，弥合自然语言与形式语言之间的差距。

Result: 1. 在计算预算较小的情况下优于现有方法；2. 解决了PutnamBench（本科级别）88%的问题、Fate-H（研究生级别）80%的问题、Fate-X（博士级别）33%的问题；3. 在9小时内解决了Putnam 2025竞赛12道题中的11道。

Conclusion: 通过高质量形式反馈驱动的经验学习扩展具有巨大潜力，为形式数学推理的未来发展指明了方向。Seed-Prover 1.5展示了智能体强化学习在提升形式定理证明能力方面的有效性。

Abstract: Large language models have recently made significant progress to generate rigorous mathematical proofs. In contrast, utilizing LLMs for theorem proving in formal languages (such as Lean) remains challenging and computationally expensive, particularly when addressing problems at the undergraduate level and beyond. In this work, we present \textbf{Seed-Prover 1.5}, a formal theorem-proving model trained via large-scale agentic reinforcement learning, alongside an efficient test-time scaling (TTS) workflow. Through extensive interactions with Lean and other tools, the model continuously accumulates experience during the RL process, substantially enhancing the capability and efficiency of formal theorem proving. Furthermore, leveraging recent advancements in natural language proving, our TTS workflow efficiently bridges the gap between natural and formal languages. Compared to state-of-the-art methods, Seed-Prover 1.5 achieves superior performance with a smaller compute budget. It solves \textbf{88\% of PutnamBench} (undergraduate-level), \textbf{80\% of Fate-H} (graduate-level), and \textbf{33\% of Fate-X} (PhD-level) problems. Notably, using our system, we solved \textbf{11 out of 12 problems} from Putnam 2025 within 9 hours. Our findings suggest that scaling learning from experience, driven by high-quality formal feedback, holds immense potential for the future of formal mathematical reasoning.

</details>


### [11] [AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators](https://arxiv.org/abs/2512.17267)
*Michael J. Ryan,Yanzhe Zhang,Amol Salunkhe,Yi Chu,Di Xu,Diyi Yang*

Main category: cs.CL

TL;DR: AutoMetrics是一个在低数据约束下合成评估指标的框架，通过检索预定义指标库和基于轻量人类反馈的LLM自动生成标准，结合回归方法最大化与人类信号的相关性，显著提升评估效果。


<details>
  <summary>Details</summary>
Motivation: 评估面向用户的AI应用（如旅行规划、临床笔记生成、对话系统）面临挑战，黄金标准（用户反馈或行为信号）在原型和研究项目中往往稀缺或响应太慢，无法用于系统优化。

Method: 1. 从MetricBank（包含48个预定义指标）中检索相关指标；2. 基于轻量人类反馈自动生成LLM-as-a-Judge评估标准；3. 通过回归方法组合这些指标，最大化与人类信号的相关性。

Result: 在5个多样化任务中，AutoMetrics将Kendall相关系数相比LLM-as-a-Judge提升了33.4%，仅需少于100个反馈点。AutoMetrics可作为代理奖励，效果与可验证奖励相当。

Conclusion: AutoMetrics提供了一种从昂贵人工评估到可解释自动指标的转换方法，加速LLM应用的适应性评估，并发布了完整的AutoMetrics工具包和MetricBank。

Abstract: Evaluating user-facing AI applications remains a central challenge, especially in open-ended domains such as travel planning, clinical note generation, or dialogue. The gold standard is user feedback (e.g., thumbs up/down) or behavioral signals (e.g., retention), but these are often scarce in prototypes and research projects, or too-slow to use for system optimization. We present AutoMetrics, a framework for synthesizing evaluation metrics under low-data constraints. AutoMetrics combines retrieval from MetricBank, a collection of 48 metrics we curate, with automatically generated LLM-as-a-Judge criteria informed by lightweight human feedback. These metrics are composed via regression to maximize correlation with human signal. AutoMetrics takes you from expensive measures to interpretable automatic metrics. Across 5 diverse tasks, AutoMetrics improves Kendall correlation with human ratings by up to 33.4% over LLM-as-a-Judge while requiring fewer than 100 feedback points. We show that AutoMetrics can be used as a proxy reward to equal effect as a verifiable reward. We release the full AutoMetrics toolkit and MetricBank to accelerate adaptive evaluation of LLM applications.

</details>


### [12] [Subjective Question Generation and Answer Evaluation using NLP](https://arxiv.org/abs/2512.17289)
*G. M. Refatul Islam,Safwan Shaheer,Yaseen Nur,Mohammad Rafid Hamid*

Main category: cs.CL

TL;DR: 该研究旨在改进或创建新的NLP模型，用于从文本输入自动生成主观问题并评估答案


<details>
  <summary>Details</summary>
Motivation: 虽然客观问题生成已有较多研究，但主观问题生成和答案评估仍处于发展阶段。自动化系统可帮助教师评估学生作业，并让学生通过自我评估来增强学习体验

Method: 研究计划改进现有NLP模型或创建新模型，专注于从文本输入自动生成主观问题并评估答案

Result: 论文摘要未提供具体实验结果，但描述了研究目标和潜在应用场景

Conclusion: 该研究旨在推动NLP在教育领域的应用，特别是在主观问题生成和评估方面，以支持教学和学习过程

Abstract: Natural Language Processing (NLP) is one of the most revolutionary technologies today. It uses artificial intelligence to understand human text and spoken words. It is used for text summarization, grammar checking, sentiment analysis, and advanced chatbots and has many more potential use cases. Furthermore, it has also made its mark on the education sector. Much research and advancements have already been conducted on objective question generation; however, automated subjective question generation and answer evaluation are still in progress. An automated system to generate subjective questions and evaluate the answers can help teachers assess student work and enhance the student's learning experience by allowing them to self-assess their understanding after reading an article or a chapter of a book. This research aims to improve current NLP models or make a novel one for automated subjective question generation and answer evaluation from text input.

</details>


### [13] [Governance-Aware Hybrid Fine-Tuning for Multilingual Large Language Models](https://arxiv.org/abs/2512.17344)
*Haomin Qi,Chengbo Huang,Zihan Dai,Yunkai Gao*

Main category: cs.CL

TL;DR: 提出一个结合梯度对齐低秩更新与结构化正交变换的混合微调框架，用于多语言低资源场景下的LLM适配，配合轻量级数据治理步骤，在有限计算预算下提升准确性、校准和跨语言平衡。


<details>
  <summary>Details</summary>
Motivation: 解决在多语言低资源环境下，大型语言模型适配面临的计算成本高、跨语言性能不平衡、概率校准不佳等问题，寻求资源高效的解决方案。

Method: 1) 混合微调算法：结合梯度对齐低秩更新与结构化正交变换，通过层间混合实现；2) 在选定子层引入酉约束以稳定深度优化；3) 轻量级无标签数据治理：语言识别、近重复去除、质量过滤。

Result: 在XNLI和FLORES数据集上，相比强PEFT基线获得一致提升，保持方向平衡并改善概率校准；对轻量级拼写变体更具鲁棒性；数据治理步骤带来额外增益；训练开销适中，具有有利的成本-质量边界。

Conclusion: 混合和酉约束的PEFT结合实用数据治理，为资源高效的多语言适配提供了稳定且可实现的路径。

Abstract: We present a governance-aware hybrid fine-tuning framework for multilingual, low-resource adaptation of large language models. The core algorithm combines gradient-aligned low-rank updates with structured orthogonal transformations through layer-wise mixing and introduces unitary constraints in selected sub-layers to stabilize deep optimization. In tandem with lightweight, label-free data governance steps, including language identification, near-duplicate removal, and quality filtering, the framework targets accuracy, calibration, and cross-language parity under tight compute budgets. Across XNLI and FLORES, the hybrid approach delivers consistent gains over strong PEFT baselines while maintaining directional balance and improving probability calibration, as shown in Tables II and III. It is more resilient to lightweight orthographic variants, as shown in Table IV, and benefits additively from simple governance steps, as shown in Table V. Training footprint measurements indicate modest overhead and a favorable cost-quality frontier, as shown in Table VI and Figure 2. Together, these results show that hybrid and unitary PEFT provide a stable and accessible path to resource-efficient multilingual adaptation when paired with practical data governance.

</details>


### [14] [Stakeholder Suite: A Unified AI Framework for Mapping Actors, Topics and Arguments in Public Debates](https://arxiv.org/abs/2512.17347)
*Mohamed Chenene,Jeanne Rouhier,Jean Daniélou,Mihir Sarkar,Elena Cabrio*

Main category: cs.CL

TL;DR: Stakeholder Suite是一个用于分析公共辩论中利益相关者、话题和论点的框架，通过统一管道实现参与者检测、话题建模、论点提取和立场分类，在能源基础设施项目中验证有效。


<details>
  <summary>Details</summary>
Motivation: 基础设施和能源项目的公共辩论涉及复杂的利益相关者网络和不断演变的叙事，现有媒体情报工具主要依赖描述性分析且透明度有限，需要更有效的工具来理解这些动态以预测争议并制定参与策略。

Method: 提出Stakeholder Suite框架，结合参与者检测、话题建模、论点提取和立场分类的统一管道，在多个能源基础设施项目中进行案例研究测试。

Result: 框架实现了高检索精度和立场准确性，在试点用例中75%的论点被判定为相关；在操作层面帮助项目团队可视化影响力网络、识别新兴争议并支持基于证据的决策制定。

Conclusion: Stakeholder Suite为公共辩论分析提供了细粒度、基于来源的洞察，框架具有领域适应性，已在操作环境中证明有效，超越了传统的描述性分析工具。

Abstract: Public debates surrounding infrastructure and energy projects involve complex networks of stakeholders, arguments, and evolving narratives. Understanding these dynamics is crucial for anticipating controversies and informing engagement strategies, yet existing tools in media intelligence largely rely on descriptive analytics with limited transparency. This paper presents Stakeholder Suite, a framework deployed in operational contexts for mapping actors, topics, and arguments within public debates. The system combines actor detection, topic modeling, argument extraction and stance classification in a unified pipeline. Tested on multiple energy infrastructure projects as a case study, the approach delivers fine-grained, source-grounded insights while remaining adaptable to diverse domains. The framework achieves strong retrieval precision and stance accuracy, producing arguments judged relevant in 75% of pilot use cases. Beyond quantitative metrics, the tool has proven effective for operational use: helping project teams visualize networks of influence, identify emerging controversies, and support evidence-based decision-making.

</details>


### [15] [Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers](https://arxiv.org/abs/2512.17351)
*Zeyuan Allen-Zhu*

Main category: cs.CL

TL;DR: 论文提出CANON LAYERS——轻量级架构组件，通过加权求和邻近token表示来促进水平信息流动，可无缝集成到各种序列架构中，显著提升模型能力。


<details>
  <summary>Details</summary>
Motivation: 在学术规模预训练（如13亿参数，1000亿token）中，语言模型的架构差异分析常被噪声和随机性主导，难以准确评估核心模型能力。

Method: 引入受控合成预训练任务来隔离和评估核心模型能力；提出CANON LAYERS组件，计算邻近token表示的加权和，可集成到Transformer、线性注意力、状态空间模型等序列架构中。

Result: 12个关键结果显示：Canon层将推理深度提升2倍，增强推理广度、知识操作等能力；使弱架构（如NoPE）匹配RoPE，线性注意力达到Mamba2/GDN等SOTA水平；通过合成任务和真实学术规模预训练验证。

Conclusion: 合成预训练任务为经济、原则性地隔离核心模型能力提供了新途径；结合无限高质量数据，可预测未来架构在训练流程改进后的表现，解锁更深层推理和层次推断能力。

Abstract: Understanding architectural differences in language models is challenging, especially at academic-scale pretraining (e.g., 1.3B parameters, 100B tokens), where results are often dominated by noise and randomness. To overcome this, we introduce controlled synthetic pretraining tasks that isolate and evaluate core model capabilities. Within this framework, we discover CANON LAYERS: lightweight architectural components -- named after the musical term "canon" -- that promote horizontal information flow across neighboring tokens. Canon layers compute weighted sums of nearby token representations and integrate seamlessly into Transformers, linear attention, state-space models, or any sequence architecture.
  We present 12 key results. This includes how Canon layers enhance reasoning depth (e.g., by $2\times$), reasoning breadth, knowledge manipulation, etc. They lift weak architectures like NoPE to match RoPE, and linear attention to rival SOTA linear models like Mamba2/GDN -- validated both through synthetic tasks and real-world academic-scale pretraining. This synthetic playground offers an economical, principled path to isolate core model capabilities often obscured at academic scales. Equipped with infinite high-quality data, it may even PREDICT how future architectures will behave as training pipelines improve -- e.g., through better data curation or RL-based post-training -- unlocking deeper reasoning and hierarchical inference.

</details>


### [16] [UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models](https://arxiv.org/abs/2512.17385)
*Jiajun Wu,Jian Yang,Wei Zhang,Lin Jing,Yuqing Ma,Ensheng Shi,Yuchi Ma,Zhoujun Li,Xianglong Liu*

Main category: cs.CL

TL;DR: IPC：一种无监督代码生成框架，通过内部探测LLM的知识和置信模式，无需外部语料库，实现与监督方法相媲美的性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成任务中表现优异，但严重依赖大量标注数据或无标注代码片段，这些数据获取成本高且难以大规模获得。需要解决对标注数据和计算资源的依赖问题。

Method: IPC框架包含：问题空间探测、测试理解探测、解决方案空间探测、知识整合与强化。通过自一致性机制和基于表示的质量估计来识别可靠代码候选，训练UCoder（无监督学习的编码器）。

Result: 在多个代码基准测试中验证，无监督方法能达到与监督方法相竞争的性能，同时显著减少对标注数据和计算资源的依赖。分析实验表明模型内部状态包含丰富的代码质量和正确性信号。

Conclusion: 通过适当利用LLM内部状态信号，可以实现有效的无监督代码生成学习，为资源受限场景下训练代码LLM开辟了新方向。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, their effectiveness heavily relies on supervised training with extensive labeled (e.g., question-answering pairs) or unlabeled datasets (e.g., code snippets), which are often expensive and difficult to obtain at scale. To address this limitation, this paper introduces a method IPC, an unsupervised framework that leverages Internal Probing of LLMs for Code generation without any external corpus, even unlabeled code snippets. We introduce the problem space probing, test understanding probing, solution space probing, and knowledge consolidation and reinforcement to probe the internal knowledge and confidence patterns existing in LLMs. Further, IPC identifies reliable code candidates through self-consistency mechanisms and representation-based quality estimation to train UCoder (coder with unsupervised learning). We validate the proposed approach across multiple code benchmarks, demonstrating that unsupervised methods can achieve competitive performance compared to supervised approaches while significantly reducing the dependency on labeled data and computational resources. Analytic experiments reveal that internal model states contain rich signals about code quality and correctness, and that properly harnessing these signals enables effective unsupervised learning for code generation tasks, opening new directions for training code LLMs in resource-constrained scenarios.

</details>


### [17] [Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?](https://arxiv.org/abs/2512.17394)
*Zabir Al Nazi,G M Shahariar,Abrar Hossain,Wei Peng*

Main category: cs.CL

TL;DR: 提出了CulturalToM-VQA基准，包含5095个问题，通过视觉问答评估跨文化心理理论推理能力，涵盖不同文化背景下的仪式、服饰、手势等文化线索。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型越来越多地应用于社会性任务，但其跨文化心理理论推理能力尚未得到充分探索。心理理论是人类社会智能的基础，但对人工智能仍是一个重大挑战。

Method: 采用VLM辅助的人机协作流程：人类专家首先策划涵盖传统、仪式和社会互动的文化丰富图像；然后VLM生成结构化的心理理论场景描述；最后将这些描述细化为涵盖六种心理理论任务和四个复杂度等级的问题-答案对。

Result: 构建了CulturalToM-VQA数据集，包含5095个问题，涵盖心理状态归因、错误信念推理、非字面沟通、社会规范违反、视角协调和多智能体推理等六个心理理论方面。

Conclusion: 该数据集能够系统评估心理理论推理能力，超越西方中心主义基准，为评估AI模型在多样化文化背景下的社会智能提供了重要工具。

Abstract: Theory of Mind (ToM) -- the ability to attribute beliefs, desires, and emotions to others -- is fundamental for human social intelligence, yet remains a major challenge for artificial agents. Existing Vision-Language Models (VLMs) are increasingly applied in socially grounded tasks, but their capacity for cross-cultural ToM reasoning is largely unexplored. In this work, we introduce CulturalToM-VQA, a new evaluation benchmark containing 5095 questions designed to probe ToM reasoning across diverse cultural contexts through visual question answering. The dataset captures culturally grounded cues such as rituals, attire, gestures, and interpersonal dynamics, enabling systematic evaluation of ToM reasoning beyond Western-centric benchmarks. Our dataset is built through a VLM-assisted human-in-the-loop pipeline, where human experts first curate culturally rich images across traditions, rituals, and social interactions; a VLM then assist in generating structured ToM-focused scene descriptions, which are refined into question-answer pairs spanning a taxonomy of six ToM tasks and four graded complexity levels. The resulting dataset covers diverse theory of mind facets such as mental state attribution, false belief reasoning, non-literal communication, social norm violations, perspective coordination, and multi-agent reasoning.

</details>


### [18] [Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection](https://arxiv.org/abs/2512.17630)
*Menna Elgabry,Ali Hamdi*

Main category: cs.CL

TL;DR: 提出基于Condorcet陪审团定理的置信加权、可信度感知集成框架，用于文本情感检测，通过架构多样的小型LLM集成在595M参数下达到93.5%的宏F1分数，超越7B参数大模型。


<details>
  <summary>Details</summary>
Motivation: 传统集成方法通常依赖同质架构，缺乏错误多样性。大型LLM虽然强大但参数效率低，且在小样本任务上表现不佳。需要设计参数高效且能利用模型独特偏见的集成方法。

Method: 1) 集成架构多样的5个小Transformer模型(BERT、RoBERTa、DistilBERT、DeBERTa、ELECTRA)，全部针对情感分类进行微调；2) 最小化参数收敛以保持错误多样性；3) 设计双加权投票机制：全局可信度(验证F1分数)和局部置信度(实例级概率)动态加权模型贡献。

Result: 在DAIR-AI数据集上达到93.5%的宏F1分数，超越所有SOTA基准模型，显著优于Falcon、Mistral、Qwen、Phi等大型LLM(即使经过LoRA微调)。仅595M总参数，比7B参数模型更参数高效和鲁棒。

Conclusion: 精心设计的小型微调模型集成可以在专门NLP任务(如情感检测)上超越大型LLM，证明参数效率与性能可兼得。Condorcet陪审团定理启发的可信度-置信度集成框架是有效的解决方案。

Abstract: This paper introduces a confidence-weighted, credibility-aware ensemble framework for text-based emotion detection, inspired by Condorcet's Jury Theorem (CJT). Unlike conventional ensembles that often rely on homogeneous architectures, our approach combines architecturally diverse small transformer-based large language models (sLLMs) - BERT, RoBERTa, DistilBERT, DeBERTa, and ELECTRA, each fully fine-tuned for emotion classification. To preserve error diversity, we minimize parameter convergence while taking advantage of the unique biases of each model. A dual-weighted voting mechanism integrates both global credibility (validation F1 score) and local confidence (instance-level probability) to dynamically weight model contributions. Experiments on the DAIR-AI dataset demonstrate that our credibility-confidence ensemble achieves a macro F1 score of 93.5 percent, surpassing state-of-the-art benchmarks and significantly outperforming large-scale LLMs, including Falcon, Mistral, Qwen, and Phi, even after task-specific Low-Rank Adaptation (LoRA). With only 595M parameters in total, our small LLMs ensemble proves more parameter-efficient and robust than models up to 7B parameters, establishing that carefully designed ensembles of small, fine-tuned models can outperform much larger LLMs in specialized natural language processing (NLP) tasks such as emotion detection.

</details>


### [19] [Linear Personality Probing and Steering in LLMs: A Big Five Study](https://arxiv.org/abs/2512.17639)
*Michel Frising,Daniel Balcells*

Main category: cs.CL

TL;DR: 研究发现大语言模型可以通过线性方向探测和引导人格特质，在人格检测方面有效，但在开放生成任务中引导效果有限。


<details>
  <summary>Details</summary>
Motivation: 大语言模型具有一致的人格特质，这对信任和参与度很重要。当前的人格特征化方法要么成本高（后训练），要么脆弱（提示工程）。线性方向探测和引导作为一种廉价高效的替代方案值得研究。

Method: 使用Llama 3.3 70B模型生成406个虚构角色及其大五人格特质分数。通过提示模型描述和Alpaca问卷问题，采样随人格特质变化的隐藏激活。使用线性回归学习激活空间中每层的线性方向，测试其探测和引导能力。

Result: 与特质分数对齐的线性方向在人格检测方面是有效的探针，但其引导能力强烈依赖于上下文：在强制选择任务中产生可靠效果，但在开放生成或提示中包含额外上下文时影响有限。

Conclusion: 线性方向可以有效地探测大语言模型的人格特质，但引导模型行为需要更复杂的机制，特别是在开放生成任务中。这为低成本的人格特征化和控制提供了有前景的方向。

Abstract: Large language models (LLMs) exhibit distinct and consistent personalities that greatly impact trust and engagement. While this means that personality frameworks would be highly valuable tools to characterize and control LLMs' behavior, current approaches remain either costly (post-training) or brittle (prompt engineering). Probing and steering via linear directions has recently emerged as a cheap and efficient alternative. In this paper, we investigate whether linear directions aligned with the Big Five personality traits can be used for probing and steering model behavior. Using Llama 3.3 70B, we generate descriptions of 406 fictional characters and their Big Five trait scores. We then prompt the model with these descriptions and questions from the Alpaca questionnaire, allowing us to sample hidden activations that vary along personality traits in known, quantifiable ways. Using linear regression, we learn a set of per-layer directions in activation space, and test their effectiveness for probing and steering model behavior. Our results suggest that linear directions aligned with trait-scores are effective probes for personality detection, while their steering capabilities strongly depend on context, producing reliable effects in forced-choice tasks but limited influence in open-ended generation or when additional context is present in the prompt.

</details>


### [20] [Simulstream: Open-Source Toolkit for Evaluation and Demonstration of Streaming Speech-to-Text Translation Systems](https://arxiv.org/abs/2512.17648)
*Marco Gaido,Sara Papi,Mauro Cettolo,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: simulstream是一个专门用于流式语音到文本翻译的统一评估和演示框架，支持增量解码和重翻译方法，并提供交互式Web界面。


<details>
  <summary>Details</summary>
Motivation: 现有的SimulEval库已不再维护，不支持输出修订系统，且设计用于短片段处理而非长音频流，缺乏演示功能，需要一个新的流式语音翻译评估框架。

Method: 开发了simulstream开源框架，支持长语音处理，兼容增量解码和重翻译方法，提供统一的评估指标（质量和延迟），并包含交互式Web演示界面。

Result: simulstream成为首个专门用于流式语音到文本翻译的统一评估和演示框架，解决了现有工具的限制，支持多种系统类型的比较和展示。

Conclusion: simulstream框架填补了流式语音翻译评估领域的空白，为研究人员提供了统一、全面的工具来评估和展示各种流式翻译系统。

Abstract: Streaming Speech-to-Text Translation (StreamST) requires producing translations concurrently with incoming speech, imposing strict latency constraints and demanding models that balance partial-information decision-making with high translation quality. Research efforts on the topic have so far relied on the SimulEval repository, which is no longer maintained and does not support systems that revise their outputs. In addition, it has been designed for simulating the processing of short segments, rather than long-form audio streams, and it does not provide an easy method to showcase systems in a demo. As a solution, we introduce simulstream, the first open-source framework dedicated to unified evaluation and demonstration of StreamST systems. Designed for long-form speech processing, it supports not only incremental decoding approaches, but also re-translation methods, enabling for their comparison within the same framework both in terms of quality and latency. In addition, it also offers an interactive web interface to demo any system built within the tool.

</details>


### [21] [Peeking Into The Future For Contextual Biasing](https://arxiv.org/abs/2512.17657)
*Ramaneswaran Selvakumar,Cindy Tseng,Eesung Kim,Vijendra Raj Apsingekar,Yun Tang*

Main category: cs.CL

TL;DR: 提出一种用于注意力编码器解码器模型的上下文偏置方法，通过同时预测多个未来token来评分候选命名实体，无需额外实体编码器或交叉注意力层


<details>
  <summary>Details</summary>
Motivation: 端到端语音识别模型在通用转录方面表现出色，但在识别罕见或未见过的命名实体（如联系人姓名、位置）方面存在困难，而这些实体对于虚拟助手等下游应用至关重要

Method: 提出基于候选命名实体列表的上下文偏置方法，不仅预测下一个token，同时预测多个未来token，使模型能够"窥视未来"并对实体列表中的候选实体进行评分。该方法直接利用多token预测logits，无需额外实体编码器或交叉注意力层

Result: 在Librispeech上的实验表明，与基线AED模型相比，该方法在命名实体词错误率方面实现了高达50.34%的相对改进

Conclusion: 该方法通过多token预测实现有效的上下文偏置，显著降低了架构复杂性，同时大幅提高了命名实体识别性能

Abstract: While end-to-end (E2E) automatic speech recognition (ASR) models excel at general transcription, they struggle to recognize rare or unseen named entities (e.g., contact names, locations), which are critical for downstream applications like virtual assistants. In this paper, we propose a contextual biasing method for attention based encoder decoder (AED) models using a list of candidate named entities. Instead of predicting only the next token, we simultaneously predict multiple future tokens, enabling the model to "peek into the future" and score potential candidate entities in the entity list. Moreover, our approach leverages the multi-token prediction logits directly without requiring additional entity encoders or cross-attention layers, significantly reducing architectural complexity. Experiments on Librispeech demonstrate that our approach achieves up to 50.34% relative improvement in named entity word error rate compared to the baseline AED model.

</details>


### [22] [Toward Ethical AI Through Bayesian Uncertainty in Neural Question Answering](https://arxiv.org/abs/2512.17677)
*Riccardo Di Sipio*

Main category: cs.CL

TL;DR: 论文探索贝叶斯推理在问答神经网络中量化不确定性的方法，从Iris数据集扩展到语言模型，比较Laplace近似与MAP估计，实现选择性预测以提升系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络问答系统缺乏不确定性量化能力，无法表达预测置信度，这限制了系统的可解释性和负责任部署。需要开发能够识别并表达"不知道"的可靠系统。

Method: 采用贝叶斯推理方法：1) 在Iris数据集上使用多层感知机进行后验推断；2) 扩展到语言模型，先应用于冻结头部；3) 最终应用于LoRA适配的Transformer；4) 比较Laplace近似与MAP估计；5) 实现基于置信度的选择性预测。

Result: 贝叶斯方法能够有效量化预测不确定性，Laplace近似相比MAP估计能更好地校准不确定性。系统能够根据置信度水平选择性地回答或放弃回答，提升了可靠性和可解释性。

Conclusion: 贝叶斯推理为神经网络问答系统提供了有效的不确定性量化方法，使模型能够在低置信度时放弃回答，这有助于构建更负责任、更符合伦理的AI系统部署。

Abstract: We explore Bayesian reasoning as a means to quantify uncertainty in neural networks for question answering. Starting with a multilayer perceptron on the Iris dataset, we show how posterior inference conveys confidence in predictions. We then extend this to language models, applying Bayesian inference first to a frozen head and finally to LoRA-adapted transformers, evaluated on the CommonsenseQA benchmark. Rather than aiming for state-of-the-art accuracy, we compare Laplace approximations against maximum a posteriori (MAP) estimates to highlight uncertainty calibration and selective prediction. This allows models to abstain when confidence is low. An ``I don't know'' response not only improves interpretability but also illustrates how Bayesian methods can contribute to more responsible and ethical deployment of neural question-answering systems.

</details>


### [23] [When the Gold Standard isn't Necessarily Standard: Challenges of Evaluating the Translation of User-Generated Content](https://arxiv.org/abs/2512.17738)
*Lydia Nishimwe,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 本文研究了用户生成内容（UGC）翻译中的非标准语言处理问题，提出了非标准现象分类和翻译操作框架，并发现翻译评分对提示指令高度敏感，需要与数据集指南对齐才能公平评估。


<details>
  <summary>Details</summary>
Motivation: 用户生成内容（UGC）包含大量非标准语言（拼写错误、俚语、字符重复、表情符号等），这使得评估UGC翻译变得特别困难，因为"好"翻译的标准取决于输出所需的标准化程度。

Method: 分析四个UGC数据集的人工翻译指南，推导出12种非标准现象分类和5种翻译操作（标准化、复制、转移、省略、审查）。通过大语言模型案例研究，探索翻译评分对提示指令的敏感性。

Result: 研究发现UGC处理方式存在显著差异，导致参考翻译的标准化程度形成连续谱系。翻译评分对包含明确UGC翻译指令的提示高度敏感，当这些指令与数据集指南一致时，评分会提高。

Conclusion: 当保留UGC风格很重要时，公平评估需要模型和指标都能理解翻译指南。呼吁在数据集创建时提供清晰指南，并开发可控的、指南感知的UGC翻译评估框架。

Abstract: User-generated content (UGC) is characterised by frequent use of non-standard language, from spelling errors to expressive choices such as slang, character repetitions, and emojis. This makes evaluating UGC translation particularly challenging: what counts as a "good" translation depends on the level of standardness desired in the output. To explore this, we examine the human translation guidelines of four UGC datasets, and derive a taxonomy of twelve non-standard phenomena and five translation actions (NORMALISE, COPY, TRANSFER, OMIT, CENSOR). Our analysis reveals notable differences in how UGC is treated, resulting in a spectrum of standardness in reference translations. Through a case study on large language models (LLMs), we show that translation scores are highly sensitive to prompts with explicit translation instructions for UGC, and that they improve when these align with the dataset's guidelines. We argue that when preserving UGC style is important, fair evaluation requires both models and metrics to be aware of translation guidelines. Finally, we call for clear guidelines during dataset creation and for the development of controllable, guideline-aware evaluation frameworks for UGC translation.

</details>


### [24] [Affect, Body, Cognition, Demographics, and Emotion: The ABCDE of Text Features for Computational Affective Science](https://arxiv.org/abs/2512.17752)
*Jan Philip Wahle,Krishnapriya Vishnubhotla,Bela Gipp,Saif M. Mohammad*

Main category: cs.CL

TL;DR: ABCDE数据集是一个包含4亿多条文本的大规模标注数据集，涵盖社交媒体、博客、书籍和AI生成内容，标注了情感、身体、认知、人口统计和情绪等特征，旨在降低跨学科研究门槛。


<details>
  <summary>Details</summary>
Motivation: 当前计算情感科学和计算社会科学研究需要大量标注数据，但现有资源发现、访问和使用存在障碍，特别是对计算机科学领域外的研究者。需要降低数据获取门槛，促进跨学科研究。

Method: 构建ABCDE数据集，从社交媒体、博客、书籍和AI生成来源收集超过4亿条文本话语，并进行广泛的特征标注，包括情感、身体、认知、人口统计和情绪等相关特征。

Result: 创建了一个大规模、多来源的标注数据集，包含400多万条文本，涵盖多种特征维度，为跨学科研究提供了统一的数据资源。

Conclusion: ABCDE数据集解决了计算情感科学和计算社会科学研究中数据获取的障碍，促进了跨学科合作，支持情感科学、认知科学、数字人文、社会学、政治学和计算语言学等多个领域的研究。

Abstract: Work in Computational Affective Science and Computational Social Science explores a wide variety of research questions about people, emotions, behavior, and health. Such work often relies on language data that is first labeled with relevant information, such as the use of emotion words or the age of the speaker. Although many resources and algorithms exist to enable this type of labeling, discovering, accessing, and using them remains a substantial impediment, particularly for practitioners outside of computer science. Here, we present the ABCDE dataset (Affect, Body, Cognition, Demographics, and Emotion), a large-scale collection of over 400 million text utterances drawn from social media, blogs, books, and AI-generated sources. The dataset is annotated with a wide range of features relevant to computational affective and social science. ABCDE facilitates interdisciplinary research across numerous fields, including affective science, cognitive science, the digital humanities, sociology, political science, and computational linguistics.

</details>


### [25] [AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora](https://arxiv.org/abs/2512.17756)
*Zhihan Zhou,Daqian Shi,Rui Song,Lida Shi,Xiaolei Diao,Hao Xu*

Main category: cs.CL

TL;DR: AncientBench：首个针对出土文献古文字理解评估的基准，包含字形、字音、字义、上下文四个维度十个任务，评估大语言模型在考古领域的古文字理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有中文基准主要针对现代汉语和传世文献，缺乏对出土文献古文字理解的评估。考古学和中华文明理解需要专门的古文字理解评估工具。

Method: 构建AncientBench基准，包含四个维度（字形、字音、字义、上下文理解）和十个任务（部首、声旁、同音字、完形填空、翻译等）。邀请考古研究人员进行实验评估，提出古文字模型作为基线，对当前最佳大语言模型进行广泛实验。

Result: 实验结果显示大语言模型在古文字场景具有巨大潜力，但仍与人类存在差距。基准为古文字理解提供了全面评估框架。

Conclusion: AncientBench填补了出土文献古文字理解评估的空白，将促进大语言模型在考古学和古汉语领域的发展与应用。

Abstract: Comprehension of ancient texts plays an important role in archaeology and understanding of Chinese history and civilization. The rapid development of large language models needs benchmarks that can evaluate their comprehension of ancient characters. Existing Chinese benchmarks are mostly targeted at modern Chinese and transmitted documents in ancient Chinese, but the part of excavated documents in ancient Chinese is not covered. To meet this need, we propose the AncientBench, which aims to evaluate the comprehension of ancient characters, especially in the scenario of excavated documents. The AncientBench is divided into four dimensions, which correspond to the four competencies of ancient character comprehension: glyph comprehension, pronunciation comprehension, meaning comprehension, and contextual comprehension. The benchmark also contains ten tasks, including radical, phonetic radical, homophone, cloze, translation, and more, providing a comprehensive framework for evaluation. We convened archaeological researchers to conduct experimental evaluations, proposed an ancient model as baseline, and conducted extensive experiments on the currently best-performing large language models. The experimental results reveal the great potential of large language models in ancient textual scenarios as well as the gap with humans. Our research aims to promote the development and application of large language models in the field of archaeology and ancient Chinese language.

</details>


### [26] [Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity](https://arxiv.org/abs/2512.17769)
*Tanjim Taharat Aurpa,Farzana Akter,Md. Mehedi Hasan,Shakil Ahmed,Shifat Ara Rafiq,Fatema Khan*

Main category: cs.CL

TL;DR: 本文提出了一种用于孟加拉语医学实体识别的多BERT集成方法，在缺乏标注数据的低资源语言环境下，该方法比单层BERT模型准确率提高了11.80%，达到89.58%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 医学实体识别（MedER）对于医疗领域的自动化系统开发至关重要，但目前研究主要集中在英语等资源丰富的语言，像孟加拉语这样的低资源语言研究不足。本文旨在填补这一空白，为孟加拉语医疗文本提供有效的实体识别解决方案。

Method: 首先评估了多种Transformer模型（BERT、DistilBERT、ELECTRA、RoBERTa），然后提出了一种新颖的多BERT集成方法。同时为了解决低资源语言缺乏标注数据的问题，专门构建了一个高质量的孟加拉语医学实体识别数据集。

Result: 多BERT集成方法在所有基线模型中表现最佳，达到89.58%的最高准确率，比单层BERT模型提高了11.80%的准确率。通过多种性能指标验证了该方法的鲁棒性和适用性。

Conclusion: 多BERT集成模型在孟加拉语医学实体识别任务中展现出巨大潜力，为低资源语言的医疗NLP研究奠定了基础，推动了该领域的进一步发展。

Abstract: Medical Entity Recognition (MedER) is an essential NLP task for extracting meaningful entities from the medical corpus. Nowadays, MedER-based research outcomes can remarkably contribute to the development of automated systems in the medical sector, ultimately enhancing patient care and outcomes. While extensive research has been conducted on MedER in English, low-resource languages like Bangla remain underexplored. Our work aims to bridge this gap. For Bangla medical entity recognition, this study first examined a number of transformer models, including BERT, DistilBERT, ELECTRA, and RoBERTa. We also propose a novel Multi-BERT Ensemble approach that outperformed all baseline models with the highest accuracy of 89.58%. Notably, it provides an 11.80% accuracy improvement over the single-layer BERT model, demonstrating its effectiveness for this task. A major challenge in MedER for low-resource languages is the lack of annotated datasets. To address this issue, we developed a high-quality dataset tailored for the Bangla MedER task. The dataset was used to evaluate the effectiveness of our model through multiple performance metrics, demonstrating its robustness and applicability. Our findings highlight the potential of Multi-BERT Ensemble models in improving MedER for Bangla and set the foundation for further advancements in low-resource medical NLP.

</details>


### [27] [DEER: A Comprehensive and Reliable Benchmark for Deep-Research Expert Reports](https://arxiv.org/abs/2512.17776)
*Janghoon Han,Heegyu Kim,Changho Lee,Dahm Lee,Min Hyung Park,Hosung Song,Stanley Jungkyu Choi,Moontae Lee,Honglak Lee*

Main category: cs.CL

TL;DR: DEER是一个评估专家级深度研究报告的基准，包含50个跨13个领域的报告写作任务，提供专家评估分类体系和任务特定指导，并提出了文档级事实核查架构来验证报告中所有声明。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型能够生成专家级报告，但现有评估基准缺乏系统性的专家报告标准，LLM评估难以捕捉需要专家判断的问题，且源验证通常只覆盖有限的部分引用声明而非整个报告的事实可靠性。

Method: 1) 构建包含50个跨13个领域报告写作任务的DEER基准；2) 开发专家基础的评估分类法（7个维度，25个子维度）细化为130个精细评分项；3) 提供任务特定专家指导以帮助LLM评估者更一致地评估报告质量；4) 提出文档级事实核查架构，提取并验证报告中所有声明（包括引用和未引用的），量化外部证据质量。

Result: DEER与人类专家判断高度相关，能够产生可解释的系统优势和弱点诊断，提供更全面和可靠的专家级报告评估。

Conclusion: DEER基准通过系统化的评估分类法、专家指导和全面的文档级事实核查，为评估专家级深度研究报告提供了更可靠和可解释的框架，解决了现有评估方法的局限性。

Abstract: As large language models (LLMs) advance, deep research systems can generate expert-level reports via multi-step reasoning and evidence-based synthesis, but evaluating such reports remains challenging. Existing benchmarks often lack systematic criteria for expert reporting, evaluations that rely heavily on LLM judges can fail to capture issues that require expert judgment, and source verification typically covers only a limited subset of explicitly cited statements rather than report-wide factual reliability. We introduce DEER, a benchmark for evaluating expert-level deep research reports. DEER comprises 50 report-writing tasks spanning 13 domains and an expert-grounded evaluation taxonomy (7 dimensions, 25 sub-dimension) operationalized into 130 fine-grained rubric items. DEER further provides task-specific expert guidance to help LLM judges assess expert-level report quality more consistently. Complementing rubric-based assessment, we propose a document-level fact-checking architecture that extracts and verifies all claims across the entire report, including both cited and uncited ones, and quantifies external-evidence quality. DEER correlates closely with human expert judgments and yields interpretable diagnostics of system strengths and weaknesses.

</details>


### [28] [ShareChat: A Dataset of Chatbot Conversations in the Wild](https://arxiv.org/abs/2512.17843)
*Yueru Yan,Tuc Nguyen,Bo Su,Melissa Lieffers,Thai Le*

Main category: cs.CL

TL;DR: ShareChat是一个大规模跨平台对话数据集，包含14万+对话和66万+轮次，覆盖5大主流LLM平台，保留了原生界面特征，支持多语言分析


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集将LLM视为通用文本生成器，剥离了界面上下文，而界面设计实际上塑造了用户交互。需要保留平台原生特性的真实对话数据来理解用户与LLM聊天机器人的实际交互

Method: 从ChatGPT、Claude、Gemini、Perplexity、Grok五个主要平台收集公开分享的URL对话，构建包含142,808个对话和超过660,000轮次的大规模跨平台语料库，保留推理痕迹、来源链接、代码工件等原生平台特性

Result: 创建了覆盖101种语言、时间跨度从2023年4月到2025年10月的数据集，具有更长的上下文窗口和更大的交互深度。通过三个代表性分析展示了数据集的多方面用途：对话完整性分析、来源引用行为评估、时间演化模式追踪

Conclusion: ShareChat为研究社区提供了一个重要且及时的资源，用于理解真实世界中用户与LLM聊天机器人的交互，填补了现有数据集在保留平台原生特性方面的空白

Abstract: While Large Language Models (LLMs) have evolved into distinct platforms with unique interface designs and capabilities, existing public datasets treat models as generic text generators, stripping away the interface context that actively shapes user interaction. To address this limitation, we present ShareChat, a large-scale, cross-platform corpus comprising 142,808 conversations and over 660,000 turns collected from publicly shared URLs across five major platforms: ChatGPT, Claude, Gemini, Perplexity, and Grok. ShareChat distinguishes itself by preserving native platform affordances often lost in standard logs, including reasoning traces, source links, and code artifacts, while spanning 101 languages over the period from April 2023 to October 2025. Furthermore, ShareChat offers substantially longer context windows and greater interaction depth than prior datasets. We demonstrate the dataset's multifaceted utility through three representative analyses: (1) analyzing conversation completeness to measure user intent satisfaction; (2) evaluating source citation behaviors in content generation; and (3) conducting temporal analysis to track evolving usage patterns. This work provides the community with a vital and timely resource for understanding authentic user-LLM chatbot interactions in the wild.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [29] [Mr.MSTE: Multi-robot Multi-Source Term Estimation with Wind-Aware Coverage Control](https://arxiv.org/abs/2512.17001)
*Rohit V. Nanavati,Tim J. Glover,Matthew J. Coombes,Cunjia Liu*

Main category: cs.RO

TL;DR: 多机器人多源气体释放参数估计框架，结合贝叶斯推理与风感知覆盖控制，实现移动机器人团队协同采样并推断未知数量的气体释放源参数。


<details>
  <summary>Details</summary>
Motivation: 传统气体源定位方法通常假设单一源或已知源数量，难以处理现实中的多源场景。现有覆盖控制策略未充分考虑风对气体扩散的各向异性影响，导致传感器部署效率低下。

Method: 提出MRMSTE框架：1）混合贝叶斯推理方案，表示联合多源概率密度，包含物理信息的状态转移（源产生、移除、合并）；2）基于叠加的测量模型，高效利用稀疏浓度测量；3）风感知覆盖控制策略，结合多源信念与局部风信息，优先探测高概率区域。

Result: 蒙特卡洛研究表明，相比传统覆盖控制策略和静态传感器网络，该方法收敛更快，个体源信念分离更清晰。使用TurtleBot平台的CO2释放真实实验进一步验证了方法的实用性。

Conclusion: 该框架为可扩展的多机器人气体传感应用提供了实用解决方案，通过结合物理模型与风感知控制，显著提升了多源气体释放参数估计的性能。

Abstract: This paper presents a Multi-Robot Multi-Source Term Estimation (MRMSTE) framework that enables teams of mobile robots to collaboratively sample gas concentrations and infer the parameters of an unknown number of airborne releases. The framework is built on a hybrid Bayesian inference scheme that represents the joint multi-source probability density and incorporates physics-informed state transitions, including source birth, removal, and merging induced by atmospheric dispersion. A superposition-based measurement model is naturally accommodated, allowing sparse concentration measurements to be exploited efficiently. To guide robot deployment, we introduce a wind-aware coverage control (WCC) strategy that integrates the evolving multi-source belief with local wind information to prioritize regions of high detection likelihood. Unlike conventional coverage control or information-theoretic planners, WCC explicitly accounts for anisotropic plume transport when modelling sensor performance, leading to more effective sensor placement for multi-source estimation. Monte Carlo studies demonstrate faster convergence and improved separation of individual source beliefs compared to traditional coverage-based strategies and small-scale static sensor networks. Real-world experiments with CO2 releases using TurtleBot platforms further validate the proposed approach, demonstrating its practicality for scalable multi-robot gas-sensing applications.

</details>


### [30] [Lang2Manip: A Tool for LLM-Based Symbolic-to-Geometric Planning for Manipulation](https://arxiv.org/abs/2512.17062)
*Muhayy Ud Din,Jan Rosell,Waseem Akram,Irfan Hussain*

Main category: cs.RO

TL;DR: 提出一个统一管道，将基于LLM的符号规划器与Kautham运动规划框架连接，实现可泛化的、机器人无关的符号到几何操作


<details>
  <summary>Details</summary>
Motivation: 仿真对机器人操作系统开发至关重要，特别是任务与运动规划（TAMP）。虽然LLM能让机器人从自然语言生成符号计划，但在仿真中执行这些计划通常需要机器人特定的工程或规划器相关的集成

Method: 构建一个统一管道，连接基于LLM的符号规划器与Kautham运动规划框架。Kautham提供ROS兼容的工业机械臂支持，并在单一接口下提供几何、运动动力学、物理驱动和基于约束的运动规划。系统将语言指令转换为符号动作，并使用Kautham的任何规划器计算和执行无碰撞轨迹

Result: 开发了一个灵活且可扩展的语言驱动TAMP工具，能够跨机器人、规划模式和操作任务进行泛化，无需额外编码

Conclusion: 该系统实现了机器人无关的符号到几何操作，为语言驱动的任务与运动规划提供了一个统一且可扩展的解决方案

Abstract: Simulation is essential for developing robotic manipulation systems, particularly for task and motion planning (TAMP), where symbolic reasoning interfaces with geometric, kinematic, and physics-based execution. Recent advances in Large Language Models (LLMs) enable robots to generate symbolic plans from natural language, yet executing these plans in simulation often requires robot-specific engineering or planner-dependent integration. In this work, we present a unified pipeline that connects an LLM-based symbolic planner with the Kautham motion planning framework to achieve generalizable, robot-agnostic symbolic-to-geometric manipulation. Kautham provides ROS-compatible support for a wide range of industrial manipulators and offers geometric, kinodynamic, physics-driven, and constraint-based motion planning under a single interface. Our system converts language instructions into symbolic actions and computes and executes collision-free trajectories using any of Kautham's planners without additional coding. The result is a flexible and scalable tool for language-driven TAMP that is generalized across robots, planning modalities, and manipulation tasks.

</details>


### [31] [Towards Senior-Robot Interaction: Reactive Robot Dog Gestures](https://arxiv.org/abs/2512.17136)
*Chunyang Meng,Eduardo B. Sandoval,Ricardo Sosa,Francisco Cruz*

Main category: cs.RO

TL;DR: 开发面向老年人的四足机器人社交伴侣系统，通过手势控制和社会化动作表达，解决老年人孤独问题


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，许多老年人面临孤独问题。伴侣机器人是潜在解决方案，但现有机器人要么功能简单，要么缺乏社交互动设计，限制了老年人的接受度。

Method: 1) 输入：基于MediaPipe实现手势和头部动作识别，实现无遥控器控制；2) 输出：在Isaac Gym中使用课程强化学习设计训练机器人狗动作，从简单站立到三腿平衡和腿部伸展等复杂动作；3) 在Unitree机器人上验证关键社交动作（抬爪）。

Result: 仿真测试平均成功率超过95%；在真实Unitree机器人上成功验证抬爪动作；实际测试证明了框架的可行性和社交表达能力，同时揭示了仿真到现实的挑战：关节柔顺性、负载分布和平衡控制。

Conclusion: 该工作推进了实用四足机器人作为老年人社交伴侣的发展，为仿真到现实的适应提供了路径，并为未来用户研究奠定了基础。

Abstract: As the global population ages, many seniors face the problem of loneliness. Companion robots offer a potential solution. However, current companion robots often lack advanced functionality, while task-oriented robots are not designed for social interaction, limiting their suitability and acceptance by seniors. Our work introduces a senior-oriented system for quadruped robots that allows for more intuitive user input and provides more socially expressive output. For user input, we implemented a MediaPipe-based module for hand gesture and head movement recognition, enabling control without a remote. For output, we designed and trained robotic dog gestures using curriculum-based reinforcement learning in Isaac Gym, progressing from simple standing to three-legged balancing and leg extensions, and more. The final tests achieved over 95\% success on average in simulation, and we validated a key social gesture (the paw-lift) on a Unitree robot. Real-world tests demonstrated the feasibility and social expressiveness of this framework, while also revealing sim-to-real challenges in joint compliance, load distribution, and balance control. These contributions advance the development of practical quadruped robots as social companions for the senior and outline pathways for sim-to-real adaptation and inform future user studies.

</details>


### [32] [Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors](https://arxiv.org/abs/2512.17180)
*Maher Mesto,Francisco Cruz*

Main category: cs.RO

TL;DR: 交互式强化学习（IRL）中，学习智能体在选择教师时表现出强烈的保守偏好：93.16%的情况下选择低奖励教师而非高奖励教师（20倍差异），优先考虑一致性而非最优性。


<details>
  <summary>Details</summary>
Motivation: 尽管交互式强化学习在让自主智能体从人类教师学习复杂行为方面显示出潜力，但教师选择的动态机制仍不清楚。本研究旨在揭示IRL中教师选择的意外现象及其对学习效果的影响。

Method: 通过在导航任务中进行1,250次实验运行，使用多个专家教师，分析智能体在不同奖励结构教师间的选择行为。研究考察了教师可用性（rho）和准确性（omega）等关键阈值。

Result: 发现三个主要结果：1）保守偏见主导教师选择（93.16%选择低奖励教师）；2）存在关键性能阈值（rho≥0.6，omega≥0.6）；3）在概念漂移下比基线Q-learning提升159%。

Conclusion: 这些发现挑战了强化学习中关于最优教学的基本假设，表明智能体优先选择一致性而非高奖励。这对人机协作有重要启示，特别是在安全关键应用中，人类对安全性和一致性的偏好可能与智能体的选择行为一致。

Abstract: Interactive reinforcement learning (IRL) has shown promise in enabling autonomous agents and robots to learn complex behaviours from human teachers, yet the dynamics of teacher selection remain poorly understood. This paper reveals an unexpected phenomenon in IRL: when given a choice between teachers with different reward structures, learning agents overwhelmingly prefer conservative, low-reward teachers (93.16% selection rate) over those offering 20x higher rewards. Through 1,250 experimental runs in navigation tasks with multiple expert teachers, we discovered: (1) Conservative bias dominates teacher selection: agents systematically choose the lowest-reward teacher, prioritising consistency over optimality; (2) Critical performance thresholds exist at teacher availability rho >= 0.6 and accuracy omega >= 0.6, below which the framework fails catastrophically; (3) The framework achieves 159% improvement over baseline Q-learning under concept drift. These findings challenge fundamental assumptions about optimal teaching in RL and suggest potential implications for human-robot collaboration, where human preferences for safety and consistency may align with the observed agent selection behaviour, potentially informing training paradigms for safety-critical robotic applications.

</details>


### [33] [Semantic Co-Speech Gesture Synthesis and Real-Time Control for Humanoid Robots](https://arxiv.org/abs/2512.17183)
*Gang Zhang*

Main category: cs.RO

TL;DR: 提出端到端框架，通过语义感知手势合成和运动跟踪控制，实现人形机器人实时生成并执行与语音同步的语义手势。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人自然、富有表现力的非语言交流挑战，创建能够理解语义并实时执行同步手势的完整系统。

Method: 结合语义感知手势合成模块（基于LLM的生成检索机制和自回归Motion-GPT模型）与高保真模仿学习控制策略（MotionTracker），通过通用运动重定向（GMR）方法解决人机运动数据差异。

Result: 系统能够生成语义恰当、节奏连贯的手势，并在Unitree G1人形机器人上准确跟踪执行，实现了语义感知的语音同步手势生成与实时物理部署的完整流程。

Conclusion: 该工作代表了向通用现实世界应用迈出的重要一步，提供了从语音输入到机器人物理执行的完整自动化语义手势生成与部署管道。

Abstract: We present an innovative end-to-end framework for synthesizing semantically meaningful co-speech gestures and deploying them in real-time on a humanoid robot. This system addresses the challenge of creating natural, expressive non-verbal communication for robots by integrating advanced gesture generation techniques with robust physical control. Our core innovation lies in the meticulous integration of a semantics-aware gesture synthesis module, which derives expressive reference motions from speech input by leveraging a generative retrieval mechanism based on large language models (LLMs) and an autoregressive Motion-GPT model. This is coupled with a high-fidelity imitation learning control policy, the MotionTracker, which enables the Unitree G1 humanoid robot to execute these complex motions dynamically and maintain balance. To ensure feasibility, we employ a robust General Motion Retargeting (GMR) method to bridge the embodiment gap between human motion data and the robot platform. Through comprehensive evaluation, we demonstrate that our combined system produces semantically appropriate and rhythmically coherent gestures that are accurately tracked and executed by the physical robot. To our knowledge, this work represents a significant step toward general real-world use by providing a complete pipeline for automatic, semantic-aware, co-speech gesture generation and synchronized real-time physical deployment on a humanoid robot.

</details>


### [34] [Design and Research of a Self-Propelled Pipeline Robot Based on Force Analysis and Dynamic Simulation](https://arxiv.org/abs/2512.17212)
*Yan Gao,Jiliang Wang,Ming Cheng,Tianyun Huang*

Main category: cs.RO

TL;DR: 提出一种基于力分析和动态仿真的自驱动管道机器人设计，解决垂直爬升失败和T型分支管道通过性差等核心问题，为城市中低压燃气管道的检测应用提供技术可行性参考。


<details>
  <summary>Details</summary>
Motivation: 传统有线检测机器人受电缆长度和重量限制，严重制约了其移动范围和可达性，需要开发不受电缆约束的自驱动管道机器人。

Method: 采用轮式配置和模块化设计，首先使用SolidWorks完成3D建模，然后导入ADAMS进行动态仿真，优化驱动模块和运动控制策略，最后搭建亚克力管道实验平台验证动态性能。

Result: 机器人通过调整身体姿态克服障碍和选择方向，能够稳定穿越各种复杂管道场景，特别是在垂直爬升和T型分支管道中表现出良好的通过性。

Conclusion: 该自驱动管道机器人设计为城市中低压燃气管道检测应用提供了可行的技术参考，解决了传统有线机器人的移动限制问题。

Abstract: In pipeline inspection, traditional tethered inspection robots are severely constrained by cable length and weight, which greatly limit their travel range and accessibility. To address these issues, this paper proposes a self-propelled pipeline robot design based on force analysis and dynamic simulation, with a specific focus on solving core challenges including vertical climbing failure and poor passability in T-branch pipes. Adopting a wheeled configuration and modular design, the robot prioritizes the core demand of body motion control. Specifically, 3D modeling of the robot was first completed using SolidWorks. Subsequently, the model was imported into ADAMS for dynamic simulation, which provided a basis for optimizing the drive module and motion control strategy.To verify the robot's dynamic performance, an experimental platform with acrylic pipes was constructed. Through adjusting its body posture to surmount obstacles and select directions, the robot has demonstrated its ability to stably traverse various complex pipeline scenarios. Notably, this work offers a technical feasibility reference for the application of pipeline robots in the inspection of medium and low-pressure urban gas pipelines.

</details>


### [35] [Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines](https://arxiv.org/abs/2512.17215)
*Yan Gao,Jiliang Wang,Minghan Wang,Xiaohua Chen,Demin Chen,Zhiyong Ren,Tian-Yun Huang*

Main category: cs.RO

TL;DR: 提出基于扩展卡尔曼滤波的管道机器人定位方法，结合惯性导航和轮式里程计，解决复杂弯曲管道定位难题


<details>
  <summary>Details</summary>
Motivation: 现有管道定位方法在复杂弯曲管道场景下存在电缆缠绕、设备灵活性不足等问题，传统视觉和激光建图方法在管道受限空间中易受光照条件和特征不足影响，导致建图漂移和发散

Method: 设计自驱动管道机器人，采用基于扩展卡尔曼滤波的定位方法：首先通过惯性测量单元获取初始姿态角，然后用EKF算法提高姿态角估计精度，最后结合轮式里程计实现高精度管道定位

Result: 在矩形环形管道中使用自驱动管道机器人进行实验，验证了所提出的航位推算算法的有效性

Conclusion: 提出的基于EKF的管道机器人定位方法能够有效解决复杂弯曲管道的定位问题，在机器人运动能力和定位精度之间取得了平衡

Abstract: In the field of gas pipeline location, existing pipeline location methods mostly rely on pipeline location instruments. However, when faced with complex and curved pipeline scenarios, these methods often fail due to problems such as cable entanglement and insufficient equipment flexibility. To address this pain point, we designed a self-propelled pipeline robot. This robot can autonomously complete the location work of complex and curved pipelines in complex pipe networks without external dragging. In terms of pipeline mapping technology, traditional visual mapping and laser mapping methods are easily affected by lighting conditions and insufficient features in the confined space of pipelines, resulting in mapping drift and divergence problems. In contrast, the pipeline location method that integrates inertial navigation and wheel odometers is less affected by pipeline environmental factors. Based on this, this paper proposes a pipeline robot location method based on extended Kalman filtering (EKF). Firstly, the body attitude angle is initially obtained through an inertial measurement unit (IMU). Then, the extended Kalman filtering algorithm is used to improve the accuracy of attitude angle estimation. Finally, high-precision pipeline location is achieved by combining wheel odometers. During the testing phase, the roll wheels of the pipeline robot needed to fit tightly against the pipe wall to reduce slippage. However, excessive tightness would reduce the flexibility of motion control due to excessive friction. Therefore, a balance needed to be struck between the robot's motion capability and positioning accuracy. Experiments were conducted using the self-propelled pipeline robot in a rectangular loop pipeline, and the results verified the effectiveness of the proposed dead reckoning algorithm.

</details>


### [36] [A Service Robot's Guide to Interacting with Busy Customers](https://arxiv.org/abs/2512.17241)
*Suraj Nukala,Meera Sushma,Leimin Tian,Akansel Cosgun,Dana Kulic*

Main category: cs.RO

TL;DR: 研究比较服务机器人在餐厅场景中不同沟通方式（语音、视觉显示、微动作）对忙碌顾客的注意力吸引和意图传达效果，发现语音最有效吸引注意力，但视觉显示最能清晰传达意图。


<details>
  <summary>Details</summary>
Motivation: 随着服务机器人在酒店业的普及，需要了解如何与忙碌的顾客有效沟通。顾客经常处于忙碌状态，机器人需要有效的沟通方式来吸引注意并传达意图。

Method: 采用两部分用户研究（N=24），使用Temi机器人模拟送餐任务。参与者通过打字游戏模拟忙碌状态。第一部分比较非语言声音提示与基线条件在单杯送餐任务中的注意力吸引效果；第二部分评估语音、视觉显示、微动作及其多模态组合在两杯送餐任务中传达特定意图（正确杯子选择）的效果。

Result: 语音在吸引注意力方面效果显著，但在清晰传达意图方面效果较差。参与者认为视觉显示是传达意图最有效的方式，其次是语音，微动作排名最低。

Conclusion: 研究为优化服务机器人沟通策略提供见解，强调在动态酒店环境中，注意力吸引和意图传达具有不同作用，需要根据具体目标选择合适的沟通方式。

Abstract: The growing use of service robots in hospitality highlights the need to understand how to effectively communicate with pre-occupied customers. This study investigates the efficacy of commonly used communication modalities by service robots, namely, acoustic/speech, visual display, and micromotion gestures in capturing attention and communicating intention with a user in a simulated restaurant scenario. We conducted a two-part user study (N=24) using a Temi robot to simulate delivery tasks, with participants engaged in a typing game (MonkeyType) to emulate a state of busyness. The participants' engagement in the typing game is measured by words per minute (WPM) and typing accuracy. In Part 1, we compared non-verbal acoustic cue versus baseline conditions to assess attention capture during a single-cup delivery task. In Part 2, we evaluated the effectiveness of speech, visual display, micromotion and their multimodal combination in conveying specific intentions (correct cup selection) during a two-cup delivery task. The results indicate that, while speech is highly effective in capturing attention, it is less successful in clearly communicating intention. Participants rated visual as the most effective modality for intention clarity, followed by speech, with micromotion being the lowest ranked.These findings provide insights into optimizing communication strategies for service robots, highlighting the distinct roles of attention capture and intention communication in enhancing user experience in dynamic hospitality settings.

</details>


### [37] [RecipeMasterLLM: Revisiting RoboEarth in the Era of Large Language Models](https://arxiv.org/abs/2512.17309)
*Asil Kaan Bozcuoglu,Ziyuan Liu*

Main category: cs.RO

TL;DR: RecipeMasterLLM：基于LLM自动生成OWL动作本体的高层规划器，用于RoboEarth知识图谱


<details>
  <summary>Details</summary>
Motivation: 传统RoboEarth知识图谱需要工程师手工创建RDF三元组，更新过程繁琐。随着大语言模型的发展，可以实现知识获取过程的自动化。

Method: 提出RecipeMasterLLM高层规划器，使用针对RoboEarth标准化知识图谱微调的LLM，结合RAG技术提供环境知识，根据用户提示自动生成OWL动作本体。

Result: 该方法能够显著自动化知识获取过程，生成符合RoboEarth标准化知识图谱的动作描述，提高了知识更新的效率和准确性。

Conclusion: RecipeMasterLLM利用LLM技术实现了RoboEarth知识图谱的自动化知识获取，为云机器人知识共享提供了更高效的解决方案。

Abstract: RoboEarth was a pioneering initiative in cloud robotics, establishing a foundational framework for robots to share and exchange knowledge about actions, objects, and environments through a standardized knowledge graph. Initially, this knowledge was predominantly hand-crafted by engineers using RDF triples within OWL Ontologies, with updates, such as changes in an object's pose, being asserted by the robot's control and perception routines. However, with the advent and rapid development of Large Language Models (LLMs), we believe that the process of knowledge acquisition can be significantly automated. To this end, we propose RecipeMasterLLM, a high-level planner, that generates OWL action ontologies based on a standardized knowledge graph in response to user prompts. This architecture leverages a fine-tuned LLM specifically trained to understand and produce action descriptions consistent with the RoboEarth standardized knowledge graph. Moreover, during the Retrieval-Augmented Generation (RAG) phase, environmental knowledge is supplied to the LLM to enhance its contextual understanding and improve the accuracy of the generated action descriptions.

</details>


### [38] [Neuro-Symbolic Control with Large Language Models for Language-Guided Spatial Tasks](https://arxiv.org/abs/2512.17321)
*Momina Liaqat Ali,Muhammad Abid*

Main category: cs.RO

TL;DR: 提出模块化神经符号控制框架，将低层运动执行与高层语义推理分离，使用LLM进行符号任务解释，神经网络控制器执行连续动作，在平面操作任务中显著提升成功率与效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在具身控制中显示出潜力，但存在不稳定性、收敛慢和幻觉动作等问题，限制了其在连续控制中的直接应用。需要一种更可靠、高效的方法来整合语言理解与连续控制。

Method: 提出模块化神经符号控制框架：1) 轻量级神经delta控制器在连续空间中执行有界增量动作；2) 本地部署的LLM解释符号任务。框架将LLM限制为符号输出，将未解释的执行分配给在人工几何数据上训练的神经控制器。

Result: 在平面操作任务中，与纯LLM基线相比，神经符号集成显著提升成功率和效率：平均步骤减少超过70%，加速高达8.83倍，且对语言模型质量保持鲁棒性。框架无需强化学习或昂贵rollout。

Conclusion: 神经符号分解为语言理解与连续控制集成提供了可扩展且原则性的方法，促进了可靠高效的语言引导具身系统的开发，增强了可解释性、稳定性和泛化能力。

Abstract: Although large language models (LLMs) have recently become effective tools for language-conditioned control in embodied systems, instability, slow convergence, and hallucinated actions continue to limit their direct application to continuous control. A modular neuro-symbolic control framework that clearly distinguishes between low-level motion execution and high-level semantic reasoning is proposed in this work. While a lightweight neural delta controller performs bounded, incremental actions in continuous space, a locally deployed LLM interprets symbolic tasks. We assess the suggested method in a planar manipulation setting with spatial relations between objects specified by language. Numerous tasks and local language models, such as Mistral, Phi, and LLaMA-3.2, are used in extensive experiments to compare LLM-only control, neural-only control, and the suggested LLM+DL framework. In comparison to LLM-only baselines, the results show that the neuro-symbolic integration consistently increases both success rate and efficiency, achieving average step reductions exceeding 70% and speedups of up to 8.83x while remaining robust to language model quality. The suggested framework enhances interpretability, stability, and generalization without any need of reinforcement learning or costly rollouts by controlling the LLM to symbolic outputs and allocating uninterpreted execution to a neural controller trained on artificial geometric data. These outputs show empirically that neuro-symbolic decomposition offers a scalable and principled way to integrate language understanding with ongoing control, this approach promotes the creation of dependable and effective language-guided embodied systems.

</details>


### [39] [Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation](https://arxiv.org/abs/2512.17349)
*Xijie Huang,Jinhan Li,Tianyue Wu,Xin Zhou,Zhichao Han,Fei Gao*

Main category: cs.RO

TL;DR: 提出结合3D高斯泼溅与对抗域适应的框架，使仅用单目RGB图像的飞行机器人能在真实世界实现零样本转移的鲁棒导航


<details>
  <summary>Details</summary>
Motivation: 现有自主导航系统主要依赖激光雷达和深度相机，但能否仅用单目RGB图像实现飞行机器人在杂乱环境中的导航？由于真实世界数据收集成本高昂，在仿真中学习策略是可行路径，但存在显著的仿真到真实感知差距

Method: 结合3D高斯泼溅（3DGS）环境的照片级真实感与对抗域适应，在高保真仿真中训练同时显式最小化特征差异，确保策略依赖领域不变特征

Result: 实验结果表明，该策略实现了对物理世界的鲁棒零样本转移，能够在不同光照条件下的非结构化环境中实现安全敏捷的飞行

Conclusion: 通过结合高保真仿真与对抗域适应，仅用单目RGB图像的飞行机器人导航策略能够有效克服仿真到真实差距，在真实世界中实现鲁棒导航

Abstract: Modern autonomous navigation systems predominantly rely on lidar and depth cameras. However, a fundamental question remains: Can flying robots navigate in clutter using solely monocular RGB images? Given the prohibitive costs of real-world data collection, learning policies in simulation offers a promising path. Yet, deploying such policies directly in the physical world is hindered by the significant sim-to-real perception gap. Thus, we propose a framework that couples the photorealism of 3D Gaussian Splatting (3DGS) environments with Adversarial Domain Adaptation. By training in high-fidelity simulation while explicitly minimizing feature discrepancy, our method ensures the policy relies on domain-invariant cues. Experimental results demonstrate that our policy achieves robust zero-shot transfer to the physical world, enabling safe and agile flight in unstructured environments with varying illumination.

</details>


### [40] [TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data](https://arxiv.org/abs/2512.17370)
*Deqing Liu,Yinfeng Gao,Deheng Qian,Qichao Zhang,Xiaoqing Ye,Junyu Han,Yupeng Zheng,Xueyi Liu,Zhongpu Xia,Dawei Ding,Yifeng Pan,Dongbin Zhao*

Main category: cs.RO

TL;DR: TakeAD：基于偏好的后优化框架，利用专家接管数据微调预训练的模仿学习策略，以提升闭环驾驶性能


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法依赖模仿学习，但面临开环训练与闭环部署之间的不对齐问题，导致驾驶员接管和系统脱离。如何利用脱离场景中的专家接管数据扩展IL策略能力是一个有价值但未探索的挑战。

Method: 提出TakeAD框架：1）设计受真实自动驾驶系统人类接管机制启发的专家接管数据收集管道；2）集成迭代DAgger用于模仿学习和DPO用于偏好对齐的后优化框架。DAgger阶段通过直接模仿专家干预使策略具备处理脱离状态的基本能力，DPO阶段则优化策略行为以更好地对齐专家在脱离场景中的偏好。

Result: 在闭环Bench2Drive基准测试中，该方法相比纯IL方法表现出有效性，全面的消融实验确认了每个组件的贡献。

Conclusion: TakeAD通过迭代学习脱离状态的恢复策略，有效缓解了开环差距，提升了自动驾驶策略在闭环部署中的性能。

Abstract: Existing end-to-end autonomous driving methods typically rely on imitation learning (IL) but face a key challenge: the misalignment between open-loop training and closed-loop deployment. This misalignment often triggers driver-initiated takeovers and system disengagements during closed-loop execution. How to leverage those expert takeover data from disengagement scenarios and effectively expand the IL policy's capability presents a valuable yet unexplored challenge. In this paper, we propose TakeAD, a novel preference-based post-optimization framework that fine-tunes the pre-trained IL policy with this disengagement data to enhance the closed-loop driving performance. First, we design an efficient expert takeover data collection pipeline inspired by human takeover mechanisms in real-world autonomous driving systems. Then, this post optimization framework integrates iterative Dataset Aggregation (DAgger) for imitation learning with Direct Preference Optimization (DPO) for preference alignment. The DAgger stage equips the policy with fundamental capabilities to handle disengagement states through direct imitation of expert interventions. Subsequently, the DPO stage refines the policy's behavior to better align with expert preferences in disengagement scenarios. Through multiple iterations, the policy progressively learns recovery strategies for disengagement states, thereby mitigating the open-loop gap. Experiments on the closed-loop Bench2Drive benchmark demonstrate our method's effectiveness compared with pure IL methods, with comprehensive ablations confirming the contribution of each component.

</details>


### [41] [Personalized Gait Patterns During Exoskeleton-Aided Training May Have Minimal Effect on User Experience. Insights from a Pilot Study](https://arxiv.org/abs/2512.17425)
*Beatrice Luciani,Katherine Lin Poggensee,Heike Vallery,Alex van den Berg,Severin David Woernle,Mostafa Mogharabi,Stefano Dalla Gasperina,Laura Marchal-Crespo*

Main category: cs.RO

TL;DR: 开发数据驱动的步态个性化框架，用于支持多平面运动的康复外骨骼，但实验发现个性化轨迹与标准轨迹在舒适度和自然性方面无显著差异，用户适应过程更重要。


<details>
  <summary>Details</summary>
Motivation: 现有康复外骨骼大多使用预录的、非个性化的步态轨迹，且局限于矢状面运动，这可能限制了运动的自然性和用户舒适度。需要开发支持多平面运动（包括髋关节外展/内收、骨盆平移和旋转）的个性化步态控制方法。

Method: 提出数据驱动的步态个性化框架，使用回归模型基于人体测量学、人口统计学和步行速度数据从规范数据库中生成个性化轨迹。在10名健康受试者中进行受试者内实验，比较个性化轨迹与两种标准模式（平均轨迹和随机选择轨迹）。

Result: 不同轨迹条件（个性化、平均、随机）在舒适度、自然性和整体体验方面没有显著差异。但发现后期试验中的轨迹比第一次试验评分更高，表明用户可能适应了外骨骼行走，与具体步态模式无关。

Conclusion: 在设计个性化步态控制器时，需要整合主观反馈并考虑用户适应过程。用户对外骨骼的适应可能比轨迹个性化本身更重要。

Abstract: Robot-aided gait rehabilitation facilitates high-intensity and repeatable therapy. However, most exoskeletons rely on pre-recorded, non-personalized gait trajectories constrained to the sagittal plane, potentially limiting movement naturalness and user comfort. We present a data-driven gait personalization framework for an exoskeleton that supports multi-planar motion, including hip abduction/adduction and pelvic translation and rotation. Personalized trajectories to individual participants were generated using regression models trained on anthropometric, demographic, and walking speed data from a normative database. In a within-subject experiment involving ten unimpaired participants, these personalized trajectories were evaluated in regard to comfort, naturalness, and overall experience and compared against two standard patterns from the same database: one averaging all the trajectories, and one randomly selected. We did not find relevant differences across pattern conditions, despite all trajectories being executed with high accuracy thanks to a stiff position-derivative controller. We found, however, that pattern conditions in later trials were rated as more comfortable and natural than those in the first trial, suggesting that participants might have adapted to walking within the exoskeleton, regardless of the enforced gait pattern. Our findings highlight the importance of integrating subjective feedback when designing personalized gait controllers and accounting for user adaptation during experimentation.

</details>


### [42] [ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination](https://arxiv.org/abs/2512.17435)
*Teng Wang,Xinxin Zhao,Wenzhe Cai,Changyin Sun*

Main category: cs.RO

TL;DR: ImagineNav++：一种基于视觉语言模型的免地图视觉导航框架，通过想象未来观测图像并选择最佳视角进行导航决策，在开放词汇对象导航任务中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的导航方法受限于文本表示，无法充分捕捉空间占用和场景几何信息，而这些对导航决策至关重要。本研究探索视觉语言模型是否能够仅使用机载RGB/RGB-D流实现免地图视觉导航，发挥其空间感知和规划潜力。

Method: 提出ImagineNav++框架：1）未来视角想象模块：蒸馏人类导航偏好生成具有高探索潜力的语义有意义视点；2）VLM视觉提示：将想象视图作为视觉提示，让VLM识别最具信息量的视点；3）选择性注视记忆机制：通过稀疏到密集的层次化框架整合关键帧观测，构建紧凑而全面的长期空间推理记忆；4）将目标导向导航转化为一系列可处理的点目标导航任务。

Result: 在开放词汇对象和实例导航基准测试中，ImagineNav++在免地图设置下达到最先进性能，甚至超越大多数基于地图的方法，突显了场景想象和记忆在VLM空间推理中的重要性。

Conclusion: 视觉语言模型能够有效实现免地图视觉导航，通过想象未来观测和选择性记忆机制，可以显著提升导航效率和性能，为家庭辅助机器人等应用提供了新的解决方案。

Abstract: Visual navigation is a fundamental capability for autonomous home-assistance robots, enabling long-horizon tasks such as object search. While recent methods have leveraged Large Language Models (LLMs) to incorporate commonsense reasoning and improve exploration efficiency, their planning remains constrained by textual representations, which cannot adequately capture spatial occupancy or scene geometry--critical factors for navigation decisions. We explore whether Vision-Language Models (VLMs) can achieve mapless visual navigation using only onboard RGB/RGB-D streams, unlocking their potential for spatial perception and planning. We achieve this through an imagination-powered navigation framework, ImagineNav++, which imagines future observation images from candidate robot views and translates navigation planning into a simple best-view image selection problem for VLMs. First, a future-view imagination module distills human navigation preferences to generate semantically meaningful viewpoints with high exploration potential. These imagined views then serve as visual prompts for the VLM to identify the most informative viewpoint. To maintain spatial consistency, we develop a selective foveation memory mechanism, which hierarchically integrates keyframe observations via a sparse-to-dense framework, constructing a compact yet comprehensive memory for long-term spatial reasoning. This approach transforms goal-oriented navigation into a series of tractable point-goal navigation tasks. Extensive experiments on open-vocabulary object and instance navigation benchmarks show that ImagineNav++ achieves SOTA performance in mapless settings, even surpassing most map-based methods, highlighting the importance of scene imagination and memory in VLM-based spatial reasoning.

</details>


### [43] [Adaptive Covariance and Quaternion-Focused Hybrid Error-State EKF/UKF for Visual-Inertial Odometry](https://arxiv.org/abs/2512.17505)
*Ufuk Asil,Efendi Nasibov*

Main category: cs.RO

TL;DR: 提出一种混合视觉惯性里程计方法，结合ESKF和SUKF处理IMU数据，通过动态传感器置信度评分适应环境挑战，在计算效率和估计精度间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 无人机在复杂环境中面临传感器可靠性变化和环境挑战，需要既能保持高精度又能控制计算成本的姿态估计方法。

Method: 采用松散耦合传感器融合架构，使用混合四元数误差状态EKF/UKF：先用ESKF传播完整状态，再用SUKF专门优化姿态；通过图像熵、强度变化、运动模糊等指标动态评估视觉测量可靠性。

Result: 在EuRoC MAV数据集上测试：挑战场景中位置精度平均提升49%，旋转精度比ESKF方法平均提升57%，计算成本比完整SUKF实现降低约48%且精度相当。

Conclusion: 该方法在计算效率和估计精度间取得了有效平衡，显著提升了无人机在传感器可靠性变化的复杂环境中的姿态估计性能。

Abstract: This study presents an innovative hybrid Visual-Inertial Odometry (VIO) method for Unmanned Aerial Vehicles (UAVs) that is resilient to environmental challenges and capable of dynamically assessing sensor reliability. Built upon a loosely coupled sensor fusion architecture, the system utilizes a novel hybrid Quaternion-focused Error-State EKF/UKF (Qf-ES-EKF/UKF) architecture to process inertial measurement unit (IMU) data. This architecture first propagates the entire state using an Error-State Extended Kalman Filter (ESKF) and then applies a targeted Scaled Unscented Kalman Filter (SUKF) step to refine only the orientation. This sequential process blends the accuracy of SUKF in quaternion estimation with the overall computational efficiency of ESKF. The reliability of visual measurements is assessed via a dynamic sensor confidence score based on metrics, such as image entropy, intensity variation, motion blur, and inference quality, adapting the measurement noise covariance to ensure stable pose estimation even under challenging conditions. Comprehensive experimental analyses on the EuRoC MAV dataset demonstrate key advantages: an average improvement of 49% in position accuracy in challenging scenarios, an average of 57% in rotation accuracy over ESKF-based methods, and SUKF-comparable accuracy achieved with approximately 48% lower computational cost than a full SUKF implementation. These findings demonstrate that the presented approach strikes an effective balance between computational efficiency and estimation accuracy, and significantly enhances UAV pose estimation performance in complex environments with varying sensor reliability.

</details>


### [44] [Deep Learning-based Robust Autonomous Navigation of Aerial Robots in Dense Forests](https://arxiv.org/abs/2512.17553)
*Guglielmo Del Col,Väinö Karjalainen,Teemu Hakala,Yibo Zhang,Eija Honkavaara*

Main category: cs.RO

TL;DR: 改进的深度学习导航框架，整合语义增强深度编码与神经运动基元评估，用于森林等密集自然环境的鲁棒飞行


<details>
  <summary>Details</summary>
Motivation: 解决密集自然环境中自主空中导航的挑战：能见度有限、细薄不规则障碍物、GNSS信号缺失、感知退化频繁

Method: 在sevae-ORACLE算法基础上增加多个模块：横向控制用于更锐利机动、时间一致性机制抑制振荡规划、立体视觉惯性里程计用于抗漂移状态估计、实时安全监督层过滤不安全动作；还包括深度细化阶段改进细枝表示和减少立体噪声，GPU优化将推理速度从4Hz提升到10Hz

Result: 相比现有学习方法，在相同环境条件和硬件约束下，展示了更高的成功率、更稳定的轨迹和更好的碰撞避免能力；在三种北方森林环境中部署，在中等和密集环境中所有飞行完全自主完成，在高度密集灌木丛中15次飞行完成12次

Conclusion: 该方法在复杂自然环境中相比现有导航方法具有更高的可靠性和安全性，为密集森林环境中的自主飞行提供了改进方案

Abstract: Autonomous aerial navigation in dense natural environments remains challenging due to limited visibility, thin and irregular obstacles, GNSS-denied operation, and frequent perceptual degradation. This work presents an improved deep learning-based navigation framework that integrates semantically enhanced depth encoding with neural motion-primitive evaluation for robust flight in cluttered forests. Several modules are incorporated on top of the original sevae-ORACLE algorithm to address limitations observed during real-world deployment, including lateral control for sharper maneuvering, a temporal consistency mechanism to suppress oscillatory planning decisions, a stereo-based visual-inertial odometry solution for drift-resilient state estimation, and a supervisory safety layer that filters unsafe actions in real time. A depth refinement stage is included to improve the representation of thin branches and reduce stereo noise, while GPU optimization increases onboard inference throughput from 4 Hz to 10 Hz.
  The proposed approach is evaluated against several existing learning-based navigation methods under identical environmental conditions and hardware constraints. It demonstrates higher success rates, more stable trajectories, and improved collision avoidance, particularly in highly cluttered forest settings. The system is deployed on a custom quadrotor in three boreal forest environments, achieving fully autonomous completion in all flights in moderate and dense clutter, and 12 out of 15 flights in highly dense underbrush. These results demonstrate improved reliability and safety over existing navigation methods in complex natural environments.

</details>


### [45] [Learning-Based Safety-Aware Task Scheduling for Efficient Human-Robot Collaboration](https://arxiv.org/abs/2512.17560)
*M. Faroni,A. Spano,A. M. Zanchettin,P. Rocco*

Main category: cs.RO

TL;DR: 提出一种安全感知框架，通过深度学习模型学习系统状态与安全减速的关系，优化任务选择以减少协作机器人循环时间


<details>
  <summary>Details</summary>
Motivation: 传统协作机器人安全措施在频繁人机交互时会增加循环时间，降低效率，需要一种方法在保证安全的同时减少效率损失

Method: 使用深度学习模型，基于执行数据学习系统状态与安全减速的关系，不预测人类运动而是直接建模交互对机器人速度的影响，运行时优化任务选择以最小化循环时间

Result: 在拣选包装场景实验中，该方法显著减少了循环时间

Conclusion: 提出的安全感知框架能够在不假设安全逻辑先验知识的情况下，有效减少协作机器人的效率损失，同时保持安全要求

Abstract: Ensuring human safety in collaborative robotics can compromise efficiency because traditional safety measures increase robot cycle time when human interaction is frequent. This paper proposes a safety-aware approach to mitigate efficiency losses without assuming prior knowledge of safety logic. Using a deep-learning model, the robot learns the relationship between system state and safety-induced speed reductions based on execution data. Our framework does not explicitly predict human motions but directly models the interaction effects on robot speed, simplifying implementation and enhancing generalizability to different safety logics. At runtime, the learned model optimizes task selection to minimize cycle time while adhering to safety requirements. Experiments on a pick-and-packaging scenario demonstrated significant reductions in cycle times.

</details>


### [46] [Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation](https://arxiv.org/abs/2512.17568)
*Kangchen Lv,Mingrui Yu,Yongyi Jia,Chenyu Zhang,Xiang Li*

Main category: cs.RO

TL;DR: 提出一种基于三维空间表示的运动学感知模仿学习框架，通过点云表示机器人状态和动作，结合扩散策略和运动学先验，实现全身控制并提高空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法在关节空间学习动作，但关节空间与实际任务空间（三维空间）不对齐，增加了策略学习的复杂性。需要全身控制来避免碰撞和实现身体-物体交互，仅考虑末端执行器姿态是不够的。

Method: 1. 使用三维空间中手臂上的点集表示机器人状态和动作，与三维点云观测自然对齐；2. 基于扩散策略，在扩散过程中融入运动学先验以保证输出动作的运动学可行性；3. 通过基于优化的全身逆运动学求解器计算关节角度指令执行。

Result: 仿真和真实世界实验表明，相比现有方法，该方法在身体感知操作策略学习中具有更高的成功率和更强的空间泛化能力。

Conclusion: 提出的运动学感知模仿学习框架通过保持任务、观测和动作空间在三维空间中的一致性表示，提高了策略的样本效率和空间泛化性，同时实现了全身控制。

Abstract: Whole-body control of robotic manipulators with awareness of full-arm kinematics is crucial for many manipulation scenarios involving body collision avoidance or body-object interactions, which makes it insufficient to consider only the end-effector poses in policy learning. The typical approach for whole-arm manipulation is to learn actions in the robot's joint space. However, the unalignment between the joint space and actual task space (i.e., 3D space) increases the complexity of policy learning, as generalization in task space requires the policy to intrinsically understand the non-linear arm kinematics, which is difficult to learn from limited demonstrations. To address this issue, this letter proposes a kinematics-aware imitation learning framework with consistent task, observation, and action spaces, all represented in the same 3D space. Specifically, we represent both robot states and actions using a set of 3D points on the arm body, naturally aligned with the 3D point cloud observations. This spatially consistent representation improves the policy's sample efficiency and spatial generalizability while enabling full-body control. Built upon the diffusion policy, we further incorporate kinematics priors into the diffusion processes to guarantee the kinematic feasibility of output actions. The joint angle commands are finally calculated through an optimization-based whole-body inverse kinematics solver for execution. Simulation and real-world experimental results demonstrate higher success rates and stronger spatial generalizability of our approach compared to existing methods in body-aware manipulation policy learning.

</details>


### [47] [On Using Neural Networks to Learn Safety Speed Reduction in Human-Robot Collaboration: A Comparative Analysis](https://arxiv.org/abs/2512.17579)
*Marco Faroni,Alessio Spanò,Andrea M. Zanchettin,Paolo Rocco*

Main category: cs.RO

TL;DR: 提出使用深度学习从执行数据直接预测机器人安全缩放因子，以改进协作机器人环境中的周期时间估计和调度算法设计


<details>
  <summary>Details</summary>
Motivation: 人机协作中的安全机制（如速度与分离监控、功率与力限制）会根据人类接近程度动态调整机器人速度，虽然降低了风险，但引入了减速，使得周期时间估计困难并影响作业调度效率。现有方法依赖预定义安全模型，可能无法准确反映实际安全实现，因为这些实现依赖于具体案例的风险评估。

Method: 提出深度学习方法来直接从过程执行数据预测机器人的安全缩放因子。分析了多种神经网络架构，证明简单的前馈网络能有效估计机器人减速。

Result: 研究表明简单的前馈神经网络能够有效估计机器人的安全缩放因子（减速程度），这为改进周期时间预测和设计更有效的调度算法提供了关键能力。

Conclusion: 深度学习可以直接从执行数据预测安全缩放因子，这对于改进协作机器人环境中的周期时间预测和调度算法设计至关重要，解决了现有基于预定义模型方法的局限性。

Abstract: In Human-Robot Collaboration, safety mechanisms such as Speed and Separation Monitoring and Power and Force Limitation dynamically adjust the robot's speed based on human proximity. While essential for risk reduction, these mechanisms introduce slowdowns that makes cycle time estimation a hard task and impact job scheduling efficiency. Existing methods for estimating cycle times or designing schedulers often rely on predefined safety models, which may not accurately reflect real-world safety implementations, as these depend on case-specific risk assessments. In this paper, we propose a deep learning approach to predict the robot's safety scaling factor directly from process execution data. We analyze multiple neural network architectures and demonstrate that a simple feed-forward network effectively estimates the robot's slowdown. This capability is crucial for improving cycle time predictions and designing more effective scheduling algorithms in collaborative robotic environments.

</details>


### [48] [Optimized Scheduling and Positioning of Mobile Manipulators in Collaborative Applications](https://arxiv.org/abs/2512.17584)
*Christian Cella,Sole Ester Sonnino,Marco Faroni,Andrea Zanchettin,Paolo Rocco*

Main category: cs.RO

TL;DR: 提出基于数字模型的移动机械臂优化框架，使用粒子群算法平衡冲突性能指标，在协作装箱场景中提升周期时间、任务排序和适应人类存在的能力


<details>
  <summary>Details</summary>
Motivation: 移动机器人在共享工作空间中的集成日益增长，需要高效的路径规划和协调，同时考虑安全性和生产效率

Method: 提出数字模型优化框架，将完整问题视为黑盒，使用粒子群优化算法平衡冲突的关键性能指标，确定机器人基座姿态序列和任务调度

Result: 在协作装箱场景中展示了在周期时间、任务排序和适应人类存在方面的改进

Conclusion: 提出的数字模型优化框架有效解决了人机协作环境中移动机械臂的路径规划和任务调度问题

Abstract: The growing integration of mobile robots in shared workspaces requires efficient path planning and coordination between the agents, accounting for safety and productivity. In this work, we propose a digital model-based optimization framework for mobile manipulators in human-robot collaborative environments, in order to determine the sequence of robot base poses and the task scheduling for the robot. The complete problem is treated as black-box, and Particle Swarm Optimization (PSO) is employed to balance conflicting Key-Performance Indicators (KPIs). We demonstrate improvements in cycle time, task sequencing, and adaptation to human presence in a collaborative box-packing scenario.

</details>


### [49] [Vidarc: Embodied Video Diffusion Model for Closed-loop Control](https://arxiv.org/abs/2512.17661)
*Yao Feng,Chendong Xiang,Xinyi Mao,Hengkai Tan,Zuyue Zhang,Shuhe Huang,Kaiwen Zheng,Haitian Liu,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: Vidarc是一种基于视频扩散的自回归具身控制方法，通过掩码逆动力学模型实现快速闭环控制，在数据稀缺环境下显著提升机器人操作性能


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺环境下，机器人手臂操作面临复杂动力学和多样场景的挑战。现有视频方法虽能捕捉时空交互，但未针对具身闭环控制优化，存在延迟高、接地不足的问题

Method: 提出Vidarc方法：1) 基于视频扩散的自回归具身控制框架；2) 使用掩码逆动力学模型对视频预测进行动作相关掩码接地；3) 通过缓存自回归生成实现实时反馈闭环控制

Result: 在100万跨具身轨迹预训练后，Vidarc超越SOTA基线：真实部署成功率提升至少15%，延迟降低91%，并在未见过的机器人平台上展现出强大的泛化和纠错能力

Conclusion: Vidarc通过视频扩散与掩码逆动力学的结合，实现了高效、低延迟的闭环具身控制，为数据稀缺环境下的机器人操作提供了有效解决方案

Abstract: Robotic arm manipulation in data-scarce settings is a highly challenging task due to the complex embodiment dynamics and diverse contexts. Recent video-based approaches have shown great promise in capturing and transferring the temporal and physical interactions by pre-training on Internet-scale video data. However, such methods are often not optimized for the embodiment-specific closed-loop control, typically suffering from high latency and insufficient grounding. In this paper, we present Vidarc (Video Diffusion for Action Reasoning and Closed-loop Control), a novel autoregressive embodied video diffusion approach augmented by a masked inverse dynamics model. By grounding video predictions with action-relevant masks and incorporating real-time feedback through cached autoregressive generation, Vidarc achieves fast, accurate closed-loop control. Pre-trained on one million cross-embodiment episodes, Vidarc surpasses state-of-the-art baselines, achieving at least a 15% higher success rate in real-world deployment and a 91% reduction in latency. We also highlight its robust generalization and error correction capabilities across previously unseen robotic platforms.

</details>


### [50] [A Dual Quaternion based RRT* Path Planning Approach for Satellite Rendezvous and Docking](https://arxiv.org/abs/2512.17680)
*Ana Stankovic,Mohamed Khalil Ben-Larbi,Wolfgang H. Müller*

Main category: cs.RO

TL;DR: 提出基于对偶四元数的RRT*采样运动规划器，用于卫星交会对接的6自由度位姿轨迹规划，在SE(3)空间中实现平滑的螺旋运动插值


<details>
  <summary>Details</summary>
Motivation: 卫星交会对接需要生成平滑、无碰撞的6自由度位姿轨迹，传统方法在SE(3)空间中难以实现自然的螺旋运动插值，且存在位姿不连续问题

Method: 将对偶四元数代数直接集成到RRT*框架中，使用对偶四元数表示位姿，在SE(3)空间中进行自然螺旋运动插值，处理禁飞区约束

Result: 在Python中实现了对偶四元数RRT*，在多障碍物场景中验证了其有效性。相比传统分离平移和四元数导向的RRT*，新方法具有更好的位姿连续性和障碍物避让能力

Conclusion: 该方法为纯运动学方法，不考虑相对轨道动力学，生成的路径可作为后续基于优化的轨迹规划器的初始估计，为实际卫星交会对接任务提供初步轨迹

Abstract: This paper proposes a sampling-based motion planner that employs a dual quaternion representation to generate smooth, collision-free six-degree-of-freedom pose trajectories for satellite rendezvous and docking under keep-out zone constraints. The proposed planner integrates the dual quaternion algebra directly into an RRT* framework, thereby enabling natural screw motion interpolation in SE(3). The dual quaternion-based RRT* has been implemented in Python and demonstrated on a representative multi-obstacle scenario. A comparison with a standard RRT* using separate translation and quaternion steering highlights the enhanced pose continuity and obstacle avoidance of the proposed method. The present approach is purely kinematic in nature and does not take into account relative orbital dynamics. Consequently, the resulting path provides a preliminary estimate for a subsequent optimisation-based trajectory planner, which will refine the motion with dynamic constraints for the purpose of practical satellite rendezvous and docking missions.

</details>


### [51] [UniStateDLO: Unified Generative State Estimation and Tracking of Deformable Linear Objects Under Occlusion for Constrained Manipulation](https://arxiv.org/abs/2512.17764)
*Kangchen Lv,Mingrui Yu,Shihefeng Wang,Xiangyang Ji,Xiang Li*

Main category: cs.RO

TL;DR: UniStateDLO：首个基于深度学习的完整DLO感知管道，利用扩散模型处理严重遮挡下的单帧状态估计和跨帧状态跟踪，实现零样本仿真到真实世界的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的DLO感知方法在受限操作环境中容易受到遮挡影响，包括周围障碍物、大变形、有限视角等。高维状态空间、缺乏视觉特征和传感器噪声进一步增加了可靠DLO感知的挑战。

Method: 将DLO感知任务（单帧状态估计和跨帧状态跟踪）表述为条件生成问题，利用扩散模型强大的能力来捕捉高度部分观测与高维DLO状态之间的复杂映射。网络仅在大规模合成数据集上训练，实现零样本仿真到真实世界的泛化。

Result: 在仿真和真实世界实验中，UniStateDLO在所有最先进的基线方法中表现最优，即使在严重遮挡下也能实时产生全局平滑且局部精确的DLO状态预测。作为闭环DLO操作系统的前端模块，支持复杂受限3D环境中的稳定反馈控制。

Conclusion: UniStateDLO是首个完整的基于深度学习的DLO感知管道，能够有效处理各种遮挡模式，包括初始遮挡、自遮挡和多物体遮挡，具有强大的数据效率，无需真实世界训练数据即可实现零样本仿真到真实世界的泛化。

Abstract: Perception of deformable linear objects (DLOs), such as cables, ropes, and wires, is the cornerstone for successful downstream manipulation. Although vision-based methods have been extensively explored, they remain highly vulnerable to occlusions that commonly arise in constrained manipulation environments due to surrounding obstacles, large and varying deformations, and limited viewpoints. Moreover, the high dimensionality of the state space, the lack of distinctive visual features, and the presence of sensor noises further compound the challenges of reliable DLO perception. To address these open issues, this paper presents UniStateDLO, the first complete DLO perception pipeline with deep-learning methods that achieves robust performance under severe occlusion, covering both single-frame state estimation and cross-frame state tracking from partial point clouds. Both tasks are formulated as conditional generative problems, leveraging the strong capability of diffusion models to capture the complex mapping between highly partial observations and high-dimensional DLO states. UniStateDLO effectively handles a wide range of occlusion patterns, including initial occlusion, self-occlusion, and occlusion caused by multiple objects. In addition, it exhibits strong data efficiency as the entire network is trained solely on a large-scale synthetic dataset, enabling zero-shot sim-to-real generalization without any real-world training data. Comprehensive simulation and real-world experiments demonstrate that UniStateDLO outperforms all state-of-the-art baselines in both estimation and tracking, producing globally smooth yet locally precise DLO state predictions in real time, even under substantial occlusions. Its integration as the front-end module in a closed-loop DLO manipulation system further demonstrates its ability to support stable feedback control in complex, constrained 3-D environments.

</details>


### [52] [Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes](https://arxiv.org/abs/2512.17846)
*Carlos Vélez García,Miguel Cazorla,Jorge Pomares*

Main category: cs.RO

TL;DR: PaD是一个离线目标条件强化学习框架，通过验证驱动轨迹合成，学习目标条件能量函数，通过梯度下降在能量景观中规划，在OGBench立方体操作任务中达到95%成功率。


<details>
  <summary>Details</summary>
Motivation: 解决离线目标条件强化学习中训练-测试不匹配问题，传统解耦建模管道（先学习模型后规划）存在性能下降，需要更鲁棒的规划方法替代直接策略学习。

Method: 学习目标条件能量函数评估潜在轨迹可行性，规划作为能量景观中的梯度优化，训练时使用自监督后见之目标重标记，推理时多轨迹候选在不同时间假设下优化。

Result: 在OGBench立方体操作任务中，使用专家演示达到95%成功率（SOTA），显著优于之前68%的方法；在噪声次优数据上训练进一步改善成功率和规划效率。

Conclusion: 学习评估和优化轨迹为离线无奖励规划提供了鲁棒替代方案，验证驱动规划优于直接策略学习，尤其在处理次优数据时表现更佳。

Abstract: We present Planning as Descent (PaD), a framework for offline goal-conditioned reinforcement learning that grounds trajectory synthesis in verification. Instead of learning a policy or explicit planner, PaD learns a goal-conditioned energy function over entire latent trajectories, assigning low energy to feasible, goal-consistent futures. Planning is realized as gradient-based refinement in this energy landscape, using identical computation during training and inference to reduce train-test mismatch common in decoupled modeling pipelines.
  PaD is trained via self-supervised hindsight goal relabeling, shaping the energy landscape around the planning dynamics. At inference, multiple trajectory candidates are refined under different temporal hypotheses, and low-energy plans balancing feasibility and efficiency are selected.
  We evaluate PaD on OGBench cube manipulation tasks. When trained on narrow expert demonstrations, PaD achieves state-of-the-art 95\% success, strongly outperforming prior methods that peak at 68\%. Remarkably, training on noisy, suboptimal data further improves success and plan efficiency, highlighting the benefits of verification-driven planning. Our results suggest learning to evaluate and refine trajectories provides a robust alternative to direct policy learning for offline, reward-free planning.

</details>


### [53] [AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning](https://arxiv.org/abs/2512.17853)
*Ran Gong,Xiaohan Zhang,Jinghuan Shang,Maria Vittoria Minniti,Jigarkumar Patel,Valerio Pepe,Riedana Yan,Ahmet Gundogdu,Ivan Kapelyukh,Ali Abbas,Xiaoqiang Yan,Harsh Patel,Laura Herlant,Karl Schmeckpeper*

Main category: cs.RO

TL;DR: AnyTask是一个自动化框架，利用大规模GPU并行仿真和基础模型来生成多样化机器人操作任务和数据，通过三种智能体生成专家演示，训练的行为克隆策略在真实机器人上实现了44%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 通用机器人学习受限于真实世界数据收集的高成本，虽然仿真可以扩展数据收集，但相关任务（仿真任务设计、场景生成、专家演示合成、仿真到真实转移）仍需要大量人工努力。

Method: 提出AnyTask框架，结合大规模GPU并行仿真和基础模型，设计多样化操作任务并合成机器人数据。引入三种智能体生成专家演示：1) ViPR：具有VLM循环并行优化的任务和运动规划智能体；2) ViPR-Eureka：具有生成密集奖励和LLM引导接触采样的强化学习智能体；3) ViPR-RL：结合规划和学习的混合方法，仅使用稀疏奖励生成高质量演示。

Result: 在生成数据上训练行为克隆策略，在仿真中验证并直接部署到真实机器人硬件。策略能够泛化到新物体姿态，在真实世界的拾取放置、抽屉打开、接触丰富的推动和长时程操作任务套件中实现了44%的平均成功率。

Conclusion: AnyTask通过自动化任务设计和数据生成，显著减少了机器人学习所需的人工努力，展示了在真实机器人上实现多样化操作任务的泛化能力，为通用机器人学习提供了有前景的解决方案。

Abstract: Generalist robot learning remains constrained by data: large-scale, diverse, and high-quality interaction data are expensive to collect in the real world. While simulation has become a promising way for scaling up data collection, the related tasks, including simulation task design, task-aware scene generation, expert demonstration synthesis, and sim-to-real transfer, still demand substantial human effort. We present AnyTask, an automated framework that pairs massively parallel GPU simulation with foundation models to design diverse manipulation tasks and synthesize robot data. We introduce three AnyTask agents for generating expert demonstrations aiming to solve as many tasks as possible: 1) ViPR, a novel task and motion planning agent with VLM-in-the-loop Parallel Refinement; 2) ViPR-Eureka, a reinforcement learning agent with generated dense rewards and LLM-guided contact sampling; 3) ViPR-RL, a hybrid planning and learning approach that jointly produces high-quality demonstrations with only sparse rewards. We train behavior cloning policies on generated data, validate them in simulation, and deploy them directly on real robot hardware. The policies generalize to novel object poses, achieving 44% average success across a suite of real-world pick-and-place, drawer opening, contact-rich pushing, and long-horizon manipulation tasks. Our project website is at https://anytask.rai-inst.com .

</details>
