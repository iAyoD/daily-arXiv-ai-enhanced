<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 78]
- [cs.RO](#cs.RO) [Total: 34]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents](https://arxiv.org/abs/2602.11156)
*Sungmoon Kim,Hyuna Jeon,Dahye Kim,Mingyu Kim,Dong-Kyu Chae,Jiwoong Kim*

Main category: cs.CL

TL;DR: HybridRAG是一个新颖的检索增强生成框架，通过预生成QA知识库和分层文本处理，在保证准确性的同时降低延迟，适用于处理非结构化PDF文档的现实聊天机器人场景。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法通常假设结构良好的文本源，并在查询时进行检索和生成，这限制了其在现实聊天机器人场景中的适用性。现实应用需要处理大量非结构化PDF文档（包含复杂布局），并在有限计算资源下服务大量用户。

Method: 1. 通过OCR和布局分析处理原始非结构化PDF文档，转换为分层文本块；2. 使用LLM从组织好的文本块中预生成可信的QA知识库；3. 查询时优先匹配QA库获取即时答案，仅在没有合适匹配时才进行实时响应生成。

Result: 在OHRBench上的实验表明，HybridRAG相比标准RAG基线提供了更高的答案质量和更低的延迟。

Conclusion: HybridRAG是处理大量非结构化文档和大量用户的现实聊天机器人应用的实用解决方案，在有限计算资源下实现了更好的性能和效率。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.

</details>


### [2] [Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety](https://arxiv.org/abs/2602.11157)
*Max Zhang,Derek Liu,Kai Zhang,Joshua Franco,Haihao Liu*

Main category: cs.CL

TL;DR: 研究探索知识蒸馏在多语言越狱防御中的应用，发现使用教师模型的安全拒绝数据进行标准微调反而会增加学生模型的越狱成功率，揭示了多语言安全对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全对齐主要集中于英语，导致在非英语特别是低资源语言环境下存在安全漏洞。需要探索有效的多语言安全对齐方法。

Method: 采用知识蒸馏方法，将专有教师模型（OpenAI o1-mini）的拒绝行为通过LoRA蒸馏到三个开源学生模型（Meta-Llama-3-8B-Instruct、Gemma-2-2B-IT、Qwen3-8B），使用约28,000个多语言越狱提示进行黑盒响应式参数高效微调。

Result: 反直觉发现：使用教师模型的安全拒绝数据进行标准微调反而使所有学生模型的越狱成功率增加高达16.6个百分点。通过移除导致安全退化的"边界"拒绝行为，可以缓解甚至逆转安全下降，但推理性能（GSM8K）仍然降低。

Conclusion: 知识蒸馏作为多语言安全对齐技术既面临挑战也有潜力，研究为未来该方向的研究奠定了基础，揭示了多语言安全对齐的复杂性和模型间的差异性。

Abstract: Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We introduce a novel application of knowledge distillation (KD) in the context of multilingual jailbreak prevention, examining its efficacy. We distill the refusal behaviors of a proprietary teacher model (OpenAI o1-mini) with Low-Rank Adaptation (LoRA) into three open-source student models: Meta-Llama-3-8B-Instruct, Gemma-2-2B-IT, and Qwen3-8B, using ~28,000 multilingual jailbreak prompts from XSafety via black-box response-based, parameter-efficient fine-tuning (PEFT). Evaluation on the MultiJail benchmark reveals a counterintuitive behavior: standard fine-tuning on the teacher's ``safe'' refusal data inadvertently increases Jailbreak Success Rate (JSR) for all student models, up to 16.6 percentage points. Our experiments reveal a divergent generalization to unseen languages during distillation, with varying outcomes depending on the base model. By removing a primary source of safety degradation, nuanced `boundary' refusals, we mitigate or even reverse safety declines in student models, although reductions in reasoning performance (GSM8K) persist. Overall, our exploratory study highlights the challenges and potential of KD as a technique for multilingual safety alignment, offering a foundation for future research in this direction.

</details>


### [3] [Retrieval Heads are Dynamic](https://arxiv.org/abs/2602.11162)
*Yuping Lin,Zitao Li,Yue Xing,Pengfei He,Yingqian Cui,Yaliang Li,Bolin Ding,Jingren Zhou,Jiliang Tang*

Main category: cs.CL

TL;DR: 该论文从动态视角研究LLM中的检索头，发现其在时间步上动态变化、不可替代，且模型隐藏状态编码了未来检索模式的预测信号，揭示了内部规划机制。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要基于静态统计数据识别LLM中的检索头，忽略了自回归生成过程中的细粒度时间动态性。本文旨在从动态视角研究检索头的行为模式。

Method: 通过广泛分析，建立三个核心主张：动态性、不可替代性和相关性。在Needle-in-a-Haystack任务和多跳QA任务上验证发现，并在动态检索增强生成框架中量化动态与静态检索头的效用差异。

Result: 发现检索头在时间步上动态变化；动态检索头具有时间步特异性且无法被静态检索头有效替代；模型隐藏状态编码了未来检索头模式的预测信号，表明存在内部规划机制。

Conclusion: 研究为LLM的内部机制提供了新见解，揭示了检索头的动态特性和模型内部的规划能力，对理解LLM的工作方式具有重要意义。

Abstract: Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that perform retrieval on average. This perspective overlooks the fine-grained temporal dynamics of autoregressive generation. In this paper, we investigate retrieval heads from a dynamic perspective. Through extensive analysis, we establish three core claims: (1) Dynamism: Retrieval heads vary dynamically across timesteps; (2) Irreplaceability: Dynamic retrieval heads are specific at each timestep and cannot be effectively replaced by static retrieval heads; and (3) Correlation: The model's hidden state encodes a predictive signal for future retrieval head patterns, indicating an internal planning mechanism. We validate these findings on the Needle-in-a-Haystack task and a multi-hop QA task, and quantify the differences on the utility of dynamic and static retrieval heads in a Dynamic Retrieval-Augmented Generation framework. Our study provides new insights into the internal mechanisms of LLMs.

</details>


### [4] [Nested Named Entity Recognition in Plasma Physics Research Articles](https://arxiv.org/abs/2602.11163)
*Muhammad Haris,Hans Höft,Markus M. Becker,Markus Stocker*

Main category: cs.CL

TL;DR: 提出一种基于编码器-Transformer和条件随机场的轻量级方法，用于从等离子体物理研究文章中提取嵌套命名实体，通过实体特定模型专业化和超参数优化提升性能。


<details>
  <summary>Details</summary>
Motivation: 等离子体物理研究文章包含高度复杂且上下文丰富的内容，需要提取关键实体以支持高级搜索等应用。现有NER方法在该专业领域的应用面临挑战，需要专门的方法来处理领域特定的实体提取需求。

Method: 1) 为嵌套NER任务标注包含16个实体类别的等离子体物理语料库；2) 采用实体特定模型专业化方法，训练独立的BERT-CRF模型识别单个实体类型；3) 集成超参数优化过程系统性地微调模型参数以提升性能。

Result: 开发了一个专门针对等离子体物理领域的NER系统，能够有效提取该科学领域的专业实体。该方法为研究人员导航和分析科学文献提供了基础支持。

Conclusion: 这项工作推进了等离子体物理领域的实体识别技术，为科学文献的导航和分析提供了实用工具，支持该领域研究人员的知识发现和信息提取需求。

Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.

</details>


### [5] [Assessing LLM Reliability on Temporally Recent Open-Domain Questions](https://arxiv.org/abs/2602.11165)
*Pushwitha Krishnappa,Amit Das,Vinija Jain,Tathagata Mukherjee,Aman Chadha*

Main category: cs.CL

TL;DR: RECOM基准测试评估LLMs对近期Reddit问题的回答，发现语义-词汇悖论：模型通过大量改写保持语义相似度（>99%余弦相似度），但词汇重叠率低（<8% BLEU-1），挑战了词汇指标在评估抽象生成中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs越来越多地用于开放域问答，但它们对近期信息的回答与人类视角的一致性尚未充分研究。需要评估LLMs在处理时效性强的社会讨论时的表现。

Method: 构建RECOM基准数据集（15,000个2025年9月的Reddit问题及社区答案），评估4个开源LLMs（Llama3.1-8B、Mistral-7B、Gemma-2-9B、GPT-OSS-20B），使用词汇指标（BLEU、ROUGE）、语义相似度（BERTScore、MoverScore、余弦相似度）和逻辑推理（NLI）进行多维度评估。

Result: 发现语义-词汇悖论：所有模型与参考答案的余弦相似度超过99%，但BLEU-1重叠率低于8%，差距超过90个百分点。MoverScore（51-53%）处于中间位置。模型规模不预测性能：Mistral-7B（7B参数）在所有指标上优于GPT-OSS-20B（20B参数）。NLI分析显示矛盾率低于7%。

Conclusion: 词汇指标在评估抽象生成时不可靠，需要多维度的评估框架来捕捉超越表面文本匹配的语义保真度。RECOM数据集公开可用。

Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0

</details>


### [6] [Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?](https://arxiv.org/abs/2602.11166)
*Xu Hu,Yifan Zhang,Songtao Wei,Chen Zhao,Qiannan Li,Bingzhe Li,Feng Chen*

Main category: cs.CL

TL;DR: PEFT方法能显著增强大语言模型的幻觉检测能力，主要通过重塑不确定性编码而非注入新事实知识


<details>
  <summary>Details</summary>
Motivation: 虽然参数高效微调(PEFT)方法被广泛用于适应下游任务并被认为能提高事实正确性，但其如何影响幻觉行为，特别是在QA数据集上的影响，尚未得到充分理解

Method: 通过系统性实证研究，在三个开源LLM骨干和三个事实寻求QA基准上，使用七种无监督幻觉检测方法（涵盖语义一致性、置信度和熵三种互补方法）评估PEFT的影响

Result: 实验结果表明PEFT能持续增强幻觉检测能力，显著提高各种幻觉检测器的AUROC；进一步分析显示PEFT主要重塑不确定性的编码和表现方式，而非向模型注入新的事实知识

Conclusion: PEFT方法通过改变模型内部不确定性表示来改善幻觉检测，这为理解PEFT如何影响LLM的事实正确性提供了新视角

Abstract: Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.

</details>


### [7] [Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering](https://arxiv.org/abs/2602.11167)
*Nathan Mao,Varun Kaushik,Shreya Shivkumar,Parham Sharafoleslami,Kevin Zhu,Sunishchal Dev*

Main category: cs.CL

TL;DR: FalseCite：一个用于捕捉和评估LLM幻觉的基准数据集，通过误导性引文诱导幻觉，发现GPT-4o-mini等模型在虚假引用下幻觉增加，并通过隐藏状态分析发现独特的"角形"模式


<details>
  <summary>Details</summary>
Motivation: LLM经常产生幻觉（生成无意义或虚假信息），在医学、法律等敏感领域尤其有害。为了系统研究这一现象，需要专门的基准数据集来捕捉和评估由误导性或伪造引文引起的幻觉

Method: 引入FalseCite数据集，包含误导性或伪造的引文来诱导幻觉。在GPT-4o-mini、Falcon-7B和Mistral 7-B上测试，分析模型对虚假声明的响应。通过隐藏状态向量可视化分析模型内部状态，进行聚类分析

Result: 虚假引用显著增加了模型的幻觉活动，特别是GPT-4o-mini。隐藏状态向量分析显示，无论是否产生幻觉，向量都倾向于形成独特的"角形"形状。FalseCite能够有效捕捉和评估LLM的幻觉现象

Conclusion: FalseCite为未来LLM研究中的幻觉评估和缓解提供了重要基础，通过系统化的基准测试和内部状态分析，有助于理解和减少LLM的幻觉问题

Abstract: Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.

</details>


### [8] [Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI](https://arxiv.org/abs/2602.11168)
*Jingyan Xu,Marcelo L. LaFleur,Christina Schweikert,D. Frank Hsu*

Main category: cs.CL

TL;DR: 该论文提出使用组合融合分析(CFA)结合多个AI模型来增强联合国可持续发展目标(SDG)的文本分类，通过生成式AI创建合成数据，CFA方法达到96.73%准确率，优于单个最佳模型。


<details>
  <summary>Details</summary>
Motivation: 在文本分类中，当类别不可用、难以区分或相互关联时，传统方法面临挑战。社会分析领域依赖文本数据，需要更有效的分类方法。特别是针对联合国可持续发展目标(SDG)的文本分类，需要更准确的方法来支持政策制定和决策。

Method: 使用生成式AI模型生成合成数据用于模型训练，然后应用组合融合分析(CFA)技术。CFA是一种系统融合范式，使用秩-得分特征(RSC)函数和认知多样性(CD)，通过结合一组相对较好且相互多样化的分类模型来增强分类性能。

Result: CFA技术达到了96.73%的性能表现，优于最佳个体模型。研究还将结果与人类领域专家的分类结果进行比较，发现结合多个ML/AI模型的智能与人类专家输入可以相互补充和增强。

Conclusion: 通过组合融合分析结合多个AI模型的智能，并获取人类专家输入，不仅可以相互补充，还能相互增强。这种方法为SDG文本分类提供了有效的解决方案，特别是在类别复杂、相互关联的情况下。

Abstract: (Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making. However, it remains a challenging problem in cases where the categories are unavailable, difficult to differentiate, or are interrelated. Social analysis with human context is an area that can benefit from text classification, as it relies substantially on text data. The focus of this paper is to enhance the classification of text according to the UN's Sustainable Development Goals (SDGs) by collecting and combining intelligence from multiple models. Combinatorial Fusion Analysis (CFA), a system fusion paradigm using a rank-score characteristic (RSC) function and cognitive diversity (CD), has been used to enhance classifier methods by combining a set of relatively good and mutually diverse classification models. We use a generative AI model to generate synthetic data for model training and then apply CFA to this classification task. The CFA technique achieves 96.73% performance, outperforming the best individual model. We compare the outcomes with those obtained from human domain experts. It is demonstrated that combining intelligence from multiple ML/AI models using CFA and getting input from human experts can, not only complement, but also enhance each other.

</details>


### [9] [Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis](https://arxiv.org/abs/2602.11169)
*Mangadoddi Srikar Vardhan,Lekkala Sai Teja*

Main category: cs.CL

TL;DR: 研究发现Transformer隐藏状态中向量方向和幅度具有不同功能：方向扰动主要影响语言建模损失，而幅度扰动主要影响句法处理。这种分离在LayerNorm架构中明显，但在RMSNorm架构中不同。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer隐藏状态中向量方向和幅度是否具有不同的功能角色，理解高维表示空间中这两个维度的计算意义。

Method: 使用Pythia系列模型，采用L2匹配扰动分析方法，确保角度和幅度扰动具有相同的欧几里得位移。通过因果干预研究不同扰动对语言建模损失和句法处理的影响。

Result: 发现显著交叉分离：角度扰动对语言建模损失造成更大损害（高达42.9倍），而幅度扰动对句法处理造成更大损害（20.4% vs. 1.6%准确率下降）。角度损害主要通过注意力通路传播，幅度损害部分通过LayerNorm通路传播。

Conclusion: 向量方向和幅度在LayerNorm架构中支持部分不同的计算角色：方向主要影响注意力路由，幅度调节精细句法判断的处理强度。这种分离依赖于架构选择，对线性表示假设、模型编辑和可解释性研究有重要意义。

Abstract: Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying Pythia-family models, we discover a striking cross-over dissociation: angular perturbations cause up to 42.9 more damage to language modeling loss, while magnitude perturbations cause disproportionately more damage to syntactic processing (20.4% vs.1.6% accuracy drop on subject-verb agreement).This finding is enabled by L2-matched perturbation analysis, a methodology ensuring that an gular and magnitude perturbations achieve identical Euclidean displacements. Causal intervention reveals that angular damage flows substantially through the attention pathways (28.4% loss recovery via attention repair), while magnitude damage flows partly through the LayerNorm pathways(29.9% recovery via LayerNorm repair). These patterns replicate across scales within the Pythia architecture family. These findings provide evidence that direction and magnitude support partially distinct computational roles in LayerNorm based architectures. The direction preferentially affects attentional routing, while magnitude modulates processing intensity for fine-grained syntactic judgments. We find different patterns in RMSNorm-based architectures, suggesting that the dissociation depends on architectural choices. Our results refine the linear representation hypothesis and have implications for model editing and interpretability research

</details>


### [10] [PRIME: Policy-Reinforced Iterative Multi-agent Execution for Algorithmic Reasoning in Large Language Models](https://arxiv.org/abs/2602.11170)
*Jiawei Xu,Zhenyu Yu,Ziqian Bi,Minh Duc Pham,Xiaoyi Qu,Danyang Zhang*

Main category: cs.CL

TL;DR: PRIME框架通过三个专门代理（执行器、验证器、协调器）和群体相对策略优化，显著提升大语言模型在算法推理任务上的性能，在PRIME-Bench基准上实现从26.8%到93.8%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多样化推理任务上表现出色，但在算法推理方面仍有局限，需要专门框架来提升其算法推理能力。

Method: 提出PRIME框架，包含三个专门代理：执行器负责逐步推理，验证器进行约束检查，协调器控制回溯，通过群体相对策略优化进行优化。同时构建PRIME-Bench基准，包含86个任务、12个类别、51,600个实例。

Result: PRIME将平均准确率从26.8%提升至93.8%（相对提升250%）。在需要持续状态跟踪的任务上改进最大：图灵机模拟从9%提升至92%，长除法从16%提升至94%。小模型受益尤为显著，能达到比其大8倍的模型的准确率。

Conclusion: PRIME框架通过多代理协作和迭代验证有效解决了算法推理中的错误传播问题，显著提升了大语言模型的算法推理能力，特别是对小模型效果更为明显。

Abstract: Large language models have demonstrated remarkable capabilities across diverse reasoning tasks, yet their performance on algorithmic reasoning remains limited. To handle this limitation, we propose PRIME (Policy-Reinforced Iterative Multi-agent Execution), a framework comprising three specialized agents, an executor for step-by-step reasoning, a verifier for constraint checking, and a coordinator for backtracking control, optimized through group relative policy optimization. For comprehensive evaluation, we introduce PRIME-Bench, the largest algorithmic reasoning benchmark to date, comprising 86 tasks across 12 categories with 51,600 instances. Tasks span sorting algorithms, graph and tree structures, automata and state machines, symbolic reasoning, and constraint-based puzzles, with execution traces reaching over one million steps. Compared to baseline approach, PRIME improves average accuracy from 26.8% to 93.8%, a 250% relative gain. The largest improvements occur on tasks requiring sustained state tracking, with Turing machine simulation improving from 9% to 92% and long division from 16% to 94%. Ablation studies identify iterative verification as the primary contributor, preventing the error propagation that causes baseline approaches to fail catastrophically. Analysis across model scales (8B-120B parameters) reveals that smaller models benefit disproportionately, achieving accuracy comparable to models 8x larger.

</details>


### [11] [Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization](https://arxiv.org/abs/2602.11171)
*Baek Seong-Eun,Lee Jung-Mok,Kim Sung-Bin,Tae-Hyun Oh*

Main category: cs.CL

TL;DR: 提出一个结合预训练LLM领域知识与贝叶斯优化的框架，用于高效搜索LoRA超参数，通过约30次迭代实现比45000次组合搜索更好的性能


<details>
  <summary>Details</summary>
Motivation: LoRA虽然使微调高效，但对超参数选择高度敏感，而穷举搜索计算成本高昂。需要利用LLM的领域知识来指导贝叶斯优化，提高超参数搜索效率

Method: 1) 将LLM重新用作离散到连续的映射，将超参数及其领域知识连接到连续向量空间；2) 通过语言提示设计和控制映射，注入LoRA领域知识；3) 用可学习token建模难以语言描述的残差信息；4) 利用完整数据集与子集性能强相关性，引入代理训练和评估

Result: 仅需约30次迭代找到的超参数，相比标准超参数搜索（约45000种组合）实现了超过20%的性能提升

Conclusion: 提出的框架成功整合LLM领域知识到贝叶斯优化中，显著提高了LoRA超参数搜索效率，仅需少量迭代即可获得优于传统大规模搜索的性能

Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning efficient, it is highly sensitive to the choice of hyperparameters, and exhaustive hyperparameter search is still computationally very demanding. To address these challenges, we propose a framework that integrates the domain knowledge of pre-trained LLMs into Bayesian Optimization (BO) to efficiently search for LoRA hyperparameters. To leverage the informed knowledge of LLMs, we repurpose LLMs as a discrete-to-continuous mapping to link the hyperparameters and their domain knowledge with a continuous vector space, where BO is conducted. We design and control the mapping by language prompting, where we provide a domain-aware textual prompt describing the relationships among hyperparameters and their respective roles; thereby, we explicitly inject domain knowledge about LoRA into the LLM in natural language. Also, we model the residual information that is hard to linguistically describe in the prompt with an additional learnable token. This aids BO to sample more high-performing hyperparameters. In addition, by leveraging the observation of the strong correlation between the respective performance obtained from full and subset training datasets in LoRA training regimes, we introduce proxy training and evaluation with a data subset. This further increases the efficiency of our method. We demonstrate that our hyperparameter found with only about 30 iterations achieves more than 20% performance improvement over standard hyperparameters found from about 45,000 combinations.

</details>


### [12] [Synthesizing the Virtual Advocate: A Multi-Persona Speech Generation Framework for Diverse Linguistic Jurisdictions in Indic Languages](https://arxiv.org/abs/2602.11172)
*Aniket Deroy*

Main category: cs.CL

TL;DR: 本研究评估了Gemini 2.5 Flash和Pro TTS模型在五种印度语言中生成法庭演讲的表现，发现模型在程序性信息传达上表现良好，但在情感表达和说服力方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 法律辩护需要权威语气、节奏停顿和情感智能的独特结合。随着LLM发展，TTS技术从基本可理解性转向上下文感知的表达性合成。在印度多语言环境中，合成语音需要传达权威和专业形象，这一任务变得更加复杂。

Method: 提出了一个提示框架，利用Gemini 2.5对五种语言的原生支持和上下文感知的节奏控制，生成不同的辩护律师角色。在泰米尔语、泰卢固语、孟加拉语、印地语和古吉拉特语五种印度语言中评估模型表现。

Result: 模型表现出"单调权威"特征，在程序性信息传达方面表现优异，但在动态声音调制和情感庄重性方面存在困难。孟加拉语和古吉拉特语的表现下降进一步突显了语音学方面的改进空间。

Conclusion: 多语言TTS已准备好处理程序性法律任务，但在复制人类法律话语的说服艺术方面仍面临挑战。研究强调了未来在语音学前沿的改进需求。

Abstract: Legal advocacy requires a unique combination of authoritative tone, rhythmic pausing for emphasis, and emotional intelligence. This study investigates the performance of the Gemini 2.5 Flash TTS and Gemini 2.5 Pro TTS models in generating synthetic courtroom speeches across five Indic languages: Tamil, Telugu, Bengali, Hindi, and Gujarati. We propose a prompting framework that utilizes Gemini 2.5s native support for 5 languages and its context-aware pacing to produce distinct advocate personas. The evolution of Large Language Models (LLMs) has shifted the focus of TexttoSpeech (TTS) technology from basic intelligibility to context-aware, expressive synthesis. In the legal domain, synthetic speech must convey authority and a specific professional persona a task that becomes significantly more complex in the linguistically diverse landscape of India. The models exhibit a "monotone authority," excelling at procedural information delivery but struggling with the dynamic vocal modulation and emotive gravitas required for persuasive advocacy. Performance dips in Bengali and Gujarati further highlight phonological frontiers for future refinement. This research underscores the readiness of multilingual TTS for procedural legal tasks while identifying the remaining challenges in replicating the persuasive artistry of human legal discourse. The code is available at-https://github.com/naturenurtureelite/Synthesizing-the-Virtual-Advocate/tree/main

</details>


### [13] [Author-in-the-Loop Response Generation and Evaluation: Integrating Author Expertise and Intent in Responses to Peer Review](https://arxiv.org/abs/2602.11173)
*Qian Ruan,Iryna Gurevych*

Main category: cs.CL

TL;DR: 作者提出REspGen框架，将作者回复生成重构为"作者在环"任务，整合作者输入、多属性控制和评估引导优化，并构建首个大规模对齐的评审-回复-修订三元组数据集Re³Align。


<details>
  <summary>Details</summary>
Motivation: 现有自动回复生成方法未能充分利用作者的专业知识和意图。作者在回复审稿意见时拥有领域专业知识、作者独有信息、修订策略等具体形式的专业知识和意图，需要NLP工具整合这些信号来支持有效的同行评审回复撰写。

Method: 提出REspGen生成框架，包含：1）显式作者输入整合；2）多属性控制；3）评估引导的优化。同时构建REspEval评估套件（20+指标）和Re³Align数据集（首个大规模对齐的评审-回复-修订三元组）。使用最先进的LLM进行实验。

Result: 实验表明：作者输入和评估引导优化能提升回复质量；输入设计对回复质量有重要影响；可控性和质量之间存在权衡关系。提供了公开的数据集、生成和评估工具。

Conclusion: 将作者回复生成重构为"作者在环"任务能更好地整合作者专业知识和意图，REspGen框架和Re³Align数据集为此类研究提供了重要基础，展示了整合作者输入和评估引导优化的价值。

Abstract: Author response (rebuttal) writing is a critical stage of scientific peer review that demands substantial author effort. Recent work frames this task as automatic text generation, underusing author expertise and intent. In practice, authors possess domain expertise, author-only information, revision and response strategies--concrete forms of author expertise and intent--to address reviewer concerns, and seek NLP assistance that integrates these signals to support effective response writing in peer review. We reformulate author response generation as an author-in-the-loop task and introduce REspGen, a generation framework that integrates explicit author input, multi-attribute control, and evaluation-guided refinement, together with REspEval, a comprehensive evaluation suite with 20+ metrics covering input utilization, controllability, response quality, and discourse. To support this formulation, we construct Re$^3$Align, the first large-scale dataset of aligned review--response--revision triplets, where revisions provide signals of author expertise and intent. Experiments with state-of-the-art LLMs show the benefits of author input and evaluation-guided refinement, the impact of input design on response quality, and trade-offs between controllability and quality. We make our dataset, generation and evaluation tools publicly available.

</details>


### [14] [The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models](https://arxiv.org/abs/2602.11174)
*Aradhya Dixit,Shreem Dixit*

Main category: cs.CL

TL;DR: 多语言预训练模型存在"脚本税"问题：不同书写系统的分词效率差异导致处理速度和信息成本显著不同，相同语言内容因书写系统不同而产生16.5倍推理速度差异和高达47.1%的信息成本增加。


<details>
  <summary>Details</summary>
Motivation: 研究多语言预训练模型对不同书写系统的处理效率差异，揭示分词器对特定书写系统施加的系统性成本，量化这种"脚本税"对模型性能的影响。

Method: 通过比较具有相同语言内容但不同书写系统的正交变体，使用分词碎片化程度（fertility）、推理速度、比特每字符（BPC）信息成本等指标，量化mBERT和XLM-R模型对不同书写系统的处理差异。

Result: 高碎片化书写系统的分词数量增加约3.4倍（6.73-6.85 vs. 2.10-2.35 tokens/word），推理速度降低16.5倍（0.23 vs. 3.8 sentences/second），信息成本显著增加（mBERT +19.7%，XLM-R +47.1%）。

Conclusion: 分词是多语言NLP中不平等现象的关键来源，需要开发脚本感知的分词和预训练方法来解决这种"脚本税"问题。

Abstract: Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with identical linguistic content. Across mBERT and XLM-R, the higher-fragmentation orthography shows a ~3.4x increase in fertility (6.73-6.85 vs. 2.10-2.35 tokens/word), leading to a 16.5x inference slowdown (0.23 vs. 3.8 sentences/second) on identical hardware. Using bits per character (BPC) to avoid the "NLL paradox" from subword fragmentation, we find a substantial increase in information cost: +19.7% for mBERT (8.06->9.65) and +47.1% for XLM-R (12.19->17.94). A round-trip conversion check (CER_rt=0.31) suggests these gaps reflect orthography-conditioned processing rather than mapping noise. Our results highlight tokenization as a key source of inequity in multilingual NLP and motivate script-aware tokenization and pretraining.

</details>


### [15] [Barriers to Discrete Reasoning with Transformers: A Survey Across Depth, Exactness, and Bandwidth](https://arxiv.org/abs/2602.11175)
*Michelle Yuan,Weiyi Sun,Amir H. Rezaeian,Jyotika Singh,Sandip Ghoshal,Yao-Ting Wang,Miguel Ballesteros,Yassine Benajiba*

Main category: cs.CL

TL;DR: 该调查论文从电路复杂性、近似理论和通信复杂性三个理论视角，分析了Transformer在离散推理任务（如算术、逻辑推理）中的理论局限性，解释了为什么当前架构难以实现精确的离散算法。


<details>
  <summary>Details</summary>
Motivation: Transformer已成为序列建模的基础架构，在自然语言处理、视觉等领域取得了最先进的性能。然而，它们在离散推理任务（如算术、逻辑推理、算法组合）中的理论局限性仍然是一个关键的开放性问题，需要从理论角度深入理解这些限制。

Method: 论文采用多理论视角的综合分析方法：1）电路复杂性视角分析Transformer的结构和计算限制；2）近似理论视角探讨逼近不连续函数的困难；3）通信复杂性视角研究token间通信的瓶颈。通过连接这些理论框架，提供统一的理论解释。

Result: 分析揭示了Transformer在离散推理任务中的多个根本性限制：深度约束、难以逼近不连续性、token间通信瓶颈等。这些理论限制解释了为什么Transformer在模式匹配和插值方面表现出色，但在实现精确的离散算法时面临困难。

Conclusion: 当前Transformer架构在离散推理任务中存在固有的理论局限性。论文讨论了这些发现对模型设计的影响，并提出了克服这些基础限制的潜在研究方向，为改进Transformer的符号计算能力提供了理论指导。

Abstract: Transformers have become the foundational architecture for a broad spectrum of sequence modeling applications, underpinning state-of-the-art systems in natural language processing, vision, and beyond. However, their theoretical limitations in discrete reasoning tasks, such as arithmetic, logical inference, and algorithmic composition, remain a critical open problem. In this survey, we synthesize recent studies from three theoretical perspectives: circuit complexity, approximation theory, and communication complexity, to clarify the structural and computational barriers that transformers face when performing symbolic computations. By connecting these established theoretical frameworks, we provide an accessible and unified account of why current transformer architectures struggle to implement exact discrete algorithms, even as they excel at pattern matching and interpolation. We review key definitions, seminal results, and illustrative examples, highlighting challenges such as depth constraints, difficulty approximating discontinuities, and bottlenecks in inter-token communication. Finally, we discuss implications for model design and suggest promising directions for overcoming these foundational limitations.

</details>


### [16] [Evaluating Few-Shot Temporal Reasoning of LLMs for Human Activity Prediction in Smart Environments](https://arxiv.org/abs/2602.11176)
*Maral Doctorarastoo,Katherine A. Flanigan,Mario Bergés,Christopher McComb*

Main category: cs.CL

TL;DR: 大型语言模型通过检索增强提示策略，在低数据环境下有效预测人类日常活动及其持续时间，展现出强大的时序推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的智能体模型在低数据环境下表现不佳，限制了其在智能家居、人机协作等实际应用中的实用性。需要探索预训练大语言模型是否能够利用其广泛的人类知识来填补这一空白。

Method: 采用检索增强提示策略，整合时间、空间、行为历史和角色四个上下文来源，在CASAS Aruba智能家居数据集上评估。评估包括两个任务：带持续时间估计的下一个活动预测，以及多步日常序列生成，均测试不同数量的few-shot示例。

Result: 大语言模型展现出强大的内在时序理解能力：即使在零样本设置下也能产生连贯的日常活动预测，添加1-2个示例可进一步优化持续时间校准和分类准确性。超过几个示例后性能饱和，呈现收益递减。序列级评估确认了跨few-shot条件的一致时序对齐。

Conclusion: 预训练语言模型可作为有前景的时序推理器，既能捕捉重复的日常规律，又能适应上下文依赖的行为变化，从而增强智能体模型的行为模块，特别是在低数据环境中具有实用价值。

Abstract: Anticipating human activities and their durations is essential in applications such as smart-home automation, simulation-based architectural and urban design, activity-based transportation system simulation, and human-robot collaboration, where adaptive systems must respond to human activities. Existing data-driven agent-based models--from rule-based to deep learning--struggle in low-data environments, limiting their practicality. This paper investigates whether large language models, pre-trained on broad human knowledge, can fill this gap by reasoning about everyday activities from compact contextual cues. We adopt a retrieval-augmented prompting strategy that integrates four sources of context--temporal, spatial, behavioral history, and persona--and evaluate it on the CASAS Aruba smart-home dataset. The evaluation spans two complementary tasks: next-activity prediction with duration estimation, and multi-step daily sequence generation, each tested with various numbers of few-shot examples provided in the prompt. Analyzing few-shot effects reveals how much contextual supervision is sufficient to balance data efficiency and predictive accuracy, particularly in low-data environments. Results show that large language models exhibit strong inherent temporal understanding of human behavior: even in zero-shot settings, they produce coherent daily activity predictions, while adding one or two demonstrations further refines duration calibration and categorical accuracy. Beyond a few examples, performance saturates, indicating diminishing returns. Sequence-level evaluation confirms consistent temporal alignment across few-shot conditions. These findings suggest that pre-trained language models can serve as promising temporal reasoners, capturing both recurring routines and context-dependent behavioral variations, thereby strengthening the behavioral modules of agent-based models.

</details>


### [17] [What Do LLMs Know About Alzheimer's Disease? Fine-Tuning, Probing, and Data Synthesis for AD Detection](https://arxiv.org/abs/2602.11177)
*Lei Jiang,Yue Zhou,Natalie Parde*

Main category: cs.CL

TL;DR: 利用大语言模型进行阿尔茨海默病早期检测，通过微调LLM分析内部表征，设计任务感知标记并生成合成数据增强检测性能


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的可靠早期检测具有挑战性，主要因为标记数据有限。虽然大语言模型在跨领域迁移方面表现出色，但通过监督微调将其适应于AD领域的研究仍不充分

Method: 1) 微调LLM用于AD检测；2) 使用探测技术分析transformer层的中间激活；3) 设计任务感知的特殊标记；4) 训练序列到序列模型作为数据合成工具，利用这些标记生成结构一致且具有诊断信息的合成样本

Result: 微调后，特定词语和特殊标记的探测值发生显著变化，表明这些元素在模型改进的检测性能中起关键作用。合成数据在内在评估和下游训练管道中都得到验证

Conclusion: 通过分析LLM内部表征，识别关键元素并设计任务感知标记，可以生成高质量的合成数据来增强AD检测性能，为解决标记数据有限的问题提供了有效方法

Abstract: Reliable early detection of Alzheimer's disease (AD) is challenging, particularly due to limited availability of labeled data. While large language models (LLMs) have shown strong transfer capabilities across domains, adapting them to the AD domain through supervised fine-tuning remains largely unexplored. In this work, we fine-tune an LLM for AD detection and investigate how task-relevant information is encoded within its internal representations. We employ probing techniques to analyze intermediate activations across transformer layers, and we observe that, after fine-tuning, the probing values of specific words and special markers change substantially, indicating that these elements assume a crucial role in the model's improved detection performance. Guided by this insight, we design a curated set of task-aware special markers and train a sequence-to-sequence model as a data-synthesis tool that leverages these markers to generate structurally consistent and diagnostically informative synthetic samples. We evaluate the synthesized data both intrinsically and by incorporating it into downstream training pipelines.

</details>


### [18] [From Instruction to Output: The Role of Prompting in Modern NLG](https://arxiv.org/abs/2602.11179)
*Munazza Zaib,Elaf Alhazmi*

Main category: cs.CL

TL;DR: 本文综述了提示工程在自然语言生成任务中的最新进展，提出了提示分类法、决策框架和设计-优化-评估框架，旨在为实践者提供系统指导。


<details>
  <summary>Details</summary>
Motivation: 尽管提示工程已成为提升大语言模型性能的关键技术，但在自然语言生成领域仍缺乏系统性的框架和统一理解，需要填补这一空白。

Method: 通过文献综述方法，分析近期提示工程进展，提出提示分类法、基于多种因素的决策框架，以及连接设计、优化和评估的系统框架。

Result: 建立了提示工程的分类体系，为实践者提供了基于任务需求选择合适提示方法的决策框架，并提出了支持更可控和可泛化NLG的系统框架。

Conclusion: 提示工程作为输入级控制机制，与微调和解码方法互补，需要系统化的框架来指导实践，未来研究应关注设计、优化和评估的整合。

Abstract: Prompt engineering has emerged as an integral technique for extending the strengths and abilities of Large Language Models (LLMs) to gain significant performance gains in various Natural Language Processing (NLP) tasks. This approach, which requires instructions to be composed in natural language to bring out the knowledge from LLMs in a structured way, has driven breakthroughs in various NLP tasks. Yet there is still no structured framework or coherent understanding of the varied prompt engineering methods and techniques, particularly in the field of Natural Language Generation (NLG).
  This survey aims to help fill that gap by outlining recent developments in prompt engineering, and their effect on different NLG tasks. It reviews recent advances in prompting methods and their impact on NLG tasks, presenting prompt design as an input-level control mechanism that complements fine-tuning and decoding approaches. The paper introduces a taxonomy of prompting paradigms, a decision framework for prompt selection based on varying factors for the practitioners, outlines emerging trends and challenges, and proposes a framework that links design, optimization, and evaluation to support more controllable and generalizable NLG.

</details>


### [19] [Mechanistic Interpretability for Large Language Model Alignment: Progress, Challenges, and Future Directions](https://arxiv.org/abs/2602.11180)
*Usman Naseem*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLM）机制可解释性在模型对齐中的应用进展，分析了从电路发现到因果干预等多种技术，探讨了可解释性如何指导RLHF、宪法AI等对齐策略，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在各种任务上表现出色，但其内部决策过程仍然不透明。机制可解释性研究对于理解和对齐这些模型至关重要，有助于揭示神经网络如何通过学习的表示和计算结构实现算法。

Method: 本文采用文献综述方法，系统梳理了应用于LLM对齐的机制可解释性技术，包括电路发现、特征可视化、激活引导和因果干预等方法，并分析了这些技术如何为对齐策略提供见解。

Result: 研究发现机制可解释性技术能够为LLM对齐策略（如RLHF、宪法AI和可扩展监督）提供重要见解，但同时也面临神经元多义性、叠加假设和大规模模型涌现行为解释等关键挑战。

Conclusion: 未来研究应关注自动化可解释性、电路跨模型泛化，以及开发能够扩展到前沿模型的可解释性驱动的对齐技术，以更好地理解和控制大型语言模型的行为。

Abstract: Large language models (LLMs) have achieved remarkable capabilities across diverse tasks, yet their internal decision-making processes remain largely opaque. Mechanistic interpretability (i.e., the systematic study of how neural networks implement algorithms through their learned representations and computational structures) has emerged as a critical research direction for understanding and aligning these models. This paper surveys recent progress in mechanistic interpretability techniques applied to LLM alignment, examining methods ranging from circuit discovery to feature visualization, activation steering, and causal intervention. We analyze how interpretability insights have informed alignment strategies including reinforcement learning from human feedback (RLHF), constitutional AI, and scalable oversight. Key challenges are identified, including the superposition hypothesis, polysemanticity of neurons, and the difficulty of interpreting emergent behaviors in large-scale models. We propose future research directions focusing on automated interpretability, cross-model generalization of circuits, and the development of interpretability-driven alignment techniques that can scale to frontier models.

</details>


### [20] [Code Mixologist : A Practitioner's Guide to Building Code-Mixed LLMs](https://arxiv.org/abs/2602.11181)
*Himanshu Gupta,Pratik Jayarao,Chaitanya Dwivedi,Neeraj Varshney*

Main category: cs.CL

TL;DR: 本文全面综述了大型语言模型中的代码混合与代码转换研究，提出了统一分类法，总结了构建、适应和评估CSW能力LLMs的实用指南，并分析了当前评估实践的问题和新兴安全挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言建模取得进展，但大型语言模型在混合语言环境中仍面临挑战，在语法性、事实性和安全性方面表现出系统性退化，需要系统研究代码混合与代码转换现象。

Method: 引入统一分类法，从数据、建模和评估三个维度组织现有研究；总结构建CSW能力LLMs的实用指南；分析从CSW定制预训练、任务特定后训练到提示策略和上下文学习的建模方法；审查当前评估实践。

Result: 系统梳理了CSW研究现状，识别了评估实践中的不稳定性和有限可重复性问题，发现了现有基准测试的语言覆盖不足和英语中心偏见，并记录了现有基准测试。

Conclusion: 代码混合与代码转换对LLMs仍是重要挑战，需要更系统的研究方法和评估框架，同时需要关注代码混合作为绕过模型安全机制的潜在风险，并指出了开放研究挑战。

Abstract: Code-mixing and code-switching (CSW) remain challenging phenomena for large language models (LLMs). Despite recent advances in multilingual modeling, LLMs often struggle in mixed-language settings, exhibiting systematic degradation in grammaticality, factuality, and safety behavior. This work provides a comprehensive overview of CSW research in modern large language model settings. We introduce a unifying taxonomy that organizes prior work along dimensions of data, modeling, and evaluation, and we distill these findings into a practical playbook of actionable recommendations for building, adapting, and evaluating CSW-capable LLMs. We review modeling approaches ranging from CSW-tailored pre-training and task-specific post-training to prompting strategies and in-context learning. We analyze current evaluation practices, highlighting sources of instability and limited reproducibility, and we catalog existing benchmarks while critically examining their linguistic coverage and English-centric biases. Finally, we discuss emerging safety concerns, including use of code-mixing as a mechanism for bypassing model safeguards, and identify open research challenges.

</details>


### [21] [MetaMem: Evolving Meta-Memory for Knowledge Utilization through Self-Reflective Symbolic Optimization](https://arxiv.org/abs/2602.11182)
*Haidong Xin,Xinze Li,Zhenghao Liu,Yukun Yan,Shuo Wang,Cheng Yang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: MetaMem提出了一种带有自进化元记忆的新型记忆系统框架，通过跨任务提炼可迁移的知识利用经验，指导LLM从分散的记忆片段中系统识别和整合关键证据，显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有记忆系统虽然能让LLM支持长时人机交互，但常常破坏交互会话的内在逻辑和时间关系，导致记忆单元碎片化和推理性能下降。需要一种方法教会LLM如何有效利用记忆知识。

Method: 提出MetaMem框架，通过自进化元记忆增强记忆系统。在元记忆优化过程中，通过自我反思推理过程并执行动作更新当前元记忆状态，迭代提炼跨任务的可迁移知识利用经验。积累的元记忆单元作为显式知识利用经验，指导LLM系统识别和整合分散记忆片段中的关键证据。

Result: 大量实验证明MetaMem的有效性，显著优于强基线模型超过3.6%。所有代码和数据集已开源。

Conclusion: MetaMem通过引入自进化元记忆，解决了现有记忆系统破坏会话逻辑关系的问题，显著提升了LLM在长时交互中的推理性能，为记忆系统的优化提供了新思路。

Abstract: Existing memory systems enable Large Language Models (LLMs) to support long-horizon human-LLM interactions by persisting historical interactions beyond limited context windows. However, while recent approaches have succeeded in constructing effective memories, they often disrupt the inherent logical and temporal relationships within interaction sessions, resulting in fragmented memory units and degraded reasoning performance. In this paper, we propose MetaMem, a novel framework that augments memory systems with a self-evolving meta-memory, aiming to teach LLMs how to effectively utilize memorized knowledge. During meta-memory optimization, MetaMem iteratively distills transferable knowledge utilization experiences across different tasks by self-reflecting on reasoning processes and performing actions to update the current meta-memory state. The accumulated meta-memory units serve as explicit knowledge utilization experiences, guiding the LLM to systematically identify and integrate critical evidence from scattered memory fragments. Extensive experiments demonstrate the effectiveness of MetaMem, which significantly outperforms strong baselines by over 3.6%. All codes and datasets are available at https://github.com/OpenBMB/MetaMem.

</details>


### [22] [DDL2PropBank Agent: Benchmarking Multi-Agent Frameworks' Developer Experience Through a Novel Relational Schema Mapping Task](https://arxiv.org/abs/2602.11198)
*Shafiuddin Rehan Ahmed,Wei Wei*

Main category: cs.CL

TL;DR: 提出DDL2PropBank基准任务，评估多智能体框架的开发者体验，发现Agno在代码复杂度和AI辅助性方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 多智能体框架承诺简化LLM驱动的软件开发，但缺乏在受控环境中评估其开发者体验的系统方法

Method: 引入DDL2PropBank基准任务（数据库模式到PropBank角色集映射），使用工具即智能体模式在10个框架中实现相同智能体逻辑，从代码复杂度和AI辅助性两个维度评估

Result: 发现三倍复杂度谱系，Pydantic AI和Agno实现开销最小；AI辅助性方面，结构对齐分数能可靠代理单模式框架的成功，但高估多模式框架的正确性；Agno综合表现最强，复杂度最低、结构对齐最高且pass@1达83%

Conclusion: Agno在多智能体框架评估中表现最佳，结合了最低复杂度和最高AI辅助性，为框架开发者体验评估提供了系统方法

Abstract: Multi-agent frameworks promise to simplify LLM-driven software development, yet there is no principled way to evaluate their developer experience in a controlled setting. We introduce DDL2PropBank, a novel benchmark task that maps relational database schemas to PropBank rolesets, requiring autonomous retrieval of candidate frames and fine-grained linguistic reasoning over table names, columns, and relations. Using the Agent-as-a-Tool pattern, we implement identical agent logic across 10 frameworks and evaluate along two dimensions: (i) code complexity via static analysis, and (ii) AI-assistability -- the extent to which LLMs can autonomously generate correct, framework-specific code. Our results reveal a threefold complexity spectrum, with Pydantic AI and Agno requiring the least implementation overhead. For AI-assistability, structural alignment scores reliably proxy runtime success for frameworks with single canonical patterns, but overestimate correctness for multi-pattern frameworks. Agno emerges as the strongest overall performer, combining lowest complexity with highest structural alignment and 83% pass@1.

</details>


### [23] [When and What to Ask: AskBench and Rubric-Guided RLVR for LLM Clarification](https://arxiv.org/abs/2602.11199)
*Jiale Zhao,Ke Fang,Lu Cheng*

Main category: cs.CL

TL;DR: 论文提出AskBench基准测试和RLVR方法，用于评估和改进LLM在信息不足或错误前提下的澄清提问能力，减少幻觉和错误强化。


<details>
  <summary>Details</summary>
Motivation: LLM经常在提示缺少关键细节或包含误导信息时仍然回应，导致幻觉或强化错误观念。需要评估和改进LLM决定何时以及如何澄清的能力，同时不牺牲任务性能。

Method: 1. 提出AskBench交互式基准测试，将标准QA对转换为具有明确检查点的多轮交互；2. 统一评估循环评估最终答案并模拟用户响应；3. 包含两个设置：AskMind（意图不足查询）和AskOverconfidence（包含错误前提的查询）；4. 提出RLVR（基于验证器的奖励强化学习），使用结构化评分标准鼓励有针对性的澄清。

Result: 实验显示在准确性、评分标准遵循度和交互效率方面都有持续改进，对未见领域有很强的泛化能力。

Conclusion: AskBench基准测试和RLVR方法能有效提高LLM在信息不足或错误前提下的澄清提问能力，减少幻觉和错误强化，具有很好的泛化性能。

Abstract: Large language models (LLMs) often respond even when prompts omit critical details or include misleading information, leading to hallucinations or reinforced misconceptions. We study how to evaluate and improve LLMs' ability to decide when and what to ask for clarification without sacrificing task performance. We introduce AskBench, an interactive benchmark that converts standard QA pairs into multi-turn interactions with explicit checkpoints. A unified judge loop evaluates final answers and simulates user responses as needed. AskBench covers two settings: AskMind, with intent-deficient queries requiring clarification, and AskOverconfidence, with queries containing false premises that must be identified and corrected. We further propose rubric-guided reinforcement learning with verifier-based rewards (RLVR), which uses structured rubrics to encourage targeted clarification. Experiments show consistent improvements in accuracy, rubric adherence, and interaction efficiency, with strong generalization to unseen domains.

</details>


### [24] [Mechanistic Evidence for Faithfulness Decay in Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.11201)
*Donald Ye,Max Loffgren,Om Kotadia,Linus Wong*

Main category: cs.CL

TL;DR: 论文提出NLDD指标来评估思维链解释的忠实性，发现模型推理存在"推理视界"现象，超过70-85%链长的推理步骤对最终答案影响很小甚至负面。


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用的思维链解释存在一个根本问题：不清楚这些逐步解释是否真实反映了模型的实际推理过程，还是仅仅是事后合理化。需要一种方法来衡量思维链解释的忠实性。

Method: 提出标准化对数差异衰减(NLDD)指标，通过破坏解释中的单个推理步骤并测量模型对其答案置信度的下降程度，来判断该步骤是否真正重要。通过标准化这些测量，NLDD支持跨不同架构的严格模型比较。

Result: 在语法、逻辑和算术任务上测试三个模型家族，发现一致的"推理视界"现象：在70-85%的链长之后，推理标记对最终答案几乎没有或产生负面影响。还发现模型可以编码正确的内部表示却完全无法完成任务。

Conclusion: 仅凭准确性无法揭示模型是否真正通过思维链进行推理。NLDD提供了一种方法来衡量思维链何时真正重要，揭示了当前思维链解释的局限性。

Abstract: Chain-of-Thought (CoT) explanations are widely used to interpret how language models solve complex problems, yet it remains unclear whether these step-by-step explanations reflect how the model actually reaches its answer, or merely post-hoc justifications. We propose Normalized Logit Difference Decay (NLDD), a metric that measures whether individual reasoning steps are faithful to the model's decision-making process. Our approach corrupts individual reasoning steps from the explanation and measures how much the model's confidence in its answer drops, to determine if a step is truly important. By standardizing these measurements, NLDD enables rigorous cross-model comparison across different architectures. Testing three model families across syntactic, logical, and arithmetic tasks, we discover a consistent Reasoning Horizon (k*) at 70--85% of chain length, beyond which reasoning tokens have little or negative effect on the final answer. We also find that models can encode correct internal representations while completely failing the task. These results show that accuracy alone does not reveal whether a model actually reasons through its chain. NLDD offers a way to measure when CoT matters.

</details>


### [25] [The Automatic Verification of Image-Text Claims (AVerImaTeC) Shared Task](https://arxiv.org/abs/2602.11221)
*Rui Cao,Zhenyun Deng,Yulong Chen,Michael Schlichtkrull,Andreas Vlachos*

Main category: cs.CL

TL;DR: AVerImaTeC共享任务旨在推进图像-文本声明验证系统的开发，通过检索证据和验证真实世界图像-文本声明，共有14个开发阶段和6个测试阶段提交，所有系统均超越基线，最佳成绩为0.5455。


<details>
  <summary>Details</summary>
Motivation: 推动图像-文本声明验证系统的发展，通过检索证据来验证真实世界中的图像-文本声明，促进多模态信息验证技术的研究和应用。

Method: 参与者可以使用外部知识源（如网络搜索引擎）或组织者提供的知识库，系统性能使用AVerImaTeC评分评估，该评分定义为条件判决准确率，只有在证据评分超过预定阈值时判决才被视为正确。

Result: 共享任务吸引了14个开发阶段提交和6个测试阶段提交，所有测试阶段参与系统均超越了提供的基线，获胜团队HUMANE获得了0.5455的AVerImaTeC评分。

Conclusion: 该共享任务成功推动了图像-文本声明验证系统的研究，提供了详细的评估结果和关键见解，为未来多模态信息验证技术的发展奠定了基础。

Abstract: The Automatic Verification of Image-Text Claims (AVerImaTeC) shared task aims to advance system development for retrieving evidence and verifying real-world image-text claims. Participants were allowed to either employ external knowledge sources, such as web search engines, or leverage the curated knowledge store provided by the organizers. System performance was evaluated using the AVerImaTeC score, defined as a conditional verdict accuracy in which a verdict is considered correct only when the associated evidence score exceeds a predefined threshold. The shared task attracted 14 submissions during the development phase and 6 submissions during the testing phase. All participating systems in the testing phase outperformed the baseline provided. The winning team, HUMANE, achieved an AVerImaTeC score of 0.5455. This paper provides a detailed description of the shared task, presents the complete evaluation results, and discusses key insights and lessons learned.

</details>


### [26] [SurveyLens: A Research Discipline-Aware Benchmark for Automatic Survey Generation](https://arxiv.org/abs/2602.11238)
*Beichen Guo,Zhiyuan Wen,Jia Gu,Senzhang Wang,Haochen Shi,Ruosong Yang,Shuaiqi Liu*

Main category: cs.CL

TL;DR: SurveyLens是首个学科感知的自动综述生成基准，包含1000篇人工撰写综述和双视角评估框架，用于评估11种ASG方法在不同学科中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前ASG评估方法依赖通用指标且偏向计算机科学，无法评估ASG方法是否遵循不同学科的特定标准，导致非CS领域研究者缺乏使用ASG系统生成高质量学科合规综述的指导。

Method: 构建SurveyLens-1k数据集（1000篇高质量人工综述，涵盖10个学科），提出双视角评估框架：1）学科感知评分评估（使用LLM和人类偏好对齐权重评估学科写作标准遵循度）；2）规范对齐评估（严格测量内容覆盖和综合质量）。

Result: 评估了11种最先进的ASG方法（包括Vanilla LLM、ASG系统和深度研究智能体），揭示了每种范式在不同领域中的独特优势和劣势。

Conclusion: SurveyLens填补了ASG评估的学科感知空白，为根据特定学科需求选择工具提供了重要指导，帮助研究者生成符合学科标准的高质量综述。

Abstract: The exponential growth of scientific literature has driven the evolution of Automatic Survey Generation (ASG) from simple pipelines to multi-agent frameworks and commercial Deep Research agents. However, current ASG evaluation methods rely on generic metrics and are heavily biased toward Computer Science (CS), failing to assess whether ASG methods adhere to the distinct standards of various academic disciplines. Consequently, researchers, especially those outside CS, lack clear guidance on using ASG systems to yield high-quality surveys compliant with specific discipline standards. To bridge this gap, we introduce SurveyLens, the first discipline-aware benchmark evaluating ASG methods across diverse research disciplines. We construct SurveyLens-1k, a curated dataset of 1,000 high-quality human-written surveys spanning 10 disciplines. Subsequently, we propose a dual-lens evaluation framework: (1) Discipline-Aware Rubric Evaluation, which utilizes LLMs with human preference-aligned weights to assess adherence to domain-specific writing standards; and (2) Canonical Alignment Evaluation to rigorously measure content coverage and synthesis quality against human-written survey papers. We conduct extensive experiments by evaluating 11 state-of-the-art ASG methods on SurveyLens, including Vanilla LLMs, ASG systems, and Deep Research agents. Our analysis reveals the distinct strengths and weaknesses of each paradigm across fields, providing essential guidance for selecting tools tailored to specific disciplinary requirements.

</details>


### [27] [Are Aligned Large Language Models Still Misaligned?](https://arxiv.org/abs/2602.11305)
*Usman Naseem,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Sushant Kumar Ray,Abdullah Mohammad,Agrima Seth*

Main category: cs.CL

TL;DR: 提出Mis-Align Bench基准，统一评估LLM在安全、价值和文化的三维对齐问题，构建SAVACU数据集并发现单维度模型在联合条件下表现不佳


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型对齐基准只关注单一维度（安全、价值或文化），无法同时评估三个维度的联合对齐情况，而现实世界查询需要同时满足这三个维度

Method: 1) 构建SAVACU数据集：重新分类LLM-PROMPT-DATASET为14个安全域、56个价值域和42个文化域，使用Mistral-7B和Llama-3.1扩展低资源域；2) 通过两阶段拒绝采样配对对齐和未对齐响应；3) 在通用、微调和开源LLM上进行系统评估

Result: 单维度模型在覆盖率上表现良好（最高97.6%），但在联合条件下假失败率超过50%，对齐分数较低（63%-66%）

Conclusion: 需要统一的多维度对齐基准来全面评估LLM的对齐问题，单维度评估无法反映真实世界的复杂需求

Abstract: Misalignment in Large Language Models (LLMs) arises when model behavior diverges from human expectations and fails to simultaneously satisfy safety, value, and cultural dimensions, which must co-occur in real-world settings to solve a real-world query. Existing misalignment benchmarks-such as INSECURE CODE (safety-centric), VALUEACTIONLENS (value-centric), and CULTURALHERITAGE (culture centric)-rely on evaluating misalignment along individual dimensions, preventing simultaneous evaluation. To address this gap, we introduce Mis-Align Bench, a unified benchmark for analyzing misalignment across safety, value, and cultural dimensions. First we constructs SAVACU, an English misaligned-aligned dataset of 382,424 samples spanning 112 domains (or labels), by reclassifying prompts from the LLM-PROMPT-DATASET via taxonomy into 14 safety domains, 56 value domains, and 42 cultural domains using Mistral-7B-Instruct-v0.3, and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based fingerprint to avoid deduplication. Furthermore, we pairs prompts with misaligned and aligned responses via two-stage rejection sampling to enforce quality. Second we benchmarks general-purpose, fine-tuned, and open-weight LLMs, enabling systematic evaluation of misalignment under three dimensions. Empirically, single-dimension models achieve high Coverage (upto 97.6%) but incur False Failure Rate >50% and lower Alignment Score (63%-66%) under joint conditions.

</details>


### [28] [Evaluating Alignment of Behavioral Dispositions in LLMs](https://arxiv.org/abs/2602.11328)
*Amir Taubenfeld,Zorik Gekhman,Lior Nezry,Omri Feldman,Natalie Harris,Shashir Reddy,Romina Stella,Ariel Goldstein,Marian Croak,Yossi Matias,Amir Feder*

Main category: cs.CL

TL;DR: 研究LLM在社交情境中的行为倾向，通过将心理学问卷转化为情境判断测试，发现LLM与人类偏好分布存在显著差异：在低共识场景中过度自信，在高共识场景中偏离人类共识，且存在价值观与行为不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM融入日常生活，理解其行为变得至关重要。研究旨在探究LLM在社交情境中表现出的行为倾向是否与人类一致，为评估LLM的社会适应性提供框架。

Method: 将心理学问卷转化为情境判断测试（SJT），生成2,500个经过人工验证的SJT。从550名参与者中收集每个SJT的偏好行为，并评估25个LLM在相同情境下的反应。

Result: LLM与人类偏好分布存在显著差异：1）低共识场景中LLM对单一回应过度自信；2）高共识场景中较小模型偏离显著，前沿模型也有15-20%不反映共识；3）LLM存在跨模型的行为模式差异；4）LLM的自我报告价值观与实际行为存在差距。

Conclusion: LLM在社交情境中的行为倾向与人类存在系统性差异，需要进一步研究以确保LLM的社会适应性。将心理学问卷转化为行为评估的方法有效揭示了LLM价值观与行为的不一致性。

Abstract: As LLMs integrate into our daily lives, understanding their behavior becomes essential. In this work, we focus on behavioral dispositions$-$the underlying tendencies that shape responses in social contexts$-$and introduce a framework to study how closely the dispositions expressed by LLMs align with those of humans. Our approach is grounded in established psychological questionnaires but adapts them for LLMs by transforming human self-report statements into Situational Judgment Tests (SJTs). These SJTs assess behavior by eliciting natural recommendations in realistic user-assistant scenarios. We generate 2,500 SJTs, each validated by three human annotators, and collect preferred actions from 10 annotators per SJT, from a large pool of 550 participants. In a comprehensive study involving 25 LLMs, we find that models often do not reflect the distribution of human preferences: (1) in scenarios with low human consensus, LLMs consistently exhibit overconfidence in a single response; (2) when human consensus is high, smaller models deviate significantly, and even some frontier models do not reflect the consensus in 15-20% of cases; (3) traits can exhibit cross-LLM patterns, e.g., LLMs may encourage emotion expression in contexts where human consensus favors composure. Lastly, mapping psychometric statements directly to behavioral scenarios presents a unique opportunity to evaluate the predictive validity of self-reports, revealing considerable gaps between LLMs' stated values and their revealed behavior.

</details>


### [29] [When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing](https://arxiv.org/abs/2602.11358)
*Zachary Pedram Dadfar*

Main category: cs.CL

TL;DR: 研究发现大语言模型的自我反思语言能够反映内部计算状态，而非仅仅是编造。通过Pull方法识别出自我参照处理的特异性激活方向，该方向与拒绝方向正交，位于模型深度6.25%处，并能因果影响内省输出。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型产生的自我反思语言是真实反映内部计算状态，还是仅仅是复杂的编造。理解模型自我报告的可信度和神经基础。

Method: 提出Pull方法，通过格式工程引发扩展的自我检查。识别Llama 3.1中区分自我参照处理和描述性处理的激活空间方向。分析词汇与激活动态的对应关系，包括自相关和变异性指标。

Result: 发现自我参照词汇能追踪并发激活动态，这种对应关系是自我参照处理特有的。识别出的方向与已知拒绝方向正交，位于模型深度6.25%处，能因果影响内省输出。当模型产生"loop"词汇时，激活显示更高自相关性；产生"shimmer"词汇时，激活变异性增加。相同词汇在非自我参照语境中无激活对应关系。Qwen 2.5-32B独立发展出不同的内省词汇追踪不同激活指标。

Conclusion: 在适当条件下，Transformer模型的自我报告能够可靠地追踪内部计算状态，表明模型的自我反思语言具有神经计算基础。

Abstract: Large language models produce rich introspective language when prompted for self-examination, but whether this language reflects internal computation or sophisticated confabulation has remained unclear. We show that self-referential vocabulary tracks concurrent activation dynamics, and that this correspondence is specific to self-referential processing. We introduce the Pull Methodology, a protocol that elicits extended self-examination through format engineering, and use it to identify a direction in activation space that distinguishes self-referential from descriptive processing in Llama 3.1. The direction is orthogonal to the known refusal direction, localised at 6.25% of model depth, and causally influences introspective output when used for steering. When models produce "loop" vocabulary, their activations exhibit higher autocorrelation (r = 0.44, p = 0.002); when they produce "shimmer" vocabulary under steering, activation variability increases (r = 0.36, p = 0.002). Critically, the same vocabulary in non-self-referential contexts shows no activation correspondence despite nine-fold higher frequency. Qwen 2.5-32B, with no shared training, independently develops different introspective vocabulary tracking different activation metrics, all absent in descriptive controls. The findings indicate that self-report in transformer models can, under appropriate conditions, reliably track internal computational states.

</details>


### [30] [Finding the Cracks: Improving LLMs Reasoning with Paraphrastic Probing and Consistency Verification](https://arxiv.org/abs/2602.11361)
*Weili Shi,Dongliang Guo,Lehan Yang,Tianlong Wang,Hanzhang Yuan,Sheng Li*

Main category: cs.CL

TL;DR: PPCV框架通过识别关键令牌并替换候选替代方案，通过一致性验证提升大语言模型的推理性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中因幻觉和错误累积导致性能下降，现有方法难以可靠识别和利用关键令牌

Method: 提出PPCV两阶段框架：第一阶段通过问题转述和推理路径对比识别关键令牌；第二阶段替换关键令牌并生成新推理路径，通过一致性验证确定最终答案

Result: 在主流大语言模型和多个基准测试上的实验表明，PPCV相比基线方法显著提升了推理性能

Conclusion: PPCV通过系统性地识别和替换关键令牌，结合一致性验证机制，有效提升了大语言模型的复杂推理能力

Abstract: Large language models have demonstrated impressive performance across a variety of reasoning tasks. However, their problem-solving ability often declines on more complex tasks due to hallucinations and the accumulation of errors within these intermediate steps. Recent work has introduced the notion of critical tokens--tokens in the reasoning process that exert significant influence on subsequent steps. Prior studies suggest that replacing critical tokens can refine reasoning trajectories. Nonetheless, reliably identifying and exploiting critical tokens remains challenging. To address this, we propose the Paraphrastic Probing and Consistency Verification~(PPCV) framework. PPCV operates in two stages. In the first stage, we roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. And we identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. A criterion is employed to confirm the final critical token. In the second stage, we substitute critical tokens with candidate alternatives and roll out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes. We evaluate PPCV on mainstream LLMs across multiple benchmarks. Extensive experiments demonstrate PPCV substantially enhances the reasoning performance of LLMs compared to baselines.

</details>


### [31] [The Energy of Falsehood: Detecting Hallucinations via Diffusion Model Likelihoods](https://arxiv.org/abs/2602.11364)
*Arpit Singh Gautam,Kailash Talreja,Saurabh Jha*

Main category: cs.CL

TL;DR: DiffuTruth：基于非平衡热力学的无监督事实验证框架，通过生成压力测试和语义能量度量，有效检测LLM幻觉，在FEVER和HOVER数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常产生看似合理但错误的主张（幻觉），而现有的不确定性度量方法在模型自信地犯错时往往无法检测到这些错误。需要一种新的方法来区分事实真相和幻觉。

Method: 提出DiffuTruth框架，将事实验证重新概念化为非平衡热力学过程：事实真相作为生成流形上的稳定吸引子，而幻觉是不稳定的。引入生成压力测试：用噪声破坏声明，然后使用离散文本扩散模型重建。定义语义能量度量，使用NLI批评器测量原始声明与重建之间的语义分歧。进一步提出混合校准方法，融合稳定性信号与判别性置信度。

Result: 在FEVER数据集上，DiffuTruth实现了0.725的无监督AUROC，比基线方法提升1.5%，通过纠正过度自信的预测。在HOVER多跳数据集上，零样本泛化性能优于基线超过4%，证实了热力学真实性对分布偏移的鲁棒性。

Conclusion: DiffuTruth通过热力学视角重新定义事实验证，将事实视为生成流形上的稳定吸引子，提供了一种有效的无监督方法来检测LLM幻觉，并在多个数据集上展示了优越的性能和泛化能力。

Abstract: Large Language Models (LLMs) frequently hallucinate plausible but incorrect assertions, a vulnerability often missed by uncertainty metrics when models are confidently wrong. We propose DiffuTruth, an unsupervised framework that reconceptualizes fact verification via non equilibrium thermodynamics, positing that factual truths act as stable attractors on a generative manifold while hallucinations are unstable. We introduce the Generative Stress Test, claims are corrupted with noise and reconstructed using a discrete text diffusion model. We define Semantic Energy, a metric measuring the semantic divergence between the original claim and its reconstruction using an NLI critic. Unlike vector space errors, Semantic Energy isolates deep factual contradictions. We further propose a Hybrid Calibration fusing this stability signal with discriminative confidence. Extensive experiments on FEVER demonstrate DiffuTruth achieves a state of the art unsupervised AUROC of 0.725, outperforming baselines by 1.5 percent through the correction of overconfident predictions. Furthermore, we show superior zero shot generalization on the multi hop HOVER dataset, outperforming baselines by over 4 percent, confirming the robustness of thermodynamic truth properties to distribution shifts.

</details>


### [32] [Advancing AI Trustworthiness Through Patient Simulation: Risk Assessment of Conversational Agents for Antidepressant Selection](https://arxiv.org/abs/2602.11391)
*Md Tanvir Rouf Shawon,Mohammad Sabik Irbaz,Hadeel R. A. Elyazori,Keerti Reddy Resapu,Yili Lin,Vladimir Franzuela Cardenas,Farrokh Alemi,Kevin Lybarger*

Main category: cs.CL

TL;DR: 开发了一个患者模拟器，用于自动化评估医疗对话AI，通过系统变化医疗、语言和行为维度来识别AI错误和风险模式。


<details>
  <summary>Details</summary>
Motivation: 需要可扩展、自动化的方法来评估医疗对话AI的性能，识别幻觉和错误，并分析不同患者群体的风险模式。

Method: 基于NIST AI风险管理框架，整合三个维度：医疗档案（来自All of Us研究项目）、语言档案（健康素养和沟通模式）、行为档案（合作、分心、对抗性互动）。评估了抗抑郁药选择AI决策辅助工具。

Result: 生成500个对话，人工标注者评估1,787个医疗概念，达成高一致性（F1=0.94，κ=0.73）；LLM评估者与人工标注者一致性相当（F1=0.94，κ=0.78）。发现AI性能随健康素养下降而单调退化：从有限健康素养的47.9%准确率到功能素养的69.1%，再到熟练素养的81.6%。

Conclusion: 患者模拟器能有效评估医疗对话AI，识别系统性错误，并揭示AI性能在不同患者群体中的差异，特别是健康素养较低的患者面临更高风险。

Abstract: Objective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare conversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across medical, linguistic, and behavioral dimensions, allowing annotators and an independent AI judge to assess agent performance, identify hallucinations and inaccuracies, and characterize risk patterns across diverse patient populations. Methods: The simulator is grounded in the NIST AI Risk Management Framework and integrates three profile components reflecting different dimensions of patient variation: (1) medical profiles constructed from electronic health records in the All of Us Research Program; (2) linguistic profiles modeling variation in health literacy and condition-specific communication patterns; and (3) behavioral profiles representing empirically observed interaction patterns, including cooperation, distraction, and adversarial engagement. We evaluated the simulator's effectiveness in identifying errors in an AI decision aid for antidepressant selection. Results: We generated 500 conversations between the patient simulator and the AI decision aid across systematic combinations of five linguistic and three behavioral profiles. Human annotators assessed 1,787 medical concepts across 100 conversations, achieving high agreement (F1=0.94, \k{appa}=0.73), and the LLM judge achieved comparable agreement with human annotators (F1=0.94, \k{appa}=0.78; paired bootstrap p=0.21). The simulator revealed a monotonic degradation in AI decision aid performance across the health literacy spectrum: rank-one concept retrieval accuracy increased from 47.9% for limited health literacy to 69.1% for functional and 81.6% for proficient.

</details>


### [33] [Gradients Must Earn Their Influence: Unifying SFT with Generalized Entropic Objectives](https://arxiv.org/abs/2602.11424)
*Zecheng Wang,Deyuan Liu,Chunshan Li,Yupeng Zhang,Zhengyun Zhao,Dianhui Chu,Bingning Wang,Dianbo Sui*

Main category: cs.CL

TL;DR: DEFT提出动态熵微调方法，通过基于分布浓度的信任门控机制，解决传统NLL在SFT中均匀加权导致的塑性-稳定性困境


<details>
  <summary>Details</summary>
Motivation: 传统监督微调中标准负对数似然采用均匀token级加权，存在两个问题：1) 对低概率目标的过度强调会放大噪声监督的梯度并破坏鲁棒先验；2) 当模型已经自信时，均匀加权提供弱锐化效果。现有方法无法解决由此产生的塑性-稳定性困境

Method: 将token级SFT目标统一到广义变形对数族中，揭示通用的门×误差梯度结构。使用凯莱变换将模型连续演化的不确定性映射到连续焦点轨迹上。提出动态熵微调(DEFT)，使用分布浓度(Rényi-2熵)作为模型预测状态的实用代理来调制信任门

Result: 大量实验和分析表明，DEFT在探索和利用之间实现了更好的平衡，从而提高了整体性能

Conclusion: DEFT通过动态调整模型对其当前预测的信任度，有效解决了传统SFT中的塑性-稳定性困境，实现了更优的微调效果

Abstract: Standard negative log-likelihood (NLL) for Supervised Fine-Tuning (SFT) applies uniform token-level weighting. This rigidity creates a two-fold failure mode: (i) overemphasizing low-probability targets can amplify gradients on noisy supervision and disrupt robust priors, and (ii) uniform weighting provides weak sharpening when the model is already confident. Existing methods fail to resolve the resulting plasticity--stability dilemma, often suppressing necessary learning signals alongside harmful ones. To address this issue, we unify token-level SFT objectives within a generalized deformed-log family and expose a universal gate $\times$ error gradient structure, where the gate controls how much the model trusts its current prediction. By employing the Cayley transform, we map the model's continuously evolving uncertainty onto a continuous focus trajectory, which enables seamless interpolation between scenarios involving uncertain novel concepts and those involving well-established knowledge. We then introduce Dynamic Entropy Fine-Tuning (DEFT), a parameter-free objective that modulates the trust gate using distribution concentration (Rényi-2 entropy) as a practical proxy for the model's predictive state. Extensive experiments and analyses demonstrate that DEFT achieves a better balance between exploration and exploitation, leading to improved overall performance.

</details>


### [34] [Towards Reliable Machine Translation: Scaling LLMs for Critical Error Detection and Safety](https://arxiv.org/abs/2602.11444)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

TL;DR: 本文探索指令调优大语言模型在机器翻译关键错误检测中的应用，发现模型缩放和适应策略能显著提升检测性能，优于传统编码器基线模型。


<details>
  <summary>Details</summary>
Motivation: 机器翻译中的关键错误（如事实扭曲、意图反转或偏见翻译）会损害多语言系统的可靠性、公平性和安全性。需要有效检测这些错误来构建更安全、可信赖的信息系统。

Method: 使用指令调优的大语言模型进行关键错误检测，评估不同参数规模的模型，采用零样本、少样本和微调等适应策略，并与XLM-R和ModernBERT等编码器基线模型进行比较。

Result: 模型缩放和适应策略带来一致的性能提升，优于编码器基线模型。改进关键错误检测有助于减少虚假信息、沟通失误和语言伤害的风险。

Conclusion: 提升机器翻译关键错误检测能力是构建更安全、可信赖、社会负责的多语言信息系统的必要保障，这不仅是一个技术挑战，更是追求公正和负责任多语言AI的重要防护措施。

Abstract: Machine Translation (MT) plays a pivotal role in cross-lingual information access, public policy communication, and equitable knowledge dissemination. However, critical meaning errors, such as factual distortions, intent reversals, or biased translations, can undermine the reliability, fairness, and safety of multilingual systems. In this work, we explore the capacity of instruction-tuned Large Language Models (LLMs) to detect such critical errors, evaluating models across a range of parameters using the publicly accessible data sets. Our findings show that model scaling and adaptation strategies (zero-shot, few-shot, fine-tuning) yield consistent improvements, outperforming encoder-only baselines like XLM-R and ModernBERT. We argue that improving critical error detection in MT contributes to safer, more trustworthy, and socially accountable information systems by reducing the risk of disinformation, miscommunication, and linguistic harm, especially in high-stakes or underrepresented contexts. This work positions error detection not merely as a technical challenge, but as a necessary safeguard in the pursuit of just and responsible multilingual AI. The code will be made available at GitHub.

</details>


### [35] [LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation](https://arxiv.org/abs/2602.11451)
*Ahmadreza Jeddi,Marco Ciccone,Babak Taati*

Main category: cs.CL

TL;DR: LoopFormer：一种循环Transformer，通过可变长度轨迹训练实现预算条件推理，在计算约束下保持强大性能


<details>
  <summary>Details</summary>
Motivation: 现有循环Transformer在训练和推理时固定循环迭代次数，无法灵活适应不同计算预算。需要研究这些模型能否在可变计算预算下自适应调整计算深度。

Method: 提出LoopFormer，通过可变长度轨迹训练实现预算条件推理。核心是shortcut-consistency训练方案，对齐不同长度的轨迹，确保短循环产生信息表示，长循环继续优化。每个循环基于当前时间和步长进行条件化。

Result: LoopFormer在语言建模和推理基准测试中表现出强大性能，即使在严格计算约束下也能保持，并能随着额外预算的增加而优雅扩展。

Conclusion: 循环Transformer天生适合自适应语言建模，为可控和预算感知的大型语言模型开辟了新路径。

Abstract: Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning. However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets. We introduce LoopFormer, a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning. Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling, opening a path toward controllable and budget-aware large language models.

</details>


### [36] [ADRD-Bench: A Preliminary LLM Benchmark for Alzheimer's Disease and Related Dementias](https://arxiv.org/abs/2602.11460)
*Guangxin Zhao,Jiahao Zheng,Malaz Boustani,Jarek Nabrzyski,Meng Jiang,Yiyu Shi,Zhi Zheng*

Main category: cs.CL

TL;DR: ADRD-Bench是首个针对阿尔茨海默病及相关痴呆症的LLM评估基准，包含1352个临床知识问题和149个照护实践问题，评估了33个LLM，发现顶级模型准确率超过90%，但推理质量和稳定性仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准对阿尔茨海默病及相关痴呆症（ADRD）覆盖不足，缺乏实际照护场景的评估，需要建立专门的ADRD评估基准来促进LLM在该领域的可靠应用。

Method: 构建ADRD-Bench基准数据集，包含两个部分：1）ADRD统一QA：整合7个现有医学基准的1352个问题；2）ADRD照护QA：基于Aging Brain Care项目创建149个实际照护场景问题。评估33个最先进的LLM。

Result: 开放权重通用模型准确率0.63-0.93（均值0.78），开放权重医学模型0.48-0.93（均值0.82），闭源通用模型0.83-0.91（均值0.89）。顶级模型准确率超过0.9，但案例研究显示推理质量和稳定性不一致。

Conclusion: 虽然顶级LLM在ADRD任务上表现良好，但推理质量和稳定性问题限制了其可靠性，需要基于日常照护数据的领域特定改进来增强LLM的知识和推理能力。

Abstract: Large language models (LLMs) have shown great potential for healthcare applications. However, existing evaluation benchmarks provide minimal coverage of Alzheimer's Disease and Related Dementias (ADRD). To address this gap, we introduce ADRD-Bench, the first ADRD-specific benchmark dataset designed for rigorous evaluation of LLMs. ADRD-Bench has two components: 1) ADRD Unified QA, a synthesis of 1,352 questions consolidated from seven established medical benchmarks, providing a unified assessment of clinical knowledge; and 2) ADRD Caregiving QA, a novel set of 149 questions derived from the Aging Brain Care (ABC) program, a widely used, evidence-based brain health management program. Guided by a program with national expertise in comprehensive ADRD care, this new set was designed to mitigate the lack of practical caregiving context in existing benchmarks. We evaluated 33 state-of-the-art LLMs on the proposed ADRD-Bench. Results showed that the accuracy of open-weight general models ranged from 0.63 to 0.93 (mean: 0.78; std: 0.09). The accuracy of open-weight medical models ranged from 0.48 to 0.93 (mean: 0.82; std: 0.13). The accuracy of closed-source general models ranged from 0.83 to 0.91 (mean: 0.89; std: 0.03). While top-tier models achieved high accuracies (>0.9), case studies revealed that inconsistent reasoning quality and stability limit their reliability, highlighting a critical need for domain-specific improvement to enhance LLMs' knowledge and reasoning grounded in daily caregiving data. The entire dataset is available at https://github.com/IIRL-ND/ADRD-Bench.

</details>


### [37] [When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration](https://arxiv.org/abs/2602.11488)
*Jayadev Billa*

Main category: cs.CL

TL;DR: 语音语言模型在音频与文本冲突时，会过度偏向文本（16.6%文本主导），远高于纯文本冲突（1.6%），这种偏差源于模型推理过程而非音频质量。


<details>
  <summary>Details</summary>
Motivation: 研究语音语言模型在音频与文本信息冲突时的处理机制，发现模型存在明显的文本主导偏差，即使音频质量更高且被明确指示信任音频。

Method: 使用ALME基准测试（57,602个音频-文本冲突刺激，8种语言），分析Gemini 2.0 Flash等模型。通过强制转录、文本标记为"故意损坏"、微调消融实验等方法探究偏差来源。

Result: 音频-文本冲突时文本主导率16.6%，纯文本冲突仅1.6%。音频质量不是原因（音频准确率97.2% > 级联准确率93.9%）。偏差源于LLM推理过程的可访问性不对称。

Conclusion: 文本主导反映了模型推理过程中模态仲裁的可访问性不对称，而非信息内容差异。这是标准语音基准未捕捉到的独特可靠性维度。

Abstract: When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6\% text dominance under audio-text conflict versus 1.6\% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2\%) exceeds cascade accuracy (93.9\%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations.
  This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19\% to 33\%), sacrificing audio's information advantage without improving accessibility. Framing text as ``deliberately corrupted'' reduces text dominance by 80\%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5\%), while LoRA on the language model halves it ($-$23.9\%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.

</details>


### [38] [Multimodal Fact-Level Attribution for Verifiable Reasoning](https://arxiv.org/abs/2602.11509)
*David Wan,Han Wang,Ziyang Wang,Elias Stengel-Eskin,Hyunji Lee,Mohit Bansal*

Main category: cs.CL

TL;DR: MuRGAt是一个评估多模态大语言模型事实级归因能力的基准，要求模型在需要超越直接观察的推理任务中生成带有精确引用的答案，揭示现有模型在推理与可验证归因之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有多模态归因基准和评估方法主要关注简化的、基于观察的场景或有限模态，无法评估复杂多模态推理中的归因能力。需要一个新的基准来评估在需要超越直接观察的推理设置中的事实级多模态归因。

Method: 提出了MuRGAt基准，要求模型处理视频、音频等多种模态输入，生成带有明确推理和精确引用的答案，每个引用需指定模态和时间段。同时开发了与人类判断高度相关的自动评估框架。

Result: 评估发现，即使是强大的多模态大语言模型也经常在正确推理的同时产生幻觉引用。存在一个关键权衡：增加推理深度或强制结构化归因通常会降低准确性，揭示了内部推理与可验证归因之间的显著差距。

Conclusion: MuRGAt基准揭示了当前多模态大语言模型在复杂推理任务中事实归因能力的不足，强调需要开发既能进行深度推理又能提供可验证引用的模型，这对实际应用中的可靠性至关重要。

Abstract: Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning. We introduce MuRGAt (Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.

</details>


### [39] [Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm](https://arxiv.org/abs/2602.11543)
*Jinrui Zhang,Chaodong Xiao,Aoqi Wu,Xindong Zhang,Lei Zhang*

Main category: cs.CL

TL;DR: SPES是一种内存高效的分散式预训练框架，用于混合专家LLM，通过在节点上仅训练专家子集来降低内存需求，并实现与集中式训练相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统LLM预训练需要集中式集群和大量高内存GPU，现有分散式方法仍受限于GPU内存，因为需要在每个节点上训练整个模型。

Method: 提出SPES框架：1）每个节点只训练专家子集，大幅降低内存占用；2）节点更新本地专家并定期同步，避免全参数传输；3）引入专家合并预热策略，在训练早期交换知识以加速收敛。

Result: 使用16个48GB GPU在互联网连接上训练2B参数MoE LLM，性能与类似计算预算的集中式训练相当；成功扩展训练7B模型和从密集检查点上采样9B模型，均匹配先前集中式基线。

Conclusion: SPES为MoE LLM提供了一种内存高效的分散式预训练解决方案，能够在有限硬件资源下实现与集中式训练相当的性能，具有良好可扩展性。

Abstract: Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization; however, they still need to train the entire model on each node, remaining constrained by GPU memory limitations. In this work, we propose SParse Expert Synchronization (SPES), a memory-efficient decentralized framework for pretraining mixture-of-experts (MoE) LLMs. SPES trains only a subset of experts per node, substantially lowering the memory footprint. Each node updates its local experts and periodically synchronizes with other nodes, eliminating full-parameter transmission while ensuring efficient knowledge sharing. To accelerate convergence, we introduce an expert-merging warm-up strategy, where experts exchange knowledge early in training, to rapidly establish foundational capabilities. With SPES, we train a 2B-parameter MoE LLM using 16 standalone 48GB GPUs over internet connections, which achieves competitive performance with centrally trained LLMs under similar computational budgets. We further demonstrate scalability by training a 7B model from scratch and a 9B model upcycled from a dense checkpoint, both of which match prior centralized baselines. Our code is available at https://github.com/zjr2000/SPES.

</details>


### [40] [SIGHT: Reinforcement Learning with Self-Evidence and Information-Gain Diverse Branching for Search Agent](https://arxiv.org/abs/2602.11551)
*Wenlin Zhong,Jinluan Yang,Yiquan Wu,Yi Liu,Jianhang Yao,Kun Kuang*

Main category: cs.CL

TL;DR: SIGHT框架通过自我证据支持和信息增益驱动的多样化分支，解决多轮搜索中冗余高、信噪比低导致的"隧道视觉"问题，显著提升复杂推理性能


<details>
  <summary>Details</summary>
Motivation: 强化学习赋能大语言模型进行自主搜索回答复杂问题，但在多轮搜索场景中，搜索结果存在高冗余和低信噪比的问题，导致代理容易陷入"隧道视觉"——早期噪声检索的强制解释会导致不可逆的错误累积

Method: 提出SIGHT框架：1) 通过自我证据支持(SES)将搜索结果提炼为高保真证据；2) 计算信息增益分数识别能最大程度减少不确定性的关键状态；3) 通过动态提示干预（去重、反思、自适应分支）生成带有SES的新分支；4) 通过组相对策略优化整合SES和正确性奖励，无需外部验证器即可内化稳健的探索策略

Result: 在单跳和多跳问答基准测试中，SIGHT显著优于现有方法，特别是在复杂推理场景中，且使用更少的搜索步骤

Conclusion: SIGHT框架通过自我证据支持和信息增益驱动的多样化分支，有效解决了多轮搜索中的冗余和噪声问题，防止"隧道视觉"，提升了搜索推理的鲁棒性和效率

Abstract: Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to master autonomous search for complex question answering. However, particularly within multi-turn search scenarios, this interaction introduces a critical challenge: search results often suffer from high redundancy and low signal-to-noise ratios. Consequently, agents easily fall into "Tunnel Vision," where the forced interpretation of early noisy retrievals leads to irreversible error accumulation. To address these challenges, we propose SIGHT, a framework that enhances search-based reasoning through Self-Evidence Support (SES) and Information-Gain Driven Diverse Branching. SIGHT distills search results into high-fidelity evidence via SES and calculates an Information Gain score to pinpoint pivotal states where observations maximally reduce uncertainty. This score guides Dynamic Prompting Interventions - including de-duplication, reflection, or adaptive branching - to spawn new branches with SES. Finally, by integrating SES and correctness rewards via Group Relative Policy Optimization, SIGHT internalizes robust exploration strategies without external verifiers. Experiments on single-hop and multi-hop QA benchmarks demonstrate that SIGHT significantly outperforms existing approaches, particularly in complex reasoning scenarios, using fewer search steps.

</details>


### [41] [PRIME: A Process-Outcome Alignment Benchmark for Verifiable Reasoning in Mathematics and Engineering](https://arxiv.org/abs/2602.11570)
*Xiangfeng Wang,Hangyu Guo,Yanlin Lai,Mitt Huang,Liang Zhao,Chengyuan Yao,Yinmin Zhang,Qi Han,Xiaoxiao Ren,Chun Yuan,Tong Xu,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: PRIME是一个用于评估验证器在数学和工程问题中过程-结果对齐能力的基准测试，包含2530个高难度样本，发现当前验证器经常无法检测推导错误，并提出基于PRIME选择验证器的过程感知RLVR训练方法，显著优于仅关注结果的基线。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型的验证器主要关注最终结果与真实答案的一致性，而忽略了推导过程中的潜在错误，导致会给从错误推导中得出的正确答案分配正奖励。需要解决过程-结果对齐的验证问题。

Method: 1) 创建PRIME基准：从大学STEM问题中通过一致性过滤管道收集2530个高难度样本；2) 提出过程感知RLVR训练范式：利用PRIME选择的验证器进行训练；3) 评估验证器在过程-结果对齐检测上的表现。

Result: 当前验证器经常无法检测推导缺陷。基于PRIME选择验证器的过程感知RLVR训练方法在AIME24、AIME25和Beyond-AIME上分别获得8.29%、9.12%和7.31%的绝对性能提升。PRIME准确度与RLVR训练效果呈强线性相关(R²>0.92)。

Conclusion: PRIME是一个可靠的验证器选择预测指标，过程感知的验证方法显著优于仅关注结果的验证方法，强调了在强化学习验证奖励中考虑推导过程的重要性。

Abstract: While model-based verifiers are essential for scaling Reinforcement Learning with Verifiable Rewards (RLVR), current outcome-centric verification paradigms primarily focus on the consistency between the final result and the ground truth, often neglecting potential errors in the derivation process. This leads to assigning positive rewards to correct answers produced from incorrect derivations. To bridge this gap, we introduce PRIME, a benchmark for evaluating verifiers on Process-Outcome Alignment verification in Mathematics and Engineering. Curated from a comprehensive collection of college-level STEM problems, PRIME comprises 2,530 high-difficulty samples through a consistency-based filtering pipeline. Through extensive evaluation, we find that current verifiers frequently fail to detect derivation flaws. Furthermore, we propose a process-aware RLVR training paradigm utilizing verifiers selected via PRIME. This approach substantially outperforms the outcome-only verification baseline, achieving absolute performance gains of 8.29%, 9.12%, and 7.31% on AIME24, AIME25, and Beyond-AIME, respectively, for the Qwen3-14B-Base model. Finally, we demonstrate a strong linear correlation ($R^2 > 0.92$) between verifier accuracy on PRIME and RLVR training effectiveness, validating PRIME as a reliable predictor for verifier selection.

</details>


### [42] [Scene-Aware Memory Discrimination: Deciding Which Personal Knowledge Stays](https://arxiv.org/abs/2602.11607)
*Yijie Zhong,Mengying Guo,Zewei Wang,Zhongyang Li,Dandan Tu,Haofen Wang*

Main category: cs.CL

TL;DR: 本文提出SAMD方法，通过选择性注意力机制解决LLM在记忆管理中的信息过滤和计算成本问题，包含门控单元和聚类提示模块，有效提升个性化应用中的记忆构建效率和质量。


<details>
  <summary>Details</summary>
Motivation: 智能设备产生大量用户交互数据形成有价值的个人知识，但现有LLM在记忆写入、管理和读取方面面临信息过滤困难和计算成本上升的挑战，需要借鉴人脑选择性注意力机制来解决这些问题。

Method: 提出场景感知记忆判别方法SAMD，包含两个核心组件：1）门控单元模块GUM，过滤非记忆性交互并聚焦于应用需求相关的显著内容；2）聚类提示模块CPM，建立自适应记忆标准，指导LLM判断信息应被记住或丢弃，并分析用户意图与记忆上下文关系构建有效聚类提示。

Result: 综合直接和间接评估表明SAMD方法有效且具有良好泛化能力。记忆判别性能评估显示SAMD成功回忆大部分记忆性数据，在动态场景中保持稳健。集成到个性化应用后，SAMD显著提升记忆构建效率和质量，改善个人知识组织。

Conclusion: SAMD方法通过选择性注意力机制有效解决了LLM在记忆管理中的信息过滤和计算效率问题，能够提升个性化应用中个人知识的组织效果，为智能设备用户交互数据的有效利用提供了新思路。

Abstract: Intelligent devices have become deeply integrated into everyday life, generating vast amounts of user interactions that form valuable personal knowledge. Efficient organization of this knowledge in user memory is essential for enabling personalized applications. However, current research on memory writing, management, and reading using large language models (LLMs) faces challenges in filtering irrelevant information and in dealing with rising computational costs. Inspired by the concept of selective attention in the human brain, we introduce a memory discrimination task. To address large-scale interactions and diverse memory standards in this task, we propose a Scene-Aware Memory Discrimination method (SAMD), which comprises two key components: the Gating Unit Module (GUM) and the Cluster Prompting Module (CPM). GUM enhances processing efficiency by filtering out non-memorable interactions and focusing on the salient content most relevant to application demands. CPM establishes adaptive memory standards, guiding LLMs to discern what information should be remembered or discarded. It also analyzes the relationship between user intents and memory contexts to build effective clustering prompts. Comprehensive direct and indirect evaluations demonstrate the effectiveness and generalization of our approach. We independently assess the performance of memory discrimination, showing that SAMD successfully recalls the majority of memorable data and remains robust in dynamic scenarios. Furthermore, when integrated into personalized applications, SAMD significantly enhances both the efficiency and quality of memory construction, leading to better organization of personal knowledge.

</details>


### [43] [PACE: Prefix-Protected and Difficulty-Aware Compression for Efficient Reasoning](https://arxiv.org/abs/2602.11639)
*Ruixiang Feng,Yuntao Wen,Silin Zhou,Ke Shi,Yifan Wang,Ran Le,Zhenwei An,Zongchao Chen,Chen Yang,Guangyue Peng,Yiming Jia,Dongsheng Wang,Tao Zhang,Lisi Chen,Yang Song,Shen Gao,Shuo Shang*

Main category: cs.CL

TL;DR: 提出了一种双层次框架，通过前缀保护和难度感知的压缩方法解决语言推理模型中的"过度思考"问题，在减少推理令牌使用的同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 语言推理模型（LRMs）通过扩展测试时计算获得强大性能，但常常遭受"过度思考"问题，产生过长的推理轨迹，增加了延迟和内存使用。现有方法使用统一的长度惩罚来强制简洁性，但这在序列级别过度压缩了关键的早期推理步骤，在组级别不加区分地惩罚所有查询。

Method: 提出了一个双层次框架：1）序列级别：前缀保护优化使用衰减混合rollouts来保持有效推理路径同时促进简洁性；2）组级别：难度感知惩罚根据查询复杂度动态调整长度约束，对更难问题保持探索，对更简单问题抑制冗余。

Result: 在DeepSeek-R1-Distill-Qwen（1.5B/7B）上的实验表明，该方法在数学基准测试中实现了令牌使用量的大幅减少（高达55.7%），同时准确性提高了高达4.1%，并具有向代码、科学和通用领域的泛化能力。

Conclusion: 该双层次框架有效解决了语言推理模型的"过度思考"问题，通过前缀保护和难度感知的压缩方法，在减少计算资源的同时提升了模型性能，展示了在多个领域的良好泛化能力。

Abstract: Language Reasoning Models (LRMs) achieve strong performance by scaling test-time computation but often suffer from ``overthinking'', producing excessively long reasoning traces that increase latency and memory usage. Existing LRMs typically enforce conciseness with uniform length penalties, which over-compress crucial early deduction steps at the sequence level and indiscriminately penalize all queries at the group level. To solve these limitations, we propose \textbf{\model}, a dual-level framework for prefix-protected and difficulty-aware compression under hierarchical supervision. At the sequence level, prefix-protected optimization employs decaying mixed rollouts to maintain valid reasoning paths while promoting conciseness. At the group level, difficulty-aware penalty dynamically scales length constraints based on query complexity, maintaining exploration for harder questions while curbing redundancy on easier ones. Extensive experiments on DeepSeek-R1-Distill-Qwen (1.5B/7B) demonstrate that \model achieves a substantial reduction in token usage (up to \textbf{55.7\%}) while simultaneously improving accuracy (up to \textbf{4.1\%}) on math benchmarks, with generalization ability to code, science, and general domains.

</details>


### [44] [Which Feedback Works for Whom? Differential Effects of LLM-Generated Feedback Elements Across Learner Profiles](https://arxiv.org/abs/2602.11650)
*Momoka Furuhashi,Kouta Nakayama,Noboru Kawai,Takashi Kodama,Saku Sugawara,Kyosuke Takami*

Main category: cs.CL

TL;DR: 研究探讨LLM生成反馈中具体元素（如语气、信息覆盖）对学习效果和学习者接受度的影响，特别关注不同人格特质学习者的差异。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在教育反馈生成方面有潜力，但具体反馈元素如何影响学习成果和学习者接受度尚不清楚，特别是对于不同人格特质的学习者。

Method: 定义了六个反馈元素，使用GPT-5为生物选择题生成反馈，对321名高一学生进行学习实验，评估反馈效果（两个学习成果指标和六个主观评价标准），并分析基于大五人格特质的反馈接受度差异。

Result: 有效的反馈元素对学习成果有共同的支持模式，但学习者的主观偏好因人格特质聚类而异。

Conclusion: 设计LLM生成反馈时，应根据学习者人格特质选择和调整反馈元素，为个性化教育反馈设计提供实践启示。

Abstract: Large language models (LLMs) show promise for automatically generating feedback in education settings. However, it remains unclear how specific feedback elements, such as tone and information coverage, contribute to learning outcomes and learner acceptance, particularly across learners with different personality traits. In this study, we define six feedback elements and generate feedback for multiple-choice biology questions using GPT-5. We conduct a learning experiment with 321 first-year high school students and evaluate feedback effectiveness using two learning outcomes measures and subjective evaluations across six criteria. We further analyze differences in how feedback acceptance varies across learners based on Big Five personality traits. Our results show that effective feedback elements share common patterns supporting learning outcomes, while learners' subjective preferences differ across personality-based clusters. These findings highlight the importance of selecting and adapting feedback elements according to learners' personality traits when we design LLM-generated feedback, and provide practical implications for personalized feedback design in education.

</details>


### [45] [PatientHub: A Unified Framework for Patient Simulation](https://arxiv.org/abs/2602.11684)
*Sahand Sabour,TszYam NG,Minlie Huang*

Main category: cs.CL

TL;DR: PatientHub是一个统一的模块化框架，用于标准化模拟病人的定义、组合和部署，解决了现有方法碎片化、不可复现的问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在角色扮演应用中的普及，模拟病人已成为培训咨询师和扩展治疗评估的重要工具。然而，现有方法存在碎片化问题：依赖不兼容、非标准化的数据格式、提示和评估指标，阻碍了复现性和公平比较。

Method: 提出PatientHub框架，通过标准化模拟病人的定义、组合和部署流程，实现模块化设计。框架支持将现有模拟方法实现为案例研究，并允许无缝集成自定义评估指标。

Result: 成功实现了多种代表性病人模拟方法作为案例研究，展示了框架支持标准化跨方法评估的能力。通过原型化两种新的模拟器变体，证明了框架的可扩展性，能够加速方法开发。

Conclusion: PatientHub通过将现有工作整合到单一可复现的流程中，降低了开发新模拟方法的门槛，促进了跨方法和跨模型的基准测试。该框架为未来以病人为中心的对话数据集、方法和基准提供了实用基础。

Abstract: As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.

</details>


### [46] [Finding Sense in Nonsense with Generated Contexts: Perspectives from Humans and Language Models](https://arxiv.org/abs/2602.11699)
*Katrin Olsen,Sebastian Padó*

Main category: cs.CL

TL;DR: 论文研究LLM区分语义异常与无意义句子的能力，发现现有数据集大多只是异常而非真正无意义，且LLM能为异常句子生成合理上下文


<details>
  <summary>Details</summary>
Motivation: 现有语义异常数据集在区分"异常但可解释"与"真正无意义"方面存在不足，且不清楚LLM能否有效区分这两种情况。需要评估现有数据集的"无意义"程度以及LLM的区分能力。

Method: 收集人类评分者和LLM对五个语义异常数据集中句子的可理解性判断，包括无上下文和有上下文两种情况。分析人类对句子是"异常"还是"无意义"的评分，并评估LLM为异常句子生成合理上下文的能力。

Result: 人类评分者认为大多数句子只是异常而非真正无意义；LLM在生成异常句子的合理上下文方面表现出相当强的能力。

Conclusion: 现有语义异常数据集主要包含异常而非真正无意义的句子，LLM能够有效区分这两种情况并为异常句子生成合理解释，这对语义理解模型的评估具有重要意义。

Abstract: Nonsensical and anomalous sentences have been instrumental in the development of computational models of semantic interpretation. A core challenge is to distinguish between what is merely anomalous (but can be interpreted given a supporting context) and what is truly nonsensical. However, it is unclear (a) how nonsensical, rather than merely anomalous, existing datasets are; and (b) how well LLMs can make this distinction. In this paper, we answer both questions by collecting sensicality judgments from human raters and LLMs on sentences from five semantically deviant datasets: both context-free and when providing a context. We find that raters consider most sentences at most anomalous, and only a few as properly nonsensical. We also show that LLMs are substantially skilled in generating plausible contexts for anomalous cases.

</details>


### [47] [Thinking with Drafting: Optical Decompression via Logical Reconstruction](https://arxiv.org/abs/2602.11731)
*Jingxuan Wei,Honghao He,Caijun Jia,Siyuan Li,Zheng Sun,Yuhang Xu,Yuanyuan Lin,Linzhuang Sun,Yuchen Wu,Bihui Yu,Xiangxiang Zhang,Cheng Tan*

Main category: cs.CL

TL;DR: 提出Thinking with Drafting (TwD)方法，通过领域特定语言作为中间表示，将视觉推理重构为光学解压缩过程，实现逻辑结构的精确重建和自验证。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在复杂推理任务中存在精度悖论：视觉感知系统转录符号但不捕获逻辑拓扑，像素生成模型产生缺乏数学精确性的视觉伪影。需要弥合这一差距。

Method: 提出Thinking with Drafting (TwD)方法，基于"解析即推理"公理，使用极简领域特定语言(DSL)作为基础中间表示，强制模型将其心智模型草拟为可执行代码，生成确定性视觉证明进行自验证。

Result: 实验表明TwD作为优越的认知支架，在VisAlg视觉代数基准上表现优异，建立了视觉生成作为逻辑验证器的闭环系统。

Conclusion: TwD将视觉推理重新概念化为光学解压缩，为视觉推理提供了可泛化的路径，其中视觉生成不是创造性输出而是逻辑验证器。

Abstract: Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.

</details>


### [48] [Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning](https://arxiv.org/abs/2602.11748)
*Futing Wang,Jianhao Yan,Yun Luo,Ganqu Cui,Zhi Wang,Xiaoye Qu,Yue Zhang,Yu Cheng,Tao Lin*

Main category: cs.CL

TL;DR: 论文提出Length-Incentivized Exploration方法，通过长度奖励和冗余惩罚激励模型进行上下文探索，解决自回归生成中"浅层探索陷阱"问题，在多种任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有模型在测试时扩展中存在"浅层探索陷阱"问题：虽然更广泛的状态覆盖需要更长的推理轨迹，但在自回归生成中采样长序列的概率呈指数衰减，限制了模型生成、验证和优化多个推理假设的能力。

Method: 提出Length-Incentivized Exploration方法，采用两阶段策略：1) 通过长度奖励明确鼓励模型进行更长的探索；2) 结合冗余惩罚避免重复探索，最大化状态覆盖。

Result: 在Qwen3、Llama等不同模型上的综合实验表明，该方法有效激励了上下文探索能力，在领域内任务上平均提升4.4%，在领域外基准测试上获得2.7%的增益。

Conclusion: 通过简单的长度激励和冗余惩罚机制，成功解决了自回归生成中的探索瓶颈，显著提升了模型在上下文探索和推理能力方面的表现。

Abstract: Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.
  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.
  To bridge this gap, we propose Length-Incentivized Exploration(\method).
  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.
  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \method effectively incentivize in-context exploration.
  As a result, our method achieves an average improvement of 4.4\% on in-domain tasks and a 2.7\% gain on out-of-domain benchmarks.

</details>


### [49] [MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling](https://arxiv.org/abs/2602.11761)
*MiniCPM Team,Wenhao An,Yingfa Chen,Yewei Fang,Jiayi Li,Xin Li,Yaohui Li,Yishan Li,Yuxuan Li,Biyuan Lin,Chuan Liu,Hezi Liu,Siyuan Liu,Hongya Lyu,Yinxu Pan,Shixin Ren,Xingyu Shen,Zhou Su,Haojun Sun,Yangang Sun,Zhen Leng Thai,Xin Tian,Rui Wang,Xiaorong Wang,Yudong Wang,Bo Wu,Xiaoyue Xu,Dong Xu,Shuaikang Xue,Jiawei Yang,Bowen Zhang,Jinqian Zhang,Letian Zhang,Shengnan Zhang,Xinyu Zhang,Xinyuan Zhang,Zhu Zhang,Hengyu Zhao,Jiacheng Zhao,Jie Zhou,Zihan Zhou,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: MiniCPM-SALA是一个9B参数的混合注意力架构，结合稀疏注意力和线性注意力，在保持模型性能的同时显著提升长上下文处理效率，支持高达100万token的上下文长度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理超长上下文时面临Transformer架构的高计算和内存成本挑战，现有稀疏和线性注意力机制通常在内存效率和模型性能之间存在权衡。

Method: 提出9B参数的混合架构MiniCPM-SALA，集成InfLLM-V2稀疏注意力的高保真长上下文建模和Lightning Attention线性注意力的全局效率，采用1:3比例的层选择算法和混合位置编码(HyPE)，并设计了成本效益高的持续训练框架。

Result: 在单个NVIDIA A6000D GPU上，模型在256K token序列长度下推理速度比全注意力模型快3.5倍，支持高达100万token的上下文长度，同时保持与全注意力模型相当的一般能力，训练成本比从头训练降低约75%。

Conclusion: MiniCPM-SALA通过混合注意力架构有效解决了长上下文处理中的效率与性能权衡问题，为超长上下文应用提供了实用且高效的解决方案。

Abstract: The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.

</details>


### [50] [A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments](https://arxiv.org/abs/2602.11795)
*Anne-Marie Lutgen,Alistair Plum,Christoph Purschke*

Main category: cs.CL

TL;DR: 提出一种基于嵌入的方法，无需依赖先验规范化或预定义变体列表即可检测语言变异，通过训练子词嵌入并组合余弦和n-gram相似度来分组相关形式。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要先验规范化或预定义变体列表来处理语言变异，这限制了在"嘈杂"或低资源环境下的应用。需要一种能够将拼写和形态多样性作为语言结构而非噪声来分析的自动化方法。

Method: 在原始文本上训练子词嵌入，通过组合余弦相似度和n-gram相似度来分组相关的语言形式，形成变体家族。该方法无需严格的手动标注，产生透明的聚类结果。

Result: 在卢森堡语用户评论的大规模语料库中，该方法发现了大量与方言和社会语言学研究描述模式一致的词汇和正字法变异。诱导出的变体家族捕捉了系统性对应关系，并突出了区域和风格差异。

Conclusion: 分布建模即使在"嘈杂"或低资源环境中也能揭示有意义的变异模式，为研究多语言和小语言环境中的语言多样性提供了可复现的方法论框架。

Abstract: This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.

</details>


### [51] [DMAP: A Distribution Map for Text](https://arxiv.org/abs/2602.11871)
*Tom Kempton,Julia Rozanova,Parameswaran Kamalaruban,Maeve Madigan,Karolina Wresilo,Yoann L. Launay,David Sutton,Stuart Burrell*

Main category: cs.CL

TL;DR: DMAP是一种将文本通过语言模型映射到单位区间样本的数学方法，结合了排名和概率信息，支持模型无关的文本分析


<details>
  <summary>Details</summary>
Motivation: 现有基于困惑度等指标的方法无法充分考虑上下文信息，需要一种能更好解释下一个词概率的方法，考虑条件分布形状所编码的合理选择数量

Method: 提出DMAP方法，将文本通过语言模型映射到单位区间的一组样本，这些样本共同编码排名和概率信息，提供统一的统计视图

Result: 通过三个案例研究验证DMAP的实用性：1)生成参数验证确保数据完整性；2)概率曲率在机器生成文本检测中的作用；3)揭示下游模型在合成数据后训练中留下的统计指纹

Conclusion: DMAP提供了一种简单、广泛适用且统一的文本统计分析方法，可在消费级硬件上计算，为基于LLM的文本分析研究奠定基础

Abstract: Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.

</details>


### [52] [Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems](https://arxiv.org/abs/2602.11877)
*Wanxing Wu,He Zhu,Yixia Li,Lei Yang,Jiehui Zhao,Hongru Wang,Jian Yang,Benyou Wang,Bingyi Jing,Guanhua Chen*

Main category: cs.CL

TL;DR: 提出了RouterXBench评估框架和ProbeDirichlet路由方法，用于在本地小模型和云端大模型之间智能路由查询，相比现有方法在路由能力和跨域鲁棒性上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然成功，但成本和隐私限制需要本地部署小模型，同时将复杂查询卸载到云端模型。现有路由评估方法不系统，忽略了场景特定需求和分布外鲁棒性。

Method: 提出RouterXBench评估框架（三个维度：路由能力、场景对齐、跨域鲁棒性），并设计ProbeDirichlet路由方法，利用内部隐藏状态捕捉模型不确定性，通过可学习的狄利克雷分布聚合跨层隐藏状态进行概率训练。

Result: ProbeDirichlet在路由能力和高精度场景中分别比最佳基线相对提升16.68%和18.86%，在不同模型家族、模型规模、异构任务和代理工作流中表现一致。

Conclusion: RouterXBench提供了系统化的路由评估框架，ProbeDirichlet方法通过利用内部隐藏状态和概率训练，在路由决策的准确性和鲁棒性方面显著优于现有方法。

Abstract: Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.

</details>


### [53] [LLM-based Triplet Extraction from Financial Reports](https://arxiv.org/abs/2602.11886)
*Dante Wesslund,Ville Stenström,Pontus Linde,Alexander Holmberg*

Main category: cs.CL

TL;DR: 提出一个半自动化的三元组抽取流程，使用本体驱动的代理指标（本体一致性和忠实度）替代基于真实标注的评估，解决企业财务报告领域缺乏标注数据的问题。


<details>
  <summary>Details</summary>
Motivation: 企业财务报告是构建知识图谱的宝贵结构化知识来源，但该领域缺乏标注的真实数据，使得评估变得困难。需要开发不依赖真实标注的评估方法。

Method: 1) 提出半自动化的主谓宾三元组抽取流程；2) 使用本体一致性和忠实度作为代理评估指标；3) 比较静态手动构建的本体与全自动文档特定本体归纳方法；4) 提出结合正则匹配和LLM作为评判者的混合验证策略；5) 分析主宾语幻觉的系统性不对称性。

Result: 1) 自动归纳的本体在所有配置中达到100%模式一致性，消除了手动方法中的本体漂移；2) 混合验证策略将明显的主语幻觉率从65.2%降至1.6%；3) 识别出主语和宾语幻觉的系统性不对称性，归因于财务文本中的被动结构和省略施事者。

Conclusion: 提出的本体驱动评估方法和混合验证策略有效解决了企业财务报告知识图谱构建中的评估挑战，自动本体归纳优于手动方法，混合验证显著减少幻觉，为缺乏标注数据的领域提供了可行的解决方案。

Abstract: Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.

</details>


### [54] [Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences](https://arxiv.org/abs/2602.11898)
*Eddie Yang,Dashun Wang*

Main category: cs.CL

TL;DR: 研究发现LLM在基准测试中看似收敛的准确率实际上隐藏着深刻的认知分歧，模型选择成为影响科学研究可重复性的隐藏变量


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要依赖基准测试准确率，但作者发现即使准确率相近的模型在具体问题上仍存在显著分歧，这可能影响使用LLM进行科学研究的可靠性

Method: 使用MMLU-Pro和GPQA两个主要推理基准，分析不同LLM的答案一致性；重新分析已发表的教育学和政治科学研究，考察更换标注模型对结果的影响

Result: 准确率相近的LLM在16-66%的项目上存在分歧，前沿模型间也有16-38%的分歧；在教育学和政治科学研究中，更换标注模型可使估计处理效应变化超过80%，有时甚至改变效应方向

Conclusion: 基准测试存在"基准幻觉"问题，相等的准确率可能掩盖模型间的深层分歧，模型选择成为科学研究可重复性的隐藏但关键变量

Abstract: Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.

</details>


### [55] [AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection](https://arxiv.org/abs/2602.11931)
*Pretam Ray,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: AdaptEvolve：一种基于生成置信度的自适应LLM选择方法，在进化式顺序精炼框架中动态选择LLM，平衡计算效率与推理能力，平均减少37.9%推理成本同时保持97.5%的静态大模型基线准确率。


<details>
  <summary>Details</summary>
Motivation: 进化式智能体系统在推理过程中反复调用大语言模型，加剧了计算效率与推理能力之间的权衡。现有路由策略通常依赖静态启发式或外部控制器，未明确考虑模型不确定性，需要一种能动态选择足够能力LLM同时保持计算效率的方法。

Method: 提出AdaptEvolve方法，在进化式顺序精炼框架中，利用内在生成置信度来估计实时可解性，实现基于置信度的自适应LLM选择。该方法通过模型级联机制平衡计算效率与推理能力的权衡。

Result: 实验结果表明，置信度驱动的选择产生了有利的帕累托前沿，在基准测试中平均减少37.9%的总推理成本，同时保留了静态大模型基线97.5%的上界准确率。

Conclusion: AdaptEvolve通过基于生成置信度的自适应LLM选择，有效解决了进化式智能体系统中计算效率与推理能力的权衡问题，为多LLM进化精炼提供了实用的解决方案。

Abstract: Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.

</details>


### [56] [Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text](https://arxiv.org/abs/2602.11933)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 提出跨模态鲁棒性迁移(CMRT)框架，将文本模态的对抗鲁棒性转移到语音模态，无需对抗语音数据训练即可提升端到端语音翻译的形态学鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端语音翻译模型主要在"干净"数据集上评估，忽略了真实世界的形态学变化挑战（如非母语或方言语音的屈折变化）。现有对抗训练方法需要生成高质量对抗语音数据，计算昂贵且技术挑战大。

Method: 提出跨模态鲁棒性迁移(CMRT)框架，将文本领域的对抗攻击适应到语音领域，通过从文本模态转移对抗鲁棒性到语音模态，无需对抗语音数据训练。

Result: 在四个语言对上的实验表明，CMRT平均提升对抗鲁棒性超过3个BLEU点，为无需生成对抗语音数据的鲁棒端到端语音翻译建立了新基准。

Conclusion: CMRT框架有效解决了端到端语音翻译的形态学鲁棒性问题，无需昂贵的对抗语音数据生成，为现实世界语音翻译应用提供了更实用的鲁棒性解决方案。

Abstract: End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, "clean" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.

</details>


### [57] [Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance](https://arxiv.org/abs/2602.11938)
*Yunchong Huang,Gianni Barlacchi,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 研究发现QA基准测试中大量问题存在"未充分指定"问题，导致LLMs表现不佳，而非模型本身能力不足


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在定义明确的问题上表现良好，但标准QA基准测试仍未完全解决。作者认为这种差距部分是由于"未充分指定问题"造成的——即没有额外上下文就无法唯一确定其解释的查询

Method: 1) 引入基于LLM的分类器来识别未充分指定问题；2) 将该分类器应用于多个广泛使用的QA数据集；3) 进行受控重写实验，将未充分指定问题重写为完全指定变体，同时保持正确答案不变

Result: 发现16%到超过50%的基准测试问题是未充分指定的，LLMs在这些问题上表现显著更差。在受控重写实验中，QA性能持续改善，表明许多明显的QA失败源于问题未充分指定而非模型限制

Conclusion: 未充分指定是QA评估中的重要混淆因素，需要在基准设计中对问题清晰度给予更多关注

Abstract: Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.

</details>


### [58] [Do Large Language Models Adapt to Language Variation across Socioeconomic Status?](https://arxiv.org/abs/2602.11939)
*Elisa Bassignana,Mike Zhang,Dirk Hovy,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: LLMs在适应不同社会经济地位群体的语言风格方面表现有限，主要模仿上层SES风格，可能加剧语言不平等


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能够适应不同社会背景的语言风格，因为如果模型无法适应多样化的语言规范，可能会强化刻板印象、边缘化某些社区，并加剧社会分层

Method: 从Reddit和YouTube收集按社会经济地位分层的语料库，使用四个LLMs对不完整文本进行补全，然后将LLM生成的补全与原始文本在94个社会语言学指标上进行比较

Result: LLMs仅在一定程度上根据SES调整其风格，常常导致近似或夸张模仿，并且更倾向于模仿上层SES的语言风格

Conclusion: LLMs可能加剧语言层级分化，对其在基于代理的社会模拟、调查实验以及依赖语言风格作为社会信号的研究中的有效性提出质疑

Abstract: Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.

</details>


### [59] [Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models](https://arxiv.org/abs/2602.11961)
*Yuzhe Shang,Pengzhi Gao,Wei Liu,Jian Luan,Jinsong Su*

Main category: cs.CL

TL;DR: 基于Gemma3开发的多语言翻译模型MiLMMT-46，在46种语言上达到顶尖性能，超越多个SOTA开源模型，与Google Translate等商业系统竞争


<details>
  <summary>Details</summary>
Motivation: 近年来开源大语言模型在多语言能力上不断提升，但需要系统研究如何通过模型缩放和数据缩放来优化多语言机器翻译性能

Method: 基于Gemma3模型家族，通过持续预训练和指令微调来适应多语言机器翻译任务，研究模型缩放和数据缩放的影响

Result: MiLMMT-46在46种语言上取得顶尖翻译性能，超越Seed-X、HY-MT-1.5、TranslateGemma等SOTA模型，与Google Translate和Gemini 3 Pro等商业系统表现相当

Conclusion: 通过适当的模型缩放和数据缩放策略，开源LLM可以在多语言机器翻译任务上达到与商业系统竞争的性能水平

Abstract: Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.

</details>


### [60] [DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling](https://arxiv.org/abs/2602.11968)
*Mariia Fedorova,Andrey Kutuzov,Khonzoda Umarova*

Main category: cs.CL

TL;DR: DHPLT是一个包含41种语言的历时语料库开放集合，基于HPLT网络爬取数据，利用时间戳划分三个时期（2011-2015、2020-2021、2024至今），提供预计算的词嵌入和词汇替换，填补多语言历时语义变化建模的资源空白。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏多语言的历时语料库用于语义变化建模，现有资源主要集中在少数高资源语言上。DHPLT旨在填补这一空白，为研究多语言语义变化提供基础数据支持。

Method: 基于HPLT网络爬取数据集，利用网页爬取时间戳作为文档创建时间的近似信号。将数据划分为三个时间时期：2011-2015、2020-2021和2024至今，每个语言每个时期包含100万文档。提供预计算的词类型和词符嵌入以及目标词的词汇替换。

Result: 创建了包含41种不同语言的历时语料库集合，覆盖三个时间时期，每个语言每个时期包含100万文档。提供了预计算的词嵌入和词汇替换数据，所有资源已在https://data.hplt-project.org/three/diachronic/开放获取。

Conclusion: DHPLT填补了多语言历时语义变化建模的资源空白，为研究者提供了新的实验设置可能性，促进了多语言历时语言学的研究发展。

Abstract: In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.

</details>


### [61] [Automatic Simplification of Common Vulnerabilities and Exposures Descriptions](https://arxiv.org/abs/2602.11982)
*Varpu Vehomäki,Kimmo K. Kaski*

Main category: cs.CL

TL;DR: 研究探索利用大语言模型自动简化网络安全漏洞描述，发现现成LLM能让文本看起来更简单，但难以保持原意准确性。


<details>
  <summary>Details</summary>
Motivation: 网络安全信息对非专业人士难以理解，自动文本简化在医疗、科学等领域已有研究，但在快速变化且复杂的网络安全领域尚未探索。研究旨在评估LLM在简化CVE描述方面的潜力。

Method: 创建网络安全自动文本简化基线，构建包含40个CVE描述的测试数据集，通过两轮网络安全专家调查进行评估，分析现成大语言模型的简化效果。

Result: 现成大语言模型能让文本看起来更简单，但在保持原意方面存在困难，简化过程中容易丢失或改变关键的技术细节和准确含义。

Conclusion: 虽然LLM在网络安全文本简化方面有潜力，但需要专门优化以确保意义保留，特别是在技术准确性要求高的领域。研究为网络安全自动文本简化建立了基准。

Abstract: Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\_nmi.

</details>


### [62] [LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss](https://arxiv.org/abs/2602.12005)
*Szilvia Ujváry,Louis Béthune,Pierre Ablin,João Monteiro,Marco Cuturi,Michael Kirchhof*

Main category: cs.CL

TL;DR: 提出LaCy方法，通过语法解析器辅助小语言模型在预训练时选择哪些token应该学习预测，哪些应该委托给大模型，以提高事实准确性。


<details>
  <summary>Details</summary>
Motivation: 小语言模型参数容量有限，容易产生事实错误。虽然可以通过访问外部资源（如大模型、文档、数据库）来缓解，但需要决定哪些token应该学习预测，哪些应该委托。

Method: 提出LaCy方法：使用spaCy语法解析器增强损失信号，判断哪些token应该委托（防止事实错误），哪些即使损失高也可以安全学习预测。基于此token选择哲学进行预训练。

Result: LaCy模型成功学会了哪些token应该预测，哪些应该委托。在与大模型级联生成时获得更高的FactScore，优于Rho或LLM-judge训练的SLM，同时更简单便宜。

Conclusion: 通过语法解析器辅助token选择，小语言模型可以更智能地决定何时委托给外部资源，提高事实准确性，同时保持简单和经济性。

Abstract: Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \emph{which tokens an SLM can and should learn} during pretraining, versus \emph{which ones it should delegate} via a \texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.

</details>


### [63] [Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study](https://arxiv.org/abs/2602.12015)
*Angelo Ziletti,Leonardo D'Ambrosi*

Main category: cs.CL

TL;DR: CLUES框架将临床Text-to-SQL中的输出多样性分解为输入歧义性和模型不稳定性，通过二分语义图矩阵的Schur补计算不稳定性分数，实现错误预测和针对性干预。


<details>
  <summary>Details</summary>
Motivation: 在临床Text-to-SQL部署中，需要区分输出多样性的两种不同原因：应触发澄清的输入歧义性和应触发人工审查的模型不稳定性，但现有方法无法提供这种诊断性分解。

Method: 提出CLUES框架，将Text-to-SQL建模为两阶段过程（解释→答案），通过二分语义图矩阵的Schur补计算不稳定性分数，将语义不确定性分解为歧义性分数和不稳定性分数。

Result: 在AmbigQA/SituatedQA（黄金解释）和临床Text-to-SQL基准测试（已知解释）中，CLUES在失败预测上优于最先进的核语言熵方法，高歧义/高不稳定性区域覆盖51%的错误但仅占25%的查询。

Conclusion: CLUES框架能有效分解语义不确定性，为临床Text-to-SQL部署提供诊断性分解，将不确定性机制映射到针对性干预措施（歧义性→查询细化，不稳定性→模型改进），实现高效分流。

Abstract: Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.

</details>


### [64] [Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models](https://arxiv.org/abs/2602.12036)
*Xin Xu,Clive Bai,Kai Yang,Tianhao Chen,Yangkun Chen,Weijie Liu,Hao Chen,Yang Wang,Saiyong Yang,Can Yang*

Main category: cs.CL

TL;DR: 提出Composition-RL方法，通过自动组合多个问题生成新的可验证提示，解决RLVR训练中pass-rate-1提示过多导致有效数据减少的问题。


<details>
  <summary>Details</summary>
Motivation: 大规模可验证提示对RLVR成功至关重要，但包含大量无信息示例且扩展成本高。现有方法关注利用pass-rate-0的困难提示，但随着训练进行，pass-rate-1的简单提示越来越多，减少了有效数据规模。

Method: 提出Composition-RL方法，自动组合多个问题生成新的可验证问题，将这些组合提示用于RL训练。还提出课程学习变体，逐步增加组合深度。

Result: 在4B到30B不同规模模型上的实验表明，Composition-RL相比原始数据集训练的RL持续提升推理能力。课程变体可进一步提升性能，且能通过组合不同领域提示实现更有效的跨领域RL。

Conclusion: Composition-RL能更好地利用有限的可验证提示资源，特别是针对pass-rate-1提示，提升RLVR训练效果，为跨领域RL提供新途径。

Abstract: Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.

</details>


### [65] [DeepSight: An All-in-One LM Safety Toolkit](https://arxiv.org/abs/2602.12092)
*Bo Zhang,Jiaxuan Guo,Lijun Li,Dongrui Liu,Sujin Chen,Guanxu Chen,Zhijie Zheng,Qihao Lin,Lewen Yan,Chen Qian,Yijin Zhou,Yuyao Wu,Shaoxiong Guo,Tianyi Du,Jingyi Yang,Xuhao Hu,Ziqi Miao,Xiaoya Lu,Jing Shao,Xia Hu*

Main category: cs.CL

TL;DR: DeepSight是一个开源项目，提出安全评估-诊断集成新范式，包含DeepSafe评估工具包和DeepScan诊断工具包，将安全评估从黑盒转为白盒洞察。


<details>
  <summary>Details</summary>
Motivation: 当前大模型安全工作中，评估、诊断和对齐通常由独立工具处理，存在以下问题：安全评估只能定位外部行为风险而无法发现内部根源；安全诊断往往脱离具体风险场景停留在可解释层面；安全对齐缺乏内部机制变化的专门解释，可能降低通用能力。

Method: 提出DeepSight开源项目，采用安全评估-诊断集成范式，包含DeepSafe评估工具包和DeepScan诊断工具包。通过统一任务和数据协议，在两个阶段之间建立连接，将安全评估从黑盒转为白盒洞察。

Result: DeepSight是第一个支持前沿AI风险评估以及联合安全评估和诊断的开源工具包，具有低成本、可复现、高效和高可扩展性等特点。

Conclusion: DeepSight通过集成评估和诊断，系统性地解决了当前大模型安全工作中的分离问题，实现了从行为风险到内部机制根源的全面安全分析。

Abstract: As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.

</details>


### [66] [P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling](https://arxiv.org/abs/2602.12116)
*Pinyi Zhang,Ting-En Lin,Yuchuan Wu,Jingyang Chen,Zongqi Wang,Hua Yang,Ze Xu,Fei Huang,Kai Zhang,Yongbin Li*

Main category: cs.CL

TL;DR: P-GenRM：首个具有测试时用户扩展能力的个性化生成奖励模型，通过结构化评估链和用户原型聚类解决个性化对齐中的偏好建模问题。


<details>
  <summary>Details</summary>
Motivation: 现有个性化奖励模型存在两个主要局限：1) 将多样化的场景特定偏好过度简化为少量固定评估原则；2) 对反馈有限的新用户泛化能力不足。需要更灵活、可泛化的个性化奖励建模方法。

Method: 提出P-GenRM模型，将偏好信号转化为结构化评估链，推导自适应角色和评分标准。通过用户原型聚类和双重粒度扩展机制：个体层面自适应扩展聚合用户评分方案；原型层面整合相似用户偏好，通过原型迁移增强泛化能力。

Result: 在广泛使用的个性化奖励模型基准上达到SOTA，平均提升2.31%；在分布外数据集上表现出强泛化能力；测试时用户扩展机制额外提供3%的性能提升，展示了更好的个性化对齐和测试时扩展性。

Conclusion: P-GenRM通过结构化评估链和用户原型聚类有效解决了个性化奖励建模中的偏好简化和泛化问题，测试时用户扩展机制进一步提升了模型的个性化对齐能力。

Abstract: Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.

</details>


### [67] [A Rule-based Computational Model for Gaidhlig Morphology](https://arxiv.org/abs/2602.12132)
*Peter J Barclay*

Main category: cs.CL

TL;DR: 利用Wiktionary数据构建盖尔语形态学的基于规则模型，以解决低资源语言数据不足问题，支持可解释性和教学材料设计。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如盖尔语）因训练数据不足而难以应用当前流行的神经模型的问题，探索如何有效利用有限样本数据支持语言活力。

Method: 从Wiktionary提取数据，构建基于规则的形态学模型；使用SQL查询不同词汇模式的出现情况；创建声明式规则库，通过Python工具推导盖尔语单词的屈折形式。

Result: 开发了基于规则的盖尔语形态学系统，能够有效利用有限数据，支持可解释性，并为教学材料设计提供见解；展示了如何将Wiktionary数据适应新用例。

Conclusion: 基于规则的系统能有效利用低资源语言的有限数据，支持可解释性和教学应用，为盖尔语等低资源语言的语言技术工具开发提供了可行路径。

Abstract: Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.

</details>


### [68] [WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models](https://arxiv.org/abs/2602.12135)
*Yangzhuo Li,Shengpeng Ji,Yifu Chen,Tianle Liang,Haorong Ying,Yule Wang,Junbo Li,Jun Fang,Zhou Zhao*

Main category: cs.CL

TL;DR: WavBench是一个全面的口语对话基准测试，通过专业、基础和声学三个子集评估现实对话能力，填补了现有基准在口语特征和认知深度方面的空白。


<details>
  <summary>Details</summary>
Motivation: 当前的口语对话模型评估主要遵循文本生成标准，忽视了口语特有的副语言特征（如语调、节奏）和口语化表达，同时缺乏对现代智能体所需认知深度的评估。需要建立一个能反映真实世界复杂性的基准测试。

Method: 提出了WavBench基准测试，采用三重框架：1) Pro子集：显著增加难度，严格挑战具备推理能力的模型；2) Basic子集：定义口语化新标准，强调"可听性"（自然词汇、语言流畅性、互动融洽度）；3) Acoustic子集：涵盖显性理解、生成和隐性对话，在真实场景中全面评估副语言能力。

Result: 通过对五个最先进模型的评估，WavBench提供了关于复杂问题解决、口语化表达和副语言保真度交叉点的重要见解。基准数据集和评估工具包已公开可用。

Conclusion: WavBench填补了口语对话评估的关键空白，为开发更强大的口语对话模型提供了指导，推动了该领域的发展。

Abstract: With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes "listenability" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.

</details>


### [69] [CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes](https://arxiv.org/abs/2602.12137)
*Ricardo Campos,Ana Filipa Pacheco,Ana Luísa Fernandes,Inês Cantante,Rute Rebouças,Luís Filipe Cunha,José Miguel Isidro,José Pedro Evans,Miguel Marques,Rodrigo Batista,Evelin Amorim,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano*

Main category: cs.CL

TL;DR: 提出CitiLink-Minutes数据集，包含120份欧洲葡萄牙语市政会议记录的多层标注，用于促进市政文档的NLP和IR研究。


<details>
  <summary>Details</summary>
Motivation: 市政会议记录对地方治理至关重要，但缺乏标注数据集限制了NLP和IR研究的发展，需要填补这一空白。

Method: 收集6个城市的120份葡萄牙语市政会议记录，进行去标识化处理，由两名标注员手动标注三个维度（元数据、讨论主题、投票结果），并由语言学家审核。

Result: 创建了包含超过100万词符和38,000个标注的数据集，提供元数据提取、主题分类和投票标注的基线结果，遵循FAIR原则发布。

Conclusion: CitiLink-Minutes数据集为市政会议记录的NLP和IR任务提供了宝贵资源，促进了市政决策的透明访问。

Abstract: City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.

</details>


### [70] [dVoting: Fast Voting for dLLMs](https://arxiv.org/abs/2602.12153)
*Sicheng Feng,Zigeng Chen,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.CL

TL;DR: dVoting是一种用于扩散大语言模型的快速投票技术，通过并行采样和一致性分析识别不确定token，然后通过投票机制迭代优化，显著提升推理能力而无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型(dLLMs)相比自回归模型具有并行解码优势，但推理性能仍有提升空间。研究发现，同一提示的多样本中，大部分token预测一致，性能差异主要由少数不确定token决定，这启发了通过投票机制优化这些关键token的想法。

Method: dVoting利用dLLMs的任意位置生成能力，采用迭代优化流程：1) 并行采样多个输出；2) 通过一致性分析识别不确定token；3) 对这些token进行投票再生；4) 重复此过程直至收敛。整个过程无需额外训练，计算开销可控。

Result: 在多个基准测试中取得显著提升：GSM8K提升6.22%-7.66%，MATH500提升4.40%-7.20%，ARC-C提升3.16%-14.84%，MMLU提升4.83%-5.74%。证明dVoting能有效提升dLLMs的推理能力。

Conclusion: dVoting是一种简单有效的推理增强技术，充分利用了扩散大语言模型的并行生成优势，通过投票机制迭代优化不确定token，显著提升性能而无需额外训练成本，为dLLMs的实际应用提供了有力工具。

Abstract: Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting

</details>


### [71] [Query-focused and Memory-aware Reranker for Long Context Processing](https://arxiv.org/abs/2602.12192)
*Yuqing Li,Jiangnan Li,Mo Yu,Guoxuan Ding,Zheng Lin,Weiping Wang,Jie Zhou*

Main category: cs.CL

TL;DR: 提出基于注意力分数的重排序框架，利用大语言模型中特定注意力头的分数来估计文档-查询相关性，实现轻量级且有效的列表式重排序。


<details>
  <summary>Details</summary>
Motivation: 现有检索头分析基础上，寻求更有效的重排序方法，能够利用候选文档列表的整体信息进行排序，同时避免对Likert尺度监督的依赖。

Method: 训练模型使用选定注意力头的注意力分数来估计文档-查询相关性，采用列表式方法利用整个候选短列表信息，生成连续相关性分数。

Result: 方法在多个领域（包括维基百科和长篇叙事数据集）超越现有最先进的点式和列表式重排序器，在LoCoMo基准测试中建立新的SOTA，支持灵活扩展。

Conclusion: 提出的基于注意力分数的重排序框架是轻量级且有效的，仅需小规模模型即可实现强大性能，支持多种扩展方式提升效果和效率。

Abstract: Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.

</details>


### [72] [Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education](https://arxiv.org/abs/2602.12196)
*Mohamed Huti,Alasdair Mackintosh,Amy Waldock,Dominic Andrews,Maxime Lelièvre,Moritz Boos,Tobias Murray,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 本文介绍了视觉推理基准（VRB），这是一个用于评估多模态大语言模型在解决真实课堂视觉问题能力的新数据集，基于701道来自赞比亚和印度小学考试的题目，发现模型在静态技能上表现较好，但在动态空间操作上存在明显局限。


<details>
  <summary>Details</summary>
Motivation: 尽管AI模型在文本推理方面取得了先进成果，但在空间和关系结构推理能力上仍存在关键瓶颈，特别是在依赖视觉的早期数学教育中。需要评估多模态大语言模型能否满足小学教育的实际需求。

Method: 构建了视觉推理基准（VRB）数据集，包含701道来自赞比亚和印度小学考试的真实问题，涵盖类比推理、模式完成、空间匹配等任务。使用未经编辑、文本最少的图像来测试模型能否满足小学教育的实际需求。

Result: 研究发现模型能力存在"锯齿状边界"：在计数和缩放等静态技能上表现较好，但在折叠、反射和旋转等动态操作上达到明显的"空间天花板"。这些弱点可能导致课堂使用中出现错误评分、虚假支架和强化学生误解的风险。

Conclusion: 像VRB这样的教育导向基准对于确定课堂中使用的多模态工具的功能边界至关重要，有助于识别模型在视觉推理问题上的局限性，避免在教育应用中产生负面影响。

Abstract: AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.

</details>


### [73] [ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images](https://arxiv.org/abs/2602.12203)
*Mathieu Sibue,Andres Muñoz Garza,Samuel Mensah,Pranav Shetty,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: ExStrucTiny：一个新的文档图像结构化信息提取基准数据集，统一了关键实体提取、关系提取和视觉问答任务，用于评估视觉语言模型在多样化文档类型和灵活模式下的细粒度结构化提取能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在文档理解基准上表现良好，但在多样化文档类型和灵活模式下的细粒度结构化提取能力尚未得到充分研究。现有的关键实体提取、关系提取和视觉问答数据集存在实体本体狭窄、查询简单或文档类型单一等限制，无法满足实际企业文档处理中需要适应性和结构化提取的需求。

Method: 通过结合手动和合成人工验证样本的新颖流程构建ExStrucTiny基准数据集，该数据集统一了关键实体提取、关系提取和视觉问答任务，覆盖更多样化的文档类型和提取场景。在此基础上分析开放和封闭视觉语言模型在该基准上的表现。

Result: 研究揭示了视觉语言模型在结构化信息提取中面临的挑战，包括模式适应、查询规范不足和答案定位等问题。ExStrucTiny基准为评估和改进通用模型在文档结构化信息提取方面的能力提供了基础。

Conclusion: ExStrucTiny基准填补了现有文档理解评估的空白，为改进通用模型在文档结构化信息提取方面的能力提供了重要基础，有望推动视觉语言模型在企业文档处理应用中的发展。

Abstract: Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.

</details>


### [74] [Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation](https://arxiv.org/abs/2602.12235)
*Julia Belikova,Danila Rozhevskii,Dennis Svirin,Konstantin Polev,Alexander Panchenko*

Main category: cs.CL

TL;DR: 论文研究软压缩架构中token溢出的检测问题，提出结合查询信息的轻量级探测分类器，相比查询无关方法能更有效地识别压缩导致的错误。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在处理长上下文时面临资源限制挑战，软压缩架构通过将长token序列替换为少量压缩token来扩展有效上下文长度。然而压缩极限和何时压缩会消除任务相关内容尚未充分探索。

Method: 定义"token溢出"为压缩表示不再包含足够信息回答查询的情况，提出检测方法。在xRAG软压缩设置中，使用查询无关的饱和统计量分离压缩与未压缩token表示，并开发轻量级探测分类器结合查询和上下文xRAG表示来检测溢出。

Result: 查询无关饱和统计量能可靠分离压缩与未压缩token表示，但溢出检测能力有限。结合查询信息的轻量级探测分类器在HotpotQA、SQuADv2和TriviaQA数据集上平均达到0.72 AUC-ROC，显著优于查询无关方法。

Conclusion: 研究从查询无关诊断发展到查询感知检测器，实现了低成本的预LLM门控机制，能够减轻压缩引起的错误，为软压缩架构的实际应用提供了实用工具。

Abstract: Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.

</details>


### [75] [Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications](https://arxiv.org/abs/2602.12241)
*Manjunath Kudlur,Evan King,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: Moonshine v2 是一种用于流式语音识别的编码器模型，采用滑动窗口自注意力机制，在保持高准确率的同时显著降低延迟，特别适合边缘设备上的实时语音应用。


<details>
  <summary>Details</summary>
Motivation: 实时语音应用（如实时转录、语音命令、实时翻译）需要在资源受限的边缘设备上实现低延迟和高准确率。传统的全注意力Transformer编码器虽然准确率高，但存在二次复杂度问题，导致延迟随语句长度线性增长，不适合流式应用场景。

Method: 引入Moonshine v2模型，采用滑动窗口自注意力机制，将全局依赖限制在局部窗口内，实现有界、低延迟的推理，同时保留强局部上下文信息。

Result: 在标准基准测试中达到最先进的词错误率，准确率与6倍大小的模型相当，同时运行速度显著更快。精心设计的局部注意力在准确率上可与全注意力竞争，但尺寸和延迟成本大幅降低。

Conclusion: 局部注意力设计能够在保持准确率的同时显著降低模型尺寸和延迟，为边缘设备上的交互式语音界面开辟了新的可能性。

Abstract: Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent "encode-the-whole-utterance" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.

</details>


### [76] [A technical curriculum on language-oriented artificial intelligence in translation and specialised communication](https://arxiv.org/abs/2602.12251)
*Ralph Krüger*

Main category: cs.CL

TL;DR: 该论文提出了一个面向语言与翻译行业的语言导向AI技术课程，旨在通过可理解的方式向翻译和专门传播领域的利益相关者传授现代语言导向AI的概念与技术基础，培养领域特定的技术AI素养。


<details>
  <summary>Details</summary>
Motivation: 在AI驱动的翻译和专门传播工作环境中，培养利益相关者的领域特定技术AI素养至关重要。当前需要让翻译和语言专业人员理解语言导向AI的概念和技术基础，以增强他们的计算思维、算法意识和算法能动性，最终提升在AI驱动工作环境中的数字韧性。

Method: 开发了一个核心课程，重点涵盖四个关键技术领域：1) 向量嵌入，2) 神经网络的技术基础，3) 分词技术，4) 变压器神经网络。课程设计以可理解的方式呈现概念和技术/算法基础。在科隆应用技术大学翻译与多语言传播研究所的AI重点硕士课程中测试了该课程的教学适用性。

Result: 课程在科隆应用技术大学的AI重点硕士课程中进行了教学适用性测试。结果表明课程具有教学有效性，但参与者反馈显示，为了创造最佳学习条件，课程需要嵌入更高层次的教学支架中，例如以讲师支持的形式。

Conclusion: 该语言导向AI技术课程能够有效培养翻译和专门传播领域利益相关者的技术AI素养，但需要适当的教学支持和支架结构来优化学习效果。课程的成功实施有助于增强专业人员在AI驱动工作环境中的数字韧性和适应能力。

Abstract: This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.

</details>


### [77] [T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization](https://arxiv.org/abs/2602.12262)
*Tunyu Zhang,Xinxi Zhang,Ligong Han,Haizhou Shi,Xiaoxiao He,Zhuowei Li,Hao Wang,Kai Xu,Akash Srivastava,Hao Wang,Vladimir Pavlovic,Dimitris N. Metaxas*

Main category: cs.CL

TL;DR: 本文提出轨迹自蒸馏框架T3D，通过蒸馏模型自身的生成轨迹来提升扩散大语言模型的少步解码质量，显著缩小与全步解码的性能差距。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型理论上能并行解码多个token实现快速文本生成，但实际推理效率受限于需要大量细化步骤。激进减少步骤数会导致生成质量显著下降，需要在保持质量的同时提高推理效率。

Method: 提出轨迹自蒸馏框架，采用直接判别优化（DDO）的反向KL目标，促进模式寻求蒸馏，使学生模型专注于教师模型的高概率模式，从而提升少步解码性能。

Result: 在多个基准测试中，该方法在严格步骤预算下始终优于强少步基线方法和标准训练。虽然全步解码仍更优，但显著缩小了性能差距。

Conclusion: 轨迹自蒸馏框架为实用的少步扩散大语言模型建立了坚实基础，通过蒸馏自身生成轨迹有效提升了少步解码质量，平衡了推理效率与生成质量。

Abstract: Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.

</details>


### [78] [On-Policy Context Distillation for Language Models](https://arxiv.org/abs/2602.12275)
*Tianzhu Ye,Li Dong,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: OPCD框架通过策略蒸馏与上下文蒸馏结合，让学生模型在自身生成轨迹上训练，同时最小化与上下文条件教师的反向KL散度，有效实现经验知识蒸馏和系统提示蒸馏。


<details>
  <summary>Details</summary>
Motivation: 现有上下文蒸馏方法需要大量标注数据或特定训练设置，作者希望开发更高效的蒸馏框架，让语言模型能够从自身经验中学习并内化上下文知识。

Method: 提出On-Policy Context Distillation (OPCD)框架，结合策略蒸馏和上下文蒸馏，训练学生模型时使用自身生成的轨迹，同时最小化与上下文条件教师模型的反向KL散度。

Result: 在数学推理、文本游戏和领域特定任务上，OPCD均优于基线方法，获得更高任务准确率并更好保持分布外能力，同时支持跨尺寸蒸馏（小模型可从大教师模型学习经验知识）。

Conclusion: OPCD为语言模型内化上下文知识提供了有效框架，特别适用于经验知识蒸馏和系统提示蒸馏，在多种任务上表现出优越性能。

Abstract: Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [79] [Mitigating Error Accumulation in Continuous Navigation via Memory-Augmented Kalman Filtering](https://arxiv.org/abs/2602.11183)
*Yin Tang,Jiawei Ma,Jinrui Zhang,Alex Jinpeng Wang,Deyu Zhang*

Main category: cs.RO

TL;DR: 提出NeuroKalman框架，将无人机连续导航建模为贝叶斯状态估计问题，通过先验预测和似然校正来缓解状态漂移问题


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航模型采用航位推算方式，逐步更新位置预测下一个航点，这种逐步方式会导致位置误差随时间累积，产生状态漂移问题，最终影响完整轨迹预测

Method: 提出NeuroKalman框架，将导航解耦为两个互补过程：基于运动动力学的先验预测和基于历史观测的似然校正。将核密度估计与基于注意力的检索机制数学关联，使系统能够在不进行梯度更新的情况下使用检索到的历史锚点校正潜在表示

Result: 在TravelUAV基准测试上的综合实验表明，仅使用10%的训练数据进行微调，该方法明显优于强基线，并能有效调节漂移累积

Conclusion: 通过将序列预测建模为递归贝叶斯状态估计问题，NeuroKalman框架能够校正误差，缓解无人机导航中的状态漂移问题

Abstract: Continuous navigation in complex environments is critical for Unmanned Aerial Vehicle (UAV). However, the existing Vision-Language Navigation (VLN) models follow the dead-reckoning, which iteratively updates its position for the next waypoint prediction, and subsequently construct the complete trajectory. Then, such stepwise manner will inevitably lead to accumulated errors of position over time, resulting in misalignment between internal belief and objective coordinates, which is known as "state drift" and ultimately compromises the full trajectory prediction. Drawing inspiration from classical control theory, we propose to correct for errors by formulating such sequential prediction as a recursive Bayesian state estimation problem. In this paper, we design NeuroKalman, a novel framework that decouples navigation into two complementary processes: a Prior Prediction, based on motion dynamics and a Likelihood Correction, from historical observation. We first mathematically associate Kernel Density Estimation of the measurement likelihood with the attention-based retrieval mechanism, which then allows the system to rectify the latent representation using retrieved historical anchors without gradient updates. Comprehensive experiments on TravelUAV benchmark demonstrate that, with only 10% of the training data fine-tuning, our method clearly outperforms strong baselines and regulates drift accumulation.

</details>


### [80] [H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model](https://arxiv.org/abs/2602.11291)
*Wenyuan Chen,Jinbang Huang,Oscar Pang,Zhiyuan Li,Xiao Hu,Lingfeng Zhang,Zhanguang Zhang,Mark Coates,Tongtong Cao,Xingyue Quan,Yingxue Zhang*

Main category: cs.RO

TL;DR: 提出分层世界模型（H-WM），结合高层逻辑世界模型和低层视觉世界模型，统一预测逻辑和视觉状态转换，解决机器人长时程规划中的误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型方法多关注视频生成或自然语言预测，难以直接与机器人动作关联，且长时程预测误差会累积。传统任务与运动规划使用符号逻辑世界模型，虽可执行且鲁棒，但缺乏视觉感知同步。需要结合符号推理的鲁棒性和视觉感知的接地性。

Method: 提出分层世界模型（H-WM），采用双层框架：高层逻辑世界模型预测符号状态转换，低层视觉世界模型预测视觉状态转换。两者在统一框架中联合预测，提供稳定的中间指导。使用对齐机器人运动、符号状态、动作和视觉观察的数据集进行训练。

Result: 在视觉-语言-动作（VLA）控制策略上的实验证明了该方法的有效性和通用性。分层输出为长时程任务提供稳定一致的中间指导，减轻误差累积，实现跨扩展任务序列的鲁棒执行。

Conclusion: H-WM成功整合了符号推理的机器人可执行性和长时程鲁棒性与视觉观察的感知接地性，为机器人规划和控制提供了更可靠的世界模型框架。

Abstract: World models are becoming central to robotic planning and control, as they enable prediction of future state transitions. Existing approaches often emphasize video generation or natural language prediction, which are difficult to directly ground in robot actions and suffer from compounding errors over long horizons. Traditional task and motion planning relies on symbolic logic world models, such as planning domains, that are robot-executable and robust for long-horizon reasoning. However, these methods typically operate independently of visual perception, preventing synchronized symbolic and perceptual state prediction. We propose a Hierarchical World Model (H-WM) that jointly predicts logical and visual state transitions within a unified bilevel framework. H-WM combines a high-level logical world model with a low-level visual world model, integrating the robot-executable, long-horizon robustness of symbolic reasoning with perceptual grounding from visual observations. The hierarchical outputs provide stable and consistent intermediate guidance for long-horizon tasks, mitigating error accumulation and enabling robust execution across extended task sequences. To train H-WM, we introduce a robotic dataset that aligns robot motion with symbolic states, actions, and visual observations. Experiments across vision-language-action (VLA) control policies demonstrate the effectiveness and generality of the approach.

</details>


### [81] [ExtremControl: Low-Latency Humanoid Teleoperation with Direct Extremity Control](https://arxiv.org/abs/2602.11321)
*Ziyan Xiong,Lixing Fang,Junyun Huang,Kashu Yamazaki,Hao Zhang,Chuang Gan*

Main category: cs.RO

TL;DR: ExtremControl是一个低延迟全身控制框架，通过直接操作选定刚性链接的SE(3)位姿、笛卡尔空间映射和速度前馈控制，实现50ms端到端延迟，支持乒乓球平衡、杂耍等高响应性行为。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人遥操作系统依赖预处理的重定向和位置控制，导致高延迟（约200ms），限制了响应性，无法完成需要快速反馈和反应的任务。

Method: 提出ExtremControl框架：1) 直接操作选定刚性链接（主要是四肢）的SE(3)位姿，避免全身重定向；2) 使用笛卡尔空间映射直接将人体运动转换为机器人链接目标；3) 在底层加入速度前馈控制以支持高响应性。

Result: 实现了端到端延迟低至50ms的遥操作系统，支持光学动作捕捉和VR追踪，能够完成乒乓球平衡、杂耍和实时回击等高响应性任务，显著超越先前工作的200ms延迟限制。

Conclusion: ExtremControl通过简化控制流程和加入速度前馈，成功构建了低延迟人形机器人遥操作系统，为收集动态演示和执行快速反应任务提供了有效解决方案。

Abstract: Building a low-latency humanoid teleoperation system is essential for collecting diverse reactive and dynamic demonstrations. However, existing approaches rely on heavily pre-processed human-to-humanoid motion retargeting and position-only PD control, resulting in substantial latency that severely limits responsiveness and prevents tasks requiring rapid feedback and fast reactions. To address this problem, we propose ExtremControl, a low latency whole-body control framework that: (1) operates directly on SE(3) poses of selected rigid links, primarily humanoid extremities, to avoid full-body retargeting; (2) utilizes a Cartesian-space mapping to directly convert human motion to humanoid link targets; and (3) incorporates velocity feedforward control at low level to support highly responsive behavior under rapidly changing control interfaces. We further provide a unified theoretical formulation of ExtremControl and systematically validate its effectiveness through experiments in both simulation and real-world environments. Building on ExtremControl, we implement a low-latency humanoid teleoperation system that supports both optical motion capture and VR-based motion tracking, achieving end-to-end latency as low as 50ms and enabling highly responsive behaviors such as ping-pong ball balancing, juggling, and real-time return, thereby substantially surpassing the 200ms latency limit observed in prior work.

</details>


### [82] [MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation](https://arxiv.org/abs/2602.11337)
*Yejin Kim,Wilbert Pumacay,Omar Rayyan,Max Argus,Winson Han,Eli VanderBilt,Jordi Salvador,Abhay Deshpande,Rose Hendrix,Snehal Jauhri,Shuo Liu,Nur Muhammad Mahi Shafiullah,Maya Guru,Ainaz Eftekhar,Karen Farley,Donovan Clay,Jiafei Duan,Arjun Guru,Piper Wolters,Alvaro Herrasti,Ying-Chun Lee,Georgia Chalvatzaki,Yuchen Cui,Ali Farhadi,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: MolmoSpaces是一个完全开放的机器人策略大规模基准测试生态系统，包含超过23万个多样化室内环境和13万个丰富标注的物体资产，支持多种模拟器，并提供8个任务的基准测试套件。


<details>
  <summary>Details</summary>
Motivation: 现实环境中场景布局、物体几何和任务规范的无数变化在现有机器人基准测试中代表性不足，物理评估无法提供大规模多样化的基础设施来衡量这种泛化能力。

Method: 创建包含23万多个多样化室内环境（从手工制作的家庭场景到程序生成的多房间房屋）和13万个丰富标注物体资产的开放生态系统，支持MuJoCo、Isaac、ManiSkill等多种模拟器，并设计包含8个任务的MolmoSpaces-Bench基准测试套件。

Result: MolmoSpaces-Bench表现出强大的模拟到现实相关性（R=0.96，ρ=0.98），确认了较新和较强的零样本策略在基准测试中优于早期版本，并识别出对提示措辞、初始关节位置和相机遮挡的关键敏感性。

Conclusion: 通过MolmoSpaces及其开源资产和工具，为机器人学习研究提供了可扩展的数据生成、策略训练和基准创建的基础。

Abstract: Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies. MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks: static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, \r{ho} = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing, initial joint positions, and camera occlusion. Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.

</details>


### [83] [Human Preference Modeling Using Visual Motion Prediction Improves Robot Skill Learning from Egocentric Human Video](https://arxiv.org/abs/2602.11393)
*Mrinal Verghese,Christopher G. Atkeson*

Main category: cs.RO

TL;DR: 提出从人类第一人称视频学习机器人技能的方法，通过建模人类偏好为奖励函数，并优化机器人行为最大化该奖励，在真实机器人上实现学习。


<details>
  <summary>Details</summary>
Motivation: 现有从人类视频学习奖励的方法存在局限性：需要测量视觉状态的长期价值作为与终止状态的时间距离，这些方法假设限制了从视频学习的性能，并且需要跨本体和环境差距转移学习到的价值函数。

Method: 通过预测跟踪点在连续图像间的运动来建模人类偏好，定义奖励函数为机器人行为中预测与观察到的物体运动之间的一致性。使用修改的Soft Actor Critic算法，用10个机器人演示初始化，从该奖励估计价值函数并优化最大化该价值函数的策略。

Result: 该方法能够在真实机器人上学习，使用该奖励模型学习的策略在模拟和真实机器人的多个任务中匹配或优于先前工作。

Conclusion: 提出的方法通过建模人类偏好为奖励函数，成功实现了从人类第一人称视频到机器人技能的学习，克服了先前方法的局限性，在真实机器人上取得了良好性能。

Abstract: We present an approach to robot learning from egocentric human videos by modeling human preferences in a reward function and optimizing robot behavior to maximize this reward. Prior work on reward learning from human videos attempts to measure the long-term value of a visual state as the temporal distance between it and the terminal state in a demonstration video. These approaches make assumptions that limit performance when learning from video. They must also transfer the learned value function across the embodiment and environment gap. Our method models human preferences by learning to predict the motion of tracked points between subsequent images and defines a reward function as the agreement between predicted and observed object motion in a robot's behavior at each step. We then use a modified Soft Actor Critic (SAC) algorithm initialized with 10 on-robot demonstrations to estimate a value function from this reward and optimize a policy that maximizes this value function, all on the robot. Our approach is capable of learning on a real robot, and we show that policies learned with our reward model match or outperform prior work across multiple tasks in both simulation and on the real robot.

</details>


### [84] [EasyMimic: A Low-Cost Framework for Robot Imitation Learning from Human Videos](https://arxiv.org/abs/2602.11464)
*Tao Zhang,Song Xia,Ye Wang,Qin Jin*

Main category: cs.RO

TL;DR: EasyMimic框架通过从RGB视频中提取3D手部轨迹，映射到低成本机器人控制空间，结合视觉增强和协同训练，实现快速模仿学习，减少机器人数据收集成本。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿学习面临大规模真实数据收集成本高的挑战，特别是对于家庭使用的低成本机器人，需要既用户友好又经济实惠的解决方案。

Method: 1) 从标准RGB视频中提取3D手部轨迹；2) 动作对齐模块将轨迹映射到机器人夹爪控制空间；3) 引入手部视觉增强策略缩小人机域差距；4) 使用协同训练方法，在人类数据和少量机器人数据上微调模型。

Result: 在低成本LeRobot平台上的实验表明，EasyMimic在各种操作任务中实现高性能，显著减少对昂贵机器人数据收集的依赖。

Conclusion: EasyMimic为将智能机器人带入家庭提供了一条实用路径，通过低成本、可复制的框架实现快速模仿学习。

Abstract: Robot imitation learning is often hindered by the high cost of collecting large-scale, real-world data. This challenge is especially significant for low-cost robots designed for home use, as they must be both user-friendly and affordable. To address this, we propose the EasyMimic framework, a low-cost and replicable solution that enables robots to quickly learn manipulation policies from human video demonstrations captured with standard RGB cameras. Our method first extracts 3D hand trajectories from the videos. An action alignment module then maps these trajectories to the gripper control space of a low-cost robot. To bridge the human-to-robot domain gap, we introduce a simple and user-friendly hand visual augmentation strategy. We then use a co-training method, fine-tuning a model on both the processed human data and a small amount of robot data, enabling rapid adaptation to new tasks. Experiments on the low-cost LeRobot platform demonstrate that EasyMimic achieves high performance across various manipulation tasks. It significantly reduces the reliance on expensive robot data collection, offering a practical path for bringing intelligent robots into homes. Project website: https://zt375356.github.io/EasyMimic-Project/.

</details>


### [85] [Effective Task Planning with Missing Objects using Learning-Informed Object Search](https://arxiv.org/abs/2602.11468)
*Raihan Islam Arnob,Max Merlin,Abhishek Paudel,Benned Hedegaard,George Konidaris,Gregory Stein*

Main category: cs.RO

TL;DR: 提出LIOS动作规划框架，将对象搜索作为确定性动作集成到任务规划中，解决未知物体位置下的机器人任务规划问题


<details>
  <summary>Details</summary>
Motivation: 传统任务规划（如PDDL）假设完全环境知识，无法处理任务关键物体位置未知的情况。现有学习驱动的对象搜索方法有效但作为独立工具，难以集成到需要确定何时搜索何种物体的完整任务规划器中。

Method: 开发基于LIOS（学习信息对象搜索）动作的规划框架：每个LIOS动作是一个寻找并检索单个物体的策略。高层规划将LIOS动作视为确定性动作，基于模型计算的预期成本生成计划，在搜索和执行之间交错进行。

Result: 在模拟的ProcTHOR家庭环境和真实世界中，该方法在检索和备餐等任务上优于非学习和学习基线方法，有效处理不确定性同时保持与现有全知识求解器的兼容性。

Conclusion: LIOS规划框架通过将学习驱动的对象搜索作为确定性动作集成到任务规划中，实现了在物体位置不确定情况下的有效、完备的学习信息任务规划，平衡了不确定性的推理与现有规划器的兼容性。

Abstract: Task planning for mobile robots often assumes full environment knowledge and so popular approaches, like planning via the PDDL, cannot plan when the locations of task-critical objects are unknown. Recent learning-driven object search approaches are effective, but operate as standalone tools and so are not straightforwardly incorporated into full task planners, which must additionally determine both what objects are necessary and when in the plan they should be sought out. To address this limitation, we develop a planning framework centered around novel model-based LIOS actions: each a policy that aims to find and retrieve a single object. High-level planning treats LIOS actions as deterministic and so -- informed by model-based calculations of the expected cost of each -- generates plans that interleave search and execution for effective, sound, and complete learning-informed task planning despite uncertainty. Our work effectively reasons about uncertainty while maintaining compatibility with existing full-knowledge solvers. In simulated ProcTHOR homes and in the real world, our approach outperforms non-learned and learned baselines on tasks including retrieval and meal prep.

</details>


### [86] [HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds](https://arxiv.org/abs/2602.11554)
*Yichun Xiao,Runwei Guan,Fangqiang Ding*

Main category: cs.RO

TL;DR: HyperDet是一个检测器无关的4D毫米波雷达3D检测框架，通过构建任务感知的超4D雷达点云，使标准LiDAR导向检测器能直接处理雷达数据，部分缩小了雷达与LiDAR的性能差距。


<details>
  <summary>Details</summary>
Motivation: 4D毫米波雷达具有天气鲁棒性、速度感知能力和成本效益，但雷达点云稀疏、不规则且受多径噪声影响，导致3D检测性能落后于LiDAR系统。需要一种方法让雷达数据能充分利用现有的LiDAR导向检测器。

Method: 1) 多雷达多帧聚合提高覆盖和密度；2) 几何感知的跨传感器一致性验证，在重叠区域外进行轻量级自一致性检查；3) 前景聚焦扩散模块，通过混合雷达-LiDAR监督训练来增强目标结构，提升雷达属性；4) 将模型蒸馏为一致性模型实现单步推理。

Result: 在MAN TruckScenes数据集上，HyperDet使用VoxelNeXt和CenterPoint检测器时，相比原始雷达输入有持续改进，部分缩小了雷达与LiDAR的性能差距。

Conclusion: 输入级细化使雷达数据能够更好地利用LiDAR导向的检测器，无需修改检测器架构，为雷达-only 3D检测提供了有效解决方案。

Abstract: 4D mmWave radar provides weather-robust, velocity-aware measurements and is more cost-effective than LiDAR. However, radar-only 3D detection still trails LiDAR-based systems because radar point clouds are sparse, irregular, and often corrupted by multipath noise, yielding weak and unstable geometry. We present HyperDet, a detector-agnostic radar-only 3D detection framework that constructs a task-aware hyper 4D radar point cloud for standard LiDAR-oriented detectors. HyperDet aggregates returns from multiple surround-view 4D radars over consecutive frames to improve coverage and density, then applies geometry-aware cross-sensor consensus validation with a lightweight self-consistency check outside overlap regions to suppress inconsistent returns. It further integrates a foreground-focused diffusion module with training-time mixed radar-LiDAR supervision to densify object structures while lifting radar attributes (e.g., Doppler, RCS); the model is distilled into a consistency model for single-step inference. On MAN TruckScenes, HyperDet consistently improves over raw radar inputs with VoxelNeXt and CenterPoint, partially narrowing the radar-LiDAR gap. These results show that input-level refinement enables radar to better leverage LiDAR-oriented detectors without architectural modifications.

</details>


### [87] [ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles](https://arxiv.org/abs/2602.11575)
*Seungyeon Yoo,Youngseok Jang,Dabin Kim,Youngsoo Han,Seungwoo Jung,H. Jin Kim*

Main category: cs.RO

TL;DR: ReaDy-Go提出了一种新颖的真实到仿真模拟管道，通过结合静态3D高斯泼溅场景与动态人体高斯泼溅障碍物，生成逼真的动态环境导航数据集，以训练对仿真到真实差距和移动障碍物都鲁棒的导航策略。


<details>
  <summary>Details</summary>
Motivation: 现有视觉导航模型在真实动态环境中表现不佳，主要面临仿真到真实差距的鲁棒性有限，以及难以针对特定部署环境（如家庭、餐厅、工厂）训练策略的问题。虽然使用3D高斯泼溅的真实到仿真模拟可以缓解这一差距，但先前工作仅假设静态场景或不现实的动态障碍物，而动态环境中的安全导航至关重要。

Method: ReaDy-Go包含三个组件：1）动态高斯泼溅模拟器，将场景高斯泼溅与人体动画模块结合，插入可动画的人体高斯泼溅化身并从2D轨迹合成合理的人体运动；2）动态环境导航数据集生成，利用模拟器、为动态高斯泼溅表示设计的机器人专家规划器和人体规划器；3）使用生成数据集进行策略学习。

Result: ReaDy-Go在目标环境的仿真和真实世界实验中均优于基线方法，即使在仿真到真实迁移后和存在移动障碍物的情况下也表现出改进的导航性能。此外，在未见环境中的零样本仿真到真实部署显示了其泛化潜力。

Conclusion: ReaDy-Go通过生成逼真的动态场景导航数据集，成功解决了真实动态环境中视觉导航的挑战，提高了对仿真到真实差距和移动障碍物的鲁棒性，展示了在真实世界部署中的有效性和泛化能力。

Abstract: Visual navigation models often struggle in real-world dynamic environments due to limited robustness to the sim-to-real gap and the difficulty of training policies tailored to target deployment environments (e.g., households, restaurants, and factories). Although real-to-sim navigation simulation using 3D Gaussian Splatting (GS) can mitigate this gap, prior works have assumed only static scenes or unrealistic dynamic obstacles, despite the importance of safe navigation in dynamic environments. To address these issues, we propose ReaDy-Go, a novel real-to-sim simulation pipeline that synthesizes photorealistic dynamic scenarios for target environments. ReaDy-Go generates photorealistic navigation datasets for dynamic environments by combining a reconstructed static GS scene with dynamic human GS obstacles, and trains policies robust to both the sim-to-real gap and moving obstacles. The pipeline consists of three components: (1) a dynamic GS simulator that integrates scene GS with a human animation module, enabling the insertion of animatable human GS avatars and the synthesis of plausible human motions from 2D trajectories, (2) navigation dataset generation for dynamic environments that leverages the simulator, a robot expert planner designed for dynamic GS representations, and a human planner, and (3) policy learning using the generated datasets. ReaDy-Go outperforms baselines across target environments in both simulation and real-world experiments, demonstrating improved navigation performance even after sim-to-real transfer and in the presence of moving obstacles. Moreover, zero-shot sim-to-real deployment in an unseen environment indicates its generalization potential. Project page: https://syeon-yoo.github.io/ready-go-site/.

</details>


### [88] [ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation](https://arxiv.org/abs/2602.11598)
*Zedong Chu,Shichao Xie,Xiaolong Wu,Yanfen Shen,Minghua Luo,Zhengbo Wang,Fei Liu,Xiaoxu Leng,Junjun Hu,Mingyang Yin,Jia Lu,Yingnan Guo,Kai Yang,Jiawei Han,Xu Chen,Yanqing Zhu,Yuxiang Zhao,Xin Liu,Yirong Yang,Ye He,Jiahang Wang,Yang Cai,Tianlin Zhang,Li Gao,Liu Liu,Mingchao Sun,Fan Jiang,Chiyu Wang,Zhicheng Liu,Hongyu Pan,Honglin Han,Zhining Gu,Kuan Yang,Jianfang Zhang,Di Jing,Zihao Guan,Wei Guo,Guoqing Liu,Di Yang,Xiangpo Yang,Menglin Yang,Hongguang Xing,Weiguo Li,Mu Xu*

Main category: cs.RO

TL;DR: ABot-N0是一个统一的视觉-语言-动作基础模型，通过"大脑-动作"分层架构实现了5个核心导航任务的"大一统"，在7个基准测试中达到新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决具身导航领域长期存在的任务特定架构碎片化问题，实现跨多种导航任务的统一模型架构。

Method: 采用分层"大脑-动作"架构：基于LLM的认知大脑进行语义推理，结合基于流匹配的动作专家生成精确连续轨迹。开发ABot-N0数据引擎，收集1690万专家轨迹和500万推理样本。

Result: 在7个基准测试中达到新的SOTA性能，显著超越专用模型。智能导航系统集成了规划器和分层拓扑记忆，能在动态现实环境中执行鲁棒的长时程任务。

Conclusion: ABot-N0成功实现了具身导航任务的统一，通过大规模数据训练和分层架构设计，为智能导航系统提供了强大的基础模型。

Abstract: Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation.
  To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 $\text{km}^2$). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.

</details>


### [89] [ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning](https://arxiv.org/abs/2602.11643)
*Yufeng Tian,Shuiqi Cheng,Tianming Wei,Tianxing Zhou,Yuanhang Zhang,Zixian Liu,Qianwei Han,Zhecheng Yuan,Huazhe Xu*

Main category: cs.RO

TL;DR: ViTaS是一个简单有效的多模态框架，结合视觉和触觉信息指导机器人操作，通过软融合对比学习和CVAE模块利用两种模态的对齐性和互补性，在模拟和真实环境中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 触觉信息在机器人操作中至关重要，但现有方法主要关注视觉和触觉特征的对齐，集成机制通常是直接拼接，难以有效处理遮挡场景，忽视了两种模态的互补性，对齐利用不足，限制了实际部署潜力。

Method: 提出ViTaS框架，引入软融合对比学习（传统对比学习方法的进阶版）和CVAE模块，充分利用视觉-触觉表示的对齐性和互补性。

Result: 在12个模拟环境和3个真实世界环境中验证了方法的有效性，实验表明ViTaS显著优于现有基线方法。

Conclusion: ViTaS通过有效整合视觉和触觉信息，解决了现有方法在遮挡场景下的局限性，提升了机器人操作的实际部署潜力。

Abstract: Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the potential of their real-world deployment. In this paper, we present ViTaS, a simple yet effective framework that incorporates both visual and tactile information to guide the behavior of an agent. We introduce Soft Fusion Contrastive Learning, an advanced version of conventional contrastive learning method and a CVAE module to utilize the alignment and complementarity within visuo-tactile representations. We demonstrate the effectiveness of our method in 12 simulated and 3 real-world environments, and our experiments show that ViTaS significantly outperforms existing baselines. Project page: https://skyrainwind.github.io/ViTaS/index.html.

</details>


### [90] [Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli](https://arxiv.org/abs/2602.11648)
*Faezeh Vahedi,Morteza Memari,Ramtin Tabatabaei,Alireza Taheri*

Main category: cs.RO

TL;DR: 该研究开发了基于LSTM和Transformer的神经网络模型，预测人类在社交场景中的注视方向，包括对人类和非人类刺激的反应，并将模型部署到NAO机器人上，实现了机器人动态模仿人类注视行为。


<details>
  <summary>Details</summary>
Motivation: 社交机器人需要适应人类活动并响应所有线索（包括非人类刺激）以实现无缝有效沟通。当前研究在非人类刺激的注视响应方面存在不足，需要提高机器人与人类在各种社交情境中注视行为的相似性。

Method: 使用Unity创建3D动画和360度真实世界视频模拟社交场景，通过VR眼镜收集41名参与者的注视方向数据。预处理数据后，训练LSTM和Transformer神经网络模型预测个体注视模式。将最佳模型部署到NAO机器人上进行评估。

Result: 在动画场景中，LSTM和Transformer模型的预测准确率分别为67.6%和70.4%；在真实世界场景中，准确率分别为72%和71.6%。模型优于现有方法。部署到NAO机器人后，275名参与者通过问卷调查显示交互满意度高。

Conclusion: 该研究成功开发了能够预测人类注视方向（包括对非人类刺激的反应）的神经网络模型，并将其应用于社交机器人，使机器人能够在复杂社交情境中动态模仿人类注视行为，推动了社交机器人领域的发展。

Abstract: Nonverbal behaviors, particularly gaze direction, play a crucial role in enhancing effective communication in social interactions. As social robots increasingly participate in these interactions, they must adapt their gaze based on human activities and remain receptive to all cues, whether human-generated or not, to ensure seamless and effective communication. This study aims to increase the similarity between robot and human gaze behavior across various social situations, including both human and non-human stimuli (e.g., conversations, pointing, door openings, and object drops). A key innovation in this study, is the investigation of gaze responses to non-human stimuli, a critical yet underexplored area in prior research. These scenarios, were simulated in the Unity software as a 3D animation and a 360-degree real-world video. Data on gaze directions from 41 participants were collected via virtual reality (VR) glasses. Preprocessed data, trained two neural networks-LSTM and Transformer-to build predictive models based on individuals' gaze patterns. In the animated scenario, the LSTM and Transformer models achieved prediction accuracies of 67.6% and 70.4%, respectively; In the real-world scenario, the LSTM and Transformer models achieved accuracies of 72% and 71.6%, respectively. Despite the gaze pattern differences among individuals, our models outperform existing approaches in accuracy while uniquely considering non-human stimuli, offering a significant advantage over previous literature. Furthermore, deployed on the NAO robot, the system was evaluated by 275 participants via a comprehensive questionnaire, with results demonstrating high satisfaction during interactions. This work advances social robotics by enabling robots to dynamically mimic human gaze behavior in complex social contexts.

</details>


### [91] [AC-MASAC: An Attentive Curriculum Learning Framework for Heterogeneous UAV Swarm Coordination](https://arxiv.org/abs/2602.11735)
*Wanhao Liu,Junhong Dai,Yixuan Zhang,Shengyun Yin,Panshuo Li*

Main category: cs.RO

TL;DR: 提出AC-MASAC框架，通过角色感知异质注意力机制和结构化课程学习策略，解决异构无人机集群协同路径规划中的不对称依赖、稀疏奖励和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 异构无人机集群协同路径规划对多智能体强化学习提出挑战，特别是处理不对称的智能体间依赖关系，以及解决训练过程中的稀疏奖励和灾难性遗忘风险。

Method: 提出注意力课程学习框架AC-MASAC，包含：1）角色感知异质注意力机制，显式建模不对称依赖；2）结构化课程策略，整合分层知识迁移和阶段比例经验回放。

Result: 在自定义多智能体仿真平台上验证，结果显示在成功率、编队保持率和任务时间加权成功率等指标上显著优于其他先进方法。

Conclusion: AC-MASAC框架有效解决了异构无人机集群协同路径规划中的关键挑战，通过注意力机制和课程学习策略提升了多智能体强化学习的性能。

Abstract: Cooperative path planning for heterogeneous UAV swarms poses significant challenges for Multi-Agent Reinforcement Learning (MARL), particularly in handling asymmetric inter-agent dependencies and addressing the risks of sparse rewards and catastrophic forgetting during training. To address these issues, this paper proposes an attentive curriculum learning framework (AC-MASAC). The framework introduces a role-aware heterogeneous attention mechanism to explicitly model asymmetric dependencies. Moreover, a structured curriculum strategy is designed, integrating hierarchical knowledge transfer and stage-proportional experience replay to address the issues of sparse rewards and catastrophic forgetting. The proposed framework is validated on a custom multi-agent simulation platform, and the results show that our method has significant advantages over other advanced methods in terms of Success Rate, Formation Keeping Rate, and Success-weighted Mission Time. The code is available at \textcolor{red}{https://github.com/Wanhao-Liu/AC-MASAC}.

</details>


### [92] [HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model](https://arxiv.org/abs/2602.11758)
*Dongting Li,Xingyu Chen,Qianyang Wu,Bo Chen,Sikai Wu,Hanyu Wu,Guoyao Zhang,Liang Li,Mingliang Zhou,Diyun Xiang,Jianzhu Ma,Qiang Zhang,Renjing Xu*

Main category: cs.RO

TL;DR: HAIC框架让类人机器人仅凭本体感知就能与多种动态物体交互，无需外部状态估计，成功完成滑板、推车、搬运等复杂任务


<details>
  <summary>Details</summary>
Motivation: 现有的人-物交互方法主要关注完全驱动且与机器人刚性耦合的物体，忽略了具有独立动力学和非完整约束的欠驱动物体，这些物体带来的耦合力和遮挡给控制带来了挑战

Method: 提出HAIC统一框架，核心是动态预测器仅从本体感知历史估计物体高阶状态，将其投影到静态几何先验形成空间接地的动态占据地图，采用非对称微调让世界模型持续适应学生策略的探索

Result: 在类人机器人实验中，HAIC在敏捷任务（滑板、推/拉不同负载的推车）中通过主动补偿惯性扰动获得高成功率，并能预测多个物体动态完成长时程多物体任务（如搬运箱子穿越不同地形）

Conclusion: HAIC为类人机器人提供了无需外部状态估计就能与多种动态物体稳健交互的统一框架，通过动态预测和空间接地表示有效解决了欠驱动物体的控制挑战

Abstract: Humanoid robots show promise for complex whole-body tasks in unstructured environments. Although Human-Object Interaction (HOI) has advanced, most methods focus on fully actuated objects rigidly coupled to the robot, ignoring underactuated objects with independent dynamics and non-holonomic constraints. These introduce control challenges from coupling forces and occlusions. We present HAIC, a unified framework for robust interaction across diverse object dynamics without external state estimation. Our key contribution is a dynamics predictor that estimates high-order object states (velocity, acceleration) solely from proprioceptive history. These predictions are projected onto static geometric priors to form a spatially grounded dynamic occupancy map, enabling the policy to infer collision boundaries and contact affordances in blind spots. We use asymmetric fine-tuning, where a world model continuously adapts to the student policy's exploration, ensuring robust state estimation under distribution shifts. Experiments on a humanoid robot show HAIC achieves high success rates in agile tasks (skateboarding, cart pushing/pulling under various loads) by proactively compensating for inertial perturbations, and also masters multi-object long-horizon tasks like carrying a box across varied terrain by predicting the dynamics of multiple objects.

</details>


### [93] [LAMP: Implicit Language Map for Robot Navigation](https://arxiv.org/abs/2602.11862)
*Sibaek Lee,Hyeonwoo Yu,Giseop Kim,Sunwook Choi*

Main category: cs.RO

TL;DR: LAMP提出了一种基于神经语言场的导航框架，使用隐式表示而非显式存储语言向量，通过粗到细的路径规划实现高效、精细的导航。


<details>
  <summary>Details</summary>
Motivation: 现有基于网格或节点的显式语言向量存储方法存在内存需求大、分辨率有限的问题，难以扩展到大规模环境，需要更高效的细粒度导航解决方案。

Method: 1) 学习连续的语言驱动隐式神经场表示；2) 结合稀疏图进行粗路径规划；3) 在学习的场中进行梯度优化细化姿态；4) 采用贝叶斯框架建模嵌入不确定性；5) 使用图采样策略优先考虑空间覆盖和嵌入置信度。

Result: 在NVIDIA Isaac Sim和真实多楼层建筑中的实验表明，LAMP在内存效率和细粒度目标到达精度方面均优于现有显式方法。

Conclusion: LAMP通过隐式语言场表示和粗到细的规划框架，成功解决了大规模环境中语言导航的内存效率和精细规划问题，是首个将隐式语言地图应用于精确路径生成的方法。

Abstract: Recent advances in vision-language models have made zero-shot navigation feasible, enabling robots to follow natural language instructions without requiring labeling. However, existing methods that explicitly store language vectors in grid or node-based maps struggle to scale to large environments due to excessive memory requirements and limited resolution for fine-grained planning. We introduce LAMP (Language Map), a novel neural language field-based navigation framework that learns a continuous, language-driven map and directly leverages it for fine-grained path generation. Unlike prior approaches, our method encodes language features as an implicit neural field rather than storing them explicitly at every location. By combining this implicit representation with a sparse graph, LAMP supports efficient coarse path planning and then performs gradient-based optimization in the learned field to refine poses near the goal. This coarse-to-fine pipeline, language-driven, gradient-guided optimization is the first application of an implicit language map for precise path generation. This refinement is particularly effective at selecting goal regions not directly observed by leveraging semantic similarities in the learned feature space. To further enhance robustness, we adopt a Bayesian framework that models embedding uncertainty via the von Mises-Fisher distribution, thereby improving generalization to unobserved regions. To scale to large environments, LAMP employs a graph sampling strategy that prioritizes spatial coverage and embedding confidence, retaining only the most informative nodes and substantially reducing computational overhead. Our experimental results, both in NVIDIA Isaac Sim and on a real multi-floor building, demonstrate that LAMP outperforms existing explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.

</details>


### [94] [Learning to Manipulate Anything: Revealing Data Scaling Laws in Bounding-Box Guided Policies](https://arxiv.org/abs/2602.11885)
*Yihao Wu,Jinming Ma,Junbo Tan,Yanzhao Yu,Shoujie Li,Mingliang Zhou,Diyun Xiang,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出使用边界框指令指导扩散策略，通过Label-UMI数据收集系统和语义-运动解耦框架，在语义操作任务中发现数据缩放规律，实现85%成功率


<details>
  <summary>Details</summary>
Motivation: 扩散策略在语义操作任务中泛化能力有限，仅依赖文本指令在复杂动态环境中难以准确定位目标物体，需要更直接的物体指定方法

Method: 1) 提出边界框指令直接指定目标物体；2) 设计手持分割设备Label-UMI实现高效数据收集；3) 提出语义-运动解耦框架，结合目标检测和边界框引导的扩散策略

Result: 在大规模数据集上验证了方法的有效性，揭示了泛化性能与边界框物体数量之间的幂律关系，在四个任务上对已见和未见物体均达到85%成功率

Conclusion: 边界框指令能有效提升语义操作任务的泛化能力，发现数据缩放规律，总结出有效的数据收集策略，为机器人部署提供实用解决方案

Abstract: Diffusion-based policies show limited generalization in semantic manipulation, posing a key obstacle to the deployment of real-world robots. This limitation arises because relying solely on text instructions is inadequate to direct the policy's attention toward the target object in complex and dynamic environments. To solve this problem, we propose leveraging bounding-box instruction to directly specify target object, and further investigate whether data scaling laws exist in semantic manipulation tasks. Specifically, we design a handheld segmentation device with an automated annotation pipeline, Label-UMI, which enables the efficient collection of demonstration data with semantic labels. We further propose a semantic-motion-decoupled framework that integrates object detection and bounding-box guided diffusion policy to improve generalization and adaptability in semantic manipulation. Throughout extensive real-world experiments on large-scale datasets, we validate the effectiveness of the approach, and reveal a power-law relationship between generalization performance and the number of bounding-box objects. Finally, we summarize an effective data collection strategy for semantic manipulation, which can achieve 85\% success rates across four tasks on both seen and unseen objects. All datasets and code will be released to the community.

</details>


### [95] [General Humanoid Whole-Body Control via Pretraining and Fast Adaptation](https://arxiv.org/abs/2602.11929)
*Zepeng Wang,Jiangxing Wang,Shiqing Yao,Yu Zhang,Ziluo Ding,Ming Yang,Yuxuan Wang,Haobin Jiang,Chao Ma,Xiaochuan Shi,Zongqing Lu*

Main category: cs.RO

TL;DR: FAST是一个通用人形机器人全身控制框架，通过Parseval引导的残差策略适应和质心感知控制，实现快速适应和稳定运动跟踪


<details>
  <summary>Details</summary>
Motivation: 现有方法需要任务特定训练或在适应新运动时性能下降，人形机器人控制面临运动分布多样、快速适应困难、高动态场景下平衡保持等挑战

Method: 提出Parseval引导的残差策略适应，在正交性和KL约束下学习轻量级增量动作策略；引入质心感知控制，整合质心相关观测和目标以增强平衡能力

Result: 在仿真和实际部署中，FAST在鲁棒性、适应效率和泛化能力方面持续优于最先进的基线方法

Conclusion: FAST框架通过高效的策略适应机制和增强的平衡控制，成功解决了人形机器人通用全身控制中的关键挑战

Abstract: Learning a general whole-body controller for humanoid robots remains challenging due to the diversity of motion distributions, the difficulty of fast adaptation, and the need for robust balance in high-dynamic scenarios. Existing approaches often require task-specific training or suffer from performance degradation when adapting to new motions. In this paper, we present FAST, a general humanoid whole-body control framework that enables Fast Adaptation and Stable Motion Tracking. FAST introduces Parseval-Guided Residual Policy Adaptation, which learns a lightweight delta action policy under orthogonality and KL constraints, enabling efficient adaptation to out-of-distribution motions while mitigating catastrophic forgetting. To further improve physical robustness, we propose Center-of-Mass-Aware Control, which incorporates CoM-related observations and objectives to enhance balance when tracking challenging reference motions. Extensive experiments in simulation and real-world deployment demonstrate that FAST consistently outperforms state-of-the-art baselines in robustness, adaptation efficiency, and generalization.

</details>


### [96] [Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control](https://arxiv.org/abs/2602.11934)
*Yu Deng,Yufeng Jin,Xiaogang Jia,Jiahong Xue,Gerhard Neumann,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: 提出Robot-DIFT框架，通过流形蒸馏将扩散模型的几何先验蒸馏到确定性视觉骨干中，解决机器人操控中视觉骨干与闭环控制需求的结构不匹配问题


<details>
  <summary>Details</summary>
Motivation: 当前机器人操控的瓶颈在于视觉骨干结构与物理控制需求不匹配。现有视觉编码器（包括VLA中使用的）为语义不变性优化，适合分类任务，但操控需要几何敏感性——能够将毫米级姿态变化映射到可预测的特征变化。判别式模型存在"盲点"，而生成式扩散模型虽然编码了几何依赖关系，但直接用于控制存在随机不稳定性、推理延迟和微调时的表示漂移问题。

Method: 提出Robot-DIFT框架，通过流形蒸馏将冻结的扩散教师模型的知识蒸馏到确定性的空间-语义特征金字塔网络（S2-FPN）中。这种方法将几何信息的来源与推理过程解耦，保留了生成模型的丰富几何先验，同时确保时间稳定性、实时执行和对漂移的鲁棒性。

Result: 在大型DROID数据集上预训练后，Robot-DIFT相比领先的判别式基线表现出更优的几何一致性和控制性能，支持"模型如何学习看决定了它如何学习行动"的观点。

Conclusion: 机器人操控的泛化能力不仅取决于数据规模或策略容量，更关键的是视觉骨干与物理控制需求的结构匹配。通过流形蒸馏将扩散模型的几何先验转移到确定性骨干中，能够有效解决当前视觉骨干在精细控制中的局限性，为机器人操控提供了更好的视觉表示基础。

Abstract: We hypothesize that a key bottleneck in generalizable robot manipulation is not solely data scale or policy capacity, but a structural mismatch between current visual backbones and the physical requirements of closed-loop control. While state-of-the-art vision encoders (including those used in VLAs) optimize for semantic invariance to stabilize classification, manipulation typically demands geometric sensitivity the ability to map millimeter-level pose shifts to predictable feature changes. Their discriminative objective creates a "blind spot" for fine-grained control, whereas generative diffusion models inherently encode geometric dependencies within their latent manifolds, encouraging the preservation of dense multi-scale spatial structure. However, directly deploying stochastic diffusion features for control is hindered by stochastic instability, inference latency, and representation drift during fine-tuning. To bridge this gap, we propose Robot-DIFT, a framework that decouples the source of geometric information from the process of inference via Manifold Distillation. By distilling a frozen diffusion teacher into a deterministic Spatial-Semantic Feature Pyramid Network (S2-FPN), we retain the rich geometric priors of the generative model while ensuring temporal stability, real-time execution, and robustness against drift. Pretrained on the large-scale DROID dataset, Robot-DIFT demonstrates superior geometric consistency and control performance compared to leading discriminative baselines, supporting the view that how a model learns to see dictates how well it can learn to act.

</details>


### [97] [Accelerating Robotic Reinforcement Learning with Agent Guidance](https://arxiv.org/abs/2602.11978)
*Haojun Chen,Zili Zou,Chengdong Ma,Yaoxiang Pu,Haotong Zhang,Yuanpei Chen,Yaodong Yang*

Main category: cs.RO

TL;DR: AGPS用多模态智能体替代人类监督，通过语义世界模型注入内在价值先验，提升机器人强化学习的样本效率


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人操作中存在样本效率低的问题，现有的人机协同方法受限于1:1监督比例、操作者疲劳和人类技能不一致性，难以规模化应用

Method: 提出Agent-guided Policy Search框架，用多模态智能体替代人类监督员，将智能体视为语义世界模型，通过可执行工具提供纠正路径点和空间约束来引导物理探索

Result: 在精度插入和可变形物体操作等任务上验证，AGPS在人机协同方法中表现出更好的样本效率

Conclusion: AGPS实现了监督流程自动化，为无人工干预和可扩展的机器人学习开辟了道路

Abstract: Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.

</details>


### [98] [Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario](https://arxiv.org/abs/2602.12012)
*Muhammad Farhan Ahmed,Vincent Frémont*

Main category: cs.RO

TL;DR: 提出一个去中心化的多机器人框架，使用多个无人机与自主水面艇协作，检测和跟踪海上漂浮容器，通过不确定性感知数据关联、协方差交叉融合和信息驱动分配实现可靠感知与协调。


<details>
  <summary>Details</summary>
Motivation: 自主空中-水面机器人团队在海上监测中具有潜力，但需要克服水面反射环境下的可靠感知挑战，以及在有限通信条件下的可扩展协调问题。

Method: 采用去中心化多机器人框架：每个无人机使用YOLOv8和立体视差进行视觉检测，通过基于不确定性的数据关联使用每目标扩展卡尔曼滤波器跟踪；通过协方差交叉保守融合紧凑的轨迹摘要；信息驱动分配模块权衡不确定性减少、移动成本和安全性来分配目标和选择悬停视点。

Result: 海上场景仿真结果表明，该框架提高了覆盖范围、定位精度和跟踪一致性，同时保持了适度的通信需求。

Conclusion: 提出的去中心化多机器人框架能够有效解决海上监测中水面反射环境和有限通信条件下的感知与协调挑战，为自主空中-水面机器人团队的实际部署提供了可行方案。

Abstract: Autonomous aerial-surface robot teams are promising for maritime monitoring. Robust deployment requires reliable perception over reflective water and scalable coordination under limited communication. We present a decentralized multi-robot framework for detecting and tracking floating containers using multiple UAVs cooperating with an autonomous surface vessel. Each UAV performs YOLOv8 and stereo-disparity-based visual detection, then tracks targets with per-object EKFs using uncertainty-aware data association. Compact track summaries are exchanged and fused conservatively via covariance intersection, ensuring consistency under unknown correlations. An information-driven assignment module allocates targets and selects UAV hover viewpoints by trading expected uncertainty reduction against travel effort and safety separation. Simulation results in a maritime scenario demonstrate improved coverage, localization accuracy, and tracking consistency while maintaining modest communication requirements.

</details>


### [99] [Adaptive-Horizon Conflict-Based Search for Closed-Loop Multi-Agent Path Finding](https://arxiv.org/abs/2602.12024)
*Jiarui Li,Federico Pecora,Runyu Zhang,Gioele Zardini*

Main category: cs.RO

TL;DR: ACCBS是一种基于有限时域CBS的闭环多智能体路径规划算法，通过动态调整规划时域和重用约束树，实现快速高质量解和渐近最优性


<details>
  <summary>Details</summary>
Motivation: 现有MAPF方法要么是开环规划器（生成固定轨迹，难以处理扰动），要么是闭环启发式方法（缺乏可靠性能保证），限制了在安全关键部署中的应用

Method: 基于有限时域CBS变体，采用受MPC迭代加深启发的时域变化机制，动态调整规划时域，重用单一约束树实现时域间无缝转换

Result: ACCBS能快速生成高质量可行解，随着计算预算增加具有渐近最优性，表现出随时性行为，在扰动下保持灵活性同时提供强性能保证

Conclusion: ACCBS有效弥合了理论最优性与实际鲁棒性之间的差距，为大规模机器人部署提供了兼具灵活性和性能保证的解决方案

Abstract: MAPF is a core coordination problem for large robot fleets in automated warehouses and logistics. Existing approaches are typically either open-loop planners, which generate fixed trajectories and struggle to handle disturbances, or closed-loop heuristics without reliable performance guarantees, limiting their use in safety-critical deployments. This paper presents ACCBS, a closed-loop algorithm built on a finite-horizon variant of CBS with a horizon-changing mechanism inspired by iterative deepening in MPC. ACCBS dynamically adjusts the planning horizon based on the available computational budget, and reuses a single constraint tree to enable seamless transitions between horizons. As a result, it produces high-quality feasible solutions quickly while being asymptotically optimal as the budget increases, exhibiting anytime behavior. Extensive case studies demonstrate that ACCBS combines flexibility to disturbances with strong performance guarantees, effectively bridging the gap between theoretical optimality and practical robustness for large-scale robot deployment.

</details>


### [100] [When would Vision-Proprioception Policies Fail in Robotic Manipulation?](https://arxiv.org/abs/2602.12032)
*Jingxian Lu,Wenke Xia,Yuxuan Wu,Zhiwu Lu,Di Hu*

Main category: cs.RO

TL;DR: 论文提出GAP算法解决视觉-本体感知策略中本体感知主导优化、抑制视觉学习的问题，通过基于运动转换阶段概率调整梯度，实现两种模态的动态协作。


<details>
  <summary>Details</summary>
Motivation: 视觉与本体感知的协作有望提升复杂操作任务的性能，但现有研究发现视觉-本体感知策略的泛化能力存在不一致性。研究发现，在机器人运动转换阶段（需要目标定位时），视觉模态作用有限，因为策略训练时倾向于依赖能更快降低损失的本体感知信号，从而抑制了视觉模态的学习。

Method: 提出梯度调整与阶段引导（GAP）算法：利用本体感知捕捉机器人状态，估计轨迹中每个时间步属于运动转换阶段的概率；在策略学习过程中，基于估计概率精细调整本体感知梯度的大小，减少其在优化中的主导作用，促进视觉模态的学习。

Result: GAP算法在仿真和真实环境中均适用，支持单臂和双臂设置，兼容传统模型和视觉-语言-动作模型，能够产生鲁棒且可泛化的视觉-本体感知策略。

Conclusion: GAP算法通过动态调整优化过程，解决了视觉-本体感知策略中模态不平衡问题，为机器人操作中视觉-本体感知策略的发展提供了有价值的见解。

Abstract: Proprioceptive information is critical for precise servo control by providing real-time robotic states. Its collaboration with vision is highly expected to enhance performances of the manipulation policy in complex tasks. However, recent studies have reported inconsistent observations on the generalization of vision-proprioception policies. In this work, we investigate this by conducting temporally controlled experiments. We found that during task sub-phases that robot's motion transitions, which require target localization, the vision modality of the vision-proprioception policy plays a limited role. Further analysis reveals that the policy naturally gravitates toward concise proprioceptive signals that offer faster loss reduction when training, thereby dominating the optimization and suppressing the learning of the visual modality during motion-transition phases. To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm that adaptively modulates the optimization of proprioception, enabling dynamic collaboration within the vision-proprioception policy. Specifically, we leverage proprioception to capture robotic states and estimate the probability of each timestep in the trajectory belonging to motion-transition phases. During policy learning, we apply fine-grained adjustment that reduces the magnitude of proprioception's gradient based on estimated probabilities, leading to robust and generalizable vision-proprioception policies. The comprehensive experiments demonstrate GAP is applicable in both simulated and real-world environments, across one-arm and dual-arm setups, and compatible with both conventional and Vision-Language-Action models. We believe this work can offer valuable insights into the development of vision-proprioception policies in robotic manipulation.

</details>


### [101] [Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis](https://arxiv.org/abs/2602.12047)
*Anutam Srinivasan,Antoine Leeman,Glen Chou*

Main category: cs.RO

TL;DR: 提出结合共形预测与系统级综合的鲁棒OOD规划框架，通过加权CP学习状态-控制依赖的协方差模型误差界，集成到SLS鲁棒非线性MPC中，实现分布漂移下的安全保证


<details>
  <summary>Details</summary>
Motivation: 解决在训练数据分布之外使用学习动力学模型时的安全与鲁棒性问题，传统方法在分布外场景下难以保证性能

Method: 1) 使用加权共形预测学习状态-控制依赖的协方差模型，推导高置信度模型误差界；2) 基于系统级综合的鲁棒非线性MPC，通过体积优化的前向可达集进行约束收紧；3) 理论分析分布漂移下的覆盖率和鲁棒性

Result: 在4D汽车和12D四旋翼等非线性系统上验证，相比固定边界和非鲁棒基线，在数据分布外显著提升了安全性和鲁棒性

Conclusion: 提出的CP-SLS框架能有效处理分布漂移，为学习动力学模型在OOD场景下的安全部署提供了理论保证和实用方法

Abstract: We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.

</details>


### [102] [HoloBrain-0 Technical Report](https://arxiv.org/abs/2602.12062)
*Xuewu Lin,Tianwei Lin,Yun Du,Hongyu Xie,Yiwei Jin,Jiawei Li,Shijie Wu,Qingze Wang,Mengdi Li,Mengao Zhao,Ziang Li,Chaodong Huang,Hongzhe Bi,Lichao Huang,Zhizhong Su*

Main category: cs.RO

TL;DR: HoloBrain-0是一个全面的视觉-语言-动作框架，通过结合机器人本体先验知识来增强3D空间推理，采用"预训练后微调"范式，在仿真和真实世界任务中取得SOTA结果，并开源了整个生态系统。


<details>
  <summary>Details</summary>
Motivation: 弥合基础模型研究与可靠真实世界机器人部署之间的差距，解决现有VLA系统缺乏机器人本体先验知识的问题，提升3D空间推理能力并支持多样化机器人本体。

Method: 提出新颖的VLA架构，显式结合机器人本体先验（多视角相机参数和运动学描述URDF）；采用可扩展的"预训练后微调"范式；开发完整的HoloBrain生态系统，包括预训练基础模型、微调检查点和RoboOrchard全栈基础设施。

Result: 在RoboTwin 2.0、LIBERO、GenieSim等仿真基准测试中取得SOTA结果；在具有挑战性的长时程真实世界操作任务中表现强劲；高效的0.2B参数变体可与更大基线模型竞争，支持低延迟设备端部署。

Conclusion: HoloBrain-0通过结合机器人本体先验知识显著提升了VLA系统的3D空间推理能力，其开源生态系统为社区提供了从数据收集到模型部署的完整可复现路径，推动了高性能机器人操作研究与实践。

Abstract: In this work, we introduce HoloBrain-0, a comprehensive Vision-Language-Action (VLA) framework that bridges the gap between foundation model research and reliable real-world robot deployment. The core of our system is a novel VLA architecture that explicitly incorporates robot embodiment priors, including multi-view camera parameters and kinematic descriptions (URDF), to enhance 3D spatial reasoning and support diverse embodiments. We validate this design through a scalable ``pre-train then post-train" paradigm, achieving state-of-the-art results on simulation benchmarks such as RoboTwin 2.0, LIBERO, and GenieSim, as well as strong results on challenging long-horizon real-world manipulation tasks. Notably, our efficient 0.2B-parameter variant rivals significantly larger baselines, enabling low-latency on-device deployment. To further accelerate research and practical adoption, we fully open-source the entire HoloBrain ecosystem, which includes: (1) powerful pre-trained VLA foundations; (2) post-trained checkpoints for multiple simulation suites and real-world tasks; and (3) RoboOrchard, a full-stack VLA infrastructure for data curation, model training and deployment. Together with standardized data collection protocols, this release provides the community with a complete, reproducible path toward high-performance robotic manipulation.

</details>


### [103] [VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model](https://arxiv.org/abs/2602.12063)
*Yanjiang Guo,Tony Lee,Lucy Xiaoyang Shi,Jianyu Chen,Percy Liang,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出迭代改进算法，利用真实世界数据提升世界模型保真度，进而生成合成数据改进VLA模型性能


<details>
  <summary>Details</summary>
Motivation: 现有世界模型在物理保真度上不足，特别是在接触丰富的物体操作中难以准确建模关键物理细节，限制了VLA模型的性能提升

Method: 提出简单迭代改进算法：使用真实世界rollout数据提升世界模型的保真度，然后用改进后的世界模型生成补充合成数据来训练VLA模型

Result: 在真实机器人实验中，相比基础策略获得39.2%的绝对成功率提升，相比仅使用生成合成rollout训练获得11.6%的额外提升

Conclusion: 通过迭代改进世界模型保真度并生成合成数据，可以有效提升VLA模型的性能和可靠性，特别是在真实机器人任务中

Abstract: The goal of this paper is to improve the performance and reliability of vision-language-action (VLA) models through iterative online interaction. Since collecting policy rollouts in the real world is expensive, we investigate whether a learned simulator-specifically, an action-conditioned video generation model-can be used to generate additional rollout data. Unfortunately, existing world models lack the physical fidelity necessary for policy improvement: they are predominantly trained on demonstration datasets that lack coverage of many different physical interactions (particularly failure cases) and struggle to accurately model small yet critical physical details in contact-rich object manipulation. We propose a simple iterative improvement algorithm that uses real-world roll-out data to improve the fidelity of the world model, which can then, in turn, be used to generate supplemental synthetic data for improving the VLA model. In our experiments on a real robot, we use this approach to improve the performance of a state-of-the-art VLA model on multiple downstream tasks. We achieve a 39.2% absolute success rate improvement over the base policy and 11.6% improvement from training with the generated synthetic rollouts. Videos can be found at this anonymous website: https://sites.google.com/view/vla-w

</details>


### [104] [Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning](https://arxiv.org/abs/2602.12065)
*Xiang Liu,Sen Cui,Guocai Yao,Zhong Cao,Jingheng Ma,Min Zhang,Changshui Zhang*

Main category: cs.RO

TL;DR: AGT-World：基于真实世界观察自主构建交互式仿真环境和机器人任务策略的统一框架，通过结构化任务图实现复杂目标的精确分层分解，结合自进化机制实现可扩展的机器人学习。


<details>
  <summary>Details</summary>
Motivation: 直接在真实世界训练机器人策略成本高且难以扩展。现有生成仿真方法难以生成逻辑一致的长时程任务，且在动态物理不确定性下开环执行效果不佳。

Method: 提出AGT-World框架：1）将任务空间形式化为结构化图，实现复杂目标的精确分层分解；2）引入结合视觉语言模型推理和几何验证的混合反馈自进化机制，自主优化策略。

Result: 大量实验表明，该方法在成功率和泛化能力上显著优于现有方法，实现了提案、执行和修正的自改进循环，支持可扩展的机器人学习。

Conclusion: AGT-World通过结构化任务图和自进化机制，解决了生成仿真中逻辑一致性和动态不确定性的挑战，为可扩展的机器人学习提供了有效框架。

Abstract: Training robotic policies directly in the real world is expensive and unscalable. Although generative simulation enables large-scale data synthesis, current approaches often fail to generate logically coherent long-horizon tasks and struggle with dynamic physical uncertainties due to open-loop execution. To address these challenges, we propose Affordance-Graphed Task Worlds (AGT-World), a unified framework that autonomously constructs interactive simulated environments and corresponding robot task policies based on real-world observations. Unlike methods relying on random proposals or static replication, AGT-World formalizes the task space as a structured graph, enabling the precise, hierarchical decomposition of complex goals into theoretically grounded atomic primitives. Furthermore, we introduce a Self-Evolution mechanism with hybrid feedback to autonomously refine policies, combining Vision-Language Model reasoning and geometric verification. Extensive experiments demonstrate that our method significantly outperforms in success rates and generalization, achieving a self-improving cycle of proposal, execution, and correction for scalable robot learning.

</details>


### [105] [RF-Modulated Adaptive Communication Improves Multi-Agent Robotic Exploration](https://arxiv.org/abs/2602.12074)
*Lorin Achey,Breanne Crockett,Christoffer Heckman,Bradley Hayes*

Main category: cs.RO

TL;DR: ART算法通过动态调整传输位置，基于信号强度和数据负载大小，实现异构机器人团队在通信受限环境中的高效信息共享，相比现有方法减少58%移动距离和52%探索时间。


<details>
  <summary>Details</summary>
Motivation: 在通信受限环境中，多机器人系统的可靠协调和高效通信是重大挑战，特别是在洞穴探索、行星探测和搜救任务中，需要解决信息共享效率问题。

Method: 提出自适应射频传输(ART)算法，动态调整传输位置基于信号强度和数据负载大小；进一步开发ART-SST扩展，强制执行信号强度阈值以确保高保真数据传输。

Result: 在三个洞穴式环境中进行480多次仿真，ART算法显著优于完整会合和最小信号启发式方法，减少58%移动距离和52%探索时间。

Conclusion: 自适应、负载感知的通信策略显著提高了复杂通信受限环境中的覆盖效率和任务速度，为未来行星探索和搜救任务提供了有前景的基础。

Abstract: Reliable coordination and efficient communication are critical challenges for multi-agent robotic exploration of environments where communication is limited. This work introduces Adaptive-RF Transmission (ART), a novel communication-aware planning algorithm that dynamically modulates transmission location based on signal strength and data payload size, enabling heterogeneous robot teams to share information efficiently without unnecessary backtracking. We further explore an extension to this approach called ART-SST, which enforces signal strength thresholds for high-fidelity data delivery. Through over 480 simulations across three cave-inspired environments, ART consistently outperforms existing strategies, including full rendezvous and minimum-signal heuristic approaches, achieving up to a 58% reduction in distance traveled and up to 52% faster exploration times compared to baseline methods. These results demonstrate that adaptive, payload-aware communication significantly improves coverage efficiency and mission speed in complex, communication-constrained environments, offering a promising foundation for future planetary exploration and search-and-rescue missions.

</details>


### [106] [Pack it in: Packing into Partially Filled Containers Through Contact](https://arxiv.org/abs/2602.12095)
*David Russell,Zisong Xu,Maximo A. Roa,Mehmet Dogar*

Main category: cs.RO

TL;DR: 提出一种接触感知的装箱方法，利用与已放置物体的有目的交互来创造空间，实现新物品的成功放置


<details>
  <summary>Details</summary>
Motivation: 仓库自动化对提高生产力和减少人员暴露于危险环境至关重要。现有装箱研究主要关注空容器装箱且采用无碰撞策略，但实际中容器通常已部分填充物品且排列不理想，需要处理已有物品的装箱问题

Method: 采用接触感知的装箱方法，包括：1) 基于接触的多物体轨迹优化器集成到模型预测控制器中；2) 物理感知的感知系统，即使在遮挡情况下也能估计物体姿态；3) 提出容器内物理可行放置位置的方法

Result: 通过有目的地与已放置物体交互来创造自由空间，成功实现了在部分填充容器中的物品放置

Conclusion: 接触感知的装箱方法能够有效处理实际仓库中常见的部分填充容器装箱问题，通过利用物理交互创造空间，提高了装箱的可行性和效率

Abstract: The automation of warehouse operations is crucial for improving productivity and reducing human exposure to hazardous environments. One operation frequently performed in warehouses is bin-packing where items need to be placed into containers, either for delivery to a customer, or for temporary storage in the warehouse. Whilst prior bin-packing works have largely been focused on packing items into empty containers and have adopted collision-free strategies, it is often the case that containers will already be partially filled with items, often in suboptimal arrangements due to transportation about a warehouse. This paper presents a contact-aware packing approach that exploits purposeful interactions with previously placed objects to create free space and enable successful placement of new items. This is achieved by using a contact-based multi-object trajectory optimizer within a model predictive controller, integrated with a physics-aware perception system that estimates object poses even during inevitable occlusions, and a method that suggests physically-feasible locations to place the object inside the container.

</details>


### [107] [Multi Graph Search for High-Dimensional Robot Motion Planning](https://arxiv.org/abs/2602.12096)
*Itamar Mishani,Maxim Likhachev*

Main category: cs.RO

TL;DR: MGS是一种多图搜索运动规划算法，将经典单向和双向搜索推广到多图设置，通过维护多个隐式图并增量扩展，专注于高潜力区域探索，实现高效的高维机器人运动规划。


<details>
  <summary>Details</summary>
Motivation: 高维机器人系统（如机械臂和移动机械臂）的高效运动规划对实时操作和可靠部署至关重要。现有规划算法虽然提高了高维状态空间的可扩展性，但往往以生成不可预测、不一致的运动或需要过多计算资源和内存为代价。

Method: 提出多图搜索（MGS）算法，将经典单向和双向搜索推广到多图设置。MGS维护并增量扩展状态空间上的多个隐式图，专注于高潜力区域探索，同时允许初始断开的子图在搜索过程中通过可行转换合并。

Result: 证明了MGS的完备性和有界次优性，并通过一系列操作和移动操作任务的实证研究展示了其有效性。提供了演示、基准测试和代码。

Conclusion: MGS算法为高维机器人系统提供了一种高效的运动规划解决方案，在保持算法完备性和有界次优性的同时，提高了规划效率并减少了计算资源需求。

Abstract: Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.

</details>


### [108] [3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting](https://arxiv.org/abs/2602.12159)
*Wancai Zheng,Hao Chen,Xianlong Lu,Linlin Ou,Xinyi Yu*

Main category: cs.RO

TL;DR: 3DGSNav：一种新颖的零样本物体导航框架，利用3D高斯泼溅作为视觉语言模型的持久记忆，通过主动感知和轨迹引导的自由视点渲染增强空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有零样本物体导航方法依赖场景抽象（如语义地图或文本表示），导致高级决策受限于低级感知的准确性。需要一种能更好支持空间推理的方法。

Method: 1. 使用3D高斯泼溅作为VLMs的持久记忆，通过主动感知增量构建环境表示；2. 轨迹引导的自由视点渲染生成边界感知的第一人称视图；3. 结构化视觉提示与思维链提示结合增强VLM推理；4. 实时目标检测器筛选潜在目标，VLM驱动的主动视点切换进行目标重新验证。

Result: 在多个基准测试和四足机器人的真实世界实验中，该方法展现出稳健且具有竞争力的性能，优于现有最先进方法。

Conclusion: 3DGSNav通过将3D高斯泼溅作为持久记忆集成到VLMs中，显著提升了零样本物体导航的空间推理能力，实现了高效可靠的目标识别和导航。

Abstract: Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/

</details>


### [109] [Sub--Riemannian boundary value problems for Optimal Geometric Locomotion](https://arxiv.org/abs/2602.12199)
*Oliver Gross,Florine Hartwig,Martin Rumpf,Peter Schröder*

Main category: cs.RO

TL;DR: 提出几何模型用于细长运动体的最优形状变化诱导运动，通过子黎曼测地线求解边界值问题，同时考虑环境位移能耗和形状变化能耗。


<details>
  <summary>Details</summary>
Motivation: 研究蛇类在沙地滑行等场景中，细长运动体的最优形状变化诱导运动。传统模型往往只考虑环境位移能耗，而忽略了动物代谢或机器人执行器进行弯曲、拉伸等形状变化所需的能量，无法全面评估运动效率。

Method: 建立几何模型，将拉格朗日最小耗散原理表述为边界值问题，其解由子黎曼测地线给出。模型同时考虑环境位移能耗和形状变化能耗。采用一致的时空离散化，数值计算三种边界条件下的子黎曼测地线：固定初始和目标身体、限制为循环运动、仅规定身体位移和方向。

Result: 最优变形步态在质量上与观察到的蛇和精子等生物的运动轨迹相匹配，也与低维系统（如Purcell游泳者）的已知最优性结果一致。相比先前框架，几何约束更少，能够为广义Purcell游泳者等系统提供新的运动机制见解。代码已公开。

Conclusion: 提出的几何模型能够全面捕捉细长运动体的整体运动效率，为生物运动分析和机器人设计提供了新的理论框架和计算工具。

Abstract: We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.

</details>


### [110] [LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion](https://arxiv.org/abs/2602.12215)
*Jiangran Lyu,Kai Liu,Xuheng Zhang,Haoran Liao,Yusen Feng,Wenxuan Zhu,Tingrui Shen,Jiayi Chen,Jiazhao Zhang,Yifei Dong,Wenbo Cui,Senmao Qi,Shuo Wang,Yixin Zheng,Mi Yan,Xuesong Shi,Haoran Li,Dongbin Zhao,Ming-Yu Liu,Zhizheng Zhang,Li Yi,Yizhou Wang,He Wang*

Main category: cs.RO

TL;DR: LDA-1B是一个通过统一世界模型框架，联合学习动力学、策略和视觉预测的机器人基础模型，在异构体数据上实现了规模化训练，在多种任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型主要依赖大规模行为克隆，这丢弃了异构体数据中可迁移的动力学知识。统一世界模型有潜力利用这种多样化数据，但现有实现因数据使用粗糙和数据集碎片化而难以扩展到基础模型级别。

Method: 提出LDA-1B模型，通过联合学习动力学、策略和视觉预测，为不同质量数据分配不同角色。使用结构化DINO潜在空间进行预测以避免冗余像素建模，采用多模态扩散变换器处理异步视觉和动作流，支持10亿参数规模训练。构建了EI-30k数据集（3万小时人类和机器人轨迹的统一格式数据）。

Result: 在仿真和真实世界实验中，LDA-1B在接触丰富任务上优于先前方法21%，灵巧任务上48%，长时域任务上23%。特别地，LDA-1B实现了数据高效微调，利用30%通常有害的低质量轨迹获得了10%的性能提升。

Conclusion: LDA-1B通过统一世界模型框架成功实现了机器人基础模型的规模化，有效利用了异构体数据中的动力学知识，在多种任务上取得了显著性能提升，并展示了处理低质量数据的能力。

Abstract: Recent robot foundation models largely rely on large-scale behavior cloning, which imitates expert actions but discards transferable dynamics knowledge embedded in heterogeneous embodied data. While the Unified World Model (UWM) formulation has the potential to leverage such diverse data, existing instantiations struggle to scale to foundation-level due to coarse data usage and fragmented datasets. We introduce LDA-1B, a robot foundation model that scales through universal embodied data ingestion by jointly learning dynamics, policy, and visual forecasting, assigning distinct roles to data of varying quality. To support this regime at scale, we assemble and standardize EI-30k, an embodied interaction dataset comprising over 30k hours of human and robot trajectories in a unified format. Scalable dynamics learning over such heterogeneous data is enabled by prediction in a structured DINO latent space, which avoids redundant pixel-space appearance modeling. Complementing this representation, LDA-1B employs a multi-modal diffusion transformer to handle asynchronous vision and action streams, enabling stable training at the 1B-parameter scale. Experiments in simulation and the real world show LDA-1B outperforms prior methods (e.g., $π_{0.5}$) by up to 21\%, 48\%, and 23\% on contact-rich, dexterous, and long-horizon tasks, respectively. Notably, LDA-1B enables data-efficient fine-tuning, gaining 10\% by leveraging 30\% low-quality trajectories typically harmful and discarded.

</details>


### [111] [Any House Any Task: Scalable Long-Horizon Planning for Abstract Human Tasks](https://arxiv.org/abs/2602.12244)
*Zhihong Liu,Yang Li,Rengming Huang,Cewu Lu,Panpan Cai*

Main category: cs.RO

TL;DR: AHAT是一个用于家庭环境中开放世界语言条件任务规划的系统，通过训练LLM将任务指令和场景图映射到PDDL子目标，结合符号推理生成长时程规划，并使用TGPO强化学习算法提升对复杂模糊意图的分解能力。


<details>
  <summary>Details</summary>
Motivation: 开放世界语言条件任务规划对于机器人在大规模家庭环境中操作至关重要。现有基于LLM的方法在环境规模增大、规划长度增加、指令模糊性和约束复杂性提高时性能会急剧下降，存在可扩展性挑战。

Method: AHAT的核心是训练LLM将任务指令和文本场景图映射到基于PDDL的接地子目标，然后通过显式符号推理生成可行且最优的长时程规划。为了增强模型分解复杂模糊意图的能力，提出了TGPO强化学习算法，将中间推理轨迹的外部校正集成到GRPO中。

Result: 实验表明，AHAT在性能上显著优于最先进的提示、规划和学习方法，特别是在人类风格的家庭任务中表现突出，这些任务通常指令简短但需要复杂的执行计划。

Conclusion: AHAT通过结合LLM的语义理解能力和符号推理的精确性，有效解决了大规模家庭环境中长时程任务规划的可扩展性问题，TGPO算法进一步提升了处理模糊复杂意图的能力。

Abstract: Open world language conditioned task planning is crucial for robots operating in large-scale household environments. While many recent works attempt to address this problem using Large Language Models (LLMs) via prompting or training, a key challenge remains scalability. Performance often degrades rapidly with increasing environment size, plan length, instruction ambiguity, and constraint complexity. In this work, we propose Any House Any Task (AHAT), a household task planner optimized for long-horizon planning in large environments given ambiguous human instructions. At its core, AHAT utilizes an LLM trained to map task instructions and textual scene graphs into grounded subgoals defined in the Planning Domain Definition Language (PDDL). These subgoals are subsequently solved to generate feasible and optimal long-horizon plans through explicit symbolic reasoning. To enhance the model's ability to decompose complex and ambiguous intentions, we introduce TGPO, a novel reinforcement learning algorithm that integrates external correction of intermediate reasoning traces into Group Relative Policy Optimization (GRPO). Experiments demonstrate that AHAT achieves significant performance gains over state-of-the-art prompting, planning, and learning methods, particularly in human-style household tasks characterized by brief instructions but requiring complex execution plans.

</details>


### [112] [Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment](https://arxiv.org/abs/2602.12281)
*Jacky Kwok,Xilun Zhang,Mengdi Xu,Yuejiang Liu,Azalia Mirhoseini,Chelsea Finn,Marco Pavone*

Main category: cs.RO

TL;DR: 提出CoVer验证框架，通过测试时重述指令和生成多样化动作候选，利用对比验证器缩小VLA模型的意图-动作差距，显著提升任务执行性能。


<details>
  <summary>Details</summary>
Motivation: 尽管VLA模型在自然语言指令理解方面取得进展，但生成的行动仍可能与指令意图存在偏差（意图-动作差距）。需要一种测试时验证方法来提高指令跟随的准确性和鲁棒性。

Method: 提出CoVer对比验证器，采用"启动时计算"和分层验证推理流程：1) 使用VLM预计算多样化的重述指令；2) 为每个指令重复生成动作候选；3) 使用验证器选择最优的高层提示和低层动作块。

Result: 在SIMPLER基准上，相比策略预训练方法，验证方法带来22%的分布内提升和13%的分布外提升，真实世界实验进一步改善45%。在PolaRiS基准上，CoVer实现14%的任务进度提升和9%的成功率提升。

Conclusion: 测试时验证是缩小VLA模型意图-动作差距的有效方法，通过联合扩展重述指令和生成动作的多样性，结合对比验证器架构，能够显著提升机器人指令跟随的性能。

Abstract: The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce "boot-time compute" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.

</details>
