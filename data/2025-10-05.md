<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 41]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Kilometer-Scale GNSS-Denied UAV Navigation via Heightmap Gradients: A Winning System from the SPRIN-D Challenge](https://arxiv.org/abs/2510.01348)
*Michal Werner,David Čapek,Tomáš Musil,Ondřej Franěk,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种在GNSS拒止环境下实现无人机长距离自主飞行的系统，通过激光雷达高度图匹配和粒子滤波来校正漂移，在嵌入式平台上实时运行


<details>
  <summary>Details</summary>
Motivation: 解决无人机在GNSS拒止环境中长距离飞行时的定位漂移问题，特别是在没有先验密集地图和有限计算资源的情况下

Method: 集成感知、建图、规划和控制的系统，采用轻量级漂移校正方法，通过梯度模板匹配将激光雷达局部高度图与先验地理数据高度图匹配，并使用聚类粒子滤波将证据与里程计融合

Result: 在竞赛中执行了公里级飞行，跨越城市、森林和开阔地带，相对于原始里程计显著减少了漂移，在仅使用CPU的硬件上实时运行

Conclusion: 该系统为GNSS拒止环境下的无人机自主飞行提供了实用的设计见解，证明了在有限计算资源下实现可靠长距离导航的可行性

Abstract: Reliable long-range flight of unmanned aerial vehicles (UAVs) in GNSS-denied
environments is challenging: integrating odometry leads to drift, loop closures
are unavailable in previously unseen areas and embedded platforms provide
limited computational power. We present a fully onboard UAV system developed
for the SPRIN-D Funke Fully Autonomous Flight Challenge, which required 9 km
long-range waypoint navigation below 25 m AGL (Above Ground Level) without GNSS
or prior dense mapping. The system integrates perception, mapping, planning,
and control with a lightweight drift-correction method that matches
LiDAR-derived local heightmaps to a prior geo-data heightmap via
gradient-template matching and fuses the evidence with odometry in a clustered
particle filter. Deployed during the competition, the system executed
kilometer-scale flights across urban, forest, and open-field terrain and
reduced drift substantially relative to raw odometry, while running in real
time on CPU-only hardware. We describe the system architecture, the
localization pipeline, and the competition evaluation, and we report practical
insights from field deployment that inform the design of GNSS-denied UAV
autonomy.

</details>


### [2] [Safe Motion Planning and Control Using Predictive and Adaptive Barrier Methods for Autonomous Surface Vessels](https://arxiv.org/abs/2510.01357)
*Alejandro Gonzalez-Garcia,Wei Xiao,Wei Wang,Alejandro Astudillo,Wilm Decré,Jan Swevers,Carlo Ratti,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种结合模型预测控制(MPC)和控制屏障函数(CBFs)的安全运动规划策略，用于自主船舶在狭窄内河水道的导航，通过时变膨胀椭圆障碍物表示来减少保守性。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在狭窄内河水道等挑战性空间中通常计算密集或过于保守，需要一种既能确保安全又能实时导航的解决方案。

Method: 使用MPC提供近似运动规划，结合高阶CBFs确保安全，采用时变膨胀椭圆障碍物表示，根据船舶与障碍物的相对位置和姿态调整膨胀半径。

Result: 仿真和真实世界实验表明，该策略使全驱动自主机器人船舶能够实时导航狭窄空间，解决潜在死锁，同时确保安全。

Conclusion: 提出的自适应膨胀方法相比传统固定椭圆障碍物表述减少了控制器的保守性，为自主船舶在狭窄水道中的安全导航提供了有效解决方案。

Abstract: Safe motion planning is essential for autonomous vessel operations,
especially in challenging spaces such as narrow inland waterways. However,
conventional motion planning approaches are often computationally intensive or
overly conservative. This paper proposes a safe motion planning strategy
combining Model Predictive Control (MPC) and Control Barrier Functions (CBFs).
We introduce a time-varying inflated ellipse obstacle representation, where the
inflation radius is adjusted depending on the relative position and attitude
between the vessel and the obstacle. The proposed adaptive inflation reduces
the conservativeness of the controller compared to traditional fixed-ellipsoid
obstacle formulations. The MPC solution provides an approximate motion plan,
and high-order CBFs ensure the vessel's safety using the varying inflation
radius. Simulation and real-world experiments demonstrate that the proposed
strategy enables the fully-actuated autonomous robot vessel to navigate through
narrow spaces in real time and resolve potential deadlocks, all while ensuring
safety.

</details>


### [3] [A Stochastic Framework for Continuous-Time State Estimation of Continuum Robots](https://arxiv.org/abs/2510.01381)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种基于因子图优化的连续时间随机状态估计框架，用于连续体机器人的状态估计，能够适应未建模的外部力和数据丢失。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人状态估计方法通常使用计算复杂的动态模型、简化的形状近似或仅限于准静态方法，这些方法对未建模的干扰敏感。

Method: 基于连续时间运动学构建因子图，引入受白噪声高斯过程影响的因子，结合简单机器人模型和高速率传感实现状态估计。

Result: 该方法能够估计机器人位姿、速度和应变的均值和协方差，可在时间或空间上连续插值，计算复杂度与时间呈线性关系。

Conclusion: 该方法在具有陀螺仪和位姿传感器的连续体机器人上验证了其在实际系统中的多功能性。

Abstract: State estimation techniques for continuum robots (CRs) typically involve
using computationally complex dynamic models, simplistic shape approximations,
or are limited to quasi-static methods. These limitations can be sensitive to
unmodelled disturbances acting on the robot. Inspired by a factor-graph
optimization paradigm, this work introduces a continuous-time stochastic state
estimation framework for continuum robots. We introduce factors based on
continuous-time kinematics that are corrupted by a white noise Gaussian process
(GP). By using a simple robot model paired with high-rate sensing, we show
adaptability to unmodelled external forces and data dropout. The result
contains an estimate of the mean and covariance for the robot's pose, velocity,
and strain, each of which can be interpolated continuously in time or space.
This same interpolation scheme can be used during estimation, allowing for
inclusion of measurements on states that are not explicitly estimated. Our
method's inherent sparsity leads to a linear solve complexity with respect to
time and interpolation queries in constant time. We demonstrate our method on a
CR with gyroscope and pose sensors, highlighting its versatility in real-world
systems.

</details>


### [4] [VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation](https://arxiv.org/abs/2510.01388)
*Arthur Zhang,Xiangyun Meng,Luca Calliari,Dong-Ki Kim,Shayegan Omidshafiei,Joydeep Biswas,Ali Agha,Amirreza Shaban*

Main category: cs.RO

TL;DR: VENTURA是一个视觉语言导航系统，通过微调互联网预训练的扩散模型进行路径规划，生成视觉路径掩码，再由轻量级策略执行轨迹，实现自然语言指令下的多样化机器人行为。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型在机器人导航任务中由于动作空间差异和预训练目标不同而难以迁移的问题，使机器人能够适应多样化的人类指令并在非结构化环境中安全操作。

Method: 使用自监督跟踪模型生成路径掩码，配合VLM增强的标注进行训练，避免手动像素级标注；通过图像扩散模型生成视觉路径规划，再由行为克隆策略转化为可执行轨迹。

Result: 在真实世界评估中，VENTURA在物体到达、障碍物避让和地形偏好任务上优于最先进的基础模型基线，成功率提高33%，碰撞减少54%，并能泛化到未见过的任务组合。

Conclusion: VENTURA展示了在机器人导航中生成视觉路径规划的有效性，具备新兴的组合能力，能够泛化到新的任务组合场景。

Abstract: Robots must adapt to diverse human instructions and operate safely in
unstructured, open-world environments. Recent Vision-Language models (VLMs)
offer strong priors for grounding language and perception, but remain difficult
to steer for navigation due to differences in action spaces and pretraining
objectives that hamper transferability to robotics tasks. Towards addressing
this, we introduce VENTURA, a vision-language navigation system that finetunes
internet-pretrained image diffusion models for path planning. Instead of
directly predicting low-level actions, VENTURA generates a path mask (i.e. a
visual plan) in image space that captures fine-grained, context-aware
navigation behaviors. A lightweight behavior-cloning policy grounds these
visual plans into executable trajectories, yielding an interface that follows
natural language instructions to generate diverse robot behaviors. To scale
training, we supervise on path masks derived from self-supervised tracking
models paired with VLM-augmented captions, avoiding manual pixel-level
annotation or highly engineered data collection setups. In extensive real-world
evaluations, VENTURA outperforms state-of-the-art foundation model baselines on
object reaching, obstacle avoidance, and terrain preference tasks, improving
success rates by 33% and reducing collisions by 54% across both seen and unseen
scenarios. Notably, we find that VENTURA generalizes to unseen combinations of
distinct tasks, revealing emergent compositional capabilities. Videos, code,
and additional materials: https://venturapath.github.io

</details>


### [5] [INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models](https://arxiv.org/abs/2510.01389)
*Ulas Berk Karli,Ziyao Shangguan,Tesca FItzgerald*

Main category: cs.RO

TL;DR: INSIGHT框架利用token级不确定性信号来预测VLA模型何时需要请求人类帮助，通过训练紧凑的Transformer分类器来映射不确定性序列到帮助触发信号。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型缺乏内省机制来预测失败并请求人类监督，需要开发能够主动识别不确定性并寻求帮助的机制。

Method: 使用π₀-FAST作为基础模型，提取每个token的熵、对数概率以及基于Dirichlet的偶然和认知不确定性估计，训练Transformer分类器来映射这些序列到帮助触发信号。

Result: 研究显示强监督标签能捕捉细粒度不确定性动态以实现可靠的帮助检测，而弱监督标签虽然噪声较多，但在训练和评估对齐时仍能提供有竞争力的内省能力。

Conclusion: 建模token级不确定性信号的时间演化比静态序列级分数具有更强的预测能力，为VLA中的主动学习和实时错误缓解开辟了新途径。

Abstract: Recent Vision-Language-Action (VLA) models show strong generalization
capabilities, yet they lack introspective mechanisms for anticipating failures
and requesting help from a human supervisor. We present \textbf{INSIGHT}, a
learning framework for leveraging token-level uncertainty signals to predict
when a VLA should request help. Using $\pi_0$-FAST as the underlying model, we
extract per-token \emph{entropy}, \emph{log-probability}, and Dirichlet-based
estimates of \emph{aleatoric and epistemic uncertainty}, and train compact
transformer classifiers to map these sequences to help triggers. We explore
supervision regimes for strong or weak supervision, and extensively compare
them across in-distribution and out-of-distribution tasks. Our results show a
trade-off: strong labels enable models to capture fine-grained uncertainty
dynamics for reliable help detection, while weak labels, though noisier, still
support competitive introspection when training and evaluation are aligned,
offering a scalable path when dense annotation is impractical. Crucially, we
find that modeling the temporal evolution of token-level uncertainty signals
with transformers provides far greater predictive power than static
sequence-level scores. This study provides the first systematic evaluation of
uncertainty-based introspection in VLAs, opening future avenues for active
learning and for real-time error mitigation through selective human
intervention.

</details>


### [6] [Beyond Collision Cones: Dynamic Obstacle Avoidance for Nonholonomic Robots via Dynamic Parabolic Control Barrier Functions](https://arxiv.org/abs/2510.01402)
*Hun Kuk Park,Taekyung Kim,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出动态抛物线控制屏障函数(DPCBF)来解决非完整机器人在密集动态环境中CBF应用的安全性和可行性问题，相比基于碰撞锥的方法显著提高了导航成功率和QP可行性。


<details>
  <summary>Details</summary>
Motivation: 现有CBF方法在非完整机器人密集动态环境中过于保守，基于碰撞锥或速度障碍的约束仅考虑相对速度角度，导致QP不可行，特别是在密集场景中。

Method: 提出动态抛物线控制屏障函数(DPCBF)，使用抛物线边界定义安全集，抛物线的顶点和曲率根据障碍物距离和相对速度大小动态调整，创建限制更少的安全约束。

Result: DPCBF控制器显著提高了导航成功率和QP可行性，在多达100个动态障碍物的密集环境中成功导航，而基于碰撞锥的方法因不可行性而失败。

Conclusion: DPCBF方法有效解决了非完整机器人在密集动态环境中的安全导航问题，相比传统方法具有更好的性能和可行性。

Abstract: Control Barrier Functions (CBFs) are a powerful tool for ensuring the safety
of autonomous systems, yet applying them to nonholonomic robots in cluttered,
dynamic environments remains an open challenge. State-of-the-art methods often
rely on collision-cone or velocity-obstacle constraints which, by only
considering the angle of the relative velocity, are inherently conservative and
can render the CBF-based quadratic program infeasible, particularly in dense
scenarios. To address this issue, we propose a Dynamic Parabolic Control
Barrier Function (DPCBF) that defines the safe set using a parabolic boundary.
The parabola's vertex and curvature dynamically adapt based on both the
distance to an obstacle and the magnitude of the relative velocity, creating a
less restrictive safety constraint. We prove that the proposed DPCBF is valid
for a kinematic bicycle model subject to input constraints. Extensive
comparative simulations demonstrate that our DPCBF-based controller
significantly enhances navigation success rates and QP feasibility compared to
baseline methods. Our approach successfully navigates through dense
environments with up to 100 dynamic obstacles, scenarios where collision
cone-based methods fail due to infeasibility.

</details>


### [7] [How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?](https://arxiv.org/abs/2510.01404)
*Lexi Foland,Thomas Cohn,Adam Wei,Nicholas Pfaff,Boyuan Chen,Russ Tedrake*

Main category: cs.RO

TL;DR: 本文研究了扩散策略在机器人模仿学习中学习运动学约束的能力，通过双手拾取任务案例分析了数据集大小、质量和流形曲率对策略学习的影响。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散策略在机器人模仿学习中表现出色，但任务性能并不能可靠反映策略精确学习训练数据中约束的能力，因此需要研究扩散策略如何发现这些约束流形。

Method: 通过双手拾取放置任务的案例研究，分析三个因素对训练策略的影响：数据集大小、数据集质量和流形曲率，并在硬件上进行评估验证。

Result: 扩散策略能够学习约束流形的粗略近似，学习效果受数据集大小和质量下降的负面影响，而流形曲率与约束满足和任务成功的关系不明确。

Conclusion: 扩散策略能够近似学习运动学约束，但学习效果受数据质量影响，硬件评估验证了结果的现实适用性。

Abstract: Diffusion policies have shown impressive results in robot imitation learning,
even for tasks that require satisfaction of kinematic equality constraints.
However, task performance alone is not a reliable indicator of the policy's
ability to precisely learn constraints in the training data. To investigate, we
analyze how well diffusion policies discover these manifolds with a case study
on a bimanual pick-and-place task that encourages fulfillment of a kinematic
constraint for success. We study how three factors affect trained policies:
dataset size, dataset quality, and manifold curvature. Our experiments show
diffusion policies learn a coarse approximation of the constraint manifold with
learning affected negatively by decreases in both dataset size and quality. On
the other hand, the curvature of the constraint manifold showed inconclusive
correlations with both constraint satisfaction and task success. A hardware
evaluation verifies the applicability of our results in the real world. Project
website with additional results and visuals:
https://diffusion-learns-kinematic.github.io

</details>


### [8] [AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation](https://arxiv.org/abs/2510.01433)
*Anukriti Singh,Kasra Torshizi,Khuzema Habib,Kelin Yu,Ruohan Gao,Pratap Tokekar*

Main category: cs.RO

TL;DR: AFFORD2ACT是一个基于affordance的轻量级机器人学习框架，通过文本提示和单张图像提取语义2D关键点，构建紧凑的38维状态策略，在15分钟内完成训练，并在各种真实世界操作任务中实现82%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉机器人学习方法依赖密集图像或点云输入，计算量大且包含无关背景特征；基于关键点的方法虽然轻量但依赖手动启发式或任务耦合选择，限制了可扩展性和语义理解。

Method: 采用三阶段流程：affordance过滤、类别级关键点构建、基于transformer的策略学习（包含嵌入式门控机制来推理最相关的关键点）。

Result: 在多样化真实世界操作任务中，AFFORD2ACT显著提高了数据效率，在未见过的物体、新类别、背景和干扰物上达到82%的成功率。

Conclusion: AFFORD2ACT框架通过affordance引导的关键点提取和紧凑策略学习，实现了高效、轻量且可扩展的机器人操作，无需本体感知或密集表示即可在实时环境中良好运行。

Abstract: Vision-based robot learning often relies on dense image or point-cloud
inputs, which are computationally heavy and entangle irrelevant background
features. Existing keypoint-based approaches can focus on manipulation-centric
features and be lightweight, but either depend on manual heuristics or
task-coupled selection, limiting scalability and semantic understanding. To
address this, we propose AFFORD2ACT, an affordance-guided framework that
distills a minimal set of semantic 2D keypoints from a text prompt and a single
image. AFFORD2ACT follows a three-stage pipeline: affordance filtering,
category-level keypoint construction, and transformer-based policy learning
with embedded gating to reason about the most relevant keypoints, yielding a
compact 38-dimensional state policy that can be trained in 15 minutes, which
performs well in real-time without proprioception or dense representations.
Across diverse real-world manipulation tasks, AFFORD2ACT consistently improves
data efficiency, achieving an 82% success rate on unseen objects, novel
categories, backgrounds, and distractors.

</details>


### [9] [Differentiable Skill Optimisation for Powder Manipulation in Laboratory Automation](https://arxiv.org/abs/2510.01438)
*Minglun Wei,Xintong Yang,Yu-Kun Lai,Ze Ji*

Main category: cs.RO

TL;DR: 提出了一种用于实验室粉末运输的轨迹优化框架，结合可微分物理模拟、低维技能空间参数化和课程学习策略，实现接触丰富的机器人轨迹端到端优化。


<details>
  <summary>Details</summary>
Motivation: 机器人自动化加速科学发现，但粉末精确操作仍具挑战性，特别是在需要准确性和稳定性的运输任务中。

Method: 使用可微分物理模拟精确建模颗粒动力学，采用低维技能空间参数化降低优化复杂度，结合课程学习策略逐步提升长期任务能力。

Result: 实验结果表明，该方法在任务成功率和稳定性方面优于强化学习基线。

Conclusion: 该框架能够实现接触丰富机器人轨迹的端到端优化，同时保持稳定性和收敛效率。

Abstract: Robotic automation is accelerating scientific discovery by reducing manual
effort in laboratory workflows. However, precise manipulation of powders
remains challenging, particularly in tasks such as transport that demand
accuracy and stability. We propose a trajectory optimisation framework for
powder transport in laboratory settings, which integrates differentiable
physics simulation for accurate modelling of granular dynamics, low-dimensional
skill-space parameterisation to reduce optimisation complexity, and a
curriculum-based strategy that progressively refines task competence over long
horizons. This formulation enables end-to-end optimisation of contact-rich
robot trajectories while maintaining stability and convergence efficiency.
Experimental results demonstrate that the proposed method achieves superior
task success rates and stability compared to the reinforcement learning
baseline.

</details>


### [10] [Touching the tumor boundary: A pilot study on ultrasound based virtual fixtures for breast-conserving surgery](https://arxiv.org/abs/2510.01452)
*Laura Connolly,Tamas Ungi,Adnan Munawar,Anton Deguet,Chris Yeung,Russell H. Taylor,Parvin Mousavi,Gabor Fichtinger Keyvan Hashtrudi-Zaad*

Main category: cs.RO

TL;DR: 开发了一种带有触觉反馈的协作机器人引导系统，用于在保乳手术中定位肿瘤边界，通过模拟实验验证了该系统能改善切除边缘并降低手术难度。


<details>
  <summary>Details</summary>
Motivation: 保乳手术中肿瘤边界定位困难，因为肿瘤通常高度移动、不可触及且边界不规则，需要开发新技术来改善手术精度。

Method: 将小型触觉机器人改装为电灼刀，结合超声和电磁导航识别肿瘤边界，设置禁区虚拟夹具，在模拟乳腺模型上进行有/无触觉引导的切除对比研究。

Result: 虚拟夹具引导改善了切除边缘，用户反馈使用触觉反馈时任务的心理需求、挫败感和努力程度都显著降低，但也发现了一些对手术流程的意外影响。

Conclusion: 虚拟夹具能在模拟保乳手术中帮助定位肿瘤边界，未来将进行更广泛的用户研究来进一步验证结果并优化引导系统。

Abstract: Purpose: Delineating tumor boundaries during breast-conserving surgery is
challenging as tumors are often highly mobile, non-palpable, and have
irregularly shaped borders. To address these challenges, we introduce a
cooperative robotic guidance system that applies haptic feedback for tumor
localization. In this pilot study, we aim to assess if and how this system can
be successfully integrated into breast cancer care.
  Methods: A small haptic robot is retrofitted with an electrocautery blade to
operate as a cooperatively controlled surgical tool. Ultrasound and
electromagnetic navigation are used to identify the tumor boundaries and
position. A forbidden region virtual fixture is imposed when the surgical tool
collides with the tumor boundary. We conducted a study where users were asked
to resect tumors from breast simulants both with and without the haptic
guidance. We then assess the results of these simulated resections both
qualitatively and quantitatively.
  Results: Virtual fixture guidance is shown to improve resection margins. On
average, users find the task to be less mentally demanding, frustrating, and
effort intensive when haptic feedback is available. We also discovered some
unanticipated impacts on surgical workflow that will guide design adjustments
and training protocol moving forward.
  Conclusion: Our results suggest that virtual fixtures can help localize tumor
boundaries in simulated breast-conserving surgery. Future work will include an
extensive user study to further validate these results and fine-tune our
guidance system.

</details>


### [11] [VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs](https://arxiv.org/abs/2510.01483)
*Mohamad Al Mdfaa,Svetlana Lukina,Timur Akhtyamov,Arthur Nigmatzyanov,Dmitrii Nalberskii,Sergey Zagoruyko,Gonzalo Ferrer*

Main category: cs.RO

TL;DR: VL-KnG是一个视觉场景理解系统，通过时空知识图谱构建和高效查询处理来解决机器人导航中视觉语言模型的局限性，在真实机器人部署中达到77.27%的成功率和76.92%的答案准确率。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在机器人导航中存在三个基本限制：缺乏持久场景记忆、空间推理能力有限、无法有效扩展视频时长以支持实时应用。

Method: 采用分块处理视频序列，利用现代视觉语言模型构建持久知识图谱，通过可查询图结构实现可解释的空间推理。

Result: 在真实差分驱动机器人上部署，达到77.27%成功率和76.92%答案准确率，性能与Gemini 2.5 Pro相当，同时提供可解释推理和计算效率。

Conclusion: VL-KnG系统成功解决了视觉语言模型在机器人导航中的关键限制，实现了可解释、高效且可扩展的视觉场景理解，适用于定位、导航和规划等任务。

Abstract: Vision-language models (VLMs) have shown potential for robot navigation but
encounter fundamental limitations: they lack persistent scene memory, offer
limited spatial reasoning, and do not scale effectively with video duration for
real-time application. We present VL-KnG, a Visual Scene Understanding system
that tackles these challenges using spatiotemporal knowledge graph construction
and computationally efficient query processing for navigation goal
identification. Our approach processes video sequences in chunks utilizing
modern VLMs, creates persistent knowledge graphs that maintain object identity
over time, and enables explainable spatial reasoning through queryable graph
structures. We also introduce WalkieKnowledge, a new benchmark with about 200
manually annotated questions across 8 diverse trajectories spanning
approximately 100 minutes of video data, enabling fair comparison between
structured approaches and general-purpose VLMs. Real-world deployment on a
differential drive robot demonstrates practical applicability, with our method
achieving 77.27% success rate and 76.92% answer accuracy, matching Gemini 2.5
Pro performance while providing explainable reasoning supported by the
knowledge graph, computational efficiency for real-time deployment across
different tasks, such as localization, navigation and planning. Code and
dataset will be released after acceptance.

</details>


### [12] [Pose Estimation of a Thruster-Driven Bioinspired Multi-Link Robot](https://arxiv.org/abs/2510.01485)
*Nicholas B. Andrews,Yanhao Yang,Sofya Akhetova,Kristi A. Morgansen,Ross L. Hatton*

Main category: cs.RO

TL;DR: 本文展示了使用无迹卡尔曼滤波结合高斯过程残差学习来估计具有非驱动关节、最小传感器配置的自由浮动仿生多连杆机器人的姿态（位置和形状）。


<details>
  <summary>Details</summary>
Motivation: 针对具有非驱动关节、最小传感器配置的自由浮动仿生多连杆机器人，需要开发可靠的姿态估计算法来解决这类欠驱动、最小感知平台的姿态估计问题。

Method: 使用无迹卡尔曼滤波增强高斯过程残差学习来补偿非零均值、非高斯噪声，通过概念验证硬件实验和离线卡尔曼滤波分析进行验证。

Result: 实验表明机器人的姿态可以可靠估计，并且在多步态数据集上训练的滤波器与仅在前进步态数据集上训练的滤波器在相同测试轨迹上表现相当。

Conclusion: 步态输入空间存在重叠，可以利用这一特性减少训练数据需求，同时提高滤波器在多种步态间的泛化能力。

Abstract: This work demonstrates pose (position and shape) estimation for a
free-floating, bioinspired multi-link robot with unactuated joints,
link-mounted thrusters for control, and a single gyroscope per link, resulting
in an underactuated, minimally sensed platform. Through a proof-of-concept
hardware experiment and offline Kalman filter analysis, we show that the
robot's pose can be reliably estimated. State estimation is performed using an
unscented Kalman filter augmented with Gaussian process residual learning to
compensate for non-zero-mean, non-Gaussian noise. We further show that a filter
trained on a multi-gait dataset (forward, backward, left, right, and turning)
performs comparably to one trained on a larger forward-gait-only dataset when
both are evaluated on the same forward-gait test trajectory. These results
reveal overlap in the gait input space, which can be exploited to reduce
training data requirements while enhancing the filter's generalizability across
multiple gaits.

</details>


### [13] [Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments](https://arxiv.org/abs/2510.01519)
*Wei Han Chen,Yuchen Liu,Alexiy Buynitsky,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出分层规划框架解决机器人导航问题：高层用稀疏图捕捉全局连通性，低层用基于神经场的规划器解决Eikonal PDE来导航局部障碍，克服谱偏差和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：传统采样方法难以控制分辨率和扩展性，模仿学习方法需要大量演示数据，ANTFields方法受谱偏差和灾难性遗忘影响。需要更有效的导航解决方案。

Method: 分层规划方法：高层构建稀疏图表示环境全局连通性，低层使用基于神经场的规划器通过求解Eikonal PDE来导航局部障碍，采用物理信息策略。

Result: 在大规模环境中验证，相比先前方法展现出更好的适应性和精度，能够实现平滑精确的成本景观表示。

Conclusion: 该框架在复杂室内环境中具有增强的导航能力，为在线探索、建图和真实世界导航提供了潜力。

Abstract: Robot navigation in large, complex, and unknown indoor environments is a
challenging problem. The existing approaches, such as traditional
sampling-based methods, struggle with resolution control and scalability, while
imitation learning-based methods require a large amount of demonstration data.
Active Neural Time Fields (ANTFields) have recently emerged as a promising
solution by using local observations to learn cost-to-go functions without
relying on demonstrations. Despite their potential, these methods are hampered
by challenges such as spectral bias and catastrophic forgetting, which diminish
their effectiveness in complex scenarios. To address these issues, our approach
decomposes the planning problem into a hierarchical structure. At the high
level, a sparse graph captures the environment's global connectivity, while at
the low level, a planner based on neural fields navigates local obstacles by
solving the Eikonal PDE. This physics-informed strategy overcomes common
pitfalls like spectral bias and neural field fitting difficulties, resulting in
a smooth and precise representation of the cost landscape. We validate our
framework in large-scale environments, demonstrating its enhanced adaptability
and precision compared to previous methods, and highlighting its potential for
online exploration, mapping, and real-world navigation.

</details>


### [14] [Real-time Multi-Plane Segmentation Based on GPU Accelerated High-Resolution 3D Voxel Mapping for Legged Robot Locomotion](https://arxiv.org/abs/2510.01592)
*Shun Niijima,Ryoichi Tsuzaki,Noriaki Takasugi,Masaya Kinoshita*

Main category: cs.RO

TL;DR: 提出了一种基于GPU加速高分辨率3D体素映射的实时多平面分割方法，用于腿式机器人运动，能在0.01米分辨率下以超过30Hz的速率实现快速准确的3D多平面分割。


<details>
  <summary>Details</summary>
Motivation: 现有在线平面映射方法难以平衡精度和计算效率：直接深度图像分割缺乏时间整合，高度图方法无法表示复杂3D结构（如悬垂），体素平面分割在实时应用中尚未探索。

Method: 开发了一个新颖框架，将基于顶点的连通分量标记与RANSAC平面检测和凸包相结合，利用GPU并行计算从高分辨率3D体素地图中累积的点云快速提取平面区域。

Result: 实验结果表明，该方法在0.01米分辨率下以超过30Hz的更新速率实现了快速准确的3D多平面分割，使检测到的平面能够实时用于运动任务。

Conclusion: 通过在模拟环境和物理腿式机器人平台上的实验验证了该方法的有效性，确认了在考虑3D平面结构时的鲁棒运动性能。

Abstract: This paper proposes a real-time multi-plane segmentation method based on
GPU-accelerated high-resolution 3D voxel mapping for legged robot locomotion.
Existing online planar mapping approaches struggle to balance accuracy and
computational efficiency: direct depth image segmentation from specific sensors
suffers from poor temporal integration, height map-based methods cannot
represent complex 3D structures like overhangs, and voxel-based plane
segmentation remains unexplored for real-time applications. To address these
limitations, we develop a novel framework that integrates vertex-based
connected component labeling with random sample consensus based plane detection
and convex hull, leveraging GPU parallel computing to rapidly extract planar
regions from point clouds accumulated in high-resolution 3D voxel maps.
Experimental results demonstrate that the proposed method achieves fast and
accurate 3D multi-plane segmentation at over 30 Hz update rate even at a
resolution of 0.01 m, enabling the detected planes to be utilized in real time
for locomotion tasks. Furthermore, we validate the effectiveness of our
approach through experiments in both simulated environments and physical legged
robot platforms, confirming robust locomotion performance when considering 3D
planar structures.

</details>


### [15] [MiniBEE: A New Form Factor for Compact Bimanual Dexterity](https://arxiv.org/abs/2510.01603)
*Sharfin Islam,Zewen Chen,Zhanpeng He,Swapneel Bhatt,Andres Permuy,Brock Taylor,James Vickery,Pedro Piacenza,Cheng Zhang,Matei Ciocarlie*

Main category: cs.RO

TL;DR: MiniBEE是一个紧凑的双手机器人末端执行器系统，使用两个低自由度机械臂（各3+自由度）耦合形成运动链，保持夹爪间完全相对定位，支持穿戴式数据收集和标准机械臂部署两种模式。


<details>
  <summary>Details</summary>
Motivation: 传统双手机器人系统复杂且只利用部分工作空间进行灵巧操作，需要更紧凑轻便的设计来扩大灵巧工作空间。

Method: 提出运动灵巧度指标指导设计，将两个低自由度机械臂耦合到运动链中，支持穿戴式运动数据收集和标准机械臂部署两种工作模式。

Result: 开发了MiniBEE系统，能够进行穿戴式演示数据收集，并通过模仿学习训练出鲁棒的双手机器人操作策略。

Conclusion: MiniBEE系统通过紧凑设计实现了扩展的灵巧工作空间，为双手机器人操作提供了轻便高效的解决方案。

Abstract: Bimanual robot manipulators can achieve impressive dexterity, but typically
rely on two full six- or seven- degree-of-freedom arms so that paired grippers
can coordinate effectively. This traditional framework increases system
complexity while only exploiting a fraction of the overall workspace for
dexterous interaction. We introduce the MiniBEE (Miniature Bimanual
End-effector), a compact system in which two reduced-mobility arms (3+ DOF
each) are coupled into a kinematic chain that preserves full relative
positioning between grippers. To guide our design, we formulate a kinematic
dexterity metric that enlarges the dexterous workspace while keeping the
mechanism lightweight and wearable. The resulting system supports two
complementary modes: (i) wearable kinesthetic data collection with self-tracked
gripper poses, and (ii) deployment on a standard robot arm, extending dexterity
across its entire workspace. We present kinematic analysis and design
optimization methods for maximizing dexterous range, and demonstrate an
end-to-end pipeline in which wearable demonstrations train imitation learning
policies that perform robust, real-world bimanual manipulation.

</details>


### [16] [ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations](https://arxiv.org/abs/2510.01607)
*Qiyuan Zeng,Chengmeng Li,Jude St. John,Zhongyi Zhou,Junjie Wen,Guorui Feng,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: ActiveUMI是一个数据收集框架，通过便携式VR遥操作系统将野外人类演示转移到能够进行复杂双手操作的机器人上，通过主动自我中心感知学习视觉注意力与操作之间的关键联系。


<details>
  <summary>Details</summary>
Motivation: 开发一个便携的数据收集系统，能够将真实世界中的人类演示有效地转移到机器人上，解决复杂双手操作任务的学习问题，并实现良好的泛化能力。

Method: 结合便携式VR遥操作套件和传感器化控制器，通过精确姿态对齐桥接人机运动学；引入沉浸式3D模型渲染、自包含可穿戴计算机和高效校准方法；记录操作者通过头戴式显示器的刻意头部运动，捕捉主动自我中心感知。

Result: 在六个具有挑战性的双手任务上评估，仅使用ActiveUMI数据训练的策略在分布内任务上平均成功率达到70%，在测试新物体和新环境时保持56%的成功率，表现出强大的泛化能力。

Conclusion: 便携式数据收集系统与学习的主动感知相结合，为创建可泛化和高能力的真实世界机器人策略提供了有效且可扩展的途径。

Abstract: We present ActiveUMI, a framework for a data collection system that transfers
in-the-wild human demonstrations to robots capable of complex bimanual
manipulation. ActiveUMI couples a portable VR teleoperation kit with sensorized
controllers that mirror the robot's end-effectors, bridging human-robot
kinematics via precise pose alignment. To ensure mobility and data quality, we
introduce several key techniques, including immersive 3D model rendering, a
self-contained wearable computer, and efficient calibration methods.
ActiveUMI's defining feature is its capture of active, egocentric perception.
By recording an operator's deliberate head movements via a head-mounted
display, our system learns the crucial link between visual attention and
manipulation. We evaluate ActiveUMI on six challenging bimanual tasks. Policies
trained exclusively on ActiveUMI data achieve an average success rate of 70\%
on in-distribution tasks and demonstrate strong generalization, retaining a
56\% success rate when tested on novel objects and in new environments. Our
results demonstrate that portable data collection systems, when coupled with
learned active perception, provide an effective and scalable pathway toward
creating generalizable and highly capable real-world robot policies.

</details>


### [17] [FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models](https://arxiv.org/abs/2510.01642)
*Zijun Lin,Jiafei Duan,Haoquan Fang,Dieter Fox,Ranjay Krishna,Cheston Tan,Bihan Wen*

Main category: cs.RO

TL;DR: FailSafe是一个新颖的失败生成和恢复系统，能够自动产生多样化的失败案例并配以可执行的恢复动作，用于提升VLA模型在机器人操作中的失败检测和恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据集主要提供地面真实轨迹，缺乏失败恢复数据；少数涉及失败检测的数据集通常只提供文本解释，难以直接在VLA模型中使用。

Method: 提出FailSafe系统，可在任何模拟器中无缝应用于任何操作任务，实现失败-动作数据的可扩展创建。基于LLaVa-OneVision-7B微调构建FailSafe-VLM。

Result: FailSafe-VLM成功帮助机械臂检测和恢复潜在失败，在Maniskill中多个任务上平均提升了三个最先进VLA模型(pi0-FAST、OpenVLA、OpenVLA-OFT)性能达22.6%。

Conclusion: FailSafe-VLM能够泛化到不同的空间配置、相机视角和机器人体现，计划向社区发布FailSafe代码。

Abstract: Recent advances in robotic manipulation have integrated low-level robotic
control into Vision-Language Models (VLMs), extending them into
Vision-Language-Action (VLA) models. Although state-of-the-art VLAs achieve
strong performance in downstream robotic applications, supported by large-scale
crowd-sourced robot training data, they still inevitably encounter failures
during execution. Enabling robots to reason about and recover from
unpredictable and abrupt failures remains a critical challenge. Existing
robotic manipulation datasets, collected in either simulation or the real
world, primarily provide only ground-truth trajectories, leaving robots unable
to recover once failures occur. Moreover, the few datasets that address failure
detection typically offer only textual explanations, which are difficult to
utilize directly in VLA models. To address this gap, we introduce FailSafe, a
novel failure generation and recovery system that automatically produces
diverse failure cases paired with executable recovery actions. FailSafe can be
seamlessly applied to any manipulation task in any simulator, enabling scalable
creation of failure-action data. To demonstrate its effectiveness, we fine-tune
LLaVa-OneVision-7B (LLaVa-OV-7B) to build FailSafe-VLM. Experimental results
show that FailSafe-VLM successfully helps robotic arm detect and recover from
potential failures, improving the performance of three state-of-the-art VLA
models pi0-FAST, OpenVLA, OpenVLA-OFT) by up to 22.6% on average across several
tasks in Maniskill. Furthermore, FailSafe-VLM could generalize across different
spatial configurations, camera viewpoints, and robotic embodiments. We plan to
release the FailSafe code to the community.

</details>


### [18] [Statistical Uncertainty Learning for Robust Visual-Inertial State Estimation](https://arxiv.org/abs/2510.01648)
*Seungwon Choi,Donggyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: 提出了一种在线学习测量可靠性的统计框架，通过多视图几何一致性作为自监督，动态评估视觉惯性里程计中传感器测量的可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设所有测量具有静态、均匀的不确定性，无法捕捉真实世界数据中的动态误差特性，限制了鲁棒性。

Method: 利用多视图几何一致性作为自监督，从传感器数据和优化结果中在线学习测量可靠性评估，推断地标不确定性并自适应加权视觉测量。

Result: 在EuRoC数据集上评估，与固定不确定性参数的基线方法相比，平均平移误差减少约24%，旋转误差减少约42%。

Conclusion: 该框架在实时运行的同时提高了精度和鲁棒性，源代码将公开以促进可复现性和进一步研究。

Abstract: A fundamental challenge in robust visual-inertial odometry (VIO) is to
dynamically assess the reliability of sensor measurements. This assessment is
crucial for properly weighting the contribution of each measurement to the
state estimate. Conventional methods often simplify this by assuming a static,
uniform uncertainty for all measurements. This heuristic, however, may be
limited in its ability to capture the dynamic error characteristics inherent in
real-world data. To improve this limitation, we present a statistical framework
that learns measurement reliability assessment online, directly from sensor
data and optimization results. Our approach leverages multi-view geometric
consistency as a form of self-supervision. This enables the system to infer
landmark uncertainty and adaptively weight visual measurements during
optimization. We evaluated our method on the public EuRoC dataset,
demonstrating improvements in tracking accuracy with average reductions of
approximately 24\% in translation error and 42\% in rotation error compared to
baseline methods with fixed uncertainty parameters. The resulting framework
operates in real time while showing enhanced accuracy and robustness. To
facilitate reproducibility and encourage further research, the source code will
be made publicly available.

</details>


### [19] [Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation](https://arxiv.org/abs/2510.01661)
*Yifei Simon Shao,Yuchen Zheng,Sunan Sun,Pratik Chaudhari,Vijay Kumar,Nadia Figueroa*

Main category: cs.RO

TL;DR: SymSkill是一个结合模仿学习和任务运动规划优势的学习框架，通过联合学习谓词、操作符和技能，实现组合泛化和实时故障恢复。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中多步操作的挑战：模仿学习缺乏组合泛化能力，而传统任务运动规划存在规划延迟问题，无法实时恢复故障。

Method: 从无标签、无分割的演示数据中联合学习谓词、操作符和技能；运行时使用符号规划器组合和重排序技能，在运动和符号层面进行实时故障恢复。

Result: 在RoboCasa模拟中执行12个单步任务成功率85%，无需额外数据即可组合成最多6次技能重组的复杂计划；真实机器人上仅用5分钟无标签数据就能通过目标指定执行多任务。

Conclusion: SymSkill成功结合了IL和TAMP的优势，实现了组合泛化和实时故障恢复，在模拟和真实环境中都表现出色。

Abstract: Multi-step manipulation in dynamic environments remains challenging. Two
major families of methods fail in distinct ways: (i) imitation learning (IL) is
reactive but lacks compositional generalization, as monolithic policies do not
decide which skill to reuse when scenes change; (ii) classical task-and-motion
planning (TAMP) offers compositionality but has prohibitive planning latency,
preventing real-time failure recovery. We introduce SymSkill, a unified
learning framework that combines the benefits of IL and TAMP, allowing
compositional generalization and failure recovery in real-time. Offline,
SymSkill jointly learns predicates, operators, and skills directly from
unlabeled and unsegmented demonstrations. At execution time, upon specifying a
conjunction of one or more learned predicates, SymSkill uses a symbolic planner
to compose and reorder learned skills to achieve the symbolic goals, while
performing recovery at both the motion and symbolic levels in real time.
Coupled with a compliant controller, SymSkill enables safe and uninterrupted
execution under human and environmental disturbances. In RoboCasa simulation,
SymSkill can execute 12 single-step tasks with 85% success rate. Without
additional data, it composes these skills into multi-step plans requiring up to
6 skill recompositions, recovering robustly from execution failures. On a real
Franka robot, we demonstrate SymSkill, learning from 5 minutes of unsegmented
and unlabeled play data, is capable of performing multiple tasks simply by goal
specifications. The source code and additional analysis can be found on
https://sites.google.com/view/symskill.

</details>


### [20] [Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances](https://arxiv.org/abs/2510.01675)
*Jaewoo Lee,Dongjae Lee,Jinwoo Lee,Hyungyu Lee,Yeonjoon Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种几何反步控制器，用于可变倾斜全向多旋翼飞行器，显式考虑伺服和转子动力学，在快速飞行和扰动恢复中表现优于不考虑执行器动态的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有执行器感知控制方法依赖执行器输入与力矩之间的线性关系，无法捕捉可变倾斜角度引起的非线性效应，需要开发能处理非线性执行器动态的控制器。

Method: 利用多旋翼刚体动力学与非线性执行器动力学之间的级联结构，设计几何反步控制器，并建立整个系统的指数稳定性。

Result: 在快速平移跟踪、快速旋转跟踪和突然扰动恢复三个实验场景中，所提控制器始终获得更好的跟踪性能，在基线方法发散坠毁的情况下仍能保持稳定完成任务。

Conclusion: 所提出的控制器能有效处理执行器非线性动态，对参数不确定性具有鲁棒性，在激进的飞行操作中显著提高了多旋翼飞行器的性能和可靠性。

Abstract: This work presents a geometric backstepping controller for a variable-tilt
omnidirectional multirotor that explicitly accounts for both servo and rotor
dynamics. Considering actuator dynamics is essential for more effective and
reliable operation, particularly during aggressive flight maneuvers or recovery
from sudden disturbances. While prior studies have investigated actuator-aware
control for conventional and fixed-tilt multirotors, these approaches rely on
linear relationships between actuator input and wrench, which cannot capture
the nonlinearities induced by variable tilt angles. In this work, we exploit
the cascade structure between the rigid-body dynamics of the multirotor and its
nonlinear actuator dynamics to design the proposed backstepping controller and
establish exponential stability of the overall system. Furthermore, we reveal
parametric uncertainty in the actuator model through experiments, and we
demonstrate that the proposed controller remains robust against such
uncertainty. The controller was compared against a baseline that does not
account for actuator dynamics across three experimental scenarios: fast
translational tracking, rapid rotational tracking, and recovery from sudden
disturbance. The proposed method consistently achieved better tracking
performance, and notably, while the baseline diverged and crashed during the
fastest translational trajectory tracking and the recovery experiment, the
proposed controller maintained stability and successfully completed the tasks,
thereby demonstrating its effectiveness.

</details>


### [21] [PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization](https://arxiv.org/abs/2510.01708)
*Zixing Lei,Zibo Zhou,Sheng Yin,Yueru Chen,Qingyao Xu,Weixin Li,Yunhong Wang,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: PolySim是一个多模拟器训练平台，通过在多个异构模拟器中并行训练人形机器人全身控制策略，减少模拟器归纳偏差，实现零样本的仿真到真实世界部署。


<details>
  <summary>Details</summary>
Motivation: 解决仿真到真实世界的差距问题，这种差距源于单个模拟器的归纳偏差（固有的假设和限制），导致跨模拟器和仿真到真实世界之间存在显著差异。

Method: 开发PolySim平台，在单个训练运行中同时启动来自不同引擎的并行环境，实现动态层面的领域随机化，联合训练策略以捕获超越任何单个模拟器假设的通用动力学。

Result: 在仿真到仿真评估中显著减少运动跟踪误差，在MuJoCo上比IsaacSim基线提高执行成功率52.8%；在真实Unitree G1机器人上实现零样本部署，无需额外微调。

Conclusion: PolySim通过多模拟器联合训练有效缓解模拟器归纳偏差，提供比单模拟器训练更紧的上界，成功实现仿真到真实世界的有效迁移。

Abstract: Humanoid whole-body control (WBC) policies trained in simulation often suffer
from the sim-to-real gap, which fundamentally arises from simulator inductive
bias, the inherent assumptions and limitations of any single simulator. These
biases lead to nontrivial discrepancies both across simulators and between
simulation and the real world. To mitigate the effect of simulator inductive
bias, the key idea is to train policies jointly across multiple simulators,
encouraging the learned controller to capture dynamics that generalize beyond
any single simulator's assumptions. We thus introduce PolySim, a WBC training
platform that integrates multiple heterogeneous simulators. PolySim can launch
parallel environments from different engines simultaneously within a single
training run, thereby realizing dynamics-level domain randomization.
Theoretically, we show that PolySim yields a tighter upper bound on simulator
inductive bias than single-simulator training. In experiments, PolySim
substantially reduces motion-tracking error in sim-to-sim evaluations; for
example, on MuJoCo, it improves execution success by 52.8 over an IsaacSim
baseline. PolySim further enables zero-shot deployment on a real Unitree G1
without additional fine-tuning, showing effective transfer from simulation to
the real world. We will release the PolySim code upon acceptance of this work.

</details>


### [22] [Contrastive Representation Regularization for Vision-Language-Action Models](https://arxiv.org/abs/2510.01711)
*Taeyoung Kim,Jimin Lee,Myungkyu Koo,Dongyoung Kim,Kyungmin Lee,Changyeon Kim,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: 提出了Robot State-aware Contrastive Loss (RS-CL)，一种简单有效的表示正则化方法，用于改善视觉语言动作模型在机器人操作任务中的表示质量，通过将表示与机器人本体感知状态对齐来增强控制相关表示学习。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型虽然利用了预训练视觉语言模型的丰富表示，但这些表示对机器人信号（如控制动作和本体感知状态）不够敏感，导致在机器人操作任务中表现欠佳。

Method: 引入Robot State-aware Contrastive Loss (RS-CL)，使用机器人状态间的相对距离作为软监督，将表示与机器人本体感知状态更紧密对齐，同时保持与标准VLA训练流程的兼容性。

Result: RS-CL显著提升了最先进VLA模型的操作性能：在RoboCasa-Kitchen的拾取放置任务中，成功率从30.8%提升至41.5%；在真实机器人操作任务中，成功率从45.0%提升至58.3%。

Conclusion: RS-CL是一种轻量级且有效的表示正则化方法，能够显著改善VLA模型在机器人操作任务中的性能，通过更好地对齐表示与机器人状态来实现更精确的控制。

Abstract: Vision-Language-Action (VLA) models have shown its capabilities in robot
manipulation by leveraging rich representations from pre-trained
Vision-Language Models (VLMs). However, their representations arguably remain
suboptimal, lacking sensitivity to robotic signals such as control actions and
proprioceptive states. To address the issue, we introduce Robot State-aware
Contrastive Loss (RS-CL), a simple and effective representation regularization
for VLA models, designed to bridge the gap between VLM representations and
robotic signals. In particular, RS-CL aligns the representations more closely
with the robot's proprioceptive states, by using relative distances between the
states as soft supervision. Complementing the original action prediction
objective, RS-CL effectively enhances control-relevant representation learning,
while being lightweight and fully compatible with standard VLA training
pipeline. Our empirical results demonstrate that RS-CL substantially improves
the manipulation performance of state-of-the-art VLA models; it pushes the
prior art from 30.8% to 41.5% on pick-and-place tasks in RoboCasa-Kitchen,
through more accurate positioning during grasping and placing, and boosts
success rates from 45.0% to 58.3% on challenging real-robot manipulation tasks.

</details>


### [23] [Dual-Mode Magnetic Continuum Robot for Targeted Drug Delivery](https://arxiv.org/abs/2510.01761)
*Wendu Zhang,Heng Wang,Shuangyi Wang,Yuanrui Huang*

Main category: cs.RO

TL;DR: 提出了一种径向嵌入永磁体的磁控连续机器人设计，通过外部永磁体可独立控制弯曲或扭转运动，并利用扭转剪切实现按需药物释放。


<details>
  <summary>Details</summary>
Motivation: 传统轴向磁化设计的磁控连续机器人主要限于弯曲运动，需要扩展变形能力以实现更复杂的操作。

Method: 在导管壁内径向嵌入永磁体，通过外部永磁体独立诱导弯曲或扭转；采用基于物理的建模和有限元分析验证驱动原理；设计了由外槽和内板组成的双层堵塞机制，利用扭转剪切实现药物释放。

Result: 实验验证了在实用磁场下的解耦模式控制；在体模干预实验中展示了从管腔跟随、弯曲接近目标到扭转激活释放的端到端操作。

Conclusion: 该紧凑、无缆平台结合了多功能变形与精确载荷递送，在下一代定点治疗中具有强大潜力。

Abstract: Magnetic continuum robots (MCRs) enable minimally invasive navigation through
tortuous anatomical channels, yet axially magnetized designs have largely been
limited to bending-only motion. To expand deformation capabilities, this paper
presents a simple assembly that embeds permanent magnets radially within the
catheter wall, allowing a single externally steered permanent magnet to
independently induce either bending or torsion. A physics-based formulation
together with finite-element analysis establishes the actuation principles, and
benchtop experiments validate decoupled mode control under practical fields.
Building on this, a dual-layer blockage mechanism consisting of outer grooves
and inner plates leverages torsional shear to achieve on-demand drug release.
Finally, an in-phantom intervention experiment demonstrates end-to-end
operation: lumen following by bending for target approach, followed by
twist-activated release at the site. The resulting compact, cable-free platform
combines versatile deformation with precise payload delivery, indicating strong
potential for next-generation, site-specific therapies.

</details>


### [24] [An Anytime, Scalable and Complete Algorithm for Embedding a Manufacturing Procedure in a Smart Factory](https://arxiv.org/abs/2510.01770)
*Christopher Leet,Aidan Sciortino,Sven Koenig*

Main category: cs.RO

TL;DR: 提出了TS-ACES，第一个可扩展到包含数百台机器的智能工厂的SFE问题解决方案


<details>
  <summary>Details</summary>
Motivation: 现代智能工厂可能包含数百台机器，而现有SFE求解器只能扩展到几十台机器，存在可扩展性差距

Method: TS-ACES（基于交通系统的任意时间循环嵌入求解器），采用基于交通系统的方法来解决智能工厂嵌入问题

Result: TS-ACES是完备的，并且能够扩展到基于真实工业场景、包含超过一百台机器的SFE实例

Conclusion: TS-ACES填补了SFE问题可扩展性方面的空白，为大规模智能工厂提供了实用的解决方案

Abstract: Modern automated factories increasingly run manufacturing procedures using a
matrix of programmable machines, such as 3D printers, interconnected by a
programmable transport system, such as a fleet of tabletop robots. To embed a
manufacturing procedure into a smart factory, an operator must: (a) assign each
of its processes to a machine and (b) specify how agents should transport parts
between machines. The problem of embedding a manufacturing process into a smart
factory is termed the Smart Factory Embedding (SFE) problem. State-of-the-art
SFE solvers can only scale to factories containing a couple dozen machines.
Modern smart factories, however, may contain hundreds of machines. We fill this
hole by introducing the first highly scalable solution to the SFE, TS-ACES, the
Traffic System based Anytime Cyclic Embedding Solver. We show that TS-ACES is
complete and can scale to SFE instances based on real industrial scenarios with
more than a hundred machines.

</details>


### [25] [Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2510.01795)
*Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Nan Guan,Chun Jason Xue*

Main category: cs.RO

TL;DR: 提出Nav-EE框架，通过导航先验指导视觉语言模型在自动驾驶中的早期退出，在保持精度的同时显著降低推理延迟


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在自动驾驶中应用广泛，但高推理延迟阻碍实时部署。传统早期退出方法因任务依赖性难以适应多样化场景

Method: 基于导航系统预知上下文，离线预计算任务特定退出层，在线根据导航先验动态应用早期退出策略

Result: 在CODA、Waymo和BOSCH数据集上，精度与完整推理相当，延迟降低高达63.9%。实车测试中推理延迟从600ms降至300ms

Conclusion: 将导航预见性与早期退出结合，为大模型在自动驾驶系统中的高效部署提供了可行路径

Abstract: Vision-Language Models (VLMs) are increasingly applied in autonomous driving
for unified perception and reasoning, but high inference latency hinders
real-time deployment. Early-exit reduces latency by terminating inference at
intermediate layers, yet its task-dependent nature limits generalization across
diverse scenarios. We observe that this limitation aligns with autonomous
driving: navigation systems can anticipate upcoming contexts (e.g.,
intersections, traffic lights), indicating which tasks will be required. We
propose Nav-EE, a navigation-guided early-exit framework that precomputes
task-specific exit layers offline and dynamically applies them online based on
navigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EE
achieves accuracy comparable to full inference while reducing latency by up to
63.9%. Real-vehicle integration with Autoware Universe further demonstrates
reduced inference latency (600ms to 300ms), supporting faster decision-making
in complex scenarios. These results suggest that coupling navigation foresight
with early-exit offers a viable path toward efficient deployment of large
models in autonomous systems. Code and data are available at our anonymous
repository: https://anonymous.4open.science/r/Nav-EE-BBC4

</details>


### [26] [What Matters in RL-Based Methods for Object-Goal Navigation? An Empirical Study and A Unified Framework](https://arxiv.org/abs/2510.01830)
*Hongze Wang,Boyang Sun,Jiaxu Xing,Fan Yang,Marco Hutter,Dhruv Shah,Davide Scaramuzza,Marc Pollefeys*

Main category: cs.RO

TL;DR: 本文对基于强化学习的物体目标导航系统进行了大规模实证研究，分解为感知、策略和测试时增强三个关键组件，发现感知质量和测试时策略是性能的决定性因素，而策略改进仅带来边际收益。


<details>
  <summary>Details</summary>
Motivation: 物体目标导航是移动机器人在非受控环境中部署的关键能力，但现有方法缺乏统一分析来确定真正驱动性能的组件。本文旨在通过分解式研究揭示各组件对性能的实际贡献。

Method: 采用大规模实证研究方法，将模块化RL系统分解为感知、策略和测试时增强三个组件，通过受控实验隔离每个组件的贡献。

Result: 研究发现感知质量和测试时策略是性能的主要驱动因素，基于这些洞察提出的增强模块化系统在SPL指标上超过现有最佳方法6.6%，成功率提高2.7%。人类专家在相同条件下达到98%成功率。

Conclusion: 感知和测试时增强是物体目标导航性能的关键，而策略改进效果有限。研究为未来ObjectNav开发和评估提供了原则性指导，并建立了新的性能基准。

Abstract: Object-Goal Navigation (ObjectNav) is a critical component toward deploying
mobile robots in everyday, uncontrolled environments such as homes, schools,
and workplaces. In this context, a robot must locate target objects in
previously unseen environments using only its onboard perception. Success
requires the integration of semantic understanding, spatial reasoning, and
long-horizon planning, which is a combination that remains extremely
challenging. While reinforcement learning (RL) has become the dominant
paradigm, progress has spanned a wide range of design choices, yet the field
still lacks a unifying analysis to determine which components truly drive
performance. In this work, we conduct a large-scale empirical study of modular
RL-based ObjectNav systems, decomposing them into three key components:
perception, policy, and test-time enhancement. Through extensive controlled
experiments, we isolate the contribution of each and uncover clear trends:
perception quality and test-time strategies are decisive drivers of
performance, whereas policy improvements with current methods yield only
marginal gains. Building on these insights, we propose practical design
guidelines and demonstrate an enhanced modular system that surpasses
State-of-the-Art (SotA) methods by 6.6% on SPL and by a 2.7% success rate. We
also introduce a human baseline under identical conditions, where experts
achieve an average 98% success, underscoring the gap between RL agents and
human-level navigation. Our study not only sets the SotA performance but also
provides principled guidance for future ObjectNav development and evaluation.

</details>


### [27] [Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots](https://arxiv.org/abs/2510.01843)
*Wanyue Li,Ji Ma,Minghao Lu,Peng Lu*

Main category: cs.RO

TL;DR: 该研究将无人机中成功的时空轨迹规划方法创新性地应用于双足机器人系统，实现了在满足目标踢球位置、速度和加速度约束的同时优化摆动相持续时间，生成模仿人类踢球行为的轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人足球中在激烈踢球动作时保持系统稳定性并实现精确球轨迹控制的挑战。现有方法（传统位置控制或强化学习）存在显著局限性，而MPC方法通常过度简化腿部摆动过程，限制了脚部环境交互能力。

Method: 将无人机应用中成功的时空轨迹规划方法适配到双足机器人系统，自主生成满足目标踢球位置、速度和加速度约束的足部轨迹，同时优化摆动相持续时间。

Result: 优化的轨迹密切模仿人类踢球行为（包含后摆动作），轨迹规划时间低于1毫秒，当足球目标在-90°到90°范围内时，任务完成准确率接近100%。

Conclusion: 该方法在仿真和硬件实验中证明了其高效性和可靠性，为双足机器人踢球任务提供了有效的解决方案。

Abstract: Humanoid robot soccer presents several challenges, particularly in
maintaining system stability during aggressive kicking motions while achieving
precise ball trajectory control. Current solutions, whether traditional
position-based control methods or reinforcement learning (RL) approaches,
exhibit significant limitations. Model predictive control (MPC) is a prevalent
approach for ordinary quadruped and biped robots. While MPC has demonstrated
advantages in legged robots, existing studies often oversimplify the leg swing
progress, relying merely on simple trajectory interpolation methods. This
severely constrains the foot's environmental interaction capability, hindering
tasks such as ball kicking. This study innovatively adapts the spatial-temporal
trajectory planning method, which has been successful in drone applications, to
bipedal robotic systems. The proposed approach autonomously generates foot
trajectories that satisfy constraints on target kicking position, velocity, and
acceleration while simultaneously optimizing swing phase duration. Experimental
results demonstrate that the optimized trajectories closely mimic human kicking
behavior, featuring a backswing motion. Simulation and hardware experiments
confirm the algorithm's efficiency, with trajectory planning times under 1 ms,
and its reliability, achieving nearly 100 % task completion accuracy when the
soccer goal is within the range of -90{\deg} to 90{\deg}.

</details>


### [28] [GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics](https://arxiv.org/abs/2510.01848)
*Diram Tabaa,Gianni Di Caro*

Main category: cs.RO

TL;DR: GreenhouseSplat是一个从RGB图像生成逼真温室资产的框架和数据集，支持ROS仿真，用于农业机器人评估。


<details>
  <summary>Details</summary>
Motivation: 现有温室仿真方法依赖简单或合成资产，限制了仿真到现实的迁移。辐射场方法如高斯溅射虽能实现逼真重建，但仅限于单个植物或实验室条件。

Method: 从廉价RGB图像直接生成逼真温室资产，集成到支持相机和LiDAR渲染的ROS仿真中，包含82个黄瓜植物的数据集。

Result: 创建了首个温室尺度的辐射场仿真框架，提供了农业机器人研究的基础。

Conclusion: GreenhouseSplat代表了向温室尺度辐射场仿真的第一步，为农业机器人未来研究提供了基础。

Abstract: Simulating greenhouse environments is critical for developing and evaluating
robotic systems for agriculture, yet existing approaches rely on simplistic or
synthetic assets that limit simulation-to-real transfer. Recent advances in
radiance field methods, such as Gaussian splatting, enable photorealistic
reconstruction but have so far been restricted to individual plants or
controlled laboratory conditions. In this work, we introduce GreenhouseSplat, a
framework and dataset for generating photorealistic greenhouse assets directly
from inexpensive RGB images. The resulting assets are integrated into a
ROS-based simulation with support for camera and LiDAR rendering, enabling
tasks such as localization with fiducial markers. We provide a dataset of 82
cucumber plants across multiple row configurations and demonstrate its utility
for robotics evaluation. GreenhouseSplat represents the first step toward
greenhouse-scale radiance-field simulation and offers a foundation for future
research in agricultural robotics.

</details>


### [29] [TACOS: Task Agnostic COordinator of a multi-drone System](https://arxiv.org/abs/2510.01869)
*Alessandro Nazzari,Roberto Rubinacci,Marco Lovera*

Main category: cs.RO

TL;DR: TACOS是一个基于大语言模型的多无人机系统统一框架，通过自然语言接口实现高层任务委托，支持从直接控制到自主群行为的多种自主模式。


<details>
  <summary>Details</summary>
Motivation: 单飞行员管理多无人机系统需要灵活的自主性层级，从直接控制到群体协调再到完全自主的群行为。语言模型在推理和规划方面的进步为这种系统提供了自然基础，通过直观的语言接口减少飞行员工作负担。

Method: TACOS框架整合了三个关键能力：一对多自然语言接口、智能协调器将用户意图转化为结构化任务计划、以及与真实世界交互的自主代理执行器。LLM与可执行API库交互，连接语义推理与实时多机器人协调。

Result: 在真实多无人机系统中进行了演示，并通过消融研究评估了每个模块的贡献。

Conclusion: TACOS提供了一个统一的框架，通过大语言模型实现多无人机系统的高层自然语言控制，有效桥接了语义推理与实时多机器人协调。

Abstract: When a single pilot is responsible for managing a multi-drone system, the
task demands varying levels of autonomy, from direct control of individual
UAVs, to group-level coordination, to fully autonomous swarm behaviors for
accomplishing high-level tasks. Enabling such flexible interaction requires a
framework that supports multiple modes of shared autonomy. As language models
continue to improve in reasoning and planning, they provide a natural
foundation for such systems, reducing pilot workload by enabling high-level
task delegation through intuitive, language-based interfaces. In this paper we
present TACOS (Task-Agnostic COordinator of a multi-drone System), a unified
framework that enables high-level natural language control of multi-UAV systems
through Large Language Models (LLMs). TACOS integrates three key capabilities
into a single architecture: a one-to-many natural language interface for
intuitive user interaction, an intelligent coordinator for translating user
intent into structured task plans, and an autonomous agent that executes plans
interacting with the real-world. TACOS allows a LLM to interact with a library
of executable APIs, bridging semantic reasoning with real-time multi-robot
coordination. We demonstrate the system in real-world multi-drone system and
conduct an ablation study to assess the contribution of each module.

</details>


### [30] [SPARC: Spine with Prismatic and Revolute Compliance for Quadruped Robot](https://arxiv.org/abs/2510.01984)
*Yue Wang*

Main category: cs.RO

TL;DR: SPARC是一个紧凑的开源3自由度脊柱模块，结合旋转和线性运动，具有可编程任务空间阻抗，用于四足机器人。


<details>
  <summary>Details</summary>
Motivation: 为四足机器人开发一个便携式平台，系统研究脊柱柔顺性在腿式运动中的作用。

Method: 集成三个扭矩控制执行器、定制1kHz控制板和受保护电源单元，开发基于RNEA的计算加速度控制器，带有平滑Stribeck摩擦补偿。

Result: 实验验证了线性力-位移特性，水平刚度300-700 N/m，相对误差≤1.5%；动态测试确认了质量-弹簧-阻尼器响应。

Conclusion: SPARC为腿式运动中脊柱柔顺性的系统研究提供了一个便携平台，并将发布完整的硬件和固件资源。

Abstract: We present SPARC, a compact, open-source 3-DoF sagittal-plane spine module
that combines revolute (pitch) and prismatic (axial) motion with programmable
task-space impedance for quadruped robots. The system integrates three
torque-controlled actuators, a custom 1 kHz control board, and a protected
power unit in a 1.26 kg package, enabling closed-loop stiffness and damping
shaping along x, z, and theta. We develop an RNEA-based computed-acceleration
controller with smooth Stribeck friction compensation to render spring-damper
behavior without explicit inertia shaping. Bench experiments validate the
approach. Quasi-static push-pull tests show linear force-displacement
characteristics with commanded horizontal stiffness spanning 300-700 N/m and <=
1.5% relative error (R^2 >= 0.992, narrow 95% CIs). Dynamic
displace-and-release trials confirm mass-spring-damper responses over multiple
damping settings, with small, interpretable phase deviations due to
configuration-dependent inertia and low-speed friction effects. A task-space PD
controller produces roughly linear stiffness but with greater variability and
coupling sensitivity. SPARC provides a portable platform for systematic studies
of spine compliance in legged locomotion and will be released with complete
hardware and firmware resources.

</details>


### [31] [Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation](https://arxiv.org/abs/2510.01986)
*Varun Kotian,Vishrut Jain,Andrea Michelle Rios Lazcano,Daan Marinus Pool,Riender Happee,Barys Shyrokau*

Main category: cs.RO

TL;DR: 提出一种基于模型预测控制的运动提示算法，通过惩罚感官冲突和比力误差来同时优化驾驶模拟器的保真度和舒适度，显著减少晕动症。


<details>
  <summary>Details</summary>
Motivation: 驾驶模拟器在研究和开发中应用日益广泛，但由于运动缩放和视觉不匹配常导致晕动症，需要开发能同时保证保真度和舒适度的运动提示算法。

Method: 使用模型预测控制(MPC)开发运动提示算法，在成本函数中同时惩罚感官冲突和比力误差，通过人机闭环实验比较四种运动设置：两种MPC变体、自适应洗出算法和无运动条件。

Result: 实验结果显示，折衷方案相比自适应洗出和纯比力跟踪算法，晕动症减少超过50%（平均MISC水平从3降至1.5），且保真度评级无显著下降。

Conclusion: 提出的方法综合考虑模拟器动力学和晕动症时间演化，在驾驶模拟器中实现晕动症控制和比力重建的最优平衡，支持模拟器的更广泛应用。

Abstract: Driving simulators are increasingly used in research and development.
However, simulators often cause motion sickness due to downscaled motion and
unscaled veridical visuals. In this paper, a motion cueing algorithm is
proposed that reduces motion sickness as predicted by the subjective vertical
conflict (SVC) model using model predictive control (MPC). Both sensory
conflict and specific force errors are penalised in the cost function, allowing
the algorithm to jointly optimise fidelity and comfort.
  Human-in-the-loop experiments were conducted to compare four simulator motion
settings: two variations of our MPC-based algorithm, one focused on pure
specific force tracking and the second compromising specific force tracking and
motion sickness minimisation, as well as reference adaptive washout and no
motion cases. The experiments were performed on a hexapod driving simulator
with participants exposed to passive driving.
  Experimental motion sickness results closely matched the sickness model
predictions. As predicted by the model, the no motion condition yielded the
lowest sickness levels. However, it was rated lowest in terms of fidelity. The
compromise solution reduced sickness by over 50% (average MISC level 3 to 1.5)
compared to adaptive washout and the algorithm focusing on specific force
tracking, without any significant reduction in fidelity rating.
  The proposed approach for developing MCA that takes into account both the
simulator dynamics and time evolution of motion sickness offers a significant
advancement in achieving an optimal control of motion sickness and specific
force recreation in driving simulators, supporting broader simulator use.

</details>


### [32] [EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2510.02080)
*Lingxiang Hu,Naima Ait Oufroukh,Fabien Bonardi,Raymond Ghandour*

Main category: cs.RO

TL;DR: EC3R-SLAM是一个无需相机标定的单目稠密SLAM框架，通过结合稀疏特征点跟踪和前馈3D重建模型，实现了高精度定位建图、低延迟和低GPU内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有单目稠密SLAM方法存在高延迟、大GPU内存消耗和依赖相机标定的问题，限制了实际应用。

Method: 结合跟踪模块（维护稀疏特征点地图）和基于前馈3D重建模型的建图模块，同时估计相机内参，并融入局部和全局闭环检测。

Result: 在多个基准测试中达到与最先进方法相当的性能，同时速度更快、内存效率更高，可在笔记本电脑和Jetson Orin NX等资源受限平台上有效运行。

Conclusion: EC3R-SLAM在精度、效率和实用性方面表现出色，具有在现实世界机器人应用中推广的潜力。

Abstract: The application of monocular dense Simultaneous Localization and Mapping
(SLAM) is often hindered by high latency, large GPU memory consumption, and
reliance on camera calibration. To relax this constraint, we propose EC3R-SLAM,
a novel calibration-free monocular dense SLAM framework that jointly achieves
high localization and mapping accuracy, low latency, and low GPU memory
consumption. This enables the framework to achieve efficiency through the
coupling of a tracking module, which maintains a sparse map of feature points,
and a mapping module based on a feed-forward 3D reconstruction model that
simultaneously estimates camera intrinsics. In addition, both local and global
loop closures are incorporated to ensure mid-term and long-term data
association, enforcing multi-view consistency and thereby enhancing the overall
accuracy and robustness of the system. Experiments across multiple benchmarks
show that EC3R-SLAM achieves competitive performance compared to
state-of-the-art methods, while being faster and more memory-efficient.
Moreover, it runs effectively even on resource-constrained platforms such as
laptops and Jetson Orin NX, highlighting its potential for real-world robotics
applications.

</details>


### [33] [LangGrasp: Leveraging Fine-Tuned LLMs for Language Interactive Robot Grasping with Ambiguous Instructions](https://arxiv.org/abs/2510.02104)
*Yunhan Lin,Wenqi Wu,Zhijie Zhang,Huasong Min*

Main category: cs.RO

TL;DR: LangGrasp是一个语言交互的机器人抓取框架，通过微调的大语言模型处理包含隐含意图的模糊指令，结合点云定位实现从物体级到部件级的精细抓取操作。


<details>
  <summary>Details</summary>
Motivation: 现有的语言驱动抓取方法难以处理包含隐含意图的模糊指令，需要能够理解语言中的隐含信息并精确执行抓取任务。

Method: 集成微调的大语言模型进行常识理解和环境感知，设计基于2D部件分割引导的点云定位模块，实现从粗粒度物体级到细粒度部件级的抓取操作。

Result: 实验表明LangGrasp能准确解析模糊指令中的隐含意图，识别未明确说明的关键操作和目标信息，动态选择最优抓取姿态，实现高精度抓取。

Conclusion: 该框架显著提升了机器人在非结构化环境中的适应性和任务执行效率，实现了从物体级到部件级的精细操作能力。

Abstract: The existing language-driven grasping methods struggle to fully handle
ambiguous instructions containing implicit intents. To tackle this challenge,
we propose LangGrasp, a novel language-interactive robotic grasping framework.
The framework integrates fine-tuned large language models (LLMs) to leverage
their robust commonsense understanding and environmental perception
capabilities, thereby deducing implicit intents from linguistic instructions
and clarifying task requirements along with target manipulation objects.
Furthermore, our designed point cloud localization module, guided by 2D part
segmentation, enables partial point cloud localization in scenes, thereby
extending grasping operations from coarse-grained object-level to fine-grained
part-level manipulation. Experimental results show that the LangGrasp framework
accurately resolves implicit intents in ambiguous instructions, identifying
critical operations and target information that are unstated yet essential for
task completion. Additionally, it dynamically selects optimal grasping poses by
integrating environmental information. This enables high-precision grasping
from object-level to part-level manipulation, significantly enhancing the
adaptability and task execution efficiency of robots in unstructured
environments. More information and code are available here:
https://github.com/wu467/LangGrasp.

</details>


### [34] [Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control](https://arxiv.org/abs/2510.02129)
*Philip Reichenberg,Tim Laue*

Main category: cs.RO

TL;DR: 本文介绍了NAO机器人从2019年开始开发的自主站立动作，通过解决关节位置误差问题显著提高了站立成功率，该方法已被多个机器人足球团队采用。


<details>
  <summary>Details</summary>
Motivation: 在类人机器人足球比赛中，机器人若无法自主站立会被暂时移出比赛，因此可靠的站立动作至关重要。

Method: 通过执行特殊动作释放卡住的肢体（如手臂），以及用其他关节补偿大误差来应对关节位置误差问题。

Result: 显著提高了站立动作的整体成功率，多个标准平台联盟团队采用该方法后也取得了类似的成功表现。

Conclusion: 解决关节位置误差是提高机器人自主站立成功率的关键，该方法经过6年验证具有可靠性和实用性。

Abstract: Stand-up motions are an indispensable part of humanoid robot soccer. A robot
incapable of standing up by itself is removed from the game for some time. In
this paper, we present our stand-up motions for the NAO robot. Our approach
dates back to 2019 and has been evaluated and slightly expanded over the past
six years. We claim that the main reason for failed stand-up attempts are large
errors in the executed joint positions. By addressing such problems by either
executing special motions to free up stuck limbs such as the arms, or by
compensating large errors with other joints, we significantly increased the
overall success rate of our stand-up routine. The motions presented in this
paper are also used by several other teams in the Standard Platform League,
which thereby achieve similar success rates, as shown in an analysis of videos
from multiple tournaments.

</details>


### [35] [SCANS: A Soft Gripper with Curvature and Spectroscopy Sensors for In-Hand Material Differentiation](https://arxiv.org/abs/2510.02164)
*Nathaniel Hanson,Austin Allison,Charles DiMarzio,Taşkın Padır,Kristen L. Dorsey*

Main category: cs.RO

TL;DR: SCANS系统是一种无电子元件、流体驱动的软体机械手，能够通过预接触夹持或手持方式评估物体的光谱特性，具有比以往软体机器人更宽的光谱感知能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种多功能的光学感知软体机器人系统，通过光谱分析来区分不同材质的物体，提升软体机器人的感知能力。

Method: 使用流体驱动的软体机械手，进行材料分析以选择最佳光谱传感软基底，评估预接触和手持性能，并通过线性判别分析识别关键波长。

Result: 实验显示系统能够对不同类别和尺寸的物体（金属、木材、塑料、有机材料、纸张、泡沫）进行可解释的统计分离，近红外波长对区分视觉相似物体至关重要。

Conclusion: SCANS系统推进了光学作为软体机器人多功能感知模式的潜力，所有部件清单、组装指南和处理代码均已公开。

Abstract: We introduce the soft curvature and spectroscopy (SCANS) system: a versatile,
electronics-free, fluidically actuated soft manipulator capable of assessing
the spectral properties of objects either in hand or through pre-touch caging.
This platform offers a wider spectral sensing capability than previous soft
robotic counterparts. We perform a material analysis to explore optimal soft
substrates for spectral sensing, and evaluate both pre-touch and in-hand
performance. Experiments demonstrate explainable, statistical separation across
diverse object classes and sizes (metal, wood, plastic, organic, paper, foam),
with large spectral angle differences between items. Through linear
discriminant analysis, we show that sensitivity in the near-infrared
wavelengths is critical to distinguishing visually similar objects. These
capabilities advance the potential of optics as a multi-functional sensory
modality for soft robots. The complete parts list, assembly guidelines, and
processing code for the SCANS gripper are accessible at:
https://parses-lab.github.io/scans/.

</details>


### [36] [Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product-Process-Resource Asset Network](https://arxiv.org/abs/2510.02167)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 本文提出使用数字孪生技术优化电动汽车电池的拆解过程，通过扩展产品-过程-资源资产网络(PAN)为双向PAN(Bi-PAN)，同时覆盖制造和再制造/回收阶段，以提高可持续性。


<details>
  <summary>Details</summary>
Motivation: 在循环经济背景下，制造商往往不共享相关数据，导致产品生命周期结束阶段的再制造和回收过程得不到足够支持，影响可持续性和环境保护。

Method: 采用数字孪生技术，基于扩展的产品-过程-资源资产网络(Bi-PAN)范式，该网络能够建模产品、生产资源、制造过程以及特定生产操作之间的关系，并扩展到再制造/回收阶段。

Result: 通过电动汽车电池拆解用例证明，利用产品数字孪生可以灵活高效地解决不同类型电池的拆解挑战，减少生态影响。

Conclusion: 数字孪生技术和Bi-PAN表示法为优化产品拆解过程提供了有效解决方案，有助于实现循环经济和可持续发展目标。

Abstract: In the context of the circular economy, products in their end-of-life phase
should be either remanufactured or recycled. Both of these processes are
crucial for sustainability and environmental conservation. However,
manufacturers often do not support these processes enough by not sharing
relevant data. This paper proposes use of a digital twin technology, which is
capable to help optimizing the disassembly processes to reduce ecological
impact and enhance sustainability. The proposed approach is demonstrated
through a disassembly use-case of the product digital twin of an electric
vehicle battery. By utilizing product digital twins, challenges associated with
the disassembly of electric vehicle batteries can be solved flexibly and
efficiently for various battery types. As a backbone for the product digital
twin representation, the paper uses the paradigm of product-process-resource
asset networks (PAN). Such networks enable to model relevant relationships
across products, production resources, manufacturing processes, and specific
production operations that have to be done in the manufacturing phase of a
product. This paper introduces a Bi-Flow Product-Process-Resource Asset Network
(Bi-PAN) representation, which extends the PAN paradigm to cover not only the
manufacturing, but also the remanufacturing/recycling phase.

</details>


### [37] [DisCo-Layout: Disentangling and Coordinating Semantic and Physical Refinement in a Multi-Agent Framework for 3D Indoor Layout Synthesis](https://arxiv.org/abs/2510.02178)
*Jialin Gao,Donghao Zhou,Mingjian Liang,Lihao Liu,Chi-Wing Fu,Xiaowei Hu,Pheng-Ann Heng*

Main category: cs.RO

TL;DR: DisCo-Layout是一个解耦物理和语义精炼的3D室内布局生成框架，通过语义精炼工具和物理精炼工具分别处理抽象关系和具体空间问题，多智能体协作实现高质量的布局生成。


<details>
  <summary>Details</summary>
Motivation: 传统方法泛化能力差，而基于LLM/VLM的方法虽然语义丰富但缺乏灵活精炼机制，导致布局质量不佳。

Method: 使用语义精炼工具(SRT)修正抽象对象关系，物理精炼工具(PRT)通过网格匹配算法解决空间问题，多智能体框架协调工具协作。

Result: 实验证明DisCo-Layout达到最先进性能，能生成真实、连贯且可泛化的3D室内布局。

Conclusion: DisCo-Layout通过解耦和协调物理与语义精炼，有效解决了3D室内布局生成中的泛化和精炼问题。

Abstract: 3D indoor layout synthesis is crucial for creating virtual environments.
Traditional methods struggle with generalization due to fixed datasets. While
recent LLM and VLM-based approaches offer improved semantic richness, they
often lack robust and flexible refinement, resulting in suboptimal layouts. We
develop DisCo-Layout, a novel framework that disentangles and coordinates
physical and semantic refinement. For independent refinement, our Semantic
Refinement Tool (SRT) corrects abstract object relationships, while the
Physical Refinement Tool (PRT) resolves concrete spatial issues via a
grid-matching algorithm. For collaborative refinement, a multi-agent framework
intelligently orchestrates these tools, featuring a planner for placement
rules, a designer for initial layouts, and an evaluator for assessment.
Experiments demonstrate DisCo-Layout's state-of-the-art performance, generating
realistic, coherent, and generalizable 3D indoor layouts. Our code will be
publicly available.

</details>


### [38] [Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0](https://arxiv.org/abs/2510.02248)
*Yan Miao,Ege Yuceel,Georgios Fainekos,Bardh Hoxha,Hideki Okamoto,Sayan Mitra*

Main category: cs.RO

TL;DR: 开发了FalconGym 2.0仿真框架和性能引导优化算法，训练出的视觉策略在无人机导航中展现出优异的泛化能力和鲁棒性，并能实现零样本的仿真到真实迁移。


<details>
  <summary>Details</summary>
Motivation: 现有视觉策略在无人机导航中容易对单一赛道过拟合，当赛道几何形状变化时性能会下降。

Method: 基于高斯泼溅构建了FalconGym 2.0仿真框架，提供编辑API快速生成多样化赛道；提出了性能引导优化算法，在训练过程中专注于挑战性赛道。

Result: 在固定翼无人机和四旋翼无人机两个案例中，单一视觉策略在三个未见赛道上达到100%成功率，无需针对每个赛道重新训练；在门位姿扰动下保持更高成功率；在真实四旋翼硬件上实现98.6%成功率。

Conclusion: FalconGym 2.0框架和性能引导优化算法能够训练出具有强大泛化能力和鲁棒性的视觉策略，并能成功实现仿真到真实的迁移。

Abstract: Visual policy design is crucial for aerial navigation. However,
state-of-the-art visual policies often overfit to a single track and their
performance degrades when track geometry changes. We develop FalconGym 2.0, a
photorealistic simulation framework built on Gaussian Splatting (GSplat) with
an Edit API that programmatically generates diverse static and dynamic tracks
in milliseconds. Leveraging FalconGym 2.0's editability, we propose a
Performance-Guided Refinement (PGR) algorithm, which concentrates visual
policy's training on challenging tracks while iteratively improving its
performance. Across two case studies (fixed-wing UAVs and quadrotors) with
distinct dynamics and environments, we show that a single visual policy trained
with PGR in FalconGym 2.0 outperforms state-of-the-art baselines in
generalization and robustness: it generalizes to three unseen tracks with 100%
success without per-track retraining and maintains higher success rates under
gate-pose perturbations. Finally, we demonstrate that the visual policy trained
with PGR in FalconGym 2.0 can be zero-shot sim-to-real transferred to a
quadrotor hardware, achieving a 98.6% success rate (69 / 70 gates) over 30
trials spanning two three-gate tracks and a moving-gate track.

</details>


### [39] [Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking](https://arxiv.org/abs/2510.02252)
*Joao Pedro Araujo,Yanjie Ze,Pei Xu,Jiajun Wu,C. Karen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种新的人形运动重定向方法GMR，通过系统评估重定向质量对策略性能的影响，发现现有方法中的伪影会显著降低策略鲁棒性。GMR在跟踪性能和运动保真度方面优于现有开源方法。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人运动跟踪中的人体-机器人体现差距问题，现有重定向方法在参考轨迹中引入的伪影（如脚部滑动、自穿透、物理不可行运动）需要强化学习策略来纠正，但往往需要大量奖励工程和领域随机化。

Method: 提出通用运动重定向(GMR)方法，与PHC、ProtoMotions等开源重定向器以及Unitree的闭源数据集进行比较，使用BeyondMimic进行策略训练以隔离重定向效果。

Result: 实验表明，虽然大多数运动可以被跟踪，但重定向数据中的伪影显著降低了策略鲁棒性，特别是在动态或长序列中。GMR在跟踪性能和源运动保真度方面始终优于现有开源方法。

Conclusion: GMR实现了接近闭源基线的感知保真度和策略成功率，证明了高质量重定向对提升人形运动跟踪策略性能的重要性。

Abstract: Humanoid motion tracking policies are central to building teleoperation
pipelines and hierarchical controllers, yet they face a fundamental challenge:
the embodiment gap between humans and humanoid robots. Current approaches
address this gap by retargeting human motion data to humanoid embodiments and
then training reinforcement learning (RL) policies to imitate these reference
trajectories. However, artifacts introduced during retargeting, such as foot
sliding, self-penetration, and physically infeasible motion are often left in
the reference trajectories for the RL policy to correct. While prior work has
demonstrated motion tracking abilities, they often require extensive reward
engineering and domain randomization to succeed. In this paper, we
systematically evaluate how retargeting quality affects policy performance when
excessive reward tuning is suppressed. To address issues that we identify with
existing retargeting methods, we propose a new retargeting method, General
Motion Retargeting (GMR). We evaluate GMR alongside two open-source
retargeters, PHC and ProtoMotions, as well as with a high-quality closed-source
dataset from Unitree. Using BeyondMimic for policy training, we isolate
retargeting effects without reward tuning. Our experiments on a diverse subset
of the LAFAN1 dataset reveal that while most motions can be tracked, artifacts
in retargeted data significantly reduce policy robustness, particularly for
dynamic or long sequences. GMR consistently outperforms existing open-source
methods in both tracking performance and faithfulness to the source motion,
achieving perceptual fidelity and policy success rates close to the
closed-source baseline. Website:
https://jaraujo98.github.io/retargeting_matters. Code:
https://github.com/YanjieZe/GMR.

</details>


### [40] [Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning](https://arxiv.org/abs/2510.02268)
*Tianchong Jiang,Jingtian Ji,Xiangshan Tan,Jiading Fang,Anand Bhattad,Vitor Guizilini,Matthew R. Walter*

Main category: cs.RO

TL;DR: 论文研究了通过显式将策略与相机外参条件化来实现视角不变模仿学习，发现这种方法显著提升了行为克隆策略在不同视角下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习策略在视角变化时泛化能力不足，特别是在固定场景中，策略可能通过静态背景线索推断相机姿态，这种捷径在相机位置或工作空间几何变化时会失效。

Method: 使用Plucker嵌入表示像素光线，将相机外参作为条件输入到策略中，包括ACT、Diffusion Policy和SmolVLA等行为克隆方法。在RoboSuite和ManiSkill中构建了6个操作任务，包含固定和随机化场景变体。

Result: 实验表明，不包含外参条件的策略在固定场景中依赖背景线索推断相机姿态，但在视角变化时性能下降；而包含外参条件的策略恢复了性能，实现了仅使用RGB图像的鲁棒控制。

Conclusion: 显式条件化相机外参可以显著提升模仿学习策略的视角不变性，避免对静态背景线索的依赖，实现更鲁棒的视觉控制。

Abstract: We study view-invariant imitation learning by explicitly conditioning
policies on camera extrinsics. Using Plucker embeddings of per-pixel rays, we
show that conditioning on extrinsics significantly improves generalization
across viewpoints for standard behavior cloning policies, including ACT,
Diffusion Policy, and SmolVLA. To evaluate policy robustness under realistic
viewpoint shifts, we introduce six manipulation tasks in RoboSuite and
ManiSkill that pair "fixed" and "randomized" scene variants, decoupling
background cues from camera pose. Our analysis reveals that policies without
extrinsics often infer camera pose using visual cues from static backgrounds in
fixed scenes; this shortcut collapses when workspace geometry or camera
placement shifts. Conditioning on extrinsics restores performance and yields
robust RGB-only control without depth. We release the tasks, demonstrations,
and code at https://ripl.github.io/know_your_camera/ .

</details>


### [41] [ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation](https://arxiv.org/abs/2510.02298)
*Wenye Yu,Jun Lv,Zixi Ying,Yang Jin,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: ARMADA是一个多机器人部署和适应系统，通过FLOAT自主在线故障检测方法，仅在必要时请求人工干预，显著减少对人类监督的依赖，实现高效获取领域内数据。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在从大规模真实世界数据中学习方面表现出潜力，但预训练策略在缺乏足够领域内数据时表现不佳，且人工收集演示数据成本高、质量参差不齐。

Method: 开发ARMADA系统，采用FLOAT自主在线故障检测方法，实现并行策略部署，仅在必要时请求人工干预，减少对人类监督的依赖。

Result: FLOAT在四个真实世界任务中平均准确率接近95%，比现有故障检测方法提高20%以上；ARMADA在多次策略部署和后训练中，成功率提高4倍以上，人工干预率降低2倍以上。

Conclusion: ARMADA系统通过FLOAT故障检测实现了更高效的领域内数据获取，显著提升了部署可扩展性和对新场景的适应速度。

Abstract: Imitation learning has shown promise in learning from large-scale real-world
datasets. However, pretrained policies usually perform poorly without
sufficient in-domain data. Besides, human-collected demonstrations entail
substantial labour and tend to encompass mixed-quality data and redundant
information. As a workaround, human-in-the-loop systems gather domain-specific
data for policy post-training, and exploit closed-loop policy feedback to offer
informative guidance, but usually require full-time human surveillance during
policy rollout. In this work, we devise ARMADA, a multi-robot deployment and
adaptation system with human-in-the-loop shared control, featuring an
autonomous online failure detection method named FLOAT. Thanks to FLOAT, ARMADA
enables paralleled policy rollout and requests human intervention only when
necessary, significantly reducing reliance on human supervision. Hence, ARMADA
enables efficient acquisition of in-domain data, and leads to more scalable
deployment and faster adaptation to new scenarios. We evaluate the performance
of ARMADA on four real-world tasks. FLOAT achieves nearly 95% accuracy on
average, surpassing prior state-of-the-art failure detection approaches by over
20%. Besides, ARMADA manifests more than 4$\times$ increase in success rate and
greater than 2$\times$ reduction in human intervention rate over multiple
rounds of policy rollout and post-training, compared to previous
human-in-the-loop learning methods.

</details>
