<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Debate2Create: Robot Co-design via Large Language Model Debates](https://arxiv.org/abs/2510.25850)
*Kevin Qiu,Marek Cygan*

Main category: cs.RO

TL;DR: D2C框架使用LLM代理进行结构化辩论，共同优化机器人形态和控制，通过迭代辩论产生多样化且高效的机器人设计。


<details>
  <summary>Details</summary>
Motivation: 解决机器人形态和控制协同设计的自动化挑战，克服设计空间庞大和身体行为紧密耦合的问题。

Method: 设计代理提出形态修改，控制代理制定相应奖励函数，评审团在模拟中评估并提供反馈，进行多轮迭代辩论。

Result: 在四足机器人运动基准测试中，D2C发现的设计比默认设计移动距离远73%，且产生多样化专用形态。

Conclusion: 基于LLM的多代理辩论结合物理反馈是自动化机器人设计的有前景新范式。

Abstract: Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.

</details>


### [2] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 本文提出了一种风险感知的安全过滤器，通过泊松方程和拉普拉斯引导场来编码环境理解和风险，确保机器人系统在导航时的安全性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人系统需要语义理解环境以确定安全行动，因此需要开发能够感知风险的安全表示方法。

Method: 采用两步法：通过泊松方程的狄利克雷问题生成安全函数，通过拉普拉斯方程的狄利克雷问题合成安全引导场，两者结合定义安全约束并合成风险感知安全过滤器。

Result: 在仿真中验证了该方法能够保证安全，同时优先避开高风险障碍物，并能直接整合先验的障碍物风险知识。

Conclusion: 该方法成功开发了风险感知的安全过滤器，能够生成安全且风险感知的行为，为机器人导航提供了数学基础。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a representation --
specifically, the goal is to develop safety filters that are risk-aware. To
this end, we take a two step approach: encoding an understanding of the
environment via Poisson's equation, and associated risk via Laplace guidance
fields. That is, we first solve a Dirichlet problem for Poisson's equation to
generate a safety function that encodes system safety as its 0-superlevel set.
We then separately solve a Dirichlet problem for Laplace's equation to
synthesize a safe \textit{guidance field} that encodes variable levels of
caution around obstacles -- by enforcing a tunable flux boundary condition. The
safety function and guidance fields are then combined to define a safety
constraint and used to synthesize a risk-aware safety filter which, given a
semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [3] [Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces](https://arxiv.org/abs/2510.25965)
*Luoyan Zhong,Heather Jin Hee Kim,Dylan P. Losey,Cara M. Nunez*

Main category: cs.RO

TL;DR: 开发了一种针对柔性电阻式触觉传感器的曲率感知校准方法，通过神经网络预测局部曲率，显著提高了在弯曲表面上的力测量精度和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有柔性触觉传感器主要在平坦表面上校准，但在实际应用中安装在弯曲几何体上时，其精度和一致性会下降，限制了在实际应用中的可靠性。

Method: 为广泛使用的电阻式触觉传感器设计开发了校准模型，训练多层感知器神经网络从无负载时的基线传感器输出预测局部曲率。

Result: 在5个不同曲率的日常物体上验证，曲率感知校准在所有表面上保持一致的力精度（2N-8N范围），而平坦表面校准随着曲率增加会低估力值。神经网络曲率预测的R2得分为0.91。

Conclusion: 曲率感知建模显著提高了柔性触觉传感器的精度、一致性和可靠性，使其能够在真实世界应用中实现可靠的性能。

Abstract: Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.

</details>


### [4] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 提出了一种基于欧拉轴角的新型姿态控制方法，相比传统的四元数控制，能保证闭环系统具有唯一的平衡点，并在大角度误差时提供更灵活的比例控制。


<details>
  <summary>Details</summary>
Motivation: 传统四元数姿态控制方法存在两个问题：1）不能保证闭环系统具有唯一的平衡点；2）当绕姿态误差欧拉轴的旋转误差超过π弧度时，比例控制效果会随着系统状态远离稳定平衡点而减弱。

Method: 利用姿态误差的欧拉轴角信息设计新的控制律，通过构造严格的Lyapunov函数来证明闭环旋转系统的唯一平衡点具有一致渐近稳定性。

Result: 数值仿真和数十次四旋翼飞行器的实时翻滚恢复机动测试表明，与高性能四元数控制器相比，所提出的轴角方法在稳定时间方面实现了更优越的飞行性能。

Conclusion: 基于欧拉轴角的姿态控制方法能够保证闭环系统的唯一平衡点，提供更灵活的比例控制，并在实际应用中展现出比传统四元数控制更优越的性能。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [5] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: DARTS是一个基于无人机和AI的实时交通事件检测系统，通过集成无人机高机动性、热成像技术和轻量级深度学习框架，实现了99%的检测准确率，比传统方法提前12分钟检测到事故。


<details>
  <summary>Details</summary>
Motivation: 传统交通事件检测方法存在检测与验证分离、灵活性有限、需要密集基础设施等问题，限制了系统的适应性和可扩展性。

Method: 使用无人机的高机动性和空中视角进行自适应监控，结合热成像技术提升低能见度性能和隐私保护，采用轻量级深度学习框架实时提取车辆轨迹和检测事件。

Result: 在自收集数据集上达到99%检测准确率，在佛罗里达州75号州际公路实地测试中，比当地交通管理中心提前12分钟检测到追尾事故，并能监控事故引发的拥堵传播。

Conclusion: DARTS展示了更灵活、集成的实时交通事件检测系统的潜力，对现代交通管理的运营效率和响应能力具有重要意义，特别是在偏远地区和资源受限环境中具有可扩展性和成本效益。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [6] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种利用微型无人机群搭载康普顿相机协同定位放射性材料的新方法，通过融合稀疏测量数据实时估计辐射源位置并实现动态追踪。


<details>
  <summary>Details</summary>
Motivation: 开发一种轻量化（40克）的康普顿相机探测器，为微型无人机群提供高灵敏度的辐射探测能力，解决放射性材料定位问题。

Method: 使用单探测器康普顿相机作为辐射探测器，通过融合多个无人机的测量数据实时估计辐射源位置，并采用动态反馈控制无人机群运动以最大化信息获取。

Result: 实现了在稀疏测量条件下实时定位辐射源，并能追踪移动辐射源，无人机群能够紧密协作以优化探测效率。

Conclusion: 该方法展示了轻量化康普顿相机与微型无人机群协同工作的可行性，为放射性材料定位提供了高效、实时的解决方案。

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [7] [Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods](https://arxiv.org/abs/2510.26040)
*Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams*

Main category: cs.RO

TL;DR: 提出了一种新型的自主赛车和超车智能体，能够在模拟和现实中可靠地导航赛道并超越对手，在真实F1Tenth车辆上实现了87%的超车成功率。


<details>
  <summary>Details</summary>
Motivation: 当前自主轮对轮赛车和超车技术仍存在严重限制，特别是在真实驾驶场景中，现有算法难以安全可靠地完成超车操作，而可靠的超车能力对于安全的自主轮对轮赛车至关重要。

Method: 开发了一种能够学习可靠导航和超车的新型赛车智能体，在F1Tenth平台上进行训练和部署，并与运行不同竞争算法的对手进行对抗。

Result: 该智能体在与对手对抗的训练中实现了87%的超车成功率，而仅进行赛车训练的智能体超车成功率为56%，证明了对抗训练对超车行为的提升效果。

Conclusion: 通过对抗对手的训练能够实现有意识的超车行为，显著提高了自主赛车的超车能力，为轮对轮赛车提供了有效的解决方案。

Abstract: While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.

</details>


### [8] [Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion](https://arxiv.org/abs/2510.26067)
*Chi Zhang,Mingrui Li,Wenzhe Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于图神经网络的强化学习框架，用于控制张拉整体机器人的运动，该框架能够捕捉机器人组件间的耦合关系，在仿真和实际硬件上都实现了稳定的运动控制。


<details>
  <summary>Details</summary>
Motivation: 张拉整体机器人具有高弹性和可部署性，但其欠驱动和高度耦合的动力学特性给运动控制带来了重大挑战，需要开发能够理解机器人物理拓扑结构的智能控制方法。

Method: 将图神经网络集成到Soft Actor-Critic强化学习算法中，通过将机器人的物理拓扑表示为图结构，使策略能够捕捉组件间的耦合关系，相比传统的多层感知机策略具有更快的收敛速度和更好的稳定性。

Result: 在3杆张拉整体机器人上验证了该方法在直线跟踪和双向转向等三种基本运动模式中的有效性，表现出优异的样本效率、对噪声和刚度变化的鲁棒性，以及改进的轨迹精度。学习到的策略无需微调即可从仿真直接迁移到硬件。

Conclusion: 结果表明，将结构先验知识融入强化学习对于张拉整体机器人控制具有显著优势，为复杂机器人系统的智能控制提供了新的思路。

Abstract: Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.

</details>


### [9] [I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship](https://arxiv.org/abs/2510.26080)
*Fan Yang,Renkai Ma,Yaxin Hu,Michael Rodgers,Lingyao Li*

Main category: cs.RO

TL;DR: 研究探讨社交机器人（如Moxie）服务终止对儿童造成的情绪伤害责任归属问题，发现责任被视为机器人公司、父母、开发者和政府的共同责任，但责任分配因政治意识形态和父母身份而异。


<details>
  <summary>Details</summary>
Motivation: 社交机器人旨在与儿童建立强烈情感联系，但服务突然终止会给儿童带来显著困扰和痛苦，这引发了关于责任归属的复杂问题。

Method: 以Moxie关闭为案例研究，通过对72名美国参与者进行定性调查。

Result: 研究发现责任被视为共同责任，但责任归属因政治意识形态和父母身份存在差异；参与者对机器人服务是否应继续的看法高度两极分化。

Conclusion: 研究提出了一个基于实证的共享责任框架，详细说明了责任如何分配和争议，为减轻机器人服务终止带来的情绪伤害提供了具体的设计和政策建议。

Abstract: Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.

</details>


### [10] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究发现，机器人拟人化程度对保护性反应的影响不是线性的。中等拟人化机器人引发最强的愤怒生理反应，而高拟人化机器人促使道德推理从财产损害评估转向对施虐者品德的谴责。


<details>
  <summary>Details</summary>
Motivation: 研究不同拟人化程度如何影响人们对机器人受虐的保护性反应，将计算机作为社会行动者理论和恐怖谷理论扩展到道德领域。

Method: 邀请201名参与者观看低、中、高三种拟人化程度机器人受虐的视频，通过自我报告问卷、自动面部表情分析的生理数据和定性反思进行三角测量分析。

Result: 中等拟人化的Two-Foot机器人引发最强的生理愤怒表达，自我报告的愤怒和愧疚感在Two-Foot和Humanoid机器人中都显著高于Spider机器人。随着拟人化程度增加，道德推理从技术评估转向品德谴责，治理建议从财产法扩展到准动物权利。

Conclusion: 恐怖谷现象不会削弱道德关注，反而会增强保护性冲动，这对机器人设计、政策和未来法律框架具有重要启示。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [11] [Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights](https://arxiv.org/abs/2510.26132)
*Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文探讨了具身智能作为微机器人设计原则，强调物理结构与行为功能的协同设计，通过多个机器人平台展示了智能行为如何从结构动力学和物理交互中涌现。


<details>
  <summary>Details</summary>
Motivation: 传统机器人架构将感知、计算和执行解耦，而具身智能方法通过将控制策略、反馈机制和决策逻辑嵌入到物理系统中，为毫米到厘米尺度的机器人提供更可扩展和鲁棒的解决方案。

Method: 采用协同设计方法，同时开发物理结构和行为功能，通过多个机器人平台（Bee++、RoBeetle、SMALLBug等）展示如何将反馈回路、决策逻辑和智能驱动策略嵌入到机器人物理属性中。

Result: 开发的机器人平台展示了智能行为从结构动力学和物理交互中自然涌现，证明了协同设计方法在微机器人领域的有效性。

Conclusion: 协同设计不仅是约束条件下的经验优化方法，更是实现具身智能的关键推动者，为毫米到厘米尺度的机器人提供了比传统控制方法更具可扩展性和鲁棒性的替代方案。

Abstract: The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.

</details>


### [12] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种基于混合状态树的动力学TAMP框架，统一表示规划过程中的符号和数值状态，通过视觉语言模型引导搜索，显著提高了成功率和规划效率。


<details>
  <summary>Details</summary>
Motivation: 现有TAMP方法在长时域问题中因过度运动采样而成本高昂，LLMs虽然提供常识先验但缺乏3D空间推理能力，无法保证几何或动力学可行性。

Method: 使用混合状态树统一表示符号和数值状态，通过现成运动规划器和物理模拟器验证动力学约束，利用VLM基于状态视觉渲染引导TAMP解决方案探索和回溯搜索。

Result: 在模拟和真实世界实验中，相比传统和基于LLM的TAMP规划器，平均成功率提高32.14%-1166.67%，复杂问题规划时间减少。

Conclusion: 该框架通过VLM引导和混合状态表示，有效解决了TAMP中的运动采样效率和空间推理问题，显著提升了规划性能。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [13] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 提出自适应轨迹优化算法，通过分段保守碰撞检测和基于穿透方向的位姿校正，解决移动机器人在拥挤环境中狭窄通道的轨迹规划问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在狭窄通道中经常失败或生成次优路径，需要解决移动机器人在拥挤环境中的轨迹规划挑战。

Method: 两阶段方法：1) 分段保守碰撞检测，递归细分风险轨迹段消除碰撞风险；2) 基于穿透方向和线性搜索的位姿校正，确保每个位姿无碰撞且远离障碍物。

Result: 仿真结果显示，相比最先进方法，成功率提高1.69倍，规划时间加快3.79倍；真实实验证实机器人能安全通过狭窄通道并保持快速规划性能。

Conclusion: 所提方法在拥挤环境中有效解决了狭窄通道的轨迹规划问题，显著提高了成功率和规划效率。

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [14] [Self-localization on a 3D map by fusing global and local features from a monocular camera](https://arxiv.org/abs/2510.26170)
*Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki*

Main category: cs.RO

TL;DR: 提出结合CNN和Vision Transformer的新方法，在动态障碍物存在时提升3D地图上的单目相机自定位精度


<details>
  <summary>Details</summary>
Motivation: 基于相机的自定位通常使用CNN提取局部特征，但在存在动态障碍物（如行人）时效果不佳

Method: 将CNN与擅长提取全局特征的Vision Transformer相结合，利用补丁间的关系来改善定位性能

Result: 在CG数据集上，动态障碍物存在时的精度提升率比无障碍物时高1.5倍；在公开数据集上定位误差比SOTA减少20.1%；机器人平均定位误差为7.51cm

Conclusion: 所提出的CNN与Vision Transformer结合方法能有效提升动态障碍物环境下的自定位精度

Abstract: Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.

</details>


### [15] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: PHUMA是一个基于物理约束的人形机器人运动数据集，通过大规模人类视频数据生成，解决了现有方法中的物理伪影问题，在运动模仿任务中表现优于Humanoid-X和AMASS。


<details>
  <summary>Details</summary>
Motivation: 现有运动模仿方法依赖高质量动作捕捉数据（如AMASS），但这些数据稀缺且昂贵，限制了可扩展性和多样性。基于互联网视频的方法（如Humanoid-X）存在物理伪影问题，影响稳定模仿。

Method: 通过精心数据筛选和物理约束重定向，PHUMA强制执行关节限制、确保地面接触、消除足部滑动，生成大规模且物理可靠的运动数据。

Result: 在未见运动模仿和骨盆引导路径跟随两种条件下，PHUMA训练的策略均优于Humanoid-X和AMASS，在模仿多样化运动方面取得显著提升。

Conclusion: PHUMA成功解决了基于视频的运动数据中的物理伪影问题，为人形机器人运动模仿提供了大规模、物理可靠的训练数据。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [16] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: 提出Thor人形机器人框架，通过力自适应躯干倾斜奖励函数和解耦强化学习架构，显著提升了人形机器人在接触丰富环境中的力交互能力。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在接触丰富环境中保持全身稳定性并产生类人自适应响应的挑战，这对于服务、工业和救援应用至关重要。

Method: 基于机器人受力分析设计FAT2奖励函数，采用解耦的强化学习架构分别控制上半身、腰部和下半身，各组件共享全局观测并联合更新参数。

Result: 在Unitree G1上部署Thor，向后移动时峰值拉力达167.7N（约G1体重的48%），向前移动时达145.5N，相比最佳基线分别提升68.9%和74.7%。能够拉动130N负载的货架和单手打开60N的防火门。

Conclusion: Thor框架有效增强了人形机器人的力交互能力，在接触丰富环境中表现出类人的自适应响应特性。

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [17] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: AgriGS-SLAM是一个用于果园环境的视觉-LiDAR SLAM框架，结合直接LiDAR里程计和多相机3D高斯溅射渲染，能在重复几何结构、季节变化和风动干扰下实现实时3D场景理解。


<details>
  <summary>Details</summary>
Motivation: 果园环境中的自主机器人需要实时3D场景理解，但面临重复行几何、季节性外观变化和风驱动叶片运动等挑战。

Method: 结合直接LiDAR里程计和闭环检测，使用多相机3D高斯溅射渲染，通过批量栅格化互补视角恢复遮挡下的果园结构，采用统一梯度驱动的地图生命周期管理。

Result: 在苹果和梨园多个季节的测试中，相比现有3DGS-SLAM基线方法，AgriGS-SLAM提供了更清晰、更稳定的重建和更平稳的轨迹，同时保持实时性能。

Conclusion: 该方法在果园监测中表现优异，也可应用于其他需要鲁棒多模态感知的户外领域。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [18] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了基于共形几何代数的多臂机器人系统协作任务空间理论框架，通过几何基元的相似变换将复杂系统抽象为单臂系统，并推导了相关的雅可比矩阵，实现了经典控制技术的集成应用。


<details>
  <summary>Details</summary>
Motivation: 人类环境中的许多任务需要多个运动链的协作行为，但协调高自由度系统的运动建模非常困难。本文旨在为多臂机器人系统建立协作任务空间的理论基础。

Method: 使用共形几何代数定义几何基元，基于这些协作几何基元的相似变换推导系统抽象表示，并导出解析和几何雅可比矩阵，集成到基于操作空间控制的经典控制技术中。

Result: 在双手机器人、仿人机器人和多指手的实验中验证了方法的有效性，包括达到期望几何基元的最优控制实验和使用微分运动学控制的遥操作实验。

Conclusion: 该工作建立了协作操作控制框架的理论基础，几何基元自然地嵌入了控制器中的零空间结构，可用于引入次级控制目标，为未来应用提供了方向。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [19] [Towards Reinforcement Learning Based Log Loading Automation](https://arxiv.org/abs/2510.26363)
*Ilya Kurinov,Miroslav Ivanov,Grzegorz Orzechowski,Aki Mikkola*

Main category: cs.RO

TL;DR: 本研究利用强化学习代理和课程学习方法，在NVIDIA Isaac Gym中开发了林业集材机模拟模型，实现了从抓取到运输的完整原木装载自动化，最佳代理成功率94%。


<details>
  <summary>Details</summary>
Motivation: 林业集材机操作对操作员来说具有挑战性且身心疲惫，部分自动化可以减轻操作员压力。本研究延续先前在自动化原木处理过程中应用强化学习代理的研究，将任务从抓取扩展到完整装载操作。

Method: 在NVIDIA Isaac Gym中开发了拖车型林业集材机模拟模型和典型原木装载场景的虚拟环境，使用强化学习代理和课程学习方法来训练代理。

Result: 训练出的代理能够从随机位置抓取原木并将其运输到车厢，最佳执行代理的成功率达到94%。

Conclusion: 该训练代理可能是将强化学习代理应用于林业集材机自动化的一个重要进展。

Abstract: Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.

</details>


### [20] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: Hi-ORS是一种简单有效的后训练方法，通过拒绝采样实现训练稳定性和高鲁棒性，在1.5小时真实世界训练中显著优于RL和IL基线方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习训练视觉语言动作模型时存在价值估计不准确和中间步骤监督稀疏的问题，而模仿学习虽然易于训练但性能不足。

Method: 采用拒绝采样过滤负奖励样本稳定价值估计，使用奖励加权的监督训练目标提供密集中间步骤监督，并开发支持在线人工校正的异步推理训练框架。

Result: 在三个真实世界任务和两个实体上，Hi-ORS在1.5小时内微调基础策略掌握接触丰富的操作，在效果和效率上都大幅优于RL和IL基线方法。

Conclusion: Hi-ORS通过结合拒绝采样和奖励加权监督训练，实现了训练稳定性和高鲁棒性，微调后的策略展现出强大的测试时扩展能力。

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [21] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了RoboOS-NeXT框架，通过统一的时空-具身记忆(STEM)实现多机器人系统的终身适应、可扩展协调和鲁棒调度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限的个体记忆，无法实现长期学习、异构团队扩展或故障恢复，需要统一的记忆表示。

Method: 核心是Spatio-Temporal-Embodiment Memory (STEM)，整合空间场景几何、时间事件历史和具身配置文件，采用大脑-小脑框架进行全局规划和本地执行。

Result: 在餐厅、超市和家庭等复杂协调任务中表现出优越性能，验证了其在异构具身系统中的有效性。

Conclusion: RoboOS-NeXT通过记忆中心设计实现了终身、可扩展和鲁棒的多机器人协作。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [22] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 提出了一种扩展机器人逆运动学求解器的新框架，使机器人能够学习使用不同长度工具的顺序动作技能，并在仿真和现实世界之间实现技能迁移。


<details>
  <summary>Details</summary>
Motivation: 传统机器人对自身运动学理解有限，只能执行预设任务，无法有效利用工具。需要解决工具使用的四个关键要素：理解期望结果、选择合适工具、确定最佳工具方向、执行精确操作。

Method: 通过扩展机器人逆运动学求解器，集成仿真学习的动作轨迹与工具，使机器人能够获取使用不同长度工具的顺序动作技能。

Result: 扩展逆运动学求解器误差小于1cm；训练策略在仿真中平均误差为8cm；使用两种不同长度工具时性能几乎无差异。

Conclusion: 该研究为探索工具使用的四个基本方面提供了潜在进展，使机器人能够掌握跨不同任务的复杂工具操作技能。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [23] [FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles](https://arxiv.org/abs/2510.26588)
*Gang Li,Chunlei Zhai,Teng Wang,Shaun Li,Shangsong Jiang,Xiangwei Zhu*

Main category: cs.RO

TL;DR: FLYINGTRUST是一个高保真、可配置的四旋翼无人机导航基准测试框架，用于评估平台动力学和场景结构对导航鲁棒性的联合影响。


<details>
  <summary>Details</summary>
Motivation: 四旋翼无人机视觉导航算法在不同平台和场景间性能差异大，增加了现场部署的成本和风险，需要系统化的早期评估方法。

Method: 使用最大推力重量比和轴间最大角加速度作为平台能力指标，结合多样化场景库和真实/虚拟平台，采用标准化评估协议和复合评分方法。

Result: 发现导航成功率可预测地依赖于平台能力和场景几何，不同算法在不同条件下表现出明显的偏好和失效模式。

Conclusion: 必须将平台能力和场景结构纳入算法设计、评估和选择，未来需要开发在多样化平台和场景下保持鲁棒性的方法。

Abstract: Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.

</details>


### [24] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种用于连续体机器人连续时间状态估计的滑动窗口滤波器，在提高滤波方法精度的同时，使连续时间方法能够在线运行，且速度快于实时速度。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人随机状态估计方法难以平衡精度和计算效率。滑动窗口方法仅限于简化的离散时间近似且不提供随机表示，而随机滤波方法受限于测量速度。连续时间估计方法虽然原理上解决了运行时约束，但目前仅限于离线操作。

Method: 开发了一种专门为连续体机器人设计的滑动窗口滤波器，用于连续时间状态估计。该方法结合了滑动窗口和连续时间估计的优势。

Result: 该滑动窗口滤波器在提高滤波方法精度的同时，使连续时间方法能够在线运行，并且运行速度快于实时速度。

Conclusion: 这是第一个专门为连续体机器人设计的随机滑动窗口滤波器，为该领域的未来研究提供了有前景的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [25] [REALMS2 -- Resilient Exploration And Lunar Mapping System 2 -- A Comprehensive Approach](https://arxiv.org/abs/2510.26638)
*Dave van der Meer,Loïck P. Chovet,Gabriel M. Garcia,Abhishek Bera,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: REALMS2是一个基于ROS 2的多机器人系统框架，用于行星勘探和地图构建，在ESA-ESRIC挑战赛的实地测试中成功绘制了约60%的区域。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在太空勘探中的挑战，特别是应对地外环境的通信延迟和中断问题。

Method: 使用ROS 2框架，集成视觉SLAM进行地图生成，采用网状网络建立鲁棒的自组织网络，通过单一GUI控制所有漫游车。

Result: 在ESA-ESRIC挑战赛第二次实地测试中，使用三个同构漫游车成功绘制了约60%的区域，能够处理通信延迟和中断。

Conclusion: REALMS2系统为异构多机器人勘探任务提供了一个有效的解决方案，特别适合应对地外环境的挑战。

Abstract: The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.

</details>


### [26] [Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments](https://arxiv.org/abs/2510.26646)
*Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai*

Main category: cs.RO

TL;DR: 提出分层路径规划与控制框架，结合高层DQN进行离散子目标选择和底层TD3控制器进行连续驱动，在动态和部分可观测环境中实现改进的成功率和样本效率。


<details>
  <summary>Details</summary>
Motivation: 解决单一算法在复杂环境中路径规划的局限性，通过分层结构结合离散决策和连续控制，提高在动态和部分可观测环境中的导航性能。

Method: 使用高层Deep Q-Network进行子目标选择，底层Twin Delayed Deep Deterministic Policy Gradient控制器执行连续速度命令，设计实用奖励机制和LiDAR安全门防止不安全运动。

Result: 在ROS + Gazebo环境中评估显示，相比单一算法基准和基于规则的规划器，具有更高的成功率、更好的泛化能力和更平滑的控制变化。

Conclusion: 分层框架有效结合了离散决策和连续控制的优势，在复杂环境中实现了更鲁棒和高效的路径规划性能。

Abstract: This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.

</details>


### [27] [Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems](https://arxiv.org/abs/2510.26656)
*Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 提出了三种启发式LFI变体（EDGE、MODE、CENTRE）来解决支持集错误指定问题，通过在推理过程中自适应调整支持集来提高后验推断和策略学习的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统LFI方法假设固定的支持集，但错误指定的支持集会导致次优且虚假确定的后验分布，影响机器人领域的适应性能。

Method: 提出了三种启发式LFI变体，每种方法以不同方式解释后验模式在推理步骤中的移动，并将支持集适应集成到LFI步骤中。

Result: 在随机动态基准测试中验证了支持集错误指定问题，并在DLO操作任务中展示了改进的参数推断和策略学习效果，实现了更精细的长度和刚度分类。

Conclusion: 提出的支持集自适应方法能够产生更鲁棒的后验分布，当用作基于仿真的策略学习的领域分布时，能提高面向对象的智能体性能。

Abstract: In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.

</details>


### [28] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: 提出混合一致性策略(HCP)，通过结合随机前缀和一致性跳跃，在保持多模态行为的同时实现快速采样


<details>
  <summary>Details</summary>
Motivation: 解决基于扩散的模仿学习中，传统方法难以同时实现快速采样和强大多模态性的问题

Method: HCP运行短随机前缀到自适应切换时间，然后应用一步一致性跳跃生成最终动作，采用时变一致性蒸馏结合轨迹一致性目标和去噪匹配目标

Result: 在仿真和真实机器人上，HCP仅需25步SDE加一次跳跃即可接近80步DDPM教师的精度和模态覆盖度，显著降低延迟

Conclusion: 多模态性不需要慢推理，切换时间将模态保持与速度解耦，为机器人策略提供了实用的精度效率权衡

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [29] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 提出了一种在单张消费级GPU上实现30Hz帧率和480Hz轨迹频率的多视角VLA实时推理方法，使大型VLA模型能够处理动态实时任务。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言动作模型在实时机器人控制中的推理延迟问题，实现之前被认为无法达到的动态实时任务。

Method: 引入一系列策略消除模型推理中的开销，包括优化推理流程和提出完整的流式推理框架。

Result: 在抓取下落笔的任务中实现了100%的成功率，证明了方法的有效性。

Conclusion: 成功实现了VLA模型的实时推理，为实时机器人控制提供了可行的解决方案，代码已开源。

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>
