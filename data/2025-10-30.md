<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 30]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving](https://arxiv.org/abs/2510.24949)
*Anil Yildiz,Sarah M. Thornton,Carl Hildebrandt,Sreeja Roy-Singh,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出SCOUT轻量级替代模型，直接从智能体潜在传感器表示预测场景覆盖标签，避免昂贵的人类标注或计算密集型大视觉语言模型推理


<details>
  <summary>Details</summary>
Motivation: 现有场景覆盖评估方法依赖昂贵的人工标注或计算密集型大视觉语言模型，不适用于大规模部署的成本和效率要求

Method: 通过蒸馏过程训练SCOUT模型，学习近似LVLM生成的覆盖标签，利用预计算感知特征避免冗余计算

Result: 在真实自动驾驶导航场景数据集上验证，SCOUT在保持高精度的同时显著降低计算成本

Conclusion: SCOUT为大规模覆盖分析提供了有效实用的替代方案，是实现自主系统高效场景覆盖监督的重要进展

Abstract: Assessing scenario coverage is crucial for evaluating the robustness of
autonomous agents, yet existing methods rely on expensive human annotations or
computationally intensive Large Vision-Language Models (LVLMs). These
approaches are impractical for large-scale deployment due to cost and
efficiency constraints. To address these shortcomings, we propose SCOUT
(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate
model designed to predict scenario coverage labels directly from an agent's
latent sensor representations. SCOUT is trained through a distillation process,
learning to approximate LVLM-generated coverage labels while eliminating the
need for continuous LVLM inference or human annotation. By leveraging
precomputed perception features, SCOUT avoids redundant computations and
enables fast, scalable scenario coverage estimation. We evaluate our method
across a large dataset of real-life autonomous navigation scenarios,
demonstrating that it maintains high accuracy while significantly reducing
computational cost. Our results show that SCOUT provides an effective and
practical alternative for large-scale coverage analysis. While its performance
depends on the quality of LVLM-generated training labels, SCOUT represents a
major step toward efficient scenario coverage oversight in autonomous systems.

</details>


### [2] [Smooth path planning with safety margins using Piece-Wise Bezier curves](https://arxiv.org/abs/2510.24972)
*Iancu Andrei,Marius Kloetzer,Cristian Mahulea,Catalin Dosoftei*

Main category: cs.RO

TL;DR: 提出了一种基于二次规划的高效路径规划方法，使用分段二次贝塞尔曲线为移动机器人生成平滑的C1连续路径，在保证安全裕度的同时实现实时计算。


<details>
  <summary>Details</summary>
Motivation: 传统分段线性路径规划方法在平滑性和鲁棒性方面存在不足，需要一种既能保证路径质量又适合实时应用的优化方法。

Method: 采用分段二次贝塞尔曲线，在结构化优化框架中显式集成安全裕度，平衡轨迹平滑度、鲁棒性和计算复杂度。

Result: 与传统分段线性方法相比，轨迹偏差显著减小，鲁棒性增强，整体路径质量提升，在Pure-Pursuit控制器仿真中验证了有效性。

Conclusion: 该方法在保证安全导航的同时具有实际有效性和可扩展性，特别适合实时和嵌入式应用。

Abstract: In this paper, we propose a computationally efficient quadratic programming
(QP) approach for generating smooth, $C^1$ continuous paths for mobile robots
using piece-wise quadratic Bezier (PWB) curves. Our method explicitly
incorporates safety margins within a structured optimization framework,
balancing trajectory smoothness and robustness with manageable numerical
complexity suitable for real-time and embedded applications. Comparative
simulations demonstrate clear advantages over traditional piece-wise linear
(PWL) path planning methods, showing reduced trajectory deviations, enhanced
robustness, and improved overall path quality. These benefits are validated
through simulations using a Pure-Pursuit controller in representative
scenarios, highlighting the practical effectiveness and scalability of our
approach for safe navigation.

</details>


### [3] [Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT](https://arxiv.org/abs/2510.24994)
*Matsive Ali,Blake Gassen,Sen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种集成机器人熔融沉积成型增材制造系统，具有闭环热控制和智能原位缺陷校正功能，使用6自由度机械臂和Oak-D相机实现实时质量保证。


<details>
  <summary>Details</summary>
Motivation: 解决传统增材制造中缺乏实时质量控制和缺陷自动校正的问题，提高打印质量和可靠性，特别适用于航空航天、生物医学等对精度要求高的应用领域。

Method: 采用6自由度机械臂配合E3D热端，通过IoT微控制器实现闭环热控制；使用ROS2协调机器人运动与挤出同步；基于OpenCV的视觉系统检测层间缺陷位置，并命令自主重新挤出；应用逆运动学进行运动规划，通过单应性变换校正相机视角。

Result: 实验验证显示系统成功缓解了打印操作中的缺陷，能够在不中断打印过程的情况下有效减轻表面异常，实现了实时质量保证。

Conclusion: 通过结合实时热调节、运动控制和智能缺陷检测与校正，该架构建立了一个可扩展和自适应的机器人增材制造框架，适用于航空航天、生物医学和工业应用。

Abstract: This paper presents an integrated robotic fused deposition modeling additive
manufacturing system featuring closed-loop thermal control and intelligent
in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D
camera. The robot arm end effector was modified to mount an E3D hotend
thermally regulated by an IoT microcontroller, enabling precise temperature
control through real-time feedback. Filament extrusion system was synchronized
with robotic motion, coordinated via ROS2, ensuring consistent deposition along
complex trajectories. A vision system based on OpenCV detects layer-wise
defects position, commanding autonomous re-extrusion at identified sites.
Experimental validation demonstrated successful defect mitigation in printing
operations. The integrated system effectively addresses challenges real-time
quality assurance. Inverse kinematics were used for motion planning, while
homography transformations corrected camera perspectives for accurate defect
localization. The intelligent system successfully mitigated surface anomalies
without interrupting the print process. By combining real-time thermal
regulation, motion control, and intelligent defect detection & correction, this
architecture establishes a scalable and adaptive robotic additive manufacturing
framework suitable for aerospace, biomedical, and industrial applications.

</details>


### [4] [Scalable predictive processing framework for multitask caregiving robots](https://arxiv.org/abs/2510.25053)
*Hayato Idei,Tamon Miyake,Tetsuya Ogata,Yuichi Yamashita*

Main category: cs.RO

TL;DR: 提出基于预测处理的分层多模态循环神经网络，能够直接整合3万维视觉-本体感觉输入，无需降维即可学习护理任务，展示了分层潜在动态自组织、视觉退化鲁棒性和多任务学习中的不对称干扰等特性。


<details>
  <summary>Details</summary>
Motivation: 现有护理机器人系统多为任务特定型且依赖手工预处理，难以泛化到多样化场景。受人类大脑通过分层预测处理实现灵活认知的启发，开发通用计算框架。

Method: 基于自由能原理的预测处理框架，构建分层多模态循环神经网络，直接处理高维视觉-本体感觉输入，无需任务特定特征工程，学习刚性物体重新定位和柔性毛巾擦拭两种护理任务。

Result: 模型能够自组织分层潜在动态来调节任务转换、捕捉不确定性变化并推断遮挡状态；在视觉退化时通过视觉-本体感觉整合保持鲁棒性；多任务学习呈现不对称干扰，但整体保持稳健性能。

Conclusion: 预测处理作为通用可扩展计算原理，为实现鲁棒、灵活、自主的护理机器人提供了方向，同时为理解人脑在不确定环境中实现灵活适应的机制提供了理论见解。

Abstract: The rapid aging of societies is intensifying demand for autonomous care
robots; however, most existing systems are task-specific and rely on
handcrafted preprocessing, limiting their ability to generalize across diverse
scenarios. A prevailing theory in cognitive neuroscience proposes that the
human brain operates through hierarchical predictive processing, which
underlies flexible cognition and behavior by integrating multimodal sensory
signals. Inspired by this principle, we introduce a hierarchical multimodal
recurrent neural network grounded in predictive processing under the
free-energy principle, capable of directly integrating over 30,000-dimensional
visuo-proprioceptive inputs without dimensionality reduction. The model was
able to learn two representative caregiving tasks, rigid-body repositioning and
flexible-towel wiping, without task-specific feature engineering. We
demonstrate three key properties: (i) self-organization of hierarchical latent
dynamics that regulate task transitions, capture variability in uncertainty,
and infer occluded states; (ii) robustness to degraded vision through
visuo-proprioceptive integration; and (iii) asymmetric interference in
multitask learning, where the more variable wiping task had little influence on
repositioning, whereas learning the repositioning task led to a modest
reduction in wiping performance, while the model maintained overall robustness.
Although the evaluation was limited to simulation, these results establish
predictive processing as a universal and scalable computational principle,
pointing toward robust, flexible, and autonomous caregiving robots while
offering theoretical insight into the human brain's ability to achieve flexible
adaptation in uncertain real-world environments.

</details>


### [5] [Non-Invasive Calibration Of A Stewart Platform By Photogrammetry](https://arxiv.org/abs/2510.25072)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出了一种基于Denavit-Hartenberg约定的前向运动学标定方法，使用摄影测量技术对Stewart平台进行非侵入式标定，通过最小二乘法估计误差补偿，显著提高了平台位姿精度。


<details>
  <summary>Details</summary>
Motivation: Stewart平台的前向运动学标定具有挑战性，因为前向运动学通常会产生多个可行和不可行的解，且六个执行器路径之间的复杂运动学关系使得难以建立直接有效的标定方法。

Method: 使用Denavit-Hartenberg约定开发前向运动学标定方法，采用摄影测量技术（高分辨率数码相机和现成软件）捕捉移动平台中心的位姿，通过最小二乘法估计误差补偿。

Result: 三种补偿方法均显示出平台位姿精度的显著提升，表明有进一步改进的空间。

Conclusion: 提出的摄影测量标定方法是非侵入式的，无需在六足机器人上附加额外设备或修改硬件，能够有效提高Stewart平台的标定精度。

Abstract: Accurate calibration of a Stewart platform is important for their precise and
efficient operation. However, the calibration of these platforms using forward
kinematics is a challenge for researchers because forward kinematics normally
generates multiple feasible and unfeasible solutions for any pose of the moving
platform. The complex kinematic relations among the six actuator paths
connecting the fixed base to the moving platform further compound the
difficulty in establishing a straightforward and efficient calibration method.
The authors developed a new forward kinematics-based calibration method using
Denavit-Hartenberg convention and used the Stewart platform Tiger 66.1
developed in their lab for experimenting with the photogrammetry-based
calibration strategies described in this paper. This system became operational
upon completion of construction, marking its inaugural use. The authors used
their calibration model for estimating the errors in the system and adopted
three compensation options or strategies as per Least Square method to improve
the accuracy of the system. These strategies leveraged a high-resolution
digital camera and off-the-shelf software to capture the poses of the moving
platform's center. This process is non-invasive and does not need any
additional equipment to be attached to the hexapod or any alteration of the
hexapod hardware. This photogrammetry-based calibration process involves
multiple high-resolution images from different angles to measure the position
and orientation of the platform center in the three-dimensional space. The
Target poses and Actual poses are then compared, and the error compensations
are estimated using the Least-Squared methods to calculate the Predicted poses.
Results from each of the three compensation approaches demonstrated noticeable
enhancements in platform pose accuracies, suggesting room for further
improvements.

</details>


### [6] [Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration](https://arxiv.org/abs/2510.25086)
*Guibin Sun,Jinhu Lü,Kexin Liu,Zhenqian Wang,Guanrong Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人群体无分配协作的最新进展，重点研究形态形成问题，提出了均值漂移探索策略，大幅提升了大规模群体的协作效率。


<details>
  <summary>Details</summary>
Motivation: 自然界中群体行为展现的高效协作启发了机器人群体智能的研究，但传统的基于分配的协作方法在效率和鲁棒性方面存在根本性限制，无法扩展到群体变体。

Method: 提出了均值漂移探索策略作为关键理论组件，用于解决机器人群体的无分配协作问题，特别关注形态形成任务。

Result: 均值漂移探索策略将大规模群体的协作效率提升了数十倍，且随着群体规模的增加，效率提升更为显著。

Conclusion: 文章讨论了均值漂移探索策略在精确形态形成、区域覆盖形成和机动形成三个重要应用，及其在智能仓储、区域探索和货物运输等工业场景中的应用前景。

Abstract: Swarms evolving from collective behaviors among multiple individuals are
commonly seen in nature, which enables biological systems to exhibit more
efficient and robust collaboration. Creating similar swarm intelligence in
engineered robots poses challenges to the design of collaborative algorithms
that can be programmed at large scales. The assignment-based method has played
an eminent role for a very long time in solving collaboration problems of robot
swarms. However, it faces fundamental limitations in terms of efficiency and
robustness due to its unscalability to swarm variants. This article presents a
tutorial review on recent advances in assignment-free collaboration of robot
swarms, focusing on the problem of shape formation. A key theoretical component
is the recently developed \emph{mean-shift exploration} strategy, which
improves the collaboration efficiency of large-scale swarms by dozens of times.
Further, the efficiency improvement is more significant as the swarm scale
increases. Finally, this article discusses three important applications of the
mean-shift exploration strategy, including precise shape formation, area
coverage formation, and maneuvering formation, as well as their corresponding
industrial scenarios in smart warehousing, area exploration, and cargo
transportation.

</details>


### [7] [NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](https://arxiv.org/abs/2510.25122)
*Jiahong Chen,Jing Wang,Long Chen,Chuwei Cai,Jinghui Lu*

Main category: cs.RO

TL;DR: 提出了NanoVLA，一种轻量级视觉-语言-动作模型，通过在边缘设备上实现高效推理，解决了传统VLA模型在资源受限设备上部署的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-语言-动作模型在资源受限的边缘设备上部署困难，计算需求高，难以满足实时场景下的功耗、延迟和计算资源要求。

Method: 采用视觉-语言解耦将早期融合改为后期融合，长短期动作分块确保多步规划的连贯性，动态路由根据任务复杂度自适应选择轻量或重量主干网络。

Result: 在边缘设备上实现比现有VLA模型快52倍的推理速度，参数减少98%，同时保持或超越任务准确性和泛化能力。

Conclusion: NanoVLA通过创新的架构设计，实现了在资源受限硬件上的高效、高精度机器人操作，为边缘设备上的VLA模型部署提供了实用解决方案。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
manipulation by integrating vision-language models (VLMs), and action decoders
into a unified architecture. However, their deployment on resource-constrained
edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin
Nano), remains challenging due to high computational demands, especially in
real-world scenarios where power, latency, and computational resources are
critical. To close this gap, we introduce Nano-scale Vision-Language Action
(NanoVLA), a family of lightweight VLA architectures that achieve high
performance with minimal resources. Our core innovations include: (1)
vision-language decoupling that moves conventional early vision and language
inputs fusion in VLM to late stage, achieving better performance while enabling
caching and reduce inference overhead and latency; (2) long-short action
chunking to ensure smooth, coherent multi-step planning without sacrificing
real-time responsiveness; (3) dynamic routing that adaptively assigns
lightweight or heavy backbones based on task complexity, further optimizing
inference efficiency. Experimental results on several benchmarks, as well as
real-world deployments, demonstrate that NanoVLA achieves up to 52x faster
inference on edge devices compared to previous state-of-the-art VLA models,
with 98% less parameters while maintaining or surpassing their task accuracy
and generalization. Ablation studies confirm that our decoupling strategy
preserves cross-task transferability, and the routing module enhances
cost-performance trade-offs, enabling practical, high-precision robotic
manipulation on resource-constrained hardware.

</details>


### [8] [Learning Spatial-Aware Manipulation Ordering](https://arxiv.org/abs/2510.25138)
*Yuxiang Yan,Zhiyuan Zhou,Xin Gao,Guanghao Li,Shenglin Li,Jiaqi Chen,Qunyan Pu,Jian Pu*

Main category: cs.RO

TL;DR: OrderMind是一个空间感知的操纵排序框架，通过空间图神经网络学习物体操纵优先级，解决杂乱环境中物体空间依赖关系导致的碰撞和访问阻塞问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法往往忽视物体间的空间关系，限制了在杂乱环境中操纵的灵活性和可扩展性。不恰当的操纵顺序会导致碰撞或访问阻塞。

Method: 使用k-最近邻构建空间图来聚合局部布局的几何信息，编码物体-物体和物体-操纵器交互。通过空间先验标注方法引导视觉语言模型生成合理的操纵顺序用于知识蒸馏。

Result: 在包含163,222个样本的操纵排序基准测试中，OrderMind在仿真和真实环境中都显著优于现有方法，在有效性和效率方面表现优异。

Conclusion: OrderMind能够实现杂乱场景中的鲁棒操纵，通过空间感知的优先级学习解决了操纵排序的关键挑战。

Abstract: Manipulation in cluttered environments is challenging due to spatial
dependencies among objects, where an improper manipulation order can cause
collisions or blocked access. Existing approaches often overlook these spatial
relationships, limiting their flexibility and scalability. To address these
limitations, we propose OrderMind, a unified spatial-aware manipulation
ordering framework that directly learns object manipulation priorities based on
spatial context. Our architecture integrates a spatial context encoder with a
temporal priority structuring module. We construct a spatial graph using
k-Nearest Neighbors to aggregate geometric information from the local layout
and encode both object-object and object-manipulator interactions to support
accurate manipulation ordering in real-time. To generate physically and
semantically plausible supervision signals, we introduce a spatial prior
labeling method that guides a vision-language model to produce reasonable
manipulation orders for distillation. We evaluate OrderMind on our Manipulation
Ordering Benchmark, comprising 163,222 samples of varying difficulty. Extensive
experiments in both simulation and real-world environments demonstrate that our
method significantly outperforms prior approaches in effectiveness and
efficiency, enabling robust manipulation in cluttered scenes.

</details>


### [9] [SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning](https://arxiv.org/abs/2510.25191)
*Hongyu Song,Rishabh Dev Yadav,Cheng Guo,Wei Pan*

Main category: cs.RO

TL;DR: SoraNav是一个自适应无人机导航框架，将零样本视觉语言模型推理与几何感知决策相结合，显著提升了无人机在2.5D和3D环境中的导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言导航方法主要针对地面机器人设计，难以推广到需要完整3D空间推理的空中任务。大型视觉语言模型虽然具有零样本语义推理能力，但缺乏空间基础，无法直接应用于导航。

Method: 提出SoraNav框架，在图像标注中融入几何先验来约束VLM动作空间，采用混合切换策略结合导航历史，在VLM推理和基于几何的探索之间交替，避免死胡同和重复访问。

Result: 在2.5D场景中，成功率提高25.7%，路径长度加权成功率提高17%；在3D场景中，成功率提高29.5%，路径长度加权成功率提高18.5%。

Conclusion: SoraNav通过结合零样本VLM推理和几何感知决策，有效解决了无人机在复杂3D环境中的导航挑战，显著提升了导航性能。

Abstract: Interpreting visual observations and natural language instructions for
complex task execution remains a key challenge in robotics and AI. Despite
recent advances, language-driven navigation is still difficult, particularly
for UAVs in small-scale 3D environments. Existing Vision-Language Navigation
(VLN) approaches are mostly designed for ground robots and struggle to
generalize to aerial tasks that require full 3D spatial reasoning. The
emergence of large Vision-Language Models (VLMs), such as GPT and Claude,
enables zero-shot semantic reasoning from visual and textual inputs. However,
these models lack spatial grounding and are not directly applicable to
navigation. To address these limitations, SoraNav is introduced, an adaptive
UAV navigation framework that integrates zero-shot VLM reasoning with
geometry-aware decision-making. Geometric priors are incorporated into image
annotations to constrain the VLM action space and improve decision quality. A
hybrid switching strategy leverages navigation history to alternate between VLM
reasoning and geometry-based exploration, mitigating dead-ends and redundant
revisits. A PX4-based hardware-software platform, comprising both a digital
twin and a physical micro-UAV, enables reproducible evaluation. Experimental
results show that in 2.5D scenarios, our method improves Success Rate (SR) by
25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it
improves SR by 29.5% and SPL by 18.5% relative to the baseline.

</details>


### [10] [RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis](https://arxiv.org/abs/2510.25211)
*Amith Khandakar,David Michelson,Shaikh Golam Rabbani,Fariya Bintay Shafi,Md. Faysal Ahamed,Khondokar Radwanur Rahman,Md Abidur Rahman,Md. Fahmidun Nabi,Mohamed Arselene Ayari,Khaled Khan,Ponnuthurai Nagaratnam Suganthan*

Main category: cs.RO

TL;DR: 提出一个结合GIS、天气和视频数据的道路质量监测数据集，用于改善交通管理和道路安全


<details>
  <summary>Details</summary>
Motivation: 缺乏高质量标准化数据集阻碍了基于智能手机传感器监测道路状况的研究进展

Method: 开发移动应用收集GPS、加速度计、陀螺仪、磁力计等多种传感器数据，并整合GIS、天气和视频信息

Result: 创建了包含车辆速度、加速度、旋转率等关键数据，以及地理空间和视觉上下文信息的综合数据集

Conclusion: 该数据集将公开可用，旨在支持智能交通系统的研究创新，促进交通管理、基础设施发展和道路安全

Abstract: It's important to monitor road issues such as bumps and potholes to enhance
safety and improve road conditions. Smartphones are equipped with various
built-in sensors that offer a cost-effective and straightforward way to assess
road quality. However, progress in this area has been slow due to the lack of
high-quality, standardized datasets. This paper discusses a new dataset created
by a mobile app that collects sensor data from devices like GPS,
accelerometers, gyroscopes, magnetometers, gravity sensors, and orientation
sensors. This dataset is one of the few that integrates Geographic Information
System (GIS) data with weather information and video footage of road
conditions, providing a comprehensive understanding of road issues with
geographic context. The dataset allows for a clearer analysis of road
conditions by compiling essential data, including vehicle speed, acceleration,
rotation rates, and magnetic field intensity, along with the visual and spatial
context provided by GIS, weather, and video data. Its goal is to provide
funding for initiatives that enhance traffic management, infrastructure
development, road safety, and urban planning. Additionally, the dataset will be
publicly accessible to promote further research and innovation in smart
transportation systems.

</details>


### [11] [Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery](https://arxiv.org/abs/2510.25233)
*Jee Won Lee,Hansol Lim,Sooyeun Yang,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: 提出了一种混合视觉跟踪框架，结合全局模板匹配、深度特征Lucas-Kanade和残差回归器，在严重遮挡下仍能保持亚像素级跟踪精度，为机器人视觉伺服控制提供稳健的实时跟踪能力。


<details>
  <summary>Details</summary>
Motivation: 解决视觉伺服控制中目标跟踪在部分或完全遮挡情况下的鲁棒性问题，传统方法如Lucas-Kanade对遮挡和漂移敏感，而深度学习方案需要持续可见性和高计算量。

Method: 采用混合方法：1)快速全局模板匹配约束位姿搜索区域；2)基于VGG早期层的深度特征Lucas-Kanade实现亚像素级对齐；3)轻量级残差回归器校正局部错位；4)当视觉置信度低时，GRU预测器从运动历史外推位姿更新。

Result: 在手持视频序列上测试，即使面对高达90%的遮挡，系统仍能维持低于2像素的跟踪误差，输出30Hz的控制信号用于图像伺服回路。

Conclusion: 该混合框架在遮挡情况下展现出鲁棒性和低延迟精度，为实际机器人视觉应用提供了可靠的实时跟踪解决方案。

Abstract: Vision-based control systems, such as image-based visual servoing (IBVS),
have been extensively explored for precise robot manipulation. A persistent
challenge, however, is maintaining robust target tracking under partial or full
occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking
but are fragile to occlusion and drift, while deep learning-based approaches
often require continuous visibility and intensive computation. To address these
gaps, we propose a hybrid visual tracking framework that bridges advanced
perception with real-time servo control. First, a fast global template matcher
constrains the pose search region; next, a deep-feature Lucas-Kanade module
operating on early VGG layers refines alignment to sub-pixel accuracy (<2px);
then, a lightweight residual regressor corrects local misalignments caused by
texture degradation or partial occlusion. When visual confidence falls below a
threshold, a GRU-based predictor seamlessly extrapolates pose updates from
recent motion history. Crucially, the pipeline's final outputs-translation,
rotation, and scale deltas-are packaged as direct control signals for 30Hz
image-based servo loops. Evaluated on handheld video sequences with up to 90%
occlusion, our system sustains under 2px tracking error, demonstrating the
robustness and low-latency precision essential for reliable real-world robot
vision applications.

</details>


### [12] [One-shot Humanoid Whole-body Motion Learning](https://arxiv.org/abs/2510.25241)
*Hao Huang,Geeta Chandra Raju Bethala,Shuaihang Yuan,Congcong Wen,Anthony Tzes,Yi Fang*

Main category: cs.RO

TL;DR: 提出了一种仅需单个非行走动作样本和现成行走动作来训练人形机器人运动策略的新方法，通过最优传输和插值生成中间姿态，在CMU MoCap数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要每个动作类别的多个训练样本，导致高质量人体运动数据集的收集既费时又昂贵，需要更高效的训练方法。

Method: 利用保序最优传输计算行走和非行走序列间的距离，沿测地线插值生成新的中间姿态骨架，优化为无碰撞配置并重定向到人形机器人，然后在模拟环境中通过强化学习进行策略训练。

Result: 在CMU MoCap数据集上的实验评估表明，该方法始终优于基线方法，在各项指标上均取得更优性能。

Conclusion: 该方法能够仅使用单个非行走动作样本有效训练人形机器人运动策略，为减少数据收集成本提供了可行方案。

Abstract: Whole-body humanoid motion represents a cornerstone challenge in robotics,
integrating balance, coordination, and adaptability to enable human-like
behaviors. However, existing methods typically require multiple training
samples per motion category, rendering the collection of high-quality human
motion datasets both labor-intensive and costly. To address this, we propose a
novel approach that trains effective humanoid motion policies using only a
single non-walking target motion sample alongside readily available walking
motions. The core idea lies in leveraging order-preserving optimal transport to
compute distances between walking and non-walking sequences, followed by
interpolation along geodesics to generate new intermediate pose skeletons,
which are then optimized for collision-free configurations and retargeted to
the humanoid before integration into a simulated environment for policy
training via reinforcement learning. Experimental evaluations on the CMU MoCap
dataset demonstrate that our method consistently outperforms baselines,
achieving superior performance across metrics. Code will be released upon
acceptance.

</details>


### [13] [Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths](https://arxiv.org/abs/2510.25255)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种基于最优控制的液体容器搬运方法，通过将液体晃动动力学纳入动态模型，在最短时间内沿预定路径运输液体容器，同时最小化液体溢出。


<details>
  <summary>Details</summary>
Motivation: 处理放置在托盘上的液体容器是一个具有挑战性的任务，特别是在轨迹规划和控制方面。当容器内装有液体时，液体晃动会增加任务的复杂性，需要避免液体溢出。

Method: 将液体晃动动力学整合到动态模型中，构建最优控制问题，并使用直接多重打靶法求解该优化问题。

Result: 开发了一种能够考虑液体晃动动力学的最优控制方法，能够在最短时间内沿预定路径运输液体容器。

Conclusion: 通过将液体晃动动力学纳入最优控制问题，可以有效处理液体容器的搬运任务，最小化液体溢出，实现高效运输。

Abstract: Handling loosely placed objects with robotic manipulators is a difficult task
from the point of view of trajectory planning and control. This becomes even
more challenging when the object to be handled is a container filled with
liquid. This paper addresses the task of transporting a liquid-filled cup
placed on a tray along a prescribed path in shortest time. The objective is to
minimize swapping, thus avoiding spillage of the fluid. To this end, the
sloshing dynamics is incorporated into the dynamic model used within the
optimal control problem formulation. The optimization problem is solved using a
direct multiple shooting approach.

</details>


### [14] [SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation](https://arxiv.org/abs/2510.25268)
*Wang zhi,Yuyan Liu,Liu Liu,Li Zhang,Ruixuan Lu,Dan Guo*

Main category: cs.RO

TL;DR: 提出SynHLMA框架，用于生成带语言指令的铰接物体手部操作序列，通过离散表示和语言模型对齐手部抓取与语言描述，实现HAOI生成、预测和插值任务。


<details>
  <summary>Details</summary>
Motivation: 铰接物体手部交互需要同时考虑物体功能性和长期操作序列，现有方法难以处理物体变形过程中的动态手部抓取。

Method: 使用离散HAOI表示建模每个交互帧，结合自然语言嵌入，通过HAOI操作语言模型在共享表示空间中对齐抓取过程与语言描述，采用关节感知损失确保手部抓取跟随铰接物体关节的动态变化。

Result: 在HAOI-lang数据集上评估，相比最先进方法展现出优越的手部抓取序列生成性能，并展示了机器人抓取应用。

Conclusion: SynHLMA框架能够有效生成铰接物体的手部语言操作序列，为具身AI和VR/AR应用提供支持。

Abstract: Generating hand grasps with language instructions is a widely studied topic
that benefits from embodied AI and VR/AR applications. While transferring into
hand articulatied object interaction (HAOI), the hand grasps synthesis requires
not only object functionality but also long-term manipulation sequence along
the object deformation. This paper proposes a novel HAOI sequence generation
framework SynHLMA, to synthesize hand language manipulation for articulated
objects. Given a complete point cloud of an articulated object, we utilize a
discrete HAOI representation to model each hand object interaction frame. Along
with the natural language embeddings, the representations are trained by an
HAOI manipulation language model to align the grasping process with its
language description in a shared representation space. A joint-aware loss is
employed to ensure hand grasps follow the dynamic variations of articulated
object joints. In this way, our SynHLMA achieves three typical hand
manipulation tasks for articulated objects of HAOI generation, HAOI prediction
and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and
experimental results demonstrate the superior hand grasp sequence generation
performance comparing with state-of-the-art. We also show a robotics grasp
application that enables dexterous grasps execution from imitation learning
using the manipulation sequence provided by our SynHLMA. Our codes and datasets
will be made publicly available.

</details>


### [15] [Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance](https://arxiv.org/abs/2510.25280)
*Yusuke Tsunoda,Seiya Yamamoto,Kazuki Ito,Runze Xiao,Keisuke Naniwa,Koichi Osuka*

Main category: cs.RO

TL;DR: 开发了一种能够在陆地和水下环境中使用统一控制方案的蜈蚣型移动机器人，通过巧妙设计腿部结构实现两栖运动。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为不同环境设计不同的步态控制器，这在复杂多变的环境中具有挑战性。本研究旨在开发一种能够在陆地和水下环境中使用统一控制方案的机器人。

Method: 基于隐式-显式控制理念，设计了具有柔性关节和左右腿的蜈蚣型机器人结构，重点开发了三种不同的腿部结构。

Result: 实验结果表明，存在一种合适的腿部结构能够在相同控制下在陆地和水下环境中导航，通过腿部滑动率和执行器能耗进行评估。

Conclusion: 通过巧妙设计腿部结构，可以实现两栖机器人在陆地和水下环境中的统一控制导航。

Abstract: Multi-legged mobile robots possess high mobility performance in rough terrain
environments, stemming from their high postural stability, joint flexibility,
and the redundancy provided by multiple legs. In prior research on navigating
between different environments such as land and water, the primary strategy
employed involves switching to a controller that generates an appropriate gait
for the new environment upon entering it. However, designing appropriate gaits
for each complex and diverse environment and accurately determining controller
switching for each environment is challenging. Therefore, this research
develops a centipede-type mobile robot that navigates both aquatic and
terrestrial environments with a simple, unified control scheme, based on the
implicit-explicit control philosophy and by ingeniously designing the robot's
body structure. In this research, we developed the robot featuring flexible
joints and left and right legs on each body segment and focused on the leg
structure which has extensive contact with the environment. This paper
evaluates the locomotion performance on land and water using the three
developed leg structures, using the robot's leg slip rate and actuator energy
consumption as evaluation metrics. The experimental results confirmed the
existence of an appropriate leg structure capable of navigating both aquatic
and terrestrial environments under identical control.

</details>


### [16] [An approach for combining transparency and motion assistance of a lower body exoskeleton](https://arxiv.org/abs/2510.25335)
*Jakob Ziegler,Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种结合透明模式和运动辅助模式的下半身外骨骼步态辅助方法，利用齿轮间隙实现透明跟随，通过自适应振荡器学习步态周期信号进行运动引导


<details>
  <summary>Details</summary>
Motivation: 开发一种能够同时实现透明跟随和主动辅助的下半身外骨骼系统，既能让用户自由运动，又能在需要时提供步态辅助

Method: 结合透明模式和运动辅助模式：透明模式利用齿轮间隙实现最小交互力跟随；运动辅助模式使用自适应振荡器学习步态周期信号，施加额外扭矩引导腿部运动

Result: 初步实验显示出有希望的结果，验证了该方法的可行性

Conclusion: 提出的透明与辅助相结合的方法为下半身外骨骼步态辅助提供了有效的解决方案

Abstract: In this paper, an approach for gait assistance with a lower body exoskeleton
is described. Two concepts, transparency and motion assistance, are combined.
The transparent mode, where the system is following the user's free motion with
a minimum of perceived interaction forces, is realized by exploiting the gear
backlash of the actuation units. During walking a superimposed assistance mode
applies an additional torque guiding the legs to their estimated future
position. The concept of adaptive oscillators is utilized to learn the
quasi-periodic signals typical for locomotion. First experiments showed
promising results.

</details>


### [17] [Geometric Robot Calibration Using a Calibration Plate](https://arxiv.org/abs/2510.25338)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种使用校准板进行几何机器人校准的新方法，通过板上已知距离的测量点来确定系统误差参数，相比传统方法更经济、机械稳定且便携。


<details>
  <summary>Details</summary>
Motivation: 传统机器人校准方法如激光跟踪仪或运动捕捉系统成本高、机械稳定性差且不易运输，需要一种更经济、稳定且便携的校准方案。

Method: 使用带有精确已知距离测量点的校准板，通过测量板上两点间的相对距离来确定系统误差参数，采用最小二乘法和约束优化问题进行参数识别。

Result: 实验验证了该方法的有效性，获得了与激光跟踪仪校准结果相一致的令人满意的结果。

Conclusion: 该方法为机器人几何校准提供了一种经济、机械稳定且便携的替代方案，虽然以龙门机器人为例进行建模，但适用于其他类型机器人。

Abstract: In this paper a new method for geometric robot calibration is introduced,
which uses a calibration plate with precisely known distances between its
measuring points. The relative measurement between two points on the
calibration plate is used to determine predefined error parameters of the
system. In comparison to conventional measurement methods, like laser tracker
or motion capture systems, the calibration plate provides a more mechanically
robust and cheaper alternative, which is furthermore easier to transport due to
its small size. The calibration method, the plate design, the mathematical
description of the error system as well as the identification of the parameters
are described in detail. For identifying the error parameters, the least
squares method and a constrained optimization problem are used. The
functionality of this method was demonstrated in experiments that led to
promising results, correlated with one of a laser tracker calibration. The
modeling and identification of the error parameters is done for a gantry
machine, but is not restricted to that type of robot.

</details>


### [18] [Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods](https://arxiv.org/abs/2510.25386)
*Kumar Manas,Mert Keser,Alois Knoll*

Main category: cs.RO

TL;DR: 本文综述了将法律和逻辑规范整合到自动驾驶系统感知、预测和规划模块的方法，分析了确保法规合规性和可解释性的技术，并提出了分类法来系统化现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在动态不确定环境中面临感知可靠性、法律合规性和决策可辩护性的交叉挑战，需要确保技术稳健且法律上可辩护的决策。

Method: 引入分类法按理论基础、架构实现和验证策略对现有方法分类，重点关注处理感知不确定性和整合明确法律规范的方法，包括神经符号集成、逻辑驱动规则表示和规范感知预测策略。

Result: 系统分析了当前方法在确保法规合规和可解释性方面的能力，识别了感知可靠性、法律合规和决策可辩护性之间的关键挑战。

Conclusion: 强调了需要解决的关键开放问题和实际权衡，提供了来自工程、逻辑和法律的多学科见解，以指导未来法律合规自动驾驶系统的发展。

Abstract: This survey provides an analysis of current methodologies integrating legal
and logical specifications into the perception, prediction, and planning
modules of automated driving systems. We systematically explore techniques
ranging from logic-based frameworks to computational legal reasoning
approaches, emphasizing their capability to ensure regulatory compliance and
interpretability in dynamic and uncertain driving environments. A central
finding is that significant challenges arise at the intersection of perceptual
reliability, legal compliance, and decision-making justifiability. To
systematically analyze these challenges, we introduce a taxonomy categorizing
existing approaches by their theoretical foundations, architectural
implementations, and validation strategies. We particularly focus on methods
that address perceptual uncertainty and incorporate explicit legal norms,
facilitating decisions that are both technically robust and legally defensible.
The review covers neural-symbolic integration methods for perception,
logic-driven rule representation, and norm-aware prediction strategies, all
contributing toward transparent and accountable autonomous vehicle operation.
We highlight critical open questions and practical trade-offs that must be
addressed, offering multidisciplinary insights from engineering, logic, and law
to guide future developments in legally compliant autonomous driving systems.

</details>


### [19] [Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning](https://arxiv.org/abs/2510.25405)
*Kei Ikemura,Yifei Dong,David Blanco-Mulero,Alberta Longhini,Li Chen,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的强化学习方法，通过应力惩罚奖励来防止易碎物体在机器人操作中受损，结合离线演示和课程学习，实现了从模拟到真实世界的零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作易碎和可变形物体的方法依赖精确物体模型或专用传感器，增加了复杂性且缺乏泛化能力。需要一种能明确防止物体损坏的通用解决方案。

Method: 使用基于视觉的强化学习，引入应力惩罚奖励机制，结合离线演示和从刚性代理到可变形物体的课程学习策略。

Result: 在模拟和真实世界实验中，学习到的策略能零样本迁移到真实世界，成功完成豆腐等易碎物体的拾取和推动任务，相比普通RL策略将施加到易碎物体的应力降低了36.5%。

Conclusion: 该方法能够学习到具有损伤意识的温和操作行为，在完成任务目标的同时显著减少对易碎物体的应力，证明了其在机器人操作易碎物体方面的有效性。

Abstract: Robotic manipulation of deformable and fragile objects presents significant
challenges, as excessive stress can lead to irreversible damage to the object.
While existing solutions rely on accurate object models or specialized sensors
and grippers, this adds complexity and often lacks generalization. To address
this problem, we present a vision-based reinforcement learning approach that
incorporates a stress-penalized reward to discourage damage to the object
explicitly. In addition, to bootstrap learning, we incorporate offline
demonstrations as well as a designed curriculum progressing from rigid proxies
to deformables. We evaluate the proposed method in both simulated and
real-world scenarios, showing that the policy learned in simulation can be
transferred to the real world in a zero-shot manner, performing tasks such as
picking up and pushing tofu. Our results show that the learned policies exhibit
a damage-aware, gentle manipulation behavior, demonstrating their effectiveness
by decreasing the stress applied to fragile objects by 36.5% while achieving
the task goals, compared to vanilla RL policies.

</details>


### [20] [Solving the Right Problem with Multi-Robot Formations](https://arxiv.org/abs/2510.25422)
*Chaz Cornwall,Jeremy P. Bos*

Main category: cs.RO

TL;DR: 提出一种编队规划器，通过两步优化问题减少编队形状与原始成本函数之间的不匹配，使用代理成本函数近似非线性不可微成本，并通过非合作编队控制器实现期望的相对位置。


<details>
  <summary>Details</summary>
Motivation: 传统编队控制将复杂成本函数简化为固定形状，但当环境信息变化时，静态形状无法最小化原始保护成本，导致编队与成本函数之间的不匹配。

Method: 两步优化：首先用加权代理成本函数估计非线性不可微成本，然后最小化代理成本函数得到期望相对位置，最后使用基于Lyapunov直接法的非合作编队控制器实现位置。

Result: 模拟显示编队规划器可将单一成本降低75%以上，同时最小化多个成本函数时，使用自适应权重的编队规划器可降低20-40%的成本。

Conclusion: 编队规划通过最小化近似原始成本函数的代理成本函数，相比依赖形状抽象，提供了更好的性能表现。

Abstract: Formation control simplifies minimizing multi-robot cost functions by
encoding a cost function as a shape the robots maintain. However, by reducing
complex cost functions to formations, discrepancies arise between maintaining
the shape and minimizing the original cost function. For example, a Diamond or
Box formation shape is often used for protecting all members of the formation.
When more information about the surrounding environment becomes available, a
static shape often no longer minimizes the original protection cost. We propose
a formation planner to reduce mismatch between a formation and the cost
function while still leveraging efficient formation controllers. Our formation
planner is a two-step optimization problem that identifies desired relative
robot positions. We first solve a constrained problem to estimate non-linear
and non-differentiable costs with a weighted sum of surrogate cost functions.
We theoretically analyze this problem and identify situations where weights do
not need to be updated. The weighted, surrogate cost function is then minimized
using relative positions between robots. The desired relative positions are
realized using a non-cooperative formation controller derived from Lyapunov's
direct approach. We then demonstrate the efficacy of this approach for
military-like costs such as protection and obstacle avoidance. In simulations,
we show a formation planner can reduce a single cost by over 75%. When
minimizing a variety of cost functions simultaneously, using a formation
planner with adaptive weights can reduce the cost by 20-40%. Formation planning
provides better performance by minimizing a surrogate cost function that
closely approximates the original cost function instead of relying on a shape
abstraction.

</details>


### [21] [Combining Moving Mass Actuators and Manoeuvring Models for Underwater Vehicles: A Lagrangian Approach](https://arxiv.org/abs/2510.25479)
*Alexander B. Rambech,Ivar B. Saksvik,Vahid Hassani*

Main category: cs.RO

TL;DR: 本文提出了带有内部移动质量执行器的水下航行器的牛顿-欧拉动力学方程，将移动质量动力学作为Fossen机动模型的扩展，并在仿真中验证了该模型。


<details>
  <summary>Details</summary>
Motivation: 为带有内部移动质量执行器的水下航行器建立更准确的动力学模型，扩展传统的Fossen机动模型以包含移动质量的影响。

Method: 采用牛顿-欧拉方法建立动力学方程，在体坐标系中描述移动质量影响，将其作为附加运动学方程和耦合刚体动力学的一部分，基于Kirchhoff方程推导科里奥利-向心效应，使用基本原理推导流体静力学。

Result: 提出的牛顿-欧拉模型通过仿真验证，并与传统的哈密顿内部移动质量执行器公式进行了比较。

Conclusion: 成功建立了带有内部移动质量执行器的水下航行器的牛顿-欧拉动力学模型，该模型能够准确描述移动质量对系统动力学的影响。

Abstract: In this paper, we present a Newton-Euler formulation of the equations of
motion for underwater vehicles with an interntal moving mass actuator.
Furthermore, the moving mass dynamics are expressed as an extension to the
manoeuvring model for underwater vehicles, originally introduced by Fossen
(1991). The influence of the moving mass is described in body-frame and
included as states in both an additional kinematic equation and as part of the
coupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal
effects are derived from Kirchhoff's equations and the hydrostatics are derived
using first principals. The proposed Newton-Euler model is validated through
simulation and compared with the traditional Hamiltonian internal moving mass
actuator formulation.

</details>


### [22] [Octopus-like Reaching Motion: A Perspective Inspired by Whipping](https://arxiv.org/abs/2510.25520)
*Shengyao Zhang,Yiyuan Zhang,Chenrui Zhang,Yiming Li,Wenci Xin,Yuliang Liufu,Hong Wei Ng,Cecilia Laschi*

Main category: cs.RO

TL;DR: 该研究通过实验验证章鱼触手伸展运动与鞭子动力学的关系，发现虽然柔性材料在水中能重现章鱼触手的曲率传播特征，但速度分布与生物运动存在差异，表明章鱼伸展运动并非单纯的被动鞭打行为。


<details>
  <summary>Details</summary>
Motivation: 研究章鱼触手伸展运动的高效控制机制，探索其与鞭子动力学的潜在相似性，理解生物柔性体运动的物理原理。

Method: 在水和空气中进行平台鞭打测试，系统改变材料刚度和驱动速度，通过图像量化分析运动学特征。

Result: Ecoflex Gel 2材料在150 rpm驱动下能重现章鱼触手的曲率传播，但弯曲点速度呈单调递减而非生物钟形分布；空气中无传播现象。

Conclusion: 章鱼伸展运动不是单纯的被动鞭打行为，周围介质在形成类似运动中起关键作用，为理解生物运动提供了新视角和流体动力学研究平台。

Abstract: The stereotypical reaching motion of the octopus arm has drawn growing
attention for its efficient control of a highly deformable body. Previous
studies suggest that its characteristic bend propagation may share underlying
principles with the dynamics of a whip. This work investigates whether
whip-like passive dynamics in water can reproduce the kinematic features
observed in biological reaching and their similarities and differences.
Platform-based whipping tests were performed in water and air while
systematically varying material stiffness and driving speed. Image-based
quantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor
speed) reproduced curvature propagation similar to that observed in octopus
reaching. However, its bend-point velocity decreased monotonically rather than
exhibiting the biological bell-shaped profile, confirming that the octopus
reaching movement is not merely a passive whipping behavior. The absence of
propagation in air further highlights the critical role of the surrounding
medium in forming octopus-like reaching motion. This study provides a new
perspective for understand biological reaching movement, and offers a potential
platform for future hydrodynamic research.

</details>


### [23] [Using VLM Reasoning to Constrain Task and Motion Planning](https://arxiv.org/abs/2510.25548)
*Muyang Yan,Miras Mengdibayev,Ardon Floros,Weihang Guo,Lydia E. Kavraki,Zachary Kingston*

Main category: cs.RO

TL;DR: VIZ-COAST利用预训练视觉语言模型的常识空间推理能力，在任务规划阶段预先识别向下精化问题，避免在规划过程中处理精化失败，显著减少规划时间。


<details>
  <summary>Details</summary>
Motivation: 任务与运动规划中，高层任务规划基于世界抽象进行，但任务级计划的可行性依赖于抽象能否向下精化为连续运动。当领域精化能力差时，看似有效的任务计划可能在运动规划阶段失败，需要重新规划，导致整体性能下降。

Method: 使用预训练视觉语言模型进行常识空间推理，从图像和领域描述中提取可信约束，在任务规划阶段预先识别向下精化问题。

Result: 在两个具有挑战性的TAMP领域实验中，该方法能够从图像和领域描述中提取可信约束，大幅减少规划时间，在某些情况下完全消除向下精化失败，并能泛化到更广泛领域的多样化实例。

Conclusion: VIZ-COAST通过利用视觉语言模型的常识空间推理能力，在任务规划阶段预先识别向下精化问题，有效提高了任务与运动规划的效率。

Abstract: In task and motion planning, high-level task planning is done over an
abstraction of the world to enable efficient search in long-horizon robotics
problems. However, the feasibility of these task-level plans relies on the
downward refinability of the abstraction into continuous motion. When a
domain's refinability is poor, task-level plans that appear valid may
ultimately fail during motion planning, requiring replanning and resulting in
slower overall performance. Prior works mitigate this by encoding refinement
issues as constraints to prune infeasible task plans. However, these approaches
only add constraints upon refinement failure, expending significant search
effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the
common-sense spatial reasoning of large pretrained Vision-Language Models to
identify issues with downward refinement a priori, bypassing the need to fix
these failures during planning. Experiments on two challenging TAMP domains
show that our approach is able to extract plausible constraints from images and
domain descriptions, drastically reducing planning times and, in some cases,
eliminating downward refinement failures altogether, generalizing to a diverse
range of instances from the broader domain.

</details>


### [24] [Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills](https://arxiv.org/abs/2510.25634)
*Weikang Wan,Fabio Ramos,Xuning Yang,Caelan Garrett*

Main category: cs.RO

TL;DR: 提出了一种用于长时程接触丰富的双手操作的分层框架，将问题构建为技能规划与调度问题，支持同时技能调用。


<details>
  <summary>Details</summary>
Motivation: 解决长时程接触丰富的双手操作中复杂的协调问题，需要混合并行执行和顺序协作，超越纯顺序决策。

Method: 基于单臂和双手原始技能库，使用强化学习在GPU加速仿真中训练，然后训练基于Transformer的规划器作为高级调度器，同时预测离散技能调度和连续参数。

Result: 该方法在复杂接触丰富任务上比端到端强化学习方法获得更高的成功率，比传统纯顺序规划器产生更高效、协调的行为。

Conclusion: 分层框架通过集成技能规划与调度，有效解决了长时程双手操作的协调挑战，实现了比现有方法更好的性能。

Abstract: Long-horizon contact-rich bimanual manipulation presents a significant
challenge, requiring complex coordination involving a mixture of parallel
execution and sequential collaboration between arms. In this paper, we
introduce a hierarchical framework that frames this challenge as an integrated
skill planning & scheduling problem, going beyond purely sequential
decision-making to support simultaneous skill invocation. Our approach is built
upon a library of single-arm and bimanual primitive skills, each trained using
Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a
Transformer-based planner on a dataset of skill compositions to act as a
high-level scheduler, simultaneously predicting the discrete schedule of skills
as well as their continuous parameters. We demonstrate that our method achieves
higher success rates on complex, contact-rich tasks than end-to-end RL
approaches and produces more efficient, coordinated behaviors than traditional
sequential-only planners.

</details>


### [25] [Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics](https://arxiv.org/abs/2510.25650)
*Ahmad Kokhahi,Mary Kurz*

Main category: cs.RO

TL;DR: 该论文提出了一种考虑能耗的多智能体路径规划方法，包含新的碰撞避免策略和两种多目标任务分配算法（NSGA和ALNS），在碰撞避免和任务分配方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF研究主要关注最小化碰撞和旅行时间，但忽略了AGV的能耗问题。本文旨在同时考虑能耗和旅行时间，解决AGV路径规划中的碰撞避免和任务分配两个关键挑战。

Method: 提出新的碰撞避免策略，同时考虑能耗和旅行时间；使用两种多目标算法进行任务分配：非支配排序遗传算法（NSGA）和自适应大邻域搜索（ALNS）。

Result: 比较评估表明，所提出的方法在碰撞避免和任务分配方面均优于现有方法。

Conclusion: 该研究成功地将能耗因素纳入AGV路径规划，提出的碰撞避免策略和多目标任务分配算法在性能上超越了现有方法。

Abstract: Multi-Agent Path Finding (MAPF) has gained significant attention, with most
research focusing on minimizing collisions and travel time. This paper also
considers energy consumption in the path planning of automated guided vehicles
(AGVs). It addresses two main challenges: i) resolving collisions between AGVs
and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy
that takes both energy use and travel time into account. For task assignment,
we present two multi-objective algorithms: Non-Dominated Sorting Genetic
Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative
evaluations show that these proposed methods perform better than existing
approaches in both collision avoidance and task assignment.

</details>


### [26] [Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models](https://arxiv.org/abs/2510.25713)
*Boshi An,Chenyu Yang,Robert Katzschmann*

Main category: cs.RO

TL;DR: 本文提出了一种改进预训练视觉-语言-动作模型的方法，用于灵巧的人机协作，通过添加任务感知视觉条件、辅助意图预测和动作后处理，实现了低延迟的实时协作行为。


<details>
  <summary>Details</summary>
Motivation: 旨在开发需要最少语言提示的灵巧人机协作系统，解决现有方法在实时协作任务中的局限性。

Method: 在预训练VLA模型基础上添加：(1) FiLM条件化视觉骨干网络实现任务感知感知；(2) 辅助意图头预测合作者手部姿态和目标线索；(3) 动作空间后处理预测紧凑的增量动作和PCA降维的手指关节。

Result: 增量动作表现良好，4个主成分解释了约96%的手部关节方差；动作后处理是主要性能驱动因素；实现了约0.3秒延迟的实时堆栈，能够组合"拾取"和"传递"为长视野行为。

Conclusion: 该方法成功实现了灵巧的人机协作，但面临"训练者过拟合"特定演示者的关键限制。

Abstract: We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for
dexterous human-robot collaboration with minimal language prompting. Our
approach adds (i) FiLM conditioning to visual backbones for task-aware
perception, (ii) an auxiliary intent head that predicts collaborator hand pose
and target cues, and (iii) action-space post-processing that predicts compact
deltas (position/rotation) and PCA-reduced finger joints before mapping to full
commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset
augmented with MediaPipe hand poses, we demonstrate that delta actions are
well-behaved and that four principal components explain ~96% of hand-joint
variance. Ablations identify action post-processing as the primary performance
driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is
detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes
"pick-up" and "pass" into a long-horizon behavior. We surface "trainer
overfitting" to specific demonstrators as the key limitation.

</details>


### [27] [A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation](https://arxiv.org/abs/2510.25725)
*Eunju Kwon,Seungwon Oh,In-Chang Baek,Yucheon Park,Gyungbo Kim,JaeYoung Moon,Yunho Choi,Kyung-Joong Kim*

Main category: cs.RO

TL;DR: 提出了一个用于操作可变形软物体的人形视觉-触觉-动作数据集，填补了机器人学习数据集中对压力条件多样性表征不足的空白。


<details>
  <summary>Details</summary>
Motivation: 机器人学习数据集先前主要关注刚性物体，未能充分体现真实世界操作中压力条件的多样性，特别是在接触丰富的操作任务中。

Method: 通过遥操作使用配备灵巧手的人形机器人收集数据，捕捉了不同压力条件下的多模态交互。

Result: 成功构建了一个包含视觉、触觉和动作信息的人形机器人数据集，专门针对可变形软物体的操作。

Conclusion: 该工作推动了未来研究开发能够有效利用触觉信号复杂性和多样性的模型，需要先进的优化策略。

Abstract: Contact-rich manipulation has become increasingly important in robot
learning. However, previous studies on robot learning datasets have focused on
rigid objects and underrepresented the diversity of pressure conditions for
real-world manipulation. To address this gap, we present a humanoid
visual-tactile-action dataset designed for manipulating deformable soft
objects. The dataset was collected via teleoperation using a humanoid robot
equipped with dexterous hands, capturing multi-modal interactions under varying
pressure conditions. This work also motivates future research on models with
advanced optimization strategies capable of effectively leveraging the
complexity and diversity of tactile signals.

</details>


### [28] [Modeling Collapse of Steered Vine Robots Under Their Own Weight](https://arxiv.org/abs/2510.25727)
*Ciera McFarland,Margaret McGuinness*

Main category: cs.RO

TL;DR: 提出了一个预测软体生长机器人坍塌长度的综合模型，该模型使用真实形状信息和尾部张力来预测任何形状的转向机器人的坍塌行为。


<details>
  <summary>Details</summary>
Motivation: 软体生长机器人在受限环境中具有高机动性，但在面对环境间隙时可能因自身重量而坍塌，需要预测和控制其坍塌行为以实现3D导航任务。

Method: 开发了一个坍塌模型，使用真实形状信息和尾部张力来预测坍塌长度，通过无转向机器人和单执行器转向机器人的实验验证模型准确性。

Result: 模型准确预测了无转向机器人实验的趋势，并能准确预测单执行器转向机器人的坍塌发生。在间隙跨越任务中，模型支持机器人需要充气执行器才能避免坍塌。

Conclusion: 该模型能够在任何开放环境中模拟机器人的坍塌行为，并理解其在3D导航任务中成功所需的参数，可应用于其他机器人变体。

Abstract: Soft, vine-inspired growing robots that move by eversion are highly mobile in
confined environments, but, when faced with gaps in the environment, they may
collapse under their own weight while navigating a desired path. In this work,
we present a comprehensive collapse model that can predict the collapse length
of steered robots in any shape using true shape information and tail tension.
We validate this model by collapsing several unsteered robots without true
shape information. The model accurately predicts the trends of those
experiments. We then attempt to collapse a robot steered with a single actuator
at different orientations. Our models accurately predict collapse when it
occurs. Finally, we demonstrate how this could be used in the field by having a
robot attempt a gap-crossing task with and without inflating its actuators. The
robot needs its actuators inflated to cross the gap without collapsing, which
our model supports. Our model has been specifically tested on straight and
series pouch motor-actuated robots made of non-stretchable material, but it
could be applied to other robot variations. This work enables us to model the
robot's collapse behavior in any open environment and understand the parameters
it needs to succeed in 3D navigation tasks.

</details>


### [29] [GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions](https://arxiv.org/abs/2510.25754)
*Bohan Wu,Paul de La Sayette,Li Fei-Fei,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: GeT-USE是一个两阶段方法，通过在模拟中学习机器人本体扩展来识别对任务最有利的工具几何形状，然后将这些知识迁移到真实机器人中，实现通用工具使用。


<details>
  <summary>Details</summary>
Motivation: 当前机器人工具使用方法假设只有一个可用对象，无法从多个对象中选择最佳工具，特别是在最优工具缺失时。需要提升机器人在多对象环境下识别、抓取和使用最佳工具的能力。

Method: 采用两步骤流程：首先在模拟中学习机器人本体扩展（构建新末端执行器），识别对任务最有利的工具几何形状；然后将学习到的策略迁移到真实机器人的视觉运动策略中。

Result: 在具有22个自由度的真实机器人上，GeT-USE在三个基于视觉的双手机器人移动操作工具使用任务中，比现有最优方法成功率高出30-60%。

Conclusion: 通过在模拟中探索机器人本体扩展来学习通用工具几何知识，可以有效提升真实机器人选择和使用最佳可用物体作为工具的能力。

Abstract: The ability to use random objects as tools in a generalizable manner is a
missing piece in robots' intelligence today to boost their versatility and
problem-solving capabilities. State-of-the-art robotic tool usage methods
focused on procedurally generating or crowd-sourcing datasets of tools for a
task to learn how to grasp and manipulate them for that task. However, these
methods assume that only one object is provided and that it is possible, with
the correct grasp, to perform the task; they are not capable of identifying,
grasping, and using the best object for a task when many are available,
especially when the optimal tool is absent. In this work, we propose GeT-USE, a
two-step procedure that learns to perform real-robot generalized tool usage by
learning first to extend the robot's embodiment in simulation and then
transferring the learned strategies to real-robot visuomotor policies. Our key
insight is that by exploring a robot's embodiment extensions (i.e., building
new end-effectors) in simulation, the robot can identify the general tool
geometries most beneficial for a task. This learned geometric knowledge can
then be distilled to perform generalized tool usage tasks by selecting and
using the best available real-world object as tool. On a real robot with 22
degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by
30-60% success rates across three vision-based bimanual mobile manipulation
tool-usage tasks.

</details>


### [30] [STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and Thread Management](https://arxiv.org/abs/2510.25768)
*Kush Hari,Ziyang Chen,Hansoul Kim,Ken Goldberg*

Main category: cs.RO

TL;DR: STITCH 2.0是一个改进的手术缝合机器人系统，通过七项技术改进实现了比前代系统更好的伤口闭合效果，在15次试验中平均达到74.4%的伤口闭合率。


<details>
  <summary>Details</summary>
Motivation: 手术缝合是一项高精度任务，影响患者愈合和疤痕形成。外科医生的缝合技能差异很大，需要机器人辅助。之前的机器人缝合系统如STITCH 1.0由于针位跟踪不准确和线管理不善而难以完全闭合伤口。

Method: STITCH 2.0提出了一个增强的灵巧性管道，包含七项改进：改进的EKF针位姿估计、新的线解缠方法、自动化的3D缝合对齐算法等。

Result: 在15次试验中，STITCH 2.0平均实现74.4%的伤口闭合率，每次试验平均4.87针缝合，相比基线系统多66%的缝合针数且节省38%时间。在允许两次人工干预的情况下，平均6针缝合且100%伤口闭合率。

Conclusion: STITCH 2.0通过多项技术改进显著提升了机器人缝合系统的性能，在伤口闭合效果和效率方面都有明显进步，为手术机器人辅助缝合提供了更可靠的解决方案。

Abstract: Surgical suturing is a high-precision task that impacts patient healing and
scarring. Suturing skill varies widely between surgeons, highlighting the need
for robot assistance. Previous robot suturing works, such as STITCH 1.0 [1],
struggle to fully close wounds due to inaccurate needle tracking and poor
thread management. To address these challenges, we present STITCH 2.0, an
elevated augmented dexterity pipeline with seven improvements including:
improved EKF needle pose estimation, new thread untangling methods, and an
automated 3D suture alignment algorithm. Experimental results over 15 trials
find that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures
per trial, representing 66% more sutures in 38% less time compared to the
previous baseline. When two human interventions are allowed, STITCH 2.0
averages six sutures with 100% wound closure rate. Project website:
https://stitch-2.github.io/

</details>
