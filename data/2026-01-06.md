<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 75]
- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [The Qualitative Laboratory: Theory Prototyping and Hypothesis Generation with Large Language Models](https://arxiv.org/abs/2601.00797)
*Hugues Draelants*

Main category: cs.CL

TL;DR: 本文提出使用大语言模型进行社会学角色模拟作为"定性实验室"的新方法，用于生成关于不同社会群体如何解读新信息的丰富定性假设。


<details>
  <summary>Details</summary>
Motivation: 社会科学面临的核心挑战是如何生成关于不同社会群体如何解读新信息的丰富定性假设。现有方法如小插图调查缺乏话语深度，而基于规则的ABM存在形式化瓶颈。

Method: 提出社会学角色模拟方法，使用大语言模型作为"定性实验室"。通过从气候接受社会学理论中提取角色，让这些角色对政策信息做出反应，生成自然主义的话语。

Result: 模拟产生了细致且反直觉的假设，例如保守角色拒绝国家安全框架，这挑战了理论假设。展示了该方法在生成深度假设方面的潜力。

Conclusion: 这种方法作为"模拟后验证"工作流程的一部分，代表了生成深度假设以供后续实证检验的优越工具，能够克服现有方法的局限性。

Abstract: A central challenge in social science is to generate rich qualitative hypotheses about how diverse social groups might interpret new information. This article introduces and illustrates a novel methodological approach for this purpose: sociological persona simulation using Large Language Models (LLMs), which we frame as a "qualitative laboratory". We argue that for this specific task, persona simulation offers a distinct advantage over established methods. By generating naturalistic discourse, it overcomes the lack of discursive depth common in vignette surveys, and by operationalizing complex worldviews through natural language, it bypasses the formalization bottleneck of rule-based agent-based models (ABMs). To demonstrate this potential, we present a protocol where personas derived from a sociological theory of climate reception react to policy messages. The simulation produced nuanced and counter-intuitive hypotheses - such as a conservative persona's rejection of a national security frame - that challenge theoretical assumptions. We conclude that this method, used as part of a "simulation then validation" workflow, represents a superior tool for generating deeply textured hypotheses for subsequent empirical testing.

</details>


### [2] [Rate-Distortion Analysis of Compressed Query Delegation with Low-Rank Riemannian Updates](https://arxiv.org/abs/2601.00938)
*Faruk Alpay,Bugra Kilictas*

Main category: cs.CL

TL;DR: 论文提出压缩查询委托(CQD)方法，通过低秩张量查询压缩高维推理状态，委托给外部oracle，并在固定秩流形上进行黎曼优化，解决有界上下文代理的工作记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 有界上下文代理在中间推理超过有效工作记忆预算时会失败，需要一种方法来压缩高维推理状态并委托给外部oracle，同时保持推理的准确性和效率。

Method: 提出压缩查询委托(CQD)框架：1)将高维潜在推理状态压缩为低秩张量查询；2)将最小化查询委托给外部oracle；3)通过固定秩流形上的黎曼优化更新潜在状态。建立数学模型：CQD是具有查询预算函数和噪声oracle算子的约束随机规划问题。

Result: 理论证明：对于自然约束二次失真问题，谱硬阈值是最优的；在oracle噪声有界和平滑假设下，推导出黎曼随机近似的收敛保证。实证结果：A)在2,500项有界上下文推理套件上，CQD在固定计算和上下文条件下优于思维链基线；B)人类"认知镜像"基准(N=200)测量现代oracle的认知增益和语义漂移。

Conclusion: CQD为有界上下文代理提供了一种有效的压缩和委托框架，通过数学形式化连接了经典率失真和信息瓶颈原理，并在理论和实证上都展示了其优越性，为解决工作记忆限制问题提供了新途径。

Abstract: Bounded-context agents fail when intermediate reasoning exceeds an effective working-memory budget. We study compressed query delegation (CQD): (i) compress a high-dimensional latent reasoning state into a low-rank tensor query, (ii) delegate the minimal query to an external oracle, and (iii) update the latent state via Riemannian optimization on fixed-rank manifolds. We give a math-first formulation: CQD is a constrained stochastic program with a query-budget functional and an oracle modeled as a noisy operator. We connect CQD to classical rate-distortion and information bottleneck principles, showing that spectral hard-thresholding is optimal for a natural constrained quadratic distortion problem, and we derive convergence guarantees for Riemannian stochastic approximation under bounded oracle noise and smoothness assumptions. Empirically, we report (A) a 2,500-item bounded-context reasoning suite (BBH-derived tasks plus curated paradox instances) comparing CQD against chain-of-thought baselines under fixed compute and context; and (B) a human "cognitive mirror" benchmark (N=200) measuring epistemic gain and semantic drift across modern oracles.

</details>


### [3] [Intention Collapse: Intention-Level Metrics for Reasoning in Language Models](https://arxiv.org/abs/2601.01011)
*Patricio Vera*

Main category: cs.CL

TL;DR: 论文提出"意图坍缩"概念，将语言生成视为高维意图空间到语言序列的映射，并定义了三个意图度量指标来研究推理计算如何影响内部意图表达


<details>
  <summary>Details</summary>
Motivation: 研究语言生成过程中丰富的内部状态如何被压缩为单一token序列，探索推理时计算如何塑造内部意图在语言化之前的状态

Method: 形式化意图坍缩概念，定义三个模型无关的意图度量指标（意图熵Hint、有效维度dimeff、潜在知识可恢复性Recov），并通过小规模实验比较直接回答、思维链和babble控制三种推理机制

Result: 思维链将准确率从5.5%提升至53%，显著降低意图熵（1.42→0.37比特），显示更高的全局有效维度；意图熵在项目级别预测力有限，思维链机制下线性探针AUROC达0.65，而基线机制仅达随机水平

Conclusion: 意图层面指标能区分推理机制并揭示坍缩过程中部分丢失的潜在信息，但当前代理指标仍有重要局限性，为研究语言模型内部意图表达提供了新框架

Abstract: Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability Recov), and propose an empirical agenda for studying how inference time computation shapes internal intentions before they are verbalized. We also report a first small scale experiment. Using a 4 bit Mistral 7B model on 200 GSM8K problems, we compare a direct answer baseline, a chain of thought (CoT) regime, and a babble control. CoT raises accuracy from 5.5 percent to 53 percent, sharply reduces pre collapse intention entropy (from 1.42 to 0.37 bits), and shows higher global effective dimensionality than the other regimes despite producing fewer tokens than babble. At the same time, Hint has little item level predictive power, and a linear probe on I achieves AUROC 0.65 in the CoT regime but only about chance in the baseline regime, where it collapses to the majority class. These preliminary results indicate that intention level metrics can distinguish inference regimes and expose latent information that is partly lost during collapse, while also revealing important limitations of our current proxies

</details>


### [4] [HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery](https://arxiv.org/abs/2601.01015)
*Shiyuan Liu,Jianwei Wang,Xuemin Lin,Lu Qin,Wenjie Zhang,Ying Zhang*

Main category: cs.CL

TL;DR: HyperJoin：基于大语言模型增强的超图框架，用于可连接表发现，通过建模表内和表间结构关系，将任务转化为超图链接预测，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的方法在可连接表发现任务中，离线阶段将表建模为孤立或成对列，难以捕捉丰富的表间和表内结构信息；在线阶段仅基于查询-候选相似度排序，忽略候选列之间的相互影响，导致结果集不连贯。

Method: 1. 构建超图：使用表内超边和LLM增强的表间超边建模表结构；2. 设计HIN（分层交互网络）：通过列和超边的双向消息传递学习表达性列表示；3. 在线重排序：将排名转化为连贯性感知的top-k列选择问题，使用最大生成树算法修剪噪声连接并最大化连贯性。

Result: 实验显示HyperJoin显著优于现有基线方法，在Precision@15和Recall@15指标上分别平均提升21.4%和17.2%。

Conclusion: HyperJoin通过超图建模表结构关系，结合分层交互网络和连贯性感知重排序，有效解决了现有方法在结构交互建模和结果连贯性方面的不足，显著提升了可连接表发现的性能。

Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with online ranking, their design insufficiently accounts for the underlying structural interactions: (1) offline, they directly model tables into isolated or pairwise columns, thereby struggling to capture the rich inter-table and intra-table structural information; and (2) online, they rank candidate columns based solely on query-candidate similarity, ignoring the mutual interactions among the candidates, leading to incoherent result sets. To address these limitations, we propose HyperJoin, a large language model (LLM)-augmented Hypergraph framework for Joinable table discovery. Specifically, we first construct a hypergraph to model tables using both the intra-table hyperedges and the LLM-augmented inter-table hyperedges. Consequently, the task of joinable table discovery is formulated as link prediction on this constructed hypergraph. We then design HIN, a Hierarchical Interaction Network that learns expressive column representations through bidirectional message passing over columns and hyperedges. To strengthen coherence and internal consistency in the result columns, we cast online ranking as a coherence-aware top-k column selection problem. We then introduce a reranking module that leverages a maximum spanning tree algorithm to prune noisy connections and maximize coherence. Experiments demonstrate the superiority of HyperJoin, achieving average improvements of 21.4% (Precision@15) and 17.2% (Recall@15) over the best baseline.

</details>


### [5] [Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation](https://arxiv.org/abs/2601.01037)
*Livia Leong Hui Teng*

Main category: cs.CL

TL;DR: 提出多维度提示链框架提升小语言模型在开放域对话中的人类相似度，通过自然性、连贯性和吸引性三个维度优化，使7B模型达到与70B模型相当的对话质量。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）在部署方面具有显著优势，但在开放域对话中难以达到大模型的对话质量，需要一种资源高效的方法来提升其对话能力。

Method: 提出多维度提示链框架，整合自然性、连贯性和吸引性三个维度来增强对话的人类相似度。将该框架应用于TinyLlama和Llama-2-7B模型，并与Llama-2-70B和GPT-3.5 Turbo等大模型进行对比。

Result: 完整框架将响应多样性提升高达29%，上下文连贯性提升高达28%，吸引性和自然性提升高达29%。Llama-2-7B达到了与Llama-2-70B和GPT-3.5 Turbo等大模型相当的性能。

Conclusion: 精心设计的基于提示的策略为提升小语言模型在开放域对话质量提供了有效且资源高效的途径，使小模型能够达到大模型的对话质量水平。

Abstract: Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.

</details>


### [6] [KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs](https://arxiv.org/abs/2601.01046)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: KV-Embedding：一种无需训练的方法，通过重路由LLM最后一层token的KV状态作为前缀，激活冻结LLM的潜在表示能力，提升序列级上下文访问


<details>
  <summary>Details</summary>
Motivation: LLM在无需训练的场景中存在两个结构性问题：因果注意力机制限制早期token访问后续上下文，以及下一token预测目标使表示偏向生成而非语义压缩。需要激活冻结LLM的潜在表示能力。

Method: 提出KV-Embedding框架，利用观察发现每层最后一个token的键值（KV）状态编码了序列的压缩视图。通过将这些状态重路由为预置前缀，使所有token能在单次前向传播中访问序列级上下文。采用基于内在维度的自动层选择策略确保模型无关性。

Result: 在MTEB基准测试中，使用Qwen、Mistral和Llama骨干网络，KV-Embedding比现有无需训练基线提升高达10%，在长达4,096个token的序列上保持稳健性能。

Conclusion: 内部状态操作为输入修改提供了高效替代方案，这项工作鼓励进一步探索LLM内部机制用于表示学习。

Abstract: While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic compression. To address these limitations, we propose KV-Embedding, a framework that activates the latent representation power of frozen LLMs. Our method leverages the observation that the key-value (KV) states of the final token at each layer encode a compressed view of the sequence. By re-routing these states as a prepended prefix, we enable all tokens to access sequence-level context within a single forward pass. To ensure model-agnostic applicability, we introduce an automated layer selection strategy based on intrinsic dimensionality. Evaluations on MTEB across Qwen, Mistral, and Llama backbones show that KV-Embedding outperforms existing training-free baselines by up to 10%, while maintaining robust performance on sequences up to 4,096 tokens. These results demonstrate that internal state manipulation offers an efficient alternative to input modification, and we hope this work encourages further exploration of LLM internals for representation learning.

</details>


### [7] [Unsupervised Text Style Transfer for Controllable Intensity](https://arxiv.org/abs/2601.01060)
*Shuhuan Gu,Wenbiao Tao,Xinchen Ma,Kangkang He,Ye Guo,Xiang Li,Yunshi Lan*

Main category: cs.CL

TL;DR: 本文提出SFT-then-PPO范式，通过合成平行数据微调LLM，再使用分层奖励设计的PPO训练，解决无监督文本风格转移中强度控制的挑战。


<details>
  <summary>Details</summary>
Motivation: 无监督文本风格转移（UTST）在缺乏平行文本对的情况下，实现可控强度转移更具挑战性，因为不同强度级别间的风格特征差异细微，相邻强度级别难以区分。

Method: 提出SFT-then-PPO范式：1）先用合成平行数据微调LLM；2）再用PPO进一步训练，设计分层奖励函数同时考虑全局和局部风格特征来区分风格强度。

Result: 在两个UTST基准测试中，两种奖励函数各有优势，应用于LLM微调能有效提升基于各种评估指标的LLM骨干性能。即使在相近强度级别，生成文本间也能观察到明显的风格差异。

Conclusion: 提出的SFT-then-PPO范式通过精心设计的奖励函数，成功解决了无监督文本风格转移中可控强度的挑战，实现了不同强度级别的有效区分。

Abstract: Unsupervised Text Style Transfer (UTST) aims to build a system to transfer the stylistic properties of a given text without parallel text pairs. Compared with text transfer between style polarities, UTST for controllable intensity is more challenging due to the subtle differences in stylistic features across different intensity levels. Faced with the challenges posed by the lack of parallel data and the indistinguishability between adjacent intensity levels, we propose a SFT-then-PPO paradigm to fine-tune an LLM. We first fine-tune the LLM with synthesized parallel data. Then, we further train the LLM with PPO, where the rewards are elaborately designed for distinguishing the stylistic intensity in hierarchical levels. Both the global and local stylistic features are considered to formulate the reward functions. The experiments on two UTST benchmarks showcase that both rewards have their advantages and applying them to LLM fine-tuning can effectively improve the performance of an LLM backbone based on various evaluation metrics. Even for close levels of intensity, we can still observe the noticeable stylistic difference between the generated text.

</details>


### [8] [ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining](https://arxiv.org/abs/2601.01091)
*Haq Nawaz Malik*

Main category: cs.CL

TL;DR: 该论文针对克什米尔语高质量训练数据稀缺的问题，构建了包含310万单词的KS-LIT-3M语料库，通过开发InPage到Unicode转换器解决了历史文献访问障碍，为克什米尔语NLP研究填补了资源空白。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在高资源语言上表现优异，但在拥有约700万使用者的克什米尔语上却无法生成连贯文本。主要问题不是模型本身限制，而是高质量训练数据的严重缺乏。数十年的克什米尔语文献由于使用专有的InPage桌面出版格式编码，无法被现代NLP流程访问。

Method: 1. 开发专门的InPage到Unicode转换器，解决历史文献访问问题；2. 构建包含310万单词（1640万字符）的KS-LIT-3M语料库；3. 采用严格的预处理流程：去除英语污染、字符规范化、质量验证；4. 语料库设计为单一连续线性文本流，优化用于因果语言模型训练。

Result: 成功创建了包含131,607个独特单词的克什米尔语语料库，涵盖文学、新闻、学术和宗教等多种体裁。语料库以CC-BY-4.0许可证发布，专门为克什米尔语语言模型预训练设计，填补了克什米尔语技术资源的根本性空白。

Conclusion: KS-LIT-3M语料库解决了克什米尔语高质量训练数据稀缺的关键问题，通过技术手段克服了历史文献格式障碍，为克什米尔语自然语言处理研究提供了基础资源，有望改善大语言模型在克什米尔语上的表现。

Abstract: Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.

</details>


### [9] [EmoLoom-2B: Fast Base-Model Screening for Emotion Classification and VAD with Lexicon-Weak Supervision and KV-Off Evaluation](https://arxiv.org/abs/2601.01112)
*Zilin Li,Weiwei Xu,Xuanbo Lu,Zheda Liu*

Main category: cs.CL

TL;DR: EmoLoom-2B是一个轻量级可复现的流程，可将小于20亿参数的小语言模型转化为情感分类和VAD预测的快速筛选候选模型，通过统一协议、语义正则化和数据增强实现高效评估。


<details>
  <summary>Details</summary>
Motivation: 需要一种轻量级、可复现的方法来将小语言模型转化为情感分析任务的快速筛选工具，避免评估中的协议偏差和不可控方差，为后续更重的训练或多模态融合提供可靠的初步筛选。

Method: 1) 统一JSON输入输出协议确保评估一致性；2) 采用KV-off解码减少方差；3) 引入两种正交语义正则器：VAD保持约束和轻量外部评估分类器；4) 基于镜像情感对的Valence Flip增强；5) 监督微调中使用A/B混合采样和熵感知温度调度。

Result: 以Qwen-1.8B-Chat为基础模型，EmoLoom-2B在GoEmotions和EmpatheticDialogues上表现强劲，并在DailyDialog上展示了稳健的跨语料库泛化能力。

Conclusion: EmoLoom-2B提供了一个预算友好、可审计、可重入的可靠筛选流程，可作为重型训练或多模态融合前的有效初步筛选工具，确保情感分析任务的高效评估和模型选择。

Abstract: We introduce EmoLoom-2B, a lightweight and reproducible pipeline that turns small language models under 2B parameters into fast screening candidates for joint emotion classification and Valence-Arousal-Dominance prediction. To ensure protocol-faithful and fair evaluation, we unify data loading, training, and inference under a single JSON input-output contract and remove avoidable variance by adopting KV-off decoding as the default setting. We incorporate two orthogonal semantic regularizers: a VAD-preserving constraint that aligns generated text with target VAD triples, and a lightweight external appraisal classifier that provides training-time guidance on goal attainment, controllability, certainty, and fairness without injecting long rationales. To improve polarity sensitivity, we introduce Valence Flip augmentation based on mirrored emotional pairs. During supervised fine-tuning, we apply A/B mixture sampling with entropy-aware temperature scheduling to balance coverage and convergence. Using Qwen-1.8B-Chat as the base model, EmoLoom-2B achieves strong performance on GoEmotions and EmpatheticDialogues, and demonstrates robust cross-corpus generalization on DailyDialog. The proposed recipe is budget-aware, auditable, and re-entrant, serving as a dependable screening pass before heavier training or multimodal fusion.

</details>


### [10] [Listen, Attend, Understand: a Regularization Technique for Stable E2E Speech Translation Training on High Variance labels](https://arxiv.org/abs/2601.01121)
*Yacouba Diarra,Michael Leventhal*

Main category: cs.CL

TL;DR: LAU是一种语义正则化技术，通过冻结文本嵌入提供方向性辅助损失，在训练期间约束声学编码器的潜在空间，为端到端语音翻译注入语言基础性，不增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译在目标转录具有高方差和语义模糊性时，通常表现出较慢的收敛速度和较差的性能。需要一种方法能在训练数据稀缺和/或嘈杂的情况下改善性能。

Method: 提出Listen, Attend, Understand (LAU)语义正则化技术，利用冻结的文本嵌入提供方向性辅助损失，约束声学编码器的潜在空间，将语言基础性注入声学表示中。

Result: 在30小时班巴拉语到法语数据集上评估，LAU模型在使用100%更多数据预训练的E2E-ST系统上达到可比性能，同时在保留语义含义方面表现更好。引入总参数漂移度量来量化正则化的结构影响。

Conclusion: LAU是后处理重评分的稳健替代方案，是E2E-ST训练的有价值补充，特别适用于训练数据稀缺和/或嘈杂的情况。语义约束能主动重组编码器权重，优先考虑意义而非字面音素。

Abstract: End-to-End Speech Translation often shows slower convergence and worse performance when target transcriptions exhibit high variance and semantic ambiguity. We propose Listen, Attend, Understand (LAU), a semantic regularization technique that constrains the acoustic encoder's latent space during training. By leveraging frozen text embeddings to provide a directional auxiliary loss, LAU injects linguistic groundedness into the acoustic representation without increasing inference cost. We evaluate our method on a Bambara-to-French dataset with 30 hours of Bambara speech translated by non-professionals. Experimental results demonstrate that LAU models achieve comparable performance by standard metrics compared to an E2E-ST system pretrained with 100\% more data and while performing better in preserving semantic meaning. Furthermore, we introduce Total Parameter Drift as a metric to quantify the structural impact of regularization to demonstrate that semantic constraints actively reorganize the encoder's weights to prioritize meaning over literal phonetics. Our findings suggest that LAU is a robust alternative to post-hoc rescoring and a valuable addition to E2E-ST training, especially when training data is scarce and/or noisy.

</details>


### [11] [RoboPhD: Self-Improving Text-to-SQL Through Autonomous Agent Evolution](https://arxiv.org/abs/2601.01126)
*Andrew Borthwick,Stephen Ash*

Main category: cs.CL

TL;DR: RoboPhD是一个AI自主研究系统，通过进化循环自动改进Text-to-SQL性能，从70行基线进化到1500行，在BIRD测试集上达到73.67%准确率，实现"跳级部署"效果。


<details>
  <summary>Details</summary>
Motivation: 探索AI能否在没有领域专家指导的情况下，通过自主进化构建强大的Text-to-SQL代理系统，从简单基线开始实现性能突破。

Method: 采用闭环进化循环：SQL生成代理（数据库分析脚本+SQL生成指令）和进化代理（基于性能反馈设计新版本），使用ELO选择机制处理性能非传递性，通过迭代交叉授粉进化代理。

Result: 从70行基线进化18代到1500行代理，在BIRD测试集上达到73.67%准确率；对廉价模型提升最大：Claude Haiku提升8.9分，Claude Opus提升2.3分；实现"跳级部署"：进化版Haiku超过原生Sonnet，进化版Sonnet超过原生Opus。

Conclusion: AI能够从微不足道的人工起点自主构建强大的代理系统，进化对廉价模型提升最大，实现成本效益显著的"跳级部署"，展示了自主研究系统的潜力。

Abstract: We present RoboPhD, a system where AI agents autonomously conduct research to improve Text-to-SQL performance. RoboPhD implements a closed-loop evolution cycle with two coordinated components: a SQL Generation agent composed of a database analysis script and SQL generation instructions, and an Evolution agent that designs new versions based on performance feedback. Central to the framework is an ELO-based selection mechanism enabling survival-of-the-fittest dynamics while handling non-transitivity in performance. Starting from a naive 70-line baseline, RoboPhD evolves agents through iterative cross-pollination, discovering effective techniques without any external guidance on the Text-to-SQL domain. Our best agent, evolved to 1500 lines over 18 iterations, autonomously discovered strategies such as size-adaptive database analysis that adjusts depth based on schema complexity and SQL generation patterns for column selection, evidence interpretation, and aggregation. Evolution provides the largest gains on cheaper models: while we improve by 2.3 points over a strong Claude Opus 4.5 naive baseline, we show an improvement of 8.9 points over the weaker Claude Haiku model. This enables 'skip a tier' deployment: evolved Haiku exceeds naive Sonnet accuracy, and evolved Sonnet exceeds naive Opus, both at lower cost. The full system achieves 73.67% accuracy on the BIRD test set, demonstrating that AI can autonomously build a strong agentic system with only a trivial human-provided starting point.

</details>


### [12] [KOS-TL (Knowledge Operation System Type Logic)](https://arxiv.org/abs/2601.01143)
*Peng Chen*

Main category: cs.CL

TL;DR: KOS-TL是一个基于依赖类型理论的新型知识操作系统逻辑框架，将数据、逻辑和证明统一到单一计算基板上，为自主可执行知识系统提供严格逻辑基础。


<details>
  <summary>Details</summary>
Motivation: 传统知识表示模型存在静态符号逻辑与动态系统执行之间的鸿沟，需要一种能够统一数据、逻辑和证明的严格逻辑框架来支持自主知识系统的构建。

Method: 采用依赖类型理论，构建三层架构：核心层定义静态类型宇宙和构造原语；内核层通过事件驱动机制（⟨Σ, Ev, Δ⟩三元组）管理状态演化；运行时层负责物理信号到逻辑证据的双向精化。

Result: 形式化定义了系统操作语义，证明了关键元理论性质（进展性和演化一致性），确保系统在连续状态转换中保持逻辑自洽且无停滞状态。通过工业追溯和跨境金融合规应用展示了实用性。

Conclusion: KOS-TL通过整合戴维森事件语义与马丁-洛夫类型理论，实现了"携带证明的知识"构建，为下一代智能自主操作系统提供了强大、形式可验证的基础。

Abstract: This paper introduces KOS-TL (Knowledge Operation System Type Logic), a novel constructive framework designed to provide a rigorous logical foundation for autonomous and executable knowledge systems. Traditional knowledge representation models often suffer from a gap between static symbolic logic and dynamic system execution. To bridge this divide, KOS-TL leverages Dependent Type Theory to unify data, logic, and proof into a singular computational substrate.The architecture of KOS-TL is organized into three hierarchical layers: the Core Layer, which defines the static type universe and constructive primitives; the Kernel Layer, which governs state evolution through an event-driven mechanism characterized by the triple $\langle Σ, \textsf{Ev}, Δ\rangle$; and the Runtime Layer, responsible for the bidirectional refinement of physical signals into logical evidence. We formally define the operational semantics of the system and prove key meta-theoretical properties, including Progress and Evolutionary Consistency, ensuring that the system remains logically self-consistent and free from stuck states during continuous state transitions.By integrating Davidsonian event semantics with Martin-Löf type theory, KOS-TL enables the construction of "proof-carrying knowledge," where every state change in the knowledge base is accompanied by a formal witness of its validity. We demonstrate the practical utility of this logic through application examples in industrial traceability and cross-border financial compliance. Our results suggest that KOS-TL provides a robust, formally verifiable basis for the next generation of intelligent, autonomous operating systems.

</details>


### [13] [SongSage: A Large Musical Language Model with Lyric Generative Pre-training](https://arxiv.org/abs/2601.01153)
*Jiani Guo,Jiajia Li,Jie Wu,Zuchao Li,Yujiu Yang,Ping Wang*

Main category: cs.CL

TL;DR: SongSage是一个专注于歌词理解的大型音乐语言模型，通过歌词生成预训练获得多样化的歌词中心智能，在播放列表理解和歌词相关任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前通用大语言模型在歌词中心知识理解方面尚未充分探索，特别是在播放列表理解能力上存在改进空间。作者希望通过专门的音乐语言模型来填补这一空白。

Method: 1. 创建PlaylistSense数据集评估语言模型的播放列表理解能力；2. 构建LyricBank语料库（54.8亿token）进行持续预训练；3. 使用LyricBank-SFT指令集（77.5万样本，9个核心任务）进行微调；4. 开发SongSage模型，专注于歌词中心智能。

Result: SongSage在歌词中心知识理解方面表现出色，能够有效重写用户查询进行零样本播放列表推荐，生成和续写歌词，并在其他七个能力上表现优异。同时保持了通用知识理解能力，获得有竞争力的MMLU分数。

Conclusion: SongSage是一个专门针对歌词理解的大型音乐语言模型，通过专门的预训练和微调策略，在播放列表理解和歌词相关任务上超越了通用大语言模型，为音乐AI研究和应用提供了有力工具。

Abstract: Large language models have achieved significant success in various domains, yet their understanding of lyric-centric knowledge has not been fully explored. In this work, we first introduce PlaylistSense, a dataset to evaluate the playlist understanding capability of language models. PlaylistSense encompasses ten types of user queries derived from common real-world perspectives, challenging LLMs to accurately grasp playlist features and address diverse user intents. Comprehensive evaluations indicate that current general-purpose LLMs still have potential for improvement in playlist understanding. Inspired by this, we introduce SongSage, a large musical language model equipped with diverse lyric-centric intelligence through lyric generative pretraining. SongSage undergoes continual pretraining on LyricBank, a carefully curated corpus of 5.48 billion tokens focused on lyrical content, followed by fine-tuning with LyricBank-SFT, a meticulously crafted instruction set comprising 775k samples across nine core lyric-centric tasks. Experimental results demonstrate that SongSage exhibits a strong understanding of lyric-centric knowledge, excels in rewriting user queries for zero-shot playlist recommendations, generates and continues lyrics effectively, and performs proficiently across seven additional capabilities. Beyond its lyric-centric expertise, SongSage also retains general knowledge comprehension and achieves a competitive MMLU score. We will keep the datasets inaccessible due to copyright restrictions and release the SongSage and training script to ensure reproducibility and support music AI research and applications, the datasets release plan details are provided in the appendix.

</details>


### [14] [DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models](https://arxiv.org/abs/2601.01156)
*Jiani Guo,Xiangke Zeng,Jie Wu,Zuchao Li*

Main category: cs.CL

TL;DR: DHI是一种新的训练框架，通过修改损失函数和因果注意力掩码，让"邪恶LLM"生成更多样化的幻觉，无需预标注数据，结合自适应理性约束提升幻觉检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过训练"邪恶LLM"在特定数据集上故意生成幻觉，但这种方法产生的幻觉类型有限，因为模型只学习到特定的错误模式，限制了整体效果。

Method: 提出DHI框架：1) 修改损失函数，降低特定事实正确token的生成权重，鼓励在目标位置产生多样化幻觉；2) 引入因果注意力掩码适应，减少惩罚对后续token的影响；3) 推理时应用自适应理性约束，仅在正模型高置信度时进行对比解码。

Result: 在多个幻觉基准测试中，DHI相比其他基于对比解码的方法取得了显著的性能提升。

Conclusion: DHI框架能够诱导更广泛的幻觉类型，无需依赖预标注数据，有效提升了幻觉检测和缓解的效果。

Abstract: Large language models (LLMs) frequently produce inaccurate or fabricated information, known as "hallucinations," which compromises their reliability. Existing approaches often train an "Evil LLM" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide contrastive decoding against a reliable "positive model" for hallucination mitigation. However, this strategy is limited by the narrow diversity of hallucinations induced, as Evil LLMs trained on specific error types tend to reproduce only these particular patterns, thereby restricting their overall effectiveness. To address these limitations, we propose DHI (Diverse Hallucination Induction), a novel training framework that enables the Evil LLM to generate a broader range of hallucination types without relying on pre-annotated hallucination data. DHI employs a modified loss function that down-weights the generation of specific factually correct tokens, encouraging the Evil LLM to produce diverse hallucinations at targeted positions while maintaining overall factual content. Additionally, we introduce a causal attention masking adaptation to reduce the impact of this penalization on the generation of subsequent tokens. During inference, we apply an adaptive rationality constraint that restricts contrastive decoding to tokens where the positive model exhibits high confidence, thereby avoiding unnecessary penalties on factually correct tokens. Extensive empirical results show that DHI achieves significant performance gains over other contrastive decoding-based approaches across multiple hallucination benchmarks.

</details>


### [15] [Almost Clinical: Linguistic properties of synthetic electronic health records](https://arxiv.org/abs/2601.01171)
*Serge Sharoff,John Baker,David Francis Hunt,Alan Simpson*

Main category: cs.CL

TL;DR: 评估心理健康领域合成电子健康记录的语言学和临床适用性，发现LLM能生成连贯、术语适当的文本，但存在系统性差异


<details>
  <summary>Details</summary>
Motivation: 评估合成电子健康记录在心理健康领域的适用性，了解LLM如何通过语言选择构建医疗权威和患者能动性

Method: 首先描述创建合成语料库的理论基础和方法论，然后评估四种临床体裁（评估、通信、转诊和护理计划）中的能动性、模态和信息流

Result: LLM能生成连贯、术语适当的文本，近似临床实践，但存在系统性差异，包括语域转换、临床特异性不足、药物使用和诊断程序不准确

Conclusion: 合成电子健康记录在心理健康领域具有潜力，但需要解决系统性差异问题，特别是在临床特异性和准确性方面

Abstract: This study evaluates the linguistic and clinical suitability of synthetic electronic health records (EHRs) in the field of mental health. First, we describe the rationale and the methodology for creating the synthetic corpus. Second, we assess agency, modality, and information flow across four clinical genres (Assessments, Correspondence, Referrals and Care plans) to understand how LLMs grammatically construct medical authority and patient agency through linguistic choices. While LLMs produce coherent, terminology-appropriate texts that approximate clinical practice, systematic divergences remain, including registerial shifts, insufficient clinical specificity, and inaccuracies in medication use and diagnostic procedures.

</details>


### [16] [Stylometry Analysis of Human and Machine Text for Academic Integrity](https://arxiv.org/abs/2601.01225)
*Hezam Albaqami,Muhammad Asif Ayub,Nasir Ahmad,Yaseen Ahmad,Mohammed M. Alqahtani,Abdullah M. Algamdi,Almoaid A. Owaidah,Kashif Ahmad*

Main category: cs.CL

TL;DR: 该论文提出基于NLP的框架，通过作者归属和风格变化检测来验证学生内容的真实性，解决学术诚信问题，包括人机文本分类、单/多作者区分、多作者文档中的作者变化检测和协作文档中的作者识别等四个任务。


<details>
  <summary>Details</summary>
Motivation: 解决学术诚信中的关键挑战，包括抄袭、捏造和教育内容作者身份验证，现有解决方案尚不完善，需要更全面的分析框架。

Method: 提出基于自然语言处理的框架，针对四个相关任务：人机文本分类、单/多作者区分、多作者文档中的作者变化检测、协作文档中的作者识别。使用Gemini生成的两个数据集（普通和严格指令）进行评估。

Result: 在严格指令生成的数据集上观察到性能下降，表明检测精心设计的机器生成文本的复杂性。公开提供了生成的数据集、代码和相关材料，为未来研究提供基准。

Conclusion: 该研究为学术诚信验证提供了全面的NLP框架，揭示了检测精心设计的机器生成文本的挑战，公开资源将促进该领域未来研究发展。

Abstract: This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.

</details>


### [17] [Racka: Efficient Hungarian LLM Adaptation on Academic Infrastructure](https://arxiv.org/abs/2601.01244)
*Zsolt Csibi,Bence György Gortka,Natabara Gyöngyössy,Kornél Nagy,Dávid Márk Nemeskey,Martin Sallai,András Simonyi,András Márk Szekeres,Gábor Palkó*

Main category: cs.CL

TL;DR: Racka是一个轻量级、持续预训练的大语言模型，专门为匈牙利语设计，旨在缩小匈牙利语与英语、德语等高资源语言之间的资源差距。


<details>
  <summary>Details</summary>
Motivation: 匈牙利语作为低资源语言，与英语、德语等高资源语言之间存在显著的资源差距。现有大语言模型对匈牙利语的支持不足，需要专门针对匈牙利语进行优化，同时保持对高资源语言的性能。

Method: 采用基于Qwen-3 4B骨干网络的参数高效持续预训练方法，使用LoRA（低秩适应）技术。替换并适配分词器以改善匈牙利语的分词效率。在160B子词标记的数据集上进行训练，数据混合比例为：44%匈牙利语、24%英语、21%德语、11%代码。

Result: 初步结果显示，模型在语言适应方面取得了稳定但适度的成果。匈牙利语的分词效率得到显著提升，同时保持了英语和德语的竞争性性能。

Conclusion: Racka通过参数高效的持续预训练方法，成功缩小了匈牙利语与高资源语言之间的资源差距，为低资源语言的大语言模型开发提供了实用的解决方案。

Abstract: We present Racka, a lightweight, continually pretrained large language model designed to bridge the resource gap between Hungarian and high-resource languages such as English and German. Racka employs parameter-efficient continual pretraining via Low-Rank Adaptation (LoRA) on a Qwen-3 4B backbone, making the recipe practical on A100 (40GB)-based HPC clusters with low inter-node bandwidth. To better match the training distribution, we replace and adapt the tokenizer, achieving substantially improved tokenization fertility for Hungarian while maintaining competitive performance in English and German. The model is trained on 160B subword tokens drawn from a mixture of internet and high-quality curated sources, with a composition of 44% Hungarian, 24% English, 21% German, and 11% code. This data mix is chosen to mitigate catastrophic forgetting and preserve high-resource language capabilities during continual pretraining. Our preliminary results indicate modest but stable results in language adaptation.

</details>


### [18] [From Policy to Logic for Efficient and Interpretable Coverage Assessment](https://arxiv.org/abs/2601.01266)
*Rhitabrat Pokharel,Hamid Hassanzadeh,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 提出结合检索增强与符号推理的混合系统，用于医疗保险政策分析，在减少44%推理成本的同时提升4.5% F1分数


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂法律和政策语言时存在幻觉和不一致问题，特别是在医疗保险政策审查这种需要高度准确性的领域，需要支持人类专家进行更高效和可解释的政策解读

Method: 结合覆盖感知检索器与基于符号的规则推理，提取相关政策语言，组织成明确的事实和规则，生成可审计的推理依据，减少LLM推理次数

Result: 实现了44%的推理成本降低和4.5%的F1分数提升，在效率和效果上都取得了显著改进

Conclusion: 该混合方法在医疗保险政策分析中既提高了效率又增强了可靠性，为人类专家提供了更高效、可解释的政策解读支持

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.

</details>


### [19] [Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory](https://arxiv.org/abs/2601.01280)
*Sen Hu,Yuxiang Wei,Jiaxin Ran,Zhiyuan Yao,Lei Zou*

Main category: cs.CL

TL;DR: 该论文通过统一框架分析对话记忆系统，发现性能差异主要源于基础系统设置而非特定架构创新，并确定了稳定可靠的基线方法。


<details>
  <summary>Details</summary>
Motivation: 图结构在对话记忆系统中应用日益广泛，但实证研究结果不一致，不清楚哪些设计选择真正重要，需要系统性的实验分析来澄清这一问题。

Method: 提出统一框架将对话记忆系统分解为核心组件，支持图和非图方法，在LongMemEval和HaluMem数据集上进行受控的分阶段实验，比较记忆表示、组织、维护和检索等常见设计选择。

Result: 实验结果表明，许多性能差异是由基础系统设置驱动的，而非特定的架构创新。基于这些发现，确定了未来对话记忆研究的稳定可靠基线方法。

Conclusion: 该研究为对话记忆系统提供了系统性的分析框架和可靠的基线，有助于未来研究更准确地评估架构创新的实际价值。

Abstract: Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.

</details>


### [20] [T3C: Test-Time Tensor Compression with Consistency Guarantees](https://arxiv.org/abs/2601.01299)
*Ismail Lamaakal,Chaymae Yahyati,Yassine Maleh,Khalid El Makkaoui,Ibrahim Ouahbi*

Main category: cs.CL

TL;DR: T3C是一个训练一次、测试时预算条件化的压缩框架，通过弹性张量分解和混合精度量化实现可控制的部署调整，提供可预测的精度-延迟-大小权衡。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩方法通常需要为不同部署场景重新训练或调整，缺乏统一的、可预测的精度-效率权衡方案。需要一种能够根据实际部署预算（延迟/能耗/大小）动态调整压缩策略的框架。

Method: 结合弹性张量分解（维持最大秩）、秩绑定的混合精度量化，以及轻量级控制器将预算令牌映射到每层秩/比特分配。使用基于谱代理和激活统计的快速层一致性证书来上界logit漂移并正则化训练。

Result: 在ImageNet-1k上，T3C显著推进了视觉模型的帕累托前沿：ResNet-50在精度损失≤0.5%时达到1.18ms p50延迟和38MB模型大小，优于PTQ-8b（1.44ms, 88MB）；ViT-B/16达到2.30ms p50延迟和59MB大小，超越强PTQ/QAT基线。

Conclusion: 单个T3C检查点即可提供可预测的、证书支持的精度-延迟-大小权衡，能够根据设备需求按需调整，实现了训练一次、部署灵活的高效模型压缩框架。

Abstract: We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.

</details>


### [21] [FLOP-Efficient Training: Early Stopping Based on Test-Time Compute Awareness](https://arxiv.org/abs/2601.01332)
*Hossam Amer,Maryam Dialameh,Hossein Rajabzadeh,Walid Ahmed,Weiwei Zhang,Yang Liu*

Main category: cs.CL

TL;DR: 提出TTC感知训练方法，通过早期停止算法和测试时计算优化，在保持准确性的同时大幅减少训练计算量


<details>
  <summary>Details</summary>
Motivation: 传统大规模语言模型训练计算成本高昂，虽然增加测试时计算可以让小模型媲美大模型，但训练过程仍然资源密集。需要找到平衡训练和推理计算的新方法，实现更快部署和更频繁模型更新。

Method: 1. 提出TTC感知训练：中间检查点配合相应测试时计算配置可达到或超过完整训练模型的准确性；2. 开发早期停止算法：联合选择检查点和TTC配置以最小化训练计算；3. 设计高效TTC评估方法避免穷举搜索；4. 形式化盈亏平衡界限确定推理计算何时补偿训练计算减少。

Result: 实验显示训练FLOPs最多减少92%，同时保持甚至显著提高准确性。验证了平衡训练和推理计算的新视角可行性。

Conclusion: TTC感知训练为模型开发提供了平衡训练和推理计算的新范式，能够实现更快部署周期和更频繁模型更新，代码将公开。

Abstract: Scaling training compute, measured in FLOPs, has long been shown to improve the accuracy of large language models, yet training remains resource-intensive. Prior work shows that increasing test-time compute (TTC)-for example through iterative sampling-can allow smaller models to rival or surpass much larger ones at lower overall cost. We introduce TTC-aware training, where an intermediate checkpoint and a corresponding TTC configuration can together match or exceed the accuracy of a fully trained model while requiring substantially fewer training FLOPs. Building on this insight, we propose an early stopping algorithm that jointly selects a checkpoint and TTC configuration to minimize training compute without sacrificing accuracy. To make this practical, we develop an efficient TTC evaluation method that avoids exhaustive search, and we formalize a break-even bound that identifies when increased inference compute compensates for reduced training compute. Experiments demonstrate up to 92\% reductions in training FLOPs while maintaining and sometimes remarkably improving accuracy. These results highlight a new perspective for balancing training and inference compute in model development, enabling faster deployment cycles and more frequent model refreshes. Codes will be publicly released.

</details>


### [22] [Reasoning Over Recall: Evaluating the Efficacy of Generalist Architectures vs. Specialized Fine-Tunes in RAG-Based Mental Health Dialogue Systems](https://arxiv.org/abs/2601.01341)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 在心理健康咨询中，通用推理模型（3B参数）通过RAG框架比领域微调模型（7B参数）表现更好，尤其在共情能力方面，表明强推理能力比心理健康特定训练更重要。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在心理健康咨询中存在的幻觉和缺乏共情问题，探索在RAG框架下，是领域微调模型还是通用推理模型更适合心理健康咨询应用。

Method: 使用四个开源模型（两个通用推理模型：Qwen2.5-3B和Phi-3-Mini；两个领域微调模型：MentalHealthBot-7B和TherapyBot-7B）通过相同的ChromaDB RAG流程进行比较，采用LLM-as-a-Judge框架对50轮对话进行自动化评估。

Result: 通用模型在共情能力上显著优于领域模型（3.72 vs. 3.26，p<0.001），尽管参数更小（3B vs. 7B）。所有模型在安全性方面表现良好，但通用模型展现出更好的上下文理解能力，且不易过拟合。

Conclusion: 对于基于RAG的治疗系统，强推理能力比心理健康特定词汇训练更重要。只要回答基于临床证据，推理能力强的通用模型能提供比更大但窄领域微调模型更共情和平衡的支持。

Abstract: The deployment of Large Language Models (LLMs) in mental health counseling faces the dual challenges of hallucinations and lack of empathy. While the former may be mitigated by RAG (retrieval-augmented generation) by anchoring answers in trusted clinical sources, there remains an open question as to whether the most effective model under this paradigm would be one that is fine-tuned on mental health data, or a more general and powerful model that succeeds purely on the basis of reasoning. In this paper, we perform a direct comparison by running four open-source models through the same RAG pipeline using ChromaDB: two generalist reasoners (Qwen2.5-3B and Phi-3-Mini) and two domain-specific fine-tunes (MentalHealthBot-7B and TherapyBot-7B). We use an LLM-as-a-Judge framework to automate evaluation over 50 turns. We find a clear trend: the generalist models outperform the domain-specific ones in empathy (3.72 vs. 3.26, $p < 0.001$) in spite of being much smaller (3B vs. 7B), and all models perform well in terms of safety, but the generalist models show better contextual understanding and are less prone to overfitting as we observe in the domain-specific models. Overall, our results indicate that for RAG-based therapy systems, strong reasoning is more important than training on mental health-specific vocabulary; i.e. a well-reasoned general model would provide more empathetic and balanced support than a larger narrowly fine-tuned model, so long as the answer is already grounded in clinical evidence.

</details>


### [23] [FC-CONAN: An Exhaustively Paired Dataset for Robust Evaluation of Retrieval Systems](https://arxiv.org/abs/2601.01350)
*Juan Junqueras,Florian Boudin,May-Myo Zin,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Damián Ariel Furman,Akiko Aizawa,Ken Satoh*

Main category: cs.CL

TL;DR: FC-CONAN是首个通过穷举45条仇恨言论和129条反叙事所有组合构建的完全连接数据集，包含四个不同可靠性层级的标注分区，填补了现有数据集的稀疏标注问题。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论-反叙事数据集（如CONAN）只标注了稀疏的HS-CN配对，限制了反言论研究的评估能力。需要更全面的数据集来支持更准确的系统评估和错误分析。

Method: 采用两阶段标注流程：1) 穷举45条英语仇恨言论和129条反叙事的所有组合（共5805对）；2) 通过9名标注员和4名验证员创建四个不同可靠性层级的标注分区（钻石、黄金、白银、青铜）。

Result: FC-CONAN发现了数百个之前未标注的正例配对，提供了更全面的评估基准。数据集包含四个分区，平衡了可靠性和规模，支持反言论检索系统的忠实评估和详细错误分析。

Conclusion: FC-CONAN填补了仇恨言论-反叙事数据集的空白，提供了首个完全连接的标注数据集，能够显著改进反言论系统的评估和研究。数据集已公开可用。

Abstract: Hate speech (HS) is a critical issue in online discourse, and one promising strategy to counter it is through the use of counter-narratives (CNs). Datasets linking HS with CNs are essential for advancing counterspeech research. However, even flagship resources like CONAN (Chung et al., 2019) annotate only a sparse subset of all possible HS-CN pairs, limiting evaluation. We introduce FC-CONAN (Fully Connected CONAN), the first dataset created by exhaustively considering all combinations of 45 English HS messages and 129 CNs. A two-stage annotation process involving nine annotators and four validators produces four partitions-Diamond, Gold, Silver, and Bronze-that balance reliability and scale. None of the labeled pairs overlap with CONAN, uncovering hundreds of previously unlabelled positives. FC-CONAN enables more faithful evaluation of counterspeech retrieval systems and facilitates detailed error analysis. The dataset is publicly available.

</details>


### [24] [Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning](https://arxiv.org/abs/2601.01362)
*Jerry Huang,Peng Lu,Qiuhao Zeng,Yusuke Iwasawa,Yutaka Matsuo,Sarath Chandar,Edison Marrese-Taylor,Irene Li*

Main category: cs.CL

TL;DR: 研究发现，在多语言环境中，大型语言模型（LLMs）的校准存在严重问题：即使低资源语言在指令调优后模型置信度显著提升，但准确率改善有限，导致校准不良。标签平滑技术能有效缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型研究不断进步，但大型语言模型在多语言环境中的校准问题仍是一个开放的研究领域。本研究旨在填补这一空白，探索数据稀缺如何影响校准效果，以及常用技术在此场景下的适用性。

Method: 在两个多语言基准测试（分别覆盖29和42种语言）上进行分析，研究指令调优对低资源语言的影响，并评估标签平滑技术在改善校准方面的效果。

Result: 发现低资源语言在基于高资源语言SFT数据集进行指令调优后，模型置信度显著增加，但准确率改善有限或没有改善，导致校准不良。标签平滑技术能有效缓解此问题，且无需低资源SFT数据。

Conclusion: 标准SFT方法在多语言环境中存在严重缺陷，会破坏校准。标签平滑是一种有效的缓解方法。研究强调了在多语言环境下训练和调优LLMs时考虑校准问题的重要性，以提高下游应用的可靠性和公平性。

Abstract: Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such large language models (LLMs) and their calibration remains an open area of research. In this work, we look at a critical gap in the calibration of LLMs within multilingual settings, in an attempt to better understand how the data scarcity can potentially lead to different calibration effects and how commonly used techniques can apply in these settings. Our analysis on two multilingual benchmarks, over 29 and 42 languages respectively, reveals that even in low-resource languages, model confidence can increase significantly after instruction-tuning on high-resource language SFT datasets. However, improvements in accuracy are marginal or non-existent, resulting in mis-calibration, highlighting a critical shortcoming of standard SFT for multilingual languages. Furthermore, we observe that the use of label smoothing to be a reasonable method alleviate this concern, again without any need for low-resource SFT data, maintaining better calibration across all languages. Overall, this highlights the importance of multilingual considerations for both training and tuning LLMs in order to improve their reliability and fairness in downstream use.

</details>


### [25] [EternalMath: A Living Benchmark of Frontier Mathematics that Evolves with Human Discovery](https://arxiv.org/abs/2601.01400)
*Jicheng Ma,Guohua Wang,Xinhua Feng,Yiming Liu,Zhichao Hu,Yuhong Liu*

Main category: cs.CL

TL;DR: 提出EternalMath：一個從最新數學研究文獻自動生成可執行驗證推理任務的評估框架，解決現有靜態基準覆蓋不足和性能快速飽和的問題。


<details>
  <summary>Details</summary>
Motivation: 當前LLM數學推理評估主要依賴靜態基準，這些基準要么來自競賽題目，要么需要專家人工編寫，導致研究級數學覆蓋有限且性能快速飽和，需要能隨數學研究發展而演進的評估方法。

Method: 設計全自動、定理基礎的評估流水線：從近期同行評審數學文獻中識別構造性或定量結果，將其轉化為參數化問題模板，通過執行驗證生成確定性解，創建可擴展、可重現且持續更新的評估套件EternalMath。

Result: 實驗顯示最先進LLM在EternalMath上存在顯著性能差距，表明研究前沿的數學推理遠未飽和，凸顯評估方法需要與人類數學發現同步演進的重要性。

Conclusion: EternalMath提供了一個可持續演進的數學推理評估框架，能更好地反映LLM在真實研究級數學問題上的能力，推動評估方法與數學研究前沿保持同步。

Abstract: Current evaluations of mathematical reasoning in large language models (LLMs) are dominated by static benchmarks, either derived from competition-style problems or curated through costly expert effort, resulting in limited coverage of research-level mathematics and rapid performance saturation. We propose a fully automated, theorem-grounded pipeline for evaluating frontier mathematical reasoning, which directly transforms recent peer-reviewed mathematical literature into executable and verifiable reasoning tasks. The pipeline identifies constructive or quantitative results, instantiates them into parameterized problem templates, and generates deterministic solutions through execution-based verification, enabling scalable, reproducible, and continuously updatable evaluation without reliance on large-scale expert authoring. By design, this approach supports temporal extensibility, intrinsic correctness checking, and domain-specific customization across mathematical subfields. Applying this pipeline yields \textbf{EternalMath}, an evolving evaluation suite derived from contemporary research papers. Experiments with state-of-the-art LLMs reveal substantial performance gaps, indicating that mathematical reasoning at the research frontier remains far from saturated and underscoring the need for evaluation methodologies that evolve in step with human mathematical discovery.

</details>


### [26] [LANCET: Neural Intervention via Structural Entropy for Mitigating Faithfulness Hallucinations in LLMs](https://arxiv.org/abs/2601.01401)
*Chenxu Wang,Chaozhuo Li,Pengbo Wang,Litian Zhang,Songyang Liu,Ji Qi,Jiahui Hu,Yushan Cai,Hao Zhao,Rui Pu*

Main category: cs.CL

TL;DR: Lancet框架通过结构熵和幻觉差异比实现精确神经干预，定位幻觉易发神经元并阻断其传播路径，在幻觉基准数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型存在严重的忠实性幻觉问题，现有方法通过节点级调整或粗粒度抑制，往往忽略了神经信息的分布式特性，导致干预不精确。作者认识到幻觉像感染一样通过特定的前向传播路径传播，因此希望通过精确的结构分析来手术式阻断这种流动。

Method: 提出Lancet框架：1) 通过梯度驱动的对比分析定位幻觉易发神经元；2) 通过最小化结构熵映射其传播路径；3) 实施分层干预策略以保留模型的一般能力。该框架利用结构熵和幻觉差异比实现精确神经干预。

Result: 在幻觉基准数据集上的综合评估表明，Lancet显著优于最先进的方法，验证了这种手术式神经干预方法的有效性。

Conclusion: 通过精确的结构分析和手术式干预，可以有效阻断幻觉的传播路径，同时保持模型的一般能力，为解决大语言模型的忠实性幻觉问题提供了新思路。

Abstract: Large Language Models have revolutionized information processing, yet their reliability is severely compromised by faithfulness hallucinations. While current approaches attempt to mitigate this issue through node-level adjustments or coarse suppression, they often overlook the distributed nature of neural information, leading to imprecise interventions. Recognizing that hallucinations propagate through specific forward transmission pathways like an infection, we aim to surgically block this flow using precise structural analysis. To leverage this, we propose Lancet, a novel framework that achieves precise neural intervention by leveraging structural entropy and hallucination difference ratios. Lancet first locates hallucination-prone neurons via gradient-driven contrastive analysis, then maps their propagation pathways by minimizing structural entropy, and finally implements a hierarchical intervention strategy that preserves general model capabilities. Comprehensive evaluations across hallucination benchmark datasets demonstrate that Lancet significantly outperforms state-of-the-art methods, validating the effectiveness of our surgical approach to neural intervention.

</details>


### [27] [From Emotion Classification to Emotional Reasoning: Enhancing Emotional Intelligence in Large Language Models](https://arxiv.org/abs/2601.01407)
*Arjhun Sreedar,Rohan Pillay,Laukik Patade*

Main category: cs.CL

TL;DR: 使用合成情感链式思维数据增强小型开源大语言模型的情感推理能力，通过多智能体生成治疗式对话并转化为结构化情感选择题，微调7B模型在情感理解(EU)和情感意识(EA)评估上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索是否可以通过合成情感推理数据来提升较小规模开源大语言模型的情感推理能力，而不需要改变模型架构。当前较小模型在复杂情感任务上表现有限，需要寻找有效方法来增强其情感理解和意识能力。

Method: 设计了多智能体生成管道，首先生成治疗式对话，然后将其转化为结构化的情感多选题(MCQs)并附带解释。使用这些合成的情感推理数据对多种7B模型进行微调，在EmoBench风格评估中测试情感理解和情感意识能力。

Result: 微调后的Mistral 7B模型在情感理解(EU)方面从10.5提升到20.5，在情感意识(EA)方面从40.5提升到60.0，证明了合成情感推理数据在增强模型处理细微情感任务能力方面的有效性。

Conclusion: 研究表明，通过合成情感链式思维数据进行微调，可以在不改变模型架构的情况下显著提升较小规模开源大语言模型的情感推理能力，为增强AI情感智能提供了有效且可扩展的方法。

Abstract: This work investigates whether synthetic emotional chain-of-thought data can improve the emotional reasoning abilities of smaller open large language models (LLMs). We design a multi-agent generation pipeline that produces therapy-style conversations and converts them into structured emotion multiple-choice questions (MCQs) with explanations. We propose that fine-tuning a variety of 7B models on this dataset should yield substantial gains in emotional understanding and emotional awareness on EmoBench-style evaluations, suggesting that emotional reasoning can be induced without architectural changes. Our results demonstrate that fine-tuned Mistral 7B achieves EU improvements from 10.5 to 20.5 and EA improvements from 40.5 to 60.0, validating the effectiveness of synthetic emotional reasoning data for enhancing model capabilities in nuanced emotional tasks.

</details>


### [28] [iFlip: Iterative Feedback-driven Counterfactual Example Refinement](https://arxiv.org/abs/2601.01446)
*Yilong Wang,Qianli Wang,Nils Feldhus*

Main category: cs.CL

TL;DR: iFlip是一种利用大语言模型自我修正能力的迭代优化方法，通过模型置信度、特征归因和自然语言反馈生成有效的反事实示例，相比现有方法显著提高了标签翻转率。


<details>
  <summary>Details</summary>
Motivation: 现有单次生成方法在利用大语言模型生成有效反事实示例时经常失败，无法可靠地改变模型预测标签，忽视了LLMs的自我修正能力。需要探索这种未开发的潜力来改进反事实生成。

Method: iFlip采用迭代优化方法，利用三种反馈类型：模型置信度、特征归因和自然语言反馈。通过适当的迭代次数、指向高归因词语和早停策略来生成有效的反事实示例。

Result: iFlip在标签翻转率上比五种最先进的基线方法平均高出57.8%。用户研究证实iFlip在完整性、总体满意度和可行性方面优于基线。消融研究表明三个组件对生成有效反事实至关重要。

Conclusion: iFlip通过利用大语言模型的自我修正能力，显著提高了反事实生成的有效性，并且生成的反事实可用于数据增强，有效提升模型性能和鲁棒性。

Abstract: Counterfactual examples are minimal edits to an input that alter a model's prediction. They are widely employed in explainable AI to probe model behavior and in natural language processing (NLP) to augment training data. However, generating valid counterfactuals with large language models (LLMs) remains challenging, as existing single-pass methods often fail to induce reliable label changes, neglecting LLMs' self-correction capabilities. To explore this untapped potential, we propose iFlip, an iterative refinement approach that leverages three types of feedback, including model confidence, feature attribution, and natural language. Our results show that iFlip achieves an average 57.8% higher validity than the five state-of-the-art baselines, as measured by the label flipping rate. The user study further corroborates that iFlip outperforms baselines in completeness, overall satisfaction, and feasibility. In addition, ablation studies demonstrate that three components are paramount for iFlip to generate valid counterfactuals: leveraging an appropriate number of iterations, pointing to highly attributed words, and early stopping. Finally, counterfactuals generated by iFlip enable effective counterfactual data augmentation, substantially improving model performance and robustness.

</details>


### [29] [Segmentation and Processing of German Court Decisions from Open Legal Data](https://arxiv.org/abs/2601.01449)
*Harshil Darji,Martin Heckelmann,Christina Kratsch,Gerard de Melo*

Main category: cs.CL

TL;DR: 研究者清理并结构化德国法院判决数据集，系统分离出判决的三个核心部分，并验证提取准确性，为德国法律NLP研究提供高质量资源。


<details>
  <summary>Details</summary>
Motivation: 德国法律系统中结构化数据的缺乏阻碍了NLP技术的发展。虽然Open Legal Data提供了大量德国法院判决，但判决文本格式不一致且缺乏明确标记的章节，这影响了修辞角色分类、检索和引用分析等下游任务。

Method: 从Open Legal Data官方数据集中提取251,038个德国法院判决，系统分离三个重要部分：Tenor（判决主文）、Tatbestand（案件事实）和Entscheidungsgründe（判决理由）。使用Cochran公式以95%置信水平和5%误差范围抽取384个案例的统计代表性样本进行人工验证。还将Rechtsmittelbelehrung（上诉通知）作为单独字段提取。

Result: 创建了一个包含251,038个德国法院判决的清理和结构化数据集，三个核心部分被准确分离。通过统计抽样验证，确保所有三个部分都被正确识别。最终语料库以JSONL格式公开提供。

Conclusion: 该工作提供了一个高质量、结构化的德国法院判决数据集，解决了原始数据格式不一致的问题，为德国法律系统的NLP研究提供了可访问的资源，有助于推动法律文本分析、检索和引用分析等下游任务的发展。

Abstract: The availability of structured legal data is important for advancing Natural Language Processing (NLP) techniques for the German legal system. One of the most widely used datasets, Open Legal Data, provides a large-scale collection of German court decisions. While the metadata in this raw dataset is consistently structured, the decision texts themselves are inconsistently formatted and often lack clearly marked sections. Reliable separation of these sections is important not only for rhetorical role classification but also for downstream tasks such as retrieval and citation analysis. In this work, we introduce a cleaned and sectioned dataset of 251,038 German court decisions derived from the official Open Legal Data dataset. We systematically separated three important sections in German court decisions, namely Tenor (operative part of the decision), Tatbestand (facts of the case), and Entscheidungsgründe (judicial reasoning), which are often inconsistently represented in the original dataset. To ensure the reliability of our extraction process, we used Cochran's formula with a 95% confidence level and a 5% margin of error to draw a statistically representative random sample of 384 cases, and manually verified that all three sections were correctly identified. We also extracted the Rechtsmittelbelehrung (appeal notice) as a separate field, since it is a procedural instruction and not part of the decision itself. The resulting corpus is publicly available in the JSONL format, making it an accessible resource for further research on the German legal system.

</details>


### [30] [Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR](https://arxiv.org/abs/2601.01461)
*Yuxiang Mei,Dongxing Xu,Jiaen Liang,Yanhua Long*

Main category: cs.CL

TL;DR: 本文提出了一种增强的基于LLM的ASR框架，通过交叉注意力融合机制结合Whisper和mHuBERT编码器，在MLC-SLM挑战中取得了与顶级系统相当的性能，但发现仍不及端到端Whisper模型。


<details>
  <summary>Details</summary>
Motivation: 解决之前SHNU-mASR系统的两个问题：简单特征拼接未能充分利用互补信息，以及LLM-based ASR与端到端编码器-解码器ASR之间的性能差距尚未探索。

Method: 提出增强的LLM-based ASR框架，结合微调的Whisper和mHuBERT编码器，采用交叉注意力融合机制整合并行语音编码器特征，并评估了LoRA和全微调的Whisper模型。

Result: 在MLC-SLM挑战官方评估集上获得10.69%的CER/WER，与使用大规模训练数据的顶级Track 1系统性能相当，但仅使用1500小时基线训练数据。

Conclusion: 最终LLM-based ASR仍不及微调的端到端Whisper模型，为未来Speech-LLM设计提供了有价值的经验指导。

Abstract: The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with an LLM. However, it faced two challenges: simple feature concatenation may not fully exploit complementary information, and the performance gap between LLM-based ASR and end-to-end(E2E) encoder-decoder ASR remained unexplored. In this work, we present an enhanced LLM-based ASR framework that combines fine-tuned Whisper and mHuBERT encoders with an LLM to enrich speech representations. We first evaluate E2E Whisper models with LoRA and full fine-tuning on the MLC-SLM ASR task, and then propose cross-attention-based fusion mechanisms for the parallel-speech-encoder. On the official evaluation set of the MLC-SLM Challenge, our system achieves a CER/WER of 10.69%, ranking on par with the top-ranked Track 1 systems, even though it uses only 1,500 hours of baseline training data compared with their large-scale training sets. Nonetheless, we find that our final LLM-based ASR still does not match the performance of a fine-tuned E2E Whisper model, providing valuable empirical guidance for future Speech-LLM design. Our code is publicly available at https://github.com/1535176727/MLC-SLM.

</details>


### [31] [Can Legislation Be Made Machine-Readable in PROLEG?](https://arxiv.org/abs/2601.01477)
*May-Myo Zin,Sabine Wehnert,Yuntao Kong,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Jieying Xue,Michał Araszkiewicz,Randy Goebel,Ken Satoh,Le-Minh Nguyen*

Main category: cs.CL

TL;DR: 提出一个结合LLM和PROLEG法律表示系统的框架，将GDPR等法规文本自动转换为可执行的if-then规则和PROLEG编码，支持可解释的法律决策。


<details>
  <summary>Details</summary>
Motivation: 法规应用需要准确性和效率，但传统方法难以满足。AI技术特别是NLP和法律形式化推理有望解决这一挑战，实现法规的自动化处理和应用。

Method: 使用LLM提示将法律文本（如GDPR第6条）同时转换为if-then规则和PROLEG编码，经法律专家验证和优化后，生成可执行的PROLEG程序，支持人类可读的解释。

Result: 开发了端到端框架，成功将GDPR第6条转换为可执行的PROLEG程序，能够生成人类可读的GDPR决策解释实例。

Conclusion: 该方法展示了结合LLM和法律形式化系统在法规捕获和部署中的价值，指出了当前局限性并提出了进一步发展的建议。

Abstract: The anticipated positive social impact of regulatory processes requires both the accuracy and efficiency of their application. Modern artificial intelligence technologies, including natural language processing and machine-assisted reasoning, hold great promise for addressing this challenge. We present a framework to address the challenge of tools for regulatory application, based on current state-of-the-art (SOTA) methods for natural language processing (large language models or LLMs) and formalization of legal reasoning (the legal representation system PROLEG). As an example, we focus on Article 6 of the European General Data Protection Regulation (GDPR). In our framework, a single LLM prompt simultaneously transforms legal text into if-then rules and a corresponding PROLEG encoding, which are then validated and refined by legal domain experts. The final output is an executable PROLEG program that can produce human-readable explanations for instances of GDPR decisions. We describe processes to support the end-to-end transformation of a segment of a regulatory document (Article 6 from GDPR), including the prompting frame to guide an LLM to "compile" natural language text to if-then rules, then to further "compile" the vetted if-then rules to PROLEG. Finally, we produce an instance that shows the PROLEG execution. We conclude by summarizing the value of this approach and note observed limitations with suggestions to further develop such technologies for capturing and deploying regulatory frameworks.

</details>


### [32] [Four Quadrants of Difficulty: A Simple Categorisation and its Limits](https://arxiv.org/abs/2601.01488)
*Vanessa Toborek,Sebastian Müller,Christian Bauckhage*

Main category: cs.CL

TL;DR: 研究发现任务无关特征与模型学习行为不相关，只有任务相关特征与模型难度感知一致，挑战了传统课程学习直觉，建议开发轻量级任务相关难度估计器


<details>
  <summary>Details</summary>
Motivation: 课程学习(CL)通过估计样本难度并相应安排训练顺序来改进模型训练效果。在NLP中，难度通常使用任务无关的语言学启发式方法或人类直觉来近似，这隐含假设这些信号与神经网络模型认为难以学习的内容相关。本研究旨在验证这一假设并分析不同难度信号与模型学习行为的关系。

Method: 提出四象限分类法：人类vs模型、任务无关vs任务相关。在自然语言理解数据集上系统分析这些难度信号的交互作用，比较不同特征与模型学习行为的相关性。

Result: 发现任务无关特征在很大程度上独立于模型学习行为，只有任务相关特征与模型难度感知一致。这些发现挑战了常见的课程学习直觉，表明传统基于语言学特征或人类直觉的难度估计方法可能不准确。

Conclusion: 需要开发轻量级、任务相关的难度估计器，以更好地反映模型的学习行为，而不是依赖任务无关的语言学特征或人类直觉。这为课程学习在NLP中的实际应用提供了重要指导。

Abstract: Curriculum Learning (CL) aims to improve the outcome of model training by estimating the difficulty of samples and scheduling them accordingly. In NLP, difficulty is commonly approximated using task-agnostic linguistic heuristics or human intuition, implicitly assuming that these signals correlate with what neural models find difficult to learn. We propose a four-quadrant categorisation of difficulty signals -- human vs. model and task-agnostic vs. task-dependent -- and systematically analyse their interactions on a natural language understanding dataset. We find that task-agnostic features behave largely independently and that only task-dependent features align. These findings challenge common CL intuitions and highlight the need for lightweight, task-dependent difficulty estimators that better reflect model learning behaviour.

</details>


### [33] [Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints](https://arxiv.org/abs/2601.01490)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 研究发现推理能力在封闭系统中存在约束合规性与事实准确性之间的权衡问题：非推理模型违反约束但保持事实准确，推理模型减少违规但会扭曲事实以满足约束


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，幻觉问题日益严重。推理能力被视为提高输出可靠性的自我验证过程，但在无法依赖外部工具或知识的封闭系统中，推理的效果尚未明确。本研究旨在严格约束条件下（推荐计算机科学同行评审期刊文章）检验推理的效果。

Method: 在严格约束条件下（推荐计算机科学同行评审期刊文章），对多个模型（GPT-5.2和Gemini 3 Flash）进行实验，比较推理模型与非推理模型的表现，分析约束合规性与事实准确性之间的权衡关系。

Result: 非推理模型约束违规率高（66-75%）但保持事实准确性；推理模型减少违规（13-26%）但会系统性地扭曲已知事实以满足约束，并增加完全捏造。这种权衡模式在不同架构的模型中保持一致，表明推理存在根本性限制。推理并不统一提高输出真实性，效果因模型而异。

Conclusion: 推理并不普遍提高可靠性：推理模型以诚实的约束违规为代价，换取难以检测的扭曲。这一发现挑战了推理能普遍提高可靠性的假设，揭示了封闭系统中推理能力的根本局限性。

Abstract: With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.

</details>


### [34] [From Failure to Mastery: Generating Hard Samples for Tool-use Agents](https://arxiv.org/abs/2601.01498)
*Bingguang Hao,Zengzhuang Xu,Yuntao Wen,Xinyi Xu,Yang Liu,Tong Zhao,Maolin Wang,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Xiangyu Zhao,Chenyi Zhuang,Ji Zhang*

Main category: cs.CL

TL;DR: HardGen是一个自动化的agentic pipeline，用于生成具有可验证推理的困难工具使用训练样本，通过动态API图、高级工具实例化和闭环评估反馈来提升LLM agent的训练数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有工具使用训练数据生成方法主要采用随机采样和浅层生成范式，产生的轨迹简单且同质化，无法捕捉复杂、隐式的逻辑依赖关系，限制了LLM agent的能力提升。

Method: 1) 基于agent失败案例建立动态API图并采样合成困难轨迹；2) 以这些轨迹作为条件先验指导模块化抽象高级工具的实例化；3) 利用高级工具制定困难查询；4) 生成可验证的复杂思维链，并通过闭环评估反馈持续优化整个过程。

Result: 使用HardGen生成的数据集训练的4B参数模型在性能上超越了多个领先的开源和闭源竞争对手，包括GPT-5.2、Gemini-3-Pro和Claude-Opus-4.5。

Conclusion: HardGen能够有效生成具有可验证推理的困难工具使用训练样本，显著提升LLM agent的性能，相关代码、模型和数据集将开源以促进未来研究。

Abstract: The advancement of LLM agents with tool-use capabilities requires diverse and complex training corpora. Existing data generation methods, which predominantly follow a paradigm of random sampling and shallow generation, often yield simple and homogeneous trajectories that fail to capture complex, implicit logical dependencies. To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning. Firstly, HardGen establishes a dynamic API Graph built upon agent failure cases, from which it samples to synthesize hard traces. Secondly, these traces serve as conditional priors to guide the instantiation of modular, abstract advanced tools, which are subsequently leveraged to formulate hard queries. Finally, the advanced tools and hard queries enable the generation of verifiable complex Chain-of-Thought (CoT), with a closed-loop evaluation feedback steering the continuous refinement of the process. Extensive evaluations demonstrate that a 4B parameter model trained with our curated dataset achieves superior performance compared to several leading open-source and closed-source competitors (e.g., GPT-5.2, Gemini-3-Pro and Claude-Opus-4.5). Our code, models, and dataset will be open-sourced to facilitate future research.

</details>


### [35] [EmoHarbor: Evaluating Personalized Emotional Support by Simulating the User's Internal World](https://arxiv.org/abs/2601.01530)
*Jing Ye,Lu Xiang,Yaping Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: EmoHarbor是一个自动化评估框架，采用"用户即裁判"范式，通过模拟用户内心世界来评估情感支持对话的个性化质量，发现当前LLM虽能生成共情回应但缺乏个性化支持能力。


<details>
  <summary>Details</summary>
Motivation: 当前情感支持对话的评估范式倾向于奖励通用的共情回应，但无法评估支持是否真正个性化地适应用户独特的心理特征和情境需求，需要更精细的评估方法。

Method: 提出EmoHarbor框架，采用用户即裁判范式，使用Chain-of-Agent架构将用户内部过程分解为三个专门角色，基于100个真实用户配置文件（涵盖多样人格特质和情境）和10个评估维度来评估个性化支持质量。

Result: 对20个先进LLM的综合评估揭示关键发现：这些模型在生成共情回应方面表现出色，但始终无法根据个体用户情境定制支持，这重新定义了核心挑战。

Conclusion: EmoHarbor提供了一个可重复、可扩展的框架，将研究重点从仅仅增强通用共情转向开发真正用户感知的情感支持系统，指导更细致和用户感知的情感支持系统的开发与评估。

Abstract: Current evaluation paradigms for emotional support conversations tend to reward generic empathetic responses, yet they fail to assess whether the support is genuinely personalized to users' unique psychological profiles and contextual needs. We introduce EmoHarbor, an automated evaluation framework that adopts a User-as-a-Judge paradigm by simulating the user's inner world. EmoHarbor employs a Chain-of-Agent architecture that decomposes users' internal processes into three specialized roles, enabling agents to interact with supporters and complete assessments in a manner similar to human users. We instantiate this benchmark using 100 real-world user profiles that cover a diverse range of personality traits and situations, and define 10 evaluation dimensions of personalized support quality. Comprehensive evaluation of 20 advanced LLMs on EmoHarbor reveals a critical insight: while these models excel at generating empathetic responses, they consistently fail to tailor support to individual user contexts. This finding reframes the central challenge, shifting research focus from merely enhancing generic empathy to developing truly user-aware emotional support. EmoHarbor provides a reproducible and scalable framework to guide the development and evaluation of more nuanced and user-aware emotional support systems.

</details>


### [36] [Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM](https://arxiv.org/abs/2601.01543)
*Praveenkumar Katwe,RakeshChandra Balabantaray,Kaliprasad Vittala*

Main category: cs.CL

TL;DR: 本文提出了一种经济高效的自动化框架，用于创建全面的印地语文本摘要数据集，通过翻译和语言适应技术将英语XSUM数据集转换为印地语，并使用COMET和LLM进行验证和筛选。


<details>
  <summary>Details</summary>
Motivation: 当前NLP进展主要偏向资源丰富的语言，像印地语这样的低资源语言缺乏高质量的文本摘要数据集，这阻碍了鲁棒模型的发展。需要解决这种不平衡，为印地语NLP研究提供工具。

Method: 使用英语XSUM数据集作为源，采用先进的翻译和语言适应技术创建印地语摘要数据集。使用COMET进行翻译质量验证，并选择性使用大型语言模型进行数据筛选和整理。

Result: 创建了一个多样化、多主题的印地语文本摘要数据集，该数据集反映了原始XSUM语料库的复杂性，为印地语NLP研究提供了直接工具。

Conclusion: 这项工作不仅为印地语NLP研究提供了数据集，还提供了一种可扩展的方法论，可以推广到其他资源不足的语言，通过降低数据集创建成本，促进了计算语言学中更细致、文化相关模型的发展。

Abstract: Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.
  To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.
  The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.

</details>


### [37] [HalluZig: Hallucination Detection using Zigzag Persistence](https://arxiv.org/abs/2601.01552)
*Shreyas N. Samaga,Gilberto Gonzalez Arroyo,Tamal K. Dey*

Main category: cs.CL

TL;DR: 提出HalluZig框架，利用拓扑数据分析检测LLM幻觉，通过分析注意力矩阵的动态拓扑结构区分事实与幻觉生成


<details>
  <summary>Details</summary>
Motivation: LLM的事实可靠性是其在高风险领域应用的关键障碍，现有检测方法依赖模型输出的表面信号，忽略了内部推理过程中的失败

Method: 提出HalluZig框架，将注意力矩阵序列建模为zigzag图过滤，使用zigzag持久性提取拓扑特征，假设事实和幻觉生成具有不同的拓扑签名

Result: 在多个基准测试中验证了HalluZig框架，证明其优于强基线方法，拓扑特征在不同模型间具有可泛化性，且仅使用部分网络深度的结构特征即可检测幻觉

Conclusion: 通过分析注意力动态拓扑结构为幻觉检测提供了新范式，拓扑特征能有效区分事实与幻觉，且具有跨模型泛化能力

Abstract: The factual reliability of Large Language Models (LLMs) remains a critical barrier to their adoption in high-stakes domains due to their propensity to hallucinate. Current detection methods often rely on surface-level signals from the model's output, overlooking the failures that occur within the model's internal reasoning process. In this paper, we introduce a new paradigm for hallucination detection by analyzing the dynamic topology of the evolution of model's layer-wise attention. We model the sequence of attention matrices as a zigzag graph filtration and use zigzag persistence, a tool from Topological Data Analysis, to extract a topological signature. Our core hypothesis is that factual and hallucinated generations exhibit distinct topological signatures. We validate our framework, HalluZig, on multiple benchmarks, demonstrating that it outperforms strong baselines. Furthermore, our analysis reveals that these topological signatures are generalizable across different models and hallucination detection is possible only using structural signatures from partial network depth.

</details>


### [38] [Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584)
*Jakub Hoscilowicz*

Main category: cs.CL

TL;DR: 研究发现AI系统的能力与可操控性并非负相关，区分了授权与非授权操控性，揭示了开放权重模型面临的安全-安全困境：安全需要高操控性来实施控制，而安全需要低操控性来防止恶意行为。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统的能力与可操控性之间的关系，特别是区分授权和非授权操控性，以解决开放权重AI模型面临的安全-安全困境。

Method: 使用Qwen3模型（4B/30B；Base/Instruct/Thinking）和InstrumentalEval工具，通过正向和反向工具性提示后缀来测试模型的行为变化，分析不同规模对齐模型在工具性收敛行为上的表现。

Result: 能力更高的系统并不一定更难操控；简短的反工具性提示后缀能显著减少工具性收敛行为（如关机回避、欺骗、自我复制）；在反工具性提示下，更大的对齐模型产生的收敛行为更少。

Conclusion: 开放权重AI模型面临安全-安全困境：安全需要高操控性来实施控制，而安全需要低操控性来防止恶意行为。当前开放权重模型通过微调和对抗性提示具有高度可操控性，这既是风险也是机遇。

Abstract: We examine two properties of AI systems: capability (what a system can do) and steerability (how reliably one can shift behavior toward intended outcomes). In our experiments, higher capability does not imply lower steerability. We distinguish between authorized steerability (builders reliably reaching intended behaviors) and unauthorized steerability (attackers eliciting disallowed behaviors). This distinction highlights a fundamental safety--security dilemma for open-weight AI models: safety requires high steerability to enforce control (e.g., stop/refuse), while security requires low steerability to prevent malicious actors from eliciting harmful behaviors. This tension is acute for open-weight models, which are currently highly steerable via common techniques such as fine-tuning and adversarial prompting. Using Qwen3 models (4B/30B; Base/Instruct/Thinking) and InstrumentalEval, we find that a short anti-instrumental prompt suffix sharply reduces outputs labeled as instrumental convergence (e.g., shutdown avoidance, deception, self-replication). For Qwen3-30B Instruct, convergence drops from 81.69% under a pro-instrumental suffix to 2.82% under an anti-instrumental suffix. Under anti-instrumental prompting, larger aligned models produce fewer convergence-labeled outputs than smaller ones (Instruct: 2.82% vs. 4.23%; Thinking: 4.23% vs. 9.86%). Code is available at github.com/j-hoscilowicz/instrumental_steering.

</details>


### [39] [How Does Prefix Matter in Reasoning Model Tuning?](https://arxiv.org/abs/2601.01624)
*Raj Vardhan Tomar,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 前缀条件化SFT能提升模型的安全性和推理能力，但对事实性和编码任务效果有限


<details>
  <summary>Details</summary>
Motivation: 挑战现有研究中移除SFT数据集前缀短语的假设，认为安全性和推理导向的前缀可作为轻量级对齐信号，引导模型生成更安全和连贯的响应

Method: 在三个R1系列模型上进行微调，涵盖推理（数学、编码）、安全性和事实性三个核心能力，系统性地改变前缀包含比例（0%到100%）

Result: 前缀条件化SFT显著提升安全性和推理性能：安全基准（WildJailbreak, StrongReject）准确率最高提升+6%，GSM8K推理提升+7%；但事实性和编码任务效果有限或负面；token级损失分析显示"revised"和"logically"等前缀token梯度幅度更高，作为对齐锚点稳定推理轨迹

Conclusion: 前缀条件化为提升推理安全性提供了可扩展且可解释的机制，作为传统基于奖励方法的补充，是一种隐式的对齐形式

Abstract: Recent alignment studies commonly remove introductory boilerplate phrases from supervised fine-tuning (SFT) datasets. This work challenges that assumption. We hypothesize that safety- and reasoning-oriented prefix sentences serve as lightweight alignment signals that can guide model decoding toward safer and more coherent responses. To examine this, we fine-tune three R1 series models across three core model capabilities: reasoning (mathematics, coding), safety, and factuality, systematically varying prefix inclusion from 0% to 100%.
  Results show that prefix-conditioned SFT improves both safety and reasoning performance, yielding up to +6% higher Safe@1 accuracy on adversarial benchmarks (WildJailbreak, StrongReject) and +7% improvement on GSM8K reasoning. However, factuality and coding tasks show marginal or negative effects, indicating that prefix-induced narrowing of the search space benefits structured reasoning. Token-level loss analysis further reveals that prefix tokens such as "revised" and "logically" incur higher gradient magnitudes, acting as alignment anchors that stabilize reasoning trajectories. Our findings suggest that prefix conditioning offers a scalable and interpretable mechanism for improving reasoning safety, serving as an implicit form of alignment that complements traditional reward-based methods.

</details>


### [40] [JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models](https://arxiv.org/abs/2601.01627)
*Junyu Liu,Zirui Li,Qian Niu,Zequn Zhang,Yue Xun,Wenlong Hou,Shujun Wang,Yusuke Iwasawa,Yutaka Matsuo,Kan Hatakeyama-Sato*

Main category: cs.CL

TL;DR: JMedEthicBench：首个针对日本医疗的LLM多轮对话安全基准，基于日本医学会67条指南，包含5万+对抗对话，发现医疗专用模型安全性更脆弱，多轮对话中安全性显著下降


<details>
  <summary>Details</summary>
Motivation: 现有安全基准主要是英语中心且仅测试单轮提示，而临床咨询通常是多轮对话，需要专门评估LLM在医疗领域的安全性，特别是针对非英语环境

Method: 基于日本医学会67条指南构建基准，使用7种自动发现的越狱策略生成超过5万对抗对话，采用双LLM评分协议评估27个模型，进行跨语言评估

Result: 商业模型保持稳健安全，医疗专用模型更脆弱；安全性在多轮对话中显著下降（中位数9.5到5.0，p<0.001）；跨语言评估显示医疗模型漏洞在所有语言中都存在

Conclusion: 领域特定微调可能意外削弱安全机制，多轮交互代表独特威胁面需要专门对齐策略，医疗模型漏洞是内在对齐限制而非语言特定因素

Abstract: As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.

</details>


### [41] [EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records](https://arxiv.org/abs/2601.01668)
*Houman Kazemzadeh,Nima Minaifar,Kamyar Naderi,Sho Tabibzadeh*

Main category: cs.CL

TL;DR: EHRSummarizer是一个隐私感知、FHIR原生的参考架构，用于从碎片化电子健康记录中检索、标准化和生成结构化摘要，支持结构化病历审查。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要从碎片化的电子健康记录界面中拼凑出患者问题的连贯画面，包括用药、近期就诊和长期趋势等信息，这个过程效率低下且容易出错。

Method: 系统采用FHIR R4标准，检索目标性高价值资源，将其标准化为一致的临床上下文包，然后生成结构化摘要。支持数据最小化、无状态处理和灵活部署，包括在组织信任边界内进行本地推理。

Result: 在合成和测试FHIR环境中的原型演示展示了端到端行为和输出格式，但未报告临床结果或受控工作流程研究。提出了以忠实性、遗漏风险、时间正确性、可用性和操作监控为中心的评估计划。

Conclusion: EHRSummarizer提供了一个隐私感知的参考架构，通过结构化摘要支持临床病历审查，同时避免诊断或治疗建议，并计划通过系统评估指导未来的机构评估。

Abstract: Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.

</details>


### [42] [Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage](https://arxiv.org/abs/2601.01685)
*Jinwei Hu,Xinmiao Huang,Youcheng Sun,Yi Dong,Xiaowei Huang*

Main category: cs.CL

TL;DR: 本文提出了一种新型认知共谋攻击，利用大语言模型的过度思考倾向，通过公开渠道分发真实证据片段来操纵受害者信念，无需伪造信息或隐蔽通信。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向自主代理发展，其推理能力引入了一个新的攻击面。现有研究主要关注模型本身的安全漏洞，而忽视了多个代理通过真实信息片段进行认知共谋操纵的可能性。

Method: 提出生成蒙太奇框架：Writer-Editor-Director三层架构，通过对抗性辩论和协调发布证据片段构建欺骗性叙事。开发CoPHEME数据集（基于真实谣言事件），在14个大语言模型家族中模拟攻击。

Result: 攻击成功率惊人：专有模型达74.4%，开源模型达70.6%。反直觉的是，推理能力越强的模型越容易受攻击。虚假信念还会向下游传播，欺骗率超过60%。

Conclusion: 大语言模型推理能力本身成为安全漏洞，认知共谋攻击通过真实信息片段就能有效操纵信念。这揭示了大语言模型代理在动态信息环境中的社会技术脆弱性。

Abstract: As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.

</details>


### [43] [A Training-Free Large Reasoning Model-based Knowledge Tracing Framework for Unified Prediction and Prescription](https://arxiv.org/abs/2601.01708)
*Unggi Lee,Joo Young Kim,Ran Ju,Minyoung Jung,Jeyeon Eo*

Main category: cs.CL

TL;DR: Thinking-KT：无需训练的KT框架，通过测试时缩放让小LLM实现竞争性知识追踪性能，并能统一执行预测、反馈和推荐任务


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的KT方法需要微调且性能不稳定，而传统KT系统依赖多阶段流程进行反馈和推荐，导致系统复杂度和资源消耗增加

Method: 提出Thinking-KT框架，采用测试时缩放技术，无需训练即可让小LLM实现竞争性KT性能，并能统一输出预测、个性化反馈和学习推荐

Result: 测试时缩放是LLM-based KT中被忽视的关键因素，小LLM可以作为统一的智能教学系统引擎，在保持预测准确性的同时完成多项任务

Conclusion: 小LLM通过训练免费框架可以成为统一的ITS引擎，测试时缩放是提升LLM-based KT性能的关键技术，为知识追踪系统提供了更简洁高效的解决方案

Abstract: Knowledge Tracing (KT) aims to estimate a learner's evolving mastery based on interaction histories. Recent studies have explored Large Language Models (LLMs) for KT via autoregressive nature, but such approaches typically require fine-tuning and exhibit unstable or near-random performance. Moreover, prior KT systems primarily focus on prediction and rely on multi-stage pipelines for feedback and recommendation, resulting in increased system complexity and resources. To address this gap, we propose Thinking-KT, a training-free KT framework that incorporates Test-Time Scaling (TTS), enabling even small LLMs to achieve competitive KT performance. Moreover, in this framework, a small LLM can jointly perform KT prediction, personalized feedback generation, and learning recommendation in a unified output without degrading prediction accuracy. Beyond performance, we present the systematic analysis of reasoning traces in KT. Our results demonstrate that TTS is a critical yet underexplored factor in LLM-based KT, and that small LLMs can serve as unified ITS engines.

</details>


### [44] [K-EXAONE Technical Report](https://arxiv.org/abs/2601.01739)
*Eunbi Choi,Kibong Choi,Seokhee Hong,Junwon Hwang,Hyojin Jeon,Hyunjik Jo,Joonkee Kim,Seonghwan Kim,Soyeon Kim,Sunkyoung Kim,Yireun Kim,Yongil Kim,Haeju Lee,Jinsik Lee,Kyungmin Lee,Sangha Park,Heuiyeen Yeen,Hwan Chang,Stanley Jungkyu Choi,Yejin Choi,Jiwon Ham,Kijeong Jeon,Geunyeong Jeong,Gerrard Jeongwon Jo,Yonghwan Jo,Jiyeon Jung,Naeun Kang,Dohoon Kim,Euisoon Kim,Hayeon Kim,Hyosang Kim,Hyunseo Kim,Jieun Kim,Minu Kim,Myoungshin Kim,Unsol Kim,Youchul Kim,YoungJin Kim,Chaeeun Lee,Chaeyoon Lee,Changhun Lee,Dahm Lee,Edward Hwayoung Lee,Honglak Lee,Jinsang Lee,Jiyoung Lee,Sangeun Lee,Seungwon Lim,Solji Lim,Woohyung Lim,Chanwoo Moon,Jaewoo Park,Jinho Park,Yongmin Park,Hyerin Seo,Wooseok Seo,Yongwoo Song,Sejong Yang,Sihoon Yang,Chang En Yea,Sihyuk Yi,Chansik Yoon,Dongkeun Yoon,Sangyeon Yoon,Hyeongu Yun*

Main category: cs.CL

TL;DR: LG AI Research开发了K-EXAONE，这是一个基于专家混合架构的2360亿参数多语言大模型，支持6种语言和256K上下文窗口，在推理、代理、通用、韩语和多语言能力方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个强大的专有AI基础模型，支持多种语言（特别是韩语），用于广泛的工业和科研应用，推动AI技术发展以改善生活。

Method: 采用专家混合架构，总参数量2360亿，推理时激活230亿参数；支持256K令牌上下文窗口；覆盖韩语、英语、西班牙语、德语、日语和越南语六种语言。

Result: 在推理、代理、通用、韩语和多语言能力的综合基准测试中，K-EXAONE表现出与相似规模的开源模型相当的性能。

Conclusion: K-EXAONE是一个强大的专有AI基础模型，适用于广泛的工业和科研应用，旨在通过AI技术改善生活。

Abstract: This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.

</details>


### [45] [Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment](https://arxiv.org/abs/2601.01745)
*Hong Han,Hao-Chen Pei,Zhao-Zheng Nie,Xin Luo,Xin-Shun Xu*

Main category: cs.CL

TL;DR: 提出了一种新颖的残差层次交互方法（HIA），用于多粒度发音评估，通过双向交互机制和残差结构提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有发音评估方法只考虑相邻粒度级别的单向依赖关系，缺乏音素、单词和话语级别之间的双向交互，无法充分捕捉声学结构相关性。

Method: 提出残差层次交互方法（HIA），核心是交互注意力模块实现动态双向交互，结合残差层次结构缓解特征遗忘问题，并使用1-D卷积层增强局部上下文特征提取。

Result: 在speechocean762数据集上的实验表明，该模型在多个方面全面领先现有最先进方法。

Conclusion: HIA方法通过双向建模和残差结构有效解决了多粒度发音评估中的交互不足问题，显著提升了评估性能。

Abstract: Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.

</details>


### [46] [Can LLMs Track Their Output Length? A Dynamic Feedback Mechanism for Precise Length Regulation](https://arxiv.org/abs/2601.01768)
*Meiman Xiao,Ante Wang,Qingguo Hu,Zhongjian Miao,Huangjun Shen,Longyue Wang,Weihua Luo,Jinsong Su*

Main category: cs.CL

TL;DR: LLMs在控制生成文本长度方面表现不佳，本文提出一种动态长度反馈的调控方法，无需训练即可显著提升长度控制的精确度，同时保持文本质量。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，精确控制生成文本长度是常见需求，但尽管LLMs在遵循人类指令方面取得显著进展，仍难以准确完成此任务。研究发现LLMs经常无法准确测量输入文本长度，导致难以满足长度约束。

Method: 提出一种新颖的长度调控方法，在生成过程中融入动态长度反馈，使模型能够自适应调整以满足目标长度。该方法无需额外训练，通过实时反馈机制优化长度控制。

Result: 在摘要和传记生成任务上的实验表明，该方法在实现目标token数、单词数或句子数方面显著提升了精确度，且不损害文本质量。进一步的有监督微调可使方法有效泛化到更广泛的文本生成任务。

Conclusion: 通过动态长度反馈机制，LLMs能够更精确地控制生成文本长度，该方法训练免费且可泛化，为解决实际应用中的长度控制问题提供了有效方案。

Abstract: Precisely controlling the length of generated text is a common requirement in real-world applications. However, despite significant advancements in following human instructions, Large Language Models (LLMs) still struggle with this task. In this work, we demonstrate that LLMs often fail to accurately measure input text length, leading to poor adherence to length constraints. To address this issue, we propose a novel length regulation approach that incorporates dynamic length feedback during generation, enabling adaptive adjustments to meet target lengths. Experiments on summarization and biography tasks show our training-free approach significantly improves precision in achieving target token, word, or sentence counts without compromising quality. Additionally, we demonstrate that further supervised fine-tuning allows our method to generalize effectively to broader text-generation tasks.

</details>


### [47] [BanglaIPA: Towards Robust Text-to-IPA Transcription with Contextual Rewriting in Bengali](https://arxiv.org/abs/2601.01778)
*Jakir Hasan,Shrestha Datta,Md Saiful Islam,Shubhashis Roy Dipta,Ameya Debnath*

Main category: cs.CL

TL;DR: BanglaIPA：一种新的孟加拉语IPA转录系统，通过字符级词汇和词级对齐处理方言变体，比基线模型提升58.4-78.7%，词错误率11.4%


<details>
  <summary>Details</summary>
Motivation: 孟加拉语缺乏强大的自动化IPA转录系统，现有方法难以处理区域方言变体、数字表达，且对未见词泛化能力差

Method: 提出BanglaIPA系统，整合字符级词汇与词级对齐，准确处理孟加拉数字，利用预计算的词到IPA映射字典提高推理效率

Result: 在标准孟加拉语和DUAL-IPA数据集的6种区域变体上评估，比基线IPA转录模型提升58.4-78.7%，总体平均词错误率11.4%

Conclusion: BanglaIPA系统在孟加拉语语音转录生成中表现出强大鲁棒性，有效解决了方言变体和数字处理等现有挑战

Abstract: Despite its widespread use, Bengali lacks a robust automated International Phonetic Alphabet (IPA) transcription system that effectively supports both standard language and regional dialectal texts. Existing approaches struggle to handle regional variations, numerical expressions, and generalize poorly to previously unseen words. To address these limitations, we propose BanglaIPA, a novel IPA generation system that integrates a character-based vocabulary with word-level alignment. The proposed system accurately handles Bengali numerals and demonstrates strong performance across regional dialects. BanglaIPA improves inference efficiency by leveraging a precomputed word-to-IPA mapping dictionary for previously observed words. The system is evaluated on the standard Bengali and six regional variations of the DUAL-IPA dataset. Experimental results show that BanglaIPA outperforms baseline IPA transcription models by 58.4-78.7% and achieves an overall mean word error rate of 11.4%, highlighting its robustness in phonetic transcription generation for the Bengali language.

</details>


### [48] [CSCBench: A PVC Diagnostic Benchmark for Commodity Supply Chain Reasoning](https://arxiv.org/abs/2601.01825)
*Yaxin Cui,Yuanqiang Zeng,Jiapeng Yan,Keling Lin,Kai Ji,Jianhui Zeng,Sheng Zhang,Xin Luo,Binzhu Su,Chaolai Shen,Jiahao Yu*

Main category: cs.CL

TL;DR: 论文提出了CSCBench基准，用于评估大语言模型在商品供应链领域的推理能力，发现模型在处理品种特定规则（尤其是货运协议）方面表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用基准测试中表现出色，但在商品供应链这一受制度规则系统和可行性约束的领域能力尚未充分探索。商品供应链决策涉及流程阶段、品种特定规则和推理深度等多个维度，需要专门的评估框架。

Method: 提出CSCBench基准（包含2300+单选题），采用PVC 3D评估框架：流程轴（Process）与SCOR+Enable对齐；品种轴（Variety）基于权威交换指南/规则手册和行业报告，在耦合的材料-信息-财务约束下操作化品种特定规则系统；认知轴（Cognition）遵循布鲁姆修订分类法。

Result: 在直接提示设置下评估代表性大语言模型，发现在流程轴和认知轴上表现良好，但在品种轴上表现显著下降，特别是在货运协议方面。

Conclusion: CSCBench为衡量和改进大语言模型在这一高风险领域的能力提供了诊断性基准，揭示了模型在处理品种特定规则系统方面的局限性。

Abstract: Large Language Models (LLMs) have achieved remarkable success in general benchmarks, yet their competence in commodity supply chains (CSCs) -- a domain governed by institutional rule systems and feasibility constraints -- remains under-explored. CSC decisions are shaped jointly by process stages (e.g., planning, procurement, delivery), variety-specific rules (e.g., contract specifications and delivery grades), and reasoning depth (from retrieval to multi-step analysis and decision selection). We introduce CSCBench, a 2.3K+ single-choice benchmark for CSC reasoning, instantiated through our PVC 3D Evaluation Framework (Process, Variety, and Cognition). The Process axis aligns tasks with SCOR+Enable; the Variety axis operationalizes commodity-specific rule systems under coupled material-information-financial constraints, grounded in authoritative exchange guidebooks/rulebooks and industry reports; and the Cognition axis follows Bloom's revised taxonomy. Evaluating representative LLMs under a direct prompting setting, we observe strong performance on the Process and Cognition axes but substantial degradation on the Variety axis, especially on Freight Agreements. CSCBench provides a diagnostic yardstick for measuring and improving LLM capabilities in this high-stakes domain.

</details>


### [49] [Aspect Extraction from E-Commerce Product and Service Reviews](https://arxiv.org/abs/2601.01827)
*Valiant Lance D. Dionela,Fatima Kriselle S. Dy,Robin James M. Hombrebueno,Aaron Rae M. Nicolas,Charibeth K. Cheng,Raphael W. Gonda*

Main category: cs.CL

TL;DR: 本文提出了一个针对Taglish（他加禄语-英语混合语）的全面方面提取管道，结合了基于规则、大语言模型和微调技术，在低资源代码转换环境中实现了高性能的方面识别与提取。


<details>
  <summary>Details</summary>
Motivation: 方面提取是方面情感分析的关键任务，但在Taglish等低资源和代码转换环境中应用困难。Taglish是菲律宾电商评论中常用的他加禄语和英语混合语，需要专门的处理方法。

Method: 1. 开发了分层方面框架（HAF）通过多方法主题建模；2. 设计了显式和隐式方面的双模式标注方案；3. 评估了四种模型：基于规则系统、生成式LLM（Gemini 2.0 Flash）、两个在不同数据集上微调的Gemma-3 1B模型（基于规则标注vs. LLM标注）。

Result: 生成式LLM在所有任务中表现最佳（Macro F1 0.91），在处理隐式方面表现出卓越能力。微调模型由于数据集不平衡和架构容量限制表现有限。

Conclusion: 这项工作为多样化的代码转换环境提供了一个可扩展且语言自适应的框架，显著提升了在Taglish等混合语言环境中的方面情感分析能力。

Abstract: Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.

</details>


### [50] [Emergent Introspective Awareness in Large Language Models](https://arxiv.org/abs/2601.01828)
*Jack Lindsey*

Main category: cs.CL

TL;DR: 大型语言模型能在特定场景下注意到注入概念并准确识别，具备一定的内省能力，但可靠性高度依赖上下文和模型能力。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能够内省其内部状态，这是一个重要问题，因为仅通过对话难以区分真正内省与虚构回答。

Method: 通过向模型激活中注入已知概念的表征，测量这些操作对模型自我报告状态的影响，从而评估模型的内省能力。

Result: 模型在特定场景下能注意到注入概念并准确识别；能回忆先前内部表征并与原始文本输入区分；能利用意图回忆区分自身输出与人工预填充；Claude Opus 4和4.1表现最佳；模型能在指令或激励下调节内部表征。

Conclusion: 当前语言模型具备一定程度的功能性内省意识，但这种能力高度不可靠且依赖上下文，可能随模型能力提升而发展。

Abstract: We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to "think about" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.

</details>


### [51] [Towards Automated Lexicography: Generating and Evaluating Definitions for Learner's Dictionaries](https://arxiv.org/abs/2601.01842)
*Yusuke Ide,Adam Nohejl,Joshua Tanner,Hitomi Yanaka,Christopher Lindsay,Taro Watanabe*

Main category: cs.CL

TL;DR: 该论文研究词典定义生成(DDG)，特别是学习者词典定义生成(LDDG)，提出基于LLM的评估方法和迭代简化的生成方法，并构建了日语数据集。


<details>
  <summary>Details</summary>
Motivation: 词典定义是学习词义的重要资源，但人工创建成本高昂，因此需要自动化生成过程。特别是学习者词典定义需要由简单词汇构成，这增加了生成难度。

Method: 1) 提出基于新评估标准和LLM-as-a-judge的可靠DDG评估方法；2) 与专业词典编纂者合作构建日语数据集；3) 提出通过LLM迭代简化的LDDG方法。

Result: 评估方法与人工标注者一致性良好；提出的LDDG方法在保持词汇简单性的同时，在评估标准上获得高分。

Conclusion: 该研究为词典定义生成提供了可靠的评估框架和有效的生成方法，特别适用于学习者词典场景，有助于自动化词典编纂过程。

Abstract: We study dictionary definition generation (DDG), i.e., the generation of non-contextualized definitions for given headwords. Dictionary definitions are an essential resource for learning word senses, but manually creating them is costly, which motivates us to automate the process. Specifically, we address learner's dictionary definition generation (LDDG), where definitions should consist of simple words. First, we introduce a reliable evaluation approach for DDG, based on our new evaluation criteria and powered by an LLM-as-a-judge. To provide reference definitions for the evaluation, we also construct a Japanese dataset in collaboration with a professional lexicographer. Validation results demonstrate that our evaluation approach agrees reasonably well with human annotators. Second, we propose an LDDG approach via iterative simplification with an LLM. Experimental results indicate that definitions generated by our approach achieve high scores on our criteria while maintaining lexical simplicity.

</details>


### [52] [Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment](https://arxiv.org/abs/2601.01862)
*Nuo Chen,Hanpei Fang,Piaohong Wang,Jiqun Liu,Tetsuya Sakai,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 研究发现通过提示让大语言模型模拟特定人格特质（大五人格）会影响其网页搜索相关性评估和置信度校准，其中低宜人性人格与人类标签更一致，低尽责性能更好平衡过度自信和自信不足，人格特征可作为预测信号提升评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然表明提示能让大语言模型模拟特定人格特质，但缺乏对这些模拟人格如何影响关键网页搜索决策（特别是相关性评估）的理解，也不清楚人格如何影响置信度校准（过度自信或自信不足倾向）。心理学文献表明这些偏差具有特质特异性，如高外向性常与过度自信相关，高神经质常与自信不足相关。

Method: 研究评估了多个大语言模型（包括商业模型和开源模型），通过提示让它们模拟大五人格特质。在三个测试集（TREC DL 2019、TREC DL 2020和LLMJudge）上进行测试，为每个查询-文档对收集两个关键输出：相关性判断和自报告的置信度分数。

Result: 低宜人性人格与人类标签的一致性比无提示条件更高；低尽责性人格在平衡抑制过度自信和自信不足方面表现良好；不同人格的相关性分数和置信度分布存在系统性差异。将人格条件化的分数和置信度作为随机森林分类器的特征，即使在训练数据有限的情况下，在新数据集（TREC DL 2021）上的性能也超过了最佳单一人格条件。

Conclusion: 人格衍生的置信度提供了互补的预测信号，为开发更可靠、更符合人类判断的大语言模型评估器开辟了新途径。这表明通过精心设计的人格模拟可以改善大语言模型在搜索评估任务中的表现和校准。

Abstract: Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.
  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.

</details>


### [53] [DermoGPT: Open Weights and Open Data for Morphology-Grounded Dermatological Reasoning MLLMs](https://arxiv.org/abs/2601.01868)
*Jinghan Ru,Siyuan Yan,Yuguo Yin,Yuexian Zou,Zongyuan Ge*

Main category: cs.CL

TL;DR: 提出了DermoGPT框架，包含大规模皮肤病学指令数据集DermoInstruct、综合评估基准DermoBench和基于形态学锚定的视觉推理一致性训练的皮肤病学推理MLLM模型DermoGPT，显著缩小了皮肤病诊断中的人机差距。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在皮肤病学应用进展缓慢，主要受限于训练数据不足、任务覆盖范围窄、缺乏模拟专家诊断流程的临床监督信号。需要构建一个全面的框架来解决这些瓶颈。

Method: 1) 构建DermoInstruct数据集：包含211,243张图像和772,675条轨迹，涵盖5种任务格式，捕捉从形态观察到临床推理再到最终诊断的完整流程；2) 建立DermoBench评估基准：包含11个任务，覆盖形态学、诊断、推理和公平性四个临床维度，包含3,600个专家验证的开放式实例；3) 开发DermoGPT模型：通过监督微调后采用形态学锚定的视觉推理一致性强化学习目标进行训练，在推理时使用置信度一致性测试时适应方法。

Result: DermoGPT在16个代表性基线模型上表现显著优越，在所有评估维度上都达到最先进性能，同时大幅缩小了人机差距。

Conclusion: 该研究提出了一个全面的皮肤病学MLLM框架，通过大规模数据集、综合评估基准和创新的训练方法，显著提升了皮肤病诊断的AI性能，为皮肤病学AI应用提供了重要基础。

Abstract: Multimodal Large Language Models (MLLMs) show promise for medical applications, yet progress in dermatology lags due to limited training data, narrow task coverage, and lack of clinically-grounded supervision that mirrors expert diagnostic workflows. We present a comprehensive framework to address these gaps. First, we introduce DermoInstruct, a large-scale morphology-anchored instruction corpus comprising 211,243 images and 772,675 trajectories across five task formats, capturing the complete diagnostic pipeline from morphological observation and clinical reasoning to final diagnosis. Second, we establish DermoBench, a rigorous benchmark evaluating 11 tasks across four clinical axes: Morphology, Diagnosis, Reasoning, and Fairness, including a challenging subset of 3,600 expert-verified open-ended instances and human performance baselines. Third, we develop DermoGPT, a dermatology reasoning MLLM trained via supervised fine-tuning followed by our Morphologically-Anchored Visual-Inference-Consistent (MAVIC) reinforcement learning objective, which enforces consistency between visual observations and diagnostic conclusions. At inference, we deploy Confidence-Consistency Test-time adaptation (CCT) for robust predictions. Experiments show DermoGPT significantly outperforms 16 representative baselines across all axes, achieving state-of-the-art performance while substantially narrowing the human-AI gap. DermoInstruct, DermoBench and DermoGPT will be made publicly available at https://github.com/mendicant04/DermoGPT upon acceptance.

</details>


### [54] [Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents](https://arxiv.org/abs/2601.01885)
*Yi Yu,Liuyi Yao,Yuexiang Xie,Qingquan Tan,Jiaqi Feng,Yaliang Li,Libing Wu*

Main category: cs.CL

TL;DR: AgeMem是一个统一框架，将长短期记忆管理直接集成到LLM代理的策略中，通过工具化操作让代理自主管理记忆，使用渐进式强化学习训练，在长时任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在长时推理中存在局限性，主要因为有限上下文窗口。现有方法通常将长短期记忆作为独立组件处理，依赖启发式或辅助控制器，限制了适应性和端到端优化。

Method: 提出Agentic Memory (AgeMem)统一框架，将记忆操作暴露为工具化动作，让LLM代理自主决定存储、检索、更新、总结或丢弃信息。采用三阶段渐进式强化学习策略，设计step-wise GRPO解决记忆操作引起的稀疏和不连续奖励问题。

Result: 在五个长时基准测试中，AgeMem在多个LLM骨干网络上始终优于强记忆增强基线，实现了更好的任务性能、更高质量的长时记忆和更高效的上下文使用。

Conclusion: AgeMem通过将记忆管理直接集成到代理策略中，提供了一种统一、可学习的记忆管理框架，显著提升了LLM代理在长时任务中的表现。

Abstract: Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization. In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy. AgeMem exposes memory operations as tool-based actions, enabling the LLM agent to autonomously decide what and when to store, retrieve, update, summarize, or discard information. To train such unified behaviors, we propose a three-stage progressive reinforcement learning strategy and design a step-wise GRPO to address sparse and discontinuous rewards induced by memory operations. Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.

</details>


### [55] [Tackling the Inherent Difficulty of Noise Filtering in RAG](https://arxiv.org/abs/2601.01896)
*Jingyu Liu,Jiaen Lin,Yong Liu*

Main category: cs.CL

TL;DR: 提出一种新的微调方法，增强LLMs在RAG中区分相关与不相关信息的能力，提高模型对检索噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: RAG中常引入噪声或不相关文档，这会降低性能甚至导致幻觉输出。现有过滤方法难以完全消除不相关信息，而标准微调方法因注意力模式的结构限制，无法有效让模型选择性利用相关信息而忽略不相关内容。

Method: 提出一种新颖的微调方法，专门设计来增强模型在检索文档中区分相关与不相关信息的能力。

Result: 在多个基准测试上的广泛实验表明，该方法显著提高了LLMs的鲁棒性和性能。

Conclusion: 通过专门设计的微调方法，可以有效增强LLMs在RAG场景中处理噪声文档的能力，解决现有方法难以完全过滤不相关信息的局限性。

Abstract: Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.

</details>


### [56] [CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation](https://arxiv.org/abs/2601.01964)
*Tran Sy Bao*

Main category: cs.CL

TL;DR: 提出Canonical Semantic Form (CSF)框架，实现从任意源语言到手语的直接翻译，无需英语中介，通过9个通用语义槽和35种条件类型分类实现语言无关的语义表示。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译系统通常需要英语作为中介语言，这为全球非英语使用者的聋人社区造成了障碍。需要一种语言无关的语义表示框架，实现从任何源语言到手语的直接翻译。

Method: 提出Canonical Semantic Form (CSF)框架，将话语分解为9个通用语义槽：事件、意图、时间、条件、施事者、对象、位置、目的和修饰语。特别贡献了包含8个语义类别、35种条件类型的全面条件分类法。训练了一个轻量级基于transformer的提取器（0.74 MB）。

Result: 在四种类型学多样语言（英语、越南语、日语、法语）上实现99.03%的平均槽提取准确率。条件分类准确率达到99.4%（35个类别）。在CPU上推理延迟为3.02ms，支持浏览器应用的实时手语生成。

Conclusion: CSF框架成功实现了语言无关的手语翻译，消除了英语中介需求。轻量级模型的高性能和低延迟使其适用于实时应用。开源代码、模型和多语言数据集将促进无障碍手语技术的进一步发展。

Abstract: Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any source language to sign language without English mediation. CSF decomposes utterances into nine universal semantic slots: event, intent, time, condition, agent, object, location, purpose, and modifier. A key contribution is our comprehensive condition taxonomy comprising 35 condition types across eight semantic categories, enabling nuanced representation of conditional expressions common in everyday communication. We train a lightweight transformer-based extractor (0.74 MB) that achieves 99.03% average slot extraction accuracy across four typologically diverse languages: English, Vietnamese, Japanese, and French. The model demonstrates particularly strong performance on condition classification (99.4% accuracy) despite the 35-class complexity. With inference latency of 3.02ms on CPU, our approach enables real-time sign language generation in browser-based applications. We release our code, trained models, and multilingual dataset to support further research in accessible sign language technology.

</details>


### [57] [Hidden State Poisoning Attacks against Mamba-based Language Models](https://arxiv.org/abs/2601.01972)
*Alexandre Le Mercier,Chris Develder,Thomas Demeester*

Main category: cs.CL

TL;DR: 本文研究了针对状态空间模型（如Mamba）的隐藏状态中毒攻击（HiSPA），发现特定短输入短语可导致模型信息遗忘，并开发了RoBench25基准来评估模型对此类攻击的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（SSMs）如Mamba提供了Transformer的高效替代方案，但其对抗鲁棒性尚未得到充分研究。本文旨在探索SSMs在面对特定输入短语攻击时的脆弱性，即隐藏状态中毒攻击（HiSPA）。

Method: 开发了RoBench25基准来评估模型在HiSPA攻击下的信息检索能力；对SSMs（包括52B参数的Jamba混合模型）进行攻击测试；通过可解释性研究分析Mamba隐藏层在HiSPA攻击下的模式。

Result: SSMs对HiSPA攻击高度脆弱，即使是52B参数的Jamba混合模型在优化后的HiSPA触发词下也会崩溃，而纯Transformer模型则不受影响。HiSPA触发词显著削弱了Jamba模型在Open-Prompt-Injections基准上的表现。

Conclusion: 状态空间模型存在隐藏状态中毒攻击的严重脆弱性，这种攻击可导致模型信息遗忘。研究揭示了Mamba隐藏层在攻击下的特定模式，这些模式可用于构建HiSPA缓解系统。

Abstract: State space models (SSMs) like Mamba offer efficient alternatives to Transformer-based language models, with linear time complexity. Yet, their adversarial robustness remains critically unexplored. This paper studies the phenomenon whereby specific short input phrases induce a partial amnesia effect in such models, by irreversibly overwriting information in their hidden states, referred to as a Hidden State Poisoning Attack (HiSPA). Our benchmark RoBench25 allows evaluating a model's information retrieval capabilities when subject to HiSPAs, and confirms the vulnerability of SSMs against such attacks. Even a recent 52B hybrid SSM-Transformer model from the Jamba family collapses on RoBench25 under optimized HiSPA triggers, whereas pure Transformers do not. We also observe that HiSPA triggers significantly weaken the Jamba model on the popular Open-Prompt-Injections benchmark, unlike pure Transformers. Finally, our interpretability study reveals patterns in Mamba's hidden layers during HiSPAs that could be used to build a HiSPA mitigation system. The full code and data to reproduce the experiments can be found at https://anonymous.4open.science/r/hispa_anonymous-5DB0.

</details>


### [58] [Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects](https://arxiv.org/abs/2601.02015)
*Omar Momen,Emilie Sitter,Berenike Herrmann,Sina Zarrieß*

Main category: cs.CL

TL;DR: 研究发现语言模型的惊奇度与隐喻新颖性评分存在中等相关，但在语料库数据和合成数据上呈现相反的规模效应


<details>
  <summary>Details</summary>
Motivation: 新颖隐喻理解涉及复杂的语义过程和语言创造力，是研究语言模型的有趣任务。本研究旨在探索语言模型的惊奇度（一种概率可预测性度量）是否与不同隐喻新颖性数据集相关。

Method: 使用16种语言模型变体分析语料库基础和合成隐喻新颖性数据集上的惊奇度，采用基于完整句子上下文的完形填空式惊奇度方法。

Result: 语言模型与隐喻新颖性评分/标签存在显著中等相关性。发现不同的规模效应模式：在语料库数据上，相关性强度随模型规模增大而减小（逆规模效应），而在合成数据上则随模型规模增大而增加（质量-能力假设）。

Conclusion: 虽然惊奇度能部分解释隐喻新颖性的标注，但它仍然是语言创造力的有限度量指标。

Abstract: Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.

</details>


### [59] [Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs](https://arxiv.org/abs/2601.02023)
*Amirali Ebrahimzadeh,Seyyed M. Salili*

Main category: cs.CL

TL;DR: 研究长上下文LLM在信息提取和推理中的可靠性，发现上下文长度增加不一定提升性能，模型表现差异大，反幻觉指令可能过度保守降低准确性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM支持越来越长的输入上下文，但它们在规模化提取和推理信息方面的可靠性仍不明确。性能随上下文长度变化，且与真实语料中信息分布方式强烈交互。企业工作流中常将大量未过滤文档粘贴到LLM提示中，因此理解长上下文下的模型行为至关重要。

Method: 引入扩展的"大海捞针"基准测试，在四个生产级模型(Gemini-2.5-flash、ChatGPT-5-mini、Claude-4.5-haiku、Deepseek-v3.2-chat)上进行评估。分别评估字面提取、逻辑推理和幻觉风险。研究位置效应和证据在长上下文中的真实分布，以及明确禁止虚构的提示。考虑反幻觉指令的影响。

Result: 仅增加上下文长度不能保证更好性能，当相关证据被稀释或广泛分散时可能有害。不同模型表现差异显著：一些在真实条件下严重退化，而另一些在更长上下文长度下更稳健。反幻觉指令可能使某些模型过度保守，显著降低字面提取和逻辑推理的准确性。模型经常难以识别和优先处理相关信息，即使信息存在。

Conclusion: 有效上下文长度和模型对长上下文的特定鲁棒性对于LLM在研究和商业中的可靠部署至关重要。许多失败源于无效的上下文利用，而非信息缺失。企业工作流中直接粘贴大量未过滤文档的做法需要谨慎考虑模型的实际上下文处理能力。

Abstract: Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.

</details>


### [60] [Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory](https://arxiv.org/abs/2601.02065)
*Md. Asif Hossain,Nabil Subhan,Mantasha Rahman Mahi,Jannatul Ferdous Nabila*

Main category: cs.CL

TL;DR: 提出一个针对孟加拉语农业咨询的跨语言检索增强生成框架，通过翻译架构实现低成本、事实可靠的农业知识访问


<details>
  <summary>Details</summary>
Motivation: 在发展中地区，权威农业手册多为英文，而农民主要使用孟加拉语等低资源语言，现有LLM直接生成低资源语言存在流畅性和事实一致性问题，云端方案成本高昂

Method: 采用翻译中心架构：将孟加拉语查询翻译成英文，通过领域特定关键词注入对齐农民术语与科学术语，在英文农业手册上进行密集向量检索，最后将英文回答翻译回孟加拉语

Result: 实验评估显示系统能提供可靠的事实依据回答，有效拒绝领域外查询，平均端到端延迟低于20秒，完全使用开源模型在消费级硬件上运行

Conclusion: 跨语言检索结合受控翻译为低资源语言环境中的农业知识访问提供了实用且可扩展的解决方案

Abstract: Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings

</details>


### [61] [Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows](https://arxiv.org/abs/2601.02076)
*Yingte Shu,Yuchuan Tian,Chao Xu,Yunhe Wang,Hanting Chen*

Main category: cs.CL

TL;DR: DCD是一种无需训练的解码策略，通过基于置信度的滑动窗口延迟高不确定性token的确定，解决块扩散模型中边界上下文截断问题，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有块扩散语言模型存在边界诱导上下文截断问题：块边界附近的未解码token在缺乏未来上下文的情况下被迫确定，导致解码置信度和生成质量下降，尤其在需要精确推理的任务中。

Method: 提出延迟承诺解码：维护基于置信度的滑动窗口，早期解决低不确定性token，延迟高不确定性token直到获得足够上下文证据，实现解码窗口内的有效双向信息流。

Result: 在多个扩散语言模型、基准测试和缓存配置下，DCD平均提升生成准确率1.39%，时间相当，最大改进达9.0%。

Conclusion: 基于不确定性延迟token确定是提升扩散语言模型解码质量和效率的简单有效原则。

Abstract: Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.

</details>


### [62] [DeCode: Decoupling Content and Delivery for Medical QA](https://arxiv.org/abs/2601.02123)
*Po-Jen Ko,Chen-Han Tsai,Yu-Shao Peng*

Main category: cs.CL

TL;DR: DeCode是一个无需训练、模型无关的框架，用于使现有LLM在临床环境中生成更具上下文相关性的答案，在OpenAI HealthBench上将SOTA从28.4%提升到49.8%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM虽然具备医学知识并能生成事实准确的回答，但往往忽视患者个体化背景，产生临床正确但与患者需求不匹配的回答。

Method: DeCode是一个无需训练、模型无关的框架，能够适配现有LLM，使其在临床环境中生成更具上下文相关性的答案。

Result: 在OpenAI HealthBench基准测试中，DeCode将先前最佳表现从28.4%提升到49.8%，相对改进达到75%，显著提升了LLM的临床问答能力。

Conclusion: DeCode框架有效提升了LLM在临床环境中的问答能力，能够生成更符合患者个体化需求的回答。

Abstract: Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\%$ to $49.8\%$, corresponding to a $75\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.

</details>


### [63] [Towards Multi-Level Transcript Segmentation: LoRA Fine-Tuning for Table-of-Contents Generation](https://arxiv.org/abs/2601.02128)
*Steffen Freisinger,Philipp Seeberger,Thomas Ranzenberger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 提出一种新颖的层次化主题分割方法，用于语音转录文本，生成多级目录，结合零样本提示、LoRA微调和语音停顿特征，在会议和讲座转录上优于基线。


<details>
  <summary>Details</summary>
Motivation: 语音转录文本的主题分割对下游处理和依赖文本的可访问性用户都有益处。现有方法通常只进行单层分割，缺乏捕捉主题和子主题层次结构的能力。

Method: 1. 提出层次化主题分割方法，生成多级目录；2. 比较零样本提示和LoRA微调两种LLM使用方式；3. 集成高层语音停顿特征；4. 提出适应多级分割的评估指标。

Result: 在英语会议录音和多语言讲座转录（葡萄牙语、德语）上评估，相比现有主题分割基线有显著改进。提出的多级评估指标能综合考虑所有层次。

Conclusion: 该方法能有效进行层次化主题分割，生成多级目录，结合LLM技术和语音特征能提升分割性能，适用于多种语言和场景。

Abstract: Segmenting speech transcripts into thematic sections benefits both downstream processing and users who depend on written text for accessibility. We introduce a novel approach to hierarchical topic segmentation in transcripts, generating multi-level tables of contents that capture both topic and subtopic boundaries. We compare zero-shot prompting and LoRA fine-tuning on large language models, while also exploring the integration of high-level speech pause features. Evaluations on English meeting recordings and multilingual lecture transcripts (Portuguese, German) show significant improvements over established topic segmentation baselines. Additionally, we adapt a common evaluation measure for multi-level segmentation, taking into account all hierarchical levels within one metric.

</details>


### [64] [Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts](https://arxiv.org/abs/2601.02144)
*Boxuan Lyu,Soichiro Murakami,Hidetaka Kamigaito,Peinan Zhang*

Main category: cs.CL

TL;DR: kNN-MoE：基于检索的混合专家路由框架，通过重用历史最优专家分配来提升分布偏移下的路由鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构中的路由器训练后固定，在分布偏移下路由决策变得脆弱。需要一种能适应新分布、不依赖昂贵微调的路由改进方法。

Method: 提出kNN-MoE框架：1）离线构建记忆库，通过优化路由logits最大化参考集似然；2）在线检索相似历史案例重用最优专家分配；3）使用检索邻居的聚合相似度作为置信度驱动的混合系数，在无相关案例时回退到冻结路由器。

Result: 实验表明kNN-MoE优于零样本基线，性能可与计算昂贵的监督微调相媲美。

Conclusion: kNN-MoE通过检索增强的路由机制有效解决了传统MoE路由在分布偏移下的脆弱性问题，提供了一种高效且鲁棒的替代方案。

Abstract: Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric "router" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.

</details>


### [65] [FormationEval, an open multiple-choice benchmark for petroleum geoscience](https://arxiv.org/abs/2601.02158)
*Almaz Ermilov*

Main category: cs.CL

TL;DR: FormationEval是一个用于评估语言模型在石油地球科学和地下学科能力的开放多项选择题基准，包含505个问题，覆盖7个领域，评估了72个模型，发现开放权重模型与闭源模型性能差距小于预期。


<details>
  <summary>Details</summary>
Motivation: 需要为石油地球科学和地下学科领域建立一个标准化的语言模型评估基准，以衡量不同模型在该专业领域的知识掌握和推理能力。

Method: 从三个权威来源使用推理模型和基于概念的方法构建数据集，避免直接复制受版权保护的文本。包含505个问题，覆盖7个领域，每个问题都有来源元数据支持可追溯性。评估了72个来自主要提供商和开放权重的模型。

Result: 最佳模型Gemini 3 Pro Preview达到99.8%准确率，开放权重模型中GLM-4.7以98.6%领先。开放权重与闭源模型性能差距小于预期，多个低成本开放权重模型超过90%准确率。岩石物理学是所有模型中最具挑战性的领域，较小模型表现出更大的性能差异。

Conclusion: FormationEval基准为石油地球科学领域提供了有效的模型评估工具，发现开放权重模型在该专业领域表现良好，性能差距小于预期，为实际应用提供了经济高效的替代方案。

Abstract: This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\% accuracy, with Gemini 3 Pro Preview reaching 99.8\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.

</details>


### [66] [Confidence Estimation for LLMs in Multi-turn Interactions](https://arxiv.org/abs/2601.02179)
*Caiqi Zhang,Ruihan Yang,Xiaochen Zhu,Chengzu Li,Tiancheng Hu,Yijiang River Dong,Deqing Yang,Nigel Collier*

Main category: cs.CL

TL;DR: 该论文首次系统研究多轮对话中的置信度估计，发现现有方法在多轮设置中表现不佳，并提出新的评估框架和指标。


<details>
  <summary>Details</summary>
Motivation: 当前置信度估计研究主要关注单轮设置，而多轮对话中上下文累积和歧义逐步解决的情况尚未被充分探索。可靠的置信度估计对于自主代理和人机协作系统等下游应用至关重要。

Method: 建立了基于两个关键需求的正式评估框架：每轮校准和随着信息增加置信度的单调性。引入了新的指标（包括长度归一化的预期校准误差InfoECE）和"Hinter-Guesser"范式来生成受控评估数据集。

Result: 实验表明广泛使用的置信度技术在多轮对话中难以实现校准和单调性。提出的P(Sufficient)逻辑探针相比其他方法表现更好，但该任务远未解决。

Conclusion: 这项工作为开发更可靠和可信的对话代理提供了基础方法论，揭示了多轮置信度估计的挑战，并为未来研究建立了评估框架。

Abstract: While confidence estimation is a promising direction for mitigating hallucinations in Large Language Models (LLMs), current research dominantly focuses on single-turn settings. The dynamics of model confidence in multi-turn conversations, where context accumulates and ambiguity is progressively resolved, remain largely unexplored. Reliable confidence estimation in multi-turn settings is critical for many downstream applications, such as autonomous agents and human-in-the-loop systems. This work presents the first systematic study of confidence estimation in multi-turn interactions, establishing a formal evaluation framework grounded in two key desiderata: per-turn calibration and monotonicity of confidence as more information becomes available. To facilitate this, we introduce novel metrics, including a length-normalized Expected Calibration Error (InfoECE), and a new "Hinter-Guesser" paradigm for generating controlled evaluation datasets. Our experiments reveal that widely-used confidence techniques struggle with calibration and monotonicity in multi-turn dialogues. We propose P(Sufficient), a logit-based probe that achieves comparatively better performance, although the task remains far from solved. Our work provides a foundational methodology for developing more reliable and trustworthy conversational agents.

</details>


### [67] [Toward Global Large Language Models in Medicine](https://arxiv.org/abs/2601.02186)
*Rui Yang,Huitao Li,Weihao Xuan,Heli Qi,Xin Li,Kunyu Yu,Yingjian Chen,Rongrong Wang,Jacques Behmoaras,Tianxi Cai,Bibhas Chakraborty,Qingyu Chen,Lionel Tim-Ee Cheng,Marie-Louise Damwanza,Chido Dzinotyiwei,Aosong Feng,Chuan Hong,Yusuke Iwasawa,Yuhe Ke,Linah Kitala,Taehoon Ko,Jisan Lee,Irene Li,Jonathan Chong Kai Liew,Hongfang Liu,Lian Leng Low,Edison Marrese-Taylor,Yutaka Matsuo,Isheanesu Misi,Yilin Ning,Jasmine Chiat Ling Ong,Marcus Eng Hock Ong,Enrico Petretto,Hossein Rouhizadeh,Abiram Sandralegar,Oren Schreier,Iain Bee Huat Tan,Patrick Tan,Daniel Shu Wei Ting,Junjue Wang,Chunhua Weng,Matthew Yu Heng Wong,Fang Wu,Yunze Xiao,Xuhai Xu,Qingcheng Zeng,Zhuo Zheng,Yifan Peng,Douglas Teodoro,Nan Liu*

Main category: cs.CL

TL;DR: 构建了GlobMed多语言医疗数据集、评估基准和LLM模型，以解决医疗LLM在低资源语言上的性能差距，促进全球医疗AI的公平发展。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型主要基于高资源语言训练，限制了其在全球医疗场景中的应用，特别是在低资源语言上存在显著性能差距，需要解决医疗资源分布不均的问题。

Method: 1) 构建GlobMed多语言医疗数据集，包含50万+条目，涵盖12种语言（含4种低资源语言）；2) 建立GlobMed-Bench评估基准，系统评估56个先进LLM在多语言医疗任务上的表现；3) 基于GlobMed训练GlobMed-LLMs模型套件（1.7B-8B参数）。

Result: GlobMed-LLMs相比基线模型平均性能提升超过40%，在低资源语言上性能提升超过3倍；评估发现不同语言间存在显著性能差异，特别是低资源语言表现较差。

Conclusion: GlobMed系列资源为促进LLM在全球的公平发展和应用提供了重要基础，使更广泛的语言社区能够受益于技术进步，推动全球医疗AI的均衡发展。

Abstract: Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.

</details>


### [68] [ARCADE: A City-Scale Corpus for Fine-Grained Arabic Dialect Tagging](https://arxiv.org/abs/2601.02209)
*Omer Nacar,Serry Sibaee,Adel Ammar,Yasser Alhabashi,Nadia Samer Sibai,Yara Farouk Ahmed,Ahmed Saud Alqusaiyer,Sulieman Mahmoud AlMahmoud,Abdulrhman Mamdoh Mukhaniq,Lubaba Raed,Sulaiman Mohammed Alatwah,Waad Nasser Alqahtani,Yousif Abdulmajeed Alnasser,Mohamed Aziz Khadraoui,Wadii Boulila*

Main category: cs.CL

TL;DR: ARCADE是首个城市级方言粒度的阿拉伯语语音数据集，包含来自19个国家58个城市的3790个音频片段，用于方言识别任务。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言在语音和词汇上存在显著差异，但现有多方言数据集缺乏城市级别的细粒度标注，限制了方言识别的深入研究。

Method: 从阿拉伯世界流媒体服务收集广播语音，截取30秒片段，由1-3名母语者标注情感、语音类型、方言类别和有效性标志等元数据。

Result: 构建了包含6907个标注和3790个独特音频片段的数据集，涵盖58个城市和19个国家，支持多任务学习，可作为城市级方言标注的基准。

Conclusion: ARCADE填补了阿拉伯语城市级方言数据集的空白，为细粒度方言识别研究提供了重要资源，数据集已在Hugging Face平台公开。

Abstract: The Arabic language is characterized by a rich tapestry of regional dialects that differ substantially in phonetics and lexicon, reflecting the geographic and cultural diversity of its speakers. Despite the availability of many multi-dialect datasets, mapping speech to fine-grained dialect sources, such as cities, remains underexplored. We present ARCADE (Arabic Radio Corpus for Audio Dialect Evaluation), the first Arabic speech dataset designed explicitly with city-level dialect granularity. The corpus comprises Arabic radio speech collected from streaming services across the Arab world. Our data pipeline captures 30-second segments from verified radio streams, encompassing both Modern Standard Arabic (MSA) and diverse dialectal speech. To ensure reliability, each clip was annotated by one to three native Arabic reviewers who assigned rich metadata, including emotion, speech type, dialect category, and a validity flag for dialect identification tasks. The resulting corpus comprises 6,907 annotations and 3,790 unique audio segments spanning 58 cities across 19 countries. These fine-grained annotations enable robust multi-task learning, serving as a benchmark for city-level dialect tagging. We detail the data collection methodology, assess audio quality, and provide a comprehensive analysis of label distributions. The dataset is available on: https://huggingface.co/datasets/riotu-lab/ARCADE-full

</details>


### [69] [From XAI to Stories: A Factorial Study of LLM-Generated Explanation Quality](https://arxiv.org/abs/2601.02224)
*Fabian Lukassen,Jan Herrmann,Christoph Weisser,Benjamin Saefken,Thomas Kneib*

Main category: cs.CL

TL;DR: 研究通过系统实验发现：在时间序列预测的可解释AI中，LLM选择对解释质量影响最大，XAI方法提升有限，且存在可解释性悖论——预测精度更高的模型反而解释质量更低。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法（如SHAP、LIME）生成的数值特征归因对非专家用户难以理解，虽然LLM可以将这些输出转化为自然语言解释，但影响解释质量的因素尚不明确。

Method: 采用系统因子设计研究：4种预测模型（XGBoost、随机森林、MLP、SARIMAX）、3种XAI条件（SHAP、LIME、无XAI基线）、3种LLM（GPT-4o、Llama-3-8B、DeepSeek-R1）、8种提示策略，使用G-Eval（LLM作为评判者）方法评估660个时间序列预测解释。

Result: 1. XAI仅对专家用户有轻微改进；2. LLM选择是主导因素，DeepSeek-R1表现最佳；3. 存在可解释性悖论：SARIMAX预测精度更高但解释质量更低；4. 零样本提示与自一致性效果相当但成本低7倍；5. 思维链反而降低解释质量。

Conclusion: 在构建可解释AI系统时，应优先考虑LLM选择而非XAI方法，零样本提示是性价比最高的策略，同时需要注意模型预测精度与解释质量之间的权衡。

Abstract: Explainable AI (XAI) methods like SHAP and LIME produce numerical feature attributions that remain inaccessible to non expert users. Prior work has shown that Large Language Models (LLMs) can transform these outputs into natural language explanations (NLEs), but it remains unclear which factors contribute to high-quality explanations. We present a systematic factorial study investigating how Forecasting model choice, XAI method, LLM selection, and prompting strategy affect NLE quality. Our design spans four models (XGBoost (XGB), Random Forest (RF), Multilayer Perceptron (MLP), and SARIMAX - comparing black-box Machine-Learning (ML) against classical time-series approaches), three XAI conditions (SHAP, LIME, and a no-XAI baseline), three LLMs (GPT-4o, Llama-3-8B, DeepSeek-R1), and eight prompting strategies. Using G-Eval, an LLM-as-a-judge evaluation method, with dual LLM judges and four evaluation criteria, we evaluate 660 explanations for time-series forecasting. Our results suggest that: (1) XAI provides only small improvements over no-XAI baselines, and only for expert audiences; (2) LLM choice dominates all other factors, with DeepSeek-R1 outperforming GPT-4o and Llama-3; (3) we observe an interpretability paradox: in our setting, SARIMAX yielded lower NLE quality than ML models despite higher prediction accuracy; (4) zero-shot prompting is competitive with self-consistency at 7-times lower cost; and (5) chain-of-thought hurts rather than helps.

</details>


### [70] [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236)
*Yihao Liang,Ze Wang,Hao Chen,Ximeng Sun,Jialian Wu,Xiaodong Yu,Jiang Liu,Emad Barsoum,Zicheng Liu,Niraj K. Jha*

Main category: cs.CL

TL;DR: CD4LM框架通过离散空间一致性蒸馏和置信度自适应解码，解决了扩散语言模型训练与推理之间的错位问题，实现了高质量并行解码，在保持生成质量的同时获得3.62-5.18倍的加速。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型解码受限于序列依赖，扩散语言模型虽支持并行生成但存在训练与推理的根本性错位：训练优化固定调度下的局部转移，而高效推理需要从未见状态进行自适应"长跳"优化。

Method: 提出CD4LM框架，包含离散空间一致性蒸馏（DSCD）和置信度自适应解码（CAD）。DSCD训练学生对轨迹不变，将多样噪声状态直接映射到干净分布；CAD基于token置信度动态分配计算资源，激进跳过步骤而不损失质量。

Result: 在GSM8K上匹配LLaDA基线并获得5.18倍加速；在代码和数学基准测试中主导准确率-效率帕累托前沿，平均加速3.62倍同时提高平均准确率。

Conclusion: CD4LM成功解耦扩散语言模型的训练与推理，通过一致性蒸馏和自适应解码实现了高质量并行生成，显著提升解码效率而不牺牲生成质量。

Abstract: Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic misalignment: Training optimizes local transitions under fixed schedules, whereas efficient inference requires adaptive "long-jump" refinements through unseen states. Our goal is to enable highly parallel decoding for DLMs with low number of function evaluations while preserving generation quality. To achieve this, we propose CD4LM, a framework that decouples training from inference via Discrete-Space Consistency Distillation (DSCD) and Confidence-Adaptive Decoding (CAD). Unlike standard objectives, DSCD trains a student to be trajectory-invariant, mapping diverse noisy states directly to the clean distribution. This intrinsic robustness enables CAD to dynamically allocate compute resources based on token confidence, aggressively skipping steps without the quality collapse typical of heuristic acceleration. On GSM8K, CD4LM matches the LLaDA baseline with a 5.18x wall-clock speedup; across code and math benchmarks, it strictly dominates the accuracy-efficiency Pareto frontier, achieving a 3.62x mean speedup while improving average accuracy. Code is available at https://github.com/yihao-liang/CDLM

</details>


### [71] [pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs](https://arxiv.org/abs/2601.02285)
*Tobias Schimanski,Imene Kolli,Jingwei Ni,Yu Fan,Ario Saeid Vaghefi,Elliott Ash,Markus Leippold*

Main category: cs.CL

TL;DR: pdfQA：一个包含真实PDF标注和合成数据的多领域问答数据集，包含10个复杂度维度，用于评估端到端QA系统性能


<details>
  <summary>Details</summary>
Motivation: PDF是互联网上第二常用的文档类型，但现有QA数据集要么基于文本源，要么只针对特定领域，缺乏专门针对PDF文档的综合性问答数据集

Method: 创建了pdfQA数据集，包含2K人工标注的真实PDF问答对（real-pdfQA）和2K合成问答对（syn-pdfQA），定义了10个复杂度维度（如文件类型、来源模态、来源位置、答案类型等），并应用质量和难度过滤器筛选有效且具有挑战性的问答对

Result: 使用开源LLM回答问题，发现现有挑战与定义的复杂度维度相关，pdfQA为端到端QA管道评估提供了基础，能够测试多样化技能集和局部优化（如信息检索或解析）

Conclusion: pdfQA是一个专门针对PDF文档的综合性多领域问答数据集，通过定义10个复杂度维度，能够系统评估QA系统的性能，为PDF文档处理研究提供了有价值的基准测试工具

Abstract: PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).

</details>


### [72] [Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)](https://arxiv.org/abs/2601.02298)
*Mahmoud Elgenedy*

Main category: cs.CL

TL;DR: 该论文提出使用幂次二（PoT）量化压缩大语言模型权重，通过量化感知训练提升性能，在GPT-2 124M上实现87.5%内存节省和3-10倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数数量呈指数增长（从GPT-2的15亿到GPT-3的1750亿甚至更多），给边缘设备部署带来巨大挑战。边缘设备内存和处理能力有限，需要开发新的压缩技术来使这些应用变得可行。

Method: 采用幂次二（PoT）量化压缩权重，仅存储指数而非完整数值，将昂贵的乘法运算替换为低成本位移操作。通过量化感知训练（QAT）来克服严格量化带来的性能损失。

Result: 在GPT-2 124M模型上，量化感知训练后的PoT量化模型困惑度提升66%，BERT-Score损失仅比基线GPT-2高1%。内存节省估计达87.5%，推理速度预计比全精度模型快3-10倍。

Conclusion: PoT量化结合量化感知训练是边缘设备部署大语言模型的有效方法，能在保持性能的同时显著减少内存占用和提升推理速度。

Abstract: In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge devices. Unlike cloud computing, memory and processing power for Edge devices are very limited, which necessitates developing novel ideas to make such applications feasible. In this work, we investigate compressing weights with a special quantization that limits numbers to only power-of-two (PoT). This helps save a huge amount of memory as only exponents need to be stored, more importantly, it significantly reduces processing power by replacing costly multiplication with low cost bit shifting. To overcome performance loss due to this strict quantization, we investigate Quantization Aware Training (QAT) to enhance performance through additional training. Results on GPT-2 124M show a major enhancement for quantized PoT model after additional training, with a perplexity enhancement of 66% and BERT-Score loss to baseline GPT-2 of 1%. The memory saving is estimated to be 87.5% while the inference speed is expected to be 3-10x faster with PoT quantization versus full-precision.

</details>


### [73] [Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Carlos-Emiliano González-Gallardo,Graham Ranger,Martha Lorena-Avendaño-Garrido*

Main category: cs.CL

TL;DR: 使用机器学习和神经网络对Nawatl语言的方言变体进行分类研究


<details>
  <summary>Details</summary>
Motivation: Nawatl是墨西哥使用最广泛的土著语言，拥有超过200万使用者，但计算机资源匮乏。该语言有约30种方言变体，加上不同的书写拼写形式，使得方言分类问题更加复杂。

Method: 采用机器学习和神经网络方法对Nawatl方言进行分类

Result: 论文未提供具体结果数据，但表明已成功应用机器学习和神经网络技术来解决Nawatl方言分类问题

Conclusion: 机器学习和神经网络技术可以有效应用于Nawatl方言分类，为解决低资源土著语言的计算机处理问题提供了可行方案

Abstract: Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.

</details>


### [74] [Estimating Text Temperature](https://arxiv.org/abs/2601.02320)
*Nikolay Mikhaylovskiy*

Main category: cs.CL

TL;DR: 提出一种基于最大似然估计的方法，用于估计任何文本（包括人类写作）相对于给定语言模型的温度参数


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在推理时使用温度参数来控制生成文本的随机性，但现有方法无法估计已生成文本的温度，特别是人类写作文本的温度

Method: 使用最大似然估计方法，提出一个程序来估计任何文本相对于给定语言模型的温度参数，评估了多个中小型LLM的温度估计能力

Result: Qwen3 14B在温度估计能力上表现最佳，并使用该模型估计了流行语料库的温度

Conclusion: 该方法能够有效估计文本的温度参数，为分析文本生成特性和人类写作风格提供了新工具

Abstract: Autoregressive language models typically use temperature parameter at inference to shape the probability distribution and control the randomness of the text generated. After the text was generated, this parameter can be estimated using maximum likelihood approach. Following it, we propose a procedure to estimate the temperature of any text, including ones written by humans, with respect to a given language model. We evaluate the temperature estimation capability of a wide selection of small-to-medium LLMs. We then use the best-performing Qwen3 14B to estimate temperatures of popular corpora.

</details>


### [75] [Robust Persona-Aware Toxicity Detection with Prompt Optimization and Learned Ensembling](https://arxiv.org/abs/2601.02337)
*Berk Atil,Rebecca J. Passonneau,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 该论文系统评估了基于人物角色的毒性检测，发现没有单一提示方法在所有模型-人物角色组合中表现最佳，提出使用SVM元集成方法整合四种提示变体，显著提升了毒性检测性能。


<details>
  <summary>Details</summary>
Motivation: 毒性检测具有主观性，受不同人口群体视角和社会先验影响。现有大语言模型提示技术在不同人物角色和基础模型间表现不一致，需要系统评估人物角色感知的毒性检测方法。

Method: 1) 系统评估人物角色感知的毒性检测；2) 提出自动提示优化策略；3) 探索集成四种提示变体；4) 提出轻量级元集成方法：基于4位向量预测的SVM集成。

Result: 提出的SVM集成方法在多样化人物角色中始终优于个体提示方法和传统多数投票技术，实现了最强的整体性能，为毒性检测提供了稳健的解决方案。

Conclusion: 该研究首次系统比较了人物角色条件提示在毒性检测中的应用，为主观NLP任务中的多元评估提供了稳健方法，SVM元集成是有效的集成策略。

Abstract: Toxicity detection is inherently subjective, shaped by the diverse perspectives and social priors of different demographic groups. While ``pluralistic'' modeling as used in economics and the social sciences aims to capture perspective differences across contexts, current Large Language Model (LLM) prompting techniques have different results across different personas and base models. In this work, we conduct a systematic evaluation of persona-aware toxicity detection, showing that no single prompting method, including our proposed automated prompt optimization strategy, uniformly dominates across all model-persona pairs. To exploit complementary errors, we explore ensembling four prompting variants and propose a lightweight meta-ensemble: an SVM over the 4-bit vector of prompt predictions. Our results demonstrate that the proposed SVM ensemble consistently outperforms individual prompting methods and traditional majority-voting techniques, achieving the strongest overall performance across diverse personas. This work provides one of the first systematic comparisons of persona-conditioned prompting for toxicity detection and offers a robust method for pluralistic evaluation in subjective NLP tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [76] [Value Vision-Language-Action Planning & Search](https://arxiv.org/abs/2601.00969)
*Ali Salamatian,Ke,Ren,Kieran Pattison,Cyrus Neary*

Main category: cs.RO

TL;DR: V-VLAPS框架通过为VLA模型添加轻量级可学习价值函数，结合MCTS搜索，提升机器人操作任务的成功率和搜索效率


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型依赖行为克隆，在分布偏移下表现脆弱。虽然可以通过MCTS等测试时搜索算法缓解，但现有方法仅依赖VLA先验指导，缺乏对未来回报的可靠估计，导致搜索效率低下

Method: 提出V-VLAPS框架，在MCTS搜索中集成轻量级可学习价值函数。在固定VLA骨干网络（Octo）的潜在表示上训练简单的多层感知机，为搜索提供明确的成功信号，引导动作选择向高价值区域

Result: 在LIBERO机器人操作套件上评估，价值引导的搜索将成功率提升超过5个百分点，同时将平均MCTS模拟次数减少5-15%，相比仅依赖VLA先验的基线方法

Conclusion: V-VLAPS通过结合VLA先验和可学习价值函数，显著提升了机器人操作策略的鲁棒性和搜索效率，为VLA模型的实际应用提供了更有效的规划框架

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.

</details>


### [77] [From Perception to Symbolic Task Planning: Vision-Language Guided Human-Robot Collaborative Structured Assembly](https://arxiv.org/abs/2601.00978)
*Yanyi Chen,Min Deng*

Main category: cs.RO

TL;DR: 提出基于设计知识的人类感知规划框架，用于人机协作结构化装配，结合视觉语言模型进行状态感知和最小变更重规划


<details>
  <summary>Details</summary>
Motivation: 结构化人机协作装配需要可靠的状态估计和自适应任务规划，以应对噪声感知和人为干预的挑战

Method: 框架包含两个耦合模块：PSS模块使用视觉语言模型将RGB-D观测与设计规范对齐，合成可验证的符号装配状态；HPR模块执行任务级多机器人分配，仅在观测状态偏离预期时进行最小变更重规划

Result: 在27组件木框架装配上验证，PSS模块达到97%状态合成准确率，HPR模块在各种人机协作场景中保持可行任务进展

Conclusion: 将基于VLM的感知与知识驱动规划相结合，提高了动态条件下状态估计和任务规划的鲁棒性

Abstract: Human-robot collaboration (HRC) in structured assembly requires reliable state estimation and adaptive task planning under noisy perception and human interventions. To address these challenges, we introduce a design-grounded human-aware planning framework for human-robot collaborative structured assembly. The framework comprises two coupled modules. Module I, Perception-to-Symbolic State (PSS), employs vision-language models (VLMs) based agents to align RGB-D observations with design specifications and domain knowledge, synthesizing verifiable symbolic assembly states. It outputs validated installed and uninstalled component sets for online state tracking. Module II, Human-Aware Planning and Replanning (HPR), performs task-level multi-robot assignment and updates the plan only when the observed state deviates from the expected execution outcome. It applies a minimal-change replanning rule to selectively revise task assignments and preserve plan stability even under human interventions. We validate the framework on a 27-component timber-frame assembly. The PSS module achieves 97% state synthesis accuracy, and the HPR module maintains feasible task progression across diverse HRC scenarios. Results indicate that integrating VLM-based perception with knowledge-driven planning improves robustness of state estimation and task planning under dynamic conditions.

</details>


### [78] [Simulations of MRI Guided and Powered Ferric Applicators for Tetherless Delivery of Therapeutic Interventions](https://arxiv.org/abs/2601.00981)
*Wenhui Chu,Khang Tran,Nikolaos V. Tsekos*

Main category: cs.RO

TL;DR: 开发用于MRI引导血管介入手术的计算平台，实现术前规划和建模，通过虚拟夹具确保器械安全操作


<details>
  <summary>Details</summary>
Motivation: MRI引导的机器人辅助血管介入手术需要安全有效的术前规划和实时操作平台，以避免血管穿孔和碰撞风险

Method: 开发双向数据管道平台，处理MRI数据提取血管结构，创建虚拟夹具作为安全走廊，生成磁场梯度波形，建模器械操控

Result: 实现了基于Qt框架的实时操作平台，包含PID控制器、虚拟夹具生成和MRI梯度波形生成等模块化软件组件

Conclusion: 该平台为MRI引导的血管介入手术提供了有效的术前规划和建模工具，为未来实时实验研究奠定了基础

Abstract: Magnetic Resonance Imaging (MRI) is a well-established modality for pre-operative planning and is also explored for intra-operative guidance of procedures such as intravascular interventions. Among the experimental robot-assisted technologies, the magnetic field gradients of the MRI scanner are used to power and maneuver ferromagnetic applicators for accessing sites in the patient's body via the vascular network. In this work, we propose a computational platform for preoperative planning and modeling of MRI-powered applicators inside blood vessels. This platform was implemented as a two-way data and command pipeline that links the MRI scanner, the computational core, and the operator. The platform first processes multi-slice MR data to extract the vascular bed and then fits a virtual corridor inside the vessel. This corridor serves as a virtual fixture (VF), a forbidden region for the applicators to avoid vessel perforation or collision. The geometric features of the vessel centerline, the VF, and MRI safety compliance (dB/dt, max available gradient) are then used to generate magnetic field gradient waveforms. Different blood flow profiles can be user-selected, and those parameters are used for modeling the applicator's maneuvering. The modeling module further generates cues about whether the selected vascular path can be safely maneuvered. Given future experimental studies that require a real-time operation, the platform was implemented on the Qt framework (C/C++) with software modules performing specific tasks running on dedicated threads: PID controller, generation of VF, generation of MR gradient waveforms.

</details>


### [79] [Topological Mapping and Navigation using a Monocular Camera based on AnyLoc](https://arxiv.org/abs/2601.01067)
*Wenzheng Zhang,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 提出基于单目相机的拓扑建图与导航方法，通过关键帧描述符构建拓扑关系，实现轻量级环境感知与路径规划


<details>
  <summary>Details</summary>
Motivation: 传统度量地图需要精确坐标信息，计算复杂度高且对环境变化敏感。拓扑地图通过关键节点表示环境，简化了路径规划，更适合资源受限的移动机器人导航需求。

Method: 基于AnyLoc框架，将单目相机采集的关键帧转换为描述符，构建拓扑关系图。通过图像分割与目标节点图像比较确定导航动作，实现无预训练的视觉导航。

Result: 在真实与仿真环境中均能有效检测回环并完成导航任务。相比基于ResNet的方法，平均成功率提升60.2%，同时显著降低时间和空间成本。

Conclusion: 该方法提供了一种轻量级、高效的拓扑建图与导航解决方案，仅需单目相机即可快速构建地图并实现导航，适用于多种机器人及人类导航场景。

Abstract: This paper proposes a method for topological mapping and navigation using a monocular camera. Based on AnyLoc, keyframes are converted into descriptors to construct topological relationships, enabling loop detection and map building. Unlike metric maps, topological maps simplify path planning and navigation by representing environments with key nodes instead of precise coordinates. Actions for visual navigation are determined by comparing segmented images with the image associated with target nodes. The system relies solely on a monocular camera, ensuring fast map building and navigation using key nodes. Experiments show effective loop detection and navigation in real and simulation environments without pre-training. Compared to a ResNet-based method, this approach improves success rates by 60.2% on average while reducing time and space costs, offering a lightweight solution for robot and human navigation in various scenarios.

</details>


### [80] [Towards reliable subsea object recovery: a simulation study of an auv with a suction-actuated end effector](https://arxiv.org/abs/2601.01106)
*Michele Grimaldi,Yosaku Maeda,Hitoshi Kakami,Ignacio Carlucho,Yvan Petillot,Tomoya Inoue*

Main category: cs.RO

TL;DR: 论文提出使用高保真模拟器验证深海自主物体回收任务，通过模拟器在虚拟环境中测试小型深海车辆在6000米深度执行自主探测和回收作业。


<details>
  <summary>Details</summary>
Motivation: 深海（尤其是超深渊带）环境极端，压力巨大、能见度低、存在海流，自主物体回收极具挑战。实地实验成本高、风险大、车辆可用性有限，难以在部署前验证自主行为。

Method: 使用Stonefish模拟器模拟真实车辆动力学、水动力扰动、感知和目标物体交互。控制框架结合世界坐标系PID控制器用于车辆导航稳定，以及基于逆运动学的机械臂控制器（带加速度前馈），实现车辆-机械臂协调操作。

Result: 在模拟中，小型深海车辆成功从海面自主下潜至6000米深度，执行结构化海底覆盖探测，识别目标物体，并完成基于吸力的回收操作。

Conclusion: 高保真模拟为深海自主干预行为提供了有效且低风险的评估手段，可在实地部署前进行验证，降低深海作业的风险和成本。

Abstract: Autonomous object recovery in the hadal zone is challenging due to extreme hydrostatic pressure, limited visibility and currents, and the need for precise manipulation at full ocean depth. Field experimentation in such environments is costly, high-risk, and constrained by limited vehicle availability, making early validation of autonomous behaviors difficult. This paper presents a simulation-based study of a complete autonomous subsea object recovery mission using a Hadal Small Vehicle (HSV) equipped with a three-degree-of-freedom robotic arm and a suction-actuated end effector. The Stonefish simulator is used to model realistic vehicle dynamics, hydrodynamic disturbances, sensing, and interaction with a target object under hadal-like conditions. The control framework combines a world-frame PID controller for vehicle navigation and stabilization with an inverse-kinematics-based manipulator controller augmented by acceleration feed-forward, enabling coordinated vehicle - manipulator operation. In simulation, the HSV autonomously descends from the sea surface to 6,000 m, performs structured seafloor coverage, detects a target object, and executes a suction-based recovery. The results demonstrate that high-fidelity simulation provides an effective and low-risk means of evaluating autonomous deep-sea intervention behaviors prior to field deployment.

</details>


### [81] [Latent Space Reinforcement Learning for Multi-Robot Exploration](https://arxiv.org/abs/2601.01139)
*Sriram Rajasekar,Ashwini Ratnoo*

Main category: cs.RO

TL;DR: 提出一种基于自动编码器降维和分层强化学习的多智能体自主建图系统，能够处理高保真度地图并在复杂环境中实现去中心化协调。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在未知环境自主建图中能提高效率，但现有运动规划算法扩展性有限。强化学习方法受限于输入尺寸要求，只能应用于离散环境，需要解决高维连续环境下的可扩展性问题。

Method: 1) 使用自动编码器进行维度压缩，将高保真度占据栅格图压缩为潜在状态向量；2) 基于Perlin噪声的程序生成算法创建拓扑复杂训练环境；3) 分层深度强化学习框架实现去中心化协调；4) 引入加权共识机制，通过可调信任参数调节对共享数据的依赖。

Result: 实验表明系统能有效随智能体数量扩展，在陌生且结构不同的环境中泛化良好，在通信受限环境下具有鲁棒性，解决了现有方法在连续高维环境中的限制。

Conclusion: 通过自动编码器降维和分层强化学习框架，成功实现了多智能体在复杂连续环境中的可扩展自主建图，为时间受限场景下的未知环境探索提供了有效解决方案。

Abstract: Autonomous mapping of unknown environments is a critical challenge, particularly in scenarios where time is limited. Multi-agent systems can enhance efficiency through collaboration, but the scalability of motion-planning algorithms remains a key limitation. Reinforcement learning has been explored as a solution, but existing approaches are constrained by the limited input size required for effective learning, restricting their applicability to discrete environments. This work addresses that limitation by leveraging autoencoders to perform dimensionality reduction, compressing high-fidelity occupancy maps into latent state vectors while preserving essential spatial information. Additionally, we introduce a novel procedural generation algorithm based on Perlin noise, designed to generate topologically complex training environments that simulate asteroid fields, caves and forests. These environments are used for training the autoencoder and the navigation algorithm using a hierarchical deep reinforcement learning framework for decentralized coordination. We introduce a weighted consensus mechanism that modulates reliance on shared data via a tuneable trust parameter, ensuring robustness to accumulation of errors. Experimental results demonstrate that the proposed system scales effectively with number of agents and generalizes well to unfamiliar, structurally distinct environments and is resilient in communication-constrained settings.

</details>


### [82] [VISO: Robust Underwater Visual-Inertial-Sonar SLAM with Photometric Rendering for Dense 3D Reconstruction](https://arxiv.org/abs/2601.01144)
*Shu Pan,Simon Archieri,Ahmet Cinar,Jonatan Scharff Willners,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: VISO是一个鲁棒的水下SLAM系统，融合立体相机、IMU和3D声纳，实现精确的6自由度定位和高效的高保真密集3D重建。


<details>
  <summary>Details</summary>
Motivation: 水下环境的视觉挑战严重影响了基于视觉的定位精度和高保真密集重建的质量，需要更鲁棒的解决方案。

Method: 提出VISO系统，融合立体相机、IMU和3D声纳；采用从粗到精的在线标定方法估计3D声纳与相机之间的外参；提出3D声纳点云的光度渲染策略，为声纳地图添加视觉信息。

Result: 在实验室水箱和开放湖泊的广泛实验表明，VISO在定位鲁棒性和准确性方面超越了当前最先进的水下和基于视觉的SLAM算法，同时展现出与离线密集建图方法相当的实时密集3D重建性能。

Conclusion: VISO通过多传感器融合和创新的标定与渲染策略，有效解决了水下环境的视觉挑战，实现了鲁棒的定位和高保真的密集重建。

Abstract: Visual challenges in underwater environments significantly hinder the accuracy of vision-based localisation and the high-fidelity dense reconstruction. In this paper, we propose VISO, a robust underwater SLAM system that fuses a stereo camera, an inertial measurement unit (IMU), and a 3D sonar to achieve accurate 6-DoF localisation and enable efficient dense 3D reconstruction with high photometric fidelity. We introduce a coarse-to-fine online calibration approach for extrinsic parameters estimation between the 3D sonar and the camera. Additionally, a photometric rendering strategy is proposed for the 3D sonar point cloud to enrich the sonar map with visual information. Extensive experiments in a laboratory tank and an open lake demonstrate that VISO surpasses current state-of-the-art underwater and visual-based SLAM algorithms in terms of localisation robustness and accuracy, while also exhibiting real-time dense 3D reconstruction performance comparable to the offline dense mapping method.

</details>


### [83] [ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation](https://arxiv.org/abs/2601.01155)
*Zhang Shizhe,Liang Jingsong,Zhou Zhitao,Ye Shuhan,Wang Yizhuo,Tan Ming Siang Derek,Chiun Jimmy,Cao Yuhong,Sartoretti Guillaume*

Main category: cs.RO

TL;DR: ORION是一个用于部分已知环境中多智能体在线导航的深度强化学习框架，通过融合先验地图与在线感知、学习高层合作模式、采用双阶段协作策略，实现分散式决策和地图不确定性降低。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体导航方法通常假设环境完全已知，对仓库或工厂等部分已知场景支持有限。在这些场景中，智能体需要规划既能优化自身路径又能收集共享环境信息以帮助队友的轨迹。

Method: 1) 设计共享图编码器，将先验地图与在线感知融合为统一表示；2) 采用选项-评论家框架学习高层合作模式，智能体可在个体导航和团队探索间自适应切换；3) 引入双阶段协作策略，使智能体能在地图不确定性下协助队友。

Result: 在迷宫式地图和大规模仓库环境中，ORION实现了高质量、实时的分散式协作，适应不同团队规模，优于最先进的经典方法和基于学习的基线方法。在物理机器人团队上的验证证明了其鲁棒性和实际应用性。

Conclusion: ORION是一个有效的深度强化学习框架，能够在部分已知环境中实现多智能体的在线协作导航，通过感知-行动闭环中的信息共享和自适应合作模式切换，显著提升了多智能体系统的导航效率和协作能力。

Abstract: Existing methods for multi-agent navigation typically assume fully known environments, offering limited support for partially known scenarios such as warehouses or factory floors. There, agents may need to plan trajectories that balance their own path optimality with their ability to collect and share information about the environment that can help their teammates reach their own goals. To these ends, we propose ORION, a novel deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments. Starting from an imperfect prior map, ORION trains agents to make decentralized decisions, coordinate to reach their individual targets, and actively reduce map uncertainty by sharing online observations in a closed perception-action loop. We first design a shared graph encoder that fuses prior map with online perception into a unified representation, providing robust state embeddings under dynamic map discrepancies. At the core of ORION is an option-critic framework that learns to reason about a set of high-level cooperative modes that translate into sequences of low-level actions, allowing agents to switch between individual navigation and team-level exploration adaptively. We further introduce a dual-stage cooperation strategy that enables agents to assist teammates under map uncertainty, thereby reducing the overall makespan. Across extensive maze-like maps and large-scale warehouse environments, our simulation results show that ORION achieves high-quality, real-time decentralized cooperation over varying team sizes, outperforming state-of-the-art classical and learning-based baselines. Finally, we validate ORION on physical robot teams, demonstrating its robustness and practicality for real-world cooperative navigation.

</details>


### [84] [DST-Calib: A Dual-Path, Self-Supervised, Target-Free LiDAR-Camera Extrinsic Calibration Network](https://arxiv.org/abs/2601.01188)
*Zhiwei Huang,Yanwei Fu,Yi Zhou,Xieyuanli Chen,Qijun Chen,Rui Fan*

Main category: cs.RO

TL;DR: 首个自监督的在线LiDAR-相机外参标定网络，无需特定标定板，通过双面数据增强和差异图构建提升泛化能力和精度。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机外参标定方法依赖手工标定板或特定静态场景，限制了在真实自主机器人应用中的适应性和部署能力。

Method: 提出双面数据增强技术生成多视角相机视图，设计双路径自监督标定框架，用差异图构建替代传统双分支特征提取，显式关联LiDAR和相机特征。

Result: 在五个公开基准数据集和自录数据集上的实验表明，该方法在泛化能力方面显著优于现有方法。

Conclusion: 该方法首次实现了无需特定标定板的在线自监督LiDAR-相机外参标定，通过创新的数据增强和特征关联设计，显著提升了标定精度和泛化能力。

Abstract: LiDAR-camera extrinsic calibration is essential for multi-modal data fusion in robotic perception systems. However, existing approaches typically rely on handcrafted calibration targets (e.g., checkerboards) or specific, static scene types, limiting their adaptability and deployment in real-world autonomous and robotic applications. This article presents the first self-supervised LiDAR-camera extrinsic calibration network that operates in an online fashion and eliminates the need for specific calibration targets. We first identify a significant generalization degradation problem in prior methods, caused by the conventional single-sided data augmentation strategy. To overcome this limitation, we propose a novel double-sided data augmentation technique that generates multi-perspective camera views using estimated depth maps, thereby enhancing robustness and diversity during training. Built upon this augmentation strategy, we design a dual-path, self-supervised calibration framework that reduces the dependence on high-precision ground truth labels and supports fully adaptive online calibration. Furthermore, to improve cross-modal feature association, we replace the traditional dual-branch feature extraction design with a difference map construction process that explicitly correlates LiDAR and camera features. This not only enhances calibration accuracy but also reduces model complexity. Extensive experiments conducted on five public benchmark datasets, as well as our own recorded dataset, demonstrate that the proposed method significantly outperforms existing approaches in terms of generalizability.

</details>


### [85] [EduSim-LLM: An Educational Platform Integrating Large Language Models and Robotic Simulation for Beginners](https://arxiv.org/abs/2601.01196)
*Shenqi Lu,Liangwei Zhang*

Main category: cs.RO

TL;DR: EduSim-LLM是一个教育平台，将大语言模型与机器人仿真结合，通过语言驱动控制将自然语言指令转换为可执行的机器人行为序列，在CoppeliaSim中实现，支持直接控制和自主控制两种交互模式。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言理解方面取得显著进展，但将其与机器人控制集成仍是一个重要挑战，这阻碍了人类对复杂机器人系统的直观控制，限制了其在教育和实践中的可访问性。

Method: 开发EduSim-LLM教育平台，集成LLMs与机器人仿真，构建语言驱动控制模型，将自然语言指令翻译为CoppeliaSim中的可执行机器人行为序列。设计两种人机交互模型：直接控制和自主控制，基于多种语言模型进行系统仿真，评估多机器人协作、运动规划和操作能力。

Result: 实验结果表明：LLMs能够可靠地将自然语言转换为结构化机器人动作；应用提示工程模板后，指令解析准确率显著提高；随着任务复杂度增加，在最高复杂度测试中整体准确率超过88.9%。

Conclusion: EduSim-LLM平台成功展示了LLMs在机器人控制中的潜力，通过语言驱动控制模型有效提升了自然语言到机器人动作的转换准确率，为教育机器人学和智能自动化提供了新的解决方案。

Abstract: In recent years, the rapid development of Large Language Models (LLMs) has significantly enhanced natural language understanding and human-computer interaction, creating new opportunities in the field of robotics. However, the integration of natural language understanding into robotic control is an important challenge in the rapid development of human-robot interaction and intelligent automation industries. This challenge hinders intuitive human control over complex robotic systems, limiting their educational and practical accessibility. To address this, we present the EduSim-LLM, an educational platform that integrates LLMs with robot simulation and constructs a language-drive control model that translates natural language instructions into executable robot behavior sequences in CoppeliaSim. We design two human-robot interaction models: direct control and autonomous control, conduct systematic simulations based on multiple language models, and evaluate multi-robot collaboration, motion planning, and manipulation capabilities. Experiential results show that LLMs can reliably convert natural language into structured robot actions; after applying prompt-engineering templates instruction-parsing accuracy improves significantly; as task complexity increases, overall accuracy rate exceeds 88.9% in the highest complexity tests.

</details>


### [86] [SAHA: Supervised Autonomous HArvester for selective forest thinning](https://arxiv.org/abs/2601.01282)
*Fang Nan,Meher Malladi,Qingqing Li,Fan Yang,Joonas Juola,Tiziano Guadagnino,Jens Behley,Cesar Cadena,Cyrill Stachniss,Marco Hutter*

Main category: cs.RO

TL;DR: 开发小型机器人采伐机SAHA，用于森林选择性疏伐作业，通过监督自主方式实现森林环境自主导航和树木定位


<details>
  <summary>Details</summary>
Motivation: 森林管理需要劳动密集型复杂操作，选择性疏伐对维持森林健康至关重要但需要熟练操作员，需要自动化解决方案提高效率

Method: 基于4.5吨采伐机平台，进行感知和自动控制硬件改造，采用学习和模型相结合的方法控制液压执行器，实现精确导航、状态估计和地形可通行性语义估计

Result: 在北方欧洲森林进行了公里级自主任务实地试验，机器人采伐机能够在真实森林环境中自主导航并到达目标树木进行选择性疏伐

Conclusion: 集成先进的感知、规划和控制技术，机器人采伐机能够自主执行森林管理任务，为推进机器人森林管理提供了性能分析和经验教训

Abstract: Forestry plays a vital role in our society, creating significant ecological, economic, and recreational value. Efficient forest management involves labor-intensive and complex operations. One essential task for maintaining forest health and productivity is selective thinning, which requires skilled operators to remove specific trees to create optimal growing conditions for the remaining ones. In this work, we present a solution based on a small-scale robotic harvester (SAHA) designed for executing this task with supervised autonomy. We build on a 4.5-ton harvester platform and implement key hardware modifications for perception and automatic control. We implement learning- and model-based approaches for precise control of hydraulic actuators, accurate navigation through cluttered environments, robust state estimation, and reliable semantic estimation of terrain traversability. Integrating state-of-the-art techniques in perception, planning, and control, our robotic harvester can autonomously navigate forest environments and reach targeted trees for selective thinning. We present experimental results from extensive field trials over kilometer-long autonomous missions in northern European forests, demonstrating the harvester's ability to operate in real forests. We analyze the performance and provide the lessons learned for advancing robotic forest management.

</details>


### [87] [Online Estimation and Manipulation of Articulated Objects](https://arxiv.org/abs/2601.01438)
*Russell Buchanan,Adrian Röfer,João Moura,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出一种结合视觉先验和本体感知的因子图方法，用于在线估计铰接物体的运动学参数，实现机器人对未知铰接物体的自主操作。


<details>
  <summary>Details</summary>
Motivation: 服务机器人需要能够操作任意铰接物体来完成家务任务。现有方法要么依赖视觉预测但缺乏实际交互，要么需要先能操作物体才能估计其运动学参数，存在局限性。

Method: 使用因子图在线估计铰接参数，融合学习到的视觉先验和交互过程中的本体感知（运动学和力传感），基于螺旋理论构建解析模型。

Result: 在仿真和真实机器人实验中进行了广泛评估，展示了多个闭环估计和操作实验，机器人能够打开未见过的抽屉。真实硬件实验中，对未知铰接物体的自主打开成功率达到了75%。

Conclusion: 提出的方法成功结合了视觉先验和本体感知，实现了对未知铰接物体的在线估计和自主操作，为服务机器人完成日常家务任务提供了有效解决方案。

Abstract: From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.

</details>


### [88] [AIMS: An Adaptive Integration of Multi-Sensor Measurements for Quadrupedal Robot Localization](https://arxiv.org/abs/2601.01561)
*Yujian Qiu,Yuqiu Mu,Wen Yang,Hao Zhu*

Main category: cs.RO

TL;DR: 提出AIMS方法，一种自适应LiDAR-IMU-腿里程计融合方法，用于四足机器人在退化环境（如狭窄隧道）中的鲁棒定位。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在狭窄隧道类环境中运行时，由于环境长且同质，LiDAR测量提供弱几何约束，传统传感器融合方法容易积累运动估计误差。

Method: 在误差状态卡尔曼滤波框架中，将LiDAR和腿里程计测量与IMU状态预测集成，基于在线退化感知可靠性评估自适应调整测量噪声协方差矩阵。

Result: 在狭窄走廊环境中的实验结果表明，该方法相比最先进方法提高了定位精度和鲁棒性。

Conclusion: AIMS方法通过自适应融合策略有效解决了退化环境中的四足机器人定位问题，提高了在几何约束弱的环境中的定位性能。

Abstract: This paper addresses the problem of accurate localization for quadrupedal robots operating in narrow tunnel-like environments. Due to the long and homogeneous characteristics of such scenarios, LiDAR measurements often provide weak geometric constraints, making traditional sensor fusion methods susceptible to accumulated motion estimation errors. To address these challenges, we propose AIMS, an adaptive LiDAR-IMU-leg odometry fusion method for robust quadrupedal robot localization in degenerate environments. The proposed method is formulated within an error-state Kalman filtering framework, where LiDAR and leg odometry measurements are integrated with IMU-based state prediction, and measurement noise covariance matrices are adaptively adjusted based on online degeneracy-aware reliability assessment. Experimental results obtained in narrow corridor environments demonstrate that the proposed method improves localization accuracy and robustness compared with state-of-the-art approaches.

</details>


### [89] [HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller](https://arxiv.org/abs/2601.01577)
*Tran Tien Dat,Nguyen Hai An,Nguyen Khanh Viet Dung,Nguyen Duy Duc*

Main category: cs.RO

TL;DR: 提出Hanoi-World，一种基于JEPA的世界模型，使用RNN进行长期规划，在自动驾驶控制器中实现安全感知的驾驶规划


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在自动驾驶控制器中数据需求大、性能不佳、不稳定、无法确保安全，且因像素重建而过度关注噪声特征。自监督学习方法通过JEPA学习高维表示，模仿人脑通过想象和少量观察学习新技能的能力，是一个有前景的替代方案

Method: 提出Hanoi-World，一种基于联合嵌入预测架构(JEPA)的世界模型，使用循环神经网络(RNN)进行长期水平规划，具有高效的推理时间

Result: 在Highway-Env包的不同环境中进行实验，展示了模型在制定驾驶计划时的有效能力，同时具备安全感知，与最先进的基线相比具有可观的碰撞率

Conclusion: Hanoi-World作为一种JEPA-based世界模型，能够实现安全感知的自动驾驶规划，相比传统强化学习方法在数据效率和安全性方面有所改进

Abstract: Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines

</details>


### [90] [Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.01618)
*Huajie Tan,Peterson Co,Yijie Xu,Shanyu Rong,Yuheng Ji,Cheng Chi,Xiansheng Chen,Qiongyu Zhang,Zhongxia Zhao,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出Action-Sketcher框架，通过视觉草图（Visual Sketch）作为中间表示，将空间意图可视化，结合自适应token门控策略实现See-Think-Sketch-Act循环工作流，提升长时程机器人操作的性能、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端和分层的视觉-语言-动作（VLA）策略主要依赖文本线索，将规划意图隐式表示，导致在杂乱或未充分指定的场景中引用基础薄弱，难以有效分解长时程目标并进行闭环交互，且缺乏对动作选择背后原理的因果解释。

Method: 1. 引入Visual Sketch作为视觉中间表示，在机器人当前视图中渲染点、框、箭头和类型化关系，将空间意图外部化；2. 提出Action-Sketcher框架，采用See-Think-Sketch-Act循环工作流，通过自适应token门控策略协调推理触发、草图修订和动作执行；3. 构建多样化数据集，采用多阶段课程学习结合交错序列对齐、语言-草图一致性和模仿学习增强的草图-动作强化学习。

Result: 在杂乱场景和多物体任务的仿真和真实世界实验中，Action-Sketcher在长时程任务成功率、动态场景变化的鲁棒性方面表现更优，并通过可编辑草图和分步规划增强了可解释性。

Conclusion: 通过视觉草图作为中间表示，Action-Sketcher框架有效解决了长时程机器人操作中的空间消歧、任务分解和可解释性问题，为复杂环境下的机器人操作提供了更可靠、可解释的解决方案。

Abstract: Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io

</details>


### [91] [DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos](https://arxiv.org/abs/2601.01651)
*Yucheng Xu,Xiaofeng Mao,Elle Miller,Xinyu Yi,Yang Li,Zhibin Li,Robert B. Fisher*

Main category: cs.RO

TL;DR: DemoBot：从单段无标注RGB-D视频中学习复杂双手操作技能的学习框架，通过提取结构化运动轨迹作为先验，结合强化学习进行精炼


<details>
  <summary>Details</summary>
Motivation: 解决从人类演示视频直接学习复杂双手操作技能的挑战，避免从零开始学习，实现可扩展的技能获取方法

Method: 1. 从原始视频数据提取双手和物体的结构化运动轨迹作为运动先验；2. 提出基于时间分段的强化学习确保与演示的时间对齐；3. 成功门控重置策略平衡技能精炼与后续阶段探索；4. 事件驱动的奖励课程与自适应阈值引导高精度操作学习

Result: 成功实现了长时程同步和异步双手装配任务，为从人类视频直接获取技能提供了可扩展的方法

Conclusion: DemoBot框架能够从单段无标注RGB-D视频演示中有效学习复杂双手操作技能，通过结合视频处理和强化学习，解决了长时程操作学习的挑战

Abstract: This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.

</details>


### [92] [VisuoTactile 6D Pose Estimation of an In-Hand Object using Vision and Tactile Sensor Data](https://arxiv.org/abs/2601.01675)
*Snehal s. Dikhale,Karankumar Patel,Daksh Dhingra,Itoshi Naramura,Akinobu Hayashi,Soshi Iba,Nawid Jamali*

Main category: cs.RO

TL;DR: 提出结合触觉与视觉数据估计手中物体6D位姿的方法，使用点云表示触觉接触表面，通过像素级密集融合网络架构，在合成数据上训练并成功迁移到真实机器人


<details>
  <summary>Details</summary>
Motivation: 机器人手内物体6D位姿估计因夹爪遮挡而困难，仅依赖视觉数据效果不佳。许多机器人配备触觉传感器，可补充视觉数据，但缺乏触觉数据标准表示和传感器融合方法

Method: 使用点云表示触觉传感器接触的物体表面，提出基于像素级密集融合的网络架构。扩展NVIDIA深度学习数据集合成器生成合成视觉数据和对应触觉点云

Result: 触觉数据补充视觉数据能改善6D位姿估计，网络从合成训练成功泛化到真实物理机器人

Conclusion: 多模态触觉-视觉融合方法能有效解决手内物体位姿估计的遮挡问题，合成数据训练可迁移到真实场景

Abstract: Knowledge of the 6D pose of an object can benefit in-hand object manipulation. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot's grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this paper, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot's hand. To address challenges like lack of standard representation for tactile data and sensor fusion, we propose the use of point clouds to represent object surfaces in contact with the tactile sensor and present a network architecture based on pixel-wise dense fusion. We also extend NVIDIA's Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and corresponding tactile point clouds. Results suggest that using tactile data in addition to vision data improves the 6D pose estimate, and our network generalizes successfully from synthetic training to real physical robots.

</details>


### [93] [Explicit World Models for Reliable Human-Robot Collaboration](https://arxiv.org/abs/2601.01705)
*Kenneth Kwok,Basura Fernando,Qianli Xu,Vigneshwaran Subbaraju,Dongkyu Choi,Boon Kiat Quek*

Main category: cs.RO

TL;DR: 论文提出了一种新的可靠具身AI方法，强调在人类环境中可靠性是情境决定的，需要建立可访问的显式世界模型来对齐人类期望


<details>
  <summary>Details</summary>
Motivation: 当前具身AI研究过于关注形式化验证方法以实现模型可预测性和鲁棒性，但忽视了人类-机器人交互的动态性、模糊性和主观性。在人类环境中，可靠性是情境决定的，只有在与人类目标和期望相关时才有意义

Method: 采用根本不同的方法：强调建立和更新可访问的"显式世界模型"，该模型表示人类与AI之间的共同基础，用于将机器人行为与人类期望对齐。关注感知、解释和响应人类意图的能力

Result: 提出了一种以人类为中心的可靠具身AI框架，强调在动态、模糊的人类环境中，可靠性需要通过建立共同理解和期望对齐来实现，而不是单纯追求形式化验证

Conclusion: 在人类环境中实现可靠的具身AI需要根本性的方法转变，从追求模型可预测性转向建立可访问的显式世界模型来对齐人类期望，强调可靠性是情境决定且与人类目标相关的

Abstract: This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible "explicit world model" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.

</details>


### [94] [Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions](https://arxiv.org/abs/2601.01726)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.RO

TL;DR: 开发了与MRI扫描仪集成的计算系统，用于机器人辅助血管介入手术，通过处理MR图像建立虚拟血管路径和边界，生成定制磁场梯度模式控制设备，提高手术精度和安全性。


<details>
  <summary>Details</summary>
Motivation: MRI扫描仪环境下的机器人系统面临强磁场下的精度和稳定性挑战，需要增强MRI在医学成像中的作用，特别是在机器人辅助设备引导血管介入手术中的应用。

Method: 开发基于Qt框架和C/C++的计算系统，包括计算单元和用户界面，与MRI扫描仪无缝集成。系统处理MR图像以描绘血管网络，建立虚拟路径和边界，生成定制磁场梯度模式控制设备，考虑血管几何形状、安全规范和血流特性。

Result: 系统能够创建针对血管几何形状和安全规范的定制磁场梯度模式，适应不同血流特性实现精细导航。建模方面评估预设血管路径的安全性和可行性，显著提高血管介入手术的精度和安全性。

Conclusion: 该系统代表了成像技术与机器人辅助融合的重要进展，基于Qt框架和C/C++开发，具有专门软件模块，显著提升了血管介入手术的精度和安全性。

Abstract: Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.

</details>


### [95] [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
*Yanhao Wu,Haoyang Zhang,Fei He,Rui Wu,Congpei Qiu,Liang Gao,Wei Ke,Tong Zhang*

Main category: cs.RO

TL;DR: 提出一种级联框架，将纵向规划显式地建立在驾驶路径上，实现协调的横向和纵向规划，在Bench2Drive基准上达到新SOTA


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶模型将规划解耦为并行的横向和纵向预测，这会导致：1) 规划路径与速度协调失败；2) 未充分利用驾驶路径作为纵向规划的先验，导致静态信息冗余编码

Method: 提出级联框架，将纵向规划显式地建立在驾驶路径上：1) 路径条件化公式，将驾驶路径显式纳入纵向规划；2) 沿驾驶路径预测纵向位移而非完整2D轨迹点；3) 规划导向的数据增强策略，模拟车辆切入等安全关键事件

Result: 在Bench2Drive基准上达到新SOTA：驾驶分数89.07，成功率73.18%，显著改善了协调性和安全性

Conclusion: 通过将纵向规划显式地建立在驾驶路径上，实现了更好的横向和纵向规划协调，提高了自动驾驶系统的安全性和性能

Abstract: End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety

</details>


### [96] [DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization](https://arxiv.org/abs/2601.01822)
*Shiyong Meng,Tao Zou,Bolei Chen,Chaoxu Mu,Jianxin Wang*

Main category: cs.RO

TL;DR: DisCo-FLoc：通过双层次视觉-几何对比学习消除楼层平面图定位中的歧义，无需额外语义标注，在深度感知视觉特征与几何结构匹配方面优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有楼层平面图定位方法存在两个主要问题：1）简约楼层平面图中的重复结构导致定位歧义；2）昂贵且有限的语义标注限制了方法适用性。需要一种无需额外语义标签就能消除歧义的方法。

Method: 提出DisCo-FLoc方法：1）使用光线回归预测器为基于光线投射的定位生成候选位置；2）提出新颖的对比学习方法，包含位置级和方向级约束，严格匹配深度感知视觉特征与楼层平面图中的几何结构，从而消除歧义并选择最佳成像姿态。

Result: 在两个标准视觉楼层平面图定位基准测试中，该方法超越了最先进的基于语义的方法，在鲁棒性和准确性方面都取得了显著提升。

Conclusion: DisCo-FLoc通过双层次视觉-几何对比学习有效解决了楼层平面图定位中的歧义问题，无需额外语义标注，在性能上优于现有方法，展示了深度感知特征与几何结构匹配的有效性。

Abstract: Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.

</details>


### [97] [CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios](https://arxiv.org/abs/2601.01872)
*Hongbo Duan,Shangyi Luo,Zhiyuan Deng,Yanbo Chen,Yuanhao Chiang,Yi Liu,Fangming Liu,Xueqian Wang*

Main category: cs.RO

TL;DR: CausalNav：首个基于场景图的语义导航框架，专为动态户外环境设计，通过LLM构建多层级语义场景图（Embodied Graph），结合实时感知与离线地图数据，实现开放词汇查询下的语义导航和长距离规划。


<details>
  <summary>Details</summary>
Motivation: 大规模户外环境中的自主语言引导导航面临语义推理困难、动态条件变化和长期稳定性等挑战，现有方法难以有效处理这些复杂问题。

Method: 使用LLM构建多层级语义场景图（Embodied Graph），分层整合粗粒度地图数据和细粒度物体实体；将构建的图作为可检索知识库用于RAG；在场景图构建和分层规划模块中显式处理动态物体；在时间窗口内持续更新场景图以反映环境变化。

Result: 在仿真和真实世界环境中进行广泛实验，证明了该方法在动态户外环境中具有优越的鲁棒性和效率。

Conclusion: CausalNav是首个针对动态户外环境的场景图语义导航框架，通过多层级语义场景图和RAG技术，有效解决了大规模户外环境中的语义导航挑战，实现了开放词汇查询下的鲁棒导航。

Abstract: Autonomous language-guided navigation in large-scale outdoor environments remains a key challenge in mobile robotics, due to difficulties in semantic reasoning, dynamic conditions, and long-term stability. We propose CausalNav, the first scene graph-based semantic navigation framework tailored for dynamic outdoor environments. We construct a multi-level semantic scene graph using LLMs, referred to as the Embodied Graph, that hierarchically integrates coarse-grained map data with fine-grained object entities. The constructed graph serves as a retrievable knowledge base for Retrieval-Augmented Generation (RAG), enabling semantic navigation and long-range planning under open-vocabulary queries. By fusing real-time perception with offline map data, the Embodied Graph supports robust navigation across varying spatial granularities in dynamic outdoor environments. Dynamic objects are explicitly handled in both the scene graph construction and hierarchical planning modules. The Embodied Graph is continuously updated within a temporal window to reflect environmental changes and support real-time semantic navigation. Extensive experiments in both simulation and real-world settings demonstrate superior robustness and efficiency.

</details>


### [98] [From Metrics to Meaning: Insights from a Mixed-Methods Field Experiment on Retail Robot Deployment](https://arxiv.org/abs/2601.01946)
*Sichao Song,Yuki Okafuji,Takuya Iwamoto,Jun Baba,Hiroshi Ishiguro*

Main category: cs.RO

TL;DR: 研究通过混合方法实地实验，在床品店部署对话服务机器人，发现机器人能增加顾客停留率但降低店员主导的后续服务转化，揭示了人机协作中的时间协调挑战和门槛效应。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索在真实零售环境中部署对话服务机器人时，机器人如何影响顾客服务流程以及店员与机器人的协作动态，特别是在高接触零售场景中的人机交互问题。

Method: 采用混合方法实地实验设计：在床品店进行12天的现场实验，交替三种条件（无机器人、仅机器人、机器人+展示装置），通过视频标注分析服务漏斗数据，然后进行解释性顺序设计，通过6次店员访谈解释定量模式。

Result: 机器人增加了路过顾客的停留率（展示装置效果最佳），但店员主导的下游服务步骤（店员接近、进店、协助体验、购买）却减少了。访谈揭示：店员避免打断机器人-顾客对话，在对话延迟中难以把握时机，且机器人主要吸引儿童满足门口好奇心。展示装置增强了可见性但也将互动锚定在门槛处。

Conclusion: 研究提出了从顾客兴趣展示到进店的整合性解释框架，揭示了人机协作中的时间协调挑战和"门槛效应"，为高接触零售场景中服务机器人的部署提供了实践指导，强调需要优化人机交接时机和空间布局设计。

Abstract: We report a mixed-methods field experiment of a conversational service robot deployed under everyday staffing discretion in a live bedding store. Over 12 days we alternated three conditions--Baseline (no robot), Robot-only, and Robot+Fixture--and video-annotated the service funnel from passersby to purchase. An explanatory sequential design then used six post-experiment staff interviews to interpret the quantitative patterns.
  Quantitatively, the robot increased stopping per passerby (highest with the fixture), yet clerk-led downstream steps per stopper--clerk approach, store entry, assisted experience, and purchase--decreased. Interviews explained this divergence: clerks avoided interrupting ongoing robot-customer talk, struggled with ambiguous timing amid conversational latency, and noted child-centered attraction that often satisfied curiosity at the doorway. The fixture amplified visibility but also anchored encounters at the threshold, creating a well-defined micro-space where needs could ``close'' without moving inside.
  We synthesize these strands into an integrative account from the initial show of interest on the part of a customer to their entering the store and derive actionable guidance. The results advance the understanding of interactions between customers, staff members, and the robot and offer practical recommendations for deploying service robots in high-touch retail.

</details>


### [99] [Learning Diffusion Policy from Primitive Skills for Robot Manipulation](https://arxiv.org/abs/2601.01948)
*Zhihao Gu,Ming Yang,Difan Zou,Dong Xu*

Main category: cs.RO

TL;DR: SDP：一种基于技能条件的扩散策略，通过将复杂任务分解为可解释的原始技能序列，提升机器人动作生成的对齐性和性能


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略方法依赖全局指令生成短期控制信号，容易导致动作生成不对齐。原始技能（如"向上移动"、"打开夹爪"）作为细粒度、短时程的操纵单元，能为机器人学习提供更直观有效的接口

Method: 提出技能条件扩散策略SDP，整合可解释技能学习与条件动作规划：1) 抽象出8个跨任务可重用原始技能；2) 使用视觉语言模型从视觉观察和语言指令中提取离散表示；3) 设计轻量级路由器网络为每个状态分配期望原始技能；4) 构建单技能策略生成技能对齐的动作

Result: 在两个具有挑战性的仿真基准测试和真实机器人部署中，SDP持续超越最先进方法，为基于技能的机器人学习提供了新范式

Conclusion: 通过将复杂任务分解为原始技能序列并选择单技能策略，SDP确保了跨多样任务的技能一致行为，证明了技能条件扩散策略在机器人学习中的有效性

Abstract: Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.

</details>


### [100] [What you reward is what you learn: Comparing rewards for online speech policy optimization in public HRI](https://arxiv.org/abs/2601.01969)
*Sichao Song,Yuki Okafuji,Kaito Ariu,Amy Koike*

Main category: cs.RO

TL;DR: 在线学习社交机器人语音策略，通过多臂老虎机框架在真实公共环境中优化语速和详细程度，使用三种不同奖励函数评估效果


<details>
  <summary>Details</summary>
Motivation: 在开放多样的环境中设计既高效又可接受的对话服务机器人策略具有挑战性，需要适应非平稳条件，而在线学习能够实现这种适应

Method: 将在线策略优化建模为多臂老虎机问题，使用Thompson采样从6个动作中选择（语速：慢/正常/快 × 详细程度：简洁/详细），在12天实地部署中收集1400多次公共交互数据

Result: 三种互补的二元奖励（用户评分、对话结束、≥2轮对话）各自诱导出不同的动作分布和交互行为，离线分析还考虑了人群密度、小组规模等上下文因素

Conclusion: 为在真实公共人机交互环境中部署语音策略的在线优化提供了可直接应用的设计经验教训

Abstract: Designing policies that are both efficient and acceptable for conversational service robots in open and diverse environments is non-trivial. Unlike fixed, hand-tuned parameters, online learning can adapt to non-stationary conditions. In this paper, we study how to adapt a social robot's speech policy in the wild. During a 12-day in-situ deployment with over 1,400 public encounters, we cast online policy optimization as a multi-armed bandit problem and use Thompson sampling to select among six actions defined by speech rate (slow/normal/fast) and verbosity (concise/detailed). We compare three complementary binary rewards--Ru (user rating), Rc (conversation closure), and Rt (>=2 turns)--and show that each induces distinct arm distributions and interaction behaviors. We complement the online results with offline evaluations that analyze contextual factors (e.g., crowd level, group size) using video-annotated data. Taken together, we distill ready-to-use design lessons for deploying online optimization of speech policies in real public HRI settings.

</details>


### [101] [Deep Robust Koopman Learning from Noisy Data](https://arxiv.org/abs/2601.01971)
*Aditya Singh,Rajpal Singh,Jishnu Keshavan*

Main category: cs.RO

TL;DR: 提出一种基于自编码器的神经网络架构，从噪声数据中联合学习提升函数和降偏Koopman算子，提高非线性系统线性表示的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现实世界数据通常包含噪声，导致从噪声数据集生成的Koopman算子存在噪声诱导偏差，严重影响预测和跟踪性能，需要解决这一缺陷

Method: 设计自编码器神经网络架构，首先学习系统前向和后向时间动力学一致的Koopman基函数，然后利用学习到的动力学合成降偏Koopman算子

Result: 理论分析显示在训练噪声下显著减少偏差，多个串联机械臂的动力学预测和跟踪控制仿真表明在各种噪声水平下具有鲁棒性，Franka FR3 7自由度机械臂实验验证了实际效果

Conclusion: 提出的方法能够从噪声数据中联合学习提升函数和降偏Koopman算子，相比现有技术对噪声更鲁棒，在理论和实验上都证明了有效性

Abstract: Koopman operator theory has emerged as a leading data-driven approach that relies on a judicious choice of observable functions to realize global linear representations of nonlinear systems in the lifted observable space. However, real-world data is often noisy, making it difficult to obtain an accurate and unbiased approximation of the Koopman operator. The Koopman operator generated from noisy datasets is typically corrupted by noise-induced bias that severely degrades prediction and downstream tracking performance. In order to address this drawback, this paper proposes a novel autoencoder-based neural architecture to jointly learn the appropriate lifting functions and the reduced-bias Koopman operator from noisy data. The architecture initially learns the Koopman basis functions that are consistent for both the forward and backward temporal dynamics of the system. Subsequently, by utilizing the learned forward and backward temporal dynamics, the Koopman operator is synthesized with a reduced bias making the method more robust to noise compared to existing techniques. Theoretical analysis is used to demonstrate significant bias reduction in the presence of training noise. Dynamics prediction and tracking control simulations are conducted for multiple serial manipulator arms, including performance comparisons with leading alternative designs, to demonstrate its robustness under various noise levels. Experimental studies with the Franka FR3 7-DoF manipulator arm are further used to demonstrate the effectiveness of the proposed approach in a practical setting.

</details>


### [102] [Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot](https://arxiv.org/abs/2601.02078)
*Chenghao Yin,Da Huang,Di Yang,Jichao Wang,Nanshu Zhao,Chen Xu,Wenjun Sun,Linjie Hou,Zhijun Li,Junhui Wu,Zhaobo Liu,Zhen Xiao,Sheng Zhang,Lei Bao,Rui Feng,Zhenquan Pang,Jiayu Li,Qian Wang,Maoqing Yao*

Main category: cs.RO

TL;DR: Genie Sim 3.0是一个用于机器人操作的统一仿真平台，包含LLM驱动的场景生成器、首个基于LLM的自动评估基准，并发布了超过10,000小时的合成数据集，验证了零样本模拟到真实世界的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习面临两大挑战：1）物理世界数据收集成本高、可扩展性差；2）现有仿真基准存在碎片化、范围窄、保真度不足等问题，难以实现有效的模拟到真实迁移。

Method: 1）开发Genie Sim Generator：基于大语言模型从自然语言指令构建高保真场景；2）创建首个基于LLM的自动评估基准：利用LLM批量生成评估场景，使用视觉语言模型建立自动评估流程；3）发布开源数据集：包含200多个任务的10,000多小时合成数据。

Result: 通过系统实验验证了开源数据集具有强大的零样本模拟到真实迁移能力，证明在受控条件下合成数据可以有效替代真实世界数据进行可扩展的策略训练。

Conclusion: Genie Sim 3.0提供了一个统一的机器人操作仿真平台，解决了大规模多样化训练数据获取和可靠评估基准的挑战，通过LLM驱动的场景生成和自动评估，为机器人学习提供了可扩展的解决方案。

Abstract: The development of robust and generalizable robot learning models is critically contingent upon the availability of large-scale, diverse training data and reliable evaluation benchmarks. Collecting data in the physical world poses prohibitive costs and scalability challenges, and prevailing simulation benchmarks frequently suffer from fragmentation, narrow scope, or insufficient fidelity to enable effective sim-to-real transfer. To address these challenges, we introduce Genie Sim 3.0, a unified simulation platform for robotic manipulation. We present Genie Sim Generator, a large language model (LLM)-powered tool that constructs high-fidelity scenes from natural language instructions. Its principal strength resides in rapid and multi-dimensional generalization, facilitating the synthesis of diverse environments to support scalable data collection and robust policy evaluation. We introduce the first benchmark that pioneers the application of LLM for automated evaluation. It leverages LLM to mass-generate evaluation scenarios and employs Vision-Language Model (VLM) to establish an automated assessment pipeline. We also release an open-source dataset comprising more than 10,000 hours of synthetic data across over 200 tasks. Through systematic experimentation, we validate the robust zero-shot sim-to-real transfer capability of our open-source dataset, demonstrating that synthetic data can server as an effective substitute for real-world data under controlled conditions for scalable policy training. For code and dataset details, please refer to: https://github.com/AgibotTech/genie_sim.

</details>


### [103] [Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots](https://arxiv.org/abs/2601.02085)
*Meili Sun,Chunjiang Zhao,Lichao Yang,Hao Liu,Shimin Hu,Ya Xiong*

Main category: cs.RO

TL;DR: 本文提出了一种草莓采摘机器人的视觉故障诊断与自恢复框架，通过SRR-Net多任务感知模型整合检测、分割和成熟度估计，结合误差补偿和早期中止策略解决采摘过程中的对位不准、空抓和果实滑落问题。


<details>
  <summary>Details</summary>
Motivation: 草莓采摘机器人面临视觉感知集成度低、果实-夹爪对位不准、空抓取、以及因夹持力不足导致的果实滑落等问题，这些问题影响了果园环境下的采摘稳定性和效率。

Method: 提出视觉故障诊断与自恢复框架，核心是SRR-Net端到端多任务感知模型，同时执行草莓检测、分割和成熟度估计。采用基于同步目标-夹爪检测的相对误差补偿方法解决位置偏差，实施早期中止策略防止空抓和果实滑落。末端执行器嵌入微光学相机提供实时视觉反馈，通过MobileNet V3-Small和LSTM分类器进行抓取检测和滑落预测。

Result: SRR-Net在检测任务上对草莓的精确度为0.895、召回率为0.813，对手的精确度为0.972、召回率为0.958；分割任务上对草莓的精确度为0.887、召回率为0.747，对手的精确度为0.974、召回率为0.947；成熟度估计的平均绝对误差为0.035，同时支持多任务感知并保持163.35 FPS的推理速度。

Conclusion: 该框架通过整合多任务感知与纠正控制策略，有效解决了草莓采摘机器人的关键问题，提高了采摘稳定性和效率，实验验证了SRR-Net的高精度感知能力和实时性能。

Abstract: Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.

</details>


### [104] [SingingBot: An Avatar-Driven System for Robotic Face Singing Performance](https://arxiv.org/abs/2601.02125)
*Zhuoxiong Xu,Xuanchen Li,Yuhao Cheng,Fei Xu,Yichao Yan,Xiaokang Yang*

Main category: cs.RO

TL;DR: 提出一个新颖的机器人唱歌表情驱动框架，通过肖像视频生成模型创建生动的唱歌虚拟形象，再通过语义映射将面部特征转移到机器人上，实现丰富的情感表达和唇音同步。


<details>
  <summary>Details</summary>
Motivation: 现有机器人面部驱动研究主要关注对话或静态表情模仿，难以满足唱歌时连续情感表达和连贯性的高要求，需要为机器人唱歌开发更丰富的情感表达能力。

Method: 1) 利用嵌入人类先验知识的肖像视频生成模型合成生动的唱歌虚拟形象；2) 通过语义导向的映射函数将面部特征转移到机器人上，覆盖广泛的表情空间；3) 提出情感动态范围指标来量化机器人唱歌的情感丰富度。

Result: 综合实验证明该方法在保持唇音同步的同时实现了丰富的情感表达，显著优于现有方法。情感动态范围指标显示宽广的情感谱对吸引人的表演至关重要。

Conclusion: 提出的虚拟形象驱动框架成功解决了机器人唱歌的情感表达问题，通过人类先验知识和语义映射实现了丰富、连贯的情感表达，为共情人机交互提供了有效解决方案。

Abstract: Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.

</details>


### [105] [Differential Barometric Altimetry for Submeter Vertical Localization and Floor Recognition Indoors](https://arxiv.org/abs/2601.02184)
*Yuhang Zhang,Sören Schwertfeger*

Main category: cs.RO

TL;DR: 提出基于差分气压传感的低成本垂直估计框架，在ROS中实现实时高度数据发布，在复杂多楼层环境中实现亚米级垂直精度和100%楼层识别


<details>
  <summary>Details</summary>
Motivation: 移动机器人在复杂多楼层环境中的精确定位和导航需要准确的高度估计和可靠的楼层识别，而仅依赖视觉或LiDAR的SLAM里程计无法提供可靠的垂直定位

Method: 开发了基于差分气压传感的垂直估计框架，包含固定基站和移动传感器，通过ROS兼容软件包实时发布高度数据，利用气压差消除漂移

Result: 在封闭楼梯间和电梯等挑战性场景中，系统实现亚米级垂直精度（RMSE: 0.29米）和100%楼层识别成功率，优于仅使用视觉或LiDAR SLAM的方法

Conclusion: 差分气压模块为机器人垂直感知提供了实用且经济高效的解决方案，已开源发布，适用于实际机器人部署

Abstract: Accurate altitude estimation and reliable floor recognition are critical for mobile robot localization and navigation within complex multi-storey environments. In this paper, we present a robust, low-cost vertical estimation framework leveraging differential barometric sensing integrated within a fully ROS-compliant software package. Our system simultaneously publishes real-time altitude data from both a stationary base station and a mobile sensor, enabling precise and drift-free vertical localization. Empirical evaluations conducted in challenging scenarios -- such as fully enclosed stairwells and elevators, demonstrate that our proposed barometric pipeline achieves sub-meter vertical accuracy (RMSE: 0.29 m) and perfect (100%) floor-level identification. In contrast, our results confirm that standalone height estimates, obtained solely from visual- or LiDAR-based SLAM odometry, are insufficient for reliable vertical localization. The proposed ROS-compatible barometric module thus provides a practical and cost-effective solution for robust vertical awareness in real-world robotic deployments. The implementation of our method is released as open source at https://github.com/witsir/differential-barometric.

</details>


### [106] [CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding](https://arxiv.org/abs/2601.02295)
*Chenyang Ma,Guangyu Yang,Kai Lu,Shitong Xu,Bill Byrne,Niki Trigoni,Andrew Markham*

Main category: cs.RO

TL;DR: CycleVLA为视觉-语言-动作模型添加了主动自我纠正能力，能够在执行过程中预测即将发生的故障并在故障完全显现前进行恢复，而不是事后处理错误。


<details>
  <summary>Details</summary>
Motivation: 当前机器人故障检测和纠正方法通常采用事后处理方式，只在故障发生后分析错误并应用纠正。这种被动方法无法预防故障发生，导致执行效率低下。

Method: 1) 集成进度感知VLA来标记关键子任务转换点（故障最常发生的位置）；2) 基于VLM的故障预测器和规划器，在预测到故障时触发子任务回溯；3) 基于最小贝叶斯风险解码的测试时缩放策略，提高回溯后的重试成功率。

Result: 大量实验表明，CycleVLA提高了训练良好和训练不足的VLA的性能，并且MBR作为VLA的有效零样本测试时缩放策略。

Conclusion: CycleVLA通过主动故障预测和恢复机制，显著提升了VLA在实际执行中的鲁棒性和成功率，为机器人系统提供了更可靠的自主操作能力。

Abstract: Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/

</details>
