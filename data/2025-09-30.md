<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 108]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Mobile Robot Localization via Indoor Positioning System and Odometry Fusion](https://arxiv.org/abs/2509.22693)
*Muhammad Hafil Nugraha,Fauzi Abdul,Lastiko Bramantyo,Estiko Rijanto,Roni Permana Saputra,Oka Mahendra*

Main category: cs.RO

TL;DR: 该论文提出了一种通过传感器融合技术将超声波室内定位系统与轮式里程计数据相结合的移动机器人定位方法，使用扩展卡尔曼滤波器来提高定位精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在室内环境中，移动机器人的精确定位对于有效操作至关重要。需要解决单独使用超声波定位系统或轮式里程计时各自的局限性问题。

Method: 采用扩展卡尔曼滤波器（EKF）融合方法，将IPS传感器数据和机器人轮式里程计数据进行融合，利用两种方法的优势互补各自的不足。

Result: 在受控室内环境中的大量实验表明，融合定位系统相比独立系统显著提高了精度和准确性，EKF方法有效减少了轮子打滑和传感器噪声相关的误差。

Conclusion: 传感器融合方法通过结合超声波IPS和轮式里程计，为移动机器人提供了更鲁棒和可靠的室内定位解决方案。

Abstract: Accurate localization is crucial for effectively operating mobile robots in
indoor environments. This paper presents a comprehensive approach to mobile
robot localization by integrating an ultrasound-based indoor positioning system
(IPS) with wheel odometry data via sensor fusion techniques. The fusion
methodology leverages the strengths of both IPS and wheel odometry,
compensating for the individual limitations of each method. The Extended Kalman
Filter (EKF) fusion method combines the data from the IPS sensors and the
robot's wheel odometry, providing a robust and reliable localization solution.
Extensive experiments in a controlled indoor environment reveal that the
fusion-based localization system significantly enhances accuracy and precision
compared to standalone systems. The results demonstrate significant
improvements in trajectory tracking, with the EKF-based approach reducing
errors associated with wheel slippage and sensor noise.

</details>


### [2] [Nonlinear Model Predictive Control with Single-Shooting Method for Autonomous Personal Mobility Vehicle](https://arxiv.org/abs/2509.22694)
*Rakha Rahmadani Pratama,Catur Hilman A. H. B. Baskoro,Joga Dharma Setiawan,Dyah Kusuma Dewi,P Paryanto,Mochammad Ariyanto,Roni Permana Saputra*

Main category: cs.RO

TL;DR: 提出了一种基于非线性模型预测控制(NMPC)的单人电动自主运输车(SEATER)控制方法，使用单射击方法通过非线性规划解决最优控制问题，在Gazebo仿真环境中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为自主个人移动车辆开发有效的控制方法，使其能够在满足约束条件（如避障）的同时到达目标位置。

Method: 采用非线性模型预测控制(NMPC)和单射击方法，通过非线性规划解决最优控制问题，使用里程计数据进行定位反馈，在ROS框架中实现。

Result: 仿真结果表明，基于NMPC的方法成功控制车辆到达目标位置，同时满足约束条件，在无障碍和静态障碍环境中均表现良好。

Conclusion: 该研究证明了NMPC结合单射击方法在自主车辆控制中的鲁棒性和实时有效性，适用于评估的场景。

Abstract: This paper introduces a proposed control method for autonomous personal
mobility vehicles, specifically the Single-passenger Electric Autonomous
Transporter (SEATER), using Nonlinear Model Predictive Control (NMPC). The
proposed method leverages a single-shooting approach to solve the optimal
control problem (OCP) via non-linear programming (NLP). The proposed NMPC is
implemented to a non-holonomic vehicle with a differential drive system, using
odometry data as localization feedback to guide the vehicle towards its target
pose while achieving objectives and adhering to constraints, such as obstacle
avoidance. To evaluate the performance of the proposed method, a number of
simulations have been conducted in both obstacle-free and static obstacle
environments. The SEATER model and testing environment have been developed in
the Gazebo Simulation and the NMPC are implemented within the Robot Operating
System (ROS) framework. The simulation results demonstrate that the NMPC-based
approach successfully controls the vehicle to reach the desired target location
while satisfying the imposed constraints. Furthermore, this study highlights
the robustness and real-time effectiveness of NMPC with a single-shooting
approach for autonomous vehicle control in the evaluated scenarios.

</details>


### [3] [ReSeFlow: Rectifying SE(3)-Equivariant Policy Learning Flows](https://arxiv.org/abs/2509.22695)
*Zhitao Wang,Yanke Wang,Jiangtao Wen,Roberto Horowitz,Yuxing Han*

Main category: cs.RO

TL;DR: 提出了ReSeFlow方法，将整流流引入SE(3)等变扩散模型，实现快速、测地线一致且计算量最小的策略生成，在机器人操作任务中显著提升推理效率和性能。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人操作需要生成鲁棒的长时程轨迹级策略，SE(3)等变扩散模型具有数据效率优势，但存在推理时间成本高的问题。

Method: 将整流流技术引入SE(3)等变扩散模型，提出ReSeFlow方法，使用SE(3)等变网络保持旋转和平移对称性，实现快速策略生成。

Result: 在模拟基准测试中，ReSeFlow仅需一步推理就能达到比基线方法更好的性能，在绘画任务中误差减少48.5%，在旋转三角形任务中减少21.9%。

Conclusion: 该方法结合了SE(3)等变性和整流流的优势，为生成式策略学习模型在真实世界应用中的数据效率和推理效率提供了前进方向。

Abstract: Robotic manipulation in unstructured environments requires the generation of
robust and long-horizon trajectory-level policy with conditions of perceptual
observations and benefits from the advantages of SE(3)-equivariant diffusion
models that are data-efficient. However, these models suffer from the inference
time costs. Inspired by the inference efficiency of rectified flows, we
introduce the rectification to the SE(3)-diffusion models and propose the
ReSeFlow, i.e., Rectifying SE(3)-Equivariant Policy Learning Flows, providing
fast, geodesic-consistent, least-computational policy generation. Crucially,
both components employ SE(3)-equivariant networks to preserve rotational and
translational symmetry, enabling robust generalization under rigid-body
motions. With the verification on the simulated benchmarks, we find that the
proposed ReSeFlow with only one inference step can achieve better performance
with lower geodesic distance than the baseline methods, achieving up to a 48.5%
error reduction on the painting task and a 21.9% reduction on the rotating
triangle task compared to the baseline's 100-step inference. This method takes
advantages of both SE(3) equivariance and rectified flow and puts it forward
for the real-world application of generative policy learning models with the
data and inference efficiency.

</details>


### [4] [Advancing Audio-Visual Navigation Through Multi-Agent Collaboration in 3D Environments](https://arxiv.org/abs/2509.22698)
*Hailong Zhang,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.RO

TL;DR: MASTAVN是一个多代理可扩展的音频-视觉导航框架，使两个代理能够在共享的3D环境中协作定位和导航到音频目标，通过跨代理通信协议和联合音频-视觉融合机制显著提高了任务完成效率和导航成功率。


<details>
  <summary>Details</summary>
Motivation: 现有音频-视觉导航研究主要关注单代理系统，在动态3D环境中存在局限性，特别是在紧急响应等时间敏感应用中需要快速多代理协调。

Method: MASTAVN集成了跨代理通信协议和联合音频-视觉融合机制，增强了空间推理和时间同步能力。

Result: 在真实感3D模拟器（Replica和Matterport3D）中的严格评估显示，与单代理和非协作基线相比，MASTAVN显著减少了任务完成时间并显著提高了导航成功率。

Conclusion: 研究结果验证了MASTAVN在时间敏感紧急场景中的有效性，并为推进复杂3D环境中可扩展多代理体现智能建立了范式。

Abstract: Intelligent agents often require collaborative strategies to achieve complex
tasks beyond individual capabilities in real-world scenarios. While existing
audio-visual navigation (AVN) research mainly focuses on single-agent systems,
their limitations emerge in dynamic 3D environments where rapid multi-agent
coordination is critical, especially for time-sensitive applications like
emergency response. This paper introduces MASTAVN (Multi-Agent Scalable
Transformer Audio-Visual Navigation), a scalable framework enabling two agents
to collaboratively localize and navigate toward an audio target in shared 3D
environments. By integrating cross-agent communication protocols and joint
audio-visual fusion mechanisms, MASTAVN enhances spatial reasoning and temporal
synchronization. Through rigorous evaluation in photorealistic 3D simulators
(Replica and Matterport3D), MASTAVN achieves significant reductions in task
completion time and notable improvements in navigation success rates compared
to single-agent and non-collaborative baselines. This highlights the essential
role of spatiotemporal coordination in multi-agent systems. Our findings
validate MASTAVN's effectiveness in time-sensitive emergency scenarios and
establish a paradigm for advancing scalable multi-agent embodied intelligence
in complex 3D environments.

</details>


### [5] [Large Language Models for 3D IC Space Planning](https://arxiv.org/abs/2509.22716)
*Hung-Ying Chu,Guan-Wei Chen,Shao-Yu Wei,Yu-Cheng Lin*

Main category: cs.RO

TL;DR: 本研究探讨了使用大语言模型进行3D IC空间规划的方法，通过后序切片树表示保证合法空间布局，旨在减少死空间。实验表明该方法在运行效率、合法性和死空间减少方面取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 随着3D集成电路设计复杂性增加，有效的空间规划对于减少死空间和确保布局质量变得至关重要。传统EDA方法面临扩展性挑战，需要数据驱动的补充方案。

Method: 使用大语言模型进行3D IC空间规划，采用后序切片树表示法保证布局合法性，在大规模合成数据集上微调开源LLMs，并在MCNC衍生的3D基准上进行评估。

Result: 提出的框架在运行效率、合法性和死空间减少之间达到良好平衡，在实用运行预算下，相当一部分测试案例实现了零死空间布局。方法可推广到MCNC案例如ami33和ami49，但较大和不规则实例仍具挑战性。

Conclusion: 基于LLM的空间规划可以作为传统电子设计自动化方法的数据驱动补充，为可扩展的3D布局生成提供新见解，并具有跨领域应用的潜力。

Abstract: Three-dimensional integrated circuits (3D ICs) have emerged as a promising
solution to the scaling limits of two-dimensional designs, offering higher
integration density, shorter interconnects, and improved performance. As design
complexity increases, effective space planning becomes essential to reduce dead
space and ensure layout quality. This study investigates the use of large
language models (LLMs) for 3D IC space planning through a post-order slicing
tree representation, which guarantees legal space plans while aiming to
minimize dead space. Open-source LLMs were fine-tuned on large-scale synthetic
datasets and further evaluated on MCNC-derived 3D benchmarks. Experimental
results indicate that the proposed framework achieves a favorable balance
between runtime efficiency, legality, and dead-space reduction, with
zero-dead-space layouts obtained in a significant portion of test cases under
practical runtime budgets. Beyond synthetic benchmarks, the method generalizes
to MCNC cases such as ami33 and ami49, though larger and irregular instances
remain challenging. The approach also shows potential for cross-domain
applications, including logistics and 3D object placement, where spatial
efficiency is critical. Overall, the results suggest that LLM-based space
planning can serve as a data-driven complement to traditional electronic design
automation (EDA) methods, providing new insights for scalable 3D layout
generation.

</details>


### [6] [Self-driving cars: Are we there yet?](https://arxiv.org/abs/2509.22754)
*Merve Atasever,Zhuochen Liu,Qingpei Li,Akshay Hitendra Shah,Hans Walker,Jyotirmoy V. Deshmukh,Rahul Jain*

Main category: cs.RO

TL;DR: 本文对CARLA、nuPlan和Waymo Open Dataset三个自动驾驶规划算法排行榜中的方法进行了比较分析，使用CARLA leaderboard v2.0作为统一评估平台，识别当前方法的优缺点和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要标准化的评估平台来比较不同运动规划算法，但目前多个排行榜各有特点，缺乏统一的比较框架。

Method: 采用CARLA leaderboard v2.0作为统一评估平台，对三个排行榜中的规划方法进行兼容性修改后进行综合比较分析。

Result: 通过比较分析揭示了当前运动规划方法的优势和不足，识别了主流趋势和共同挑战。

Conclusion: 研究为自动驾驶运动规划领域提供了有价值的见解，指出了未来研究的发展方向。

Abstract: Autonomous driving remains a highly active research domain that seeks to
enable vehicles to perceive dynamic environments, predict the future
trajectories of traffic agents such as vehicles, pedestrians, and cyclists and
plan safe and efficient future motions. To advance the field, several
competitive platforms and benchmarks have been established to provide
standardized datasets and evaluation protocols. Among these, leaderboards by
the CARLA organization and nuPlan and the Waymo Open Dataset have become
leading benchmarks for assessing motion planning algorithms. Each offers a
unique dataset and challenging planning problems spanning a wide range of
driving scenarios and conditions. In this study, we present a comprehensive
comparative analysis of the motion planning methods featured on these three
leaderboards. To ensure a fair and unified evaluation, we adopt CARLA
leaderboard v2.0 as our common evaluation platform and modify the selected
models for compatibility. By highlighting the strengths and weaknesses of
current approaches, we identify prevailing trends, common challenges, and
suggest potential directions for advancing motion planning research.

</details>


### [7] [Persistent Autoregressive Mapping with Traffic Rules for Autonomous Driving](https://arxiv.org/abs/2509.22756)
*Shiyi Liang,Xinyuan Chang,Changjie Wu,Huiyuan Yan,Yifan Bai,Xinran Liu,Hang Zhang,Yujian Yuan,Shuang Zeng,Mu Xu,Xing Wei*

Main category: cs.RO

TL;DR: PAMR是一个新颖的自动驾驶框架，通过自回归方式联合构建车道向量和交通规则，解决了现有方法无法在长时间驾驶序列中保持规则持续有效性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只关注几何元素，要么将交通规则视为临时分类，无法在交通标志不可见时保持规则的持续有效性，这对安全自动驾驶至关重要。

Method: 提出PAMR框架，包含两个关键机制：Map-Rule Co-Construction用于处理时间片段中的驾驶场景，Map-Rule Cache用于跨片段保持规则一致性。

Result: 在联合向量-规则映射任务中表现出优越性能，能够在长时间驾驶序列中保持规则的持续有效性。

Conclusion: PAMR框架成功解决了交通规则在长时间驾驶序列中的持续有效性问题，为安全自动驾驶提供了重要支撑。

Abstract: Safe autonomous driving requires both accurate HD map construction and
persistent awareness of traffic rules, even when their associated signs are no
longer visible. However, existing methods either focus solely on geometric
elements or treat rules as temporary classifications, failing to capture their
persistent effectiveness across extended driving sequences. In this paper, we
present PAMR (Persistent Autoregressive Mapping with Traffic Rules), a novel
framework that performs autoregressive co-construction of lane vectors and
traffic rules from visual observations. Our approach introduces two key
mechanisms: Map-Rule Co-Construction for processing driving scenes in temporal
segments, and Map-Rule Cache for maintaining rule consistency across these
segments. To properly evaluate continuous and consistent map generation, we
develop MapDRv2, featuring improved lane geometry annotations. Extensive
experiments demonstrate that PAMR achieves superior performance in joint
vector-rule mapping tasks, while maintaining persistent rule effectiveness
throughout extended driving sequences.

</details>


### [8] [Towards Developing Standards and Guidelines for Robot Grasping and Manipulation Pipelines in the COMPARE Ecosystem](https://arxiv.org/abs/2509.22801)
*Huajing Zhao,Brian Flynn,Adam Norton,Holly Yanco*

Main category: cs.RO

TL;DR: COMPARE生态系统通过开发组件级和流水线级标准指南，旨在提升机器人操作开源产品的兼容性和基准测试能力。


<details>
  <summary>Details</summary>
Motivation: 改善机器人操作开源产品的兼容性和基准测试能力，通过标准化模块化实践来促进不同组件和流水线的互操作性。

Method: 1) 构建开源产品库识别流水线中各组件的共同特征；2) 研究现有模块化流水线以获取最佳实践；3) 开发符合标准的新模块化流水线。

Result: 正在进行的工作包括构建产品库、分析现有流水线实践，并开发符合标准的新模块化流水线。

Conclusion: COMPARE生态系统通过标准化和模块化实践，有望显著提升机器人操作系统的兼容性和基准测试能力。

Abstract: The COMPARE Ecosystem aims to improve the compatibility and benchmarking of
open-source products for robot manipulation through a series of activities. One
such activity is the development of standards and guidelines to specify
modularization practices at the component-level for individual modules (e.g.,
perception, grasp planning, motion planning) and integrations of components
that form robot manipulation capabilities at the pipeline-level. This paper
briefly reviews our work-in-progress to date to (1) build repositories of
open-source products to identify common characteristics of each component in
the pipeline, (2) investigate existing modular pipelines to glean best
practices, and (3) develop new modular pipelines that advance prior work while
abiding by the proposed standards and guidelines.

</details>


### [9] [Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots](https://arxiv.org/abs/2509.22815)
*Ruturaj Sambhus,Muneeb Ahmad,Basit Muhammad Imran,Sujith Vijayan,Dylan P. Losey,Kaveh Akbari Hamed*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人共享自主权的自适应非线性模型预测控制框架，通过在线学习人类意图参数和集成控制屏障函数约束，实现安全的人机协作避障。


<details>
  <summary>Details</summary>
Motivation: 传统共享控制方法使用固定的混合策略，无法捕捉腿式机器人的动态特性，可能危及安全。需要开发能够适应人类行为不确定性的安全关键控制框架。

Method: 采用分层控制架构：高层CBF-ANMPC（10Hz）生成混合速度参考，中层动态感知NMPC（60Hz）跟踪参考，低层非线性全身控制器（500Hz）执行完整动态跟踪。使用Boltzmann模型在线学习人类意图参数。

Result: 在Unitree Go2四足机器人上的数值和硬件实验验证了框架的有效性，实现了实时避障、在线学习人类意图参数和安全的人机协作。

Conclusion: 该框架通过自适应学习和安全约束，显著提升了腿式机器人在共享自主权环境中的安全性和协作效果。

Abstract: Ensuring safe and effective collaboration between humans and autonomous
legged robots is a fundamental challenge in shared autonomy, particularly for
teleoperated systems navigating cluttered environments. Conventional
shared-control approaches often rely on fixed blending strategies that fail to
capture the dynamics of legged locomotion and may compromise safety. This paper
presents a teleoperator-aware, safety-critical, adaptive nonlinear model
predictive control (ANMPC) framework for shared autonomy of quadrupedal robots
in obstacle-avoidance tasks. The framework employs a fixed arbitration weight
between human and robot actions but enhances this scheme by modeling the human
input with a noisily rational Boltzmann model, whose parameters are adapted
online using a projected gradient descent (PGD) law from observed joystick
commands. Safety is enforced through control barrier function (CBF) constraints
integrated into a computationally efficient NMPC, ensuring forward invariance
of safe sets despite uncertainty in human behavior. The control architecture is
hierarchical: a high-level CBF-based ANMPC (10 Hz) generates blended
human-robot velocity references, a mid-level dynamics-aware NMPC (60 Hz)
enforces reduced-order single rigid body (SRB) dynamics to track these
references, and a low-level nonlinear whole-body controller (500 Hz) imposes
the full-order dynamics via quadratic programming to track the mid-level
trajectories. Extensive numerical and hardware experiments, together with a
user study, on a Unitree Go2 quadrupedal robot validate the framework,
demonstrating real-time obstacle avoidance, online learning of human intent
parameters, and safe teleoperator collaboration.

</details>


### [10] [Parameter Identification of a Differentiable Human Arm Musculoskeletal Model without Deep Muscle EMG Reconstruction](https://arxiv.org/abs/2509.22825)
*Philip Sanderink,Yingfan Zhou,Shuzhen Luo,Cheng Fang*

Main category: cs.RO

TL;DR: 提出了一种无需重建深层肌肉EMG信号即可同时识别人体手臂骨骼和浅层肌肉参数的方法，通过可微分优化框架实现参数识别。


<details>
  <summary>Details</summary>
Motivation: 当前基于EMG的个性化肌肉骨骼模型参数识别方法受限于深层肌肉EMG信号难以无创测量，现有重建方法因对深层肌肉行为的假设而可靠性有限。

Method: 使用深层肌肉力的最小二乘解计算模型参数的损失梯度，在可微分优化框架中识别参数，无需重建深层肌肉EMG信号。

Result: 广泛的对比仿真结果表明，该方法能达到与使用所有肌肉EMG信号的类似方法相当的估计精度。

Conclusion: 该方法能够有效识别肌肉骨骼模型参数，避免了深层肌肉EMG测量的困难，为物理协作机器人系统开发提供了可靠工具。

Abstract: Accurate parameter identification of a subject-specific human musculoskeletal
model is crucial to the development of safe and reliable physically
collaborative robotic systems, for instance, assistive exoskeletons.
Electromyography (EMG)-based parameter identification methods have demonstrated
promising performance for personalized musculoskeletal modeling, whereas their
applicability is limited by the difficulty of measuring deep muscle EMGs
invasively. Although several strategies have been proposed to reconstruct deep
muscle EMGs or activations for parameter identification, their reliability and
robustness are limited by assumptions about the deep muscle behavior. In this
work, we proposed an approach to simultaneously identify the bone and
superficial muscle parameters of a human arm musculoskeletal model without
reconstructing the deep muscle EMGs. This is achieved by only using the
least-squares solution of the deep muscle forces to calculate a loss gradient
with respect to the model parameters for identifying them in a framework of
differentiable optimization. The results of extensive comparative simulations
manifested that our proposed method can achieve comparable estimation accuracy
compared to a similar method, but with all the muscle EMGs available.

</details>


### [11] [Dynamic Buffers: Cost-Efficient Planning for Tabletop Rearrangement with Stacking](https://arxiv.org/abs/2509.22828)
*Arman Barghi,Hamed Hosseini,Seraj Ghasemi,Mehdi Tale Masouleh,Ahmad Kalhor*

Main category: cs.RO

TL;DR: 提出动态缓冲器作为新的规划原语，允许机器人形成临时可移动的堆叠，提高密集环境下的重排效率和可行性。


<details>
  <summary>Details</summary>
Motivation: 传统规划器在杂乱桌面环境中效率低下，使用固定缓冲区导致高成本计划。静态堆叠限制了效率，因为一旦物体支撑另一个，基座就无法移动。

Method: 引入动态缓冲器规划原语，允许形成临时可移动的堆叠，这些堆叠可以作为整体运输，类似于人类的分组策略。

Result: 与最先进的重排规划器相比，在密集场景中减少机械臂移动成本11.89%，在大型低密度设置中减少5.69%。在Delta并联机器人上验证了实用性。

Conclusion: 动态缓冲是成本高效和稳健重排规划的关键原语，显著提高了密集布局的可行性和效率。

Abstract: Rearranging objects in cluttered tabletop environments remains a
long-standing challenge in robotics. Classical planners often generate
inefficient, high-cost plans by shuffling objects individually and using fixed
buffers--temporary spaces such as empty table regions or static stacks--to
resolve conflicts. When only free table locations are used as buffers, dense
scenes become inefficient, since placing an object can restrict others from
reaching their goals and complicate planning. Allowing stacking provides extra
buffer capacity, but conventional stacking is static: once an object supports
another, the base cannot be moved, which limits efficiency. To overcome these
issues, a novel planning primitive called the Dynamic Buffer is introduced.
Inspired by human grouping strategies, it enables robots to form temporary,
movable stacks that can be transported as a unit. This improves both
feasibility and efficiency in dense layouts, and it also reduces travel in
large-scale settings where space is abundant. Compared with a state-of-the-art
rearrangement planner, the approach reduces manipulator travel cost by 11.89%
in dense scenarios with a stationary robot and by 5.69% in large, low-density
settings with a mobile manipulator. Practicality is validated through
experiments on a Delta parallel robot with a two-finger gripper. These findings
establish dynamic buffering as a key primitive for cost-efficient and robust
rearrangement planning.

</details>


### [12] [Empart: Interactive Convex Decomposition for Converting Meshes to Parts](https://arxiv.org/abs/2509.22847)
*Brandon Vu,Shameek Ganguly,Pushkar Joshi*

Main category: cs.RO

TL;DR: Empart是一个交互式工具，允许用户为网格的不同区域指定不同的简化容差，通过区域特定的约束优化凸分解，显著减少凸部分数量并提升模拟性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整个网格上应用统一的误差容差，导致在非关键区域过度细化或在关键区域细节不足，无法在精度和性能之间实现最优权衡。

Method: 利用现有凸分解算法作为子程序，采用新颖的并行化框架高效处理区域特定约束，提供带有视觉反馈的用户友好界面。

Result: 在固定误差阈值下，相比最先进方法(V-HACD)显著减少凸部分数量，在机器人拾放任务中将整体模拟时间减少69%。

Conclusion: 交互式、区域特定的简化对于高性能机器人应用具有重要价值，能够实现更好的精度-性能权衡。

Abstract: Simplifying complex 3D meshes is a crucial step in robotics applications to
enable efficient motion planning and physics simulation. Common methods, such
as approximate convex decomposition, represent a mesh as a collection of simple
parts, which are computationally inexpensive to simulate. However, existing
approaches apply a uniform error tolerance across the entire mesh, which can
result in a sub-optimal trade-off between accuracy and performance. For
instance, a robot grasping an object needs high-fidelity geometry in the
vicinity of the contact surfaces but can tolerate a coarser simplification
elsewhere. A uniform tolerance can lead to excessive detail in non-critical
areas or insufficient detail where it's needed most.
  To address this limitation, we introduce Empart, an interactive tool that
allows users to specify different simplification tolerances for selected
regions of a mesh. Our method leverages existing convex decomposition
algorithms as a sub-routine but uses a novel, parallelized framework to handle
region-specific constraints efficiently. Empart provides a user-friendly
interface with visual feedback on approximation error and simulation
performance, enabling designers to iteratively refine their decomposition. We
demonstrate that our approach significantly reduces the number of convex parts
compared to a state-of-the-art method (V-HACD) at a fixed error threshold,
leading to substantial speedups in simulation performance. For a robotic
pick-and-place task, Empart-generated collision meshes reduced the overall
simulation time by 69% compared to a uniform decomposition, highlighting the
value of interactive, region-specific simplification for performant robotics
applications.

</details>


### [13] [Multi-Robot Allocation for Information Gathering in Non-Uniform Spatiotemporal Environments](https://arxiv.org/abs/2509.22883)
*Kaleb Ben Naveed,Haejoon Lee,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出一个两阶段多机器人场估计框架，通过变差函数驱动的规划器学习区域特定的空间长度尺度，并基于不确定性重新分配机器人来更新时间长度尺度。


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程方法通常假设全局长度尺度或仅定期更新，有些允许空间变化但忽略时间变化，导致不确定性估计不准确。

Method: 两阶段框架：第一阶段使用变差函数驱动的规划器学习区域特定的空间长度尺度；第二阶段采用分配策略，基于当前不确定性重新分配机器人，并在细化时间长度尺度时更新采样。

Result: 在多样化环境中评估了所提方法，提供了空间长度尺度估计的收敛性分析，以及量化与oracle分配序列差距的动态遗憾界限。

Conclusion: 该框架能够有效处理非均匀时空环境中的场估计问题，通过区域特定的长度尺度学习和动态机器人分配提高估计精度。

Abstract: Autonomous robots are increasingly deployed to estimate spatiotemporal fields
(e.g., wind, temperature, gas concentration) that vary across space and time.
We consider environments divided into non-overlapping regions with distinct
spatial and temporal dynamics, termed non-uniform spatiotemporal environments.
Gaussian Processes (GPs) can be used to estimate these fields. The GP model
depends on a kernel that encodes how the field co-varies in space and time,
with its spatial and temporal lengthscales defining the correlation. Hence,
when these lengthscales are incorrect or do not correspond to the actual field,
the estimates of uncertainty can be highly inaccurate. Existing GP methods
often assume one global lengthscale or update only periodically; some allow
spatial variation but ignore temporal changes. To address these limitations, we
propose a two-phase framework for multi-robot field estimation. Phase 1 uses a
variogram-driven planner to learn region-specific spatial lengthscales. Phase 2
employs an allocation strategy that reassigns robots based on the current
uncertainty, and updates sampling as temporal lengthscales are refined. For
encoding uncertainty, we utilize clarity, an information metric from our
earlier work. We evaluate the proposed method across diverse environments and
provide convergence analysis for spatial lengthscale estimation, along with
dynamic regret bounds quantifying the gap to the oracle's allocation sequence.

</details>


### [14] [Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM](https://arxiv.org/abs/2509.22910)
*Yanwei Du,Jing-Chen Peng,Patricio A. Vela*

Main category: cs.RO

TL;DR: Good Weights算法通过自适应融合航位推算和视觉SLAM，在视觉退化环境中提供连续准确的姿态估计


<details>
  <summary>Details</summary>
Motivation: 视觉SLAM在纹理缺失或视觉退化环境中表现不佳，而机器人通常配备的航位推算传感器短期性能良好但长期不可靠

Method: 开发自适应权重框架，根据视觉跟踪可靠性动态调整航位推算的融合权重，并修改SLAM系统所有模块以集成航位推算

Result: 在收集的数据集和实际部署中，Good Weights提高了视觉SLAM的性能和鲁棒性

Conclusion: Good Weights为移动导航提供了实用解决方案，能在视觉不可靠时保持姿态跟踪而不过度依赖航位推算

Abstract: Given that Visual SLAM relies on appearance cues for localization and scene
understanding, texture-less or visually degraded environments (e.g., plain
walls or low lighting) lead to poor pose estimation and track loss. However,
robots are typically equipped with sensors that provide some form of dead
reckoning odometry with reasonable short-time performance but unreliable
long-time performance. The Good Weights (GW) algorithm described here provides
a framework to adaptively integrate dead reckoning (DR) with passive visual
SLAM for continuous and accurate frame-level pose estimation. Importantly, it
describes how all modules in a comprehensive SLAM system must be modified to
incorporate DR into its design. Adaptive weighting increases DR influence when
visual tracking is unreliable and reduces when visual feature information is
strong, maintaining pose track without overreliance on DR. Good Weights yields
a practical solution for mobile navigation that improves visual SLAM
performance and robustness. Experiments on collected datasets and in real-world
deployment demonstrate the benefits of Good Weights.

</details>


### [15] [ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality](https://arxiv.org/abs/2509.22914)
*Rohan Walia,Yusheng Wang,Ralf Römer,Masahiro Nishio,Angela P. Schoellig,Jun Ota*

Main category: cs.RO

TL;DR: ARMimic是一个轻量级框架，仅使用消费级XR头显和固定工作场所摄像头，通过集成手部追踪、AR机器人叠加和实时深度感知，实现无机器人、可扩展的演示数据收集。


<details>
  <summary>Details</summary>
Motivation: 传统机器人技能模仿学习方法（如动觉教学和遥操作）笨重、硬件密集且干扰工作流程，而现有XR方法需要额外硬件、复杂校准或受限记录条件，限制了可扩展性和可用性。

Method: 集成XR头显的自我中心手部追踪、AR机器人叠加和实时深度感知，确保碰撞感知和运动学可行的演示。统一模仿学习管道将人类和虚拟机器人轨迹视为可互换的。

Result: 在两个操作任务（包括具有挑战性的长时域碗堆叠）上验证，ARMimic相比遥操作减少50%演示时间，相比最先进基线ACT提高11%任务成功率。

Conclusion: ARMimic实现了安全、无缝的野外数据收集，为多样化真实世界场景中的可扩展机器人学习提供了巨大潜力。

Abstract: Imitation learning is a powerful paradigm for robot skill acquisition, yet
conventional demonstration methods--such as kinesthetic teaching and
teleoperation--are cumbersome, hardware-heavy, and disruptive to workflows.
Recently, passive observation using extended reality (XR) headsets has shown
promise for egocentric demonstration collection, yet current approaches require
additional hardware, complex calibration, or constrained recording conditions
that limit scalability and usability. We present ARMimic, a novel framework
that overcomes these limitations with a lightweight and hardware-minimal setup
for scalable, robot-free data collection using only a consumer XR headset and a
stationary workplace camera. ARMimic integrates egocentric hand tracking,
augmented reality (AR) robot overlays, and real-time depth sensing to ensure
collision-aware, kinematically feasible demonstrations. A unified imitation
learning pipeline is at the core of our method, treating both human and virtual
robot trajectories as interchangeable, which enables policies that generalize
across different embodiments and environments. We validate ARMimic on two
manipulation tasks, including challenging long-horizon bowl stacking. In our
experiments, ARMimic reduces demonstration time by 50% compared to
teleoperation and improves task success by 11% over ACT, a state-of-the-art
baseline trained on teleoperated data. Our results demonstrate that ARMimic
enables safe, seamless, and in-the-wild data collection, offering great
potential for scalable robot learning in diverse real-world settings.

</details>


### [16] [DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent Autonomous Racing Overtakes](https://arxiv.org/abs/2509.22937)
*Trent Weiss,Amar Kulkarni,Madhur Behl*

Main category: cs.RO

TL;DR: 提出基于扩展差分贝叶斯滤波框架的轨迹合成方法，用于自主赛车超车场景，将问题构建为在复合贝齐尔曲线空间上的贝叶斯推断问题


<details>
  <summary>Details</summary>
Motivation: 自主赛车超车是一个重大挑战，现有优化技术和图方法通常依赖过度简化的碰撞避免和动态约束假设

Method: 采用差分贝叶斯滤波框架，将无碰撞轨迹合成问题构建为复合贝齐尔曲线空间上的贝叶斯推断问题，无需导数、球形车辆足迹近似、约束线性化或简化碰撞避免上界

Result: 闭环分析显示DBF-MA方法在87%的测试场景中成功超车，在自主超车方面优于现有方法

Conclusion: 该方法为复杂赛道上的自主超车提供了有效的轨迹合成解决方案

Abstract: A significant challenge in autonomous racing is to generate overtaking
maneuvers. Racing agents must execute these maneuvers on complex racetracks
with little room for error. Optimization techniques and graph-based methods
have been proposed, but these methods often rely on oversimplified assumptions
for collision-avoidance and dynamic constraints. In this work, we present an
approach to trajectory synthesis based on an extension of the Differential
Bayesian Filtering framework. Our approach for collision-free trajectory
synthesis frames the problem as one of Bayesian Inference over the space of
Composite Bezier Curves. Our method is derivative-free, does not require a
spherical approximation of the vehicle footprint, linearization of constraints,
or simplifying upper bounds on collision avoidance. We conduct a closed-loop
analysis of DBF-MA and find it successfully overtakes an opponent in 87% of
tested scenarios, outperforming existing methods in autonomous overtaking.

</details>


### [17] [Hierarchical Control Design for Space Robots with Application to In-Orbit Servicing Missions](https://arxiv.org/abs/2509.22955)
*Pietro Bruschi*

Main category: cs.RO

TL;DR: 提出了一种用于自主捕获空间翻滚物体的分层控制框架，结合了李雅普诺夫鲁棒控制和扩展逆运动学问题求解。


<details>
  <summary>Details</summary>
Motivation: 在轨服务和主动碎片清除需要先进的机器人能力来捕获和稳定非合作目标，特别是考虑空间机器人中很少研究的燃料晃动动力学效应。

Method: 开发了包含燃料晃动动力学的仿真环境，提出了分层控制器：内环使用基于李雅普诺夫的鲁棒控制处理多体动力学，外环解决扩展逆运动学问题。

Result: 仿真结果表明，与现有控制方案相比，该方法具有更好的鲁棒性和适应性。

Conclusion: 该分层控制框架能够有效处理空间机器人捕获翻滚物体时的复杂动力学问题，特别是燃料晃动效应，为在轨服务和碎片清除提供了更可靠的解决方案。

Abstract: In-Orbit Servicing and Active Debris Removal require advanced robotic
capabilities for capturing and detumbling uncooperative targets. This work
presents a hierarchical control framework for autonomous robotic capture of
tumbling objects in space. A simulation environment is developed, incorporating
sloshing dynamics of the chaser, a rarely studied effect in space robotics. The
proposed controller combines an inner Lyapunov-based robust control loop for
multi-body dynamics with an outer loop addressing an extended inverse
kinematics problem. Simulation results show improved robustness and
adaptability compared to existing control schemes.

</details>


### [18] [Robot Learning from Any Images](https://arxiv.org/abs/2509.22970)
*Siheng Zhao,Jiageng Mao,Wei Chow,Zeyu Shangguan,Tianheng Shi,Rong Xue,Yuxi Zheng,Yijia Weng,Yang You,Daniel Seita,Leonidas Guibas,Sergey Zakharov,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: RoLA框架可将任意图像转换为支持物理交互的机器人环境，无需额外硬件或数字资产，实现快速的大规模机器人数据生成。


<details>
  <summary>Details</summary>
Motivation: 解决传统机器人数据生成方法需要额外硬件或数字资产的问题，实现从单一图像直接生成交互式物理环境的能力。

Method: 结合单视角物理场景恢复方法和高效视觉融合策略，从相机拍摄、机器人数据集和网络图像等来源生成逼真数据。

Result: 展示了在可扩展机器人数据生成、从网络图像学习机器人技能以及单图像实-仿-实系统等多个应用中的有效性。

Conclusion: RoLA框架能够民主化机器人数据生成，在几分钟内从各种图像源产生大量视觉运动机器人演示数据。

Abstract: We introduce RoLA, a framework that transforms any in-the-wild image into an
interactive, physics-enabled robotic environment. Unlike previous methods, RoLA
operates directly on a single image without requiring additional hardware or
digital assets. Our framework democratizes robotic data generation by producing
massive visuomotor robotic demonstrations within minutes from a wide range of
image sources, including camera captures, robotic datasets, and Internet
images. At its core, our approach combines a novel method for single-view
physical scene recovery with an efficient visual blending strategy for
photorealistic data collection. We demonstrate RoLA's versatility across
applications like scalable robotic data generation and augmentation, robot
learning from Internet images, and single-image real-to-sim-to-real systems for
manipulators and humanoids. Video results are available at
https://sihengz02.github.io/RoLA .

</details>


### [19] [Safe Task Space Synchronization with Time-Delayed Information](https://arxiv.org/abs/2509.22976)
*Rounak Bhattacharya,Vrithik R. Guthikonda,Ashwin P. Dani*

Main category: cs.RO

TL;DR: 设计了一种自适应控制器，用于在存在通信时延的情况下实现机器人轨迹与人类轨迹的同步，同时确保安全约束。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人协作任务中，通信时延（如传感器处理、网络延迟等）会影响轨迹同步，需要开发能够处理未知运动学和动力学且保证安全的自适应控制器。

Method: 使用障碍Lyapunov函数(BLF)约束笛卡尔坐标确保安全，采用ICL自适应律处理未知运动学，梯度自适应律估计未知动力学，使用障碍Lyapunov-Krasovskii函数进行稳定性分析。

Result: 仿真结果表明，设计的同步控制器在存在时延的情况下有效实现了轨迹同步，同时满足安全约束。

Conclusion: 提出的自适应控制器能够处理通信时延、未知运动学和动力学，在人类-机器人同步场景中实现安全有效的轨迹跟踪。

Abstract: In this paper, an adaptive controller is designed for the synchronization of
the trajectory of a robot with unknown kinematics and dynamics to that of the
current human trajectory in the task space using the delayed human trajectory
information. The communication time delay may be a result of various factors
that arise in human-robot collaboration tasks, such as sensor processing or
fusion to estimate trajectory/intent, network delays, or computational
limitations. The developed adaptive controller uses Barrier Lyapunov Function
(BLF) to constrain the Cartesian coordinates of the robot to ensure safety, an
ICL-based adaptive law to account for the unknown kinematics, and a
gradient-based adaptive law to estimate unknown dynamics. Barrier
Lyapunov-Krasovskii (LK) functionals are used for the stability analysis to
show that the synchronization and parameter estimation errors remain
semi-globally uniformly ultimately bounded (SGUUB). The simulation results
based on a human-robot synchronization scenario with time delay are provided to
demonstrate the effectiveness of the designed synchronization controller with
safety constraints.

</details>


### [20] [UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes](https://arxiv.org/abs/2509.23021)
*Xiao Hu,Qi Yin,Yangming Shi,Yang Ye*

Main category: cs.RO

TL;DR: UniPrototype框架通过共享运动基元实现从人类到机器人领域的知识迁移，解决了机器人学习中数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 机器人操作面临训练数据稀缺的挑战，而人类演示数据丰富。为了弥合人类与机器人操作能力之间的差距，需要有效的知识迁移方法。

Method: 提出UniPrototype框架，包含三个关键贡献：1）具有软分配的复合原型发现机制，允许多个基元共同激活以捕捉混合和分层技能；2）自适应原型选择策略，自动调整原型数量以匹配任务复杂性；3）在仿真环境和真实机器人系统中进行广泛实验验证。

Result: UniPrototype成功将人类操作知识迁移到机器人，相比现有方法显著提高了学习效率和任务性能。

Conclusion: 该框架为解决机器人学习中的数据稀缺问题提供了有效方案，通过人类知识迁移显著提升了机器人操作能力。

Abstract: Data scarcity remains a fundamental challenge in robot learning. While human
demonstrations benefit from abundant motion capture data and vast internet
resources, robotic manipulation suffers from limited training examples. To
bridge this gap between human and robot manipulation capabilities, we propose
UniPrototype, a novel framework that enables effective knowledge transfer from
human to robot domains via shared motion primitives. ur approach makes three
key contributions: (1) We introduce a compositional prototype discovery
mechanism with soft assignments, enabling multiple primitives to co-activate
and thus capture blended and hierarchical skills; (2) We propose an adaptive
prototype selection strategy that automatically adjusts the number of
prototypes to match task complexity, ensuring scalable and efficient
representation; (3) We demonstrate the effectiveness of our method through
extensive experiments in both simulation environments and real-world robotic
systems. Our results show that UniPrototype successfully transfers human
manipulation knowledge to robots, significantly improving learning efficiency
and task performance compared to existing approaches.The code and dataset will
be released upon acceptance at an anonymous repository.

</details>


### [21] [RAISE: A Robot-Assisted Selective Disassembly and Sorting System for End-of-Life Phones](https://arxiv.org/abs/2509.23048)
*Chang Liu,Badrinath Balasubramaniam,Neal Yancey,Michael Severson,Adam Shine,Philip Bove,Beiwen Li,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出低成本、易部署的自动化选择性拆解系统，用于废弃手机回收，包含自适应切割、视觉机器人分拣和电池移除三个子系统，每小时可处理120+部手机，成功率98.9%。


<details>
  <summary>Details</summary>
Motivation: 废弃手机因产量高、生命周期短而加剧全球电子垃圾问题，人工拆解劳动密集且耗时，需要自动化解决方案。

Method: 开发包含自适应切割系统、基于视觉的机器人分拣系统和电池移除系统的自动化拆解系统。

Result: 系统每小时处理超过120部手机，平均拆解成功率98.9%，能高效分离高价值组件供下游处理。

Conclusion: 该系统为废弃手机拆解提供了可靠且可扩展的自动化解决方案，能将原本无利可图的拆解过程转变为产生净利润的过程。

Abstract: End-of-Life (EoL) phones significantly exacerbate global e-waste challenges
due to their high production volumes and short lifecycles. Disassembly is among
the most critical processes in EoL phone recycling. However, it relies heavily
on human labor due to product variability. Consequently, the manual process is
both labor-intensive and time-consuming. In this paper, we propose a low-cost,
easily deployable automated and selective disassembly and sorting system for
EoL phones, consisting of three subsystems: an adaptive cutting system, a
vision-based robotic sorting system, and a battery removal system. The system
can process over 120 phones per hour with an average disassembly success rate
of 98.9%, efficiently delivering selected high-value components to downstream
processing. It provides a reliable and scalable automated solution to the
pressing challenge of EoL phone disassembly. Additionally, the automated system
can enhance disassembly economics, converting a previously unprofitable process
into one that yields a net profit per unit weight of EoL phones.

</details>


### [22] [In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer](https://arxiv.org/abs/2509.23075)
*Soofiyan Atar,Daniel Huang,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 该论文提出了一种结合仿真训练和硬件演示的控制器，用于机器人手对铰接工具的灵巧操作，通过触觉和力反馈的跨注意力集成实现在线适应和稳定控制。


<details>
  <summary>Details</summary>
Motivation: 解决铰接机制操作中由于接触动力学复杂和关节现象（如摩擦、粘滞、回隙等）建模不足导致的策略脆弱性问题。

Method: 在仿真训练的基础策略上，通过硬件演示学习传感器驱动的细化策略，融合本体感知、目标关节状态以及全手触觉和力反馈，使用跨注意力机制集成策略内部动作意图。

Result: 在剪刀、钳子、微创手术工具和订书机等多种真实世界示例中验证了方法，实现了从仿真到硬件的鲁棒迁移、改进的抗干扰能力和对未见铰接工具的泛化能力。

Conclusion: 该方法减少了在接触丰富场景中对精确物理建模的依赖，能够适应特定实例的关节特性，稳定接触交互，调节内力，并在扰动下协调耦合连杆运动。

Abstract: Reinforcement learning (RL) and sim-to-real transfer have advanced robotic
manipulation of rigid objects. Yet, policies remain brittle when applied to
articulated mechanisms due to contact-rich dynamics and under-modeled joint
phenomena such as friction, stiction, backlash, and clearances. We address this
challenge through dexterous in-hand manipulation of articulated tools using a
robotic hand with reduced articulation and kinematic redundancy relative to the
human hand. Our controller augments a simulation-trained base policy with a
sensor-driven refinement learned from hardware demonstrations, conditioning on
proprioception and target articulation states while fusing whole-hand tactile
and force feedback with the policy's internal action intent via
cross-attention-based integration. This design enables online adaptation to
instance-specific articulation properties, stabilizes contact interactions,
regulates internal forces, and coordinates coupled-link motion under
perturbations. We validate our approach across a diversity of real-world
examples, including scissors, pliers, minimally invasive surgical tools, and
staplers. We achieve robust transfer from simulation to hardware, improved
disturbance resilience, and generalization to previously unseen articulated
tools, thereby reducing reliance on precise physical modeling in contact-rich
settings.

</details>


### [23] [Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning](https://arxiv.org/abs/2509.23107)
*Yi Wang,Zeyu Xue,Mujie Liu,Tongqin Zhang,Yan Hu,Zhou Zhao,Chenguang Yang,Zhenyu Lu*

Main category: cs.RO

TL;DR: 提出了ST-OVSG（时空开放词汇场景图）来解决远程操作中的传输延迟问题，通过在场景图中嵌入时间动态和延迟标注，帮助语言视觉模型规划器更准确地理解远程场景状态。


<details>
  <summary>Details</summary>
Motivation: 在动态远程场景中，双向通信的传输延迟会导致远程感知状态与操作者意图之间的差距，造成命令误解和执行错误。需要一种能够缓解延迟影响的场景表示方法。

Method: 利用语言视觉模型构建开放词汇3D物体表示，通过匈牙利分配和时序匹配成本扩展到时间域，形成统一的时空场景图。嵌入延迟标签使规划器能够回溯查询过去场景状态，并采用任务导向子图过滤策略减少冗余。

Result: 在Replica基准测试中达到74%的节点准确率，优于ConceptGraph。在延迟鲁棒性实验中，ST-OVSG辅助的语言视觉模型规划器实现了70.5%的规划成功率。

Conclusion: ST-OVSG能够泛化到新类别，无需微调即可增强规划对传输延迟的鲁棒性，有效解决了远程操作中的状态不匹配问题。

Abstract: Teleoperation via natural-language reduces operator workload and enhances
safety in high-risk or remote settings. However, in dynamic remote scenes,
transmission latency during bidirectional communication creates gaps between
remote perceived states and operator intent, leading to command
misunderstanding and incorrect execution. To mitigate this, we introduce the
Spatio-Temporal Open-Vocabulary Scene Graph (ST-OVSG), a representation that
enriches open-vocabulary perception with temporal dynamics and lightweight
latency annotations. ST-OVSG leverages LVLMs to construct open-vocabulary 3D
object representations, and extends them into the temporal domain via Hungarian
assignment with our temporal matching cost, yielding a unified spatio-temporal
scene graph. A latency tag is embedded to enable LVLM planners to
retrospectively query past scene states, thereby resolving local-remote state
mismatches caused by transmission delays. To further reduce redundancy and
highlight task-relevant cues, we propose a task-oriented subgraph filtering
strategy that produces compact inputs for the planner. ST-OVSG generalizes to
novel categories and enhances planning robustness against transmission latency
without requiring fine-tuning. Experiments show that our method achieves 74
percent node accuracy on the Replica benchmark, outperforming ConceptGraph.
Notably, in the latency-robustness experiment, the LVLM planner assisted by
ST-OVSG achieved a planning success rate of 70.5 percent.

</details>


### [24] [Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications](https://arxiv.org/abs/2509.23111)
*Chen Yizhe,Wang Qi,Hu Dongxiao,Jingzhe Fang,Liu Sichao,Zixin An,Hongliang Niu,Haoran Liu,Li Dong,Chuanfen Feng,Lan Dapeng,Liu Yu,Zhibo Pang*

Main category: cs.RO

TL;DR: 提出了一个工业级多模态干扰数据集，用于机器人在复杂条件下的感知和控制，包含视觉、扭矩和关节状态的多维干扰特征同步采集。


<details>
  <summary>Details</summary>
Motivation: 工业4.0应用中，动态环境干扰导致环境状态与机器人行为之间产生高度非线性和强耦合的相互作用，当前机器人数据集难以有效表示动态环境状态。

Method: 集成尺寸、颜色和光照变化等多维干扰特征，采用高精度传感器同步采集视觉、扭矩和关节状态测量数据，通过ROS实现微秒级时间同步和抗振动数据采集协议。

Result: 实验结果表明，该数据集增强了模型验证的鲁棒性，提高了机器人在动态、干扰丰富环境中的操作稳定性。

Conclusion: 该数据集为机器人在复杂工业环境中的感知和控制研究提供了有价值的资源，已公开可用。

Abstract: In Industry 4.0 applications, dynamic environmental interference induces
highly nonlinear and strongly coupled interactions between the environmental
state and robotic behavior. Effectively representing dynamic environmental
states through multimodal sensor data fusion remains a critical challenge in
current robotic datasets. To address this, an industrial-grade multimodal
interference dataset is presented, designed for robotic perception and control
under complex conditions. The dataset integrates multi-dimensional interference
features including size, color, and lighting variations, and employs
high-precision sensors to synchronously collect visual, torque, and joint-state
measurements. Scenarios with geometric similarity exceeding 85\% and
standardized lighting gradients are included to ensure real-world
representativeness. Microsecond-level time-synchronization and
vibration-resistant data acquisition protocols, implemented via the Robot
Operating System (ROS), guarantee temporal and operational fidelity.
Experimental results demonstrate that the dataset enhances model validation
robustness and improves robotic operational stability in dynamic,
interference-rich environments. The dataset is publicly available
at:https://modelscope.cn/datasets/Liaoh_LAB/Liaohe-CobotMagic-PnP.

</details>


### [25] [FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task](https://arxiv.org/abs/2509.23112)
*Ryo Watanabe,Maxime Alvarez,Pablo Ferreiro,Pavel Savkin,Genki Sano*

Main category: cs.RO

TL;DR: 提出了一种多模态模仿学习策略，通过将力/扭矩传感与Action Chunking Transformer结合，在零售环境中改进机器人对直立饮料瓶的拾取和重定向任务。


<details>
  <summary>Details</summary>
Motivation: 零售环境中的机械臂机器人经常需要人工远程操作来处理接触丰富的边缘情况，特别是直立饮料瓶操作中，仅靠视觉线索往往不足以解决精确操作所需的微妙接触事件。

Method: 开发了多模态模仿学习策略，将力/扭矩传感集成到Action Chunking Transformer中，实现图像、关节状态、力和扭矩的端到端学习。

Result: 硬件实验表明，与仅匹配ACT观测空间的基线相比，该方法在拾取和重定向瓶任务中取得了更高的成功率，力/扭矩信号在视觉可观测性有限的按压和放置阶段特别有益。

Conclusion: 通过将现代模仿学习架构与轻量级力/扭矩传感相结合，为扩展零售操作提供了一条实用路径，支持将交互力作为接触丰富技能的补充模态。

Abstract: Manipulator robots are increasingly being deployed in retail environments,
yet contact rich edge cases still trigger costly human teleoperation. A
prominent example is upright lying beverage bottles, where purely visual cues
are often insufficient to resolve subtle contact events required for precise
manipulation. We present a multimodal Imitation Learning policy that augments
the Action Chunking Transformer with force and torque sensing, enabling
end-to-end learning over images, joint states, and forces and torques. Deployed
on Ghost, single-arm platform by Telexistence Inc, our approach improves
Pick-and-Reorient bottle task by detecting and exploiting contact transitions
during pressing and placement. Hardware experiments demonstrate greater task
success compared to baseline matching the observation space of ACT as an
ablation and experiments indicate that force and torque signals are beneficial
in the press and place phases where visual observability is limited, supporting
the use of interaction forces as a complementary modality for contact rich
skills. The results suggest a practical path to scaling retail manipulation by
combining modern imitation learning architectures with lightweight force and
torque sensing.

</details>


### [26] [EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation](https://arxiv.org/abs/2509.23118)
*Zeyi Li,Zhe Tang,Kyeong Soo Kim,Sihao Li,Jeremy S. Smith*

Main category: cs.RO

TL;DR: 提出了一种融合Wi-Fi RSSI指纹识别、LiDAR SLAM和IMU的多传感器室内定位导航框架，通过EKF融合抑制Wi-Fi噪声和IMU漂移，实现稳定高精度定位。


<details>
  <summary>Details</summary>
Motivation: 传统Wi-Fi RSSI指纹定位精度不足，而LiDAR方案成本高且复杂，需要一种融合多传感器的解决方案来平衡精度和成本。

Method: 使用DNN进行Wi-Fi RSSI粗定位，结合IMU动态定位和Gmapping SLAM生成地图，通过EKF预测-更新融合传感器信息，抑制Wi-Fi噪声和IMU漂移误差。

Result: 在真实环境实验中，该框架的2D平均误差为0.2449-0.3781米，而Wi-Fi RSSI在信号干扰区域误差达1.3404米，LiDAR/IMU因累积漂移误差为0.6233-2.8803米。

Conclusion: 多传感器融合框架能有效抑制单一方法的不足，在所有路径配置下提供稳定的定位精度，优于单一传感器方案。

Abstract: Conventional Wi-Fi received signal strength indicator (RSSI) fingerprinting
cannot meet the growing demand for accurate indoor localization and navigation
due to its lower accuracy, while solutions based on light detection and ranging
(LiDAR) can provide better localization performance but is limited by their
higher deployment cost and complexity. To address these issues, we propose a
novel indoor localization and navigation framework integrating Wi-Fi RSSI
fingerprinting, LiDAR-based simultaneous localization and mapping (SLAM), and
inertial measurement unit (IMU) navigation based on an extended Kalman filter
(EKF). Specifically, coarse localization by deep neural network (DNN)-based
Wi-Fi RSSI fingerprinting is refined by IMU-based dynamic positioning using a
Gmapping-based SLAM to generate an occupancy grid map and output high-frequency
attitude estimates, which is followed by EKF prediction-update integrating
sensor information while effectively suppressing Wi-Fi-induced noise and IMU
drift errors. Multi-group real-world experiments conducted on the IR building
at Xi'an Jiaotong-Liverpool University demonstrates that the proposed
multi-sensor fusion framework suppresses the instability caused by individual
approaches and thereby provides stable accuracy across all path configurations
with mean two-dimensional (2D) errors ranging from 0.2449 m to 0.3781 m. In
contrast, the mean 2D errors of Wi-Fi RSSI fingerprinting reach up to 1.3404 m
in areas with severe signal interference, and those of LiDAR/IMU localization
are between 0.6233 m and 2.8803 m due to cumulative drift.

</details>


### [27] [LAGEA: Language Guided Embodied Agents for Robotic Manipulation](https://arxiv.org/abs/2509.23155)
*Abdul Monaf Chowdhury,Akm Moshiur Rahman Mazumder,Rabeya Akter,Safaeid Hossain Arib*

Main category: cs.RO

TL;DR: LAGEA框架利用视觉语言模型生成语言反馈，将错误反思转化为强化学习的时序引导，通过自适应奖励系数在机器人操作任务中实现自我反思和性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前机器人代理缺乏从自身错误中学习的系统方法，研究探索自然语言是否能作为反馈信号，帮助具身智能体诊断错误并纠正行为。

Method: LAGEA框架将视觉语言模型的反思总结为简洁语言，定位轨迹中的关键时刻，在共享表示中对齐反馈与视觉状态，并将目标进展和反馈一致性转化为有界的逐步塑形奖励，使用自适应失败感知系数调节影响。

Result: 在Meta-World MT10机器人操作基准测试中，LAGEA相比最先进方法在随机目标上平均成功率提高9.0%，在固定目标上提高5.3%，且收敛更快。

Conclusion: 研究证实：当语言被结构化并在时间上接地时，是教导机器人自我反思错误并做出更好选择的有效机制。

Abstract: Robotic manipulation benefits from foundation models that describe goals, but
today's agents still lack a principled way to learn from their own mistakes. We
ask whether natural language can serve as feedback, an error reasoning signal
that helps embodied agents diagnose what went wrong and correct course. We
introduce LAGEA (Language Guided Embodied Agents), a framework that turns
episodic, schema-constrained reflections from a vision language model (VLM)
into temporally grounded guidance for reinforcement learning. LAGEA summarizes
each attempt in concise language, localizes the decisive moments in the
trajectory, aligns feedback with visual state in a shared representation, and
converts goal progress and feedback agreement into bounded, step-wise shaping
rewardswhose influence is modulated by an adaptive, failure-aware coefficient.
This design yields dense signals early when exploration needs direction and
gracefully recedes as competence grows. On the Meta-World MT10 embodied
manipulation benchmark, LAGEA improves average success over the
state-of-the-art (SOTA) methods by 9.0% on random goals and 5.3% on fixed
goals, while converging faster. These results support our hypothesis: language,
when structured and grounded in time, is an effective mechanism for teaching
robots to self-reflect on mistakes and make better choices. Code will be
released soon.

</details>


### [28] [Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion](https://arxiv.org/abs/2509.23185)
*Ziyi Zhou,Qian Meng,Hadas Kress-Gazit,Ye Zhao*

Main category: cs.RO

TL;DR: 提出一个四足机器人动态地形运动规划框架，结合反应式合成和混合整数凸规划，通过符号修复机制减少计算负担，实现离线合成与在线操作的平滑衔接。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式实时立足点选择（限制鲁棒性和适应性）或计算密集的轨迹优化，需要更高效可靠的动态地形运动规划方案。

Method: 结合反应式合成生成构造正确的符号级控制器，使用混合整数凸规划进行动态物理可行步态规划，采用符号修复机制减少MICP求解次数，实时MICP重规划结合运行时符号修复和延迟感知协调。

Result: 通过大量仿真和硬件实验验证，框架能够识别缺失的运动技能，在安全关键环境中有效响应，包括分散踏脚石和钢筋场景。

Conclusion: 该集成规划框架成功解决了动态变化、未知地形上的四足运动规划问题，实现了离线合成与在线执行的平滑过渡，提高了系统的鲁棒性和适应性。

Abstract: We present an integrated planning framework for quadrupedal locomotion over
dynamically changing, unforeseen terrains. Existing methods often depend on
heuristics for real-time foothold selection-limiting robustness and
adaptability-or rely on computationally intensive trajectory optimization
across complex terrains and long horizons. In contrast, our approach combines
reactive synthesis for generating correct-by-construction symbolic-level
controllers with mixed-integer convex programming (MICP) for dynamic and
physically feasible footstep planning during each symbolic transition. To
reduce the reliance on costly MICP solves and accommodate specifications that
may be violated due to physical infeasibility, we adopt a symbolic repair
mechanism that selectively generates only the required symbolic transitions.
During execution, real-time MICP replanning based on actual terrain data,
combined with runtime symbolic repair and delay-aware coordination, enables
seamless bridging between offline synthesis and online operation. Through
extensive simulation and hardware experiments, we validate the framework's
ability to identify missing locomotion skills and respond effectively in
safety-critical environments, including scattered stepping stones and rebar
scenarios.

</details>


### [29] [CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation](https://arxiv.org/abs/2509.23203)
*Kai Yang,Tianlin Zhang,Zhengbo Wang,Zedong Chu,Xiaolong Wu,Yang Cai,Mu Xu*

Main category: cs.RO

TL;DR: CE-Nav是一个两阶段框架，通过解耦几何推理和动态适应，实现跨机器人形态的通用导航策略，大幅降低适应成本。


<details>
  <summary>Details</summary>
Motivation: 解决跨机器人形态导航的挑战：需要昂贵的特定形态数据、规划与控制紧密耦合、以及确定性模型无法处理多模态决策问题。

Method: 两阶段方法：1) 离线训练通用专家（VelFlow模型）学习运动学可行动作分布；2) 在线训练轻量级动态感知精炼器，针对特定机器人动态进行微调。

Result: 在四足、双足和四旋翼机器人上实验表明，CE-Nav达到最先进性能，同时显著降低适应成本，并在真实环境中成功部署。

Conclusion: CE-Nav为构建可扩展的通用导航系统提供了高效解决方案，成功解决多模态决策和跨形态适应问题。

Abstract: Generalizing local navigation policies across diverse robot morphologies is a
critical challenge. Progress is often hindered by the need for costly and
embodiment-specific data, the tight coupling of planning and control, and the
"disastrous averaging" problem where deterministic models fail to capture
multi-modal decisions (e.g., turning left or right). We introduce CE-Nav, a
novel two-stage (IL-then-RL) framework that systematically decouples universal
geometric reasoning from embodiment-specific dynamic adaptation. First, we
train an embodiment-agnostic General Expert offline using imitation learning.
This expert, a conditional normalizing flow model named VelFlow, learns the
full distribution of kinematically-sound actions from a large-scale dataset
generated by a classical planner, completely avoiding real robot data and
resolving the multi-modality issue. Second, for a new robot, we freeze the
expert and use it as a guiding prior to train a lightweight, Dynamics-Aware
Refiner via online reinforcement learning. This refiner rapidly learns to
compensate for the target robot's specific dynamics and controller
imperfections with minimal environmental interaction. Extensive experiments on
quadrupeds, bipeds, and quadrotors show that CE-Nav achieves state-of-the-art
performance while drastically reducing adaptation cost. Successful real-world
deployments further validate our approach as an efficient and scalable solution
for building generalizable navigation systems.

</details>


### [30] [Simulated Annealing for Multi-Robot Ergodic Information Acquisition Using Graph-Based Discretization](https://arxiv.org/abs/2509.23214)
*Benjamin Wong,Aaron Weber,Mohamed M. Safwat,Santosh Devasia,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 本文提出使用模拟退火方法为多机器人团队生成目标采样分布，从均匀分布开始，逐渐转向估计的最优分布，以在不确定环境中实现一致的采集质量。


<details>
  <summary>Details</summary>
Motivation: 多机器人主动信息采集的目标是保持各区域相对不确定性在相同水平，以确保所有区域具有一致的采集质量。然而，观测噪声水平未知且初始估计不可靠，会导致波动值。

Method: 使用模拟退火生成目标采样分布，从均匀分布开始，通过变化玻尔兹曼分布的冷度参数，以估计的采样熵作为能量，逐渐转向估计的最优分布。

Result: 仿真结果显示，与均匀搜索和直接遍历搜索相比，该方法在瞬时熵和渐近熵方面都有显著改善。在TurtleBot群系统上的演示验证了算法的物理适用性。

Conclusion: 模拟退火方法能有效处理多机器人系统中未知观测噪声的问题，实现更稳定的信息采集质量，并在实际机器人系统中得到验证。

Abstract: One of the goals of active information acquisition using multi-robot teams is
to keep the relative uncertainty in each region at the same level to maintain
identical acquisition quality (e.g., consistent target detection) in all the
regions. To achieve this goal, ergodic coverage can be used to assign the
number of samples according to the quality of observation, i.e., sampling noise
levels. However, the noise levels are unknown to the robots. Although this
noise can be estimated from samples, the estimates are unreliable at first and
can generate fluctuating values. The main contribution of this paper is to use
simulated annealing to generate the target sampling distribution, starting from
uniform and gradually shifting to an estimated optimal distribution, by varying
the coldness parameter of a Boltzmann distribution with the estimated sampling
entropy as energy. Simulation results show a substantial improvement of both
transient and asymptotic entropy compared to both uniform and direct-ergodic
searches. Finally, a demonstration is performed with a TurtleBot swarm system
to validate the physical applicability of the algorithm.

</details>


### [31] [GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking](https://arxiv.org/abs/2509.23220)
*Ye Chen,Zichen Zhou,Jianyu Dou,Te Cui,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: GLUE是一个基于关键补丁跟踪的全局-局部统一编码框架，通过文本引导机制选择并跟踪关键补丁作为局部表示，解决复杂OOD环境下视觉表示学习中的注意力稀释问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂OOD设置中，全局视觉表示的注意力可能被稀释或干扰，导致策略性能下降。局部表示对任务相关对象的不变性提供了一种解决方案。

Method: GLUE采用文本引导机制选择关键补丁，通过全局补丁特征查询局部补丁来提取关键信息，生成与全局上下文异质性低的细粒度局部特征。

Result: 实验表明GLUE在仿真和真实环境中均表现优异，比最强基线在仿真中提升17.6%，真实环境中提升36.3%，真实世界泛化设置中提升58.3%。

Conclusion: GLUE通过融合表示引导机器人视觉注意力到任务相关对象，同时保留精确的全局上下文，将训练和测试分布对齐到相似且任务信息丰富的特征空间，增强了模仿学习策略的鲁棒性。

Abstract: In recent years, visual representation learning has gained widespread
attention in robotic imitation learning. However, in complex
Out-of-Distribution(OOD) settings characterized by clutter and occlusion, the
attention of global visual representations can be diluted or interfered,
leading to degraded policy performance. The invariance of local representations
for task-relevant objects offers a solution. By efficiently utilizing these
local representations, training and testing data can be mapped to a more
similar feature space, thereby mitigating the covariate shift problem.
Accordingly, we propose GLUE, a global-local unified encoding framework for
imitation learning based on key-patch tracking. GLUE selects and tracks
key-patches as critical local representations by employing a text-guided
mechanism. It features a novel fusion framework where global patch features
query local patches to distill essential information, yielding fine-grained
local features with low heterogeneity relative to the global context. This
fused representation steers the robot's visual attention toward task-relevant
objects and preserves precise global context, which together align the training
and testing distributions into a similar and task-informative feature space,
ultimately enhancing the robustness of the imitation learning policy.
Experiments demonstrate that GLUE achieves strong performance across diverse
tasks in both simulation and real-world settings, outperforming the strongest
baseline by 17.6% in simulation, 36.3% in real-world environments, and 58.3% on
real-world generalization settings. The project website of GLUE is available at
https://GLUE666.github.io/.

</details>


### [32] [SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion](https://arxiv.org/abs/2509.23223)
*Aoqian Zhang,Zixuan Zhuang,Chunzheng Wang,Shuzhi Sam Ge,Fan Shi,Cheng Xiang*

Main category: cs.RO

TL;DR: 提出了一个切换策略框架，用于实现四足机器人的柔顺和安全运动控制，结合了可调柔顺度的力柔顺策略和基于捕获点的安全策略，通过可恢复性网络进行策略切换。


<details>
  <summary>Details</summary>
Motivation: 现有四足机器人控制方法缺乏动物所具备的自适应和可调节柔顺性，大多数运动控制器无法提供可调柔顺度，在大扰动下容易失效。

Method: 使用师生强化学习框架训练具有可调柔顺度的力柔顺策略（无需显式力感知），开发基于捕获点概念的安全策略，并通过可恢复性网络预测失败可能性来切换策略。

Result: 该框架使四足机器人在遭受严重外部扰动时能够同时实现力柔顺和鲁棒安全性。

Conclusion: 提出的切换策略框架成功解决了四足机器人在外部扰动下的柔顺性和安全性问题，实现了类似动物的自适应柔顺能力。

Abstract: Quadruped robots are designed to achieve agile locomotion by mimicking legged
animals. However, existing control methods for quadrupeds often lack one of the
key capabilities observed in animals: adaptive and adjustable compliance in
response to external disturbances. Most locomotion controllers do not provide
tunable compliance and tend to fail under large perturbations. In this work, we
propose a switched policy framework for compliant and safe quadruped
locomotion. First, we train a force compliant policy with adjustable compliance
levels using a teacher student reinforcement learning framework, eliminating
the need for explicit force sensing. Next, we develop a safe policy based on
the capture point concept to stabilize the robot when the compliant policy
fails. Finally, we introduce a recoverability network that predicts the
likelihood of failure and switches between the compliant and safe policies.
Together, this framework enables quadruped robots to achieve both force
compliance and robust safety when subjected to severe external disturbances.

</details>


### [33] [Leave No Observation Behind: Real-time Correction for VLA Action Chunks](https://arxiv.org/abs/2509.23224)
*Kohei Sendai,Maxime Alvarez,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: 提出A2C2方法，通过轻量级实时动作块校正头解决VLA模型动作分块导致的反应性下降问题，无需重新训练基础策略即可提升实时控制性能。


<details>
  <summary>Details</summary>
Motivation: VLA模型使用动作分块提高效率和时序一致性，但这在推理延迟和长时程下会损害反应性，需要一种保持基础模型能力同时恢复闭环响应性的方法。

Method: 设计异步动作块校正头，结合最新观测、VLA预测动作、动作在块中的位置特征和基础策略特征，输出每步校正量，与异步执行方案正交。

Result: 在动态Kinetix任务套件和LIBERO Spatial上，相比RTC方法，在不同延迟和执行时程下均获得一致的成功率提升（分别+23%和+7%），且在零延迟长时程下也提高鲁棒性。

Conclusion: A2C2是一种有效、即插即用的机制，可在实时控制中部署高容量分块策略，校正头轻量快速，对大型VLA模型推理开销极小。

Abstract: To improve efficiency and temporal coherence, Vision-Language-Action (VLA)
models often predict action chunks; however, this action chunking harms
reactivity under inference delay and long horizons. We introduce Asynchronous
Action Chunk Correction (A2C2), which is a lightweight real-time chunk
correction head that runs every control step and adds a time-aware correction
to any off-the-shelf VLA's action chunk. The module combines the latest
observation, the predicted action from VLA (base action), a positional feature
that encodes the index of the base action within the chunk, and some features
from the base policy, then outputs a per-step correction. This preserves the
base model's competence while restoring closed-loop responsiveness. The
approach requires no retraining of the base policy and is orthogonal to
asynchronous execution schemes such as Real Time Chunking (RTC). On the dynamic
Kinetix task suite (12 tasks) and LIBERO Spatial, our method yields consistent
success rate improvements across increasing delays and execution horizons (+23%
point and +7% point respectively, compared to RTC), and also improves
robustness for long horizons even with zero injected delay. Since the
correction head is small and fast, there is minimal overhead compared to the
inference of large VLA models. These results indicate that A2C2 is an
effective, plug-in mechanism for deploying high-capacity chunking policies in
real-time control.

</details>


### [34] [Online Dynamic Goal Recognition in Gym Environments](https://arxiv.org/abs/2509.23244)
*Shamir Matan,Elhadad Osher,Nageris Ben,Mirsky Reuth*

Main category: cs.RO

TL;DR: 提出了gr-libs和gr-envs两个开源框架，用于标准化目标识别算法的开发、评估和比较，解决该领域基准测试和评估协议不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 目标识别领域由于基准测试、领域和评估协议的不一致性而碎片化，需要标准化平台来促进研究发展。

Method: 开发了两个互补的开源框架：gr-libs包含模块化的MDP基础目标识别算法实现、诊断工具和评估工具；gr-envs提供经过调整的环境套件，支持动态和目标导向行为，并确保与标准强化学习工具包的兼容性。

Result: 创建了一个标准化、可扩展且可复现的平台，支持目标识别算法的开发和比较，两个包已在GitHub和PyPI上开源提供。

Conclusion: gr-libs和gr-envs框架为目标识别研究提供了统一的基准和工具，有助于推动该领域的标准化和进一步发展。

Abstract: Goal Recognition (GR) is the task of inferring an agent's intended goal from
partial observations of its behavior, typically in an online and one-shot
setting. Despite recent advances in model-free GR, particularly in applications
such as human-robot interaction, surveillance, and assistive systems, the field
remains fragmented due to inconsistencies in benchmarks, domains, and
evaluation protocols.
  To address this, we introduce gr-libs
(https://github.com/MatanShamir1/gr_libs) and gr-envs
(https://github.com/MatanShamir1/gr_envs), two complementary open-source
frameworks that support the development, evaluation, and comparison of GR
algorithms in Gym-compatible environments. gr-libs includes modular
implementations of MDP-based GR baselines, diagnostic tools, and evaluation
utilities. gr-envs provides a curated suite of environments adapted for dynamic
and goal-directed behavior, along with wrappers that ensure compatibility with
standard reinforcement learning toolkits. Together, these libraries offer a
standardized, extensible, and reproducible platform for advancing GR research.
Both packages are open-source and available on GitHub and PyPI.

</details>


### [35] [Preventing Robotic Jailbreaking via Multimodal Domain Adaptation](https://arxiv.org/abs/2509.23281)
*Francesco Marchiori,Rohan Sinha,Christopher Agia,Alexander Robey,George J. Pappas,Mauro Conti,Marco Pavone*

Main category: cs.RO

TL;DR: J-DAPT是一个轻量级多模态越狱检测框架，通过注意力融合和领域自适应技术，在机器人环境中保护视觉语言模型免受越狱攻击，检测准确率接近100%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型在机器人环境中部署时容易受到越狱攻击，绕过安全机制导致现实世界中的不安全行为。现有基于数据驱动的防御方法在专业数据集稀缺的领域泛化能力不足。

Method: J-DAPT框架通过注意力融合整合文本和视觉嵌入，捕捉语义意图和环境背景，同时将通用越狱数据集与领域特定的参考数据进行对齐。

Result: 在自动驾驶、海洋机器人和四足机器人导航等场景的评估中，J-DAPT将检测准确率提升至接近100%，且开销极小。

Conclusion: J-DAPT为机器人应用中的视觉语言模型提供了一种实用的安全防御方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) are
increasingly deployed in robotic environments but remain vulnerable to
jailbreaking attacks that bypass safety mechanisms and drive unsafe or
physically harmful behaviors in the real world. Data-driven defenses such as
jailbreak classifiers show promise, yet they struggle to generalize in domains
where specialized datasets are scarce, limiting their effectiveness in robotics
and other safety-critical contexts. To address this gap, we introduce J-DAPT, a
lightweight framework for multimodal jailbreak detection through
attention-based fusion and domain adaptation. J-DAPT integrates textual and
visual embeddings to capture both semantic intent and environmental grounding,
while aligning general-purpose jailbreak datasets with domain-specific
reference data. Evaluations across autonomous driving, maritime robotics, and
quadruped navigation show that J-DAPT boosts detection accuracy to nearly 100%
with minimal overhead. These results demonstrate that J-DAPT provides a
practical defense for securing VLMs in robotic applications. Additional
materials are made available at: https://j-dapt.github.io.

</details>


### [36] [A Novel Narrow Region Detector for Sampling-Based Planners' Efficiency: Match Based Passage Identifier](https://arxiv.org/abs/2509.23288)
*Yafes Enes Şahiner,Esat Yusuf Gündoğdu,Volkan Sezer*

Main category: cs.RO

TL;DR: 提出一种新型采样器，使用占据栅格地图确定性识别窄通道环境，并在这些区域增加采样量，在规划时间和里程碑数量上表现优于基线采样器。


<details>
  <summary>Details</summary>
Motivation: 概率路径规划方法在窄通道环境中普遍存在问题，需要改进在这些区域的采样策略。

Method: 使用占据栅格地图确定性识别窄通道环境，并在这些区域增加采样量的新型采样器算法。

Result: 在特定模拟环境、随机模拟环境和真实世界环境的基准测试中，该算法在规划时间和里程碑数量上表现优于基线采样器。

Conclusion: 提出的采样器能有效解决窄通道环境中的路径规划问题，提供开源实现，在多个测试场景中均表现出优越性能。

Abstract: Autonomous technology, which has become widespread today, appears in many
different configurations such as mobile robots, manipulators, and drones. One
of the most important tasks of these vehicles during autonomous operations is
path planning. In the literature, path planners are generally divided into two
categories: probabilistic and deterministic methods. In the analysis of
probabilistic methods, the common problem of almost all methods is observed in
narrow passage environments. In this paper, a novel sampler is proposed that
deterministically identifies narrow passage environments using occupancy grid
maps and accordingly increases the amount of sampling in these regions. The
codes of the algorithm is provided as open source. To evaluate the performance
of the algorithm, benchmark studies are conducted in three distinct categories:
specific and random simulation environments, and a real-world environment. As a
result, it is observed that our algorithm provides higher performance in
planning time and number of milestones compared to the baseline samplers.

</details>


### [37] [Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment](https://arxiv.org/abs/2509.23308)
*Jun Chen,Jiaqing Ma,Philip Dames*

Main category: cs.RO

TL;DR: 提出了一种集成前沿探索、保证覆盖和多目标跟踪策略的运动规划算法框架，用于在未知非凸环境中同时优化环境探索、信息搜索和目标跟踪任务。


<details>
  <summary>Details</summary>
Motivation: 在室内、地下等未知非凸环境中，部署机器人舰队同时进行环境探索、目标搜索和跟踪以维持高精度数据采集是环境监测和救援等应用中的关键挑战。现有研究尚未建立同时优化这些任务的框架。

Method: 提出集成三种控制策略的运动规划算法：基于前沿的探索策略、基于Lloyd算法的保证覆盖策略、基于传感器的多目标跟踪策略，平衡覆盖搜索和高精度主动跟踪。

Result: 通过MATLAB仿真验证了算法的有效性和优越性，相比标准方法表现更佳。

Conclusion: 该算法框架成功解决了在复杂环境中同时优化环境探索、信息搜索和目标跟踪的问题，为实际应用提供了有效解决方案。

Abstract: In unknown non-convex environments, such as indoor and underground spaces,
deploying a fleet of robots to explore the surroundings while simultaneously
searching for and tracking targets of interest to maintain high-precision data
collection represents a fundamental challenge that urgently requires resolution
in applications such as environmental monitoring and rescue operations. Current
research has made significant progress in addressing environmental exploration,
information search, and target tracking problems, but has yet to establish a
framework for simultaneously optimizing these tasks in complex environments. In
this paper, we propose a novel motion planning algorithm framework that
integrates three control strategies: a frontier-based exploration strategy, a
guaranteed coverage strategy based on Lloyd's algorithm, and a sensor-based
multi-target tracking strategy. By incorporating these three strategies, the
proposed algorithm balances coverage search and high-precision active tracking
during exploration. Our approach is validated through a series of MATLAB
simulations, demonstrating validity and superiority over standard approaches.

</details>


### [38] [GUARD: Toward a Compromise between Traditional Control and Learning for Safe Robot Systems](https://arxiv.org/abs/2509.23312)
*Johannes A. Gaus,Junheon Yoon,Woo-Jeong Baek,Seungwon Choi,Suhan Park,Jaeheung Park*

Main category: cs.RO

TL;DR: GUARD框架结合传统控制与不确定性感知感知技术，通过主动学习和实时能力实现安全的机器人碰撞避免，在传统方法与学习算法之间找到合理平衡。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学中传统方法与学习算法之间的平衡问题，开发安全、高效且灵活的应用，处理机器人文献中"安全"概念的模糊性。

Method: 将反应式模型预测轮廓控制(RMPCC)与迭代最近点(ICP)算法相结合，通过概率核优化技术在线归因不确定性源，具备实时主动学习能力。

Result: 实验研究表明GUARD具有高性能，突显了其相关性和未来扩展应用的必要性。

Conclusion: GUARD框架成功统一了传统控制与学习算法，为安全机器人决策提供了有效解决方案，未来需要扩大其应用范围。

Abstract: This paper presents the framework \textbf{GUARD} (\textbf{G}uided robot
control via \textbf{U}ncertainty attribution and prob\textbf{A}bilistic kernel
optimization for \textbf{R}isk-aware \textbf{D}ecision making) that combines
traditional control with an uncertainty-aware perception technique using active
learning with real-time capability for safe robot collision avoidance. By doing
so, this manuscript addresses the central challenge in robotics of finding a
reasonable compromise between traditional methods and learning algorithms to
foster the development of safe, yet efficient and flexible applications. By
unifying a reactive model predictive countouring control (RMPCC) with an
Iterative Closest Point (ICP) algorithm that enables the attribution of
uncertainty sources online using active learning with real-time capability via
a probabilistic kernel optimization technique, \emph{GUARD} inherently handles
the existing ambiguity of the term \textit{safety} that exists in robotics
literature. Experimental studies indicate the high performance of \emph{GUARD},
thereby highlighting the relevance and need to broaden its applicability in
future.

</details>


### [39] [Space Robotics Bench: Robot Learning Beyond Earth](https://arxiv.org/abs/2509.23328)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 提出了Space Robotics Bench开源仿真框架，用于太空机器人学习，包含模块化架构、程序化生成和大规模并行仿真，支持创建多样化训练分布和基准任务。


<details>
  <summary>Details</summary>
Motivation: 太空探索需要能在极端外星环境下运行的自主系统，但机器人学习在该领域应用受限，主要由于技术演示成本高昂和数据可用性有限。

Method: 开发开源仿真框架，采用模块化架构集成按需程序化生成和大规模并行仿真环境，提供全面的基准任务套件，并使用标准强化学习算法建立性能基线。

Result: 通过实验案例研究揭示了当前方法在泛化、端到端学习、自适应控制和仿真到真实迁移方面的局限性，证明了框架能产生具备真实世界操作能力的策略。

Conclusion: Space Robotics Bench为开发、基准测试和部署太空探索所需的鲁棒自主系统提供了宝贵资源。

Abstract: The growing ambition for space exploration demands robust autonomous systems
that can operate in unstructured environments under extreme extraterrestrial
conditions. The adoption of robot learning in this domain is severely hindered
by the prohibitive cost of technology demonstrations and the limited
availability of data. To bridge this gap, we introduce the Space Robotics
Bench, an open-source simulation framework for robot learning in space. It
offers a modular architecture that integrates on-demand procedural generation
with massively parallel simulation environments to support the creation of vast
and diverse training distributions for learning-based agents. To ground
research and enable direct comparison, the framework includes a comprehensive
suite of benchmark tasks that span a wide range of mission-relevant scenarios.
We establish performance baselines using standard reinforcement learning
algorithms and present a series of experimental case studies that investigate
key challenges in generalization, end-to-end learning, adaptive control, and
sim-to-real transfer. Our results reveal insights into the limitations of
current methods and demonstrate the utility of the framework in producing
policies capable of real-world operation. These contributions establish the
Space Robotics Bench as a valuable resource for developing, benchmarking, and
deploying the robust autonomous systems required for the final frontier.

</details>


### [40] [Robust Orientation Estimation with TRIAD-aided Manifold EKF](https://arxiv.org/abs/2509.23456)
*Arjun Sadananda,Ravi Banavar,Kavi Arya*

Main category: cs.RO

TL;DR: 提出了一种结合TRIAD算法和流形扩展卡尔曼滤波的方法，用于减轻磁力计读数对俯仰和滚转轴姿态确定的影响。


<details>
  <summary>Details</summary>
Motivation: 磁力计作为姿态确定传感器容易受到校准和外部磁场干扰，而TRIAD算法作为次优姿态估计器具有特定优势，需要将其与流形EKF结合以提升姿态估计的鲁棒性。

Method: 将TRIAD算法的次优特性整合到流形扩展卡尔曼滤波中，特别针对俯仰和滚转轴姿态确定中的磁力计读数影响进行缓解。

Result: 通过实验验证了所提方法的有效性，表明该方法能够有效减轻磁力计干扰对姿态估计的影响。

Conclusion: 结合TRIAD算法的流形EKF方法能够有效提高姿态确定系统在磁力计受干扰情况下的鲁棒性和准确性。

Abstract: The manifold extended Kalman filter (Manifold EKF) has found extensive
application for attitude determination. Magnetometers employed as sensors for
such attitude determination are easily prone to disturbances by their
sensitivity to calibration and external magnetic fields. The TRIAD (Tri-Axial
Attitude Determination) algorithm is well known as a sub-optimal attitude
estimator. In this article, we incorporate this sub-optimal feature of the
TRIAD in mitigating the influence of the magnetometer reading in the pitch and
roll axis determination in the Manifold EKF algorithm. We substantiate our
results with experiments.

</details>


### [41] [Multi-Modal Manipulation via Multi-Modal Policy Consensus](https://arxiv.org/abs/2509.23468)
*Haonan Chen,Jiaming Xu,Hongyu Chen,Kaiwen Hong,Binghao Huang,Chaoqi Liu,Jiayuan Mao,Yunzhu Li,Yilun Du,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 提出了一种多模态策略分解方法，将策略分解为多个专门处理单一模态的扩散模型，通过路由器网络自适应组合各模态贡献，在接触丰富的操作任务中优于特征拼接基线。


<details>
  <summary>Details</summary>
Motivation: 传统特征拼接方法存在主导模态（如视觉）淹没稀疏但关键信号（如触觉）的问题，且单一架构无法灵活处理新模态或缺失模态而无需重新训练。

Method: 将策略分解为一组扩散模型，每个专门处理单一表征（如视觉或触觉），使用路由器网络学习共识权重来自适应组合各模态贡献，支持新表征的增量集成。

Result: 在模拟和真实世界操作任务（如遮挡物体抓取、手中勺子重定向、拼图插入）中显著优于特征拼接基线，对物理扰动和传感器损坏具有鲁棒性。

Conclusion: 该方法实现了多模态的自适应融合，在需要多模态推理的场景中表现出色，扰动重要性分析揭示了模态间的自适应切换。

Abstract: Effectively integrating diverse sensory modalities is crucial for robotic
manipulation. However, the typical approach of feature concatenation is often
suboptimal: dominant modalities such as vision can overwhelm sparse but
critical signals like touch in contact-rich tasks, and monolithic architectures
cannot flexibly incorporate new or missing modalities without retraining. Our
method factorizes the policy into a set of diffusion models, each specialized
for a single representation (e.g., vision or touch), and employs a router
network that learns consensus weights to adaptively combine their
contributions, enabling incremental of new representations. We evaluate our
approach on simulated manipulation tasks in {RLBench}, as well as real-world
tasks such as occluded object picking, in-hand spoon reorientation, and puzzle
insertion, where it significantly outperforms feature-concatenation baselines
on scenarios requiring multimodal reasoning. Our policy further demonstrates
robustness to physical perturbations and sensor corruption. We further conduct
perturbation-based importance analysis, which reveals adaptive shifts between
modalities.

</details>


### [42] [Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic](https://arxiv.org/abs/2509.23506)
*Dan BW Choe,Sundhar Vinodh Sangeetha,Steven Emanuel,Chih-Yuan Chiu,Samuel Coogan,Shreyas Kousik*

Main category: cs.RO

TL;DR: 提出了一种去中心化框架，让机器人通过自然语言请求和提供帮助，使用LLM进行决策和推理，结合STL和MILP优化，显著优于启发式方法。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人团队在仓储等场景中应对意外冲突时无缝协作的需求。

Method: 机器人检测冲突后使用LLM决定是否需要外部帮助，发送自然语言请求；帮助机器人使用基于STL的LLM推理，通过BNF语法确保NL到STL的有效转换，并用MILP求解；请求者基于系统级任务完成时间选择帮助者。

Result: 实验表明考虑多个帮助提议能让请求者最小化增加的makespan，显著优于选择最近可用机器人等启发式方法，性能接近集中式基准但信息需求更低。

Conclusion: 该去中心化框架有效实现了异构机器人团队的无缝协作，在减少信息需求的同时达到接近最优性能。

Abstract: Increased robot deployment, such as in warehousing, has revealed a need for
seamless collaboration among heterogeneous robot teams to resolve unforeseen
conflicts. To address this challenge, we propose a novel decentralized
framework that enables robots to request and provide help. The process begins
when a robot detects a conflict and uses a Large Language Model (LLM) to decide
whether external assistance is required. If so, it crafts and broadcasts a
natural language (NL) help request. Potential helper robots reason over the
request and respond with offers of assistance, including information about the
effect on their ongoing tasks. Helper reasoning is implemented via an LLM
grounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar,
ensuring syntactically valid NL-to-STL translations, which are then solved as a
Mixed Integer Linear Program (MILP). Finally, the requester robot selects a
helper by reasoning over the expected increase in system-level total task
completion time. We evaluated our framework through experiments comparing
different helper-selection strategies and found that considering multiple
offers allows the requester to minimize added makespan. Our approach
significantly outperforms heuristics such as selecting the nearest available
candidate helper robot, and achieves performance comparable to a centralized
"Oracle" baseline but without heavy information demands.

</details>


### [43] [Zero-shot Whole-Body Manipulation with a Large-Scale Soft Robotic Torso via Guided Reinforcement Learning](https://arxiv.org/abs/2509.23556)
*Curtis C. Johnson,Carlo Alessi,Egidio Falotico,Marc D. Killpack*

Main category: cs.RO

TL;DR: 开发了高速软体机器人全身操作仿真框架，实现350倍实时速度，并成功将学习策略零样本迁移到真实机器人，在10kg负载下达到88%成功率。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因其被动柔顺性适合接触丰富的全身操作任务，但其运动学和动力学不确定性给仿真和控制带来挑战。

Method: 使用MuJoCo构建高速仿真框架，结合简单运动基元引导强化学习，实现全身操作策略学习。

Result: 仿真速度达350倍实时，零样本迁移成功率88%，学习策略表现出重新抓取和扰动恢复等反应行为。

Conclusion: 这是首次实现两个连续软体臂在大型平台上进行强力六自由度全身操作，并成功零样本策略迁移。

Abstract: Whole-body manipulation is a powerful yet underexplored approach that enables
robots to interact with large, heavy, or awkward objects using more than just
their end-effectors. Soft robots, with their inherent passive compliance, are
particularly well-suited for such contact-rich manipulation tasks, but their
uncertainties in kinematics and dynamics pose significant challenges for
simulation and control. In this work, we address this challenge with a
simulation that can run up to 350x real time on a single thread in MuJoCo and
provide a detailed analysis of the critical tradeoffs between speed and
accuracy for this simulation. Using this framework, we demonstrate a successful
zero-shot sim-to-real transfer of a learned whole-body manipulation policy,
achieving an 88% success rate on the Baloo hardware platform. We show that
guiding RL with a simple motion primitive is critical to this success where
standard reward shaping methods struggled to produce a stable and successful
policy for whole-body manipulation. Furthermore, our analysis reveals that the
learned policy does not simply mimic the motion primitive. It exhibits
beneficial reactive behavior, such as re-grasping and perturbation recovery. We
analyze and contrast this learned policy against an open-loop baseline to show
that the policy can also exhibit aggressive over-corrections under
perturbation. To our knowledge, this is the first demonstration of forceful,
six-DoF whole-body manipulation using two continuum soft arms on a large-scale
platform (10 kg payloads), with zero-shot policy transfer.

</details>


### [44] [High Torque Density PCB Axial Flux Permanent Magnet Motor for Micro Robots](https://arxiv.org/abs/2509.23561)
*Jianren Wang,Jie Han,Abhinav Gupta,Deepak Pathak,Yang Zhang*

Main category: cs.RO

TL;DR: 本文开发了一种采用PCB绕组和HDI技术的微型轴向磁通永磁电机，解决了传统绕线定子在小型化时铜填充率低的问题，实现了45%的高铜填充率和紧凑的5mm厚度设计。


<details>
  <summary>Details</summary>
Motivation: 准直驱驱动需要在小尺寸关节包络内提供高扭矩，但传统AFPM电机在直径小于20mm时因铜填充率低导致电阻增加和连续扭矩受限。

Method: 使用印刷电路板绕组和先进IC基板高密度互连技术，通过堆叠四个12层HDI模块形成48层定子结构。

Result: 实现了45%的铜填充率，电机厚度仅5mm，直径19mm，并通过电磁和热分析验证了设计，制造了原型机进行性能测试。

Conclusion: PCB绕组结合HDI技术成功解决了微型AFPM电机的铜填充率限制，为小型化高扭矩电机提供了可行方案。

Abstract: Quasi-direct-drive (QDD) actuation is transforming legged and manipulator
robots by eliminating high-ratio gearboxes, yet it demands motors that deliver
very high torque at low speed within a thin, disc-shaped joint envelope.
Axial-flux permanent-magnet (AFPM) machines meet these geometric and torque
requirements, but scaling them below a 20mm outer diameter is hampered by poor
copper fill in conventional wound stators, inflating resistance and throttling
continuous torque. This paper introduces a micro-scale AFPM motor that
overcomes these limitations through printed-circuit-board (PCB) windings
fabricated with advanced IC-substrate high-density interconnect (HDI)
technology. The resulting 48-layer stator-formed by stacking four 12-layer HDI
modules-achieves a record 45\% copper fill in a package only 5mm thick and 19mm
in diameter. We perform comprehensive electromagnetic and thermal analyses to
inform the motor design, then fabricate a prototype whose performance
characteristics are experimentally verified.

</details>


### [45] [RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation](https://arxiv.org/abs/2509.23563)
*Seungchan Kim,Omar Alama,Dmytro Kurdydyk,John Keller,Nikhil Keetha,Wenshan Wang,Yonatan Bisk,Sebastian Scherer*

Main category: cs.RO

TL;DR: RAVEN是一个基于3D记忆和行为树的空中语义导航框架，用于非结构化户外环境，通过语义体素射线地图实现长程规划，结合短程体素搜索和长程射线搜索，利用大视觉语言模型提供辅助线索，在户外语义导航任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决户外空中语义导航的挑战：现有方法要么局限于室内结构化环境，要么在户外环境中依赖反应式策略导致短视行为，或需要离线预计算场景图而缺乏在线适应性。

Method: 使用空间一致的语义体素射线地图作为持久记忆，结合短程体素搜索和长程射线搜索，利用大视觉语言模型提供辅助线索，通过行为树协调自适应切换行为。

Result: 在10个逼真户外仿真环境中测试100个语义任务，RAVEN比基线方法性能提升85.25%，并在真实户外环境中成功部署验证。

Conclusion: RAVEN框架通过3D记忆、多尺度搜索策略和视觉语言模型的有效结合，成功解决了户外空中语义导航的挑战，实现了鲁棒的长期规划能力。

Abstract: Aerial outdoor semantic navigation requires robots to explore large,
unstructured environments to locate target objects. Recent advances in semantic
navigation have demonstrated open-set object-goal navigation in indoor
settings, but these methods remain limited by constrained spatial ranges and
structured layouts, making them unsuitable for long-range outdoor search. While
outdoor semantic navigation approaches exist, they either rely on reactive
policies based on current observations, which tend to produce short-sighted
behaviors, or precompute scene graphs offline for navigation, limiting
adaptability to online deployment. We present RAVEN, a 3D memory-based,
behavior tree framework for aerial semantic navigation in unstructured outdoor
environments. It (1) uses a spatially consistent semantic voxel-ray map as
persistent memory, enabling long-horizon planning and avoiding purely reactive
behaviors, (2) combines short-range voxel search and long-range ray search to
scale to large environments, (3) leverages a large vision-language model to
suggest auxiliary cues, mitigating sparsity of outdoor targets. These
components are coordinated by a behavior tree, which adaptively switches
behaviors for robust operation. We evaluate RAVEN in 10 photorealistic outdoor
simulation environments over 100 semantic tasks, encompassing single-object
search, multi-class, multi-instance navigation and sequential task changes.
Results show RAVEN outperforms baselines by 85.25% in simulation and
demonstrate its real-world applicability through deployment on an aerial robot
in outdoor field tests.

</details>


### [46] [GES-UniGrasp: A Two-Stage Dexterous Grasping Strategy With Geometry-Based Expert Selection](https://arxiv.org/abs/2509.23567)
*Fangting Xu,Jilin Zhu,Xiaoming Gu,Jianzhong Tang*

Main category: cs.RO

TL;DR: 提出了ContactGrasp数据集和Geometry-based Expert Selection框架，用于实现类人灵巧抓握，在训练集和测试集上分别达到99.4%和96.3%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于抓握先验的强化学习方法往往产生不自然的行为，需要开发更自然的人类化灵巧抓握方法。

Method: 构建ContactGrasp数据集，考虑任务相关手腕方向和拇指-食指捏合协调；通过几何聚类将物体按形状分组，采用两阶段几何专家选择框架选择专门专家。

Result: 展示了自然的抓握姿势，在训练集和测试集上分别达到99.4%和96.3%的高成功率，表现出强大的泛化能力和高质量的抓握执行。

Conclusion: 该方法能够实现类人的灵巧抓握，对多样化物体形状具有良好适应性，并能跨类别泛化。

Abstract: Robust and human-like dexterous grasping of general objects is a critical
capability for advancing intelligent robotic manipulation in real-world
scenarios. However, existing reinforcement learning methods guided by grasp
priors often result in unnatural behaviors. In this work, we present
\textit{ContactGrasp}, a robotic dexterous pre-grasp and grasp dataset that
explicitly accounts for task-relevant wrist orientation and thumb-index
pinching coordination. The dataset covers 773 objects in 82 categories,
providing a rich foundation for training human-like grasp strategies. Building
upon this dataset, we perform geometry-based clustering to group objects by
shape, enabling a two-stage Geometry-based Expert Selection (GES) framework
that selects among specialized experts for grasping diverse object geometries,
thereby enhancing adaptability to diverse shapes and generalization across
categories. Our approach demonstrates natural grasp postures and achieves high
success rates of 99.4\% and 96.3\% on the train and test sets, respectively,
showcasing strong generalization and high-quality grasp execution.

</details>


### [47] [Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints](https://arxiv.org/abs/2509.23575)
*Jianshu Hu,Lidi Wang,Shujia Li,Yunpeng Jiang,Xiao Li,Paul Weng,Yutong Ban*

Main category: cs.RO

TL;DR: 提出CLAP框架，通过任务分解、VLM微调进行3D关键点预测和3D感知表示，增强分层策略在机器人3D操作任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有分层粗到细策略在机器人3D操作任务中虽然提高了样本效率和操作精度，但在面对新指令和环境变化时泛化能力不足。

Method: CLAP框架包含三个关键组件：任务分解、VLM微调进行3D关键点预测、3D感知表示，通过语言对齐增强泛化能力。

Result: 在GemBench基准测试中，平均成功率比SOTA方法提高12%，仅使用1/5的训练轨迹。真实实验中，仅用10个演示就能泛化到新指令和环境。

Conclusion: CLAP框架显著提升了分层策略的泛化能力，在样本效率和泛化性能方面都优于现有方法。

Abstract: Hierarchical coarse-to-fine policy, where a coarse branch predicts a region
of interest to guide a fine-grained action predictor, has demonstrated
significant potential in robotic 3D manipulation tasks by especially enhancing
sample efficiency and enabling more precise manipulation. However, even
augmented with pre-trained models, these hierarchical policies still suffer
from generalization issues. To enhance generalization to novel instructions and
environment variations, we propose Coarse-to-fine Language-Aligned manipulation
Policy (CLAP), a framework that integrates three key components: 1) task
decomposition, 2) VLM fine-tuning for 3D keypoint prediction, and 3) 3D-aware
representation. Through comprehensive experiments in simulation and on a real
robot, we demonstrate its superior generalization capability. Specifically, on
GemBench, a benchmark designed for evaluating generalization, our approach
achieves a 12\% higher average success rate than the SOTA method while using
only 1/5 of the training trajectories. In real-world experiments, our policy,
trained on only 10 demonstrations, successfully generalizes to novel
instructions and environments.

</details>


### [48] [Encoding Material Safety using Control Barrier Functions for Soft Actuator Control](https://arxiv.org/abs/2509.23623)
*Nicholas Pagliocca,Behrad Koohbor,Mitja Trkov*

Main category: cs.RO

TL;DR: 本文提出了基于应变能函数的软体机器人材料安全性正式定义，并开发了使用高阶控制屏障函数和二次规划反馈控制来强制执行材料安全的控制器。


<details>
  <summary>Details</summary>
Motivation: 随着软体机器人向实际应用发展，需要明确定义安全性概念。软体机器人通过变形实现功能，但材料本构模型精度限制和失效风险是所有软体机器人固有的挑战。

Method: 基于应变能函数定义材料安全性，使用高阶控制屏障函数和二次规划反馈控制来强制执行安全约束，以不可压缩超弹性管为案例进行研究。

Result: 仿真结果验证了所提方法能够有效强制执行材料安全规范。

Conclusion: 该工作为软体机器人提供了形式化的安全定义和控制框架，解决了材料失效风险这一关键挑战。

Abstract: Until recently, the concept of soft robot safety was an informal notion,
often attributed solely to the fact that soft robots are less likely to damage
their operating environment than rigid robots. As the field moves toward
feedback control for practical applications, it becomes increasingly important
to define what safety means and to characterize how soft robots can become
unsafe. The unifying theme of soft robotics is to achieve useful functionality
through deformation. Consequently, limitations in constitutive model accuracy
and risks of material failure are inherent to all soft robots and pose a key
challenge in designing provably safe controllers. This work introduces a formal
definition of material safety based on strain energy functions and provides a
controller that enforces it. We characterize safe and unsafe sets of an
incompressible hyperelastic material and demonstrate that safety can be
enforced using a high-order control barrier function (HOCBF) with quadratic
program-based feedback control. As a case study, we consider a pressurized
hyperelastic tube with inertial effects, first-order viscous effects, and
full-state feedback. Simulation results verify that the proposed methodology
can enforce the material safety specification.

</details>


### [49] [KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion](https://arxiv.org/abs/2509.23650)
*Peizhuo Li,Hongyi Li,Yuxuan Ma,Linnan Chang,Xinrong Yang,Ruiqi Yu,Yifeng Zhang,Yuhong Cao,Qiuguo Zhu,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出KiVi框架，通过分离本体感觉和视觉空间推理路径，让四足机器人在复杂地形中稳定运动，视觉感知用于地形感知和避障，本体感觉作为稳定支撑。


<details>
  <summary>Details</summary>
Motivation: 视觉信息易受遮挡、反射和光照变化影响，导致运动不稳定。受动物感觉运动整合启发，需要平衡视觉和本体感觉的整合。

Method: 分离本体感觉和视觉空间推理路径，本体感觉作为稳定主干，选择性整合视觉用于地形感知，结合记忆增强注意力机制。

Result: 四足机器人能稳定穿越多样化地形，在非结构化户外环境中可靠运行，对训练中未见过的视觉噪声和遮挡保持鲁棒性。

Conclusion: KiVi框架通过模态平衡的整合设计，实现了真实世界腿式运动的有效性和适用性。

Abstract: Vision-based locomotion has shown great promise in enabling legged robots to
perceive and adapt to complex environments. However, visual information is
inherently fragile, being vulnerable to occlusions, reflections, and lighting
changes, which often cause instability in locomotion. Inspired by animal
sensorimotor integration, we propose KiVi, a Kinesthetic-Visuospatial
integration framework, where kinesthetics encodes proprioceptive sensing of
body motion and visuospatial reasoning captures visual perception of
surrounding terrain. Specifically, KiVi separates these pathways, leveraging
proprioception as a stable backbone while selectively incorporating vision for
terrain awareness and obstacle avoidance. This modality-balanced, yet
integrative design, combined with memory-enhanced attention, allows the robot
to robustly interpret visual cues while maintaining fallback stability through
proprioception. Extensive experiments show that our method enables quadruped
robots to stably traverse diverse terrains and operate reliably in unstructured
outdoor environments, remaining robust to out-of-distribution (OOD) visual
noise and occlusion unseen during training, thereby highlighting its
effectiveness and applicability to real-world legged locomotion.

</details>


### [50] [HeLoM: Hierarchical Learning for Whole-Body Loco-Manipulation in Hexapod Robot](https://arxiv.org/abs/2509.23651)
*Xinrong Yang,Peizhuo Li,Hongyi Li,Junkai Lu,Linnan Chang,Yuhong Cao,Yifeng Zhang,Ge Sun,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出HeLoM框架，让六足机器人通过协调多肢体控制实现稳定推重物操作


<details>
  <summary>Details</summary>
Motivation: 机器人需要推举与自身重量相当的物体，推操作比抓取更直接高效，但需要足够的推力和稳定性，特别是对重型或不规则物体

Method: 分层学习框架：高层规划推行为和目标姿态，低层控制器维持运动稳定性并生成动态一致的关节动作，利用冗余接触点协调多肢体控制

Result: 仿真训练的策略可直接部署到真实机器人，无需微调，能够稳定推动不同尺寸和未知物理属性的箱子到指定目标位置

Conclusion: HeLoM框架通过协调多肢体控制，使六足机器人能够稳定推动重物，验证了在真实环境中的有效性

Abstract: Robots in real-world environments are often required to move/manipulate
objects comparable in weight to their own bodies. Compared to grasping and
carrying, pushing provides a more straightforward and efficient non-prehensile
manipulation strategy, avoiding complex grasp design while leveraging direct
contact to regulate an object's pose. Achieving effective pushing, however,
demands both sufficient manipulation forces and the ability to maintain
stability, which is particularly challenging when dealing with heavy or
irregular objects. To address these challenges, we propose HeLoM, a
learning-based hierarchical whole-body manipulation framework for a hexapod
robot that exploits coordinated multi-limb control. Inspired by the cooperative
strategies of multi-legged insects, our framework leverages redundant contact
points and high degrees of freedom to enable dynamic redistribution of contact
forces. HeLoM's high-level planner plans pushing behaviors and target object
poses, while its low-level controller maintains locomotion stability and
generates dynamically consistent joint actions. Our policies trained in
simulation are directly deployed on real robots without additional fine-tuning.
This design allows the robot to maintain balance while exerting continuous and
controllable pushing forces through coordinated foreleg interaction and
supportive hind-leg propulsion. We validate the effectiveness of HeLoM through
both simulation and real-world experiments. Results show that our framework can
stably push boxes of varying sizes and unknown physical properties to
designated goal poses in the real world.

</details>


### [51] [Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models](https://arxiv.org/abs/2509.23655)
*Rokas Bendikas,Daniel Dijkman,Markus Peschl,Sanjay Haresh,Pietro Mazzaglia*

Main category: cs.RO

TL;DR: Oat-VLA提出了一种面向对象和智能体的视觉标记化方法，通过减少视觉标记数量来显著提高Vision-Language-Action模型训练效率，在保持性能的同时实现至少两倍的收敛速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有Vision-Language-Action模型在适应机器人领域时计算成本过高，主要问题在于视觉输入的标记化方案效率低下。

Method: 提出Oat-VLA方法，基于对象中心表示学习的思想，引入对场景对象和智能体自身视觉信息的归纳偏置，将视觉标记数量大幅减少到仅几个标记。

Result: 在LIBERO套件上收敛速度至少是OpenVLA的两倍，在多样化真实世界拾取放置任务中性能优于OpenVLA。

Conclusion: Oat-VLA通过高效的视觉标记化方案成功解决了VLA模型训练中的计算效率问题，为大规模机器人操作学习提供了更实用的解决方案。

Abstract: Vision-Language-Action (VLA) models offer a pivotal approach to learning
robotic manipulation at scale by repurposing large pre-trained
Vision-Language-Models (VLM) to output robotic actions. However, adapting VLMs
for robotic domains comes with an unnecessarily high computational cost, which
we attribute to the tokenization scheme of visual inputs. In this work, we aim
to enable efficient VLA training by proposing Oat-VLA, an Object-Agent-centric
Tokenization for VLAs. Building on the insights of object-centric
representation learning, our method introduces an inductive bias towards scene
objects and the agent's own visual information. As a result, we find that
Oat-VLA can drastically reduce the number of visual tokens to just a few tokens
without sacrificing performance. We reveal that Oat-VLA converges at least
twice as fast as OpenVLA on the LIBERO suite, as well as outperform OpenVLA in
diverse real-world pick and place tasks.

</details>


### [52] [Certifiably Optimal State Estimation and Robot Calibration Using Trace-Constrained SDP](https://arxiv.org/abs/2509.23656)
*Liangting Wu,Roberto Tron*

Main category: cs.RO

TL;DR: 该论文提出了一种基于迹约束半定规划的机器人问题求解框架，通过固定迹约束和梯度优化方法有效恢复秩1解，并在多个机器人标定任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 许多机器人学中的非凸问题可以通过半定规划松弛为凸问题，但实际解的质量取决于能否获得秩1矩阵。迹约束不仅捕捉结构特性，还便于使用一阶方法恢复秩1解。

Method: 引入定制化的固定迹变量和约束来表示旋转和平移等机器人量，开发基于梯度的精炼过程将松弛解投影到秩1候选解，并通过对偶问题验证全局最优性。

Result: 该框架成功应用于PnP估计、手眼标定和双机器人系统标定等任务，展示了其有效性。

Conclusion: 迹约束SDP框架为机器人问题提供了有效的求解方法，通过模块化的"虚拟机器人"抽象简化了不同问题场景的建模。

Abstract: Many nonconvex problems in robotics can be relaxed into convex formulations
via semidefinite programming (SDP), which offers the advantage of global
optimality. The practical quality of these solutions, however, critically
depends on achieving rank-1 matrices, a condition that typically requires
additional tightening. In this work, we focus on trace-constrained SDPs, where
the decision variables are positive semidefinite (PSD) matrices with fixed
trace values. These additional constraints not only capture important
structural properties but also facilitate first-order methods for recovering
rank-1 solutions. We introduce customized fixed-trace variables and constraints
to represent common robotic quantities such as rotations and translations,
which can be exactly recovered when the corresponding variables are rank-1. To
further improve practical performance, we develop a gradient-based refinement
procedure that projects relaxed SDP solutions toward rank-1, low-cost
candidates, which can then be certified for global optimality via the dual
problem. We demonstrate that many robotics tasks can be expressed within this
trace-constrained SDP framework, and showcase its effectiveness through
simulations in perspective-n-point (PnP) estimation, hand-eye calibration, and
dual-robot system calibration. To support broader use, we also introduce a
modular ``virtual robot'' abstraction that simplifies modeling across different
problem settings.

</details>


### [53] [MDCPP: Multi-robot Dynamic Coverage Path Planning for Workload Adaptation](https://arxiv.org/abs/2509.23705)
*Jun Chen,Mingjia Chen,Shinkyu Park*

Main category: cs.RO

TL;DR: 提出了一种多机器人动态覆盖路径规划算法，通过动态估计机器人工作负载和使用容量约束Voronoi图来分配覆盖区域，解决了传统方法中固定速度假设导致的负载不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人覆盖路径规划方法假设机器人以固定速度移动，这在现实应用中不切实际，导致工作负载分布不均和任务完成时间增加。

Method: 使用高斯混合模型近似目标分布来动态估计每个机器人的剩余工作负载，并采用容量约束Voronoi图分配覆盖区域，还开发了分布式实现用于通信范围受限的机器人网络。

Result: 仿真结果表明MDCPP算法在性能上优于现有的扫描算法，并量化了通信范围对覆盖效率的影响。

Conclusion: MDCPP算法能够有效解决多机器人覆盖路径规划中的动态负载分配问题，提高覆盖效率。

Abstract: Multi-robot Coverage Path Planning (MCPP) addresses the problem of computing
paths for multiple robots to effectively cover a large area of interest.
Conventional approaches to MCPP typically assume that robots move at fixed
velocities, which is often unrealistic in real-world applications where robots
must adapt their speeds based on the specific coverage tasks assigned to
them.Consequently, conventional approaches often lead to imbalanced workload
distribution among robots and increased completion time for coverage tasks. To
address this, we introduce a novel Multi-robot Dynamic Coverage Path Planning
(MDCPP) algorithm for complete coverage in two-dimensional environments. MDCPP
dynamically estimates each robot's remaining workload by approximating the
target distribution with Gaussian mixture models, and assigns coverage regions
using a capacity-constrained Voronoi diagram. We further develop a distributed
implementation of MDCPP for range-constrained robotic networks. Simulation
results validate the efficacy of MDCPP, showing qualitative improvements and
superior performance compared to an existing sweeping algorithm, and a
quantifiable impact of communication range on coverage efficiency.

</details>


### [54] [DA-MMP: Learning Coordinated and Accurate Throwing with Dynamics-Aware Motion Manifold Primitives](https://arxiv.org/abs/2509.23721)
*Chi Chu,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出了Dynamics-Aware Motion Manifold Primitives (DA-MMP)框架，用于目标条件动态操作，在环抛任务中通过紧凑参数化扩展运动流形原语，结合条件流匹配模型生成考虑执行动力学的投掷轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖手动设计的动作参数化，难以产生复杂任务所需的高度协调运动；运动规划存在动力学差距问题，导致规划轨迹与实际执行轨迹偏差较大。

Method: 扩展运动流形原语支持变长轨迹，从大规模规划运动数据学习高质量流形，在潜在空间训练条件流匹配模型，利用少量真实世界试验数据生成考虑执行动力学的投掷轨迹。

Result: 在环抛任务中生成协调平滑的运动轨迹，真实世界评估达到高成功率，甚至超越训练有素的人类专家表现，并能泛化到训练范围之外的新目标。

Conclusion: DA-MMP成功学习了轨迹-动力学映射，为动态操作任务提供了有效的运动生成框架，在复杂动态任务中表现出优越性能。

Abstract: Dynamic manipulation is a key capability for advancing robot performance,
enabling skills such as tossing. While recent learning-based approaches have
pushed the field forward, most methods still rely on manually designed action
parameterizations, limiting their ability to produce the highly coordinated
motions required in complex tasks. Motion planning can generate feasible
trajectories, but the dynamics gap-stemming from control inaccuracies, contact
uncertainties, and aerodynamic effects-often causes large deviations between
planned and executed trajectories. In this work, we propose Dynamics-Aware
Motion Manifold Primitives (DA-MMP), a motion generation framework for
goal-conditioned dynamic manipulation, and instantiate it on a challenging
real-world ring-tossing task. Our approach extends motion manifold primitives
to variable-length trajectories through a compact parametrization and learns a
high-quality manifold from a large-scale dataset of planned motions. Building
on this manifold, a conditional flow matching model is trained in the latent
space with a small set of real-world trials, enabling the generation of
throwing trajectories that account for execution dynamics. Experiments show
that our method can generate coordinated and smooth motion trajectories for the
ring-tossing task. In real-world evaluations, it achieves high success rates
and even surpasses the performance of trained human experts. Moreover, it
generalizes to novel targets beyond the training range, indicating that it
successfully learns the underlying trajectory-dynamics mapping.

</details>


### [55] [LocoFormer: Generalist Locomotion via Long-context Adaptation](https://arxiv.org/abs/2509.23745)
*Min Liu,Deepak Pathak,Ananye Agarwal*

Main category: cs.RO

TL;DR: LocoFormer是一个通用的全身运动控制模型，能够控制未见过的腿式和轮式机器人，无需精确的运动学知识，并能适应形态和动态变化。


<details>
  <summary>Details</summary>
Motivation: 现代运动控制器通常针对特定机器人手动调优，缺乏通用性和适应性。本文旨在开发一个能够控制各种不同形态机器人的通用运动模型。

Method: 1. 在程序生成的机器人上进行大规模强化学习训练；2. 使用激进的领域随机化；3. 大幅扩展上下文长度，跨越episode边界。

Result: LocoFormer能够部署到各种机器人上，即使在重量变化和电机故障等大扰动下也能保持鲁棒控制。在极端场景中，模型能够跨episode学习，从早期跌倒中学习改进控制策略。

Conclusion: 这种简单而通用的方法可以用于训练其他机器人技能的基础模型，为通用机器人控制提供了有前景的解决方案。

Abstract: Modern locomotion controllers are manually tuned for specific embodiments. We
present LocoFormer, a generalist omni-bodied locomotion model that can control
previously unseen legged and wheeled robots, even without precise knowledge of
their kinematics. LocoFormer is able to adapt to changes in morphology and
dynamics at test time. We find that two key choices enable adaptation. First,
we train massive scale RL on procedurally generated robots with aggressive
domain randomization. Second, in contrast to previous policies that are myopic
with short context lengths, we extend context by orders of magnitude to span
episode boundaries. We deploy the same LocoFormer to varied robots and show
robust control even with large disturbances such as weight change and motor
failures. In extreme scenarios, we see emergent adaptation across episodes,
LocoFormer learns from falls in early episodes to improve control strategies in
later ones. We believe that this simple, yet general recipe can be used to
train foundation models for other robotic skills in the future. Videos at
generalist-locomotion.github.io.

</details>


### [56] [Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse](https://arxiv.org/abs/2509.23778)
*Zeyuan Zhang,Chaoran Li,Shao Zhang,Ying Wen*

Main category: cs.RO

TL;DR: 提出了Sequential Pathfinder (SePar)方法，使用Transformer范式解决多智能体拾取配送问题，通过序列建模实现隐式信息交换，将决策复杂度从指数级降至线性级。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在仓库等狭窄环境中仅依赖局部观测时表现不佳，而通信学习虽然能缓解全局信息缺失问题，但点对点通信带来了高计算复杂度。

Method: 将MAPF建模为序列建模问题，利用Transformer架构实现隐式信息交换，结合模仿学习处理复杂地图环境。

Result: SePar在各种MAPF任务及其变体上持续优于现有基于学习的方法，并在未见环境中表现出良好的泛化能力。

Conclusion: 序列建模方法为MAPD问题提供了有效的解决方案，证明了路径规划策略在序列建模下具有顺序不变的最优性，同时强调了在复杂地图中集成模仿学习的必要性。

Abstract: Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of
Multi-Agent Path Finding (MAPF), where agents are required to sequentially
complete tasks with fixed-location pickup and delivery demands. Although
learning-based methods have made progress in MAPD, they often perform poorly in
warehouse-like environments with narrow pathways and long corridors when
relying only on local observations for distributed decision-making.
Communication learning can alleviate the lack of global information but
introduce high computational complexity due to point-to-point communication. To
address this challenge, we formulate MAPF as a sequence modeling problem and
prove that path-finding policies under sequence modeling possess
order-invariant optimality, ensuring its effectiveness in MAPD. Building on
this, we propose the Sequential Pathfinder (SePar), which leverages the
Transformer paradigm to achieve implicit information exchange, reducing
decision-making complexity from exponential to linear while maintaining
efficiency and global awareness. Experiments demonstrate that SePar
consistently outperforms existing learning-based methods across various MAPF
tasks and their variants, and generalizes well to unseen environments.
Furthermore, we highlight the necessity of integrating imitation learning in
complex maps like warehouses.

</details>


### [57] [High-Precision Climbing Robot Localization Using Planar Array UWB/GPS/IMU/Barometer Integration](https://arxiv.org/abs/2509.23801)
*Shuning Zhang,Renjing Xu,Zhanchen Zhu,Xiangyu Chen,Yunheng Wang,Xu Jiang,Peibo Duan*

Main category: cs.RO

TL;DR: 提出了一种基于注意力机制的多传感器融合系统，用于复杂高空环境中爬壁机器人的高精度定位，通过融合UWB、GPS、IMU和气压计数据，解决了GPS遮挡和UWB非视距问题。


<details>
  <summary>Details</summary>
Motivation: 解决复杂高空环境下爬壁机器人定位精度不足的问题，克服单传感器方法的局限性，特别是在GPS信号遮挡和UWB非视距传播等挑战性场景下。

Method: 设计了基于注意力机制的融合算法(AMFA)，结合平面阵列UWB、GPS、IMU和气压计；开发了UWB和气压计的端到端神经网络推理模型；采用多模态注意力机制进行自适应数据融合；应用无迹卡尔曼滤波器(UKF)优化轨迹。

Result: 实验结果显示该方法实现了0.48米的定位精度，最大误差为1.50米，优于GPS/INS-EKF等基线算法，并展现出更强的鲁棒性。

Conclusion: 所提出的多传感器融合系统在复杂高空环境中有效提高了爬壁机器人的定位精度和鲁棒性，为类似应用场景提供了可行的解决方案。

Abstract: To address the need for high-precision localization of climbing robots in
complex high-altitude environments, this paper proposes a multi-sensor fusion
system that overcomes the limitations of single-sensor approaches. Firstly, the
localization scenarios and the problem model are analyzed. An integrated
architecture of Attention Mechanism-based Fusion Algorithm (AMFA) incorporating
planar array Ultra-Wideband (UWB), GPS, Inertial Measurement Unit (IMU), and
barometer is designed to handle challenges such as GPS occlusion and UWB
Non-Line-of-Sight (NLOS) problem. Then, End-to-end neural network inference
models for UWB and barometer are developed, along with a multimodal attention
mechanism for adaptive data fusion. An Unscented Kalman Filter (UKF) is applied
to refine the trajectory, improving accuracy and robustness. Finally,
real-world experiments show that the method achieves 0.48 m localization
accuracy and lower MAX error of 1.50 m, outperforming baseline algorithms such
as GPS/INS-EKF and demonstrating stronger robustness.

</details>


### [58] [Fostering Robots: A Governance-First Conceptual Framework for Domestic, Curriculum-Based Trajectory Collection](https://arxiv.org/abs/2509.23821)
*Federico Pablo-Marti,Carlos Mir Fernandez*

Main category: cs.RO

TL;DR: 提出了机器人培育的概念框架，这是一种以课程驱动、治理优先的家庭机器人部署方法，强调长期的、精心策划的交互轨迹。


<details>
  <summary>Details</summary>
Motivation: 为家庭机器人部署提供一个概念性和经验可测试的框架，强调长期交互轨迹的质量和治理标准。

Method: 形式化轨迹质量，使用可量化的指标和评估协议，符合欧盟级治理标准，并制定低资源经验路线图。

Result: 提出了一个框架，能够通过未来的试点研究进行严格验证。

Conclusion: 机器人培育框架为家庭机器人的长期部署提供了理论基础和实证验证路径，强调治理和交互质量。

Abstract: We propose a conceptual, empirically testable framework for Robot Fostering,
-a curriculum-driven, governance-first approach to domestic robot deployments,
emphasizing long-term, curated interaction trajectories. We formalize
trajectory quality with quantifiable metrics and evaluation protocols aligned
with EU-grade governance standards, delineating a low-resource empirical
roadmap to enable rigorous validation through future pilot studies.

</details>


### [59] [Control Your Robot: A Unified System for Robot Control and Policy Deployment](https://arxiv.org/abs/2509.23823)
*Tian Nian,Weijie Ke,Yao Mu,Tianxing Chen,Shaolong Zhu,Bingshan Hu*

Main category: cs.RO

TL;DR: Control Your Robot是一个模块化、通用框架，通过标准化工作流、统一API和闭环架构，解决了跨平台机器人控制中的硬件接口、数据格式和控制范式碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 跨平台机器人控制面临硬件接口、数据格式和控制范式差异大的挑战，导致工具链碎片化，部署速度慢。需要统一框架来简化数据收集和策略部署。

Method: 采用模块化设计、统一API和闭环架构，支持灵活的机器人注册、双模式控制（遥操作和轨迹回放），以及从多模态数据采集到推理的无缝集成。

Result: 在单臂和双臂系统上的实验显示，该系统能够高效、低延迟地收集数据，并有效支持模仿学习和视觉-语言-动作模型的策略学习。

Conclusion: 使用Control Your Robot收集的数据训练的策略与专家演示高度匹配，表明该框架能够实现跨平台的可扩展和可复现的机器人学习。

Abstract: Cross-platform robot control remains difficult because hardware interfaces,
data formats, and control paradigms vary widely, which fragments toolchains and
slows deployment. To address this, we present Control Your Robot, a modular,
general-purpose framework that unifies data collection and policy deployment
across diverse platforms. The system reduces fragmentation through a
standardized workflow with modular design, unified APIs, and a closed-loop
architecture. It supports flexible robot registration, dual-mode control with
teleoperation and trajectory playback, and seamless integration from multimodal
data acquisition to inference. Experiments on single-arm and dual-arm systems
show efficient, low-latency data collection and effective support for policy
learning with imitation learning and vision-language-action models. Policies
trained on data gathered by Control Your Robot match expert demonstrations
closely, indicating that the framework enables scalable and reproducible robot
learning across platforms.

</details>


### [60] [DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation](https://arxiv.org/abs/2509.23829)
*Kefei Zhu,Fengshuo Bai,YuanHao Xiang,Yishuai Cai,Xinglin Chen,Ruochong Li,Xingtao Wang,Hao Dong,Yaodong Yang,Xiaopeng Fan,Yuanpei Chen*

Main category: cs.RO

TL;DR: DexFlyWheel是一个可扩展的灵巧操作数据生成框架，通过自改进循环不断丰富数据多样性，在四个挑战性任务中生成2000多个多样化演示，训练出的策略在真实世界中达到78.3%的成功率。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作对提升机器人真实世界应用能力至关重要，但现有数据收集方法依赖人工遥操作或需要大量人工工程，生成的数据多样性有限，限制了可扩展性和泛化能力。

Method: 采用自改进循环框架：从种子演示开始，通过模仿学习提取人类行为，残差强化学习增强策略泛化，在仿真中生成轨迹，进行环境和空间配置的数据增强，形成数据飞轮效应。

Result: 生成超过2000个多样化演示，训练的策略在挑战测试集上平均成功率81.9%，通过数字孪生迁移到真实世界，在双臂提升任务中达到78.3%成功率。

Conclusion: DexFlyWheel框架能够有效生成多样化灵巧操作数据集，显著提升策略性能并成功实现从仿真到真实世界的迁移。

Abstract: Dexterous manipulation is critical for advancing robot capabilities in
real-world applications, yet diverse and high-quality datasets remain scarce.
Existing data collection methods either rely on human teleoperation or require
significant human engineering, or generate data with limited diversity, which
restricts their scalability and generalization. In this paper, we introduce
DexFlyWheel, a scalable data generation framework that employs a self-improving
cycle to continuously enrich data diversity. Starting from efficient seed
demonstrations warmup, DexFlyWheel expands the dataset through iterative
cycles. Each cycle follows a closed-loop pipeline that integrates Imitation
Learning (IL), residual Reinforcement Learning (RL), rollout trajectory
collection, and data augmentation. Specifically, IL extracts human-like
behaviors from demonstrations, and residual RL enhances policy generalization.
The learned policy is then used to generate trajectories in simulation, which
are further augmented across diverse environments and spatial configurations
before being fed back into the next cycle. Over successive iterations, a
self-improving data flywheel effect emerges, producing datasets that cover
diverse scenarios and thereby scaling policy performance. Experimental results
demonstrate that DexFlyWheel generates over 2,000 diverse demonstrations across
four challenging tasks. Policies trained on our dataset achieve an average
success rate of 81.9\% on the challenge test sets and successfully transfer to
the real world through digital twin, achieving a 78.3\% success rate on
dual-arm lift tasks.

</details>


### [61] [MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control](https://arxiv.org/abs/2509.23960)
*Manan Tayal,Aditya Singh,Shishir Kolathaya,Somil Bansal*

Main category: cs.RO

TL;DR: 提出MAD-PINN框架，通过物理信息神经网络解决多智能体状态约束最优控制问题，实现安全与性能的协同优化。


<details>
  <summary>Details</summary>
Motivation: 现有MARL、安全过滤或MPC方法要么缺乏严格安全保证，要么过于保守或难以扩展，需要新的解决方案。

Method: 采用基于外延的重构方法，利用物理信息神经网络近似SC-OCP值函数，结合HJ可达性邻居选择策略和滚动时域策略执行。

Result: 在多智能体导航任务中，MAD-PINN实现了优越的安全-性能权衡，保持可扩展性，并优于现有最优方法。

Conclusion: MAD-PINN为大规模多智能体系统提供了一种有效解决安全与性能协同优化的去中心化框架。

Abstract: Co-optimizing safety and performance in large-scale multi-agent systems
remains a fundamental challenge. Existing approaches based on multi-agent
reinforcement learning (MARL), safety filtering, or Model Predictive Control
(MPC) either lack strict safety guarantees, suffer from conservatism, or fail
to scale effectively. We propose MAD-PINN, a decentralized physics-informed
machine learning framework for solving the multi-agent state-constrained
optimal control problem (MASC-OCP). Our method leverages an epigraph-based
reformulation of SC-OCP to simultaneously capture performance and safety, and
approximates its solution via a physics-informed neural network. Scalability is
achieved by training the SC-OCP value function on reduced-agent systems and
deploying them in a decentralized fashion, where each agent relies only on
local observations of its neighbours for decision-making. To further enhance
safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based
neighbour selection strategy to prioritize safety-critical interactions, and a
receding-horizon policy execution scheme that adapts to dynamic interactions
while reducing computational burden. Experiments on multi-agent navigation
tasks demonstrate that MAD-PINN achieves superior safety-performance
trade-offs, maintains scalability as the number of agents grows, and
consistently outperforms state-of-the-art baselines.

</details>


### [62] [Prepare for Warp Speed: Sub-millisecond Visual Place Recognition Using Event Cameras](https://arxiv.org/abs/2509.24094)
*Vignesh Ramanathan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Flash是一个轻量级视觉位置识别系统，使用亚毫秒级事件数据片段进行位置预测，通过二进制帧编码活跃像素位置并利用快速位运算计算相似度。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的VPR方法依赖密集表示且需要数十到数百毫秒的事件数据，Flash旨在突破这一范式，实现亚毫秒级的位置识别。

Method: 基于活跃像素位置提供强判别特征的观察，Flash使用高效的二进制帧编码活跃像素位置，通过快速位运算计算相似度，并根据查询帧和参考帧的相对事件活动进行归一化。

Result: 在室内QCR-Event-Dataset上Recall@1提升11.33倍，在8公里Brisbane-Event-VPR数据集上提升5.92倍，显著减少了机器人无位置感知的运行时间。

Conclusion: Flash首次实现了基于事件相机的亚毫秒级视觉位置识别，显著提高了识别速度和精度，降低了定位延迟。

Abstract: Visual Place Recognition (VPR) enables systems to identify previously visited
locations within a map, a fundamental task for autonomous navigation. Prior
works have developed VPR solutions using event cameras, which asynchronously
measure per-pixel brightness changes with microsecond temporal resolution.
However, these approaches rely on dense representations of the inherently
sparse camera output and require tens to hundreds of milliseconds of event data
to predict a place. Here, we break this paradigm with Flash, a lightweight VPR
system that predicts places using sub-millisecond slices of event data. Our
method is based on the observation that active pixel locations provide strong
discriminative features for VPR. Flash encodes these active pixel locations
using efficient binary frames and computes similarities via fast bitwise
operations, which are then normalized based on the relative event activity in
the query and reference frames. Flash improves Recall@1 for sub-millisecond VPR
over existing baselines by 11.33x on the indoor QCR-Event-Dataset and 5.92x on
the 8 km Brisbane-Event-VPR dataset. Moreover, our approach reduces the
duration for which the robot must operate without awareness of its position, as
evidenced by a localization latency metric we term Time to Correct Match (TCM).
To the best of our knowledge, this is the first work to demonstrate
sub-millisecond VPR using event cameras.

</details>


### [63] [Ancestry Tree Clustering for Particle Filter Diversity Maintenance](https://arxiv.org/abs/2509.24124)
*Ilari Vallivaara,Bingnan Duan,Yinhuan Dong,Tughrul Arslan*

Main category: cs.RO

TL;DR: 提出了一种基于粒子祖先树拓扑结构的线性时间多样性维护方法，通过聚类密切相关的粒子来防止多模态环境中的过早收敛。


<details>
  <summary>Details</summary>
Motivation: 在多模态环境中，粒子滤波器容易过早收敛到单一模式，需要有效的多样性维护机制来保持对多个可能状态的跟踪。

Method: 基于粒子祖先树的拓扑结构进行聚类，将密切相关的粒子分组，结合簇内适应度共享和未聚类粒子的保护机制。

Result: 在多模态机器人仿真和真实室内环境中验证，相比确定性重采样和粒子高斯混合等方法，实现了高成功率且对紧凑性影响很小。

Conclusion: 该方法在不同领域和挑战性初始条件下表现出强鲁棒性，能有效防止过早收敛同时保持估计紧凑性。

Abstract: We propose a method for linear-time diversity maintenance in particle
filtering. It clusters particles based on ancestry tree topology: closely
related particles in sufficiently large subtrees are grouped together. The main
idea is that the tree structure implicitly encodes similarity without the need
for spatial or other domain-specific metrics. This approach, when combined with
intra-cluster fitness sharing and the protection of particles not included in a
cluster, effectively prevents premature convergence in multimodal environments
while maintaining estimate compactness. We validate our approach in a
multimodal robotics simulation and a real-world multimodal indoor environment.
We compare the performance to several diversity maintenance algorithms from the
literature, including Deterministic Resampling and Particle Gaussian Mixtures.
Our algorithm achieves high success rates with little to no negative effect on
compactness, showing particular robustness to different domains and challenging
initial conditions.

</details>


### [64] [BOSfM: A View Planning Framework for Optimal 3D Reconstruction of Agricultural Scenes](https://arxiv.org/abs/2509.24126)
*Athanasios Bacharis,Konstantinos D. Polyzos,Georgios B. Giannakis,Nikolaos Papanikolopoulos*

Main category: cs.RO

TL;DR: 提出了一种基于贝叶斯优化的视点规划框架，用于在农业环境中高效选择最优相机位置，以最少但信息丰富的2D图像实现准确的3D重建。


<details>
  <summary>Details</summary>
Motivation: 解决主动视觉中相机位置噪声和图像噪声的挑战，同时实现在未知相似农业环境中的良好泛化能力，避免重新优化或重新训练的需求。

Method: 采用基于重建质量的优化公式，利用'运动恢复结构'概念从选定2D图像重建3D环境。由于优化函数无解析表达式且评估成本高，提出贝叶斯优化方法，仅需少量函数评估即可完成视点规划过程。

Result: 在模拟和真实农业环境中的数值测试表明，该方法能有效估计最优相机位置，准确重建3D环境，并在相似未知环境中具有良好的泛化性能。

Conclusion: 所提出的视点规划框架能够高效处理噪声挑战，通过少量相机位置实现准确的3D重建，并具有良好的泛化能力，适用于农业环境监测等应用。

Abstract: Active vision (AV) has been in the spotlight of robotics research due to its
emergence in numerous applications including agricultural tasks such as
precision crop monitoring and autonomous harvesting to list a few. A major AV
problem that gained popularity is the 3D reconstruction of targeted
environments using 2D images from diverse viewpoints. While collecting and
processing a large number of arbitrarily captured 2D images can be arduous in
many practical scenarios, a more efficient solution involves optimizing the
placement of available cameras in 3D space to capture fewer, yet more
informative, images that provide sufficient visual information for effective
reconstruction of the environment of interest. This process termed as view
planning (VP), can be markedly challenged (i) by noise emerging in the location
of the cameras and/or in the extracted images, and (ii) by the need to
generalize well in other unknown similar agricultural environments without need
for re-optimizing or re-training. To cope with these challenges, the present
work presents a novel VP framework that considers a reconstruction
quality-based optimization formulation that relies on the notion of
`structure-from-motion' to reconstruct the 3D structure of the sought
environment from the selected 2D images. With no analytic expression of the
optimization function and with costly function evaluations, a Bayesian
optimization approach is proposed to efficiently carry out the VP process using
only a few function evaluations, while accounting for different noise cases.
Numerical tests on both simulated and real agricultural settings signify the
benefits of the advocated VP approach in efficiently estimating the optimal
camera placement to accurately reconstruct 3D environments of interest, and
generalize well on similar unknown environments.

</details>


### [65] [Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress](https://arxiv.org/abs/2509.24129)
*Priyanka Mandikal,Jiaheng Hu,Shivin Dass,Sagnik Majumder,Roberto Martín-Martín,Kristen Grauman*

Main category: cs.RO

TL;DR: SPARTA是首个统一处理物体状态变化操作任务的框架，通过空间渐进式物体变化分割图来感知可操作区域与已变换区域，生成结构化策略观察和密集奖励，支持强化学习和贪心控制两种策略变体。


<details>
  <summary>Details</summary>
Motivation: 大多数机器人操作关注物体的运动状态变化（如抓取、放置），但现实世界中许多任务涉及物体物理和视觉状态的渐进式变化（如捣碎、涂抹、切割），这些任务缺乏统一的处理框架。

Method: SPARTA基于空间渐进式物体变化分割图，将物体状态变化表示为从可操作区域向变换区域的过渡，生成结构化策略观察和密集奖励，提供强化学习和贪心控制两种策略变体。

Result: 在真实机器人上验证了3个具有挑战性的任务和10种不同真实物体，相比稀疏奖励和视觉目标条件基线，在训练时间和准确性方面取得了显著提升。

Conclusion: 基于进度感知的视觉表示是处理更广泛物体状态操作任务的多功能基础，SPARTA框架为这类任务提供了有效的解决方案。

Abstract: Most robot manipulation focuses on changing the kinematic state of objects:
picking, placing, opening, or rotating them. However, a wide range of
real-world manipulation tasks involve a different class of object state
change--such as mashing, spreading, or slicing--where the object's physical and
visual state evolve progressively without necessarily changing its position. We
present SPARTA, the first unified framework for the family of object state
change manipulation tasks. Our key insight is that these tasks share a common
structural pattern: they involve spatially-progressing, object-centric changes
that can be represented as regions transitioning from an actionable to a
transformed state. Building on this insight, SPARTA integrates spatially
progressing object change segmentation maps, a visual skill to perceive
actionable vs. transformed regions for specific object state change tasks, to
generate a) structured policy observations that strip away appearance
variability, and b) dense rewards that capture incremental progress over time.
These are leveraged in two SPARTA policy variants: reinforcement learning for
fine-grained control without demonstrations or simulation; and greedy control
for fast, lightweight deployment. We validate SPARTA on a real robot for three
challenging tasks across 10 diverse real-world objects, achieving significant
improvements in training time and accuracy over sparse rewards and visual
goal-conditioned baselines. Our results highlight progress-aware visual
representations as a versatile foundation for the broader family of object
state manipulation tasks. Project website:
https://vision.cs.utexas.edu/projects/sparta-robot

</details>


### [66] [A Novel Model for 3D Motion Planning for a Generalized Dubins Vehicle with Pitch and Yaw Rate Constraints](https://arxiv.org/abs/2509.24143)
*Deepak Prakash Kumar,Swaroop Darbha,Satyanarayana Gupta Manyam,David Casbeer*

Main category: cs.RO

TL;DR: 提出了一种新的固定翼无人机3D运动规划方法和快速算法，考虑完整车辆姿态（滚转、俯仰、偏航角）和双控制输入，生成满足运动约束的最短路径。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅考虑俯仰和/或航向角，无法唯一确定姿态；且大多依赖单一输入（如路径曲率），无法准确建模3D运动学。需要更完整的姿态表示和更精确的控制模型。

Method: 使用旋转最小化框架描述车辆配置及其演化，通过连接球面、圆柱面或平面上的最优Dubins路径来构建路径，采用两个控制输入表示有界俯仰和偏航速率。

Result: 数值模拟显示该方法平均在10秒内生成可行路径，在大多数情况下比现有方法产生更短的路径。

Conclusion: 该方法能够有效处理固定翼无人机的完整3D运动规划问题，提供更准确的运动学建模和更优的路径规划性能。

Abstract: In this paper, we propose a new modeling approach and a fast algorithm for 3D
motion planning, applicable for fixed-wing unmanned aerial vehicles. The goal
is to construct the shortest path connecting given initial and final
configurations subject to motion constraints. Our work differs from existing
literature in two ways. First, we consider full vehicle orientation using a
body-attached frame, which includes roll, pitch, and yaw angles. However,
existing work uses only pitch and/or heading angle, which is insufficient to
uniquely determine orientation. Second, we use two control inputs to represent
bounded pitch and yaw rates, reflecting control by two separate actuators. In
contrast, most previous methods rely on a single input, such as path curvature,
which is insufficient for accurately modeling the vehicle's kinematics in 3D.
We use a rotation minimizing frame to describe the vehicle's configuration and
its evolution, and construct paths by concatenating optimal Dubins paths on
spherical, cylindrical, or planar surfaces. Numerical simulations show our
approach generates feasible paths within 10 seconds on average and yields
shorter paths than existing methods in most cases.

</details>


### [67] [Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation](https://arxiv.org/abs/2509.24160)
*Tomoyuki Kagaya,Subramanian Lakshmi,Yuxuan Lou,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: 提出了Memory Transfer Planning (MTP)框架，利用来自不同环境的成功控制代码作为程序知识，为LLM驱动的机器人操作规划提供上下文指导，无需更新模型参数即可适应新环境。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在机器人操作中的方法难以适应新环境，需要环境特定的策略训练或依赖固定提示和单次代码生成，导致可迁移性有限且需要手动重新调整。

Method: MTP框架：(i) 使用LLM生成初始计划和代码；(ii) 从代码记忆中检索相关成功示例；(iii) 将检索到的代码上下文适应到目标设置中进行重新规划。

Result: 在RLBench、CALVIN和物理机器人上的评估显示，MTP相比固定提示代码生成、简单检索和无记忆重新规划，持续提高了成功率和适应性。利用仿真构建的记忆在硬件实验中也被证明有效。

Conclusion: MTP提供了一种实用方法，利用程序知识实现跨多样化机器人操作场景的鲁棒LLM规划，增强了对新环境的适应性，并弥合了仿真和现实部署之间的差距。

Abstract: Large language models (LLMs) are increasingly explored in robot manipulation,
but many existing methods struggle to adapt to new environments. Many systems
require either environment-specific policy training or depend on fixed prompts
and single-shot code generation, leading to limited transferability and manual
re-tuning. We introduce Memory Transfer Planning (MTP), a framework that
leverages successful control-code examples from different environments as
procedural knowledge, using them as in-context guidance for LLM-driven
planning. Specifically, MTP (i) generates an initial plan and code using LLMs,
(ii) retrieves relevant successful examples from a code memory, and (iii)
contextually adapts the retrieved code to the target setting for re-planning
without updating model parameters. We evaluate MTP on RLBench, CALVIN, and a
physical robot, demonstrating effectiveness beyond simulation. Across these
settings, MTP consistently improved success rate and adaptability compared with
fixed-prompt code generation, naive retrieval, and memory-free re-planning.
Furthermore, in hardware experiments, leveraging a memory constructed in
simulation proved effective. MTP provides a practical approach that exploits
procedural knowledge to realize robust LLM-based planning across diverse
robotic manipulation scenarios, enhancing adaptability to novel environments
and bridging simulation and real-world deployment.

</details>


### [68] [Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models](https://arxiv.org/abs/2509.24163)
*Wanming Yu,Adrian Röfer,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 该论文提出使用多模态大语言模型作为机器人堆叠任务的高级规划器，通过微调模型使其能够推理物理属性如重量、稳定性等，在长时域堆叠任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型在机器人规划中缺乏对物体物理属性的知识和长时域操作任务的有效性，特别是在涉及隐藏物理属性（如重量、稳定性）的堆叠任务中表现不足。

Method: 使用多模态LLM作为高级规划器，通过创建考虑堆叠偏好（重量、稳定性、尺寸、占地面积）的自定义数据集来微调模型，使其能够同时推理多个偏好而无需显式指令。

Result: 与仅使用提示调优的预训练LLM相比，使用自定义数据集微调的LLM在大规模模拟评估中显示出改进的堆叠完成度，并在真实人形机器人上在线展示了有效性。

Conclusion: 通过多模态LLM和定制数据集微调的方法，能够有效提升机器人在长时域堆叠任务中的规划能力，特别是在需要推理物理属性的复杂场景中。

Abstract: Pretrained large language models (LLMs) can work as high-level robotic
planners by reasoning over abstract task descriptions and natural language
instructions, etc. However, they have shown a lack of knowledge and
effectiveness in planning long-horizon robotic manipulation tasks where the
physical properties of the objects are essential. An example is the stacking of
containers with hidden objects inside, which involves reasoning over hidden
physics properties such as weight and stability. To this end, this paper
proposes to use multimodal LLMs as high-level planners for such long-horizon
robotic stacking tasks. The LLM takes multimodal inputs for each object to
stack and infers the current best stacking sequence by reasoning over stacking
preferences. Furthermore, in order to enable the LLM to reason over multiple
preferences at the same time without giving explicit instructions, we propose
to create a custom dataset considering stacking preferences including weight,
stability, size, and footprint, to fine-tune the LLM. Compared to the
pretrained LLM with prompt tuning, we demonstrate the improved stacking
completion of the LLM fine-tuned with our custom dataset via large-scale
simulation evaluation. Furthermore, we showcase the effectiveness of the
proposed framework for the long-horizon stacking task on a real humanoid robot
in an online manner.

</details>


### [69] [Very High Frequency Interpolation for Direct Torque Control](https://arxiv.org/abs/2509.24175)
*Rafael Kourdis,Maciej Stępień,Jérôme Manhes,Nicolas Mansard,Steve Tonneau,Philippe Souères,Thomas Flayols*

Main category: cs.RO

TL;DR: 提出了一种在开源硬件上实现高达40kHz全身线性反馈的新方法，用于稳定扭矩控制器并执行非线性方案


<details>
  <summary>Details</summary>
Motivation: 扭矩控制虽然能实现灵活稳健的机器人运动，但实际部署常因不稳定性和硬件限制而受阻

Method: 在开源硬件上执行高达40kHz的全身线性反馈，并在实际执行过程中插值非线性方案（如逆动力学和学习扭矩策略）

Result: 通过稳定扭矩控制器，高频线性反馈成为释放扭矩控制机器人潜力的有效途径

Conclusion: 高频线性反馈是解锁扭矩控制机器人潜力的有效方法

Abstract: Torque control enables agile and robust robot motion, but deployment is often
hindered by instability and hardware limits. Here, we present a novel solution
to execute whole-body linear feedback at up to 40 kHz on open-source hardware.
We use this to interpolate non-linear schemes during real-world execution, such
as inverse dynamics and learned torque policies. Our results show that by
stabilizing torque controllers, high-frequency linear feedback could be an
effective route towards unlocking the potential of torque-controlled robotics.

</details>


### [70] [ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning](https://arxiv.org/abs/2509.24219)
*Tomoyuki Kagaya,Subramanian Lakshmi,Anbang Ye,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: ViReSkill是一个结合视觉重规划和技能记忆的框架，通过LLMs/VLMs生成动作序列并在失败时重新规划，成功时存储为可重用技能，实现自主持续学习。


<details>
  <summary>Details</summary>
Motivation: 传统RL/IL方法适应新任务慢，而LLMs/VLMs虽然能从少量数据中规划，但存在符号计划缺乏场景几何基础和执行可靠性差的问题。

Method: 提出ViReSkill框架，包含视觉基础的重规划器和技能记忆库。失败时基于当前场景重新规划，成功时存储执行计划作为可重用技能。

Result: 在LIBERO、RLBench模拟器和真实机器人上评估，ViReSkill在任务成功率上持续优于传统基线方法，展示了强大的仿真到真实泛化能力。

Conclusion: ViReSkill通过结合LLMs/VLMs的规划能力和技能记忆的稳定性，实现了高效的自主持续学习，显著提升了任务执行的成功率和可靠性。

Abstract: Robots trained via Reinforcement Learning (RL) or Imitation Learning (IL)
often adapt slowly to new tasks, whereas recent Large Language Models (LLMs)
and Vision-Language Models (VLMs) promise knowledge-rich planning from minimal
data. Deploying LLMs/VLMs for motion planning, however, faces two key
obstacles: (i) symbolic plans are rarely grounded in scene geometry and object
physics, and (ii) model outputs can vary for identical prompts, undermining
execution reliability. We propose ViReSkill, a framework that pairs
vision-grounded replanning with a skill memory for accumulation and reuse. When
a failure occurs, the replanner generates a new action sequence conditioned on
the current scene, tailored to the observed state. On success, the executed
plan is stored as a reusable skill and replayed in future encounters without
additional calls to LLMs/VLMs. This feedback loop enables autonomous continual
learning: each attempt immediately expands the skill set and stabilizes
subsequent executions. We evaluate ViReSkill on simulators such as LIBERO and
RLBench as well as on a physical robot. Across all settings, it consistently
outperforms conventional baselines in task success rate, demonstrating robust
sim-to-real generalization.

</details>


### [71] [Towards Tighter Convex Relaxation of Mixed-integer Programs: Leveraging Logic Network Flow for Task and Motion Planning](https://arxiv.org/abs/2509.24235)
*Xuan Lin,Jiming Ren,Yandong Luo,Weijun Xie,Ye Zhao*

Main category: cs.RO

TL;DR: 提出基于逻辑网络流的任务与运动规划框架，将时序逻辑规范集成到混合整数规划中，通过流网络模型编码时序谓词，实现比传统逻辑树方法更紧的凸松弛和更少的约束。


<details>
  <summary>Details</summary>
Motivation: 传统逻辑树方法在处理时序逻辑规划时存在凸松弛不够紧、约束过多的问题，需要更高效的优化框架来提升机器人规划性能。

Method: 采用网络流模型，将时序谓词编码为边上的多面体约束，提出基于网络流的Fourier-Motzkin消元法去除连续流变量，保持凸松弛紧度。

Result: 在车辆路径规划、多机器人协调和时序逻辑控制等任务中，计算速度提升数个数量级，四足机器人硬件实验验证了动态环境下的实时重规划能力。

Conclusion: 逻辑网络流框架在时序逻辑运动规划中显著优于传统方法，实现了高效的计算性能和实时重规划能力。

Abstract: This paper proposes an optimization-based task and motion planning framework,
named "Logic Network Flow", that integrates temporal logic specifications into
mixed-integer programs for efficient robot planning. Inspired by the
Graph-of-Convex-Sets formulation, temporal predicates are encoded as polyhedron
constraints on each edge of a network flow model, instead of as constraints
between nodes in traditional Logic Tree formulations. We further propose a
network-flow-based Fourier-Motzkin elimination procedure that removes
continuous flow variables while preserving convex relaxation tightness, leading
to provably tighter convex relaxations and fewer constraints than Logic Tree
formulations. For temporal logic motion planning with piecewise-affine dynamic
systems, comprehensive experiments across vehicle routing, multi-robot
coordination, and temporal logic control on dynamical systems using point mass
and linear inverted pendulum models demonstrate computational speedups of up to
several orders of magnitude. Hardware demonstrations with quadrupedal robots
validate real-time replanning capabilities under dynamically changing
environmental conditions. The project website is at
https://logicnetworkflow.github.io/.

</details>


### [72] [PROFusion: Robust and Accurate Dense Reconstruction via Camera Pose Regression and Optimization](https://arxiv.org/abs/2509.24236)
*Siyan Dong,Zijun Wang,Lulu Cai,Yi Ma,Yanchao Yang*

Main category: cs.RO

TL;DR: 提出了一种结合学习式初始化和优化式精化的RGB-D SLAM方法，通过相机位姿回归网络预测相对位姿作为优化起点，解决了大视角变化和快速运动下的重建失败问题。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D SLAM系统在相机经历大视角变化、快速运动或突然抖动时会失败。基于优化的方法精度高但对初始化敏感，基于学习的方法鲁棒性好但精度不足。

Method: 使用相机位姿回归网络从连续RGB-D帧预测度量感知的相对位姿，作为随机优化算法的可靠起点，进一步将深度图像与场景几何对齐。

Result: 在挑战性基准测试中优于最佳竞争对手，在稳定运动序列上保持相当精度，系统可实时运行。

Conclusion: 结合简单而原则性的技术可以实现对不稳定运动的鲁棒性和密集重建的精度。

Abstract: Real-time dense scene reconstruction during unstable camera motions is
crucial for robotics, yet current RGB-D SLAM systems fail when cameras
experience large viewpoint changes, fast motions, or sudden shaking. Classical
optimization-based methods deliver high accuracy but fail with poor
initialization during large motions, while learning-based approaches provide
robustness but lack sufficient accuracy for dense reconstruction. We address
this challenge through a combination of learning-based initialization with
optimization-based refinement. Our method employs a camera pose regression
network to predict metric-aware relative poses from consecutive RGB-D frames,
which serve as reliable starting points for a randomized optimization algorithm
that further aligns depth images with the scene geometry. Extensive experiments
demonstrate promising results: our approach outperforms the best competitor on
challenging benchmarks, while maintaining comparable accuracy on stable motion
sequences. The system operates in real-time, showcasing that combining simple
and principled techniques can achieve both robustness for unstable motions and
accuracy for dense reconstruction. Project page:
https://github.com/siyandong/PROFusion.

</details>


### [73] [SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control Barrier Functions](https://arxiv.org/abs/2509.24243)
*Jeongyong Yang,Seunghwan Jang,Soojean Han*

Main category: cs.RO

TL;DR: SafeFlowMatcher结合流匹配和控制屏障函数，通过预测-校正积分器实现实时高效且安全认证的路径规划。


<details>
  <summary>Details</summary>
Motivation: 基于流匹配的生成规划器虽然能快速生成高质量路径，但缺乏正式的安全保证，在约束附近可能产生不完整路径。

Method: 使用两阶段预测-校正积分器：预测阶段通过流匹配生成候选路径；校正阶段用时间缩放向量场和CBF二次规划进行最小扰动修正。

Result: 在迷宫导航和运动基准测试中，比基于扩散和流匹配的基线方法获得更快、更平滑、更安全的路径。

Conclusion: SafeFlowMatcher通过仅对执行路径施加安全约束，避免了分布漂移和局部陷阱问题，实现了高效安全规划。

Abstract: Generative planners based on flow matching (FM) can produce high-quality
paths in one or a few ODE steps, but their sampling dynamics offer no formal
safety guarantees and can yield incomplete paths near constraints. We present
SafeFlowMatcher, a planning framework that couples FM with control barrier
functions (CBFs) to achieve both real-time efficiency and certified safety.
SafeFlowMatcher uses a two-phase prediction-correction (PC) integrator: (i) a
prediction phase integrates the learned FM once (or a few steps) to obtain a
candidate path without intervention; (ii) a correction phase refines this path
with a vanishing time-scaled vector field and a CBF-based quadratic program
that minimally perturbs the vector field. We prove a barrier certificate for
the resulting flow system, establishing forward invariance of a robust safe set
and finite-time convergence to the safe set. By enforcing safety only on the
executed path (rather than on all intermediate latent paths), SafeFlowMatcher
avoids distributional drift and mitigates local trap problems. Across maze
navigation and locomotion benchmarks, SafeFlowMatcher attains faster, smoother,
and safer paths than diffusion- and FM-based baselines. Extensive ablations
corroborate the contributions of the PC integrator and the barrier certificate.

</details>


### [74] [Contextual Neural Moving Horizon Estimation for Robust Quadrotor Control in Varying Conditions](https://arxiv.org/abs/2509.24281)
*Kasra Torshizi,Chak Lam Shek,Khuzema Habib,Guangyao Shi,Pratap Tokekar,Troi Williams*

Main category: cs.RO

TL;DR: 提出了一种基于贝叶斯优化和高斯过程的上下文选择策略，用于在四旋翼飞行器中自适应调整神经移动地平线估计器的参数，避免在所有环境中进行穷举训练。


<details>
  <summary>Details</summary>
Motivation: 传统自适应控制器需要针对特定场景进行大量调参，缺乏灵活性且难以适应变化的环境条件。机器学习方法虽然有望解决这一问题，但在所有可能环境中收集数据不现实且效率低下。

Method: 使用贝叶斯优化和高斯过程来选择需要收集数据的环境上下文，通过神经移动地平线估计器动态调整参数，实现跨环境的鲁棒性能。

Result: 实验结果表明，该方法在最大绝对位置误差方面比先前工作提升了20.3%，仅需少量精心选择的上下文就能捕捉环境变化。

Conclusion: Contextual NeuroMHE方法消除了在所有环境中进行穷举训练的需求，同时在不同条件下保持鲁棒性能，提高了效率和泛化能力。

Abstract: Adaptive controllers on quadrotors typically rely on estimation of
disturbances to ensure robust trajectory tracking. Estimating disturbances
across diverse environmental contexts is challenging due to the inherent
variability and uncertainty in the real world. Such estimators require
extensive fine-tuning for a specific scenario, which makes them inflexible and
brittle to changing conditions. Machine-learning approaches, such as training a
neural network to tune the estimator's parameters, are promising. However,
collecting data across all possible environmental contexts is impossible. It is
also inefficient as the same estimator parameters could work for "nearby"
contexts. In this paper, we present a sequential decision making strategy that
decides which environmental contexts, using Bayesian Optimization with a
Gaussian Process, to collect data from in order to ensure robust performance
across a wide range of contexts. Our method, Contextual NeuroMHE, eliminates
the need for exhaustive training across all environments while maintaining
robust performance under different conditions. By enabling the neural network
to adapt its parameters dynamically, our method improves both efficiency and
generalization. Experimental results in various real-world settings demonstrate
that our approach outperforms the prior work by 20.3\% in terms of maximum
absolute position error and can capture the variations in the environment with
a few carefully chosen contexts.

</details>


### [75] [Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning](https://arxiv.org/abs/2509.24313)
*Korbinian Moller,Roland Stroop,Mattia Piccinini,Alexander Langmann,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种混合运动规划框架，结合强化学习指导采样过程，在保持轨迹生成和评估可分析验证的同时，显著减少了采样需求。


<details>
  <summary>Details</summary>
Motivation: 在复杂城市驾驶场景中，传统的均匀或启发式采样方法会产生大量不可行或不相关的轨迹，导致效率低下。

Method: 使用强化学习代理指导采样过程，结合基于可解码深度集合编码器的世界模型，保持轨迹生成和评估的确定性验证能力。

Result: 在CommonRoad仿真环境中评估，所需样本减少达99%，运行时间减少达84%，同时保持规划质量和无碰撞率。

Conclusion: 该方法实现了更快速、更可靠的自动驾驶决策，在真实世界约束下实现更安全和响应性更强的导航。

Abstract: Sampling-based motion planning is a well-established approach in autonomous
driving, valued for its modularity and analytical tractability. In complex
urban scenarios, however, uniform or heuristic sampling often produces many
infeasible or irrelevant trajectories. We address this limitation with a hybrid
framework that learns where to sample while keeping trajectory generation and
evaluation fully analytical and verifiable. A reinforcement learning (RL) agent
guides the sampling process toward regions of the action space likely to yield
feasible trajectories, while evaluation and final selection remains governed by
deterministic feasibility checks and cost functions. We couple the RL sampler
with a world model (WM) based on a decodable deep set encoder, enabling both
variable numbers of traffic participants and reconstructable latent
representations. The approach is evaluated in the CommonRoad simulation
environment, showing up to 99% fewer required samples and a runtime reduction
of up to 84% while maintaining planning quality in terms of success and
collision-free rates. These improvements lead to faster, more reliable
decision-making for autonomous vehicles in urban environments, achieving safer
and more responsive navigation under real-world constraints. Code and trained
artifacts are publicly available at:
https://github.com/TUM-AVS/Learning-to-Sample

</details>


### [76] [SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm](https://arxiv.org/abs/2509.24321)
*Yao Wang,Zhirui Sun,Wenzheng Chi,Baozhi Jia,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: 提出了SONAR方法，通过跨模态聚合推理解决视觉语言导航中的泛化性和场景适应性问题，在MP3D数据集上达到38.4%的成功率和17.7%的SPL。


<details>
  <summary>Details</summary>
Motivation: 现有模块化方法依赖训练数据质量且泛化性差，而基于视觉语言模型的方法在语义线索弱时表现不佳，需要平衡泛化能力和场景适应性。

Method: 提出SONAR方法，整合基于语义地图的目标预测模块和基于视觉语言模型的价值地图模块，采用多尺度语义地图与置信度地图融合策略来减少目标误检。

Result: 在Gazebo模拟器中使用MP3D数据集进行测试，SONAR实现了38.4%的成功率和17.7%的SPL。

Conclusion: SONAR通过跨模态聚合推理有效提升了在未知环境中导航的鲁棒性，平衡了泛化能力和场景适应性。

Abstract: Understanding human instructions and accomplishing Vision-Language Navigation
tasks in unknown environments is essential for robots. However, existing
modular approaches heavily rely on the quality of training data and often
exhibit poor generalization. Vision-Language Model based methods, while
demonstrating strong generalization capabilities, tend to perform
unsatisfactorily when semantic cues are weak. To address these issues, this
paper proposes SONAR, an aggregated reasoning approach through a cross modal
paradigm. The proposed method integrates a semantic map based target prediction
module with a Vision-Language Model based value map module, enabling more
robust navigation in unknown environments with varying levels of semantic cues,
and effectively balancing generalization ability with scene adaptability. In
terms of target localization, we propose a strategy that integrates multi-scale
semantic maps with confidence maps, aiming to mitigate false detections of
target objects. We conducted an evaluation of the SONAR within the Gazebo
simulator, leveraging the most challenging Matterport 3D (MP3D) dataset as the
experimental benchmark. Experimental results demonstrate that SONAR achieves a
success rate of 38.4% and an SPL of 17.7%.

</details>


### [77] [AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation](https://arxiv.org/abs/2509.24387)
*Xin Ding,Jianyu Wei,Yifan Yang,Shiqi Jiang,Qianxi Zhang,Hao Wu,Fucheng Jia,Liang Mi,Yuxuan Yan,Weijun Wang,Yunxin Liu,Zhibo Chen,Ting Cao*

Main category: cs.RO

TL;DR: AdaNav是一个基于不确定性的自适应推理框架，通过动态触发推理来提升视觉语言导航性能，在数据有限的情况下显著优于大规模训练的模型。


<details>
  <summary>Details</summary>
Motivation: 视觉语言导航需要代理根据自然语言指令在长序列视觉观察中进行导航。固定步长的推理往往导致性能不佳和计算冗余，因此需要自适应推理机制来提升时间一致性和感知-动作对齐。

Method: 提出AdaNav框架，核心是不确定性自适应推理块(UAR)，这是一个轻量级插件，通过动作熵作为策略先验动态触发推理。采用启发式到强化学习的训练方法逐步优化推理策略。

Result: 仅用6K训练样本，AdaNav在R2R val-unseen上成功率提升20%，RxR-CE上提升11.7%，真实场景中提升11.4%，显著优于百万级数据训练的闭源模型。

Conclusion: AdaNav证明了自适应推理在数据受限的具身任务中的有效性，通过不确定性驱动的动态推理策略实现了更好的导航性能。

Abstract: Vision Language Navigation (VLN) requires agents to follow natural language
instructions by grounding them in sequential visual observations over long
horizons. Explicit reasoning could enhance temporal consistency and perception
action alignment, but reasoning at fixed steps often leads to suboptimal
performance and unnecessary computation. To address this, we propose AdaNav, an
uncertainty-based adaptive reasoning framework for VLN. At its core is the
Uncertainty Adaptive Reasoning Block (UAR), a lightweight plugin that
dynamically triggers reasoning. We introduce Action Entropy as a policy prior
for UAR and progressively refine it through a Heuristics to RL training method,
enabling agents to learn difficulty aware reasoning policies under the strict
data limitations of embodied tasks. Results show that with only 6K training
samples, AdaNav achieves substantial gains over closed source models trained on
million scale data, improving success rate by 20% on R2R val-unseen, 11.7% on
RxR-CE, and 11.4% in real world scenes. The code is available at
https://github.com/xinding-sys/AdaNav.

</details>


### [78] [DynaMIC: Dynamic Multimodal In-Context Learning Enabled Embodied Robot Counterfactual Resistance Ability](https://arxiv.org/abs/2509.24413)
*Tianqiang Yan,Ziqiao Lin,Sicheng Wang,Tianwei Zhang,Zhenglong Sun*

Main category: cs.RO

TL;DR: 该论文提出了DynaMIC框架，用于识别机器人任务中的误导性指令（DCFs）并主动向人类提供反馈，以提高机器人执行任务的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的机器人系统严格遵循人类指令，但包含误导信息的指令可能导致执行错误和安全风险，这一问题在机器人研究中尚未得到足够重视。

Method: 提出DynaMIC框架，通过生成机器人任务流程来识别指令反事实（DCFs），并主动向人类提供反馈。

Result: 进行了语义级实验和消融研究，证明了该框架的有效性。

Conclusion: 该框架能够帮助机器人对任务中的潜在DCFs保持敏感，从而增强执行过程的可靠性。

Abstract: The emergence of large pre-trained models based on natural language has
breathed new life into robotics development. Extensive research has integrated
large models with robots, utilizing the powerful semantic understanding and
generation capabilities of large models to facilitate robot control through
natural language instructions gradually. However, we found that robots that
strictly adhere to human instructions, especially those containing misleading
information, may encounter errors during task execution, potentially leading to
safety hazards. This resembles the concept of counterfactuals in natural
language processing (NLP), which has not yet attracted much attention in
robotic research. In an effort to highlight this issue for future studies, this
paper introduced directive counterfactuals (DCFs) arising from misleading human
directives. We present DynaMIC, a framework for generating robot task flows to
identify DCFs and relay feedback to humans proactively. This capability can
help robots be sensitive to potential DCFs within a task, thus enhancing the
reliability of the execution process. We conducted semantic-level experiments
and ablation studies, showcasing the effectiveness of this framework.

</details>


### [79] [PhysiAgent: An Embodied Agent Framework in Physical World](https://arxiv.org/abs/2509.24524)
*Zhihao Wang,Jianxiong Li,Jinliang Zheng,Wencong Zhang,Dongxiu Liu,Yinan Zheng,Haoyi Niu,Junzhi Yu,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 提出PhysiAgent框架，通过监控、记忆、自反思机制和轻量级工具箱，实现VLM和VLA的有效协作，在物理环境中提升任务解决性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型泛化能力有限，而VLM作为辅助的集成方法通常采用僵化的顺序结构，导致协作效率低下和接地挑战。

Method: 引入监控、记忆、自反思机制和轻量级工具箱，构建自主支架框架，根据VLA的实时能力反馈来组织不同组件。

Result: 在复杂真实世界机器人任务上显著提升任务解决性能，展示了VLM的有效自我调节、工具协作连贯性和框架的自适应演化。

Conclusion: PhysiAgent为VLM和VLA的集成做出了实用且开创性的努力，有效将具身智能体框架接地到真实世界环境中。

Abstract: Vision-Language-Action (VLA) models have achieved notable success but often
struggle with limited generalizations. To address this, integrating generalized
Vision-Language Models (VLMs) as assistants to VLAs has emerged as a popular
solution. However, current approaches often combine these models in rigid,
sequential structures: using VLMs primarily for high-level scene understanding
and task planning, and VLAs merely as executors of lower-level actions, leading
to ineffective collaboration and poor grounding challenges. In this paper, we
propose an embodied agent framework, PhysiAgent, tailored to operate
effectively in physical environments. By incorporating monitor, memory,
self-reflection mechanisms, and lightweight off-the-shelf toolboxes, PhysiAgent
offers an autonomous scaffolding framework to prompt VLMs to organize different
components based on real-time proficiency feedback from VLAs to maximally
exploit VLAs' capabilities. Experimental results demonstrate significant
improvements in task-solving performance on complex real-world robotic tasks,
showcasing effective self-regulation of VLMs, coherent tool collaboration, and
adaptive evolution of the framework during execution. PhysiAgent makes
practical and pioneering efforts to integrate VLMs and VLAs, effectively
grounding embodied agent frameworks in real-world settings.

</details>


### [80] [Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game](https://arxiv.org/abs/2509.24530)
*Giulia Pusceddu,Sara Mongile,Francesco Rea,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 本研究通过改进的公共物品游戏，探讨人形机器人iCub的不同游戏策略对人类参与者合作倾向的影响。


<details>
  <summary>Details</summary>
Motivation: 探索博弈论作为研究人机混合群体中合作与信任的潜在工具，了解机器人在促进人机交互中信任和凝聚力的作用。

Method: 使用改进的公共物品游戏模型，让三名人类参与者与人形机器人iCub进行游戏，测试不同机器人策略（总是合作、总是搭便车、以牙还牙）对人类合作行为的影响。

Result: 初步分析显示，尽管参与者认为机器人很慷慨，但他们仍倾向于不向公共池投资资金。

Conclusion: 这项研究为开发能够在人机混合群体中促进信任与合作的社会机器人提供了有价值的见解和潜力。

Abstract: In this study, we explore the potential of Game Theory as a means to
investigate cooperation and trust in human-robot mixed groups. Particularly, we
introduce the Public Good Game (PGG), a model highlighting the tension between
individual self-interest and collective well-being. In this work, we present a
modified version of the PGG, where three human participants engage in the game
with the humanoid robot iCub to assess whether various robot game strategies
(e.g., always cooperate, always free ride, and tit-for-tat) can influence the
participants' inclination to cooperate. We test our setup during a pilot study
with nineteen participants. A preliminary analysis indicates that participants
prefer not to invest their money in the common pool, despite they perceive the
robot as generous. By conducting this research, we seek to gain valuable
insights into the role that robots can play in promoting trust and cohesion
during human-robot interactions within group contexts. The results of this
study may hold considerable potential for developing social robots capable of
fostering trust and cooperation within mixed human-robot groups.

</details>


### [81] [Unlocking the Potential of Soft Actor-Critic for Imitation Learning](https://arxiv.org/abs/2509.24539)
*Nayari Marie Lessa,Melya Boukheddimi,Frank Kirchner*

Main category: cs.RO

TL;DR: 提出一种结合对抗运动先验(AMP)和离策略软演员-评论家(SAC)的新型模仿学习框架，用于四足机器人步态学习，相比主流的AMP+PPO方法具有更高的样本效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前基于PPO的模仿学习方法虽然稳定但样本效率低且策略泛化能力有限，需要更高效的离策略学习方法来提升机器人运动生成的自然性和适应性。

Method: 将对抗运动先验(AMP)与离策略软演员-评论家(SAC)算法结合，利用重放驱动学习和熵正则化探索，在多种参考运动和不同地形上评估四足机器人步态。

Result: 实验表明AMP+SAC框架不仅保持稳定的任务执行，还比广泛使用的AMP+PPO方法获得更高的模仿奖励，证明了离策略IL在运动生成中的优势。

Conclusion: 离策略模仿学习框架在机器人运动生成方面具有显著潜力，能够实现更自然的行为和任务执行，同时提高数据效率和鲁棒性。

Abstract: Learning-based methods have enabled robots to acquire bio-inspired movements
with increasing levels of naturalness and adaptability. Among these, Imitation
Learning (IL) has proven effective in transferring complex motion patterns from
animals to robotic systems. However, current state-of-the-art frameworks
predominantly rely on Proximal Policy Optimization (PPO), an on-policy
algorithm that prioritizes stability over sample efficiency and policy
generalization. This paper proposes a novel IL framework that combines
Adversarial Motion Priors (AMP) with the off-policy Soft Actor-Critic (SAC)
algorithm to overcome these limitations. This integration leverages
replay-driven learning and entropy-regularized exploration, enabling
naturalistic behavior and task execution, improving data efficiency and
robustness. We evaluate the proposed approach (AMP+SAC) on quadruped gaits
involving multiple reference motions and diverse terrains. Experimental results
demonstrate that the proposed framework not only maintains stable task
execution but also achieves higher imitation rewards compared to the widely
used AMP+PPO method. These findings highlight the potential of an off-policy IL
formulation for advancing motion generation in robotics.

</details>


### [82] [Prompting Robot Teams with Natural Language](https://arxiv.org/abs/2509.24575)
*Nicolas Pfitzer,Eduardo Sebastián,Ajay Shankar,Amanda Prorok*

Main category: cs.RO

TL;DR: 提出了一个使用自然语言提示多机器人团队执行高级任务的框架，将语言模型的推理能力与机器人协作决策相结合


<details>
  <summary>Details</summary>
Motivation: 利用语言模型理解人类意图表达的能力，将其重新用于多机器人协作和决策制定，解决集体中个体行为难以指定和解释的挑战

Method: 将任务表示为确定性有限自动机(DFA)，使用RNN编码多个自动机，将语言模型获得的逻辑和子任务序列分解提炼到RNN中，并训练基于RNN隐藏状态和语言嵌入的GNN控制策略

Result: 在需要顺序和协作行为的各种模拟和实际多机器人任务中评估了这种轻量级可解释模型

Conclusion: 该方法使机器人能够以分散方式执行与任务相关的动作，支持实时交互操作

Abstract: This paper presents a framework towards prompting multi-robot teams with
high-level tasks using natural language expressions. Our objective is to use
the reasoning capabilities demonstrated by recent language models in
understanding and decomposing human expressions of intent, and repurpose these
for multi-robot collaboration and decision-making. The key challenge is that an
individual's behavior in a collective can be hard to specify and interpret, and
must continuously adapt to actions from others. This necessitates a framework
that possesses the representational capacity required by the logic and
semantics of a task, and yet supports decentralized and interactive real-time
operation. We solve this dilemma by recognizing that a task can be represented
as a deterministic finite automaton (DFA), and that recurrent neural networks
(RNNs) can encode numerous automata. This allows us to distill the logic and
sequential decompositions of sub-tasks obtained from a language model into an
RNN, and align its internal states with the semantics of a given task. By
training a graph neural network (GNN) control policy that is conditioned on the
hidden states of the RNN and the language embeddings, our method enables robots
to execute task-relevant actions in a decentralized manner. We present
evaluations of this single light-weight interpretable model on various
simulated and real-world multi-robot tasks that require sequential and
collaborative behavior by the team -- sites.google.com/view/prompting-teams.

</details>


### [83] [U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation](https://arxiv.org/abs/2509.24579)
*Linzhi Wu,Aoran Mei,Xiyue Wang,Guo-Niu Zhu,Zhongxue Gan*

Main category: cs.RO

TL;DR: 提出U-DiT Policy，一种结合U-Net多尺度特征融合和Transformer全局上下文建模能力的新型扩散策略框架，在机器人操作任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的机器人控制方法主要采用U-Net架构（DP-U），存在全局上下文建模能力有限和过度平滑伪影的问题。

Method: 设计U形扩散Transformer框架，保留U-Net的多尺度特征融合优势，同时集成Transformer的全局上下文建模能力。

Result: 在仿真任务中平均性能提升10%，超越基于Transformer的扩散策略6%；在真实机器人任务中平均提升22.5%，在干扰和光照变化下表现出更好的鲁棒性和泛化能力。

Conclusion: U-DiT Policy作为基于扩散的机器人操作新基础，展现出有效性和实际潜力。

Abstract: Diffusion-based methods have been acknowledged as a powerful paradigm for
end-to-end visuomotor control in robotics. Most existing approaches adopt a
Diffusion Policy in U-Net architecture (DP-U), which, while effective, suffers
from limited global context modeling and over-smoothing artifacts. To address
these issues, we propose U-DiT Policy, a novel U-shaped Diffusion Transformer
framework. U-DiT preserves the multi-scale feature fusion advantages of U-Net
while integrating the global context modeling capability of Transformers,
thereby enhancing representational power and policy expressiveness. We evaluate
U-DiT extensively across both simulation and real-world robotic manipulation
tasks. In simulation, U-DiT achieves an average performance gain of 10\% over
baseline methods and surpasses Transformer-based diffusion policies (DP-T) that
use AdaLN blocks by 6\% under comparable parameter budgets. On real-world
robotic tasks, U-DiT demonstrates superior generalization and robustness,
achieving an average improvement of 22.5\% over DP-U. In addition, robustness
and generalization experiments under distractor and lighting variations further
highlight the advantages of U-DiT. These results highlight the effectiveness
and practical potential of U-DiT Policy as a new foundation for diffusion-based
robotic manipulation.

</details>


### [84] [PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control](https://arxiv.org/abs/2509.24591)
*Haozhuo Zhang,Michele Caprio,Jing Shao,Qiang Zhang,Jian Tang,Shanghang Zhang,Wei Pan*

Main category: cs.RO

TL;DR: PoseDiff是一个统一的扩散模型框架，将机器人状态估计和控制整合在一起，能够从单张RGB图像估计机器人状态，并生成平滑的长时程动作序列。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要多阶段流程和辅助模态来连接感知与控制，PoseDiff旨在提供一个统一的框架来高效整合感知与控制。

Method: 使用条件扩散模型，从原始视觉观察映射到结构化机器人状态，并基于世界模型生成的稀疏视频关键帧进行视频到动作的逆动力学建模，采用重叠平均策略生成连续动作序列。

Result: 在DREAM数据集上实现了最先进的姿态估计精度和实时性能；在Libero-Object操作任务中显著提高了成功率，即使在严格的离线设置下。

Conclusion: PoseDiff为具身AI中的感知、规划和控制提供了一个可扩展、准确且高效的桥梁。

Abstract: We present PoseDiff, a conditional diffusion model that unifies robot state
estimation and control within a single framework. At its core, PoseDiff maps
raw visual observations into structured robot states-such as 3D keypoints or
joint angles-from a single RGB image, eliminating the need for multi-stage
pipelines or auxiliary modalities. Building upon this foundation, PoseDiff
extends naturally to video-to-action inverse dynamics: by conditioning on
sparse video keyframes generated by world models, it produces smooth and
continuous long-horizon action sequences through an overlap-averaging strategy.
This unified design enables scalable and efficient integration of perception
and control. On the DREAM dataset, PoseDiff achieves state-of-the-art accuracy
and real-time performance for pose estimation. On Libero-Object manipulation
tasks, it substantially improves success rates over existing inverse dynamics
modules, even under strict offline settings. Together, these results show that
PoseDiff provides a scalable, accurate, and efficient bridge between
perception, planning, and control in embodied AI. The video visualization
results can be found on the project page:
https://haozhuo-zhang.github.io/PoseDiff-project-page/.

</details>


### [85] [CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations](https://arxiv.org/abs/2509.24661)
*Zhiyuan Wu,Rolandos Alexandros Potamias,Xuyang Zhang,Zhongqun Zhang,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: 提出CEDex方法，通过将机器人运动学模型与生成的人类接触表示对齐，实现跨形态灵巧抓取合成，并构建了最大的跨形态抓取数据集


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖缺乏人类运动学理解的物理优化，要么需要局限于拟人结构的手动数据收集过程，需要可靠多样的抓取数据来实现通用机器人操作

Method: 使用在人类接触数据上预训练的条件变分自编码器生成人类接触表示，通过拓扑合并进行运动学对齐，然后进行基于符号距离场的抓取优化

Result: 构建了包含500K个物体、四种夹爪类型、总计2000万抓取的最大跨形态抓取数据集，实验表明方法优于现有技术

Conclusion: CEDex通过桥接人类抓取运动学和机器人运动学，实现了高质量的跨形态灵巧抓取合成，数据集对跨形态抓取学习有益

Abstract: Cross-embodiment dexterous grasp synthesis refers to adaptively generating
and optimizing grasps for various robotic hands with different morphologies.
This capability is crucial for achieving versatile robotic manipulation in
diverse environments and requires substantial amounts of reliable and diverse
grasp data for effective model training and robust generalization. However,
existing approaches either rely on physics-based optimization that lacks
human-like kinematic understanding or require extensive manual data collection
processes that are limited to anthropomorphic structures. In this paper, we
propose CEDex, a novel cross-embodiment dexterous grasp synthesis method at
scale that bridges human grasping kinematics and robot kinematics by aligning
robot kinematic models with generated human-like contact representations. Given
an object's point cloud and an arbitrary robotic hand model, CEDex first
generates human-like contact representations using a Conditional Variational
Auto-encoder pretrained on human contact data. It then performs kinematic human
contact alignment through topological merging to consolidate multiple human
hand parts into unified robot components, followed by a signed distance
field-based grasp optimization with physics-aware constraints. Using CEDex, we
construct the largest cross-embodiment grasp dataset to date, comprising 500K
objects across four gripper types with 20M total grasps. Extensive experiments
show that CEDex outperforms state-of-the-art approaches and our dataset
benefits cross-embodiment grasp learning with high-quality diverse grasps.

</details>


### [86] [Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering](https://arxiv.org/abs/2509.24697)
*Evelyn D'Elia,Paolo Maria Viceconte,Lorenzo Rapetti,Diego Ferigo,Giulio Romualdi,Giuseppe L'Erario,Raffaello Camoriano,Daniele Pucci*

Main category: cs.RO

TL;DR: 提出一种结合物理先验和比例积分控制器的双管齐下学习方法，用于提升人形机器人轨迹生成的物理可行性和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法受限于数据量且缺乏物理知识，可能导致轨迹发散和滑动接触问题，影响真实世界稳定性

Method: 1) 在监督模仿学习中编码物理先验以促进轨迹可行性；2) 在推理时应用比例积分控制器最小化漂移

Result: 在ergoCub人形机器人上验证，物理信息损失鼓励零接触足部速度，显著提高轨迹精度和物理约束符合度

Conclusion: 该方法与多种控制器兼容，能有效提升生成轨迹的准确性和物理约束一致性

Abstract: Recent trends in humanoid robot control have successfully employed imitation
learning to enable the learned generation of smooth, human-like trajectories
from human data. While these approaches make more realistic motions possible,
they are limited by the amount of available motion data, and do not incorporate
prior knowledge about the physical laws governing the system and its
interactions with the environment. Thus they may violate such laws, leading to
divergent trajectories and sliding contacts which limit real-world stability.
We address such limitations via a two-pronged learning strategy which leverages
the known physics of the system and fundamental control principles. First, we
encode physics priors during supervised imitation learning to promote
trajectory feasibility. Second, we minimize drift at inference time by applying
a proportional-integral controller directly to the generated output state. We
validate our method on various locomotion behaviors for the ergoCub humanoid
robot, where a physics-informed loss encourages zero contact foot velocity. Our
experiments demonstrate that the proposed approach is compatible with multiple
controllers on a real robot and significantly improves the accuracy and
physical constraint conformity of generated trajectories.

</details>


### [87] [LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers](https://arxiv.org/abs/2509.24706)
*Andreea Tulbure,Rene Zurbruegg,Timm Grigat,Marco Hutter*

Main category: cs.RO

TL;DR: LLM-Handover框架结合大语言模型推理和部件分割，实现基于任务上下文的抓取选择，优化人机协作中物体交接后的可用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视人类交接后的动作，依赖限制泛化性的假设，需要解决上下文感知的抓取选择问题。

Method: 使用RGB-D图像和任务描述，通过LLM推理相关物体部件，选择优化交接后可用性的抓取方式，并引入包含60个家庭物体的新数据集。

Result: 在零样本设置下达到83%的成功率，用户研究中86%的参与者偏好该方法，证明了更好的抓取成功率和任务适应性。

Conclusion: LLM-Handover能够实现更直观、上下文感知的物体交接，提升人机协作效果。

Abstract: Effective human-robot collaboration depends on task-oriented handovers, where
robots present objects in ways that support the partners intended use. However,
many existing approaches neglect the humans post-handover action, relying on
assumptions that limit generalizability. To address this gap, we propose
LLM-Handover, a novel framework that integrates large language model
(LLM)-based reasoning with part segmentation to enable context-aware grasp
selection and execution. Given an RGB-D image and a task description, our
system infers relevant object parts and selects grasps that optimize
post-handover usability. To support evaluation, we introduce a new dataset of
60 household objects spanning 12 categories, each annotated with detailed part
labels. We first demonstrate that our approach improves the performance of the
used state-of-the-art part segmentation method, in the context of robot-human
handovers. Next, we show that LLM-Handover achieves higher grasp success rates
and adapts better to post-handover task constraints. During hardware
experiments, we achieve a success rate of 83% in a zero-shot setting over
conventional and unconventional post-handover tasks. Finally, our user study
underlines that our method enables more intuitive, context-aware handovers,
with participants preferring it in 86% of cases.

</details>


### [88] [APREBot: Active Perception System for Reflexive Evasion Robot](https://arxiv.org/abs/2509.24733)
*Zihao Xu,Kuankuan Sima,Junhao Deng,Zixuan Zhuang,Chunzheng Wang,Ce Hao,Jin Song Dong*

Main category: cs.RO

TL;DR: APREBot是一个用于四足机器人的主动感知系统，结合LiDAR全向扫描和相机主动聚焦，实现动态环境中的敏捷避障。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在动态环境中可靠感知的挑战，单传感器系统存在局限性：LiDAR缺乏纹理信息，相机视野受限。

Method: 集成反射式规避与主动分层感知，策略性结合LiDAR全向扫描和相机主动聚焦。

Result: 通过仿真到真实实验验证，在安全指标和操作效率上显著优于现有基准方法。

Conclusion: APREBot在安全关键场景中具有可靠自主性的潜力。

Abstract: Reliable onboard perception is critical for quadruped robots navigating
dynamic environments, where obstacles can emerge from any direction under
strict reaction-time constraints. Single-sensor systems face inherent
limitations: LiDAR provides omnidirectional coverage but lacks rich texture
information, while cameras capture high-resolution detail but suffer from
restricted field of view. We introduce APREBot (Active Perception System for
Reflexive Evasion Robot), a novel framework that integrates reflexive evasion
with active hierarchical perception. APREBot strategically combines LiDAR-based
omnidirectional scanning with camera-based active focusing, achieving
comprehensive environmental awareness essential for agile obstacle avoidance in
quadruped robots. We validate APREBot through extensive sim-to-real experiments
on a quadruped platform, evaluating diverse obstacle types, trajectories, and
approach directions. Our results demonstrate substantial improvements over
state-of-the-art baselines in both safety metrics and operational efficiency,
highlighting APREBot's potential for dependable autonomy in safety-critical
scenarios. Videos are available at https://sites.google.com/view/aprebot/

</details>


### [89] [SSR-ZSON: Zero-Shot Object Navigation via Spatial-Semantic Relations within a Hierarchical Exploration Framework](https://arxiv.org/abs/2509.24763)
*Xiangyi Meng,Delun Li,Zihao Mao,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: SSR-ZSON是一种基于TARE分层探索框架的空间语义相对零样本对象导航方法，通过平衡空间覆盖和语义密度的视点生成策略与基于LLM的全局引导机制，解决了零样本对象导航中的语义引导不足和空间记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 零样本对象导航面临两个主要挑战：语义引导不足导致探索效率低下，以及环境结构造成的空间记忆限制导致局部区域困陷。

Method: 提出SSR-ZSON方法，包含两个关键创新：1）视点生成策略优先考虑可遍历子区域内的高语义密度区域；2）基于LLM的全局引导机制评估语义关联，引导导航朝向高价值空间。

Result: 在Matterport3D和Habitat-Matterport3D数据集上，相比最先进方法，成功率和SPL分别提高了18.5%/11.2%和0.181/0.140。

Conclusion: SSR-ZSON实现了实时操作和优越性能，有效解决了零样本对象导航中的探索效率和局部困陷问题。

Abstract: Zero-shot object navigation in unknown environments presents significant
challenges, mainly due to two key limitations: insufficient semantic guidance
leads to inefficient exploration, while limited spatial memory resulting from
environmental structure causes entrapment in local regions. To address these
issues, we propose SSR-ZSON, a spatial-semantic relative zero-shot object
navigation method based on the TARE hierarchical exploration framework,
integrating a viewpoint generation strategy balancing spatial coverage and
semantic density with an LLM-based global guidance mechanism. The performance
improvement of the proposed method is due to two key innovations. First, the
viewpoint generation strategy prioritizes areas of high semantic density within
traversable sub-regions to maximize spatial coverage and minimize invalid
exploration. Second, coupled with an LLM-based global guidance mechanism, it
assesses semantic associations to direct navigation toward high-value spaces,
preventing local entrapment and ensuring efficient exploration. Deployed on
hybrid Habitat-Gazebo simulations and physical platforms, SSR-ZSON achieves
real-time operation and superior performance. On Matterport3D and
Habitat-Matterport3D datasets, it improves the Success Rate(SR) by 18.5\% and
11.2\%, and the Success weighted by Path Length(SPL) by 0.181 and 0.140,
respectively, over state-of-the-art methods.

</details>


### [90] [IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks](https://arxiv.org/abs/2509.24768)
*Eric Hannus,Miika Malin,Tran Nguyen Le,Ville Kyrki*

Main category: cs.RO

TL;DR: IA-VLA框架利用大型视觉语言模型的强大语言理解能力作为预处理阶段，为视觉语言动作模型(VLA)生成改进的上下文输入，以处理涉及视觉重复对象的复杂语义任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型(VLA)由于需要输出适合机器人控制频率的动作，限制了其语言模型的规模，从而影响了理解复杂语言指令的能力。特别是在处理需要根据相对位置识别目标对象等复杂语义任务时存在困难。

Method: 提出IA-VLA框架，利用大型视觉语言模型作为预处理阶段，生成增强的上下文信息来改进VLA的输入。该方法专门针对涉及视觉重复对象（视觉上无法区分的对象）的复杂语义任务进行设计。

Result: 在包含重复对象的三类场景数据集上的实验表明，增强后的VLA性能显著提升，特别是在处理需要从演示中推断概念的复杂语言指令时效果明显。

Conclusion: IA-VLA框架通过利用大型视觉语言模型的强大语言理解能力来增强VLA的输入，有效提升了处理复杂语义任务的能力，特别是在面对需要推断的复杂语言指令时表现优异。

Abstract: Vision-language-action models (VLAs) have become an increasingly popular
approach for addressing robot manipulation problems in recent years. However,
such models need to output actions at a rate suitable for robot control, which
limits the size of the language model they can be based on, and consequently,
their language understanding capabilities. Manipulation tasks may require
complex language instructions, such as identifying target objects by their
relative positions, to specify human intention. Therefore, we introduce IA-VLA,
a framework that utilizes the extensive language understanding of a large
vision language model as a pre-processing stage to generate improved context to
augment the input of a VLA. We evaluate the framework on a set of semantically
complex tasks which have been underexplored in VLA literature, namely tasks
involving visual duplicates, i.e., visually indistinguishable objects. A
dataset of three types of scenes with duplicate objects is used to compare a
baseline VLA against two augmented variants. The experiments show that the VLA
benefits from the augmentation scheme, especially when faced with language
instructions that require the VLA to extrapolate from concepts it has seen in
the demonstrations. For the code, dataset, and videos, see
https://sites.google.com/view/ia-vla.

</details>


### [91] [Fidelity-Aware Data Composition for Robust Robot Generalization](https://arxiv.org/abs/2509.24797)
*Zizhao Tong,Di Chen,Sicheng Hu,Hongwei Fan,Liliang Chen,Guanghui Ren,Hao Tang,Hao Dong,Ling Shao*

Main category: cs.RO

TL;DR: 提出了CIFT框架，通过基于信息保真度的数据组合优化来解决机器人策略在分布外泛化中的问题，显著提升了OOD成功率。


<details>
  <summary>Details</summary>
Motivation: 大规模训练的通才机器人策略容易受到捷径学习影响，导致分布外泛化能力差。传统生成式数据增强方法虽然引入多样性，但可能损害信息保真度。

Method: 引入CIFT框架，将数据组合视为优化问题，使用特征空间几何作为信息保真度的代理指标，识别训练稳定性下降的退相干点，并开发MVAug生成引擎合成因果解缠的数据谱。

Result: 在π₀和Diffusion Policy等策略架构上应用CIFT，将OOD成功率提高了54%以上。

Conclusion: 信息保真度感知的数据组合（而不仅仅是数据合成）是开发鲁棒通用机器人的重要组成部分。

Abstract: Generalist robot policies trained on large-scale, visually homogeneous
datasets can be susceptible to shortcut learning, which impairs their
out-of-distribution (OOD) generalization. While generative data augmentation is
a common approach to introduce diversity, it presents a subtle challenge: data
composition. Naively mixing real and synthetic data can corrupt the learning
signal, as this process often prioritizes visual diversity at the expense of
information fidelity. This paper suggests that robust generalization depends on
principled, fidelity-aware data composition. We introduce Coherent Information
Fidelity Tuning (CIFT), a framework that treats data composition as an
optimization problem. CIFT uses a practical proxy for Information Fidelity
based on the feature-space geometry of a dataset. This enables the
identification of a phase transition, termed the Decoherence Point, where
training stability degrades. The framework includes a generative engine,
Multi-View Video Augmentation (MVAug), to synthesize a causally disentangled
data spectrum for this tuning process. Applying CIFT to policy architectures
such as $\pi_0$ and Diffusion Policy improves OOD success rates by over 54\%.
These results indicate that fidelity-aware composition, beyond data synthesis
alone, is an important component for developing robust, general-purpose robots.

</details>


### [92] [Towards Modular and Accessible AUV Systems](https://arxiv.org/abs/2509.24864)
*Mingxi Zhou,Farhang Naderi,Yuewei Fu,Tony Jacob,Lin Zhao,Manavi Panjnani,Chengzhi Yuan,William McConnell,Emir Cem Gezer*

Main category: cs.RO

TL;DR: 开发了名为Marine Vehicle Packages (MVP)的新型开源模块化框架，用于自主水下航行器，包含软硬件设计，提高可定制性和有效载荷能力。


<details>
  <summary>Details</summary>
Motivation: 为研究目的提供易于构建AUV的框架，增加可定制性和足够的有效载荷容量。

Method: 采用可扩展的硬件系统设计和模块化软件架构，集成铰接推进器和高层图形用户界面等新功能。

Result: 通过仿真和现场实验验证了MVP的性能和兼容性。

Conclusion: MVP框架成功实现了AUV的模块化设计和开发，为研究提供了灵活且功能完善的解决方案。

Abstract: This paper reports the development of a new open-access modular framework,
called Marine Vehicle Packages (MVP), for Autonomous Underwater Vehicles. The
framework consists of both software and hardware designs allowing easy
construction of AUV for research with increased customizability and sufficient
payload capacity. This paper will present the scalable hardware system design
and the modular software design architecture. New features, such as articulated
thruster integration and high-level Graphic User Interface will be discussed.
Both simulation and field experiments results are shown to highlight the
performance and compatibility of the MVP.

</details>


### [93] [Finding an Initial Probe Pose in Teleoperated Robotic Echocardiography via 2D LiDAR-Based 3D Reconstruction](https://arxiv.org/abs/2509.24867)
*Mariadas Capsran Roshan,Edgar M Hidalgo,Mats Isaksson,Michelle Dunn,Jagannatha Charjee Pyaraka*

Main category: cs.RO

TL;DR: 提出了一种基于机器人安装2D LiDAR的方法，用于自动估计超声心动图检查的初始探头位置，通过3D重建胸廓表面来减少机器人超声检查的时间负担。


<details>
  <summary>Details</summary>
Motivation: 解决远程机器人超声心动图检查时间过长的问题，传统方法对光照、纹理和解剖变异敏感，需要自动化非专家任务来减轻操作负担。

Method: 使用机器人安装的2D LiDAR进行胸廓表面3D重建，通过平面标定估计LiDAR与机器人基座之间的变换，然后使用非刚性模板对齐来识别初始探头位置。

Result: 标定精度RMS残差1.8mm，旋转不确定性低于0.2度；人体模型重建误差2.78±0.21mm；人体试验中初始点距离临床定义点20-30mm，同一受试者重复试验变异小于4mm。

Conclusion: 该方法首次展示了机器人安装2D LiDAR用于人体表面3D重建，能够可靠地自动估计超声探头初始位置，为机器人超声检查提供了可行的自动化解决方案。

Abstract: Echocardiography is a key imaging modality for cardiac assessment but remains
highly operator-dependent, and access to trained sonographers is limited in
underserved settings. Teleoperated robotic echocardiography has been proposed
as a solution; however, clinical studies report longer examination times than
manual procedures, increasing diagnostic delays and operator workload.
Automating non-expert tasks, such as automatically moving the probe to an ideal
starting pose, offers a pathway to reduce this burden. Prior vision- and
depth-based approaches to estimate an initial probe pose are sensitive to
lighting, texture, and anatomical variability. We propose a robot-mounted 2D
LiDAR-based approach that reconstructs the chest surface in 3D and estimates
the initial probe pose automatically. To the best of our knowledge, this is the
first demonstration of robot-mounted 2D LiDAR used for 3D reconstruction of a
human body surface. Through plane-based extrinsic calibration, the
transformation between the LiDAR and robot base frames was estimated with an
overall root mean square (RMS) residual of 1.8 mm and rotational uncertainty
below 0.2{\deg}. The chest front surface, reconstructed from two linear LiDAR
sweeps, was aligned with non-rigid templates to identify an initial probe pose.
A mannequin-based study assessing reconstruction accuracy showed mean surface
errors of 2.78 +/- 0.21 mm. Human trials (N=5) evaluating the proposed approach
found probe initial points typically 20-30 mm from the clinically defined
initial point, while the variation across repeated trials on the same subject
was less than 4 mm.

</details>


### [94] [JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning](https://arxiv.org/abs/2509.24892)
*Shilong Ji,Yinuo Chen,Chuqi Wang,Jiayu Chen,Ruize Zhang,Feng Gao,Wenhao Tang,Shu'ang Yu,Sirui Xiang,Xinlei Chen,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: JuggleRL是首个基于强化学习的空中杂耍系统，通过大规模仿真学习闭环策略，在真实四旋翼上实现零样本部署，平均能连续击球311次，远超基于模型的方法。


<details>
  <summary>Details</summary>
Motivation: 空中机器人需要与物体进行精确的接触式交互，但面临不确定性问题。空中球类杂耍任务要求准确的时间控制、稳定控制和持续适应能力。

Method: 使用系统校准的四旋翼和球体动力学来减小仿真到现实的差距，通过奖励塑造鼓励球拍中心击球和持续杂耍，采用领域随机化增强鲁棒性，学习到的策略输出中层级命令并由底层控制器执行。

Result: 在真实世界中平均连续击球311次，最高达462次，远超基于模型基线（最多14次，平均3.1次）；还能泛化到未见过的5克轻球，平均击球145.9次。

Conclusion: 这项工作证明强化学习能够为空中机器人在动态交互任务中提供鲁棒稳定的控制能力。

Abstract: Aerial robots interacting with objects must perform precise, contact-rich
maneuvers under uncertainty. In this paper, we study the problem of aerial ball
juggling using a quadrotor equipped with a racket, a task that demands accurate
timing, stable control, and continuous adaptation. We propose JuggleRL, the
first reinforcement learning-based system for aerial juggling. It learns
closed-loop policies in large-scale simulation using systematic calibration of
quadrotor and ball dynamics to reduce the sim-to-real gap. The training
incorporates reward shaping to encourage racket-centered hits and sustained
juggling, as well as domain randomization over ball position and coefficient of
restitution to enhance robustness and transferability. The learned policy
outputs mid-level commands executed by a low-level controller and is deployed
zero-shot on real hardware, where an enhanced perception module with a
lightweight communication protocol reduces delays in high-frequency state
estimation and ensures real-time control. Experiments show that JuggleRL
achieves an average of $311$ hits over $10$ consecutive trials in the real
world, with a maximum of $462$ hits observed, far exceeding a model-based
baseline that reaches at most $14$ hits with an average of $3.1$. Moreover, the
policy generalizes to unseen conditions, successfully juggling a lighter $5$ g
ball with an average of $145.9$ hits. This work demonstrates that reinforcement
learning can empower aerial robots with robust and stable control in dynamic
interaction tasks.

</details>


### [95] [DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits](https://arxiv.org/abs/2509.24903)
*Lantao Li,Kang Yang,Rui Song,Chen Sun*

Main category: cs.RO

TL;DR: DRCP是一个实时可部署的协同感知框架，通过交叉模态协同感知模块和轻量级扩散细化模块，提升自动驾驶在动态驾驶环境中的检测准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界部署中面临的硬检测问题，如部分检测和噪声累积，这些限制了下游检测精度。

Method: 集成两个关键组件：Precise-Pyramid-Cross-Modality-Cross-Agent（利用相机内参感知的角度分区进行注意力融合和自适应卷积）和Mask-Diffusion-Mask-Aggregation（轻量级扩散细化模块）。

Result: 在移动平台上实现实时性能，同时在挑战性条件下显著提高鲁棒性。

Conclusion: DRCP框架有效解决了协同感知中的关键问题，为自动驾驶提供了更可靠的感知能力。

Abstract: Cooperative perception enabled by Vehicle-to-Everything communication has
shown great promise in enhancing situational awareness for autonomous vehicles
and other mobile robotic platforms. Despite recent advances in perception
backbones and multi-agent fusion, real-world deployments remain challenged by
hard detection cases, exemplified by partial detections and noise accumulation
which limit downstream detection accuracy. This work presents Diffusion on
Reinforced Cooperative Perception (DRCP), a real-time deployable framework
designed to address aforementioned issues in dynamic driving environments. DRCP
integrates two key components: (1) Precise-Pyramid-Cross-Modality-Cross-Agent,
a cross-modal cooperative perception module that leverages
camera-intrinsic-aware angular partitioning for attention-based fusion and
adaptive convolution to better exploit external features; and (2)
Mask-Diffusion-Mask-Aggregation, a novel lightweight diffusion-based refinement
module that encourages robustness against feature perturbations and aligns
bird's-eye-view features closer to the task-optimal manifold. The proposed
system achieves real-time performance on mobile platforms while significantly
improving robustness under challenging conditions. Code will be released in
late 2025.

</details>


### [96] [Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation](https://arxiv.org/abs/2509.24907)
*Thanh Long Nguyen,Duc Phu Nguyen,Thanh Thao Ton Nu,Quan Le,Thuan Hoang Tran,Manh Duong Phung*

Main category: cs.RO

TL;DR: 提出了一种用于社交感知导航的人类群体交互识别框架，使用RGB-D相机估计3D人体关键点和位置，通过PCA确定主要交互方向，利用鞋带公式计算兴趣点和参与区域。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统主要关注障碍物避让，忽视了社交线索，无法实现无缝的人机交互。需要开发能够识别人类群体交互的社交感知导航方法。

Method: 使用单目RGB-D相机的彩色和深度帧估计3D人体关键点和位置，应用主成分分析确定主导交互方向，使用鞋带公式计算兴趣点和参与区域。

Result: 该方法能够在不同场景和人数变化的情况下有效识别群体交互，在单板计算机上每帧处理时间约为4毫秒，实现了高速性能。

Conclusion: 提出的方法能够有效识别人类群体交互，作为ROS 2包实现，便于集成到现有导航系统中，为社交机器人提供更好的环境感知能力。

Abstract: {Recognizing human interactions is essential for social robots as it enables
them to navigate safely and naturally in shared environments. Conventional
robotic systems however often focus on obstacle avoidance, neglecting social
cues necessary for seamless human-robot interaction. To address this gap, we
propose a framework to recognize human group interactions for socially aware
navigation. Our method utilizes color and depth frames from a monocular RGB-D
camera to estimate 3D human keypoints and positions. Principal component
analysis (PCA) is then used to determine dominant interaction directions. The
shoelace formula is finally applied to compute interest points and engagement
areas. Extensive experiments have been conducted to evaluate the validity of
the proposed method. The results show that our method is capable of recognizing
group interactions across different scenarios with varying numbers of
individuals. It also achieves high-speed performance, processing each frame in
approximately 4 ms on a single-board computer used in robotic systems. The
method is implemented as a ROS 2 package making it simple to integrate into
existing navigation systems. Source code is available at
https://github.com/thanhlong103/social-interaction-detector

</details>


### [97] [From Code to Action: Hierarchical Learning of Diffusion-VLM Policies](https://arxiv.org/abs/2509.24917)
*Markus Peschl,Pietro Mazzaglia,Daniel Dijkman*

Main category: cs.RO

TL;DR: 提出了一种分层框架，结合代码生成视觉语言模型和低层扩散策略，通过将开源机器人API作为结构化监督源，实现机器人行为的模仿和泛化。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿学习在复杂长时程任务中存在泛化能力有限和数据稀缺的问题，需要更好的方法来分解任务并提升泛化性能。

Method: 训练视觉语言模型将任务描述分解为可执行子程序，通过扩散策略模仿对应机器人行为，并引入记忆机制处理非马尔可夫任务。

Result: 该设计实现了可解释的策略分解，相比扁平策略提升了泛化能力，并能分别评估高层规划和低层控制。

Conclusion: 将机器人API作为结构化监督源的分层框架有效解决了模仿学习中的泛化和数据稀缺问题，实现了更好的任务分解和性能提升。

Abstract: Imitation learning for robotic manipulation often suffers from limited
generalization and data scarcity, especially in complex, long-horizon tasks. In
this work, we introduce a hierarchical framework that leverages code-generating
vision-language models (VLMs) in combination with low-level diffusion policies
to effectively imitate and generalize robotic behavior. Our key insight is to
treat open-source robotic APIs not only as execution interfaces but also as
sources of structured supervision: the associated subtask functions - when
exposed - can serve as modular, semantically meaningful labels. We train a VLM
to decompose task descriptions into executable subroutines, which are then
grounded through a diffusion policy trained to imitate the corresponding robot
behavior. To handle the non-Markovian nature of both code execution and certain
real-world tasks, such as object swapping, our architecture incorporates a
memory mechanism that maintains subtask context across time. We find that this
design enables interpretable policy decomposition, improves generalization when
compared to flat policies and enables separate evaluation of high-level
planning and low-level control.

</details>


### [98] [CineWild: Balancing Art and Robotics for Ethical Wildlife Documentary Filmmaking](https://arxiv.org/abs/2509.24921)
*Pablo Pueyo,Fernando Caballero,Ana Cristina Murillo,Eduardo Montijano*

Main category: cs.RO

TL;DR: CineWild是一个结合机器人技术、电影摄影和伦理学的自主无人机框架，通过模型预测控制动态调整飞行路径和相机设置，在保证电影质量的同时保护动物福利。


<details>
  <summary>Details</summary>
Motivation: 无人机在野生动物纪录片制作中提供了独特的视角，但也存在干扰动物的伦理问题。需要开发能够在拍摄过程中平衡电影质量和动物福利的自主系统。

Method: 基于模型预测控制构建CineWild框架，包括自适应变焦（从声学和视觉安全距离拍摄）、避开动物视野的路径规划、平滑低噪音机动等关键功能。

Result: 通过仿真研究验证了系统的有效性，代码将在论文接受后发布。

Conclusion: CineWild展示了跨学科创新的价值，将工程学、视觉叙事和环境伦理学相结合，为无人机在野生动物纪录片中的伦理应用提供了解决方案。

Abstract: Drones, or unmanned aerial vehicles (UAVs), have become powerful tools across
domains-from industry to the arts. In documentary filmmaking, they offer
dynamic, otherwise unreachable perspectives, transforming how stories are told.
Wildlife documentaries especially benefit, yet drones also raise ethical
concerns: the risk of disturbing the animals they aim to capture. This paper
introduces CineWild, an autonomous UAV framework that combines robotics,
cinematography, and ethics. Built on model predictive control, CineWild
dynamically adjusts flight paths and camera settings to balance cinematic
quality with animal welfare. Key features include adaptive zoom for filming
from acoustic and visual safe distances, path-planning that avoids an animal's
field of view, and smooth, low-noise maneuvers. CineWild exemplifies
interdisciplinary innovation-bridging engineering, visual storytelling, and
environmental ethics. We validate the system through simulation studies and
will release the code upon acceptance.

</details>


### [99] [Trajectory Prediction via Bayesian Intention Inference under Unknown Goals and Kinematics](https://arxiv.org/abs/2509.24928)
*Shunan Yin,Zehui Lu,Shaoshuai Mou*

Main category: cs.RO

TL;DR: 提出一种自适应贝叶斯算法，通过意图推理实现实时轨迹预测，能够处理目标意图和运动特性的未知变化。


<details>
  <summary>Details</summary>
Motivation: 目标在运动过程中的意图和运动特性通常是未知且可能突然变化的，需要一种能够实时适应这些变化的预测方法。

Method: 同时估计两个关键变量：目标的当前意图（马尔可夫潜在状态）和意图参数（描述目标遵循最短路径策略的程度），采用联合更新技术保持对意图突变和未知运动动态的鲁棒性。

Result: 在数值实验和硬件演示中，该方法显著优于非自适应和部分自适应方法，实时运行频率达270Hz，无需训练或对目标行为的详细先验知识。

Conclusion: 该自适应贝叶斯算法在各种机器人系统中具有广泛适用性，能够有效处理意图变化和未知运动动态的实时轨迹预测问题。

Abstract: This work introduces an adaptive Bayesian algorithm for real-time trajectory
prediction via intention inference, where a target's intentions and motion
characteristics are unknown and subject to change. The method concurrently
estimates two critical variables: the target's current intention, modeled as a
Markovian latent state, and an intention parameter that describes the target's
adherence to a shortest-path policy. By integrating this joint update
technique, the algorithm maintains robustness against abrupt intention shifts
and unknown motion dynamics. A sampling-based trajectory prediction mechanism
then exploits these adaptive estimates to generate probabilistic forecasts with
quantified uncertainty. We validate the framework through numerical
experiments: Ablation studies of two cases, and a 500-trial Monte Carlo
analysis; Hardware demonstrations on quadrotor and quadrupedal platforms.
Experimental results demonstrate that the proposed approach significantly
outperforms non-adaptive and partially adaptive methods. The method operates in
real time around 270 Hz without requiring training or detailed prior knowledge
of target behavior, showcasing its applicability in various robotic systems.

</details>


### [100] [World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training](https://arxiv.org/abs/2509.24948)
*Junjin Xiao,Yandan Yang,Xinyuan Chang,Ronghan Chen,Feng Xiong,Mu Xu,Wei-Shi Zheng,Qing Zhang*

Main category: cs.RO

TL;DR: 提出了World-Env框架，使用基于世界模型的虚拟模拟器替代物理交互，通过强化学习后训练解决VLA模型在数据稀缺场景下的性能退化问题。


<details>
  <summary>Details</summary>
Motivation: VLA模型在数据稀缺场景下性能显著下降，且真实世界环境不可重置的特性限制了强化学习的应用，特别是在高风险工业自动化领域。现有方法缺乏任务完成检测机制，导致冗余动作降低任务成功率。

Method: World-Env包含两个关键组件：基于视频的世界模拟器生成时间一致的未来视觉观察，以及VLM引导的即时反射器提供连续奖励信号并预测动作终止。

Result: 在复杂机器人操作任务上的实验表明，该方法仅需每个任务5个专家演示就能获得显著性能提升，有效克服了传统VLA模型的数据低效、安全约束和执行效率问题。

Conclusion: World-Env为资源受限环境下的后训练提供了实用且可扩展的解决方案，使VLA模型能够安全探索并超越初始模仿学习分布。

Abstract: Vision-Language-Action (VLA) models trained via imitation learning suffer
from significant performance degradation in data-scarce scenarios due to their
reliance on large-scale demonstration datasets. Although reinforcement learning
(RL)-based post-training has proven effective in addressing data scarcity, its
application to VLA models is hindered by the non-resettable nature of
real-world environments. This limitation is particularly critical in high-risk
domains such as industrial automation, where interactions often induce state
changes that are costly or infeasible to revert. Furthermore, existing VLA
approaches lack a reliable mechanism for detecting task completion, leading to
redundant actions that reduce overall task success rates. To address these
challenges, we propose World-Env, an RL-based post-training framework that
replaces physical interaction with a low-cost, world model-based virtual
simulator. World-Env consists of two key components: (1) a video-based world
simulator that generates temporally consistent future visual observations, and
(2) a vision-language model (VLM)-guided instant reflector that provides
continuous reward signals and predicts action termination. This simulated
environment enables VLA models to safely explore and generalize beyond their
initial imitation learning distribution. Our method achieves notable
performance gains with as few as five expert demonstrations per task.
Experiments on complex robotic manipulation tasks demonstrate that World-Env
effectively overcomes the data inefficiency, safety constraints, and
inefficient execution of conventional VLA models that rely on real-world
interaction, offering a practical and scalable solution for post-training in
resource-constrained settings.

</details>


### [101] [MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation](https://arxiv.org/abs/2509.24956)
*Jan Ole von Hartz,Lukas Schweizer,Joschka Boedecker,Abhinav Valada*

Main category: cs.RO

TL;DR: 提出了MSG框架，通过训练多个物体中心策略并在推理时组合它们，显著提高了生成式机器人策略的样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成式机器人策略如Flow Matching虽然灵活多模态，但样本效率低。现有的物体中心策略虽然有所改进，但仍未解决这一限制。

Method: MSG是一个推理时组合框架，训练多个物体中心策略并在推理时组合它们。该方法是模型无关且仅需推理，适用于各种生成式策略和训练范式。

Result: 从仅5个演示中学习高质量生成式策略，演示减少95%，性能比单流方法提高89%。支持零样本物体实例迁移。

Conclusion: MSG显著提高了生成式机器人策略的样本效率和性能，具有广泛适用性，并为部署提供了实用建议。

Abstract: Generative robot policies such as Flow Matching offer flexible, multi-modal
policy learning but are sample-inefficient. Although object-centric policies
improve sample efficiency, it does not resolve this limitation. In this work,
we propose Multi-Stream Generative Policy (MSG), an inference-time composition
framework that trains multiple object-centric policies and combines them at
inference to improve generalization and sample efficiency. MSG is
model-agnostic and inference-only, hence widely applicable to various
generative policies and training paradigms. We perform extensive experiments
both in simulation and on a real robot, demonstrating that our approach learns
high-quality generative policies from as few as five demonstrations, resulting
in a 95% reduction in demonstrations, and improves policy performance by 89
percent compared to single-stream approaches. Furthermore, we present
comprehensive ablation studies on various composition strategies and provide
practical recommendations for deployment. Finally, MSG enables zero-shot object
instance transfer. We make our code publicly available at
https://msg.cs.uni-freiburg.de.

</details>


### [102] [Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks](https://arxiv.org/abs/2509.24972)
*Vijja Wichitwechkarn,Emlyn Williams,Charles Fox,Ruchi Choudhary*

Main category: cs.RO

TL;DR: 提出一种单次模仿学习方法，无需额外训练或标注即可处理多步骤操作任务，在单步骤和多步骤任务中分别达到90%和82.5%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 现有单次模仿学习方法在单步骤任务上表现良好，但在处理长视野、多步骤任务时需要额外模型训练或人工标注，这限制了其实际应用。

Method: 开发了一种无需额外模型训练或人工标注的方法，仅需单次演示即可应用于多步骤操作任务，并比较了不同预训练特征提取器的性能和计算效率。

Result: 在多步骤任务中平均成功率为82.5%，单步骤任务中为90%，均达到或超过基线方法性能。

Conclusion: 该方法成功扩展了单次模仿学习的应用范围，能够有效处理多步骤操作任务，且计算效率良好。

Abstract: Recent advances in one-shot imitation learning have enabled robots to acquire
new manipulation skills from a single human demonstration. While existing
methods achieve strong performance on single-step tasks, they remain limited in
their ability to handle long-horizon, multi-step tasks without additional model
training or manual annotation. We propose a method that can be applied to this
setting provided a single demonstration without additional model training or
manual annotation. We evaluated our method on multi-step and single-step
manipulation tasks where our method achieves an average success rate of 82.5%
and 90%, respectively. Our method matches and exceeds the performance of the
baselines in both these cases. We also compare the performance and
computational efficiency of alternative pre-trained feature extractors within
our framework.

</details>


### [103] [Path Diffuser: Diffusion Model for Data-Driven Traffic Simulator](https://arxiv.org/abs/2509.24995)
*Da Saem Lee,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 提出了Path Diffuser，一种基于扩散模型的两阶段方法，无需历史轨迹信息即可生成地图条件下的智能体姿态初始化和轨迹，通过Frenet帧候选轨迹提升多样性并确保道路合规性。


<details>
  <summary>Details</summary>
Motivation: 传统规则规划器缺乏多样性和真实性，而基于学习的模拟器依赖历史轨迹数据，难以生成新场景且在处理分布外地图场景时产生不现实轨迹。

Method: 两阶段扩散模型，包含姿态初始化和轨迹生成，采用Frenet帧运动基元先验来增强多样性并确保道路合规性，探索多智能体交互建模。

Result: 在Argoverse2数据集上表现优异，在分布外地图变体上具有良好的泛化能力，在分布指标上比基线方法提升1.92倍，常识指标提升1.14倍，道路合规性提升1.62倍。

Conclusion: Path Diffuser能够有效生成多样且真实的交通场景，无需历史轨迹信息，在分布外场景下仍能保持良好性能。

Abstract: Simulating diverse and realistic traffic scenarios is critical for developing
and testing autonomous planning. Traditional rule-based planners lack diversity
and realism, while learning-based simulators often replay, forecast, or edit
scenarios using historical agent trajectories. However, they struggle to
generate new scenarios, limiting scalability and diversity due to their
reliance on fully annotated logs and historical data. Thus, a key challenge for
a learning-based simulator's performance is that it requires agents' past
trajectories and pose information in addition to map data, which might not be
available for all agents on the road.Without which, generated scenarios often
produce unrealistic trajectories that deviate from drivable areas, particularly
under out-of-distribution (OOD) map scenes (e.g., curved roads). To address
this, we propose Path Diffuser (PD): a two-stage, diffusion model for
generating agent pose initializations and their corresponding trajectories
conditioned on the map, free of any historical context of agents' trajectories.
Furthermore, PD incorporates a motion primitive-based prior, leveraging Frenet
frame candidate trajectories to enhance diversity while ensuring road-compliant
trajectory generation. We also explore various design choices for modeling
complex multi-agent interactions. We demonstrate the effectiveness of our
method through extensive experiments on the Argoverse2 Dataset and additionally
evaluate the generalizability of the approach on OOD map variants. Notably,
Path Diffuser outperforms the baseline methods by 1.92x on distribution
metrics, 1.14x on common-sense metrics, and 1.62x on road compliance from
adversarial benchmarks.

</details>


### [104] [AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation](https://arxiv.org/abs/2509.25032)
*Ryosuke Takanami,Petr Khrapchenkov,Shu Morikuni,Jumpei Arima,Yuta Takaba,Shunsuke Maeda,Takuya Okubo,Genki Sano,Satoshi Sekioka,Aoi Kadoya,Motonari Kambara,Naoya Nishiura,Haruto Suzuki,Takanori Yoshimoto,Koya Sakamoto,Shinnosuke Ono,Hu Yang,Daichi Yashima,Aoi Horo,Tomohiro Motoda,Kensuke Chiyoma,Hiroshi Ito,Koki Fukuda,Akihito Goto,Kazumi Morinaga,Yuya Ikeda,Riko Kawada,Masaki Yoshikawa,Norio Kosuge,Yuki Noguchi,Kei Ota,Tatsuya Matsushima,Yusuke Iwasawa,Yutaka Matsuo,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 提出了AIRoA MoMa数据集，这是一个用于移动操作的大规模多模态数据集，包含同步的RGB图像、关节状态、六轴腕部力-扭矩信号和机器人内部状态，以及用于分层学习和错误分析的两层注释模式。


<details>
  <summary>Details</summary>
Motivation: 随着机器人从受控环境转向非结构化的人类环境，构建能够可靠遵循自然语言指令的通用智能体仍然是一个核心挑战。现有的数据集缺乏同步的力-扭矩感知、分层注释和明确的失败案例。

Method: 收集了25,469个片段（约94小时）的数据，使用Human Support Robot (HSR)机器人，包含同步的多模态数据，并采用新颖的两层注释模式（子目标和基本动作）。

Result: 数据集已标准化为LeRobot v2.1格式，并在HuggingFace上公开发布，为推进下一代视觉-语言-动作模型提供了关键基准。

Conclusion: AIRoA MoMa通过整合移动操作、接触丰富的交互和长时程结构，填补了现有资源的空白，为机器人移动操作研究提供了重要资源。

Abstract: As robots transition from controlled settings to unstructured human
environments, building generalist agents that can reliably follow natural
language instructions remains a central challenge. Progress in robust mobile
manipulation requires large-scale multimodal datasets that capture contact-rich
and long-horizon tasks, yet existing resources lack synchronized force-torque
sensing, hierarchical annotations, and explicit failure cases. We address this
gap with the AIRoA MoMa Dataset, a large-scale real-world multimodal dataset
for mobile manipulation. It includes synchronized RGB images, joint states,
six-axis wrist force-torque signals, and internal robot states, together with a
novel two-layer annotation schema of sub-goals and primitive actions for
hierarchical learning and error analysis. The initial dataset comprises 25,469
episodes (approx. 94 hours) collected with the Human Support Robot (HSR) and is
fully standardized in the LeRobot v2.1 format. By uniquely integrating mobile
manipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMa
provides a critical benchmark for advancing the next generation of
Vision-Language-Action models. The first version of our dataset is now
available at https://huggingface.co/datasets/airoa-org/airoa-moma .

</details>


### [105] [AgriCruiser: An Open Source Agriculture Robot for Over-the-row Navigation](https://arxiv.org/abs/2509.25056)
*Kenny Truong,Yongkyu Lee,Jason Irie,Shivam Kumar Panda,Shahab Ahmad,Md. Mukhlesur Rahman,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriCruiser是一款开源农业机器人，具有可调节轨道宽度和紧凑转弯半径，通过精准喷洒系统实现高效杂草管理，成本约为5000-6000美元。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、可快速适应不同作物和行距布局的开源农业机器人平台，以降低劳动力需求并减少作物损伤。

Method: 使用商品T型槽型材构建可调节底盘（轨道宽度1.42-1.57米，离地间隙0.94米），集成精准喷洒系统，在亚麻田进行杂草管理测试。

Result: 单次机器人喷洒使杂草数量比人工除草减少24-42倍，作物损伤更小；在多种地面条件下均能可靠运行。

Conclusion: 低成本、可重构的行间机器人能有效管理杂草，减少作物损伤和劳动力需求，为表型分析和农业应用提供多功能平台。

Abstract: We present the AgriCruiser, an open-source over-the-row agricultural robot
developed for low-cost deployment and rapid adaptation across diverse crops and
row layouts. The chassis provides an adjustable track width of 1.42 m to 1.57
m, along with a ground clearance of 0.94 m. The AgriCruiser achieves compact
pivot turns with radii of 0.71 m to 0.79 m, enabling efficient headland
maneuvers. The platform is designed for the integration of the other
subsystems, and in this study, a precision spraying system was implemented to
assess its effectiveness in weed management. In twelve flax plots, a single
robotic spray pass reduced total weed populations (pigweed and Venice mallow)
by 24- to 42-fold compared to manual weeding in four flax plots, while also
causing less crop damage. Mobility experiments conducted on concrete, asphalt,
gravel, grass, and both wet and dry soil confirmed reliable traversal
consistent with torque sizing. The complete chassis can be constructed from
commodity T-slot extrusion with minimal machining, resulting in a bill of
materials costing approximately $5,000 - $6,000, which enables replication and
customization. The mentioned results demonstrate that low-cost, reconfigurable
over-the-row robots can achieve effective weed management with reduced crop
damage and labor requirements, while providing a versatile foundation for
phenotyping, sensing, and other agriculture applications. Design files and
implementation details are released to accelerate research and adoption of
modular agricultural robotics.

</details>


### [106] [Crop Spirals: Re-thinking the field layout for future robotic agriculture](https://arxiv.org/abs/2509.25091)
*Lakshan Lavan,Lanojithan Thiyagarasa,Udara Muthugala,Rajitha de Silva*

Main category: cs.RO

TL;DR: 提出机器人中心的方形螺旋布局替代传统线性布局，通过DH-ResNet18路径点回归、像素到里程计映射、A*规划和模型预测控制实现高效导航，在仿真中路径缩短28%，执行时间减少25%。


<details>
  <summary>Details</summary>
Motivation: 传统线性作物布局为拖拉机优化，但阻碍机器人导航，存在急转弯、长距离行驶和感知混淆问题。

Method: 开发结合DH-ResNet18路径点回归、像素到里程计映射、A*规划和模型预测控制的导航系统，采用方形螺旋布局和中央轨道线。

Result: 螺旋布局比线性布局路径缩短28%，执行时间减少约25%；多机器人研究中贪婪分配器比匈牙利分配降低33-37%批量完成时间。

Conclusion: 重新设计田间几何形状能更好地适应自主农业需求，螺旋布局在机器人导航中表现出显著优势。

Abstract: Conventional linear crop layouts, optimised for tractors, hinder robotic
navigation with tight turns, long travel distances, and perceptual aliasing. We
propose a robot-centric square spiral layout with a central tramline, enabling
simpler motion and more efficient coverage. To exploit this geometry, we
develop a navigation stack combining DH-ResNet18 waypoint regression,
pixel-to-odometry mapping, A* planning, and model predictive control (MPC). In
simulations, the spiral layout yields up to 28% shorter paths and about 25%
faster execution for waypoint-based tasks across 500 waypoints than linear
layouts, while full-field coverage performance is comparable to an optimised
linear U-turn strategy. Multi-robot studies demonstrate efficient coordination
on the spirals rule-constrained graph, with a greedy allocator achieving 33-37%
lower batch completion times than a Hungarian assignment under our setup. These
results highlight the potential of redesigning field geometry to better suit
autonomous agriculture.

</details>


### [107] [Curriculum Imitation Learning of Distributed Multi-Robot Policies](https://arxiv.org/abs/2509.25097)
*Jesús Roche,Eduardo Sebastián,Eduardo Montijano*

Main category: cs.RO

TL;DR: 提出一种从第三人称全局演示中学习多机器人系统分布式控制策略的方法，通过课程学习改进长期协调，并通过感知估计方法处理局部观测不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统中长期协调的挑战以及获取真实训练数据的困难，旨在从全局演示中学习分布式控制策略。

Method: 使用课程学习逐渐增加专家轨迹长度以稳定训练，提出感知估计方法将全局状态转换为局部观测，包括邻居过滤、参考系转换和传感器噪声模拟。

Result: 实验表明课程学习提高了长期行为准确性，感知估计方法使策略对现实不确定性具有鲁棒性，能够学习到稳健的分布式控制器。

Conclusion: 该方法能够从全局演示中学习鲁棒的分布式控制策略，无需专家动作或机载测量，在多机器人系统任务中表现良好。

Abstract: Learning control policies for multi-robot systems (MRS) remains a major
challenge due to long-term coordination and the difficulty of obtaining
realistic training data. In this work, we address both limitations within an
imitation learning framework. First, we shift the typical role of Curriculum
Learning in MRS, from scalability with the number of robots, to focus on
improving long-term coordination. We propose a curriculum strategy that
gradually increases the length of expert trajectories during training,
stabilizing learning and enhancing the accuracy of long-term behaviors. Second,
we introduce a method to approximate the egocentric perception of each robot
using only third-person global state demonstrations. Our approach transforms
idealized trajectories into locally available observations by filtering
neighbors, converting reference frames, and simulating onboard sensor
variability. Both contributions are integrated into a physics-informed
technique to produce scalable, distributed policies from observations. We
conduct experiments across two tasks with varying team sizes and noise levels.
Results show that our curriculum improves long-term accuracy, while our
perceptual estimation method yields policies that are robust to realistic
uncertainty. Together, these strategies enable the learning of robust,
distributed controllers from global demonstrations, even in the absence of
expert actions or onboard measurements.

</details>


### [108] [Safe Planning in Unknown Environments using Conformalized Semantic Maps](https://arxiv.org/abs/2509.25124)
*David Smith Sundarsingh,Yifei Li,Tianji Tang,George J. Pappas,Nikolay Atanasov,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出首个无需传感器模型知识的语义规划算法，在未知环境中完成语义到达-避障任务，通过保形预测量化语义地图不确定性，确保用户指定的任务完成率。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境下语义规划中的感知不确定性挑战，现有方法要么忽略感知不确定性缺乏正确性保证，要么需要已知传感器模型，而实际应用中传感器模型往往未知。

Method: 使用保形预测在模型无关和分布无关的方式下量化语义地图的不确定性，在线构建语义地图，确保任务完成概率满足用户指定要求。

Result: 通过大量实验验证，该方法始终优于基线方法，在任务成功率方面表现优异，理论任务完成率得到验证。

Conclusion: 提出的规划器是首个能够在无需传感器模型知识的情况下，为语义到达-避障任务提供用户指定任务完成率保证的方法，有效解决了感知不确定性下的语义规划问题。

Abstract: This paper addresses semantic planning problems in unknown environments under
perceptual uncertainty. The environment contains multiple unknown semantically
labeled regions or objects, and the robot must reach desired locations while
maintaining class-dependent distances from them. We aim to compute robot paths
that complete such semantic reach-avoid tasks with user-defined probability
despite uncertain perception. Existing planning algorithms either ignore
perceptual uncertainty - thus lacking correctness guarantees - or assume known
sensor models and noise characteristics. In contrast, we present the first
planner for semantic reach-avoid tasks that achieves user-specified mission
completion rates without requiring any knowledge of sensor models or noise.
This is enabled by quantifying uncertainty in semantic maps - constructed
on-the-fly from perceptual measurements - using conformal prediction in a
model- and distribution-free manner. We validate our approach and the
theoretical mission completion rates through extensive experiments, showing
that it consistently outperforms baselines in mission success rates.

</details>
