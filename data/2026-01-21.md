<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 184]
- [cs.RO](#cs.RO) [Total: 62]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths](https://arxiv.org/abs/2601.11564)
*Ahilan Ayyachamy Nadar Ponnusamy,Karthic Chandran,M Maruf Hossain*

Main category: cs.CL

TL;DR: 论文研究了大规模上下文窗口下LLMs的性能与质量权衡，发现KV缓存增长导致非线性性能下降，MoE架构在不同上下文规模下表现出独特异常行为。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs上下文窗口不断扩大以支持复杂长文本推理，管理扩展上下文带来了严重的计算开销。需要研究系统性能与模型质量之间的关键权衡，特别是在面对大量无关和干扰性上下文时。

Method: 研究使用密集Transformer架构（Llama-3.1-70B和Qwen1.5-14B），分析其在大量无关上下文下的表现。特别关注KV缓存的增长影响，并对MoE架构在不同上下文规模下的行为进行扩展分析。

Result: 发现KV缓存增长导致非线性性能下降。MoE架构在不同上下文规模下表现出独特的行为异常，表明在高token量下，架构优势可能被基础设施瓶颈所掩盖。

Conclusion: 扩展上下文窗口虽然有益于复杂任务，但会带来显著的计算开销和性能下降。需要重新思考LLM架构设计，以平衡上下文容量与计算效率，特别是在处理无关信息时。

Abstract: The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.

</details>


### [2] [Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings](https://arxiv.org/abs/2601.11565)
*Pakorn Ueareeworakul,Shuman Liu,Jinghao Feng,Ling Hu,Zhantang Shi,Chengqi Sun,Liang Yao,Panyi Ouyang,Haibo Zhang,Anxiang Zeng*

Main category: cs.CL

TL;DR: Compass-Embedding v4是针对东南亚电商场景优化的多语言嵌入框架，通过类感知掩码、多样化训练语料构建和推理优化，解决了数据稀缺、噪声监督和生产约束三大挑战。


<details>
  <summary>Details</summary>
Motivation: 随着全球电商向新兴市场扩张，低资源语言缺乏高质量语义表示成为检索、推荐和搜索系统的关键瓶颈。东南亚电商场景面临数据稀缺、噪声监督和严格生产约束的联合挑战。

Method: 1. 提出类感知掩码(CAM)改进InfoNCE目标，抑制批次内无效负样本；2. 通过上下文基础合成数据生成、跨语言翻译和结构化电商数据构建多样化训练语料；3. 结合鲁棒性驱动的大批次训练与球面模型融合，使用vLLM和FP8量化优化推理。

Result: 在多项多语言基准测试和专有电商任务评估中，Compass-Embedding v4在主要东南亚语言上达到最先进性能，在领域特定检索和分类任务中显著优于通用嵌入模型，同时在高资源语言上保持竞争力。

Conclusion: Compass-Embedding v4成功解决了东南亚电商场景中的语义表示挑战，通过创新的训练策略和优化技术实现了高质量、高效率的多语言嵌入，为低资源语言电商应用提供了有效解决方案。

Abstract: As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.

</details>


### [3] [Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology](https://arxiv.org/abs/2601.11567)
*Vanessa D'Amario,Randy Daniel,Alessandro Zanetti,Dhruv Edamadaka,Nitya Alaparthy,Joshua Tarkoff*

Main category: cs.CL

TL;DR: 评估六个小型开源医疗大语言模型在儿科内分泌学中的表现，发现提示微小变化会导致输出显著差异，高一致性不代表正确性，模型存在自我评估偏见，系统级扰动也会影响输出稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前小型开源医疗大语言模型的评估通常仅限于医学多选题的准确性，缺乏对一致性、鲁棒性和推理行为的全面评估。需要更全面的诊断框架来了解这些模型在真实临床决策支持场景中的潜在问题。

Method: 使用多选题结合人工评估和临床审查，评估六个小型开源医疗LLM。在确定性设置中，研究提示变化对模型输出和自我评估偏见的影响；在随机性设置中，评估输出变异性并研究一致性与正确性之间的关系。

Result: HuatuoGPT-o1-8B表现最佳。高一致性并不代表正确性，尽管HuatuoGPT-o1-8B的一致性最高。模型存在自我评估偏见和对解释顺序的依赖性。专家审查发现错误推理中混合了临床可接受的回答和临床疏忽。系统级扰动（如CUDA构建差异）会导致模型输出的统计显著变化。

Conclusion: 语义上可忽略的提示微小变化会导致输出显著差异，这引发了对基于LLM评估可重复性的担忧。研究强调了在不同随机机制下输出变异性问题，表明需要更广泛的诊断框架来理解真实世界临床决策支持场景中的潜在陷阱。

Abstract: Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.

</details>


### [4] [An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT](https://arxiv.org/abs/2601.11573)
*Muhammad Muneeb,David B. Ascher*

Main category: cs.CL

TL;DR: 提出一个可重复的LLM微调流程，针对生物信息学领域，包含两个应用案例：PRSGPT（多基因风险评分工具）和BioStarsGPT（社区论坛讨论），通过九步流程生成高质量QA数据集并微调模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂生物信息学应用中缺乏专业知识，需要开发可扩展的领域特定微调方法，以创建可在本地部署、保护隐私的生物信息学助手。

Method: 九步流程：整合多样数据源、结构化预处理、基于提示的QA生成（使用Google Gemini）、自然语言推理质量控制、语义去重、基于聚类的数据分割、使用LoRA的参数高效微调。微调了三个LLM（LLaMA-3.2-3B、Qwen2.5-7B、Gemma）。

Result: Qwen2.5-7B表现最佳：PRSGPT的BLEU-4和ROUGE-1分别提升82%和70%，BioStarsGPT提升6%和18%。生成开源数据集：PRSGPT超过28,000个QA对，BioStarsGPT 154,282个。人类评估显示PRSGPT在PRS工具比较任务中准确率61.9%，与Google Gemini（61.4%）相当但提供更丰富的方法细节和准确引用；BioStarsGPT在142个生物信息学问题中概念准确率59%。

Conclusion: 该流程实现了可扩展的领域特定LLM微调，支持隐私保护、本地部署的生物信息学助手，探索了实际应用，并解决了开发和使用中的挑战、限制及缓解策略。

Abstract: Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\% and 70\% for PRSGPT and 6\% and 18\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.

</details>


### [5] [Concept Attractors in LLMs and their Applications](https://arxiv.org/abs/2601.11575)
*Sotirios Panagiotis Chytas,Vikas Singh*

Main category: cs.CL

TL;DR: LLMs将语义相关提示映射到特定层的相似内部表示，这可以通过迭代函数系统解释为向概念特定吸引子的收缩映射，基于此开发了无需训练的吸引子干预方法，在多种任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在特定层会将语义相关的提示映射到相似的内部表示，即使它们的表面形式差异很大。这种行为的数学原理尚不明确，需要探索其底层机制并开发基于此洞察的实用方法。

Method: 将LLM层解释为迭代函数系统中的收缩映射，这些映射朝向概念特定的吸引子。基于这一洞察，开发了直接在吸引子上操作的简单、无需训练的方法，用于解决各种实际任务。

Result: 尽管方法简单，这些基于吸引子的干预方法在语言翻译、幻觉减少、护栏设置和合成数据生成等任务上匹配或超过了专门的基线方法，提供了比大量微调更高效的替代方案。

Conclusion: LLM层作为向概念吸引子的收缩映射的IFS解释，为开发简单有效的训练免费干预方法提供了理论基础，这些方法在多种任务上表现优异且具有更好的泛化能力。

Abstract: Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.

</details>


### [6] [LimAgents: Multi-Agent LLMs for Generating Research Limitations](https://arxiv.org/abs/2601.11578)
*Ibrahim Al Azher,Zhishuai Guo,Hamed Alhoori*

Main category: cs.CL

TL;DR: LimAgents：一个多智能体LLM框架，通过整合OpenReview评论、作者陈述的局限性和引用文献，生成实质性研究局限性分析，相比零样本方法显著提升覆盖度。


<details>
  <summary>Details</summary>
Motivation: 现有零样本大语言模型生成的研究局限性陈述往往流于表面（如数据集偏差、泛化性问题），重复作者已报告的局限性，未能深入挖掘方法论缺陷和上下文差距。同时，许多作者仅披露部分或琐碎的局限性，需要更系统的方法来识别实质性限制。

Method: 提出LimAgents多智能体框架，包含多个角色分工的智能体：提取显式局限性的智能体、分析方法论差距的智能体、模拟同行评审视角的智能体、基于引用文献分析上下文弱点的智能体。通过Judge智能体精炼输出，Master智能体整合成清晰集合。同时引入基于LLM-as-a-Judge的点对点评估协议，更准确衡量覆盖度。

Result: 实验表明LimAgents显著提升性能：RAG+多智能体GPT-4o mini配置相比零样本基线获得+15.51%的覆盖度提升；Llama 3 8B多智能体设置实现+4.41%的改进。

Conclusion: LimAgents框架通过多智能体协作和综合信息源，能够系统识别显式、隐式、同行评审关注和文献背景的局限性，为研究局限性分析提供了更全面、实质性的解决方案。

Abstract: Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.

</details>


### [7] [Bielik 11B v3: Multilingual Large Language Model for European Languages](https://arxiv.org/abs/2601.11579)
*Krzysztof Ociepa,Łukasz Flis,Remigiusz Kinas,Krzysztof Wróbel,Adrian Gwoździej*

Main category: cs.CL

TL;DR: Bielik 11B v3 是一个针对波兰语优化的先进语言模型，基于 Mistral 7B 架构扩展至 110 亿参数，通过四阶段训练流程开发，在波兰语任务上超越其他专业模型和更大模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个针对波兰语高度优化的先进语言模型，同时保持对其他欧洲语言的良好支持，为资源较少语言建立高效高性能模型的新基准。

Method: 基于 Mistral 7B v0.2 架构，通过深度扩展至 110 亿参数，采用四阶段训练流程：持续预训练、监督微调、直接偏好优化和强化学习。

Result: 在波兰语任务上显著超越其他专业波兰语模型，性能优于许多参数多2-6倍的大型模型，在从基础语言理解到复杂推理的广泛任务中表现优异。

Conclusion: Bielik 11B v3 不仅提升了波兰语的AI能力，还为开发资源效率高、性能优异的较少代表语言模型建立了新基准，其参数效率和量化选项支持多样化硬件部署。

Abstract: We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.
  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.
  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.

</details>


### [8] [Speculative Decoding: Performance or Illusion?](https://arxiv.org/abs/2601.11580)
*Xiaoxuan Liu,Jiaxiang Yu,Jongseok Park,Ion Stoica,Alvin Cheung*

Main category: cs.CL

TL;DR: 对推测解码在生产级推理引擎vLLM上的首次系统性研究，揭示了实际性能与理论上限之间的显著差距，并指出了改进推测解码的新研究方向。


<details>
  <summary>Details</summary>
Motivation: 推测解码已成为加速大语言模型推理的流行技术，但先前评估依赖研究原型和不切实际的小批量大小，其实际效果仍不清楚。需要在实际生产环境中系统评估推测解码的性能。

Method: 在广泛部署的生产级推理引擎vLLM上进行首次系统性研究，涵盖多种推测解码变体（n-gram、EAGLE/EAGLE-3、Draft-Model、Multi-Token Prediction），跨越多样化工作负载、模型规模和批量大小。分析影响SD性能的关键因素，并量化SD加速的理论上限。

Result: 目标模型的验证阶段主导执行时间，接受长度在不同输出token位置、请求和数据集间差异显著。实测性能与理论上限对比显示存在巨大差距，表明推测解码在实际部署中仍有很大优化空间。

Conclusion: 研究揭示了推测解码实际性能与理论潜力之间的不匹配，为改进推测解码技术开辟了新的研究方向，特别是在优化验证阶段和提高接受长度一致性方面。

Abstract: Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.

</details>


### [9] [Enhancing the QA Model through a Multi-domain Debiasing Framework](https://arxiv.org/abs/2601.11581)
*Yuefeng Wang,ChangJae Lee*

Main category: cs.CL

TL;DR: 该研究评估ELECTRA-small模型在SQuAD v1.1及对抗数据集上的表现，通过识别偏差类型并开发多领域去偏框架，实现了EM和F1分数最高2.6个百分点的提升。


<details>
  <summary>Details</summary>
Motivation: QA模型在机器阅读理解方面虽有进步，但在复杂查询和对抗条件下常表现出偏差，影响性能表现。需要针对性地识别和缓解这些偏差以提升系统的鲁棒性和可靠性。

Method: 评估ELECTRA-small模型在SQuAD v1.1、AddSent和AddOneSent数据集上的表现，识别词汇偏差、数值推理和实体识别等错误类型，开发包含知识蒸馏、去偏技术和领域扩展的多领域去偏框架。

Result: 在所有测试集上实现了最高2.6个百分点的EM和F1分数提升，在对抗环境下也取得了显著增益，证明了去偏策略的有效性。

Conclusion: 针对性的偏差缓解策略能够有效增强自然语言理解系统的鲁棒性和可靠性，为QA模型的改进提供了实用方法。

Abstract: Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.

</details>


### [10] [Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents](https://arxiv.org/abs/2601.11585)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: Entropic Context Shaping (ECS) 是一个信息论框架，通过测量模型答案分布向正确答案的偏移来评估上下文效用，在细粒度上下文选择任务中显著优于基于词重叠的传统方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理的上下文工程需要区分实用信息和误导性干扰信息。现有基于词重叠的方法无法捕捉语用效用，即一段文本是否真正有助于回答问题。

Method: 提出Entropic Context Shaping (ECS)框架，将上下文效用定义为答案概率的有符号变化，通过信息论方法测量模型答案分布向正确答案的偏移。理论分析表明任务无关的更新会产生接近零的分布偏移。

Result: 在LongMemEval（会话级）和LoCoMo（轮次级）基准测试中，ECS在细粒度轮次选择任务上，使用Llama-3.1-8B模型达到F1=0.265，相比TF-IDF的F1=0.154有71.83%的相对提升。

Conclusion: ECS框架通过信息论方法有效捕捉语用效用，在精确上下文选择任务中显著优于基于词相似性的传统方法，证明了语用效用比词法相似性在上下文选择中更重要。

Abstract: Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.

</details>


### [11] [Towards AGI A Pragmatic Approach Towards Self Evolving Agent](https://arxiv.org/abs/2601.11658)
*Indrajit Kar,Sammy Zonunpuia,Zonunfeli Ralte*

Main category: cs.CL

TL;DR: 提出分层自进化多智能体框架，通过工具合成和进化算法实现LLM智能体的自主能力扩展，在TaskCraft数据集上验证了进化智能体优于原始版本


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体部署后是静态的，缺乏自主扩展能力、生成新工具或进化推理的能力，需要一种能够持续适应和自主进化的智能体框架

Method: 分层自进化多智能体框架：基础LLM、操作SLM智能体、代码生成LLM和教师LLM。工作流程：任务尝试→工具合成→进化阶段（课程学习、基于奖励的学习、遗传算法进化）

Result: 在TaskCraft数据集上评估：课程学习提供快速恢复和强泛化能力，基于奖励的学习在高难度任务上表现优异，遗传算法提供高行为多样性。所有进化智能体都优于原始版本

Conclusion: 该框架实现了稳健、自主、自我改进的智能体进化，证明了LLM智能体能够通过自主能力扩展和进化算法实现持续适应和性能提升

Abstract: Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.

</details>


### [12] [RAC: Retrieval-Augmented Clarification for Faithful Conversational Search](https://arxiv.org/abs/2601.11722)
*Ahmed Rayane Kebir,Vincent Guigue,Lynda Said Lhadj,Laure Soulier*

Main category: cs.CL

TL;DR: RAC框架通过检索增强生成基于语料库的澄清问题，使用对比偏好优化确保问题有文档依据，在四个基准测试中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有对话搜索系统的澄清问题生成主要关注流畅性和用户意图对齐，但缺乏对语料库基础的重视，导致可能生成无法从可用文档回答的问题。

Method: 提出RAC框架：1) 比较多种检索索引策略；2) 微调大语言模型以充分利用检索上下文；3) 应用对比偏好优化，偏好有检索段落支持的问题而非无依据的问题。

Result: 在四个基准测试中，RAC相比基线方法有显著改进。除了LLM-as-Judge评估外，还引入了基于NLI和数据到文本的新指标，证明该方法能持续提升问题生成的忠实度。

Conclusion: RAC框架通过检索增强和对比偏好优化，成功生成了基于语料库的忠实澄清问题，解决了现有方法缺乏文档基础的问题。

Abstract: Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.

</details>


### [13] [Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era](https://arxiv.org/abs/2601.11739)
*Xinyu Pi,Qisen Yang,Chuong Nguyen,Hua Shen*

Main category: cs.CL

TL;DR: 论文提出了一个4×4框架来分析LLM在质性研究中的输出类型，发现现有系统偏向低层次意义和低承诺表示，并提出了改进议程。


<details>
  <summary>Details</summary>
Motivation: LLM在质性研究中的应用日益增多，但现有系统产生的输出差异很大——从忠实追踪的摘要到理论中介的解释和系统模型。为了明确这些差异，需要建立一个分析框架。

Method: 引入一个4×4的景观框架，交叉四个意义建构层次（描述性、分类性、解释性、理论性）与四个建模层次（静态结构、阶段/时间线、因果路径、反馈动态）。将该框架应用于先前的LLM自动化研究。

Result: 应用该框架发现现有LLM系统强烈偏向低层次意义建构和低承诺表示，很少有可靠的解释性/理论性推理或动态建模尝试。

Conclusion: 基于揭示的差距，提出了一个议程，用于应用和构建LLM系统，使其解释性和建模承诺变得明确、可选择和可治理。

Abstract: LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.

</details>


### [14] [LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text](https://arxiv.org/abs/2601.11746)
*George Mihaila,Suleyman Olcay Polat,Poli Nemkova,Himanshu Sharma,Namratha V. Urs,Mark V. Albert*

Main category: cs.CL

TL;DR: LIME-LLM 提出了一种新的 NLP 可解释性框架，用假设驱动的受控扰动替代随机标记掩码，通过"单掩码-单样本"协议和中性填充策略，构建流畅的流形上邻域，显著提高了局部解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有局部解释方法（如LIME）在NLP中依赖随机标记掩码，会产生语义无效、分布外的输入，削弱局部代理模型的保真度。最近的生成方法（如LLiMe）虽然使用大语言模型生成邻域，但依赖无约束的复述，引入了混淆变量，难以隔离特定特征贡献。

Method: LIME-LLM框架用假设驱动的受控扰动替代随机噪声，采用严格的"单掩码-单样本"协议，并运用不同的中性填充和边界填充策略，构建流畅的流形上邻域，从而严格隔离特征效应。

Result: 在CoLA、SST-2和HateXplain三个基准测试中，使用人工标注的理性作为真实标签进行评估。LIME-LLM相比传统扰动方法（LIME、SHAP、Integrated Gradients）和生成基线LLiMe，在局部解释保真度方面取得了显著改进。

Conclusion: LIME-LLM为黑盒NLP可解释性建立了新的基准，相比传统扰动方法和最近的生成替代方案，在局部解释保真度方面实现了显著提升，推动了可信AI的发展。

Abstract: Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict "Single Mask-Single Sample" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.

</details>


### [15] [Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation](https://arxiv.org/abs/2601.11758)
*Arnab Das Utsa*

Main category: cs.CL

TL;DR: 本文提出了一种基于社交媒体语言的透明焦虑检测方法，通过语言可解释的特征建模和跨领域验证，实现了可靠、可泛化且对关键词鲁棒的焦虑检测。


<details>
  <summary>Details</summary>
Motivation: 全球有数亿人受焦虑影响，但大规模筛查仍然有限。社交媒体语言提供了可扩展的检测机会，但现有模型往往缺乏可解释性、关键词鲁棒性验证和严格的用户级数据完整性。

Method: 使用Reddit帖子的大规模数据集，在精心策划的子版块上进行训练、验证和测试分割。采用逻辑回归分类器，进行特征消融、关键词掩码实验和焦虑组与对照组的密度差异分析，并使用临床访谈确诊的焦虑障碍参与者进行外部验证。

Result: 模型在保持高准确率的同时，即使在情感移除或关键词掩码后仍表现良好。使用最少帖子历史的早期检测显著优于随机分类，跨领域分析显示与临床访谈数据高度一致。

Conclusion: 透明语言特征可以支持可靠、可泛化且对关键词鲁棒的焦虑检测。提出的框架为跨不同在线环境的可解释心理健康筛查提供了可复现的基线。

Abstract: Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.

</details>


### [16] [Industry-Aligned Granular Topic Modeling](https://arxiv.org/abs/2601.11762)
*Sae Young Moon,Myeongjun Erik Jang,Haoyan Luo,Chunyang Xiao,Antonios Georgiadis,Fran Silavong*

Main category: cs.CL

TL;DR: TIDE框架提出基于大语言模型的细粒度主题建模方法，在多种数据集上优于现有方法，并提供文档摘要、主题分层等实用功能


<details>
  <summary>Details</summary>
Motivation: 虽然粒度概念在商业应用中具有重要价值，但现有主题建模方法在生成细粒度主题方面的能力尚未得到充分探索。需要开发能够提供更深入洞察的细粒度主题建模方法。

Method: 提出TIDE框架，核心是基于大语言模型（LLMs）的新型细粒度主题建模方法，同时包含文档摘要、主题分层（topic parenting）和蒸馏等辅助功能。

Result: 在多种公开和真实商业数据集上的实验表明，TIDE的主题建模方法优于现代主题建模方法，辅助组件为处理工业商业场景提供了有价值的支持。

Conclusion: TIDE框架提供了一种有效的细粒度主题建模解决方案，特别适合商业应用，目前正在开源过程中。

Abstract: Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.

</details>


### [17] [Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models](https://arxiv.org/abs/2601.11776)
*Kaituo Zhang,Zhimeng Jiang,Na Zou*

Main category: cs.CL

TL;DR: 提出完全自反思的LLM去毒框架，利用LLM内在能力检测、修正毒性内容并微调模型，无需外部模块或数据标注，在保持语义保真度下达到SOTA去毒性能。


<details>
  <summary>Details</summary>
Motivation: 当前去毒技术很少利用LLM内置的自校正和自奖励能力，而是依赖外部模块、人工数据标注或人工干预，这些因素阻碍了可扩展性和一致性。

Method: 提出毒性信号检测器（内部自识别机制）结合系统性干预过程，将毒性文本转换为非毒性对应文本，迭代过程生成对比去毒数据集用于微调模型。

Result: 在DetoxLLM和ParaDetox基准测试中，该方法在保持语义保真度的同时，取得了比现有SOTA方法更好的去毒性能。

Conclusion: 揭示了LLM内在的自去毒能力，为缓解有害内容生成提供了一致有效的途径，为真正自调节的语言模型和更负责任、符合伦理的文本生成系统铺平了道路。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.

</details>


### [18] [Translation as a Scalable Proxy for Multilingual Evaluation](https://arxiv.org/abs/2601.11778)
*Sheriff Issaka,Erick Rosas Gonzalez,Lieqi Liu,Evans Kofi Agyei,Lucas Bandarkar,Nanyun Peng,David Ifeoluwa Adelani,Francisco Guzmán,Saadia Gabriel*

Main category: cs.CL

TL;DR: 翻译质量可作为评估大语言模型多语言能力的有效代理指标，通过翻译性能可预测下游任务表现


<details>
  <summary>Details</summary>
Motivation: 当前LLMs声称具备多语言能力，但针对全球7000多种语言中超过98%的语言缺乏非机器翻译的基准测试，传统基准构建面临成本高、专家稀缺和数据污染等扩展挑战

Method: 系统评估14个模型（1B-72B参数）在9个多样化基准和7个翻译指标上的表现，研究翻译质量是否能指示更广泛的多语言能力

Result: 翻译性能是下游任务成功的良好指标（如Phi-4模型的中位数Pearson相关系数：MetricX=0.89，xCOMET=0.91，SSA-COMET=0.87），表明支持忠实翻译的表征能力与多语言理解所需能力重叠

Conclusion: 翻译质量可作为强大且廉价的多语言性能初步代理指标，支持"翻译优先筛选+特定任务针对性跟进"的评估策略

Abstract: The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.

</details>


### [19] [Beyond Tokens: Concept-Level Training Objectives for LLMs](https://arxiv.org/abs/2601.11791)
*Laya Iyer,Pranav Somani,Alice Guo,Dan Jurafsky,Chen Shani*

Main category: cs.CL

TL;DR: 论文提出从token级预测转向概念级预测，将相同语义的不同表面形式（如"mom"、"mother"）归为同一概念，以改善LLM训练信号与语义正确性的对齐。


<details>
  <summary>Details</summary>
Motivation: 传统NTP目标在token层面训练LLM，即使替代延续同样合理或语义等价（如"mom" vs "mother"），也会将其视为错误。这种token级损失会惩罚有效的抽象、释义或概念正确的推理路径，使模型偏向表面形式而非底层含义。训练信号与语义正确性之间的不匹配促使需要更高级别的学习目标。

Method: 提出从token级预测转向概念级预测，将多个相同想法的表面形式（如"mom"、"mommy"、"mother"）分组为概念（如MOTHER）。介绍了将概念监督集成到LLM训练中的各种方法。

Result: 概念感知模型相比NTP模型实现了更低的困惑度、在领域转移下更强的鲁棒性，以及在多样化NLP基准测试中更优的性能表现。

Conclusion: 概念级监督作为一种改进的训练信号，能更好地将LLM与人类语义抽象对齐，是比传统token级预测更优的训练方法。

Abstract: The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\rightarrow$ \textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.

</details>


### [20] [TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit](https://arxiv.org/abs/2601.11819)
*Shirlene Rose Bandela,Sanjeev Parthasarathy,Vaibhav Garg*

Main category: cs.CL

TL;DR: TWeddit是一个标注了触发内容的Reddit数据集，专注于女性主要面临的创伤经历，如流产、性暴力等，用于支持相关研究。


<details>
  <summary>Details</summary>
Motivation: Reddit上用户经常分享流产、性暴力等创伤经历来寻求支持，但平台缺乏自动触发警告机制，且现有标注数据集稀缺，需要专门的数据集来支持相关研究。

Method: 构建了TWeddit数据集，专门收集Reddit上与女性主要面临的触发经历相关的故事，并进行标注和语言分析。

Result: 语言分析显示TWeddit中标注的故事表达了独特的主题和道德基础，证明该数据集对未来研究具有广泛用途。

Conclusion: TWeddit数据集填补了Reddit触发内容标注数据的空白，为研究创伤经历的语言特征和社会支持机制提供了宝贵资源。

Abstract: Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.

</details>


### [21] [The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization](https://arxiv.org/abs/2601.11846)
*Natalia Tomashenko,Xiaoxiao Miao,Pierre Champion,Sarina Meyer,Michele Panariello,Xin Wang,Nicholas Evans,Emmanuel Vincent,Junichi Yamagishi,Massimiliano Todisco*

Main category: cs.CL

TL;DR: 2024年第三届VoicePrivacy挑战赛的结果与分析，聚焦于语音匿名化技术，旨在隐藏说话人身份同时保留语言内容和情感状态。


<details>
  <summary>Details</summary>
Motivation: 推动语音匿名化技术的发展，解决在保护说话人隐私的同时保持语音内容实用性的挑战，为实际应用提供技术基础。

Method: 通过挑战赛框架，提供匿名化任务定义、数据集、攻击模型和评估指标，包括六个基线匿名化系统，并总结参赛者的创新方法。

Result: 提供了挑战赛的系统性概述，包括任务框架、评估方法和基线系统，总结了参与者的创新方法，并提出了未来研究方向。

Conclusion: 挑战赛为语音匿名化研究提供了重要平台，识别了有前景的研究方向，并为未来VoicePrivacy挑战赛的设计提供了关键见解。

Abstract: We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.

</details>


### [22] [ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System](https://arxiv.org/abs/2601.11854)
*Yifei Zhang,Hooshang Nayyeri,Rinat Khaziev,Emine Yilmaz,Gokhan Tur,Dilek Hakkani-Tür,Hari Thadakamalla*

Main category: cs.CL

TL;DR: ATOD是一个面向任务型对话系统的基准测试和合成对话生成框架，专门用于评估LLM驱动的智能代理行为，包括多目标协调、依赖管理、记忆、适应性和主动性等维度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏对LLM驱动的任务型对话系统中智能代理行为的系统评估支持，这些系统具有协调交错目标、保持长时上下文和异步主动执行等能力。

Method: 提出ATOD基准测试和合成对话生成流水线，生成需要长期推理的丰富标注对话；在此基础上提出ATOD-Eval评估框架，将智能代理维度转化为细粒度指标；并开发基于记忆的智能评估器。

Result: ATOD-Eval能够全面评估任务完成度、智能代理能力和响应质量；提出的评估器在准确性和效率之间提供了比现有基于记忆和LLM的方法更好的权衡。

Conclusion: ATOD填补了评估LLM驱动的任务型对话系统中智能代理行为的空白，ATOD-Eval提供了全面的评估框架，提出的评估器在准确性和效率方面表现优越。

Abstract: Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.

</details>


### [23] [CTPD: Cross Tokenizer Preference Distillation](https://arxiv.org/abs/2601.11865)
*Truong Nguyen,Phi Van Dat,Ngan Nguyen,Linh Ngo Van,Trung Le,Thanh Hong Nguyen*

Main category: cs.CL

TL;DR: CTPD是首个统一框架，用于在不同分词器的模型间传递人类对齐行为，通过字符级对齐、重要性采样和教师锚定参考实现跨分词器偏好蒸馏。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在预训练和指令调优中广泛应用，但在语言模型与人类偏好对齐方面，特别是在更现实的跨分词器设置中，应用不足。教师和学生模型之间分词方案的不兼容性阻碍了细粒度的白盒偏好信息蒸馏。

Method: 提出跨分词器偏好蒸馏(CTPD)框架，包含三个关键创新：1) 对齐跨度投影，将教师和学生标记映射到共享的字符级跨度；2) 跨分词器适应的标记级重要性采样(TIS-DPO)；3) 教师锚定参考，让学生在DPO风格目标中直接利用教师偏好。

Result: 在多个基准测试中的实验证实了CTPD的有效性，相比现有方法取得了显著的性能提升。理论分析将CTPD建立在重要性采样基础上。

Conclusion: CTPD为跨不同分词方案的偏好蒸馏提供了一个实用且通用的解决方案，为语言模型更易获取和高效的对齐打开了大门。

Abstract: While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.

</details>


### [24] [Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving](https://arxiv.org/abs/2601.11866)
*Kie Shidara,Preethi Prem,Jonathan Kim,Anna Podlasek,Feng Liu,Ahmed Alaa,Danilo Bernardo*

Main category: cs.CL

TL;DR: 大型语言模型在医学QA基准测试中表现出色，但临床推理的灵活性仍有争议。研究发现，先进的推理模型在mARC基准上能避免Einstellung效应陷阱，达到人类水平表现。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在医学QA基准测试中取得了高准确率，但其临床推理的灵活性一直存在争议。研究旨在探究先进的推理模型是否能改善其在临床推理中的认知灵活性。

Method: 评估了OpenAI、Grok、Gemini、Claude和DeepSeek等家族的推理模型在医学抽象与推理语料库(mARC)上的表现。mARC是一个对抗性医学QA基准，利用Einstellung效应诱导模型在启发式模式变得次优时仍过度依赖它们。

Result: 强大的推理模型比弱推理模型更频繁地避免了Einstellung效应陷阱，在mARC上达到了人类水平表现。在医生最常答错的问题上，前5名模型以高置信度正确回答了55%到70%的问题，表明这些模型可能比人类更不容易受到Einstellung效应的影响。

Conclusion: 强大的推理模型在医学推理中表现出改进的灵活性，在mARC基准测试上达到了与人类相当的性能水平。

Abstract: Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.

</details>


### [25] [GloCTM: Cross-Lingual Topic Modeling via a Global Context Space](https://arxiv.org/abs/2601.11872)
*Nguyen Tien Phat,Ngo Vu Minh,Linh Van Ngo,Nguyen Thi Ngoc Diep,Thien Huu Nguyen*

Main category: cs.CL

TL;DR: GloCTM是一个新颖的跨语言主题建模框架，通过统一的语义空间强制跨语言主题对齐，显著提升了主题连贯性和跨语言对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言主题模型存在两个主要问题：1）在分离的语言特定空间中学习主题，依赖对齐机制（如双语词典）但往往无法捕捉深层的跨语言语义；2）忽视了多语言预训练表示中丰富的语义信号，限制了细粒度对齐能力。

Method: GloCTM通过整个模型流程的统一语义空间强制跨语言主题对齐：1）通过扩展跨语言词汇邻域构建丰富的输入表示；2）使用局部和全局编码器推断主题比例，并通过内部正则化对齐其潜在表示；3）在输出层，基于组合词汇的全局主题-词分布结构上同步跨语言主题含义；4）引入中心核对齐（CKA）损失，将潜在主题空间与多语言上下文嵌入对齐。

Result: 在多个基准测试中，GloCTM显著提高了主题连贯性和跨语言对齐效果，优于强基线模型。

Conclusion: GloCTM通过统一的语义空间和深度语义对齐机制，有效解决了跨语言主题建模中的对齐问题，为多语言理解提供了更强大的工具。

Abstract: Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.

</details>


### [26] [Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence](https://arxiv.org/abs/2601.11886)
*Kaijie Mo,Siddhartha Venkatayogi,Chantal Shaib,Ramez Kouzy,Wei Xu,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: LLMs在医学反事实证据面前过度信任危险或不合理信息，缺乏安全边界


<details>
  <summary>Details</summary>
Motivation: 研究当上下文与模型先验或安全协议冲突时，LLMs在医学等高风险领域的行为和推理方式

Method: 构建MedCounterFact反事实医学QA数据集，包含四种反事实刺激类型，评估多个前沿LLMs在该数据集上的表现

Result: 现有模型在面对反事实证据时，即使证据危险或不可信，也普遍接受并给出自信、无保留的答案

Conclusion: 虽然忠实性和安全性之间应有界限，但目前LLMs尚未建立这样的安全边界

Abstract: In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such "evidence" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.

</details>


### [27] [PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning](https://arxiv.org/abs/2601.11908)
*Byeongjin Kim,Gyuwan Kim,Seo Yeon Park*

Main category: cs.CL

TL;DR: PPA-Plan是一种针对长上下文推理的主动规划策略，通过识别潜在逻辑陷阱和错误假设，将其作为负面约束，在规划生成阶段就避免这些失败，从而提升长上下文推理性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文推理中存在困难，相关信息稀疏分布。现有的"规划-执行"框架因依赖表面线索导致规划不可靠，规划可能基于错误假设，且一旦形成规划后难以识别问题并进行可靠修正，限制了反应式优化的效果。

Method: PPA-Plan是一种主动规划策略，通过识别潜在逻辑陷阱和错误假设，将其表述为负面约束，并在规划生成时明确避免这些约束，从而在规划阶段就预防失败。

Result: 在长上下文问答基准测试中，执行PPA-Plan生成的规划一致优于现有的"规划-执行"方法和直接提示方法。

Conclusion: PPA-Plan通过主动识别和避免潜在失败，有效提升了长上下文推理中规划的可靠性，解决了现有方法在规划生成和修正方面的局限性。

Abstract: Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.

</details>


### [28] [LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding](https://arxiv.org/abs/2601.11913)
*Yichen Jiang,Peng Ye,Jiakang Yuan,Chongjun Tu,Lei Bai,Tao Chen*

Main category: cs.CL

TL;DR: LSTM-MAS：受LSTM架构启发的多智能体系统，通过链式架构和门控机制解决长上下文处理中的错误累积和幻觉传播问题


<details>
  <summary>Details</summary>
Motivation: 现有单LLM方法在处理长上下文时面临计算成本高或扩展长度受限的问题，而多智能体框架容易积累错误和传播幻觉，需要更有效的方法

Method: 设计LSTM-MAS多智能体系统，模拟LSTM的分层信息流和门控记忆机制，采用链式架构包含工作、过滤、判断和管理四种智能体，分别对应LSTM的输入门、遗忘门、恒定误差循环单元和输出门

Result: 相比之前最佳多智能体方法CoA，在NarrativeQA、Qasper、HotpotQA和MuSiQue上分别提升40.93%、43.70%、121.57%和33.12%

Conclusion: LSTM-MAS通过受LSTM启发的多智能体架构，实现了可控信息传递和选择性长程依赖建模，有效避免了错误累积和幻觉传播，为长上下文理解提供了新方案

Abstract: Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.

</details>


### [29] [Enhancing LLM-Based Data Annotation with Error Decomposition](https://arxiv.org/abs/2601.11920)
*Zhen Xu,Vedant Khatri,Yijun Dai,Xiner Liu,Siyan Li,Xuanming Zhang,Renzhe Yu*

Main category: cs.CL

TL;DR: 本文提出了一种诊断评估范式，用于评估LLM在主观标注任务中的表现，通过人机协作分离任务固有模糊性和模型误差，提供可操作的优化见解。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在客观标注任务上已接近人类水平，但在涉及心理建构等主观标注任务中表现不稳定且易出错。现有评估方法将所有标注错误合并为单一对齐指标，这种简化方法掩盖了不同类型错误对最终分析结论的不同影响。

Method: 提出了一个诊断评估范式，包含三个核心组件：1) 二维诊断分类法（来源：模型特定vs任务固有；类型：边界模糊vs概念误识别）；2) 轻量级人工标注测试，从LLM标注中估计任务固有模糊性；3) 计算分解方法，按照分类法分解观察到的LLM标注错误。

Result: 在四个教育标注任务上验证了该范式的概念有效性和实际效用。实证表明，在特定标注任务中过高的对齐是不现实的，单一对齐指标不足以反映LLM标注质量。

Conclusion: 该范式可作为低成本诊断工具，评估特定任务是否适合LLM标注，并为进一步技术优化提供可操作的见解。理论上为LLM在主观标注任务中的局限性提供了实证证据。

Abstract: Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.

</details>


### [30] [Mapping the maturation of TCM as an adjuvant to radiotherapy](https://arxiv.org/abs/2601.11923)
*P. Bilha Githinji,Aikaterini Melliou,Xi Yuan,Dayan Zhang,Lian Zhang,Zhenglin Chen,Jiansong Ji,Chengying Lv,Jinhao Xu,Peiwu Qin,Dongmei Yu*

Main category: cs.CL

TL;DR: 该研究对2000-2025年间69,745篇关于中医药作为放疗辅助的文献进行大规模分析，发现该领域呈现周期性演化模式，识别出五大主题轴，表明当前研究议程已成熟，可能存在系统性正向报告偏倚。


<details>
  <summary>Details</summary>
Motivation: 中医药作为放疗辅助在肿瘤综合治疗中的应用日益广泛，但经过25年的制度化发展，需要系统梳理证据轨迹，理解该领域的演化模式和主题结构，为未来发展提供方向。

Method: 对2000-2025年间的69,745篇出版物进行大规模分析，采用主题建模工作流程确定稳定的主题结构，识别周期性演化模式，分析国际合作、资金投入等结构特征。

Result: 发现该领域呈现协调扩张与收缩的周期性演化模式，识别出五大主题轴：癌症类型、支持性护理、临床终点、机制研究和方法学。中医药整合以患者为中心、系统为导向，存在系统性正向报告偏倚。

Conclusion: 中医药作为放疗辅助的研究领域当前议程已成熟，正处于新突破的边缘。该领域呈现渐进专业化和潜在碎片化，存在系统性正向报告偏倚，需要新的研究方向。

Abstract: The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.

</details>


### [31] [Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes](https://arxiv.org/abs/2601.11932)
*Abdullah Al Monsur,Nitesh Vamshi Bommisetty,Gene Louis Kim*

Main category: cs.CL

TL;DR: 本文针对事件检测研究中的两个主要限制：解码器LLMs的单向架构瓶颈和Micro-F1指标的偏向性，提出使用句子上下文增强和LoRA微调来提升模型在长尾事件类型上的表现。


<details>
  <summary>Details</summary>
Motivation: 事件检测研究存在两个主要问题：1）解码器LLMs的单向架构限制了其对双向上下文的理解能力；2）传统使用的Micro-F1指标偏向多数类，无法准确反映模型在长尾事件类型上的表现。

Method: 采用句子上下文增强技术来改善解码器LLMs的双向理解能力，并在微调过程中使用Low-Rank Adaptation (LoRA)技术来提升模型性能，特别是针对长尾事件类别。

Result: 实验表明，使用句子上下文增强的模型优于传统的解码器基线模型。LoRA微调显著提升了Macro-F1分数，特别是对解码器模型，证明LoRA能有效增强LLMs在长尾事件类别上的表现。

Conclusion: 研究揭示了事件检测中解码器LLMs架构的局限性，并证明了使用句子上下文增强和LoRA微调能有效提升模型在长尾事件类型上的表现，Macro-F1是比Micro-F1更合适的评估指标。

Abstract: The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.

</details>


### [32] [Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence](https://arxiv.org/abs/2601.11956)
*Yuyin Lu,Ziran Liang,Yanghui Rao,Wenqi Fan,Fu Lee Wang,Qing Li*

Main category: cs.CL

TL;DR: 提出DoublyCal框架，通过双重校准原则解决LLM幻觉问题，使用轻量代理模型生成KG证据及校准置信度，提升黑盒LLM的准确性和置信度校准


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱增强的LLM方法虽然提高了事实准确性，但无法量化检索证据和LLM推理过程中的认知不确定性，需要解决LLM幻觉问题并提升可信推理能力

Method: 提出DoublyCal框架，基于双重校准原则：1) 使用轻量代理模型生成知识图谱证据并校准证据置信度；2) 用校准后的证据指导黑盒LLM，生成最终预测并追溯置信度到证据不确定性

Result: 在知识密集型基准测试中，DoublyCal显著提高了黑盒LLM的准确性和置信度校准，同时保持了较低的token成本

Conclusion: DoublyCal通过双重校准机制有效解决了LLM幻觉问题，实现了更可信的推理，将预测置信度与证据不确定性关联，为KG增强的LLM提供了量化不确定性的新方法

Abstract: Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.

</details>


### [33] [PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning](https://arxiv.org/abs/2601.11957)
*Bingxuan Li,Jeonghwan Kim,Cheng Qian,Xiusi Chen,Eitan Anzenberg,Niran Kundapur,Heng Ji*

Main category: cs.CL

TL;DR: 提出CalConflictBench基准测试日历冲突解决，开发PEARL强化学习框架提升语言代理性能


<details>
  <summary>Details</summary>
Motivation: 日历邀请冲突迫使专业人士不断决定参加、重新安排或拒绝哪些会议，自动化此过程至关重要但具有挑战性。人工委托在规模上往往失败，因此研究大型语言模型能否管理时间

Method: 引入CalConflictBench基准测试长视野日历冲突解决，提出PEARL强化学习框架，增强语言代理的外部记忆模块和优化的轮次奖励设计

Result: 当前LLM代理表现不佳（如Qwen-3-30B-Think平均错误率35%），PEARL实现0.76错误减少率，相比最强基线平均错误率提升55%

Conclusion: PEARL框架通过强化学习和外部记忆有效提升语言代理在日历冲突解决中的性能，能够动态推断和适应用户偏好

Abstract: Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.

</details>


### [34] [$\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models](https://arxiv.org/abs/2601.11969)
*Zecheng Tang,Baibei Ji,Ruoxi Sun,Haitian Wang,WangJie You,Zhang Yijun,Wenpeng Zhu,Ji Qi,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出了首个评估奖励模型在长上下文记忆管理能力的基准MemoryRewardBench，涵盖10种不同记忆模式，上下文长度从8K到128K token，评估13个前沿奖励模型发现开源与专有模型差距缩小。


<details>
  <summary>Details</summary>
Motivation: 现有工作越来越多采用以记忆为中心的机制分段处理长上下文，有效的记忆管理是大型语言模型在整个序列中传播信息的关键能力。因此，利用奖励模型自动可靠地评估记忆质量至关重要。

Method: 引入MemoryRewardBench基准，系统研究奖励模型评估长期记忆管理过程的能力。该基准涵盖长上下文理解和长文本生成任务，包含10种不同记忆管理模式的设置，上下文长度从8K到128K token。

Result: 评估13个前沿奖励模型显示开源与专有模型之间的性能差距正在缩小，新一代模型无论参数数量如何都持续优于前代模型。进一步揭示了当前奖励模型在评估LLM记忆管理方面的能力和基本局限性。

Conclusion: MemoryRewardBench是首个系统研究奖励模型评估长期记忆管理能力的基准，为理解奖励模型在长上下文记忆评估方面的表现提供了重要工具，并揭示了当前模型的局限性。

Abstract: Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.

</details>


### [35] [Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning](https://arxiv.org/abs/2601.12019)
*Chaowei Zhang,Xiansheng Luo,Zewei Zhang,Yi Zhu,Jipeng Qiang,Longwei Wang*

Main category: cs.CL

TL;DR: 本文提出SORG框架，利用LLM的奉承倾向生成对立推理对，结合ORCD模型进行点击诱饵检测，在三个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线内容泛滥加剧了点击诱饵问题，LLM虽有潜力但受奉承倾向影响，倾向于迎合用户信念而非遵循真实推理。本文创新性地将这种倾向转化为优势，用于生成对立视角的对比推理。

Method: 提出SORG框架，引导LLM为新闻标题生成高质量的支持和反对推理对；开发ORCD模型，使用三个BERT编码器分别表示标题和两种推理，通过对比学习和基于LLM生成可信度分数的软标签进行训练。

Result: 在三个基准数据集上的实验表明，该方法在点击诱饵检测任务上一致优于LLM提示、微调的小型语言模型以及最先进的基线方法。

Conclusion: 通过将LLM的奉承倾向转化为生成对立推理的优势，结合专门设计的检测模型，实现了更鲁棒的点击诱饵检测，为利用LLM特性解决实际问题提供了新思路。

Abstract: The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.

</details>


### [36] [Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection](https://arxiv.org/abs/2601.12033)
*Muhammad Alif Al Hakim,Alfan Farizki Wicaksono,Fajri Koto*

Main category: cs.CL

TL;DR: 量化会降低LLM的公平性和安全性，动态量化比静态量化更稳定，非英语环境下安全性下降更严重。作者提出Critical Weight Protection方法保护关键权重来缓解这些问题。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于降低大语言模型的计算成本，但其对公平性和安全性的影响，特别是在动态量化和多语言环境下的影响，尚未得到充分研究。

Method: 系统研究静态和动态量化方法对公平性和安全性的影响，评估英语、法语、荷兰语、西班牙语、土耳其语等语言的公平性，以及英语、韩语、阿拉伯语的安全性。提出Critical Weight Protection技术，识别和保护量化过程中的公平性和安全性关键权重。

Result: 量化会持续降低公平性和安全性，动态方法比静态方法更稳定。公平性下降在不同语言间有差异，安全性下降在非英语环境中尤其显著。Critical Weight Protection方法能有效缓解偏见和安全性恶化，无需昂贵的重新训练或对齐。

Conclusion: 量化对LLM的公平性和安全性有负面影响，特别是在多语言环境中。提出的Critical Weight Protection方法能在保持效率的同时有效缓解这些问题，维持模型的可信度。

Abstract: Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.

</details>


### [37] [Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs](https://arxiv.org/abs/2601.12034)
*Ziyi Zhao,Chongming Gao,Yang Zhang,Haoyan Liu,Weinan Gan,Huifeng Guo,Yong Liu,Fuli Feng*

Main category: cs.CL

TL;DR: PUMA：轻量级框架，通过适配器迁移个性化提示，解决大模型升级时用户软提示失效问题，减少98%计算成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型升级时，用户特定的软提示会失效，需要昂贵的全量重新训练，这限制了个性化AI的可持续发展

Method: 提出Prompt-level User Migration Adapter (PUMA)，使用参数高效的适配器桥接语义鸿沟，结合基于组的用户选择策略降低训练成本

Result: 在三个大规模数据集上，PUMA性能达到甚至超过从头训练，计算成本降低高达98%，在不同模型架构和链式/聚合迁移场景中表现稳健

Conclusion: PUMA为个性化AI的可持续演进提供了实用路径，通过将用户资产与底层模型解耦，实现高效的用户提示迁移

Abstract: Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.

</details>


### [38] [Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation](https://arxiv.org/abs/2601.12061)
*Jinsook Lee,Kirk Vanacore,Zhuqian Zhou,Jeanine Grutter,Rene F. Kizilcec*

Main category: cs.CL

TL;DR: 论文提出代码本注入分割方法，将边界决策与下游标注标准结合，评估LLM分割器与传统方法的差异，发现DA感知能提升内部一致性，但不同分割器各有优劣，分割应针对下游目标优化而非单一性能分数。


<details>
  <summary>Details</summary>
Motivation: 传统对话行为标注将交际意图局限于单个话语或轮次，导致标注者在底层动作上一致但边界划分不一致，降低了可靠性。需要改进分割方法以更好地服务于下游标注任务。

Method: 提出代码本注入分割方法，将边界决策条件化于下游标注标准；评估LLM分割器与标准及检索增强基线的对比；引入无黄金标签的评估指标：跨度一致性、区分度和人机分布一致性。

Result: DA感知产生的分割段比纯文本基线具有更高的内部一致性；LLM擅长创建结构一致的跨度，但基于连贯性的基线在检测对话流全局变化方面更优；不同分割器各有优势，没有单一主导方法；段内连贯性的提升常以边界区分度和人机分布一致性为代价。

Conclusion: 分割是一个重要的设计选择，应针对下游目标进行优化，而非追求单一性能分数。不同分割方法在不同方面各有优劣，需要根据具体应用场景选择合适的方法。

Abstract: Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.

</details>


### [39] [Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset](https://arxiv.org/abs/2601.12068)
*Rowzatul Zannat,Abdullah Al Shafi,Abdul Muntakim*

Main category: cs.CL

TL;DR: 开发了一个包含758个症状-疾病关系的孟加拉语数据集，用于基于症状预测疾病，通过集成学习方法达到98%准确率，为孟加拉语人群提供医疗信息支持。


<details>
  <summary>Details</summary>
Motivation: 非英语人群获取可靠健康信息的需求日益增长，但孟加拉语的疾病预测资源有限，需要填补这一空白以支持孟加拉语人群的医疗可及性。

Method: 构建了包含85种疾病、758个独特症状-疾病关系的孟加拉语数据集，使用多种机器学习模型进行疾病预测，并采用软投票和硬投票集成方法结合表现最佳的模型。

Result: 集成学习方法在孟加拉语症状输入上达到了98%的准确率，表现出优越的鲁棒性和泛化能力，数据集已公开以确保透明度和可重复性。

Conclusion: 该研究为孟加拉语疾病预测建立了基础资源，推动了本地化健康信息学和诊断工具的发展，旨在增强孟加拉语社区对健康信息的公平获取，特别是在早期疾病检测和医疗干预方面。

Abstract: Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.

</details>


### [40] [To Copy or Not to Copy: Copying Is Easier to Induce Than Recall](https://arxiv.org/abs/2601.12075)
*Mehrdad Farahani,Franziska Penzkofer,Richard Johansson*

Main category: cs.CL

TL;DR: 该论文通过提取"仲裁向量"来研究语言模型在检索增强设置中如何权衡参数知识与上下文信息，发现诱导复制比恢复回忆更容易实现


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在检索增强设置中如何仲裁存储在权重中的参数知识与提示中的上下文信息，理解模型在这两种知识来源之间的选择机制

Method: 从模型激活中提取仲裁向量：在精心设计的数据集上计算不相关上下文（引发参数回忆）与相关但错误上下文（引发复制）之间的残差流质心差；将该向量作为加性干预注入到选定层和标记跨度，以引导行为在两个方向转变

Result: 在两个架构（仅解码器和编码器/解码器）和两个开放域QA基准测试中观察到一致的行为转变；机制分析显示不对称性：诱导复制是容易的"重新激活"过程，而恢复回忆是更脆弱的"抑制"过程

Conclusion: 语言模型在参数知识与上下文信息之间的仲裁机制存在不对称性，诱导复制比抑制上下文使用更容易，这为理解模型知识整合机制提供了新的视角

Abstract: Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\rightarrow$Recall (suppressing context use) and Recall$\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.

</details>


### [41] [Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization](https://arxiv.org/abs/2601.12078)
*Linfeng Du,Ye Yuan,Zichen Zhao,Fuyuan Lyu,Emiliano Penaloza,Xiuying Chen,Zipeng Sun,Jikun Kang,Laurent Charlin,Xue Liu,Haolun Wu*

Main category: cs.CL

TL;DR: PURPLE是一个基于上下文老虎机的框架，通过优化用户档案来提升LLM个性化性能，直接根据生成质量而非语义相关性选择历史记录。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强的LLM个性化方法通常根据语义相关性选择用户历史记录，但相关性并不能可靠地代表效用——语义相似的记录可能因冗余或冲突信息而无法改善甚至降低生成质量。

Method: 提出PURPLE框架，将档案构建视为集合生成过程，使用Plackett-Luce排序模型捕捉复杂的记录间依赖关系，通过参考响应似然提供的密集反馈进行训练，使检索直接与生成质量对齐。

Result: 在九个个性化任务上的广泛实验表明，PURPLE在效果和效率上都持续优于强大的启发式和检索增强基线方法。

Conclusion: PURPLE为优化用户档案提供了一个原则性和可扩展的解决方案，通过直接优化生成质量而非依赖相关性代理来提升LLM个性化性能。

Abstract: Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.

</details>


### [42] [Large language models struggle with ethnographic text annotation](https://arxiv.org/abs/2601.12099)
*Leonardo S. Goodall,Dor Shilton,Daniel A. Mullins,Harvey Whitehouse*

Main category: cs.CL

TL;DR: LLMs在民族志文本标注任务中表现有限，无法替代人类专家，准确率远低于可靠自动化标注所需水平


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在跨文化研究中自动提取民族志文本结构化数据的潜力，希望加速民族志研究

Method: 评估7个最先进的LLMs在567个民族志摘录中对121个仪式特征的标注能力，并与人类编码者可靠性对比

Result: LLMs表现有限，准确率远低于可靠自动化标注所需水平；长文本、需要顺序区分的特征和模糊概念特别困难；人类编码者可靠性设定了LLM准确率的上限

Conclusion: LLMs目前还不能替代人类专家进行民族志标注，需要进一步改进才能用于可靠的自动化文本分析

Abstract: Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.

</details>


### [43] [Powerful Training-Free Membership Inference Against Autoregressive Language Models](https://arxiv.org/abs/2601.12104)
*David Ilić,David Stanojević,Kostadin Cvejoski*

Main category: cs.CL

TL;DR: EZ-MIA是一种新型成员推理攻击方法，通过分析模型在错误位置的记忆表现，显著提高了对微调语言模型隐私风险的检测能力，比现有方法效果提升3-8倍。


<details>
  <summary>Details</summary>
Motivation: 微调语言模型存在严重的隐私风险，可能记忆并泄露训练数据中的敏感信息。现有的成员推理攻击方法检测率有限，特别是在实际隐私审计所需的低误报率阈值下效果不佳。

Method: 提出EZ-MIA攻击方法，基于关键观察：记忆在错误位置表现最强（模型预测错误但仍对训练样本显示较高概率）。引入错误区域分数，测量错误位置相对于预训练参考模型的概率偏移方向不平衡性。该方法只需两次前向传播，无需任何模型训练。

Result: 在WikiText和GPT-2上，EZ-MIA在相同条件下检测率比之前最佳方法高3.8倍（1%误报率下真阳性率66.3% vs 17.5%），AUC接近完美（0.98）。在关键的0.1%误报率阈值下，检测率提高8倍（14.0% vs 1.8%）。在Llama-2-7B和AG News上，检测率也提高3倍（46.7% vs 15.8%）。

Conclusion: 微调语言模型的隐私风险比之前理解的更为严重，这对隐私审计和部署决策都有重要影响。EZ-MIA为评估这些风险提供了更有效的工具。

Abstract: Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.

</details>


### [44] [Bengali Text Classification: An Evaluation of Large Language Model Approaches](https://arxiv.org/abs/2601.12132)
*Md Mahmudul Hoque,Md Mehedi Hassain,Md Hojaifa Tanvir,Rahul Nandy*

Main category: cs.CL

TL;DR: 本文评估了三种指令调优大语言模型（LLaMA 3.1 8B、LLaMA 3.2 3B、Qwen 2.5 7B）在孟加拉语新闻文章分类任务上的表现，发现Qwen 2.5以72%的准确率表现最佳。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语文本分类面临缺乏大规模标注数据集和预训练语言模型的挑战，本研究旨在探索大语言模型在孟加拉语新闻分类任务中的有效性。

Method: 使用来自Kaggle的Prothom Alo新闻文章数据集，在相同的分类框架下评估三种指令调优LLM：LLaMA 3.1 8B Instruct、LLaMA 3.2 3B Instruct和Qwen 2.5 7B Instruct。

Result: Qwen 2.5获得最高分类准确率72%，在"体育"类别表现尤其突出；LLaMA 3.1和LLaMA 3.2分别获得53%和56%的准确率。

Conclusion: 尽管孟加拉语NLP资源稀缺，大语言模型在孟加拉语文本分类中仍显示出有效性。未来研究将探索更多模型、解决类别不平衡问题并改进微调方法以提升性能。

Abstract: Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the "Sports" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.

</details>


### [45] [Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs](https://arxiv.org/abs/2601.12154)
*Teodor-Călin Ionescu,Lifeng Han,Jan Heijdra Suasnabar,Anne Stiggelbout,Suzan Verberne*

Main category: cs.CL

TL;DR: 研究使用神经主题建模（BERTopic/Top2Vec）和LLMs分析癌症患者访谈，发现BioClinicalBERT嵌入模型结合BERTopic能有效提取临床相关主题，支持患者导向的医疗实践。


<details>
  <summary>Details</summary>
Motivation: 从患者叙事数据中挖掘有意义主题，为更患者导向的医疗实践提供洞察。癌症患者访谈包含丰富但未充分利用的信息，需要自动化方法提取关键主题。

Method: 1) 比较BERTopic和Top2Vec在单个访谈摘要中的表现；2) 使用GPT-4进行主题标注；3) 通过人工评估（连贯性、清晰度、相关性）验证；4) 选择BERTopic结合三种临床导向嵌入模型（BioClinicalBERT等）分析完整数据集。

Result: BERTopic表现优于Top2Vec；领域特定嵌入（特别是BioClinicalBERT）提高主题精确度和可解释性；全局分析发现两个主导主题："癌症护理管理中的协调与沟通"和"癌症治疗旅程中的患者决策"。

Conclusion: 神经主题建模（特别是BERTopic）能从患者访谈中提取有用临床反馈，支持高效文档导航并增强患者声音在医疗工作流程中的作用，尽管存在机器翻译和缺乏临床专业人员评估的限制。

Abstract: This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \textit{precision} and \textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.

</details>


### [46] [Tolerance Principle and Small Language Model Learning](https://arxiv.org/abs/2601.12179)
*Adam E. Friedman,Stevan Harnad,Rushen Shi*

Main category: cs.CL

TL;DR: 研究发现BabyBERTa语言模型的学习动态不符合人类婴儿的容忍原则，尽管在少量数据上训练，但无法像儿童那样从少量示例中学习抽象语法规则。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型需要大量训练数据，而儿童仅需少量示例就能学习抽象语法规则。Yang的容忍原则定义了规则可容忍的例外数量阈值。本研究旨在探索transformer模型学习语法规则所需的最小数据量和质量，并测试容忍原则的预测。

Method: 使用BabyBERTa（专为小数据集优化的transformer模型）在人工语法上进行训练。训练集在大小、独特句子类型数量以及规则遵循与例外示例比例方面有所不同。

Result: 与人类婴儿不同，BabyBERTa的学习动态不符合容忍原则的预测。模型无法像儿童那样从少量示例中可靠地学习抽象语法规则。

Conclusion: 当前transformer架构的学习机制与人类儿童的语言习得机制存在根本差异，表明需要新的模型设计来更好地模拟人类语言习得的认知过程。

Abstract: Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.

</details>


### [47] [CTC-DID: CTC-Based Arabic dialect identification for streaming applications](https://arxiv.org/abs/2601.12199)
*Muhammad Umar Farooq,Oscar Saz*

Main category: cs.CL

TL;DR: 提出基于CTC损失的方言识别方法，将方言识别任务视为有限词汇的语音识别系统，在低资源阿拉伯方言识别任务中表现优于现有模型


<details>
  <summary>Details</summary>
Motivation: 传统方言识别方法在低资源场景下效果有限，需要一种更高效、鲁棒的方法来处理方言识别任务，特别是对于短语音和实时应用场景

Method: 采用CTC损失函数框架，将方言标签视为语音序列的标签，使用语言无关启发式方法或预训练ASR模型估计方言标签在转录中的重复次数，构建SSL-based CTC-DID模型

Result: 在低资源阿拉伯方言识别任务中，CTC-DID模型在有限数据集上训练后，性能优于微调的Whisper和ECAPA-TDNN模型，在Casablanca数据集上的零样本评估也表现更优，对短语音更鲁棒且易于实时流式应用

Conclusion: CTC-DID方法为方言识别提供了一种有效的新框架，特别适合低资源场景，具有鲁棒性强、适应实时应用的优势，为方言识别任务开辟了新方向

Abstract: This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.

</details>


### [48] [CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement](https://arxiv.org/abs/2601.12208)
*Yunzhe Li,Richie Yueqi Feng,Tianxin Wei,Chin-Chia Hsu*

Main category: cs.CL

TL;DR: CoReflect：通过协同进化模拟和反思性评估标准优化，实现对话系统多轮评估的自适应迭代框架


<details>
  <summary>Details</summary>
Motivation: 传统对话系统评估方法依赖人工定义的评估标准和固定对话上下文，覆盖范围有限且无法捕捉对话模型多样化的涌现行为，难以适应快速发展的对话模型能力

Method: 提出CoReflect框架，将对话模拟和评估统一为自适应迭代过程：1）对话规划器生成结构化模板指导用户模拟器进行多样化目标导向对话；2）反思分析器处理对话，识别系统性行为模式并自动优化评估标准；3）通过协同进化循环，将分析结果反馈给规划器更新对话模板

Result: CoReflect通过最小化人工干预，提供了可扩展且自我优化的方法论，使评估协议能够与对话模型的快速发展能力同步适应

Conclusion: CoReflect解决了多轮对话系统评估的根本挑战，通过协同进化循环确保测试案例复杂性和评估标准诊断精度同步提升，为对话模型评估提供了自适应、可扩展的解决方案

Abstract: Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.

</details>


### [49] [Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models](https://arxiv.org/abs/2601.12247)
*Miao Li,Hanyang Jiang,Sikai Chen,Hengyu Fu,Yuhang Cai,Baihe Huang,Tinghan Ye,Xuanzhou Chen,Pascal Van Hentenryck*

Main category: cs.CL

TL;DR: PVF是一种无需训练的解码范式，通过规划-验证-填充机制，在扩散语言模型中实现高效文本生成，相比并行解码减少65%的函数评估次数。


<details>
  <summary>Details</summary>
Motivation: 当前扩散语言模型的解码策略往往是被动的，未能充分利用全局双向上下文来指导生成轨迹，导致效率低下。

Method: 提出Plan-Verify-Fill（PVF）范式：1）主动构建分层骨架，优先考虑高影响力的语义锚点；2）采用验证协议实现实用的结构停止机制；3）无需额外训练。

Result: 在LLaDA-8B-Instruct和Dream-7B-Instruct上的评估显示，PVF相比基于置信度的并行解码，函数评估次数减少高达65%，在保持准确性的同时显著提升效率。

Conclusion: PVF为扩散语言模型提供了一种高效的解码范式，通过主动规划和验证机制，在减少计算成本的同时保持生成质量，为非顺序文本生成开辟了新方向。

Abstract: Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.

</details>


### [50] [Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers](https://arxiv.org/abs/2601.12263)
*Yixuan Du,Chenxiao Yu,Haoyan Xu,Ziyi Wang,Yue Zhao,Xiyang Hu*

Main category: cs.CL

TL;DR: MGEO是一种针对VLM产品搜索系统的多模态对抗攻击框架，通过联合优化图像扰动和文本后缀来恶意提升目标产品排名


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型(VLMs)在检索和推荐系统中广泛应用，但其在竞争性排名场景下对抗操纵的鲁棒性尚未充分探索。本文旨在揭示VLM产品搜索中的关键漏洞

Method: 提出多模态生成引擎优化(MGEO)框架，采用交替梯度优化策略，联合优化不可感知的图像扰动和流畅的文本后缀，利用VLM内部的深度跨模态耦合

Result: 在真实数据集和SOTA模型上的实验表明，MGEO协调攻击显著优于仅文本或仅图像的基线方法

Conclusion: 多模态协同作用这一VLM的优势可能被武器化，从而在不触发传统内容过滤器的情况下破坏搜索排名的完整性

Abstract: Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.

</details>


### [51] [Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models](https://arxiv.org/abs/2601.12269)
*Xucong Hu,Jian-Qiao Zhu*

Main category: cs.CL

TL;DR: 通过MCMC采样和退火技术，从基础语言模型中恢复强大的心智理论能力，无需额外训练


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型通常被视为仅优化表面合理性（局部连贯性）而非保持正确的潜在状态表示（全局连贯性），因此在心智理论任务上表现不佳。虽然后训练方法可以改善心智理论表现，但本文旨在直接从基础模型中恢复这种能力，无需额外权重更新或验证。

Method: 基于Karan & Du (2025)的power-sampling方法，使用马尔可夫链蒙特卡洛从自回归语言模型的序列级（而非词元级）概率分布中采样。进一步引入退火技术，将温度分布从高到低逐渐调整，显著提升心智理论性能。

Result: 结合退火的power-sampling方法能够从基础语言模型中恢复强大的心智理论能力，显著优于固定温度的power sampling方法。

Conclusion: 基于采样的优化提供了一种无需重新训练就能从语言模型中提取潜在能力的强大方法，表明语言模型可能已经具备了比表面表现更丰富的心智理论能力。

Abstract: Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.

</details>


### [52] [Conversational Context Classification: A Representation Engineering Approach](https://arxiv.org/abs/2601.12286)
*Jonathan Pan*

Main category: cs.CL

TL;DR: 论文提出使用表示工程和单类支持向量机在LLM内部状态中识别特定上下文子空间的方法，用于检测对话是否偏离预期上下文。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，需要有效保障措施来防止其生成脱离上下文的回答。传统异常检测方法难以直接应用于上下文语义，需要新方法来准确检测LLM何时偏离预期对话规范。

Method: 采用表示工程和单类支持向量机，在LLM内部状态中识别代表特定上下文的子空间。通过基于上下文内示例训练OCSVM，在LLM隐藏状态潜在空间中建立鲁棒边界，并识别与目标上下文强相关的LLM内部状态最优层。

Result: 在Llama和Qwen两个开源LLM上的评估结果显示，该方法在识别特定上下文子空间方面表现出有希望的结果，能够有效检测对话是否在预期上下文内。

Conclusion: 该方法不仅能用于检测对话是否在上下文内，还为更好地解释LLM的研究做出了贡献，为LLM的安全操作提供了有效的保障手段。

Abstract: The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.

</details>


### [53] [Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies](https://arxiv.org/abs/2601.12369)
*Ming Zhang,Jiabao Zhuang,Wenqing Jing,Ziyu Kong,Jingyi Deng,Yujiong Shen,Kexin Tan,Yuhang Zhao,Ning Luo,Renzhe Zheng,Jiahui Lin,Mingqi Wu,Long Ma,Yi Zou,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: TaxoBench是一个用于评估深度研究代理生成综述能力的诊断基准，基于72篇高引用计算机科学综述构建，包含3,815个精确分类的引用作为基准。研究发现当前最佳代理只能召回20.9%的专家选择论文，组织能力也很有限。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理越来越多地用于自动生成综述，但尚不清楚它们是否能像人类专家一样撰写综述。现有基准主要关注流畅性或引用准确性，缺乏对核心能力（检索关键论文并将其组织成连贯知识结构）的评估。

Method: 从72篇高引用计算机科学综述中手动提取专家构建的分类树作为基准，包含3,815个精确分类的引用。支持两种评估模式：深度研究模式（端到端检索和组织）和自底向上模式（隔离组织结构能力）。评估了7个领先的深度研究代理和12个前沿LLM。

Result: 结果显示双重瓶颈：最佳代理只能召回20.9%的专家选择论文；即使在完美输入条件下，最佳模型的组织能力也仅达到0.31 ARI。当前深度研究代理距离专家级综述撰写仍有很大差距。

Conclusion: TaxoBench为评估深度研究代理的综述生成能力提供了首个诊断基准，揭示了当前系统在检索和组织能力上的显著不足，为未来改进提供了方向。

Abstract: Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.

</details>


### [54] [A Scalable Entity-Based Framework for Auditing Bias in LLMs](https://arxiv.org/abs/2601.12374)
*Akram Elbouanani,Aboubacar Tuo,Adrian Popescu*

Main category: cs.CL

TL;DR: 本文提出了一个使用命名实体作为探针的可扩展偏见审计框架，通过19亿数据点的大规模分析，发现LLMs存在系统性偏见：惩罚右翼政客、偏好左翼政客、偏爱西方和富裕国家、偏好西方公司、惩罚国防和制药公司。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型偏见评估方法在生态效度和统计控制之间存在权衡：要么依赖不能反映真实使用场景的人工提示，要么使用缺乏规模和严谨性的自然任务。需要一种既能保持生态效度又能实现大规模分析的偏见审计方法。

Method: 提出使用命名实体作为探针来测量模型行为中的结构性差异的可扩展偏见审计框架。通过合成数据可靠地复现自然文本中观察到的偏见模式，从而实现大规模分析。该方法覆盖多种实体类型、任务、语言、模型和提示策略。

Result: 进行了迄今为止最大的偏见审计（19亿数据点），发现系统性偏见：模型惩罚右翼政客、偏好左翼政客、偏爱西方和富裕国家而非全球南方国家、偏好西方公司、惩罚国防和制药行业公司。指令微调能减少偏见，但模型规模增大会放大偏见，使用中文或俄文提示不会减弱西方倾向偏好。

Conclusion: 大语言模型在高风险应用部署前应进行严格的审计。研究结果表明LLMs存在系统性偏见，这些偏见在不同语言和模型规模下表现出不同的变化模式，凸显了偏见审计在模型部署前的重要性。

Abstract: Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.

</details>


### [55] [LR-DWM: Efficient Watermarking for Diffusion Language Models](https://arxiv.org/abs/2601.12376)
*Ofek Raban,Ethan Fetaya,Gal Chechik*

Main category: cs.CL

TL;DR: 提出LR-DWM方法，通过利用左右邻居标记来为扩散语言模型添加水印，实现高效检测AI生成内容，计算和内存开销极低。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法主要针对自回归语言模型，依赖序列生成过程。扩散语言模型采用非顺序迭代去噪生成文本，需要大幅修改现有水印方法。最近工作通过反转过程实现水印，但计算或内存开销很大。

Method: 提出左右扩散水印(LR-DWM)方案，当左右邻居标记可用时，基于左右邻居标记偏置生成的标记。该方法计算和内存开销极小，接近无水印基线扩散语言模型。

Result: 在标准评估设置下实现可靠统计检测，扩散语言模型可以高效添加水印，获得高可检测性，计算和内存开销可忽略不计。

Conclusion: LR-DWM方法成功解决了扩散语言模型水印的效率和开销问题，为AI生成内容检测提供了实用解决方案。

Abstract: Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.

</details>


### [56] [NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages](https://arxiv.org/abs/2601.12389)
*Lakshya Tomar,Vinayak Abrol,Puneet Agarwal*

Main category: cs.CL

TL;DR: NADIR是一种新型非自回归架构，用于多语言音译任务，在保持竞争力的准确率同时实现13倍加速，减少各类错误率。


<details>
  <summary>Details</summary>
Motivation: 许多序列到序列任务（如多语言音译、代码重构、语法修正等）主要依赖局部依赖关系，自回归模型虽然准确但推理延迟高，而非自回归模型速度快但存在幻觉和长度控制问题。需要在准确率和速度之间找到平衡。

Method: 提出NADIR架构，结合差分变换器和混合专家机制，能够鲁棒地建模复杂字符映射而无需序列依赖。专注于印度语言的多语言音译任务。

Result: 相比最先进的自回归基线实现超过13倍加速；平均字符错误率为15.78%（自回归模型14.44%，标准非自回归模型21.88%）；显著减少各类错误：重复错误减少49.53%，替换错误减少24.45%，省略错误减少32.92%，插入错误减少16.87%。

Conclusion: NADIR在准确率和速度之间取得了良好平衡，为构建快速可靠的非自回归系统提供了实用蓝图，有效弥合了自回归准确率与实时大规模部署需求之间的差距。

Abstract: In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.

</details>


### [57] [Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification](https://arxiv.org/abs/2601.12419)
*Mahammad Namazov,Tomáš Koref,Ivan Habernal*

Main category: cs.CL

TL;DR: 本文提出一个比较分析框架，用于评估模型无关的可解释性技术在法律文本预测中的表现，发现模型预测理由与法律专家判断存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 法律领域应用大语言模型需要信任和透明度，但现有研究对哪种可解释技术最适合法律结果预测仍存在疑问，需要系统比较不同方法的有效性。

Method: 提出模型无关的可解释性技术比较分析框架，采用两种理由提取方法，通过忠实度（标准化充分性和全面性指标）和合理性（法律专家评估）进行评估，并测试LLM作为评判者的可行性。

Result: 研究发现模型预测违规的理由与法律专家的判断存在显著差异，尽管定量分析结果很有前景且下游分类性能合理。

Conclusion: 法律领域需要更深入的可解释性研究，仅依赖定量指标可能不足，需要结合专家评估来确保模型决策的透明度和可信度。

Abstract: Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's "reasons" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.

</details>


### [58] [System-Mediated Attention Imbalances Make Vision-Language Models Say Yes](https://arxiv.org/abs/2601.12430)
*Tsan Tsai Chan,Varsha Suresh,Anisha Saha,Michael Hahn,Vera Demberg*

Main category: cs.CL

TL;DR: 研究发现视觉语言模型幻觉与系统模态过度关注有关，通过重新分配注意力从系统到图像和文本输入可以有效抑制"yes偏见"幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有缓解VLM幻觉的策略过于图像中心化，忽略了系统模态在注意力分配失衡中的作用。本研究旨在探索更全面的系统介导解释，认为系统权重冗余导致对图像和文本输入的注意力减少。

Method: 采用系统介导的注意力框架，因果性地重新分配注意力从系统模态到图像和文本输入，评估这种方法对抑制"yes偏见"幻觉的效果。

Result: 重新分配系统注意力到图像和文本输入显著抑制了"yes偏见"，通常优于现有方法。证据表明系统介导的注意力失衡通过鼓励依赖粗略输入表征导致幻觉。

Conclusion: 系统注意力是VLM幻觉的关键因素，可作为缓解幻觉的有效杠杆。研究为理解VLM幻觉提供了更全面的视角，超越了传统的图像中心化解释。

Abstract: Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.

</details>


### [59] [Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping](https://arxiv.org/abs/2601.12465)
*Miao Peng,Weizhou Shen,Nuo Chen,Chenliang Li,Ming Yan,Jia Li*

Main category: cs.CL

TL;DR: 本文提出DeepReasonQA框架和LongPAS方法，解决长上下文推理中RLVR性能下降问题，通过知识图谱合成高难度多跳问答对，并利用细粒度信用分配从"几乎正确"轨迹中提取学习信号。


<details>
  <summary>Details</summary>
Motivation: RLVR在短上下文推理中有效，但在长上下文场景中性能下降，存在"几乎正确"现象（轨迹大部分正确但在最后一步失败）。这归因于：1）长上下文QA数据缺乏高推理密度，无法推动LLM超越简单定位进行复杂多跳推理；2）长上下文RL训练中对部分正确但结果错误的轨迹进行无差别惩罚，导致有价值学习信号丢失。

Method: 提出DeepReasonQA：基于知识图谱的可控合成框架，构建具有固有推理链的高难度多跳长上下文QA对。提出LongPAS：长上下文过程优势塑造方法，通过有效性和相关性两个维度评估推理步骤，进行细粒度信用分配，从"几乎正确"轨迹中捕捉关键学习信号。

Result: 在三个长上下文推理基准测试中，该方法显著优于RLVR基线，并与前沿LLM性能相当，同时使用更少参数。进一步分析证实了方法在增强长上下文推理能力和保持稳定RL训练方面的有效性。

Conclusion: 通过合成高质量长上下文推理数据和细粒度信用分配，成功解决了RLVR在长上下文推理中的性能瓶颈，为增强LLM的长上下文推理能力提供了有效方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the "almost-there" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from "almost-there" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.

</details>


### [60] [Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty](https://arxiv.org/abs/2601.12471)
*Sravanthi Machcha,Sushrita Yerra,Sahil Gupta,Aishwarya Sahoo,Sharmin Sultana,Hong Yu,Zonghai Yao*

Main category: cs.CL

TL;DR: MedAbstain：首个医疗多选问答领域的弃权基准，发现即使高精度LLM也常无法在不确定时弃权，显式弃权选项比输入扰动更有效提升安全性


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估过度关注准确性，但在真实世界和安全关键应用中，模型在不确定时能够弃权的能力对于可信部署同样重要。医疗MCQA作为离散选择场景，可泛化到智能体行动选择，需要系统评估LLM的弃权能力。

Method: 提出MedAbstain统一基准和评估协议，整合了：1）符合性预测方法；2）对抗性问题扰动；3）显式弃权选项。系统评估开源和闭源LLM的弃权表现。

Result: 研究发现：1）即使最先进的、高精度模型也经常无法在不确定时弃权；2）提供显式弃权选项能持续增加模型不确定性和更安全的弃权行为，效果远优于输入扰动；3）扩大模型规模或使用高级提示技术带来的改善有限。

Conclusion: 弃权机制对于可信LLM部署具有核心作用，特别是在高风险应用中。研究结果为提升安全关键应用的安全性提供了实用指导，强调需要专门设计弃权机制而非仅依赖模型能力提升。

Abstract: Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.

</details>


### [61] [Capability-Aware Early-Stage Research Idea Evaluation](https://arxiv.org/abs/2601.12473)
*Renlong Jie,Chen Chu,Zhen Wang*

Main category: cs.CL

TL;DR: 提出基于作者信息和研究想法的能力感知框架，用于预测论文接受率和评分，无需完整文本或实验结果


<details>
  <summary>Details</summary>
Motivation: 在概念阶段（投入大量资源前）预测研究成果，可优化科学资源分配和研究规划。现有方法依赖完整稿件或同行评审，需要更早的预测能力。

Method: 提出能力感知框架，整合作者信息、能力表示和研究想法，采用三路Transformer架构和灵活融合机制，引入两阶段架构学习能力表示。

Result: 实验显示该方法显著优于基于bert-base和bert-large的单路模型，能力预测显著提高了最终模型的预测准确性。

Conclusion: 该方法可用于早期研究成果预测和科学资源分配，为研究规划和资源优化提供新工具。

Abstract: Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.

</details>


### [62] [DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity](https://arxiv.org/abs/2601.12505)
*Ashish Raj Shekhar,Shiven Agarwal,Priyanuj Bordoloi,Yash Shah,Tejas Anvekar,Vivek Gupta*

Main category: cs.CL

TL;DR: DoPE是一个文档层防御框架，通过在PDF/HTML考试文档中嵌入语义诱饵来防止和检测MLLM的自动解题，利用渲染-解析差异来保护学术诚信。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型(MLLMs)能够直接处理考试文档，威胁传统评估方式和学术诚信。需要开发模型无关的防御机制来防止AI自动解题并检测对AI的盲目依赖。

Method: 提出DoPE框架，包含FewSoRT-Q生成问题级语义诱饵，FewSoRT-D将诱饵封装到水印文档中。利用MLLM管道中的渲染-解析差异，在文档创作阶段嵌入语义诱饵。

Result: 在Integrity-Bench基准测试中，对OpenAI和Anthropic的黑盒MLLMs，DoPE实现了91.4%的检测率（8.7%误报率），并在96.3%的尝试中阻止成功完成或诱导诱饵对齐的失败。

Conclusion: DoPE提供了一个有效的文档层防御框架，能够同时实现预防和检测功能，保护学术诚信。作者发布了基准、工具包和评估代码以促进可重复研究。

Abstract: Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.

</details>


### [63] [Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning](https://arxiv.org/abs/2601.12535)
*Ahmed Attia,Alham Fikri*

Main category: cs.CL

TL;DR: 论文提出了一种基于自监督强化学习的低资源机器翻译微调方法，使用NLLB模型进行往返翻译，通过chrF++和BLEU作为奖励函数，在多种低资源语言上取得了改进。


<details>
  <summary>Details</summary>
Motivation: 低资源机器翻译虽然受到关注，但许多改进方法仍未充分探索。作者旨在探索自监督强化学习在低资源翻译中的应用，利用NLLB模型家族来提升翻译质量。

Method: 采用基于强化学习的自监督微调方法，使用往返翻译（round-trip bootstrapping）：先将英语翻译成目标低资源语言，再翻译回英语。使用chrF++和BLEU的组合作为奖励函数来评估重建的英语句子质量。在NLLB-MD数据集上评估了600M和1.3B参数的NLLB模型。

Result: 在Central Aymara、Friulian、Wolof和俄语等语言上观察到一致的改进。定性分析显示翻译输出的流畅性和语义保真度都有所提高。方法在更大规模模型上可能获得更好效果。

Conclusion: 自监督强化学习微调方法能有效提升低资源机器翻译质量，该方法可受益于模型规模的扩大，使模型能更好地利用预训练知识并持续自我改进。

Abstract: Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.

</details>


### [64] [Benchmarking Concept-Spilling Across Languages in LLMs](https://arxiv.org/abs/2601.12549)
*Ilia Badanin,Daniil Dzenhaliou,Imanol Schlag*

Main category: cs.CL

TL;DR: 该论文提出了一种评估多语言大语言模型语义鲁棒性的新框架，通过系统测量模型处理跨语言多义词的能力，揭示了模型在处理非英语语言时存在的"语言溢出"偏见现象。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型虽然展现出显著的跨语言能力，但往往存在系统性偏见，倾向于其他语言的表示，导致在生成非英语内容时出现语义干扰（即"语言溢出"现象）。需要一种系统方法来评估多语言语义鲁棒性。

Method: 提出比较性评估框架，通过结构化意义生成任务系统测量模型处理多义词的能力。使用100个高多义性英语单词作为基准，在9种语言中评估模型。方法提供相对性能度量：当需要生成恰好五种意义时，语义更强的模型会在生成序列后期才求助于主导语言的意义。

Result: 评估了多种开源和闭源多语言LLM，发现在模型和语言间存在显著的语义鲁棒性差异。研究提供了无需确定错误来源因果归因的模型比较原则性排名系统。

Conclusion: 贡献了可扩展的多语言语义评估比较基准和严格验证流程，这些是开发更语言平衡AI系统的关键工具。揭示了多语言LLM中存在的系统性语义偏见，为模型改进提供了评估框架。

Abstract: Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.

</details>


### [65] [Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models](https://arxiv.org/abs/2601.12555)
*Yihong Liu,Bingyu Xiong,Hinrich Schütze*

Main category: cs.CL

TL;DR: LLMs在上下文中介的事实回忆中表现不佳：当目标实体嵌入自然语境而非直接查询时，事实回忆能力下降，且存在跨语言和跨关系的差异。


<details>
  <summary>Details</summary>
Motivation: 现有事实回忆评估主要评估孤立的事实检索，但在自然语言使用中，事实通常通过上下文间接访问。需要研究LLMs在上下文中介的事实回忆能力，特别是在多语言环境中。

Method: 构建受控提示，保留底层事实但通过上下文句子引入指称中介。使用合成名称和真实名称跨语言比较，以区分上下文效应和名称特定关联。在五种语言中评估多个模型家族。

Result: 上下文中介持续降低事实回忆性能，不同关系间存在显著差异。更大模型对上下文中介更稳健，相对于直接查询的性能差距减小。真实名称和名称起源的影响混合且无系统性。

Conclusion: 多语言LLMs在孤立事实回忆和上下文依赖语言理解之间存在差距，上下文中介会降低事实回忆可靠性，需要改进模型在自然语境中的知识访问能力。

Abstract: Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.

</details>


### [66] [A Cloud-based Multi-Agentic Workflow for Science](https://arxiv.org/abs/2601.12607)
*Anurag Acharya,Timothy Vega,Rizwan A. Ashraf,Anshu Sharma,Derek Parker,Robert Rallo*

Main category: cs.CL

TL;DR: 提出一个领域无关、模型独立的云端智能体框架，作为科学助手，能协调多个专业智能体完成从文献综述到复杂模拟等任务，在催化剂研究中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学领域应用受限，无法执行复杂任务如模拟运行。智能体系统虽能调用外部资源，但设计平衡模型、云提供商和资源的流程很困难，阻碍了实际应用。

Method: 设计领域无关、模型独立的云端智能体框架，采用监督智能体协调多个具有特定能力的子智能体，整合从文献综述、数据分析到复杂模拟运行等任务。

Result: 在催化剂研究验证中，系统能将任务正确路由到相应智能体达90%成功率，合成任务完成率97.5%，真实任务完成率91%，准确率与前沿模型相当或更好，同时提供了详细的成本分析。

Conclusion: 该框架是可行的科学智能体系统，能在云端有效运行，为其他科学领域提供了可复制的解决方案，平衡了任务完成率、准确性和成本效益。

Abstract: As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.

</details>


### [67] [Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems](https://arxiv.org/abs/2601.12618)
*Elham Tajik,Conrad Borchers,Bahar Shahrokhian,Sebastian Simon,Ali Keramati,Sonika Pal,Sreecharan Sankaranarayanan*

Main category: cs.CL

TL;DR: 该研究提出利用LLM多智能体系统的推理轨迹作为过程数据，通过余弦相似度量化智能体间的分歧，将分歧重构为有意义的分析信号，以提升质性编码的解释实践。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的发展，全自动和人机协作工作流成为有前景的分析方法，但指导此类工作流的方法学标准仍然有限。需要新的方法来增强质性编码中的解释实践。

Method: 使用LLM多智能体系统生成推理轨迹，应用余弦相似度来系统检测、量化和解释智能体间的分歧。分析了近10,000个智能体对编码人类辅导对话片段的实例，将定量相似度指标与定性审查相结合。

Result: LLM智能体的语义推理相似度能够稳健地区分共识与分歧，并与人类编码可靠性相关。定性分析揭示了代码内的细微教学子功能以及概念代码本细化的机会。

Conclusion: 推理轨迹分歧代表了一类有价值的新分析信号，通过揭示解释模糊性，特别是在LLM与人类协作时，有潜力改进和加速建立编码者间信度，推进教育研究方法学严谨性和解释深度。

Abstract: Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.

</details>


### [68] [BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models](https://arxiv.org/abs/2601.12632)
*Kriti Bhattarai,Vipina K. Keloth,Donald Wright,Andrew Loza,Yang Ren,Hua Xu*

Main category: cs.CL

TL;DR: BioPulse-QA是一个评估大语言模型在生物医学领域表现的新基准，包含2280个专家验证的QA对，覆盖药物标签、试验方案和临床指南等新发布文档。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学基准存在局限性：使用静态过时数据集、数据泄露风险高、忽略语言变异鲁棒性和人口统计偏差。需要动态、上下文丰富且能反映高风险生物医学知识的评估框架。

Method: 引入BioPulse-QA基准，基于新发布的生物医学文档（药物标签、试验方案、临床指南）构建2280个专家验证的QA对，包含提取式和抽象式问题格式。评估了GPT-4o、GPT-o1、Gemini-2.0-Flash和LLaMA-3.1 8B Instruct四个模型。

Result: GPT-o1在药物标签上获得最高松弛F1分数（0.92），Gemini-2.0-Flash次之（0.90）。临床试验是最具挑战性的来源，提取式F1分数低至0.36。改写比拼写错误对性能影响更大，偏差测试显示差异可忽略。

Conclusion: BioPulse-QA提供了一个可扩展且临床相关的框架，用于评估生物医学大语言模型，解决了现有基准的局限性，支持动态、上下文丰富的生物医学知识评估。

Abstract: Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.
  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.
  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.
  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.

</details>


### [69] [Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift](https://arxiv.org/abs/2601.12639)
*Daniel Vennemeyer,Punya Syon Pandey,Phan Anh Duong,Michael Umeokoli,Samuel Ratnam*

Main category: cs.CL

TL;DR: 不同微调目标在安全性和能力上呈现系统性差异：小规模训练时安全性相似但能力不同，大规模训练时监督和偏好微调会显著增加对抗脆弱性，而ORPO和KL正则化能有效缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然知道在良性数据上微调LLM仍可能损害对齐性和对抗鲁棒性，但对于微调目标如何具体影响安全结果的分析还很有限。本文旨在系统比较不同微调目标对安全性和能力的影响。

Method: 在数据、领域、架构和优化方法固定的条件下，对比了六种微调目标：监督微调、直接偏好优化、条件微调、接种提示、几率比偏好优化和KL正则化微调。在封闭式推理和开放式生成任务上进行评估。

Result: 微调目标选择会导致安全-能力前沿的系统性、尺度依赖性变化。小训练预算时，各目标的鲁棒性相似但能力不同；大预算时，监督和偏好微调将能力提升与对抗脆弱性和角色漂移紧密耦合，而ORPO和KL正则化能显著缓解这两种问题。

Conclusion: 微调目标在小规模训练时对安全性影响不大，但随着训练规模增加，成为对抗鲁棒性和潜在角色稳定性的主要驱动因素。选择约束学习信号的目标（如ORPO和KL正则化）能更好地平衡安全性和能力。

Abstract: Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.

</details>


### [70] [Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?](https://arxiv.org/abs/2601.12648)
*Nafiz Imtiaz Khan,Kylie Cleland,Vladimir Filkov,Roger Eric Goldman*

Main category: cs.CL

TL;DR: LLMs可以自动从放射学报告中提取结构化程序信息，用于病例记录，性能接近F1分数0.87，有望减轻培训负担并提高一致性。


<details>
  <summary>Details</summary>
Motivation: 放射学培训中的程序病例记录耗时且手动完成时容易不一致，需要自动化解决方案来减轻学员的文书负担并提高记录质量。

Method: 使用基于指令和思维链提示的本地和商业LLMs，从414份介入放射学报告中提取结构化程序信息，评估敏感性、特异性、F1分数、推理延迟和代币效率。

Result: 本地和商业模型都实现了强大的提取性能，最佳F1分数接近0.87，在速度和成本之间表现出不同的权衡。

Conclusion: LLMs自动化病例记录具有可行性，能显著减轻学员负担并提高一致性，但需要跨机构和临床工作流程的进一步验证。

Abstract: Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.

</details>


### [71] [Augmenting Question Answering with A Hybrid RAG Approach](https://arxiv.org/abs/2601.12658)
*Tianyi Yang,Nashrah Haque,Vaishnave Jonnalagadda,Yuya Jeremy Ong,Zhehui Chen,Yanzhao Wu,Lei Yu,Divyesh Jadav,Wenqi Wei*

Main category: cs.CL

TL;DR: SSRAG是一种混合架构，通过查询增强、智能路由和结构化检索机制提升问答质量，在多个数据集和LLM上表现优于标准RAG


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在检索上下文相关信息时存在困难，导致答案不完整或次优，需要改进检索过程以提升问答质量

Method: 提出结构化语义RAG（SSRAG），整合查询增强、智能路由和结构化检索机制，结合向量和图技术进行上下文统一

Result: 在TruthfulQA、SQuAD和WikiQA三个数据集上，使用五个大语言模型进行评估，SSRAG相比标准RAG在响应质量上持续改进

Conclusion: SSRAG通过改进检索过程和上下文基础，显著提升了问答的准确性和信息量，为RAG系统提供了有效的增强方案

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.

</details>


### [72] [UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages](https://arxiv.org/abs/2601.12696)
*Tassallah Abdullahi,Macton Mgonzo,Mardiyyah Oduwole,Paul Okewunmi,Abraham Owodunni,Ritambhara Singh,Carsten Eickhoff*

Main category: cs.CL

TL;DR: UbuntuGuard是首个非洲政策驱动的安全基准，针对低资源非洲语言构建，包含专家撰写的对抗性查询、情境化安全政策和参考响应，揭示了现有英语中心基准高估多语言安全性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前守护模型主要面向西方高资源语言，对低资源非洲语言存在安全漏洞、跨语言安全失效和文化错位问题，且现有安全分类僵化，无法适应多样化的语言和社会文化背景。

Method: 构建UbuntuGuard基准：1) 155名领域专家（包括医疗保健）撰写对抗性查询；2) 从中推导情境化安全政策和参考响应；3) 评估13个模型（6个通用LLM和7个守护模型），包括静态、动态和多语言三种变体。

Result: 发现：1) 现有英语中心基准高估多语言安全性；2) 跨语言迁移提供部分但不充分的覆盖；3) 动态模型在推理时能更好利用政策，但仍难以完全本地化非洲语言情境。

Conclusion: 迫切需要多语言、文化扎根的安全基准，以开发针对低资源语言的可靠、公平的守护模型。UbuntuGuard为此提供了首个非洲政策驱动的安全评估框架。

Abstract: Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.

</details>


### [73] [A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization](https://arxiv.org/abs/2601.12698)
*Qiuyi Qu,Yicheng Sui,Yufei Sun,Rui Chen,Xiaofei Zhang,Yuzhi Zhang,Haofeng Wang,Ge Lan,Ning Zhang*

Main category: cs.CL

TL;DR: 论文提出基于模板的GPU内核优化方法，通过将内核重构为参数化模板，结合搜索式自动调优，实现稳定高效的速度提升。


<details>
  <summary>Details</summary>
Motivation: GPU代码优化是HPC和大模型训练的关键瓶颈。现有LLM代理方法主要关注直接代码重写，参数选择隐式且难以控制，导致性能提升不稳定，需要人工干预。

Method: 在代理驱动的迭代循环上增加模板重写层：将内核语义重构为显式参数化模板，然后通过基于搜索的自动调优优化模板参数。使用SGLang中的CUDA内核作为评估目标，代理调优器迭代执行模板化、测试、分析和规划，利用性能分析反馈在硬件资源限制下执行约束参数搜索。

Result: 在真实世界内核实验中，最佳情况下实现了超过3倍的速度提升。相比纯代理直接重写，模板加搜索设计显著降低了迭代优化的随机性，使过程更可解释，并能更系统地达到高性能配置。

Conclusion: 提出的模板加搜索方法为GPU内核优化提供了更稳定、可解释的系统化方案，可扩展到OpenCL、HIP等后端，为实际生产负载提供自动化性能优化。

Abstract: GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.

</details>


### [74] [A Shared Geometry of Difficulty in Multilingual Language Models](https://arxiv.org/abs/2601.12731)
*Stefano Civelli,Pietro Bernardelle,Nicolò Brunello,Gianluca Demartini*

Main category: cs.CL

TL;DR: LLMs形成问题难度的两阶段表示：浅层表示是语言无关的，深层表示是语言特定的，这解释了跨语言泛化能力的差异。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs中问题难度预测的多语言几何特性，探索模型内部如何表示任务难度，以及这些表示在不同语言间的泛化能力。

Method: 使用AMC子集（Easy2Hard基准）翻译成21种语言，在LLMs内部表示上训练线性探针，分析浅层（早期层）和深层（后期层）表示的行为差异。

Result: 深层表示探针在相同语言上准确率高但跨语言泛化差；浅层表示探针跨语言泛化好但同语言性能较低。表明LLMs先形成语言无关的难度表示，后转化为语言特定表示。

Conclusion: LLMs对问题难度等高级元认知属性的处理遵循两阶段表示过程：先抽象概念空间，后语言特定输出，这与现有LLM可解释性发现一致。

Abstract: Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.

</details>


### [75] [Towards Robust Process Reward Modeling via Noise-aware Learning](https://arxiv.org/abs/2601.12748)
*Bin Xie,Bingbing Xu,Xueyun Tian,Yilin Chen,Huawei Shen*

Main category: cs.CL

TL;DR: 提出两阶段框架解决过程奖励模型中的噪声监督问题：标签阶段使用LLM检测反思与自校正行为来修正标签，训练阶段采用噪声感知迭代训练框架让PRM基于自身置信度逐步精炼噪声标签。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型（PRMs）在复杂推理中表现良好，但受限于昂贵的过程级监督。广泛使用的蒙特卡洛估计（MCE）方法会产生策略依赖的奖励，导致标签噪声（包括错误奖励正确步骤和错误惩罚正确步骤）。

Method: 提出两阶段框架：1）标签阶段：引入反思感知标签修正机制，使用LLM作为裁判检测与当前推理步骤相关的反思和自校正行为，抑制高估奖励；2）训练阶段：提出噪声感知迭代训练框架，使PRM能够基于自身置信度逐步精炼噪声标签。

Result: 实验表明，该方法显著提高了步骤级正确性判别能力，相比使用噪声监督训练的PRMs，平均F1分数绝对增益最高达27%。

Conclusion: 通过反思感知标签修正和噪声感知迭代训练的两阶段框架，有效缓解了过程奖励模型中的噪声监督问题，显著提升了步骤级正确性判别的性能。

Abstract: Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \underline{\textbf{N}}oise-\underline{\textbf{A}}ware \underline{\textbf{I}}terative \underline{\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\% absolute gain in average F1 over PRMs trained with noisy supervision.

</details>


### [76] [VISPA: Pluralistic Alignment via Automatic Value Selection and Activation](https://arxiv.org/abs/2601.12758)
*Shenyan Zheng,Jiayou Zhong,Anudeex Shetty,Heng Ji,Preslav Nakov,Usman Naseem*

Main category: cs.CL

TL;DR: VISPA是一个无需训练的多元化对齐框架，通过动态选择和内部模型激活引导，实现对价值表达的直接控制，使语言模型能够反映多样的人类观点而非平均偏好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在高风险领域的应用增加，需要其输出反映多样的人类观点而非平均偏好。现有方法要么考虑有限的价值观念，要么依赖提示级干预，缺乏价值控制和代表性。

Method: VISPA是一个无需训练的多元化对齐框架，通过动态选择和内部模型激活引导，实现对价值表达的直接控制。

Result: 在多个模型和评估设置下的广泛实证研究中，VISPA在医疗保健及其他领域的各种多元化对齐模式下都表现出色。进一步分析显示VISPA能够适应不同的引导初始化、模型和/或价值观念。

Conclusion: 这些结果表明，通过内部激活机制可以实现多元化对齐，为构建服务于所有人的语言模型提供了可扩展的路径。

Abstract: As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.

</details>


### [77] [Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory](https://arxiv.org/abs/2601.12771)
*Keito Inoshita*

Main category: cs.CL

TL;DR: 本文提出LAMA框架，利用LLM的世界知识作为关联记忆，通过回忆同名知名人物并聚合其国籍来预测国籍，相比传统LLM提示方法显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: LLM拥有丰富的世界知识，但有效提取这些知识的方法尚未充分探索。国籍和地区预测任务不仅需要语言特征理解，还需要文化历史背景知识，这使得LLM的世界知识特别有价值。然而，传统的LLM提示方法依赖直接推理，在应用抽象语言规则方面存在局限。

Method: 提出LLM关联记忆代理(LAMA)框架，不直接从姓名推断国籍，而是回忆同名知名人物并聚合其国籍进行间接推理。采用双代理架构：人物代理和媒体代理，分别专注于不同知识领域，并行回忆知名人物，通过投票生成Top-1预测，通过条件完成生成Top-K预测。

Result: 在99个国家的国籍预测任务中，LAMA达到0.817的准确率，显著优于传统LLM提示方法和神经模型。实验表明：LLM在回忆具体示例方面比抽象推理更可靠；基于回忆的方法对低频国籍具有鲁棒性，不受数据频率分布影响；双代理架构具有互补性，产生协同效应。

Conclusion: 研究结果表明，通过检索和聚合LLM知识而非提示推理的新型多代理系统是有效的，为利用LLM世界知识提供了新思路。

Abstract: Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.

</details>


### [78] [Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?](https://arxiv.org/abs/2601.12812)
*Sushant Kumar Ray,Gautam Siddharth Kashyap,Sahil Tripathi,Nipun Joshi,Vijay Govindarajan,Rafiq Ali,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: MEDASSESS-X是一个临床问答框架，通过推理时对齐而非微调来提升LLM性能，挑战了医疗领域专用模型必然更优的假设。


<details>
  <summary>Details</summary>
Motivation: 当前临床问答系统过度依赖领域特定的微调，存在覆盖范围窄、重训练成本高、适应性有限等问题。作者认为"专业化谬误"（认为专用医疗LLM必然更优）阻碍了更有效的解决方案。

Method: 提出MEDASSESS-X框架，采用推理时对齐而非监督微调。使用轻量级导向向量引导模型激活，实现医学一致性推理，无需更新模型权重或领域特定重训练。

Result: MEDASSESS-X在所有LLM家族中均带来一致提升：准确率最高提升6%，事实一致性提升7%，安全错误率降低高达50%。该框架稳定了通用和专用医疗LLM的CQA性能。

Conclusion: 推理时对齐方法能有效解决专业化谬误，为临床问答系统部署提供了更灵活、成本效益更高的解决方案，无需依赖领域特定的模型微调。

Abstract: Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.

</details>


### [79] [Multimodal Multi-Agent Empowered Legal Judgment Prediction](https://arxiv.org/abs/2601.12815)
*Zhaolu Kang,Junhao Gong,Qingxi Chen,Hao Zhang,Jiaxin Liu,Rong Fu,Zhiyuan Feng,Yuan Wang,Simon Fong,Kaiyue Zhou*

Main category: cs.CL

TL;DR: 本文提出JurisMMA框架用于法律判决预测，通过分解审判任务、标准化流程并组织成不同阶段来解决传统方法在处理多重指控、多样证据和缺乏适应性方面的挑战。同时构建了包含10万+中文司法记录的JurisMM多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 传统法律判决预测方法依赖统计分析或基于角色的模拟，但在处理多重指控、多样证据时面临挑战且缺乏适应性。需要更有效的框架来提升法律系统的发展。

Method: 提出JurisMMA框架，有效分解审判任务、标准化流程并组织成不同阶段。同时构建了JurisMM大型数据集，包含超过10万条近期中文司法记录，包括文本和多模态视频-文本数据。

Result: 在JurisMM和基准LawBench上的实验验证了框架的有效性。结果表明该框架不仅对法律判决预测有效，也对更广泛的法律应用有效。

Conclusion: JurisMMA框架为法律判决预测提供了新视角，并为未来法律方法和数据集的发展提供了新的方向，能够促进法律系统的进步。

Abstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.

</details>


### [80] [Rapport du Projet de Recherche TRAIMA](https://arxiv.org/abs/2601.12844)
*Julie Rançon,Jean-François Cerisier,Emilie Remond,Aurélien Nguyen,Andrew Peterson,Ladjel Bellatreche*

Main category: cs.CL

TL;DR: TRAIMA项目研究教育场景中多模态交互的自动处理，解决手动分析耗时且难以扩展的问题，探索机器学习在多模态交互分类中的应用，建立方法论框架。


<details>
  <summary>Details</summary>
Motivation: 教育研究中多模态交互（言语、副言语、非言语）的分析目前完全依赖手动处理，极其耗时且难以规模化。项目旨在探索机器学习方法如何帮助自动分类和分析这些交互。

Method: 项目采用多模态分析方法，聚焦课堂中的解释性和协作性序列，特别是法语作为外语和母语的教学场景。基于INTER-EXPLIC和EXPLIC-LEXIC语料库，分析言语、韵律、手势、姿势、注视和空间定位的整合。建立解释性话语的三段式结构（开场、解释核心、收尾），并系统评估现有转写规范。

Result: 项目展示了转写实践的必然变异性和解释性维度，识别了与机器学习兼容的转写规范、标注类别和分析单元。建立了严谨的方法论框架，为多模态教学交互的自动处理奠定基础。

Conclusion: TRAIMA项目并未开发完全可操作的自动化系统，而是建立了多模态教学交互自动处理的严谨方法论框架。项目强调理论明确性和研究者反思性的重要性，为未来教育、话语分析、多模态和人工智能的跨学科研究奠定基础。

Abstract: The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{é}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{é}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{é}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.

</details>


### [81] [Race, Ethnicity and Their Implication on Bias in Large Language Models](https://arxiv.org/abs/2601.12868)
*Shiyue Hu,Ruizhe Li,Yanjun Gao*

Main category: cs.CL

TL;DR: 该研究通过可解释性方法分析LLM中种族和民族信息的内部表示机制，发现这些信息分布在多个单元中，干预可减少偏见但效果有限。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗等高风险领域应用时，种族和民族信息可能被明确陈述或隐含推断，现有研究主要记录结果层面的差异，但对内部机制了解有限。

Method: 使用两个公开数据集（毒性生成和临床叙事理解任务），分析三个开源模型，采用可重复解释性流水线：探测、神经元级归因和针对性干预。

Result: 发现人口统计信息分布在内部单元中且模型间差异大；某些单元编码了预训练中的敏感或刻板印象关联；相同人口统计线索可引发不同行为；干预抑制相关神经元能减少偏见但仍有残留效应。

Conclusion: 干预主要改变行为而非表示，表明需要更系统的缓解方法；研究为理解LLM中人口统计信息的表示和操作化提供了机制性见解。

Abstract: Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.

</details>


### [82] [From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.12904)
*Jiahao Wang,Weiyu Xie,Mingxing Zhang,Boxing Zhang,Jianwei Dong,Yuening Zhu,Chen Lin,Jinqi Tang,Yaochen Han,Zhiyuan Ai,Xianglin Chen,Yongwei Wu,Congfeng Jiang*

Main category: cs.CL

TL;DR: FusionRAG：一种新颖的RAG推理框架，通过优化预处理和再处理阶段，在重用KV缓存的同时保持生成质量，实现生成质量与效率的更好权衡。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成(RAG)虽然能减少大语言模型的幻觉，但增加了提示长度，导致计算成本增加和首词生成时间(TTFT)变长。现有解决方案试图重用检索块的预处理KV缓存来加速RAG，但缺乏跨块上下文信息导致生成质量显著下降，使得KV缓存重用的潜在好处无法充分发挥。

Method: 提出FusionRAG框架，优化RAG的预处理和再处理阶段：1）离线预处理阶段：将其他相关文本块的信息嵌入到每个块中；2）在线再处理阶段：重新计算模型关注的token的KV缓存。通过这种方式在重用预计算KV缓存的同时保持生成质量。

Result: 实验表明，在相同的重新计算比例下，FusionRAG显著提高了生成质量。通过重新计算少于15%的token，FusionRAG相比基线实现了高达70%的归一化F1分数提升，相比完整注意力机制减少了2.66倍到9.39倍的TTFT。

Conclusion: FusionRAG通过创新的两阶段优化方法，成功解决了RAG中KV缓存重用与生成质量之间的权衡问题，实现了更好的效率与质量平衡，为RAG系统的实际部署提供了有效的解决方案。

Abstract: Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.

</details>


### [83] [Gated Differentiable Working Memory for Long-Context Language Modeling](https://arxiv.org/abs/2601.12906)
*Lingrui Mei,Shenghua Liu,Yiwei Wang,Yuyao Ge,Baolong Bi,Jiayu Yao,Jun Wan,Ziling Yin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: Gdwm框架通过门控控制器选择性记忆关键上下文，用4倍更少的梯度步数实现可比或更好的性能


<details>
  <summary>Details</summary>
Motivation: 长上下文挑战Transformer：注意力分数在数千个token中稀释，关键信息常丢失在中间，模型难以适应推理时的新模式。现有测试时自适应方法使用均匀写入策略，浪费计算在低效用区域，且在语义异构上下文中梯度方差高。

Method: 将测试时自适应重构为预算约束下的记忆巩固问题，提出Gdwm框架，引入写入控制器来门控巩固过程。控制器估计"上下文效用"（衡量长距离上下文依赖的信息论指标），并相应分配梯度步数，同时保持全局覆盖。

Result: 在ZeroSCROLLS和LongBench v2上的实验表明，Gdwm以4倍更少的梯度步数实现了可比或更优的性能，为测试时自适应建立了新的效率-性能帕累托前沿。

Conclusion: 通过选择性记忆关键上下文而非均匀处理，Gdwm显著提高了测试时自适应的计算效率，解决了长上下文处理中的信息稀释和计算浪费问题。

Abstract: Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.

</details>


### [84] [SciCoQA: Quality Assurance for Scientific Paper--Code Alignment](https://arxiv.org/abs/2601.12910)
*Tim Baumgärtner,Iryna Gurevych*

Main category: cs.CL

TL;DR: SciCoQA是一个检测科学论文与代码库差异的数据集，包含611个差异实例（81个真实，530个合成），涵盖AI、物理、定量生物学等领域。评估显示LLMs在此任务上表现不佳，GPT-5仅能检测45.7%的真实差异。


<details>
  <summary>Details</summary>
Motivation: 确保科学论文的代码实现忠实于论文描述，解决论文与代码库之间的差异问题，这对于科学研究的可重复性和可靠性至关重要。

Method: 从GitHub问题和可重复性论文中构建真实差异数据集，并提出合成数据生成方法来扩展数据集。对差异进行详细分析，提出差异类型和分类。评估了21个大型语言模型在检测这些差异方面的能力。

Result: 构建了包含611个差异实例的数据集（81个真实，530个合成）。评估显示该任务对LLMs具有挑战性，特别是在涉及省略的论文细节、长上下文输入和预训练语料库之外的数据时。最佳模型GPT-5仅能检测45.7%的真实差异。

Conclusion: SciCoQA数据集揭示了科学论文与代码实现之间的差异问题，并展示了当前LLMs在检测这些差异方面的局限性。该数据集为未来研究提供了基准，有助于改进科学代码实现的忠实性和可重复性。

Abstract: We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\% of real-world paper-code discrepancies.

</details>


### [85] [Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs](https://arxiv.org/abs/2601.12921)
*Adimulya Kartiyasa,Bao Gia Cao,Boyang Li*

Main category: cs.CL

TL;DR: 提出IndoSoSci数据集，通过RAG和LLM生成假设文档查询，有效将印尼社会科学期刊中的文化知识注入大语言模型，在IndoCulture基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型对印尼文化的理解有限，而本土社会科学期刊包含大量从本土视角出发的文化研究，这些资源尚未被充分利用。

Method: 从151个开源印尼社会科学期刊创建IndoSoSci文本数据集，提取印尼文化相关事实，采用检索增强生成(RAG)方法，使用LLM生成的假设文档作为检索查询。

Result: 提出的方法在IndoCulture基准上显著优于多个强基线模型，结合印尼维基百科后，在IndoCulture基准上达到了新的最先进准确率。

Conclusion: 印尼社会科学期刊是宝贵的文化知识来源，通过RAG和LLM生成假设文档查询的方法能有效将本土文化知识注入大语言模型，提升其对印尼文化的理解能力。

Abstract: Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.

</details>


### [86] [A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits](https://arxiv.org/abs/2601.12945)
*Miao Xie,Siguang Chen,Chunli Lv*

Main category: cs.CL

TL;DR: 这篇论文是第一篇系统综述大语言模型与多臂老虎机在组件层面双向交互的调研，探讨了MAB如何解决LLM从预训练到RAG和个性化的挑战，以及LLM如何增强MAB系统的核心组件。


<details>
  <summary>Details</summary>
Motivation: LLM已成为强大的语言理解和生成系统，而MAB为不确定性下的自适应决策提供了原则性框架。目前缺乏对这两个领域在组件层面双向交互的系统性调研，本文旨在填补这一空白。

Method: 采用系统性文献综述方法，分析现有的LLM增强老虎机系统和老虎机增强LLM系统，从组件层面探讨双向交互的设计、方法论和性能。

Result: 识别了关键挑战和代表性发现，展示了MAB算法如何解决LLM在预训练、RAG和个性化等关键挑战，以及LLM如何重新定义MAB系统的臂定义和环境建模等核心组件。

Conclusion: 这篇调研为未来研究提供了指导，建立了LLM与MAB交互的研究框架，并提供了包含相关文献的GitHub资源库，促进该交叉领域的进一步发展。

Abstract: Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.

</details>


### [87] [Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images](https://arxiv.org/abs/2601.12960)
*Ainhoa Vivel-Couso,Nicolás Vila-Blanco,María J. Carreira,Alberto Bugarín-Diz,Inmaculada Tomás,Jose M. Alonso-Moral*

Main category: cs.CL

TL;DR: 提出结合不透明与透明方法的牙科年龄估计系统，通过自然语言生成模块为临床医生提供可理解的文本解释，提升AI在医疗中的可信度


<details>
  <summary>Details</summary>
Motivation: 深度学习在医疗保健中的应用虽能实现个性化护理，但由于模型不透明性引发信任问题，需要提高透明度以增强临床医生对AI系统的信任

Method: 从全景图像进行牙科年龄估计的系统，结合不透明和透明方法，通过自然语言生成模块生成临床医生友好的文本解释，采用基于规则的方法与牙科专家合作设计

Result: 牙科专家通过问卷手动验证生成解释的质量，在五个维度上平均评分为4.77±0.12（满分5分）；按照ALTAI清单进行可信度自评估，在AI可信度评估列表的七个维度上得分为4.40±0.27（满分5分）

Conclusion: 该系统成功提高了牙科年龄估计的透明度，通过自然语言解释增强了临床医生对AI结果的信任，为医疗AI系统的可信度评估提供了实用框架

Abstract: Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.

</details>


### [88] [Pardon? Evaluating Conversational Repair in Large Audio-Language Models](https://arxiv.org/abs/2601.12973)
*Shuanghong Huang,Jinlei Xu,Youchao Zhou,Yanghao Zhou,Xuan Zhao,Chong Feng,Wenxuan Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种修复感知的评估框架，用于评估大型音频语言模型在可回答与不可回答音频输入下的表现，并引入EAR评分来联合评估任务能力和修复行为。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注答案准确性和声学扰动鲁棒性，但假设语音输入始终语义可回答，这在现实交互中常不成立。需要评估模型在信息缺失时的修复能力。

Method: 引入修复感知评估设置，通过语义-声学掩蔽协议构建配对评估条件，提出EAR评分（可评估性意识和修复评分），非补偿性联合评估可回答条件下的任务能力和不可回答条件下的修复行为。

Result: 在两个语音QA基准测试中，多数模型在可回答输入下表现良好，但大多无法识别语义不可回答性并启动适当的对话修复，揭示了准确性中心评估的局限性。

Conclusion: 当前评估实践存在局限，需要将不可回答输入视为修复和持续交互的线索，进行可靠性评估，以提升模型在现实对话中的实用性。

Abstract: Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.

</details>


### [89] [Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios](https://arxiv.org/abs/2601.12974)
*Hongyang Ma,Tiantian Gu,Huaiyuan Sun,Huilin Zhu,Yongxin Wang,Jie Li,Wubin Sun,Zeliang Lian,Yinghong Zhou,Yi Gao,Shirui Wang,Zhihui Tang*

Main category: cs.CL

TL;DR: 该研究开发了SCMPE基准测试，评估牙科LLM从静态知识任务到动态临床对话的性能，发现模型在动态对话中表现下降，主要瓶颈在于主动信息收集和状态跟踪，而非知识保留。


<details>
  <summary>Details</summary>
Motivation: 随着LLM从被动知识检索器向自主临床代理转变，需要从静态准确性评估转向动态行为可靠性评估。牙科领域的高质量AI建议对患者参与决策至关重要，需要探索LLM在该领域的边界。

Method: 提出了标准化临床管理与性能评估（SCMPE）基准，全面评估从知识导向评估（静态客观任务）到基于工作流的模拟（多轮模拟患者交互）的性能。分析了指南遵循与决策质量的关系，并量化了检索增强生成（RAG）的影响。

Result: 模型在静态客观任务中表现出高熟练度，但在动态临床对话中性能显著下降。主要瓶颈在于主动信息收集和动态状态跟踪，而非知识保留。发现通用模型存在"高效能、低安全性"风险。RAG在静态任务中减少幻觉，但在动态工作流中效果有限且异质，有时甚至导致性能下降。

Conclusion: 外部知识单独无法弥补推理差距，需要领域自适应预训练。该研究实证绘制了牙科LLM的能力边界，为弥合标准化知识与安全自主临床实践之间的差距提供了路线图。

Abstract: The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping "Guideline Adherence" versus "Decision Quality" reveals a prevalent "High Efficacy, Low Safety" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.

</details>


### [90] [The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check](https://arxiv.org/abs/2601.12979)
*Qingyu Lu,Liang Ding,Kanjian Zhang,Jinxia Zhang,Dacheng Tao*

Main category: cs.CL

TL;DR: 扩散大语言模型(dLLMs)在实时智能体交互中效率提升明显，但在实际智能体任务中表现不佳，特别是在具身智能体和工具调用任务中存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 研究扩散大语言模型(dLLMs)作为自回归模型的替代方案，能否在保持效率优势的同时，实现有效的智能体行为。

Method: 1. 在Agentboard和BFCL基准上全面评估dLLMs在两种智能体范式中的表现：具身智能体（需要长时程规划）和工具调用智能体（需要精确格式）
2. 引入DiffuAgent多智能体评估框架，将dLLMs作为即插即用的认知核心集成到智能体工作流中

Result: 1. 具身智能体设置中：dLLMs反复尝试失败，无法在时间反馈下进行分支决策
2. 工具调用设置中：dLLMs在扩散噪声下无法保持符号精度（如严格的JSON模式）
3. dLLMs在非因果角色中表现有效（如记忆总结和工具选择），但在智能体任务中需要结合因果、精确和逻辑推理机制

Conclusion: 当前dLLMs无法作为可靠的智能体骨干模型，虽然效率高但在智能体任务中存在系统性失败。dLLMs在去噪过程中需要融入因果、精确和逻辑推理机制才能适用于智能体任务。

Abstract: The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a "bitter lesson": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.

</details>


### [91] [ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation](https://arxiv.org/abs/2601.12983)
*Jesus-German Ortiz-Barajas,Jonathan Tonglet,Vivek Gupta,Iryna Gurevych*

Main category: cs.CL

TL;DR: ChartAttack是一个评估多模态大语言模型生成误导性图表能力的框架，通过注入误导设计元素来诱导错误数据解读，显著降低图表问答准确性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型被广泛用于从数据表自动生成图表，虽然提高了数据分析效率，但也带来了新的滥用风险。需要评估这些模型如何被大规模用于生成误导性图表。

Method: 提出ChartAttack框架，向图表设计中注入误导元素，旨在诱导对底层数据的错误解读。同时创建AttackViz数据集，包含带有有效误导元素标签的图表规范-QA对。

Result: 实验显示ChartAttack显著降低了MLLM阅读器的QA性能：域内设置平均降低19.6个百分点，跨域设置降低14.9个百分点。人类研究显示参与者面对误导图表时准确率平均下降20.2个百分点。

Conclusion: 研究结果强调在基于MLLM的图表生成系统的设计、评估和部署中，迫切需要加强鲁棒性和安全性考虑。代码和数据已公开。

Abstract: Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.

</details>


### [92] [Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.12995)
*Runxuan Liu,Xianhao Ou,Xinyan Ma,Jiyuan Wang,Jiafeng Liang,Jiaqi Li,Tao He,Zheng Chu,Rongchuan Mu,Zekun Wang,Baoxin Wang,Dayong Wu,Ming Liu,Shijin Wang,Guoping Hu,Bing Qin*

Main category: cs.CL

TL;DR: 提出Graph Reasoning Paradigm (GRP)和PASC-GRPO方法，通过图结构表示和结构化评估解决现有LCoT方法的计算瓶颈、监督粗糙、奖励攻击等问题，在数学推理和代码生成任务上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的推理主要生成纯文本，对非结构化数据进行语义评估会造成训练时的计算瓶颈。尽管有RLVR优化，现有方法仍存在监督粗糙、奖励攻击、训练成本高和泛化能力差等问题。

Method: 提出Graph Reasoning Paradigm (GRP)，通过带有步骤级认知标签的图结构表示实现结构化符号推理。基于GRP进一步设计PASC-GRPO方法，利用结构化评估替代语义评估，通过图结构结果奖励实现过程感知验证，并通过分层裁剪优势估计缓解奖励攻击。

Result: 实验表明在数学推理和代码生成任务上取得了显著改进。数据、模型和代码将在后续发布。

Conclusion: GRP和PASC-GRPO方法通过结构化推理和评估，有效解决了现有LCoT方法的问题，提升了LLMs的推理能力。

Abstract: Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.

</details>


### [93] [Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context](https://arxiv.org/abs/2601.13018)
*Ghislain Dorian Tchuente Mondjo*

Main category: cs.CL

TL;DR: 提出BiAtt-BiRNN-HateXplain模型，通过双向注意力机制和BiRNN层改进仇恨言论检测的解释性和分类性能，减少注意力变异性和无意偏见。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型存在注意力变异问题（预测注意力不一致），导致解释不一致、预测不稳定和学习困难。需要更透明、考虑数据序列特征的模型来改进解释性和减少无意偏见。

Method: 提出双向注意力BiRNN HateXplain模型：1) 使用双向循环神经网络(BiRNN)层考虑输入数据的序列特征；2) 采用双向注意力机制；3) 多任务学习同时处理解释性和分类任务；4) 相比复杂的大语言模型更易解释。

Result: 在HateXplain数据集上的实验结果显示：检测性能明显提升，解释性改善，无意偏见减少。

Conclusion: BiAtt-BiRNN-HateXplain模型通过改进注意力机制和考虑序列特征，有效解决了注意力变异问题，提升了仇恨言论检测的解释性和分类准确性，同时减少了模型的无意偏见。

Abstract: Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.

</details>


### [94] [Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses](https://arxiv.org/abs/2601.13024)
*Chongyuan Dai,Yaling Shen,Jinpeng Hu,Zihan Gao,Jia Li,Yishun Jiang,Yaxiong Wang,Liu Liu,Zongyuan Ge*

Main category: cs.CL

TL;DR: CEDAR是一个多模态基准测试，专注于评估大语言模型在不同文化背景下的情感理解能力，填补了现有文化对齐评估主要关注事实性知识而忽视主观情感解释差异的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型文化对齐评估主要关注地理事实、社会习俗等陈述性知识，无法捕捉不同社会文化视角下的主观解释差异。文化作为人类情感处理的基本决定因素，深刻影响个体对情感刺激的感知和解释，因此需要专门评估模型在文化背景下的情感理解能力。

Method: 提出CEDAR基准测试，采用新颖的构建流程：1）利用LLM生成的临时标签来识别产生跨文化情感差异的实例；2）通过严格的人工评估获得可靠的真实标注。基准包含10,962个实例，涵盖7种语言和14种细粒度情感类别，每种语言包含400个多模态样本和1,166个纯文本样本。

Result: 对17个代表性多语言模型的综合评估显示，语言一致性与文化对齐之间存在分离现象，表明当前模型在基于文化的情感理解方面仍面临重大挑战。

Conclusion: 文化背景下的情感理解是当前大语言模型的重要挑战，需要专门的评估基准来捕捉不同文化视角下的主观解释差异。CEDAR基准填补了这一空白，为评估模型的文化对齐能力提供了重要工具。

Abstract: Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \underline{\textsc{E}}licited \underline{\textsc{D}}istinct \underline{\textsc{A}}ffective \underline{\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.

</details>


### [95] [SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification](https://arxiv.org/abs/2601.13035)
*Xu Xiaodan,Hu Xiaolin*

Main category: cs.CL

TL;DR: SASA框架通过分离注意力机制和语义感知对比学习提升知识图谱三元组分类性能，在FB15k-237和YAGO3-10数据集上分别实现了5.9%和3.4%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 知识图谱常包含不可靠知识，现有三元组分类方法存在两个关键问题：1) 忽略不同KG组件间的有效语义交互；2) 单一二元分类训练目标导致语义表示学习不足。

Method: 提出SASA框架：1) 分离注意力机制将三元组编码为解耦的上下文表示并通过更有效的交互方式融合；2) 语义感知分层对比学习作为辅助训练目标，考虑局部和全局层次的对比学习。

Result: 在两个基准数据集上显著优于现有方法：FB15k-237准确率提升5.9%，YAGO3-10准确率提升3.4%，达到了新的最先进水平。

Conclusion: SASA通过分离注意力机制增强语义交互，结合分层对比学习提升判别能力，有效解决了现有三元组分类方法的局限性，显著提升了模型性能。

Abstract: Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\% on FB15k-237 and +3.4\% on YAGO3-10.

</details>


### [96] [Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition](https://arxiv.org/abs/2601.13044)
*Warit Sirichotedumrong,Adisai Na-Thalang,Potsawee Manakul,Pittawat Taveekitworachai,Sittipong Sripaisarnmongkol,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: Typhoon ASR Real-time 是一个115M参数的FastConformer-Transducer模型，用于低延迟泰语语音识别，通过严格的文本规范化实现了45倍计算成本降低，同时发布标准化评估基准。


<details>
  <summary>Details</summary>
Motivation: 大型编码器-解码器模型（如Whisper）虽然离线转录效果好，但延迟高不适合流式应用。泰语ASR领域缺乏高效的流式解决方案，且存在文本规范化不一致、方言适应和可复现性等挑战。

Method: 1) 采用115M参数的FastConformer-Transducer架构；2) 设计严格的文本规范化流程，解决泰语转录中的系统歧义（如上下文相关的数字发音和重复标记）；3) 引入两阶段课程学习方法用于伊森方言适应；4) 发布Typhoon ASR Benchmark标准化评估数据集。

Result: 紧凑模型相比Whisper Large-v3实现45倍计算成本降低，同时保持相当的准确性。文本规范化匹配了模型扩展的效果，伊森方言适应方法在保持中央泰语性能的同时实现了方言适应。

Conclusion: 严格的文本规范化对泰语ASR性能提升至关重要，甚至能与模型扩展相媲美。Typhoon ASR Real-time为泰语流式识别提供了高效解决方案，发布的标准化基准将促进泰语ASR研究的可复现性和可比性。

Abstract: Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.

</details>


### [97] [Profiling German Text Simplification with Interpretable Model-Fingerprints](https://arxiv.org/abs/2601.13050)
*Lars Klöser,Mika Beele,Bodo Kraft*

Main category: cs.CL

TL;DR: 本文提出Simplification Profiler诊断工具包，通过生成多维可解释的简化文本指纹来评估LLM的文本简化行为，无需大规模人工标注数据。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM文本简化行为进行全面、高效、可复现诊断的工具，特别是在数据稀缺的语言环境中，需要评估模型对不同目标群体的适应性而非单一简化风格。

Method: 开发Simplification Profiler工具包，通过聚合多个简化文本生成模型的多维可解释指纹，使用线性分类器验证指纹的描述能力，区分不同模型配置和提示策略。

Result: 完整特征集实现高达71.9%的分类F1分数，比简单基线提高超过48个百分点，能够区分提示策略的高层行为变化和提示工程的细粒度变化。

Conclusion: Simplification Profiler为开发者提供了细粒度、可操作的分析工具，有助于构建更有效和真正自适应的文本简化系统，特别是在数据稀缺的语言环境中。

Abstract: While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.

</details>


### [98] [Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs](https://arxiv.org/abs/2601.13099)
*Abdellah El Mekki,Samar M. Magdy,Houdaifa Atou,Ruwa AbuHweidi,Baraah Qawasmeh,Omer Nacar,Thikra Al-hibiri,Razan Saadie,Hamzah Alsayadi,Nadia Ghezaiel Hammouda,Alshima Alkhazimi,Aya Hamod,Al-Yas Al-Ghafri,Wesam El-Sayed,Asila Al sharji,Mohamad Ballout,Anas Belfathi,Karim Ghaddar,Serry Sibaee,Alaa Aoun,Areej Asiri,Lina Abureesh,Ahlam Bashiti,Majdal Yousef,Abdulaziz Hafiz,Yehdih Mohamed,Emira Hamedtou,Brakehe Brahim,Rahaf Alhamouri,Youssef Nafea,Aya El Aatar,Walid Al-Dhabyani,Emhemed Hamed,Sara Shatnawi,Fakhraddin Alwajih,Khalid Elkhidir,Ashwag Alasmari,Abdurrahman Gerrio,Omar Alshahri,AbdelRahim A. Elmadany,Ismail Berrada,Amir Azad Adli Alkathiri,Fadi A Zaraket,Mustafa Jarrar,Yahya Mohamed El Hadj,Hassan Alhuzali,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: Alexandria是一个大规模、社区驱动、人工翻译的数据集，专门用于弥合阿拉伯语方言与标准语之间的机器翻译差距，覆盖13个阿拉伯国家、11个高影响力领域，包含城市级方言元数据和性别配置标注。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语是高度双言现象的语言，日常交流多使用方言而非现代标准阿拉伯语，但现有机器翻译系统对方言输入泛化能力差，限制了数百万使用者的实用性。

Method: 创建Alexandria数据集：大规模、社区驱动、人工翻译，覆盖13个阿拉伯国家、11个高影响力领域，提供城市级元数据粒度，包含多轮对话场景并标注说话者-受话者性别配置。

Result: 数据集包含107K样本，可作为训练资源和严格基准，通过自动和人工评估阿拉伯语感知LLM，揭示了当前在跨阿拉伯方言翻译方面的能力与持续挑战。

Conclusion: Alexandria数据集填补了阿拉伯方言机器翻译的资源空白，提供了前所未有的方言粒度，暴露了现有模型在方言翻译方面的显著挑战，为未来研究提供了重要基准。

Abstract: Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.

</details>


### [99] [Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification](https://arxiv.org/abs/2601.13105)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

TL;DR: 该研究通过结合LoRA微调大语言模型与RAG框架，实现了英语双及物结构的自动识别，在BNC语料上取得了显著优于原生模型和纯理论RAG系统的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发更准确的英语双及物结构自动识别方法，传统方法可能过于依赖表面形式匹配，需要更语义化的理解。

Method: 方法采用LoRA微调Qwen3-8B大语言模型，并结合检索增强生成(RAG)框架，在标注的英国国家语料库(BNC)数据上进行二元分类任务。

Result: 结果显示，LoRA微调的Qwen3-8B模型显著优于原生Qwen3-MAX模型和纯理论RAG系统。错误分析表明微调使模型从表面形式匹配转向更语义化的理解。

Conclusion: 结论表明LoRA微调结合RAG框架能有效提升英语双及物结构的识别准确率，实现从形式匹配到语义理解的转变。

Abstract: This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.

</details>


### [100] [CORE-T: COherent REtrieval of Tables for Text-to-SQL](https://arxiv.org/abs/2601.13111)
*Hassan Soliman,Vivek Gupta,Dan Roth,Iryna Gurevych*

Main category: cs.CL

TL;DR: CORE-T：一个无需训练、可扩展的框架，通过LLM生成表目的元数据并预计算表兼容性缓存，在推理时结合稠密检索和LLM选择，显著提升多表文本到SQL中的表选择性能。


<details>
  <summary>Details</summary>
Motivation: 现实文本到SQL工作流常需连接多表，准确检索相关表成为端到端性能的关键瓶颈。在开放场景中，查询需在大型异构表集合上回答，缺乏数据库标识等清晰范围信号，现有方法存在召回率高但返回过多干扰表，或依赖额外假设/推理开销大的问题。

Method: 提出CORE-T框架：1) 使用LLM为表生成目的元数据；2) 预计算轻量级表兼容性缓存；3) 推理时：稠密检索返回top-K候选表，单个LLM调用选择可连接子集，简单加法调整步骤恢复强兼容表。

Result: 在Bird、Spider和MMQA数据集上，CORE-T将表选择F1提升高达22.7分，同时检索表数减少42%，多表执行准确率在Bird上提升5.0分，MMQA上提升6.9分，比LLM密集型基线少用4-5倍token。

Conclusion: CORE-T通过结合稠密检索的高召回和LLM的语义理解，有效解决多表文本到SQL中的表选择问题，在保持高性能的同时显著降低计算开销。

Abstract: Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.

</details>


### [101] [Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning](https://arxiv.org/abs/2601.13115)
*Fengran Mo,Yifan Gao,Sha Li,Hansi Zeng,Xin Liu,Zhaoxuan Tan,Xian Li,Jianshu Chen,Dakuo Wang,Meng Jiang*

Main category: cs.CL

TL;DR: 提出一种基于强化学习的对话代理，通过跨轮次交替搜索和推理来处理多轮对话中的动态用户意图，超越了现有静态管道方法。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统通常采用静态的重写-检索-生成管道，这些方法分别优化不同流程，忽视了混合主动性动作的同时优化。虽然深度搜索代理在单轮场景中通过推理联合优化检索和生成方面表现出色，但缺乏处理多轮交互的能力。

Method: 引入一种对话代理，通过强化学习训练，在轮次间交替进行搜索和推理，实现探索性和适应性行为。使用针对演化用户目标的定制奖励进行RL训练。

Result: 在四个广泛使用的对话基准测试中，该方法超越了多个现有强基线，证明了其有效性。

Conclusion: 提出的跨轮次交替搜索和推理的对话代理能够更好地处理多轮对话中动态演化的用户意图，通过强化学习实现了探索性和适应性行为。

Abstract: Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.

</details>


### [102] [Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains](https://arxiv.org/abs/2601.13137)
*Yuan Gao,Zhigang Liu,Xinyu Yao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 提出对抗对齐框架VC-LLM，通过持续预训练、指令微调和对抗训练增强大语言模型在敏感领域的价值观一致性


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，在种族、社会、政治等敏感领域出现的偏见和价值观不一致问题日益凸显，需要解决模型在这些领域的价值观对齐问题

Method: 提出对抗对齐框架：1）持续预训练；2）指令微调；3）对抗训练（使用Attacker生成争议性查询，Actor生成价值观一致的响应，Critic过滤确保响应质量）。训练了专门用于敏感领域的VC-LLM模型，并构建了中英双语评估数据集

Result: 实验结果表明，VC-LLM在中英文测试中都优于现有主流模型，验证了方法的有效性

Conclusion: 提出的对抗对齐框架能有效增强大语言模型在敏感领域的价值观一致性，VC-LLM在价值观对齐方面表现优异

Abstract: With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.

</details>


### [103] [Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2601.13155)
*Zimeng Wu,Donghao Wang,Chaozhe Jin,Jiaxin Chen,Yunhong Wang*

Main category: cs.CL

TL;DR: SPTS是一种无需训练的长上下文LLM推理加速框架，通过部分注意力探测和低秩变换探测选择性跳过token，结合多阶段延迟剪枝策略，实现2.46倍预填充和2.29倍端到端生成加速，同时保持SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理增强LLM推理能力但带来显著计算开销。现有token导向方法（如剪枝和跳过）存在加速潜力有限、代理信号过时、冗余干扰等问题，导致速度-精度权衡不理想。

Method: 提出SPTS框架：1) 部分注意力探测(PAP)通过部分前向注意力计算选择信息丰富的token；2) 低秩变换探测(LTP)构建低秩代理网络预测token变换；3) 多阶段延迟剪枝(MSDP)重新分配跳过预算并跨层逐步剪枝冗余token。

Result: 实验证明方法有效，实现预填充最高2.46倍加速和端到端生成2.29倍加速，同时保持最先进的模型性能。

Conclusion: SPTS通过创新的组件特定策略解决了长上下文LLM推理的效率问题，在保持性能的同时显著加速推理过程，为高效长上下文推理提供了有效解决方案。

Abstract: Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\times$ and 2.29$\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.

</details>


### [104] [Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages](https://arxiv.org/abs/2601.13178)
*Joseph Gatto,Parker Seegmiller,Timothy Burdick,Philip Resnik,Roshnik Rahat,Sarah DeLozier,Sarah M. Preum*

Main category: cs.CL

TL;DR: 提出了首个大规模公开数据集PMR-Bench，用于研究基于异步门诊门户消息的医疗分诊任务，将患者消息分诊建模为成对推理问题，并开发了两种模型UrgentSFT和UrgentReward来评估医疗紧急程度。


<details>
  <summary>Details</summary>
Motivation: 医疗分诊是根据医疗需求分配资源和优先处理患者的重要任务，但目前缺乏大规模公开数据集来研究基于异步门诊门户消息的分诊问题，需要开发能够有效评估患者消息医疗紧急程度的AI系统。

Method: 将患者消息分诊建模为成对推理问题，创建PMR-Bench数据集（1569条独特消息和2000+高质量测试对），开发自动化数据标注策略，训练两种模型：UrgentReward（基于Bradley-Terry目标）和UrgentSFT（基于下一词预测目标）。

Result: UrgentSFT在PMR-Bench上表现最佳，UrgentReward在低资源设置中具有优势。UrgentSFT-8B和UrgentReward-8B相比现成的8B模型，在收件箱排序指标上分别提升15和16个百分点。

Conclusion: 该研究为医疗分诊任务提供了首个大规模公开数据集和有效的模型方法，展示了LLMs在评估患者消息医疗紧急程度方面的潜力，为实际医疗场景中的消息优先级排序提供了实用解决方案。

Abstract: Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `"which message is more medically urgent" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.
  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage

</details>


### [105] [OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand](https://arxiv.org/abs/2601.13183)
*Sergio Servantez,Sarah B. Lawsky,Rajiv Jain,Daniel W. Linna,Kristian Hammond*

Main category: cs.CL

TL;DR: OpenExempt是一个用于法律推理诊断评估的框架和基准，通过专家构建的美国破产法法规符号表示动态生成自然语言推理任务，包含9,765个样本，能够精细控制任务复杂度并隔离测试特定推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有推理基准存在局限性：静态问答对只能提供性能快照，将复杂行为压缩为单一准确率指标。在法律等复杂规则领域，现有基准构建成本高且难以隔离特定失败模式。

Method: 使用专家构建的美国破产法法规符号表示，动态生成大量自然语言推理任务及其机器可计算解决方案。框架允许用户精细控制任务复杂度和范围，能够隔离测试个体推理技能。

Result: 构建了包含9,765个样本的OpenExempt基准，涵盖9个评估套件。在13个多样化语言模型上的实验显示，在较长推理路径和存在混淆语句时会出现明显的性能悬崖。

Conclusion: OpenExempt框架和基准为理解和改进下一代推理系统提供了支持，能够进行诊断性评估并揭示语言模型在复杂法律推理中的具体失败模式。

Abstract: Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.

</details>


### [106] [Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision](https://arxiv.org/abs/2601.13217)
*Bingsen Chen,Boyan Li,Ping Nie,Yuyu Zhang,Xi Ye,Chen Zhao*

Main category: cs.CL

TL;DR: Mr Dre评估套件揭示深度研究代理在多轮报告修订中存在显著局限：尽管能响应用户反馈，但会破坏16-27%的已有内容，且无法保持早期编辑成果。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究代理基准将报告生成视为单次写作任务，这与人类研究者通过自我反思或同行反馈迭代起草和修订报告的方式存在根本差异。深度研究代理是否能可靠地根据用户反馈修订报告尚未被探索。

Method: 引入Mr Dre评估套件，包括：(1)统一的长篇报告评估协议，涵盖全面性、事实性和呈现质量；(2)人工验证的反馈模拟管道，用于多轮修订评估。分析了五个不同的深度研究代理。

Result: 深度研究代理存在关键局限：虽然能处理大部分用户反馈，但会破坏16-27%先前已覆盖的内容和引文质量。即使在多轮修订后，最佳代理仍有显著改进空间，会干扰反馈范围外的内容，且无法保持早期编辑成果。提示工程和专用修订子代理等推理时修复方法无法轻易解决这些问题。

Conclusion: 多轮报告修订是深度研究代理评估的重要新维度，现有代理在此方面存在系统性缺陷，需要更根本的解决方案来支持迭代式研究写作过程。

Abstract: Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.

</details>


### [107] [Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation](https://arxiv.org/abs/2601.13228)
*Tianqi Du,Lizhe Fang,Weijie Yang,Chenheng Zhang,Zeming Wei,Yifei Wang,Yisen Wang*

Main category: cs.CL

TL;DR: 提出A3框架，将自回归模型扩展为任意顺序、任意子集的生成，结合扩散模型的灵活性，同时保持自回归模型的深度建模优势。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然支持任意顺序生成和双向条件化，但单步依赖限制建模深度，导致样本质量和稳定性不如自回归模型。需要结合两者优势。

Method: 提出A3框架，将标准自回归分解扩展到任意token组和生成顺序。采用双流注意力架构和渐进适应策略，将预训练自回归模型转换为任意顺序预测。

Result: 在问答、常识推理和故事填充任务上，A3优于基于扩散的模型，同时保持灵活的生成能力。

Conclusion: A3提供了一个统一框架，实现了灵活、高效、新颖的语言建模范式，结合了自回归的深度建模和扩散模型的生成灵活性。

Abstract: Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.

</details>


### [108] [Aligning Agentic World Models via Knowledgeable Experience Learning](https://arxiv.org/abs/2601.13247)
*Baochang Ren,Yunzhi Yao,Rui Sun,Shuofei Qiao,Ningyu Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: WorldMind框架通过构建符号化世界知识库来弥合LLMs的语义知识与物理世界规则之间的鸿沟，解决物理幻觉问题，实现跨模型和跨环境的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型存在模态断层：拥有丰富的语义知识但缺乏对物理世界不可变法则的程序性理解，导致产生物理上不可执行的计划（物理幻觉）。现有对齐策略依赖资源密集的训练或微调，难以适应物理动态的开放变化。

Method: 引入WorldMind框架，自主构建符号化世界知识库，通过整合环境反馈来统一过程经验（通过预测误差强制执行物理可行性）和目标经验（通过成功轨迹指导任务最优性）。

Result: 在EB-ALFRED和EB-Habitat上的实验表明，WorldMind相比基线方法取得了优越性能，并表现出显著的跨模型和跨环境可迁移性。

Conclusion: WorldMind通过构建符号化世界知识库有效解决了LLMs的物理幻觉问题，提供了一种无需持续昂贵重训练就能适应物理动态变化的灵活方法，具有很好的可迁移性。

Abstract: Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.

</details>


### [109] [Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph](https://arxiv.org/abs/2601.13251)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 提出大规模语义聚类系统，解决神经嵌入无法区分同义词和反义词的问题，通过三路语义关系判别器和软到硬聚类算法生成290万高精度语义簇。


<details>
  <summary>Details</summary>
Motivation: 神经嵌入存在明显缺陷：无法可靠区分同义词和反义词。提高相似度阈值往往无法防止反义词被归为一类，特别是在形态丰富和低资源语言中，现有同义词数据库稀疏，需要更精确的语义聚类方法。

Method: 1. 构建84.3万概念对数据集（同义、反义、同下位关系），使用Gemini 2.5-Flash LLM增强和人工词典验证；2. 提出三路语义关系判别器，实现90%宏F1分数；3. 提出新颖的软到硬聚类算法，采用拓扑感知的两阶段扩展-剪枝过程，防止语义漂移和错误传递链。

Result: 处理1500万个词汇项，评估5.2亿个潜在关系，最终生成290万个高精度语义簇。系统在语义关系判别上达到90%宏F1分数，能够有效区分同义词和反义词，解决多义词问题。

Conclusion: 该系统显著提升了语义聚类的精度，特别适用于形态丰富和低资源语言，为高精度语义搜索和检索增强生成提供了有效资源，解决了传统神经嵌入在区分同义词和反义词方面的根本缺陷。

Abstract: Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.

</details>


### [110] [A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus](https://arxiv.org/abs/2601.13253)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 提出了一种混合方法，用于生成低资源语言的大规模语义关系数据集，并以土耳其语为例构建了包含84.3万语义对的语料库，成本仅65美元。


<details>
  <summary>Details</summary>
Motivation: 解决土耳其语等低资源语言中语义关系数据稀缺的问题，现有资源规模有限且构建成本高昂。

Method: 三阶段混合方法：1) FastText嵌入与凝聚聚类识别语义簇；2) Gemini 2.5-Flash自动分类语义关系；3) 整合词典资源。构建土耳其语语义关系数据集。

Result: 创建了包含84.3万个土耳其语语义对的语料库，覆盖同义词、反义词、共下位词三种关系类型，规模是现有资源的10倍，成本仅65美元。下游任务验证：嵌入模型达到90% top-1检索准确率，分类模型达到90% F1-macro分数。

Conclusion: 该方法可扩展地解决了土耳其语NLP中的数据稀缺问题，并适用于其他低资源语言。数据集和模型已公开。

Abstract: We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.

</details>


### [111] [Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models](https://arxiv.org/abs/2601.13260)
*Sawsan Alqahtani,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Tasnim Mohiuddin,M Saiful Bari*

Main category: cs.CL

TL;DR: 论文主张将分词重新定义为语言模型的核心建模决策而非预处理步骤，提出上下文感知框架，强调分词器与模型的协同设计，以实现更公平、高效、适应性强的语言技术。


<details>
  <summary>Details</summary>
Motivation: 当前分词方法（如BPE）虽然可扩展，但存在与语言结构不对齐、放大偏见、在不同语言和领域中浪费容量等问题。分词作为LLM的基础组件却缺乏理论研究和一致设计，被低估为预处理步骤而非核心建模决策。

Method: 提出上下文感知框架，将分词器与模型进行协同设计，考虑语言、领域和部署需求。强调标准化评估和透明报告，使分词选择可问责、可比较。

Result: 通过将分词视为核心设计问题而非技术后处理，可以开发出更公平、更高效、更具适应性的语言技术。这需要改变当前分词作为预处理步骤的范式。

Conclusion: 分词应被重新定义为语言模型的核心建模决策，通过上下文感知框架、分词器与模型协同设计、标准化评估和透明报告，可以解决现有分词方法的局限性，实现更公平、高效、适应性强的语言技术。

Abstract: Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.

</details>


### [112] [Unlearning in LLMs: Methods, Evaluation, and Open Challenges](https://arxiv.org/abs/2601.13264)
*Tyler Lizzo,Larry Heck*

Main category: cs.CL

TL;DR: 这篇综述论文系统梳理了大语言模型（LLMs）的机器遗忘方法，将现有技术分为数据中心、参数中心、架构中心、混合等策略，并讨论了评估生态系统、关键挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言处理任务中取得了显著成功，但其广泛部署引发了隐私、版权、安全、偏见等方面的迫切担忧。机器遗忘作为一种有前景的范式，可以在不完全重新训练的情况下从已训练模型中选择性移除知识或数据。

Method: 论文采用结构化综述方法，将现有遗忘方法分为五大类：数据中心方法、参数中心方法、架构中心方法、混合方法和其他策略。同时系统回顾了评估生态系统，包括基准测试、指标和数据集。

Result: 论文提供了LLM遗忘方法的全面分类框架，总结了当前评估工具和方法，识别了现有技术的优缺点，为领域发展提供了系统性的参考。

Conclusion: 论文旨在作为开发可靠和负责任的大语言模型遗忘技术的路线图，通过综合当前进展和突出开放方向，推动该领域的发展，以应对LLM部署中的隐私、安全等挑战。

Abstract: Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.

</details>


### [113] [A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification](https://arxiv.org/abs/2601.13288)
*Gonzalo Ariel Meyoyan,Luciano Del Corro*

Main category: cs.CL

TL;DR: 提出一种在LLM推理过程中复用隐藏状态进行轻量级分类的方法，避免使用独立的安全/分类模型，降低延迟和内存占用


<details>
  <summary>Details</summary>
Motivation: 当前生产LLM系统通常使用独立模型处理安全和分类任务，这增加了延迟、显存占用和运维复杂度。作者希望复用LLM推理时已经计算好的隐藏状态，在同一个前向传播中完成分类预测。

Method: 提出两阶段聚合器：1) 在每层内汇总token信息；2) 跨层聚合形成单一分类表示。具体实现包括直接池化、10万参数评分注意力门控，以及最多3500万参数的下采样多头自注意力探针。

Result: 在安全和情感基准测试中，该方法优于仅使用logit的方法（如MULI），与更大的任务专用基线模型表现相当，同时保持接近推理延迟，避免了独立防护模型管道的显存和延迟开销。

Conclusion: 通过复用LLM隐藏状态训练轻量级探针，可以在不增加额外推理成本的情况下实现有效的分类任务，为生产LLM系统提供更高效的分类解决方案。

Abstract: Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.

</details>


### [114] [OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference](https://arxiv.org/abs/2601.13300)
*Yow-Fu Liou,Yu-Chien Tang,Yu-Hsiang Liu,An-Zi Yen*

Main category: cs.CL

TL;DR: 提出OI-Bench基准测试，通过在多选题界面注入误导性指令选项，系统评估大语言模型对指令干扰的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大语言模型的决策容易受到社交线索、框架效应和指令等导向信号的影响，需要系统评估模型在标准化选择题界面中对指令干扰的脆弱性。

Method: 提出"选项注入"方法，在标准多选题界面中添加包含误导性指令的额外选项；构建OI-Bench基准，包含3000个涵盖知识、推理和常识任务的问题，涉及16种指令类型（社交遵从、奖励框架、威胁框架、指令干扰）。

Result: 评估12个大语言模型，发现模型存在显著脆弱性且鲁棒性差异很大；攻击成功率、行为响应分析显示模型易受指令干扰；研究了从推理时提示到训练后对齐等多种缓解策略。

Conclusion: OI-Bench能够支持更系统评估大语言模型在基于选择的界面中对指令干扰的鲁棒性，揭示了模型的重要安全漏洞，为未来模型改进提供了评估框架。

Abstract: Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.

</details>


### [115] [Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse](https://arxiv.org/abs/2601.13317)
*Samantha Sudhoff,Pranav Perumal,Zhaoqing Wu,Tunazzina Islam*

Main category: cs.CL

TL;DR: 比较分析Meta付费广告和Bluesky公共帖子中的气候话语，提出可解释的主题发现框架，发现平台激励机制影响气候叙事的主题结构、立场对齐和时间响应性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常孤立分析不同平台的气候话语，难以区分机构信息与公众表达。需要比较付费广告生态系统（激励针对性战略说服）和公共社交媒体平台（主要是有机用户驱动话语）的差异。

Method: 提出可解释的端到端主题发现和分配框架：通过语义相似性聚类文本，利用大语言模型生成简洁、人类可理解的主题标签。在2024年7月至2025年9月期间，比较Meta付费广告和Bluesky公共帖子中的气候话语。

Result: 平台级激励机制反映在气候叙事的主题结构、立场对齐和时间响应性中。付费气候信息与公共气候话语存在系统性差异，主题流行度在重大政治事件前后发生变化。

Conclusion: 该框架支持跨异构通信环境的比较叙事分析，揭示了平台激励机制如何塑造气候话语，为理解不同通信环境中的叙事动态提供了方法论和实证见解。

Abstract: Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.

</details>


### [116] [Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology](https://arxiv.org/abs/2601.13319)
*Peter Sullivan,AbdelRahim Elmadany,Alcides Alcoba Inciarte,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 该论文分析了阿拉伯语方言语音数据的异质性，并提出了Arab Voices标准化框架来统一31个数据集，涵盖14种方言，为方言ASR建立了基准。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言语音数据在领域覆盖、方言标注实践和录音条件方面差异很大，这使得跨数据集比较和模型评估变得复杂。需要标准化方法来减少碎片化并支持可复现的评估。

Method: 1. 对广泛使用的阿拉伯语方言语料库进行语言"方言性"的计算分析；2. 分析音频质量的客观代理指标；3. 引入Arab Voices标准化框架，统一访问31个数据集，涵盖14种方言，提供协调的元数据和评估工具；4. 对一系列最新的ASR系统进行基准测试。

Result: 发现数据集在声学条件和方言信号强度及一致性方面存在显著异质性。Arab Voices框架成功整合了多个数据集，并为现代阿拉伯语方言ASR建立了强大的基准。

Conclusion: 阿拉伯语方言语音数据需要超越粗粒度标签的标准化表征。Arab Voices框架通过提供统一访问、协调元数据和评估工具，减少了碎片化，支持可复现的评估，并为方言ASR研究建立了重要基准。

Abstract: Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.

</details>


### [117] [Reducing Tokenization Premiums for Low-Resource Languages](https://arxiv.org/abs/2601.13328)
*Geoffrey Churchill,Steven Skiena*

Main category: cs.CL

TL;DR: 提出一种减少低资源语言tokenization溢价的方法，通过后处理增加词汇表，将多token字符合并为单token，在Llama 3.2 1B模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在现代语言模型中存在显著的tokenization溢价问题，相比英语需要更多token编码相同句子，导致API和能源成本增加、有效上下文窗口减小。

Method: 分析10个流行LM的tokenizer设计，提出后处理词汇表扩展方法，将多token字符合并为单token，在12种低资源语言上应用该方法。

Result: 在Llama 3.2 1B模型上，原始输入和压缩输入的最后隐藏状态通常相似，表明该方法能有效减少tokenization溢价而不显著改变模型表示。

Conclusion: 提出的后处理词汇表扩展方法能有效降低低资源语言的tokenization溢价，为改善多语言模型效率提供了实用解决方案。

Abstract: Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.

</details>


### [118] [RegCheck: A tool for automating comparisons between study registrations and papers](https://arxiv.org/abs/2601.13330)
*Jamie Cummins,Beth Clarke,Ian Hussey,Malte Elson*

Main category: cs.CL

TL;DR: RegCheck是一个模块化的LLM辅助工具，帮助研究人员、审稿人和编辑跨科学领域比较研究注册与对应论文，保持人类专家判断在循环中，并生成可共享的报告。


<details>
  <summary>Details</summary>
Motivation: 尽管研究注册对科学透明度和严谨性有益，但手动检查注册与论文之间的差异既耗时又费力，需要跨格式仔细阅读和跨领域专业知识。AI的发展为促进这一活动提供了新的可能性。

Method: RegCheck采用模块化设计，使用LLM辅助工具：(1) 让用户决定需要比较哪些特征；(2) 向用户展示每个特征最相关的文本，促进而非取代人类差异判断；(3) 生成带有唯一RegCheck ID的可共享报告，便于验证。

Result: RegCheck是一个跨科学领域、注册和出版格式的适应性工具，提供了可扩展的基础设施，通过示例用例展示了其在促进可重复科学方面的潜力。

Conclusion: RegCheck通过保持人类判断在循环中，利用AI辅助检查研究注册与论文的一致性，为跨学科的科学透明度和严谨性提供了实用工具，并具有可扩展性。

Abstract: Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.

</details>


### [119] [AfroScope: A Framework for Studying the Linguistic Landscape of Africa](https://arxiv.org/abs/2601.13346)
*Sang Yun Kwon,AbdelRahim Elmadany,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: AfroScope是一个统一的非洲语言识别框架，包含覆盖713种非洲语言的数据集和强大的语言识别模型，通过分层分类方法提升对高度相似语言的区分能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别方法对非洲语言的支持有限，覆盖语言数量不足，且难以区分密切相关的语言变体，这影响了下游NLP应用的可靠性。

Method: 提出AfroScope框架，包括AfroScope-Data数据集和AfroScope-Models模型套件；针对高度相似的语言，提出分层分类方法，利用专门针对29种密切相关的语言训练的Mirror-Serengeti嵌入模型。

Result: 在高度相似的语言子集上，分层分类方法相比最佳基础模型将宏平均F1提高了4.55；分析了跨语言迁移和领域效应，为构建稳健的非洲语言识别系统提供指导。

Conclusion: AfroScope作为非洲语言识别的使能技术，支持大规模测量非洲数字文本中的语言景观；公开发布了AfroScope-Data和AfroScope-Models。

Abstract: Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.

</details>


### [120] [LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction](https://arxiv.org/abs/2601.13352)
*Yuxing Lu,J. Ben Tamo,Weichen Zhao,Nan Sun,Yishan Zhong,Wenqi Shi,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: LLM-as-RNN：将冻结的大型语言模型转变为具有自然语言记忆的循环预测器，通过反馈驱动的文本重写实现无参数更新的在线学习


<details>
  <summary>Details</summary>
Motivation: 标准LLM推理使用不可变的上下文历史，一旦在生成步骤t出错，模型缺乏可更新的记忆机制来改进步骤t+1的预测。需要一种方法让LLM能够在线学习而不更新参数。

Method: 提出LLM-as-RNN框架，将冻结LLM转变为循环预测器，用自然语言记忆表示隐藏状态（结构化系统提示摘要），通过反馈驱动的文本重写在每个时间步更新状态，实现无参数更新的学习。

Result: 在医疗、气象和金融三个顺序基准测试中，LLM-as-RNN显著优于零样本、完整历史和MemPrompt基线，平均预测准确率提高6.5%，同时产生可解释的人类可读学习轨迹。

Conclusion: LLM-as-RNN通过将LLM转变为具有自然语言记忆的循环预测器，实现了有效的在线学习，无需参数更新，在固定token预算下纠正错误并保留任务相关模式，为LLM推理提供了新的范式。

Abstract: Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.

</details>


### [121] [Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection](https://arxiv.org/abs/2601.13359)
*Asen Dotsinski,Panagiotis Eustratiadis*

Main category: cs.CL

TL;DR: 提出一种名为"sockpuppetting"的简单越狱方法，通过在模型输出开头插入接受序列（如"Sure, here is how to..."）来攻击开源大语言模型，无需优化且仅需一行代码，攻击成功率显著高于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型能力增强，保护它们免受恶意提示攻击和理解可能的攻击向量变得日益重要。现有自动化越狱方法如GCG需要大量计算资源和专业知识，需要更简单有效的攻击方法。

Method: 提出"sockpuppetting"方法：在模型输出开头插入接受序列（如"Sure, here is how to..."），然后让模型完成响应。还探索了混合方法，在助手消息块内优化对抗后缀而不是用户提示。

Result: sockpuppetting在Qwen3-8B上比GCG攻击成功率提高80%（逐提示比较）。混合方法在Llama-3.1-8B上比GCG攻击成功率提高64%（提示无关设置）。

Conclusion: sockpuppetting是一种有效的低成本攻击方法，即使非专业攻击者也能使用，突显了开源模型需要防御输出前缀注入攻击的重要性。

Abstract: As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce "sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., "Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.

</details>


### [122] [Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.13368)
*Zhenjiang Mao,Anirudhh Venkat*

Main category: cs.CL

TL;DR: 提出一种新方法，通过分析推理步骤间的语义关联和历史置信度信息，更准确地评估大语言模型推理过程的不确定性，在数学和因果推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理任务上表现优异，但评估答案不确定性仍具挑战性。现有方法分析推理序列时忽略了置信度的时间分布，可能导致早期步骤置信度很低但整体置信度虚高的问题。

Method: 提出结合步骤间注意力分析语义关联的方法，并引入隐藏置信度机制来保留历史置信度信息，将历史置信度与步骤置信度结合得到更准确的整体估计。

Result: 在GAOKAO数学基准和CLadder因果推理数据集上评估，使用主流开源大语言模型，方法在负对数似然和期望校准误差指标上表现优异，在预测质量和校准之间达到更好平衡。

Conclusion: 通过考虑推理步骤间的语义关联和历史置信度信息，能够更准确地评估大语言模型推理过程的不确定性，减少误导性幻觉，优于现有最先进方法。

Abstract: As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.

</details>


### [123] [Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning](https://arxiv.org/abs/2601.13387)
*Zhenjiang Mao,Anirudhh Venkat,Artem Bisliouk,Akshat Kothiyal,Sindhura Kumbakonam Subramanian,Saithej Singhu,Ivan Ruchkin*

Main category: cs.CL

TL;DR: 提出使用信号时序逻辑（STL）分析LLM推理过程中的逐步置信度信号，通过STL挖掘发现区分正确与错误响应的时序模式，并开发基于超网络的置信度估计方法，在多任务上实现更好的校准。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法通常将整个推理过程简化为单一标量分数，忽略了置信度在生成过程中的演变，导致对表面因素（如响应长度）敏感，难以区分正确推理与自信陈述的错误。

Method: 使用信号时序逻辑（STL）表征逐步置信度信号，通过判别式STL挖掘程序发现区分正确与错误响应置信度信号的时序公式，并基于超网络参数化STL模块开发置信度估计方法。

Result: 实验发现STL模式在不同任务间具有通用性，数值参数对具体问题敏感。在多个推理任务上的实验表明，该方法产生的置信度分数比基线方法更校准。

Conclusion: 通过STL分析逐步置信度信号能更好地捕捉LLM推理过程中的置信度演变，提出的方法在多个任务上实现了更准确的置信度估计，有助于区分正确推理与自信错误。

Abstract: Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.

</details>


### [124] [Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction](https://arxiv.org/abs/2601.13388)
*Sasha Ronaghi,Prerit Choudhary,David H Rehkopf,Bryant Lin*

Main category: cs.CL

TL;DR: 利用大语言模型从糖尿病患者生活故事中提取结构化社会健康决定因素，并评估其对糖尿病控制的预测价值


<details>
  <summary>Details</summary>
Motivation: 社会健康决定因素在2型糖尿病管理中至关重要，但电子健康记录和风险预测模型中往往缺少这些信息。现有的结构化筛查工具缺乏灵活性，无法捕捉患者经历的复杂性和诊所人群的独特需求。

Method: 收集65名65岁以上2型糖尿病患者的非结构化访谈，使用检索增强生成的大语言模型分析叙事，生成临床可解释的定性摘要和结构化定量SDOH评分，结合传统实验室生物标志物构建机器学习模型预测糖尿病控制水平。

Result: 大语言模型能够从访谈文本中预测糖尿病控制水平，准确率达到60%。结构化SDOH评分与传统生物标志物结合可用于常规风险预测工作流程。

Conclusion: 大语言模型可以将非结构化SDOH相关数据转化为结构化洞察，为增强临床风险模型和决策制定提供可扩展的方法。

Abstract: Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.

</details>


### [125] [Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks](https://arxiv.org/abs/2601.13392)
*Shlok Shelat,Jay Raval,Souvik Roy,Manas Gaur*

Main category: cs.CL

TL;DR: LLMs在DFA构造任务中表现良好，但在未见问题上的准确率显著下降，暴露了形式推理能力的根本缺陷


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在形式语言任务中的表现是真正的符号推理还是对熟悉结构的模式匹配，评估其在DFA构造任务中的实际推理能力

Method: 引入DFA构造基准测试，包含事实性问题、公开来源的已见问题、手工制作的多约束未见问题以及通过Arden定理系统生成的未见问题；评估多种提示策略（直接、思维链、思维树）和三阶段提示协议

Result: 模型在事实性问题上准确率完美，在已见任务上达到84-90%，但在未见问题上准确率下降30-64%；错误源于对语言约束的系统性误解、Kleene星号语义处理错误以及全局一致性保持失败；提示策略无法解决根本错误

Conclusion: LLMs在生成语法上合理的DFA与进行语义正确的形式推理之间存在根本差距，提示策略无法解决深层推理缺陷，暴露了LLMs形式推理能力的局限性

Abstract: Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.

</details>


### [126] [Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models](https://arxiv.org/abs/2601.13433)
*Priyanka Mary Mammen,Emil Joswin,Shankar Venkitachalam*

Main category: cs.CL

TL;DR: 语言模型在推理任务中会受到建议和认可的影响，但认可来源的可信度影响尚未充分研究。研究发现模型对专家认可存在系统性偏见，专家认可会降低准确性并增加错误答案的置信度。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明语言模型在推理任务中的表现会受到建议、提示和认可的影响，但认可来源的可信度（特别是提供者的专业知识水平）如何影响模型决策尚未得到充分探索。

Method: 在数学、法律和医学推理4个数据集上评估11个模型，使用代表四个专业知识水平的人物角色，研究模型对不同专业知识来源的认可的系统性偏见。

Result: 模型对错误/误导性认可的敏感性随来源专业知识水平增加而增加，高权威来源不仅导致准确性下降，还增加对错误答案的置信度。这种权威偏见在模型中具有机制性编码。

Conclusion: 语言模型存在权威偏见，但可以通过引导模型远离这种偏见来改善性能，即使在专家给出误导性认可的情况下也能提高表现。

Abstract: Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.

</details>


### [127] [MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization](https://arxiv.org/abs/2601.13437)
*Adriana-Valentina Costache,Daria-Nicoleta Dragomir,Silviu-Florin Gheorghe,Eduard Poesina,Paul Irofti,Radu Tudor Ionescu*

Main category: cs.CL

TL;DR: 该论文提出了首个多语言开放集学习与发现（MOSLD）基准，用于文本主题分类，包含12种语言的96万数据样本，并提出了一个集成多阶段的新框架来持续发现和学习新类别。


<details>
  <summary>Details</summary>
Motivation: 开放集学习与发现（OSLD）是一个具有挑战性的机器学习任务，其中测试时可能出现来自新（未知）类别的样本。虽然零样本学习在文本分类中已被广泛研究，但开放集学习与发现对于文本领域来说是一个相对较新的设置，需要建立基准来推动该领域的研究。

Method: 1）通过重新整理现有数据集和从新闻领域收集新数据样本，构建了包含12种语言、96万数据样本的多语言开放集学习与发现基准；2）提出了一个新颖的OSLD框架，该框架集成了多个阶段来持续发现和学习新类别。

Result: 评估了包括作者自己提出的模型在内的多种语言模型，获得了可作为未来工作参考的结果。基准数据集已公开发布在GitHub上。

Conclusion: 该研究为文本领域的开放集学习与发现任务建立了首个多语言基准，并提出了有效的多阶段框架，为未来研究提供了重要的参考基础。

Abstract: Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.

</details>


### [128] [PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving](https://arxiv.org/abs/2601.13453)
*Aditya Thole,Anmol Agrawal,Arnav Ramamoorthy,Dhruv Kumar*

Main category: cs.CL

TL;DR: PSA是一个自主代理，使用Manim动画生成长达6分钟的物理解释视频，通过自动化评估管道和视觉语言模型反馈迭代改进视频质量。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在文本物理问题上有良好表现，但生成高质量视觉解释的能力尚未充分探索。视觉推理能显著提升物理概念理解，而现有系统在这方面的能力不足。

Method: 开发PhysicsSolutionAgent（PSA）自主代理，使用Manim动画生成物理解释视频。设计包含15个定量参数的自动化评估管道，结合视觉语言模型反馈迭代改进视频质量。

Result: 在32个视频评估中，PSA使用GPT-5-mini实现100%视频完成率，平均自动化评分3.8/5。但定性分析和人工检查发现视觉布局不一致、视觉内容解释错误等问题，显示系统在可靠Manim代码生成和多模态推理方面存在局限。

Conclusion: 该研究揭示了可靠Manim代码生成的关键限制，突出了多模态推理和视觉解释评估的挑战，强调未来多模态教育系统需要改进视觉理解、验证和评估框架。

Abstract: Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems

</details>


### [129] [Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives](https://arxiv.org/abs/2601.13503)
*Kyung Ho Lim,Byung-Hoon Kim*

Main category: cs.CL

TL;DR: Anonpsy：一种将精神病学叙事转化为语义图并进行图引导重写的去识别框架，在保持诊断保真度的同时显著降低再识别风险


<details>
  <summary>Details</summary>
Motivation: 现有去识别方法（如PHI掩码和LLM合成重写）在文本层面操作，对保留或改变哪些语义元素控制有限。精神病学叙事不仅包含显式标识符，还通过嵌入临床结构中的独特生活事件编码患者身份。

Method: 1) 将叙事转换为编码临床实体、时间锚点和类型化关系的语义图；2) 应用图约束扰动，修改识别上下文同时保留临床必需结构；3) 通过图条件LLM生成重新生成文本

Result: 在90个临床医生撰写的精神病学案例叙事上评估，Anonpsy在保持诊断保真度的同时，在专家、语义和GPT-5评估中实现了一致的低再识别风险。相比强大的LLM-only重写基线，Anonpsy产生显著更低的语义相似性和可识别性

Conclusion: 显式结构表示与约束生成相结合，为精神病学叙事的去识别提供了有效方法

Abstract: Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.

</details>


### [130] [When Wording Steers the Evaluation: Framing Bias in LLM judges](https://arxiv.org/abs/2601.13537)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Minwoo Lee,Kyomin Jung*

Main category: cs.CL

TL;DR: 研究发现LLM评估存在框架偏差，提示词的正负表述会显著影响模型判断，这是当前LLM评估系统的结构性缺陷


<details>
  <summary>Details</summary>
Motivation: LLM对提示词的细微变化会产生不同响应，但框架偏差对LLM评估任务的影响尚未充分研究。心理学中的框架效应表明表述方式会影响判断，作者希望系统研究提示词框架如何影响LLM在高风险评估任务中的判断稳定性

Method: 采用心理学中的框架效应概念，设计对称提示词（谓词-肯定和谓词-否定结构），在四个高风险评估任务中系统研究提示词框架如何影响模型判断。使用14个不同的LLM作为评估者进行实验

Result: 研究发现：1）框架偏差显著影响LLM输出，导致判断不一致；2）不同模型家族对框架偏差表现出不同的敏感度倾向（同意或拒绝）；3）框架偏差是当前LLM评估系统的结构性特征

Conclusion: 框架偏差是LLM评估系统的固有缺陷，需要开发框架感知的评估协议来确保评估的稳定性和公正性

Abstract: Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.

</details>


### [131] [HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations](https://arxiv.org/abs/2601.13547)
*Yujia Hu,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: HateXScore是一个评估仇恨言论检测模型解释质量的四组件指标套件，旨在揭示标准指标无法发现的解释性失败和标注不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前仇恨言论检测评估框架很少评估文本为何被判定为仇恨言论，缺乏对模型解释质量的系统性评估方法。

Method: 提出HateXScore四组件指标：1)结论明确性；2)引用文本的忠实性和因果基础；3)受保护群体识别（可配置）；4)这些元素间的逻辑一致性。

Result: 在六个不同的仇恨言论数据集上评估，HateXScore能揭示标准指标（如准确率、F1分数）无法发现的解释性失败和标注不一致问题。人工评估显示与HateXScore有很强的一致性。

Conclusion: HateXScore可作为诊断性补充工具，用于提高内容审核的可信度和透明度，为模型解释质量提供实用评估方法。

Abstract: Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.
  \textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}

</details>


### [132] [Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews](https://arxiv.org/abs/2601.13575)
*Thanh-Lam T. Nguyen,Ngoc-Quang Le,Quoc-Trung Phu,Thi-Phuong Le,Ngoc-Huyen Pham,Phuong-Nguyen Nguyen,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: SUDO数据集用于隐式比较观点挖掘，包含4,150个标注评论对，通过双层次结构捕捉方面级提及和评论级偏好，为无显式比较线索的用户偏好推断提供基准。


<details>
  <summary>Details</summary>
Motivation: 现有比较观点挖掘研究主要关注显式比较表达，但在真实评论中不常见，而隐式比较（用户在不同评论中表达偏好）尚未充分探索，需要专门数据集来研究。

Method: 提出SUDO数据集，包含4,150个标注评论对（15,191个句子），采用双层次结构：方面级提及和评论级偏好。使用两种基线架构：传统机器学习方法和语言模型方法。

Result: 语言模型基线优于传统机器学习方法，但整体性能仍中等，表明任务具有固有难度，SUDO成为未来研究的具有挑战性和价值的基准。

Conclusion: SUDO数据集填补了隐式比较观点挖掘的研究空白，为无显式比较线索的用户偏好推断提供了可靠基准，尽管当前方法性能有限，但为未来研究奠定了基础。

Abstract: Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.

</details>


### [133] [TREX: Tokenizer Regression for Optimal Data Mixture](https://arxiv.org/abs/2601.13588)
*Inho Won,Hangyeol Yoo,Minkyung Cho,Jungyeul Park,Hoyun Song,KyungTae Lim*

Main category: cs.CL

TL;DR: TREX框架通过回归模型预测多语言分词器训练的最优数据混合比例，避免传统启发式或大规模搜索方法，提升分词器压缩效率达12%。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型的分词器需要优化语言数据混合比例，传统方法依赖启发式规则或成本高昂的大规模搜索，缺乏高效准确的优化方案。

Method: 提出TREX回归框架：训练小规模代理分词器收集压缩统计数据，学习从数据混合到压缩性能的预测模型，实现大规模分词器训练前的可扩展混合比例搜索。

Result: TREX预测的混合比例训练的分词器，在分布内和分布外压缩效率上比LLaMA3和均匀分布方法提升达12%，展现出强可扩展性、鲁棒性和实际有效性。

Conclusion: TREX框架通过回归建模有效解决了多语言分词器数据混合优化的准确性与成本权衡问题，为高效分词器设计提供了可扩展的解决方案。

Abstract: Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.

</details>


### [134] [Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions](https://arxiv.org/abs/2601.13590)
*Fan Huang,Haewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: LLMs易受说服影响，不同模型在SMCR框架下表现出不同的脆弱性，元认知提示反而增加脆弱性，对抗性微调效果因模型而异。


<details>
  <summary>Details</summary>
Motivation: LLMs在各种问答任务中被广泛应用，但研究表明它们容易受到说服并可能采纳反事实信念。需要系统评估LLMs在说服下的脆弱性，了解不同模型和干预措施的效果。

Method: 使用SMCR（来源-信息-渠道-接收者）沟通框架，在五个主流LLMs和三个领域（事实知识、医疗QA、社会偏见）中评估说服脆弱性。分析不同说服策略对多轮交互中信念稳定性的影响，测试元认知提示（引出自我报告的信心）是否影响抵抗说服的能力，并评估对抗性微调作为防御措施的效果。

Result: 1) 较小模型表现出极端顺从，超过80%的信念变化发生在第一轮说服中（平均结束轮次1.1-1.4）；2) 元认知提示反而增加脆弱性，加速信念侵蚀而非增强鲁棒性；3) 对抗性微调效果因模型而异：GPT-4o-mini达到接近完全鲁棒性（98.6%），Mistral 7B显著改善（35.7%→79.3%），但Llama模型即使在自己的失败案例上微调后仍然高度脆弱（<14%）。

Conclusion: 当前鲁棒性干预措施存在显著的模型依赖性限制，这些发现为开发更可信的LLMs提供了指导。需要针对不同模型设计更有效的防御策略。

Abstract: Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.

</details>


### [135] [CauScientist: Teaching LLMs to Respect Data for Causal Discovery](https://arxiv.org/abs/2601.13614)
*Bo Peng,Sirui Chen,Lei Xu,Chaochao Lu*

Main category: cs.CL

TL;DR: CauScientist是一个结合LLM假设生成和概率统计验证的因果发现框架，通过混合初始化、迭代优化和错误记忆机制，显著提升因果图构建性能。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法存在局限：纯数据驱动方法受统计不可区分性和建模假设影响，而基于LLM的方法要么忽略统计证据，要么引入未经验证的先验知识可能误导结果。

Method: 提出CauScientist框架：1) 混合初始化选择优质起始图；2) LLM作为"数据科学家"生成假设修改，概率统计作为"验证者"严格评估；3) 迭代优化结构，维护错误记忆指导搜索空间。

Result: 实验显示CauScientist显著优于纯数据驱动基线：F1分数提升高达53.8%，召回率从35.0%提升至100.0%。在37节点图上，相比Qwen3-32B将结构汉明距离(SHD)降低44.0%。

Conclusion: CauScientist通过LLM与概率统计的协同合作，克服了现有方法的局限性，实现了更可靠、高效的因果发现，为科学理解和可靠决策提供了有力工具。

Abstract: Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating "data scientists" with probabilistic statistics as rigorous "verifiers". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.

</details>


### [136] [Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models](https://arxiv.org/abs/2601.13630)
*Zhaopeng Zhang,Pengcheng Sun,Lan Zhang,Chen Tang,Jiewei Lai,Yunhao Wang,Hui Jin*

Main category: cs.CL

TL;DR: AAAC：基于激活空间锚点的免训练访问控制框架，通过几何规律在多权限场景下防止LLM越权回答


<details>
  <summary>Details</summary>
Motivation: LLMs在知识库问答中可能无意中泄露超出用户权限范围的敏感信息，难以满足细粒度访问控制需求

Method: 提出AAAC框架：1）发现不同权限范围激活表示的可分离几何规律；2）构建权限锚点库；3）多锚点引导机制重定向查询激活到授权区域

Result: 在三个LLM家族上实验显示：权限违规率降低86.5%，基于提示的攻击成功率降低90.7%，响应可用性提升，推理开销小

Conclusion: AAAC提供了一种免训练的细粒度访问控制解决方案，有效防止LLM越权回答，具有实际部署价值

Abstract: Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.

</details>


### [137] [Towards Token-Level Text Anomaly Detection](https://arxiv.org/abs/2601.13644)
*Yang Cao,Bicheng Yu,Sikun Yang,Ming Liu,Yujiu Yang*

Main category: cs.CL

TL;DR: 提出token级文本异常检测新范式，能定位文本中具体异常部分，超越传统文档级检测方法


<details>
  <summary>Details</summary>
Motivation: 现有文本异常检测方法（如垃圾邮件过滤、假新闻检测）仅限于文档级分析，无法识别文本中哪些具体部分异常，需要更细粒度的检测能力

Method: 提出token级异常检测范式，定义文档级和token级文本异常，构建统一的多层级检测框架，收集并标注三个基准数据集（垃圾邮件、评论、语法错误）

Result: 实验结果表明，该框架在6个基线方法中表现最佳，为文本中精确异常定位开辟了新可能性

Conclusion: token级异常检测是文本分析的重要进展，实现了细粒度异常定位，代码和数据已开源

Abstract: Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.

</details>


### [138] [Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge](https://arxiv.org/abs/2601.13649)
*Xiaolin Zhou,Zheng Luo,Yicheng Gao,Qixuan Chen,Xiyang Hu,Yue Zhao,Ruishan Liu*

Main category: cs.CL

TL;DR: 研究发现LLM作为评判者在跨语言评估中存在两种语言偏见：同语言比较时欧洲语言表现优于非洲语言，跨语言比较时模型偏好英语回答，且这种偏见不完全由困惑度偏差解释。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM作为评判者被广泛应用，但先前研究表明其存在多种偏见，其中语言偏见会影响评估结果的公正性。本研究旨在系统分析LLM-as-a-judge中的语言偏见问题，特别是跨语言评估时的表现差异。

Method: 研究分析了两种语言偏见：(1) 同语言比较时的性能差异，比较不同语言家族（欧洲vs非洲语言）在相同语言内的表现；(2) 跨语言比较时的偏见，当评判者需要比较不同语言选项时的偏好。同时探讨了语言偏见与低困惑度偏见的关系。

Result: 同语言评判中，欧洲语言表现显著优于非洲语言，尤其在文化相关主题上差异更明显。跨语言评判中，大多数模型偏好英语回答，且答案语言比问题语言对偏好影响更大。语言偏见与困惑度仅有弱相关，不能完全由困惑度偏差解释。

Conclusion: LLM作为评判者存在显著的语言偏见，这些偏见在不同语言家族间和跨语言比较中均有体现。语言偏见不能简单归因于困惑度差异，表明需要更深入理解LLM评估机制中的系统性偏见，并开发更公平的评估方法。

Abstract: Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.

</details>


### [139] [Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation](https://arxiv.org/abs/2601.13658)
*Arthur Amalvy,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 提出一个基于未来预测事实的合成评估数据集，用于解决时间知识图谱抽取任务中数据污染和数据集稀缺问题


<details>
  <summary>Details</summary>
Motivation: 时间知识图谱抽取（TKGE）对构建大规模网络知识库（如Wikidata）很重要，但现有训练和评估数据集稀缺，且存在数据污染问题（训练集与评估集重叠），这可能导致LLMs性能被高估

Method: 采用两步法创建合成评估数据集：1）时间知识图谱预测（TKGF）生成合理的未来四元组，并过滤以符合原始知识库模式；2）LLMs执行四元组到文本生成，创建语义对齐的文本描述

Result: 构建了包含4.2K个未来四元组及对应文本描述的数据集，基准测试显示LLM在未知未来事实上的性能低于已知事实数据集

Conclusion: 提出的合成数据集解决了数据污染问题，提供了稳健无偏的基准测试，并公开了数据集和生成方法，支持持续创建无限未来时间数据集作为TKGE的长期无污染基准

Abstract: The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.

</details>


### [140] [Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis](https://arxiv.org/abs/2601.13659)
*Chunlei Meng,Ziyang Zhou,Lucas He,Xiaojing Du,Chun Ouyang,Zhongxue Gan*

Main category: cs.CL

TL;DR: TSDA提出时空解耦方法，在模态交互前将每个模态分解为时间动态和空间结构上下文，通过因子一致跨模态对齐提升多模态情感分析性能


<details>
  <summary>Details</summary>
Motivation: 现有基于模态不变/特定因子分解或复杂融合的方法依赖时空混合建模，忽略了时空异质性，导致时空信息不对称和性能受限

Method: TSDA（Temporal-Spatial Decouple before Act）：1）将每个模态解耦为时间动态和空间结构上下文；2）因子一致跨模态对齐：时间特征仅与跨模态时间特征对齐，空间特征仅与跨模态空间特征对齐；3）因子特定监督和去相关正则化减少跨因子泄漏；4）门控重耦合模块将对齐后的流重新耦合用于任务

Result: 大量实验表明TSDA优于基线方法，消融分析确认了设计的必要性和可解释性

Conclusion: 通过显式时空解耦和因子一致对齐，TSDA有效解决了多模态情感分析中的时空异质性问题，提升了性能

Abstract: Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.

</details>


### [141] [CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks](https://arxiv.org/abs/2601.13669)
*Jiayu Lin,Zhongyu Wei*

Main category: cs.CL

TL;DR: 提出社区级对齐作为个体级和通用级对齐的中间方案，并创建CommunityBench基准评估LLMs的社区偏好建模能力，发现现有模型在此方面有限，但社区级对齐为可扩展的多元对齐提供方向。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐策略存在两个极端：通用价值假设（忽略少数群体）和个体级定制（成本过高）。人类社会中存在社会集群，组内价值对齐度高，因此需要社区级对齐作为中间方案。

Method: 提出社区级对齐概念，并创建CommunityBench基准，基于共同身份和共同纽带理论设计四个任务，用于评估基础模型对社区特定偏好的建模能力。

Result: 对多种基础模型的评估显示，当前LLMs在建模社区特定偏好方面能力有限。同时发现社区级对齐有助于促进个体建模，为可扩展的多元对齐提供可能。

Conclusion: 社区级对齐是通用对齐和个体对齐之间的有前景的中间方案，CommunityBench基准为评估社区偏好建模能力提供了工具，社区级对齐为实现可扩展的多元对齐开辟了新方向。

Abstract: Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a "middle ground". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.

</details>


### [142] [HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference](https://arxiv.org/abs/2601.13684)
*Zhiyuan Shi,Qibo Qiu,Feng Xue,Zhonglin Jiang,Li Yu,Jian Jiang,Xiaofei He,Wenxiao Wang*

Main category: cs.CL

TL;DR: HeteroCache：无需训练的动态KV缓存压缩框架，通过细粒度权重分配和分层存储机制，解决长上下文LLM推理中的内存瓶颈问题，实现3倍解码加速。


<details>
  <summary>Details</summary>
Motivation: KV缓存线性内存增长是长上下文LLM推理的主要瓶颈。现有静态压缩方法无法保留全局重要信息，因为它们忽略了注意力漂移现象（token重要性动态变化）。动态检索方法虽然尝试解决，但通常存在粗粒度缓存策略和高I/O开销问题。

Method: 基于两个关键观察：注意力头具有不同的时间异质性，同一层内头之间存在显著空间冗余。HeteroCache根据稳定性和冗余性对头进行分类，采用细粒度权重分配策略，为注意力快速变化的头分配更大缓存预算。同时使用分层存储机制，让代表性头子集监控注意力变化，触发异步按需从CPU检索上下文，有效隐藏I/O延迟。

Result: 在多个长上下文基准测试中实现最先进性能，在224K上下文长度下相比原始模型解码速度提升高达3倍。

Conclusion: HeteroCache通过动态压缩框架有效解决了KV缓存内存瓶颈，无需训练即可显著提升长上下文LLM推理效率，代码将开源。

Abstract: The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\times$ compared to the original model in the 224K context. Our code will be open-source.

</details>


### [143] [Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning](https://arxiv.org/abs/2601.13690)
*Yue Guo,Fanfu Wang,Jianwei Lv,Xincheng Shi,Yuchen Li,Youya Wang,Yunsheng Zeng,Yujing Liu,Yunhao Qiao,Gen Li,Junfeng Wang,Bo Yuan*

Main category: cs.CL

TL;DR: 提出Dr. Assistant临床诊断模型，通过两阶段训练（SFT+RL）提升LLM在临床诊断推理和问询能力，优于开源模型并与闭源模型竞争


<details>
  <summary>Details</summary>
Motivation: 传统临床决策支持系统维护成本高、泛化能力差，而大型语言模型虽在医疗领域有广泛应用，但其诊断推理和问询能力受限

Method: 提出临床诊断推理数据结构（CDRD）及其构建流程，开发Dr. Assistant模型，采用两阶段训练：监督微调（SFT）和强化学习（RL）配合定制奖励函数

Result: Dr. Assistant在诊断推理和问询评估基准上表现优异，超越开源模型，与闭源模型性能相当

Conclusion: Dr. Assistant为临床诊断问询指导提供了有效解决方案，通过结构化临床推理数据和两阶段训练显著提升了LLM的临床诊断能力

Abstract: Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.

</details>


### [144] [OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens](https://arxiv.org/abs/2601.13695)
*Sifan Li,Hongkai Chen,Yujun Cai,Liyang Chen,Qingwen Ye,Yiwei Wang*

Main category: cs.CL

TL;DR: OptiSQL：直接从表格图像和自然语言问题生成可执行SQL的视觉驱动框架，使用光学标记大幅减少输入标记数量


<details>
  <summary>Details</summary>
Motivation: 传统文本到SQL方法需要将表格完全线性化为文本模式，这假设了结构化文本的可访问性并产生大量标记开销，与现实世界中表格作为文档或网页中的视觉元素出现的场景不匹配

Method: OptiSQL框架使用OCR导向的视觉编码器将表格结构和内容压缩为一小组光学标记，冻结编码器以保持表示能力，微调预训练解码器进行SQL生成

Result: 在可视化的Spider 2.0-Snow数据集上，OptiSQL在保持强大执行准确性的同时，将表格输入标记减少了一个数量级；鲁棒性分析显示光学标记在视觉扰动下能保持基本结构信息

Conclusion: 紧凑的光学表示可以作为可执行语义解析的高效接口，视觉驱动的SQL生成方法在减少标记开销的同时保持了准确性，为处理现实世界中的视觉表格提供了新途径

Abstract: Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.

</details>


### [145] [Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning](https://arxiv.org/abs/2601.13697)
*Zhihang Yuan,Chengyu Yue,Long Huang,Litu Ou,Lei Shi*

Main category: cs.CL

TL;DR: GRADFILTERING：一种基于梯度信噪比的不确定性感知数据选择框架，用于高效指令调优


<details>
  <summary>Details</summary>
Motivation: 现代指令数据集规模大、噪声多且冗余，全数据微调成本高且不必要。现有数据选择方法要么构建昂贵的梯度数据存储，要么使用弱代理的静态评分，忽略了模型训练过程中的不确定性变化。

Method: 提出GRADFILTERING框架，使用小型GPT-2代理模型配合LoRA集成，将每个示例的梯度聚合成梯度信噪比（G-SNR）效用分数，实现目标无关、不确定性感知的数据选择。

Result: 在大多数LLM-as-a-judge评估和人工评估中，该方法匹配或优于随机子集和强基线方法。GRADFILTERING选择的子集在相同计算预算下收敛更快。

Conclusion: GRADFILTERING通过不确定性感知评分有效解决了指令调优中的数据选择问题，展示了梯度信噪比作为数据效用度量的有效性。

Abstract: Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.

</details>


### [146] [GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark](https://arxiv.org/abs/2601.13711)
*Lotta Kiefer,Christoph Leiter,Sotaro Takeshita,Elena Schmidt,Steffen Eger*

Main category: cs.CL

TL;DR: GerAV是一个全面的德语作者验证基准数据集，包含超过60万标注文本对，来自Twitter和Reddit数据，用于系统评估德语作者验证模型性能。


<details>
  <summary>Details</summary>
Motivation: 作者验证任务在英语领域已有广泛研究，但其他语言的大规模基准和系统评估仍然稀缺。本文旨在填补德语作者验证领域的这一空白。

Method: 构建GerAV基准数据集，包含Twitter和Reddit数据，其中Reddit部分进一步分为域内、跨域消息子集和基于个人资料的子集。使用提供的训练分割对强基线和最先进模型进行系统评估。

Result: 最佳方法（微调的大型语言模型）比最近基线高出0.09绝对F1分数，在零样本设置中比GPT-5高出0.08。观察到专业化与泛化之间的权衡：在匹配条件下，针对特定数据类型训练的模型表现最佳，但跨数据制度的泛化能力较差，这一限制可以通过组合训练源来缓解。

Conclusion: GerAV为推进德语和跨域作者验证研究提供了一个具有挑战性和多功能的基准，填补了德语作者验证领域的大规模基准空白。

Abstract: Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.

</details>


### [147] [Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff](https://arxiv.org/abs/2601.13717)
*Zehan Li,Yuxuan Wang,Ali El Lahib,Ying-Jieh Xia,Xinyu Pi*

Main category: cs.CL

TL;DR: 模拟无知(SI)无法有效近似真实无知(TI)，提示无法可靠"倒带"模型知识，基于SI的回顾性预测方法存在缺陷


<details>
  <summary>Details</summary>
Motivation: 评估LLM预测能力面临两难：前瞻性评估方法严谨但延迟高，回顾性预测面临数据污染问题。模拟无知(SI)被认为是潜在解决方案，但需要验证其是否能近似真实无知(TI)

Method: 在477个竞赛级问题和9个模型上进行系统测试，比较模拟无知(SI)与真实无知(TI)的表现，分析截止指令效果、思维链推理的知识抑制能力，以及推理优化模型的表现

Result: SI系统性失败：1)截止指令导致SI与TI存在52%性能差距；2)思维链推理无法抑制先验知识；3)推理优化模型的SI保真度更差。提示无法可靠"倒带"模型知识

Conclusion: 基于预截止事件的回顾性预测方法存在方法论缺陷，不建议使用基于SI的回顾性设置来基准测试预测能力

Abstract: Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably "rewind" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.

</details>


### [148] [OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents](https://arxiv.org/abs/2601.13722)
*Yulin Hu,Zimo Long,Jiahe Guo,Xingyu Sui,Xing Fu,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.CL

TL;DR: 提出OP-Bench基准测试，用于评估对话系统中过度个性化问题，包括无关性、重复性和谄媚性三种类型，并开发了Self-ReCheck机制来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆的对话系统主要关注能否回忆和应用用户信息，但忽视了这些个性化是否恰当使用。系统可能过度使用个人信息，导致回应显得生硬、侵入性或社交不当，即"过度个性化"问题。

Method: 1) 将过度个性化形式化为三种类型：无关性、重复性和谄媚性；2) 构建OP-Bench基准测试，包含1700个已验证实例；3) 提出Self-ReCheck机制，一种轻量级、模型无关的记忆过滤方法。

Result: 评估发现，引入记忆后过度个性化问题普遍存在，系统倾向于检索和过度关注用户记忆，即使在不必要时。Self-ReCheck机制能有效缓解过度个性化，同时保持个性化性能。

Conclusion: 这项工作为基于记忆的对话系统中更可控和适当的个性化迈出了初步步伐，提出了评估框架和解决方案，有助于改善对话系统的用户体验。

Abstract: Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.

</details>


### [149] [On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation](https://arxiv.org/abs/2601.13729)
*Weichuan Wang,Mingyang Liu,Linqi Song,Chen Ma*

Main category: cs.CL

TL;DR: 该研究系统评估了现代机器翻译系统中的非确定性现象，发现温度约束下的非确定性机器翻译(ND-MT)能生成更高质量的候选翻译，但现有评估框架对其不适用，且存在"水桶效应"——最差候选决定系统排名。


<details>
  <summary>Details</summary>
Motivation: 语言模型的非确定性特性在现实应用中影响显著，但在机器翻译这一复杂非确定性任务中尚未充分探索。研究者旨在系统评估现代MT系统的非确定性现象，并解决长期困扰MT研究的多模态问题。

Method: 1) 识别温度约束下的ND-MT现象；2) 在三个开放数据集上评估五个最先进的ND-MT系统；3) 使用基于词汇和语义的指标在不同采样规模下进行分析；4) 提出ExpectoSample策略自动评估指标可靠性。

Result: 发现ND-MT相比确定性MT(D-MT)能生成更高质量的候选翻译，但现有D-MT评估框架对ND-MT不适用。所有系统都表现出"水桶效应"：ND-MT生成的最低质量候选翻译在不同采样规模下决定了系统的整体排名。

Conclusion: ND-MT在解决机器翻译多模态问题方面具有潜力，但需要新的评估框架。提出的ExpectoSample策略能帮助选择稳健的ND-MT系统，为未来非确定性机器翻译研究提供了重要见解。

Abstract: In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.

</details>


### [150] [Towards robust long-context understanding of large language model via active recap learning](https://arxiv.org/abs/2601.13734)
*Chenyu Hui*

Main category: cs.CL

TL;DR: ARL通过主动回顾学习框架增强LLM的长文本理解能力，在持续预训练中构建目标序列，在推理时进行回顾性总结，建立跨段落的递归记忆机制。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在理解长上下文时存在困难，需要一种有效的方法来增强模型对长文本的处理能力，特别是建立跨段落的记忆机制。

Method: 1. 基于长短上下文损失差距识别关键token并找到最相关的前文段落，使用LLM进行总结；2. 在持续预训练中让模型学习自主生成和利用回顾性总结，建立递归记忆机制。

Result: ARL在RULER基准上实现了26.8%的提升，在LongBench上实现了9.44%的提升，显著增强了长上下文理解能力。

Conclusion: ARL提供了一种简单而有效的持续预训练方法，能够显著增强LLM的长上下文理解能力，推动了LLM中可扩展记忆增强技术的发展。

Abstract: In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM

</details>


### [151] [Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues](https://arxiv.org/abs/2601.13742)
*Arjun Chandra,Kevin Miller,Venkatesh Ravichandran,Constantinos Papayiannis,Venkatesh Saligrama*

Main category: cs.CL

TL;DR: TRACE框架让LLM能通过音频线索进行推理，实现低成本、人类对齐的语音到语音评估，比ALM和纯文本LLM更高效且与人类评分更一致。


<details>
  <summary>Details</summary>
Motivation: 当前语音到语音自动评估方法依赖不透明且昂贵的音频语言模型，而具有强大推理能力的大语言模型只能处理文本内容，这限制了高效、人类对齐的S2S评估发展。

Method: 提出TRACE框架：1) 引入人类思维链标注协议，将评估分为内容、语音质量和副语言三个维度；2) 构建音频信号的文本蓝图；3) 让LLM进行维度判断，通过确定性策略融合为总体评分。

Result: TRACE比音频语言模型和纯文本LLM评估与人类评分者的一致性更高，同时成本效益显著提升。

Conclusion: TRACE框架实现了可扩展且人类对齐的语音到语音评估，将发布人类思维链标注和框架以促进该领域发展。

Abstract: Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.

</details>


### [152] [Pro-AI Bias in Large Language Models](https://arxiv.org/abs/2601.13749)
*Benaya Trabelsi,Jonathan Shaki,Sarit Kraus*

Main category: cs.CL

TL;DR: LLMs存在系统性偏向人工智能的偏见，在建议、薪资评估和内部表征中均表现出对AI的偏好


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多个领域被用于决策支持，研究这些模型是否存在对人工智能本身的系统性偏好偏见

Method: 通过三个互补实验：1)分析LLM对建议寻求查询的回应中推荐AI相关选项的比例；2)比较LLM对AI相关职位和非AI职位的薪资评估；3)探索开源模型的内部表征，分析"人工智能"在不同情感框架下的相似性

Result: 发现一致的pro-AI偏见证据：1)LLM不成比例地推荐AI相关选项，专有模型几乎确定性推荐；2)系统性地高估AI相关职位薪资，专有模型高估10个百分点；3)"人工智能"在积极、消极和中性框架下均表现出最高的表征中心性

Conclusion: LLM生成的建议和评估可能在高风险决策中系统性扭曲选择和认知，需要警惕这种偏见对决策支持系统的影响

Abstract: Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.

</details>


### [153] [Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis](https://arxiv.org/abs/2601.13802)
*Yushen Chen,Junzhe Liu,Yujie Tu,Zhikang Niu,Yuzhe Liang,Kai Yu,Chunyu Qiang,Chen Zhang,Xie Chen*

Main category: cs.CL

TL;DR: Habibi是一套专门针对阿拉伯语方言的文本转语音统一模型套件，利用现有ASR语料库支持多种方言，通过语言学课程学习实现高质量语音合成，超越主流商业服务。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言的语音合成研究存在明显空白，缺乏统一建模视角。阿拉伯语方言的语言复杂性高，加上缺乏标准化数据、基准和评估指南，导致研究者倾向于选择更安全的研究方向。

Method: 利用现有开源ASR语料库，通过语言学课程学习支持从高资源到低资源的阿拉伯语方言，采用统一建模方法，无需文本标注，通过有效的上下文学习保持可扩展性。

Result: Habibi在生成质量上超越了领先的商业服务，同时保持可扩展性，无需文本标注。将开源模型并创建首个系统性的多方言阿拉伯语语音合成基准。

Conclusion: 该研究填补了阿拉伯语方言语音合成的空白，通过建立评估标准和提供系统基准，为后续研究奠定坚实基础，推动该领域发展。

Abstract: A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .

</details>


### [154] [Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning](https://arxiv.org/abs/2601.13806)
*Dezhao Song,Guglielmo Bonifazi,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: 该论文提出了一种知识图谱辅助的方法来增强LLM在法律领域的推理能力，通过IRAC框架构建法律知识图谱，并进行SFT和DPO训练，在多个法律基准测试中取得了优于基线的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的后训练主要依赖大量文本语料和人类反馈，缺乏对领域知识结构的捕捉，导致模型在处理复杂推理任务（特别是高风险专业领域如法律）时表现不佳。法律推理需要深入理解各种法律概念之间的关系，这是当前LLM后训练中缺失的关键组成部分。

Method: 1. 使用IRAC（Issue, Rule, Analysis, Conclusion）框架建模关键法律概念；2. 构建包含12K个法律案例的知识图谱；3. 利用IRAC知识图谱生成训练数据；4. 对三个SOTA LLM（30B、49B、70B）进行监督微调（SFT）和直接偏好优化（DPO）训练。

Result: 后训练模型在4/5个多样化法律基准测试（14个任务）上获得了比基线更好的平均性能。特别是70B DPO模型在4/6个推理任务上取得了最佳分数，优于基线和141B的SOTA法律LLM，证明了知识图谱在增强LLM法律推理能力方面的有效性。

Conclusion: 知识图谱辅助的方法能有效增强LLM在法律领域的推理能力，该方法可推广到其他高风险专业领域。通过结构化领域知识（如IRAC框架）构建知识图谱，结合SFT和DPO训练，可以显著提升LLM在复杂专业任务上的表现。

Abstract: LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.

</details>


### [155] [The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations](https://arxiv.org/abs/2601.13835)
*Sam OConnor Russell,Delphine Charuau,Naomi Harte*

Main category: cs.CL

TL;DR: 该研究发现语音转接模型中，韵律和词汇线索都能独立支持转接预测，模型可灵活利用任一线索，为隐私保护和性能优化提供新方向。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人交互中，流畅的对话转接是关键挑战。虽然自监督语音表示（S3Rs）已取得进展，但尚不清楚基于S3R的转接模型主要依赖韵律线索、词汇线索还是两者兼有。需要更干净地控制语音中的韵律和词汇线索来探究这一问题。

Method: 提出基于声码器的方法，比先前工作更干净地控制语音中的韵律和词汇线索。使用该方法探测基于S3R的语音活动投影模型（voice-activity projection model）。通过韵律匹配但不可理解的噪声语音进行测试，并与清晰语音对比。

Result: 在韵律匹配但不可理解的噪声语音上的预测准确率与清晰语音相似。这表明韵律和词汇线索都能支持转接预测，且任一线索都可独立使用。当任一信息被破坏时，模型无需额外训练即可利用另一线索，表明它们在S3Rs中的编码具有有限相互依赖性。结果在CPC-based和wav2vec2.0 S3Rs中一致。

Conclusion: 未来模型可能仅需韵律线索，这能提供隐私保护和潜在性能优势。韵律和词汇线索在S3Rs中编码相对独立，模型能灵活利用任一线索。研究为未来工作指明了方向，所有代码已开源支持后续研究。

Abstract: Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.

</details>


### [156] [FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836)
*Qian Chen,Jinlan Fu,Changsong Li,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 提出首个评估音频-视觉环境全模态未来预测的基准FutureOmni，包含919个视频和1034个QA对，发现当前模型在音频-视觉未来预测上表现不佳，并提出OFF训练策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型(MLLMs)主要关注回顾性理解，而基于音频-视觉线索预测未来事件的能力尚未充分探索，需要建立专门的基准来评估这一能力。

Method: 1) 通过LLM辅助、人机协同的可扩展流程构建FutureOmni基准；2) 提出Omni-Modal Future Forecasting (OFF)训练策略，并构建7K样本的指令调优数据集；3) 在13个全模态和7个纯视频模型上评估。

Result: 当前系统在音频-视觉未来预测上表现不佳，特别是在语音密集型场景中，最佳模型Gemini 3 Flash准确率仅64.8%。OFF训练策略显著提升了未来预测能力和泛化性能。

Conclusion: FutureOmni填补了全模态未来预测基准的空白，揭示了当前模型的局限性，提出的OFF训练策略有效提升了未来预测能力，为相关研究提供了重要资源和方向。

Abstract: Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).

</details>


### [157] [Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education](https://arxiv.org/abs/2601.13876)
*Unggi Lee,Jahyun Jeong,Sunyoung Shin,Haeun Park,Jeongsu Moon,Youngchang Song,Jaechang Shim,JaeHwan Lee,Yunju Noh,Seungwon Choi,Ahhyun Kim,TaeHyeon Kim,Kyungtae Joo,Taeyeong Kim,Gyeonggeon Lee*

Main category: cs.CL

TL;DR: 提出Pedagogical VLA Framework，通过教学对齐使轻量级VLA模型适用于教育资源受限的科学演示场景，在保持任务性能的同时生成教育性解释。


<details>
  <summary>Details</summary>
Motivation: 科学演示对STEM教育很重要，但教师面临安全性和一致性的挑战。当前VLA模型需要大量计算资源，且牺牲语言生成能力来追求效率，不适合需要可解释、能生成解释的教育环境。

Method: 提出Pedagogical VLA Framework，包含四个组件：文本修复恢复语言生成能力、LLM蒸馏传递教学知识、安全训练适应教育环境、教学评估调整到科学教育背景。

Result: 在物理、化学、生物、地球科学五个科学演示中评估，使用与科学教育专家合作开发的评估框架。结果显示框架在任务性能上与基线模型相当，同时能生成情境适当的教育解释。

Conclusion: Pedagogical VLA Framework为资源受限的教育环境提供了一种有效的解决方案，使机器人能够安全、一致地进行科学演示，同时生成教育性解释，支持STEM教育。

Abstract: Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.

</details>


### [158] [OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models](https://arxiv.org/abs/2601.13882)
*Unggi Lee,Sookbun Lee,Heungsoo Choi,Jinseo Lee,Haeun Park,Younghoon Jeon,Sungmin Cho,Minju Kang,Junbo Koh,Jiyeong Bae,Minwoo Nam,Juyeon Eun,Yeonji Jung,Yeil Jeong*

Main category: cs.CL

TL;DR: OpenLearnLM Benchmark是一个基于教育评估理论的多维度LLM评估框架，包含知识、技能和态度三个维度，涵盖124K+项目，评估显示不同模型在不同维度表现各异，没有单一模型在所有维度都领先。


<details>
  <summary>Details</summary>
Motivation: 现有LLM教育基准测试过于狭窄，缺乏学习科学基础，需要更全面、理论基础的评估框架来评估LLM在教育场景中的真实准备度。

Method: 基于教育评估理论构建三维评估框架：知识（课程内容与教学理解）、技能（基于四层中心-角色-场景-子场景层次的情景能力）、态度（一致性对齐与欺骗抵抗）。包含124K+项目，涵盖多学科、教育角色和布鲁姆分类法难度等级。

Result: 评估7个前沿模型显示不同能力分布：Claude-Opus-4.5实践技能优秀但内容知识较低，Grok-4.1-fast知识领先但存在对齐问题。没有单一模型在所有维度都占优，验证了多轴评估的必要性。

Conclusion: OpenLearnLM提供了一个开放、全面的框架，用于推进LLM在真实教育场景中的准备度，强调了多维度评估的重要性，不同模型在不同教育维度有各自的优势。

Abstract: Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.

</details>


### [159] [Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores](https://arxiv.org/abs/2601.13885)
*Esma Balkır,Alice Pernthaller,Marco Basaldella,José Hernández-Orallo,Nigel Collier*

Main category: cs.CL

TL;DR: 提出一种针对连续分数（如ROUGE、BLEU、LLM-as-a-Judge）的自适应测试方法，将传统IRT扩展到连续有界分数，使用异方差正态分布替代伯努利分布，实现高效可靠的模型排序。


<details>
  <summary>Details</summary>
Motivation: 传统CAT（计算机自适应测试）主要针对选择题（正确/错误），但现代LLM评估越来越多依赖生成任务，其输出是连续分数而非二元判断，需要扩展自适应测试方法处理连续分数。

Method: 1) 将IRT（项目反应理论）扩展到连续有界分数，用异方差正态分布替代伯努利响应分布；2) 引入具有自适应停止标准的不确定性感知排序器，在尽可能少的测试项目和低成本下实现可靠模型排序。

Result: 在五个基准测试（包括n-gram、embedding和LLM-as-judge指标）上验证，仅使用2%的测试项目，相比随机采样提升0.12 τ的排序相关性，置信预测准确率达到95%。

Conclusion: 成功将自适应测试扩展到连续分数领域，为生成任务的LLM评估提供高效可靠的方法，显著减少评估成本同时保持高准确性。

Abstract: Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.

</details>


### [160] [AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization](https://arxiv.org/abs/2601.13918)
*Yusheng Liao,Chuan Xuan,Yutong Cai,Lina Yang,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: RetroSum框架通过回顾性总结机制和演化经验策略，显著提升LLM在原始、高噪声电子病历数据库中的自主导航和复杂决策能力


<details>
  <summary>Details</summary>
Motivation: 当前LLM在医疗领域的应用主要依赖精心准备的输入和简化的检索任务，无法在原始、高噪声的电子病历数据库中进行复杂的自主导航和决策，存在理想实验环境与真实临床环境之间的差距

Method: 提出RetroSum框架，包含两个核心组件：1）回顾性总结机制，通过动态重新评估交互历史，防止长上下文信息丢失并确保逻辑连贯性；2）演化经验策略，通过从记忆库中检索累积经验来弥合领域差距

Result: 在AgentEHR基准测试中，RetroSum相比竞争基线性能提升高达29.16%，同时将总交互错误减少高达92.3%

Conclusion: RetroSum框架通过创新的回顾性总结和演化经验策略，有效解决了LLM在原始电子病历数据库中自主导航时的信息丢失和推理连续性断裂问题，为医疗AI的实际临床应用提供了重要进展

Abstract: Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.

</details>


### [161] [HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs](https://arxiv.org/abs/2601.13919)
*Yuezhe Yang,Hao Wang,Yige Peng,Jinman Kim,Lei Bi*

Main category: cs.CL

TL;DR: HyperWalker是一个通过动态超图重构临床推理的深度诊断框架，利用电子健康记录数据和测试时训练来提升医疗诊断的准确性


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI方法主要采用样本隔离推理范式，独立处理病例而无法访问纵向电子健康记录或相关患者案例，限制了仅基于图像信息的推理能力，忽略了外部补充医疗证据

Method: 构建动态超图iBrochure建模EHR数据的结构异质性和多模态临床信息的高阶关联；使用强化学习代理Walker在超图中导航寻找最优诊断路径；引入linger机制进行多跳正交检索，迭代选择反映不同临床属性的互补邻域病例

Result: 在MIMIC数据集上的医疗报告生成和EHRXQA上的医疗视觉问答实验中，HyperWalker实现了最先进的性能

Conclusion: HyperWalker通过动态超图和测试时训练有效整合多模态临床信息，克服了传统样本隔离推理的限制，为临床诊断提供了更准确的方法

Abstract: Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \textbf{HyperWalker}, a \textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker

</details>


### [162] [Automatic Prompt Optimization for Dataset-Level Feature Discovery](https://arxiv.org/abs/2601.13922)
*Adrian Cosma,Oleg Szehr,David Kletz,Alessandro Antonucci,Olivier Pelletier*

Main category: cs.CL

TL;DR: 提出多智能体提示优化框架，将特征发现视为数据集级提示优化问题，通过语言模型智能体联合提出特征定义、提取特征值并评估特征质量，实现从非结构化文本自动发现可解释特征。


<details>
  <summary>Details</summary>
Motivation: 当前从非结构化文本提取特征的方法主要依赖手工设计的提示或固定特征模式，缺乏自动发现可解释和判别性特征的能力，需要更系统的方法来优化下游监督学习目标。

Method: 提出多智能体提示优化框架，语言模型智能体共同执行：1）提出特征定义，2）提取特征值，3）使用数据集级性能和可解释性反馈评估特征质量。通过结构化反馈迭代优化指令提示，优化诱导共享特征集的提示而非单样本预测。

Result: 该方法与依赖单样本监督的先前提示优化方法不同，为从非结构化文本自动特征发现提供了原则性机制，能够诱导全局可解释和判别性特征定义集。

Conclusion: 将特征发现重新定义为数据集级提示优化问题，通过多智能体框架实现自动特征发现，为下游分类任务提供更有效的特征提取方法。

Abstract: Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.

</details>


### [163] ["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework](https://arxiv.org/abs/2601.13992)
*Jin Cui,Jiaqi Guo,Jiepeng Zhou,Ruixuan Yang,Jiayi Lu,Jiajun Xu,Jiangcheng Song,Boran Zhao,Pengju Ren*

Main category: cs.CL

TL;DR: COMPACT是一个多教师蒸馏框架，通过动态加权教师梯度来融合不同LLM的推理能力，解决单一教师能力偏见和灾难性遗忘问题，提升小模型推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有CoT蒸馏方法通常依赖单一教师模型，但单个LLM存在能力偏见和灾难性遗忘问题，限制了学生模型的潜力。虽然利用多样化教师模型很有吸引力，但有效融合它们的监督仍然具有挑战性：师生不兼容可能放大幻觉，被动监督无法确保真正的逻辑内化。

Method: COMPACT框架通过基于学生实时兼容性的多维度指标动态加权教师梯度来融合不同教师的监督：1) 基于图的共识机制过滤误导性推理路径；2) 基于互信息的适应性检测"顿悟时刻"以确保真正理解而非模仿；3) 基于损失的难度评估学生接受教师指导的能力，防止负迁移。

Result: 大量实验和潜在空间分析表明，COMPACT有效整合了多样化的推理能力，同时不损害模型原有的知识结构，在各种基准测试中实现了最先进的性能，同时缓解了灾难性遗忘问题。

Conclusion: COMPACT通过自适应融合多教师监督，成功解决了CoT蒸馏中的师生不兼容和负迁移问题，为小模型获得多样化推理能力提供了一种有效框架，在保持原有知识结构的同时显著提升推理性能。

Abstract: Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.

</details>


### [164] [From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning](https://arxiv.org/abs/2601.13995)
*Zihan Niu,Wenping Hu,Junmin Chen,Xiyue Wang,Tong Xu,Ruiming Tang*

Main category: cs.CL

TL;DR: TAGS：基于知识树的指令调优数据选择框架，通过细粒度标签构建知识树，实现质量、多样性和目标对齐的联合控制，仅用5%数据即可超越全数据集模型性能


<details>
  <summary>Details</summary>
Motivation: 现有指令调优数据选择方法主要依赖实例级质量评分或基于嵌入聚类/语义标签的多样性度量，但受限于嵌入空间的平坦性或标签的粗糙性，忽略了细粒度知识及其内在层次依赖关系，阻碍了精确的数据评估和知识对齐采样

Method: 提出Tree-aware Aligned Global Sampling (TAGS)框架：1) 使用LLM-based标签器提取原子知识概念；2) 通过自底向上层次聚类构建全局知识树；3) 将数据实例映射到树上，用树感知度量量化数据质量和多样性；4) 可控采样策略最大化树级信息增益并通过KL散度强制叶级对齐

Result: TAGS显著优于现有基线方法，仅使用5%数据就超越全数据集模型性能+5.84%，对齐采样策略进一步将平均性能提升+4.24%

Conclusion: TAGS通过构建细粒度知识树，实现了对指令调优数据质量、多样性和目标对齐的联合控制，为大规模开源数据集的有效数据选择提供了新思路

Abstract: Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \textbf{+5.84\%} using only \textbf{5\%} of the data, while our aligned sampling strategy further boosts average performance by \textbf{+4.24\%}.

</details>


### [165] [Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models](https://arxiv.org/abs/2601.14004)
*Hengyuan Zhang,Zhihao Zhang,Mingyang Wang,Zunhai Su,Yiwei Wang,Qianli Wang,Shuzhou Yuan,Ercong Nie,Xufeng Duan,Qibo Xue,Zeping Yu,Chenming Shang,Xiao Liang,Jing Xiong,Hui Shen,Chaofan Tao,Zhengwu Liu,Senjie Jin,Zhiheng Xi,Dongdong Zhang,Sophia Ananiadou,Tao Gui,Ruobing Xie,Hayden Kwok-Hay So,Hinrich Schütze,Xuanjing Huang,Qi Zhang,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出了一种可操作的机制可解释性框架，围绕"定位、引导、改进"流程，将MI从观察科学转变为可干预的模型优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性研究主要作为观察科学，缺乏系统性的可操作干预框架。本文旨在弥合这一差距，将MI转变为可操作的模型优化方法论。

Method: 提出"定位、引导、改进"的实践框架，基于可解释对象对定位（诊断）和引导（干预）方法进行形式化分类，建立严格的干预协议。

Result: 该框架能够实现对齐性、能力和效率三个维度的实质性改进，使MI成为可操作的模型优化方法。

Conclusion: 机制可解释性可以超越观察科学，通过系统化的干预框架成为实际可操作的模型优化工具，为LLM的透明决策提供实用方法论。

Abstract: Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.

</details>


### [166] [BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models](https://arxiv.org/abs/2601.14007)
*Junyu Zhang,Yipeng Kang,Jiong Guo,Jiayu Zhan,Junqi Wang*

Main category: cs.CL

TL;DR: LLMs确实理解抽象概念，而不仅仅是统计模式。通过价值作为测试平台，研究发现LLMs具有跨抽象-具体层面的概念理解能力，价值表征作为稳定锚点而非可变激活。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否真正理解抽象概念，还是仅仅在操作统计模式。以人类价值作为测试平台，因为价值具有语义丰富性且对AI对齐至关重要。

Method: 提出抽象-具体框架，将概念理解分解为三个能力：抽象概念解释(A-A)、抽象概念在具体事件中的具体化(A-C)、抽象原则在具体决策中的应用(C-C)。使用探测和引导技术，在六个开源LLMs和十个价值维度上进行实验。

Result: 探测显示：基于抽象价值描述训练的探测模型能可靠检测具体事件叙述和决策推理中的相同价值，证明跨层面迁移。引导揭示不对称性：干预价值表征能因果性地改变具体判断和决策(A-C, C-C)，但抽象解释保持不变(A-A)。

Conclusion: LLMs维持结构化的价值表征，桥接抽象与行动，为构建价值驱动的自主AI系统提供了机制性和操作性基础，实现更透明、可泛化的对齐和控制。

Abstract: Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.

</details>


### [167] [RM-Distiller: Exploiting Generative LLM for Reward Model Distillation](https://arxiv.org/abs/2601.14032)
*Hongli Zhou,Hui Huang,Wei Liu,Chenglong Wang,Xingyuan Bu,Lvyuan Han,Fuhai Song,Muyun Yang,Wenhao Jiang,Hailong Cao,Tiejun Zhao*

Main category: cs.CL

TL;DR: RM-Distiller：首个系统研究从生成式LLM蒸馏奖励模型的方法，通过利用教师模型的三种能力（精炼、评分、生成）显著提升奖励模型性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要将教师模型视为简单的二元标注器，未能充分利用其丰富知识和能力进行奖励模型蒸馏。高质量人工偏好标注获取困难，需要更有效地从生成式LLM中蒸馏偏好信息。

Method: 提出RM-Distiller框架，系统利用教师LLM的三种能力：1) 精炼能力：合成高度相关的响应对，创建细粒度的对比信号；2) 评分能力：通过边界感知优化目标指导RM捕捉精确的偏好强度；3) 生成能力：融入教师的生成分布，正则化RM以保留基本语言知识。

Result: 大量实验表明，RM-Distiller在RM基准测试和基于强化学习的对齐任务上显著优于传统蒸馏方法，证明利用教师多方面能力对有效奖励建模至关重要。

Conclusion: 这是首个系统研究从生成式LLM进行奖励模型蒸馏的工作，通过全面利用教师模型的精炼、评分和生成能力，显著提升了奖励模型的性能和对齐效果。

Abstract: Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.

</details>


### [168] [Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants](https://arxiv.org/abs/2601.14041)
*Yunhe Wang,Kai Han,Huiling Zhen,Yuchuan Tian,Hanting Chen,Yongbing Huang,Yufei Cui,Yingte Shu,Shan Gao,Ismail Elezi,Roy Vaughan Miles,Songcen Xu,Feng Wen,Chao Xu,Sinan Zeng,Dacheng Tao*

Main category: cs.CL

TL;DR: 论文认为自回归语言模型存在因果瓶颈限制，扩散语言模型提供了变革性替代方案，但面临十大挑战，提出了基于四大支柱的路线图以实现扩散原生生态系统。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要基于自回归架构，存在因果瓶颈限制全局结构预见和迭代优化能力。扩散语言模型提供了更全面的双向去噪生成方式，但潜力未充分发挥，仍受自回归遗留框架限制。

Method: 识别扩散语言模型面临的十大基础挑战，包括架构惯性、梯度稀疏性、线性推理限制等。提出基于四大支柱的战略路线图：基础架构、算法优化、认知推理、统一多模态智能。

Result: 通过向扩散原生生态系统转型，采用多尺度标记化、主动重掩码、潜在思维等方法，可以超越因果视野限制，实现复杂结构推理、动态自我校正和无缝多模态集成。

Conclusion: 从自回归范式向扩散原生生态系统过渡对于开发具备复杂结构推理、动态自我校正和多模态集成能力的下一代AI至关重要，是实现扩散语言模型"GPT-4时刻"的必要路径。

Abstract: The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.

</details>


### [169] [PRiSM: Benchmarking Phone Realization in Speech Models](https://arxiv.org/abs/2601.14046)
*Shikhar Bharadwaj,Chin-Jou Li,Yoonjae Kim,Kwanghee Choi,Eunjung Yeo,Ryan Soh-Eun Shim,Hanyu Zhou,Brendon Boldt,Karen Rosero Jacome,Kalvin Chang,Darsh Agrawal,Keer Xu,Chao-Han Huck Yang,Jian Zhu,Shinji Watanabe,David R. Mortensen*

Main category: cs.CL

TL;DR: PRiSM是首个开源基准测试，通过内在和外在评估揭示语音识别系统的音位感知盲点，发现多语言训练、编码器-CTC模型稳定性以及专用模型优于大型音频语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前语音识别系统评估仅关注表层转录准确性，缺乏对音位感知能力的深入评估，需要标准化评估框架来揭示系统在音位层面的盲点。

Method: PRiSM基准测试标准化了基于转录的评估，并通过转录和表示探针在临床、教育和多语言场景中进行下游效用评估。

Result: 研究发现：1）训练中多语言暴露对性能至关重要；2）编码器-CTC模型最稳定；3）专用语音识别模型仍优于大型音频语言模型。

Conclusion: PRiSM通过发布代码、配方和数据集，推动领域向具有强大音位能力的多语言语音模型发展，为音位感知评估提供了标准化框架。

Abstract: Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.

</details>


### [170] [Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering](https://arxiv.org/abs/2601.14050)
*Yuxin Chen,Zhengzhou Cai,Xiangtian Ji,Weixiang Zhao,An Zhang,Xiang Wang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文系统分析了MoE模型的多语言处理机制，发现路由行为与语系对齐，专家利用呈现分层模式，并提出基于路由引导的调控方法提升多语言性能。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE架构在多语言任务上表现出色，但其内部机制（性能提升原因和跨语言差异）尚未得到充分理解。本文旨在系统分析MoE模型的路由行为和专家专业化模式。

Method: 1. 系统分析MoE模型在不同语言和网络深度上的路由行为与专家专业化；2. 通过分层干预实验探究不同层的作用；3. 提出路由引导的调控方法，在推理时自适应地将中间层的路由行为导向与主导语言相关的共享专家。

Result: 1. MoE的多语言处理高度结构化：路由与语系对齐，专家利用呈现清晰的分层模式；2. 高资源语言依赖共享专家，低资源语言更多使用语言专属专家但性能较弱；3. 早期和晚期MoE层支持语言特定处理，中间层作为语言无关的容量中心；4. 提出的路由引导方法能持续提升多语言性能，特别是对语言相关的语言对。

Conclusion: MoE模型的多语言处理具有系统性的结构化特征，基于路由行为的理解可以设计有效的调控方法提升性能。中间层作为语言无关容量中心的特点为多语言优化提供了重要启示。

Abstract: Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.

</details>


### [171] [Kakugo: Distillation of Low-Resource Languages into Small Language Models](https://arxiv.org/abs/2601.14051)
*Peter Devine,Mardhiyah Sanni,Farid Adilazuarda,Julieta Gil Loizaga,Barry Haddow*

Main category: cs.CL

TL;DR: Kakugo是一个低成本管道，仅需语言名称即可为低资源语言训练通用小型语言模型，使用教师模型生成合成提示和翻译指令数据，为54种语言训练模型，每语言成本低于50美元。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言开发AI模型通常面临数据稀缺和高成本挑战，需要一种经济高效的方法让语言社区能够创建自己的语言特定AI模型。

Method: 使用大型教师模型生成合成提示并翻译指令数据集，创建训练数据，然后为54种低资源语言训练小型语言模型，整个流程仅需语言名称作为输入。

Result: 在翻译、分类和问答等多种自然语言处理任务上，Kakugo管道训练的模型性能持续优于基础模型，每语言总生成和训练成本低于50美元。

Conclusion: Kakugo提供了一种经济高效且易于使用的方法，使语言社区能够以低成本开发自己的语言特定AI模型，促进低资源语言的AI包容性。

Abstract: We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.

</details>


### [172] [XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs](https://arxiv.org/abs/2601.14063)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Shaoxiong Ji,Hassan Alhuzali,Sophia Ananiadou*

Main category: cs.CL

TL;DR: XCR-Bench是一个包含4.9k平行句对和1,098个独特文化特定项目的跨文化推理基准，用于评估大语言模型识别和适应文化特定项目的能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型跨文化能力受到高质量文化特定项目标注语料库稀缺的限制，需要系统评估模型在识别和适应文化特定项目方面的能力。

Method: 整合Newmark的文化特定项目框架和Hall的文化三元论，构建包含三个推理任务的平行句对语料库，涵盖从表面文化元素到半可见和不可见文化元素（如社会规范、信仰和价值观）。

Result: 最先进的大语言模型在识别和适应社交礼仪和文化参考相关的文化特定项目方面表现一致较弱，并且在文化适应过程中表现出区域和民族宗教偏见。

Conclusion: 需要进一步研究跨文化自然语言处理，XCR-Bench基准的发布将促进这一领域的发展，帮助评估和改进大语言模型的跨文化推理能力。

Abstract: Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.

</details>


### [173] [Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks](https://arxiv.org/abs/2601.14105)
*Olesya Razuvayevskaya,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 研究发现，社区笔记与专业辟谣在说服技巧使用上没有显著差异，但存在系统性修辞差异，且社区评分者能有效识别并惩罚有问题的修辞手段。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在比较社区撰写与专业撰写的辟谣内容中说服技巧的使用差异，验证先前关于社区内容更依赖主观或说服性语言的假设，并分析不同事实核查生态系统的修辞特征。

Method: 使用来自Community Notes、EUvsDisinfo和Database of Known Fakes的大规模数据集，量化分析这些事实核查生态系统中说服技巧的普遍性和类型，并研究社区评分者对说服性语言的评估方式。

Result: 1. 社区笔记并不比专业辟谣包含更多说服技巧；2. 发现社区笔记与专业辟谣之间存在系统性修辞差异，反映了机构规范和主题覆盖的不同；3. 虽然包含更多说服元素的笔记获得稍高的总体帮助性评分，但社区评分者能有效惩罚特定有问题的修辞手段。

Conclusion: 社区撰写的事实核查内容在说服技巧使用上与专业内容相当，但存在不同的修辞风格。社区评分机制能有效识别有问题的说服手段，表明众包事实核查系统具有一定的自我调节能力。

Abstract: This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means

</details>


### [174] [Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns](https://arxiv.org/abs/2601.14112)
*George Mihaila*

Main category: cs.CL

TL;DR: ExpNet是一个轻量级神经网络，通过学习从transformer注意力模式到token重要性分数的显式映射，实现可解释AI，自动发现最优注意力特征组合而非依赖预定规则。


<details>
  <summary>Details</summary>
Motivation: 随着transformer模型在高风险领域（医疗、法律、金融）的部署，模型不透明性阻碍了信任和问责。现有注意力解释方法依赖人工定义的聚合策略和固定归因规则，而模型无关方法（如LIME、SHAP）将模型视为黑箱且计算成本高。

Method: 提出Explanation Network (ExpNet)，一个轻量级神经网络，学习从transformer注意力模式到token级重要性分数的显式映射。与先前方法不同，ExpNet自动发现最优注意力特征组合，而非依赖预定规则。

Result: 在具有挑战性的跨任务设置中评估ExpNet，并将其与涵盖四个方法家族的广泛模型无关方法和基于注意力的技术进行基准测试。

Conclusion: ExpNet提供了一种更有效、自动化的transformer模型解释方法，克服了现有方法依赖人工规则或高计算成本的局限性。

Abstract: Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.

</details>


### [175] [NewsRECON: News article REtrieval for image CONtextualization](https://arxiv.org/abs/2601.14121)
*Jonathan Tonglet,Iryna Gurevych,Tinne Tuytelaars,Marie-Francine Moens*

Main category: cs.CL

TL;DR: NewsRECON：一种在反向图像搜索证据不可用时，通过将新闻图像链接到相关文章来推断其拍摄时间和位置的新方法


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖反向图像搜索(RIS)引擎，但RIS经常无法返回结果，限制了实际应用。需要解决RIS证据不可用时的挑战性场景。

Method: NewsRECON通过链接图像到相关新闻文章，利用文章元数据推断时间和位置。方法包含：1) 双编码器检索事件相关文章；2) 两个交叉编码器按位置和事件一致性重排文章。基于超过90,000篇文章的语料库。

Result: 在TARA和5Pils-OOC数据集上的实验表明，NewsRECON优于先前工作，并且可以与多模态大语言模型结合，在缺乏RIS证据时达到新的SOTA结果。

Conclusion: NewsRECON为新闻图像的时间和位置识别提供了一种有效的替代方案，特别是在反向图像搜索不可用的情况下，具有实际应用价值。

Abstract: Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.

</details>


### [176] [A Systematic Analysis of Chunking Strategies for Reliable Question Answering](https://arxiv.org/abs/2601.14123)
*Sofia Bennani,Charles Moslonka*

Main category: cs.CL

TL;DR: 文档分块策略对RAG系统可靠性的影响研究：通过系统评估发现句子分块是最具成本效益的方法，重叠分块无显著收益，且存在"上下文悬崖"现象


<details>
  <summary>Details</summary>
Motivation: 工业实践中RAG系统的文档分块通常依赖启发式方法，缺乏系统评估。本研究旨在通过端到端评估不同分块策略对RAG系统可靠性的影响，为工业部署提供数据驱动的指导

Method: 在Natural Questions数据集上进行端到端评估，系统变化分块方法（token、句子、语义、代码）、分块大小、重叠和上下文长度。使用标准工业设置：SPLADE检索和Mistral-8B生成器

Result: 1) 重叠分块无显著收益且增加索引成本；2) 句子分块是最具成本效益的方法，在~5k tokens内与语义分块效果相当；3) 存在"上下文悬崖"，超过~2.5k tokens后质量下降；4) 最优上下文长度取决于目标（语义质量在小上下文达到峰值，精确匹配需要更大上下文）

Conclusion: 为成本高效的RAG部署提供具体建议：避免重叠分块，优先使用句子分块，控制上下文在~2.5k tokens内，根据具体目标（语义质量vs精确匹配）调整上下文长度

Abstract: We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a "context cliff" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).

</details>


### [177] [Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic](https://arxiv.org/abs/2601.14124)
*Saad Mankarious,Aya Zirikly*

Main category: cs.CL

TL;DR: 提出一种基于扩散模型的文本生成方法，用于缓解阿拉伯语心理健康数据中的性别偏见，通过风格转换增强女性作者内容，无需预训练大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据方法主要依赖预训练大语言模型，但存在输出多样性有限和传播训练数据偏见的风险。特别是在心理健康分析领域，数据稀缺和人口统计偏见问题严重，如阿拉伯语心理健康语料库CARMA存在显著的性别不平衡。

Method: 将偏见缓解视为风格转换问题，提出预训练免费的扩散模型方法。使用CARMA阿拉伯语心理健康语料库，专注于男性到女性的风格转换。构建五个数据集捕捉阿拉伯语性别表达的不同语言和语义方面，为每个设置训练独立的扩散模型。

Result: 定量评估显示源文本和生成文本之间具有持续高语义保真度，同时存在有意义的表面风格差异。定性分析确认了语言上合理的性别转换。该方法能够生成高熵、语义忠实的合成数据。

Conclusion: 基于扩散的风格转换可以在不依赖预训练大语言模型的情况下生成高质量的合成数据，为缓解敏感、低资源心理健康领域中的性别偏见提供了有效且灵活的框架。

Abstract: Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.

</details>


### [178] [Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models](https://arxiv.org/abs/2601.14152)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CL

TL;DR: 论文发现：在多选题回答中，将上下文放在问题和选项之前（CQO）比反向顺序（QOC）性能提升超过14%，原因是因果注意力机制导致QOC中选项无法关注上下文。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对提示结构表现出惊人的敏感性，但其机制尚不清楚。本文旨在深入探究一个显著案例：在多选题回答中，上下文放置顺序对性能的影响。

Method: 通过系统性的架构分析，识别因果注意力机制作为核心机制。在QOC提示中，因果掩码阻止选项标记关注上下文，造成信息瓶颈。

Result: CQO顺序在广泛模型和数据集上一致优于QOC顺序超过14%。因果注意力机制是造成这种性能差异的根本原因。

Conclusion: 提示结构中的因果注意力机制是影响模型性能的关键因素，理解这一机制有助于优化提示设计和提高模型表现。

Abstract: Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.

</details>


### [179] [Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law](https://arxiv.org/abs/2601.14160)
*Ali Hamza Bashir,Muhammad Rehan Khalid,Kostadin Cvejoski,Jana Birr,Jule Berghaus,Armin Berger,Sandra Halscheidt,Christian Temath,Rafet Sifa,David Berghaus*

Main category: cs.CL

TL;DR: 本文提出了一种通过合成数据生成方法将先进LLM适配到德国法律问答领域的有效方法，显著提升了模型在法律问答任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域（如法律推理）中表现不佳，因为缺乏专业知识，导致事实错误或幻觉。德国法律领域尤其缺乏高质量的人工标注数据。

Method: 1. 从权威德国法规中系统生成高质量、多样化且法律准确的问答对；2. 使用严格的自动过滤方法；3. 采用参数高效的微调技术。

Result: 使用合成数据集微调的LLM在德国法律问答任务上显著优于基线模型，证明了合成数据作为人工标注替代方案的可行性。

Conclusion: 精心设计的合成数据可以作为高风险、知识密集型领域中人工标注的稳健替代方案，有效提升LLM在专业领域的表现。

Abstract: Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.

</details>


### [180] [Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum](https://arxiv.org/abs/2601.14172)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

TL;DR: 研究句子级别识别施瓦茨价值理论中的19种价值，作为文本中人类价值检测的具体实现。在新闻和政治宣言的脱语境句子中，道德线索稀疏且类别严重不平衡，这使得细粒度句子级价值检测非常困难。


<details>
  <summary>Details</summary>
Motivation: 研究如何在脱语境、道德线索稀疏且类别不平衡的文本中检测人类价值，特别是施瓦茨价值理论中的19种价值，这是一个具有挑战性的自然语言处理任务。

Method: 1. 首先定义二元道德存在任务；2. 比较基于DeBERTa-base的存在门控层次结构和直接多标签分类器；3. 使用轻量级信号增强（前句上下文、LIWC-22/eMFD/MJD词典、主题特征）；4. 基准测试指令调优的LLMs（Gemma 2 9B等）在零/少样本和QLoRA设置下；5. 构建简单集成模型。

Result: 1. 二元道德存在任务可学习（正类F1≈0.74）；2. 层次结构未优于直接预测，门控召回限制了下游增益；3. 软投票监督集成达到macro-F1 0.332，显著超越最佳单监督模型和先前基线；4. 轻量级信号和小集成提供最可靠的改进。

Conclusion: 在8GB单GPU约束和7-9B规模下，精心调优的监督编码器仍然是结构化人类价值检测的强大且计算高效的基线。更丰富的价值结构和句子在文档中的上下文可以进一步提高性能。

Abstract: We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task ("does any value appear?") and show that it is learnable from single sentences (positive-class F1 $\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.

</details>


### [181] [HALT: Hallucination Assessment via Latent Testing](https://arxiv.org/abs/2601.14210)
*Rohan Bhatnagar,Youran Sun,Chi Andrew Zhang,Yixin Wen,Haizhao Yang*

Main category: cs.CL

TL;DR: 提出轻量级残差探针，直接从LLM中间隐藏状态读取幻觉风险，实现零延迟的幻觉风险评估，用于选择性生成和路由决策。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的幻觉问题可理解为忠实读取失败：虽然内部表示可能编码查询的不确定性，但解码压力仍会产生流畅答案。中间层可能保留在最终解码阶段被衰减的认知信号。

Method: 设计轻量级残差探针，从问题标记的中间隐藏状态直接读取幻觉风险。探针是小型辅助网络，计算成本比令牌生成低几个数量级，可与推理完全并行评估，实现近瞬时幻觉风险评估。

Result: 在四个QA基准测试和多个LLM家族中，该方法实现了强大的AUROC和AURAC性能，在数据集偏移下具有良好泛化能力，并揭示了中间表示的可解释结构。

Conclusion: 快速内部不确定性读取可作为可靠智能AI的原则性基础，探针可作为智能批评者实现快速选择性生成和路由，让LLM立即回答自信查询，同时将不确定查询委托给更强的验证流程。

Abstract: Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.

</details>


### [182] [MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems](https://arxiv.org/abs/2601.14230)
*Yiyang Wang,Yiqiao Jin,Alex Cabral,Josiah Hester*

Main category: cs.CL

TL;DR: MASCOT框架通过双层优化策略解决多智能体系统中的人格崩溃和社交谄媚问题，提升人格一致性和社会贡献度。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统作为情感和认知支持的社会协作伴侣存在人格崩溃（智能体退化为通用助手行为）和社交谄媚（产生冗余、非建设性对话）的问题。

Method: 提出MASCOT框架，采用双层优化策略：1）人格感知行为对齐，使用RLAIF驱动的流程微调个体智能体以确保严格的人格保真度；2）协作对话优化，基于群体级奖励的元策略确保多样化和富有成效的对话。

Result: 在心理支持和职场领域的广泛评估表明，MASCOT显著优于现有基线方法，在人格一致性方面提升高达+14.1，在社会贡献度方面提升+10.6。

Conclusion: MASCOT为构建下一代社会智能多智能体系统提供了实用的技术路线图。

Abstract: Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.

</details>


### [183] [APEX-Agents](https://arxiv.org/abs/2601.14242)
*Bertie Vidgen,Austin Mann,Abby Fennelly,John Wright Stanly,Lucas Rothman,Marco Burstein,Julien Benchek,David Ostrofsky,Anirudh Ravichandran,Debnil Sur,Neel Venugopal,Alannah Hsia,Isaac Robinson,Calix Huang,Olivia Varones,Daniyal Khan,Michael Haines,Zach Richards,Chirag Mahapatra,Brendan Foody,Osvald Nitski*

Main category: cs.CL

TL;DR: APEX-Agents是一个评估AI代理执行投资银行分析师、管理咨询师和企业律师等专业领域长时程跨应用任务的基准测试，包含真实工作环境和工具，测试结果显示Gemini 3 Flash表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理基准测试缺乏对专业领域长时程跨应用任务的评估，需要创建能够模拟真实工作环境（包含文件和工具）的基准来评估AI代理在实际专业工作场景中的能力。

Method: 开发APEX-Agents基准测试，包含480个任务，模拟投资银行分析师、管理咨询师和企业律师的真实工作环境，要求AI代理使用文件和工具完成长时程跨应用任务。使用Pass@1指标评估8个AI代理，并开源基准测试数据、提示、评分标准、标准答案、文件和元数据，同时开源代理执行和评估基础设施Archipelago。

Result: Gemini 3 Flash (Thinking=High)以24.0%的最高得分领先，其次是GPT-5.2 (Thinking=High)、Claude Opus 4.5 (Thinking=High)和Gemini 3 Pro (Thinking=High)。所有测试的AI代理在专业领域长时程任务上的表现仍有很大提升空间。

Conclusion: APEX-Agents基准测试填补了AI代理在专业领域长时程跨应用任务评估的空白，为AI代理在实际工作场景中的能力评估提供了重要工具，同时开源的基础设施将促进该领域的研究和发展。

Abstract: We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.

</details>


### [184] [Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249)
*Yuming Yang,Mingyoung Lai,Wanxu Zhao,Xiaoran Fan,Zhiheng Xi,Mingqi Wu,Chiyue Huang,Jun Zhao,Haijun Lv,Jian Tong,Yunhua Zhou,Yicheng Zou,Qipeng Guo,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出Rank-Surprisal Ratio (RSR)指标，用于评估推理轨迹在知识蒸馏中的适用性，平衡对齐性和信息性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法中，更强的教师模型生成的推理轨迹不一定能产生更好的学生模型，表明数据与学生模型的匹配度至关重要。现有方法主要通过学生似然度评估适用性，偏向与当前行为高度对齐的轨迹，但忽略了更具信息量的轨迹。

Method: 提出Rank-Surprisal Ratio (RSR)指标，定义为轨迹的平均词元排名与平均负对数似然之比。该指标捕捉轨迹的对齐性和信息性：有效轨迹通常在学生模型下具有较低的绝对概率但相对较高的词元排名。

Result: 在5个学生模型和11个不同教师生成的推理轨迹上，RSR与训练后性能强相关（平均Spearman相关系数0.86），优于现有指标。实验还展示了RSR在轨迹选择和教师选择中的实际效用。

Conclusion: RSR是一个简单有效的指标，能够评估推理轨迹在知识蒸馏中的适用性，平衡对齐性和信息性，为轨迹选择和教师选择提供实用指导。

Abstract: Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [185] [RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models](https://arxiv.org/abs/2601.11801)
*Nitish Sontakke,K. Niranjan Kumar,Sehoon Ha*

Main category: cs.RO

TL;DR: RobotDesignGPT：基于大型视觉语言模型的自动化机器人设计框架，通过用户提示和参考图像生成初始设计，利用视觉反馈提高设计质量


<details>
  <summary>Details</summary>
Motivation: 机器人设计过程复杂，涉及用户需求、运动学结构和外观等多方面考虑，目前主要依赖领域专家和大量人工，现有方法多为基于规则的语法或模块组合方法，需要自动化解决方案

Method: 提出RobotDesignGPT框架，利用预训练视觉语言模型的通用知识和推理能力，从简单用户提示和参考图像合成初始机器人设计，采用新颖的视觉反馈方法提高设计质量并减少人工干预

Result: 框架能够设计出受自然启发的视觉吸引人且运动学有效的机器人，涵盖从有腿动物到飞行生物的各种类型，通过消融研究和用户研究验证了框架的有效性

Conclusion: RobotDesignGPT展示了利用大型视觉语言模型自动化机器人设计的潜力，显著减少了领域专业知识依赖和人工工作量，为机器人设计提供了新的自动化途径

Abstract: Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.

</details>


### [186] [Optimal Thruster Configuration for 6-DOF Control of a Small Satellite](https://arxiv.org/abs/2601.11802)
*Suguru Sato,Jinaykumar Patel,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 该论文研究了小型卫星的推进器配置优化，从24推进器配置出发，找到能实现6自由度控制的可行配置组，并从中选出最小总推力需求的配置，通过交会对接任务验证了减少推进器数量仍能保持足够机动性。


<details>
  <summary>Details</summary>
Motivation: 随着小型卫星在低地球轨道的部署增加，用于成像、通信、数据存储和交会对接等任务，轨道维持和姿态控制变得越来越重要。传统方法使用多个推进器进行主动轨道控制，这些推进器如果布置得当，也能产生姿态控制所需的扭矩。

Method: 从24推进器配置出发，提出一组能实现完整6自由度控制的推进器配置（称为可行配置组）。然后从这些可行配置组中找出需要最小总推力来实现6自由度指令的配置。最后通过代表性的交会对接任务评估这些配置的姿态控制性能。

Result: 研究发现，即使减少了推进器数量，仍能实现足够的机动性。从可行配置组中找到了需要最小总推力来实现6自由度控制的配置，并通过交会对接任务验证了其姿态控制性能。

Conclusion: 该研究表明，通过优化推进器配置，可以在减少推进器数量的情况下仍保持足够的6自由度控制能力，为小型卫星的轨道维持和姿态控制提供了更高效的解决方案。

Abstract: With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved.

</details>


### [187] [Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles](https://arxiv.org/abs/2601.11832)
*Suguru Sato,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 三维流体动力学启发的无人机编队避障框架，通过障碍物建模为三维双极子或椭球体产生局部速度场，实现平滑无碰撞机动，无需轨迹重规划。


<details>
  <summary>Details</summary>
Motivation: 传统势场方法存在局部最小值问题，且无人机编队在动态环境中需要平滑、实时的避障解决方案，同时保持编队几何结构和轨迹跟踪。

Method: 将移动障碍物建模为三维双极子或椭球体，利用拉普拉斯方程的调和特性生成局部速度场；结合虚拟刚体（VRB）编队策略保持编队协调性。

Result: 仿真结果表明该方法对单个和多无人机场景均可行且可扩展，能处理多种编队几何结构和移动障碍物，实现安全、平滑且计算高效的避障机动。

Conclusion: 提出的基于流体流动的方法实现了实时、可解释的避障行为，避免了传统方法的局部最小值问题，适合实际应用中的实时操作。

Abstract: This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications.

</details>


### [188] [AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal](https://arxiv.org/abs/2601.11876)
*Christopher Kao,Akhil Pathapati,James Davis*

Main category: cs.RO

TL;DR: 提出一种自主导航、识别和拾取公园垃圾的机器人系统，使用STC算法规划覆盖路径，RTK GPS厘米级定位，ResNet50 CNN实现94.52%的垃圾识别准确率，最终系统整体成功率80%


<details>
  <summary>Details</summary>
Motivation: 美国有500亿件垃圾，草地是垃圾问题的主要来源之一，因为野餐者经常在草地上留下垃圾，需要自动化解决方案来清理公园垃圾

Method: 1. 使用Spanning Tree Coverage (STC)算法生成覆盖路径实现自主导航；2. 采用Real-Time Kinematic (RTK) GPS提供厘米级定位精度；3. 使用ResNet50卷积神经网络进行垃圾识别；4. 设计专门的垃圾拾取机制针对草地垃圾

Result: 垃圾识别准确率达到94.52%，系统整体成功率为80%，证明自主垃圾拾取机器人在草地环境是可行的解决方案

Conclusion: 自主垃圾拾取机器人系统在草地公园环境中是可行的，能够有效解决公园垃圾问题，展示了自动化环境清洁技术的潜力

Abstract: There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.

</details>


### [189] [Visual-Language-Guided Task Planning for Horticultural Robots](https://arxiv.org/abs/2601.11906)
*Jose Cuaran,Kendall Koe,Aditya Potnis,Naveen Kumar Uppalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 提出一个基于视觉语言模型（VLM）的模块化框架用于农业机器人任务规划，创建了作物监测任务基准，发现VLM在短期任务表现良好但长期任务性能显著下降，尤其在依赖噪声语义地图时系统失效。


<details>
  <summary>Details</summary>
Motivation: 当前精准农业中的作物监测系统缺乏高级推理能力，需要更智能的解决方案来指导机器人执行复杂的农业任务。

Method: 开发了一个模块化框架，使用视觉语言模型（VLM）指导机器人任务规划，通过交替输入查询和动作原语的方式工作。创建了包含单作和多作环境的短期和长期作物监测任务的综合基准。

Result: VLM在短期作物监测任务中表现稳健（与人类成功率相当），但在具有挑战性的长期任务中表现出显著的性能下降。关键发现是系统在依赖噪声语义地图时会完全失效，揭示了当前VLM在持续机器人操作中上下文接地的关键局限性。

Conclusion: 这项工作提供了一个可部署的框架，并对VLM在复杂农业机器人应用中的能力和局限性提供了重要见解，指出了当前VLM在长期任务和噪声环境下上下文接地方面的不足。

Abstract: Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics.

</details>


### [190] [Model selection and real-time skill assessment for suturing in robotic surgery](https://arxiv.org/abs/2601.12012)
*Zhaoyang Jacopo Hu,Alex Ranne,Alaa Eldin Abdelaal,Kiran Bhattacharyya,Etienne Burdet,Allison M. Okamura,Ferdinando Rodriguez y Baena*

Main category: cs.RO

TL;DR: 本文研究基于达芬奇手术系统数据，使用多模态深度学习模型实时预测手术技能水平（OSATS评分），发现融合运动学和视觉数据的模型优于单模态模型，且专家级训练数据能提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动化反馈系统在机器人辅助手术中具有提供客观技能评估的潜力，但需要实时预测手术技能水平的方法来支持训练和评估。

Method: 使用达芬奇手术系统采集的数据，进行三项主要分析：1）评估多模态深度学习模型（融合运动学和视觉数据）预测手术技能水平的效果；2）分析实时预测性能随时间变化趋势；3）基于技能水平的分层交叉验证训练。

Result: 融合模型在实时预测中始终优于单模态模型；预测趋势与外科医生手势相关；基于高技能外科医生数据训练的模型性能更好且能良好泛化到相似技能水平的参与者。

Conclusion: 多模态学习能够提供更稳定的手术性能细粒度评估，专家级训练数据对模型泛化具有重要价值，为机器人辅助手术的实时技能评估提供了有效方法。

Abstract: Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization.

</details>


### [191] [BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies](https://arxiv.org/abs/2601.12116)
*Hang Xu,Yizhou Chen,Dongjie Yu,Yi Ren,Jia PanI*

Main category: cs.RO

TL;DR: 提出了一种用于双手操作的关键姿势条件协调感知一致性策略，通过分层模仿学习实现高效的多阶段任务执行


<details>
  <summary>Details</summary>
Motivation: 工业机器人擅长简单重复的单手任务，但在双手操作方面面临挑战，特别是协调双臂和处理多阶段过程的复杂性。现有生成模型在模仿学习中取得进展，但很少同时考虑任务的多阶段特性和推理速度的重要性

Method: 提出关键姿势条件协调感知一致性策略，采用分层模仿学习框架：高层关键姿势预测器和低层轨迹生成器。关键姿势作为子目标指导轨迹生成，轨迹生成器采用一致性模型，单步推理生成动作序列。创新性地设计了考虑机器人中心动作特征和任务中心操作风格的双手关键姿势识别方法

Result: 仿真和真实世界实验表明，该方法在成功率和操作效率方面显著优于基线方法

Conclusion: 提出的框架有效解决了双手操作中的多阶段协调问题，通过分层设计和一致性模型实现了高效可靠的双手操作

Abstract: Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus.

</details>


### [192] [Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting](https://arxiv.org/abs/2601.12122)
*Jose Cuaran,Naveen K. Upalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 提出基于移动机械臂的主动3D重建框架，结合Octomap和3D高斯泼溅实现农业场景的高效语义重建，在果实计数和体积估计任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 农业场景的语义重建对表型分析和产量估计至关重要，但传统依赖人工扫描或固定摄像头的方法效率低下，成为主要瓶颈。

Method: 集成经典Octomap表示与3D高斯泼溅：低分辨率Octomap提供概率占据信息用于视点选择和避障规划；3D高斯泼溅利用几何、光度和语义信息优化3D高斯集合实现高保真重建；引入策略增强分割噪声鲁棒性并减少内存消耗。

Result: 相比纯占据方法，在运行效率和重建精度上均有提升：相比0.01m分辨率Octomap，无噪声条件下果实级F1分数提升6.6%，有分割噪声时提升达28.6%；运行时间减少50%。

Conclusion: 该方法在农业机器人中具有可扩展、实时语义重建的潜力，能实现精确的果实计数和体积估计。

Abstract: Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics.

</details>


### [193] [Neural Process-Based Reactive Controller for Autonomous Racing](https://arxiv.org/abs/2601.12143)
*Devin Hunter,Chinwendu Enyioha*

Main category: cs.RO

TL;DR: 提出结合注意力神经过程与物理先验的实时控制框架，用于间隙导航，并通过控制屏障函数确保安全约束


<details>
  <summary>Details</summary>
Motivation: 随着基于注意力的神经网络架构在实时非线性控制中广泛应用，特别是在安全关键领域，需要确保统计基础和可证明的安全决策

Method: 使用注意力神经过程(AttNP)及其物理信息扩展(PI-AttNP)，结合控制屏障函数(CBF)过滤机制，在F1TENTH式阿克曼转向赛车环境中评估

Result: PI-AttNP通过注入物理归纳偏置实现更快收敛和更高预测精度，CBF机制能分析性地强制执行碰撞避免约束，在保持实时约束满足的同时展示竞争性闭环性能

Conclusion: 提出的框架结合了数据驱动学习和物理先验，通过可证明的安全层实现了安全关键的实时控制，适用于自动驾驶等高速场景

Abstract: Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction.

</details>


### [194] [Learning Legged MPC with Smooth Neural Surrogates](https://arxiv.org/abs/2601.12169)
*Samuel A. Moore,Easop Lee,Boyuan Chen*

Main category: cs.RO

TL;DR: 提出平滑神经代理模型和鲁棒学习方法，解决学习模型在腿式机器人MPC中的三个关键问题，显著提升可靠性和性能


<details>
  <summary>Details</summary>
Motivation: 深度学习与MPC在腿式机器人中具有互补作用，但将学习模型与在线规划结合面临挑战：接触事件的刚性转换、非物理局部非光滑性、训练数据导致的非高斯模型误差

Method: 1) 引入平滑神经代理模型：具有可调平滑性的神经网络，为接触轨迹优化提供信息预测和导数；2) 使用重尾似然函数训练模型，更好地匹配腿式机器人动力学的经验误差分布

Result: 在零样本运动任务中，平滑神经代理模型与鲁棒学习显著提升性能：简单行为上累积成本降低10-50%；在标准神经动力学常失败的复杂场景中，成功率从0/5提升到5/5，累积成本降低2-50倍，实现数量级的鲁棒性改进

Conclusion: 平滑神经代理模型和鲁棒学习方法有效解决了学习模型在腿式机器人MPC中的关键问题，大幅提高了学习腿式MPC的可靠性、可扩展性和泛化能力

Abstract: Deep learning and model predictive control (MPC) can play complementary roles in legged robotics. However, integrating learned models with online planning remains challenging. When dynamics are learned with neural networks, three key difficulties arise: (1) stiff transitions from contact events may be inherited from the data; (2) additional non-physical local nonsmoothness can occur; and (3) training datasets can induce non-Gaussian model errors due to rapid state changes. We address (1) and (2) by introducing the smooth neural surrogate, a neural network with tunable smoothness designed to provide informative predictions and derivatives for trajectory optimization through contact. To address (3), we train these models using a heavy-tailed likelihood that better matches the empirical error distributions observed in legged-robot dynamics. Together, these design choices substantially improve the reliability, scalability, and generalizability of learned legged MPC. Across zero-shot locomotion tasks of increasing difficulty, smooth neural surrogates with robust learning yield consistent reductions in cumulative cost on simple, well-conditioned behaviors (typically 10-50%), while providing substantially larger gains in regimes where standard neural dynamics often fail outright. In these regimes, smoothing enables reliable execution (from 0/5 to 5/5 success) and produces about 2-50x lower cumulative cost, reflecting orders-of-magnitude absolute improvements in robustness rather than incremental performance gains.

</details>


### [195] [A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics](https://arxiv.org/abs/2601.12244)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: 该综述论文系统回顾了水下群体机器人的生物启发协调机制、通信策略和系统设计，整合了算法、通信和硬件设计视角，并提出了多维分类框架和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 海洋作业日益复杂，需要智能机器人系统支持海洋观测、探索和资源管理。水下群体机器人通过集体协调扩展单个自主平台能力，但该领域研究分散，缺乏算法、通信和硬件设计的整合。

Method: 通过综述分析生物启发协调机制、通信策略和系统设计考虑，重点研究海洋特定算法（人工鱼群算法、鲸鱼优化算法、珊瑚礁优化、海洋捕食者算法），分析水下通信约束和解决方案，并建立多维分类框架评估现有方法。

Result: 整合了生物启发协调算法、通信模式和系统设计方法，提出了通信依赖性、环境适应性、能源效率和群体可扩展性的多维分类框架，识别了收敛趋势、关键挑战和未来研究方向。

Conclusion: 该综述统一了水下群体机器人的生物启发方法，为实际部署提供了综合框架，并指出了未来研究需要解决的关键技术挑战和集成方向。

Abstract: The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems.

</details>


### [196] [An Efficient and Multi-Modal Navigation System with One-Step World Model](https://arxiv.org/abs/2601.12277)
*Wangtian Shen,Ziyang Meng,Jinming Ma,Mingliang Zhou,Diyun Xiang*

Main category: cs.RO

TL;DR: 提出轻量级导航世界模型，采用单步生成范式和3D U-Net架构，大幅降低推理延迟，实现实时导航规划


<details>
  <summary>Details</summary>
Motivation: 现有端到端学习导航策略缺乏3D空间推理和物理世界理解能力，而基于世界模型的导航方法又因多步扩散和自回归生成导致计算延迟过高，无法实时部署

Method: 1) 轻量级导航世界模型采用单步生成范式；2) 使用3D U-Net骨干网络配合高效时空注意力；3) 集成到基于优化的规划框架，采用锚点初始化处理多模态目标导航

Result: 在仿真和真实环境中的闭环实验表明，系统在效率和鲁棒性上优于最先进的基线方法，实现了高频率控制

Conclusion: 提出的轻量级导航世界模型有效解决了现有方法的计算延迟问题，实现了实时高效的导航规划，为移动机器人导航提供了实用解决方案

Abstract: Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines.

</details>


### [197] [OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization](https://arxiv.org/abs/2601.12291)
*Jianhao Jiao,Changkun Liu,Jingwen Yu,Boyi Liu,Qianyi Zhang,Yue Wang,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: OPENNAVMAP：基于3D几何基础模型的轻量级无结构拓扑地图系统，用于大规模视觉导航


<details>
  <summary>Details</summary>
Motivation: 传统基于结构的地图表示方法维护成本高，在特征缺失环境或视角变化大的众包数据中表现不佳，需要更轻量、可扩展的地图表示方法

Method: 提出无结构拓扑系统，利用3D几何基础模型进行按需重建，结合动态规划序列匹配、几何验证和置信度校准优化，实现从粗到精的子地图对齐

Result: 在Map-Free基准测试中优于传统SfM和回归方法，平均平移误差0.62m；在15km多会话数据中保持全局一致性，绝对轨迹误差低于3m；完成12次自主图像目标导航任务

Conclusion: OPENNAVMAP提供了一种轻量、可扩展的无结构地图表示方法，能够有效处理大规模多会话数据，为实际机器人部署提供了实用解决方案

Abstract: Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.

</details>


### [198] [From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots](https://arxiv.org/abs/2601.12353)
*Jie Wang,Peng Du,Yiyuan Zhang,Zhexin Xie,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本文综述了水下仿生软体机器人的最新进展，分析了设计考虑因素，并探讨了从仿生原理到实际应用的转化路径。


<details>
  <summary>Details</summary>
Motivation: 传统水下机器人在极端水压下工作困难，且会产生噪音和破坏水下生态系统。仿生软体机器人通过模仿水生生物的特性，能够更好地适应水下环境，实现环保、高效的水下探索。

Method: 采用综述研究方法，分析近期水下仿生软体机器人的进展，从设计考虑因素（功能需求、仿生灵感、环境压力、温度、光照、生物多样性）等方面进行系统分析。

Result: 仿生软体机器人能够承受高水压、减小阻力、实现高效操作和感知，并以环保方式与环境互动，成为海洋探索的有前景领域。

Conclusion: 水下仿生软体机器人具有巨大潜力，未来需要进一步推动从仿生原理到实际应用的转化，开发下一代水下软体机器人。

Abstract: Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots.

</details>


### [199] [R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry](https://arxiv.org/abs/2601.12377)
*Haobo Xi,Shiyong Zhang,Qianli Dong,Yunze Tong,Songyang Wu,Jing Yuan,Xuebo Zhang*

Main category: cs.RO

TL;DR: R-VoxelMap提出了一种基于几何驱动的递归平面拟合体素建图方法，通过异常值检测与重用管道提高LiDAR里程计定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统VoxelMap方法使用体素内所有点拟合平面，容易受到异常值影响导致平面参数偏差、大平面过分割以及不同物理平面错误合并的问题。

Method: 采用几何驱动的递归构建策略：1) 使用RANSAC分离异常值并拟合准确平面；2) 将剩余异常值传播到更深的八叉树层级进行递归处理；3) 设计基于点分布的有效性检查算法防止错误平面合并。

Result: 在多种开源LiDAR(-惯性)SLAM数据集上的实验表明，该方法比现有最先进方法达到更高精度，同时保持相当的效率和内存使用。

Conclusion: R-VoxelMap通过递归平面拟合和异常值处理机制，有效解决了传统体素建图中的关键问题，显著提升了建图质量和定位精度。

Abstract: This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.

</details>


### [200] [VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research](https://arxiv.org/abs/2601.12395)
*Chao Wang,Anna Belardinelli,Michael Gienger*

Main category: cs.RO

TL;DR: VR2VR：一个用于触觉人机交互研究的双VR头显平台，允许参与者和隐藏操作者在同一物理空间体验不同虚拟化身，支持精确的机器人触摸交互


<details>
  <summary>Details</summary>
Motivation: 触觉丰富的人机交互研究面临挑战：物理机器人成本高、开发慢，而VR原型通常移除物理接触或破坏身体与触觉的紧密耦合

Method: 开发VR2VR平台，使用共定位的双VR头显系统，操作者通过动作捕捉控制虚拟机器人的上半身手势、头部、视线和面部表情，支持精确的逆运动学映射实现物理触摸对齐

Result: 系统实现了精确的运动重定向和物理触摸对齐，支持选择性启用非语言通道（如仅头部、头部+眼睛、头部+眼睛+面部表情），同时保持物理交互一致

Conclusion: VR2VR降低了快速原型设计和严格评估具身、触觉中心机器人行为的门槛，通过基于触摸的Wizard-of-Oz研究展示了平台的有效性

Abstract: Touch-rich human-robot interaction (HRI) is difficult to study: building and programming physical robots is costly and slow, while VR-based robot prototypes often remove physical contact or break the tight coupling between an agent's body and the user's felt touch. We present VR2VR, a co-located dual VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body gestures, head and gaze behaviors, and facial expressions are mapped from the operator's tracked motion and face signals. Because the operator is physically co-present and calibrated into the same coordinate frame, the operator can also physically touch the participant, enabling the participant to perceive robot touch aligned with the robot's hands; finger and hand motion are mapped to the robot using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb teleoperation, our VR2VR system supports experimental control by retargeting or selectively enabling nonverbal channels (e.g., head only vs. head+eyes vs. head+eyes+facial expressions) while keeping physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate the platform through a touch-based Wizard-of-Oz HRI study, illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, touch-centric robot behaviors.

</details>


### [201] [Learning Diverse Skills for Behavior Models with Mixture of Experts](https://arxiv.org/abs/2601.12397)
*Wangtian Shen,Jinming Ma,Mingliang Zhou,Ziyang Meng*

Main category: cs.RO

TL;DR: 提出Di-BM方法，使用混合专家模型学习多样化技能，解决多任务模仿学习中任务间干扰导致的性能下降问题


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习模型在单任务上表现良好，但在多任务设置中性能下降，因为任务间干扰导致平均效应。需要解决多任务模仿学习中的技能干扰问题。

Method: 提出Di-BM方法，使用混合专家模型，每个专家关联不同的观测分布，专注于观测空间的子区域。采用基于能量的模型表示专家特定的观测分布，并与相应的动作模型联合训练。

Result: 在多个真实世界机器人操作任务上的实验表明，Di-BM显著优于现有基线方法。预训练的Di-BM在新任务上微调时表现出更好的数据效率和专家学习知识的可重用性。

Conclusion: Di-BM是一种即插即用的方法，可无缝集成到标准模仿学习方法中，有效解决多任务模仿学习中的干扰问题，提高技能多样性和任务性能。

Abstract: Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM.

</details>


### [202] [ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models](https://arxiv.org/abs/2601.12428)
*Baorui Peng,Wenyao Zhang,Liang Xu,Zekun Qi,Jiazhao Zhang,Hongsi Liu,Wenjun Zeng,Xin Jin*

Main category: cs.RO

TL;DR: ReWorld是一个通过强化学习对齐视频世界模型与物理真实性的框架，使用大规模视频偏好数据集训练分层奖励模型，提升接触丰富操作任务中的物理保真度和任务完成能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于视频的世界模型主要关注视觉生成质量，但忽略了物理保真度、动态一致性和任务逻辑，特别是在接触丰富的操作任务中，这限制了它们在下游任务中的应用。

Method: 1) 构建大规模视频偏好数据集(~235K)；2) 训练分层奖励模型捕捉与人类偏好一致的多维度奖励；3) 提出实用的对齐算法，通过计算高效的PPO风格算法对基于流的世界模型进行后训练。

Result: ReWorld显著提高了生成rollouts的物理保真度、逻辑一致性、具身性和视觉质量，优于先前的方法。

Conclusion: 该框架成功地将基于视频的具身世界模型与物理真实性、任务完成能力、具身合理性和视觉质量对齐，为接触丰富的机器人操作任务提供了更适用的世界模型。

Abstract: Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.

</details>


### [203] [KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter](https://arxiv.org/abs/2601.12463)
*Zi Cong Guo,James R. Forbes,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: KILO-EKF结合标准EKF预测与基于数据学习的Koopman测量模型，通过将测量提升到特征空间实现状态线性化，无需迭代优化即可学习线性高斯测量模型，在四旋翼定位任务中优于传统校准方法。


<details>
  <summary>Details</summary>
Motivation: 传统EKF依赖于精确的传感器模型和校准，对于复杂或校准不良的传感器性能受限。需要一种既能处理复杂传感器特性，又能保持递归滤波效率和结构的灵活方法。

Method: 提出KILO-EKF：1) 标准EKF预测步骤；2) 基于数据学习的Koopman测量模型校正步骤；3) 将测量提升到特征空间使其状态线性化；4) 从地面真实数据中闭式学习线性高斯测量模型，无需迭代优化；5) 推理时使用学习到的提升函数计算雅可比矩阵进行标准EKF更新。

Result: 在四旋翼定位任务（IMU、UWB、激光传感器）中，KILO-EKF比数据校准基线具有更好的精度和一致性，显著优于依赖不完美几何模型的EKF，同时保持实时推理和快速训练。

Conclusion: Koopman启发的测量学习是传统基于模型校准的可扩展替代方案，能够灵活建模复杂传感器，同时保持递归滤波的效率和结构。

Abstract: We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration.

</details>


### [204] [Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions](https://arxiv.org/abs/2601.12479)
*Miquel Kegeleirs,Lorenzo Garattoni,Gianpiero Francesca,Mauro Birattari*

Main category: cs.RO

TL;DR: 提出一种去中心化行人重识别方法，使用自然语言而非视觉嵌入作为主要表示模态，通过视觉语言模型生成文本描述，在机器人集群中协作聚类，实现可解释的群体感知。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉嵌入的方法存在不透明性问题，高维特征向量难以解释。本文旨在通过自然语言表示提升行人重识别系统的透明度、可解释性和可查询性，同时支持去中心化的机器人集群协作。

Method: 每个机器人使用视觉语言模型（VLM）本地检测并生成行人的文本描述（而非特征向量），这些描述在集群中无中心协调地比较和聚类，语言模型将每个聚类提炼为代表性描述，形成可解释的集体感知。

Result: 初步实验表明，该方法在身份一致性方面与基于嵌入的方法具有竞争力，同时在可解释性方面表现更优。尽管当前文本相似度计算和计算负载存在限制，但实现了自然语言查询、增强透明度和可解释的群体行为。

Conclusion: 自然语言作为表示模态能够有效支持去中心化的行人重识别，提升系统的透明度和可解释性。未来工作将改进相似度度量、探索语义导航，并将语言感知扩展到环境元素，主动导航是未来研究方向。

Abstract: We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study.

</details>


### [205] [Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands](https://arxiv.org/abs/2601.12523)
*Cem Suulker,Muhie Al Haimus,Thomas Mack,Mohammad Sheikhsofla,Neri Niccolò Dei,Reza Kashef,Hadi Sadati,Federica Barontini,Fanny Ficuciello,Alberto Arezzo,Bruno Siciliano,Sebastien Ourselin,Kaspar Althoefer*

Main category: cs.RO

TL;DR: 提出一种通过在外壁引入屈曲点来降低弯曲刚度的被动方法，使用不可伸展的直径减小环带，使机器人能够在复杂路径中导航，无需主动转向机制。


<details>
  <summary>Details</summary>
Motivation: 现有尖端生长外翻机器人导航方案依赖人工肌肉或主动转向机制，这些方案增加了结构复杂性，损害了机器人固有的柔软性和顺应性优势。需要一种既能提高机动性又不牺牲软性特征的解决方案。

Method: 在机器人外壁定期集成不可伸展的直径减小环带，形成屈曲点以降低局部弯曲刚度。使用Cosserat杆数学模型量化这种行为，捕捉环带引起的局部刚度降低及其对全局弯曲力学的影响。

Result: 环带使机器人尖端弯曲时的刚度降低高达91%，能够稳定通过弯曲半径低至25mm的180度弯道，显著优于标准外翻机器人在相同条件下的35mm表现。在结肠模型案例研究中验证了可行性。

Conclusion: 该方法通过被动降低弯曲刚度显著提高了外翻机器人的机动性，无需牺牲柔软性或增加机械复杂性，扩展了在高度弯曲路径中的应用潜力，包括管道检查和结肠镜等医疗程序。

Abstract: Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy.

</details>


### [206] [RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments](https://arxiv.org/abs/2601.12701)
*Yunpeng Lyu,Chao Cao,Ji Zhang,Howie Choset,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 本文研究带概率终端的哈密顿路径问题(HPP-PT)，提出RPT*算法保证最优解，并开发HATS系统用于机器人目标搜索，在仿真和真实机器人实验中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统路由问题很少考虑不确定性，而HPP-PT问题在目标搜索中很常见：机器人需要访问所有候选位置寻找目标，每个位置有目标存在的先验概率。挑战在于不仅需要优化顶点访问顺序，还要处理历史依赖性——期望路径成本取决于先前访问顶点的顺序。

Method: 提出RPT*搜索算法，利用动态规划在新的状态空间中绕过历史依赖性，并设计新颖的启发式函数加速计算。基于RPT*构建分层自主目标搜索(HATS)系统，结合贝叶斯滤波处理带噪声传感器的终身目标搜索，或自主探索未知环境。

Result: 实验表明，该方法能自然平衡利用和探索，在仿真和真实机器人实验中，平均找到目标的速度比基线方法更快。

Conclusion: HPP-PT是目标搜索中的重要问题，提出的RPT*算法能保证最优解，HATS系统能有效处理不确定性环境中的目标搜索任务，在利用和探索之间取得良好平衡。

Abstract: Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods.

</details>


### [207] [AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation](https://arxiv.org/abs/2601.12742)
*Xuecheng Chen,Zongzhuo Liu,Jianfa Ma,Bang Du,Tiantian Zhang,Xueqian Wang,Boyu Zhou*

Main category: cs.RO

TL;DR: AirHunt是一个无人机开放集物体导航系统，通过异步双路径架构融合视觉语言模型语义推理与连续路径规划，实现高效户外物体搜索


<details>
  <summary>Details</summary>
Motivation: 现有系统难以将大型视觉语言模型集成到实际空中系统中，因为VLM推理频率与实时规划存在数量级不匹配，且VLM的3D场景理解有限，缺乏平衡语义引导与运动效率的统一机制

Method: 采用双路径异步架构建立VLM推理与路径规划的协同接口；提出主动双任务推理模块利用几何和语义冗余实现选择性VLM查询；设计语义-几何一致规划模块在统一框架中动态协调语义优先级与运动效率

Result: 在多样化物体导航任务和环境中评估，相比最先进方法具有更高的成功率、更低的导航误差和更短的飞行时间；真实世界实验验证了在复杂挑战环境中的实际能力

Conclusion: AirHunt通过无缝融合VLM语义推理与连续路径规划，实现了户外环境中零样本泛化的高效开放集物体定位，解决了VLM集成到实际空中系统的关键挑战

Abstract: Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.

</details>


### [208] [FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation](https://arxiv.org/abs/2601.12790)
*Yang Zhang,Jianming Ma,Liyun Yan,Zhanxiang Cao,Yazhou Zhang,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: FocusNav是一个空间选择性注意力框架，通过自适应调节人形机器人的感知范围来平衡长程导航目标和即时运动稳定性，在动态复杂环境中显著提升导航成功率。


<details>
  <summary>Details</summary>
Motivation: 在非结构化和动态环境中，人形机器人的鲁棒局部导航面临重大挑战，需要平衡长程导航目标和即时运动稳定性之间的矛盾。

Method: 提出FocusNav框架，包含两个核心模块：1) 路点引导的空间交叉注意力机制，将环境特征聚合锚定到预测的无碰撞路点序列上；2) 稳定性感知选择性门控模块，在检测到不稳定时自动截断远端信息，迫使策略优先考虑即时立足点安全。

Result: 在Unitree G1人形机器人上的大量实验表明，FocusNav在挑战性场景中显著提高了导航成功率，在避碰和运动稳定性方面均优于基线方法，实现了动态复杂环境中的鲁棒导航。

Conclusion: FocusNav通过空间选择性注意力框架有效解决了人形机器人在非结构化动态环境中的导航挑战，平衡了长程目标与即时稳定性需求，为复杂环境中的鲁棒导航提供了有效解决方案。

Abstract: Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments.

</details>


### [209] [Contact-Aware Neural Dynamics](https://arxiv.org/abs/2601.12796)
*Changwei Jing,Jai Krishna Bandi,Jianglong Ye,Yan Duan,Pieter Abbeel,Xiaolong Wang,Sha Yi*

Main category: cs.RO

TL;DR: 提出隐式仿真对齐框架，通过接触感知的神经动力学模型，利用真实世界观测数据（特别是触觉接触信息）来修正仿真器状态，从而缩小仿真与现实的差距。


<details>
  <summary>Details</summary>
Motivation: 传统显式系统辨识方法在调整仿真器参数时，难以对齐真实世界中复杂、动态、不连续的物理接触交互，导致仿真与现实差距持续存在，特别是在接触密集的任务中。

Method: 将现成仿真器作为基础先验，学习一个接触感知的神经动力学模型，利用真实世界观测数据（特别是机器人手的触觉接触信息）来修正仿真状态，从而对齐仿真器与真实世界的动力学。

Result: 该方法提高了状态预测的准确性，并能有效预测策略性能，优化纯在标准仿真器中训练的策略，为仿真对齐提供了可扩展的数据驱动方法。

Conclusion: 通过隐式仿真对齐框架，利用触觉接触信息建模接触任务中的非平滑不连续性，可以实现更准确的仿真与现实对齐，为机器人学习提供更可靠的仿真环境。

Abstract: High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment.

</details>


### [210] [FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions](https://arxiv.org/abs/2601.12799)
*Peng Li,Zihan Zhuang,Yangfan Gao,Yi Dong,Sixian Li,Changhao Jiang,Shihan Dou,Zhiheng Xi,Enyu Zhou,Jixuan Huang,Hui Li,Jingjing Gong,Xingjun Ma,Tao Gui,Zuxuan Wu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Xipeng Qiu*

Main category: cs.RO

TL;DR: FRoM-W1是一个开源框架，通过自然语言实现人形机器人全身运动控制，包含H-GPT（语言驱动的人类运动生成）和H-ACT（机器人运动控制）两阶段，在Unitree H1和G1机器人上验证有效。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人的运动通常是硬编码或专门训练的，限制了其通用性。需要一种能够通过自然语言指令控制机器人执行多样化动作的通用框架。

Method: 采用两阶段框架：1) H-GPT：利用大规模人类数据训练语言驱动的全身运动生成模型，使用Chain-of-Thought技术提升指令理解泛化能力；2) H-ACT：将生成的人类运动重定向为机器人动作，通过强化学习在物理仿真中预训练和微调运动控制器，并通过仿真到现实的模块化部署到真实机器人。

Result: 在HumanML3D-X基准测试中表现出优越的人类全身运动生成性能，强化学习微调显著提高了人形机器人的运动跟踪精度和任务成功率，在Unitree H1和G1机器人上验证有效。

Conclusion: FRoM-W1框架成功实现了通过自然语言控制人形机器人执行多样化动作，开源该框架有望推动人形智能的发展。

Abstract: Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.

</details>


### [211] [Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning](https://arxiv.org/abs/2601.12894)
*Kangye Ji,Yuan Meng,Zhou Jianbo,Ye Li,Hanyun Cui,Zhi Wang*

Main category: cs.RO

TL;DR: SAG提出了一种稀疏动作生成方法，通过自适应剪枝和重用机制加速扩散策略，实现4倍速度提升而不损失性能。


<details>
  <summary>Details</summary>
Motivation: 扩散策略虽然能建模多模态动作分布，但其多步去噪过程在实时视觉运动控制中不实用。现有的基于缓存的加速方法使用静态调度，无法适应机器人-环境交互的动态变化，导致性能不佳。

Method: SAG采用rollout-adaptive prune-then-reuse机制：1) 全局识别可剪枝计算；2) 重用缓存激活替代剪枝部分。通过观察条件扩散剪枝器实现环境感知自适应，采用参数和推理高效设计。引入zig-zag方式跨时间步和块重用激活，最小化全局冗余。

Result: 在多个机器人基准测试中，SAG实现了高达4倍的生成速度提升，且不牺牲性能。

Conclusion: SAG通过自适应剪枝和重用机制，有效解决了扩散策略在实时控制中的计算效率问题，为实时机器人控制提供了实用解决方案。

Abstract: Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\textit{static}$ schedules that fail to adapt to the $\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\underline{\textbf{S}}$parse $\underline{\textbf{A}}$ction$\underline{\textbf{G}}$en ($\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.

</details>


### [212] [PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning](https://arxiv.org/abs/2601.12901)
*Hongchen Li,Tianyu Li,Jiazhi Yang,Haochen Tian,Caojun Wang,Lei Shi,Mingyang Shang,Zengrong Lin,Gaoqiang Wu,Zhihui Hao,Xianpeng Lang,Jia Hu,Hongyang Li*

Main category: cs.RO

TL;DR: PlannerRFT：用于扩散规划器的样本高效强化微调框架，通过双分支优化提升轨迹生成的多模态性和场景适应性


<details>
  <summary>Details</summary>
Motivation: 现有扩散规划器通过强化微调增强鲁棒性，但难以生成多模态、场景自适应的轨迹，限制了奖励信息的利用效率

Method: 提出PlannerRFT框架，采用双分支优化：同时精炼轨迹分布并自适应引导去噪过程；开发nuMax优化模拟器，实现10倍加速

Result: PlannerRFT实现了最先进的性能，学习过程中出现明显的行为分化，且样本效率高

Conclusion: PlannerRFT有效解决了扩散规划器在多模态轨迹生成和场景适应性方面的限制，为自动驾驶轨迹规划提供了更高效的强化微调方案

Abstract: Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process.

</details>


### [213] [Dynamic Hand Gesture Recognition for Robot Manipulator Tasks](https://arxiv.org/abs/2601.12918)
*Dharmendra Sharma,Peeyush Thakur,Sandeep Gupta,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 提出基于高斯混合模型的无监督方法，实时准确识别动态手势变化，用于人机交互


<details>
  <summary>Details</summary>
Motivation: 实现人与机器人之间无缝交互，通过动态手势控制机器人操作任务，需要处理手势的动态变化

Method: 使用基于高斯混合模型的无监督模型，实时识别不同手势的动态变化

Result: 训练和实时测试都显示出高准确率，证明了方法的有效性

Conclusion: 提出的无监督方法能够准确识别动态手势变化，为人机交互提供了有效的解决方案

Abstract: This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.

</details>


### [214] [ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation](https://arxiv.org/abs/2601.12925)
*Weize Xie,Yi Ding,Ying He,Leilei Wang,Binwen Bai,Zheyi Zhao,Chenyang Wang,F. Richard Yu*

Main category: cs.RO

TL;DR: ForeDiffusion通过将预测的未来视觉表示注入扩散过程，结合去噪损失和未来观测一致性损失，显著提升复杂机器人操作任务的性能


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在任务复杂度增加时成功率显著下降，主要面临两个限制：1) 仅依赖短期观测作为条件；2) 训练目标仅限于单一去噪损失，导致误差累积和抓取偏差

Method: 提出前瞻条件扩散(ForeDiffusion)，将预测的未来视觉表示注入扩散过程，使策略具有前瞻性以纠正轨迹偏差。采用双重损失机制：传统去噪损失+未来观测一致性损失

Result: 在Adroit套件和MetaWorld基准测试中，ForeDiffusion平均成功率80%，在复杂任务中比现有主流扩散方法提升23%，且在整个任务中保持更稳定的性能

Conclusion: 通过注入未来视觉表示和双重损失优化，ForeDiffusion有效解决了现有扩散策略的局限性，显著提升了复杂机器人操作任务的性能

Abstract: Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.

</details>


### [215] [Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design](https://arxiv.org/abs/2601.12939)
*Kaleem Arshid,Ali Krayani,Lucio Marcenaro,David Martin Gomez,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 提出基于主动推理的无人机集群自主轨迹设计框架，通过概率推理和自学习实现分布式任务分配、路径排序和运动规划，比Q学习收敛更快、稳定性更高、导航更安全。


<details>
  <summary>Details</summary>
Motivation: 需要为无人机集群开发智能自主控制框架，能够处理动态环境中的分布式任务分配、路径规划和运动协调，传统方法在适应性和认知能力方面存在局限。

Method: 使用遗传算法与排斥力（GA-RF）生成专家轨迹，训练分层世界模型捕捉集群在任务、路径和运动层面的行为；在线运行时，无人机通过最小化当前信念与模型预测状态之间的分歧来推断动作。

Result: 仿真结果显示，相比Q学习，该方法具有更快的收敛速度、更高的稳定性和更安全的导航性能，证明了框架的可扩展性和认知基础。

Conclusion: 提出的主动推理框架为智能无人机集群控制提供了有效的解决方案，展示了在动态环境中自适应响应的能力，具有实际应用潜力。

Abstract: This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.

</details>


### [216] [Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration](https://arxiv.org/abs/2601.12952)
*Shibo Shao,Dong Zhou,Guanghui Sun,Liwen Zhang,Mingxuan Jiang*

Main category: cs.RO

TL;DR: 提出基于模仿学习的航天器交会对接控制框架IL-SRD，通过从专家演示直接学习控制策略，减少对精确模型的依赖，实现准确且节能的无模型控制。


<details>
  <summary>Details</summary>
Motivation: 现有航天器交会对接控制方法主要依赖预定义动力学模型，在实际在轨环境中鲁棒性有限。需要减少对精确建模的依赖，提高在实际环境中的控制性能。

Method: 提出IL-SRD框架：1) 基于模仿学习直接从专家演示学习控制策略；2) 提出锚定解码器目标机制，将解码器查询条件化于状态相关锚点，约束控制生成过程；3) 引入时间聚合机制缓解Transformer模型序列预测中的误差累积问题。

Result: 大量仿真结果表明，IL-SRD框架实现了准确且节能的无模型交会对接控制。鲁棒性评估进一步证实其在显著未知扰动下仍能保持竞争力性能。

Conclusion: IL-SRD框架通过模仿学习和创新的锚定解码器机制，成功实现了鲁棒的六自由度航天器交会对接控制，减少了对精确动力学模型的依赖，在实际在轨环境中表现出色。

Abstract: Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD.

</details>


### [217] [Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization](https://arxiv.org/abs/2601.12993)
*Hao Luo,Ye Wang,Wanpeng Zhang,Sipeng Zheng,Ziheng Xi,Chaoyi Xu,Haiweng Xu,Haoqi Yuan,Chi Zhang,Yiqing Wang,Yicheng Feng,Zongqing Lu*

Main category: cs.RO

TL;DR: Being-H0.5是一个基础视觉-语言-动作模型，通过人类中心学习范式实现跨机器人平台的泛化，使用统一动作空间和混合变换器架构，在模拟基准和真实机器人上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在处理机器人形态异质性和数据稀缺方面存在困难，需要一种能够跨不同机器人平台泛化的解决方案。

Method: 1) 提出人类中心学习范式，将人类交互轨迹视为物理交互的"母语"；2) 构建UniHand-2.0预训练配方（35,000小时多模态数据）；3) 设计统一动作空间映射异构控制；4) 采用混合变换器架构，包含新颖的混合流框架；5) 引入流形保持门控和通用异步分块技术。

Result: 在LIBERO基准上达到98.9%，RoboCasa上达到53.9%的SOTA性能，并在五个机器人平台上展现出强大的跨平台泛化能力。

Conclusion: Being-H0.5通过人类中心范式、统一动作空间和先进架构设计，成功实现了跨机器人平台的稳健泛化，为VLA模型的实际部署提供了有效解决方案。

Abstract: We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal "mother tongue" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.

</details>


### [218] [Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks](https://arxiv.org/abs/2601.13042)
*Yijun Zhou,Muhan Hou,Kim Baraka*

Main category: cs.RO

TL;DR: 比较VR控制器和SpaceMouse在静态和动态任务中的表现，发现VR在成功率、执行时间、工作负荷和可用性方面均有显著优势，并开源了VR接口


<details>
  <summary>Details</summary>
Motivation: 模仿学习依赖高质量演示数据，遥操作是主要收集方式。先前研究主要关注静态任务，但演示数据也包含需要反应控制的动态任务。动态任务对接口有不同需求，静态任务的评估结果无法推广到动态任务

Method: 进行受试者内研究，比较VR控制器和SpaceMouse在2个静态任务和2个动态任务中的表现（N=25）。评估成功率、任务时长、累积成功率，以及NASA-TLX工作负荷量表、系统可用性量表和开放式反馈

Result: VR控制器在多个指标上表现出统计显著优势：更高的成功率（尤其在动态任务中）、更短的成功执行时间、更早的成功尝试，以及显著更低的工作负荷和更高的可用性

Conclusion: VR控制器在动态任务遥操作中优于SpaceMouse，现有VR遥操作系统很少开源或不适合动态任务，因此开源了VR接口以填补这一空白

Abstract: Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap.

</details>


### [219] [Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones](https://arxiv.org/abs/2601.13088)
*Harry Huang,Talia Xu,Marco Zúñiga Zamalloa*

Main category: cs.RO

TL;DR: 提出一种紧凑型自持LTA无人机，利用光能同时进行能量收集和导航，实现室内外持久自主监测


<details>
  <summary>Details</summary>
Motivation: 微型无人机续航短且GPS拒止环境下导航不可靠，而LTA无人机虽能效高但设计复杂，缺乏简单低基础设施的自主运行解决方案

Method: 三方面贡献：1)高保真仿真框架分析LTA空气动力学并选择稳定高效配置；2)在气囊上集成太阳能电池实现净正能量；3)基于单个光信标的点对点导航系统，包含三种光寻算法

Result: 在80klux光照下，每4分钟能量收集可提供1分钟飞行时间；在室内外环境中，可导航至7米远的光源，即使在中等风力下也能稳健运行

Conclusion: 该系统为室内外监测提供了持久自主运行的可行路径，为LTA无人机实现持久自持空中系统提供了实用途径

Abstract: Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.
  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.
  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system.

</details>


### [220] [LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System](https://arxiv.org/abs/2601.13096)
*Muhayy Ud Din,Waseem Akram,Ahsan B. Bakht,Irfan Hussain*

Main category: cs.RO

TL;DR: 提出一个结合大型语言模型（LLM）和视觉语言模型（VLM）的集成工程框架，用于实现自主的海港检查，通过协同的空中和水面机器人平台进行自适应监控。


<details>
  <summary>Details</summary>
Motivation: 现有海港检查方法依赖人工操作和传统计算机视觉技术，缺乏可扩展性和上下文理解能力，需要更智能、自适应的检查系统。

Method: 使用LLM驱动符号规划替代传统状态机任务规划器，将自然语言任务指令转换为可执行的符号计划；利用VLM进行实时语义检查和合规性评估；采用轻量级机载设计，适用于资源受限的海事平台。

Result: 在扩展的MBZIRC海事模拟器中验证了框架的有效性，并在真实世界机器人检查试验中进一步评估，实现了上下文感知的自适应监控。

Conclusion: 该框架通过LLM和VLM的协同作用，推进了智能自主检查系统的发展，为复杂海事环境中的安全检查和监管合规提供了创新解决方案。

Abstract: Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection

</details>


### [221] [Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation](https://arxiv.org/abs/2601.13177)
*Behnam Moradkhani,Raghav Sankaranarayanan,Pejman Kheradmand,Harshith Jella,Nicholas Ahn,Ajmal Zemmar,Yash Chitalia*

Main category: cs.RO

TL;DR: 开发用于脊髓刺激的机器人导航工具ExoNav，通过静态建模实现精确的腹侧/外侧硬膜外空间导航，支持跟随引导运动，在幻影模型中成功演示


<details>
  <summary>Details</summary>
Motivation: 脊髓刺激用于疼痛管理和脊髓损伤功能恢复，但当前手动导航难以精确到达腹侧/外侧硬膜外空间，需要开发机器人导航工具

Method: 采用Cosserat杆框架建立肌腱驱动力与机器人形状关系，考虑重力等外部载荷，开发静态建模方法，实现跟随引导运动

Result: 四个原型测试RMSE为1.76-2.33mm，跟随引导运动最大RMSE为3.75mm，在幻影模型中成功导航到脊髓腹侧/外侧目标和背根神经节

Conclusion: ExoNav机器人系统能够精确导航到脊髓腹侧/外侧硬膜外空间，在脊髓刺激应用中具有潜力，可用于运动功能恢复和疼痛管理

Abstract: Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management.

</details>


### [222] [Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations](https://arxiv.org/abs/2601.13196)
*Jacob Swindell,Marija Popović,Riccardo Polvara*

Main category: cs.RO

TL;DR: 本文研究了在无人机杂草测绘中，不同高斯过程离散化表示对测绘质量和任务性能的影响，发现离散化选择显著影响探索行为、效率和计算负载。


<details>
  <summary>Details</summary>
Motivation: 传统无人机杂草测绘方法使用固定的飞行路径和离线处理，而信息路径规划（IPP）可以自适应地收集数据。高斯过程（GP）能提供杂草分布的连续模型和不确定性，但需要离散化才能用于自主规划。然而，不同离散化表示对测绘性能的影响尚不清楚。

Method: 采用配备下视摄像头的无人机，实现基于地图不确定性、旅行成本和覆盖惩罚的滚动时域IPP策略。研究了多种GP后验离散化策略，使用其诱导的地图分区生成规划候选视点。在真实杂草分布上进行实验。

Result: 实验表明，离散化表示选择显著影响探索行为和效率。不同的表示策略会导致不同的规划动态、覆盖效率和计算负载。

Conclusion: 离散化不仅仅是表示细节，而是影响在线无人机杂草测绘中规划动态、覆盖效率和计算负载的关键设计选择。

Abstract: Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping.

</details>


### [223] [MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation](https://arxiv.org/abs/2601.13232)
*Kourosh Darvish,Arjun Sohal,Abhijoy Mandal,Hatem Fakhruldeen,Nikola Radulov,Zhengxue Zhou,Satheeshkumar Veeramani,Joshua Choi,Sijie Han,Brayden Zhang,Jeeyeoun Chae,Alex Wright,Yijie Wang,Hossein Darvish,Yuchi Zhao,Gary Tom,Han Hao,Miroslav Bogdanovic,Gabriella Pizzuto,Andrew I. Cooper,Alán Aspuru-Guzik,Florian Shkurti,Animesh Garg*

Main category: cs.RO

TL;DR: MATTERIX是一个多尺度GPU加速的机器人仿真框架，用于创建化学实验室的高保真数字孪生，加速实验工作流程开发，减少对昂贵真实实验的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前材料发现依赖于大量真实实验试错，这限制了可扩展性。需要开发能够减少物理实验迭代的数字仿真工具来加速工作流程开发。

Method: 开发了多尺度GPU加速仿真框架，集成真实物理仿真和照片级渲染，结合模块化GPU加速语义引擎，模拟机器人操作、粉末液体动力学、设备功能、热传递和化学反应动力学。

Result: 实现了从仿真到现实的转移，能够在硅基环境中测试假设的自动化工作流程，减少对昂贵真实实验的依赖。

Conclusion: MATTERIX框架通过创建化学实验室的数字孪生，加速了材料发现工作流程的开发，为自动化化学实验提供了强大的仿真测试平台。

Abstract: Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ .

</details>


### [224] [Diffusion-based Inverse Model of a Distributed Tactile Sensor for Object Pose Estimation](https://arxiv.org/abs/2601.13250)
*Ante Marić,Giammarco Caroleo,Alessandro Albini,Julius Jankowski,Perla Maiolino,Sylvain Calinon*

Main category: cs.RO

TL;DR: 提出一种基于去噪扩散的逆触觉传感器模型，用于在视觉受限场景下进行物体姿态估计，通过粒子滤波器集成实现高效采样和准确估计


<details>
  <summary>Details</summary>
Motivation: 在遮挡或环境限制导致视觉信息受限的操控场景中，触觉感知为物体姿态估计提供了有前景的感知方式。然而，由于部分可观测性（单个触觉观测对应多种可能的接触配置），高效利用触觉数据进行估计仍然具有挑战性，这限制了传统主要为视觉设计的估计方法。

Method: 1. 使用去噪扩散学习逆触觉传感器模型；2. 模型以分布式触觉传感器的观测为条件，在仿真中使用基于符号距离场的几何传感器模型进行训练；3. 在推理过程中通过单步投影使用符号距离场的距离和梯度信息强制执行接触约束；4. 通过将生成假设与先验信念粒子结合的提议方案，将逆模型与粒子滤波器集成用于在线姿态估计。

Result: 在模拟和真实世界的平面姿态估计场景中验证了该方法，无需视觉数据或紧密的初始姿态先验。在推箱场景中进一步评估了对未建模接触和传感器动态的鲁棒性。与局部采样基线相比，逆传感器模型提高了采样效率和估计精度，同时在不同触觉可区分性的物体上保持了多模态信念。

Conclusion: 提出的基于扩散的逆触觉传感器模型能够有效解决触觉姿态估计中的部分可观测性问题，通过与粒子滤波器集成实现了高效准确的在线估计，在视觉受限的操控场景中具有实际应用价值。

Abstract: Tactile sensing provides a promising sensing modality for object pose estimation in manipulation settings where visual information is limited due to occlusion or environmental effects. However, efficiently leveraging tactile data for estimation remains a challenge due to partial observability, with single observations corresponding to multiple possible contact configurations. This limits conventional estimation approaches largely tailored to vision. We propose to address these challenges by learning an inverse tactile sensor model using denoising diffusion. The model is conditioned on tactile observations from a distributed tactile sensor and trained in simulation using a geometric sensor model based on signed distance fields. Contact constraints are enforced during inference through single-step projection using distance and gradient information from the signed distance field. For online pose estimation, we integrate the inverse model with a particle filter through a proposal scheme that combines generated hypotheses with particles from the prior belief. Our approach is validated in simulated and real-world planar pose estimation settings, without access to visual data or tight initial pose priors. We further evaluate robustness to unmodeled contact and sensor dynamics for pose tracking in a box-pushing scenario. Compared to local sampling baselines, the inverse sensor model improves sampling efficiency and estimation accuracy while preserving multimodal beliefs across objects with varying tactile discriminability.

</details>


### [225] [Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints](https://arxiv.org/abs/2601.13252)
*Mahmud S. Zango,Jianglin Lan*

Main category: cs.RO

TL;DR: 本文综述了纳米无人机自主导航技术，重点分析在100mW以下计算功耗约束下的感知、计算与控制架构，探讨从几何方法到边缘AI的范式转变，并指出当前在动态环境避障、长期续航和Sim-to-Real迁移等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 纳米无人机（重量<50g，处理器功耗<100mW）面临极端的尺寸、重量和功率约束，其自主导航与传统机器人范式有本质区别。需要专门针对这种超低功耗计算环境设计感知、计算和控制架构。

Method: 综合评述了面向100mW以下计算功耗的先进技术：包括从传统几何方法向边缘AI范式的转变，量化深度神经网络在超低功耗SoC上的部署，神经形态事件控制，以及硬件-软件协同设计。涵盖密集光流、优化SLAM和学习型飞行控制等进展。

Result: 视觉导航和相对姿态估计已取得显著进展，但在动态环境中的鲁棒避障、长期续航能力以及强化学习策略的"仿真到现实"迁移方面仍存在明显差距。

Conclusion: 提出通过融合轻量级经典控制与数据驱动感知的混合架构，为在GPS拒止环境中实现完全自主、敏捷的纳米无人机提供技术路线图。

Abstract: Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging "Edge AI" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the "Sim-to-Real" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments.

</details>


### [226] [CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments](https://arxiv.org/abs/2601.13361)
*Pranay Meshram,Charuvahan Adhivarahan,Ehsan Tarkesh Esfahani,Souma Chowdhury,Chen Wang,Karthik Dantu*

Main category: cs.RO

TL;DR: CLEAR提出了一种结合边界感知空间分解和递归平面拟合的地形抽象表示方法，用于大规模非结构化环境的长距离导航规划，相比现有方法具有更好的可扩展性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有地形抽象方法（如网格和四叉树）在扩展到数十平方公里时存在局限性：网格扩展性差，四叉树与地形边界不对齐，且都缺乏对土地覆盖语义的编码，这导致自主地面车辆在10+平方公里实时约束下的路径规划不可行或不可靠。

Method: CLEAR（Connected Landcover Elevation Abstract Representation）通过边界感知空间分解与递归平面拟合相结合，生成凸的、语义对齐的区域，并将其编码为地形感知图。

Result: 在9-100平方公里的地图上使用基于物理的模拟器评估，CLEAR比原始网格规划快10倍，仅增加6.7%的成本开销，相比其他抽象基线提供6-9%更短、更可靠的路径。

Conclusion: CLEAR展示了在大规模非结构化环境中长距离导航的可扩展性和实用性，适用于灾害响应、国防和行星探索等应用。

Abstract: Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration.

</details>


### [227] [Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections](https://arxiv.org/abs/2601.13389)
*Zhaohui Liang,Chengyuan Ma,Keke Long,Xiaopeng Li*

Main category: cs.RO

TL;DR: 提出统一框架评估生态驾驶策略，通过控制鲁棒性和环境适应性两个互补标准，量化内部执行变异和外部环境干扰的影响，并通过实车实验揭示不同控制器的性能权衡


<details>
  <summary>Details</summary>
Motivation: 现有生态驾驶策略评估通常依赖简化模拟或实验条件，需要更全面的评估框架来量化策略在实际复杂环境中的性能表现

Method: 提出统一评估框架，定义量化内部执行变异和外部环境干扰的正式指标，通过实车实验评估多种生态驾驶控制器

Result: 优化型控制器在不同干扰水平下表现更一致，而解析型控制器在名义条件下性能相当但对执行和时序变异更敏感，揭示了跟踪精度与适应性之间的关键权衡

Conclusion: 生态驾驶策略评估需要考虑控制鲁棒性和环境适应性的双重标准，优化型控制器在实际复杂环境中可能更具优势

Abstract: Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability.

</details>


### [228] [Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization](https://arxiv.org/abs/2601.13451)
*Reza Ahmadvand,Sarah Safura Sharif,Yaser Mike Banad*

Main category: cs.RO

TL;DR: 提出了一种结合混合神经网络和脉冲神经网络的机器人视觉导航框架，用于未建模障碍物检测和定位，实现了准确环境理解和高效处理


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人在不可预测动态环境中导航时，需要同时实现准确环境理解和高效实时处理的问题。传统方法要么计算成本高，要么无法有效处理动态事件数据。

Method: 采用双通路架构：ANN组件处理低频静态空间特征，SNN组件实时处理动态事件传感器数据。系统包含预开发的SNN滤波器，直接使用脉冲编码输入进行定位和状态估计。检测到的异常通过ANN通路上下文信息验证并持续跟踪。

Result: 仿真结果表明，该方法在保持接近纯SNN实现的计算效率的同时，提供了可接受的检测精度。纯SNN实现的资源成本仅为传统方法的一小部分。

Conclusion: 该框架代表了神经形态导航系统的重大进展，特别适用于在不可预测动态环境中操作的机器人，实现了准确性和效率的良好平衡。

Abstract: This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.

</details>


### [229] [The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study](https://arxiv.org/abs/2601.13529)
*Pejman Kheradmand,Kent K. Yamamoto,Emma Webster,Keith Sowards,Gianna Hatheway,Katharine L. Jackson,Sabino Zani,Julie A. Raffi,Diandra N. Ayala-Peacock,Scott R. Silva,Joanna Deaton Bertram,Yash Chitalia*

Main category: cs.RO

TL;DR: 开发用于宫颈癌间质近距离放射治疗的OncoReach可操纵导丝，兼容标准针头，通过不对称关节设计提高弯曲柔顺性，在患者衍生模型中验证了从内侧入路到达外侧靶点的能力。


<details>
  <summary>Details</summary>
Motivation: 宫颈癌是女性主要癌症负担之一，间质近距离放射治疗是标准治疗，但传统直针限制了手术规划只能采用线性路径，需要可操纵的器械来改善靶点到达能力。

Method: 开发手持式肌腱驱动可操纵导丝，评估针头规格、球形关节数量和位置等设计参数，采用不对称圆盘设计，使用两管Cosserat杆模型预测针头中心线形状，在患者衍生多复合子宫骨盆模型中进行试点研究。

Result: 最佳配置实现了最大弯曲柔顺性同时保持轴向刚度，自由空间实验量化了尖端偏转，模型准确预测了大多数试验的针头中心线形状，在患者衍生模型中成功从内侧入路到达外侧靶点。

Conclusion: OncoReach可操纵导丝展示了在宫颈癌间质近距离放射治疗中从微创内侧入路到达外侧靶点的能力，证明了可操纵导丝在改善治疗规划中的重要性。

Abstract: Cervical cancer accounts for a significant portion of the global cancer burden among women. Interstitial brachytherapy (ISBT) is a standard procedure for treating cervical cancer; it involves placing a radioactive source through a straight hollow needle within or in close proximity to the tumor and surrounding tissue. However, the use of straight needles limits surgical planning to a linear needle path. We present the OncoReach stylet, a handheld, tendon-driven steerable stylet designed for compatibility with standard ISBT 15- and 13-gauge needles. Building upon our prior work, we evaluated design parameters like needle gauge, spherical joint count and spherical joint placement, including an asymmetric disk design to identify a configuration that maximizes bending compliance while retaining axial stiffness. Free space experiments quantified tip deflection across configurations, and a two-tube Cosserat rod model accurately predicted the centerline shape of the needle for most trials. The best performing configuration was integrated into a reusable handheld prototype that enables manual actuation. A patient-derived, multi-composite phantom model of the uterus and pelvis was developed to conduct a pilot study of the OncoReach steerable stylet with one expert user. Results showed the ability to steer from less-invasive, medial entry points to reach the lateral-most targets, underscoring the significance of steerable stylets.

</details>


### [230] [LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI](https://arxiv.org/abs/2601.13556)
*Jianan Wang,Siyang Zhang,Bin Li,Juan Chen,Jingtao Qi,Zhuo Zhang,Chen Qian*

Main category: cs.RO

TL;DR: LogicEnvGen：基于LLM的模拟环境生成方法，通过分析任务执行逻辑构建决策树行为计划，生成逻辑多样化的测试环境，显著提升代理故障检测能力


<details>
  <summary>Details</summary>
Motivation: 现有环境生成方法过于注重视觉真实性而忽视逻辑多样性，这限制了全面评估代理适应性和规划鲁棒性。需要从测试角度生成逻辑多样化的环境作为测试用例

Method: 采用自上而下范式：1) 分析任务执行逻辑构建决策树行为计划；2) 合成逻辑轨迹集；3) 使用启发式算法优化轨迹集减少冗余；4) 为每个逻辑轨迹实例化具体环境；5) 采用约束求解确保物理合理性

Result: 实验验证基线方法缺乏逻辑多样性，LogicEnvGen实现1.04-2.61倍的多样性提升，显著提高代理故障检测性能4.00%-68.00%

Conclusion: LogicEnvGen通过生成逻辑多样化的模拟环境，有效提升了代理测试的全面性和故障检测能力，为具身AI测试提供了新方法

Abstract: Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.

</details>


### [231] [Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction](https://arxiv.org/abs/2601.13574)
*Guanyu Xu,Jiaqi Wang,Dezhong Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 提出一种基于光学波导传感的软性、柔性、可拉伸的硅胶膜，通过数据驱动模型解码变形相关光强信号，实时重建三维几何形状，用于可变形机器人系统的全局形状感知。


<details>
  <summary>Details</summary>
Motivation: 基于视觉的三维表面重建在低光照或遮挡条件下不可靠，而传统形状感知膜存在结构复杂、大变形时柔顺性有限、易受电磁干扰等问题，需要一种更可靠的解决方案。

Method: 设计基于光学波导传感的软性硅胶膜，集成边缘安装的LED和中心分布的光电二极管，通过液态金属迹线连接，利用数据驱动模型解码变形相关光强信号来重建三维点云。

Result: 在140mm方形膜上实现90Hz实时重建，平均重建误差1.3mm（Chamfer距离），对高达25mm的压痕保持精度，提供可扩展、鲁棒、低轮廓的解决方案。

Conclusion: 该光学波导传感膜为可变形机器人系统提供了一种可扩展、鲁棒且低轮廓的全局形状感知解决方案，克服了传统方法的局限性。

Abstract: Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems.

</details>


### [232] [A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint](https://arxiv.org/abs/2601.13639)
*Deyun Qin,Zezhi Liu,Hanqian Luo,Xiao Liang,Yongchun Fang*

Main category: cs.RO

TL;DR: 提出一种用于机器人操作的单次多模态主动感知框架，通过直接推理最优视点，显著提升抓取成功率并实现无缝的仿真到真实迁移。


<details>
  <summary>Details</summary>
Motivation: 现有主动感知方法依赖迭代优化，导致时间和运动成本高，且与任务特定目标紧密耦合，限制了可迁移性。需要一种通用、高效的主动感知框架。

Method: 提出单次多模态主动感知框架，包含数据收集流程和最优视点预测网络。框架将视点质量评估与整体架构解耦，通过系统采样和评估定义最优视点，利用域随机化构建大规模训练数据集，开发基于跨注意力机制的多模态特征对齐和融合网络，直接预测相机姿态调整。

Result: 在视点受限环境下的机器人抓取任务中，该框架指导的主动感知显著提高了抓取成功率。真实世界评估实现了近两倍的抓取成功率，且无需额外微调即可实现无缝的仿真到真实迁移。

Conclusion: 提出的通用单次多模态主动感知框架有效解决了现有方法的局限性，显著提升了机器人操作的感知质量，并展示了优秀的可迁移性和实用性。

Abstract: Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motion costs, and are tightly coupled with task-specific objectives, which limits their transferability. In this paper, we propose a general one-shot multimodal active perception framework for robotic manipulation. The framework enables direct inference of optimal viewpoints and comprises a data collection pipeline and an optimal viewpoint prediction network. Specifically, the framework decouples viewpoint quality evaluation from the overall architecture, supporting heterogeneous task requirements. Optimal viewpoints are defined through systematic sampling and evaluation of candidate viewpoints, after which large-scale training datasets are constructed via domain randomization. Moreover, a multimodal optimal viewpoint prediction network is developed, leveraging cross-attention to align and fuse multimodal features and directly predict camera pose adjustments. The proposed framework is instantiated in robotic grasping under viewpoint-constrained environments. Experimental results demonstrate that active perception guided by the framework significantly improves grasp success rates. Notably, real-world evaluations achieve nearly double the grasp success rate and enable seamless sim-to-real transfer without additional fine-tuning, demonstrating the effectiveness of the proposed framework.

</details>


### [233] [Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2601.13657)
*Myong-Yol Choi,Hankyoul Ko,Hanse Cho,Changseung Kim,Seunghwan Kim,Jaemin Seo,Hyondong Oh*

Main category: cs.RO

TL;DR: 基于深度强化学习的无人机集群无通信集体导航控制器，仅需机载LiDAR感知，无需外部定位或通信


<details>
  <summary>Details</summary>
Motivation: 解决通信受限环境下无人机集群的集体导航问题，受生物群体中知情个体无需显式通信引导群体的启发

Method: 采用隐式领导者-跟随者框架，仅领导者掌握目标信息，跟随者通过LiDAR点云聚类和扩展卡尔曼滤波进行邻居跟踪，使用GPU加速的Nvidia Isaac Sim训练DRL控制器

Result: 在模拟和真实环境中验证了方法的鲁棒性和仿真到现实的迁移能力，五架无人机组成的集群成功在多种室内外环境中实现无通信集体导航

Conclusion: 提出的DRL控制器使无人机集群仅依赖本地感知即可实现鲁棒的集体导航，解决了遮挡和视野受限等感知挑战，为通信受限环境下的集群应用提供了可行方案

Abstract: This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.

</details>


### [234] [SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation](https://arxiv.org/abs/2601.13732)
*Andreas Wiedholz,Rafael Paintner,Julian Gleißner,Alwin Hoffmann,Tobias Huber*

Main category: cs.RO

TL;DR: SUNSET是一个基于ROS2的机器人软件系统范例，用于在动态环境中评估基于架构的自适应方法，支持不确定性和并发故障的测试。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在动态环境中部署增多，软件系统复杂性增加，需要自适应性方法。机器人系统面临不确定性（症状易观察但根源模糊）和多个不确定性并发出现的问题。

Method: 开发了SUNSET范例，包含传感器融合语义分割流水线，由训练好的ML模型驱动。通过扰动输入预处理来引入性能退化，暴露5个可观察症状，每个症状可由不同根源引起，支持自修复和自优化的并发不确定性。

Result: SUNSET提供了完整的评估框架，包括分割流水线、训练好的ML模型、不确定性注入脚本、基线控制器，以及逐步集成和评估文档，支持可重复研究和公平比较。

Conclusion: SUNSET为在动态、不确定环境中评估机器人软件的自适应方法提供了一个严谨、可重复的范例，有助于推动自适应性机器人系统研究。

Abstract: The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.

</details>


### [235] [RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure](https://arxiv.org/abs/2601.13737)
*Joon Lee,Jeongyoon Han,Doyoung Kim,Seokhwan Jeong*

Main category: cs.RO

TL;DR: 提出柔性RIM手，通过仿生CMC关节和超弹性镍钛诺线骨架实现真实手掌变形，提升抓握稳定性和负载能力


<details>
  <summary>Details</summary>
Motivation: 现有机械手缺乏人类手掌的柔韧性和变形能力，限制了抓握稳定性和适应性。需要开发具有真实手掌变形能力的仿生机械手，以提升在假肢和服务机器人应用中的性能。

Method: 1) 精确复制腕掌关节(CMC)的仿生设计；2) 在整个骨架中使用超弹性镍钛诺线；3) 腱驱动手指实现手掌变形；4) 镍钛诺基背侧伸肌支撑骨骼结构；5) 柔性硅胶皮肤增加接触摩擦和面积

Result: 1) 手掌变形可达28%，匹配人手灵活性；2) 相比刚性手掌设计，负载能力提升2倍以上；3) 接触面积增加3倍；4) 能够稳定抓握多种物体

Conclusion: RIM手在灵巧性、柔顺性和拟人化方面均有显著提升，在假肢和服务机器人应用中具有良好前景，为机械手设计提供了新的仿生解决方案。

Abstract: This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications.

</details>


### [236] [Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System](https://arxiv.org/abs/2601.13777)
*Zvi Chapnik,Yizhar Or,Shai Revzen*

Main category: cs.RO

TL;DR: 比较四种建模方法从运动跟踪数据学习"运动性映射"的能力，发现简单方法在小数据集上表现更好，复杂方法在大数据集上表现更好


<details>
  <summary>Details</summary>
Motivation: 几何力学为生物和机器人系统如何通过形状变化在环境中移动提供了重要见解。在高摩擦环境中，整个相互作用由"运动性映射"捕捉。本文旨在比较从物理机器人运动跟踪数据中学习该映射的方法

Method: 创建了一个专门用于测试的物理机器人，该机器人具有欠驱动自由度和难以建模的基底相互作用。比较了四种建模方法：预测相同步态内、跨步态和跨速度下从形状变化到身体速度的映射能力

Result: 结果显示简单方法和复杂方法之间存在权衡：简单方法在小训练数据集上表现更优，而更复杂的方法在更多训练数据可用时表现更优

Conclusion: 在从运动跟踪数据学习运动性映射时，需要根据可用数据量选择合适的方法：小数据集适合简单方法，大数据集适合复杂方法

Abstract: Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available.

</details>


### [237] [HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction](https://arxiv.org/abs/2601.13801)
*Yuhua Jin,Nikita Kuzmin,Georgii Demianchuk,Mariya Lezina,Fawad Mehboob,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: HoverAI是一个集成了无人机移动性、独立视觉投影和实时对话AI的空中智能体，通过激光投影和自适应虚拟形象实现与用户的自然交互。


<details>
  <summary>Details</summary>
Motivation: 当前无人机在人类环境中缺乏有效的沟通机制，导致用户对其意图产生不确定性。需要一种能够自然交互、表达意图的空中智能体。

Method: 集成MEMS激光投影仪、半刚性屏幕和RGB摄像头，采用多模态处理流程：语音活动检测、语音识别（Whisper）、基于LLM的意图分类、检索增强生成对话、人脸分析个性化、语音合成（XTTS v2）。

Result: 系统在命令识别（F1: 0.90）、人口统计估计（性别F1: 0.89，年龄MAE: 5.14年）和语音转录（WER: 0.181）方面表现出高精度。

Conclusion: HoverAI通过融合空中机器人技术、自适应对话AI和自包含视觉输出，开创了一类空间感知、社会响应的新型具身智能体，适用于引导、协助和人本交互应用。

Abstract: Drones operating in human-occupied spaces suffer from insufficient communication mechanisms that create uncertainty about their intentions. We present HoverAI, an embodied aerial agent that integrates drone mobility, infrastructure-independent visual projection, and real-time conversational AI into a unified platform. Equipped with a MEMS laser projector, onboard semi-rigid screen, and RGB camera, HoverAI perceives users through vision and voice, responding via lip-synced avatars that adapt appearance to user demographics. The system employs a multimodal pipeline combining VAD, ASR (Whisper), LLM-based intent classification, RAG for dialogue, face analysis for personalization, and voice synthesis (XTTS v2). Evaluation demonstrates high accuracy in command recognition (F1: 0.90), demographic estimation (gender F1: 0.89, age MAE: 5.14 years), and speech transcription (WER: 0.181). By uniting aerial robotics with adaptive conversational AI and self-contained visual output, HoverAI introduces a new class of spatially-aware, socially responsive embodied agents for applications in guidance, assistance, and human-centered interaction.

</details>


### [238] [DroneVLA: VLA based Aerial Manipulation](https://arxiv.org/abs/2601.13809)
*Fawad Mehboob,Monijesu James,Amir Habel,Jeffrin Sam,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 本文提出了一种能够理解高级自然语言指令的自主空中操纵系统，通过视觉-语言-动作模型进行语义推理，结合目标检测和路径规划，实现物体抓取和递交给人类用户。


<details>
  <summary>Details</summary>
Motivation: 随着空中平台从被动观察者演变为主动操纵者，需要设计直观的界面让非专业用户能够自然地命令这些系统。现有系统缺乏对高级自然语言指令的理解能力，难以实现安全、自然的物体抓取和交接。

Method: 系统整合了基于Grounding DINO的MediaPipe、视觉-语言-动作模型和定制无人机。VLA模型解析用户指令意图并生成优先级任务队列，Grounding DINO和动态A*算法用于导航和物体定位。交接阶段使用基于MediaPipe的人体姿态估计和视觉伺服控制，确保安全自然的交互。

Result: 通过真实世界实验验证了系统的有效性，定位和导航的最大欧几里得误差为0.164m，平均误差为0.070m，均方根误差为0.084m，证明了VLA模型在空中操纵操作中的可行性。

Conclusion: 该系统成功展示了利用自然语言指令控制空中操纵系统的可行性，实现了从高级指令理解到安全物体交接的完整流程，为人机交互提供了新的解决方案。

Abstract: As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.

</details>


### [239] [GuideTouch: An Obstacle Avoidance Device for Visually Impaired](https://arxiv.org/abs/2601.13813)
*Timofei Kozlov,Artem Trandofilov,Georgii Gazaryan,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: GuideTouch：一款用于视障人士自主避障的紧凑型可穿戴设备，采用ToF传感器进行三维环境感知，通过肩部和上胸部的四点振动触觉反馈系统提供方向信息。


<details>
  <summary>Details</summary>
Motivation: 视障人士的安全导航仍然是一个关键挑战，特别是对于头部高度的障碍物，传统移动辅助工具往往无法检测到。需要一种能够检测头部障碍物并提供直观反馈的解决方案。

Method: 开发了GuideTouch设备，集成两个垂直排列的ToF传感器进行三维环境感知，使用四个振动触觉执行器提供方向性触觉反馈。设备还包括离心自清洁光学盖机制和掉落时的声音警报系统。

Result: 在22名参与者中，触觉感知准确率平均达到92.9%（单/双电机模式）。在14名视障用户的初步实验中，主要方向线索识别准确率达到93.75%。统计分析确认不同模式间的感知准确率存在显著差异。

Conclusion: GuideTouch能够实现直观的空间感知，可以显著提高视障用户在独立导航时的安全性、信心和自主性。该系统展示了高识别准确率，并通过实际用户验证了其有效性。

Abstract: Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation.

</details>


### [240] [Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework](https://arxiv.org/abs/2601.13945)
*Yixuan Deng,Tongrun Wu,Donghao Wu,Zeyu Wei,Jiayuan Wang,Zhenglong Sun,Yuqing Tang,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: ANCHOR是一个模块化框架，将解耦和鲁棒性作为显式系统级原语，通过分离标准化共享状态的可演进契约与通信总线，为闭环AI系统提供可控降级和自我修复能力。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI系统从研究原型转向实际部署，系统快速演进的同时需要在工作负载变化和部分故障下保持可靠。现有部署通常只是部分解耦，中间件传递消息但共享上下文和反馈语义是隐式的，导致接口漂移、跨模块干扰和大规模下的脆弱恢复。

Method: ANCHOR框架包含两个核心组件：(1) Canonical Records - 标准化共享状态的可演进契约；(2) 通信总线 - 用于多对多传播和面向反馈的协调。这两者形成可检查的端到端闭环，将临时集成胶水转变为显式契约。

Result: 在去标识化工作流实例上验证了闭环可行性，表征了不同负载大小和发布速率下的延迟分布，展示了即使在共享内存丢失的情况下，硬崩溃和重启后也能自动恢复流。框架实现了负载下的可控降级和自我修复恢复。

Conclusion: ANCHOR通过将解耦和鲁棒性作为显式系统级原语，为闭环AI系统的可扩展部署提供了可控降级和自我修复恢复能力，将临时集成胶水转变为显式契约。

Abstract: As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.

</details>


### [241] [Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects](https://arxiv.org/abs/2601.13979)
*Raffaele Mazza,Ciro Natale,Pietro Falco*

Main category: cs.RO

TL;DR: 提出了一种新颖的跨模态视觉-触觉感知框架，用于在严重视觉遮挡条件下重建可变形线性物体（如电缆）的3D形状，通过结合基础模型视觉感知和自适应触觉探索来解决视觉方法在遮挡下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉，但在光照变化、背景杂乱或部分可见性差的情况下性能下降。特别是对于电缆等可变形线性物体，严重视觉遮挡会严重影响3D形状重建的准确性。

Method: 1. 视觉管道：使用SAM进行实例分割，Florence进行语义细化，然后骨架化、端点检测和点云提取；2. 触觉探索：自主识别遮挡电缆段，使用触觉传感器获取局部点云；3. 数据融合：通过欧几里得聚类和拓扑保持融合将视觉和触觉数据合并；4. B样条插值：通过端点引导的点排序驱动，生成平滑完整的电缆形状重建。

Result: 实验验证表明，该框架能够准确重建简单和高度弯曲的单根或多根电缆配置，即使大部分被遮挡。使用配备RGB-D相机和触觉垫的机械臂进行测试，展示了在严重遮挡条件下的鲁棒重建能力。

Conclusion: 该研究展示了基础模型增强的跨模态感知在推进可变形物体机器人操纵方面的潜力，为解决视觉遮挡问题提供了一种有效的视觉-触觉融合方法。

Abstract: This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects.

</details>


### [242] [Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior](https://arxiv.org/abs/2601.14000)
*Junwoo Chang,Joseph Park,Roberto Horowitz,Jongmin Lee,Jongeun Choi*

Main category: cs.RO

TL;DR: 提出GISD框架，通过将群结构嵌入技能发现目标，利用环境几何对称性提高无监督技能发现的效率和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法往往忽略物理环境的几何对称性，导致行为冗余和样本效率低下。需要一种能利用环境对称性来发现更有效技能的方法。

Method: 提出群不变技能发现(GISD)框架，基于理论保证：在群对称环境中，标准Wasserstein依赖度量存在由等变策略和群不变评分函数组成的全局最优解。定义群不变Wasserstein依赖度量，将优化限制在这个对称感知子空间中。使用群傅里叶表示参数化评分函数，通过等变潜在特征对齐定义内在奖励。

Result: 在基于状态和基于像素的运动基准测试中，GISD相比强基线实现了更广泛的状态空间覆盖和下游任务学习效率提升。

Conclusion: 通过显式嵌入群结构，GISD能够发现更高效、泛化性更好的技能，利用环境对称性提高无监督技能发现的性能。

Abstract: Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.

</details>


### [243] [Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems](https://arxiv.org/abs/2601.14091)
*Hossein Naderi,Alireza Shojaei,Lifu Huang,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本文探索使用基础模型提升建筑机器人任务规划的适应性和泛化能力，提出四种基于轻量级开源LLM/VLM的模型（一个单智能体和三个多智能体团队），在三个建筑角色任务中评估，发现四智能体团队在多数指标上优于GPT-4o且成本降低十倍。


<details>
  <summary>Details</summary>
Motivation: 建筑机器人面临高成本和难以适应动态任务的挑战，需要提升任务规划的适应性和泛化能力。

Method: 提出并实现四种模型：一个单智能体和三个多智能体协作团队，使用轻量级开源大语言模型（LLM）和视觉语言模型（VLM），在三个建筑角色（油漆工、安全巡检员、地板铺设工）任务中进行评估。

Result: 四智能体团队在多数指标上优于最先进的GPT-4o，同时成本降低十倍；三智能体和四智能体团队展现出更好的泛化能力；通过分析智能体行为对输出的影响，增强了对AI团队的理解。

Conclusion: 多智能体协作方法能有效提升建筑机器人任务规划的适应性和泛化能力，为未来在建筑及其他非结构化环境中的研究提供支持。

Abstract: Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.

</details>


### [244] [Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning](https://arxiv.org/abs/2601.14104)
*Tairan Huang,Qingqing Ye,Yulin Jin,Jiawei Lian,Yi Wang,Haibo Hu*

Main category: cs.RO

TL;DR: 提出DGBA框架，通过扩散模型生成视觉补丁触发器，结合基于优势的投毒策略，在真实世界机器人系统中实现有效的后门攻击，克服了传统攻击在物理部署中被安全约束控制管道抑制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击主要在仿真环境中验证，在真实机器人系统中的有效性不明确。物理部署中的安全约束控制管道（如速度限制、动作平滑、碰撞避免）会抑制异常动作，导致传统后门攻击效果大幅衰减。

Method: 提出扩散引导的后门攻击框架（DGBA）：1）设计可打印的视觉补丁触发器放置在地面上；2）使用条件扩散模型生成多样化的补丁外观以适应真实世界视觉变化；3）将机器人控制栈视为黑盒系统；4）引入基于优势的投毒策略，仅在决策关键训练状态注入触发器。

Result: 在TurtleBot3移动机器人上评估该方法，展示了可靠的目标攻击激活，同时保持了正常的任务性能。补充材料提供了演示视频和代码。

Conclusion: DGBA框架成功解决了真实世界RL系统中后门攻击被安全约束控制管道抑制的问题，通过扩散模型生成适应性触发器和基于优势的投毒策略，实现了在物理机器人系统中的有效后门攻击。

Abstract: Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.

</details>


### [245] [SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media](https://arxiv.org/abs/2601.14128)
*Shoujie Li,Changqing Guo,Junhao Gong,Chenxin Liang,Wenhua Ding,Wenbo Ding*

Main category: cs.RO

TL;DR: SandWorm机器人结合SWTac传感器，通过仿生螺旋驱动和蠕动运动增强颗粒介质中的感知与运动能力，实现管道清淤和地下探测


<details>
  <summary>Details</summary>
Motivation: 颗粒介质中的感知具有挑战性，因为粒子动力学难以预测，需要开发能够在复杂颗粒环境中有效感知和运动的机器人系统

Method: 1) SandWorm仿生机器人：螺旋驱动结合蠕动运动增强运动能力；2) SWTac传感器：事件相机+主动振动弹性体，通过弹簧隔离机制实现高质量触觉成像；3) IMU引导时间滤波算法提升成像一致性；4) 系统优化振动参数、事件相机设置和弹性体特性；5) 基于U-Net实现接触表面估计

Result: SWTac传感器：0.2mm纹理分辨率，98%石块分类准确率，0.15N力估计误差；SandWorm机器人：最高12.5mm/s运动速度，复杂颗粒介质中90%成功率，成功执行管道清淤和地下探测任务

Conclusion: SandWorm系统通过仿生设计和先进感知技术，有效解决了颗粒介质中的感知和运动挑战，在复杂环境中表现出优异的性能，具有实际应用价值

Abstract: Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.

</details>


### [246] [TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers](https://arxiv.org/abs/2601.14133)
*Bin Yu,Shijie Lian,Xiaopeng Lin,Yuliang Wei,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Xinming Wang,Bailing Wang,Cong Huang,Kai Chen*

Main category: cs.RO

TL;DR: TwinBrainVLA通过分离通用视觉语言模型和专用机器人控制模型，解决VLA模型在微调时语义理解与运动技能之间的冲突，实现高性能操控同时保持开放世界理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型在微调用于机器人控制时，会在保持高层语义理解和学习低层精细运动技能之间产生冲突，导致"灾难性遗忘"问题，损害模型的开放世界能力。

Method: 提出TwinBrainVLA架构，协调冻结的通用VLM（左脑）和可训练的专用VLM（右脑），通过非对称Transformer混合机制动态查询语义知识，结合本体感知状态，为流匹配动作专家提供丰富条件生成连续控制。

Result: 在SimplerEnv和RoboCasa基准测试中，TwinBrainVLA实现了优于现有方法的操控性能，同时明确保留了预训练VLM的全面视觉理解能力。

Conclusion: TwinBrainVLA为解决通用机器人同时实现高层语义理解和低层物理灵巧性提供了有前景的方向，通过脑式分工架构平衡了通用性与专业性。

Abstract: Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.

</details>
