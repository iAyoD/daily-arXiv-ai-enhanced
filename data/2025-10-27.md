<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning](https://arxiv.org/abs/2510.20884)
*Pranamya Kulkarni,Puranjay Datta,Burak Varıcı,Emre Acartürk,Karthikeyan Shanmugam,Ali Tajer*

Main category: cs.RO

TL;DR: ROPES是一个基于分数因果表示学习的无监督机器人姿态估计框架，通过利用机器人自然干预（关节控制）来识别可控的潜在变量，无需标注数据即可高保真地解耦生成因素。


<details>
  <summary>Details</summary>
Motivation: 因果表示学习在理论和实际应用之间存在显著差距，本文旨在通过将CRL应用于机器人姿态估计这一具体领域来缩小这一差距，利用机器人自然提供的干预机制。

Method: 提出ROPES框架，利用机器人执行器命令作为自然干预，通过分数因果表示学习识别可控潜在变量（如关节角度），仅使用分布变化而无标注数据。

Result: 在半合成机械臂实验中，ROPES成功以高保真度解耦潜在生成因素，与真实值高度一致，且优于最近提出的半监督基线方法。

Conclusion: 机器人姿态估计可作为因果表示学习的近实用测试平台，ROPES展示了无监督CRL在真实机器人应用中的可行性。

Abstract: Causal representation learning (CRL) has emerged as a powerful unsupervised
framework that (i) disentangles the latent generative factors underlying
high-dimensional data, and (ii) learns the cause-and-effect interactions among
the disentangled variables. Despite extensive recent advances in
identifiability and some practical progress, a substantial gap remains between
theory and real-world practice. This paper takes a step toward closing that gap
by bringing CRL to robotics, a domain that has motivated CRL. Specifically,
this paper addresses the well-defined robot pose estimation -- the recovery of
position and orientation from raw images -- by introducing Robotic Pose
Estimation via Score-Based CRL (ROPES). Being an unsupervised framework, ROPES
embodies the essence of interventional CRL by identifying those generative
factors that are actuated: images are generated by intrinsic and extrinsic
latent factors (e.g., joint angles, arm/limb geometry, lighting, background,
and camera configuration) and the objective is to disentangle and recover the
controllable latent variables, i.e., those that can be directly manipulated
(intervened upon) through actuation. Interventional CRL theory shows that
variables that undergo variations via interventions can be identified. In
robotics, such interventions arise naturally by commanding actuators of various
joints and recording images under varied controls. Empirical evaluations in
semi-synthetic manipulator experiments demonstrate that ROPES successfully
disentangles latent generative factors with high fidelity with respect to the
ground truth. Crucially, this is achieved by leveraging only distributional
changes, without using any labeled data. The paper also includes a comparison
with a baseline based on a recently proposed semi-supervised framework. This
paper concludes by positioning robot pose estimation as a near-practical
testbed for CRL.

</details>


### [2] [Aircraft Collision Avoidance Systems: Technological Challenges and Solutions on the Path to Regulatory Acceptance](https://arxiv.org/abs/2510.20916)
*Sydney M. Katz,Robert J. Moss,Dylan M. Asmar,Wesley A. Olson,James K. Kuchar,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 本文概述了飞机防撞系统的技术挑战和解决方案，重点关注经过严格验证并被监管机构接受的系统。


<details>
  <summary>Details</summary>
Motivation: 飞机防撞系统对现代航空至关重要，需要解决监视、决策和验证等技术挑战，这些挑战在其他安全关键系统中也普遍存在。

Method: 通过综述过去几十年的研究和开发成果，分析各种防撞解决方案，特别关注经过严格验证的方法。

Result: 识别了有效的防撞系统技术方案，这些方案已通过监管机构认证，可作为其他安全关键系统的案例研究。

Conclusion: 飞机防撞系统的发展为解决安全关键系统的技术挑战提供了宝贵经验，对其他领域具有重要参考价值。

Abstract: Aircraft collision avoidance systems is critical to modern aviation. These
systems are designed to predict potential collisions between aircraft and
recommend appropriate avoidance actions. Creating effective collision avoidance
systems requires solutions to a variety of technical challenges related to
surveillance, decision making, and validation. These challenges have sparked
significant research and development efforts over the past several decades that
have resulted in a variety of proposed solutions. This article provides an
overview of these challenges and solutions with an emphasis on those that have
been put through a rigorous validation process and accepted by regulatory
bodies. The challenges posed by the collision avoidance problem are often
present in other domains, and aircraft collision avoidance systems can serve as
case studies that provide valuable insights for a wide range of safety-critical
systems.

</details>


### [3] [SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing](https://arxiv.org/abs/2510.20965)
*Jesse Haworth,Juo-Tung Chen,Nigel Nelson,Ji Woong Kim,Masoud Moghani,Chelsea Finn,Axel Krieger*

Main category: cs.RO

TL;DR: SutureBot是一个在da Vinci研究套件上的自主缝合基准，包括针头拾取、组织插入和打结。作者发布了包含1890个缝合演示的高质量数据集，并提出了优化插入点精度的目标条件框架。


<details>
  <summary>Details</summary>
Motivation: 缝合是典型的长时程灵巧操作任务，尽管已有许多端到端自主化的努力，但尚未在物理硬件上实现完全自主的缝合流程。自主缝合是实现手术机器人自主化的关键里程碑。

Method: 提出了目标条件框架，显式优化插入点精度。评估了包括π₀、GR00T N1、OpenVLA-OFT和多任务ACT在内的最先进视觉-语言-动作模型，每个都配备了高级任务预测策略。

Result: 目标条件框架比仅任务基线提高了59%-74%的目标精度。建立了可重复的缝合基准，并发布了包含1890个演示的数据集。

Conclusion: 这些贡献支持可重复评估和开发专注于精度的长时程灵巧操作策略，这些策略对于端到端缝合是必要的。数据集已公开提供。

Abstract: Robotic suturing is a prototypical long-horizon dexterous manipulation task,
requiring coordinated needle grasping, precise tissue penetration, and secure
knot tying. Despite numerous efforts toward end-to-end autonomy, a fully
autonomous suturing pipeline has yet to be demonstrated on physical hardware.
We introduce SutureBot: an autonomous suturing benchmark on the da Vinci
Research Kit (dVRK), spanning needle pickup, tissue insertion, and knot tying.
To ensure repeatability, we release a high-fidelity dataset comprising 1,890
suturing demonstrations. Furthermore, we propose a goal-conditioned framework
that explicitly optimizes insertion-point precision, improving targeting
accuracy by 59\%-74\% over a task-only baseline. To establish this task as a
benchmark for dexterous imitation learning, we evaluate state-of-the-art
vision-language-action (VLA) models, including $\pi_0$, GR00T N1, OpenVLA-OFT,
and multitask ACT, each augmented with a high-level task-prediction policy.
Autonomous suturing is a key milestone toward achieving robotic autonomy in
surgery. These contributions support reproducible evaluation and development of
precision-focused, long-horizon dexterous manipulation policies necessary for
end-to-end suturing. Dataset is available at:
https://huggingface.co/datasets/jchen396/suturebot

</details>


### [4] [Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization](https://arxiv.org/abs/2510.20974)
*Michael Bezick,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出PPC框架，通过将任意刚性变换的点云映射到规范姿态，提升点云强化学习对相机位姿变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决点云强化学习对相机位姿不匹配的敏感性，提高在真实环境中的可靠性。

Method: 使用主成分分析(PCA)将任意刚性变换的点云映射到唯一的规范姿态，使观测对齐到一致坐标系。

Result: 实验显示PPC在挑战性机器人任务中显著提升对未见相机位姿的鲁棒性。

Conclusion: PPC为点云强化学习提供了对相机位姿变化的鲁棒解决方案，是领域随机化的原则性替代方法。

Abstract: Reinforcement Learning (RL) from raw visual input has achieved impressive
successes in recent years, yet it remains fragile to out-of-distribution
variations such as changes in lighting, color, and viewpoint. Point Cloud
Reinforcement Learning (PC-RL) offers a promising alternative by mitigating
appearance-based brittleness, but its sensitivity to camera pose mismatches
continues to undermine reliability in realistic settings. To address this
challenge, we propose PCA Point Cloud (PPC), a canonicalization framework
specifically tailored for downstream robotic control. PPC maps point clouds
under arbitrary rigid-body transformations to a unique canonical pose, aligning
observations to a consistent frame, thereby substantially decreasing
viewpoint-induced inconsistencies. In our experiments, we show that PPC
improves robustness to unseen camera poses across challenging robotic tasks,
providing a principled alternative to domain randomization.

</details>


### [5] [HRT1: One-Shot Human-to-Robot Trajectory Transfer for Mobile Manipulation](https://arxiv.org/abs/2510.21026)
*Sai Haneesh Allu,Jishnu Jaykumar P,Ninad Khargonkar,Tyler Summers,Jian Yao,Yu Xiang*

Main category: cs.RO

TL;DR: 提出了一种从人类演示视频学习机器人操作轨迹的系统，包含数据收集、视频理解、轨迹转换和轨迹优化四个模块，使机器人能够通过观看一次演示视频在不同环境中重复移动操作任务


<details>
  <summary>Details</summary>
Motivation: 让机器人能够通过观看人类演示视频学习操作技能，并在不同环境中重复执行相同的移动操作任务，即使物体摆放位置与演示时不同

Method: 系统包含四个模块：1) 使用AR头显从机器人视角收集人类演示视频；2) 视频理解模块检测物体并提取3D人手轨迹；3) 将人手轨迹转换为机器人末端执行器的参考轨迹；4) 使用轨迹优化算法在机器人配置空间中求解能够跟随转换后末端执行器轨迹的路径

Result: 在不同操作任务上对移动机械臂进行了实验，验证了系统的有效性

Conclusion: 该系统使机器人能够通过一次观看人类演示视频，在不同环境中重复执行相同的移动操作任务

Abstract: We introduce a novel system for human-to-robot trajectory transfer that
enables robots to manipulate objects by learning from human demonstration
videos. The system consists of four modules. The first module is a data
collection module that is designed to collect human demonstration videos from
the point of view of a robot using an AR headset. The second module is a video
understanding module that detects objects and extracts 3D human-hand
trajectories from demonstration videos. The third module transfers a human-hand
trajectory into a reference trajectory of a robot end-effector in 3D space. The
last module utilizes a trajectory optimization algorithm to solve a trajectory
in the robot configuration space that can follow the end-effector trajectory
transferred from the human demonstration. Consequently, these modules enable a
robot to watch a human demonstration video once and then repeat the same mobile
manipulation task in different environments, even when objects are placed
differently from the demonstrations. Experiments of different manipulation
tasks are conducted on a mobile manipulator to verify the effectiveness of our
system

</details>


### [6] [Sequentially Teaching Sequential Tasks $(ST)^2$: Teaching Robots Long-horizon Manipulation Skills](https://arxiv.org/abs/2510.21046)
*Zlatan Ajanović,Ravi Prakash,Leandro de Souza Rosa,Jens Kober*

Main category: cs.RO

TL;DR: 比较了两种机器人示教框架：传统整体方法和顺序方法，提出了(ST)^2顺序学习方法，通过用户研究发现在轨迹质量和成功率上两种方法相似，但用户偏好不同。


<details>
  <summary>Details</summary>
Motivation: 从演示中学习能高效教授机器人复杂技能，但教授包含多个技能的长期任务很困难，因为偏差会累积、分布偏移增加，人类教师会疲劳，增加了失败几率。

Method: 提出了(ST)^2顺序学习方法，允许用户通过定义关键点来控制教学流程，支持增量式和结构化演示。通过16名参与者在零售环境中的用户研究，比较了传统整体方法和顺序方法。

Result: 两种方法在轨迹质量和成功率上表现相似。部分参与者偏好顺序方法的迭代控制，而其他参与者则喜欢整体方法的简单性。

Conclusion: 两种示教框架在性能上相当，但用户偏好存在差异，表明应根据具体应用场景和用户偏好选择合适的教学框架。

Abstract: Learning from demonstration is effective for teaching robots complex skills
with high sample efficiency. However, teaching long-horizon tasks with multiple
skills is difficult, as deviations accumulate, distributional shift increases,
and human teachers become fatigued, raising the chance of failure. In this
work, we study user responses to two teaching frameworks: (i) a traditional
monolithic approach, where users demonstrate the entire trajectory of a
long-horizon task; and (ii) a sequential approach, where the task is segmented
by the user and demonstrations are provided step by step. To support this
study, we introduce $(ST)^2$, a sequential method for learning long-horizon
manipulation tasks that allows users to control the teaching flow by defining
key points, enabling incremental and structured demonstrations. We conducted a
user study on a restocking task with 16 participants in a realistic retail
environment to evaluate both user preference and method effectiveness. Our
objective and subjective results show that both methods achieve similar
trajectory quality and success rates. Some participants preferred the
sequential approach for its iterative control, while others favored the
monolithic approach for its simplicity.

</details>


### [7] [Revisiting Replanning from Scratch: Real-Time Incremental Planning with Fast Almost-Surely Asymptotically Optimal Planners](https://arxiv.org/abs/2510.21074)
*Mitchell E. C. Sabbadini,Andrew H. Liu,Joseph Ruan,Tyler S. Wilson,Zachary Kingston,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 本文挑战了反应式重规划必须更新现有计划的传统假设，提出使用快速渐近最优规划算法将增量规划问题转化为一系列独立问题求解，在动态环境中无需显式计划重用即可获得高质量路径。


<details>
  <summary>Details</summary>
Motivation: 传统反应式规划方法需要重用信息并更新密集规划图，这在信息变化时计算成本高昂，且在某些应用中检测变化需要大量努力。本文旨在探索更高效的替代方案。

Method: 使用快速几乎必然渐近最优(ASAO)规划算法，将增量规划问题转化为一系列独立问题求解。这些算法能快速找到初始解并收敛到最优解，无需显式计划重用。通过Effort Informed Trees (EIT*)和Asymptotically Optimal RRT-Connect (AORRTC)进行验证。

Result: 模拟实验显示EIT*找到的中位解路径比测试的反应式规划算法更短。在真实机器人臂规划问题上，AORRTC进一步验证了该方法的有效性。

Conclusion: 反应式重规划不一定需要更新现有计划，通过ASAO算法将增量规划作为独立问题序列求解，可以在动态障碍物环境中找到一致的全局计划，且计算效率更高。

Abstract: Robots operating in changing environments either predict obstacle changes
and/or plan quickly enough to react to them. Predictive approaches require a
strong prior about the position and motion of obstacles. Reactive approaches
require no assumptions about their environment but must replan quickly and find
high-quality paths to navigate effectively.
  Reactive approaches often reuse information between queries to reduce
planning cost. These techniques are conceptually sound but updating dense
planning graphs when information changes can be computationally prohibitive. It
can also require significant effort to detect the changes in some applications.
  This paper revisits the long-held assumption that reactive replanning
requires updating existing plans. It shows that the incremental planning
problem can alternatively be solved more efficiently as a series of independent
problems using fast almost-surely asymptotically optimal (ASAO) planning
algorithms. These ASAO algorithms quickly find an initial solution and converge
towards an optimal solution which allows them to find consistent global plans
in the presence of changing obstacles without requiring explicit plan reuse.
This is demonstrated with simulated experiments where Effort Informed Trees
(EIT*) finds shorter median solution paths than the tested reactive planning
algorithms and is further validated using Asymptotically Optimal RRT-Connect
(AORRTC) on a real-world planning problem on a robot arm.

</details>


### [8] [Generalizable Hierarchical Skill Learning via Object-Centric Representation](https://arxiv.org/abs/2510.21121)
*Haibo Zhao,Yu Qi,Boce Hu,Yizhe Zhu,Ziyan Chen,Heng Tian,Xupeng Zhu,Owen Howell,Haojie Huang,Robin Walters,Dian Wang,Robert Platt*

Main category: cs.RO

TL;DR: GSL是一个分层策略学习框架，通过物体中心技能作为高层视觉语言模型与低层视觉运动策略的接口，显著提升机器人操作中的策略泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作任务中策略泛化能力不足和样本效率低下的问题，特别是在面对未见过的空间布局、物体外观和任务组合时。

Method: 将演示分解为可迁移的物体规范化技能原语，使用基础模型确保在物体坐标系中的高效低层技能学习。测试时，高层代理预测的技能-物体对被送入低层模块，推断出的规范动作被映射回世界坐标系执行。

Result: 在仿真中，GSL仅用每个任务3个演示就比使用30倍数据的基线方法在未见任务上性能提升15.5%。在真实世界实验中，GSL也优于使用10倍数据的基线。

Conclusion: GSL的结构化但灵活设计在样本效率和泛化能力方面取得了显著改进，能够有效应对各种未见场景。

Abstract: We present Generalizable Hierarchical Skill Learning (GSL), a novel framework
for hierarchical policy learning that significantly improves policy
generalization and sample efficiency in robot manipulation. One core idea of
GSL is to use object-centric skills as an interface that bridges the high-level
vision-language model and the low-level visual-motor policy. Specifically, GSL
decomposes demonstrations into transferable and object-canonicalized skill
primitives using foundation models, ensuring efficient low-level skill learning
in the object frame. At test time, the skill-object pairs predicted by the
high-level agent are fed to the low-level module, where the inferred canonical
actions are mapped back to the world frame for execution. This structured yet
flexible design leads to substantial improvements in sample efficiency and
generalization of our method across unseen spatial arrangements, object
appearances, and task compositions. In simulation, GSL trained with only 3
demonstrations per task outperforms baselines trained with 30 times more data
by 15.5 percent on unseen tasks. In real-world experiments, GSL also surpasses
the baseline trained with 10 times more data.

</details>


### [9] [An Agnostic End-Effector Alignment Controller for Robust Assembly of Modular Space Robots](https://arxiv.org/abs/2510.21164)
*Shamistan Karimov,Elian Neppel,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 开发了一种用于模块化机器人的自适应速度边界控制器，通过动态超球面钳制确保在月球环境中的平稳稳定运动，测试显示步进版本运动更可预测，连续版本收敛更快且精度高。


<details>
  <summary>Details</summary>
Motivation: 模块化机器人在月球任务中需要可重构性和容错性，但需要能够安全适应现实世界干扰的控制器。

Method: 在Motion Stack基础上开发了通过动态超球面钳制实施自适应速度边界的控制器，仅使用实时末端执行器和目标位姿测量，实现平移和旋转速度限制的调整。实现了离散步进和连续速度两种变体。

Result: 在JAXA月球环境模拟器中测试两个MoonBot肢体，步进变体产生高度可预测、低摆动的运动，连续变体收敛更快且保持毫米级位置精度，两者都对机械缺陷和传感噪声具有鲁棒性。

Conclusion: 结果突出了机器人无关框架在恶劣条件下自主自组装和重构的灵活性和鲁棒性。

Abstract: Modular robots offer reconfigurability and fault tolerance essential for
lunar missions, but require controllers that adapt safely to real-world
disturbances. We build on our previous hardware-agnostic actuator
synchronization in Motion Stack to develop a new controller enforcing adaptive
velocity bounds via a dynamic hypersphere clamp. Using only real-time
end-effector and target pose measurements, the controller adjusts its
translational and rotational speed limits to ensure smooth, stable alignment
without abrupt motions. We implemented two variants, a discrete, step-based
version and a continuous, velocity-based version, and tested them on two
MoonBot limbs in JAXA's lunar environment simulator. Field trials demonstrate
that the step-based variant produces highly predictable, low-wobble motions,
while the continuous variant converges more quickly and maintains
millimeter-level positional accuracy, and both remain robust across limbs with
differing mechanical imperfections and sensing noise (e.g., backlash and flex).
These results highlight the flexibility and robustness of our robot-agnostic
framework for autonomous self-assembly and reconfiguration under harsh
conditions.

</details>


### [10] [Underwater Visual-Inertial-Acoustic-Depth SLAM with DVL Preintegration for Degraded Environments](https://arxiv.org/abs/2510.21215)
*Shuoshuo Ding,Tiedong Zhang,Dapeng Jiang,Ming Lei*

Main category: cs.RO

TL;DR: 提出了一种基于图优化的视觉-惯性-声学-深度SLAM系统，集成四种传感器模态，在水下视觉退化环境中实现稳定可靠的定位与建图。


<details>
  <summary>Details</summary>
Motivation: 水下环境存在能见度受限、光照不足和特征稀缺等视觉退化问题，给视觉-惯性SLAM系统带来重大挑战。

Method: 采用图优化框架，提出速度偏差DVL预积分策略，前端采用混合跟踪策略和声学-惯性-深度联合优化，并融入多源混合残差。

Result: 在模拟和真实水下场景中的定量和定性分析表明，该系统在稳定性和定位精度上优于当前最先进的立体视觉-惯性SLAM系统。

Conclusion: 该系统在视觉挑战性环境中表现出卓越的鲁棒性，通过多传感器紧密集成有效解决了水下SLAM的视觉退化问题。

Abstract: Visual degradation caused by limited visibility, insufficient lighting, and
feature scarcity in underwater environments presents significant challenges to
visual-inertial simultaneous localization and mapping (SLAM) systems. To
address these challenges, this paper proposes a graph-based
visual-inertial-acoustic-depth SLAM system that integrates a stereo camera, an
inertial measurement unit (IMU), the Doppler velocity log (DVL), and a pressure
sensor. The key innovation lies in the tight integration of four distinct
sensor modalities to ensure reliable operation, even under degraded visual
conditions. To mitigate DVL drift and improve measurement efficiency, we
propose a novel velocity-bias-based DVL preintegration strategy. At the
frontend, hybrid tracking strategies and acoustic-inertial-depth joint
optimization enhance system stability. Additionally, multi-source hybrid
residuals are incorporated into a graph optimization framework. Extensive
quantitative and qualitative analyses of the proposed system are conducted in
both simulated and real-world underwater scenarios. The results demonstrate
that our approach outperforms current state-of-the-art stereo visual-inertial
SLAM systems in both stability and localization accuracy, exhibiting
exceptional robustness, particularly in visually challenging environments.

</details>


### [11] [Remote Autonomy for Multiple Small Lowcost UAVs in GNSS-denied Search and Rescue Operations](https://arxiv.org/abs/2510.21357)
*Daniel Schleich,Jan Quenzel,Sven Behnke*

Main category: cs.RO

TL;DR: 提出一个使用消费级DJI无人机实现自主飞行的系统，通过Android应用在无人机遥控器上进行状态估计和避障，支持单个操作员同时监控多架异构无人机，并将所有观测数据整合为联合3D环境模型。


<details>
  <summary>Details</summary>
Motivation: 消费级无人机已被急救人员广泛使用，但通常需要手动操作，特别是在未知GNSS受限环境和结构附近需要训练有素的飞行员。自主飞行可以简化无人机应用并减轻操作员负担，但现有自主系统通常需要特殊编程接口、定制传感器设置和强大的机载计算机，限制了更广泛部署。

Method: 开发了一个轻量级系统，使用消费级DJI无人机，通过Android应用在无人机遥控器上直接运行状态估计和避障算法。地面控制站允许单个操作员配置和监控多架异构无人机，并将所有无人机的观测数据整合为联合3D环境模型。

Result: 系统成功实现了使用消费级无人机进行自主飞行，无需特殊硬件或复杂设置，同时提供了多无人机协同操作和增强的情境感知能力。

Conclusion: 该系统证明了使用现成的消费级无人机实现自主飞行的可行性，通过轻量级软件解决方案克服了传统自主系统的硬件限制，为急救等应用场景提供了更易部署的自主无人机解决方案。

Abstract: In recent years, consumer-grade UAVs have been widely adopted by first
responders. In general, they are operated manually, which requires trained
pilots, especially in unknown GNSS-denied environments and in the vicinity of
structures. Autonomous flight can facilitate the application of UAVs and reduce
operator strain. However, autonomous systems usually require special
programming interfaces, custom sensor setups, and strong onboard computers,
which limits a broader deployment.
  We present a system for autonomous flight using lightweight consumer-grade
DJI drones. They are controlled by an Android app for state estimation and
obstacle avoidance directly running on the UAV's remote control. Our ground
control station enables a single operator to configure and supervise multiple
heterogeneous UAVs at once. Furthermore, it combines the observations of all
UAVs into a joint 3D environment model for improved situational awareness.

</details>


### [12] [Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain](https://arxiv.org/abs/2510.21369)
*Vivian S. Medeiros,Giovanni B. Dessy,Thiago Boaventura,Marcelo Becker,Claudio Semini,Victor Barasuol*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人在不稳定地形上安全导航的鲁棒运动框架，通过整合地形探测、承重分析、运动规划和控制策略，使机器人能够检测可坍塌区域并动态调整落脚点。


<details>
  <summary>Details</summary>
Motivation: 坍塌地形在搜救任务或行星探索中普遍存在，给四足机器人带来重大挑战。传统方法依赖专用传感器或外部地形测绘，无法有效应对不稳定表面。

Method: 利用关节测量评估地形稳定性而无需硬件修改，结合模型预测控制(MPC)优化机器人运动，通过状态机协调地形探测动作。

Result: 在定制坍塌平台和岩石地形上的实验结果表明，该框架能够在保持稳定性和优先考虑安全性的同时穿越坍塌地形。

Conclusion: 该框架为四足机器人在不稳定地形上的安全导航提供了有效解决方案，通过集成探测、分析和控制策略实现了鲁棒的运动性能。

Abstract: Collapsing terrains, often present in search and rescue missions or planetary
exploration, pose significant challenges for quadruped robots. This paper
introduces a robust locomotion framework for safe navigation over unstable
surfaces by integrating terrain probing, load-bearing analysis, motion
planning, and control strategies. Unlike traditional methods that rely on
specialized sensors or external terrain mapping alone, our approach leverages
joint measurements to assess terrain stability without hardware modifications.
A Model Predictive Control (MPC) system optimizes robot motion, balancing
stability and probing constraints, while a state machine coordinates terrain
probing actions, enabling the robot to detect collapsible regions and
dynamically adjust its footholds. Experimental results on custom-made
collapsing platforms and rocky terrains demonstrate the framework's ability to
traverse collapsing terrain while maintaining stability and prioritizing
safety.

</details>


### [13] [PREVENT: Proactive Risk Evaluation and Vigilant Execution of Tasks for Mobile Robotic Chemists using Multi-Modal Behavior Trees](https://arxiv.org/abs/2510.21438)
*Satheeshkumar Veeramani,Zhengxue Zhou,Francisco Munguia-Galeano,Hatem Fakhruldeen,Thomas Roddelkopf,Mohammed Faeik Ruzaij Al-Okby,Kerstin Thurow,Andrew Ian Cooper*

Main category: cs.RO

TL;DR: 提出PREVENT系统，通过多模态行为树方法解决移动化学机器人缺乏工作流意识的问题，避免误报和漏报


<details>
  <summary>Details</summary>
Motivation: 现有移动化学机器人缺乏工作流意识，小异常如未盖紧样品瓶可能中断整个工作流，浪费时间和资源，且现有感知机制误报过多

Method: 基于多模态行为树的导航和操作技能，采用分层感知机制，结合AI技术和传感器反馈（灵巧视觉、导航视觉摄像头、物联网气体传感器）

Result: 在模拟风险场景中完全避免误报和漏报，多模态感知技能在导航和操作中的部署准确率高于相应单模态技能的平均水平

Conclusion: PREVENT系统能有效集成到现有软件架构中，提高移动化学机器人的工作流意识和安全性

Abstract: Mobile robotic chemists are a fast growing trend in the field of chemistry
and materials research. However, so far these mobile robots lack workflow
awareness skills. This poses the risk that even a small anomaly, such as an
improperly capped sample vial could disrupt the entire workflow. This wastes
time, and resources, and could pose risks to human researchers, such as
exposure to toxic materials. Existing perception mechanisms can be used to
predict anomalies but they often generate excessive false positives. This may
halt workflow execution unnecessarily, requiring researchers to intervene and
to resume the workflow when no problem actually exists, negating the benefits
of autonomous operation. To address this problem, we propose PREVENT a system
comprising navigation and manipulation skills based on a multimodal Behavior
Tree (BT) approach that can be integrated into existing software architectures
with minimal modifications. Our approach involves a hierarchical perception
mechanism that exploits AI techniques and sensory feedback through Dexterous
Vision and Navigational Vision cameras and an IoT gas sensor module for
execution-related decision-making. Experimental evaluations show that the
proposed approach is comparatively efficient and completely avoids both false
negatives and false positives when tested in simulated risk scenarios within
our robotic chemistry workflow. The results also show that the proposed
multi-modal perception skills achieved deployment accuracies that were higher
than the average of the corresponding uni-modal skills, both for navigation and
for manipulation.

</details>


### [14] [Enhancing Social Robots through Resilient AI](https://arxiv.org/abs/2510.21469)
*Domenico Palmisano,Giuseppe Palestra,Berardina Nadja De Carolis*

Main category: cs.RO

TL;DR: 本文探讨了社会机器人中韧性的重要性，特别是在医疗保健等敏感领域，强调韧性是确保用户信任的关键特性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在医疗、教育等敏感领域的深入应用，需要确保这些系统具有韧性和鲁棒性，特别是在与老年人互动时建立信任。

Method: 通过分析社会机器人在压力条件下的运行能力，研究韧性如何帮助机器人在性能下降时仍保持基本功能。

Result: 研究表明韧性是社会机器人的基本特征，能够确保在不利条件下维持运行能力，从而增强用户特别是老年人对机器人的信任。

Conclusion: 韧性是构建可信社会机器人的关键要素，特别是在敏感应用场景中，能够确保系统在压力条件下持续可靠运行。

Abstract: As artificial intelligence continues to advance and becomes more integrated
into sensitive areas like healthcare, education, and everyday life, it's
crucial for these systems to be both resilient and robust. This paper shows how
resilience is a fundamental characteristic of social robots, which, through it,
ensure trust in the robot itself-an essential element especially when operating
in contexts with elderly people, who often have low trust in these systems.
Resilience is therefore the ability to operate under adverse or stressful
conditions, even when degraded or weakened, while maintaining essential
operational capabilities.

</details>


### [15] [AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation](https://arxiv.org/abs/2510.21536)
*Narendhiran Vijayakumar,Sridevi. M*

Main category: cs.RO

TL;DR: 提出AURASeg地面分割模型，通过注意力引导上采样和边界细化模块，在保持高分割精度的同时提升边界精度，在室内外环境中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型在室内和结构化环境中难以处理细粒度特征，存在多尺度处理效率低、边界细化不足和特征表示有限等问题。

Method: 使用CSP-Darknet骨干网络，添加残差边界细化模块(RBRM)进行精确边缘划分，注意力渐进上采样解码器(APUD)进行特征整合，以及轻量级ASPP-Lite模块进行多尺度上下文提取。

Result: 在GMRP数据集和自定义Gazebo室内数据集上，相比最先进模型，mIoU提升1.26%，分割精度提升1.65%，同时保持实时性能。

Conclusion: 该方法在室内外自主感知中具有可行性，能够实现精确边界细化且对推理速度影响最小。

Abstract: Free space ground segmentation is essential to navigate robots and autonomous
vehicles, recognize drivable zones, and traverse efficiently. Fine-grained
features remain challenging for existing segmentation models, particularly for
robots in indoor and structured environments. These difficulties arise from
ineffective multi-scale processing, suboptimal boundary refinement, and limited
feature representation. In order to overcome these limitations, we propose
Attention-Guided Upsampling with Residual Boundary-Assistive Refinement
(AURASeg), a ground-plane semantic segmentation model that maintains high
segmentation accuracy while improving border precision. Our method uses
CSP-Darknet backbone by adding a Residual Border Refinement Module (RBRM) for
accurate edge delineation and an Attention Progressive Upsampling Decoder
(APUD) for strong feature integration. We also incorporate a lightweight Atrous
Spatial Pyramid Pooling (ASPP-Lite) module to ensure multi-scale context
extraction without compromising real-time performance. The proposed model beats
benchmark segmentation architectures in mIoU and F1 metrics when tested on the
Ground Mobile Robot Perception (GMRP) Dataset and a custom Gazebo indoor
dataset. Our approach achieves an improvement in mean Intersection-over-Union
(mIoU) of +1.26% and segmentation precision of +1.65% compared to
state-of-the-art models. These results show that our technique is feasible for
autonomous perception in both indoor and outdoor environments, enabling precise
border refinement with minimal effect on inference speed.

</details>


### [16] [Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos](https://arxiv.org/abs/2510.21571)
*Qixiu Li,Yu Deng,Yaobo Liang,Lin Luo,Lei Zhou,Chengtang Yao,Lingqi Zeng,Zhiyuan Feng,Huizhi Liang,Sicheng Xu,Yizhong Zhang,Xi Chen,Hao Chen,Lily Sun,Dong Chen,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: 提出了一种利用未标注的真实人类手部活动视频预训练机器人视觉-语言-动作模型的新方法，将人类手部视为灵巧的机器人末端执行器，实现了大规模VLA模型的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人数据覆盖范围有限，无法支持通用机器人智能的发展。利用大量无标注的人类手部活动视频可以创建覆盖更广泛对象、概念和任务的训练数据。

Method: 开发了全自动的人类活动分析方法，将任意人类手部视频转换为与机器人VLA训练数据格式对齐的片段，包含原子级手部活动分割、语言描述、3D手部运动和相机运动。

Result: 创建了包含100万片段、2600万帧的手部VLA训练数据集，模型在未见过的真实世界观察中表现出强大的零样本能力，经过少量真实机器人数据微调后显著提高了任务成功率和泛化能力。

Conclusion: 这项工作为可扩展的VLA预训练奠定了坚实基础，推动了机器人向真正可泛化的具身智能发展，并展示了模型性能随预训练数据规模扩展的良好特性。

Abstract: This paper presents a novel approach for pretraining robotic manipulation
Vision-Language-Action (VLA) models using a large corpus of unscripted
real-life video recordings of human hand activities. Treating human hand as
dexterous robot end-effector, we show that "in-the-wild" egocentric human
videos without any annotations can be transformed into data formats fully
aligned with existing robotic V-L-A training data in terms of task granularity
and labels. This is achieved by the development of a fully-automated holistic
human activity analysis approach for arbitrary human hand videos. This approach
can generate atomic-level hand activity segments and their language
descriptions, each accompanied with framewise 3D hand motion and camera motion.
We process a large volume of egocentric videos and create a hand-VLA training
dataset containing 1M episodes and 26M frames. This training data covers a wide
range of objects and concepts, dexterous manipulation tasks, and environment
variations in real life, vastly exceeding the coverage of existing robot data.
We design a dexterous hand VLA model architecture and pretrain the model on
this dataset. The model exhibits strong zero-shot capabilities on completely
unseen real-world observations. Additionally, fine-tuning it on a small amount
of real robot action data significantly improves task success rates and
generalization to novel objects in real robotic experiments. We also
demonstrate the appealing scaling behavior of the model's task performance with
respect to pretraining data scale. We believe this work lays a solid foundation
for scalable VLA pretraining, advancing robots toward truly generalizable
embodied intelligence.

</details>


### [17] [Enhancing Tactile-based Reinforcement Learning for Robotic Control](https://arxiv.org/abs/2510.21609)
*Elle Miller,Trevor McInroe,David Abel,Oisin Mac Aodha,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 该论文开发了自监督学习方法，有效利用稀疏二进制触觉信号提升机器人操作的灵巧性，在复杂接触任务中达到超人类水平，并发布了RoTO基准。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界机器人操作中视觉感知的局限性，通过触觉传感克服感官缺陷和对理想状态信息的依赖，提升强化学习中触觉传感的效能。

Method: 采用自监督学习方法，结合本体感觉和稀疏二进制接触信号，将SSL记忆与策略记忆解耦以提高性能。

Result: 稀疏二进制触觉信号对灵巧性至关重要，特别是在解耦的机器人-物体运动中。智能体在复杂接触任务（球弹跳和保定球旋转）中达到超人类灵巧性。

Conclusion: 触觉传感对于实现安全可靠的机器人操作至关重要，提出的方法有效提升了触觉强化学习的性能，RoTO基准将促进未来触觉操作研究的发展。

Abstract: Achieving safe, reliable real-world robotic manipulation requires agents to
evolve beyond vision and incorporate tactile sensing to overcome sensory
deficits and reliance on idealised state information. Despite its potential,
the efficacy of tactile sensing in reinforcement learning (RL) remains
inconsistent. We address this by developing self-supervised learning (SSL)
methodologies to more effectively harness tactile observations, focusing on a
scalable setup of proprioception and sparse binary contacts. We empirically
demonstrate that sparse binary tactile signals are critical for dexterity,
particularly for interactions that proprioceptive control errors do not
register, such as decoupled robot-object motions. Our agents achieve superhuman
dexterity in complex contact tasks (ball bouncing and Baoding ball rotation).
Furthermore, we find that decoupling the SSL memory from the on-policy memory
can improve performance. We release the Robot Tactile Olympiad (RoTO) benchmark
to standardise and promote future research in tactile-based manipulation.
Project page: https://elle-miller.github.io/tactile_rl

</details>


### [18] [Design and Structural Validation of a Micro-UAV with On-Board Dynamic Route Planning](https://arxiv.org/abs/2510.21648)
*Inbazhagan Ravikumar,Ram Sundhar,Narendhiran Vijayakumar*

Main category: cs.RO

TL;DR: 本文提出了一种低成本、模块化的定制无人机系统，用于搜救任务，解决了轻型无人机在复杂地形中的结构耐用性和动态路径重规划问题。


<details>
  <summary>Details</summary>
Motivation: 解决低成本轻型无人机在搜救任务中面临的两个关键限制：在复杂地形飞行时缺乏结构耐用性，以及在检测到新受害者或障碍物时无法动态重规划路径。

Method: 使用常见组件和材料从头构建完全定制的无人机，强调模块化、低成本和易组装性。结构框架采用轻量耐用的材料加固，机载控制系统完全基于免费开源软件。

Result: 所提出的系统展示了实时感知和自适应导航能力，无需依赖昂贵的硬件加速器，为实际搜救任务提供了经济实用的解决方案。

Conclusion: 该定制无人机系统通过结构加固和开源软件控制，成功解决了低成本无人机在搜救应用中的耐用性和动态规划问题，为实际部署提供了可行方案。

Abstract: Micro aerial vehicles are becoming increasingly important in search and
rescue operations due to their agility, speed, and ability to access confined
spaces or hazardous areas. However, designing lightweight aerial systems
presents significant structural, aerodynamic, and computational challenges.
This work addresses two key limitations in many low-cost aerial systems under
two kilograms: their lack of structural durability during flight through rough
terrains and inability to replan paths dynamically when new victims or
obstacles are detected. We present a fully customised drone built from scratch
using only commonly available components and materials, emphasising modularity,
low cost, and ease of assembly. The structural frame is reinforced with
lightweight yet durable materials to withstand impact, while the onboard
control system is powered entirely by free, open-source software solutions. The
proposed system demonstrates real-time perception and adaptive navigation
capabilities without relying on expensive hardware accelerators, offering an
affordable and practical solution for real-world search and rescue missions.

</details>
