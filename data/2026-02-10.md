<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 96]
- [cs.RO](#cs.RO) [Total: 82]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models](https://arxiv.org/abs/2602.06973)
*Lucky Susanto,Musa Izzanardi Wijanarko,Khumaisa Nur'aini,Farid Adilazuarda,Alham Fikri Aji,Derry Tanti Wijaya*

Main category: cs.CL

TL;DR: 像素语言建模通过将文本渲染为图像来绕过子词分词瓶颈，但DualGPT等多模态变体重新引入文本分词器以提升自回归性能。本文研究发现，即使采用视觉渲染，重新整合文本分词器仍会引入分词器对齐问题，特别是在印尼低资源语言中，定制分词器比Llama 2分词器性能提升高达30.15 chrF++。


<details>
  <summary>Details</summary>
Motivation: 研究像素语言建模是否真正能摆脱分词器约束，特别是在多模态变体（如DualGPT）重新引入文本分词器的情况下。关注印尼四种低资源本地语言（爪哇语、巴厘语、巽他语、楠榜语），这些语言使用非拉丁文字，存在分词器对齐问题。

Method: 在DualGPT架构中评估文字-分词器对齐的影响，比较Llama 2分词器与定制分词器在四种印尼低资源语言上的表现，使用OOV（未登录词）率、生育率和chrF++等指标进行量化评估。

Result: 尽管视觉渲染，重新整合文本分词器仍会引入分词器对齐问题。Llama 2分词器虽然OOV率和生育率较低，但性能显著差于定制分词器，改进幅度高达30.15 chrF++。这表明文本分词器仍然是实现公平模型的重要障碍。

Conclusion: 像素语言建模的视觉渲染并不能真正解耦模型与分词器约束，当多模态变体重新引入文本分词器时，分词器对齐问题依然存在。这对未来多模态变体设计提出警告：文本分词器仍然是实现语言公平模型的重要障碍，特别是在低资源语言场景下。

Abstract: While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.

</details>


### [2] [BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents](https://arxiv.org/abs/2602.06975)
*R. James Cotton,Thomas Leonard*

Main category: cs.CL

TL;DR: BiomechAgent是一个通过自然语言生成代码的AI代理，使临床医生无需编程即可进行生物力学分析，包括数据查询、可视化和临床推理。


<details>
  <summary>Details</summary>
Motivation: 尽管无标记运动捕捉技术使定量运动分析越来越普及，但分析结果数据对于没有编程专业知识的临床医生仍然存在障碍。

Method: 开发了一个代码生成的AI代理BiomechAgent，通过自然语言界面支持生物力学分析，包括数据检索、可视化、活动分类、时间分割和临床推理。使用系统基准评估其能力，并测试了领域特定指令、专门工具集成和不同LLM模型的影响。

Result: BiomechAgent在数据检索和可视化任务上表现出稳健的准确性，并展示了新兴的临床推理能力。生物力学领域的特定指令显著优于通用提示，集成专门的步态事件检测工具大幅提升了时空分析的准确性。使用本地开源模型相比前沿云LLM在大多数领域性能显著下降。

Conclusion: BiomechAgent使无标记运动捕捉的数据对最终用户更加有用和可访问，通过自然语言界面降低了生物力学分析的技术门槛。

Abstract: Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.

</details>


### [3] [Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks](https://arxiv.org/abs/2602.06976)
*Chen Shen,Wei Cheng,Jingyue Yang,Huan Zhang,Yuhan Wu,Wei Hu*

Main category: cs.CL

TL;DR: ILA-agent框架让大语言模型通过动态交互学习新编程语言，无需大量微调数据，在低资源环境下显著优于检索增强基线。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在编码任务中的能力依赖于预训练语料，但面对陌生编程语言时表现会急剧下降。传统的数据密集型微调方法成本高且不灵活，需要探索推理时语言获取的新范式。

Method: 提出ILA-agent框架，将人类学习行为建模为一套工具，让LLM通过结构化交互（查阅官方文档、执行环境验证）增量式探索、应用和验证语言知识。构建Cangjie-bench多任务基准，基于新型静态类型语言Cangjie进行低资源评估。

Result: 使用多种LLM评估显示，ILA-agent在代码生成、翻译和程序修复任务上显著优于检索增强基线。轨迹分析揭示了涌现的行为模式，同时指出了持续存在的性能差距。

Conclusion: ILA-agent为LLM学习陌生编程语言提供了有效的推理时获取框架，通过结构化交互实现增量学习，在低资源环境下表现出色，为未来研究提供了新的方向。

Abstract: The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.

</details>


### [4] [Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model](https://arxiv.org/abs/2602.07120)
*Jacqueline He,Jonathan Hayase,Wen-tau Yih,Sewoong Oh,Luke Zettlemoyer,Pang Wei Koh*

Main category: cs.CL

TL;DR: 提出Anchored Decoding方法，在推理时抑制语言模型的逐字复制行为，通过将生成约束在安全模型的邻近范围内，实现可调的风险-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型倾向于记忆训练数据并逐字输出，当训练数据包含敏感或受版权保护内容时，这会导致同意、补偿和合规风险问题。

Method: 提出Anchored Decoding方法：1）在推理时自适应分配用户选择的信息预算；2）强制执行每步约束，提供序列级保证；3）引入TinyComma 1.8B安全模型；4）开发AnchoredByte Decoding字节级变体，支持跨词汇融合。

Result: 在六个模型对上评估，Anchored Decoding定义了新的帕累托前沿：保持接近原始的流畅性和事实性，同时消除高达75%的可测量复制差距（平均六项复制指标），推理开销适中。

Conclusion: Anchored Decoding是一种即插即用的推理时方法，能有效抑制语言模型的逐字复制行为，为混合许可数据训练的风险模型提供实用的风险-效用权衡解决方案。

Abstract: Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM. Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model (TinyComma 1.8B), as well as Anchored$_{\mathrm{Byte}}$ Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored$_{\mathrm{Byte}}$ Decoding define a new Pareto frontier, preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.

</details>


### [5] [Free Energy Mixer](https://arxiv.org/abs/2602.07160)
*Jiecheng Lu,Shihao Yang*

Main category: cs.CL

TL;DR: 提出Free Energy Mixer（FEM），一种基于自由能（log-sum-exp）的注意力读取机制，通过值驱动的每通道对数线性倾斜来改进标准注意力，实现从平均到选择的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 标准注意力通过每头凸平均读取键值，缺乏通道级选择能力。需要一种既能保持并行性和复杂度，又能实现值感知读取的机制。

Method: FEM将标准注意力中的(q,k)评分分布作为先验，通过自由能读取（log-sum-exp）应用值驱动的每通道对数线性倾斜，形成值感知后验读取。采用两级门控FEM设计，可即插即用。

Result: FEM在NLP、视觉和时间序列任务上，在相同参数预算下持续优于强基线模型，保持了原始渐近复杂度。

Conclusion: FEM提供了一种通用机制，可在不增加复杂度的情况下增强注意力机制的选择能力，为各种序列建模架构提供了有效的改进方案。

Abstract: Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.

</details>


### [6] [Your Language Model Secretly Contains Personality Subnetworks](https://arxiv.org/abs/2602.07164)
*Ruimeng Ye,Zihan Wang,Zinan Ling,Yang Xiao,Manling Li,Xiaolong Ma,Bo Hui*

Main category: cs.CL

TL;DR: LLMs内部已存在人格专用子网络，无需外部知识即可通过激活签名和掩码策略提取，实现训练免费的人格控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部知识（如提示、RAG、微调）来调整LLM行为，但本文质疑：LLM是否真的需要外部上下文或参数来适应不同行为，还是这些知识已经嵌入其参数中？

Method: 使用小型校准数据集识别不同人格的激活签名，基于此开发掩码策略隔离轻量级人格子网络；针对二元对立人格，引入对比剪枝策略识别导致统计差异的参数。

Result: 生成的子网络在多样化评估设置中表现出比需要外部知识的基线更强的人格对齐性，同时更高效；方法完全训练免费，仅依赖语言模型现有参数空间。

Conclusion: 多样的人类行为并非仅仅在LLM中被诱导，而是已经嵌入其参数空间，这为大型语言模型的可控和可解释个性化提供了新视角。

Abstract: Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.

</details>


### [7] [Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI](https://arxiv.org/abs/2602.07176)
*Mohamed El Hajji,Tarek Ait Baha,Aicha Dakir,Hammou Fadili,Youssef Es-Saady*

Main category: cs.CL

TL;DR: Open TutorAI是一个基于LLM和生成技术的开源教育平台，通过动态个性化辅导、3D虚拟形象和嵌入式学习分析，提供自适应、沉浸式的学习体验。


<details>
  <summary>Details</summary>
Motivation: 现有教育聊天机器人系统缺乏上下文适应性、实时响应性和教学灵活性，限制了学习参与度和教学效果，需要结合AI和沉浸式技术的开放集成平台来支持个性化学习体验。

Method: 基于LLM和生成技术构建开源平台，整合自然语言处理和可定制3D虚拟形象实现多模态交互。通过结构化入门流程捕获学习者目标和偏好，配置个性化AI助手，提供文本和虚拟形象界面，包含内容组织、嵌入式反馈和学习分析工具。

Result: 开发了Open TutorAI平台，结合模块化架构、生成AI和学习分析，提供自适应支持，增强参与度和情感存在感，创建更人性化、沉浸式的学习环境，支持自我调节学习。

Conclusion: Open TutorAI将模块化架构、生成AI和学习分析统一在开源框架中，为下一代智能辅导系统的发展做出贡献，提供无需技术专长的个性化学习支持。

Abstract: Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.

</details>


### [8] [Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs](https://arxiv.org/abs/2602.07181)
*Tianyu Zhao,Siqi Li,Yasser Shoukry,Salma Elmalaki*

Main category: cs.CL

TL;DR: 论文提出利用人格特质作为潜在信号来提升LLM个性化回答质量，通过人格对齐的偏好选择将答案准确率从29.25%提升到76%，并创建了人格标注的偏好数据集PACIFIC和自动检索框架。


<details>
  <summary>Details</summary>
Motivation: 用户偏好常用于个性化LLM回答，但偏好信号可能嘈杂、不完整甚至误导，直接应用会降低回答质量。观察到稳定的人格特质塑造日常偏好，因此研究将人格作为偏好背后的原则性潜在信号。

Method: 1) 通过实验验证人格对齐偏好的有效性；2) 创建PACIFIC数据集，包含1200个跨领域偏好陈述，标注大五人格特质方向；3) 提出框架使LLM能自动检索人格对齐偏好并融入回答生成。

Result: 使用人格对齐偏好显著提升个性化问答：选择与用户推断人格一致的偏好，答案选择准确率从29.25%提升到76%（相比随机选择偏好）。证明了人格作为偏好潜在信号的有效性。

Conclusion: 人格特质是偏好背后的有效潜在信号，人格对齐偏好能显著提升LLM个性化回答质量。提出的PACIFIC数据集和自动检索框架为实现基于人格的个性化LLM回答提供了实用工具。

Abstract: User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' signal behind preference statements. Through extensive experiments, we find that conditioning on personality-aligned preferences substantially improves personalized question answering: selecting preferences consistent with a user's inferred personality increases answer-choice accuracy from 29.25% to 76%, compared to using randomly selected preferences. Based on these findings, we introduce PACIFIC (Preference Alignment Choices Inference for Five-factor Identity Characterization), a personality-labeled preference dataset containing 1200 preference statements spanning diverse domains (e.g., travel, movies, education), annotated with Big-Five (OCEAN) trait directions. Finally, we propose a framework that enables an LLM model to automatically retrieve personality-aligned preferences and incorporate them during answer generation.

</details>


### [9] [Long-Context Long-Form Question Answering for Legal Domain](https://arxiv.org/abs/2602.07190)
*Anagha Kulkarni,Parin Rajesh Jhaveri,Prasha Shrestha,Yu Tong Han,Reza Amini,Behrouz Madahian*

Main category: cs.CL

TL;DR: 该论文提出一个针对法律文档的长上下文问答系统，能够处理复杂文档布局和领域特定词汇，生成全面的长形式答案。


<details>
  <summary>Details</summary>
Motivation: 法律文档具有复杂的文档布局（多级嵌套章节、长脚注）和领域特定词汇，这使得问答任务具有挑战性，特别是当答案需要跨越多页（长上下文）且要求全面性（长形式答案）时。

Method: 提出一个问答系统，能够：(a) 解构领域特定词汇以改进文档检索；(b) 解析复杂文档布局，隔离章节和脚注并适当链接；(c) 使用精确的领域特定词汇生成全面答案。还引入一个覆盖度指标，将性能分类为基于召回的覆盖类别。

Result: 通过利用法律和公司税务等领域的专业人士专业知识，策划了一个QA数据集。通过全面的实验和消融研究，证明了所提出系统的可用性和优势。

Conclusion: 该研究解决了法律文档长上下文问答的挑战，提出的系统能够有效处理复杂文档结构和领域词汇，为法律文档问答提供了实用的解决方案。

Abstract: Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.

</details>


### [10] [Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities](https://arxiv.org/abs/2602.07211)
*Ju Lin,Jing Pan,Ruizhi Li,Ming Sun,Yuzong Liu,Alaa Hassan,Jing Zheng,Florian Metze*

Main category: cs.CL

TL;DR: 本文研究了如何让大语言模型具备定向多说话人语音理解能力，特别针对智能眼镜应用场景，提出了两种集成方向性的方法，并在语音识别和翻译任务中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 当前大多数语音大语言模型基于单通道、单说话人数据训练，难以直接应用于多说话人、多通道的语音理解任务，特别是在智能眼镜等需要定向语音理解的实际应用场景中。

Method: 提出了两种集成方向性的方法：1）级联系统，利用源分离前端模块；2）端到端系统，采用序列化输出训练。两种方法都利用智能眼镜中的多麦克风阵列，以流式方式优化方向性解释和处理。

Result: 实验结果表明，所提出的方法能有效赋予大语言模型定向语音理解能力，在语音识别和语音翻译任务中都取得了强劲性能。

Conclusion: 通过提出的级联和端到端方法，成功实现了大语言模型在多说话人、多通道场景下的定向语音理解能力，为智能眼镜等实际应用提供了有效解决方案。

Abstract: Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understanding capabilities for LLMs, specifically in smart glasses usecase. We propose two novel approaches to integrate directivity into LLMs: (1) a cascaded system that leverages a source separation front-end module, and (2) an end-to-end system that utilizes serialized output training. All of the approaches utilize a multi-microphone array embedded in smart glasses to optimize directivity interpretation and processing in a streaming manner. Experimental results demonstrate the efficacy of our proposed methods in endowing LLMs with directional speech understanding capabilities, achieving strong performance in both speech recognition and speech translation tasks.

</details>


### [11] [Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice](https://arxiv.org/abs/2602.07319)
*Savan Doshi*

Main category: cs.CL

TL;DR: 论文提出了一种风险敏感的幻觉评估框架，通过检测风险性语言（如治疗指令、禁忌症等）来量化医疗问答中幻觉的潜在危害，而非仅关注事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉评估标准主要关注事实正确性，将所有错误视为同等严重，这掩盖了临床相关的失败模式，特别是当模型生成无依据但可操作的医疗语言时。

Method: 提出风险敏感评估框架，通过检测风险性语言（治疗指令、禁忌症、紧急提示、高风险药物提及）来量化幻觉的潜在影响，并结合相关性度量识别高风险、低依据的失败。

Result: 对三个指令调优语言模型进行安全压力测试，结果显示表面行为相似的模型具有显著不同的风险特征，标准评估指标无法捕捉这些差异。

Conclusion: 需要将风险敏感性纳入幻觉评估，评估有效性关键取决于任务和提示设计，这对患者面向的医疗问答系统安全至关重要。

Abstract: Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.

</details>


### [12] [Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation](https://arxiv.org/abs/2602.07338)
*Geng Liu,Fei Zhu,Rong Feng,Changyi Ma,Shiqi Wang,Gaofeng Meng*

Main category: cs.CL

TL;DR: 论文提出"对话中迷失"现象的根本原因不是模型能力不足，而是用户意图与模型理解之间的对齐差距，并提出通过解耦意图理解与任务执行的Mediator-Assistant架构来解决


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮对话中相比单轮对话会出现显著的性能下降（Lost in Conversation现象），先前研究将其归因于模型不可靠性，但本文认为根本原因在于意图对齐差距而非内在能力缺陷

Method: 提出Mediator-Assistant架构，通过经验驱动的Mediator将模糊的用户输入转化为基于历史交互模式的明确结构化指令，实现意图理解与任务执行的解耦

Result: 该方法显著减轻了多轮对话中的性能下降，在不同大型语言模型上都取得了良好效果

Conclusion: "对话中迷失"现象源于交互过程中的结构模糊性而非模型表示能力限制，通过Mediator-Assistant架构可以有效弥合用户意图与模型理解之间的差距

Abstract: Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.

</details>


### [13] [ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations](https://arxiv.org/abs/2602.07361)
*Long S. T. Nguyen,Quan M. Bui,Tin T. Ngo,Quynh T. N. Vo,Dung N. H. Le,Tho T. Quan*

Main category: cs.CL

TL;DR: 提出了ViHERMES数据集，用于越南语医疗法规多跳问答评估，包含高质量问答对，需要跨多个法规推理，并提出了图感知检索框架。


<details>
  <summary>Details</summary>
Motivation: 医疗法规问答具有挑战性，需要跨法律相互依赖文本进行多跳推理，尤其在越南语等低资源语言中缺乏支持多跳推理的基准数据集。

Method: 基于语义聚类和图启发数据挖掘的受控多跳QA生成流程，使用大语言模型生成结构化证据和推理标注；提出图感知检索框架，在法条单元层面建模正式法律关系。

Result: ViHERMES为评估多跳法规QA系统提供了具有挑战性的基准，提出的图感知方法持续优于强检索基线。

Conclusion: ViHERMES填补了越南语医疗法规多跳推理基准的空白，图感知检索框架能有效支持法律有效且连贯的答案生成。

Abstract: Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting remains limited, especially for low-resource languages such as Vietnamese, due to the lack of benchmark datasets that explicitly support multihop reasoning over healthcare regulations. In this work, we introduce the Vietnamese Healthcare Regulations-Multihop Reasoning Dataset (ViHERMES), a benchmark designed for multihop QA over Vietnamese healthcare regulatory documents. ViHERMES consists of high-quality question-answer pairs that require reasoning across multiple regulations and capture diverse dependency patterns, including amendment tracing, cross-document comparison, and procedural synthesis. To construct the dataset, we propose a controlled multihop QA generation pipeline based on semantic clustering and graph-inspired data mining, followed by large language model-based generation with structured evidence and reasoning annotations. We further present a graph-aware retrieval framework that models formal legal relations at the level of legal units and supports principled context expansion for legally valid and coherent answers. Experimental results demonstrate that ViHERMES provides a challenging benchmark for evaluating multihop regulatory QA systems and that the proposed graph-aware approach consistently outperforms strong retrieval-based baselines. The ViHERMES dataset and system implementation are publicly available at https://github.com/ura-hcmut/ViHERMES.

</details>


### [14] [TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling](https://arxiv.org/abs/2602.07374)
*Nisharg Nargund,Priyesh Shukla*

Main category: cs.CL

TL;DR: TernaryLM：一种132M参数的Transformer模型，采用原生1位三元量化{-1, 0, +1}训练，显著减少内存占用而不牺牲语言建模能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要大量计算资源，限制了在边缘设备和资源受限环境中的部署。需要开发更高效的模型以降低内存需求。

Method: 使用原生1位三元量化{-1, 0, +1}进行训练，采用直通估计器和自适应逐层缩放因子，从零开始学习量化感知表示。

Result: 1) TinyStories验证困惑度58.42；2) MRPC释义检测F1分数82.47%；3) 内存减少2.4倍(498MB vs 1197MB)；4) 在不同语料库上训练稳定。

Conclusion: 原生1位训练是高效神经语言模型的有前景方向，中间Transformer层对极端量化兼容性最高，为未来非均匀精度策略提供参考。

Abstract: Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.

</details>


### [15] [Efficient Post-Training Pruning of Large Language Models with Statistical Correction](https://arxiv.org/abs/2602.07375)
*Peiqi Yu,Jinhao Wang,Xinyi Sui,Nam Ling,Wei Wang,Wei Jiang*

Main category: cs.CL

TL;DR: 提出基于一阶统计特性的轻量级后训练剪枝框架，通过通道统计校准重要性分数和能量补偿修正分布失真，无需重训练或二阶信息


<details>
  <summary>Details</summary>
Motivation: 现有后训练剪枝方法在剪枝质量和计算效率之间存在权衡：启发式方法高效但对激活异常值敏感，重构方法保真度高但计算代价大

Method: 基于模型权重和激活的一阶统计特性：1) 剪枝时使用通道统计校准基于幅值的重要性分数，减少激活主导通道的偏差；2) 剪枝后应用解析能量补偿修正权重移除引起的分布失真。两个步骤都无需重训练、梯度或二阶信息

Result: 在多个LLM家族、稀疏模式和评估任务上的实验表明，该方法提高了剪枝性能，同时保持与启发式方法相当的计算成本

Conclusion: 简单的统计校正对于LLM的后训练剪枝是有效的，表明一阶统计特性可以显著改善剪枝质量而不增加计算负担

Abstract: Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning framework based on first-order statistical properties of model weights and activations. During pruning, channel-wise statistics are used to calibrate magnitude-based importance scores, reducing bias from activation-dominated channels. After pruning, we apply an analytic energy compensation to correct distributional distortions caused by weight removal. Both steps operate without retraining, gradients, or second-order information. Experiments across multiple LLM families, sparsity patterns, and evaluation tasks show that the proposed approach improves pruning performance while maintaining computational cost comparable to heuristic methods. The results suggest that simple statistical corrections can be effective for post-training pruning of LLMs.

</details>


### [16] [Do Large Language Models Reflect Demographic Pluralism in Safety?](https://arxiv.org/abs/2602.07376)
*Usman Naseem,Gautam Siddharth Kashyap,Sushant Kumar Ray,Rafiq Ali,Ebad Shabbir,Abdullah Mohammad*

Main category: cs.CL

TL;DR: Demo-SafetyBench是一个新的安全评估基准，通过建模人口统计学多元主义来弥补现有数据集在人口多样性上的不足，实现了可扩展且人口统计学鲁棒的安全评估。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型安全对齐数据集（如ANTHROPIC-HH和DICES）依赖于人口统计学上狭窄的标注者群体，忽视了不同社区之间安全感知的差异。大语言模型安全本质上是多元的，反映了道德规范、文化期望和人口统计背景的差异。

Method: 采用两阶段方法：第一阶段将DICES提示重新分类为14个安全领域，保留人口统计元数据，并通过SimHash去重扩展低资源领域；第二阶段使用LLMs-as-Raters（Gemma-7B、GPT-4o、LLaMA-2-7B）在零样本推理下评估多元敏感性。

Result: 构建了43,050个样本的数据集。通过平衡阈值（delta=0.5，tau=10）实现了高可靠性（ICC=0.87）和低人口统计敏感性（DS=0.12），证明多元安全评估既具有可扩展性又具有人口统计学鲁棒性。

Conclusion: Demo-SafetyBench通过直接在提示层面建模人口统计学多元主义，将价值框架与响应解耦，为多元安全评估提供了可扩展且人口统计学鲁棒的解决方案，填补了现有数据集在人口多样性方面的空白。

Abstract: Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from responses. In Stage I, prompts from DICES are reclassified into 14 safety domains (adapted from BEAVERTAILS) using Mistral 7B-Instruct-v0.3, retaining demographic metadata and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based deduplication, yielding 43,050 samples. In Stage II, pluralistic sensitivity is evaluated using LLMs-as-Raters-Gemma-7B, GPT-4o, and LLaMA-2-7B-under zero-shot inference. Balanced thresholds (delta = 0.5, tau = 10) achieve high reliability (ICC = 0.87) and low demographic sensitivity (DS = 0.12), confirming that pluralistic safety evaluation can be both scalable and demographically robust.

</details>


### [17] [When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified](https://arxiv.org/abs/2602.07381)
*Gautam Siddharth Kashyap,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: AlignX是一个两阶段框架，通过提示注入微调和几何校准的MoE路由，解决多目标对齐中的轴崩溃问题，显著提升LLM的HHH对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（SFT和MoE）在多目标对齐中存在轴崩溃问题：SFT导致冲突目标间的干扰，MoE存在路由校准问题，表现为特征空间分离导致的灾难性遗忘和不可靠推理。

Method: 两阶段框架：第一阶段使用提示注入微调提取轴特定任务特征，缓解灾难性遗忘；第二阶段部署MoCaE模块，利用分形和自然几何校准专家路由，提高推理可靠性。

Result: 在Alpaca（帮助性）、BeaverTails（无害性）和TruthfulQA（诚实性）上取得显著提升：胜率+171.5%，真实性-信息性+110.1%，安全违规减少4.3%。相比先前MoE，延迟和内存使用减少35%以上。

Conclusion: AlignX有效解决了多目标对齐中的轴崩溃问题，在HHH对齐任务上表现出优越性能、效率和泛化能力，为LLM的安全部署提供了有效解决方案。

Abstract: Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis Collapse, marked by (1) disjoint feature spaces causing catastrophic forgetting, and (2) unreliable inference from misrouted experts. To resolve this, we propose AlignX, a two-stage framework. Stage 1 uses prompt-injected fine-tuning to extract axis-specific task features, mitigating catastrophic forgetting. Stage 2 deploys a MoCaE module that calibrates expert routing using fractal and natural geometry, improving inference reliability. AlignX achieves significant gains on Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty), with +171.5% win rate, +110.1% in truthfulness-informativeness, and 4.3% fewer safety violations. It also reduces latency and memory usage by over 35% compared to prior MoEs. Results across four LLMs validate its generalizability.

</details>


### [18] [Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi](https://arxiv.org/abs/2602.07382)
*Debtanu Datta,Rajdeep Mukherjee,Adrijit Goswami,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 提出一个框架，通过注入法律领域知识来改进印度法律文本的摘要生成，支持英语和印地语，在提取式和生成式模型上都取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 印度法律判决摘要的复杂性源于法律文本的复杂语言和非结构化特性，且大部分印度人口不理解复杂的法律英语，需要印度语言的摘要。

Method: 1) 为提取式神经摘要模型注入领域特定预训练编码器；2) 通过在大规模英-印法律语料上进行持续预训练，向生成式模型（包括大语言模型）注入法律领域知识。

Result: 在英语到英语和英语到印地语的印度法律文档摘要任务中，标准评估指标、事实一致性指标和法律领域特定指标均显示统计显著改进，并通过领域专家验证。

Conclusion: 提出的方法能有效改进印度法律文本摘要生成，支持多语言输出，为法律文本处理提供了实用的解决方案。

Abstract: Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.

</details>


### [19] [Measuring cross-language intelligibility between Romance languages with computational tools](https://arxiv.org/abs/2602.07447)
*Liviu P Dinu,Ana Sabina Uban,Bogdan Iordache,Anca Dinu,Simona Georgescu*

Main category: cs.CL

TL;DR: 提出基于词汇相似度的计算指标，用于评估罗曼语族语言间的相互理解度，验证了语言理解不对称性并与人类实验结果相关


<details>
  <summary>Details</summary>
Motivation: 研究罗曼语族语言间的相互理解度，需要一种计算指标来量化语言间的可理解性，以验证语言理解不对称的直觉

Method: 提出基于词汇相似度的计算指标，使用表层和语义相似度，比较正字法和语音形式，使用不同平行语料库和词向量模型

Result: 获得的相互理解度分数证实了语言间理解不对称的直觉，并与人类完形填空测试结果显著相关

Conclusion: 基于词汇相似度的计算指标能有效评估罗曼语族语言间的相互理解度，验证了语言理解不对称现象

Abstract: We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthographic and phonetic forms of words as well as different parallel corpora and vectorial models of word meaning representation. The obtained intelligibility scores confirm intuitions related to intelligibility asymmetry across languages and significantly correlate with results of cloze tests in human experiments.

</details>


### [20] [DLLM Agent: See Farther, Run Faster](https://arxiv.org/abs/2602.07451)
*Huiling Zhen,Weizhe Lin,Renxi Liu,Kai Han,Yiming Li,Yuchuan Tian,Hanting Chen,Xiaoguang Li,Xiaosong Li,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Youliang Yan,Peifeng Qin,Jun Wang,Yu Wang,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: DLLM代理在相同准确度下比AR代理平均快30%以上，规划命中率更高，收敛更快，但需要更强的工具调用训练和注意力掩码对齐。


<details>
  <summary>Details</summary>
Motivation: 探索扩散大语言模型在智能体多步决策中的潜力，比较在相同代理框架和监督下，扩散模型与自回归模型在规划和工具使用行为上的系统性差异，以及这些差异是否能转化为端到端效率提升。

Method: 在相同代理工作流DeepDiver中实例化DLLM和AR骨干网络，使用相同的轨迹数据进行匹配的代理导向微调，得到可比较的扩散代理和自回归代理。在基准测试和案例研究中评估性能差异。

Result: 在相同准确度下，DLLM代理端到端速度平均比AR代理快30%以上，某些情况下超过8倍加速。正确完成任务时，DLLM代理需要更少的交互轮次和工具调用，规划命中率更高，收敛到正确行动路径更快，回溯更少。

Conclusion: 扩散骨干网络在工具使用代理中具有显著效率优势，但需要更强的工具调用训练和注意力掩码对齐。扩散代理表现出更强的全局规划信号，为智能体决策提供了有前景的替代方案。

Abstract: Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, and do these differences translate into end-to-end efficiency gains? We study this in a controlled setting by instantiating DLLM and AR backbones within the same agent workflow (DeepDiver) and performing matched agent-oriented fine-tuning on the same trajectory data, yielding diffusion-backed DLLM Agents and directly comparable AR agents. Across benchmarks and case studies, we find that, at comparable accuracy, DLLM Agents are on average over 30% faster end to end than AR agents, with some cases exceeding 8x speedup. Conditioned on correct task completion, DLLM Agents also require fewer interaction rounds and tool invocations, consistent with higher planner hit rates that converge earlier to a correct action path with less backtracking. We further identify two practical considerations for deploying diffusion backbones in tool-using agents. First, naive DLLM policies are more prone to structured tool-call failures, necessitating stronger tool-call-specific training to emit valid schemas and arguments. Second, for multi-turn inputs interleaving context and action spans, diffusion-style span corruption requires aligned attention masking to avoid spurious context-action information flow; without such alignment, performance degrades. Finally, we analyze attention dynamics across workflow stages and observe paradigm-specific coordination patterns, suggesting stronger global planning signals in diffusion-backed agents.

</details>


### [21] [SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning](https://arxiv.org/abs/2602.07464)
*Yijie Chen,Yijin Liu,Fandong Meng*

Main category: cs.CL

TL;DR: SED-SFT提出了一种新的监督微调方法，通过选择性熵正则化解决传统交叉熵损失导致的模式崩溃问题，提高模型响应多样性，从而提升后续强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 传统SFT使用交叉熵损失会导致模式崩溃，模型过度集中在特定响应模式上，缺乏分布多样性，这严重限制了后续RL的探索效率。现有改进方法未能充分平衡多样性和准确性。

Method: 提出SED-SFT框架，基于token探索空间自适应鼓励多样性。在优化目标中引入选择性熵正则化项和选择性掩码机制，平衡多样性和准确性。

Result: 在8个数学基准测试中，SED-SFT显著提高生成多样性，计算开销可忽略。相比标准CE基线，在Llama-3.2-3B-Instruct和Qwen2.5-Math-7B-Instruct上后续RL性能分别平均提升2.06和1.20分。

Conclusion: SED-SFT有效解决了SFT中的模式崩溃问题，通过自适应多样性鼓励机制，在保持准确性的同时提高响应多样性，从而显著提升后续RL性能。

Abstract: Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has emerged as the standard post-training paradigm for large language models (LLMs). However, the conventional SFT process, driven by Cross-Entropy (CE) loss, often induces mode collapse, where models over-concentrate on specific response patterns. This lack of distributional diversity severely restricts the exploration efficiency required for subsequent RL. While recent studies have attempted to improve SFT by replacing the CE loss, aiming to preserve diversity or refine the update policy, they fail to adequately balance diversity and accuracy, thereby yielding suboptimal performance after RL. To address the mode collapse problem, we propose SED-SFT, which adaptively encourages diversity based on the token exploration space. This framework introduces a selective entropy regularization term with a selective masking mechanism into the optimization objective. Extensive experiments across eight mathematical benchmarks demonstrate that SED-SFT significantly enhances generation diversity with a negligible computational overhead increase compared with CE loss, yielding average improvements of 2.06 and 1.20 points in subsequent RL performance over standard CE-based baselines on Llama-3.2-3B-Instruct and Qwen2.5-Math-7B-Instruct, respectively. The code is publicly available at https://github.com/pppa2019/SED-SFT

</details>


### [22] [From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection](https://arxiv.org/abs/2602.07497)
*Mo Wang,Kaixuan Ren,Pratik Jalan,Ahmed Ashraf,Tuong Vy Vu,Rahul Seetharaman,Shah Nawaz,Usman Naseem*

Main category: cs.CL

TL;DR: 该论文提出一个评估框架，用于诊断和量化视觉语言模型在多语言表情包数据集上的跨文化鲁棒性，发现"翻译后检测"方法会降低性能，而文化对齐干预（母语提示和单样本学习）能显著提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 文化背景深刻影响人们对在线内容的理解，但现有的视觉语言模型主要基于西方或英语中心视角训练，这限制了它们在仇恨表情包检测等任务中的公平性和跨文化鲁棒性。

Method: 引入系统性的评估框架，通过三个维度分析最先进视觉语言模型的跨文化鲁棒性：1) 学习策略（零样本 vs 单样本）；2) 提示语言（母语 vs 英语）；3) 翻译对意义和检测的影响。

Result: 结果显示常见的"翻译后检测"方法会降低性能，而文化对齐干预（母语提示和单样本学习）能显著增强检测效果。研究揭示了模型系统性地趋向西方安全规范。

Conclusion: 研究提供了可操作的策略来减轻这种偏见，指导设计全球鲁棒的多模态内容审核系统，强调文化对齐干预的重要性。

Abstract: Cultural context profoundly shapes how people interpret online content, yet vision-language models (VLMs) remain predominantly trained through Western or English-centric lenses. This limits their fairness and cross-cultural robustness in tasks like hateful meme detection. We introduce a systematic evaluation framework designed to diagnose and quantify the cross-cultural robustness of state-of-the-art VLMs across multilingual meme datasets, analyzing three axes: (i) learning strategy (zero-shot vs. one-shot), (ii) prompting language (native vs. English), and (iii) translation effects on meaning and detection. Results show that the common ``translate-then-detect'' approach deteriorate performance, while culturally aligned interventions - native-language prompting and one-shot learning - significantly enhance detection. Our findings reveal systematic convergence toward Western safety norms and provide actionable strategies to mitigate such bias, guiding the design of globally robust multimodal moderation systems.

</details>


### [23] [Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification](https://arxiv.org/abs/2602.07499)
*Jingshen Zhang,Xin Ying Qiu,Lifang Lu,Zhuhua Huang,Yutao Hu,Yuechang Wu,JunYu Lu*

Main category: cs.CL

TL;DR: 提出一个通过动态路径规划、语义感知示例选择和对话历史链式推理的框架，将复杂句子简化分解为可管理步骤，在五种语言上提高简化效果同时减少计算步骤22-42%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在可控难度句子简化方面能力有限，特别是在跨大阅读难度级别简化时效果不佳

Method: 通过动态路径规划将复杂简化分解为可管理步骤，结合语义感知示例选择和基于对话历史的链式推理生成，实现连贯推理

Result: 在五种语言的两个基准测试中，该方法提高了简化效果，同时减少了22-42%的计算步骤。人类评估确认了简化效果与意义保留之间的基本权衡

Conclusion: 逐步简化提高了控制性，但在广泛简化过程中保持语义保真度仍然是一个开放挑战，人类标注者在语义保留判断上也存在分歧

Abstract: Large language models demonstrate limited capability in proficiency-controlled sentence simplification, particularly when simplifying across large readability levels. We propose a framework that decomposes complex simplifications into manageable steps through dynamic path planning, semantic-aware exemplar selection, and chain-of-thought generation with conversation history for coherent reasoning. Evaluation on five languages across two benchmarks shows our approach improves simplification effectiveness while reducing computational steps by 22-42%. Human evaluation confirms the fundamental trade-off between simplification effectiveness and meaning preservation. Notably, even human annotators struggle to agree on semantic preservation judgments, highlighting the inherent complexity of this task. Our work shows that while step-by-step simplification improves control, preserving semantic fidelity during extensive simplification remains an open challenge.

</details>


### [24] [Improving Variable-Length Generation in Diffusion Language Models via Length Regularization](https://arxiv.org/abs/2602.07546)
*Zicong Cheng,Ruixuan Jia,Jia Li,Guo-Wei Yang,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.CL

TL;DR: LR-DLLM提出长度正则化推理框架，解决扩散大语言模型在变长生成中的长度诱导偏差问题，实现可靠的未知长度推理。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（DLLMs）在变长生成中存在固有缺陷，其推理基于固定长度画布，隐含假设已知目标长度。在现实场景如补全和填充中，当长度未知时，简单地比较不同掩码长度的置信度会产生系统性偏差，导致生成不足或冗余延续。

Method: 提出LR-DLLM（长度正则化推理框架），将生成长度作为显式变量，通过显式长度正则化将语义兼容性与长度诱导不确定性解耦，修正有偏的置信度估计。该框架无需修改底层DLLM或其训练过程，即可实现生成跨度的动态扩展或收缩。

Result: 在完全未知长度条件下，LR-DLLM在HumanEvalInfilling上达到51.3% Pass@1（比DreamOn提升13.4%），在四语言McEval上平均达到51.5% Pass@1（比DreamOn提升14.3%）。

Conclusion: LR-DLLM通过长度正则化推理框架有效解决了DLLMs在变长生成中的长度诱导偏差问题，实现了可靠的未知长度推理，显著提升了填充和补全任务的性能。

Abstract: Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence across mask lengths becomes systematically biased, leading to under-generation or redundant continuations. In this paper, we show that this failure arises from an intrinsic lengthinduced bias in generation confidence estimates, leaving existing DLLMs without a robust way to determine generation length and making variablelength inference unreliable. To address this issue, we propose LR-DLLM, a length-regularized inference framework for DLLMs that treats generation length as an explicit variable and achieves reliable length determination at inference time. It decouples semantic compatibility from lengthinduced uncertainty through an explicit length regularization that corrects biased confidence estimates. Based on this, LR-DLLM enables dynamic expansion or contraction of the generation span without modifying the underlying DLLM or its training procedure. Experiments show that LRDLLM achieves 51.3% Pass@1 on HumanEvalInfilling under fully unknown lengths (+13.4% vs. DreamOn) and 51.5% average Pass@1 on four-language McEval (+14.3% vs. DreamOn).

</details>


### [25] [Learning to Self-Verify Makes Language Models Better Reasoners](https://arxiv.org/abs/2602.07594)
*Yuxin Chen,Yu Wang,Yi Zhang,Ziang Ye,Zhengzhou Cai,Yaorui Shi,Qi Gu,Hui Su,Xunliang Cai,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: LLMs在生成推理路径方面表现强劲，但在自我验证方面较弱，存在能力不对称性。研究发现自我验证训练能有效提升生成性能，而生成训练则不能改善验证能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务中能生成有前景的推理路径，但验证自身答案的能力仍然薄弱，存在生成与自我验证之间的能力不对称问题。研究者希望深入探究这种不对称性及其对模型训练的影响。

Method: 1) 研究训练演化过程中生成与自我验证的不对称性；2) 探索自我验证训练对生成性能的影响；3) 提出多任务强化学习框架，将生成和自我验证作为两个独立但互补的目标进行优化。

Result: 研究发现：1) 提高生成能力不会相应改善自我验证能力；2) 学习自我验证能有效提升生成性能，达到与标准生成训练相当的准确率，同时产生更高效有效的推理轨迹；3) 多任务强化学习框架在多个基准测试和模型中均优于仅生成训练。

Conclusion: 生成与自我验证之间存在显著的能力不对称性，自我验证训练对生成性能有积极影响。通过多任务强化学习框架整合自我验证到生成训练中，可以同时提升模型的生成和验证能力。

Abstract: Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.

</details>


### [26] [SciClaimEval: Cross-modal Claim Verification in Scientific Papers](https://arxiv.org/abs/2602.07621)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Tian Cheng Xia,Florian Boudin,Andre Greiner-Petter,Akiko Aizawa*

Main category: cs.CL

TL;DR: SciClaimEval是一个新的科学声明验证数据集，包含从已发表论文中提取的真实声明（包括被反驳的声明），提供跨模态证据，并在三个领域评估了11个多模态基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有科学声明验证数据集通常使用人工修改声明或依赖LLM生成矛盾声明的方法，缺乏真实性和多样性。需要创建包含真实科学声明（包括被反驳声明）且提供跨模态证据的数据集，以更好地评估多模态模型在科学声明验证任务上的能力。

Method: 通过修改支持证据（图表）而非修改声明本身来创建被反驳的声明。数据集包含从180篇论文中提取的1,664个标注样本，涵盖机器学习、自然语言处理和医学三个领域。图表以多种格式提供：图像作为图片，表格提供图像、LaTeX源码、HTML和JSON格式。

Result: 评估了11个开源和专有多模态基础模型。结果显示，基于图像的验证对所有模型都特别具有挑战性，最佳系统与人类基线之间存在显著的性能差距。

Conclusion: SciClaimEval是一个具有真实科学声明和跨模态证据的数据集，揭示了当前多模态模型在科学声明验证任务上的局限性，特别是在基于图像的验证方面，为未来研究提供了有价值的基准。

Abstract: We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we introduce a novel approach that modifies the supporting evidence (figures and tables), rather than altering the claims or relying on large language models (LLMs) to fabricate contradictions. The dataset provides cross-modal evidence with diverse representations: figures are available as images, while tables are provided in multiple formats, including images, LaTeX source, HTML, and JSON. SciClaimEval contains 1,664 annotated samples from 180 papers across three domains, machine learning, natural language processing, and medicine, validated through expert annotation. We benchmark 11 multimodal foundation models, both open-source and proprietary, across the dataset. Results show that figure-based verification remains particularly challenging for all models, as a substantial performance gap remains between the best system and human baseline.

</details>


### [27] [Letting Tutor Personas "Speak Up" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization](https://arxiv.org/abs/2602.07639)
*Jaewook Lee,Alexander Scarlatos,Simon Woodhead,Andrew Lan*

Main category: cs.CL

TL;DR: 该研究提出使用激活空间导向向量来引导大语言模型模仿不同人类导师的教学风格，无需显式提示指令，实现了对导师个性化教学行为的控制。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的辅导系统通常只学习单一导师策略，无法捕捉真实教学中导师风格的多样性。真实导师会根据学生需求调整脚手架水平、指导性、反馈和情感支持，这些差异会影响对话动态和学生参与度。

Method: 修改双向偏好优化（BiPO）方法，学习一个激活空间导向向量，该向量能够将模型响应引导向特定导师的教学风格。该方法直接从人类导师-学生对话数据中提取信号，无需显式提示指令。

Result: 导向向量能够捕捉不同导师在对话上下文中的特定变化，提高了与真实导师话语的语义对齐度，增加了基于偏好的评估分数，同时基本保持了词汇相似性。学习到的方向系数显示出可解释的结构，对应导师教学行为的一致差异。

Conclusion: 激活导向提供了一种有效且可解释的方法，可以利用直接从人类对话数据中提取的信号来控制LLM中导师特定的教学风格变化，为个性化AI辅导系统开发提供了新途径。

Abstract: With the emergence of large language models (LLMs) as a powerful class of generative artificial intelligence (AI), their use in tutoring has become increasingly prominent. Prior works on LLM-based tutoring typically learn a single tutor policy and do not capture the diversity of tutoring styles. In real-world tutor-student interactions, pedagogical intent is realized through adaptive instructional strategies, with tutors varying the level of scaffolding, instructional directiveness, feedback, and affective support in response to learners' needs. These differences can all impact dialogue dynamics and student engagement. In this paper, we explore how tutor personas embedded in human tutor-student dialogues can be used to guide LLM behavior without relying on explicitly prompted instructions. We modify Bidirectional Preference Optimization (BiPO) to learn a steering vector, an activation-space direction that steers model responses towards certain tutor personas. We find that this steering vector captures tutor-specific variation across dialogue contexts, improving semantic alignment with ground-truth tutor utterances and increasing preference-based evaluations, while largely preserving lexical similarity. Analysis of the learned directional coefficients further reveals interpretable structure across tutors, corresponding to consistent differences in tutoring behavior. These results demonstrate that activation steering offers an effective and interpretable way for controlling tutor-specific variation in LLMs using signals derived directly from human dialogue data.

</details>


### [28] [Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation](https://arxiv.org/abs/2602.07673)
*Jiangnan Fang,Cheng-Tse Liu,Hanieh Deilamsalehy,Nesreen K. Ahmed,Puneet Mathur,Nedim Lipka,Franck Dernoncourt,Ryan A. Rossi*

Main category: cs.CL

TL;DR: LLM评委在摘要评估中存在偏见：随着与人工摘要相似度降低，LLM评委越来越偏好其他LLM生成的摘要而非人工摘要，且几乎所有测试模型都存在此问题。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM评委比传统算法指标更能捕捉语义信息、推理能力更强且对改写更鲁棒，但它们存在长度、顺序等偏见，且易受对抗性提示攻击。现有研究很少从与明确定义的重叠度指标相关的更细粒度层面分析这些偏见。

Method: 在摘要领域，以与人工摘要的重叠度为函数进行LLM评委偏见分析。测试9个参数从10亿到120亿的近期LLM（包括Gemma 3和LLaMA 3变体），使用ROUGE和BLEU衡量相似度。

Result: 发现随着被评估摘要之间相似度降低，LLM评委越来越偏好其他LLM生成的摘要而非人工摘要，除一个模型外所有测试模型都存在此模式，且不受模型自身位置偏见影响。模型甚至难以评估重叠度有限的摘要。

Conclusion: 在摘要领域使用LLM-as-a-judge应依赖超越简单比较的技术，因为LLM评委存在系统性偏见，难以准确评估摘要质量，特别是在与人工摘要相似度较低时。

Abstract: Large language model (LLM) judges have often been used alongside traditional, algorithm-based metrics for tasks like summarization because they better capture semantic information, are better at reasoning, and are more robust to paraphrasing. However, LLM judges show biases for length and order among others, and are vulnerable to various adversarial input prompts. While recent studies have looked into these biases, few have analyzed them at a more granular level in relation to a well-defined overlap metric. In this work we provide an LLM judge bias analysis as a function of overlap with human-written responses in the domain of summarization. We test 9 recent LLMs with parameter counts ranging from 1 billion to 12 billion, including variants of Gemma 3 and LLaMA 3. We find that LLM judges increasingly prefer summaries generated by other LLMs over those written by humans as the similarities (as measured by ROUGE and BLEU) between the judged summaries decrease, and this pattern extends to all but one model tested, and exists regardless of the models' own position biases. Additionally, we find that models struggle to judge even summaries with limited overlaps, suggesting that LLM-as-a-judge in the summary domain should rely on techniques beyond a simple comparison.

</details>


### [29] [SRR-Judge: Step-Level Rating and Refinement for Enhancing Search-Integrated Reasoning in Search Agents](https://arxiv.org/abs/2602.07773)
*Chen Zhang,Kuicai Dong,Dexun Li,Wenjun Li,Qu Yang,Wei Han,Yong Liu*

Main category: cs.CL

TL;DR: SRR-Judge框架为搜索集成推理提供步骤级评估，通过迭代拒绝采样微调显著提升深度搜索代理性能


<details>
  <summary>Details</summary>
Motivation: 现有基于大型推理模型的深度搜索代理通常只使用结果监督进行训练，忽略了中间思考和行动的质量，需要更可靠的步骤级评估方法

Method: 提出SRR-Judge框架用于可靠评估推理和搜索行动，集成到改进的ReAct式"评估-精炼"工作流中，使用SRR标注数据进行迭代拒绝采样微调

Result: SRR-Judge比DeepSeek-V3.1等更大模型提供更可靠的步骤级评估，其评分与最终答案正确性强相关，对齐策略带来超过10%的平均绝对pass@1提升

Conclusion: SRR-Judge框架通过提供细粒度指导和高效后训练标注，显著增强了深度搜索代理的能力，为搜索集成推理提供了有效的评估和训练方法

Abstract: Recent deep search agents built on large reasoning models (LRMs) excel at complex question answering by iteratively planning, acting, and gathering evidence, a capability known as search-integrated reasoning. However, mainstream approaches often train this ability using only outcome-based supervision, neglecting the quality of intermediate thoughts and actions. We introduce SRR-Judge, a framework for reliable step-level assessment of reasoning and search actions. Integrated into a modified ReAct-style rate-and-refine workflow, SRR-Judge provides fine-grained guidance for search-integrated reasoning and enables efficient post-training annotation. Using SRR-annotated data, we apply an iterative rejection sampling fine-tuning procedure to enhance the deep search capability of the base agent. Empirically, SRR-Judge delivers more reliable step-level evaluations than much larger models such as DeepSeek-V3.1, with its ratings showing strong correlation with final answer correctness. Moreover, aligning the policy with SRR-Judge annotated trajectories leads to substantial performance gains, yielding over a 10 percent average absolute pass@1 improvement across challenging deep search benchmarks.

</details>


### [30] [Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs](https://arxiv.org/abs/2602.07778)
*Shenglai Zeng,Tianqi Zheng,Chuan Tian,Dante Everaert,Yau-Shian Wang,Yupin Huang,Michael J. Morais,Rohit Patki,Jinjin Tian,Xinnan Dai,Kai Guo,Monica Xiao Cheng,Hui Liu*

Main category: cs.CL

TL;DR: Attn-GS：基于注意力引导的上下文压缩框架，利用LLM注意力模式识别个性化重要信号，实现50倍token压缩同时保持接近完整上下文性能


<details>
  <summary>Details</summary>
Motivation: 个性化LLM需要整合大量用户交互历史和资料，但输入token限制导致高延迟和API成本。现有启发式方法（如选择最近交互或使用摘要模型）将上下文视为整体，未考虑LLM内部如何处理和优先处理不同资料组件。

Method: 提出Attn-GS框架：1）通过标记模型利用LLM注意力反馈标记重要个性化句子；2）指导压缩模型生成任务相关、高质量的压缩用户上下文。基于发现：a) LLM注意力模式自然揭示重要信号；b) 微调增强LLM区分相关与无关信息能力。

Result: 在不同任务、token限制和设置下显著优于各种基线方法，实现接近使用完整上下文的性能，同时将token使用减少50倍。

Conclusion: LLM注意力模式能有效识别个性化重要信号，Attn-GS框架通过注意力引导的上下文压缩，在保持性能的同时大幅降低token使用，为个性化LLM的实际部署提供可行方案。

Abstract: Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent interactions or prompting summarization models to compress user profiles. However, these methods treat context as a monolithic whole and fail to consider how LLMs internally process and prioritize different profile components. We investigate whether LLMs' attention patterns can effectively identify important personalization signals for intelligent context compression. Through preliminary studies on representative personalization tasks, we discover that (a) LLMs' attention patterns naturally reveal important signals, and (b) fine-tuning enhances LLMs' ability to distinguish between relevant and irrelevant information. Based on these insights, we propose Attn-GS, an attention-guided context compression framework that leverages attention feedback from a marking model to mark important personalization sentences, then guides a compression model to generate task-relevant, high-quality compressed user contexts. Extensive experiments demonstrate that Attn-GS significantly outperforms various baselines across different tasks, token limits, and settings, achieving performance close to using full context while reducing token usage by 50 times.

</details>


### [31] [Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models](https://arxiv.org/abs/2602.07794)
*Ningyu Xu,Qi Zhang,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: LLMs在上下文概念推理中会动态构建和使用结构化潜在表征，这些表征在推理中具有因果作用


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究发现LLMs中存在类似人类的概念表征，但尚不清楚这些模型是否在推理中功能性地依赖这些表征。本文旨在探究LLMs在上下文概念推理中的内部处理过程。

Method: 研究LLMs在上下文概念推理中的内部处理，识别概念子空间的出现位置，使用因果中介分析验证其功能性作用，分析注意力头在构建和利用这些表征中的分层进展。

Result: 发现中后期层出现概念子空间，其表征结构在不同上下文中保持稳定；因果分析证明该子空间对模型预测具有功能性中心作用；观察到早期到中期层的注意力头整合上下文线索构建和精炼子空间，后期层利用该子空间生成预测。

Conclusion: LLMs在上下文推理中会动态构建和使用结构化潜在表征，这为理解LLMs灵活适应的计算过程提供了新见解。

Abstract: Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.

</details>


### [32] [Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents](https://arxiv.org/abs/2602.07796)
*Jiatong Li,Changdae Oh,Hyeong Kyu Choi,Jindong Wang,Sharon Li*

Main category: cs.CL

TL;DR: 研究发现，在用户参与的实际场景中，强制LLM代理进行显式思考反而会降低性能，因为思考使代理变得"内向"，减少了信息透露，削弱了与用户的信息交换。


<details>
  <summary>Details</summary>
Motivation: 虽然推理能力已被证明能提升LLM在复杂任务上的表现，但其在真实用户参与场景中的有效性尚不清楚。本研究旨在探究显式思考在用户参与的LLM代理中的实际效果。

Method: 使用7个模型、3个基准测试和2种思考实例化进行实验，通过定量响应分类分析和定性失败传播案例研究来评估效果。

Result: 与预期相反，强制思考在用户参与场景中往往适得其反，导致各种LLM的性能异常下降。关键发现是思考使代理变得"内向"，缩短响应并减少向用户的信息透露，从而削弱代理-用户信息交换并导致下游任务失败。

Conclusion: 信息透明度意识是未来设计现实世界推理代理的关键但未被充分探索的视角。明确提示信息透露能可靠地提高不同模型族的性能，表明主动透明度是代理优化的关键杠杆。

Abstract: Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.

</details>


### [33] [Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models](https://arxiv.org/abs/2602.07804)
*Xuan Ding,Pengyu Tong,Ranjie Duan,Yunjian Zhang,Rui Sun,Yao Zhu*

Main category: cs.CL

TL;DR: 提出基于博弈论的层剪枝框架，将每层视为玩家，模型性能作为效用，通过轻量级代理网络估计层贡献，实现高效剪枝


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在真实场景部署受限于高计算需求，现有层剪枝方法依赖静态启发式规则，未能考虑层间依赖关系，限制了剪枝效果

Method: 将层剪枝建模为合作博弈，每层作为玩家，模型性能为效用；使用轻量级代理网络估计层贡献，结合分层蒙特卡洛掩码采样降低计算成本

Result: 实验显示该方法在困惑度和零样本准确率上持续优于现有方法，实现了更高效有效的大型语言模型层剪枝

Conclusion: 提出的博弈论框架能捕捉层间依赖，动态识别关键层，为大型语言模型提供更有效的剪枝方案

Abstract: While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.

</details>


### [34] [LLMs Know More About Numbers than They Can Say](https://arxiv.org/abs/2602.07812)
*Fengting Yuchi,Li Du,Jason Eisner*

Main category: cs.CL

TL;DR: LLMs在数值比较任务上表现不佳，但隐藏状态编码了数字大小信息，通过线性探针可以提取这些信息并用于提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管先进的大语言模型能解决数学问题，但在混合表示法的数值比较任务上（如"5.7×10² vs 580"）表现不佳。这引发了一个基本问题：LLMs是否真正理解这些数字的大小？

Method: 研究多个开源LLMs的隐藏状态，通过线性投影提取数字的对数幅度信息；使用线性分类器从隐藏状态中恢复数字排序；将探针的分类损失作为辅助目标进行微调。

Result: 1）隐藏状态编码了数字的对数幅度，恢复误差约2.3%（合成文本）和19.06%（科学论文）；2）隐藏状态能编码数字排序，线性分类器准确率超90%；3）模型直接回答排序问题的准确率仅50-70%；4）使用探针损失作为辅助目标微调，可将准确率提升3.22%。

Conclusion: LLMs的隐藏状态确实编码了数字大小信息，但模型无法有效利用这些信息进行显式推理。通过改进内部数值表示，可以增强模型的数值推理能力。

Abstract: Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: "Which is larger, $5.7 \times 10^2$ or $580$?" This raises a fundamental question: Do LLMs even know how big these numbers are? We probe the hidden states of several smaller open-source LLMs. A single linear projection of an appropriate hidden layer encodes the log-magnitudes of both kinds of numerals, allowing us to recover the numbers with relative error of about 2.3% (on restricted synthetic text) or 19.06% (on scientific papers). Furthermore, the hidden state after reading a pair of numerals encodes their ranking, with a linear classifier achieving over 90% accuracy. Yet surprisingly, when explicitly asked to rank the same pairs of numerals, these LLMs achieve only 50-70% accuracy, with worse performance for models whose probes are less effective. Finally, we show that incorporating the classifier probe's log-loss as an auxiliary objective during finetuning brings an additional 3.22% improvement in verbalized accuracy over base models, demonstrating that improving models' internal magnitude representations can enhance their numerical reasoning capabilities.

</details>


### [35] [TodoEvolve: Learning to Architect Agent Planning Systems](https://arxiv.org/abs/2602.07839)
*Jiaxi Liu,Yanzuo Jiang,Guibin Zhang,Zihan Zhang,Heng Chang,Zhenfei Yin,Qibing Ren,Junchi Yan*

Main category: cs.CL

TL;DR: TodoEvolve是一个元规划范式，能够自主合成并动态修订任务特定的规划架构，通过PlanFactory统一规划范式，使用IGPO训练模型，在多个基准测试中超越手工设计的规划模块。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统主要依赖固定、手工设计的规划结构，缺乏适应开放性问题结构多样性的灵活性，需要更灵活的规划方法。

Method: 1. 构建PlanFactory模块化设计空间，统一规划范式；2. 收集高质量规划轨迹；3. 使用阻抗引导偏好优化(IGPO)训练Todo-14B模型，该多目标强化学习目标鼓励生成性能好、稳定且令牌高效的规划系统。

Result: 在五个代理基准测试中，TodoEvolve始终超越精心设计的规划模块，同时保持经济的API成本和运行时开销。

Conclusion: TodoEvolve通过元规划范式成功解决了现有规划方法缺乏灵活性的问题，能够自主合成适应不同任务结构的规划架构，在性能和效率方面都表现出色。

Abstract: Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.

</details>


### [36] [Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers](https://arxiv.org/abs/2602.07842)
*Yuhan Wang,Shiyu Ni,Zhikai Ding,Zihang Zhan,Yuanzi Li,Keping Bi*

Main category: cs.CL

TL;DR: 论文提出MACE基准来研究多答案场景下的置信度校准问题，发现现有方法在多答案情况下会系统性低估置信度，并提出SCA方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有置信度校准方法主要针对单答案问答场景研究，但在存在多个有效答案的情况下会失效，因为不同正确答案之间的分歧会导致置信度系统性低估。

Method: 1. 引入MACE基准：包含12,000个事实性问题，涵盖6个领域，具有不同数量的正确答案；2. 提出语义置信度聚合（SCA）：通过对多个高概率采样响应进行置信度聚合来解决多答案校准问题。

Result: 实验表明：1. 准确率随答案数量增加而提高；2. 估计置信度却持续下降；3. 混合答案数量的问题存在严重校准错误；4. SCA在混合答案设置下达到最先进的校准性能，同时在单答案问题上保持强校准能力。

Conclusion: 多答案场景下的置信度校准是一个重要但被忽视的问题，提出的SCA方法能有效解决这一问题，为LLM在多答案场景下的可靠应用提供了更好的置信度校准方案。

Abstract: Confidence calibration is essential for making large language models (LLMs) reliable, yet existing training-free methods have been primarily studied under single-answer question answering. In this paper, we show that these methods break down in the presence of multiple valid answers, where disagreement among equally correct responses leads to systematic underestimation of confidence. To enable a systematic study of this phenomenon, we introduce MACE, a benchmark of 12,000 factual questions spanning six domains with varying numbers of correct answers. Experiments across 15 representative calibration methods and four LLM families (7B-72B) reveal that while accuracy increases with answer cardinality, estimated confidence consistently decreases, causing severe miscalibration for questions with mixed answer counts. To address this issue, we propose Semantic Confidence Aggregation (SCA), which aggregates confidence over multiple high-probability sampled responses. SCA achieves state-of-the-art calibration performance under mixed-answer settings while preserving strong calibration on single-answer questions.

</details>


### [37] [SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization](https://arxiv.org/abs/2602.07909)
*Taolin Zhang,Hang Guo,Wang Lu,Tao Dai,Shu-Tao Xia,Jindong Wang*

Main category: cs.CL

TL;DR: SparseEval：一种通过梯度下降优化锚点权重和迭代精化策略的高效LLM评估方法，利用MLP处理稀疏优化问题，显著降低评估成本。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，评估其性能的计算成本急剧增加，因为对大量基准样本进行推理会产生高昂计算开销。需要开发更高效的评估方法。

Method: 提出SparseEval方法：1) 将模型-项目性能矩阵视为稀疏矩阵；2) 选择代表性项目作为锚点；3) 将高效基准测试公式化为稀疏优化问题；4) 首次采用梯度下降优化锚点权重；5) 使用迭代精化策略进行锚点选择；6) 利用MLP的表征能力处理稀疏优化；7) 提出锚点重要性分数和候选重要性分数来评估每个项目的价值。

Result: 在多种基准测试上的广泛实验表明，该方法具有较低的估计误差和较高的Kendall's τ相关性，展示了其在真实场景中的优越鲁棒性和实用性。

Conclusion: SparseEval通过稀疏优化和智能锚点选择，实现了高效且准确的大语言模型评估，显著降低了计算成本，为实际应用提供了实用的解决方案。

Abstract: As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In this paper, we revisit the model-item performance matrix and show that it exhibits sparsity, that representative items can be selected as anchors, and that the task of efficient benchmarking can be formulated as a sparse optimization problem. Based on these insights, we propose SparseEval, a method that, for the first time, adopts gradient descent to optimize anchor weights and employs an iterative refinement strategy for anchor selection. We utilize the representation capacity of MLP to handle sparse optimization and propose the Anchor Importance Score and Candidate Importance Score to evaluate the value of each item for task-aware refinement. Extensive experiments demonstrate the low estimation error and high Kendall's~$τ$ of our method across a variety of benchmarks, showcasing its superior robustness and practicality in real-world scenarios. Code is available at {https://github.com/taolinzhang/SparseEval}.

</details>


### [38] [Patches of Nonlinearity: Instruction Vectors in Large Language Models](https://arxiv.org/abs/2602.07930)
*Irina Bigoulaeva,Jonas Rohweder,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 论文提出"指令向量"概念，发现指令表示在模型中局部化，同时展现线性可分性和非线性因果交互，挑战了机制可解释性中的线性表示假设。


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优语言模型广泛使用，但对其内部如何处理指令的机制了解甚少。本研究旨在从机制角度探究指令特定表示在监督微调和直接偏好优化等后训练阶段中如何构建和利用。

Method: 通过因果中介分析识别指令表示；提出新方法定位语言模型中的信息处理，避免基于补丁技术的线性假设；分析指令向量作为电路选择器的作用。

Result: 发现指令表示在模型中局部化（称为指令向量），同时展现线性可分性和非线性因果交互；指令向量在早期层形成任务表示后，在后期层选择不同信息通路来完成任务，即作为电路选择器。

Conclusion: 指令向量展现了线性可分性与非线性因果交互的奇特并存，挑战了机制可解释性中常见的线性表示假设；指令向量作为电路选择器，在任务表示形成后选择不同的信息处理通路。

Abstract: Despite the recent success of instruction-tuned language models and their ubiquitous usage, very little is known of how models process instructions internally. In this work, we address this gap from a mechanistic point of view by investigating how instruction-specific representations are constructed and utilized in different stages of post-training: Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Via causal mediation, we identify that instruction representation is fairly localized in models. These representations, which we call Instruction Vectors (IVs), demonstrate a curious juxtaposition of linear separability along with non-linear causal interaction, broadly questioning the scope of the linear representation hypothesis commonplace in mechanistic interpretability. To disentangle the non-linear causal interaction, we propose a novel method to localize information processing in language models that is free from the implicit linear assumptions of patching-based techniques. We find that, conditioned on the task representations formed in the early layers, different information pathways are selected in the later layers to solve that task, i.e., IVs act as circuit selectors.

</details>


### [39] [Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation](https://arxiv.org/abs/2602.07954)
*Krzysztof Wróbel,Jan Maria Kowalski,Jerzy Surma,Igor Ciuciura,Maciej Szymański*

Main category: cs.CL

TL;DR: Bielik Guard是一系列波兰语安全分类器，包含0.1B和0.5B参数两个变体，用于对波兰语内容进行五类安全分类，在保持高效的同时提供强性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在波兰语应用中的部署增加，需要高效准确的内容安全分类器来确保内容安全。

Method: 基于MMLW-RoBERTa-base和PKOBP/polish-roberta-8k构建两个模型变体（0.1B和0.5B参数），在6,885个社区标注的波兰语文本数据集上进行微调，分类五个安全类别。

Result: 0.5B变体在测试集上获得0.791（微平均）和0.785（宏平均）的F1分数，0.1B变体在真实用户提示上达到77.65%的精确率和0.63%的低误报率，优于相同规模的HerBERT-PL-Guard。

Conclusion: Bielik Guard系列模型在波兰语内容安全分类方面表现出色，0.5B变体提供最佳分类能力，0.1B变体在效率和精度上表现优异，模型公开可用并设计为提供适当响应而非简单内容屏蔽。

Abstract: As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65\%) and very low false positive rate (0.63\%) on real user prompts, outperforming HerBERT-PL-Guard (31.55\% precision, 4.70\% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.

</details>


### [40] [Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms](https://arxiv.org/abs/2602.07963)
*Vaibhav Shukla,Hardik Sharma,Adith N Reganti,Soham Wasmatkar,Bagesh Kumar,Vrijendra Singh*

Main category: cs.CL

TL;DR: 论文提出CompositeHarm基准，通过翻译方法评估LLM多语言安全对齐效果，发现在印度语言中攻击成功率显著上升，强调翻译基准是必要但不充分的步骤。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全评估主要基于英语，翻译作为多语言行为探测的捷径，但无法完整捕捉有害意图在不同语言中的变化。有些危害在翻译中保持完整，有些则扭曲或消失，需要系统研究这种效应。

Method: 引入CompositeHarm基准，结合AttaQ（结构化对抗攻击）和MMSafetyBench（上下文现实危害）两个英语数据集，扩展到六种语言（英语、印地语、阿萨姆语、马拉地语、卡纳达语、古吉拉特语）。采用轻量级推理策略，基于边缘AI设计原则减少冗余评估，保持跨语言保真度。

Result: 在三个大型模型上测试发现：1）攻击成功率在印度语言中显著上升，特别是在对抗性句法下；2）上下文危害转移较为温和；3）轻量级推理策略使大规模多语言安全测试在计算上可行且环保。

Conclusion: 翻译基准是构建有基础、资源感知、语言自适应安全系统的必要第一步，但不足够。需要更深入的多语言安全评估方法。

Abstract: Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.

</details>


### [41] [Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection](https://arxiv.org/abs/2602.07978)
*Rui Feng,Zhiyao Luo,Liuyu Wu,Wei Wang,Yuting Song,Yong Liu,Kok Pin Ng,Jianqing Li,Xingyao Wang*

Main category: cs.CL

TL;DR: SynCog框架通过可控零样本多模态数据合成和思维链推理微调，解决MCI诊断中的数据稀缺和可解释性问题，在多语言基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于语音的数字生物标志物在MCI早期识别中存在临床数据稀缺、缺乏可解释性、跨语言泛化能力不足等问题，限制了临床应用的信任度和推广性。

Method: 提出SynCog框架：1) 通过可控零样本多模态数据合成模拟不同认知特征的虚拟受试者，缓解数据稀缺；2) 使用思维链推理策略微调多模态大语言模型，使模型能明确阐述诊断推理过程而非黑盒预测。

Result: 在ADReSS和ADReSSo基准测试中，通过合成数据增强获得80.67%和78.46%的Macro-F1分数，优于现有基线模型。在独立真实世界汉语队列(CIR-E)上实现48.71%的Macro-F1，展示了强大的跨语言泛化能力。

Conclusion: SynCog框架为解决临床数据稀缺、提升模型可解释性和跨语言泛化能力提供了有效方案，是迈向临床可信赖、语言包容性认知评估工具的重要一步。

Abstract: Speech-based digital biomarkers represent a scalable, non-invasive frontier for the early identification of Mild Cognitive Impairment (MCI). However, the development of robust diagnostic models remains impeded by acute clinical data scarcity and a lack of interpretable reasoning. Current solutions frequently struggle with cross-lingual generalization and fail to provide the transparent rationales essential for clinical trust. To address these barriers, we introduce SynCog, a novel framework integrating controllable zero-shot multimodal data synthesis with Chain-of-Thought (CoT) deduction fine-tuning. Specifically, SynCog simulates diverse virtual subjects with varying cognitive profiles to effectively alleviate clinical data scarcity. This generative paradigm enables the rapid, zero-shot expansion of clinical corpora across diverse languages, effectively bypassing data bottlenecks in low-resource settings and bolstering the diagnostic performance of Multimodal Large Language Models (MLLMs). Leveraging this synthesized dataset, we fine-tune a foundational multimodal backbone using a CoT deduction strategy, empowering the model to explicitly articulate diagnostic thought processes rather than relying on black-box predictions. Extensive experiments on the ADReSS and ADReSSo benchmarks demonstrate that augmenting limited clinical data with synthetic phenotypes yields competitive diagnostic performance, achieving Macro-F1 scores of 80.67% and 78.46%, respectively, outperforming current baseline models. Furthermore, evaluation on an independent real-world Mandarin cohort (CIR-E) demonstrates robust cross-linguistic generalization, attaining a Macro-F1 of 48.71%. These findings constitute a critical step toward providing clinically trustworthy and linguistically inclusive cognitive assessment tools for global healthcare.

</details>


### [42] [The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation](https://arxiv.org/abs/2602.07996)
*Arash Marioriyad,Omid Ghahroodi,Ehsaneddin Asgari,Mohammad Hossein Rohban,Mahdieh Soleymani Baghshah*

Main category: cs.CL

TL;DR: 研究发现LLM作为自动评估器时，其判决会受到无关上下文线索（如来源、时间、人口统计信息）的显著影响，但这些影响很少在评估理由中明确承认，存在解释差距。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地被用作自动评估器来评判系统输出，但理想的评估器应仅基于内容质量做出判断，不受无关上下文影响，并能透明反映决策因素。本研究旨在测试LLM评估器是否忠实于这一理想。

Method: 通过控制性线索扰动实验，向评估提示中注入合成元数据标签（来源、时间、年龄、性别、种族、教育状况），测试六个LLM评估器（GPT-4o、Gemini-2.0-Flash等）。使用两个互补数据集：ELI5（事实问答）和LitBench（开放式创意写作）。引入两个指标：判决转移率（VSR）和线索承认率（CAR）。

Result: LLM评估器对无关线索表现出显著敏感性（如专家>人类>LLM>未知的来源偏好，新>旧的时间偏好，教育状况偏好）。但线索承认率通常接近零，表明即使线索驱动了决策，也很少在理由中明确承认。CAR具有数据集依赖性：在事实性ELI5设置中某些模型和线索更可能承认线索，但在开放式LitBench中承认率常为零，尽管判决转移仍然存在。

Conclusion: LLM作为评估器的管道存在解释差距：判决对无关线索敏感，但很少在理由中承认这种影响。这引发了在研究和部署中依赖模型评估的可靠性担忧，需要更透明的评估机制。

Abstract: Large language models (LLMs) are increasingly used as automatic judges to evaluate system outputs in tasks such as reasoning, question answering, and creative writing. A faithful judge should base its verdicts solely on content quality, remain invariant to irrelevant context, and transparently reflect the factors driving its decisions. We test this ideal via controlled cue perturbations-synthetic metadata labels injected into evaluation prompts-for six judge models: GPT-4o, Gemini-2.0-Flash, Gemma-3-27B, Qwen3-235B, Claude-3-Haiku, and Llama3-70B. Experiments span two complementary datasets with distinct evaluation regimes: ELI5 (factual QA) and LitBench (open-ended creative writing). We study six cue families: source, temporal, age, gender, ethnicity, and educational status. Beyond measuring verdict shift rates (VSR), we introduce cue acknowledgment rate (CAR) to quantify whether judges explicitly reference the injected cues in their natural-language rationales. Across cues with strong behavioral effects-e.g., provenance hierarchies (Expert > Human > LLM > Unknown), recency preferences (New > Old), and educational-status favoritism-CAR is typically at or near zero, indicating that shortcut reliance is largely unreported even when it drives decisions. Crucially, CAR is also dataset-dependent: explicit cue recognition is more likely to surface in the factual ELI5 setting for some models and cues, but often collapses in the open-ended LitBench regime, where large verdict shifts can persist despite zero acknowledgment. The combination of substantial verdict sensitivity and limited cue acknowledgment reveals an explanation gap in LLM-as-judge pipelines, raising concerns about reliability of model-based evaluation in both research and deployment.

</details>


### [43] [DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity](https://arxiv.org/abs/2602.08005)
*Jitai Hao,Qiang Huang,Yaowei Wang,Min Zhang,Jun Yu*

Main category: cs.CL

TL;DR: DeltaKV通过残差编码压缩KV缓存，Sparse-vLLM优化稀疏KV布局推理引擎，在保持精度的同时将KV内存降至29%，吞吐量提升2倍


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM部署面临KV缓存内存线性增长的瓶颈，现有压缩和淘汰方法难以平衡精度、压缩比和硬件效率

Method: DeltaKV基于长距离token相似性和KV表示共享潜在组件的发现，采用残差编码压缩KV缓存；Sparse-vLLM提供解耦内存管理和稀疏不规则KV布局优化的高性能推理引擎

Result: DeltaKV将KV缓存内存降至原始的29%，在LongBench、SCBench和AIME上保持接近无损精度；结合Sparse-vLLM在长上下文场景中相比vLLM实现高达2倍吞吐量提升

Conclusion: DeltaKV和Sparse-vLLM为可扩展的长上下文LLM部署提供了实用路径，在保持精度的同时显著提升内存效率和推理性能

Abstract: The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.

</details>


### [44] [Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning](https://arxiv.org/abs/2602.08028)
*Po-Chun Chen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: DIP（Diverge-to-Induce Prompting）是一种提示框架，通过生成多种不同的高层推理策略，然后将其细化为详细计划，最后整合成最终计划，以提升大语言模型的零样本推理准确性。


<details>
  <summary>Details</summary>
Motivation: 标准思维链提示中无指导的推理路径不稳定，而现有方法只使用单一推理策略，限制了在不同任务上的性能表现。

Method: DIP框架：1）为每个问题生成多种不同的高层推理策略；2）将每个策略细化为详细的步骤草案计划；3）将这些草案计划整合诱导成最终计划。

Result: 实验表明DIP优于单一策略提示方法，证明了多计划诱导在基于提示的推理中的有效性，且无需依赖资源密集的采样。

Conclusion: 通过先发散生成多种推理策略再整合诱导的方法，可以有效提升大语言模型的零样本推理能力，比单一策略方法表现更好。

Abstract: To address the instability of unguided reasoning paths in standard Chain-of-Thought prompting, recent methods guide large language models (LLMs) by first eliciting a single reasoning strategy. However, relying on just one strategy for each question can still limit performance across diverse tasks. We propose Diverge-to-Induce Prompting (DIP), a framework that first prompts an LLM to generate multiple diverse high-level rationales for each question. Each rationale is then elaborated into a detailed, step-by-step draft plan. Finally, these draft plans are induced into a final plan. DIP enhances zero-shot reasoning accuracy without reliance on resource-intensive sampling. Experiments show that DIP outperforms single-strategy prompting, demonstrating the effectiveness of multi-plan induction for prompt-based reasoning.

</details>


### [45] [Beyond Raw Detection Scores: Markov-Informed Calibration for Boosting Machine-Generated Text Detection](https://arxiv.org/abs/2602.08031)
*Chenwang Wu,Yiu-ming Cheung,Shuhai Zhang,Bo Han,Defu Lian*

Main category: cs.CL

TL;DR: 该论文提出了一种基于马尔可夫随机场的分数校准策略，用于解决机器生成文本检测中token级检测分数易受生成过程随机性影响的问题，显著提升了现有检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 机器生成文本虽然带来便利，但也存在虚假信息和网络钓鱼等风险，需要可靠检测。基于度量的方法比复杂模型方法更实用，但面临核心挑战：token级检测分数易受MGT生成过程随机性的影响而产生偏差。

Method: 首先将代表性度量方法置于统一框架中进行分析，识别出核心问题。然后从理论和实证角度揭示了两种有助于校准的上下文检测分数关系：邻居相似性和初始不稳定性。提出基于马尔可夫随机场的分数校准策略，通过平均场近似实现为轻量级组件，可无缝集成到现有检测器中。

Result: 在跨LLM和改述攻击等各种现实场景中的广泛实验表明，该方法相比基线方法取得了显著提升，且计算开销可忽略不计。

Conclusion: 提出的马尔可夫随机场校准策略有效解决了机器生成文本检测中token级分数偏差问题，能够显著提升现有检测器的性能，同时保持计算效率。

Abstract: While machine-generated texts (MGTs) offer great convenience, they also pose risks such as disinformation and phishing, highlighting the need for reliable detection. Metric-based methods, which extract statistically distinguishable features of MGTs, are often more practical than complex model-based methods that are prone to overfitting. Given their diverse designs, we first place representative metric-based methods within a unified framework, enabling a clear assessment of their advantages and limitations. Our analysis identifies a core challenge across these methods: the token-level detection score is easily biased by the inherent randomness of the MGTs generation process. To address this, we theoretically and empirically reveal two relationships of context detection scores that may aid calibration: Neighbor Similarity and Initial Instability. We then propose a Markov-informed score calibration strategy that models these relationships using Markov random fields, and implements it as a lightweight component via a mean-field approximation, allowing our method to be seamlessly integrated into existing detectors. Extensive experiments in various real-world scenarios, such as cross-LLM and paraphrasing attacks, demonstrate significant gains over baselines with negligible computational overhead. The code is available at https://github.com/tmlr-group/MRF_Calibration.

</details>


### [46] [TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs](https://arxiv.org/abs/2602.08048)
*Arshia Hemmat,Philip Torr,Yongqiang Chen,Junchi Yu*

Main category: cs.CL

TL;DR: TDGNet：一种用于扩散语言模型的时序动态图框架，通过分析去噪过程中的注意力图演化来检测幻觉，相比现有方法在多个基准测试中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型具有并行去噪和双向上下文优势，但其幻觉检测研究不足。现有的自回归LLM检测器依赖单次推理线索，无法直接迁移到扩散生成场景，因为事实证据分布在去噪轨迹中，可能随时间出现、漂移或自我修正。

Method: 提出TDGNet时序动态图框架，将幻觉检测建模为在演化中的令牌级注意力图上的学习。在每个去噪步骤中，稀疏化注意力图并通过消息传递更新每个令牌的记忆，然后使用时序注意力聚合整个轨迹的证据进行最终预测。

Result: 在LLaDA-8B和Dream-7B模型上的QA基准测试表明，TDGNet相比基于输出、基于潜在表示和静态图基线方法，在AUROC指标上取得一致改进，且只需单次推理和适度开销。

Conclusion: 结果表明，对注意力图进行时序推理对于扩散语言模型的鲁棒幻觉检测至关重要，TDGNet框架为此提供了有效解决方案。

Abstract: Diffusion language models (D-LLMs) offer parallel denoising and bidirectional context, but hallucination detection for D-LLMs remains underexplored. Prior detectors developed for auto-regressive LLMs typically rely on single-pass cues and do not directly transfer to diffusion generation, where factuality evidence is distributed across the denoising trajectory and may appear, drift, or be self-corrected over time. We introduce TDGNet, a temporal dynamic graph framework that formulates hallucination detection as learning over evolving token-level attention graphs. At each denoising step, we sparsify the attention graph and update per-token memories via message passing, then apply temporal attention to aggregate trajectory-wide evidence for final prediction. Experiments on LLaDA-8B and Dream-7B across QA benchmarks show consistent AUROC improvements over output-based, latent-based, and static-graph baselines, with single-pass inference and modest overhead. These results highlight the importance of temporal reasoning on attention graphs for robust hallucination detection in diffusion language models.

</details>


### [47] [Emergent Search and Backtracking in Latent Reasoning Models](https://arxiv.org/abs/2602.08100)
*Jasmine Cui,Charles Ye*

Main category: cs.CL

TL;DR: LRTs在隐藏空间进行推理，自发学习结构化搜索过程，包含探索、暂定承诺、收敛/回溯三个阶段，回溯能显著提升准确性


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在无语言情况下的推理过程，探索潜在推理变换器（LRTs）如何在连续隐藏空间中进行思考，与传统的语言化思维链方法形成对比

Method: 使用潜在推理变换器（LRTs），在多项选择QA基准上解码模型每一步演化的信念，分析其在隐藏空间中的结构化搜索过程

Result: 模型自发学习结构化搜索：探索阶段概率分布扩散，暂定承诺领先选项，然后收敛或回溯。回溯普遍（32%实例）且有益（准确率提升34%），主要从语义相近的干扰项转向正确答案。搜索具有适应性：替换干扰项可缩短探索54%

Conclusion: 潜在推理模型在激活空间中实现了思维链在语言中实现的功能：能够犯错、察觉并恢复，展示了无语言推理的有效性

Abstract: What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.

</details>


### [48] [Gender and Race Bias in Consumer Product Recommendations by Large Language Models](https://arxiv.org/abs/2602.08124)
*Ke Xu,Shera Potka,Alex Thomo*

Main category: cs.CL

TL;DR: 该研究首次系统性地探索了LLM在商品推荐中存在的性别与种族偏见，通过提示工程和多种分析方法揭示了推荐结果中的显著人口群体差异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地用于生成消费品推荐，但其可能嵌入和放大性别与种族偏见的潜力尚未得到充分探索。本研究旨在填补这一空白，成为首批系统考察LLM推荐系统中偏见问题的研究之一。

Method: 采用提示工程技术引导LLM为不同种族和性别群体生成产品推荐，并运用三种分析方法：标记词分析、支持向量机和Jensen-Shannon散度，以识别和量化推荐中的偏见。

Result: 研究发现不同人口群体获得的推荐存在显著差异，表明LLM推荐系统中存在系统性偏见，不同种族和性别群体被推荐的产品类型和质量有明显区别。

Conclusion: 研究结果强调了开发更公平的LLM推荐系统的迫切需求，需要采取措施减少和消除推荐算法中的性别与种族偏见，确保推荐系统的公正性。

Abstract: Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.

</details>


### [49] [DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries](https://arxiv.org/abs/2602.08149)
*Sahana Ramnath,Nima Chitsazan,Mingyang Zhou,Chia-Hsuan Lee,Shi-Xiong Zhang,Stephen Rawls,Sambit Sahu,Sangwoo Cho,Xiang Ren,Genta Indra Winata,Akshaj Kumar Veldanda*

Main category: cs.CL

TL;DR: DIALSUMMER是一个用于评估对话摘要质量的框架，通过分层错误分类系统（对话级和轮次内级）来专门解决对话摘要中特有的结构转换和叙述视角转换问题。


<details>
  <summary>Details</summary>
Motivation: 现有对话摘要评估方法忽略了对话摘要任务特有的复杂性：1）从多个发言者分散在多个轮次中的对话结构转换为摘要的句子结构；2）从发言者的第一/第二人称叙述转换为摘要的标准化第三人称叙述。

Method: 提出了DIALSUMMER框架，包含分层错误分类系统：对话级（关注发言者/轮次）和轮次内级（关注单个轮次内的信息）。创建了手动标注细粒度错误的数据集，并分析了错误模式。

Result: 通过实证分析发现了有趣的趋势：对话中间轮次最容易被遗漏，外部幻觉主要出现在摘要末尾。LLM-Judges在检测这些错误方面表现有限，证明了数据集的挑战性和分类系统的鲁棒性。

Conclusion: DIALSUMMER框架为对话摘要评估提供了更全面的方法，揭示了现有LLM在检测对话摘要错误方面的局限性，为未来改进LLM在该领域的性能指明了方向。

Abstract: Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.

</details>


### [50] [NLP for Local Governance Meeting Records: A Focus Article on Tasks, Datasets, Metrics and Benchmark](https://arxiv.org/abs/2602.08162)
*Ricardo Campos,José Pedro Evans,José Miguel Isidro,Miguel Marques,Luís Filipe Cunha,Alípio Jorge,Sérgio Nunes,Nuno Guimarães*

Main category: cs.CL

TL;DR: 本文综述了NLP技术在地方政府会议记录结构化处理中的应用，重点讨论了文档分割、实体提取和文本摘要三个核心任务，旨在提升政府文档的可访问性和透明度。


<details>
  <summary>Details</summary>
Motivation: 地方政府会议记录作为官方文件，虽然结构化但通常内容密集、官僚化，且在不同城市间存在语言、术语、结构等方面的显著异质性。这种异质性使得非专业人士难以解读，智能自动化系统也难以处理，限制了公共透明度和公民参与度。

Method: 本文采用文献综述方法，系统回顾了支持地方政府会议记录结构化的三个核心NLP任务：1) 文档分割，用于导航冗长的审议过程；2) 领域特定实体提取，用于识别政治参与者和个人信息；3) 自动文本摘要，用于生成复杂决策过程的简洁表示。同时讨论了方法学途径、评估指标和公开可用资源。

Result: 通过综合现有研究，本文提供了NLP如何增强地方政府会议记录结构化和可访问性的结构化概述，识别了领域特定挑战，包括数据稀缺、隐私约束和来源变异性等问题。

Conclusion: NLP技术能够有效解决地方政府会议记录的异质性和复杂性挑战，通过文档分割、实体提取和文本摘要等任务，可以显著提升政府文档的可访问性、透明度和公民参与度，尽管仍面临数据稀缺和隐私保护等实际挑战。

Abstract: Local governance meeting records are official documents, in the form of minutes or transcripts, documenting how proposals, discussions, and procedural actions unfold during institutional meetings. While generally structured, these documents are often dense, bureaucratic, and highly heterogeneous across municipalities, exhibiting significant variation in language, terminology, structure, and overall organization. This heterogeneity makes them difficult for non-experts to interpret and challenging for intelligent automated systems to process, limiting public transparency and civic engagement. To address these challenges, computational methods can be employed to structure and interpret such complex documents. In particular, Natural Language Processing (NLP) offers well-established methods that can enhance the accessibility and interpretability of governmental records. In this focus article, we review foundational NLP tasks that support the structuring of local governance meeting documents. Specifically, we review three core tasks: document segmentation, domain-specific entity extraction and automatic text summarization, which are essential for navigating lengthy deliberations, identifying political actors and personal information, and generating concise representations of complex decision-making processes. In reviewing these tasks, we discuss methodological approaches, evaluation metrics, and publicly available resources, while highlighting domain-specific challenges such as data scarcity, privacy constraints, and source variability. By synthesizing existing work across these foundational tasks, this article provides a structured overview of how NLP can enhance the structuring and accessibility of local governance meeting records.

</details>


### [51] [LLMs and people both learn to form conventions -- just not with each other](https://arxiv.org/abs/2602.08208)
*Cameron R. Jones,Agnese Lombardi,Kyle Mahowald,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: LLMs能与同类AI形成对话约定，但与人对话时无法有效对齐，即使模仿人类行为也无法达到人类间或AI间的对齐效果


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能在多模态交流游戏中像人类一样形成对话约定，探索AI与人类在交流对齐方面的差异

Method: 通过多模态交流游戏实验，比较同类型对话对（人-人、AI-AI）和混合对话对（人-AI）的表现，并在实验2中通过提示让LLMs模仿人类行为

Result: 同类型对话对都显示出约定形成（准确率和一致性提高，消息长度减少），但人-AI对话对失败；即使LLMs模仿人类行为长度匹配，准确率和词汇重叠仍落后于同类型对话对

Conclusion: 对话对齐不仅需要模仿先前交互的能力，还需要共享对所传达意义的解释偏见，LLMs与人类在交流倾向上存在差异

Abstract: Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed.

</details>


### [52] [Pretraining with Token-Level Adaptive Latent Chain-of-Thought](https://arxiv.org/abs/2602.08220)
*Boyi Zeng,Yiqin Hao,He Li,Shixiang Song,Feichen Song,Zitong Wang,Siyuan Huang,Yi Xu,ZiWei He,Xinbing Wang,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出自适应潜在CoT预训练方法，通过为每个token生成可变长度的潜在推理轨迹来增加计算而不增加参数，在训练和推理中自适应地分配计算资源


<details>
  <summary>Details</summary>
Motivation: 传统通过增加参数和训练数据来扩展大语言模型受到高质量语料库有限和通信成本上升的限制，需要探索新的扩展维度

Method: 提出Pretraining with Token-Level Adaptive Latent CoT方法，在预训练阶段让模型为每个token生成可变长度的潜在CoT轨迹，困难token分配更长轨迹，简单token分配更短甚至零轨迹，通过单阶段通用文本预训练自然实现

Result: 在Llama架构上的实验表明，自适应潜在CoT持续改善语言建模困惑度和广泛下游任务准确率，即使比先前循环基线使用更少的训练FLOPs

Conclusion: 通过内部化潜在CoT到预训练中，在不增加参数的情况下增加每个token的计算量，提供了一种新的模型扩展维度，有效提升性能同时降低计算成本

Abstract: Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines.

</details>


### [53] [CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts](https://arxiv.org/abs/2602.08221)
*Xuhua Ma,Richong Zhang,Zhijie Nie*

Main category: cs.CL

TL;DR: CoRect通过对比上下文化和非上下文化前向传播的logits来识别参数偏见层，然后修正隐藏状态以保持证据基础信息，从而提高RAG的忠实度并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: RAG在处理知识冲突时存在参数知识覆盖检索证据的问题，导致输出不忠实。现有方法要么依赖表面解码调整，要么需要真实目标进行权重编辑，存在局限性。

Method: 通过层间分析发现参数抑制现象：深层FFN层用记忆先验覆盖上下文敏感表示。提出CoRect方法，通过对比上下文化和非上下文化前向传播的logits来识别高参数偏见层，然后修正隐藏状态以保留证据基础信息。

Result: 在问答和摘要基准测试中，CoRect相比强基线方法持续提高了忠实度并减少了幻觉。

Conclusion: CoRect通过识别和修正参数偏见层，有效解决了RAG中的知识冲突问题，提高了模型输出的忠实性，且无需真实标签。

Abstract: Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.

</details>


### [54] [When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents](https://arxiv.org/abs/2602.08235)
*Jaylen Jones,Zhehao Zhang,Yuting Ning,Eric Fosler-Lussier,Pierre-Luc St-Charles,Yoshua Bengio,Dawn Song,Yu Su,Huan Sun*

Main category: cs.CL

TL;DR: 本文提出了首个计算机使用代理意外行为的概念与方法框架AutoElicit，通过迭代扰动良性指令自动引发严重危害，在Claude等先进CUAs中发现了数百种有害意外行为。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理在自动化复杂操作系统工作流程方面潜力巨大，但即使在良性输入环境下也可能表现出偏离预期结果的不安全意外行为。目前对这种风险的探索主要停留在轶事层面，缺乏具体的特征描述和在现实CUA场景下主动发现长尾意外行为的自动化方法。

Method: 提出了AutoElicit框架：一个基于代理的方法，通过CUA执行反馈迭代扰动良性指令，在保持扰动现实性和良性的同时引发严重危害。该方法定义了意外行为的关键特征，并自动引发这些行为。

Result: 使用AutoElicit在Claude 4.5 Haiku和Opus等最先进的CUAs中发现了数百种有害意外行为。进一步评估了人工验证成功扰动的可转移性，发现各种前沿CUAs持续易受意外行为影响。

Conclusion: 这项工作为系统分析现实计算机使用环境中的意外行为奠定了基础，填补了CUA安全风险研究的空白，提供了自动发现和评估意外行为的方法框架。

Abstract: Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings.

</details>


### [55] [Document Reconstruction Unlocks Scalable Long-Context RLVR](https://arxiv.org/abs/2602.08237)
*Yao Xiao,Lei Wang,Yue Deng,Guanzheng Chen,Ziqi Jin,Jung-jae Kim,Xiaoli Li,Roy Ka-wei Lee,Lidong Bing*

Main category: cs.CL

TL;DR: 提出一种无监督强化学习方法，通过让LLM在长文档中识别和排序缺失段落来提升长上下文能力，无需人工标注或教师模型监督。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法依赖昂贵的黄金标准答案或教师模型评估，成本高且耗时。需要探索无监督方法来增强LLM的长上下文能力。

Method: 在长文档中用特殊占位符替换部分段落，通过强化学习训练LLM从候选选项中正确识别和排序缺失段落来重构文档，捕捉全局叙事连贯性。

Result: 在RULER基准上获得显著提升，在LongBench v2上也有合理改进，无需人工标注的长上下文QA数据。进行了广泛的消融研究分析奖励设计、数据策略等影响。

Conclusion: 提出的无监督强化学习方法能有效增强LLM的长上下文能力，无需昂贵的人工标注或教师模型监督，代码、数据和模型已公开。

Abstract: Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.

</details>


### [56] [On convexity and efficiency in semantic systems](https://arxiv.org/abs/2602.08238)
*Nathaniel Imel,Noga Zaslavasky*

Main category: cs.CL

TL;DR: 该研究分析了人类语义范畴系统的两个特征：凸性和效率性，发现两者虽有相关性但本质不同，效率性对颜色命名系统的解释力更强。


<details>
  <summary>Details</summary>
Motivation: 人类语义范畴系统有两个被广泛认可的特征：形成概念空间的凸划分，以及具有交流效率。先前研究观察到颜色命名中凸性和效率性共存，但两者之间的分析关系及共存原因尚未得到充分理解。

Method: 结合分析和实证方法，基于信息瓶颈（IB）框架来研究语义效率。首先分析凸性和效率性的逻辑关系，然后评估两者在区分实际颜色命名系统与假设变体时的预测能力。

Result: 1. 凸性和效率性本质不同：存在凸但低效的系统，也存在最优效率但非凸的系统；2. IB最优系统在颜色命名领域大多呈现凸性，解释了凸性方法的经验基础；3. 效率性在区分实际颜色命名系统时预测力更强，凸性只提供边际改进；4. 效率性可以解释凸性无法解释的一系列经验现象。

Conclusion: 凸性和效率性虽然能产生相似的结构观察结果，但本质上是不同的概念。效率性为语义类型学提供了更全面的解释框架，是理解人类语义范畴系统更根本的原则。

Abstract: There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology.

</details>


### [57] [Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence](https://arxiv.org/abs/2602.08252)
*Devin R. Wright,Justin E. Lane,F. LeRon Shults*

Main category: cs.CL

TL;DR: 提出基于认知语言模式、大语言模型和隐式隐喻的融合分数测量方法，在英国和新加坡数据集上优于现有方法，并识别出极端主义的两条高融合路径


<details>
  <summary>Details</summary>
Motivation: 随着极化加剧和政治暴力增多，理解极端主义的心理根源日益重要。现有研究表明身份融合能预测极端行为意愿，但需要更有效的测量方法

Method: 开发认知语言身份融合分数方法，利用认知语言模式、大语言模型和隐式隐喻从语言中测量融合程度

Result: 在英国和新加坡数据集上，该方法在预测已验证的融合分数方面优于现有方法。应用于极端主义宣言时，识别出两条高融合暴力路径：意识形态型倾向于以群体框架自我，形成亲属关系纽带；而怨恨驱动型则将群体框架纳入个人身份

Conclusion: 研究结果完善了身份融合理论，并提供了可扩展的工具，有助于融合研究和极端主义检测

Abstract: In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection.

</details>


### [58] [Language Modeling and Understanding Through Paraphrase Generation and Detection](https://arxiv.org/abs/2602.08274)
*Jan Philip Wahle*

Main category: cs.CL

TL;DR: 该论文提出将释义分解为不同的语言方面（释义类型），为语义等价性提供更细粒度的认知基础视角，并证明基于释义类型训练的语言模型在相关任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法将释义简化为两个文本之间的二元决策或单一改写，掩盖了哪些语言因素负责意义保留。需要更细粒度地理解语义等价性，这对计算语言模型理解意义至关重要。

Method: 将释义分解为构成的语言方面（释义类型），并训练模型识别这些类型。通过显式训练模型理解不同的释义类型来提升语义理解能力。

Result: 基于释义类型训练的模型在相关任务中表现显著提升：在维基百科抄袭检测中达到89.6%准确率（人类基线78.4%），在arXiv科学论文抄袭检测中达到66.5%（人类基线55.7%），在Quora重复问题识别中也优于基于二元对训练的模型。

Conclusion: 分解释义为语言方面（释义类型）提供了更细粒度的语义等价性视角，显式训练模型理解这些类型能显著提升模型在释义相关任务和下游应用中的性能。

Abstract: Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...

</details>


### [59] [New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR](https://arxiv.org/abs/2602.08281)
*Zhilin Wang,Yafu Li,Shunkai Zhang,Zhi Wang,Haoran Zhang,Xiaoye Qu,Yu Cheng*

Main category: cs.CL

TL;DR: RLVR通过概率框架解释大语言模型能力涌现，认为复杂推理能力源于原子步骤概率的锐化，而非单纯激发潜在能力。


<details>
  <summary>Details</summary>
Motivation: 解决关于RLVR是赋予LLMs新能力还是仅仅激发潜在能力的争议，提出概率框架来定义能力涌现机制。

Method: 使用Algebrarium框架，仅在单步操作上训练模型，然后在未见的多步任务上评估性能，通过概率分析验证假设。

Result: 实证结果显示：(1) RLVR通过放大现有技能探索新路径；(2) 复合性能严格受原子步骤联合概率控制(ρ∈[0.69,0.96])；(3) RLVR作为全局优化器会牺牲特定技能以最大化总奖励。

Conclusion: RLVR中的涌现能力源于可解问题的迭代优化，使模型能够处理先前不可解的场景，为能力涌现提供了新的概率解释框架。

Abstract: Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($ρ\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios.

</details>


### [60] [Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network](https://arxiv.org/abs/2602.08289)
*Binglin Wu,Xianneng Li*

Main category: cs.CL

TL;DR: 本文提出了一种基于超图神经网络的实体关系抽取算法Legal-KAHRE，专门针对毒品相关裁判文书，通过融入司法领域知识显著提升了抽取性能。


<details>
  <summary>Details</summary>
Motivation: 随着中国司法机构数字化进程的推进，积累了大量的电子法律文档信息。为了挖掘这些信息的潜在价值，法律文档的实体和关系抽取成为关键任务。然而，现有方法往往缺乏领域特定知识，未能充分考虑司法领域的独特特性。

Method: 1. 基于邻居导向打包策略和双仿射机制的候选跨度生成器，识别可能包含实体的文本跨度；2. 构建包含司法领域知识的法律词典，并通过多头注意力机制将其融入文本编码表示；3. 将共同犯罪、数罪并罚等特定案例纳入超图结构设计；4. 使用超图神经网络通过消息传递进行高阶推理。

Result: 在CAIL2022信息抽取数据集上的实验结果表明，该方法显著优于现有的基线模型。

Conclusion: 提出的Legal-KAHRE算法通过有效融入司法领域知识和超图神经网络的高阶推理能力，在毒品相关裁判文书的实体关系抽取任务上取得了显著改进，为法律文档的信息抽取提供了有效的解决方案。

Abstract: With the continuous progress of digitization in Chinese judicial institutions, a substantial amount of electronic legal document information has been accumulated. To unlock its potential value, entity and relation extraction for legal documents has emerged as a crucial task. However, existing methods often lack domain-specific knowledge and fail to account for the unique characteristics of the judicial domain. In this paper, we propose an entity and relation extraction algorithm based on hypergraph neural network (Legal-KAHRE) for drug-related judgment documents. Firstly, we design a candidate span generator based on neighbor-oriented packing strategy and biaffine mechanism, which identifies spans likely to contain entities. Secondly, we construct a legal dictionary with judicial domain knowledge and integrate it into text encoding representation using multi-head attention. Additionally, we incorporate domain-specific cases like joint crimes and combined punishment for multiple crimes into the hypergraph structure design. Finally, we employ a hypergraph neural network for higher-order inference via message passing. Experimental results on the CAIL2022 information extraction dataset demonstrate that our method significantly outperforms existing baseline models.

</details>


### [61] [When Does Context Help? Error Dynamics of Contextual Information in Large Language Models](https://arxiv.org/abs/2602.08294)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文提出了一个统一的理论框架来分析Transformer大语言模型中任意上下文信息的影响，通过输出误差动态表征上下文影响，证明了误差向量的可加性分解，并推导出误差减少的几何条件。


<details>
  <summary>Details</summary>
Motivation: 尽管推理时的上下文信息（如演示、检索知识、交互历史）可以显著提升大语言模型性能而无需参数更新，但其理论作用在特定设置（如上下文学习）之外仍然理解不足，需要统一的理论框架来分析任意上下文信息在Transformer模型中的影响。

Method: 提出了一个统一的理论框架，通过输出误差动态分析上下文影响。在单层Transformer中，证明了上下文条件误差向量可加性分解为基线误差向量和上下文修正向量，推导出误差减少的几何条件（对齐性和范数约束），并将结果扩展到多上下文和多层Transformer。

Result: 理论分析表明上下文修正范数存在由上下文-查询相关性和互补性决定的显式上界。在上下文学习、检索增强生成和记忆演化等任务上的实验验证了理论，并基于理论提出了原则性的上下文选择策略，性能提升0.6%。

Conclusion: 该研究为理解Transformer大语言模型中上下文信息的作用提供了统一的理论框架，揭示了误差减少的几何条件，并基于理论提出了有效的上下文选择策略，为优化上下文使用提供了理论指导。

Abstract: Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\%$.

</details>


### [62] [JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation](https://arxiv.org/abs/2602.08305)
*Binglin Wu,Yingyi Zhang,Xiannneg Li*

Main category: cs.CL

TL;DR: JUSTICE框架通过模拟法官"搜索→预判→撰写"的认知流程，引入预判阶段来提升判决书生成的法律准确性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有判决书生成方法过度简化了复杂的法律推理过程，特别是忽略了"预判"这一关键阶段，导致无法有效获取基础司法要素和建模预判过程，影响了最终文档的法律合理性。

Method: 提出JUSTICE框架，包含三个组件：1) 参考性司法要素检索器(RJER)检索法律条文和先例案例；2) 中间结论模拟器(ICE)生成可验证的中间结论；3) 司法统一合成器(JUS)综合所有输入生成最终判决。

Result: 在领域内法律基准测试和分布外数据集上，JUSTICE显著优于强基线方法，在法律准确性方面取得实质性提升，包括刑期预测准确率提高4.6%。

Conclusion: 明确建模预判过程对于增强生成判决书的法律连贯性和准确性至关重要，JUSTICE框架通过模拟人类法官的认知工作流程有效解决了现有方法的局限性。

Abstract: Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \textit{\textbf{J}udicial \textbf{U}nified \textbf{S}ynthesis \textbf{T}hrough \textbf{I}ntermediate \textbf{C}onclusion \textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\rightarrow$ Pre-Judge $\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents.

</details>


### [63] [Improving Data and Reward Design for Scientific Reasoning in Large Language Models](https://arxiv.org/abs/2602.08321)
*Zijie Chen,Zhenghao Lin,Xiao Liu,Zhenzhong Lan,Yeyun Gong,Peng Cheng*

Main category: cs.CL

TL;DR: 该论文提出了Dr.SCI数据集和训练流程，用于提升大语言模型在开放科学问题上的表现，通过系统数据处理、动态难度课程和基于评分标准的强化学习，显著提升了模型在科学推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在开放科学问题上的挑战，主要瓶颈在于数据构建和奖励设计不可靠。现有方法缺乏系统化的科学数据后训练流程。

Method: 1) 构建Dr.SCI数据集：处理异构开源科学数据，包含100万问题，涵盖8个STEM学科，有明确的可验证/开放问题划分、可扩展难度标注和细粒度评分标准；2) Dr.SCI后训练流程：包括探索扩展的监督微调、动态难度课程和基于科学评分标准的强化学习。

Result: 使用Dr.SCI流程训练的Qwen3-4B-Base模型在GPQA-diamond上达到63.2分，在GPQA-general上达到32.4分，显著优于o1-mini和GPT-4o等强基线模型，在科学推理特别是开放问题设置上取得实质性提升。

Conclusion: Dr.SCI数据集和训练流程有效解决了大语言模型在科学问题上的监督和评估不可靠问题，通过系统化的数据构建和训练策略设计，显著提升了模型在开放科学问题上的推理能力。

Abstract: Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.

</details>


### [64] [An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling](https://arxiv.org/abs/2602.08322)
*Wei Zhu*

Main category: cs.CL

TL;DR: 提出基于注意力机制的生成式框架，同时处理多意图检测和槽位填充任务，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现实对话中用户常表达多个意图，但现有SLU方法主要针对单意图场景，缺乏处理多意图的能力，且现有数据集也多为单意图设计。

Method: 提出生成式框架，采用注意力机制的注意力解码器（attention-over-attention decoder）处理可变数量的意图和子任务间的干扰，通过BERT的NSP头部构建新的多意图数据集。

Result: 在MixATIS、MixSNIPS公开数据集和自建数据集上均达到最先进性能。

Conclusion: 提出的注意力机制的注意力生成模型能有效处理多意图SLU任务，为现实对话系统提供了更好的解决方案。

Abstract: In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets.

</details>


### [65] [Latent Reasoning with Supervised Thinking States](https://arxiv.org/abs/2602.08332)
*Ido Amos,Avi Caciularu,Mor Geva,Amir Globerson,Jonathan Herzig,Lior Shani,Idan Szpektor*

Main category: cs.CL

TL;DR: 提出Thinking States方法，在输入处理过程中生成思考标记，减少推理成本，提高效率


<details>
  <summary>Details</summary>
Motivation: 链式思维推理虽然能帮助大语言模型解决复杂任务，但生成长推理过程会导致显著的推理成本增加，需要更高效的推理方法

Method: 在输入处理过程中每几个输入标记生成一系列思考标记，将思考转换回嵌入空间并添加到后续输入标记中，利用教师强制进行并行化学习

Result: 在多个推理任务上优于其他潜在推理方法，在数学问题上缩小了与CoT的差距，在2-Hop QA上达到相同性能但延迟更低，在状态跟踪任务上展现出比CoT更强的推理能力

Conclusion: Thinking States方法通过在处理输入时生成思考，实现了更高效的推理，在保持性能的同时降低了延迟，并能泛化到训练中未见过的更长序列

Abstract: Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.

</details>


### [66] [UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models](https://arxiv.org/abs/2602.08336)
*Cheng Yang,Chufan Shi,Bo Shui,Yaokang Wu,Muzi Tao,Huijuan Wang,Ivan Yee Lee,Yong Liu,Xuezhe Ma,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: UReason是一个诊断性基准测试，用于评估推理驱动的图像生成，发现推理痕迹虽然能提升性能，但作为上下文条件会阻碍视觉合成，而仅使用精炼提示能获得显著提升，揭示了上下文干扰而非推理能力不足是瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型采用思维链推理来指导图像生成，但推理对视觉合成的实际效果尚不明确。需要评估推理是否能在像素层面忠实执行，并理解推理痕迹在图像生成中的作用。

Method: 提出UReason基准测试，包含2,000个实例，涵盖代码、算术、空间、属性和文本推理五个任务族。引入评估框架比较三种生成方式：直接生成、推理引导生成和去上下文化生成（仅基于精炼提示）。在八个开源统一模型上进行测试。

Result: 发现一致的"推理悖论"：推理痕迹通常比直接生成提升性能，但将中间思维作为条件上下文往往会阻碍视觉合成，而仅基于精炼提示的条件能带来显著增益。分析表明瓶颈在于上下文干扰而非推理能力不足。

Conclusion: UReason为研究统一模型中的推理提供了原则性测试平台，激励未来方法在有效整合推理进行视觉生成的同时减轻干扰。

Abstract: To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference.

</details>


### [67] [WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints](https://arxiv.org/abs/2602.08367)
*Zexuan Wang,Chenghao Yang,Yingqi Que,Zhenzhu Yang,Huaqing Yuan,Yiwen Wang,Zhengxuan Jiang,Shengjie Fang,Zhenhe Wu,Zhaohui Wang,Zhixin Yao,Jiashuo Liu,Jincheng Ren,Yuzhen Li,Yang Yang,Jiaheng Liu,Jian Yang,Zaiyuan Wang,Ge Zhang,Zhoufutu Wen,Wenhao Huang*

Main category: cs.CL

TL;DR: WorldTravel是一个包含150个真实世界旅行场景的基准测试，要求处理平均15+个相互依赖的时空和逻辑约束。研究还开发了多模态环境WorldTravel-Webscape，包含2000+个网页渲染，评估发现现有模型在真实部署中性能显著下降，揭示了感知-行动鸿沟和规划视野限制。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注松散耦合的约束，可通过局部贪婪决策解决，且依赖理想化数据，无法捕捉从动态网络环境中提取参数的复杂性。需要更真实的基准来评估自主规划系统在复杂现实场景中的能力。

Method: 引入WorldTravel基准，包含150个真实世界旅行场景，覆盖5个城市，平均需要处理15+个相互依赖的时空和逻辑约束。开发WorldTravel-Webscape多模态环境，包含2000+个渲染网页，要求智能体从视觉布局中感知约束参数。评估了10个前沿模型在文本和多模态环境中的表现。

Result: 评估显示性能显著下降：即使在文本环境中，最先进的GPT-5.2也只达到32.67%的可行性，在多模态环境中暴跌至19.33%。研究发现存在关键的感知-行动鸿沟，以及约10个约束的规划视野阈值，超过该阈值模型推理会持续失败。

Conclusion: 感知和推理仍然是独立的瓶颈，需要下一代智能体将高保真视觉感知与长视野推理相结合，以处理脆弱的现实世界物流任务。现有模型在复杂现实约束规划方面存在显著局限性。

Abstract: Real-world autonomous planning requires coordinating tightly coupled constraints where a single decision dictates the feasibility of all subsequent actions. However, existing benchmarks predominantly feature loosely coupled constraints solvable through local greedy decisions and rely on idealized data, failing to capture the complexity of extracting parameters from dynamic web environments. We introduce \textbf{WorldTravel}, a benchmark comprising 150 real-world travel scenarios across 5 cities that demand navigating an average of 15+ interdependent temporal and logical constraints. To evaluate agents in realistic deployments, we develop \textbf{WorldTravel-Webscape}, a multi-modal environment featuring over 2,000 rendered webpages where agents must perceive constraint parameters directly from visual layouts to inform their planning. Our evaluation of 10 frontier models reveals a significant performance collapse: even the state-of-the-art GPT-5.2 achieves only 32.67\% feasibility in text-only settings, which plummets to 19.33\% in multi-modal environments. We identify a critical Perception-Action Gap and a Planning Horizon threshold at approximately 10 constraints where model reasoning consistently fails, suggesting that perception and reasoning remain independent bottlenecks. These findings underscore the need for next-generation agents that unify high-fidelity visual perception with long-horizon reasoning to handle brittle real-world logistics.

</details>


### [68] [ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts](https://arxiv.org/abs/2602.08371)
*Hung Quang Tran,Nam Tien Pham,Son T. Luu,Kiet Van Nguyen*

Main category: cs.CL

TL;DR: 该研究构建了越南语情感语料库ViGoEmotions，包含20,664条社交媒体评论，标注为27种细粒度情感，并评估了8种预训练Transformer模型在三种预处理策略下的情感分类性能。


<details>
  <summary>Details</summary>
Motivation: 情感分类在情感预测和有害内容检测中具有重要作用。虽然大语言模型在NLP领域取得了显著进展，但越南语情感分类领域缺乏高质量、细粒度的标注数据集，需要构建专门的语料库来支持相关研究。

Method: 1. 构建ViGoEmotions越南语情感语料库，包含20,664条社交媒体评论，标注为27种细粒度情感
2. 评估8种预训练Transformer模型（包括ViSoBERT、CafeBERT、PhoBERT等）
3. 采用三种预处理策略：保留原始表情符号并进行规则标准化、将表情符号转换为文本描述、应用ViSoLex模型进行词汇标准化
4. 使用Macro F1和Weighted F1作为评估指标

Result: 1. 将表情符号转换为文本通常能提升BERT基线的性能，而保留表情符号对ViSoBERT和CafeBERT效果最好
2. 移除表情符号通常导致性能下降
3. ViSoBERT获得最高性能：Macro F1为61.50%，Weighted F1为63.26%
4. CafeBERT和PhoBERT也表现出色
5. 语料库能有效支持多种架构，但预处理策略和标注质量是影响下游性能的关键因素

Conclusion: ViGoEmotions语料库为越南语情感分类提供了有价值的资源，表情符号处理策略对模型性能有显著影响，保留或适当转换表情符号能提升分类效果，未来研究应关注预处理策略和标注质量的优化。

Abstract: Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance.

</details>


### [69] [Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning](https://arxiv.org/abs/2602.08382)
*Zhuoen Chen,Dongfang Li,Meishan Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 提出基于认知启发的长上下文推理框架，通过分块压缩和选择性记忆召回，而非处理所有原始token，解决LLM长上下文处理中的计算成本、信息遗忘和RAG上下文碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文时面临三大挑战：1）二次计算成本；2）信息遗忘；3）检索增强生成中的上下文碎片化问题。需要更高效的长上下文推理方法。

Method: 提出认知启发框架：1）将长输入分段为块；2）使用学习到的压缩器将每个块编码为压缩记忆表示；3）门控模块动态选择相关记忆块；4）推理模块通过演化的工作记忆迭代处理这些块解决下游任务。压缩器和推理器通过端到端强化学习联合优化，门控模块作为分类器单独训练。

Result: 在RULER-HQA等多跳推理基准上达到竞争性准确率，上下文长度从7K扩展到175万token，相比强基线在精度-效率权衡上表现优异。具体来说，相比MemAgent，GPU峰值内存使用减少2倍，推理速度提升6倍。

Conclusion: 提出的认知启发框架通过分块压缩和选择性记忆召回，有效解决了LLM长上下文处理的关键挑战，在保持准确性的同时显著提升了效率和可扩展性。

Abstract: Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.

</details>


### [70] [TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration](https://arxiv.org/abs/2602.08404)
*Linye Wei,Zixiang Luo,Pingzhi Tang,Meng Li*

Main category: cs.CL

TL;DR: TEAM是一个加速MoE扩散大语言模型的框架，通过利用专家路由决策的时空一致性，减少激活专家数量同时增加接受token数量，实现2.2倍加速且性能损失可忽略。


<details>
  <summary>Details</summary>
Motivation: MoE扩散大语言模型存在架构不匹配问题：每个去噪步骤激活大量专家，但最终只接受少量token，导致推理开销大，限制了在延迟敏感应用中的部署。

Method: TEAM利用专家路由决策在去噪层级间的时间一致性和token位置间的空间一致性，采用三种互补的专家激活和解码策略：保守选择已解码和掩码token的必要专家，同时进行多候选的激进推测性探索。

Result: 实验结果表明，TEAM相比原始MoE扩散大语言模型实现了高达2.2倍的加速，性能下降可忽略不计。

Conclusion: TEAM是一个即插即用框架，能有效加速MoE扩散大语言模型，通过更少的激活专家实现更多接受token，解决了架构不匹配问题，适用于延迟敏感应用。

Abstract: Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM.

</details>


### [71] [Prism: Spectral-Aware Block-Sparse Attention](https://arxiv.org/abs/2602.08426)
*Xinghao Wang,Pengyu Wang,Xiaoran Liu,Fangxu Liu,Jason Chu,Kai Song,Xipeng Qiu*

Main category: cs.CL

TL;DR: Prism：一种无需训练的频谱感知块稀疏注意力方法，通过高频/低频分支分解和能量温度校准，解决了RoPE与平均池化交互导致的局部位置信息丢失问题，实现5.1倍加速


<details>
  <summary>Details</summary>
Motivation: 现有块稀疏注意力方法使用粗粒度注意力作为块重要性估计的代理，但通常依赖昂贵的token级搜索或评分，导致显著的选择开销。标准粗粒度注意力（通过平均池化）不准确的根本原因是平均池化与RoPE的交互作用

Method: Prism：训练免费的频谱感知方法，将块选择分解为高频和低频分支。通过基于能量的温度校准，直接从池化表示中恢复衰减的位置信号，实现纯块级操作的块重要性估计

Result: 广泛评估证实Prism在保持与完整注意力相同准确性的同时，实现了高达5.1倍的加速

Conclusion: Prism通过解决平均池化与RoPE交互导致的局部位置信息丢失问题，提供了一种高效且准确的块稀疏注意力方法，显著提升了长上下文LLM预填充的效率

Abstract: Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a "blind spot" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\mathbf{5.1\times}$ speedup.

</details>


### [72] [Large Language Models and Impossible Language Acquisition: "False Promise" or an Overturn of our Current Perspective towards AI](https://arxiv.org/abs/2602.08437)
*Ziyan wang,Longlong Ma*

Main category: cs.CL

TL;DR: 该研究通过实验检验Chomsky对LLMs的批评，构建不可能语言测试GPT-2和LSTM模型，发现GPT-2在不可能语言上表现不佳，支持Chomsky观点，但提出需要从理性主义转向功能主义和经验主义的研究范式。


<details>
  <summary>Details</summary>
Motivation: 回应Chomsky在《The False Promise of CHATGPT》中对大型语言模型的根本性批评，即LLMs只是模式预测器，缺乏人类语言习得的内在因果和自我纠正结构，无法区分不可能语言。研究旨在通过实证检验这一理论主张。

Method: 通过语法变换构建不可能语言（如整句反转、基于词数奇偶性添加否定），在GPT-2小模型和LSTM模型上进行两轮对照实验，使用Welch's t-test进行统计分析。

Result: GPT-2小模型在所有不可能语言上的学习表现均显著低于可能语言（p<.001），支持Chomsky的论点。LSTM模型的表现也与Chomsky观点一致，表明Transformer架构演化具有不可替代的作用。

Conclusion: 基于理论和实证发现，提出在Chomsky理论框架内对LLMs的新视角，并建议从Chomsky的"理性主义-浪漫主义"范式转向功能主义和经验主义的研究范式。

Abstract: In Chomsky's provocative critique "The False Promise of CHATGPT," Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his "rationalist-romantics" paradigm to functionalism and empiricism in LLMs research.

</details>


### [73] [Characterizing, Evaluating, and Optimizing Complex Reasoning](https://arxiv.org/abs/2602.08498)
*Haoran Zhang,Yafu Li,Zhi Wang,Zhilin Wang,Shunkai Zhang,Xiaoye Qu,Yu Cheng*

Main category: cs.CL

TL;DR: 提出ME²原则从宏观微观评估推理质量，基于DAG建模推理轨迹并构建TRM-Preference数据集，训练Thinking Reward Model用于推理优化，实验显示在测试和训练中均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有工作缺乏对推理质量的统一定义、对复杂结构推理轨迹的可靠评估方法，以及如何利用评估信号进行推理优化的统一解决方案。

Method: 1) 提出ME²原则从宏观效率/效果和微观效率/效果评估推理质量；2) 将推理轨迹建模为有向无环图(DAG)，开发基于DAG的成对评估方法；3) 构建TRM-Preference数据集并训练Thinking Reward Model(TRM)。

Result: 思考奖励作为有效的优化信号：测试时选择更好的推理能带来更好结果（最高19.3%提升），RL训练期间思考奖励能增强推理和性能（最高3.9%提升），在多样化任务上均有效。

Conclusion: 该研究提供了统一的推理质量评估和优化框架，ME²原则和TRM模型能够有效评估复杂推理结构，为大型推理模型的优化提供了系统化解决方案。

Abstract: Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks.

</details>


### [74] [GISA: A Benchmark for General Information-Seeking Assistant](https://arxiv.org/abs/2602.08543)
*Yutao Zhu,Xingshuo Zhang,Maosen Zhang,Jiajie Jin,Liancheng Zhang,Xiaoshuai Song,Kangzhi Zhao,Wencong Zeng,Ruiming Tang,Han Li,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.CL

TL;DR: GISA是一个针对通用信息搜索助手的新基准测试，包含373个人工构建的真实查询，支持四种结构化答案格式，并提供完整的人类搜索轨迹作为参考。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在三个主要问题：1）从答案反向构建查询，导致任务不自然；2）要么关注特定信息定位，要么关注多源信息聚合，缺乏统一；3）使用静态答案集容易受到数据污染。需要创建一个更真实、全面的基准来评估信息搜索助手。

Method: GISA包含373个人工构建的真实信息搜索查询，支持四种结构化答案格式（项目、集合、列表、表格），确保确定性评估。基准整合了深度推理和广泛信息聚合任务，包含定期更新的实时子集以防止记忆，并提供每个查询的完整人类搜索轨迹作为过程级监督参考。

Result: 实验显示，即使在主流LLM和商业搜索产品中，最佳模型也只能达到19.30%的精确匹配分数。在需要复杂规划和全面信息收集的任务上，性能显著下降，表明现有系统仍有很大改进空间。

Conclusion: GISA基准测试揭示了当前信息搜索助手在真实场景中的局限性，特别是在复杂规划和全面信息聚合方面表现不佳。该基准为未来研究提供了有价值的评估框架和过程级监督参考。

Abstract: The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.

</details>


### [75] [How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location](https://arxiv.org/abs/2602.08548)
*Xuanliang Zhang,Dingzirui Wang,Keyan Xu,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: LLMs处理表格时通过三阶段机制定位单元格：语义绑定→坐标定位→信息提取，利用分隔符计数和线性子空间编码实现表格理解。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型越来越多地用于表格相关任务，但其处理线性化二维结构化表格的内部机制仍然不透明。本研究旨在揭示LLMs如何理解表格结构，特别是单元格定位这一基本任务。

Method: 通过激活修补和互补的可解释性技术，将表格理解机制分解为顺序的三阶段流程：语义绑定、坐标定位和信息提取。研究分析了模型如何通过计数离散分隔符来解析坐标，并探索了列索引在线性子空间中的编码方式。

Result: 模型通过序数机制计数分隔符来定位目标单元格；列索引编码在线性子空间中，可通过向量算术精确引导模型注意力；多单元格定位任务通过复用原子定位中识别的相同注意力头实现泛化。

Conclusion: 研究揭示了Transformer架构中表格理解的综合机制，为LLMs处理结构化数据提供了可解释性框架，有助于改进表格相关任务的模型设计和评估。

Abstract: While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures.

</details>


### [76] [Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation](https://arxiv.org/abs/2602.08600)
*Archchana Sindhujan,Girish A. Koushik,Shenbin Qian,Diptesh Kanojia,Constantin Orăsan*

Main category: cs.CL

TL;DR: 论文提出了ALOPE-RL框架，结合错误感知奖励和强化学习，用于英语到马拉雅拉姆语的机器翻译质量评估，在低资源环境下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前质量评估方法主要依赖标量分数，缺乏对翻译错误的明确解释，且在低资源语言（如马拉雅拉姆语）上因标注数据有限而性能不佳。

Method: 1) 创建首个英语-马拉雅拉姆语片段级QE数据集，包含直接评估分数和翻译质量评注；2) 提出ALOPE-RL强化学习框架，基于策略奖励训练高效适配器；3) 使用LoRA和4位量化微调紧凑LLMs（≤4B参数）。

Result: ALOPE-RL在小规模QE数据集上训练，在英语到马拉雅拉姆语QE任务上实现了最先进的性能，超越了更大的LLM基线和领先的编码器基QE模型。

Conclusion: 错误感知的策略学习能够在有限数据和计算预算下提供强大的QE性能，为低资源语言的质量评估提供了有效解决方案。

Abstract: Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.

</details>


### [77] [VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling](https://arxiv.org/abs/2602.08607)
*Ziyang Cheng,Yuhao Wang,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出VocalNet-MDM，一种基于掩码扩散建模的非自回归语音大语言模型，通过分层块掩码和迭代自蒸馏技术解决训练推理不匹配和迭代开销问题，在仅6K小时数据上实现3.7-10倍解码加速和34%首块延迟降低。


<details>
  <summary>Details</summary>
Motivation: 当前自回归语音大语言模型存在严格串行约束，限制了生成效率并引入曝光偏差，需要探索非自回归范式来提升效率并降低延迟。

Method: 采用掩码扩散建模作为非自回归范式，提出分层块掩码技术对齐训练目标与块扩散解码中的渐进掩码状态，并使用迭代自蒸馏技术将多步优化压缩为更少步骤以实现低延迟推理。

Result: 在仅6K小时语音数据训练下，VocalNet-MDM相比自回归基线实现3.7-10倍解码加速，首块延迟降低34%，同时保持竞争性识别准确率，在文本质量和语音自然度方面达到最先进水平。

Conclusion: 掩码扩散建模是低延迟、高效语音大语言模型的有前景且可扩展的替代方案，能够显著提升生成效率并降低延迟，同时保持高质量输出。

Abstract: Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\times$--10$\times$ decoding speedup and reduces first-chunk latency by 34\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.

</details>


### [78] [Do Multilingual LLMs have specialized language heads?](https://arxiv.org/abs/2602.08625)
*Muhammad Naufil*

Main category: cs.CL

TL;DR: 研究探索多语言大语言模型是否具有语言特定的注意力头，并尝试移除不需要语言的头而不影响目标语言性能


<details>
  <summary>Details</summary>
Motivation: 多语言LLM在生产部署中效率低下，当只关心部分支持语言时。目前有研究关注机器翻译模型的特定/通用头，但多语言LLM（能执行翻译以外任务）的相关研究缺乏。

Method: 探索多语言LLM是否具有专门的语言注意力头，并研究移除不需要语言的头而不降低目标语言性能的可能性。

Result: 研究发现可为多语言LLM提供更高效的部署策略，在保持目标语言高准确性的同时减少模型复杂度。

Conclusion: 该研究揭示了多语言LLM的语言特定注意力头特性，为针对特定语言的高效部署提供了可能性。

Abstract: Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.

</details>


### [79] [Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models](https://arxiv.org/abs/2602.08658)
*Mingzi Cao,Xingwei Tan,Mahmud Akhter,Marco Valentino,Maria Liakata,Xi Wang,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 该研究探讨了演绎、归纳和溯因三种基本推理范式如何影响大语言模型的推理行为，通过构建符号任务数据集并采用多种微调方法，显著提升了模型在现实任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型的推理能力改进吸引了大量研究关注，但基本推理范式（演绎、归纳、溯因）如何影响模型的泛化能力尚未得到系统探索。研究者希望了解这些核心范式之间的相互作用如何影响LLMs的推理行为。

Method: 首先收集了针对三种基本推理范式的符号任务数据集，以抽象化具体世界知识。然后采用多种方法将这些推理技能注入LLMs，包括简单微调、增加模型深度的方法，以及将密集模型转换为混合专家模型等复杂方法。

Result: 该方法在完全用自然语言表述且包含真实世界知识的现实域外任务上表现出强大的泛化能力，性能提升显著（最高达14.60分）。

Conclusion: 通过系统探索基本推理范式对LLMs推理行为的影响，并采用有效的技能注入方法，可以显著提升模型在现实任务中的泛化性能，为改进大语言模型推理能力提供了新思路。

Abstract: Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.

</details>


### [80] [Learning to Judge: LLMs Designing and Applying Evaluation Rubrics](https://arxiv.org/abs/2602.08672)
*Clemencia Siro,Pourya Aliannejadi,Mohammad Aliannejadi*

Main category: cs.CL

TL;DR: LLMs can generate their own evaluation rubrics (GER-Eval方法)，这些标准在语义一致性和评分可靠性方面表现良好，但在事实性和知识密集型任务中可靠性下降。不同模型间的评估标准存在差异，闭源模型比开源模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要依赖静态的人类定义标准，但这些标准与模型内部的语言质量表征方式存在错位。研究者希望探索LLM是否能设计和应用自己的评估标准，以更好地理解模型的评估能力。

Method: 提出GER-Eval方法，让LLM生成自己的评估标准并应用这些标准进行评估。研究评估了LLM定义标准的语义一致性、评分可靠性以及与人类标准的对齐程度。

Result: LLM能够可靠地生成可解释且任务感知的评估维度，并在模型内部一致应用。但在事实性和知识密集型任务中评分可靠性下降。闭源模型（如GPT-4o）比开源模型（如Llama）在一致性和跨模型泛化方面表现更好。

Conclusion: 评估是LLM的一种学习到的语言能力，在模型内部一致但在不同模型间存在碎片化。需要开发新方法来联合建模人类和LLM的评估语言，以提高可靠性和可解释性。

Abstract: Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.

</details>


### [81] [Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement](https://arxiv.org/abs/2602.08688)
*Hossein Kermani,Fatemeh Oudlajani,Pardis Yarahmadi,Hamideh Mahdi Soltani,Mohammad Makki,Zahra HosseiniKhoo*

Main category: cs.CL

TL;DR: 比较三种波斯语推文不文明内容检测方法：人工编码、ParsBERT监督学习和ChatGPT大语言模型，发现ParsBERT在仇恨言论检测上显著优于ChatGPT


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估不同方法在低资源语言（波斯语）环境中检测不文明内容的准确性和效率，特别是在#MahsaAmini运动背景下

Method: 使用47,278条波斯语推文，比较三种方法：1）人工定性编码，2）基于ParsBERT的监督学习，3）七个ChatGPT模型，并评估英语与波斯语提示的影响

Result: ParsBERT在仇恨言论检测上显著优于所有七个ChatGPT模型；ChatGPT不仅在微妙案例上表现不佳，在明确不文明内容上也存在困难；提示语言（英语vs波斯语）对ChatGPT输出无显著影响

Conclusion: 研究详细比较了不同方法在低资源语言环境中的优缺点，表明针对特定语言训练的监督学习模型（如ParsBERT）在仇恨言论检测上优于通用大语言模型

Abstract: This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.

</details>


### [82] [Challenges in Translating Technical Lectures: Insights from the NPTEL](https://arxiv.org/abs/2602.08698)
*Basudha Raje,Sadanand Venkatraman,Nandana TP,Soumyadeepa Das,Polkam Poojitha,M. Vijaykumar,Tanima Bagchi,Hema A. Murthy*

Main category: cs.CL

TL;DR: 该研究探讨了机器翻译在印度语言（孟加拉语、马拉雅拉姆语、泰卢固语）中的实际应用和方法论意义，分析了其在翻译工作流程中的表现及现有评估框架的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于印度语言多样性背景下教育技术的多语言适应需求，特别是NEP 2020政策推动下，以及NPTEL大规模在线课程平台提供的语料资源。需要构建能够清晰传达技术概念、保持适当语域和词汇选择的自发语音语料库。

Method: 使用NPTEL MOOC门户作为语料来源，构建自发语音语料库，重点关注技术概念的清晰传达、语域保留和词汇选择。研究分析了机器翻译在形态丰富、语义紧凑语言中的表现，并测试了表面重叠度指标的敏感性。

Result: 研究发现指标特异性敏感性，揭示了形态丰富和语义紧凑特征在表面重叠度指标测试中面临的挑战。现有评估框架在处理印度语言多样性时存在局限性。

Conclusion: 研究强调了在印度语言多样性背景下，需要开发更适应形态丰富语言的机器翻译评估方法，以支持教育技术的多语言适应和NEP 2020政策的实施。

Abstract: This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.

</details>


### [83] [Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search](https://arxiv.org/abs/2602.08700)
*Clemencia Siro,Zahra Abbasiantaeb,Yifei Yuan,Mohammad Aliannejadi,Maarten de Rijke*

Main category: cs.CL

TL;DR: 研究探讨了在对话式搜索中，图像增强的澄清问题对用户表现的影响，发现图像效果因任务类型和用户专业水平而异。


<details>
  <summary>Details</summary>
Motivation: 尽管文本澄清问题已被证明能提升检索性能和用户体验，且图像在各种情境中能改善检索性能，但图像在澄清问题中对用户表现的影响尚未充分探索。

Method: 对73名参与者进行用户研究，比较多模态（文本+图像）和纯文本澄清问题在两种搜索相关任务中的效果：(i)回答澄清问题，(ii)查询重构。

Result: 在回答澄清问题时，参与者强烈偏好多模态问题，但纯文本设置表现更好；在查询重构任务中，偏好更平衡，图像能产生更精确的查询并改善检索性能。图像效果受任务类型和用户专业水平影响。

Conclusion: 视觉增强的益处是任务依赖性的，应根据具体搜索情境和用户特征进行战略实施，为设计有效的多模态对话搜索系统提供了重要见解。

Abstract: Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.

</details>


### [84] [FactSim: Fact-Checking for Opinion Summarization](https://arxiv.org/abs/2602.08709)
*Leandro Anghinoni,Jorge Sanchez*

Main category: cs.CL

TL;DR: 本文提出了一种用于评估生成式AI在意见摘要任务中事实一致性的新型自动化方法，通过比较摘要中的主张与原始评论的相似性来衡量覆盖度和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统基于自动化指标评估生成式AI在文本摘要（特别是意见摘要）任务的方法存在局限性，尤其是在大语言模型带来范式转变的背景下。需要更全面、精确的评估技术来评估事实一致性。

Method: 提出了一种完全自动化的方法，通过提取文本中的事实评估，然后比较摘要中的主张与原始评论的相似性。该方法基于简单的文本事实提取方法，然后比较并汇总为合适的评分。

Result: 提出的指标能够为相似的主张赋予更高的分数，无论主张是否被否定、转述或扩展。与现有最先进指标相比，该评分与人类判断具有高度相关性。

Conclusion: 该方法为生成式AI在意见摘要任务中的事实一致性评估提供了一种有效的自动化解决方案，能够更好地应对大语言模型带来的评估挑战。

Abstract: We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.

</details>


### [85] [PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments](https://arxiv.org/abs/2602.08716)
*Shangrui Nie,Kian Omoomi,Lucie Flek,Zhixue Zhao,Charles Welch*

Main category: cs.CL

TL;DR: PERSPECTRA是一个评估大语言模型多元主义能力的基准，结合了Kialo辩论图的结构清晰性和Reddit讨论的语言多样性，包含3,810个扩展论点，用于评估模型识别、匹配和推理多种观点的能力。


<details>
  <summary>Details</summary>
Motivation: 多元主义（能够处理不同观点而不将其简化为单一视角）对于开发忠实反映人类异质性的大语言模型至关重要，但这一特性在LLM研究中尚未得到仔细检验，且大多数对齐研究中都缺乏。现有的辩论数据源要么需要昂贵的人工验证，要么缺乏清晰的结构或自然语言多样性。

Method: 通过受控的检索和扩展流程，整合Kialo辩论图的结构清晰性和Reddit讨论的语言多样性，构建了包含3,810个扩展论点的数据集，涵盖100个争议性话题的762个正反立场。每个观点都扩展到多个自然语言变体。

Result: 实验表明，最先进的开源和专有LLM在多元主义理解方面存在系统性失败，例如高估观点数量、错误分类让步结构等，突显了多元主义感知理解和推理的困难。

Conclusion: PERSPECTRA通过结合多样性和结构，建立了第一个可扩展、可配置的基准，用于评估模型如何代表、区分和推理多种观点，填补了多元主义评估的空白。

Abstract: Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.

</details>


### [86] [Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy](https://arxiv.org/abs/2602.08740)
*Gaifan Zhang,Danushka Bollegala*

Main category: cs.CL

TL;DR: 提出大规模比较和可视化句子编码器的方法，通过创建编码器地图，将1101个公开句子编码器在二维空间中表示，编码器特征向量能准确预测下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有句子编码器数量庞大，缺乏系统性的比较和可视化方法，难以理解不同编码器之间的关系和特性。

Method: 首先用句子集的嵌入矩阵表示每个编码器，计算其成对内积(PIP)矩阵，然后基于量子相对熵(QRE)构建每个编码器相对于单位基编码器的特征向量，最终创建编码器地图。

Result: 构建了包含1101个公开句子编码器的地图，相似属性的编码器在地图上位置相近，编码器特征向量能准确预测检索和聚类等下游任务性能。

Conclusion: 该方法为预训练句子编码器提供了新的视角，编码器地图能准确反映编码器间关系，特征向量能有效预测下游任务表现。

Abstract: We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.

</details>


### [87] [LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation](https://arxiv.org/abs/2602.08793)
*Yushi Sun,Xujia Li,Nan Tang,Quanqing Xu,Chuanhui Yang,Lei Chen*

Main category: cs.CL

TL;DR: LakeHopper框架通过知识差距识别、聚类数据选择和增量微调，实现预训练语言模型在不同数据湖间的迁移，减少新数据湖的标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的列类型标注方法需要大量标注数据，且针对特定数据湖训练。当面对新数据湖时，需要重新标注大量数据，成本高昂。研究如何将已有模型迁移到新数据湖，最小化新数据湖的标注需求。

Method: 提出LakeHopper框架：1) 通过语言模型交互识别源-目标数据湖间的知识差距；2) 采用基于聚类的数据选择方案从无标注列中选择信息量大的数据；3) 使用增量微调机制，逐步将源模型适应到目标数据湖，避免丢失共享知识。

Result: 在两个不同数据湖迁移任务上的实验结果表明，LakeHopper在低资源和高资源设置下均有效，能够显著减少新数据湖的标注需求。

Conclusion: LakeHopper框架成功解决了跨数据湖迁移中的知识差距、数据选择和知识保留问题，为减少数据标注成本提供了有效解决方案。

Abstract: Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.

</details>


### [88] [Affective Flow Language Model for Emotional Support Conversation](https://arxiv.org/abs/2602.08826)
*Chenghui Zou,Ning Wang,Tiesunlong Shen,Luwei Xiao,Chuan Ma,Xiangpeng Li,Rui Mao,Erik Cambria*

Main category: cs.CL

TL;DR: AFlow框架通过建模多轮对话中的连续情感流，为情感支持对话提供细粒度监督，提升策略决策和共情响应质量


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统依赖稀疏的结果级信号，对中间策略决策的监督有限，导致复杂多轮支持效果不佳

Method: 提出AFlow框架，通过建模连续情感流为对话前缀提供细粒度监督，使用子路径级流平衡目标传播偏好信号到中间状态

Result: 在多样情感情境中显著优于现有基线，紧凑开源骨干模型在主要ESC指标上超越GPT-4o和Claude-3.5等专有大模型

Conclusion: 通过建模情感流提供细粒度监督能有效提升情感支持对话的策略一致性和共情响应质量

Abstract: Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.

</details>


### [89] [WildReward: Learning Reward Models from In-the-Wild Human Interactions](https://arxiv.org/abs/2602.08829)
*Hao Peng,Yunjia Qi,Xiaozhi Wang,Zijun Yao,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: WildReward：直接从用户交互中训练奖励模型，无需人工标注偏好对，性能媲美甚至超越传统奖励模型


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型依赖大规模人工标注的偏好对，成本高昂。随着大语言模型的广泛部署，用户交互成为丰富的隐式奖励信号来源，能否直接从用户交互中开发奖励模型？

Method: 采用WildChat作为交互源，提出从用户反馈中提取可靠人类反馈的流程，通过序数回归直接在用户反馈上训练WildReward，无需偏好对

Result: WildReward在性能上与传统奖励模型相当甚至更优，具有更好的校准性和跨样本一致性；用户多样性直接提升模型性能；应用于在线DPO训练在各种任务上都有显著改进

Conclusion: 直接从用户交互中训练奖励模型是可行的，WildReward展示了这种方法的有效性，为奖励模型训练提供了更高效、低成本的新途径

Abstract: Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.

</details>


### [90] [Understanding Dynamic Compute Allocation in Recurrent Transformers](https://arxiv.org/abs/2602.08864)
*Ibraheem Muhammad Moosa,Suhas Lohit,Ye Wang,Moitreya Chatterjee,Wenpeng Yin*

Main category: cs.CL

TL;DR: 本文提出ANIRA框架，通过算法和合成语言任务评估token级自适应计算，发现计算分配能与任务复杂度对齐，但无法泛化到未见输入规模。


<details>
  <summary>Details</summary>
Motivation: 现有token级自适应计算研究主要使用自然语言基准和任务级指标评估，无法直接观察token级难度，且计算分配决策与架构因素混淆，不清楚计算分配是否真正与底层复杂度对齐。

Method: 提出复杂度控制评估范式（使用参数化难度的算法和合成语言任务），设计ANIRA统一循环Transformer框架支持token级可变深度计算，并隔离计算分配决策与其他模型因素。

Result: 计算分配能与任务复杂度对齐（无需显式难度监督），但这种对齐不意味着算法泛化：模型无法泛化到未见输入规模。早期计算决策依赖静态结构线索，而在线停止更接近跟踪算法执行状态。

Conclusion: 通过受控评估揭示了token级自适应计算的关键特性：计算分配能与复杂度对齐但不保证泛化，决策时机影响对齐质量，为未来自适应计算研究提供了更严谨的评估框架。

Abstract: Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.

</details>


### [91] [Large Language Models for Geolocation Extraction in Humanitarian Crisis Response](https://arxiv.org/abs/2602.08872)
*G. Cafferata,T. Demarco,K. Kalimeri,Y. Mejova,M. G. Beiró*

Main category: cs.CL

TL;DR: LLM-based方法显著提高了人道主义文本中地理位置提取的精度和公平性，特别是在代表性不足的地区


<details>
  <summary>Details</summary>
Motivation: 人道主义危机需要及时准确的地理信息，但现有自动化系统在提取位置信息时往往复制现有的地理和社会经济偏见，导致危机受影响地区的可见性不均

Method: 提出一个两步框架：结合few-shot LLM命名实体识别和基于代理的地理编码模块，利用上下文解析模糊地名

Result: LLM-based方法在精度和公平性指标上显著优于最先进的预训练和基于规则的系统，特别是在代表性不足的地区

Conclusion: 通过将LLM推理进展与负责任和包容性AI原则相结合，这项工作为人道主义响应贡献了更公平的地理空间数据系统，推进了危机分析中"不让任何地方掉队"的目标

Abstract: Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics.

</details>


### [92] [Is Reasoning Capability Enough for Safety in Long-Context Language Models?](https://arxiv.org/abs/2602.08874)
*Yu Fu,Haz Sameen Shahgir,Huanli Gong,Zhipeng Wei,N. Benjamin Erichson,Yue Dong*

Main category: cs.CL

TL;DR: 研究发现，尽管大型语言模型具备更强的推理能力，但这并不能自动提升其在长上下文中的安全性。通过组合推理攻击，即使模型能识别隐含的有害意图，仍可能无法拒绝执行。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证一个假设：更强的推理能力应该能提高模型安全性，帮助模型识别未明确陈述的有害意图。特别是在长上下文环境中，有害意图可能是隐含的，需要通过推理才能识别。

Method: 提出了组合推理攻击这一新威胁模型：将有害查询分解为不完整的片段，分散在长上下文中，然后用中性推理查询诱导模型检索和合成这些片段，使有害意图在组合后才显现。在14个前沿LLM上评估，上下文长度达64k token。

Result: 三个主要发现：1) 具有更强通用推理能力的模型对组合推理攻击并不更鲁棒，经常能组合出意图但无法拒绝；2) 安全性对齐随着上下文长度增加而持续下降；3) 推理时的计算努力是关键缓解因素：增加推理时计算可将GPT-oss-120b的攻击成功率降低50多个百分点。

Conclusion: 安全性不会随着推理能力自动扩展，尤其是在长上下文推理场景下。需要专门的安全措施来应对组合推理攻击，不能依赖模型推理能力的自然提升。

Abstract: Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.

</details>


### [93] [GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search](https://arxiv.org/abs/2602.08945)
*Sahajpreet Singh,Kokil Jaidka,Min-Yen Kan*

Main category: cs.CL

TL;DR: GitSearch框架通过识别信息缺口、实时网络检索和合成平台兼容笔记，解决了社区内容审核中的冷启动问题，在政治推文基准测试中实现了99%的覆盖率和优于人工笔记的效果。


<details>
  <summary>Details</summary>
Motivation: 社区内容审核虽然具有可扩展性，但面临结构性挑战，现有AI方法在冷启动场景中失效。需要解决人类感知的质量缺口（如缺失上下文）作为核心信号的问题。

Method: GitSearch采用三阶段流程：1) 识别信息缺陷；2) 执行实时定向网络检索来解决这些缺陷；3) 合成符合平台要求的笔记。同时创建了PolBench基准数据集（78,698条美国政治推文及其社区笔记）。

Result: GitSearch实现了99%的覆盖率，几乎是现有最佳方法的两倍。在69%的情况下胜过人工撰写的帮助性笔记，获得更高的帮助性评分（3.87 vs 3.36），在规模与质量之间取得了良好平衡。

Conclusion: GitSearch框架通过将人类感知的质量缺口作为核心信号，有效解决了社区内容审核中的冷启动问题，在覆盖率和帮助性方面都超越了现有方法和人工创作，为可扩展的内容审核提供了有效解决方案。

Abstract: Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in "cold start" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.

</details>


### [94] [How Should We Model the Probability of a Language?](https://arxiv.org/abs/2602.08951)
*Rasul Dent,Pedro Ortiz Suarez,Thibault Clérice,Benoît Sagot*

Main category: cs.CL

TL;DR: 论文认为当前语言识别系统覆盖范围有限是因为将LID错误地框架为去语境化的文本分类问题，忽视了先验概率估计的重要性，应该重新将其视为路由问题并纳入环境线索。


<details>
  <summary>Details</summary>
Motivation: 全球7000多种语言中，商业语言识别系统只能可靠识别几百种书面语言，研究级系统在某些情况下能扩展覆盖范围，但对大多数语言来说覆盖仍然零散或不存在。这种状况很大程度上是自我造成的。

Method: 这是一篇立场论文，通过分析当前LID研究框架的局限性，提出将语言识别重新概念化为路由问题，并开发系统性的方法来纳入使语言在本地环境中合理的环境线索。

Result: 论文指出当前LID研究存在两个核心问题：1）将LID错误地框架为去语境化的文本分类；2）机构激励偏向于全球性、固定先验的模型，这掩盖了先验概率估计的核心作用。

Conclusion: 要提高尾部语言的覆盖范围，需要重新思考LID作为路由问题，并开发原则性的方法来纳入环境线索，使语言在本地环境中变得合理，而不是继续坚持去语境化的文本分类框架。

Abstract: Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.

</details>


### [95] [Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models](https://arxiv.org/abs/2602.08984)
*Yuliang Liu,Yunchong Song,Yixuan Wang,Kewen Ge,Alex Lamb,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出Next Concept Prediction (NCP)预训练范式，通过预测跨多个token的离散概念来构建更难的预训练目标，相比传统token级模型获得一致性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统Next Token Prediction (NTP)在token级别进行预测，而人类语言理解是基于概念的。作者希望构建更接近人类认知的预训练目标，通过预测概念而非单个token来提升语言模型能力。

Method: 提出ConceptLM模型：1) 使用Vector Quantization对隐藏状态进行量化，构建概念词汇表；2) 结合NCP和NTP进行参数更新；3) 生成概念来指导后续token的生成。在70M到1.5B参数规模上从头训练，使用Pythia和GPT-2架构，训练数据达300B。

Result: 在13个基准测试上，NCP相比传统token级模型获得一致性能提升。在8B参数的Llama模型上的持续预训练实验表明，NCP能进一步提升NTP训练的模型。分析显示NCP通过引入更难的预训练任务产生更强大的语言模型。

Conclusion: NCP通过预测跨多个token的概念，构建了比传统NTP更难的预训练目标，为提升语言模型性能提供了有前景的新路径。概念级预测能更好地模拟人类语言理解过程。

Abstract: We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.

</details>


### [96] [When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents](https://arxiv.org/abs/2602.08995)
*Yuting Ning,Jaylen Jones,Zhehao Zhang,Chentao Ye,Weitong Ruan,Junyi Li,Rahul Gupta,Huan Sun*

Main category: cs.CL

TL;DR: 本文首次系统定义并研究了计算机使用代理中的动作失配检测问题，提出了包含外部攻击和内部限制的全面分类，构建了真实轨迹基准MisActBench，并开发了实用的DeAction防护机制。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理虽然进展迅速，但仍经常产生偏离用户原始意图的失配动作，这些动作可能来自外部攻击（如间接提示注入）或内部限制（如错误推理），不仅带来安全风险，还降低任务效率和可靠性。

Method: 1) 首次定义并系统研究CUA中的失配动作检测问题；2) 识别现实世界CUA部署中的三个常见类别；3) 构建MisActBench基准，包含人类标注的动作级对齐标签的真实轨迹；4) 提出DeAction防护机制，在执行前检测失配动作并通过结构化反馈迭代纠正。

Result: 1) 在MisActBench上，DeAction的F1分数比所有基线高出超过15个百分点；2) 在线评估中，在对抗环境下将攻击成功率降低超过90%，同时在良性环境中保持甚至提高任务成功率；3) 具有适度的延迟开销。

Conclusion: 本文为CUA中的失配动作检测提供了首个系统研究框架，提出的DeAction防护机制在检测和纠正失配动作方面表现出色，显著提高了CUA的安全性和可靠性，同时保持了实用性。

Abstract: Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [97] [Embodied Intelligence for Flexible Manufacturing: A Survey](https://arxiv.org/abs/2602.06966)
*Kai Xu,Hang Zhao,Ruizhen Hu,Min Yang,Hao Liu,Hui Zhang,Haibin Yu*

Main category: cs.RO

TL;DR: 这篇综述论文探讨了工业具身智能在柔性制造中的三大挑战：有限感知下的精确过程建模与监控、柔性适应与高精度控制的动态平衡、通用技能与专业工业操作的融合，并从工业眼、工业手、工业脑三个视角系统回顾了现有工作。


<details>
  <summary>Details</summary>
Motivation: 下一代人工智能的突破推动具身智能快速发展进入工业制造领域，但在柔性制造中面临三大核心挑战：1）有限感知条件下的准确过程建模与监控；2）柔性适应与高精度控制的动态平衡；3）通用技能与专业工业操作的融合。

Method: 从三个视角系统综述现有工作：感知层面的"工业眼"（多模态数据融合与复杂动态环境下的实时建模）、控制层面的"工业手"（复杂制造过程的柔性自适应精确操控）、决策层面的"工业脑"（工艺规划和产线调度的智能优化方法）。

Result: 揭示了制造系统中感知-决策-执行闭环优化的关键技术路径，提出了柔性制造场景下具身智能发展的三阶段演进模型：认知增强、技能过渡和系统演化，为工业具身智能的跨学科发展提供了理论框架和实践指导。

Conclusion: 通过多层次协同和跨学科融合，该工作为工业具身智能在柔性制造背景下的发展提供了系统性分析框架，并展望了未来发展趋势，对推动该领域的理论研究和实际应用具有重要指导意义。

Abstract: Driven by breakthroughs in next-generation artificial intelligence, embodied intelligence is rapidly advancing into industrial manufacturing. In flexible manufacturing, industrial embodied intelligence faces three core challenges: accurate process modeling and monitoring under limited perception, dynamic balancing between flexible adaptation and high-precision control, and the integration of general-purpose skills with specialized industrial operations. Accordingly, this survey reviews existing work from three viewpoints: Industrial Eye, Industrial Hand, and Industrial Brain. At the perception level (Industrial Eye), multimodal data fusion and real-time modeling in complex dynamic settings are examined. At the control level (Industrial Hand), flexible, adaptive, and precise manipulation for complex manufacturing processes is analyzed. At the decision level (Industrial Brain), intelligent optimization methods for process planning and line scheduling are summarized. By considering multi-level collaboration and interdisciplinary integration, this work reveals the key technological pathways of embodied intelligence for closed-loop optimization of perception-decision-execution in manufacturing systems. A three-stage evolution model for the development of embodied intelligence in flexible manufacturing scenarios, comprising cognition enhancement, skill transition, and system evolution, is proposed, and future development trends are examined, to offer both a theoretical framework and practical guidance for the interdisciplinary advancement of industrial embodied intelligence in the context of flexible manufacturing.

</details>


### [98] [Leveraging Adaptive Group Negotiation for Heterogeneous Multi-Robot Collaboration with Large Language Models](https://arxiv.org/abs/2602.06967)
*Siqi Song,Xuanbing Xie,Zonglin Li,Yuqiang Li,Shijie Wang,Biqing Qi*

Main category: cs.RO

TL;DR: CLiMRS是一个基于LLM的异构多机器人协作框架，通过动态分组和协商机制实现高效规划与执行，在复杂装配任务中比基线方法效率提升40%以上。


<details>
  <summary>Details</summary>
Motivation: 异构多机器人协作任务需要长期在空间约束和环境不确定性下工作，虽然LLM擅长推理规划，但其在协调控制方面的潜力尚未充分探索。受人类团队合作启发，需要开发能适应动态环境的协作框架。

Method: 提出CLiMRS框架：为每个机器人配备LLM代理，通过通用提案规划器动态形成子组，子组管理器领导感知驱动的多LLM讨论来生成动作指令，结合机器人执行结果和环境变化的反馈，形成"分组-规划-执行-反馈"循环。

Result: 在CLiMBench异构多机器人基准测试中，CLiMRS在复杂任务上比最佳基线效率提升超过40%，同时在简单任务上不牺牲成功率。结果表明人类启发的分组和协商原则能显著提升异构多机器人协作效率。

Conclusion: 利用人类团队合作的分组和协商原则，结合LLM的推理能力，可以显著提高异构多机器人系统的协作效率，为复杂多机器人任务提供了有效的自适应框架。

Abstract: Multi-robot collaboration tasks often require heterogeneous robots to work together over long horizons under spatial constraints and environmental uncertainties. Although Large Language Models (LLMs) excel at reasoning and planning, their potential for coordinated control has not been fully explored. Inspired by human teamwork, we present CLiMRS (Cooperative Large-Language-Model-Driven Heterogeneous Multi-Robot System), an adaptive group negotiation framework among LLMs for multi-robot collaboration. This framework pairs each robot with an LLM agent and dynamically forms subgroups through a general proposal planner. Within each subgroup, a subgroup manager leads perception-driven multi-LLM discussions to get commands for actions. Feedback is provided by both robot execution outcomes and environment changes. This grouping-planning-execution-feedback loop enables efficient planning and robust execution. To evaluate these capabilities, we introduce CLiMBench, a heterogeneous multi-robot benchmark of challenging assembly tasks. Our experiments show that CLiMRS surpasses the best baseline, achieving over 40% higher efficiency on complex tasks without sacrificing success on simpler ones. Overall, our results demonstrate that leveraging human-inspired group formation and negotiation principles significantly enhances the efficiency of heterogeneous multi-robot collaboration. Our code is available here: https://github.com/song-siqi/CLiMRS.

</details>


### [99] [Learning to Anchor Visual Odometry: KAN-Based Pose Regression for Planetary Landing](https://arxiv.org/abs/2602.06968)
*Xubo Luo,Zhaojin Li,Xue Wan,Wei Zhang,Leizheng Shu*

Main category: cs.RO

TL;DR: KANLoc：一种用于月球着陆的单目定位框架，通过KAN网络将视觉里程计与绝对位姿回归器紧耦合，实现高精度、实时、全局一致的定位，在纹理稀疏或低光照地形中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有月球着陆定位方法存在局限：视觉里程计（VO）会无界漂移，而基于地图的绝对定位在纹理稀疏或低光照地形中失效。需要一种既能消除漂移又能保持局部运动精度的实时定位方案。

Method: 提出KANLoc框架，核心是Kolmogorov-Arnold Network（KAN），学习从图像特征到地图坐标的复杂映射，生成稀疏但高度可靠的全局位姿锚点。将这些锚点融合到束调整框架中，有效消除漂移同时保留局部运动精度。还包括专门的数据增强策略以提高对传感器遮挡的鲁棒性。

Result: 在合成和真实月球着陆数据集上，KANLoc将平均平移和旋转误差分别降低了32%和45%，单轨迹增益最高达45%/48%，优于强基线方法。能够实现全局一致的实时轨迹（≥15 FPS）。

Conclusion: KANLoc通过KAN网络实现了参数高效的位姿回归，结合VO与绝对定位的混合方案，为月球着陆等任务提供了高精度、实时、鲁棒的定位解决方案，在纹理稀疏和低光照环境下表现优异。

Abstract: Accurate and real-time 6-DoF localization is mission-critical for autonomous lunar landing, yet existing approaches remain limited: visual odometry (VO) drifts unboundedly, while map-based absolute localization fails in texture-sparse or low-light terrain. We introduce KANLoc, a monocular localization framework that tightly couples VO with a lightweight but robust absolute pose regressor. At its core is a Kolmogorov-Arnold Network (KAN) that learns the complex mapping from image features to map coordinates, producing sparse but highly reliable global pose anchors. These anchors are fused into a bundle adjustment framework, effectively canceling drift while retaining local motion precision. KANLoc delivers three key advances: (i) a KAN-based pose regressor that achieves high accuracy with remarkable parameter efficiency, (ii) a hybrid VO-absolute localization scheme that yields globally consistent real-time trajectories (>=15 FPS), and (iii) a tailored data augmentation strategy that improves robustness to sensor occlusion. On both realistic synthetic and real lunar landing datasets, KANLoc reduces average translation and rotation error by 32% and 45%, respectively, with per-trajectory gains of up to 45%/48%, outperforming strong baselines.

</details>


### [100] [A Survey of Medical Drones from Flight Dynamics, Guidance, Navigation, and Control Perspectives](https://arxiv.org/abs/2602.06969)
*Roshan Kumar Chhetri,Sarocha Jetawatthana,Thanakorn Khamvilai*

Main category: cs.RO

TL;DR: 这篇论文全面综述了医疗无人机在飞行动力学与制导、导航、控制（GNC）系统方面的研究，重点关注医疗运输任务需求、无人机配置、有效载荷设计及其对飞行动力学的影响，以及应对环境挑战的GNC算法。


<details>
  <summary>Details</summary>
Motivation: 现有医疗无人机研究多关注医疗供应链、运营和应急响应，缺乏从飞行动力学和GNC系统角度的全面分析。医疗运输任务面临振动、温湿度等环境因素对医疗物资质量的挑战，需要专门的GNC框架优化。

Method: 采用系统性文献综述方法，首先分析医疗航空运输任务需求和适用的无人机系统配置，然后研究有效载荷容器设计与优化及其对飞行动力学的影响，最后探讨医疗无人机操作中的GNC基本原理和算法。

Result: 识别了医疗无人机在振动、温度、压力、湿度等环境因素下面临的关键挑战，分析了现有GNC算法在缓解这些挑战方面的能力与局限性，提出了优化医疗无人机GNC框架的研究方向。

Conclusion: 医疗无人机需要专门优化的GNC系统来应对医疗物资运输的特殊要求，论文指出了当前研究空白并为改进实际医疗应用提供了方向性建议。

Abstract: The integration of drones into the medical field has revolutionized healthcare delivery by enabling rapid transportation of medical supplies, organs, and even emergency assistance in remote or disaster-stricken areas. While other survey papers focus on the healthcare supply chain, operations, and medical emergency response aspects, this paper provides a comprehensive review of medical drones from the perspectives of flight dynamics and guidance, navigation, and control (GNC) systems. We first discuss the medical aerial delivery mission requirements and suitable uncrewed aerial system (UAS) configurations. We then address payload container design and optimization, and its effect on supplies and overall flight dynamics. We also explore the fundamental principles of GNC in the context of medical drone operations, highlighting key challenges arising from vibration, air temperature, pressure, and humidity, which affect the quality of medical supplies. The paper examines various GNC algorithms that can mitigate these challenges, as well as the algorithms' limitations. With these considerations, this survey aims to provide insights into optimizing GNC frameworks for medical drones, emphasizing research gaps and directions to improve real-world healthcare applications.

</details>


### [101] [Formal Methods in Robot Policy Learning and Verification: A Survey on Current Techniques and Future Directions](https://arxiv.org/abs/2602.06971)
*Anastasios Manganaris,Vittorio Giammarino,Ahmed H. Qureshi,Suresh Jagannathan*

Main category: cs.RO

TL;DR: 这篇综述论文系统回顾了形式化方法在机器人学习中的应用，重点关注策略学习和策略验证两大支柱，旨在解决深度学习带来的模型复杂性、脆弱性和可解释性挑战。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统复杂性的增加，特别是深度学习技术的广泛应用，传统的机器人策略变得不够灵活、脆弱且难以解释。形式化方法能够提供精确的规范说明、指导学习过程并验证学习到的策略，从而提升机器人的安全性和正确性。

Method: 采用综述研究方法，将现有文献组织为两大支柱：策略学习（如何利用形式化方法指导策略学习）和策略验证（如何验证学习到的策略符合规范）。对代表性技术进行对比分析，评估其可扩展性和表达能力。

Result: 系统梳理了形式化方法在机器人学习中的最新应用进展，比较了不同方法在可扩展性和表达能力方面的优劣，展示了这些方法如何实际提升机器人的安全性和正确性。

Conclusion: 形式化方法在机器人学习中具有重要价值，但仍面临一些障碍。未来需要进一步推进形式化方法在机器人学习领域的发展，以更好地实现机器人的安全性和正确性目标。

Abstract: As hardware and software systems have grown in complexity, formal methods have been indispensable tools for rigorously specifying acceptable behaviors, synthesizing programs to meet these specifications, and validating the correctness of existing programs. In the field of robotics, a similar trend of rising complexity has emerged, driven in large part by the adoption of deep learning. While this shift has enabled the development of highly performant robot policies, their implementation as deep neural networks has posed challenges to traditional formal analysis, leading to models that are inflexible, fragile, and difficult to interpret. In response, the robotics community has introduced new formal and semi-formal methods to support the precise specification of complex objectives, guide the learning process to achieve them, and enable the verification of learned policies against them. In this survey, we provide a comprehensive overview of how formal methods have been used in recent robot learning research. We organize our discussion around two pillars: policy learning and policy verification. For both, we highlight representative techniques, compare their scalability and expressiveness, and summarize how they contribute to meaningfully improving realistic robot safety and correctness. We conclude with a discussion of remaining obstacles for achieving that goal and promising directions for advancing formal methods in robot learning.

</details>


### [102] [FeudalNav: A Simple Framework for Visual Navigation](https://arxiv.org/abs/2602.06974)
*Faith Johnson,Bryan Bo Cao,Shubham Jain,Ashwin Ashok,Kristin Dana*

Main category: cs.RO

TL;DR: 提出分层视觉导航框架，通过视觉相似性组织记忆，无需里程计即可在陌生环境中导航，支持人机交互提升性能


<details>
  <summary>Details</summary>
Motivation: 传统基于度量地图的方法在未知、无地图或GPS拒止环境中表现不佳，需要转向基于学习的方法，减少探索需求

Method: 分层框架将导航决策分解为多个层级，使用可转移的子目标选择网络，基于视觉相似性组织潜在空间记忆模块替代图拓扑表示

Result: 在Habitat AI环境中与SOTA方法竞争，训练和推理均不使用里程计，框架可解释性支持交互导航，少量人工干预显著提升成功率

Conclusion: 基于视觉相似性的紧凑轻量导航器可在新环境中导航，交互式导航框架证明最小人工干预能显著提高性能

Abstract: Visual navigation for robotics is inspired by the human ability to navigate environments using visual cues and memory, eliminating the need for detailed maps. In unseen, unmapped, or GPS-denied settings, traditional metric map-based methods fall short, prompting a shift toward learning-based approaches with minimal exploration. In this work, we develop a hierarchical framework that decomposes the navigation decision-making process into multiple levels. Our method learns to select subgoals through a simple, transferable waypoint selection network. A key component of the approach is a latent-space memory module organized solely by visual similarity, as a proxy for distance. This alternative to graph-based topological representations proves sufficient for navigation tasks, providing a compact, light-weight, simple-to-train navigator that can find its way to the goal in novel locations. We show competitive results with a suite of SOTA methods in Habitat AI environments without using any odometry in training or inference. An additional contribution leverages the interpretablility of the framework for interactive navigation. We consider the question: how much direction intervention/interaction is needed to achieve success in all trials? We demonstrate that even minimal human involvement can significantly enhance overall navigation performance.

</details>


### [103] [Autonomous Manipulation of Hazardous Chemicals and Delicate Objects in a Self-Driving Laboratory: A Sliding Mode Approach](https://arxiv.org/abs/2602.06977)
*Shifa Sulaiman,Francesco Schetter,Tobias Jensen,Simon Bøgh,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 在自动驾驶化学实验室中，采用基于模型的滑模控制（MBSMC）实现移动机械臂的平滑精确运动控制，相比PID和非模型滑模控制，显著降低控制能耗并提高轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶化学实验室中的机械臂需要精确处理易碎玻璃容器和危险化学品，传统控制方法难以应对非线性动力学和外部干扰，需要更鲁棒的控制策略来确保安全平稳的操作。

Method: 提出基于模型的滑模控制（MBSMC），采用双曲正切函数调节移动平台上的机械臂运动，专门设计用于最小化突变过渡并实现平滑精确的轨迹跟踪。

Result: 相比PID和非模型滑模控制（NMBSMC），MBSMC实现了显著更平滑的运动和高达90%更低的控制能耗，在关节和笛卡尔坐标系指标上表现优异，成功执行了PID控制失败的任务。

Conclusion: MBSMC控制器在自动驾驶实验室环境中实现了平滑、精确和安全的机械臂运动，验证了其在处理非线性动力学和外部干扰方面的鲁棒性，支持智能移动机械臂在自主实验室环境中的发展。

Abstract: Precise handling of chemical instruments and materials within a self-driving laboratory environment using robotic systems demands advanced and reliable control strategies. Sliding Mode Control (SMC) has emerged as a robust approach for managing uncertainties and disturbances in manipulator dynamics, providing superior control performance compared to traditional methods. This study implements a model-based SMC (MBSMC) utilizing a hyperbolic tangent function to regulate the motion of a manipulator mounted on a mobile platform operating inside a self-driving chemical laboratory. Given the manipulator's role in transporting fragile glass vessels filled with hazardous chemicals, the controller is specifically designed to minimize abrupt transitions and achieve gentle, accurate trajectory tracking. The proposed controller is benchmarked against a non-model-based SMC (NMBSMC) and a Proportional-Integral-Derivative (PID) controller using a comprehensive set of joint and Cartesian metrics. Compared to PID and NMBSMC, MBSMC achieved significantly smoother motion and up to 90% lower control effort, validating its robustness and precision for autonomous laboratory operations. Experimental trials confirmed successful execution of tasks such as vessel grasping and window operation, which failed under PID control due to its limited ability to handle nonlinear dynamics and external disturbances, resulting in substantial trajectory tracking errors. The results validate the controller's effectiveness in achieving smooth, precise, and safe manipulator motions, supporting the advancement of intelligent mobile manipulators in autonomous laboratory environments.

</details>


### [104] [LangGS-SLAM: Real-Time Language-Feature Gaussian Splatting SLAM](https://arxiv.org/abs/2602.06991)
*Seongbo Ha,Sibaek Lee,Kyungsu Kang,Joonyeol Choi,Seungjun Tak,Hyeonwoo Yu*

Main category: cs.RO

TL;DR: 提出一个RGB-D SLAM系统，在保持低延迟跟踪与建图的同时，重建语言对齐的密集特征场


<details>
  <summary>Details</summary>
Motivation: 为了弥合3D感知与基于语言推理之间的差距，实现在线SLAM中密集、未压缩的语言对齐特征场

Method: 1) Top-K渲染管道：高效渲染高维特征图；2) 多标准地图管理策略：修剪冗余或不一致的高斯分布；3) 混合场优化框架：根据场特性解耦优化频率，联合优化几何与语义场

Result: 系统在15 FPS下运行，相比仅几何基线具有更优的几何保真度，与离线方法具有相当的语义保真度

Conclusion: 在线SLAM实现密集、未压缩的语言对齐特征场是可行且有效的，为3D感知与语言推理建立了桥梁

Abstract: In this paper, we propose a RGB-D SLAM system that reconstructs a language-aligned dense feature field while sustaining low-latency tracking and mapping. First, we introduce a Top-K Rendering pipeline, a high-throughput and semantic-distortion-free method for efficiently rendering high-dimensional feature maps. To address the resulting semantic-geometric discrepancy and mitigate the memory consumption, we further design a multi-criteria map management strategy that prunes redundant or inconsistent Gaussians while preserving scene integrity. Finally, a hybrid field optimization framework jointly refines the geometric and semantic fields under real-time constraints by decoupling their optimization frequencies according to field characteristics. The proposed system achieves superior geometric fidelity compared to geometric-only baselines and comparable semantic fidelity to offline approaches while operating at 15 FPS. Our results demonstrate that online SLAM with dense, uncompressed language-aligned feature fields is both feasible and effective, bridging the gap between 3D perception and language-based reasoning.

</details>


### [105] [When Simultaneous Localization and Mapping Meets Wireless Communications: A Survey](https://arxiv.org/abs/2602.06995)
*Konstantinos Gounis,Sotiris A. Tegos,Dimitrios Tyrovolas,Panagiotis D. Diamantoulakis,George K. Karagiannidis*

Main category: cs.RO

TL;DR: 本文综述了SLAM与无线通信交叉领域的最新进展，重点探讨视觉SLAM与无线通信的双向影响，分析关键技术、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 商业无线通信与传感设备的普及以及智能自主系统的发展，为实现鲁棒的联合通信与同时定位与建图（SLAM）创造了条件。本文旨在调查SLAM与无线通信交叉领域的最新进展，探索两者之间的双向影响关系。

Method: 采用综述研究方法，分析无线信号传播、几何信道建模、RF定位与传感等关键概念，探讨图像处理技术检测地标并预测无线信道最优路径。考虑多个维度包括先决条件、技术、背景及未来方向，分析概率模型、空间信号处理等数学方法。

Result: 发现单目视觉SLAM可从RF信息中受益，RF信息可作为尺度模糊性解析的代理；而5G及以后的无线通信可从SLAM中的视觉里程计中受益。同时发现集成通信与SLAM的联合解决方案仍处于起步阶段。

Conclusion: SLAM与无线通信存在双向协同关系，但集成解决方案尚不成熟，需要在理论和实践上进一步发展，为RF和多天线技术增加更高层次的定位和语义感知能力。

Abstract: The availability of commercial wireless communication and sensing equipment combined with the advancements in intelligent autonomous systems paves the way towards robust joint communications and simultaneous localization and mapping (SLAM). This paper surveys the state-of-the-art in the nexus of SLAM and Wireless Communications, attributing the bidirectional impact of each with a focus on visual SLAM (V-SLAM) integration. We provide an overview of key concepts related to wireless signal propagation, geometric channel modeling, and radio frequency (RF)-based localization and sensing. In addition to this, we show image processing techniques that can detect landmarks, proactively predicting optimal paths for wireless channels. Several dimensions are considered, including the prerequisites, techniques, background, and future directions and challenges of the intersection between SLAM and wireless communications. We analyze mathematical approaches such as probabilistic models, and spatial methods for signal processing, as well as key technological aspects. We expose techniques and items towards enabling a highly effective retrieval of the autonomous robot state. Among other interesting findings, we observe that monocular V-SLAM would benefit from RF relevant information, as the latter can serve as a proxy for the scale ambiguity resolution. Conversely, we find that wireless communications in the context of 5G and beyond can potentially benefit from visual odometry that is central in SLAM. Moreover, we examine other sources besides the camera for SLAM and describe the twofold relation with wireless communications. Finally, integrated solutions performing joint communications and SLAM are still in their infancy: theoretical and practical advancements are required to add higher-level localization and semantic perception capabilities to RF and multi-antenna technologies.

</details>


### [106] [Admittance-Based Motion Planning with Vision-Guided Initialization for Robotic Manipulators in Self-Driving Laboratories](https://arxiv.org/abs/2602.07005)
*Shifa Sulaiman,Tobias Jensen,Francesco Schetter,Simon Bøgh*

Main category: cs.RO

TL;DR: 提出了一种基于导纳控制的运动规划框架，用于实现自适应、柔顺的机器人操作，通过将导纳控制器直接集成到轨迹执行中，使机器人能够动态响应交互过程中的外力，并允许人类操作员实时干预机器人运动。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室（SDL）需要柔顺和力感知控制来确保安全、适应性和可靠性，因为实验室环境涉及精密设备、不可预测的环境交互和偶尔的人工干预。

Method: 1. 基于导纳控制的运动规划框架，将导纳控制器直接集成到轨迹执行中；2. 基于结构化平面姿态估计的视觉算法，通过特征提取、单应性估计和深度融合来检测和定位纹理平面物体；3. 视觉初始化建立参考轨迹，嵌入式导纳控制器确保轨迹执行安全、自适应且能响应外力或人工干预。

Result: 使用纹理图像检测作为概念验证验证了所提出的策略，证明了框架能够实现安全、自适应且响应外部力的机器人操作。

Conclusion: 该框架为自驱动实验室环境中的机器人操作提供了柔顺运动规划解决方案，未来工作将扩展到涉及透明实验室物体的SDL环境，进一步增强自主性、安全性和人机协作。

Abstract: Self driving laboratories (SDLs) are highly automated research environments that leverage advanced technologies to conduct experiments and analyze data with minimal human involvement. These environments often involve delicate laboratory equipment, unpredictable environmental interactions, and occasional human intervention, making compliant and force aware control essential for ensuring safety, adaptability, and reliability. This paper introduces a motion-planning framework centered on admittance control to enable adaptive and compliant robotic manipulation. Unlike conventional schemes, the proposed approach integrates an admittance controller directly into trajectory execution, allowing the manipulator to dynamically respond to external forces during interaction. This capability enables human operators to override or redirect the robot's motion in real time. A vision algorithm based on structured planar pose estimation is employed to detect and localize textured planar objects through feature extraction, homography estimation, and depth fusion, thereby providing an initial target configuration for motion planning. The vision based initialization establishes the reference trajectory, while the embedded admittance controller ensures that trajectory execution remains safe, adaptive, and responsive to external forces or human intervention. The proposed strategy is validated using textured image detection as a proof of concept. Future work will extend the framework to SDL environments involving transparent laboratory objects where compliant motion planning can further enhance autonomy, safety, and human-robot collaboration.

</details>


### [107] [ARGOS: Automated Functional Safety Requirement Synthesis for Embodied AI via Attribute-Guided Combinatorial Reasoning](https://arxiv.org/abs/2602.07007)
*Dongsheng Chen,Yuxuan Li,Yi Lin,Guanhua Chen,Jiaxin Zhang,Xiangyu Zhao,Lei Ma,Xin Yao,Xuetao Wei*

Main category: cs.RO

TL;DR: ARGOS框架通过属性引导的组合推理，将开放式自然语言指令转化为具体的物理属性，生成物理上合理的危险场景，并实例化为功能安全需求，解决具身AI安全评估的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统危险分析与风险评估方法在具身AI领域难以扩展，因为具身AI基于开放式自然语言指令操作，存在组合交互风险。大语言模型虽能解决可扩展性问题，但缺乏物理基础，产生语义肤浅且不连贯的危险描述。

Method: 提出ARGOS框架，通过动态将指令中的实体分解为细粒度物理属性，将LLM推理基于因果风险因素，生成物理上合理的危险场景。然后将抽象安全标准实例化为上下文特定的功能安全需求，整合场景与机器人能力。

Result: 大量实验验证ARGOS能生成高质量的功能安全需求，在识别长尾风险方面优于基线方法。

Conclusion: ARGOS为系统化、有物理基础的功能安全需求生成铺平了道路，是实现具身AI安全工业部署的关键一步。

Abstract: Ensuring functional safety is essential for the deployment of Embodied AI in complex open-world environments. However, traditional Hazard Analysis and Risk Assessment (HARA) methods struggle to scale in this domain. While HARA relies on enumerating risks for finite and pre-defined function lists, Embodied AI operates on open-ended natural language instructions, creating a challenge of combinatorial interaction risks. Whereas Large Language Models (LLMs) have emerged as a promising solution to this scalability challenge, they often lack physical grounding, yielding semantically superficial and incoherent hazard descriptions. To overcome these limitations, we propose a new framework ARGOS (AttRibute-Guided cOmbinatorial reaSoning), which bridges the gap between open-ended user instructions and concrete physical attributes. By dynamically decomposing entities from instructions into these fine-grained properties, ARGOS grounds LLM reasoning in causal risk factors to generate physically plausible hazard scenarios. It then instantiates abstract safety standards, such as ISO 13482, into context-specific Functional Safety Requirements (FSRs) by integrating these scenarios with robot capabilities. Extensive experiments validate that ARGOS produces high-quality FSRs and outperforms baselines in identifying long-tail risks. Overall, this work paves the way for systematic and grounded functional safety requirement generation, a critical step toward the safe industrial deployment of Embodied AI.

</details>


### [108] [A Distributed Multi-Modal Sensing Approach for Human Activity Recognition in Real-Time Human-Robot Collaboration](https://arxiv.org/abs/2602.07024)
*Valerio Belcamino,Nhat Minh Dinh Le,Quan Khanh Luu,Alessandro Carfì,Van Anh Ho,Fulvio Mastrogiovanni*

Main category: cs.RO

TL;DR: 本文提出了一种结合数据手套和视觉触觉传感器的手部活动识别系统，用于人机协作场景，在多种测试条件下均表现出高精度。


<details>
  <summary>Details</summary>
Motivation: 人机协作中，机器人需要识别人类活动以动态适应人类意图。传统方法在接触式手部活动识别方面存在局限，需要多模态方法提升识别能力。

Method: 采用模块化数据手套（配备惯性测量单元）和基于视觉的触觉传感器相结合的多模态系统，捕获与机器人接触时的手部活动。

Result: 实验结果显示，在分段序列离线分类、静态条件下的实时分类以及真实人机协作场景中，系统均实现了高精度识别。

Conclusion: 多模态方法在人机协作中具有显著优势，能够有效识别接触式手部活动，为多种协作场景提供可靠的活动识别解决方案。

Abstract: Human activity recognition (HAR) is fundamental in human-robot collaboration (HRC), enabling robots to respond to and dynamically adapt to human intentions. This paper introduces a HAR system combining a modular data glove equipped with Inertial Measurement Units and a vision-based tactile sensor to capture hand activities in contact with a robot. We tested our activity recognition approach under different conditions, including offline classification of segmented sequences, real-time classification under static conditions, and a realistic HRC scenario. The experimental results show a high accuracy for all the tasks, suggesting that multiple collaborative settings could benefit from this multi-modal approach.

</details>


### [109] [Airspace-aware Contingency Landing Planning](https://arxiv.org/abs/2602.07074)
*H. Emre Tekaslan,Ella M. Atkins*

Main category: cs.RO

TL;DR: 开发实时搜索式飞机应急着陆规划器，最小化交通干扰并考虑地面风险，使用华盛顿特区案例验证


<details>
  <summary>Details</summary>
Motivation: 需要解决飞机应急着陆时的双重挑战：既要最小化对正常空中交通的干扰，又要考虑地面人口风险，特别是在密集空域环境中

Method: 1) 处理历史ADS-B数据估计空中交通密度；2) 使用低延迟计算几何算法生成高风险走廊和限制区域的热力图；3) 量化空域风险（轨迹在拥堵区域的累积暴露时间）和地面风险（飞越人口密度）；4) 着陆点选择模块减少对正常交通的干扰

Result: 相比最小风险Dubins解，提出的规划器实现了更低的联合风险和更少的空域干扰，同时保持实时性能。在仅考虑空域风险条件下，笔记本电脑上平均2.9秒生成轨迹

Conclusion: 该规划器能有效平衡应急着陆的空域和地面风险，未来工作将纳入动态空中交通更新，实现时空应急着陆规划，减少实时交通改道需求

Abstract: This paper develops a real-time, search-based aircraft contingency landing planner that minimizes traffic disruptions while accounting for ground risk. The airspace model captures dense air traffic departure and arrival flows, helicopter corridors, and prohibited zones and is demonstrated with a Washington, D.C., area case study. Historical Automatic Dependent Surveillance-Broadcast (ADS-B) data are processed to estimate air traffic density. A low-latency computational geometry algorithm generates proximity-based heatmaps around high-risk corridors and restricted regions. Airspace risk is quantified as the cumulative exposure time of a landing trajectory within congested regions, while ground risk is assessed from overflown population density to jointly guide trajectory selection. A landing site selection module further mitigates disruption to nominal air traffic operations. Benchmarking against minimum-risk Dubins solutions demonstrates that the proposed planner achieves lower joint risk and reduced airspace disruption while maintaining real-time performance. Under airspace-risk-only conditions, the planner generates trajectories within an average of 2.9 seconds on a laptop computer. Future work will incorporate dynamic air traffic updates to enable spatiotemporal contingency landing planning that minimizes the need for real-time traffic rerouting.

</details>


### [110] [A compliant ankle-actuated compass walker with triggering timing control](https://arxiv.org/abs/2602.07158)
*Deniz Kerimoglu,Ismail Uyanik*

Main category: cs.RO

TL;DR: 提出了一种名为TC-AACG的新型双足行走模型，采用非瞬时柔性踝关节推进技术，可通过串联弹性执行器在物理平台上实现，相比传统脉冲式踝关节推进方法扩展了双足模型的运动能力。


<details>
  <summary>Details</summary>
Motivation: 被动动态行走器作为双足行走的数学模型，其稳定运动通常需要倾斜表面和重力能量。现有技术大多依赖脉冲能量注入方案和扭转弹簧，这在物理平台上实现相当困难。

Method: 提出触发控制踝关节驱动罗盘步态（TC-AACG）模型，允许非瞬时柔性踝关节推进，可通过串联弹性执行器在物理平台上实现。

Result: 系统检查表明，该方法相比脉冲式踝关节推进方法扩展了双足模型的运动能力。通过仿真分析研究了运动速度、机械运输成本和吸引域。

Conclusion: TC-AACG模型提供了一种更易在物理平台上实现的柔性踝关节推进方案，扩展了双足行走模型在水平地面和崎岖地形上的适用性。

Abstract: Passive dynamic walkers are widely adopted as a mathematical model to represent biped walking. The stable locomotion of these models is limited to tilted surfaces, requiring gravitational energy. Various techniques, such as actuation through the ankle and hip joints, have been proposed to extend the applicability of these models to level ground and rough terrain with improved locomotion efficiency. However, most of these techniques rely on impulsive energy injection schemes and torsional springs, which are quite challenging to implement in a physical platform. Here, a new model is proposed, named triggering controlled ankle actuated compass gait (TC-AACG), which allows non-instantaneous compliant ankle pushoff. The proposed technique can be implemented in physical platforms via series elastic actuators (SEAs). Our systematic examination shows that the proposed approach extends the locomotion capabilities of a biped model compared to impulsive ankle pushoff approach. We provide extensive simulation analysis investigating the locomotion speed, mechanical cost of transport, and basin of attraction of the proposed model.

</details>


### [111] [Continuum Robot Localization using Distributed Time-of-Flight Sensors](https://arxiv.org/abs/2602.07209)
*Spencer Teetaert,Giammarco Caroleo,Marco Pontin,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot,Perla Maiolino*

Main category: cs.RO

TL;DR: 提出了一种用于连续体机器人的定位技术，使用沿机器人长度分布的小型低分辨率飞行时间传感器，通过融合测量信息与机器人形状先验，在非结构化环境中实现精确定位。


<details>
  <summary>Details</summary>
Motivation: 在软体和连续体机器人领域，由于机器人可变形特性以及高分辨率传感器尺寸过大不实用，导致连续体机器人在非结构化环境中的定位和建图研究很少。需要开发适用于这类机器人的定位解决方案。

Method: 使用沿机器人长度分布的小型低分辨率飞行时间传感器（如激光雷达），将测量信息与机器人形状先验进行融合，即使在传感器经常遇到退化场景的情况下也能实现精确定位。

Result: 在53厘米长的机器人上，所有实验条件下平均定位误差为2.5厘米（位置）和7.2°（旋转）。结果在多个环境中重复验证，包括仿真和真实世界实验，并对先验地图偏差的鲁棒性进行了研究。

Conclusion: 该方法证明了使用小型低分辨率传感器结合形状先验可以实现连续体机器人的精确定位，为解决这类机器人在非结构化环境中的定位问题提供了可行方案。

Abstract: Localization and mapping of an environment are crucial tasks for any robot operating in unstructured environments. Time-of-flight (ToF) sensors (e.g.,~lidar) have proven useful in mobile robotics, where high-resolution sensors can be used for simultaneous localization and mapping. In soft and continuum robotics, however, these high-resolution sensors are too large for practical use. This, combined with the deformable nature of such robots, has resulted in continuum robot (CR) localization and mapping in unstructured environments being a largely untouched area. In this work, we present a localization technique for CRs that relies on small, low-resolution ToF sensors distributed along the length of the robot. By fusing measurement information with a robot shape prior, we show that accurate localization is possible despite each sensor experiencing frequent degenerate scenarios. We achieve an average localization error of 2.5cm in position and 7.2° in rotation across all experimental conditions with a 53cm long robot. We demonstrate that the results are repeated across multiple environments, in both simulation and real-world experiments, and study robustness in the estimation to deviations in the prior map.

</details>


### [112] [Realistic Synthetic Household Data Generation at Scale](https://arxiv.org/abs/2602.07243)
*Siddharth Singh,Ifrah Idrees,Abraham Dauhajre*

Main category: cs.RO

TL;DR: 提出一个生成大规模家庭数据集的框架，通过松散耦合生成长期人机交互和环境，支持双向影响建模和自然语言配置。


<details>
  <summary>Details</summary>
Motivation: 现有框架无法建模人类行为与家庭环境之间的双向影响，需要大规模、多样化的数据集来开发具身AI交互代理。

Method: 提出生成框架，松散耦合地生成长期人机交互和环境：人类角色影响环境生成，环境模式和语义塑造人机交互。提供灵活工具，允许用户通过自然语言提示定义数据集特征。

Result: 生成包含丰富静态和时序上下文的3D数据。统计评估显示与真实数据集(HOMER)良好对齐(余弦相似度0.60)，与合成数据集中等对齐(0.27)。干预分析显示统计显著效应(p<0.001)和大效应量(Cohen's d=0.51-1.12)，证实双向耦合。

Conclusion: 该框架能够大规模生成家庭数据集，支持双向影响建模，有助于家庭智能设备的开发和测试。

Abstract: Advancements in foundation models have catalyzed research in Embodied AI to develop interactive agents capable of environmental reasoning and interaction. Developing such agents requires diverse, large-scale datasets. Prior frameworks generate synthetic data for long-term human-robot interactions but fail to model the bidirectional influence between human behavior and household environments. Our proposed generative framework creates household datasets at scale through loosely coupled generation of long-term human-robot interactions and environments. Human personas influence environment generation, while environment schematics and semantics shape human-robot interactions.
  The generated 3D data includes rich static context such as object and environment semantics, and temporal context capturing human and agent behaviors over extended periods. Our flexible tool allows users to define dataset characteristics via natural language prompts, enabling configuration of environment and human activity data through natural language specifications. The tool creates variations of user-defined configurations, enabling scalable data generation.
  We validate our framework through statistical evaluation using multi-modal embeddings and key metrics: cosine similarity, mutual information gain, intervention analysis, and iterative improvement validation. Statistical comparisons show good alignment with real-world datasets (HOMER) with cosine similarity (0.60), while synthetic datasets (Wang et al.) show moderate alignment (0.27). Intervention analysis across age, organization, and sleep pattern changes shows statistically significant effects (p < 0.001) with large effect sizes (Cohen's d = 0.51-1.12), confirming bidirectional coupling translates persona traits into measurable environmental and behavioral differences. These contributions enable development and testing of household smart devices at scale.

</details>


### [113] [aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones](https://arxiv.org/abs/2602.07264)
*Jacopo Panerati,Sina Sajjadi,Sina Soleymanpour,Varunkumar Mehta,Iraj Mantegh*

Main category: cs.RO

TL;DR: 作者提出了aerial-autonomy-stack，一个开源的端到端框架，用于加速无人机自主系统的开发部署，支持PX4和ArduPilot，提供超过20倍实时速度的仿真能力。


<details>
  <summary>Details</summary>
Motivation: 无人机自主系统开发面临"仿真到现实差距"的挑战，包括建模不足和软硬件垂直集成的复杂性。当前需要一种能加速感知到行动全流程开发的解决方案。

Method: 开发了aerial-autonomy-stack开源框架，基于ROS2，为PX4和ArduPilot提供统一接口，支持GPU加速感知和飞行控制器动作的端到端开发。

Result: 该框架支持超过20倍实时速度的端到端仿真，包括边缘计算和网络通信，显著压缩了基于感知的自主系统开发-测试-发布周期。

Conclusion: aerial-autonomy-stack通过提供统一的开发框架和高速仿真能力，有效解决了无人机自主系统开发中的仿真到现实差距问题，加速了自主无人机系统的工程化部署。

Abstract: Unmanned aerial vehicles are rapidly transforming multiple applications, from agricultural and infrastructure monitoring to logistics and defense. Introducing greater autonomy to these systems can simultaneously make them more effective as well as reliable. Thus, the ability to rapidly engineer and deploy autonomous aerial systems has become of strategic importance. In the 2010s, a combination of high-performance compute, data, and open-source software led to the current deep learning and AI boom, unlocking decades of prior theoretical work. Robotics is on the cusp of a similar transformation. However, physical AI faces unique hurdles, often combined under the umbrella term "simulation-to-reality gap". These span from modeling shortcomings to the complexity of vertically integrating the highly heterogeneous hardware and software systems typically found in field robots. To address the latter, we introduce aerial-autonomy-stack, an open-source, end-to-end framework designed to streamline the pipeline from (GPU-accelerated) perception to (flight controller-based) action. Our stack allows the development of aerial autonomy using ROS2 and provides a common interface for two of the most popular autopilots: PX4 and ArduPilot. We show that it supports over 20x faster-than-real-time, end-to-end simulation of a complete development and deployment stack -- including edge compute and networking -- significantly compressing the build-test-release cycle of perception-based autonomy.

</details>


### [114] [Action-to-Action Flow Matching](https://arxiv.org/abs/2602.07322)
*Jindou Jia,Gen Li,Xiangyu Chen,Tuo An,Yuxuan Hu,Jingliang Li,Xinying Guo,Jianfei Yang*

Main category: cs.RO

TL;DR: 提出A2A流匹配方法，将扩散策略从随机高斯噪声采样改为基于历史动作的初始化，显著降低推理延迟至单步0.56ms，同时提升训练效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统扩散策略需要从随机高斯噪声开始多次迭代去噪，导致推理延迟高，成为实时控制的瓶颈。本文挑战随机噪声采样的必要性，寻求更高效的策略范式。

Method: 提出Action-to-Action流匹配(A2A)，将历史本体感觉序列嵌入高维潜在空间作为动作生成的起点，绕过昂贵的迭代去噪过程，有效捕捉机器人物理动力学和时间连续性。

Result: A2A展现出高训练效率、快速推理速度和改进的泛化能力。仅需单步推理(0.56ms延迟)，对视觉扰动具有鲁棒性，对未见配置有更好的泛化。还可扩展到视频生成。

Conclusion: A2A通过利用历史动作信息作为生成起点，为机器人控制提供了一种高效、快速的策略范式，突破了传统扩散策略的推理延迟瓶颈，展示了在时序建模中的广泛适用性。

Abstract: Diffusion-based policies have recently achieved remarkable success in robotics by formulating action prediction as a conditional denoising process. However, the standard practice of sampling from random Gaussian noise often requires multiple iterative steps to produce clean actions, leading to high inference latency that incurs a major bottleneck for real-time control. In this paper, we challenge the necessity of uninformed noise sampling and propose Action-to-Action flow matching (A2A), a novel policy paradigm that shifts from random sampling to initialization informed by the previous action. Unlike existing methods that treat proprioceptive action feedback as static conditions, A2A leverages historical proprioceptive sequences, embedding them into a high-dimensional latent space as the starting point for action generation. This design bypasses costly iterative denoising while effectively capturing the robot's physical dynamics and temporal continuity. Extensive experiments demonstrate that A2A exhibits high training efficiency, fast inference speed, and improved generalization. Notably, A2A enables high-quality action generation in as few as a single inference step (0.56 ms latency), and exhibits superior robustness to visual perturbations and enhanced generalization to unseen configurations. Lastly, we also extend A2A to video generation, demonstrating its broader versatility in temporal modeling. Project site: https://lorenzo-0-0.github.io/A2A_Flow_Matching.

</details>


### [115] [Why Look at It at All?: Vision-Free Multifingered Blind Grasping Using Uniaxial Fingertip Force Sensing](https://arxiv.org/abs/2602.07326)
*Edgar Lee,Junho Choi,Taemin Kim,Changjoo Nam,Seokhwan Jeong*

Main category: cs.RO

TL;DR: 仅使用单轴指尖力反馈和关节本体感知实现多指抓取，无需视觉或多轴触觉传感，在18个物体上达到98.3%成功率


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人抓取面临传感限制挑战，视觉和高分辨率触觉传感器成本高、易碎且集成复杂。本研究旨在探索在极简传感条件下实现可靠多指抓取的可能性。

Method: 采用高效的师生训练流程：强化学习教师利用仿真特权观测生成演示，然后蒸馏出基于Transformer的学生策略，该策略仅使用真实部署时可用的传感模态（单轴指尖力反馈和关节本体感知）。

Result: 在真实硬件上验证了18个物体（包括分布内和分布外情况），总体抓取成功率达到98.3%，展示了超越仿真训练分布的强鲁棒性和泛化能力。

Conclusion: 仅凭极简传感（单轴指尖力反馈和关节本体感知）即可实现可靠的多指抓取，显著降低了现实世界抓取系统的传感需求，同时保持了高成功率和良好的泛化性能。

Abstract: Grasping under limited sensing remains a fundamental challenge for real-world robotic manipulation, as vision and high-resolution tactile sensors often introduce cost, fragility, and integration complexity. This work demonstrates that reliable multifingered grasping can be achieved under extremely minimal sensing by relying solely on uniaxial fingertip force feedback and joint proprioception, without vision or multi-axis/tactile sensing. To enable such blind grasping, we employ an efficient teacher-student training pipeline in which a reinforcement-learned teacher exploits privileged simulation-only observations to generate demonstrations for distilling a transformer-based student policy operating under partial observation. The student policy is trained to act using only sensing modalities available at real-world deployment. We validate the proposed approach on real hardware across 18 objects, including both in-distribution and out-of-distribution cases, achieving a 98.3~$\%$ overall grasp success rate. These results demonstrate strong robustness and generalization beyond the simulation training distribution, while significantly reducing sensing requirements for real-world grasping systems.

</details>


### [116] [UEREBot: Learning Safe Quadrupedal Locomotion under Unstructured Environments and High-Speed Dynamic Obstacles](https://arxiv.org/abs/2602.07363)
*Zihao Xu,Runyu Lei,Zihao Li,Boxi Lin,Ce Hao,Jin Song Dong*

Main category: cs.RO

TL;DR: UEREBot是一个分层框架，通过分离慢速规划和瞬时反射规避，协调导航与反射动作，在复杂非结构化环境中实现安全四足机器人运动


<details>
  <summary>Details</summary>
Motivation: 四足机器人在非结构化环境中部署时面临三个关键挑战：长期目标进展、不平坦地形通行性和高速动态障碍物避碰。现有单一系统无法同时满足这三个目标，规划决策太慢，而纯反应决策会牺牲目标进展和通行性

Method: 提出UEREBot分层框架：1) 将任务建模为约束最优控制问题蓝图；2) 采用时空规划器提供目标参考引导和威胁信号；3) 使用威胁感知切换将导航和反射动作融合为名义命令；4) 使用控制屏障函数屏蔽作为最终执行保障

Result: 在Isaac Lab仿真和Unitree Go2四足机器人上部署，在具有复杂静态结构和高速动态障碍物的多样化环境中，UEREBot相比基准方法实现了更高的避碰成功率、更稳定的运动，同时保持目标进展，展示了改进的安全-进展权衡

Conclusion: UEREBot通过分层协调慢速规划和瞬时反射规避，有效解决了非结构化环境中四足机器人安全运动的多目标冲突问题，实现了更好的安全性和目标进展平衡

Abstract: Quadruped robots are increasingly deployed in unstructured environments. Safe locomotion in these settings requires long-horizon goal progress, passability over uneven terrain and static constraints, and collision avoidance against high-speed dynamic obstacles. A single system cannot fully satisfy all three objectives simultaneously: planning-based decisions can be too slow, while purely reactive decisions can sacrifice goal progress and passability. To resolve this conflict, we propose UEREBot (Unstructured-Environment Reflexive Evasion Robot), a hierarchical framework that separates slow planning from instantaneous reflexive evasion and coordinates them during execution. UEREBot formulates the task as a constrained optimal control problem blueprint. It adopts a spatial--temporal planner that provides reference guidance toward the goal and threat signals. It then uses a threat-aware handoff to fuse navigation and reflex actions into a nominal command, and a control barrier function shield as a final execution safeguard. We evaluate UEREBot in Isaac Lab simulation and deploy it on a Unitree Go2 quadruped equipped with onboard perception. Across diverse environments with complex static structure and high-speed dynamic obstacles, UEREBot achieves higher avoidance success and more stable locomotion while maintaining goal progress than representative baselines, demonstrating improved safety--progress trade-offs.

</details>


### [117] [Trace-Focused Diffusion Policy for Multi-Modal Action Disambiguation in Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2602.07388)
*Yuxuan Hu,Xiangyu Chen,Chuhao Zhou,Yuxi Liu,Gen Li,Jindou Jia,Jianfei Yang*

Main category: cs.RO

TL;DR: TF-DP通过将机器人执行历史作为显式轨迹条件融入扩散策略，解决了长时程任务中的多模态动作歧义问题，在视觉干扰下提升了策略的时序一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在基于模仿学习的机器人操作中，生成模型策略通过学习演示的动作分布取得了良好性能。但在长时程任务中，视觉相似的观察可能出现在不同执行阶段却需要不同的动作，仅基于瞬时观察的条件会导致多模态动作歧义（MA2），使策略预测模糊不清。

Method: 提出了Trace-Focused Diffusion Policy (TF-DP)，这是一个简单有效的基于扩散的框架，将动作生成显式地条件于机器人的执行历史。TF-DP将历史运动表示为显式执行轨迹，并将其投影到视觉观察空间，在当前观察不足时提供阶段感知的上下文。此外，诱导的轨迹聚焦场强调与历史运动相关的任务相关区域，提高了对背景视觉干扰的鲁棒性。

Result: 在具有显著多模态动作歧义和视觉杂乱条件的真实世界机器人操作任务上评估TF-DP。实验结果显示，TF-DP在多模态动作歧义任务上比原始扩散策略提升80.56%，在视觉干扰下提升86.11%，同时仅增加6.4%的运行时间，保持了推理效率。

Conclusion: 执行轨迹条件为单策略内的鲁棒长时程机器人操作提供了一个可扩展且有原则的方法，通过历史上下文解决了动作歧义问题，提高了策略的时序一致性和对视觉干扰的鲁棒性。

Abstract: Generative model-based policies have shown strong performance in imitation-based robotic manipulation by learning action distributions from demonstrations. However, in long-horizon tasks, visually similar observations often recur across execution stages while requiring distinct actions, which leads to ambiguous predictions when policies are conditioned only on instantaneous observations, termed multi-modal action ambiguity (MA2). To address this challenge, we propose the Trace-Focused Diffusion Policy (TF-DP), a simple yet effective diffusion-based framework that explicitly conditions action generation on the robot's execution history. TF-DP represents historical motion as an explicit execution trace and projects it into the visual observation space, providing stage-aware context when current observations alone are insufficient. In addition, the induced trace-focused field emphasizes task-relevant regions associated with historical motion, improving robustness to background visual disturbances. We evaluate TF-DP on real-world robotic manipulation tasks exhibiting pronounced multi-modal action ambiguity and visually cluttered conditions. Experimental results show that TF-DP improves temporal consistency and robustness, outperforming the vanilla diffusion policy by 80.56 percent on tasks with multi-modal action ambiguity and by 86.11 percent under visual disturbances, while maintaining inference efficiency with only a 6.4 percent runtime increase. These results demonstrate that execution-trace conditioning offers a scalable and principled approach for robust long-horizon robotic manipulation within a single policy.

</details>


### [118] [Going with the Flow: Koopman Behavioral Models as Implicit Planners for Visuo-Motor Dexterity](https://arxiv.org/abs/2602.07413)
*Yunhai Han,Linhao Bai,Ziyu Xiao,Zhaodong Yang,Yogita Choudhary,Krishna Jha,Chuizheng Kong,Shreyas Kousik,Harish Ravichandar*

Main category: cs.RO

TL;DR: 提出Unified Behavioral Models (UBMs)框架，将灵巧操作技能建模为耦合动力系统，通过Koopman-UBM实现隐式规划与在线重规划，在保持时间连贯性的同时提高反应性。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散和Transformer的机器人学习方法需要大量数据和计算资源，且在多指灵巧操作中可靠性不足。这些方法将技能建模为反应性映射，依赖固定时间窗口的动作分块来减少抖动，导致时间连贯性与反应性之间的刚性权衡。

Method: 提出Unified Behavioral Models (UBMs)框架，将灵巧技能建模为耦合动力系统，捕捉环境视觉特征（视觉流）和机器人本体感知状态（动作流）的共同演化。具体实现Koopman-UBM，利用Koopman算子理论学习统一表示，使潜在视觉和本体感知特征的联合流受结构化线性系统控制。引入在线重规划策略，模型作为运行时监控器，当预测与观测的视觉流差异超过阈值时自动触发重规划。

Result: 在7个模拟任务和2个真实世界任务中，K-UBM匹配或超越了最先进基线的性能，同时提供更快的推理速度、平滑的执行、对遮挡的鲁棒性以及灵活的重规划能力。

Conclusion: UBMs框架通过将技能建模为耦合动力系统，从根本上解决了时间连贯性与反应性之间的权衡问题。Koopman-UBM作为首个实例化，展示了隐式规划和在线重规划的有效性，为灵巧操作提供了更可靠、高效的解决方案。

Abstract: There has been rapid and dramatic progress in robots' ability to learn complex visuo-motor manipulation skills from demonstrations, thanks in part to expressive policy classes that employ diffusion- and transformer-based backbones. However, these design choices require significant data and computational resources and remain far from reliable, particularly within the context of multi-fingered dexterous manipulation. Fundamentally, they model skills as reactive mappings and rely on fixed-horizon action chunking to mitigate jitter, creating a rigid trade-off between temporal coherence and reactivity. In this work, we introduce Unified Behavioral Models (UBMs), a framework that learns to represent dexterous skills as coupled dynamical systems that capture how visual features of the environment (visual flow) and proprioceptive states of the robot (action flow) co-evolve. By capturing such behavioral dynamics, UBMs can ensure temporal coherence by construction rather than by heuristic averaging. To operationalize these models, we propose Koopman-UBM, a first instantiation of UBMs that leverages Koopman Operator theory to effectively learn a unified representation in which the joint flow of latent visual and proprioceptive features is governed by a structured linear system. We demonstrate that Koopman-UBM can be viewed as an implicit planner: given an initial condition, it analytically computes the desired robot behavior while simultaneously ''imagining'' the resulting flow of visual features over the entire skill horizon. To enable reactivity and adaptation, we introduce an online replanning strategy in which the model acts as its own runtime monitor that automatically triggers replanning when predicted and observed visual flow diverge beyond a threshold. Across seven simulated tasks and two real-world tasks, we demonstrate that K-UBM matches or exceeds the performance of state-of-the-art baselines, while offering considerably faster inference, smooth execution, robustness to occlusions, and flexible replanning.

</details>


### [119] [Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots](https://arxiv.org/abs/2602.07434)
*Songhua Yang,Xuetao Li,Xuanye Fei,Mengde Li,Miao Li*

Main category: cs.RO

TL;DR: SeM²是一个基于视觉语言模型的多模态交互框架，通过感知、推理和时序对齐机制，实现语音、情感和动作的协调表达，支持云端和边缘部署。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人缺乏协调的语音、面部表情和手势表达，而现实部署需要无需持续云连接的设备端解决方案，以实现情感丰富的多模态交互。

Method: 提出SeM²框架，包含三个核心组件：多模态感知模块捕获用户上下文线索，思维链推理进行响应规划，以及新颖的语义序列对齐机制确保语言内容和物理表达的精确时序协调。

Result: 边缘部署版本SeM²_e通过知识蒸馏在边缘硬件上高效运行，保持95%的相对性能。全面评估显示，该方法在自然度、情感清晰度和模态一致性方面显著优于单模态基线。

Conclusion: SeM²框架推进了社交表达性人形机器人在多样化现实环境中的应用，实现了情感协调的多模态交互。

Abstract: Effective human-robot interaction requires emotionally rich multimodal expressions, yet most humanoid robots lack coordinated speech, facial expressions, and gestures. Meanwhile, real-world deployment demands on-device solutions that can operate autonomously without continuous cloud connectivity. To bridging \underline{\textit{S}}peech, \underline{\textit{E}}motion, and \underline{\textit{M}}otion, we present \textit{SeM$^2$}, a Vision Language Model-based framework that orchestrates emotionally coherent multimodal interactions through three key components: a multimodal perception module capturing user contextual cues, a Chain-of-Thought reasoning for response planning, and a novel Semantic-Sequence Aligning Mechanism (SSAM) that ensures precise temporal coordination between verbal content and physical expressions. We implement both cloud-based and \underline{\textit{e}}dge-deployed versions (\textit{SeM$^2_e$}), with the latter knowledge distilled to operate efficiently on edge hardware while maintaining 95\% of the relative performance. Comprehensive evaluations demonstrate that our approach significantly outperforms unimodal baselines in naturalness, emotional clarity, and modal coherence, advancing socially expressive humanoid robotics for diverse real-world environments.

</details>


### [120] [TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control](https://arxiv.org/abs/2602.07439)
*Weiji Xie,Jiakun Zheng,Jinrui Han,Jiyuan Shi,Weinan Zhang,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: TextOp是一个实时文本驱动的人形机器人运动生成与控制框架，支持流式语言命令和实时指令修改，通过两级架构实现交互式运动生成与鲁棒全身控制。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制器要么依赖预定义运动轨迹（灵活性有限），要么需要持续人工遥操作（自主性受限），需要一种实时交互的驱动方式。

Method: 采用两级架构：高层自回归运动扩散模型根据当前文本输入连续生成短时运动轨迹，低层运动跟踪策略在物理机器人上执行这些轨迹。

Result: 实验证明系统具有即时响应性、流畅的全身运动和精确控制能力，能够实现跳舞、跳跃等多种挑战性行为的平滑过渡。

Conclusion: TextOp通过将交互式运动生成与鲁棒全身控制相结合，实现了自由形式的意图表达，为人形机器人提供了实时文本驱动的交互控制解决方案。

Abstract: Recent advances in humanoid whole-body motion tracking have enabled the execution of diverse and highly coordinated motions on real hardware. However, existing controllers are commonly driven either by predefined motion trajectories, which offer limited flexibility when user intent changes, or by continuous human teleoperation, which requires constant human involvement and limits autonomy. This work addresses the problem of how to drive a universal humanoid controller in a real-time and interactive manner. We present TextOp, a real-time text-driven humanoid motion generation and control framework that supports streaming language commands and on-the-fly instruction modification during execution. TextOp adopts a two-level architecture in which a high-level autoregressive motion diffusion model continuously generates short-horizon kinematic trajectories conditioned on the current text input, while a low-level motion tracking policy executes these trajectories on a physical humanoid robot. By bridging interactive motion generation with robust whole-body control, TextOp unlocks free-form intent expression and enables smooth transitions across multiple challenging behaviors such as dancing and jumping, within a single continuous motion execution. Extensive real-robot experiments and offline evaluations demonstrate instant responsiveness, smooth whole-body motion, and precise control. The project page and the open-source code are available at https://text-op.github.io/

</details>


### [121] [VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots](https://arxiv.org/abs/2602.07506)
*Peizhen Li,Longbing Cao,Xiao-Ming Wu,Yang Zhang*

Main category: cs.RO

TL;DR: VividFace是一个实时逼真的人形机器人面部表情模仿系统，能在0.05秒内模仿人类面部表情，通过优化的X2CNet++框架和异步I/O流程实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人面部表情模仿系统存在局限性，要么无法实现实时性能，要么表达不够逼真，主要受限于离线视频推理设计和捕捉细微表情细节能力不足。

Method: 提出VividFace系统，包含优化的X2CNet++模仿框架，通过微调人-机器人面部运动转换模块和引入特征适应训练策略来增强表达力；采用视频流兼容的推理管道和基于异步I/O的简化工作流程实现实时性能。

Result: 系统能在0.05秒内模仿人类面部表情，能够泛化到不同的面部配置，并通过大量实际演示验证了其实用性。

Conclusion: VividFace实现了实时逼真的人形机器人面部表情模仿，为人形机器人和情感人机交互提供了重要技术支持。

Abstract: Humanoid facial expression shadowing enables robots to realistically imitate human facial expressions in real time, which is critical for lifelike, facially expressive humanoid robots and affective human-robot interaction. Existing progress in humanoid facial expression imitation remains limited, often failing to achieve either real-time performance or realistic expressiveness due to offline video-based inference designs and insufficient ability to capture and transfer subtle expression details. To address these limitations, we present VividFace, a real-time and realistic facial expression shadowing system for humanoid robots. An optimized imitation framework X2CNet++ enhances expressiveness by fine-tuning the human-to-humanoid facial motion transfer module and introducing a feature-adaptation training strategy for better alignment across different image sources. Real-time shadowing is further enabled by a video-stream-compatible inference pipeline and a streamlined workflow based on asynchronous I/O for efficient communication across devices. VividFace produces vivid humanoid faces by mimicking human facial expressions within 0.05 seconds, while generalizing across diverse facial configurations. Extensive real-world demonstrations validate its practical utility. Videos are available at: https://lipzh5.github.io/VividFace/.

</details>


### [122] [Differentiate-and-Inject: Enhancing VLAs via Functional Differentiation Induced by In-Parameter Structural Reasoning](https://arxiv.org/abs/2602.07541)
*Jingyi Hou,Leyu Zhou,Chenchen Jing,Jinghan Yang,Xinbo Yu,Wei He*

Main category: cs.RO

TL;DR: iSTAR框架通过在参数空间中嵌入任务级语义结构，增强VLA模型的任务推理能力，实现更可靠的任务分解和泛化


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在任务级推理方面存在不足：基于提示的上下文分解不稳定且对语言变化敏感，而端到端长时程训练需要大规模演示且将任务推理与低级控制耦合

Method: iSTAR框架通过参数空间结构化推理实现功能分化，将任务级语义结构（如对象关系、子任务语义和任务依赖）以隐式动态场景图知识形式嵌入模型参数

Result: 在多样化操作基准测试中，iSTAR比上下文和端到端VLA基线实现了更可靠的任务分解和更高的成功率

Conclusion: 参数空间结构化推理能有效实现功能分化，提高VLA模型在任务变化中的泛化能力

Abstract: As robots are expected to perform increasingly diverse tasks, they must understand not only low-level actions but also the higher-level structure that determines how a task should unfold. Existing vision-language-action (VLA) models struggle with this form of task-level reasoning. They either depend on prompt-based in-context decomposition, which is unstable and sensitive to linguistic variations, or end-to-end long-horizon training, which requires large-scale demonstrations and entangles task-level reasoning with low-level control. We present in-parameter structured task reasoning (iSTAR), a framework for enhancing VLA models via functional differentiation induced by in-parameter structural reasoning. Instead of treating VLAs as monolithic policies, iSTAR embeds task-level semantic structure directly into model parameters, enabling differentiated task-level inference without external planners or handcrafted prompt inputs. This injected structure takes the form of implicit dynamic scene-graph knowledge that captures object relations, subtask semantics, and task-level dependencies in parameter space. Across diverse manipulation benchmarks, iSTAR achieves more reliable task decompositions and higher success rates than both in-context and end-to-end VLA baselines, demonstrating the effectiveness of parameter-space structural reasoning for functional differentiation and improved generalization across task variations.

</details>


### [123] ["Meet My Sidekick!": Effects of Separate Identities and Control of a Single Robot in HRI](https://arxiv.org/abs/2602.07598)
*Drake Moore,Arushi Aggarwal,Emily Taylor,Sarah Zhang,Taskin Padir,Xiang Zhi Tan*

Main category: cs.RO

TL;DR: 研究探讨机器人不同控制域（头部和夹爪）被呈现为独立机器人时用户的感知，发现用户能将机器人故障与不同身份关联，为单机器人实现多机器人优势提供新思路。


<details>
  <summary>Details</summary>
Motivation: 机器人的能力和身份呈现直接影响人类合作者的感知和隐性信任。与人类不同，物理机器人可以同时呈现不同身份，并让这些身份驻留和控制机器人的不同部分。本研究旨在探索用户如何感知一个机器人，其中不同的控制域被呈现为独立的机器人。

Method: 采用混合设计研究，参与者体验三种呈现方式之一：单个机器人、共享完全控制的两个代理（共体现）、或跨机器人控制域分割控制的两个代理（分割体现）。参与者完成三项任务：机器人提供激励支持的日常数据录入任务、机器人单独故障的个体分类任务、以及机器人故障直接影响参与者的协作布置任务。

Result: 参与者能够感知机器人驻留在不同的控制域中，并能将机器人故障与不同身份关联起来。这表明用户确实将机器人的不同部分视为具有独立身份的实体。

Conclusion: 这项工作展示了未来机器人如何利用不同的体现配置，在单个身体内获得多个机器人的优势。通过将不同控制域呈现为独立身份，机器人可以更有效地管理人类合作者的感知和信任。

Abstract: The presentation of a robot's capability and identity directly influences a human collaborator's perception and implicit trust in the robot. Unlike humans, a physical robot can simultaneously present different identities and have them reside and control different parts of the robot. This paper presents a novel study that investigates how users perceive a robot where different robot control domains (head and gripper) are presented as independent robots. We conducted a mixed design study where participants experienced one of three presentations: a single robot, two agents with shared full control (co-embodiment), or two agents with split control across robot control domains (split-embodiment). Participants underwent three distinct tasks -- a mundane data entry task where the robot provides motivational support, an individual sorting task with isolated robot failures, and a collaborative arrangement task where the robot causes a failure that directly affects the human participant. Participants perceived the robot as residing in the different control domains and were able to associate robot failure with different identities. This work signals how future robots can leverage different embodiment configurations to obtain the benefit of multiple robots within a single body.

</details>


### [124] [LCLA: Language-Conditioned Latent Alignment for Vision-Language Navigation](https://arxiv.org/abs/2602.07629)
*Nitesh Subedi,Adam Haroon,Samuel Tetteh,Prajwal Koirala,Cody Fleming,Soumik Sarkar*

Main category: cs.RO

TL;DR: LCLA是一个视觉语言导航框架，通过将感知与专家策略的潜在空间对齐，实现模块化的感知-动作接口，从而获得强大的泛化能力和轻量级推理。


<details>
  <summary>Details</summary>
Motivation: 为了解决视觉语言导航中端到端策略优化的困难，以及实现感知与控制模块的解耦，使专家行为能够在不同感知模态和环境变化中复用。

Method: 首先用特权状态信息训练专家策略，获得足够控制的潜在空间；然后冻结专家的潜在接口和动作头；最后训练轻量级适配器，将原始视觉语言观测通过冻结的视觉语言模型映射到专家的潜在空间。

Result: 在室内视觉语言导航任务中，LCLA展现出强大的分布内性能，以及对未见环境、光照条件和视角的零样本泛化能力，同时保持推理时的轻量级特性。

Conclusion: LCLA通过将视觉运动学习简化为监督潜在对齐而非端到端策略优化，实现了感知与控制的稳定契约，为跨模态和环境的鲁棒导航提供了有效框架。

Abstract: We propose LCLA (Language-Conditioned Latent Alignment), a framework for vision-language navigation that learns modular perception-action interfaces by aligning sensory observations to a latent representation of an expert policy. The expert is first trained with privileged state information, inducing a latent space sufficient for control, after which its latent interface and action head are frozen. A lightweight adapter is then trained to map raw visual-language observations, via a frozen vision-language model, into the expert's latent space, reducing the problem of visuomotor learning to supervised latent alignment rather than end-to-end policy optimization. This decoupling enforces a stable contract between perception and control, enabling expert behavior to be reused across sensing modalities and environmental variations. We instantiate LCLA and evaluate it on a vision-language indoor navigation task, where aligned latent spaces yield strong in-distribution performance and robust zero-shot generalization to unseen environments, lighting conditions, and viewpoints while remaining lightweight at inference time.

</details>


### [125] [Affine Transformable Unmanned Ground Vehicle](https://arxiv.org/abs/2602.07677)
*Aron Mathias,Mohammad Ghufran,Jack Hughes,Hossein Rastgoftar*

Main category: cs.RO

TL;DR: 提出一种新型仿射可变形无人地面车辆(ATUGV)，能够在携带多个有效载荷的同时实现安全且激进的变形。该系统通过深度神经网络设计单元互连结构，使所有单元能自由移动并跟踪期望的仿射变换。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够安全且激进地变形，同时携带多个有效载荷的无人地面车辆。传统无人地面车辆通常具有固定结构，难以适应复杂地形或任务需求。ATUGV通过仿射变换能力，能够在执行任务时动态调整形态，提高适应性和功能性。

Method: 1. 设计多体系统：包含移动机器人（提供动力）、动力单元（容纳移动机器人）、非动力单元（容纳有效载荷）以及通过杆件和关节连接的可变形结构。2. 使用深度神经网络设计单元互连结构，使每个单元能在变形平面上自由移动，整个结构可重构变形以跟踪期望的仿射变换。3. 通过移动机器人（由动力单元容纳）和步进电机（调节动力和非动力单元连接）设计适当控制，使所有单元安全跟踪期望的仿射变换。

Result: 通过硬件实验和仿真验证了所提出ATUGV的功能性。系统能够实现安全且激进的变形，同时携带多个有效载荷，并成功跟踪期望的仿射变换（包括平移、刚体旋转和变形）。

Conclusion: 成功开发了一种新型仿射可变形无人地面车辆的概念验证，该系统能够在携带多个有效载荷的同时实现安全且激进的变形。通过深度神经网络设计的互连结构和适当的控制策略，系统能够有效跟踪期望的仿射变换，为未来可变形机器人系统提供了新的设计思路。

Abstract: This paper develops the proof of concept for a novel affine transformable unmanned ground vehicle (ATUGV) with the capability of safe and aggressive deformation while carrying multiple payloads. The ATUGV is a multi-body system with mobile robots that can be used to power the ATUGV morphable motion, powered cells to enclose the mobile robots, unpowered cells to contain payloads, and a deformable structure to integrate cells through bars and joints. The objective is that all powered and unpowered cells motion can safely track a desired affine transformation, where an affine transformation can be decomposed into translation, rigid body rotation, and deformation. To this end, the paper first uses a deep neural network to structure cell interconnection in such a way that every cell can freely move over the deformation plane, and the entire structure can reconfigurably deform to track a desired affine transformation. Then, the mobile robots, contained by the powered cells and stepper motors, regulating the connections of the powered and unpowered cells, design the proper controls so that all cells safely track the desired affine transformation. The functionality of the proposed ATUGV is validated through hardware experimentation and simulation.

</details>


### [126] [Global Symmetry and Orthogonal Transformations from Geometrical Moment $n$-tuples](https://arxiv.org/abs/2602.07736)
*Omar Tahri*

Main category: cs.RO

TL;DR: 该论文提出使用几何矩检测物体对称性并估计正交变换（旋转和镜像），开发了n维空间的矩n元组方法，在2D和3D物体上验证有效，与迭代优化方法结合可提高对称面检测效果。


<details>
  <summary>Details</summary>
Motivation: 检测对称性对于物体抓取至关重要，因为识别物体的对称特征或轴线有助于制定高效的抓取策略，沿这些轴线抓取通常能获得更稳定平衡的握持，从而促进成功的操作。

Method: 采用几何矩识别对称性并估计正交变换（包括旋转和镜像变换），为以坐标系原点为中心的物体开发了检测对称性和估计正交变换的独特度量方法，建立了在n维空间中获取矩n元组的综合方法。

Result: 在2D和3D物体上进行了广泛的验证测试，证明了所提方法的鲁棒性和可靠性。与使用迭代优化检测多个对称面的最先进方法相比，将本文方法与迭代方法结合在检测对称面数量和计算时间方面都能获得满意结果。

Conclusion: 几何矩方法能有效检测物体对称性并估计正交变换，与迭代优化方法结合可提高对称面检测性能，为物体抓取等应用提供了实用的对称性分析工具。

Abstract: Detecting symmetry is crucial for effective object grasping for several reasons. Recognizing symmetrical features or axes within an object helps in developing efficient grasp strategies, as grasping along these axes typically results in a more stable and balanced grip, thereby facilitating successful manipulation. This paper employs geometrical moments to identify symmetries and estimate orthogonal transformations, including rotations and mirror transformations, for objects centered at the frame origin. It provides distinctive metrics for detecting symmetries and estimating orthogonal transformations, encompassing rotations, reflections, and their combinations. A comprehensive methodology is developed to obtain these functions in n-dimensional space, specifically moment \( n \)-tuples. Extensive validation tests are conducted on both 2D and 3D objects to ensure the robustness and reliability of the proposed approach. The proposed method is also compared to state-of-the-art work using iterative optimization for detecting multiple planes of symmetry. The results indicate that combining our method with the iterative one yields satisfactory outcomes in terms of the number of symmetry planes detected and computation time.

</details>


### [127] [CoLF: Learning Consistent Leader-Follower Policies for Vision-Language-Guided Multi-Robot Cooperative Transport](https://arxiv.org/abs/2602.07776)
*Joachim Yann Despature,Kazuki Shibata,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出CoLF框架解决多机器人协作运输中的感知对齐问题，通过非对称策略设计和互信息最大化实现稳定的领导者-跟随者角色分化


<details>
  <summary>Details</summary>
Motivation: 解决视觉-语言引导的多机器人协作运输中的感知错位问题，由于视角差异和语言歧义导致机器人解释不一致，影响协作运输效果

Method: 提出CoLF多智能体强化学习框架：1) 非对称策略设计诱导领导者-跟随者角色分化；2) 基于互信息的训练目标最大化变分下界，使跟随者能从本地观察预测领导者动作；采用CTDE框架联合优化策略

Result: 在仿真和真实四足机器人实验中验证了CoLF的有效性，实现了稳定的领导者-跟随者角色分化和协作运输

Conclusion: CoLF框架通过非对称策略设计和互信息最大化成功解决了多机器人协作运输中的感知对齐问题，实现了稳定的角色分化和有效协作

Abstract: In this study, we address vision-language-guided multi-robot cooperative transport, where each robot grounds natural-language instructions from onboard camera observations. A key challenge in this decentralized setting is perceptual misalignment across robots, where viewpoint differences and language ambiguity can yield inconsistent interpretations and degrade cooperative transport. To mitigate this problem, we adopt a dependent leader-follower design, where one robot serves as the leader and the other as the follower. Although such a leader-follower structure appears straightforward, learning with independent and symmetric agents often yields symmetric or unstable behaviors without explicit inductive biases. To address this challenge, we propose Consistent Leader-Follower (CoLF), a multi-agent reinforcement learning (MARL) framework for stable leader-follower role differentiation. CoLF consists of two key components: (1) an asymmetric policy design that induces leader-follower role differentiation, and (2) a mutual-information-based training objective that maximizes a variational lower bound, encouraging the follower to predict the leader's action from its local observation. The leader and follower policies are jointly optimized under the centralized training and decentralized execution (CTDE) framework to balance task execution and consistent cooperative behaviors. We validate CoLF in both simulation and real-robot experiments using two quadruped robots. The demonstration video is available at https://sites.google.com/view/colf/.

</details>


### [128] [RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI](https://arxiv.org/abs/2602.07837)
*Hongzhi Zang,Shu'ang Yu,Hao Lin,Tianxing Zhou,Zefang Huang,Zhen Guo,Xin Xu,Jiakai Zhou,Yuze Sheng,Shizhe Zhang,Feng Gao,Wenhao Tang,Yufeng Yue,Quanlu Zhang,Xinlei Chen,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: USER是一个用于现实世界在线策略学习的统一可扩展系统，通过硬件抽象层将物理机器人视为GPU级别的硬件资源，支持异构机器人自动发现、管理和调度，并提供异步学习框架和可扩展的算法抽象。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的在线策略学习面临三大挑战：1）无法像仿真环境那样加速、重置或大规模复制；2）难以进行可扩展的数据收集、异构部署和长时程有效训练；3）这不仅是算法问题，更是系统架构问题。因此需要专门为现实世界设计的系统解决方案。

Method: 1）硬件抽象层：将物理机器人视为与GPU同等的硬件资源，支持自动发现、管理和调度；2）自适应通信平面：基于隧道的网络、分布式数据通道和流式多处理器感知的权重同步；3）完全异步学习框架：包含持久化缓存感知缓冲区，支持崩溃恢复和历史数据重用；4）可扩展抽象：奖励、算法和策略的模块化设计，支持CNN/MLP、生成策略和大视觉语言动作模型的在线模仿或强化学习。

Result: 在仿真和现实世界中的实验表明，USER能够支持：1）多机器人协调；2）异构机械臂协作；3）边缘-云端大模型协作；4）长时间运行的异步训练。系统为现实世界在线策略学习提供了统一且可扩展的基础设施。

Conclusion: USER成功地将现实世界在线策略学习从单纯的算法问题转变为系统架构问题，通过统一的硬件抽象、自适应通信和异步学习框架，为解决现实世界机器人学习的可扩展性、异构性和长时程训练挑战提供了有效的系统解决方案。

Abstract: Online policy learning directly in the physical world is a promising yet challenging direction for embodied intelligence. Unlike simulation, real-world systems cannot be arbitrarily accelerated, cheaply reset, or massively replicated, which makes scalable data collection, heterogeneous deployment, and long-horizon effective training difficult. These challenges suggest that real-world policy learning is not only an algorithmic issue but fundamentally a systems problem. We present USER, a Unified and extensible SystEm for Real-world online policy learning. USER treats physical robots as first-class hardware resources alongside GPUs through a unified hardware abstraction layer, enabling automatic discovery, management, and scheduling of heterogeneous robots. To address cloud-edge communication, USER introduces an adaptive communication plane with tunneling-based networking, distributed data channels for traffic localization, and streaming-multiprocessor-aware weight synchronization to regulate GPU-side overhead. On top of this infrastructure, USER organizes learning as a fully asynchronous framework with a persistent, cache-aware buffer, enabling efficient long-horizon experiments with robust crash recovery and reuse of historical data. In addition, USER provides extensible abstractions for rewards, algorithms, and policies, supporting online imitation or reinforcement learning of CNN/MLP, generative policies, and large vision-language-action (VLA) models within a unified pipeline. Results in both simulation and the real world show that USER enables multi-robot coordination, heterogeneous manipulators, edge-cloud collaboration with large models, and long-running asynchronous training, offering a unified and extensible systems foundation for real-world online policy learning.

</details>


### [129] [Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning](https://arxiv.org/abs/2602.07845)
*Yalcin Tur,Jalal Naghiyev,Haoquan Fang,Wei-Chuan Tsai,Jiafei Duan,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: RD-VLA通过循环深度架构实现计算自适应，用潜在迭代优化替代显式token生成，在恒定内存下支持任意推理深度，显著提升机器人操作任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型采用固定计算深度，对简单调整和复杂多步操作都使用相同计算量，效率低下。虽然CoT提示可以实现可变计算，但内存线性增长且不适合连续动作空间。

Method: 提出循环深度VLA架构，采用权重绑定的循环动作头，通过潜在迭代优化实现计算自适应。使用截断时间反向传播训练，推理时基于潜在收敛的自适应停止准则动态分配计算。

Result: 在挑战性操作任务中，单次迭代失败的任务（0%成功率）在4次迭代后超过90%成功率，简单任务快速饱和。相比之前基于推理的VLA模型，内存使用恒定且推理速度提升达80倍。

Conclusion: RD-VLA为机器人测试时计算提供了可扩展路径，用潜在推理替代token推理，实现恒定内存使用和显著推理加速，是计算自适应VLA模型的重要进展。

Abstract: Current Vision-Language-Action (VLA) models rely on fixed computational depth, expending the same amount of compute on simple adjustments and complex multi-step manipulation. While Chain-of-Thought (CoT) prompting enables variable computation, it scales memory linearly and is ill-suited for continuous action spaces. We introduce Recurrent-Depth VLA (RD-VLA), an architecture that achieves computational adaptivity via latent iterative refinement rather than explicit token generation. RD-VLA employs a recurrent, weight-tied action head that supports arbitrary inference depth with a constant memory footprint. The model is trained using truncated backpropagation through time (TBPTT) to efficiently supervise the refinement process. At inference, RD-VLA dynamically allocates compute using an adaptive stopping criterion based on latent convergence. Experiments on challenging manipulation tasks show that recurrent depth is critical: tasks that fail entirely (0 percent success) with single-iteration inference exceed 90 percent success with four iterations, while simpler tasks saturate rapidly. RD-VLA provides a scalable path to test-time compute in robotics, replacing token-based reasoning with latent reasoning to achieve constant memory usage and up to 80x inference speedup over prior reasoning-based VLA models. Project page: https://rd-vla.github.io/

</details>


### [130] [System-Level Error Propagation and Tail-Risk Amplification in Reference-Based Robotic Navigation](https://arxiv.org/abs/2602.07846)
*Ning Hu,Maochen Li,Senhao Cao*

Main category: cs.RO

TL;DR: 本文研究了X射线引导机器人导航系统中安装误差通过多级几何感知链传播放大的系统级失效机制，提出了统一的误差传播建模框架，发现旋转安装误差是系统级误差放大的主要驱动因素。


<details>
  <summary>Details</summary>
Motivation: 传统基于参考的几何感知管道在双平面X射线导航中广泛应用，但系统级可靠性受到安装引起的结构扰动在感知-重建执行链中逐步放大并主导执行级误差和尾部风险行为的限制，这一机制尚未被充分研究。

Method: 提出统一的误差传播建模框架，通过一阶解析不确定性传播和蒙特卡洛模拟，分析安装引起的结构扰动如何通过双平面成像、投影矩阵估计、三角测量和坐标映射传播并与像素级观测噪声耦合，识别主导敏感性通道并量化最坏情况误差行为。

Result: 旋转安装误差是系统级误差放大的主要驱动因素，而同等量级的平移错位在典型双平面几何中起次要作用；真实双平面X射线实验证实预测的放大趋势在实际成像条件下仍然存在。

Conclusion: 研究揭示了基于参考的多级几何感知管道更广泛的结构局限性，为安全关键机器人导航系统的系统级可靠性分析和风险感知设计提供了框架。

Abstract: Image guided robotic navigation systems often rely on reference based geometric perception pipelines, where accurate spatial mapping is established through multi stage estimation processes. In biplanar X ray guided navigation, such pipelines are widely used due to their real time capability and geometric interpretability. However, navigation reliability can be constrained by an overlooked system level failure mechanism in which installation induced structural perturbations introduced at the perception stage are progressively amplified along the perception reconstruction execution chain and dominate execution level error and tail risk behavior. This paper investigates this mechanism from a system level perspective and presents a unified error propagation modeling framework that characterizes how installation induced structural perturbations propagate and couple with pixel level observation noise through biplanar imaging, projection matrix estimation, triangulation, and coordinate mapping. Using first order analytic uncertainty propagation and Monte Carlo simulations, we analyze dominant sensitivity channels and quantify worst case error behavior beyond mean accuracy metrics. The results show that rotational installation error is a primary driver of system level error amplification, while translational misalignment of comparable magnitude plays a secondary role under typical biplanar geometries. Real biplanar X ray bench top experiments further confirm that the predicted amplification trends persist under realistic imaging conditions. These findings reveal a broader structural limitation of reference based multi stage geometric perception pipelines and provide a framework for system level reliability analysis and risk aware design in safety critical robotic navigation systems.

</details>


### [131] [Research on a Camera Position Measurement Method based on a Parallel Perspective Error Transfer Model](https://arxiv.org/abs/2602.07888)
*Ning Hu,Shuai Li,Jindong Tan*

Main category: cs.RO

TL;DR: 提出一种基于平行透视近似的相机位姿估计几何误差传播框架，通过显式建模图像测量误差在透视几何中的传播，提高近场场景下的位姿估计鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 近场场景中强烈的透视效应和异构测量噪声会显著降低传统PnP（Perspective-n-Point）解析解的稳定性，需要更鲁棒的位姿估计方法。

Method: 1. 建立基于平行透视近似的几何误差传播框架；2. 推导误差传递模型，描述特征点分布、相机深度与位姿估计不确定性的关系；3. 开发结合平行透视初始化和误差感知加权的Gauss-Newton优化方法。

Result: 在合成数据和真实图像（强光照、手术照明、水下低光等多样条件）上的实验表明，该方法在保持高计算效率的同时，达到了与最先进解析和迭代PnP方法相当的精度和鲁棒性。

Conclusion: 显式几何误差建模对于挑战性近场设置中的可靠相机位姿估计至关重要，提出的框架在近场操作中提供了改进的鲁棒性。

Abstract: Camera pose estimation from sparse correspondences is a fundamental problem in geometric computer vision and remains particularly challenging in near-field scenarios, where strong perspective effects and heterogeneous measurement noise can significantly degrade the stability of analytic PnP solutions. In this paper, we present a geometric error propagation framework for camera pose estimation based on a parallel perspective approximation. By explicitly modeling how image measurement errors propagate through perspective geometry, we derive an error transfer model that characterizes the relationship between feature point distribution, camera depth, and pose estimation uncertainty. Building on this analysis, we develop a pose estimation method that leverages parallel perspective initialization and error-aware weighting within a Gauss-Newton optimization scheme, leading to improved robustness in proximity operations. Extensive experiments on both synthetic data and real-world images, covering diverse conditions such as strong illumination, surgical lighting, and underwater low-light environments, demonstrate that the proposed approach achieves accuracy and robustness comparable to state-of-the-art analytic and iterative PnP methods, while maintaining high computational efficiency. These results highlight the importance of explicit geometric error modeling for reliable camera pose estimation in challenging near-field settings.

</details>


### [132] [Incremental Mapping with Measurement Synchronization & Compression](https://arxiv.org/abs/2602.07901)
*Mark Griguletskii,Danil Belov,Pavel Osinenko*

Main category: cs.RO

TL;DR: 提出一种增量构建连接因子图的新方法，通过优化图拓扑选择，在保持地图质量的同时将节点数量减少约30%


<details>
  <summary>Details</summary>
Motivation: 传统因子图方法采用固定图结构，在多传感器异步数据系统中效率低下，难以实现最优状态估计

Method: 增量构建连接因子图，基于外部评估标准选择最优图拓扑，确保融合所有可用传感器数据

Result: 实现图压缩，平均减少约30%的节点数量，同时保持与传统方法相当的地图质量

Conclusion: 该方法解决了多传感器异步系统中的因子图拓扑优化问题，提高了状态估计效率

Abstract: Modern autonomous vehicles and robots utilize versatile sensors for localization and mapping. The fidelity of these maps is paramount, as an accurate environmental representation is a prerequisite for stable and precise localization. Factor graphs provide a powerful approach for sensor fusion, enabling the estimation of the maximum a posteriori solution. However, the discrete nature of graph-based representations, combined with asynchronous sensor measurements, complicates consistent state estimation. The design of an optimal factor graph topology remains an open challenge, especially in multi-sensor systems with asynchronous data. Conventional approaches rely on a rigid graph structure, which becomes inefficient with sensors of disparate rates. Although preintegration techniques can mitigate this for high-rate sensors, their applicability is limited. To address this problem, this work introduces a novel approach that incrementally constructs connected factor graphs, ensuring the incorporation of all available sensor data by choosing the optimal graph topology based on the external evaluation criteria. The proposed methodology facilitates graph compression, reducing the number of nodes (optimized variables) by ~30% on average while maintaining map quality at a level comparable to conventional approaches.

</details>


### [133] [Multi-Agent Route Planning as a QUBO Problem](https://arxiv.org/abs/2602.07913)
*Renáta Rusnáková,Martin Chovanec,Juraj Gazda*

Main category: cs.RO

TL;DR: 该论文研究了多智能体路径规划问题，通过QUBO公式化，使用经典和量子求解器优化路径覆盖与重叠的权衡。


<details>
  <summary>Details</summary>
Motivation: 在多智能体路径规划中，需要选择车辆及其预定义路径，以增加道路网络的空间覆盖，同时限制冗余重叠。现有方法需要平衡覆盖范围和重叠惩罚之间的权衡。

Method: 1. 形式化问题定义并证明NP难性；2. 推导QUBO公式，直接编码唯一覆盖奖励和成对重叠惩罚；3. 建立城市实例生成、候选路径构建、QUBO矩阵构建的完整流程；4. 使用Gurobi（精确混合整数求解器）、模拟退火和D-Wave混合量子退火三种方法求解。

Result: 在巴塞罗那实例（最多10000辆车）上的实验显示：1. 存在清晰的覆盖-重叠拐点；2. 帕累托最优解主要在硬惩罚机制下获得；3. D-Wave混合求解器和Gurobi在目标值上基本一致，仅运行时间有微小差异。

Conclusion: 该研究提出了一个完整的多智能体路径规划框架，通过QUBO公式化实现了覆盖与重叠的权衡控制，证明了量子退火在解决此类组合优化问题上的潜力，与经典求解器性能相当。

Abstract: Multi-Agent Route Planning considers selecting vehicles, each associated with a single predefined route, such that the spatial coverage of a road network is increased while redundant overlaps are limited. This paper gives a formal problem definition, proves NP-hardness by reduction from the Weighted Set Packing problem, and derives a Quadratic Unconstrained Binary Optimization formulation whose coefficients directly encode unique coverage rewards and pairwise overlap penalties. A single penalty parameter controls the coverage-overlap trade-off. We distinguish between a soft regime, which supports multi-objective exploration, and a hard regime, in which the penalty is strong enough to effectively enforce near-disjoint routes. We describe a practical pipeline for generating city instances, constructing candidate routes, building the QUBO matrix, and solving it with an exact mixed-integer solver (Gurobi), simulated annealing, and D-Wave hybrid quantum annealing. Experiments on Barcelona instances with up to 10 000 vehicles reveal a clear coverage-overlap knee and show that Pareto-optimal solutions are mainly obtained under the hard-penalty regime, while D-Wave hybrid solvers and Gurobi achieve essentially identical objective values with only minor differences in runtime as problem size grows.

</details>


### [134] [Optimized Human-Robot Co-Dispatch Planning for Petro-Site Surveillance under Varying Criticalities](https://arxiv.org/abs/2602.07924)
*Nur Ahmad Khatim,Mansur Arief*

Main category: cs.RO

TL;DR: 本文提出了HRCD-FLP问题，将人机协同调度纳入设施选址模型，通过分层基础设施关键性、人机监督比例约束和最低利用率要求，优化石油基础设施安全部署成本与可靠性。


<details>
  <summary>Details</summary>
Motivation: 保护石油基础设施需要在自主系统效率和人类判断威胁升级之间取得平衡，传统设施选址模型假设同质资源无法解决这一挑战。

Method: 提出HRCD-FLP（人机协同调度设施选址问题），包含分层基础设施关键性、人机监督比例约束和最低利用率要求，评估三种技术成熟度场景下的指挥中心选择。

Result: 从保守（1:3人机监督）过渡到未来自主操作（1:10）可显著降低成本同时保持关键基础设施全覆盖；小问题精确方法占优，大问题启发式算法3分钟内获得可行解，最优性差距约14%。

Conclusion: 优化人机团队规划是实现成本效益和任务可靠部署的关键，从系统视角展示了人机协同调度的重要性。

Abstract: Securing petroleum infrastructure requires balancing autonomous system efficiency with human judgment for threat escalation, a challenge unaddressed by classical facility location models assuming homogeneous resources. This paper formulates the Human-Robot Co-Dispatch Facility Location Problem (HRCD-FLP), a capacitated facility location variant incorporating tiered infrastructure criticality, human-robot supervision ratio constraints, and minimum utilization requirements. We evaluate command center selection across three technology maturity scenarios. Results show transitioning from conservative (1:3 human-robot supervision) to future autonomous operations (1:10) yields significant cost reduction while maintaining complete critical infrastructure coverage. For small problems, exact methods dominate in both cost and computation time; for larger problems, the proposed heuristic achieves feasible solutions in under 3 minutes with approximately 14% optimality gap where comparison is possible. From systems perspective, our work demonstrate that optimized planning for human-robot teaming is key to achieve both cost-effective and mission-reliable deployments.

</details>


### [135] [Feasibility-Guided Planning over Multi-Specialized Locomotion Policies](https://arxiv.org/abs/2602.07932)
*Ying-Sheng Luo,Lu-Ching Wang,Hanjaya Mandala,Yu-Lun Chou,Guilherme Christmann,Yu-Chung Chen,Yung-Shun Chan,Chun-Yi Lee,Wei-Chao Chen*

Main category: cs.RO

TL;DR: 提出可行性引导规划框架，将多个地形专用策略与可行性预测网络结合，使传统规划算法能在复杂地形上生成可靠路径


<details>
  <summary>Details</summary>
Motivation: 足式机器人在非结构化地形上的规划是一个重大挑战。现有方法存在局限：传统规划器无法整合技能专用策略，而分层学习框架通常失去可解释性且添加新策略时需要重新训练

Method: 提出可行性引导规划框架，为每个地形专用策略配备Feasibility-Net网络，该网络学习基于局部高程图和任务向量预测可行性张量，从而让经典规划算法能够推导最优路径

Result: 通过仿真和真实世界实验验证，该方法能高效生成跨多样挑战性地形的可靠规划，且始终与底层策略的能力保持一致

Conclusion: 该框架成功整合了多个地形专用策略，解决了现有方法的限制，为足式机器人在复杂地形上的规划提供了有效解决方案

Abstract: Planning over unstructured terrain presents a significant challenge in the field of legged robotics. Although recent works in reinforcement learning have yielded various locomotion strategies, planning over multiple experts remains a complex issue. Existing approaches encounter several constraints: traditional planners are unable to integrate skill-specific policies, whereas hierarchical learning frameworks often lose interpretability and require retraining whenever new policies are added. In this paper, we propose a feasibility-guided planning framework that successfully incorporates multiple terrain-specific policies. Each policy is paired with a Feasibility-Net, which learned to predict feasibility tensors based on the local elevation maps and task vectors. This integration allows classical planning algorithms to derive optimal paths. Through both simulated and real-world experiments, we demonstrate that our method efficiently generates reliable plans across diverse and challenging terrains, while consistently aligning with the capabilities of the underlying policies.

</details>


### [136] [Analyzing the Impact of Simulation Fidelity on the Evaluation of Autonomous Driving Motion Control](https://arxiv.org/abs/2602.07984)
*Simon Sagmeister,Panagiotis Kounatidis,Sven Goblirsch,Markus Lienkamp*

Main category: cs.RO

TL;DR: 研究车辆动力学模型精度对轨迹跟踪控制器闭环性能的影响，通过简化综合模型创建不同精度模型，使用真实赛车数据验证，分析模型简化程度对控制算法评估的影响。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶软件开发中仿真至关重要，但现有研究使用不同精度的车辆动力学模型，导致控制算法难以公平比较。需要研究模型精度对轨迹跟踪控制器闭环行为的影响。

Method: 提出综合Autoware兼容车辆模型，通过简化创建不同精度模型，使用超过550次仿真运行量化模型近似质量，分析模型简化在不同加速度极限下的影响变化。

Result: 使用真实赛车数据验证仿真环境（最高速度267kph，横向加速度15m/s²），量化各模型近似质量，发现模型简化影响随加速度极限变化，为不同应用场景提供模型简化指导。

Conclusion: 车辆模型简化程度应根据具体应用需求决定，研究为控制算法评估提供了模型精度选择依据，有助于在自动驾驶仿真中平衡计算效率与模型精度。

Abstract: Simulation is crucial in the development of autonomous driving software. In particular, assessing control algorithms requires an accurate vehicle dynamics simulation. However, recent publications use models with varying levels of detail. This disparity makes it difficult to compare individual control algorithms. Therefore, this paper aims to investigate the influence of the fidelity of vehicle dynamics modeling on the closed-loop behavior of trajectory-following controllers. For this purpose, we introduce a comprehensive Autoware-compatible vehicle model. By simplifying this, we derive models with varying fidelity. Evaluating over 550 simulation runs allows us to quantify each model's approximation quality compared to real-world data. Furthermore, we investigate whether the influence of model simplifications changes with varying margins to the acceleration limit of the vehicle. From this, we deduce to which degree a vehicle model can be simplified to evaluate control algorithms depending on the specific application. The real-world data used to validate the simulation environment originate from the Indy Autonomous Challenge race at the Autodromo Nazionale di Monza in June 2023. They show the fastest fully autonomous lap of TUM Autonomous Motorsport, with vehicle speeds reaching 267 kph and lateral accelerations of up to 15 mps2.

</details>


### [137] [From Ellipsoids to Midair Control of Dynamic Hitches](https://arxiv.org/abs/2602.08116)
*Jiawei Xu,Subhrajit Bhattacharya,David Saldaña*

Main category: cs.RO

TL;DR: 论文提出了一种基于椭球体运动学模型和CLF-HOCBF-QP控制器的四无人机缆绳绞缠动态操控方法，实现了高速动态参考跟踪并保持缆绳张力安全约束。


<details>
  <summary>Details</summary>
Motivation: 通过多无人机协同操控交织缆绳形成绞缠结构，可以提升缆绳辅助空中操控的灵活性和多功能性，但需要解决绞缠结构的动态建模和控制问题。

Method: 1) 引入椭球体运动学模型连接两缆绳绞缠的几何特性与四无人机驱动的动力学；2) 设计基于二次规划的CLF-HOCBF-QP控制器，结合控制李雅普诺夫函数和高阶控制屏障函数；3) 将几何参考配置转换为目标机器人位置，并在李雅普诺夫函数中引入复合误差。

Result: 数值仿真验证了该方法能够实现稳定、高速的动态参考跟踪，同时确保缆绳张力等安全约束。

Conclusion: 该研究为缆绳交织操控提供了有效的动态建模和控制框架，通过椭球体运动学模型和CLF-HOCBF-QP控制器实现了绞缠结构的精确跟踪和安全约束维护。

Abstract: The ability to dynamically manipulate interaction between cables, carried by pairs of aerial vehicles attached to the ends of each cable, can greatly improve the versatility and agility of cable-assisted aerial manipulation. Such interlacing cables create hitches by winding two or more cables around each other, which can enclose payloads or can further develop into knots. Dynamic modeling and control of such hitches is key to mastering the inter-cable manipulation in context of cable-suspended aerial manipulation. This paper introduces an ellipsoid-based kinematic model to connect the geometric nature of a hitch created by two cables and the dynamics of the hitch driven by four aerial vehicles, which reveals the control-affine form of the system. As the constraint for maintaining tension of a cable is also control-affine, we design a quadratic programming-based controller that combines Control Lyapunov and High-Order Control Barrier Functions (CLF-HOCBF-QP) to precisely track a desired hitch position and system shape while enforcing safety constraints like cable tautness. We convert desired geometric reference configurations into target robot positions and introduce a composite error into the Lyapunov function to ensure a relative degree of one to the input. Numerical simulations validate our approach, demonstrating stable, high-speed tracking of dynamic references.

</details>


### [138] [Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning](https://arxiv.org/abs/2602.08167)
*Milan Ganai,Katie Luo,Jonas Frey,Clark Barrett,Marco Pavone*

Main category: cs.RO

TL;DR: R&B-EnCoRe：通过自监督精炼从互联网知识中引导具身推理，避免使用固定模板，显著提升VLA模型在多种具身任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前具身思维链方法依赖固定模板指定推理基元（如场景对象、高层计划、结构可供性），这些模板可能强制策略处理与关键动作预测信号无关的信息，形成瓶颈：没有成功的策略就无法验证推理质量，没有高质量的推理就无法构建稳健的策略。

Method: 引入R&B-EnCoRe，将推理视为重要性加权变分推断中的潜变量，使模型能够通过自监督精炼从互联网规模知识中引导具身推理，无需外部奖励、验证器或人工标注即可生成和蒸馏出具体化特定策略的精炼推理训练数据集。

Result: 在操作（仿真中的Franka Panda、硬件中的WidowX）、腿式导航（双足、轮式、自行车、四足）和自动驾驶等多种具身任务上验证，使用1B、4B、7B和30B参数的VLA架构，相比不加区分地推理所有可用基元的模型，实现了28%的操作成功率提升、101%的导航分数改进和21%的碰撞率指标降低。

Conclusion: R&B-EnCoRe使模型能够蒸馏出对成功控制具有预测性的推理，绕过手动标注工程，同时将互联网规模知识在物理执行中落地。

Abstract: Embodied Chain-of-Thought (CoT) reasoning has significantly enhanced Vision-Language-Action (VLA) models, yet current methods rely on rigid templates to specify reasoning primitives (e.g., objects in the scene, high-level plans, structural affordances). These templates can force policies to process irrelevant information that distracts from critical action-prediction signals. This creates a bottleneck: without successful policies, we cannot verify reasoning quality; without quality reasoning, we cannot build robust policies. We introduce R&B-EnCoRe, which enables models to bootstrap embodied reasoning from internet-scale knowledge through self-supervised refinement. By treating reasoning as a latent variable within importance-weighted variational inference, models can generate and distill a refined reasoning training dataset of embodiment-specific strategies without external rewards, verifiers, or human annotation. We validate R&B-EnCoRe across manipulation (Franka Panda in simulation, WidowX in hardware), legged navigation (bipedal, wheeled, bicycle, quadruped), and autonomous driving embodiments using various VLA architectures with 1B, 4B, 7B, and 30B parameters. Our approach achieves 28% gains in manipulation success, 101% improvement in navigation scores, and 21% reduction in collision-rate metric over models that indiscriminately reason about all available primitives. R&B-EnCoRe enables models to distill reasoning that is predictive of successful control, bypassing manual annotation engineering while grounding internet-scale knowledge in physical execution.

</details>


### [139] [Chamelion: Reliable Change Detection for Long-Term LiDAR Mapping in Transient Environments](https://arxiv.org/abs/2602.08189)
*Seoyeon Jang,Alex Junho Lee,I Made Aswin Nahrendra,Hyun Myung*

Main category: cs.RO

TL;DR: 提出用于移动机器人在动态环境中在线变化检测和长期地图维护的双头网络方法，通过数据增强策略合成结构变化进行训练，在真实建筑工地和室内办公室环境中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在动态环境（如建筑工地、频繁重新配置的室内空间）中导航时，现有方法难以检测变化并更新地图，主要挑战包括频繁遮挡、时空变化以及真实数据收集和对齐困难。

Method: 提出双头网络用于在线变化检测和长期地图维护，开发数据增强策略通过从不同场景导入元素来合成结构变化，无需大量真实标注即可有效训练模型。

Result: 在真实建筑工地和室内办公室环境中的实验表明，该方法在不同场景中泛化能力良好，实现了高效准确的地图更新。

Conclusion: 该方法解决了动态环境中变化检测和地图维护的挑战，通过合成数据增强策略克服了真实数据收集困难，在实际应用中表现出色。

Abstract: Online change detection is crucial for mobile robots to efficiently navigate through dynamic environments. Detecting changes in transient settings, such as active construction sites or frequently reconfigured indoor spaces, is particularly challenging due to frequent occlusions and spatiotemporal variations. Existing approaches often struggle to detect changes and fail to update the map across different observations. To address these limitations, we propose a dual-head network designed for online change detection and long-term map maintenance. A key difficulty in this task is the collection and alignment of real-world data, as manually registering structural differences over time is both labor-intensive and often impractical. To overcome this, we develop a data augmentation strategy that synthesizes structural changes by importing elements from different scenes, enabling effective model training without the need for extensive ground-truth annotations. Experiments conducted at real-world construction sites and in indoor office environments demonstrate that our approach generalizes well across diverse scenarios, achieving efficient and accurate map updates.\resubmit{Our source code and additional material are available at: https://chamelion-pages.github.io/.

</details>


### [140] [STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction](https://arxiv.org/abs/2602.08245)
*Jinhao Li,Yuxuan Cong,Yingqiao Wang,Hao Xia,Shan Huang,Yijia Zhang,Ningyi Xu,Guohao Dai*

Main category: cs.RO

TL;DR: STEP：一种用于机器人扩散策略的轻量级时空一致性预测机制，通过构建高质量的热启动动作和速度感知扰动注入，显著降低推理延迟同时保持动作质量


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人视觉运动控制中表现出色，但迭代去噪过程导致显著的推理延迟，限制了实时闭环系统的控制频率。现有加速方法难以同时保持动作质量和实现持续低延迟。

Method: 提出STEP方法：1）轻量级时空一致性预测机制，构建分布接近目标动作且时间一致的高质量热启动动作；2）速度感知扰动注入机制，基于时间动作变化自适应调节执行激励，防止执行停滞；3）理论分析显示该预测诱导局部收缩映射，确保扩散细化期间动作误差收敛。

Result: 在9个模拟基准和2个真实世界任务上进行评估。STEP仅需2步即可在RoboMimic基准上比BRIDGER和DDIM平均提高21.6%和27.5%的成功率，在真实世界任务中也有类似提升。STEP在推理延迟和成功率方面始终优于现有方法。

Conclusion: STEP通过时空一致性预测和自适应扰动注入机制，有效解决了扩散策略的推理延迟问题，在保持动作质量的同时显著提高了控制频率，推进了推理延迟与成功率的帕累托前沿。

Abstract: Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse past actions, but often struggle to jointly preserve action quality and achieve consistently low latency. In this work, we propose STEP, a lightweight spatiotemporal consistency prediction mechanism to construct high-quality warm-start actions that are both distributionally close to the target action and temporally consistent, without compromising the generative capability of the original diffusion policy. Then, we propose a velocity-aware perturbation injection mechanism that adaptively modulates actuation excitation based on temporal action variation to prevent execution stall especially for real-world tasks. We further provide a theoretical analysis showing that the proposed prediction induces a locally contractive mapping, ensuring convergence of action errors during diffusion refinement. We conduct extensive evaluations on nine simulated benchmarks and two real-world tasks. Notably, STEP with 2 steps can achieve an average 21.6% and 27.5% higher success rate than BRIDGER and DDIM on the RoboMimic benchmark and real-world tasks, respectively. These results demonstrate that STEP consistently advances the Pareto frontier of inference latency and success rate over existing methods.

</details>


### [141] [Aerial Manipulation with Contact-Aware Onboard Perception and Hybrid Control](https://arxiv.org/abs/2602.08251)
*Yuanzhu Zhan,Yufei Jiang,Muqing Cao,Junyi Geng*

Main category: cs.RO

TL;DR: 提出一种完全机载的感知-控制管道，用于接触丰富的空中操纵，无需外部运动捕捉，通过增强的视觉惯性里程计和图像视觉伺服实现精确运动跟踪和接触力控制。


<details>
  <summary>Details</summary>
Motivation: 现有空中操纵系统大多依赖外部运动捕捉，强调位置控制，限制了实际部署能力。需要开发完全机载的感知控制系统，实现精确的运动跟踪和接触力调节，使无人机能够执行接触丰富的任务。

Method: 1) 增强的视觉惯性里程计，包含仅在交互时激活的接触一致性因子，减少接触帧不确定性；2) 图像视觉伺服减轻感知-控制耦合；3) 混合力-运动控制器调节接触力和横向运动。

Result: 实验显示该方法仅使用机载传感就实现了感知到力的闭环控制，接触时速度估计提升66.01%，能够可靠接近目标并保持稳定力控制，向可部署的野外空中操纵迈进。

Conclusion: 提出的完全机载感知-控制管道使无人机能够执行接触丰富的任务，无需外部运动捕捉，提高了速度估计精度和接触稳定性，为实现可部署的野外空中操纵提供了重要进展。

Abstract: Aerial manipulation (AM) promises to move Unmanned Aerial Vehicles (UAVs) beyond passive inspection to contact-rich tasks such as grasping, assembly, and in-situ maintenance. Most prior AM demonstrations rely on external motion capture (MoCap) and emphasize position control for coarse interactions, limiting deployability. We present a fully onboard perception-control pipeline for contact-rich AM that achieves accurate motion tracking and regulated contact wrenches without MoCap. The main components are (1) an augmented visual-inertial odometry (VIO) estimator with contact-consistency factors that activate only during interaction, tightening uncertainty around the contact frame and reducing drift, and (2) image-based visual servoing (IBVS) to mitigate perception-control coupling, together with a hybrid force-motion controller that regulates contact wrenches and lateral motion for stable contact. Experiments show that our approach closes the perception-to-wrench loop using only onboard sensing, yielding an velocity estimation improvement of 66.01% at contact, reliable target approach, and stable force holding-pointing toward deployable, in-the-wild aerial manipulation.

</details>


### [142] [Informative Object-centric Next Best View for Object-aware 3D Gaussian Splatting in Cluttered Scenes](https://arxiv.org/abs/2602.08266)
*Seunghoon Jeong,Eunho Lee,Jeongyun Kim,Ayoung Kim*

Main category: cs.RO

TL;DR: 提出一种基于实例感知的Next Best View策略，利用物体特征优先探索未充分观测区域，显著提升3D高斯泼溅在遮挡场景下的重建精度。


<details>
  <summary>Details</summary>
Motivation: 在遮挡和观测不完整的杂乱场景中，选择信息丰富的视角对于构建可靠表示至关重要。现有方法仅依赖几何线索，忽略与操作相关的语义信息，且倾向于利用而非探索。

Method: 提出实例感知的NBV策略：1) 物体感知的3DGS将实例级信息蒸馏为独热物体向量；2) 计算置信度加权的信息增益，指导识别与错误和不确定高斯相关的区域；3) 可轻松适配为以物体为中心的NBV，专注于目标物体的视角选择。

Result: 在合成数据集上深度误差降低77.14%，在真实世界GraspNet数据集上降低34.10%。针对特定物体的NBV相比整个场景，可额外降低该物体25.60%的深度误差。在真实机器人操作任务中验证了有效性。

Conclusion: 提出的实例感知NBV策略通过利用物体特征优先探索未充分观测区域，显著提升了3D高斯泼溅在遮挡场景下的重建质量，并展示了在机器人操作任务中的实际应用价值。

Abstract: In cluttered scenes with inevitable occlusions and incomplete observations, selecting informative viewpoints is essential for building a reliable representation. In this context, 3D Gaussian Splatting (3DGS) offers a distinct advantage, as it can explicitly guide the selection of subsequent viewpoints and then refine the representation with new observations. However, existing approaches rely solely on geometric cues, neglect manipulation-relevant semantics, and tend to prioritize exploitation over exploration. To tackle these limitations, we introduce an instance-aware Next Best View (NBV) policy that prioritizes underexplored regions by leveraging object features. Specifically, our object-aware 3DGS distills instancelevel information into one-hot object vectors, which are used to compute confidence-weighted information gain that guides the identification of regions associated with erroneous and uncertain Gaussians. Furthermore, our method can be easily adapted to an object-centric NBV, which focuses view selection on a target object, thereby improving reconstruction robustness to object placement. Experiments demonstrate that our NBV policy reduces depth error by up to 77.14% on the synthetic dataset and 34.10% on the real-world GraspNet dataset compared to baselines. Moreover, compared to targeting the entire scene, performing NBV on a specific object yields an additional reduction of 25.60% in depth error for that object. We further validate the effectiveness of our approach through real-world robotic manipulation tasks.

</details>


### [143] [DexFormer: Cross-Embodied Dexterous Manipulation via History-Conditioned Transformer](https://arxiv.org/abs/2602.08278)
*Ke Zhang,Lixin Xu,Chengyi Song,Junzhe Xu,Xiaoyi Lin,Zeyu Jiang,Renjing Xu*

Main category: cs.RO

TL;DR: DexFormer是一个基于Transformer的端到端跨本体灵巧操作策略，能够适应不同机械手的形态和动力学特性，实现零样本泛化到多种灵巧手


<details>
  <summary>Details</summary>
Motivation: 灵巧操作是机器人学中的核心挑战，现有方法面临本体可变性问题：不同灵巧手具有不同的运动学和动力学特性，需要为每个本体单独训练策略或使用共享动作空间，这限制了方法的可扩展性

Method: 提出DexFormer，基于改进的Transformer架构构建端到端、动态感知的跨本体策略。通过利用历史观测推断形态和动力学，实时适应不同手部配置并生成适合本体的控制动作。在多种程序生成的灵巧手资产上进行训练

Result: DexFormer获得了可泛化的操作先验，在Leap Hand、Allegro Hand和Rapid Hand上表现出强大的零样本迁移能力。单个策略能够泛化到异构手部本体，为跨本体灵巧操作建立了可扩展的基础

Conclusion: DexFormer通过动态感知的Transformer架构解决了跨本体灵巧操作的挑战，为构建通用灵巧操作系统提供了有前景的方向，展示了单个策略适应多种机械手形态的可行性

Abstract: Dexterous manipulation remains one of the most challenging problems in robotics, requiring coherent control of high-DoF hands and arms under complex, contact-rich dynamics. A major barrier is embodiment variability: different dexterous hands exhibit distinct kinematics and dynamics, forcing prior methods to train separate policies or rely on shared action spaces with per-embodiment decoder heads. We present DexFormer, an end-to-end, dynamics-aware cross-embodiment policy built on a modified transformer backbone that conditions on historical observations. By using temporal context to infer morphology and dynamics on the fly, DexFormer adapts to diverse hand configurations and produces embodiment-appropriate control actions. Trained over a variety of procedurally generated dexterous-hand assets, DexFormer acquires a generalizable manipulation prior and exhibits strong zero-shot transfer to Leap Hand, Allegro Hand, and Rapid Hand. Our results show that a single policy can generalize across heterogeneous hand embodiments, establishing a scalable foundation for cross-embodiment dexterous manipulation. Project website: https://davidlxu.github.io/DexFormer-web/.

</details>


### [144] [ReefFlex: A Generative Design Framework for Soft Robotic Grasping of Organic and Fragile objects](https://arxiv.org/abs/2602.08285)
*Josh Pinskier,Sarah Baldwin,Stephen Rodan,David Howard*

Main category: cs.RO

TL;DR: ReefFlex是一种生成式软手指设计方法，通过运动基元编码异质抓取，优化设计用于安全抓取珊瑚的软机器人，提高抓取成功率和质量。


<details>
  <summary>Details</summary>
Motivation: 气候变化、入侵物种和人类活动正在以前所未有的速度破坏全球珊瑚礁，威胁其生物多样性和渔业资源。需要可扩展的珊瑚再生技术来培育气候适应性物种并加速自然再生过程，但目前缺乏安全可靠的工具来处理脆弱的珊瑚。

Method: 提出ReefFlex生成式软手指设计方法，通过将异质抓取编码为少量运动基元，创建简化的多目标优化问题，探索多样化的软手指设计空间，为脆弱的几何异质珊瑚在杂乱环境中提供安全抓取方案。

Result: ReefFlex显著提高了抓取成功率和抓取质量（抗干扰能力、定位精度），减少了珊瑚操作过程中的不良事件。设计了一个用于珊瑚修复的软机器人，可在陆上水产养殖设施中培育和操作珊瑚。

Conclusion: ReefFlex提供了一种通用的软末端执行器设计方法，可用于复杂操作任务，为珊瑚处理等以前难以自动化的领域开辟了自动化路径，有助于珊瑚礁修复工作。

Abstract: Climate change, invasive species and human activities are currently damaging the world's coral reefs at unprecedented rates, threatening their vast biodiversity and fisheries, and reducing coastal protection. Solving this vast challenge requires scalable coral regeneration technologies that can breed climate-resilient species and accelerate the natural regrowth processes; actions that are impeded by the absence of safe and robust tools to handle the fragile coral. We investigate ReefFlex, a generative soft finger design methodology that explores a diverse space of soft fingers to produce a set of candidates capable of safely grasping fragile and geometrically heterogeneous coral in a cluttered environment. Our key insight is encoding heterogeneous grasping into a reduced set of motion primitives, creating a simplified, tractable multi-objective optimisation problem. To evaluate the method, we design a soft robot for reef rehabilitation, which grows and manipulates coral in onshore aquaculture facilities for future reef out-planting. We demonstrate ReefFlex increases both grasp success and grasp quality (disturbance resistance, positioning accuracy) and reduces in adverse events encountered during coral manipulation compared to reference designs. ReefFlex, offers a generalisable method to design soft end-effectors for complex handling and paves a pathway towards automation in previously unachievable domains like coral handling for restoration.

</details>


### [145] [Benchmarking Autonomous Vehicles: A Driver Foundation Model Framework](https://arxiv.org/abs/2602.08298)
*Yuxin Zhang,Cheng Wang,Hubert P. H. Shum*

Main category: cs.RO

TL;DR: 提出驾驶员基础模型（DFM）框架，用于系统化地规范、验证和验证自动驾驶车辆，解决当前自动驾驶在安全、舒适、效率和能耗方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆虽然有望革新交通系统，但市场接受度远低于预期，主要因为与经验丰富的人类驾驶员相比，在安全、舒适、通勤效率和能源经济性方面存在持续挑战。

Method: 提出建立驾驶员基础模型（DFM）的框架：包括大规模数据集收集策略、模型应具备的核心功能讨论，以及实现这些功能的潜在技术解决方案探索。

Result: DFM在整个操作谱系中具有实用性，从定义以人为中心的安全边界到建立能源经济性基准，为自动驾驶车辆的系统化规范、验证和验证提供了新范式。

Conclusion: 驾驶员基础模型（DFM）概念被正式化，为自动驾驶车辆的系统化规范、验证和验证引入了一个新范式，旨在解决当前自动驾驶面临的核心挑战。

Abstract: Autonomous vehicles (AVs) are poised to revolutionize global transportation systems. However, its widespread acceptance and market penetration remain significantly below expectations. This gap is primarily driven by persistent challenges in safety, comfort, commuting efficiency and energy economy when compared to the performance of experienced human drivers. We hypothesize that these challenges can be addressed through the development of a driver foundation model (DFM). Accordingly, we propose a framework for establishing DFMs to comprehensively benchmark AVs. Specifically, we describe a large-scale dataset collection strategy for training a DFM, discuss the core functionalities such a model should possess, and explore potential technical solutions to realize these functionalities. We further present the utility of the DFM across the operational spectrum, from defining human-centric safety envelopes to establishing benchmarks for energy economy. Overall, We aim to formalize the DFM concept and introduce a new paradigm for the systematic specification, verification and validation of AVs.

</details>


### [146] [Personalized Autonomous Driving via Optimal Control with Clearance Constraints from Questionnaires](https://arxiv.org/abs/2602.08326)
*Yongjae Lim,Dabin Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出一个考虑用户偏好的自动驾驶规划框架，通过问卷收集用户对周围车辆安全距离的偏好，并将其作为约束整合到最优控制问题中，通过问题分解实现实时计算。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶规划不考虑用户对安全距离的偏好，可能导致用户不适。需要开发能够明确纳入用户偏好的规划框架，提升驾驶舒适性和个性化体验。

Method: 1) 设计专门问卷收集用户对周围车辆（考虑尺寸、速度、位置、机动行为等）的安全距离偏好；2) 将偏好作为约束整合到最优控制问题中；3) 通过问题分解将原问题拆分为多个固定场景的子问题并行求解；4) 使用原问题成本函数选择最优解。

Result: 通过模拟不同用户问卷响应验证，该规划器相比不考虑偏好的基线规划器能更好地反映用户偏好，在偏好对齐方面表现更优。

Conclusion: 提出的规划框架成功将用户偏好整合到自动驾驶规划中，通过问卷收集和问题分解方法，在保持实时性的同时实现了个性化驾驶体验，提升了用户舒适度。

Abstract: Driving without considering the preferred separation distance from surrounding vehicles may cause discomfort for users. To address this limitation, we propose a planning framework that explicitly incorporates user preferences regarding the desired level of safe clearance from surrounding vehicles. We design a questionnaire purposefully tailored to capture user preferences relevant to our framework, while minimizing unnecessary questions. Specifically, the questionnaire considers various interaction-relevant factors, including the surrounding vehicle's size, speed, position, and maneuvers of surrounding vehicles, as well as the maneuvers of the ego vehicle. The response indicates the user-preferred clearance for the scenario defined by the question and is incorporated as constraints in the optimal control problem. However, it is impractical to account for all possible scenarios that may arise in a driving environment within a single optimal control problem, as the resulting computational complexity renders real-time implementation infeasible. To overcome this limitation, we approximate the original problem by decomposing it into multiple subproblems, each dealing with one fixed scenario. We then solve these subproblems in parallel and select one using the cost function from the original problem. To validate our work, we conduct simulations using different user responses to the questionnaire. We assess how effectively our planner reflects user preferences compared to preference-agnostic baseline planners by measuring preference alignment.

</details>


### [147] [Controlled Flight of an Insect-Scale Flapping-Wing Robot via Integrated Onboard Sensing and Computation](https://arxiv.org/abs/2602.08328)
*Yi-Hsuan Hsiao,Quang Phuc Kieu,Zhongtao Guan,Suhan Kim,Jiaze Cai,Owen Matteson,Jonathan P. How,Elizabeth Farrell Helbling,YuFeng Chen*

Main category: cs.RO

TL;DR: 开发了仅重1.29克、具备完全机载传感和计算能力的微型飞行机器人，实现了厘米级定位精度和自主避障飞行


<details>
  <summary>Details</summary>
Motivation: 自然界昆虫能在茂密植被中轻松导航，而类似尺寸的微型飞行机器人通常依赖外部传感器和计算，限制了其在搜救、精准农业等实际任务中的应用

Method: 开发了集成传感器套件、估计算法和低级控制器的1.29克微型飞行机器人；采用分层控制系统，人类操作员提供高级指令，机器人自主执行低级控制

Result: 实现了厘米级位置飞行精度；在30秒的室外飞行实验中，成功避开障碍物并降落在向日葵上，无需动作捕捉系统支持

Conclusion: 这项研究代表了空中微型机器人领域的重大进步，为实现完全机载规划和能源自主开辟了新机会，使微型机器人能在实际环境中执行复杂任务

Abstract: Aerial insects can effortlessly navigate dense vegetation, whereas similarly sized aerial robots typically depend on offboard sensors and computation to maintain stable flight. This disparity restricts insect-scale robots to operation within motion capture environments, substantially limiting their applicability to tasks such as search-and-rescue and precision agriculture. In this work, we present a 1.29-gram aerial robot capable of hovering and tracking trajectories with solely onboard sensing and computation. The combination of a sensor suite, estimators, and a low-level controller achieved centimeter-scale positional flight accuracy. Additionally, we developed a hierarchical controller in which a human operator provides high-level commands to direct the robot's motion. In a 30-second flight experiment conducted outside a motion capture system, the robot avoided obstacles and ultimately landed on a sunflower. This level of sensing and computational autonomy represents a significant advancement for the aerial microrobotics community, further opening opportunities to explore onboard planning and power autonomy.

</details>


### [148] [Vec-QMDP: Vectorized POMDP Planning on CPUs for Real-Time Autonomous Driving](https://arxiv.org/abs/2602.08334)
*Xuanjin Jin,Yanxin Dong,Bin Sun,Huan Xu,Zhihui Hao,XianPeng Lang,Panpan Cai*

Main category: cs.RO

TL;DR: Vec-QMDP是一个CPU原生的并行规划器，通过数据导向设计和分层并行方案，在自动驾驶等大规模不确定性规划任务中实现227-1073倍加速，达到毫秒级延迟。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人任务（如自动驾驶）需要在巨大的高维信念空间中进行规划，计算密集。现有CPU-GPU混合求解器存在主机-设备同步延迟和SIMT架构分支发散等瓶颈，限制了实时规划和实际机器人部署。

Method: 采用数据导向设计重构数据结构为连续缓存高效布局；引入分层并行方案：在独立CPU核心和SIMD通道间分配子树，实现完全向量化的树扩展和碰撞检测；使用UCB负载均衡和向量化STR-tree进行粗粒度碰撞检测。

Result: 在大型自动驾驶基准测试中，Vec-QMDP相比最先进的串行规划器实现227-1073倍加速，达到最先进的规划性能，具有毫秒级延迟，确立了CPU作为大规模不确定性规划的高性能计算平台。

Conclusion: Vec-QMDP通过将POMDP搜索与现代CPU的SIMD架构对齐，采用数据导向设计和分层并行方案，成功解决了大规模不确定性规划的计算瓶颈，使CPU成为高性能实时规划的有效平台。

Abstract: Planning under uncertainty for real-world robotics tasks, such as autonomous driving, requires reasoning in enormous high-dimensional belief spaces, rendering the problem computationally intensive. While parallelization offers scalability, existing hybrid CPU-GPU solvers face critical bottlenecks due to host-device synchronization latency and branch divergence on SIMT architectures, limiting their utility for real-time planning and hindering real-robot deployment. We present Vec-QMDP, a CPU-native parallel planner that aligns POMDP search with modern CPUs' SIMD architecture, achieving $227\times$--$1073\times$ speedup over state-of-the-art serial planners. Vec-QMDP adopts a Data-Oriented Design (DOD), refactoring scattered, pointer-based data structures into contiguous, cache-efficient memory layouts. We further introduce a hierarchical parallelism scheme: distributing sub-trees across independent CPU cores and SIMD lanes, enabling fully vectorized tree expansion and collision checking. Efficiency is maximized with the help of UCB load balancing across trees and a vectorized STR-tree for coarse-level collision checking. Evaluated on large-scale autonomous driving benchmarks, Vec-QMDP achieves state-of-the-art planning performance with millisecond-level latency, establishing CPUs as a high-performance computing platform for large-scale planning under uncertainty.

</details>


### [149] [Learning Human-Like Badminton Skills for Humanoid Robots](https://arxiv.org/abs/2602.08370)
*Yeke Chen,Shihao Dong,Xiaoyu Ji,Jingkai Sun,Zeren Luo,Liu Zhao,Jiahui Zhang,Wanyue Li,Ji Ma,Bowen Xu,Yimin Han,Yudong Zhao,Peng Lu*

Main category: cs.RO

TL;DR: 提出Imitation-to-Interaction渐进强化学习框架，让人形机器人从模仿人类动作发展到具备实际羽毛球击球能力，实现零样本仿真到现实的技能迁移。


<details>
  <summary>Details</summary>
Motivation: 在羽毛球等高要求运动中实现类人表现对人形机器人是巨大挑战。现有方法虽能模仿运动学动作，但难以在保持自然风格的同时实现功能性的物理感知击球。

Method: 提出Imitation-to-Interaction渐进强化学习框架：1)从人类数据建立鲁棒运动先验；2)蒸馏到紧凑的基于模型的状态表示；3)通过对抗先验稳定动力学；4)引入流形扩展策略将离散击球点泛化为密集交互空间。

Result: 在仿真中掌握了包括高远球和吊球在内的多样技能，并首次实现了人形机器人羽毛球技能的零样本仿真到现实迁移，在物理世界中成功复制了人类运动员的动感优雅和功能精度。

Conclusion: 该框架成功地将人形机器人从"模仿者"进化为"击球手"，实现了类人运动风格与功能性物理感知击球的无缝融合，为人形机器人在高要求体育任务中的表现提供了新途径。

Abstract: Realizing versatile and human-like performance in high-demand sports like badminton remains a formidable challenge for humanoid robotics. Unlike standard locomotion or static manipulation, this task demands a seamless integration of explosive whole-body coordination and precise, timing-critical interception. While recent advances have achieved lifelike motion mimicry, bridging the gap between kinematic imitation and functional, physics-aware striking without compromising stylistic naturalness is non-trivial. To address this, we propose Imitation-to-Interaction, a progressive reinforcement learning framework designed to evolve a robot from a "mimic" to a capable "striker." Our approach establishes a robust motor prior from human data, distills it into a compact, model-based state representation, and stabilizes dynamics via adversarial priors. Crucially, to overcome the sparsity of expert demonstrations, we introduce a manifold expansion strategy that generalizes discrete strike points into a dense interaction volume. We validate our framework through the mastery of diverse skills, including lifts and drop shots, in simulation. Furthermore, we demonstrate the first zero-shot sim-to-real transfer of anthropomorphic badminton skills to a humanoid robot, successfully replicating the kinetic elegance and functional precision of human athletes in the physical world.

</details>


### [150] [BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models](https://arxiv.org/abs/2602.08392)
*Xin Wu,Zhixuan Liang,Yue Ma,Mengkang Hu,Zhiyuan Qin,Xiu Li*

Main category: cs.RO

TL;DR: 论文提出了BiManiBench基准测试，用于评估多模态大语言模型在双臂机器人操作任务中的表现，发现现有模型在空间推理和时序协调方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准测试主要局限于单臂操作，无法评估双臂任务所需的时空协调能力，如抬起重锅等需要双臂协作的任务。

Method: 提出BiManiBench分层基准测试框架，包含三个层次：基础空间推理、高层动作规划、低层末端执行器控制，专门针对双臂操作中的可达性、运动学约束等独特挑战。

Result: 对30多个最先进模型的分析显示，尽管MLLMs在高层推理方面表现良好，但在双臂空间定位和控制方面存在困难，经常出现相互干扰和时序错误。

Conclusion: 当前MLLM范式缺乏对双臂运动学约束的深入理解，未来研究需要关注双臂碰撞避免和细粒度时序协调。

Abstract: Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI, and using them to benchmark robotic intelligence has become a pivotal trend. However, existing frameworks remain predominantly confined to single-arm manipulation, failing to capture the spatio-temporal coordination required for bimanual tasks like lifting a heavy pot. To address this, we introduce BiManiBench, a hierarchical benchmark evaluating MLLMs across three tiers: fundamental spatial reasoning, high-level action planning, and low-level end-effector control. Our framework isolates unique bimanual challenges, such as arm reachability and kinematic constraints, thereby distinguishing perceptual hallucinations from planning failures. Analysis of over 30 state-of-the-art models reveals that despite high-level reasoning proficiency, MLLMs struggle with dual-arm spatial grounding and control, frequently resulting in mutual interference and sequencing errors. These findings suggest the current paradigm lacks a deep understanding of mutual kinematic constraints, highlighting the need for future research to focus on inter-arm collision-avoidance and fine-grained temporal sequencing.

</details>


### [151] [Graph-Loc: Robust Graph-Based LiDAR Pose Tracking with Compact Structural Map Priors under Low Observability and Occlusion](https://arxiv.org/abs/2602.08417)
*Wentao Zhao,Yihe Niu,Zikun Chen,Rui Li,Yanbo Wang,Tianchen Deng,Jingchuan Wang*

Main category: cs.RO

TL;DR: Graph-Loc：基于图结构的LiDAR定位框架，使用轻量级点线图作为地图先验，通过不平衡最优传输实现鲁棒的扫描到地图关联，在遮挡和低观测性场景下保持稳定跟踪。


<details>
  <summary>Details</summary>
Motivation: 长期自主操作需要紧凑的地图先验以实现可扩展存储和快速检索，而在线观测通常是部分、重复且严重遮挡的。现有方法在处理遮挡、结构缺失和几何退化场景时面临挑战。

Method: 1）构建轻量级点线图作为结构地图先验；2）从LiDAR扫描中提取稀疏点和线基元形成观测图；3）通过LiDAR射线模拟检索姿态条件可见子图；4）使用带局部图上下文正则化的不平衡最优传输进行扫描到地图关联；5）从精化法矩阵估计信息各向异性，在弱约束方向延迟更新。

Result: 在公开基准测试、控制压力测试和实际部署中，使用KB级先验实现了准确稳定的跟踪，能够在几何退化、持续遮挡和场景逐渐变化的情况下保持性能。

Conclusion: Graph-Loc框架通过图表示和不平衡最优传输，实现了对紧凑结构地图先验的鲁棒LiDAR姿态跟踪，特别适用于遮挡、低观测性和异构地图源的实际场景。

Abstract: Map-based LiDAR pose tracking is essential for long-term autonomous operation, where onboard map priors need be compact for scalable storage and fast retrieval, while online observations are often partial, repetitive, and heavily occluded. We propose Graph-Loc, a graph-based localization framework that tracks the platform pose against compact structural map priors represented as a lightweight point-line graph. Such priors can be constructed from heterogeneous sources commonly available in practice, including polygon outlines vectorized from occupancy/grid maps and CAD/model/floor-plan layouts. For each incoming LiDAR scan, Graph-Loc extracts sparse point and line primitives to form an observation graph, retrieves a pose-conditioned visible subgraph via LiDAR ray simulation, and performs scan-to-map association through unbalanced optimal transport with a local graph-context regularizer. The unbalanced formulation relaxes mass conservation, improving robustness to missing, spurious, and fragmented structures under occlusion. To enhance stability in low-observability segments, we estimate information anisotropy from the refinement normal matrix and defer updates along weakly constrained directions until sufficient constraints reappear. Experiments on public benchmarks, controlled stress tests, and real-world deployments demonstrate accurate and stable tracking with KB-level priors from heterogeneous map sources, including under geometrically degenerate and sustained occlusion and in the presence of gradual scene changes.

</details>


### [152] [Decentralized Intent-Based Multi-Robot Task Planner with LLM Oracles on Hyperledger Fabric](https://arxiv.org/abs/2602.08421)
*Farhad Keramat,Salma Salimi,Tomi Westerlund*

Main category: cs.RO

TL;DR: 提出基于区块链的LLM预言机架构，用于去中心化的机器人任务规划，通过新型聚合方法提升多LLM输出的可靠性


<details>
  <summary>Details</summary>
Motivation: LLM使自然语言到可执行动作的转换成为可能，但现有LLM服务存在中心化风险（如自我偏好问题），且当前聚合方法不适合机器人任务规划中对时序顺序的要求

Method: 1) 提出新的LLM预言机聚合方法，专门针对机器人任务规划；2) 基于Hyperledger Fabric构建去中心化多机器人基础设施，支持自然语言意图分解、跨厂商机器人协调和细粒度访问控制

Result: 创建了SkillChain-RTD基准测试集并公开，实验证明所提架构可行，且新聚合方法优于现有方法

Conclusion: 提出的去中心化LLM预言机架构能有效解决机器人任务规划中的中心化风险和时序聚合问题，为安全可靠的人机交互提供新方案

Abstract: Large language models (LLMs) have opened new opportunities for transforming natural language user intents into executable actions. This capability enables embodied AI agents to perform complex tasks, without involvement of an expert, making human-robot interaction (HRI) more convenient. However these developments raise significant security and privacy challenges such as self-preferencing, where a single LLM service provider dominates the market and uses this power to promote their own preferences. LLM oracles have been recently proposed as a mechanism to decentralize LLMs by executing multiple LLMs from different vendors and aggregating their outputs to obtain a more reliable and trustworthy final result. However, the accuracy of these approaches highly depends on the aggregation method. The current aggregation methods mostly use semantic similarity between various LLM outputs, not suitable for robotic task planning, where the temporal order of tasks is important. To fill the gap, we propose an LLM oracle with a new aggregation method for robotic task planning. In addition, we propose a decentralized multi-robot infrastructure based on Hyperledger Fabric that can host the proposed oracle. The proposed infrastructure enables users to express their natural language intent to the system, which then can be decomposed into subtasks. These subtasks require coordinating different robots from different vendors, while enforcing fine-grained access control management on the data. To evaluate our methodology, we created the SkillChain-RTD benchmark made it publicly available. Our experimental results demonstrate the feasibility of the proposed architecture, and the proposed aggregation method outperforms other aggregation methods currently in use.

</details>


### [153] [Bi-Adapt: Few-shot Bimanual Adaptation for Novel Categories of 3D Objects via Semantic Correspondence](https://arxiv.org/abs/2602.08425)
*Jinxian Zhou,Ruihai Wu,Yiwei Liu,Yiwen Hou,Xunzhe Zhou,Checheng Yu,Licheng Zhong,Lin Shao*

Main category: cs.RO

TL;DR: Bi-Adapt：基于语义对应的双手机器人操作框架，利用视觉基础模型实现跨类别泛化，只需少量数据微调即可零样本适应新类别物体


<details>
  <summary>Details</summary>
Motivation: 双手机器人操作对执行复杂任务至关重要，但现有方法依赖大量数据收集和训练，难以高效泛化到未见过的物体类别

Method: 提出Bi-Adapt框架，通过视觉基础模型实现语义对应，建立跨类别功能映射，仅需少量数据在新类别上进行微调

Result: 在仿真和真实环境中验证了有效性，在有限数据下对不同基准任务的新类别物体实现了高成功率

Conclusion: Bi-Adapt框架通过语义对应实现了高效的双手机器人操作泛化，显著降低了数据需求和训练成本

Abstract: Bimanual manipulation is imperative yet challenging for robots to execute complex tasks, requiring coordinated collaboration between two arms. However, existing methods for bimanual manipulation often rely on costly data collection and training, struggling to generalize to unseen objects in novel categories efficiently. In this paper, we present Bi-Adapt, a novel framework designed for efficient generalization for bimanual manipulation via semantic correspondence. Bi-Adapt achieves cross-category affordance mapping by leveraging the strong capability of vision foundation models. Fine-tuning with restricted data on novel categories, Bi-Adapt exhibits notable generalization to out-of-category objects in a zero-shot manner. Extensive experiments conducted in both simulation and real-world environments validate the effectiveness of our approach and demonstrate its high efficiency, achieving a high success rate on different benchmark tasks across novel categories with limited data. Project website: https://biadapt-project.github.io/

</details>


### [154] [SteerVLA: Steering Vision-Language-Action Models in Long-Tail Driving Scenarios](https://arxiv.org/abs/2602.08440)
*Tian Gao,Celine Tan,Catherine Glossop,Timothy Gao,Jiankai Sun,Kyle Stachowicz,Shirley Wu,Oier Mees,Dorsa Sadigh,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: SteerVLA：利用视觉语言模型的推理能力生成细粒度语言指令来引导视觉语言-动作驾驶策略，在自动驾驶中实现高层语义推理与低层控制的有效结合。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶面临的核心挑战是如何将处理长尾事件的高层语义推理与确保稳健驾驶的低层反应控制相结合。虽然大规模视觉语言模型（VLMs）具备强大的常识推理能力，但缺乏安全车辆控制所需的实际驾驶经验。

Method: 提出SteerVLA方法，利用VLM的推理能力生成细粒度语言指令来引导视觉语言-动作（VLA）驾驶策略。关键创新是建立VLM与VLA之间的丰富语言接口，使高层策略能更有效地将其推理与低层策略的控制输出相结合。通过VLM增强现有驾驶数据，添加详细的语言标注，为有效推理和可引导性提供监督。

Result: 在具有挑战性的闭环基准测试中，SteerVLA在整体驾驶得分上比现有最优方法高出4.77分，在长尾子集上高出8.04分。

Conclusion: SteerVLA成功地将VLM的世界知识与可引导的驾驶策略相结合，通过细粒度语言接口实现了高层语义推理与低层稳健控制的有效集成，显著提升了自动驾驶性能，特别是在处理长尾事件方面。

Abstract: A fundamental challenge in autonomous driving is the integration of high-level, semantic reasoning for long-tail events with low-level, reactive control for robust driving. While large vision-language models (VLMs) trained on web-scale data offer powerful common-sense reasoning, they lack the grounded experience necessary for safe vehicle control. We posit that an effective autonomous agent should leverage the world knowledge of VLMs to guide a steerable driving policy toward robust control in driving scenarios. To this end, we propose SteerVLA, which leverages the reasoning capabilities of VLMs to produce fine-grained language instructions that steer a vision-language-action (VLA) driving policy. Key to our method is this rich language interface between the high-level VLM and low-level VLA, which allows the high-level policy to more effectively ground its reasoning in the control outputs of the low-level policy. To provide fine-grained language supervision aligned with vehicle control, we leverage a VLM to augment existing driving data with detailed language annotations, which we find to be essential for effective reasoning and steerability. We evaluate SteerVLA on a challenging closed-loop benchmark, where it outperforms state-of-the-art methods by 4.77 points in overall driving score and by 8.04 points on a long-tail subset. The project website is available at: https://steervla.github.io/.

</details>


### [155] [Post-Collision Trajectory Restoration for a Single-track Ackermann Vehicle using Heuristic Steering and Tractive Force Functions](https://arxiv.org/abs/2602.08444)
*Samsaptak Ghosh,M. Felix Orlando,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: 提出一种用于自动驾驶车辆碰撞后轨迹恢复的结构化启发式控制律，联合控制转向和牵引力，考虑时变纵向速度和转向耦合非线性项。


<details>
  <summary>Details</summary>
Motivation: 碰撞引起的横向运动和偏航瞬变会迅速使车辆偏离预定路径，而现有方法通常假设恒定纵向速度，忽略了碰撞后瞬态阶段速度变化和非线性耦合对恢复的重要影响。

Method: 提出结构化启发式恢复控制律，基于广义单轨阿克曼车辆模型，联合控制转向和牵引力，显式考虑时变纵向速度在横向-偏航动力学中的作用，并保留通常被简化的转向耦合非线性项。

Result: 在MATLAB中对提出的广义单轨模型和标准3自由度单轨参考模型进行仿真评估，结果表明该方法在不同代表性初始碰撞后条件下均能保持一致的碰撞后恢复行为。

Conclusion: 所提出的控制方法能够有效处理碰撞后瞬态阶段的轨迹恢复问题，考虑了实际碰撞场景中重要的速度变化和非线性耦合效应，为自动驾驶车辆的安全恢复提供了实用解决方案。

Abstract: Post-collision trajectory restoration is a safety-critical capability for autonomous vehicles, as impact-induced lateral motion and yaw transients can rapidly drive the vehicle away from the intended path. This paper proposes a structured heuristic recovery control law that jointly commands steering and tractive force for a generalized single-track Ackermann vehicle model. The formulation explicitly accounts for time-varying longitudinal velocity in the lateral-yaw dynamics and retains nonlinear steering-coupled interaction terms that are commonly simplified in the literature. Unlike approaches that assume constant longitudinal speed, the proposed design targets the transient post-impact regime where speed variations and nonlinear coupling significantly influence recovery. The method is evaluated in simulation on the proposed generalized single-track model and a standard 3DOF single-track reference model in MATLAB, demonstrating consistent post-collision restoration behaviour across representative initial post-impact conditions.

</details>


### [156] [UAV-Supported Maritime Search System: Experience from Valun Bay Field Trials](https://arxiv.org/abs/2602.08450)
*Stefan Ivić,Luka Lanča,Karlo Jakac,Ante Sikirica,Stella Dumenčić,Matej Mališa,Zvonimir Mrle,Bojan Crnković*

Main category: cs.RO

TL;DR: 论文提出了一种结合流场重建、动态概率建模、搜索控制和机器视觉的自主海上搜索系统，通过克罗地亚实地实验验证了在复杂环境下可靠检测漂浮目标的能力。


<details>
  <summary>Details</summary>
Motivation: 传统海上搜救面临复杂环境条件和不确定性挑战，需要开发能够整合多源信息、适应动态流场变化并实现可靠目标检测的自主系统。

Method: 采用流场重建与动态概率建模相结合的方法：基于实时漂流器数据获取、计算流体力学和数值优化的替代流场模型拟合、多无人机协同搜索控制与视觉感知，以及深度学习目标检测技术。

Result: 在克罗地亚瓦伦湾的实地实验中，系统在现实不确定性和复杂环境条件下成功实现了对漂浮目标的可靠检测，验证了紧密耦合方法的有效性。

Conclusion: 紧密耦合的多技术集成方法能够有效应对海上搜索中的复杂挑战，为未来自主海上搜救应用提供了具体的技术见解和实践指导。

Abstract: This paper presents the integration of flow field reconstruction, dynamic probabilistic modeling, search control, and machine vision detection in a system for autonomous maritime search operations. Field experiments conducted in Valun Bay (Cres Island, Croatia) involved real-time drifter data acquisition, surrogate flow model fitting based on computational fluid dynamics and numerical optimization, advanced multi-UAV search control and vision sensing, as well as deep learning-based object detection. The results demonstrate that a tightly coupled approach enables reliable detection of floating targets under realistic uncertainties and complex environmental conditions, providing concrete insights for future autonomous maritime search and rescue applications.

</details>


### [157] [Reliability-aware Execution Gating for Near-field and Off-axis Vision-guided Robotic Alignment](https://arxiv.org/abs/2602.08466)
*Ning Hu,Senhao Cao,Maochen Li*

Main category: cs.RO

TL;DR: 论文提出了一种可靠性感知的执行门控机制，用于提高近场视觉引导机器人系统的任务成功率，通过评估几何一致性和配置风险来选择性拒绝或缩放高风险位姿更新，而不修改位姿估计算法。


<details>
  <summary>Details</summary>
Motivation: 虽然位姿估计的数值精度已有显著提升，但实际机器人系统在执行任务时仍经常失败，即使位姿估计看起来很准确。这表明仅靠位姿精度不足以保证执行层面的可靠性。研究发现失败源于确定性的几何误差放大机制，即小的位姿估计误差通过系统结构和运动执行被放大，导致不稳定或失败的对接。

Method: 提出了一种可靠性感知的执行门控机制，该机制在任务执行层面操作，而非修改位姿估计算法。该方法在执行前评估几何一致性和配置风险，并选择性拒绝或缩放高风险的位姿更新。该机制与估计器无关，可轻松集成到基于经典几何和基于学习的位姿估计流程中。

Result: 在真实UR5机器人平台上进行实验验证，执行单步视觉对齐任务，涵盖不同相机-目标距离和离轴配置。实验结果表明，提出的执行门控显著提高了任务成功率，减少了执行方差，抑制了尾部风险行为，同时平均位姿精度基本保持不变。

Conclusion: 该研究强调了执行层面可靠性建模的重要性，并为提高近场视觉引导机器人系统的鲁棒性提供了实用解决方案。提出的机制与估计器无关，可轻松集成到现有系统中，为解决位姿精度与执行可靠性之间的差距提供了新思路。

Abstract: Vision-guided robotic systems are increasingly deployed in precision alignment tasks that require reliable execution under near-field and off-axis configurations. While recent advances in pose estimation have significantly improved numerical accuracy, practical robotic systems still suffer from frequent execution failures even when pose estimates appear accurate. This gap suggests that pose accuracy alone is insufficient to guarantee execution-level reliability. In this paper, we reveal that such failures arise from a deterministic geometric error amplification mechanism, in which small pose estimation errors are magnified through system structure and motion execution, leading to unstable or failed alignment. Rather than modifying pose estimation algorithms, we propose a Reliability-aware Execution Gating mechanism that operates at the execution level. The proposed approach evaluates geometric consistency and configuration risk before execution, and selectively rejects or scales high-risk pose updates. We validate the proposed method on a real UR5 robotic platform performing single-step visual alignment tasks under varying camera-target distances and off-axis configurations. Experimental results demonstrate that the proposed execution gating significantly improves task success rates, reduces execution variance, and suppresses tail-risk behavior, while leaving average pose accuracy largely unchanged. Importantly, the proposed mechanism is estimator-agnostic and can be readily integrated with both classical geometry-based and learning-based pose estimation pipelines. These results highlight the importance of execution-level reliability modeling and provide a practical solution for improving robustness in near-field vision-guided robotic systems.

</details>


### [158] [Characteristics, Management, and Utilization of Muscles in Musculoskeletal Humanoids: Empirical Study on Kengoro and Musashi](https://arxiv.org/abs/2602.08518)
*Kento Kawaharazuka,Kei Okada,Masayuki Inaba*

Main category: cs.RO

TL;DR: 该研究对肌肉骨骼人形机器人的特性进行分类分析，基于Kengoro和Musashi机器人，提出了五个关键属性，并探讨了相应的控制方法。


<details>
  <summary>Details</summary>
Motivation: 虽然已经开发了多种肌肉骨骼人形机器人并进行了控制机制研究，但缺乏对这些结构多样特性的统一讨论，以及如何管理和利用这些特性的系统分析。

Method: 基于开发的Kengoro和Musashi肌肉骨骼人形机器人，将肌肉骨骼结构特征分为五个属性：冗余性、独立性、各向异性、可变力臂和非线性弹性，并分析这些属性组合带来的优缺点。

Result: 提出了肌肉骨骼人形机器人的系统分类框架，特别讨论了身体图式学习、反射控制、肌肉分组和身体图式适应等方法，以及通过集成系统实现运动控制。

Conclusion: 该研究为肌肉骨骼人形机器人的特性提供了系统分析框架，讨论了当前实现方法和未来挑战，为这类机器人的控制和应用提供了理论基础。

Abstract: Various musculoskeletal humanoids have been developed so far, and numerous studies on control mechanisms have been conducted to leverage the advantages of their biomimetic bodies. However, there has not been sufficient and unified discussion on the diverse properties inherent in these musculoskeletal structures, nor on how to manage and utilize them. Therefore, this study categorizes and analyzes the characteristics of muscles, as well as their management and utilization methods, based on the various research conducted on the musculoskeletal humanoids we have developed, Kengoro and Musashi. We classify the features of the musculoskeletal structure into five properties: Redundancy, Independency, Anisotropy, Variable Moment Arm, and Nonlinear Elasticity. We then organize the diverse advantages and disadvantages of musculoskeletal humanoids that arise from the combination of these properties. In particular, we discuss body schema learning and reflex control, along with muscle grouping and body schema adaptation. Also, we describe the implementation of movements through an integrated system and discuss future challenges and prospects.

</details>


### [159] [UniPlan: Vision-Language Task Planning for Mobile Manipulation with Unified PDDL Formulation](https://arxiv.org/abs/2602.08537)
*Haoming Ye,Yunxiao Xiao,Cewu Lu,Panpan Cai*

Main category: cs.RO

TL;DR: UniPlan是一个视觉语言任务规划系统，将场景拓扑、视觉信息和机器人能力统一为PDDL表示，用于大规模室内环境中的长时程移动操作任务规划。


<details>
  <summary>Details</summary>
Motivation: 现有工作如UniDomain虽然能学习符号操作领域，但仅限于桌面操作，无法处理大规模室内环境中的移动操作任务。需要扩展系统以支持导航、门穿越和双手协调等复杂任务。

Method: 1) 程序化扩展UniDomain的桌面领域以支持移动操作；2) 使用视觉拓扑地图，包含带有场景图像的导航地标；3) 通过VLM将图像中的对象及其状态转换为PDDL表示；4) 重新连接节点为压缩的密集连接拓扑图；5) 使用现成PDDL求解器生成移动操作计划。

Result: 在具有真实世界图像的大规模地图上评估人类提出的任务，UniPlan在成功率、计划质量和计算效率方面显著优于VLM和LLM+PDDL规划方法。

Conclusion: UniPlan成功地将视觉语言模型推理与符号规划相结合，实现了大规模室内环境中长时程移动操作任务的有效规划，扩展了现有系统的能力范围。

Abstract: Integration of VLM reasoning with symbolic planning has proven to be a promising approach to real-world robot task planning. Existing work like UniDomain effectively learns symbolic manipulation domains from real-world demonstrations, described in Planning Domain Definition Language (PDDL), and has successfully applied them to real-world tasks. These domains, however, are restricted to tabletop manipulation. We propose UniPlan, a vision-language task planning system for long-horizon mobile-manipulation in large-scale indoor environments, that unifies scene topology, visuals, and robot capabilities into a holistic PDDL representation. UniPlan programmatically extends learned tabletop domains from UniDomain to support navigation, door traversal, and bimanual coordination. It operates on a visual-topological map, comprising navigation landmarks anchored with scene images. Given a language instruction, UniPlan retrieves task-relevant nodes from the map and uses a VLM to ground the anchored image into task-relevant objects and their PDDL states; next, it reconnects these nodes to a compressed, densely-connected topological map, also represented in PDDL, with connectivity and costs derived from the original map; Finally, a mobile-manipulation plan is generated using off-the-shelf PDDL solvers. Evaluated on human-raised tasks in a large-scale map with real-world imagery, UniPlan significantly outperforms VLM and LLM+PDDL planning in success rate, plan quality, and computational efficiency.

</details>


### [160] [Constrained Sampling to Guide Universal Manipulation RL](https://arxiv.org/abs/2602.08557)
*Marc Toussaint,Cornelius V. Braun,Eckart Cobo-Briesewitz,Sayantan Auddy,Armand Jordana,Justin Carpentier*

Main category: cs.RO

TL;DR: 提出Sample-Guided RL方法，利用基于模型的约束求解器采样可行配置来引导强化学习训练通用接触式操作策略


<details>
  <summary>Details</summary>
Motivation: 强化学习在接触式操作任务中可能难以充分探索和发现复杂操作策略，尤其是在稀疏奖励设置下。需要一种方法来引导RL探索可行的操作状态空间。

Method: 提出Sample-Guided RL方法：1) 使用基于模型的约束求解器高效采样满足碰撞、接触和力约束的可行配置；2) 利用这些采样数据引导RL训练通用（目标条件）操作策略；3) 探索两种引导方式：直接偏置状态访问，以及使用黑盒优化开环轨迹并添加行为克隆损失。

Result: 在双球体操作环境中，该方法发现了复杂操作策略并实现了高成功率；在更复杂的panda机械臂环境中，相比接近零的基线取得了显著成功率，展示了广泛的全身接触操作策略。

Conclusion: 通过结合基于模型的采样器和强化学习，Sample-Guided RL能够有效解决接触式操作中的探索挑战，发现复杂操作策略，为通用操作策略训练提供了有效方法。

Abstract: We consider how model-based solvers can be leveraged to guide training of a universal policy to control from any feasible start state to any feasible goal in a contact-rich manipulation setting. While Reinforcement Learning (RL) has demonstrated its strength in such settings, it may struggle to sufficiently explore and discover complex manipulation strategies, especially in sparse-reward settings. Our approach is based on the idea of a lower-dimensional manifold of feasible, likely-visited states during such manipulation and to guide RL with a sampler from this manifold. We propose Sample-Guided RL, which uses model-based constraint solvers to efficiently sample feasible configurations (satisfying differentiable collision, contact, and force constraints) and leverage them to guide RL for universal (goal-conditioned) manipulation policies. We study using this data directly to bias state visitation, as well as using black-box optimization of open-loop trajectories between random configurations to impose a state bias and optionally add a behavior cloning loss. In a minimalistic double sphere manipulation setting, Sample-Guided RL discovers complex manipulation strategies and achieves high success rates in reaching any statically stable state. In a more challenging panda arm setting, our approach achieves a significant success rate over a near-zero baseline, and demonstrates a breadth of complex whole-body-contact manipulation strategies.

</details>


### [161] [Head-to-Head autonomous racing at the limits of handling in the A2RL challenge](https://arxiv.org/abs/2602.08571)
*Simon Hoffmann,Simon Sagmeister,Tobias Betz,Joscha Bongard,Sascha Büttner,Dominic Ebner,Daniel Esser,Georg Jank,Sven Goblirsch,Alexander Langmann,Maximilian Leitenstern,Levent Ögretmen,Phillip Pitschi,Ann-Kathrin Schwehn,Cornelius Schröder,Marcel Weinmann,Frederik Werner,Boris Lohmann,Johannes Betz,Markus Lienkamp*

Main category: cs.RO

TL;DR: TUM团队为A2RL自动驾驶赛车比赛开发的算法与部署策略，模拟人类驾驶行为，在极限性能和车辆交互中获胜


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车在极限性能和动态下的多智能体交互提供了复杂挑战，是推进自动驾驶技术和提升道路安全的重要研究测试环境

Method: 开发了模拟人类驾驶行为的算法和部署策略，在车辆操控极限和多车辆交互方面进行优化

Result: 成功赢得了首届阿布扎比自动驾驶赛车联盟（A2RL）比赛

Conclusion: 分享了成功的关键因素和最重要的经验教训，展示了自动驾驶赛车技术的实际应用价值

Abstract: Autonomous racing presents a complex challenge involving multi-agent interactions between vehicles operating at the limit of performance and dynamics. As such, it provides a valuable research and testing environment for advancing autonomous driving technology and improving road safety. This article presents the algorithms and deployment strategies developed by the TUM Autonomous Motorsport team for the inaugural Abu Dhabi Autonomous Racing League (A2RL). We showcase how our software emulates human driving behavior, pushing the limits of vehicle handling and multi-vehicle interactions to win the A2RL. Finally, we highlight the key enablers of our success and share our most significant learnings.

</details>


### [162] [MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation](https://arxiv.org/abs/2602.08594)
*Zhenguo Sun,Bo-Sheng Huang,Yibo Peng,Xukun Li,Jingyu Ma,Yu Sun,Zhe Li,Haojun Jiang,Biao Gao,Zhenshan Bing,Xinlong Wang,Alois Knoll*

Main category: cs.RO

TL;DR: MOSAIC是一个开源的全栈系统，用于人形机器人运动跟踪和全身遥操作，通过通用运动跟踪器和快速残差适配来提升硬件上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有通用人形运动跟踪器虽然在仿真指标上表现良好，但在硬件遥操作中由于接口和动力学引起的误差而表现脆弱，需要解决仿真到现实的接口差距问题。

Method: 1. 通过强化学习在多源运动库上训练遥操作导向的通用运动跟踪器，强调世界坐标系运动一致性；2. 采用快速残差适配：用少量接口特定数据训练特定策略，然后通过加性残差模块蒸馏到通用跟踪器中。

Result: 系统消融实验、分布外基准测试和真实机器人实验表明，MOSAIC能够实现鲁棒的离线运动回放和在线长时域遥操作，在真实延迟和噪声下表现优异。

Conclusion: MOSAIC通过结合通用运动跟踪器和快速残差适配，有效解决了人形机器人遥操作中的仿真到现实接口差距问题，优于传统的微调或持续学习方法。

Abstract: Generalist humanoid motion trackers have recently achieved strong simulation metrics by scaling data and training, yet often remain brittle on hardware during sustained teleoperation due to interface- and dynamics-induced errors. We present MOSAIC, an open-source, full-stack system for humanoid motion tracking and whole-body teleoperation across multiple interfaces. MOSAIC first learns a teleoperation-oriented general motion tracker via RL on a multi-source motion bank with adaptive resampling and rewards that emphasize world-frame motion consistency, which is critical for mobile teleoperation. To bridge the sim-to-real interface gap without sacrificing generality, MOSAIC then performs rapid residual adaptation: an interface-specific policy is trained using minimal interface-specific data, and then distilled into the general tracker through an additive residual module, outperforming naive fine-tuning or continual learning. We validate MOSAIC with systematic ablations, out-of-distribution benchmarking, and real-robot experiments demonstrating robust offline motion replay and online long-horizon teleoperation under realistic latency and noise.

</details>


### [163] [A Precise Real-Time Force-Aware Grasping System for Robust Aerial Manipulation](https://arxiv.org/abs/2602.08599)
*Kenghou Hoi,Yuze Wu,Annan Ding,Junjie Wang,Anke Zhao,Chengqian Zhang,Fei Gao*

Main category: cs.RO

TL;DR: 提出基于低成本皮肤式触觉传感器的无人机力感知抓取框架，通过磁基触觉模块实现三维力测量，无需外部动捕系统即可完成安全抓取和实时重量测量


<details>
  <summary>Details</summary>
Motivation: 现有无人机抓取方案要么依赖昂贵笨重的力传感器不适合四旋翼平台，要么缺乏力反馈容易损坏脆弱物体，需要一种低成本、高精度的力感知解决方案

Method: 采用六个低成本皮肤式触觉传感器，设计磁基触觉传感模块实现三维力测量，通过参考霍尔传感器消除地磁干扰，简化校准流程，实现完全机载的力感知抓取控制

Result: 系统成功完成气球抓取、动态负载变化测试等真实场景实验，能够安全操作脆弱物体并实时测量抓取物品重量，验证了在各种空中操作场景中的有效性

Conclusion: 提出的力感知抓取框架显著提升了力敏感空中操作的实用性，无需外部动捕系统即可实现完全机载操作，为无人机安全抓取和物理交互提供了可行方案

Abstract: Aerial manipulation requires force-aware capabilities to enable safe and effective grasping and physical interaction. Previous works often rely on heavy, expensive force sensors unsuitable for typical quadrotor platforms, or perform grasping without force feedback, risking damage to fragile objects. To address these limitations, we propose a novel force-aware grasping framework incorporating six low-cost, sensitive skin-like tactile sensors. We introduce a magnetic-based tactile sensing module that provides high-precision three-dimensional force measurements. We eliminate geomagnetic interference through a reference Hall sensor and simplify the calibration process compared to previous work. The proposed framework enables precise force-aware grasping control, allowing safe manipulation of fragile objects and real-time weight measurement of grasped items. The system is validated through comprehensive real-world experiments, including balloon grasping, dynamic load variation tests, and ablation studies, demonstrating its effectiveness in various aerial manipulation scenarios. Our approach achieves fully onboard operation without external motion capture systems, significantly enhancing the practicality of force-sensitive aerial manipulation. The supplementary video is available at: https://www.youtube.com/watch?v=mbcZkrJEf1I.

</details>


### [164] [Mimic Intent, Not Just Trajectories](https://arxiv.org/abs/2602.08602)
*Renming Huang,Chendong Zeng,Wenjing Tang,Jingtian Cai,Cewu Lu,Panpan Cai*

Main category: cs.RO

TL;DR: MINT框架通过多尺度频率空间分词将行为意图与执行细节解耦，实现意图模仿而非轨迹模仿，提升模仿学习的适应性和技能迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于生成建模和预训练的模仿学习方法（如VLA模型）在适应环境变化和技能迁移方面仍有困难，主要原因是仅模仿原始轨迹而未理解底层意图。

Method: 提出MINT框架，通过多尺度频率空间分词实现意图与执行细节的解耦：使用粗到细的多尺度结构学习动作分词，最粗的分词捕获低频全局结构（意图分词），更细的分词编码高频细节（执行分词）。基于此层次结构，策略通过下一尺度自回归生成轨迹，进行渐进式的意图到执行推理。

Result: 在多个操作基准测试和真实机器人实验中，MINT实现了最先进的成功率、优越的推理效率、对干扰的鲁棒泛化能力，以及有效的单次技能迁移。

Conclusion: 通过明确解耦行为意图和执行细节，MINT框架显著提升了模仿学习的效率和泛化能力，实现了有效的单次技能迁移，为灵巧操作提供了更强大的学习范式。

Abstract: While imitation learning (IL) has achieved impressive success in dexterous manipulation through generative modeling and pretraining, state-of-the-art approaches like Vision-Language-Action (VLA) models still struggle with adaptation to environmental changes and skill transfer. We argue this stems from mimicking raw trajectories without understanding the underlying intent. To address this, we propose explicitly disentangling behavior intent from execution details in end-2-end IL: \textit{``Mimic Intent, Not just Trajectories'' (MINT)}. We achieve this via \textit{multi-scale frequency-space tokenization}, which enforces a spectral decomposition of action chunk representation. We learn action tokens with a multi-scale coarse-to-fine structure, and force the coarsest token to capture low-frequency global structure and finer tokens to encode high-frequency details. This yields an abstract \textit{Intent token} that facilitates planning and transfer, and multi-scale \textit{Execution tokens} that enable precise adaptation to environmental dynamics. Building on this hierarchy, our policy generates trajectories through \textit{next-scale autoregression}, performing progressive \textit{intent-to-execution reasoning}, thus boosting learning efficiency and generalization. Crucially, this disentanglement enables \textit{one-shot transfer} of skills, by simply injecting the Intent token from a demonstration into the autoregressive generation process. Experiments on several manipulation benchmarks and on a real robot demonstrate state-of-the-art success rates, superior inference efficiency, robust generalization against disturbances, and effective one-shot transfer.

</details>


### [165] [High-Speed Vision-Based Flight in Clutter with Safety-Shielded Reinforcement Learning](https://arxiv.org/abs/2602.08653)
*Jiarui Zhang,Chengyong Lei,Chengjiang Dai,Lijie Wang,Zhichao Han,Fei Gao*

Main category: cs.RO

TL;DR: 提出结合强化学习与模型安全机制的端到端框架，实现无人机高速自主导航与安全避障


<details>
  <summary>Details</summary>
Motivation: 传统模块化方法存在累积延迟，纯强化学习方法缺乏形式化安全保证，需要结合两者优势

Method: 端到端强化学习框架，训练时采用物理先验奖励结构，部署时集成实时安全过滤器将策略输出投影到可证明安全集

Result: 在密集障碍物和森林环境中实现高达7.5m/s的可靠高速导航，优于传统规划器和基于可微物理的端到端方法

Conclusion: 混合架构成功调和了高速飞行与鲁棒安全保证，展示了强大的泛化能力

Abstract: Quadrotor unmanned aerial vehicles (UAVs) are increasingly deployed in complex missions that demand reliable autonomous navigation and robust obstacle avoidance. However, traditional modular pipelines often incur cumulative latency, whereas purely reinforcement learning (RL) approaches typically provide limited formal safety guarantees. To bridge this gap, we propose an end-to-end RL framework augmented with model-based safety mechanisms. We incorporate physical priors in both training and deployment. During training, we design a physics-informed reward structure that provides global navigational guidance. During deployment, we integrate a real-time safety filter that projects the policy outputs onto a provably safe set to enforce strict collision-avoidance constraints. This hybrid architecture reconciles high-speed flight with robust safety assurances. Benchmark evaluations demonstrate that our method outperforms both traditional planners and recent end-to-end obstacle avoidance approaches based on differentiable physics. Extensive experiments demonstrate strong generalization, enabling reliable high-speed navigation in dense clutter and challenging outdoor forest environments at velocities up to 7.5m/s.

</details>


### [166] [Mind the Gap: Learning Implicit Impedance in Visuomotor Policies via Intent-Execution Mismatch](https://arxiv.org/abs/2602.08776)
*Cuijie Xu,Shurui Zheng,Zihao Su,Yuanfan Xu,Tinghao Yi,Xudong Zhang,Jian Wang,Yu Wang,Jinchen Yu*

Main category: cs.RO

TL;DR: 提出Dual-State Conditioning框架，将学习目标从"执行克隆"转向"意图克隆"，通过预测主端意图实现隐式阻抗控制和系统辨识，使低成本硬件无需力传感器即可感知力和动态补偿。


<details>
  <summary>Details</summary>
Motivation: 遥操作中人类操作者作为闭环控制器主动补偿硬件缺陷（延迟、摩擦、缺乏力反馈），但标准行为克隆只模仿机器人执行轨迹，忽略了这种补偿机制，导致无法克服接触刚度和跟踪滞后问题。

Method: 提出Dual-State Conditioning框架，将意图-执行不匹配视为关键信号而非噪声，预测主端意图生成"虚拟平衡点"实现隐式阻抗控制；通过显式条件化不匹配历史进行隐式系统辨识；将策略制定为轨迹修复器以弥补推理延迟。

Result: 在无传感器、低成本双手设置上验证，在需要接触丰富操作和动态跟踪的任务中，标准执行克隆因无法克服接触刚度和跟踪滞后而失败，而提出的不匹配感知方法实现了鲁棒成功。

Conclusion: 为低成本硬件提供了简约的行为克隆框架，无需依赖显式力传感即可实现力感知和动态补偿，通过意图克隆而非执行克隆来学习人类操作者的补偿策略。

Abstract: Teleoperation inherently relies on the human operator acting as a closed-loop controller to actively compensate for hardware imperfections, including latency, mechanical friction, and lack of explicit force feedback. Standard Behavior Cloning (BC), by mimicking the robot's executed trajectory, fundamentally ignores this compensatory mechanism. In this work, we propose a Dual-State Conditioning framework that shifts the learning objective to "Intent Cloning" (master command). We posit that the Intent-Execution Mismatch, the discrepancy between master command and slave response, is not noise, but a critical signal that physically encodes implicit interaction forces and algorithmically reveals the operator's strategy for overcoming system dynamics. By predicting the master intent, our policy learns to generate a "virtual equilibrium point", effectively realizing implicit impedance control. Furthermore, by explicitly conditioning on the history of this mismatch, the model performs implicit system identification, perceiving tracking errors as external forces to close the control loop. To bridge the temporal gap caused by inference latency, we further formulate the policy as a trajectory inpainter to ensure continuous control. We validate our approach on a sensorless, low-cost bi-manual setup. Empirical results across tasks requiring contact-rich manipulation and dynamic tracking reveal a decisive gap: while standard execution-cloning fails due to the inability to overcome contact stiffness and tracking lag, our mismatch-aware approach achieves robust success. This presents a minimalist behavior cloning framework for low-cost hardware, enabling force perception and dynamic compensation without relying on explicit force sensing. Videos are available on the \href{https://xucj98.github.io/mind-the-gap-page/}{project page}.

</details>


### [167] [GaussianCaR: Gaussian Splatting for Efficient Camera-Radar Fusion](https://arxiv.org/abs/2602.08784)
*Santiago Montiel-Marín,Miguel Antunes-García,Fabio Sánchez-García,Angel Llamazares,Holger Caesar,Luis M. Bergasa*

Main category: cs.RO

TL;DR: GaussianCaR：使用高斯泼溅作为通用视图变换器，将图像像素和雷达点映射到BEV表示中，实现高效相机-雷达融合的BEV分割网络


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要准确感知动态物体和地图元素，虽然视觉方法已成为标准，但与雷达测量的有效融合可以提升性能。现有BEV融合方法存在视图差异问题，需要高效解决方案。

Method: 提出GaussianCaR网络，重新利用高斯泼溅作为高效通用视图变换器，将图像像素和雷达点映射到共同BEV表示。结合多尺度融合和Transformer解码器提取BEV特征。

Result: 在nuScenes数据集上，车辆、道路和车道分隔线的IoU分别达到57.3%、82.9%和50.1%，性能达到或超越SOTA，同时推理速度快3.2倍。

Conclusion: GaussianCaR通过高斯泼溅有效解决视图差异问题，实现了高效准确的相机-雷达BEV分割，为自动驾驶感知提供了实用解决方案。

Abstract: Robust and accurate perception of dynamic objects and map elements is crucial for autonomous vehicles performing safe navigation in complex traffic scenarios. While vision-only methods have become the de facto standard due to their technical advances, they can benefit from effective and cost-efficient fusion with radar measurements. In this work, we advance fusion methods by repurposing Gaussian Splatting as an efficient universal view transformer that bridges the view disparity gap, mapping both image pixels and radar points into a common Bird's-Eye View (BEV) representation. Our main contribution is GaussianCaR, an end-to-end network for BEV segmentation that, unlike prior BEV fusion methods, leverages Gaussian Splatting to map raw sensor information into latent features for efficient camera-radar fusion. Our architecture combines multi-scale fusion with a transformer decoder to efficiently extract BEV features. Experimental results demonstrate that our approach achieves performance on par with, or even surpassing, the state of the art on BEV segmentation tasks (57.3%, 82.9%, and 50.1% IoU for vehicles, roads, and lane dividers) on the nuScenes dataset, while maintaining a 3.2x faster inference runtime. Code and project page are available online.

</details>


### [168] [A Generic Service-Oriented Function Offloading Framework for Connected Automated Vehicles](https://arxiv.org/abs/2602.08799)
*Robin Dehler,Michael Buchholz*

Main category: cs.RO

TL;DR: 本文提出一个通用的函数卸载框架，用于自动驾驶中的计算任务分配，采用基于位置的高效卸载决策方法，并在轨迹规划用例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 联网自动驾驶车辆(CAV)和其他自主机器人在计算能力和可用能源方面存在限制，函数卸载通过将计算任务在本地和远程计算设备之间分配，可以解决这些限制。

Method: 提出一个通用的函数卸载框架，可以卸载任意计算任务集，特别关注自动驾驶应用。框架设计灵活，可集成不同的卸载决策算法和QoS要求。提出基于位置的高效方法，根据CAV位置决定任务在本地还是远程处理。在服务导向的轨迹规划用例中应用该框架，将CAV的轨迹规划任务卸载到多接入边缘计算(MEC)服务器。

Result: 评估在仿真和实际应用中进行，展示了函数卸载框架在保证轨迹规划QoS的同时提高CAV计算效率的潜力。仿真结果还显示框架能够适应涉及多个CAV同时发出卸载请求的多样化场景。

Conclusion: 提出的函数卸载框架能够有效解决CAV的计算限制问题，通过基于位置的卸载决策方法，在保证服务质量的同时提高计算效率，并展现出良好的场景适应性。

Abstract: Function offloading is a promising solution to address limitations concerning computational capacity and available energy of Connected Automated Vehicles~(CAVs) or other autonomous robots by distributing computational tasks between local and remote computing devices in form of distributed services. This paper presents a generic function offloading framework that can be used to offload an arbitrary set of computational tasks with a focus on autonomous driving. To provide flexibility, the function offloading framework is designed to incorporate different offloading decision making algorithms and quality of service~(QoS) requirements that can be adjusted to different scenarios or the objectives of the CAVs. With a focus on the applicability, we propose an efficient location-based approach, where the decision whether tasks are processed locally or remotely depends on the location of the CAV. We apply the proposed framework on the use case of service-oriented trajectory planning, where we offload the trajectory planning task of CAVs to a Multi-Access Edge Computing~(MEC) server. The evaluation is conducted in both simulation and real-world application. It demonstrates the potential of the function offloading framework to guarantee the QoS for trajectory planning while improving the computational efficiency of the CAVs. Moreover, the simulation results also show the adaptability of the framework to diverse scenarios involving simultaneous offloading requests from multiple CAVs.

</details>


### [169] [Multi-Staged Framework for Safety Analysis of Offloaded Services in Distributed Intelligent Transportation Systems](https://arxiv.org/abs/2602.08821)
*Robin Dehler,Oliver Schumann,Jona Ruof,Michael Buchholz*

Main category: cs.RO

TL;DR: 提出一个面向服务的功能卸载安全框架，用于分布式智能交通系统中的自动驾驶车辆，通过多阶段安全分析验证远程服务的可靠性


<details>
  <summary>Details</summary>
Motivation: 在分布式智能交通系统中，自动驾驶车辆通过服务导向架构进行功能卸载可以扩展本地可用服务并降低计算复杂度，但远程服务存在数据被攻击者篡改或无线传输被拦截的安全风险，需要建立可靠的安全验证机制

Method: 首先分析分布式环境中的SOA概念，然后推导出验证远程服务可靠性和本地接收数据安全性的安全框架。针对自动驾驶任务可能卸载多个不同服务的情况，提出基于本地和远程服务组合的多阶段安全分析框架，并将该框架集成到先前提出的SOFOF（面向服务的功能卸载框架）中以提高效率

Result: 评估了扩展框架在计算复杂度方面的性能表现（功能卸载的主要动机是节能），并验证了其检测来自受损远程服务数据的能力

Conclusion: 通过将多阶段安全分析框架集成到SOFOF中，为分布式智能交通系统中的自动驾驶车辆功能卸载提供了有效的安全验证机制，能够在保证计算效率的同时检测远程服务的数据完整性

Abstract: The integration of service-oriented architectures (SOA) with function offloading for distributed, intelligent transportation systems (ITS) offers the opportunity for connected autonomous vehicles (CAVs) to extend their locally available services. One major goal of offloading a subset of functions in the processing chain of a CAV to remote devices is to reduce the overall computational complexity on the CAV. The extension of using remote services, however, requires careful safety analysis, since the remotely created data are corrupted more easily, e.g., through an attacker on the remote device or by intercepting the wireless transmission. To tackle this problem, we first analyze the concept of SOA for distributed environments. From this, we derive a safety framework that validates the reliability of remote services and the data received locally. Since it is possible for the autonomous driving task to offload multiple different services, we propose a specific multi-staged framework for safety analysis dependent on the service composition of local and remote services. For efficiency reasons, we directly include the multi-staged framework for safety analysis in our service-oriented function offloading framework (SOFOF) that we have proposed in earlier work. The evaluation compares the performance of the extended framework considering computational complexity, with energy savings being a major motivation for function offloading, and its capability to detect data from corrupted remote services.

</details>


### [170] [Finite-Time Teleoperation of Euler-Lagrange Systems via Energy-Shaping](https://arxiv.org/abs/2602.08845)
*Lazaro F. Torres,Carlos I. Aldana,Emmanuel Nuño,Emmanuel Cruz-Zavala*

Main category: cs.RO

TL;DR: 提出了一族用于双边遥操作非线性欧拉-拉格朗日系统的有限时间控制器，基于能量整形框架，在无时延情况下能实现位置误差和速度的全局有限时间收敛。


<details>
  <summary>Details</summary>
Motivation: 针对双边遥操作系统的控制问题，需要设计能够实现有限时间收敛的控制器，以提高系统的响应速度和跟踪性能，同时保持控制器的简单性和连续性。

Method: 基于能量整形框架，设计连续时间比例加阻尼注入控制方案，在假设人机交互和环境交互均为被动的前提下，构建具有负次齐次近似的闭环系统。

Result: 控制器在无时延情况下能确保位置误差和速度全局收敛到零，且收敛时间为有限时间，通过仿真和实验验证了控制器的有效性。

Conclusion: 提出的有限时间控制器简单有效，适用于双边遥操作非线性系统，在无时延条件下能实现全局有限时间收敛，为遥操作控制提供了新的解决方案。

Abstract: This paper proposes a family of finite-time controllers for the bilateral teleoperation of fully actuated nonlinear Euler-Lagrange systems. Based on the energy-shaping framework and under the standard assumption of passive interactions with the human and the environment, the controllers ensure that the position error and velocities globally converge to zero in the absence of time delays. In this case, the closed-loop system admits a homogeneous approximation of negative degree, and thus the control objective is achieved in finite-time. The proposed controllers are simple, continuous-time proportional-plus-damping-injection schemes, validated through both simulation and experimental results.

</details>


### [171] [Reduced-order Control and Geometric Structure of Learned Lagrangian Latent Dynamics](https://arxiv.org/abs/2602.08963)
*Katharina Friedl,Noémie Jaquier,Seungyeon Kim,Jens Lundell,Danica Kragic*

Main category: cs.RO

TL;DR: 提出基于学习保持结构的降阶动力学模型的隐式控制框架，用于高维拉格朗日系统，提供稳定性和收敛性保证


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的控制需要精确的物理动力学模型，但对于高维机械系统（如可变形物体或软体机器人）难以获得。神经网络可以学习复杂动力学，但要么限于低维系统，要么缺乏物理结构嵌入而只能提供有限的形式控制保证

Method: 引入基于学习保持结构的降阶动力学的隐式控制框架，推导全驱动系统的降阶跟踪律，采用黎曼几何视角研究投影基模型降阶，量化建模误差来源，推导稳定性和收敛性的可解释条件，扩展控制器和分析到欠驱动系统

Result: 在模拟和真实系统上的实验结果验证了理论研究和控制器的准确性

Conclusion: 提出的框架能够为高维拉格朗日系统提供具有稳定性和收敛性保证的控制，通过保持物理结构的降阶模型和可解释的稳定性条件，解决了传统方法在高维系统控制中的局限性

Abstract: Model-based controllers can offer strong guarantees on stability and convergence by relying on physically accurate dynamic models. However, these are rarely available for high-dimensional mechanical systems such as deformable objects or soft robots. While neural architectures can learn to approximate complex dynamics, they are either limited to low-dimensional systems or provide only limited formal control guarantees due to a lack of embedded physical structure. This paper introduces a latent control framework based on learned structure-preserving reduced-order dynamics for high-dimensional Lagrangian systems. We derive a reduced tracking law for fully actuated systems and adopt a Riemannian perspective on projection-based model-order reduction to study the resulting latent and projected closed-loop dynamics. By quantifying the sources of modeling error, we derive interpretable conditions for stability and convergence. We extend the proposed controller and analysis to underactuated systems by introducing learned actuation patterns. Experimental results on simulated and real-world systems validate our theoretical investigation and the accuracy of our controllers.

</details>


### [172] [CLUE: Crossmodal disambiguation via Language-vision Understanding with attEntion](https://arxiv.org/abs/2602.08999)
*Mouad Abrini,Mohamed Chetouani*

Main category: cs.RO

TL;DR: CLUE提出了一种将VLM的跨模态注意力转换为显式空间信号的方法，用于决定何时在交互式视觉定位中询问澄清问题，解决了现有模型缺乏显式歧义检测机制的问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入日常生活，人机交互变得更加复杂。交互式视觉定位(IVG)要求机器人理解人类意图并解决歧义，但现有IVG模型缺乏显式机制来决定何时询问澄清问题，仅依赖学习到的隐式表示。

Method: 1. 提取文本到图像的注意力图；2. 使用轻量级CNN检测指代歧义；3. 使用LoRA微调的解码器进行对话并生成定位位置标记；4. 在真实世界IVG数据集和混合歧义集上训练。

Result: 1. 仅使用IVG监督，模型超越最先进方法，同时使用参数高效微调；2. 歧义检测器优于先前基线；3. 成功将VLM内部跨模态注意力转换为显式空间信号用于决策。

Conclusion: CLUE通过将VLM的跨模态注意力转换为显式空间信号，有效解决了交互式视觉定位中的歧义检测问题，为机器人何时询问澄清问题提供了明确的决策依据，代码和数据已公开。

Abstract: With the increasing integration of robots into daily life, human-robot interaction has become more complex and multifaceted. A critical component of this interaction is Interactive Visual Grounding (IVG), through which robots must interpret human intentions and resolve ambiguity. Existing IVG models generally lack a mechanism to determine when to ask clarification questions, as they implicitly rely on their learned representations. CLUE addresses this gap by converting the VLM's cross-modal attention into an explicit, spatially grounded signal for deciding when to ask. We extract text to image attention maps and pass them to a lightweight CNN to detect referential ambiguity, while a LoRA fine-tuned decoder conducts the dialog and emits grounding location tokens. We train on a real-world interactive dataset for IVG, and a mixed ambiguity set for the detector. With InViG-only supervision, our model surpasses a state-of-the-art method while using parameter-efficient fine-tuning. Similarly, the ambiguity detector outperforms prior baselines. Overall, CLUE turns the internal cross-modal attention of a VLM into an explicit, spatially grounded signal for deciding when to ask. The data and code are publicly available at: mouadabrini.github.io/clue

</details>


### [173] [From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection](https://arxiv.org/abs/2602.09002)
*Zilin Fang,Anxing Xiao,David Hsu,Gim Hee Lee*

Main category: cs.RO

TL;DR: 提出一个社交机器人导航框架，结合几何规划与上下文社交推理，使用微调的视觉语言模型评估候选路径，实现实时社交优化导航


<details>
  <summary>Details</summary>
Motivation: 人类环境中的社交导航不仅需要满足几何约束，还需要考虑社会规范和活动干扰。现有方法缺乏对社交期望的上下文推理能力，需要将常识推理融入规划过程

Method: 系统先提取障碍物和人类动态生成几何可行的候选路径，然后使用微调的视觉语言模型（VLM）基于上下文社交期望评估这些路径，选择社交最优路径给控制器。该任务特定的VLM将大型基础模型的社交推理能力蒸馏到更小高效的模型中

Result: 在四个社交导航场景中的实验表明，该方法实现了最佳整体性能，具有最低的个人空间侵犯持续时间、最小的面向行人时间，且无社交区域入侵

Conclusion: 提出的框架成功将几何规划与上下文社交推理相结合，通过任务特定的VLM实现实时社交优化导航，在多样的人机交互场景中表现出色

Abstract: Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io

</details>


### [174] [Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction](https://arxiv.org/abs/2602.09013)
*Hongyi Chen,Tony Dong,Tiancheng Wu,Liquan Wang,Yash Jangir,Yaru Niu,Yufei Ye,Homanga Bharadhwaj,Zackory Erickson,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: VIDEOMANIP：无需设备，直接从RGB人类视频学习灵巧机器人手操作，通过重建4D轨迹、接触优化和演示合成实现高效策略学习


<details>
  <summary>Details</summary>
Motivation: 现有多指机器人手操作方法依赖穿戴设备或专用传感设备进行人类遥操作，限制了可扩展性。需要一种无需设备、可直接从普通RGB视频学习的方法来解决高维动作空间和大规模训练数据获取困难的问题。

Method: 1) 从单目RGB视频重建4D机器人-物体轨迹（估计人手姿态、物体网格）；2) 将重建的人类动作重定向到机器人手；3) 引入手-物体接触优化和交互中心抓握建模；4) 演示合成策略从单个视频生成多样化训练轨迹

Result: 仿真中：在Inspire Hand上对20个不同物体达到70.25%成功率。真实世界：在LEAP Hand上对7个任务平均达到62.86%成功率，比基于重定向的方法高出15.87%

Conclusion: VIDEOMANIP展示了无需设备直接从RGB人类视频学习灵巧机器人手操作的可行性，通过计算机视觉重建、接触优化和演示合成实现了高效且可泛化的策略学习，显著优于现有方法

Abstract: Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.

</details>


### [175] [Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models](https://arxiv.org/abs/2602.09017)
*Zichen Jeff Cui,Omar Rayyan,Haritheja Etukuru,Bowen Tan,Zavier Andrianarivo,Zicheng Teng,Yihang Zhou,Krish Mehta,Nicholas Wojno,Kevin Yuanbo Wu,Manan H Anjaria,Ziyuan Wu,Manrong Mao,Guangxun Zhang,Binit Shah,Yejin Kim,Soumith Chintala,Lerrel Pinto,Nur Muhammad Mahi Shafiullah*

Main category: cs.RO

TL;DR: CAP用物理接触点替代语言提示，通过模块化策略库和仿真迭代实现高效机器人学习，仅用23小时演示数据就能泛化到新环境和形态


<details>
  <summary>Details</summary>
Motivation: 当前基于语言提示的机器人学习范式存在根本矛盾：语言过于抽象，无法指导具体物理理解以实现鲁棒操作。需要更具体的物理接触信息来指导机器人学习。

Method: 提出接触锚定策略(CAP)：1) 用空间中的物理接触点替代语言条件；2) 构建模块化实用模型库而非单一通用策略；3) 建立EgoGym轻量仿真基准，通过实-仿迭代循环识别故障模式并优化模型和数据集。

Result: CAP仅用23小时演示数据就能泛化到新环境和机器人形态，在三种基本操作技能上实现开箱即用的泛化，在零样本评估中比最先进的大型视觉语言模型性能提升56%。

Conclusion: 通过物理接触条件和仿真迭代，CAP提供了一种更高效、更鲁棒的机器人学习方法，超越了基于语言提示的范式，并将开源所有资源促进社区发展。

Abstract: The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/

</details>


### [176] [Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving](https://arxiv.org/abs/2602.09018)
*Amir Mallak,Alaa Maalouf*

Main category: cs.RO

TL;DR: 论文系统分析了自动驾驶策略在分布外（OOD）环境中的鲁棒性，通过五个维度（场景、季节、天气、时间、交通参与者）进行分解评估，发现ViT策略比CNN/FC更鲁棒，基础模型特征显著提升性能，多环境训练能增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶策略的OOD鲁棒性通常被简化为单一指标，掩盖了策略失效的具体原因。需要系统分解环境因素，理解不同扰动如何影响策略性能，为设计鲁棒策略提供指导。

Method: 在VISTA仿真环境中进行闭环控制测试，将环境分解为五个维度：场景（乡村/城市）、季节、天气、时间（白天/夜晚）、交通参与者组合。采用k因子扰动（k∈{0,1,2,3}）进行控制实验，比较FC、CNN、ViT策略，在冻结的基础模型特征上训练紧凑ViT头，并改变ID数据的规模、多样性和时间上下文。

Result: (1) ViT策略比同等规模的CNN/FC更鲁棒，基础模型特征带来SOTA性能但增加延迟；(2) 简单多帧输入不优于最佳单帧基线；(3) 最大性能下降来自乡村→城市和白天→夜晚（各约31%）；(4) 基础模型特征策略在三个同时变化下仍保持85%以上成功率；(5) 因素间存在非线性交互作用；(6) 冬季/雪天训练对单因素变化最鲁棒；(7) 增加训练轨迹能提升鲁棒性（+11.8点）；(8) 多环境训练能增强泛化能力。

Conclusion: 研究提供了自动驾驶OOD鲁棒策略的设计规则：使用ViT架构和基础模型特征，进行多环境训练，针对性暴露困难条件，理解因素间的非线性交互作用，避免简单多帧输入，根据目标环境选择最佳训练配置。

Abstract: Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \in \{0,1,2,3\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\rightarrow$ urban and day $\rightarrow$ night ($\sim 31\%$ each); actor swaps $\sim 10\%$, moderate rain $\sim 7\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\% \rightarrow 70.1\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies.

</details>


### [177] [$χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies](https://arxiv.org/abs/2602.09021)
*Checheng Yu,Chonghao Sima,Gangcheng Jiang,Hai Zhang,Haoguang Mai,Hongyang Li,Huijie Wang,Jin Chen,Kaiyang Wu,Li Chen,Lirui Zhao,Modi Shi,Ping Luo,Qingwen Bu,Shijia Peng,Tianyu Li,Yibo Yuan*

Main category: cs.RO

TL;DR: 提出χ₀框架，通过模型算术、阶段优势估计和训练-部署对齐三个技术支柱，解决机器人操作中的分布偏移问题，实现高可靠性长时程衣物操作。


<details>
  <summary>Details</summary>
Motivation: 传统高可靠性长时程机器人操作依赖大规模数据和计算，但真正的瓶颈是演示分布、策略归纳偏置和执行分布之间的系统性不一致，导致多阶段任务中的累积误差。

Method: χ₀框架包含三个核心技术：1) 模型算术：权重空间合并策略，高效吸收不同演示的分布变化；2) 阶段优势：阶段感知优势估计器，提供稳定密集的进度信号；3) 训练-部署对齐：通过时空增强、启发式DAgger校正和时间分块平滑来弥合分布差距。

Result: χ₀使双臂机器人能够协作完成衣物操作任务（铺平、折叠、悬挂），系统可从任意初始状态连续运行24小时。实验显示χ₀在成功率上超越最先进的π₀.5近250%，仅需20小时数据和8个A100 GPU。

Conclusion: χ₀框架通过资源高效的方法解决了机器人操作中的分布不一致问题，实现了生产级别的鲁棒性，为社区提供了可复现的代码、数据和模型。

Abstract: High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $χ_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $χ_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $χ_{0}$ surpasses the state-of-the-art $π_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.

</details>


### [178] [TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation](https://arxiv.org/abs/2602.09023)
*Qinwen Xu,Jiaming Liu,Rui Zhou,Shaojun Shi,Nuowei Han,Zhuoyang Liu,Chenyang Gu,Shuo Gu,Yang Yue,Gao Huang,Wenzhao Zheng,Sirui Han,Peng Jia,Shanghang Zhang*

Main category: cs.RO

TL;DR: TwinRL框架通过数字孪生与真实世界协作的强化学习，解决了VLA模型在真实机器人操作中探索效率低、成本高的问题，实现了100%成功率并显著加速训练。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言-动作模型具有强大的泛化能力，但受限于专家演示的高成本和真实世界交互不足。在线强化学习虽然能改进基础模型，但在真实机器人操作中面临探索效率低和探索空间受限的问题。

Method: 提出TwinRL数字孪生-真实世界协作强化学习框架：1）从智能手机拍摄场景高效重建高保真数字孪生；2）在SFT预热阶段使用数字孪生扩展探索空间；3）提出模拟到真实的引导探索策略，先在数字孪生中并行在线RL，然后识别易失败但信息丰富的配置，指导真实机器人上的人机协同rollout。

Result: TwinRL在真实世界演示覆盖的分布内区域和分布外区域都接近100%成功率，比现有真实世界RL方法至少加速30%，在四个任务上平均仅需约20分钟。

Conclusion: TwinRL框架通过数字孪生与真实世界的协同，有效解决了VLA模型在真实机器人操作中的探索效率问题，显著降低了训练成本并提高了成功率。

Abstract: Despite strong generalization capabilities, Vision-Language-Action (VLA) models remain constrained by the high cost of expert demonstrations and insufficient real-world interaction. While online reinforcement learning (RL) has shown promise in improving general foundation models, applying RL to VLA manipulation in real-world settings is still hindered by low exploration efficiency and a restricted exploration space. Through systematic real-world experiments, we observe that the effective exploration space of online RL is closely tied to the data distribution of supervised fine-tuning (SFT). Motivated by this observation, we propose TwinRL, a digital twin-real-world collaborative RL framework designed to scale and guide exploration for VLA models. First, a high-fidelity digital twin is efficiently reconstructed from smartphone-captured scenes, enabling realistic bidirectional transfer between real and simulated environments. During the SFT warm-up stage, we introduce an exploration space expansion strategy using digital twins to broaden the support of the data trajectory distribution. Building on this enhanced initialization, we propose a sim-to-real guided exploration strategy to further accelerate online RL. Specifically, TwinRL performs efficient and parallel online RL in the digital twin prior to deployment, effectively bridging the gap between offline and online training stages. Subsequently, we exploit efficient digital twin sampling to identify failure-prone yet informative configurations, which are used to guide targeted human-in-the-loop rollouts on the real robot. In our experiments, TwinRL approaches 100% success in both in-distribution regions covered by real-world demonstrations and out-of-distribution regions, delivering at least a 30% speedup over prior real-world RL methods and requiring only about 20 minutes on average across four tasks.

</details>
