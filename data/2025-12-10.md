<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 19]
- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Short-Context Dominance: How Much Local Context Natural Language Actually Needs?](https://arxiv.org/abs/2512.08082)
*Vala Vakilian,Zimeng Wang,Ankit Singh Rawat,Christos Thrampoulidis*

Main category: cs.CL

TL;DR: 研究提出短上下文主导假说，发现75-80%的长序列仅需最后96个token即可准确预测，开发DaMCL检测需要长上下文的挑战序列，并提出解码算法提升长距离相关token的性能。


<details>
  <summary>Details</summary>
Motivation: 研究短上下文主导假说：验证大多数序列是否仅需局部前缀即可预测下一个token，并解决短上下文主导带来的偏见问题。

Method: 使用大语言模型作为统计预言机测量最小上下文长度(MCL)；提出无需实际下一个token知识的分布感知MCL(DaMCL)；开发解码算法检测并提升长距离相关token。

Result: 在1-7k token的长文档序列中，75-80%仅需最后96个token；DaMCL能有效检测长上下文序列；解码算法在问答任务中提升性能。

Conclusion: 短上下文主导现象普遍存在，但通过DaMCL检测挑战序列并调整解码策略，可以缓解由此产生的偏见，提升模型在需要长距离依赖任务上的表现。

Abstract: We investigate the short-context dominance hypothesis: that for most sequences, a small local prefix suffices to predict their next tokens. Using large language models as statistical oracles, we measure the minimum context length (MCL) needed to reproduce accurate full-context predictions across datasets with sequences of varying lengths. For sequences with 1-7k tokens from long-context documents, we consistently find that 75-80% require only the last 96 tokens at most. Given the dominance of short-context tokens, we then ask whether it is possible to detect challenging long-context sequences for which a short local prefix does not suffice for prediction. We introduce a practical proxy to MCL, called Distributionally Aware MCL (DaMCL), that does not require knowledge of the actual next-token and is compatible with sampling strategies beyond greedy decoding. Our experiments validate that simple thresholding of the metric defining DaMCL achieves high performance in detecting long vs. short context sequences. Finally, to counter the bias that short-context dominance induces in LLM output distributions, we develop an intuitive decoding algorithm that leverages our detector to identify and boost tokens that are long-range-relevant. Across Q&A tasks and model architectures, we confirm that mitigating the bias improves performance.

</details>


### [2] [Adaptation of Embedding Models to Financial Filings via LLM Distillation](https://arxiv.org/abs/2512.08088)
*Eliot Brenner,Dominic Seyler,Manjunath Hegde,Andrei Simion,Koustuv Dasgupta,Bing Xiang*

Main category: cs.CL

TL;DR: 提出一個可擴展的訓練流程，使用通用檢索嵌入模型作為基礎，從無標註語料訓練專用模型，在金融領域檢索任務上顯著提升效能。


<details>
  <summary>Details</summary>
Motivation: 儘管生成式大語言模型有進展，但專用對話AI的實際應用仍受限於計算成本、延遲要求和特定領域相關性測量的需求。現有嵌入模型在前兩個限制上表現良好，但在金融等專業領域的信息檢索上表現不佳。

Method: 提出一個可擴展的訓練流程，使用通用檢索嵌入模型作為基礎，從無標註語料訓練專用模型。方法採用師生模型互動，交錯進行基於檢索的困難正負例挖掘與迭代重新訓練，使用LLM判斷的相關性將領域知識蒸餾到緊湊的檢索器中。

Result: 在14種財務文件類型的21,800個查詢-文件對上，MRR@5平均提升27.7%，mean DCG@5提升44.6%；在FinanceBench的4個文件類別中，3個類別的NDCG有所改善。

Conclusion: 該方法提供了一個成本效益高的解決方案，在不需人工標註的情況下，彌合通用模型與專業領域之間的差距，特別適用於金融等專業領域的檢索任務。

Abstract: Despite advances in generative large language models (LLMs), practical application of specialized conversational AI agents remains constrained by computation costs, latency requirements, and the need for precise domain-specific relevance measures. While existing embedding models address the first two constraints, they underperform on information retrieval in specialized domains like finance. This paper introduces a scalable pipeline that trains specialized models from an unlabeled corpus using a general purpose retrieval embedding model as foundation. Our method yields an average of 27.7% improvement in MRR$\texttt{@}$5, 44.6% improvement in mean DCG$\texttt{@}$5 across 14 financial filing types measured over 21,800 query-document pairs, and improved NDCG on 3 of 4 document classes in FinanceBench. We adapt retrieval embeddings (bi-encoder) for RAG, not LLM generators, using LLM-judged relevance to distill domain knowledge into a compact retriever. There are prior works which pair synthetically generated queries with real passages to directly fine-tune the retrieval model. Our pipeline differs from these by introducing interaction between student and teacher models that interleaves retrieval-based mining of hard positive/negative examples from the unlabeled corpus with iterative retraining of the student model's weights using these examples. Each retrieval iteration uses the refined student model to mine the corpus for progressively harder training examples for the subsequent training iteration. The methodology provides a cost-effective solution to bridging the gap between general-purpose models and specialized domains without requiring labor-intensive human annotation.

</details>


### [3] [Segment, Embed, and Align: A Universal Recipe for Aligning Subtitles to Signing](https://arxiv.org/abs/2512.08094)
*Zifan Jiang,Youngjoon Jang,Liliane Momeni,Gül Varol,Sarah Ebling,Andrew Zisserman*

Main category: cs.CL

TL;DR: SEA是一个通用的字幕对齐框架，可将口语文本与手语视频时间戳对齐，支持多语言和多领域，无需特定数据集训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于特定语言或数据集的端到端训练，限制了通用性。需要开发一个跨语言和领域的通用字幕对齐方法。

Method: SEA框架包含三个步骤：1) 使用预训练模型分割视频帧序列为单个手语；2) 将每个手语视频片段嵌入到与文本共享的潜在空间；3) 使用轻量级动态规划程序进行对齐，CPU上分钟级处理小时长视频。

Result: 在四个手语数据集上的实验表明，SEA实现了最先进的对齐性能，能够生成高质量平行数据用于手语处理研究。

Conclusion: SEA提供了一个灵活、高效的通用字幕对齐框架，支持从小型词典到大型连续语料库的各种场景，代码和模型已开源。

Abstract: The goal of this work is to develop a universal approach for aligning subtitles (i.e., spoken language text with corresponding timestamps) to continuous sign language videos. Prior approaches typically rely on end-to-end training tied to a specific language or dataset, which limits their generality. In contrast, our method Segment, Embed, and Align (SEA) provides a single framework that works across multiple languages and domains. SEA leverages two pretrained models: the first to segment a video frame sequence into individual signs and the second to embed the video clip of each sign into a shared latent space with text. Alignment is subsequently performed with a lightweight dynamic programming procedure that runs efficiently on CPUs within a minute, even for hour-long episodes. SEA is flexible and can adapt to a wide range of scenarios, utilizing resources from small lexicons to large continuous corpora. Experiments on four sign language datasets demonstrate state-of-the-art alignment performance, highlighting the potential of SEA to generate high-quality parallel data for advancing sign language processing. SEA's code and models are openly available.

</details>


### [4] [Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation](https://arxiv.org/abs/2512.08123)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 该论文提出了一种通用对抗后缀攻击方法，通过优化短令牌序列（4-10个令牌）来降低语言模型在多种任务上的分类准确率，该方法具有跨任务和跨模型的良好迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗提示方法通常是针对特定任务或模型优化的，导致结果难以比较且迁移性有限。需要一种通用的对抗攻击方法，能够在不同任务和模型间有效转移。

Method: 使用Gumbel-Softmax松弛学习可微分的"软"后缀，然后离散化用于推理。训练时最大化标签区域的校准交叉熵，同时掩码黄金令牌防止信息泄漏，并加入熵正则化避免崩溃。

Result: 在情感分析、自然语言推理、释义检测、常识问答和物理推理等任务上，使用Qwen2-1.5B、Phi-1.5和TinyLlama-1.1B模型进行实验，单个后缀在多个模型间有效转移，显著降低了准确率和校准置信度。

Conclusion: 通用对抗后缀是一种有效的攻击方法，能够在不同任务和模型架构间保持攻击效果，揭示了语言模型在对抗攻击下的脆弱性，为模型鲁棒性研究提供了新视角。

Abstract: Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable "soft" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.

</details>


### [5] [Universal Adversarial Suffixes for Language Models Using Reinforcement Learning with Calibrated Reward](https://arxiv.org/abs/2512.08131)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 本文提出使用强化学习框架训练对抗性后缀，通过PPO算法优化后缀策略，利用校准交叉熵奖励提高跨任务和模型的迁移性。


<details>
  <summary>Details</summary>
Motivation: 语言模型容易受到短对抗性后缀的攻击，现有方法通常使用梯度搜索或基于规则的方法，但这些方法脆弱且通常局限于单一任务或模型。

Method: 采用强化学习框架，将对抗性后缀视为策略，使用近端策略优化（PPO）算法进行训练，以冻结模型作为奖励评估器。通过校准交叉熵奖励来消除标签偏差，并聚合不同表面形式以提高迁移性。

Result: 在五个不同的NLP基准数据集（涵盖情感分析、自然语言推理、释义和常识推理）上评估，使用三种不同语言模型（Qwen2-1.5B Instruct、TinyLlama-1.1B Chat和Phi-1.5）。结果显示，RL训练的后缀能持续降低模型准确率，且比类似类型的先前对抗性触发器在跨任务和模型间具有更好的迁移效果。

Conclusion: 强化学习框架能有效生成对抗性后缀，这些后缀不仅能在单一任务上攻击模型，还能更好地迁移到不同任务和模型，展示了比传统方法更强的通用性和鲁棒性。

Abstract: Language models are vulnerable to short adversarial suffixes that can reliably alter predictions. Previous works usually find such suffixes with gradient search or rule-based methods, but these are brittle and often tied to a single task or model. In this paper, a reinforcement learning framework is used where the suffix is treated as a policy and trained with Proximal Policy Optimization against a frozen model as a reward oracle. Rewards are shaped using calibrated cross-entropy, removing label bias and aggregating across surface forms to improve transferability. The proposed method is evaluated on five diverse NLP benchmark datasets, covering sentiment, natural language inference, paraphrase, and commonsense reasoning, using three distinct language models: Qwen2-1.5B Instruct, TinyLlama-1.1B Chat, and Phi-1.5. Results show that RL-trained suffixes consistently degrade accuracy and transfer more effectively across tasks and models than previous adversarial triggers of similar genres.

</details>


### [6] [ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access](https://arxiv.org/abs/2512.08193)
*Jiwoo Park,Ruoqi Liu,Avani Jagdale,Andrew Srisuwananukorn,Jing Zhao,Lang Li,Ping Zhang,Sachin Kumar*

Main category: cs.CL

TL;DR: ClinicalTrialsHub是一个整合ClinicalTrials.gov和PubMed数据的交互式平台，通过LLM自动提取结构化试验信息，将结构化临床试验数据访问量提升83.8%


<details>
  <summary>Details</summary>
Motivation: 现有临床试验数据分散在ClinicalTrials.gov和PubMed等不同平台，缺乏统一的结构化访问方式，限制了患者、临床医生、研究人员和政策制定者获取完整试验证据的能力

Method: 使用GPT-5.1和Gemini-3-Pro等大语言模型自动解析PubMed全文研究文章提取结构化试验信息，将用户查询转换为结构化数据库搜索，并提供基于证据的问答系统，答案链接到具体源句

Result: 相比仅依赖ClinicalTrials.gov，系统将结构化临床试验数据访问量提高了83.8%；通过临床医生、临床研究人员和药学/护理学博士生的用户研究以及自动评估验证了系统的信息提取和问答能力

Conclusion: ClinicalTrialsHub通过整合和结构化临床试验数据，显著提高了证据获取效率，有潜力促进循证医学发展，为医疗决策提供更好的支持

Abstract: We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.

</details>


### [7] [Are generative AI text annotations systematically biased?](https://arxiv.org/abs/2512.08404)
*Sjoerd B. Stolwijk,Mark Boukes,Damian Trilling*

Main category: cs.CL

TL;DR: 研究通过概念性复制Boukes(2024)的手动标注，发现GLLMs在F1分数上表现尚可，但与人工标注在流行度、下游结果上存在差异，且存在系统性偏见（GLLMs之间一致性高于与人工标注的一致性）


<details>
  <summary>Details</summary>
Motivation: 调查生成式大语言模型(GLLMs)在文本标注任务中存在的偏见问题，通过概念性复制先前研究的手动标注来评估GLLMs的标注质量与可靠性

Method: 使用多种GLLMs（Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b）配合五种不同的提示词，对五个概念（政治内容、互动性、理性、不文明性、意识形态）进行标注，并与Boukes(2024)的人工标注进行对比

Result: GLLMs在F1分数上表现尚可，但与人工标注在流行度估计上存在差异，导致下游结果显著不同；GLLMs之间存在系统性偏见，它们彼此之间的一致性高于与人工标注的一致性；F1分数差异无法充分反映偏见程度

Conclusion: 虽然GLLMs在技术指标上表现良好，但其标注存在系统性偏见，与人工标注存在实质性差异，仅依赖F1分数评估GLLMs标注质量可能不够充分，需要考虑偏见对下游分析的影响

Abstract: This paper investigates bias in GLLM annotations by conceptually replicating manual annotations of Boukes (2024). Using various GLLMs (Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b) in combination with five different prompts for five concepts (political content, interactivity, rationality, incivility, and ideology). We find GLLMs perform adequate in terms of F1 scores, but differ from manual annotations in terms of prevalence, yield substantively different downstream results, and display systematic bias in that they overlap more with each other than with manual annotations. Differences in F1 scores fail to account for the degree of bias.

</details>


### [8] [What Triggers my Model? Contrastive Explanations Inform Gender Choices by Translation Models](https://arxiv.org/abs/2512.08440)
*Janiça Hackenbuchner,Arda Tezcan,Joke Daems*

Main category: cs.CL

TL;DR: 该研究使用对比解释和显著性归因方法，分析机器翻译模型中性别偏见的来源，通过性别模糊的自然源数据，识别影响目标语言性别屈折选择的源词，并与人类感知进行比较。


<details>
  <summary>Details</summary>
Motivation: 当前可解释性研究主要关注理解黑盒模型决策，但对机器翻译和大型语言模型中存在的性别偏见问题研究有限。研究旨在超越简单的偏见测量，探索性别偏见的根源。

Method: 使用性别模糊的自然源数据，采用对比解释和显著性归因方法，分析源句中哪些输入词影响翻译模型选择特定性别屈折。首先解决缺乏评分阈值的问题，比较不同归因水平下源词对模型性别决策的影响。

Result: 研究发现显著源词与人类性别感知之间存在明显重叠，提供了显著词的语言学分析。展示了理解模型翻译决策在性别方面的重要性，以及这与人类决策的比较。

Conclusion: 这项工作展示了理解模型翻译决策在性别方面的重要性，以及这些信息应被用于减轻性别偏见。研究结果为利用可解释性方法缓解机器翻译中的性别偏见提供了基础。

Abstract: Interpretability can be implemented as a means to understand decisions taken by (black box) models, such as machine translation (MT) or large language models (LLMs). Yet, research in this area has been limited in relation to a manifested problem in these models: gender bias. With this research, we aim to move away from simply measuring bias to exploring its origins. Working with gender-ambiguous natural source data, this study examines which context, in the form of input tokens in the source sentence, influences (or triggers) the translation model choice of a certain gender inflection in the target language. To analyse this, we use contrastive explanations and compute saliency attribution. We first address the challenge of a lacking scoring threshold and specifically examine different attribution levels of source words on the model gender decisions in the translation. We compare salient source words with human perceptions of gender and demonstrate a noticeable overlap between human perceptions and model attribution. Additionally, we provide a linguistic analysis of salient words. Our work showcases the relevance of understanding model translation decisions in terms of gender, how this compares to human decisions and that this information should be leveraged to mitigate gender bias.

</details>


### [9] [Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models](https://arxiv.org/abs/2512.08480)
*Ju-Young Kim,Ji-Hong Park,Se-Yeon Lee,Sujin Park,Gun-Woo Kim*

Main category: cs.CL

TL;DR: 本研究提出一种软归纳偏置方法，通过明确定义推理视角来引导大语言模型的推理过程，用于韩语不当言论检测，相比标准监督学习提升约3.89%的准确率。


<details>
  <summary>Details</summary>
Motivation: 在线游戏和社区中匿名环境下的不当言论经常升级为言语暴力和犯罪行为，需要检测技术来构建更安全的交流环境。虽然韩语大语言模型和思维链推理受到关注，但在不当言论检测方面的应用研究仍然有限。

Method: 提出软归纳偏置方法，明确定义推理视角来引导推理过程，促进理性决策并防止推理错误。使用该方法对韩语大语言模型进行微调，并进行不同训练策略的定量性能比较和定性评估。

Result: Kanana-1.5模型平均准确率达到87.0046，相比标准监督学习提升约3.89%。该方法不仅模仿大语言模型的知识，还能通过约束推理视角实现更精确和一致的判断。

Conclusion: 提出的软归纳偏置方法通过约束推理视角，使大语言模型能够进行更精确和一致的判断，在不当言论检测任务中表现出有效性，超越了简单的知识模仿。

Abstract: Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.

</details>


### [10] [Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks](https://arxiv.org/abs/2512.08545)
*Indrajit Kar,Kalathur Chenchu Kishore Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种分层多智能体架构，在64×64网格上分布轻量级智能体，通过空间课程学习逐步扩展操作区域，结合NLL置信度度量和Thompson采样课程管理器，在空间化汉诺塔基准上实现了更好的稳定性、更少的oracle使用和更强的长程推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和多智能体系统在分解复杂任务方面有潜力，但在长时程推理任务中面临困难且计算成本高昂。需要一种能够有效处理长时程推理、降低计算成本的新架构。

Method: 1. 分层多智能体架构：在64×64网格上分布轻量级智能体，由选择性oracle支持；2. 空间课程学习：逐步扩展网格操作区域，让智能体先掌握中心简单任务再处理边缘困难任务；3. 置信度集成：使用负对数似然(NLL)作为置信度度量；4. Thompson采样课程管理器：基于能力和NLL驱动的奖励信号自适应选择训练区域。

Result: 在空间化汉诺塔基准测试中，该方法表现出：1. 改进的稳定性；2. 减少的oracle使用；3. 通过分布式智能体协作实现更强的长程推理能力。

Conclusion: 提出的分层多智能体架构结合空间课程学习和置信度度量，能够有效解决长时程推理任务，降低计算成本，在空间化任务中表现出优越性能，为机器人操作和规划任务提供了有前景的解决方案。

Abstract: Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.

</details>


### [11] [HealthcareNLP: where are we and what is next?](https://arxiv.org/abs/2512.08617)
*Lifeng Han,Paul Rayson,Suzan Verberne,Andrew Moore,Goran Nenadic*

Main category: cs.CL

TL;DR: 这是一篇关于医疗领域NLP应用的教程论文，旨在系统介绍HealthcareNLP的重要子领域，包括数据资源层、NLP评估层和患者层三个层次，并包含实践环节。


<details>
  <summary>Details</summary>
Motivation: 现有医疗NLP领域的综述要么忽略了一些重要任务（如合成数据生成、可解释性临床NLP），要么遗漏了关键方法（如检索增强生成、神经符号集成）。因此需要提供一个更全面的入门教程。

Method: 采用三层层次结构组织教程内容：1) 数据/资源层（标注指南、伦理审批、合成数据等）；2) NLP评估层（NER、关系抽取、情感分析等任务及可解释方法）；3) 患者层（患者参与、健康素养、翻译简化等任务）。包含实践环节让观众使用HealthcareNLP应用。

Result: 设计了一个系统性的HealthcareNLP教程框架，涵盖从数据准备到患者应用的全流程，针对医疗NLP从业者、研究人员和学生，无需先验知识即可参与。

Conclusion: 该教程为医疗领域NLP应用提供了一个全面的入门指南，通过三层架构系统性地介绍了HealthcareNLP的关键方面，有助于推动该领域的研究和应用发展。

Abstract: This proposed tutorial focuses on Healthcare Domain Applications of NLP, what we have achieved around HealthcareNLP, and the challenges that lie ahead for the future. Existing reviews in this domain either overlook some important tasks, such as synthetic data generation for addressing privacy concerns, or explainable clinical NLP for improved integration and implementation, or fail to mention important methodologies, including retrieval augmented generation and the neural symbolic integration of LLMs and KGs. In light of this, the goal of this tutorial is to provide an introductory overview of the most important sub-areas of a patient- and resource-oriented HealthcareNLP, with three layers of hierarchy: data/resource layer: annotation guidelines, ethical approvals, governance, synthetic data; NLP-Eval layer: NLP tasks such as NER, RE, sentiment analysis, and linking/coding with categorised methods, leading to explainable HealthAI; patients layer: Patient Public Involvement and Engagement (PPIE), health literacy, translation, simplification, and summarisation (also NLP tasks), and shared decision-making support. A hands-on session will be included in the tutorial for the audience to use HealthcareNLP applications. The target audience includes NLP practitioners in the healthcare application domain, NLP researchers who are interested in domain applications, healthcare researchers, and students from NLP fields. The type of tutorial is "Introductory to CL/NLP topics (HealthcareNLP)" and the audience does not need prior knowledge to attend this. Tutorial materials: https://github.com/4dpicture/HealthNLP

</details>


### [12] [QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models](https://arxiv.org/abs/2512.08646)
*Maximilian Kreutner,Jens Rupprecht,Georg Ahnert,Ahmed Salem,Markus Strohmaier*

Main category: cs.CL

TL;DR: QSTN是一个开源Python框架，用于通过问卷式提示系统生成LLM响应，支持虚拟调查和标注任务，包含无代码界面和低成本大规模评估功能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM研究中缺乏系统化生成问卷响应的工具，需要支持虚拟调查和标注任务，同时确保研究的可重复性和可靠性。

Method: 开发开源Python框架QSTN，支持问卷呈现、提示扰动和响应生成方法的评估，提供无代码用户界面，通过大规模实验（超过4000万调查响应）评估不同因素对响应质量的影响。

Result: 问题结构和响应生成方法对LLM生成调查响应与人类答案的一致性有显著影响，且可以以极低的计算成本获得。框架支持大规模实验设置。

Conclusion: QSTN框架有助于提高LLM研究的可重复性和可靠性，为研究人员提供强大的实验工具，支持未来LLM研究的稳健发展。

Abstract: We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation ($>40 $ million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers, and can be obtained for a fraction of the compute cost. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs without coding knowledge. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.

</details>


### [13] [An Agentic AI System for Multi-Framework Communication Coding](https://arxiv.org/abs/2512.08659)
*Bohao Yang,Rui Yang,Joshua M. Biro,Haoyuan Wang,Jessica L. Handley,Brianna Richardson,Sophia Bessias,Nicoleta Economou-Zavlanos,Armando D. Bedoya,Monica Agrawal,Michael M. Zavlanos,Anand Chowdhury,Raj M. Ratwani,Kai Sun,Kathryn I. Pollak,Michael J. Pencina,Chuan Hong*

Main category: cs.CL

TL;DR: MOSAIC是一个基于LangGraph的多框架结构化AI系统，用于临床沟通分析，通过四个核心代理实现自动化标注，在风湿病学和妇产科领域达到0.928的F1分数。


<details>
  <summary>Details</summary>
Motivation: 临床沟通对患者结果至关重要，但大规模人工标注患者-提供者对话劳动密集、不一致且难以扩展。现有基于大语言模型的方法通常依赖单任务模型，缺乏适应性、可解释性和可靠性，特别是在不同沟通框架和临床领域中的应用。

Method: 开发了基于LangGraph架构的MOSAIC系统，包含四个核心代理：计划代理（代码本选择和流程规划）、更新代理（维护最新检索数据库）、标注代理（应用代码本引导的检索增强生成和动态少样本提示）、验证代理（一致性检查和反馈）。

Result: 在26个训练转录本和50个测试转录本上评估，MOSAIC总体F1分数为0.928。风湿病学子集表现最佳（F1=0.962），患者行为类别（如提问、表达偏好、表现自信）表现最强。消融实验显示MOSAIC优于基准方法。

Conclusion: MOSAIC系统通过多代理架构有效解决了临床沟通标注的可扩展性和一致性问题，在不同临床领域和沟通框架中表现出高准确性和适应性。

Abstract: Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.

</details>


### [14] [Automatic Essay Scoring and Feedback Generation in Basque Language Learning](https://arxiv.org/abs/2512.08713)
*Ekhi Azurmendi,Xabier Arregi,Oier Lopez de Lacalle*

Main category: cs.CL

TL;DR: 首个巴斯克语自动作文评分与反馈生成公开数据集，包含3200篇CEFR C1级别作文，专家标注评分与详细反馈。微调开源模型在评分一致性和反馈质量上超越GPT-5等闭源系统。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言（巴斯克语）建立透明、可复现且教育基础扎实的NLP研究资源，填补巴斯克语自动作文评分与反馈生成领域的空白。

Method: 收集3200篇巴斯克语C1级别作文，专家标注五个维度的评分和详细反馈。微调RoBERTa-EusCrawl和Latxa 8B/70B等开源模型，提出结合自动一致性指标和专家验证的新型反馈评估方法。

Result: 编码器模型在自动评分中保持高可靠性，SFT微调的Latxa模型在评分一致性和反馈质量上超越GPT-5、Claude Sonnet 4.5等闭源系统，能生成与评分标准对齐、具有教学意义的反馈，识别更多错误类型。

Conclusion: 该数据集和基准为巴斯克语等低资源语言建立了透明、可复现的教育NLP研究基础，展示了开源模型在自动作文评分和反馈生成任务上的优越性能。

Abstract: This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.

</details>


### [15] [Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages](https://arxiv.org/abs/2512.08777)
*David Samuel,Lilja Øvrelid,Erik Velldal,Andrey Kutuzov*

Main category: cs.CL

TL;DR: 提出一种针对低资源语言的后训练方法，即使使用不流利的奖励模型也能保持语言模型的流畅性，无需目标语言的指令调优数据。


<details>
  <summary>Details</summary>
Motivation: 偏好优化研究主要集中在英语和中文，低资源语言缺乏母语者撰写的数据集和生成流畅合成数据的语言模型，需要开发无需目标语言指令数据的流畅偏好对齐模型。

Method: 采用基于策略的训练方法，与两种常见方法进行比较：机器翻译数据的监督微调，以及多语言微调。以挪威博克马尔语为案例研究，通过母语者评估流畅性。

Result: 结果显示基于策略的训练方法至关重要，优于其他替代方法，且不依赖难以获取的数据。

Conclusion: 该方法为低资源语言提供了一种有效的偏好对齐解决方案，无需目标语言的指令数据，基于策略的训练是关键优势。

Abstract: We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokmål and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.

</details>


### [16] [A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs](https://arxiv.org/abs/2512.08786)
*Mahmoud Srewa,Tianyu Zhao,Salma Elmalaki*

Main category: cs.CL

TL;DR: 该论文提出了一种在联邦学习环境中评估大语言模型与多样化人类偏好对齐的框架，并引入自适应聚合策略来平衡对齐质量和公平性。


<details>
  <summary>Details</summary>
Motivation: 标准方法在联邦学习环境中难以充分代表多样化的人类偏好，需要解决LLM对齐中的公平性与质量权衡问题。

Method: 建立联邦学习评估框架，各组本地评估生成结果并产生奖励信号，服务器聚合组级奖励而不访问原始数据。评估标准聚合技术（最小、最大、平均值）并引入基于历史对齐性能动态调整偏好权重的自适应方案。

Result: 在基于PPO的RLHF管道上进行的问答任务实验表明，自适应方法在保持竞争性对齐分数的同时，始终实现更优的公平性。

Conclusion: 该工作提供了评估LLM在多样化人群中行为的稳健方法，并为开发真正多元化和公平对齐的模型提供了实用解决方案。

Abstract: This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.

</details>


### [17] [Ask, Answer, and Detect: Role-Playing LLMs for Personality Detection with Question-Conditioned Mixture-of-Experts](https://arxiv.org/abs/2512.08814)
*Yifan Lyu,Liang Zhang*

Main category: cs.CL

TL;DR: ROME框架通过模拟心理问卷回答，将心理学知识注入人格检测，解决了标签稀缺和语义映射不明确的问题，显著提升了人格检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人格检测方法主要采用"帖子->用户向量->标签"的建模范式，虽然大语言模型提升了文本编码能力，但仍受限于标签稀缺性以及用户语言与抽象心理概念之间语义映射不明确的问题。

Method: ROME框架利用大语言模型的角色扮演能力，模拟用户对标准化心理问卷的回答，将自由形式的用户帖子转化为可解释的、基于问卷的证据。采用问题条件化的专家混合模块联合处理帖子和问题表示，在多任务学习框架中，将问卷回答作为人格检测的辅助任务。

Result: 在两个真实世界数据集上的广泛实验表明，ROME始终优于最先进的基线方法，在Kaggle数据集上实现了15.41%的性能提升。

Conclusion: ROME通过显式注入心理学知识，将问卷回答作为中间监督信号，有效缓解了标签稀缺问题，提供了语义推理链来指导文本到人格的映射学习，为人格检测提供了可解释且有效的解决方案。

Abstract: Understanding human personality is crucial for web applications such as personalized recommendation and mental health assessment. Existing studies on personality detection predominantly adopt a "posts -> user vector -> labels" modeling paradigm, which encodes social media posts into user representations for predicting personality labels (e.g., MBTI labels). While recent advances in large language models (LLMs) have improved text encoding capacities, these approaches remain constrained by limited supervision signals due to label scarcity, and under-specified semantic mappings between user language and abstract psychological constructs. We address these challenges by proposing ROME, a novel framework that explicitly injects psychological knowledge into personality detection. Inspired by standardized self-assessment tests, ROME leverages LLMs' role-play capability to simulate user responses to validated psychometric questionnaires. These generated question-level answers transform free-form user posts into interpretable, questionnaire-grounded evidence linking linguistic cues to personality labels, thereby providing rich intermediate supervision to mitigate label scarcity while offering a semantic reasoning chain that guides and simplifies the text-to-personality mapping learning. A question-conditioned Mixture-of-Experts module then jointly routes over post and question representations, learning to answer questionnaire items under explicit supervision. The predicted answers are summarized into an interpretable answer vector and fused with the user representation for final prediction within a multi-task learning framework, where question answering serves as a powerful auxiliary task for personality detection. Extensive experiments on two real-world datasets demonstrate that ROME consistently outperforms state-of-the-art baselines, achieving improvements (15.41% on Kaggle dataset).

</details>


### [18] [Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis](https://arxiv.org/abs/2512.08819)
*Ferdinand Kapl,Emmanouil Angelis,Tobias Höppe,Kaitlin Maile,Johannes von Oswald,Nino Scherrer,Stefan Bauer*

Main category: cs.CL

TL;DR: 通过渐进增加Transformer深度训练可提升推理性能，本文揭示了其机制：缓解"深度诅咒"，改善残差流结构，形成可置换计算块


<details>
  <summary>Details</summary>
Motivation: 虽然MIDAS已证明渐进增加Transformer深度能降低训练成本并提升推理性能，但其机制尚不明确。本文旨在理解这种性能提升背后的计算机制，特别是与"深度诅咒"现象的关系

Method: 采用深度分析技术，研究渐进中间堆叠生长方式如何影响模型深度利用效率、改变残差流结构，并促进可置换计算块的形成。同时提出MIDAS的轻量级改进方案

Result: 研究表明，渐进深度生长能更有效地利用模型深度，改变残差流结构，促进可置换计算块的形成。提出的改进方案在下游推理基准测试中进一步提升了性能

Conclusion: 渐进增加模型深度能形成独特的计算电路，克服标准非生长模型中深度利用有限的问题，为Transformer架构优化提供了新的机制理解

Abstract: Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csordás et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.

</details>


### [19] [Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders](https://arxiv.org/abs/2512.08892)
*Guangzhi Xiong,Zhenghao He,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: RAGLens：基于稀疏自编码器和特征选择的轻量级RAG幻觉检测器，利用LLM内部表示准确识别不忠实输出，无需大规模训练或外部LLM查询


<details>
  <summary>Details</summary>
Motivation: RAG虽然通过检索证据提高了LLM的事实性，但仍存在忠实性失败问题（生成内容与源信息矛盾或超出范围）。现有幻觉检测方法要么需要大量标注数据训练检测器，要么依赖外部LLM判断导致高推理成本，而基于LLM内部表示的方法准确率有限。

Method: 利用稀疏自编码器（SAEs）解耦LLM内部激活，识别RAG幻觉触发特征；基于信息论的特征选择和加性特征建模构建RAGLens检测器，轻量级地利用LLM内部表示标记不忠实RAG输出。

Result: RAGLens在检测性能上优于现有方法，同时提供可解释的决策依据，能够有效进行事后缓解；研究还揭示了LLM中幻觉相关信号的分布新见解。

Conclusion: RAGLens通过结合稀疏自编码器和系统化特征选择，实现了高效准确的RAG幻觉检测，为理解和缓解RAG忠实性问题提供了新方法。

Abstract: Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [Sparse Variable Projection in Robotic Perception: Exploiting Separable Structure for Efficient Nonlinear Optimization](https://arxiv.org/abs/2512.07969)
*Alan Papalia,Nikolas Sanderson,Haoyu Han,Heng Yang,Hanumant Singh,Michael Everett*

Main category: cs.RO

TL;DR: 提出一种针对具有规范对称性的机器人感知问题的变量投影方法，通过联合利用可分离性和稀疏性，构建矩阵无关的舒尔补算子，实现比现有方法快2-35倍的运行速度。


<details>
  <summary>Details</summary>
Motivation: 机器人感知中的大规模非线性最小二乘问题通常具有可分离性结构（某些变量线性出现），变量投影方法可以充分利用这种结构。然而，规范对称性（如全局平移和旋转不变性）在感知问题中普遍存在，给传统变量投影方法带来了计算挑战，限制了其在机器人感知中的应用。

Method: 提出一种专门针对具有规范对称性问题的变量投影方案，联合利用可分离性和稀疏性。该方法可作为一次性预处理步骤，构建矩阵无关的舒尔补算子，支持高效计算约简问题的成本、梯度和Hessian-向量积，并能与标准迭代NLS求解器集成。论文提供了方法适用的精确条件，并描述了当条件部分满足时的扩展方案。

Result: 在SLAM、SNL和SfM的合成和真实基准测试中，该方法比最先进方法实现了2-35倍的运行速度提升，同时保持了准确性。作者发布了开源的C++实现和所有实验数据集。

Conclusion: 该方法成功解决了规范对称性给变量投影带来的挑战，通过联合利用可分离性和稀疏性，为机器人感知中的大规模非线性最小二乘问题提供了高效解决方案，显著提升了计算性能。

Abstract: Robotic perception often requires solving large nonlinear least-squares (NLS) problems. While sparsity has been well-exploited to scale solvers, a complementary and underexploited structure is \emph{separability} -- where some variables (e.g., visual landmarks) appear linearly in the residuals and, for any estimate of the remaining variables (e.g., poses), have a closed-form solution. Variable projection (VarPro) methods are a family of techniques that exploit this structure by analytically eliminating the linear variables and presenting a reduced problem in the remaining variables that has favorable properties. However, VarPro has seen limited use in robotic perception; a major challenge arises from gauge symmetries (e.g., cost invariance to global shifts and rotations), which are common in perception and induce specific computational challenges in standard VarPro approaches. We present a VarPro scheme designed for problems with gauge symmetries that jointly exploits separability and sparsity. Our method can be applied as a one-time preprocessing step to construct a \emph{matrix-free Schur complement operator}. This operator allows efficient evaluation of costs, gradients, and Hessian-vector products of the reduced problem and readily integrates with standard iterative NLS solvers. We provide precise conditions under which our method applies, and describe extensions when these conditions are only partially met. Across synthetic and real benchmarks in SLAM, SNL, and SfM, our approach achieves up to \textbf{2$\times$--35$\times$ faster runtimes} than state-of-the-art methods while maintaining accuracy. We release an open-source C++ implementation and all datasets from our experiments.

</details>


### [21] [VLD: Visual Language Goal Distance for Reinforcement Learning Navigation](https://arxiv.org/abs/2512.07976)
*Lazar Milikic,Manthan Patel,Jonas Frey*

Main category: cs.RO

TL;DR: 提出Vision-Language Distance (VLD)学习框架，将感知学习与策略学习解耦，通过自监督距离预测器处理多模态目标，在仿真中训练RL策略，实现可扩展的机器人导航


<details>
  <summary>Details</summary>
Motivation: 现有端到端图像到动作的导航策略存在两个主要问题：1) 仿真到现实的迁移差距(sim-to-real gap)；2) 带动作标签的训练数据有限。需要一种可扩展的解决方案来克服这些限制

Method: 提出VLD框架：1) 在互联网规模的视频数据上训练自监督的距离到目标预测器，支持图像和文本目标；2) 在仿真中使用特权几何距离信号训练RL策略，注入噪声模拟距离预测器的不确定性；3) 部署时策略使用VLD预测，继承大规模视觉训练的语义目标信息

Result: VLD在仿真中实现竞争性导航性能，支持灵活的目标模态(图像和文本)，优于ViNT和VIP等现有时序距离方法。通过序数一致性评估距离函数，证明解耦设计有效

Conclusion: VLD框架提供了一种可扩展的路径，通过解耦感知学习和策略学习，结合大规模视觉训练的语义理解与仿真中学习的鲁棒低级导航行为，实现可靠的多模态导航策略

Abstract: Training end-to-end policies from image data to directly predict navigation actions for robotic systems has proven inherently difficult. Existing approaches often suffer from either the sim-to-real gap during policy transfer or a limited amount of training data with action labels. To address this problem, we introduce Vision-Language Distance (VLD) learning, a scalable framework for goal-conditioned navigation that decouples perception learning from policy learning. Instead of relying on raw sensory inputs during policy training, we first train a self-supervised distance-to-goal predictor on internet-scale video data. This predictor generalizes across both image- and text-based goals, providing a distance signal that can be minimized by a reinforcement learning (RL) policy. The RL policy can be trained entirely in simulation using privileged geometric distance signals, with injected noise to mimic the uncertainty of the trained distance predictor. At deployment, the policy consumes VLD predictions, inheriting semantic goal information-"where to go"-from large-scale visual training while retaining the robust low-level navigation behaviors learned in simulation. We propose using ordinal consistency to assess distance functions directly and demonstrate that VLD outperforms prior temporal distance approaches, such as ViNT and VIP. Experiments show that our decoupled design achieves competitive navigation performance in simulation while supporting flexible goal modalities, providing an alternative and, most importantly, scalable path toward reliable, multimodal navigation policies.

</details>


### [22] [DIJIT: A Robotic Head for an Active Observer](https://arxiv.org/abs/2512.07998)
*Mostafa Kamali Tabrizi,Mingshi Chi,Bir Bikram Dey,Yu Qing Yuan,Markus D. Solbach,Yiqian Liu,Michael Jenkin,John K. Tsotsos*

Main category: cs.RO

TL;DR: DIJIT是一个专为移动智能体设计的双目机器人头部，具有9个机械自由度和4个光学自由度，能够模拟人类眼-头-颈运动，用于主动视觉研究和人机视觉对比研究。


<details>
  <summary>Details</summary>
Motivation: 设计一个能够模拟人类眼-头-颈运动的机器人头部，用于研究主动视觉、人类视觉机制以及人机视觉差异，特别是探索眼动和头动在视觉任务中的作用。

Method: 设计了具有9个机械自由度和4个光学自由度的双目机器人头部DIJIT，实现了人类水平的运动范围和速度，支持汇聚立体视觉所需的运动（辐辏、共轭、旋转），并开发了新的扫视相机运动方法，建立了相机方向与电机值之间的直接关系。

Result: DIJIT能够实现接近人类运动的扫视相机运动精度，其机械设计参数与人类性能相当，为主动视觉研究和人机视觉对比提供了有效的实验平台。

Conclusion: DIJIT是一个功能全面的机器人头部平台，能够模拟人类眼-头-颈运动，为主动视觉研究、人类视觉机制探索以及人机视觉差异分析提供了重要工具，其扫视运动方法实现了接近人类水平的精度。

Abstract: We present DIJIT, a novel binocular robotic head expressly designed for mobile agents that behave as active observers. DIJIT's unique breadth of functionality enables active vision research and the study of human-like eye and head-neck motions, their interrelationships, and how each contributes to visual ability. DIJIT is also being used to explore the differences between how human vision employs eye/head movements to solve visual tasks and current computer vision methods. DIJIT's design features nine mechanical degrees of freedom, while the cameras and lenses provide an additional four optical degrees of freedom. The ranges and speeds of the mechanical design are comparable to human performance. Our design includes the ranges of motion required for convergent stereo, namely, vergence, version, and cyclotorsion. The exploration of the utility of these to both human and machine vision is ongoing. Here, we present the design of DIJIT and evaluate aspects of its performance. We present a new method for saccadic camera movements. In this method, a direct relationship between camera orientation and motor values is developed. The resulting saccadic camera movements are close to human movements in terms of their accuracy.

</details>


### [23] [Optimized Area Coverage in Disaster Response Utilizing Autonomous UAV Swarm Formations](https://arxiv.org/abs/2512.08028)
*Lampis Papakostas,Aristeidis Geladaris,Athanasios Mastrogeorgiou,Jim Sharples,Gautier Hattenberger,Panagiotis Chatzakos,Panagiotis Polygerinos*

Main category: cs.RO

TL;DR: 该论文提出了一种用于灾害救援的无人机集群系统，通过分布式传感器延长飞行时间，采用局部ESDF地图进行避障，结合TSP变体优化兴趣点覆盖，并在仿真中验证了系统性能。


<details>
  <summary>Details</summary>
Motivation: 在野火等灾害场景中，第一响应者需要高效的环境感知和救援支持。传统单无人机系统存在飞行时间有限、数据可用性不足、碰撞风险高等问题，需要开发更可靠的集群系统来提升灾害响应能力。

Method: 1) 采用多智能体分布式传感器系统延长飞行时间和增强数据可用性；2) 基于局部欧几里得符号距离场(ESDF)地图的自主导航框架实现避障和集群编队保持；3) 引入旅行商问题(TSP)变体优化区域覆盖，根据环境行为和关键基础设施预分配值优先覆盖兴趣点(POIs)。

Result: 通过不同集群规模的仿真验证，系统能够最大化区域覆盖，同时确保无人机之间以及无人机与障碍物之间的碰撞避免，显著降低了任务失败风险。

Conclusion: 该无人机集群系统为灾害响应提供了有效的解决方案，通过分布式传感、智能避障和优化覆盖策略，提升了救援行动的可靠性和效率，具有实际应用价值。

Abstract: This paper presents a UAV swarm system designed to assist first responders in disaster scenarios like wildfires. By distributing sensors across multiple agents, the system extends flight duration and enhances data availability, reducing the risk of mission failure due to collisions. To mitigate this risk further, we introduce an autonomous navigation framework that utilizes a local Euclidean Signed Distance Field (ESDF) map for obstacle avoidance while maintaining swarm formation with minimal path deviation. Additionally, we incorporate a Traveling Salesman Problem (TSP) variant to optimize area coverage, prioritizing Points of Interest (POIs) based on preassigned values derived from environmental behavior and critical infrastructure. The proposed system is validated through simulations with varying swarm sizes, demonstrating its ability to maximize coverage while ensuring collision avoidance between UAVs and obstacles.

</details>


### [24] [An Introduction to Deep Reinforcement and Imitation Learning](https://arxiv.org/abs/2512.08052)
*Pedro Santana*

Main category: cs.RO

TL;DR: 本文介绍了深度强化学习(DRL)和深度模仿学习(DIL)在具身智能体控制中的应用，采用深度优先方法讲解基础算法，涵盖从马尔可夫决策过程到PPO和GAIL等关键技术。


<details>
  <summary>Details</summary>
Motivation: 具身智能体（如机器人和虚拟角色）需要解决复杂的顺序决策问题，手动设计控制器很困难，因此基于学习的方法（特别是DRL和DIL）成为有前景的替代方案。

Method: 采用深度优先的文献研究方法，自包含地呈现必要的数学和机器学习概念。重点介绍一小套基础算法和技术，包括：DRL部分的马尔可夫决策过程、REINFORCE、PPO；DIL部分的行为克隆、DAgger、GAIL。

Result: 文档提供了对DRL和DIL在具身智能体控制中的系统性介绍，建立了从理论基础到实践算法的完整知识框架，为读者深入理解这些技术提供了坚实基础。

Conclusion: 本文通过深度优先的方法，系统地介绍了DRL和DIL在具身智能体控制中的核心算法，为学习和应用这些技术提供了全面的理论基础和实践指导，强调深度理解而非广泛覆盖。

Abstract: Embodied agents, such as robots and virtual characters, must continuously select actions to execute tasks effectively, solving complex sequential decision-making problems. Given the difficulty of designing such controllers manually, learning-based approaches have emerged as promising alternatives, most notably Deep Reinforcement Learning (DRL) and Deep Imitation Learning (DIL). DRL leverages reward signals to optimize behavior, while DIL uses expert demonstrations to guide learning. This document introduces DRL and DIL in the context of embodied agents, adopting a concise, depth-first approach to the literature. It is self-contained, presenting all necessary mathematical and machine learning concepts as they are needed. It is not intended as a survey of the field; rather, it focuses on a small set of foundational algorithms and techniques, prioritizing in-depth understanding over broad coverage. The material ranges from Markov Decision Processes to REINFORCE and Proximal Policy Optimization (PPO) for DRL, and from Behavioral Cloning to Dataset Aggregation (DAgger) and Generative Adversarial Imitation Learning (GAIL) for DIL.

</details>


### [25] [Chat with UAV -- Human-UAV Interaction Based on Large Language Models](https://arxiv.org/abs/2512.08145)
*Haoran Wang,Zhuohang Chen,Guang Li,Bo Ma,Chuanghuang Li*

Main category: cs.RO

TL;DR: 提出基于双智能体LLM框架的人机无人机交互系统，通过任务规划与执行分离的架构，提升复杂场景下的交互流畅度和任务执行灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前无人机交互系统正从工程师驱动转向用户驱动，但缺乏用户与无人机之间的通用语言，现有基于LLM的HUI框架在混合任务规划与执行方面存在困难，难以适应复杂场景。

Method: 提出双智能体HUI框架，构建两个独立的LLM智能体（任务规划智能体和执行智能体），应用不同的提示工程分别处理任务理解、规划和执行。

Result: 构建了覆盖四个典型无人机应用场景的任务数据库，使用三个独立指标量化HUI框架性能，实验结果表明该框架提升了HUI的流畅度和任务执行灵活性，有效满足用户个性化需求。

Conclusion: 双智能体LLM框架通过任务规划与执行的分离设计，有效解决了现有HUI框架在复杂场景下的适应性问题，为人机无人机交互提供了更灵活、个性化的解决方案。

Abstract: The future of UAV interaction systems is evolving from engineer-driven to user-driven, aiming to replace traditional predefined Human-UAV Interaction designs. This shift focuses on enabling more personalized task planning and design, thereby achieving a higher quality of interaction experience and greater flexibility, which can be used in many fileds, such as agriculture, aerial photography, logistics, and environmental monitoring. However, due to the lack of a common language between users and the UAVs, such interactions are often difficult to be achieved. The developments of Large Language Models possess the ability to understand nature languages and Robots' (UAVs') behaviors, marking the possibility of personalized Human-UAV Interaction. Recently, some HUI frameworks based on LLMs have been proposed, but they commonly suffer from difficulties in mixed task planning and execution, leading to low adaptability in complex scenarios. In this paper, we propose a novel dual-agent HUI framework. This framework constructs two independent LLM agents (a task planning agent, and an execution agent) and applies different Prompt Engineering to separately handle the understanding, planning, and execution of tasks. To verify the effectiveness and performance of the framework, we have built a task database covering four typical application scenarios of UAVs and quantified the performance of the HUI framework using three independent metrics. Meanwhile different LLM models are selected to control the UAVs with compared performance. Our user study experimental results demonstrate that the framework improves the smoothness of HUI and the flexibility of task execution in the tasks scenario we set up, effectively meeting users' personalized needs.

</details>


### [26] [RAVES-Calib: Robust, Accurate and Versatile Extrinsic Self Calibration Using Optimal Geometric Features](https://arxiv.org/abs/2512.08170)
*Haoxin Zhang,Shuaixin Li,Xiaozhou Zhu,Hongbo Chen,Wen Yao*

Main category: cs.RO

TL;DR: 提出一个无需标定板、兼容多种LiDAR和相机传感器的标定工具包，仅需单对激光点云和图像，通过自适应特征加权实现高精度外参标定。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机标定方法通常需要标定板或初始变换估计，且在传感器外参偏差较大时鲁棒性不足。需要一种更简单、更鲁棒的标定方法，适用于无标定板环境。

Method: 1) 使用Gluestick管道建立2D-3D点和线特征对应关系，实现鲁棒的自动初始估计；2) 定量分析特征分布对标定结果的影响；3) 基于分析指标自适应加权每个特征的代价，过滤劣质特征的不良影响。

Result: 在室内外多种LiDAR-相机传感器上进行了广泛实验验证，相比现有SOTA方法，该方法展现出更优的鲁棒性和精度。

Conclusion: 提出了一种无需标定板、无需初始变换的LiDAR-相机标定工具包，通过自适应特征加权实现了高精度外参标定，代码已开源供社区使用。

Abstract: In this paper, we present a user-friendly LiDAR-camera calibration toolkit that is compatible with various LiDAR and camera sensors and requires only a single pair of laser points and a camera image in targetless environments. Our approach eliminates the need for an initial transform and remains robust even with large positional and rotational LiDAR-camera extrinsic parameters. We employ the Gluestick pipeline to establish 2D-3D point and line feature correspondences for a robust and automatic initial guess. To enhance accuracy, we quantitatively analyze the impact of feature distribution on calibration results and adaptively weight the cost of each feature based on these metrics. As a result, extrinsic parameters are optimized by filtering out the adverse effects of inferior features. We validated our method through extensive experiments across various LiDAR-camera sensors in both indoor and outdoor settings. The results demonstrate that our method provides superior robustness and accuracy compared to SOTA techniques. Our code is open-sourced on GitHub to benefit the community.

</details>


### [27] [Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation](https://arxiv.org/abs/2512.08186)
*Meng Wei,Chenyang Wan,Jiaqi Peng,Xiqian Yu,Yuqiang Yang,Delin Feng,Wenzhe Cai,Chenming Zhu,Tai Wang,Jiangmiao Pang,Xihui Liu*

Main category: cs.RO

TL;DR: DualVLN：首个双系统视觉语言导航基础模型，将高级推理与低级动作执行相结合，实现实时动态环境导航


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法通常采用端到端管道，直接将视觉语言输入映射到短期离散动作，导致运动碎片化、延迟高，且难以应对动态障碍物避让等现实挑战

Method: 提出双系统架构：System 2（基于VLM的全局规划器）通过图像基础推理预测中期路径点目标；System 1（轻量级多模态条件扩散变换器策略）利用System 2的显式像素目标和潜在特征生成平滑准确轨迹

Result: 在所有VLN基准测试中优于先前方法，真实世界实验展示了在动态环境中稳健的长时程规划和实时适应能力

Conclusion: 双系统设计实现了稳健的实时控制和复杂动态环境中的自适应局部决策，通过解耦训练保留了VLM的泛化能力，同时实现了可解释且有效的局部导航

Abstract: While recent large vision-language models (VLMs) have improved generalization in vision-language navigation (VLN), existing methods typically rely on end-to-end pipelines that map vision-language inputs directly to short-horizon discrete actions. Such designs often produce fragmented motions, incur high latency, and struggle with real-world challenges like dynamic obstacle avoidance. We propose DualVLN, the first dual-system VLN foundation model that synergistically integrates high-level reasoning with low-level action execution. System 2, a VLM-based global planner, "grounds slowly" by predicting mid-term waypoint goals via image-grounded reasoning. System 1, a lightweight, multi-modal conditioning Diffusion Transformer policy, "moves fast" by leveraging both explicit pixel goals and latent features from System 2 to generate smooth and accurate trajectories. The dual-system design enables robust real-time control and adaptive local decision-making in complex, dynamic environments. By decoupling training, the VLM retains its generalization, while System 1 achieves interpretable and effective local navigation. DualVLN outperforms prior methods across all VLN benchmarks and real-world experiments demonstrate robust long-horizon planning and real-time adaptability in dynamic environments.

</details>


### [28] [Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model](https://arxiv.org/abs/2512.08188)
*Wenjiang Xu,Cindy Wang,Rui Fang,Mingkang Zhang,Lusong Li,Jing Xu,Jiayuan Gu,Zecui Zeng,Rui Chen*

Main category: cs.RO

TL;DR: 提出EToT框架，通过物理模拟的数字孪生作为具身世界模型，将操作规划构建为树搜索，结合先验分支和反思分支机制，在物理约束下生成可靠的长时程操作计划。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型缺乏物理基础，容易产生幻觉且无法保持长时程物理约束的一致性，需要更可靠的具身世界模型来支持机器人操作规划。

Method: 提出Embodied Tree of Thoughts (EToT)框架，采用Real2Sim2Real方法，利用物理交互数字孪生作为具身世界模型。规划过程通过两种分支机制：先验分支（基于语义空间分析生成候选路径）和反思分支（利用VLM诊断模拟中的执行失败并迭代优化规划树）。

Result: 在短时程和长时程操作任务套件上验证，EToT持续优于基线方法，能有效预测物理动力学并适应潜在失败。

Conclusion: EToT通过物理模拟的数字孪生将高层推理与物理约束相结合，为机器人操作规划提供了更可靠、物理一致的解决方案。

Abstract: World models have emerged as a pivotal component in robot manipulation planning, enabling agents to predict future environmental states and reason about the consequences of actions before execution. While video-generation models are increasingly adopted, they often lack rigorous physical grounding, leading to hallucinations and a failure to maintain consistency in long-horizon physical constraints. To address these limitations, we propose Embodied Tree of Thoughts (EToT), a novel Real2Sim2Real planning framework that leverages a physics-based interactive digital twin as an embodied world model. EToT formulates manipulation planning as a tree search expanded through two synergistic mechanisms: (1) Priori Branching, which generates diverse candidate execution paths based on semantic and spatial analysis; and (2) Reflective Branching, which utilizes VLMs to diagnose execution failures within the simulator and iteratively refine the planning tree with corrective actions. By grounding high-level reasoning in a physics simulator, our framework ensures that generated plans adhere to rigid-body dynamics and collision constraints. We validate EToT on a suite of short- and long-horizon manipulation tasks, where it consistently outperforms baselines by effectively predicting physical dynamics and adapting to potential failures. Website at https://embodied-tree-of-thoughts.github.io .

</details>


### [29] [High-Performance Dual-Arm Task and Motion Planning for Tabletop Rearrangement](https://arxiv.org/abs/2512.08206)
*Duo Zhang,Junshan Huang,Jingjin Yu*

Main category: cs.RO

TL;DR: SDAR是一个用于桌面重排的双臂任务与运动规划框架，通过紧密集成的任务规划器和同步双臂运动规划器，在复杂纠缠场景中实现100%成功率和高质量解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决双臂机器人在紧密协作环境下重排高度纠缠物体的挑战，传统单臂规划方法无法有效处理这种复杂的依赖关系和同步协作需求。

Method: SDAR包含两个核心组件：1) SDAR-T任务规划器，通过分解全局对象依赖图生成优化的双臂任务计划；2) SDAR-M运动规划器，采用分层运动规划策略，利用GPU SIMD工具筛选最佳同步双臂运动计划。

Result: 在复杂、非单调、长视野的桌面重排任务中实现100%成功率，解决方案质量远超先前最先进方法，并在UR-5e双臂机器人上验证了可靠的实际部署能力。

Conclusion: SDAR框架通过紧密集成的任务与运动规划，有效解决了双臂协作重排高度纠缠物体的挑战，在成功率和解决方案质量方面均显著优于现有方法，并具备实际机器人部署的可靠性。

Abstract: We propose Synchronous Dual-Arm Rearrangement Planner (SDAR), a task and motion planning (TAMP) framework for tabletop rearrangement, where two robot arms equipped with 2-finger grippers must work together in close proximity to rearrange objects whose start and goal configurations are strongly entangled. To tackle such challenges, SDAR tightly knit together its dependency-driven task planner (SDAR-T) and synchronous dual-arm motion planner (SDAR-M), to intelligently sift through a large number of possible task and motion plans. Specifically, SDAR-T applies a simple yet effective strategy to decompose the global object dependency graph induced by the rearrangement task, to produce more optimal dual-arm task plans than solutions derived from optimal task plans for a single arm. Leveraging state-of-the-art GPU SIMD-based motion planning tools, SDAR-M employs a layered motion planning strategy to sift through many task plans for the best synchronous dual-arm motion plan while ensuring high levels of success rate. Comprehensive evaluation demonstrates that SDAR delivers a 100% success rate in solving complex, non-monotone, long-horizon tabletop rearrangement tasks with solution quality far exceeding the previous state-of-the-art. Experiments on two UR-5e arms further confirm SDAR directly and reliably transfers to robot hardware.

</details>


### [30] [Semantic-Metric Bayesian Risk Fields: Learning Robot Safety from Human Videos with a VLM Prior](https://arxiv.org/abs/2512.08233)
*Timothy Chen,Marcus Dominguez-Kuhne,Aiden Swann,Xu Liu,Mac Schwager*

Main category: cs.RO

TL;DR: 提出贝叶斯框架从人类演示视频中学习空间变化的风险模型，通过VLM先验和ViT似然函数生成像素级风险图像，用于机器人规划任务


<details>
  <summary>Details</summary>
Motivation: 人类对安全的理解不是二元信号，而是连续、上下文和空间相关的风险概念。为了让自主系统能够内化类似人类的风险认知，需要从人类演示中提取隐式风险模型

Method: 提出贝叶斯风险框架：1) 使用预训练视觉语言模型提供先验知识；2) 学习ViT似然函数将预训练特征映射到像素对齐的风险值；3) 输入RGB图像和查询对象字符串，输出像素密集的风险图像

Result: 框架能够生成与人类偏好一致的情境化风险估计，可泛化到新对象和上下文，并支持快速适应额外观察或常识规则。在下游应用中，可作为视觉运动规划的价值预测器或与经典轨迹优化算法结合

Conclusion: 该框架是使自主系统内化人类风险认知的重要一步，具有扩展到更大训练数据集的潜力，贝叶斯框架支持快速适应新观察和常识规则

Abstract: Humans interpret safety not as a binary signal but as a continuous, context- and spatially-dependent notion of risk. While risk is subjective, humans form rational mental models that guide action selection in dynamic environments. This work proposes a framework for extracting implicit human risk models by introducing a novel, semantically-conditioned and spatially-varying parametrization of risk, supervised directly from safe human demonstration videos and VLM common sense. Notably, we define risk through a Bayesian formulation. The prior is furnished by a pretrained vision-language model. In order to encourage the risk estimate to be more human aligned, a likelihood function modulates the prior to produce a relative metric of risk. Specifically, the likelihood is a learned ViT that maps pretrained features, to pixel-aligned risk values. Our pipeline ingests RGB images and a query object string, producing pixel-dense risk images. These images that can then be used as value-predictors in robot planning tasks or be projected into 3D for use in conventional trajectory optimization to produce human-like motion. This learned mapping enables generalization to novel objects and contexts, and has the potential to scale to much larger training datasets. In particular, the Bayesian framework that is introduced enables fast adaptation of our model to additional observations or common sense rules. We demonstrate that our proposed framework produces contextual risk that aligns with human preferences. Additionally, we illustrate several downstream applications of the model; as a value learner for visuomotor planners or in conjunction with a classical trajectory optimization algorithm. Our results suggest that our framework is a significant step toward enabling autonomous systems to internalize human-like risk. Code and results can be found at https://riskbayesian.github.io/bayesian_risk/.

</details>


### [31] [Learning Spatiotemporal Tubes for Temporal Reach-Avoid-Stay Tasks using Physics-Informed Neural Networks](https://arxiv.org/abs/2512.08248)
*Ahan Basu,Ratnangshu Das,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出基于时空管道的控制框架，用于未知动态的MIMO非线性纯反馈系统，在外部扰动下实现规定时间的到达-避障-停留任务


<details>
  <summary>Details</summary>
Motivation: 针对具有未知动态、外部扰动和复杂任务规格（到达-避障-停留）的非线性控制系统，需要一种能够保证安全性和性能的鲁棒控制框架

Method: 定义时空管道作为时变球体，使用物理信息神经网络联合逼近其中心和半径，通过损失函数约束训练，提出基于Lipschitz的有效性验证条件，并设计无近似的闭式控制器

Result: 框架在移动机器人和飞行器的避障导航案例研究中验证了有效性和可扩展性，能够保证T-RAS任务规格的满足

Conclusion: 提出的STT控制框架为未知动态非线性系统提供了一种基于学习的鲁棒控制方法，能够保证复杂时空任务规格的满足，并通过形式验证确保连续时间范围内的有效性

Abstract: This paper presents a Spatiotemporal Tube (STT)-based control framework for general control-affine MIMO nonlinear pure-feedback systems with unknown dynamics to satisfy prescribed time reach-avoid-stay tasks under external disturbances. The STT is defined as a time-varying ball, whose center and radius are jointly approximated by a Physics-Informed Neural Network (PINN). The constraints governing the STT are first formulated as loss functions of the PINN, and a training algorithm is proposed to minimize the overall violation. The PINN being trained on certain collocation points, we propose a Lipschitz-based validity condition to formally verify that the learned PINN satisfies the conditions over the continuous time horizon. Building on the learned STT representation, an approximation-free closed-form controller is defined to guarantee satisfaction of the T-RAS specification. Finally, the effectiveness and scalability of the framework are validated through two case studies involving a mobile robot and an aerial vehicle navigating through cluttered environments.

</details>


### [32] [Zero-Splat TeleAssist: A Zero-Shot Pose Estimation Framework for Semantic Teleoperation](https://arxiv.org/abs/2512.08271)
*Srijan Dokania,Dharini Raghavan*

Main category: cs.RO

TL;DR: Zero-Splat TeleAssist：零样本传感器融合管道，将普通CCTV视频流转换为共享6自由度世界模型，用于多边遥操作


<details>
  <summary>Details</summary>
Motivation: 解决多机器人遥操作中需要实时全局位置和姿态信息的问题，避免使用标记物或深度传感器，降低系统成本和复杂度

Method: 集成视觉语言分割、单目深度估计、加权PCA姿态提取和3D高斯溅射技术，从普通监控视频流构建6自由度世界模型

Result: 为每个操作员提供多个机器人的实时全局位置和姿态信息，无需标记物或深度传感器，实现交互为中心的遥操作

Conclusion: Zero-Splat TeleAssist提供了一种低成本、零样本的传感器融合方案，将普通监控系统升级为支持多机器人遥操作的6自由度世界模型系统

Abstract: We introduce Zero-Splat TeleAssist, a zero-shot sensor-fusion pipeline that transforms commodity CCTV streams into a shared, 6-DoF world model for multilateral teleoperation. By integrating vision-language segmentation, monocular depth, weighted-PCA pose extraction, and 3D Gaussian Splatting (3DGS), TeleAssist provides every operator with real-time global positions and orientations of multiple robots without fiducials or depth sensors in an interaction-centric teleoperation setup.

</details>


### [33] [Model-Based Diffusion Sampling for Predictive Control in Offline Decision Making](https://arxiv.org/abs/2512.08280)
*Haldun Balim,Na Li,Yilun Du*

Main category: cs.RO

TL;DR: MPDiffuser是一个基于扩散模型的离线决策框架，通过规划器、动力学模型和排序器的组合设计，生成既符合任务目标又动力学可行的轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有生成式方法在离线决策中常产生动力学不可行的轨迹，需要一种能同时保证任务对齐和动力学可行性的框架。

Method: 采用组合式模型：1）规划器生成多样化任务对齐轨迹；2）动力学模型确保系统动力学一致性；3）排序器选择最优行为。使用交替扩散采样方案，在采样过程中逐步优化轨迹。

Result: 在D4RL和DSRL基准测试中表现优于现有方法，提高了样本效率，能适应新动力学，并在真实四足机器人上验证了实用性。

Conclusion: MPDiffuser通过组合设计有效解决了离线决策中轨迹可行性问题，具有理论依据和实际应用价值，可扩展到高维视觉控制任务。

Abstract: Offline decision-making requires synthesizing reliable behaviors from fixed datasets without further interaction, yet existing generative approaches often yield trajectories that are dynamically infeasible. We propose Model Predictive Diffuser (MPDiffuser), a compositional model-based diffusion framework consisting of: (i) a planner that generates diverse, task-aligned trajectories; (ii) a dynamics model that enforces consistency with the underlying system dynamics; and (iii) a ranker module that selects behaviors aligned with the task objectives. MPDiffuser employs an alternating diffusion sampling scheme, where planner and dynamics updates are interleaved to progressively refine trajectories for both task alignment and feasibility during the sampling process. We also provide a theoretical rationale for this procedure, showing how it balances fidelity to data priors with dynamics consistency. Empirically, the compositional design improves sample efficiency, as it leverages even low-quality data for dynamics learning and adapts seamlessly to novel dynamics. We evaluate MPDiffuser on both unconstrained (D4RL) and constrained (DSRL) offline decision-making benchmarks, demonstrating consistent gains over existing approaches. Furthermore, we present a preliminary study extending MPDiffuser to vision-based control tasks, showing its potential to scale to high-dimensional sensory inputs. Finally, we deploy our method on a real quadrupedal robot, showcasing its practicality for real-world control.

</details>


### [34] [Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging](https://arxiv.org/abs/2512.08333)
*Yajat Yadav,Zhiyuan Zhou,Andrew Wagenmaker,Karl Pertsch,Sergey Levine*

Main category: cs.RO

TL;DR: 提出模型权重插值方法，在微调新任务时保留预训练模型的泛化能力，实现单一策略既能学习新技能又不丢失原有能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略在微调新任务时容易过拟合到特定演示，既失去原有泛化能力，又无法在新任务内部泛化。需要一种方法在微调时保留预训练的泛化能力。

Method: 采用简单有效的策略：将微调后的模型权重与预训练模型权重进行插值合并，产生单一模型继承基础模型的通用能力并稳健学习新任务。

Result: 模型合并方法在大量仿真和真实世界实验中表现优异，在新任务的分布外变化上优于预训练和微调模型，并能实现持续学习新技能而不牺牲原有能力。

Conclusion: 权重插值合并是一种有效方法，能让单一策略既学习新任务泛化，又保留预训练的广泛能力，支持终身学习场景。

Abstract: Generalist robot policies, trained on large and diverse datasets, have demonstrated the ability to generalize across a wide spectrum of behaviors, enabling a single policy to act in varied real-world environments. However, they still fall short on new tasks not covered in the training data. When finetuned on limited demonstrations of a new task, these policies often overfit to the specific demonstrations--not only losing their prior abilities to solve a wide variety of generalist tasks but also failing to generalize within the new task itself. In this work, we aim to develop a method that preserves the generalization capabilities of the generalist policy during finetuning, allowing a single policy to robustly incorporate a new skill into its repertoire. Our goal is a single policy that both learns to generalize to variations of the new task and retains the broad competencies gained from pretraining. We show that this can be achieved through a simple yet effective strategy: interpolating the weights of a finetuned model with that of the pretrained model. We show, across extensive simulated and real-world experiments, that such model merging produces a single model that inherits the generalist abilities of the base model and learns to solve the new task robustly, outperforming both the pretrained and finetuned model on out-of-distribution variations of the new task. Moreover, we show that model merging enables continual acquisition of new skills in a lifelong learning setting, without sacrificing previously learned generalist abilities.

</details>


### [35] [Learning Robot Manipulation from Audio World Models](https://arxiv.org/abs/2512.08405)
*Fan Zhang,Michael Gienger*

Main category: cs.RO

TL;DR: 提出一种生成式潜在流匹配模型来预测未来音频观测，使机器人策略能够推理长期后果，在需要感知真实世界音频或音乐信号的操作任务中表现优于无前瞻的方法。


<details>
  <summary>Details</summary>
Motivation: 许多机器人学习任务需要多模态推理，例如灌水任务中仅凭视觉信息可能模糊或不完整，需要基于音频的时间演化进行推理，考虑其物理特性和音高模式。

Method: 提出生成式潜在流匹配模型来预测未来音频观测，该模型能够整合到机器人策略中，使系统能够推理长期后果。

Result: 在两个需要感知真实世界音频或音乐信号的操作任务中，该系统相比无前瞻的方法展现出优越性能。

Conclusion: 成功的机器人动作学习不仅依赖多模态输入，更关键的是准确预测体现内在节奏模式的未来音频状态。

Abstract: World models have demonstrated impressive performance on robotic learning tasks. Many such tasks inherently demand multimodal reasoning; for example, filling a bottle with water will lead to visual information alone being ambiguous or incomplete, thereby requiring reasoning over the temporal evolution of audio, accounting for its underlying physical properties and pitch patterns. In this paper, we propose a generative latent flow matching model to anticipate future audio observations, enabling the system to reason about long-term consequences when integrated into a robot policy. We demonstrate the superior capabilities of our system through two manipulation tasks that require perceiving in-the-wild audio or music signals, compared to methods without future lookahead. We further emphasize that successful robot action learning for these tasks relies not merely on multi-modal input, but critically on the accurate prediction of future audio states that embody intrinsic rhythmic patterns.

</details>


### [36] [A Multi-Agent LLM Framework for Design Space Exploration in Autonomous Driving Systems](https://arxiv.org/abs/2512.08476)
*Po-An Shih,Shao-Hua Wang,Yung-Che Li,Chia-Heng Tu,Chih-Han Chang*

Main category: cs.RO

TL;DR: 提出基于多智能体LLM的设计空间探索框架，用于自动驾驶系统硬件/软件配置优化，通过多模态推理自动分析执行输出，相比遗传算法找到更多帕累托最优解。


<details>
  <summary>Details</summary>
Motivation: 传统设计空间探索方法难以处理多模态执行输出和复杂性能权衡，需要人工参与评估正确性，限制了自动驾驶系统设计的效率和自动化程度。

Method: 采用多智能体LLM框架，集成多模态推理、3D仿真和性能分析工具，通过专用LLM代理处理用户输入解释、设计点生成、执行编排以及视觉/文本输出分析。

Result: 在机器人出租车案例研究中，相比遗传算法基线，在相同探索预算下识别出更多帕累托最优、成本效益更高的解决方案，导航时间减少，证明了LLM方法的效率。

Conclusion: 该框架为自动驾驶系统设计自动化开辟了新途径，通过LLM驱动的多智能体系统实现了设计空间探索的自动化和效率提升。

Abstract: Designing autonomous driving systems requires efficient exploration of large hardware/software configuration spaces under diverse environmental conditions, e.g., with varying traffic, weather, and road layouts. Traditional design space exploration (DSE) approaches struggle with multi-modal execution outputs and complex performance trade-offs, and often require human involvement to assess correctness based on execution outputs. This paper presents a multi-agent, large language model (LLM)-based DSE framework, which integrates multi-modal reasoning with 3D simulation and profiling tools to automate the interpretation of execution outputs and guide the exploration of system designs. Specialized LLM agents are leveraged to handle user input interpretation, design point generation, execution orchestration, and analysis of both visual and textual execution outputs, which enables identification of potential bottlenecks without human intervention. A prototype implementation is developed and evaluated on a robotaxi case study (an SAE Level 4 autonomous driving application). Compared with a genetic algorithm baseline, the proposed framework identifies more Pareto-optimal, cost-efficient solutions with reduced navigation time under the same exploration budget. Experimental results also demonstrate the efficiency of the adoption of the LLM-based approach for DSE. We believe that this framework paves the way to the design automation of autonomous driving systems.

</details>


### [37] [Prospect Theory in Physical Human-Robot Interaction: A Pilot Study of Probability Perception](https://arxiv.org/abs/2512.08481)
*Yixiang Lin,Tiancheng Yang,Jonathan Eden,Ying Tan*

Main category: cs.RO

TL;DR: 人类在物理人机交互中对不确定性的反应存在个体差异，可分为"权衡型"和"总是补偿型"两种行为模式，需要累积前景理论等可解释模型来改进机器人控制器设计。


<details>
  <summary>Details</summary>
Motivation: 传统pHRI控制框架基于最优控制理论，假设人类行为最小化成本函数，但人类在不确定性下的行为常偏离最优模式。需要更深入理解人类在不确定性下的行为，以设计更安全有效的物理人机交互系统。

Method: 实施物理耦合目标到达任务，机器人以系统变化概率（10%到90%）提供协助或干扰。分析参与者的力输入和决策策略，识别不同的行为模式。

Result: 发现两种明显的行为集群："权衡型"群体根据干扰可能性调整物理反应，"总是补偿型"群体表现出强烈的风险规避，不考虑概率。人类决策高度个性化，概率感知可能与实际值不同。

Conclusion: 需要累积前景理论等更可解释的行为模型来准确捕捉这些行为，为未来自适应机器人控制器的设计提供依据，以更好地适应人类在不确定性下的个体化决策模式。

Abstract: Understanding how humans respond to uncertainty is critical for designing safe and effective physical human-robot interaction (pHRI), as physically working with robots introduces multiple sources of uncertainty, including trust, comfort, and perceived safety. Conventional pHRI control frameworks typically build on optimal control theory, which assumes that human actions minimize a cost function; however, human behavior under uncertainty often departs from such optimal patterns. To address this gap, additional understanding of human behavior under uncertainty is needed. This pilot study implemented a physically coupled target-reaching task in which the robot delivered assistance or disturbances with systematically varied probabilities (10\% to 90\%). Analysis of participants' force inputs and decision-making strategies revealed two distinct behavioral clusters: a "trade-off" group that modulated their physical responses according to disturbance likelihood, and an "always-compensate" group characterized by strong risk aversion irrespective of probability. These findings provide empirical evidence that human decision-making in pHRI is highly individualized and that the perception of probability can differ to its true value. Accordingly, the study highlights the need for more interpretable behavioral models, such as cumulative prospect theory (CPT), to more accurately capture these behaviors and inform the design of future adaptive robot controllers.

</details>


### [38] [SensHRPS: Sensing Comfortable Human-Robot Proxemics and Personal Space With Eye-Tracking](https://arxiv.org/abs/2512.08518)
*Nadezhda Kushina,Ko Watanabe,Aarthi Kannan,Ashita Ashok,Andreas Dengel,Karsten Berns*

Main category: cs.RO

TL;DR: 研究使用眼动追踪和机器学习评估人与机器人互动中的舒适度，发现决策树模型表现最佳，最小瞳孔直径是关键预测因子，表明人机互动的舒适度阈值与人际互动不同。


<details>
  <summary>Details</summary>
Motivation: 社交机器人需要适应人类的近体空间规范以确保用户舒适度和参与度。虽然先前研究表明眼动追踪特征能可靠估计人际互动中的舒适度，但这些方法在人形机器人互动中的应用尚未探索。

Method: 研究使用机器人"Ameca"在四个实验控制距离（0.5米至2.0米）下，通过移动眼动追踪和主观报告（N=19）评估用户舒适度。评估了多种机器学习和深度学习模型，基于注视特征估计舒适度。

Result: 与先前人际互动研究中Transformer模型表现优异不同，决策树分类器取得了最高性能（F1分数=0.73），最小瞳孔直径被确定为最关键预测因子。

Conclusion: 研究结果表明，人机互动中的生理舒适度阈值与人际互动动态不同，可以使用可解释的逻辑模型有效建模。

Abstract: Social robots must adjust to human proxemic norms to ensure user comfort and engagement. While prior research demonstrates that eye-tracking features reliably estimate comfort in human-human interactions, their applicability to interactions with humanoid robots remains unexplored. In this study, we investigate user comfort with the robot "Ameca" across four experimentally controlled distances (0.5 m to 2.0 m) using mobile eye-tracking and subjective reporting (N=19). We evaluate multiple machine learning and deep learning models to estimate comfort based on gaze features. Contrary to previous human-human studies where Transformer models excelled, a Decision Tree classifier achieved the highest performance (F1-score = 0.73), with minimum pupil diameter identified as the most critical predictor. These findings suggest that physiological comfort thresholds in human-robot interaction differ from human-human dynamics and can be effectively modeled using interpretable logic.

</details>


### [39] [vEDGAR -- Can CARLA Do HiL?](https://arxiv.org/abs/2512.08541)
*Nils Gehrke,David Brecht,Dominik Kulmer,Dheer Patel,Frank Diermeyer*

Main category: cs.RO

TL;DR: 开发了vEDGAR框架，将CARLA模拟器扩展用于自动驾驶系统的硬件在环测试，填补了CARLA在实时全传感器堆栈仿真方面的空白。


<details>
  <summary>Details</summary>
Motivation: CARLA等开源模拟器在自动驾驶算法训练和评估中被广泛使用，但缺乏对完整传感器和执行器堆栈的实时仿真能力，无法支持硬件在环测试。这限制了CARLA在整个自动驾驶开发流程中的一致性应用。

Method: 首先推导需求并指定仿真架构，然后实现vEDGAR软件框架，将CARLA模拟器扩展为支持硬件在环测试的平台，包括对专用硬件和实时性能的支持。

Result: 成功开发了开源的vEDGAR框架和修改版CARLA分支，实现了对自动驾驶系统专用硬件的实时仿真测试，能够识别系统极限，填补了CARLA在硬件在环测试方面的空白。

Conclusion: vEDGAR框架证明了CARLA可以扩展用于自动驾驶的硬件在环测试，使其成为贯穿整个开发流程的一致评估工具，大大提升了开源自动驾驶开发工作流程的效率。

Abstract: Simulation offers advantages throughout the development process of automated driving functions, both in research and product development. Common open-source simulators like CARLA are extensively used in training, evaluation, and software-in-the-loop testing of new automated driving algorithms. However, the CARLA simulator lacks an evaluation where research and automated driving vehicles are simulated with their entire sensor and actuation stack in real time. The goal of this work is therefore to create a simulation framework for testing the automation software on its dedicated hardware and identifying its limits. Achieving this goal would greatly benefit the open-source development workflow of automated driving functions, designating CARLA as a consistent evaluation tool along the entire development process. To achieve this goal, in a first step, requirements are derived, and a simulation architecture is specified and implemented. Based on the formulated requirements, the proposed vEDGAR software is evaluated, resulting in a final conclusion on the applicability of CARLA for HiL testing of automated vehicles. The tool is available open source: Modified CARLA fork: https://github.com/TUMFTM/carla, vEDGAR Framework: https://github.com/TUMFTM/vEDGAR

</details>


### [40] [Bridging Scale Discrepancies in Robotic Control via Language-Based Action Representations](https://arxiv.org/abs/2512.08548)
*Yuchi Zhang,Churui Sun,Shiqi Liang,Diyuan Liu,Chao Ji,Wei-Nan Zhang,Ting Liu*

Main category: cs.RO

TL;DR: 提出语义基础的语言表示来规范化机器人动作，通过强调方向性而非数值尺度来缓解分布偏移，提高预训练表示的可泛化性


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的机器人操作架构面临严重分布偏移问题，主要源于不同机器人平台和任务间动作命令的数值变化，阻碍了预训练知识的有效迁移

Method: 提出语义基础的语言表示来规范化动作，强调方向性而非数值尺度，这种运动表示忽略数值尺度效应，专注于方向性，缩小动作标记与标准词汇标记的特征距离

Result: 在两个基准测试的多任务实验中，该方法显著提高了机器人操作任务的泛化性能和可迁移性

Conclusion: 通过语义基础的语言表示规范化动作，有效缓解分布偏移问题，提高预训练表示的泛化能力，促进跨平台和任务的机器人操作知识迁移

Abstract: Recent end-to-end robotic manipulation research increasingly adopts architectures inspired by large language models to enable robust manipulation. However, a critical challenge arises from severe distribution shifts between robotic action data, primarily due to substantial numerical variations in action commands across diverse robotic platforms and tasks, hindering the effective transfer of pretrained knowledge. To address this limitation, we propose a semantically grounded linguistic representation to normalize actions for efficient pretraining. Unlike conventional discretized action representations that are sensitive to numerical scales, the motion representation specifically disregards numeric scale effects, emphasizing directionality instead. This abstraction mitigates distribution shifts, yielding a more generalizable pretraining representation. Moreover, using the motion representation narrows the feature distance between action tokens and standard vocabulary tokens, mitigating modality gaps. Multi-task experiments on two benchmarks demonstrate that the proposed method significantly improves generalization performance and transferability in robotic manipulation tasks.

</details>


### [41] [RVC-NMPC: Nonlinear Model Predictive Control with Reciprocal Velocity Constraints for Mutual Collision Avoidance in Agile UAV Flight](https://arxiv.org/abs/2512.08574)
*Vit Kratky,Robert Penicka,Parakh M. Gupta,Ondrej Prochazka,Martin Saska*

Main category: cs.RO

TL;DR: 基于非线性模型预测控制（NMPC）和时间相关互惠速度约束（RVCs）的无人机互避碰撞方法，无需过多通信，运行频率达100Hz，在10架无人机、25m/s速度场景中实现无碰撞导航，飞行时间减少31%。


<details>
  <summary>Details</summary>
Motivation: 现有无人机互避碰撞方法通常需要大量通信，而本文旨在开发一种仅依赖可观测信息、无需过多通信的高效碰撞避免方法，适用于敏捷无人机飞行。

Method: 采用非线性模型预测控制（NMPC）结合时间相关互惠速度约束（RVCs），通过计算高效的RVCs算法，将约束直接集成到控制器级别的NMPC问题中，整个流水线运行频率达100Hz。

Result: 在模拟10架无人机、速度达25m/s的真实场景中，以及在加速度达30m/s²的真实实验中，所有试验均实现无碰撞导航。与现有技术相比，在挑战性场景中飞行时间减少31%。

Conclusion: 提出的基于NMPC和RVCs的方法能够实现高效、无通信依赖的无人机互避碰撞，运行频率高，适用于敏捷飞行，在复杂多无人机场景中表现出优越性能。

Abstract: This paper presents an approach to mutual collision avoidance based on Nonlinear Model Predictive Control (NMPC) with time-dependent Reciprocal Velocity Constraints (RVCs). Unlike most existing methods, the proposed approach relies solely on observable information about other robots, eliminating the necessity of excessive communication use. The computationally efficient algorithm for computing RVCs, together with the direct integration of these constraints into NMPC problem formulation on a controller level, allows the whole pipeline to run at 100 Hz. This high processing rate, combined with modeled nonlinear dynamics of the controlled Uncrewed Aerial Vehicles (UAVs), is a key feature that facilitates the use of the proposed approach for an agile UAV flight. The proposed approach was evaluated through extensive simulations emulating real-world conditions in scenarios involving up to 10 UAVs and velocities of up to 25 m/s, and in real-world experiments with accelerations up to 30 m/s$^2$. Comparison with state of the art shows 31% improvement in terms of flight time reduction in challenging scenarios, while maintaining a collision-free navigation in all trials.

</details>


### [42] [Mind to Hand: Purposeful Robotic Control via Embodied Reasoning](https://arxiv.org/abs/2512.08580)
*Peijun Tang,Shangjin Xie,Binyan Sun,Baifu Huang,Kuncheng Luo,Haotian Yang,Weiqi Jin,Jianan Wang*

Main category: cs.RO

TL;DR: Lumo-1是一个统一的视觉-语言-动作模型，通过三阶段预训练将AI推理能力与机器人物理动作相结合，在具身推理和机器人控制任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 虽然互联网规模数据使AI系统具备了广泛的推理能力，但将这些能力落地到物理动作中仍然是一个重大挑战。人类行动具有上下文和意图，推理在其中起着核心作用，因此需要将机器人的"思维"（推理）与"手"（动作）统一起来

Method: 采用三阶段预训练流程：1）在精选的视觉-语言数据上继续预训练VLM，增强具身推理能力；2）在跨具身机器人数据和视觉-语言数据上进行联合训练；3）在Astribot S1双手机器人收集的轨迹上进行带推理过程的动作训练。最后整合强化学习来优化推理-动作一致性

Result: Lumo-1在具身视觉-语言推理方面取得显著性能提升，这是通用机器人控制的关键组件。真实世界评估显示，Lumo-1在广泛挑战性机器人任务中超越强基线，对新物体和环境具有强泛化能力，在长时域任务和需要策略、概念和空间推理的人类自然指令响应方面表现优异

Conclusion: Lumo-1成功地将预训练视觉语言模型的推理能力扩展到具身推理和动作预测，实现了机器人"思维"与"动作"的统一，为通用机器人控制提供了有前景的解决方案

Abstract: Humans act with context and intention, with reasoning playing a central role. While internet-scale data has enabled broad reasoning capabilities in AI systems, grounding these abilities in physical action remains a major challenge. We introduce Lumo-1, a generalist vision-language-action (VLA) model that unifies robot reasoning ("mind") with robot action ("hand"). Our approach builds upon the general multi-modal reasoning capabilities of pre-trained vision-language models (VLMs), progressively extending them to embodied reasoning and action prediction, and ultimately towards structured reasoning and reasoning-action alignment. This results in a three-stage pre-training pipeline: (1) Continued VLM pre-training on curated vision-language data to enhance embodied reasoning skills such as planning, spatial understanding, and trajectory prediction; (2) Co-training on cross-embodiment robot data alongside vision-language data; and (3) Action training with reasoning process on trajectories collected on Astribot S1, a bimanual mobile manipulator with human-like dexterity and agility. Finally, we integrate reinforcement learning to further refine reasoning-action consistency and close the loop between semantic inference and motor control. Extensive experiments demonstrate that Lumo-1 achieves significant performance improvements in embodied vision-language reasoning, a critical component for generalist robotic control. Real-world evaluations further show that Lumo-1 surpasses strong baselines across a wide range of challenging robotic tasks, with strong generalization to novel objects and environments, excelling particularly in long-horizon tasks and responding to human-natural instructions that require reasoning over strategy, concepts and space.

</details>


### [43] [Multi-Task Bayesian Optimization for Tuning Decentralized Trajectory Generation in Multi-UAV Systems](https://arxiv.org/abs/2512.08630)
*Marta Manzoni,Alessandro Nazzari,Roberto Rubinacci,Marco Lovera*

Main category: cs.RO

TL;DR: 使用多任务贝叶斯优化调整多无人机系统中的分散轨迹生成算法，通过多任务高斯过程建模不同场景间关系，比较平均任务优化和单任务优化策略。


<details>
  <summary>Details</summary>
Motivation: 在多无人机系统中，分散轨迹生成算法的参数调优面临挑战，特别是随着无人机数量增加，优化成本急剧上升。需要一种能够跨不同交互场景共享信息的高效优化方法。

Method: 采用多任务贝叶斯优化框架，将每个任务定义为特定无人机间交互数量的轨迹生成场景。使用多任务高斯过程建模任务间关系，实现优化过程中的信息传递。比较两种策略：优化所有任务的平均任务时间和单独优化每个任务。

Result: 模拟实验表明，单任务优化随着群体规模增长能实现逐渐缩短的任务时间，但需要比平均任务方法显著更多的优化时间。

Conclusion: 多任务贝叶斯优化为多无人机系统轨迹生成参数调优提供了有效框架，平均任务优化策略在优化效率方面具有优势，而单任务优化在性能提升方面表现更好但代价更高。

Abstract: This paper investigates the use of Multi-Task Bayesian Optimization for tuning decentralized trajectory generation algorithms in multi-drone systems. We treat each task as a trajectory generation scenario defined by a specific number of drone-to-drone interactions. To model relationships across scenarios, we employ Multi-Task Gaussian Processes, which capture shared structure across tasks and enable efficient information transfer during optimization. We compare two strategies: optimizing the average mission time across all tasks and optimizing each task individually. Through a comprehensive simulation campaign, we show that single-task optimization leads to progressively shorter mission times as swarm size grows, but requires significantly more optimization time than the average-task approach.

</details>


### [44] [A Sensor-Aware Phenomenological Framework for Lidar Degradation Simulation and SLAM Robustness Evaluation](https://arxiv.org/abs/2512.08653)
*Doumegna Mawuto Koudjo Felix,Xianjia Yu,Zhuo Zou,Tomi Westerlund*

Main category: cs.RO

TL;DR: 提出一个传感器感知的激光雷达退化模拟框架，用于在真实点云上模拟可解释的退化效果，以可控和可重复的方式测试SLAM系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的激光雷达SLAM鲁棒性评估方法要么缺乏物理基础，要么无法捕捉传感器特定的行为。激光雷达SLAM系统对遮挡、噪声和视场退化等恶劣条件高度敏感，需要一种更物理基础的评估方法。

Method: 开发了一个传感器感知的现象学框架，直接在真实点云上模拟可解释的激光雷达退化。该方法保留每点的几何、强度和时间结构，同时应用结构化丢失、视场减少、高斯噪声、遮挡掩码、稀疏化和运动失真。框架具有自主主题和传感器检测、模块化配置（四个严重级别）和实时性能（每帧小于20毫秒）。

Result: 在三种激光雷达架构和五种最先进的SLAM系统上进行实验验证，揭示了由传感器设计和环境背景塑造的独特鲁棒性模式。开源实现为在物理有意义的退化场景下基准测试激光雷达SLAM提供了实用基础。

Conclusion: 该框架提供了一种传感器感知、物理基础的方法来评估激光雷达SLAM系统的鲁棒性，填补了现有评估方法的空白，为可控和可重复的SLAM压力测试提供了实用工具。

Abstract: Lidar-based SLAM systems are highly sensitive to adverse conditions such as occlusion, noise, and field-of-view (FoV) degradation, yet existing robustness evaluation methods either lack physical grounding or do not capture sensor-specific behavior. This paper presents a sensor-aware, phenomenological framework for simulating interpretable lidar degradations directly on real point clouds, enabling controlled and reproducible SLAM stress testing. Unlike image-derived corruption benchmarks (e.g., SemanticKITTI-C) or simulation-only approaches (e.g., lidarsim), the proposed system preserves per-point geometry, intensity, and temporal structure while applying structured dropout, FoV reduction, Gaussian noise, occlusion masking, sparsification, and motion distortion. The framework features autonomous topic and sensor detection, modular configuration with four severity tiers (light--extreme), and real-time performance (less than 20 ms per frame) compatible with ROS workflows. Experimental validation across three lidar architectures and five state-of-the-art SLAM systems reveals distinct robustness patterns shaped by sensor design and environmental context. The open-source implementation provides a practical foundation for benchmarking lidar-based SLAM under physically meaningful degradation scenarios.

</details>


### [45] [Sim2Swim: Zero-Shot Velocity Control for Agile AUV Maneuvering in 3 Minutes](https://arxiv.org/abs/2512.08656)
*Lauritz Rismark Fosso,Herman Biørn Amundsen,Marios Xanthidis,Sveinung Johan Ohrem*

Main category: cs.RO

TL;DR: 首个零样本sim2real深度强化学习速度控制器，仅需3分钟训练即可实现AUV的6自由度敏捷机动和路径跟踪


<details>
  <summary>Details</summary>
Motivation: 全向自主水下航行器（AUV）具备硬件上的敏捷机动能力，但由于复杂的水静力学和水动力学、参数不确定性以及载荷变化导致的动态特性频繁改变，控制具有挑战性。传统方法需要针对特定平台配置精心调优控制器，且在不同载荷和水动力条件下需要重新调优，导致6自由度敏捷机动在实践中很少使用。

Method: 提出Sim2Swim方法，受最先进的DRL位置控制启发，利用域随机化和大规模并行训练，无需后处理或调优即可为不同特性的AUV收敛到可现场部署的控制策略。这是首个通用的零样本sim2real深度强化学习速度控制器。

Result: 在多种配置的池试验中进行了广泛验证，展示了高度敏捷运动的鲁棒控制性能。训练时间仅需3分钟，就能实现路径跟踪和6自由度敏捷机动。

Conclusion: Sim2Swim方法成功实现了首个零样本sim2real DRL速度控制器，能够处理AUV的复杂动态特性变化，为水下航行器的敏捷机动控制提供了实用解决方案。

Abstract: Holonomic autonomous underwater vehicles (AUVs) have the hardware ability for agile maneuvering in both translational and rotational degrees of freedom (DOFs). However, due to challenges inherent to underwater vehicles, such as complex hydrostatics and hydrodynamics, parametric uncertainties, and frequent changes in dynamics due to payload changes, control is challenging. Performance typically relies on carefully tuned controllers targeting unique platform configurations, and a need for re-tuning for deployment under varying payloads and hydrodynamic conditions. As a consequence, agile maneuvering with simultaneous tracking of time-varying references in both translational and rotational DOFs is rarely utilized in practice. To the best of our knowledge, this paper presents the first general zero-shot sim2real deep reinforcement learning-based (DRL) velocity controller enabling path following and agile 6DOF maneuvering with a training duration of just 3 minutes. Sim2Swim, the proposed approach, inspired by state-of-the-art DRL-based position control, leverages domain randomization and massively parallelized training to converge to field-deployable control policies for AUVs of variable characteristics without post-processing or tuning. Sim2Swim is extensively validated in pool trials for a variety of configurations, showcasing robust control for highly agile motions.

</details>


### [46] [Ergodic Trajectory Planning with Dynamic Sensor Footprints](https://arxiv.org/abs/2512.08661)
*Ziyue Zheng,Yongce Liu,Hesheng Wang,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 提出一种考虑动态传感器足迹的遍历规划新方法，能够同时优化轨迹和传感器配置，相比传统方法提升一个数量级的遍历性。


<details>
  <summary>Details</summary>
Motivation: 现有遍历规划方法通常假设点传感器或固定形状分辨率的传感器足迹，而实际中传感器足迹会随机器人运动动态变化（如无人机俯仰角、高度变化导致视野变化），需要新的规划框架来处理这种动态传感器模型。

Method: 提出考虑动态传感器足迹的新度量指标，分析理论局部最优条件，并开发数值轨迹优化算法，能够同时优化机器人轨迹和传感器配置。

Result: 实验结果表明，所提方法能同时优化轨迹和传感器足迹，相比传统方法提升高达一个数量级的遍历性，并在多无人机系统中成功应用于3D空间物体覆盖。

Conclusion: 该研究解决了动态传感器足迹下的遍历规划问题，提出的新度量和优化算法能有效处理传感器配置变化，为实际机器人信息采集任务提供了更实用的解决方案。

Abstract: This paper addresses the problem of trajectory planning for information gathering with a dynamic and resolution-varying sensor footprint. Ergodic planning offers a principled framework that balances exploration (visiting all areas) and exploitation (focusing on high-information regions) by planning trajectories such that the time spent in a region is proportional to the amount of information in that region. Existing ergodic planning often oversimplifies the sensing model by assuming a point sensor or a footprint with constant shape and resolution. In practice, the sensor footprint can drastically change over time as the robot moves, such as aerial robots equipped with downward-facing cameras, whose field of view depends on the orientation and altitude. To overcome this limitation, we propose a new metric that accounts for dynamic sensor footprints, analyze the theoretic local optimality conditions, and propose numerical trajectory optimization algorithms. Experimental results show that the proposed approach can simultaneously optimize both the trajectories and sensor footprints, with up to an order of magnitude better ergodicity than conventional methods. We also deploy our approach in a multi-drone system to ergodically cover an object in 3D space.

</details>


### [47] [Non Normalized Shared-Constraint Dynamic Games for Human-Robot Collaboration with Asymmetric Responsibility](https://arxiv.org/abs/2512.08688)
*Mark Pustilnik,Francesco Borrelli*

Main category: cs.RO

TL;DR: 提出一种用于人机协作导航的动态博弈框架，引入非归一化均衡结构处理共享安全约束，并嵌入到滚动时域最优控制中


<details>
  <summary>Details</summary>
Motivation: 在存在障碍物的共享工作空间中，需要人机协作完成共同任务，同时满足共享安全约束（如避碰和间距保持）。传统方法通常假设双方贡献相同努力，但实际中人和机器人可能有不同的能力和责任，需要更灵活的合作机制。

Method: 1. 建立人机协作导航的动态博弈模型；2. 引入非归一化均衡结构处理共享安全约束，允许双方以不同努力水平执行安全要求；3. 将该均衡结构嵌入到滚动时域最优控制框架中。

Result: 提出了一个能够处理共享安全约束的灵活协作框架，允许人和机器人根据各自能力以不同努力水平参与安全约束的执行，相比传统归一化方法更具实际应用价值。

Conclusion: 通过非归一化均衡结构和滚动时域最优控制的结合，为人机协作导航提供了一种更灵活、更实用的解决方案，能够适应实际应用中双方能力差异的情况。

Abstract: This paper proposes a dynamic game formulation for cooperative human-robot navigation in shared workspaces with obstacles, where the human and robot jointly satisfy shared safety constraints while pursuing a common task. A key contribution is the introduction of a non-normalized equilibrium structure for the shared constraints. This structure allows the two agents to contribute different levels of effort towards enforcing safety requirements such as collision avoidance and inter-players spacing. We embed this non-normalized equilibrium into a receding-horizon optimal control scheme.

</details>


### [48] [A Multi-Robot Platform for Robotic Triage Combining Onboard Sensing and Foundation Models](https://arxiv.org/abs/2512.08754)
*Jason Hughes,Marcel Hussing,Edward Zhang,Shenbagaraj Kannapiran,Joshua Caswell,Kenneth Chaney,Ruichen Deng,Michaela Feehery,Agelos Kratimenos,Yi Fan Li,Britny Major,Ethan Sanchez,Sumukh Shrote,Youkang Wang,Jeremy Wang,Daudi Zein,Luying Zhang,Ruijun Zhang,Alex Zhou,Tenzi Zhouga,Jeremy Cannon,Zaffir Qasim,Jay Yelon,Fernando Cladera,Kostas Daniilidis,Camillo J. Taylor,Eric Eaton*

Main category: cs.RO

TL;DR: 提出一个用于大规模伤亡事件远程初级分诊的异构机器人系统，由无人机和地面机器人协同工作，在不危及救援人员的情况下定位受害者、评估伤情并确定医疗优先级。


<details>
  <summary>Details</summary>
Motivation: 大规模伤亡事件中，传统救援方式会危及救援人员生命，且缺乏完整的远程分诊系统。现有机器人研究多关注探索或有限的医疗评估，无法完成完整的分诊流程。

Method: 采用无人机与地面机器人协同的异构系统：无人机负责定位受害者并提供俯视图；地面机器人配备专业传感器测量生命体征、检测和定位身体损伤。系统整合了受害者定位、生命体征测量、伤情严重程度分类、精神状态评估和数据整合等完整分诊流程。

Result: 该系统作为DARPA分诊挑战赛的一部分开发，展示了多机器人系统如何在灾难响应场景中增强人类能力，最大限度地挽救生命。

Conclusion: 异构机器人系统能够有效支持大规模伤亡事件的远程初级分诊，通过无人机和地面机器人的协同工作，在不危及救援人员的情况下完成完整的分诊流程，为灾难响应提供创新解决方案。

Abstract: This report presents a heterogeneous robotic system designed for remote primary triage in mass-casualty incidents (MCIs). The system employs a coordinated air-ground team of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) to locate victims, assess their injuries, and prioritize medical assistance without risking the lives of first responders. The UAV identify and provide overhead views of casualties, while UGVs equipped with specialized sensors measure vital signs and detect and localize physical injuries. Unlike previous work that focused on exploration or limited medical evaluation, this system addresses the complete triage process: victim localization, vital sign measurement, injury severity classification, mental status assessment, and data consolidation for first responders. Developed as part of the DARPA Triage Challenge, this approach demonstrates how multi-robot systems can augment human capabilities in disaster response scenarios to maximize lives saved.

</details>


### [49] [Data-Driven Dynamic Parameter Learning of manipulator robots](https://arxiv.org/abs/2512.08767)
*Mohammed Elseiagy,Tsige Tadesse Alemayoh,Ranulfo Bezerra,Shotaro Kojima,Kazunori Ohno*

Main category: cs.RO

TL;DR: 提出基于Transformer的动态参数估计方法，通过自动生成多样化机器人模型和轨迹数据，结合雅可比特征，实现高精度参数估计，提升仿真到现实的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 机器人仿真到现实的差距是根本挑战，准确的动态参数估计对基于模型的控制、真实仿真和安全部署至关重要。传统分析方法难以处理复杂机器人结构和交互，而传统神经网络无法捕捉长距离依赖关系。

Method: 提出基于Transformer的动态参数估计方法，构建自动化的数据生成流程，生成8,192个具有不同惯性和摩擦特性的机器人模型，使用雅可比推导的特征丰富轨迹数据，利用注意力机制捕捉时空依赖关系。

Result: 最佳配置（序列长度64、64Hz采样率、4层、32头）达到验证R2为0.8633。质量和惯性估计接近完美，库仑摩擦达到中高精度，而粘性摩擦和远端连杆质心估计更具挑战性。

Conclusion: Transformer结合自动化数据集生成和运动学特征增强，能够实现可扩展、准确的动态参数估计，有助于改善机器人系统的仿真到现实迁移。

Abstract: Bridging the sim-to-real gap remains a fundamental challenge in robotics, as accurate dynamic parameter estimation is essential for reliable model-based control, realistic simulation, and safe deployment of manipulators. Traditional analytical approaches often fall short when faced with complex robot structures and interactions. Data-driven methods offer a promising alternative, yet conventional neural networks such as recurrent models struggle to capture long-range dependencies critical for accurate estimation. In this study, we propose a Transformer-based approach for dynamic parameter estimation, supported by an automated pipeline that generates diverse robot models and enriched trajectory data using Jacobian-derived features. The dataset consists of 8,192 robots with varied inertial and frictional properties. Leveraging attention mechanisms, our model effectively captures both temporal and spatial dependencies. Experimental results highlight the influence of sequence length, sampling rate, and architecture, with the best configuration (sequence length 64, 64 Hz, four layers, 32 heads) achieving a validation R2 of 0.8633. Mass and inertia are estimated with near-perfect accuracy, Coulomb friction with moderate-to-high accuracy, while viscous friction and distal link center-of-mass remain more challenging. These results demonstrate that combining Transformers with automated dataset generation and kinematic enrichment enables scalable, accurate dynamic parameter estimation, contributing to improved sim-to-real transfer in robotic systems

</details>


### [50] [Heterogeneity in Multi-Robot Environmental Monitoring for Resolving Time-Conflicting Tasks](https://arxiv.org/abs/2512.08813)
*Connor York,Zachary R Madin,Paul O'Dowd,Edmund R Hunt*

Main category: cs.RO

TL;DR: 多机器人系统在连续任务中被紧急子任务中断时面临性能权衡，研究通过角色专业化（巡逻者和搜索者）和感知异质性来优化这种权衡


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在执行连续任务时，如果被紧急、时间关键的子任务中断，会面临性能权衡问题。本文研究如何在区域巡逻和定位异常无线电信号这两个时间冲突的任务之间找到最优平衡

Method: 通过模拟评估两种异质性策略：1）行为异质性（角色专业化：巡逻者和搜索者），2）感知异质性（只有搜索者能感知无线电信号）。在不同团队组成下识别帕累托最优权衡

Result: 行为异质性团队在大多数情况下表现出最平衡的权衡。当感知能力受限时，只有一半机器人具备感知能力的异质性团队与同质性团队表现相当，这为限制传感器部署提供了成本节约依据

Conclusion: 预部署角色和感知专业化是多机器人系统面对时间冲突任务时的重要设计考虑因素，通过调整行为异质性程度可以调节系统性能偏向特定任务

Abstract: Multi-robot systems performing continuous tasks face a performance trade-off when interrupted by urgent, time-critical sub-tasks. We investigate this trade-off in a scenario where a team must balance area patrolling with locating an anomalous radio signal. To address this trade-off, we evaluate both behavioral heterogeneity through agent role specialization ("patrollers" and "searchers") and sensing heterogeneity (i.e., only the searchers can sense the radio signal). Through simulation, we identify the Pareto-optimal trade-offs under varying team compositions, with behaviorally heterogeneous teams demonstrating the most balanced trade-offs in the majority of cases. When sensing capability is restricted, heterogeneous teams with half of the sensing-capable agents perform comparably to homogeneous teams, providing cost-saving rationale for restricting sensor payload deployment. Our findings demonstrate that pre-deployment role and sensing specialization are powerful design considerations for multi-robot systems facing time-conflicting tasks, where varying the degree of behavioral heterogeneity can tune system performance toward either task.

</details>


### [51] [IPPO Learns the Game, Not the Team: A Study on Generalization in Heterogeneous Agent Teams](https://arxiv.org/abs/2512.08877)
*Ryan LeRoy,Jack Kolb*

Main category: cs.RO

TL;DR: 在异构多智能体环境中，研究发现简单的IPPO自博弈基线方法对未见过的队友算法具有良好泛化能力，与专门设计的多样化训练方法RPT表现相当。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体强化学习中自博弈训练是否真正学习到基于游戏本质的通用协调策略，还是仅仅过拟合到训练伙伴的行为模式。

Method: 提出旋转策略训练(RPT)方法，在训练过程中轮换不同学习算法的异构队友策略，让智能体接触更广泛的伙伴策略；使用HeMAC异构多智能体挑战环境，包含观察者和无人机两种互补能力的智能体。

Result: 当与保留的队友策略(DDQN)一起游戏时，RPT与标准的自博弈基线IPPO表现相似，表明IPPO基线能够泛化到未见过的队友算法，尽管训练中没有经历队友多样性。

Conclusion: 简单的IPPO基线方法可能已经具备了专门设计的多样化训练方法所期望达到的对新队友的泛化能力，这表明在异构多智能体设置中，自博弈训练可能比预期更具泛化性。

Abstract: Multi-Agent Reinforcement Learning (MARL) is commonly deployed in settings where agents are trained via self-play with homogeneous teammates, often using parameter sharing and a single policy architecture. This opens the question: to what extent do self-play PPO agents learn general coordination strategies grounded in the underlying game, compared to overfitting to their training partners' behaviors? This paper investigates the question using the Heterogeneous Multi-Agent Challenge (HeMAC) environment, which features distinct Observer and Drone agents with complementary capabilities. We introduce Rotating Policy Training (RPT), an approach that rotates heterogeneous teammate policies of different learning algorithms during training, to expose the agent to a broader range of partner strategies. When playing alongside a withheld teammate policy (DDQN), we find that RPT achieves similar performance to a standard self-play baseline, IPPO, where all agents were trained sharing a single PPO policy. This result indicates that in this heterogeneous multi-agent setting, the IPPO baseline generalizes to novel teammate algorithms despite not experiencing teammate diversity during training. This shows that a simple IPPO baseline may possess the level of generalization to novel teammates that a diverse training regimen was designed to achieve.

</details>


### [52] [OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer](https://arxiv.org/abs/2512.08920)
*Jessica Yin,Haozhi Qi,Youngsun Wi,Sayantan Kundu,Mike Lambeta,William Yang,Changhao Wang,Tingfan Wu,Jitendra Malik,Tess Hellebrekers*

Main category: cs.RO

TL;DR: OSMO是一种开源可穿戴触觉手套，用于人类到机器人的技能转移，通过12个三轴触觉传感器收集接触信号，使机器人能够仅凭人类演示数据学习执行接触丰富的操作任务。


<details>
  <summary>Details</summary>
Motivation: 人类视频演示为学习机器人策略提供了丰富的训练数据，但视频本身无法捕捉操作中关键的丰富接触信号，这限制了机器人掌握复杂操作任务的能力。

Method: 开发OSMO开源可穿戴触觉手套，配备12个三轴触觉传感器分布在指尖和手掌，兼容先进的手部跟踪方法进行野外数据收集。通过为人类和机器人配备相同的手套，最小化视觉和触觉的体现差距，实现连续剪切力和法向力反馈的转移。

Result: 仅使用OSMO收集的人类演示数据训练的机器人策略（无需真实机器人数据）能够执行具有挑战性的接触丰富操作任务。在需要持续接触压力的真实世界擦拭任务中，触觉感知策略达到72%的成功率，优于仅基于视觉的基线方法。

Conclusion: OSMO通过最小化人类和机器人之间的体现差距，实现了有效的触觉技能转移，为接触丰富的操作任务提供了新的解决方案，并通过开源硬件设计促进社区采用。

Abstract: Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, is capable of executing a challenging contact-rich manipulation task. By equipping both the human and the robot with the same glove, OSMO minimizes the visual and tactile embodiment gap, enabling the transfer of continuous shear and normal force feedback while avoiding the need for image inpainting or other vision-based force inference. On a real-world wiping task requiring sustained contact pressure, our tactile-aware policy achieves a 72% success rate, outperforming vision-only baselines by eliminating contact-related failure modes. We release complete hardware designs, firmware, and assembly instructions to support community adoption.

</details>
