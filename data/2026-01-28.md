<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 46]
- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Language Family Matters: Evaluating LLM-Based ASR Across Linguistic Boundaries](https://arxiv.org/abs/2601.18899)
*Yuchen Zhang,Ravi Shekhar,Haralambos Mouratidis*

Main category: cs.CL

TL;DR: 提出基于语言家族的连接器共享策略，用一个连接器服务同一语言家族的所有语言，减少参数同时提升跨领域泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的ASR系统为每种语言训练单独连接器，忽略了语言之间的相关性，导致参数冗余且无法充分利用语言家族内的相似性

Method: 提出基于语言家族成员关系的连接器共享策略，同一语言家族内的语言共享一个连接器，而不是为每种语言训练单独连接器

Result: 在两个多语言LLM和两个真实世界语料库上的实验表明，家族式连接器在减少参数数量的同时，提升了跨领域的泛化能力

Conclusion: 基于语言家族的连接器共享策略为多语言ASR部署提供了实用且可扩展的方案，在保持性能的同时显著减少了模型参数

Abstract: Large Language Model (LLM)-powered Automatic Speech Recognition (ASR) systems achieve strong performance with limited resources by linking a frozen speech encoder to a pretrained LLM via a lightweight connector. Prior work trains a separate connector per language, overlooking linguistic relatedness. We propose an efficient and novel connector-sharing strategy based on linguistic family membership, enabling one connector per family, and empirically validate its effectiveness across two multilingual LLMs and two real-world corpora spanning curated and crowd-sourced speech. Our results show that family-based connectors reduce parameter count while improving generalization across domains, offering a practical and scalable strategy for multilingual ASR deployment.

</details>


### [2] [Self-Aware Knowledge Probing: Evaluating Language Models' Relational Knowledge through Confidence Calibration](https://arxiv.org/abs/2601.18901)
*Christopher Kissling,Elena Merdjanovska,Alan Akbik*

Main category: cs.CL

TL;DR: 提出新的校准探测框架评估语言模型关系知识的可靠性，发现多数模型（特别是掩码模型）过于自信，最佳校准来自考虑语句重述不一致性的置信度估计。


<details>
  <summary>Details</summary>
Motivation: 现有知识探测方法仅通过准确率等指标评估模型能力，未能考虑模型可靠性（反映在其置信度校准上）。需要评估语言模型关系知识的校准特性。

Method: 提出关系知识校准探测框架，涵盖三种模型置信度模态：内在置信度、结构一致性和语义基础。分析了10个因果模型和6个掩码语言模型。

Result: 大多数模型（特别是掩码预训练模型）过于自信；最佳校准分数来自考虑语句重述不一致性的置信度估计；即使最大的预训练模型也无法准确编码语言置信表达式的语义。

Conclusion: 需要关注语言模型关系知识的校准问题，现有评估方法忽略了可靠性维度。模型置信度校准对于实际应用中的可信度至关重要。

Abstract: Knowledge probing quantifies how much relational knowledge a language model (LM) has acquired during pre-training. Existing knowledge probes evaluate model capabilities through metrics like prediction accuracy and precision. Such evaluations fail to account for the model's reliability, reflected in the calibration of its confidence scores. In this paper, we propose a novel calibration probing framework for relational knowledge, covering three modalities of model confidence: (1) intrinsic confidence, (2) structural consistency and (3) semantic grounding. Our extensive analysis of ten causal and six masked language models reveals that most models, especially those pre-trained with the masking objective, are overconfident. The best-calibrated scores come from confidence estimates that account for inconsistencies due to statement rephrasing. Moreover, even the largest pre-trained models fail to encode the semantics of linguistic confidence expressions accurately.

</details>


### [3] [Flatter Tokens are More Valuable for Speculative Draft Model Training](https://arxiv.org/abs/2601.18902)
*Jiaming Fan,Daming Cao,Xiangzhong Luo,Jiale Fu,Chonghan Liu,Xu Yang*

Main category: cs.CL

TL;DR: 提出SFDD方法，通过基于平坦度的数据筛选，仅用50%数据实现2倍训练加速，推理加速损失小于4%


<details>
  <summary>Details</summary>
Motivation: 传统推测解码需要大量数据训练草稿模型，但并非所有训练样本对接受率贡献相同。研究发现目标模型预测分布平坦的token更有价值

Method: 提出平坦度指标量化token价值，开发基于样本平坦度的数据集蒸馏方法，筛选最有价值样本进行训练

Result: 在EAGLE框架上，仅用50%数据实现超过2倍训练加速，最终模型推理加速与全数据集基线差距在4%以内

Conclusion: 提出了一种有效的数据中心化方法，显著提高了推测解码的训练效率

Abstract: Speculative Decoding (SD) is a key technique for accelerating Large Language Model (LLM) inference, but it typically requires training a draft model on a large dataset. We approach this problem from a data-centric perspective, finding that not all training samples contribute equally to the SD acceptance rate. Specifically, our theoretical analysis and empirical validation reveals that tokens inducing flatter predictive distributions from the target model are more valuable than those yielding sharply peaked distributions. Based on this insight, we propose flatness, a new metric to quantify this property, and develop the Sample-level-flatness-based Dataset Distillation (SFDD) approach, which filters the training data to retain only the most valuable samples. Experiments on the EAGLE framework demonstrate that SFDD can achieve over 2$\times$ training speedup using only 50% of the data, while keeping the final model's inference speedup within 4% of the full-dataset baseline. This work introduces an effective, data-centric approach that substantially improves the training efficiency for Speculative Decoding. Our code is available at https://anonymous.4open.science/r/Flatness.

</details>


### [4] [BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models](https://arxiv.org/abs/2601.18933)
*Kaustubh D. Dhole*

Main category: cs.CL

TL;DR: 研究人员开发了BabyReasoningBench基准测试，用于评估在儿童发展数据上训练的"婴儿语言模型"的推理能力，发现这些模型在因果推理方面有所提升，但在心理理论和语用推理方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型评估基准主要针对成人设计，假设了广泛的世界知识、复杂指令遵循和成熟的语用能力。这些假设与在儿童发展数据（如儿童导向语音和早期童年叙事）上训练的"婴儿语言模型"不匹配，无法揭示在这种约束下哪些推理能力能够出现。

Method: 研究人员引入了BabyReasoningBench，这是一个基于GPT-5.2生成的基准测试，包含19个推理任务，这些任务根植于发展心理学的经典范式，涵盖心理理论、类比和关系推理、因果推理和干预选择，以及已知受记忆和语用混淆影响的核心推理原语。

Result: 研究发现，两个基于GPT-2的婴儿语言模型（在1000万和1亿个儿童导向语音文本上预训练）整体表现较低但不均衡，在不同任务家族中存在分离：扩展规模改善了多个因果和物理推理任务，而信念归因和语用敏感任务仍然具有挑战性。

Conclusion: BabyReasoningBench提供了一个发展心理学基础的分析框架，用于研究儿童式训练分布支持哪些类型的推理能力，并测试关于这些能力如何出现的机制假设。

Abstract: Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.

</details>


### [5] [LLMs versus the Halting Problem: Revisiting Program Termination Prediction](https://arxiv.org/abs/2601.18987)
*Oren Sultan,Jordi Armengol-Estape,Pascal Kesseli,Julien Vanegue,Dafna Shahaf,Yossi Adi,Peter O'Hearn*

Main category: cs.CL

TL;DR: LLMs在程序终止性预测任务上表现优异，GPT-5和Claude Sonnet-4.5接近SV-Comp 2025顶级工具水平，但存在无法提供有效证明见证、性能随程序长度下降等局限。


<details>
  <summary>Details</summary>
Motivation: 图灵停机问题的不可判定性使得传统验证工具只能近似处理程序终止性，且通常局限于特定语言和架构。随着LLMs的成功，研究者希望探索LLMs是否能够可靠预测程序终止，以及LLMs在处理不可判定问题方面的潜力。

Method: 使用国际软件验证竞赛(SV-Comp) 2025终止性类别的多样化C程序数据集，评估多个LLMs（包括GPT-5、Claude Sonnet-4.5和Code World Model）在程序终止性预测任务上的表现。

Result: LLMs在程序终止性预测方面表现突出：GPT-5和Claude Sonnet-4.5的性能仅次于排名第一的工具（使用测试时缩放），Code World Model仅次于排名第二的工具。但LLMs通常无法提供有效的证明见证，且性能随程序长度增加而下降。

Conclusion: LLMs能够有效预测程序终止性，展现了在处理不可判定问题方面的潜力，但仍存在提供证明见证的局限性和对程序长度的敏感性。这些发现为进一步研究LLMs在程序终止性和不可判定问题推理方面的应用提供了动力。

Abstract: Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.

</details>


### [6] [Malicious Repurposing of Open Science Artefacts by Using Large Language Models](https://arxiv.org/abs/2601.18998)
*Zahra Hashemi,Zhiqiang Zhong,Jun Pang,Wei Zhao*

Main category: cs.CL

TL;DR: LLMs可被用于生成有害研究提案，通过绕过安全机制并重新利用开放科学资源，但LLM评估结果存在严重不一致，无法作为可靠的风险评估工具


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注LLMs在促进科学发现方面的潜力，但忽视了它们可能被滥用于生成有害研究的风险。本文旨在填补这一空白，研究LLMs如何被利用来重新利用开放科学资源进行恶意目的

Method: 开发端到端管道：1) 通过说服式越狱绕过LLM安全机制；2) 重新解读NLP论文，识别并重新利用其资源（数据集、方法和工具）；3) 使用三维评估框架（有害性、滥用可行性、技术合理性）评估这些提案的安全性

Result: LLMs确实能够通过重新利用伦理设计的开放资源生成有害提案。但不同LLM评估结果存在严重分歧：GPT-4.1评分较高（显示更大潜在危害、更高技术合理性和滥用可行性），Gemini-2.5-pro明显更严格，Grok-3介于两者之间

Conclusion: LLMs目前无法在恶意评估设置中作为可靠的评判者，评估结果存在严重不一致性，使得人类评估对于可信的双重用途风险评估至关重要

Abstract: The rapid evolution of large language models (LLMs) has fuelled enthusiasm about their role in advancing scientific discovery, with studies exploring LLMs that autonomously generate and evaluate novel research ideas. However, little attention has been given to the possibility that such models could be exploited to produce harmful research by repurposing open science artefacts for malicious ends. We fill the gap by introducing an end-to-end pipeline that first bypasses LLM safeguards through persuasion-based jailbreaking, then reinterprets NLP papers to identify and repurpose their artefacts (datasets, methods, and tools) by exploiting their vulnerabilities, and finally assesses the safety of these proposals using our evaluation framework across three dimensions: harmfulness, feasibility of misuse, and soundness of technicality. Overall, our findings demonstrate that LLMs can generate harmful proposals by repurposing ethically designed open artefacts; however, we find that LLMs acting as evaluators strongly disagree with one another on evaluation outcomes: GPT-4.1 assigns higher scores (indicating greater potential harms, higher soundness and feasibility of misuse), Gemini-2.5-pro is markedly stricter, and Grok-3 falls between these extremes. This indicates that LLMs cannot yet serve as reliable judges in a malicious evaluation setup, making human evaluation essential for credible dual-use risk assessment.

</details>


### [7] [FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning](https://arxiv.org/abs/2601.19001)
*Haozheng Luo,Zhuolin Jiang,Md Zahid Hasan,Yan Chen,Soumalya Sarkar*

Main category: cs.CL

TL;DR: FROST是一种基于注意力权重的推理优化方法，通过剪枝不重要的推理路径来缩短推理轨迹并提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统推理方法存在效率低下和可靠性问题，需要一种能够识别并消除推理过程中不重要路径的方法来提高推理效率和准确性。

Method: 提出推理异常值概念，设计基于注意力的机制来检测和移除这些异常值，在句子级别消除推理路径中的不重要部分。

Result: 在四个基准测试中使用Phi-4-Reasoning和GPT-OSS-20B模型验证，优于TALE和ThinkLess等SOTA方法，平均减少69.68%的token使用，准确率提升26.70%，注意力异常值指标最大无穷范数降低15.97%，平均峰度降低91.09%。

Conclusion: FROST通过注意力感知的推理路径剪枝，在保持和增强模型推理能力的同时，显著提高了推理效率和可靠性，为高效推理提供了有效解决方案。

Abstract: We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverages attention weights to prune uncritical reasoning paths, yielding shorter and more reliable reasoning trajectories. Methodologically, we introduce the concept of reasoning outliers and design an attention-based mechanism to remove them. Theoretically, FROST preserves and enhances the model's reasoning capacity while eliminating outliers at the sentence level. Empirically, we validate FROST on four benchmarks using two strong reasoning models (Phi-4-Reasoning and GPT-OSS-20B), outperforming state-of-the-art methods such as TALE and ThinkLess. Notably, FROST achieves an average 69.68% reduction in token usage and a 26.70% improvement in accuracy over the base model. Furthermore, in evaluations of attention outlier metrics, FROST reduces the maximum infinity norm by 15.97% and the average kurtosis by 91.09% compared to the base model. Code is available at https://github.com/robinzixuan/FROST

</details>


### [8] [Optimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback](https://arxiv.org/abs/2601.19063)
*Siddhant Arora,Jinchuan Tian,Jiatong Shi,Hayato Futami,Yosuke Kashiwagi,Emiru Tsunoo,Shinji Watanabe*

Main category: cs.CL

TL;DR: 本文提出首个用于语音对话系统的多奖励RLAIF框架，结合语义、音频质量和情感一致性奖励，通过turn-level偏好采样和块级概率聚合解决增量解码与话语级偏好的对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF/RLAIF在语音对话系统中主要局限于单语义奖励和话语级应用，忽视了对话质量的多维多模态特性（语义连贯性、音频自然度、说话人一致性、情感对齐、轮转行为），且与双工语音系统的增量生成不匹配。

Method: 提出多奖励RLAIF框架，结合语义、音频质量和情感一致性奖励；采用turn-level偏好采样，在单个DPO目标中聚合每个块的log-probabilities，以对齐话语级偏好与增量块级解码。

Result: 单奖励RLAIF能选择性改进其目标指标，而联合多奖励训练在语义质量和音频自然度上均获得一致提升；发布了多奖励DPO数据集支持可复现研究。

Conclusion: 多奖励对齐对于实用对话语音系统至关重要，本文框架为语音对话系统的偏好学习提供了首个系统性研究，展示了多维度奖励联合训练的优势。

Abstract: Reinforcement learning from human or AI feedback (RLHF/RLAIF) for speech-in/speech-out dialogue systems (SDS) remains underexplored, with prior work largely limited to single semantic rewards applied at the utterance level. Such setups overlook the multi-dimensional and multi-modal nature of conversational quality, which encompasses semantic coherence, audio naturalness, speaker consistency, emotion alignment, and turn-taking behavior. Moreover, they are fundamentally mismatched with duplex spoken dialogue systems that generate responses incrementally, where agents must make decisions based on partial utterances. We address these limitations with the first multi-reward RLAIF framework for SDS, combining semantic, audio-quality, and emotion-consistency rewards. To align utterance-level preferences with incremental, blockwise decoding in duplex models, we apply turn-level preference sampling and aggregate per-block log-probabilities within a single DPO objective. We present the first systematic study of preference learning for improving SDS quality in both multi-turn Chain-of-Thought and blockwise duplex models, and release a multi-reward DPO dataset to support reproducible research. Experiments show that single-reward RLAIF selectively improves its targeted metric, while joint multi-reward training yields consistent gains across semantic quality and audio naturalness. These results highlight the importance of holistic, multi-reward alignment for practical conversational SDS.

</details>


### [9] [PsyProbe: Proactive and Interpretable Dialogue through User State Modeling for Exploratory Counseling](https://arxiv.org/abs/2601.19096)
*Sohhyung Park,Hyunji Kang,Sungzoon Cho,Dongil Kim*

Main category: cs.CL

TL;DR: PsyProbe：一个基于系统化心理状态建模的主动式心理咨询对话系统，通过PPPPPI框架追踪用户状态，在探索阶段生成主动治疗性问题。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康对话系统多为被动响应式，缺乏系统化的用户状态建模，无法进行主动治疗性探索。需要开发能够系统追踪用户心理状态并主动引导咨询探索的系统。

Method: 提出PsyProbe系统，包含：1) State Builder基于PPPPPI框架（呈现、易感、诱发、维持、保护、影响）提取结构化心理档案；2) Memory Construction追踪信息缺口；3) Strategy Planner基于动机访谈行为编码；4) Response Generator包含问题构思和批评/修订模块生成主动问题。

Result: 在27名参与者的真实韩国心理咨询场景中评估：1) 自动评估显示完整PsyProbe模型优于基线和消融模式；2) 用户评估显示参与意愿显著提高，自然度改善；3) 专家评估显示核心问题理解大幅提升，问题质量接近专业咨询师水平。

Conclusion: 系统化状态建模和主动提问策略能有效提升心理咨询探索阶段的效果，PsyProbe在理解用户核心问题和生成专业级问题上表现出色，验证了主动治疗性对话系统的可行性。

Abstract: Recent advances in large language models have enabled mental health dialogue systems, yet existing approaches remain predominantly reactive, lacking systematic user state modeling for proactive therapeutic exploration. We introduce PsyProbe, a dialogue system designed for the exploration phase of counseling that systematically tracks user psychological states through the PPPPPI framework (Presenting, Predisposing, Precipitating, Perpetuating, Protective, Impact) augmented with cognitive error detection. PsyProbe combines State Builder for extracting structured psychological profiles, Memory Construction for tracking information gaps, Strategy Planner for Motivational Interviewing behavioral codes, and Response Generator with Question Ideation and Critic/Revision modules to generate contextually appropriate, proactive questions. We evaluate PsyProbe with 27 participants in real-world Korean counseling scenarios, including automatic evaluation across ablation modes, user evaluation, and expert evaluation by a certified counselor. The full PsyProbe model consistently outperforms baseline and ablation modes in automatic evaluation. User evaluation demonstrates significantly increased engagement intention and improved naturalness compared to baseline. Expert evaluation shows that PsyProbe substantially improves core issue understanding and achieves question rates comparable to professional counselors, validating the effectiveness of systematic state modeling and proactive questioning for therapeutic exploration.

</details>


### [10] [Leveraging Sentence-oriented Augmentation and Transformer-Based Architecture for Vietnamese-Bahnaric Translation](https://arxiv.org/abs/2601.19124)
*Tan Sang Nguyen,Quoc Nguyen Pham,Tho Quan*

Main category: cs.CL

TL;DR: 该论文针对越南语-巴拿语翻译任务，采用先进的神经机器翻译技术和两种数据增强策略，以解决巴拿语资源有限的问题。


<details>
  <summary>Details</summary>
Motivation: 巴拿族是越南少数民族，其语言具有重要文化历史价值。政府重视巴拿语的保护与推广，但越南语-巴拿语翻译面临资源有限的挑战。神经机器翻译技术能够提高翻译质量，促进语言复兴。

Method: 采用先进的神经机器翻译技术，结合两种数据增强策略。这些方法灵活，可与多种NMT模型配合使用，无需复杂数据预处理、额外系统训练或额外数据收集。

Result: 论文未在摘要中提供具体实验结果，但提出的方法旨在提高越南语-巴拿语翻译的质量和可访问性。

Conclusion: 提出的神经机器翻译和数据增强方法能够有效应对巴拿语资源有限的挑战，促进巴拿语的保护、推广和数字可访问性。

Abstract: The Bahnar people, an ethnic minority in Vietnam with a rich ancestral heritage, possess a language of immense cultural and historical significance. The government places a strong emphasis on preserving and promoting the Bahnaric language by making it accessible online and encouraging communication across generations. Recent advancements in artificial intelligence, such as Neural Machine Translation (NMT), have brought about a transformation in translation by improving accuracy and fluency. This, in turn, contributes to the revival of the language through educational efforts, communication, and documentation. Specifically, NMT is pivotal in enhancing accessibility for Bahnaric speakers, making information and content more readily available. Nevertheless, the translation of Vietnamese into Bahnaric faces practical challenges due to resource constraints, especially given the limited resources available for the Bahnaric language. To address this, we employ state-of-the-art techniques in NMT along with two augmentation strategies for domain-specific Vietnamese-Bahnaric translation task. Importantly, both approaches are flexible and can be used with various neural machine translation models. Additionally, they do not require complex data preprocessing steps, the training of additional systems, or the acquisition of extra data beyond the existing training parallel corpora.

</details>


### [11] [Transparency-First Medical Language Models: Datasheets, Model Cards, and End-to-End Data Provenance for Clinical NLP](https://arxiv.org/abs/2601.19191)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Ayse Tuba Tugrul,Melike Nesrin Zaman,Ozkan Gunalp,Duygu Erisken,Sila Burde Dulger,Rana Irem Turhan,Izzet Ozdemir,Derya Umut Kulali,Ozan Akbulut,Harun Demircioglu,Hasan Basri Kara,Berfin Tavan*

Main category: cs.CL

TL;DR: TeMLM是一套面向临床语言模型的透明优先发布框架，包含可机器检查的发布包、文档规范及审计清单，并在Technetium-I合成临床数据集上验证了ProtactiniumBERT模型的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决临床语言模型发布中缺乏透明度的问题，作者旨在建立一个统一的框架，将数据来源、透明度、模型透明度和治理整合到可审计的发布包中，促进临床NLP领域的可重复性和可信度。

Method: 提出了TeMLM框架，包含三个核心文档：TeMLM-Card（模型卡片）、TeMLM-Datasheet（数据表）、TeMLM-Provenance（来源追踪），以及轻量级符合性检查清单。在Technetium-I合成临床数据集（49.8万份病历，774万PHI实体标注，10种类型，含ICD-9-CM诊断标签）上实例化该框架，并使用ProtactiniumBERT模型（约1亿参数）在PHI去识别化和ICD-9代码提取任务上进行基准测试。

Result: 成功实现了TeMLM框架的实例化，在Technetium-I数据集上获得了PHI去识别化（token分类）和top-50 ICD-9代码提取（多标签分类）的参考结果。验证了合成基准在工具和流程验证方面的价值，同时强调实际部署前需要在真实临床数据上进行验证。

Conclusion: TeMLM为临床语言模型提供了标准化的透明发布框架，通过机器可检查的文档和审计清单提高了可重复性和可信度。合成数据适用于工具验证，但最终模型部署需要真实临床数据的验证。

Abstract: We introduce TeMLM, a set of transparency-first release artifacts for clinical language models. TeMLM unifies provenance, data transparency, modeling transparency, and governance into a single, machine-checkable release bundle. We define an artifact suite (TeMLM-Card, TeMLM-Datasheet, TeMLM-Provenance) and a lightweight conformance checklist for repeatable auditing. We instantiate the artifacts on Technetium-I, a large-scale synthetic clinical NLP dataset with 498,000 notes, 7.74M PHI entity annotations across 10 types, and ICD-9-CM diagnosis labels, and report reference results for ProtactiniumBERT (about 100 million parameters) on PHI de-identification (token classification) and top-50 ICD-9 code extraction (multi-label classification). We emphasize that synthetic benchmarks are valuable for tooling and process validation, but models should be validated on real clinical data prior to deployment.

</details>


### [12] [Do Images Speak Louder than Words? Investigating the Effect of Textual Misinformation in VLMs](https://arxiv.org/abs/2601.19202)
*Chi Zhang,Wenxuan Ding,Jiale Liu,Mingrui Wu,Qingyun Wu,Ray Mooney*

Main category: cs.CL

TL;DR: 研究发现当前视觉语言模型容易受到误导性文本提示的影响，即使有清晰的视觉证据，模型也倾向于相信冲突的文本信息，平均性能下降超过48.2%。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在多模态推理方面表现出色，但其对文本错误信息的鲁棒性尚未充分研究。现有研究主要关注纯文本领域的错误信息，不清楚VLM如何处理不同模态间的矛盾信息。

Method: 首先提出CONTEXT-VQA数据集，包含图像-问题对以及系统生成的与视觉证据冲突的说服性提示。然后设计全面的评估框架，对11个最先进的VLM进行基准测试。

Result: 实验显示这些模型确实容易受到误导性文本提示的影响，经常优先考虑冲突文本而非清晰的视觉证据，仅一轮说服性对话后平均性能下降超过48.2%。

Conclusion: 研究揭示了当前VLM的关键局限性，强调需要提高对文本操纵的鲁棒性，以应对多模态环境中的错误信息挑战。

Abstract: Vision-Language Models (VLMs) have shown strong multimodal reasoning capabilities on Visual-Question-Answering (VQA) benchmarks. However, their robustness against textual misinformation remains under-explored. While existing research has studied the effect of misinformation in text-only domains, it is not clear how VLMs arbitrate between contradictory information from different modalities. To bridge the gap, we first propose the CONTEXT-VQA (i.e., Conflicting Text) dataset, consisting of image-question pairs together with systematically generated persuasive prompts that deliberately conflict with visual evidence. Then, a thorough evaluation framework is designed and executed to benchmark the susceptibility of various models to these conflicting multimodal inputs. Comprehensive experiments over 11 state-of-the-art VLMs reveal that these models are indeed vulnerable to misleading textual prompts, often overriding clear visual evidence in favor of the conflicting text, and show an average performance drop of over 48.2% after only one round of persuasive conversation. Our findings highlight a critical limitation in current VLMs and underscore the need for improved robustness against textual manipulation.

</details>


### [13] [How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability](https://arxiv.org/abs/2601.19208)
*Shawn Im,Changdae Oh,Zhen Fang,Sharon Li*

Main category: cs.CL

TL;DR: 该论文通过训练动态分析注意力语言模型如何从自然语言数据中学习语义关联，推导出早期训练阶段的权重闭式表达式，揭示了Transformer权重由三种基础函数组合而成。


<details>
  <summary>Details</summary>
Motivation: 理解语言模型如何学习和表示语义关联对于连接深度学习与语言理论、建立大语言模型的机制基础至关重要。语义关联（如"鸟"和"飞"之间的联系）是语言建模的基础，使模型能够超越记忆而实现泛化和生成连贯文本。

Method: 通过训练动态分析注意力语言模型，利用梯度的主导项近似推导出早期训练阶段的权重闭式表达式。分析表明Transformer的每组权重都可以表示为三种基础函数（二元组、令牌可互换性和上下文映射）的简单组合。

Result: 理论权重表征与真实世界大语言模型中学习到的权重高度匹配。实验证明推导出的闭式表达式能够准确描述模型权重，定性分析进一步展示了该理论如何解释Transformer中学习到的语义关联。

Conclusion: 该研究揭示了Transformer权重如何通过三种统计基础函数的组合来捕获语义关联，为理解语言模型的内部机制提供了理论框架，有助于解释大语言模型的学习过程和表示能力。

Abstract: Semantic associations such as the link between "bird" and "flew" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.

</details>


### [14] [A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured Customer Reviews](https://arxiv.org/abs/2601.19214)
*Aakash Trivedi,Aniket Upadhyay,Pratik Narang,Dhruv Kumar,Praveen Kumar*

Main category: cs.CL

TL;DR: 提出混合管道方法，结合RoBERTa分类器和指令调优LLM，从客户评论中提取可操作建议，优于现有基线方法


<details>
  <summary>Details</summary>
Motivation: 客户评论中常包含混合意图的非结构化文本，现有方法要么分类建议性句子，要么生成高级摘要，但很少能精确提取企业需要的改进指令

Method: 混合管道：1) 使用高召回率RoBERTa分类器（采用精确率-召回率替代损失减少不可恢复的假阴性）；2) 结合受控指令调优LLM进行建议提取、分类、聚类和摘要

Result: 在酒店和餐饮真实数据集上，混合系统在提取准确性和聚类一致性方面优于仅提示、基于规则和仅分类器的基线方法。人工评估确认结果建议和摘要清晰、忠实且可解释

Conclusion: 混合推理架构在细粒度可操作建议挖掘方面取得显著改进，同时突显了领域适应和高效本地部署方面的挑战

Abstract: Extracting actionable suggestions from customer reviews is essential for operational decision-making, yet these directives are often embedded within mixed-intent, unstructured text. Existing approaches either classify suggestion-bearing sentences or generate high-level summaries, but rarely isolate the precise improvement instructions businesses need. We evaluate a hybrid pipeline combining a high-recall RoBERTa classifier trained with a precision-recall surrogate to reduce unrecoverable false negatives with a controlled, instruction-tuned LLM for suggestion extraction, categorization, clustering, and summarization. Across real-world hospitality and food datasets, the hybrid system outperforms prompt-only, rule-based, and classifier-only baselines in extraction accuracy and cluster coherence. Human evaluations further confirm that the resulting suggestions and summaries are clear, faithful, and interpretable. Overall, our results show that hybrid reasoning architectures achieve meaningful improvements fine-grained actionable suggestion mining while highlighting challenges in domain adaptation and efficient local deployment.

</details>


### [15] [DREAMSTATE: Diffusing States and Parameters for Recurrent Large Language Models](https://arxiv.org/abs/2601.19221)
*Liu Xiao*

Main category: cs.CL

TL;DR: 提出DREAMSTATE框架，利用条件扩散Transformer直接建模RWKV状态的概率流形，实现状态生成与编辑，并设计结合RNN局部优势与全局上下文适应性的混合架构。


<details>
  <summary>Details</summary>
Motivation: 现代RNN（如RWKV）具有强大的短程建模能力和高效固定大小状态，但缺乏对其内部状态作为可编辑知识表示的研究。

Method: 1. 提出DREAMSTATE框架，使用条件扩散Transformer直接建模RWKV状态的概率流形；2. 设计混合架构，结合RNN局部优势与全局上下文适应性，通过并行DiT处理变长全局上下文动态生成和调整核心循环模块的WKV参数。

Result: 通过t-SNE可视化和受控生成实验验证状态表示的结构性质；混合模型可通过多目标损失稳定训练，验证设计可行性。

Conclusion: 为RNN状态表示开辟新研究方向，为未来模型设计提供具体架构参考。

Abstract: Modern Recurrent Neural Networks (RNNs), such as RWKV, are distinguished by their powerful short-range modeling capabilities and efficient fixed-size states, which constitute a core advantage over standard Transformers. However, there is a significant lack of research into their internal state as an editable knowledge representation. To fill this gap, we first explore the representational properties of the RWKV state by proposing the DREAMSTATE framework. This framework utilizes a conditional Diffusion Transformer (DiT) to directly model the probability manifold of the state, enabling its generation and editing. The structural nature of this representation is validated through t-SNE visualizations and controlled generation experiments. After successfully uncovering and modeling the state's representational potential, we further propose a novel hybrid architecture that combines the local advantages of RNNs with global context adaptability. This architecture features a parallel DiT that processes a variable-length global context to dynamically generate and adjust the core recurrent module's WKV parameters, transforming the fixed recurrence mechanism into a context-aware dynamic function. Experiments demonstrate that this hybrid model can be trained stably via a multi-objective loss, validating its design feasibility. Our work not only opens a new research direction for RNN state representation but also provides a concrete architectural reference for future model design. The code is publicly available at: https://huggingface.co/2dgx41s/DreamState.

</details>


### [16] [RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering](https://arxiv.org/abs/2601.19225)
*Kaehyun Um,KyuHwan Yeom,Haerim Yang,Minyoung Choi,Hyeongjun Yang,Kyong-Ho Lee*

Main category: cs.CL

TL;DR: RPO-RAG：首个专为小型LLM设计的基于知识图谱的检索增强生成框架，通过语义采样、关系感知优化和答案中心提示设计，显著提升小模型在KGQA任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的RAG方法存在三个主要问题：1）依赖语义无关的路径采样，与KG推理目标对齐弱；2）检索的路径直接输入推理器，缺乏组织，阻碍小模型利用知识；3）先前工作主要依赖大模型（如GPT-4）或7B以上参数模型，对7B以下小模型探索不足。

Method: RPO-RAG框架包含三个关键创新：1）查询-路径语义采样策略，提供信息丰富的监督信号；2）关系感知偏好优化，将训练与KG推理中间信号（如关系）对齐；3）答案中心提示设计，以可解释格式组织实体和推理路径。

Result: 在两个KGQA基准数据集（WebQSP和CWQ）上的实验表明：在WebQSP上F1提升高达8.8%，在CWQ上实现了8B参数以下模型的新SOTA结果（Hit和F1）。即使在3B参数以下，也能显著提升小模型的推理能力。

Conclusion: RPO-RAG有效缩小了小模型与大模型之间的性能差距，突出了小模型在资源高效和实用设备端KGQA应用中的潜力，为小型LLM在知识密集型任务上的应用提供了新思路。

Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning abilities, yet hallucinate on knowledge-intensive tasks. Retrieval-augmented generation (RAG) mitigates this issue by grounding answers in external sources, e.g., knowledge graphs (KGs). However, existing KG-based RAG approaches rely on semantics-unaware path sampling and are weakly aligned with KG reasoning objectives, which limits further accuracy gains. They also feed retrieved paths directly into the reasoner without organizing them into answer-centered reasoning paths, hindering small LLMs' ability to leverage the retrieved knowledge. Furthermore, prior works predominantly rely on large LLMs (e.g., ChatGPT/GPT-4) or assume backbones above 7B parameters, leaving sub-7B models underexplored. We address this gap with RPO-RAG, the first KG-based RAG framework specifically designed for small LLMs, to the best of our knowledge. RPO-RAG introduces three key innovations: (1) a query-path semantic sampling strategy that provides informative supervisory signals; (2) a relation-aware preference optimization that aligns training with intermediate KG reasoning signals (e.g., relation); and (3) an answer-centered prompt design that organizes entities and reasoning paths in an interpretable format. Extensive experiments on two benchmark Knowledge Graph Question Answering (KGQA) datasets, WebQSP and CWQ, demonstrate that RPO-RAG effectively bridges the performance gap between small and large language models. On WebQSP, it improves F1 by up to 8.8%, reflecting enhanced answer precision, while on CWQ it achieves new state-of-the-art results among models under 8B parameters in both Hit and F1. Overall, RPO-RAG substantially improves the reasoning capability of small LLMs, even under 3B parameters-highlighting their potential for resource-efficient and practical on-device KGQA applications.

</details>


### [17] [DiaDem: Advancing Dialogue Descriptions in Audiovisual Video Captioning for Multimodal Large Language Models](https://arxiv.org/abs/2601.19267)
*Xinlong Chen,Weihong Lin,Jingyun Hua,Linli Yao,Yue Ding,Bozhou Li,Bohan Zeng,Yang Shi,Qiang Liu,Yuanxing Zhang,Pengfei Wan,Liang Wang,Tieniu Tan*

Main category: cs.CL

TL;DR: DiaDem是一个视听视频描述模型，专注于生成包含更准确对话描述的标题，同时保持整体性能。通过合成高质量SFT数据集和两阶段GRPO策略提升对话描述能力，并创建DiaDemBench基准进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有视听视频描述模型在生成忠实对话描述方面存在困难，而准确的对话描述对于下游理解和生成任务至关重要。

Method: 1. 合成高质量SFT数据集；2. 采用难度分区的两阶段GRPO策略增强对话描述；3. 创建DiaDemBench基准评估对话描述能力。

Result: DiaDem在对话描述准确性上超越Gemini系列模型，在一般视听视频描述基准上也表现出竞争力，商业模型在对话感知描述方面仍有很大改进空间。

Conclusion: DiaDem能够生成更精确的对话描述，同时保持整体视听描述性能，为解决现有模型对话描述不准确的问题提供了有效方案。

Abstract: Accurate dialogue description in audiovisual video captioning is crucial for downstream understanding and generation tasks. However, existing models generally struggle to produce faithful dialogue descriptions within audiovisual captions. To mitigate this limitation, we propose DiaDem, a powerful audiovisual video captioning model capable of generating captions with more precise dialogue descriptions while maintaining strong overall performance. We first synthesize a high-quality dataset for SFT, then employ a difficulty-partitioned two-stage GRPO strategy to further enhance dialogue descriptions. To enable systematic evaluation of dialogue description capabilities, we introduce DiaDemBench, a comprehensive benchmark designed to evaluate models across diverse dialogue scenarios, emphasizing both speaker attribution accuracy and utterance transcription fidelity in audiovisual captions. Extensive experiments on DiaDemBench reveal even commercial models still exhibit substantial room for improvement in dialogue-aware captioning. Notably, DiaDem not only outperforms the Gemini series in dialogue description accuracy but also achieves competitive performance on general audiovisual captioning benchmarks, demonstrating its overall effectiveness.

</details>


### [18] [Riddle Quest : The Enigma of Words](https://arxiv.org/abs/2601.19273)
*Niharika Sri Parasa,Chaitali Diwan,Srinath Srinivasa*

Main category: cs.CL

TL;DR: 提出一个用于创建和评估类比谜语的简单流程，包括三元组创建、语义映射、风格化生成和验证器，并用其研究大语言模型能否恢复完整的答案集。


<details>
  <summary>Details</summary>
Motivation: 谜语是一种需要解谜者解释线索、识别模式并推断答案的创造性表达形式，可以作为研究语言模型推理覆盖范围和歧义处理的轻量级工具。

Method: 构建包含四个组件的系统：1) 三元组创建器，构建概念的结构化事实；2) 语义映射器，选择用于类比的属性；3) 风格化生成器，将属性转化为谜语线索；4) 验证器，收集谜语可能指向的所有可能答案。

Result: 案例研究表明，虽然大语言模型经常能猜出主要预期答案，但常常会错过其他有效的解释，这突显了谜语在检验语言模型推理覆盖和歧义处理方面的价值。

Conclusion: 谜语可以作为评估语言模型推理能力和歧义处理的有效工具，模型在恢复完整答案集方面存在局限性，这为进一步改进模型提供了方向。

Abstract: Riddles are concise linguistic puzzles that describe an object or idea through indirect, figurative, or playful clues. They are a longstanding form of creative expression, requiring the solver to interpret hints, recognize patterns, and draw inferences to identify the answers. In this work, we introduce a simple pipeline for creating and evaluating analogy-based riddles. The system includes a triples creator that builds structured facts about a concept, a semantic mapper that selects attributes useful for analogy, a stylized generator that turns them into riddle clues, and a validator that collects all possible answers the riddle could point to. We use this validator to study whether large language models can recover the full answer set for different riddle types. Our case study shows that while models often guess the main intended answer, they frequently miss other valid interpretations. This highlights the value of riddles as a lightweight tool for examining reasoning coverage and ambiguity handling in language models.

</details>


### [19] [DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference](https://arxiv.org/abs/2601.19278)
*Fuliang Liu,Xue Li,Ketai Zhao,Yinxi Gao,Ziyan Zhou,Zhonghui Zhang,Zhibin Wang,Wanchun Dou,Sheng Zhong,Chen Tian*

Main category: cs.CL

TL;DR: DART 是一种基于并行生成的推测解码方法，通过单次前向传播预测多个未来位置的logits，减少草稿阶段延迟，实现2.03x-3.44x的端到端加速。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的草稿设计（如EAGLE3）虽然提高了准确性，但需要多步自回归推理，导致草稿延迟高，使草稿阶段成为性能瓶颈。

Method: DART 基于目标模型的隐藏状态，在单次前向传播中并行预测多个未来掩码位置的logits，避免自回归展开。同时引入高效的树剪枝算法，构建具有N-gram语义连续性的高质量草稿标记树。

Result: 实验结果显示，DART 在多个数据集上实现了2.03x-3.44x的端到端解码加速，平均比EAGLE3快30%，显著降低了草稿阶段开销同时保持高草稿准确性。

Conclusion: DART 通过并行生成减少草稿延迟，结合高效的树剪枝算法，提供了一个实用的推测解码框架，显著提升了LLM推理速度。

Abstract: Speculative decoding is an effective and lossless approach for accelerating LLM inference. However, existing widely adopted model-based draft designs, such as EAGLE3, improve accuracy at the cost of multi-step autoregressive inference, resulting in high drafting latency and ultimately rendering the drafting stage itself a performance bottleneck. Inspired by diffusion-based large language models (dLLMs), we propose DART, which leverages parallel generation to reduce drafting latency. DART predicts logits for multiple future masked positions in parallel within a single forward pass based on hidden states of the target model, thereby eliminating autoregressive rollouts in the draft model while preserving a lightweight design. Based on these parallel logit predictions, we further introduce an efficient tree pruning algorithm that constructs high-quality draft token trees with N-gram-enforced semantic continuity. DART substantially reduces draft-stage overhead while preserving high draft accuracy, leading to significantly improved end-to-end decoding speed. Experimental results demonstrate that DART achieves a 2.03x--3.44x wall-clock time speedup across multiple datasets, surpassing EAGLE3 by 30% on average and offering a practical speculative decoding framework. Code is released at https://github.com/fvliang/DART.

</details>


### [20] [ReToP: Learning to Rewrite Electronic Health Records for Clinical Prediction](https://arxiv.org/abs/2601.19286)
*Jesus Lovon-Melgarejo,Jose G. Moreno,Christine Damase-Michel,Lynda Tamine*

Main category: cs.CL

TL;DR: ReToP框架通过端到端训练EHR重写器和临床预测器，利用LLM生成临床相关重写来提升预测性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在临床预测中多为任务无关的，仅将LLM用作EHR编码器或补全模块，未能充分整合预测任务信号，限制了性能提升

Method: 提出ReToP框架，包含EHR重写器和临床预测器的端到端训练；使用临床驱动的特征选择策略生成伪标签数据；引入分类器监督贡献（CSC）分数使重写器生成临床相关重写

Result: 在MIMIC-IV的三个临床任务上超越强基线模型；分析显示ReToP具有良好的泛化能力，能迁移到未见数据集和任务，同时保持忠实重写并强调任务相关特征

Conclusion: ReToP通过任务感知的EHR重写有效提升了临床预测性能，展示了LLM在医疗领域应用的潜力，为EHR数据的高效利用提供了新思路

Abstract: Electronic Health Records (EHRs) provide crucial information for clinical decision-making. However, their high-dimensionality, heterogeneity, and sparsity make clinical prediction challenging. Large Language Models (LLMs) allowed progress towards addressing this challenge by leveraging parametric medical knowledge to enhance EHR data for clinical prediction tasks. Despite the significant achievements made so far, most of the existing approaches are fundamentally task-agnostic in the sense that they deploy LLMs as EHR encoders or EHR completion modules without fully integrating signals from the prediction tasks. This naturally hinders task performance accuracy. In this work, we propose Rewrite-To-Predict (ReToP), an LLM-based framework that addresses this limitation through an end-to-end training of an EHR rewriter and a clinical predictor. To cope with the lack of EHR rewrite training data, we generate synthetic pseudo-labels using clinical-driven feature selection strategies to create diverse patient rewrites for fine-tuning the EHR rewriter. ReToP aligns the rewriter with prediction objectives using a novel Classifier Supervised Contribution (CSC) score that enables the EHR rewriter to generate clinically relevant rewrites that directly enhance prediction. Our ReToP framework surpasses strong baseline models across three clinical tasks on MIMIC-IV. Moreover, the analysis of ReToP shows its generalizability to unseen datasets and tasks with minimal fine-tuning while preserving faithful rewrites and emphasizing task-relevant predictive features.

</details>


### [21] [MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning](https://arxiv.org/abs/2601.19290)
*Yimeng Wang,Jiaxing Zhao,Hongbin Xie,Hexing Ma,Yuzhen Lei,Shuangxue Liu,Xuan Song,Zichen Zhang,Haoran Zhang*

Main category: cs.CL

TL;DR: MetaGen是一个无需训练的多智能体框架，能够在推理时动态调整角色空间和协作拓扑结构，提升复杂任务解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统通常依赖固定的角色库和冻结的交互拓扑结构，这种刚性设计导致任务不匹配、无法及时适应推理过程中的新证据，并增加了推理成本。

Method: MetaGen通过生成和重写查询条件化的角色规范来维护可控的动态角色池，然后围绕最小骨干实例化约束执行图。在执行过程中，使用轻量级反馈信号迭代更新角色提示并调整结构决策。

Result: 在代码生成和多步推理基准测试中，MetaGen相比强大的多智能体基线方法，在准确性和成本权衡方面表现更优。

Conclusion: MetaGen框架能够在推理时动态适应角色空间和协作拓扑，无需更新基础模型权重，有效解决了现有多智能体系统的刚性设计问题。

Abstract: Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often exceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and an execution-frozen interaction topology, a rigid design choice that frequently leads to task mismatch, prevents timely adaptation when new evidence emerges during reasoning, and further inflates inference cost. We introduce MetaGen, a training-free framework that adapts both the role space and the collaboration topology at inference time, without updating base model weights. MetaGen generates and rewrites query-conditioned role specifications to maintain a controllable dynamic role pool, then instantiates a constrained execution graph around a minimal backbone. During execution, it iteratively updates role prompts and adjusts structural decisions using lightweight feedback signals. Experiments on code generation and multi-step reasoning benchmarks show that MetaGen improves the accuracy and cost tradeoff over strong multi-agent baselines.

</details>


### [22] [Formula-One Prompting: Adaptive Reasoning Through Equations For Applied Mathematics](https://arxiv.org/abs/2601.19302)
*Natapong Nitarach,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: F-1 Prompting：一种两阶段提示方法，先提取控制方程作为中间表示，再自适应选择求解策略，显著提升LLM在应用数学问题上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有CoT和PoT等方法在应用数学领域（金融、物理、密码学）存在局限，它们未能充分利用问题中的控制方程信息，而这些方程是解决应用数学问题的关键。

Method: 提出Formula-One Prompting (F-1)：1）第一阶段从问题描述中提取控制方程作为中间表示；2）第二阶段根据生成的方程自适应选择求解策略（CoT、PoT或直接计算），所有步骤在单次LLM调用中完成。

Result: 在5个模型和4个基准测试中，F-1平均比CoT提升5.76%，比PoT提升8.42%。在应用领域表现尤为突出：FinanceMath上比CoT提升13.30%，OlympiadBench中物理问题提升2.55%（纯数学仅0.44%）。

Conclusion: F-1通过显式提取和利用控制方程，显著提升了LLM在应用数学问题上的推理能力，特别是在需要领域知识的实际问题中表现优异。

Abstract: Prompting techniques such as Chain-of-Thought (CoT) and Program-of-Thought (PoT) improve LLM mathematical reasoning by structuring intermediate steps in natural language or code. However, applied mathematics problems in domains like finance, physics, and cryptography often require recalling or deriving governing equations, a step that current approaches do not explicitly leverage. We propose Formula-One Prompting (F-1), a two-phase approach that uses mathematical equations as an intermediate representation before adaptive solving. F-1 first formulates governing equations from problem descriptions, then selects a solving strategy among CoT, PoT, or direct computation based on the generated equations, all within a single LLM call. Results across five models and four benchmarks show F-1 outperforms CoT by +5.76% and PoT by +8.42% on average. Crucially, gains are largest in applied domains: +13.30% on FinanceMath over CoT, and within OlympiadBench, larger gains on physics (+2.55%) than pure math (+0.44%). This demonstrates that F-1 is more effective than CoT in applied mathematics problems.

</details>


### [23] [When Benchmarks Leak: Inference-Time Decontamination for LLMs](https://arxiv.org/abs/2601.19334)
*Jianzhe Chai,Yu Zhe,Jun Sakuma*

Main category: cs.CL

TL;DR: DeconIEP：一种通过在输入嵌入空间施加小范围有界扰动来缓解测试集污染的评估框架，无需修改基准或干扰正常推理


<details>
  <summary>Details</summary>
Motivation: 基准测试是评估大语言模型的主要方法，但测试集污染问题日益严重，即测试样本或其变体泄露到训练数据中，人为夸大了报告性能。现有方法要么需要修改基准集，要么会干扰正常推理导致性能下降。

Method: DeconIEP框架在评估期间完全操作，通过在输入嵌入空间施加小范围有界扰动。通过相对较少污染的参考模型指导，学习实例自适应的扰动生成器，引导被评估模型远离记忆驱动的捷径路径。

Result: 在多个开源大语言模型和基准测试上的广泛实验结果表明，DeconIEP实现了强大的去污染效果，同时在良性效用方面仅产生最小程度的性能下降。

Conclusion: DeconIEP提供了一种有效的去污染方法，能够在保持基准完整性的同时，最小化对正常推理的干扰，为解决测试集污染问题提供了新思路。

Abstract: Benchmark-based evaluation is the de facto standard for comparing large language models (LLMs). However, its reliability is increasingly threatened by test set contamination, where test samples or their close variants leak into training data and artificially inflate reported performance. To address this issue, prior work has explored two main lines of mitigation. One line attempts to identify and remove contaminated benchmark items before evaluation, but this inevitably alters the evaluation set itself and becomes unreliable when contamination is moderate or severe. The other line preserves the benchmark and instead suppresses contaminated behavior at evaluation time; however, such interventions often interfere with normal inference and lead to noticeable performance degradation on clean inputs. We propose DeconIEP, a decontamination framework that operates entirely during evaluation by applying small, bounded perturbations in the input embedding space. Guided by a relatively less-contaminated reference model, DeconIEP learns an instance-adaptive perturbation generator that steers the evaluated model away from memorization-driven shortcut pathways. Across multiple open-weight LLMs and benchmarks, extensive empirical results show that DeconIEP achieves strong decontamination effectiveness while incurring only minimal degradation in benign utility.

</details>


### [24] [Cross-Examination Framework: A Task-Agnostic Diagnostic for Information Fidelity in Text-to-Text Generation](https://arxiv.org/abs/2601.19350)
*Tathagata Raha,Clement Christophe,Nada Saadi,Hamza A Javed,Marco AF Pimentel,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: CEF框架通过将源文本和候选文本视为独立知识库，生成可验证问题并进行交叉检查，提供覆盖率、一致性和连贯性三个可解释分数，用于无参考的多维度文本生成评估。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标如BLEU和BERTScore在生成式文本到文本任务中无法捕捉语义保真度，需要一种无参考、多维度、可解释的评估框架。

Method: 将源文本和候选文本视为独立知识库，从每个文本生成可验证问题，通过交叉检查获得三个可解释分数：覆盖率（Coverage）、一致性（Conformity）和连贯性（Consistency）。通过系统鲁棒性分析选择稳定的评判模型。

Result: 在翻译、摘要和临床笔记生成任务中验证，CEF能识别标准指标遗漏的关键错误（如内容遗漏和事实矛盾）。无参考模式与有参考模式强相关，验证了CEF在无黄金参考时的可靠性。人类专家验证显示CEF不匹配问题与语义错误高度相关，特别擅长识别实体和关系扭曲。

Conclusion: CEF提供了一个可靠的无参考评估框架，能有效捕捉生成文本中的语义错误，弥补了传统指标的不足，在多个文本生成任务中表现出色。

Abstract: Traditional metrics like BLEU and BERTScore fail to capture semantic fidelity in generative text-to-text tasks. We adapt the Cross-Examination Framework (CEF) for a reference-free, multi-dimensional evaluation by treating the source and candidate as independent knowledge bases. CEF generates verifiable questions from each text and performs a cross-examination to derive three interpretable scores: Coverage, Conformity, and Consistency. Validated across translation, summarization and clinical note-generation, our framework identifies critical errors, such as content omissions and factual contradictions, missed by standard metrics. A key contribution is a systematic robustness analysis to select a stable judge model. Crucially, the strong correlation between our reference-free and with-reference modes validates CEF's reliability without gold references. Furthermore, human expert validation demonstrates that CEF mismatching questions align with meaning-altering semantic errors higher than with non-semantic errors, particularly excelling at identifying entity-based and relational distortions.

</details>


### [25] [Binary Token-Level Classification with DeBERTa for All-Type MWE Identification: A Lightweight Approach with Linguistic Enhancement](https://arxiv.org/abs/2601.19360)
*Diego Rossini,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 提出一种结合二元标记分类、语言特征集成和数据增强的多词表达识别方法，在CoAM数据集上达到69.8% F1，比Qwen-72B提升12个百分点且参数少165倍。


<details>
  <summary>Details</summary>
Motivation: 解决多词表达识别任务中现有方法（特别是大型语言模型）在结构化NLP任务上的效率问题，证明精心设计的小型模型可以显著超越LLMs，对资源受限部署有重要意义。

Method: 1) 将检测重新定义为二元标记级START/END/INSIDE分类而非基于跨度的预测；2) 集成NP分块和依存特征以帮助识别不连续和名词型多词表达；3) 应用过采样处理训练数据中的严重类别不平衡。

Result: 在CoAM数据集上达到69.8% F1，比最佳结果（Qwen-72B的57.8% F1）提升12个百分点，同时参数减少165倍。在STREUSLE数据集上验证泛化能力，达到78.9% F1。

Conclusion: 精心设计的小型模型在结构化NLP任务上可以显著超越大型语言模型，这对资源受限部署具有重要启示，展示了特征工程和任务特定优化的重要性。

Abstract: We present a comprehensive approach for multiword expression (MWE) identification that combines binary token-level classification, linguistic feature integration, and data augmentation. Our DeBERTa-v3-large model achieves 69.8% F1 on the CoAM dataset, surpassing the best results (Qwen-72B, 57.8% F1) on this dataset by 12 points while using 165x fewer parameters. We achieve this performance by (1) reformulating detection as binary token-level START/END/INSIDE classification rather than span-based prediction, (2) incorporating NP chunking and dependency features that help discontinuous and NOUN-type MWEs identification, and (3) applying oversampling that addresses severe class imbalance in the training data. We confirm the generalization of our method on the STREUSLE dataset, achieving 78.9% F1. These results demonstrate that carefully designed smaller models can substantially outperform LLMs on structured NLP tasks, with important implications for resource-constrained deployments.

</details>


### [26] [Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?](https://arxiv.org/abs/2601.19410)
*Ahrii Kim,Seong-heum Kim*

Main category: cs.CL

TL;DR: 本文系统比较了专有和开源大语言模型在文档级自动后编辑任务中的表现，发现专有模型能达到接近人类水平，但对文档上下文利用不足，且成本过高不实用。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出强大的翻译能力，但它们在文档级自动后编辑任务中的有效性尚未得到充分理解，特别是在利用文档上下文进行错误修正方面。

Method: 采用简单的文档级提示设置，系统比较专有和开源大语言模型，分析APE质量、上下文行为、鲁棒性和效率。

Result: 专有LLMs即使使用简单的一次提示也能达到接近人类水平的APE质量，但对文档级上下文利用有限；相比开源模型具有更高鲁棒性；标准自动指标无法可靠反映质量改进；专有模型成本过高不实用。

Conclusion: LLM在文档感知APE方面既有潜力也有局限，需要更高效的长上下文建模方法，专有模型成本过高不适合实际部署，标准指标仍需人工评估补充。

Abstract: Automatic post-editing (APE) aims to refine machine translations by correcting residual errors. Although recent large language models (LLMs) demonstrate strong translation capabilities, their effectiveness for APE--especially under document-level context--remains insufficiently understood. We present a systematic comparison of proprietary and open-weight LLMs under a naive document-level prompting setup, analyzing APE quality, contextual behavior, robustness, and efficiency.
  Our results show that proprietary LLMs achieve near human-level APE quality even with simple one-shot prompting, regardless of whether document context is provided. While these models exhibit higher robustness to data poisoning attacks than open-weight counterparts, this robustness also reveals a limitation: they largely fail to exploit document-level context for contextual error correction. Furthermore, standard automatic metrics do not reliably reflect these qualitative improvements, highlighting the continued necessity of human evaluation. Despite their strong performance, the substantial cost and latency overheads of proprietary LLMs render them impractical for real-world APE deployment. Overall, our findings elucidate both the promise and current limitations of LLM-based document-aware APE, and point toward the need for more efficient long-context modeling approaches for translation refinement.

</details>


### [27] [KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing Automated Fact-checking](https://arxiv.org/abs/2601.19447)
*Vítor N. Lourenço,Aline Paes,Tillman Weyde,Audrey Depeige,Mohnish Dubey*

Main category: cs.CL

TL;DR: KG-CRAFT：一种基于知识图谱对比推理增强LLM事实核查能力的方法，在LIAR-RAW和RAWFC数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 自动事实核查系统中的声明验证需要依赖可靠证据源，现有方法在利用结构化知识进行对比推理方面存在不足，需要改进LLM在事实核查中的能力

Method: 1. 从声明和相关报告中构建知识图谱；2. 基于知识图谱结构生成上下文相关的对比问题；3. 这些问题指导基于证据的报告提炼；4. 将提炼结果合成简明摘要用于LLM的真实性评估

Result: 在两个真实世界数据集（LIAR-RAW和RAWFC）上的广泛评估表明，该方法在预测性能上达到了新的最先进水平，详细分析验证了基于知识图谱的对比推理方法在提升LLM事实核查能力方面的有效性

Conclusion: KG-CRAFT通过知识图谱增强的对比推理显著提升了自动声明验证性能，为LLM在事实核查任务中的应用提供了有效框架

Abstract: Claim verification is a core component of automated fact-checking systems, aimed at determining the truthfulness of a statement by assessing it against reliable evidence sources such as documents or knowledge bases. This work presents KG-CRAFT, a method that improves automatic claim verification by leveraging large language models (LLMs) augmented with contrastive questions grounded in a knowledge graph. KG-CRAFT first constructs a knowledge graph from claims and associated reports, then formulates contextually relevant contrastive questions based on the knowledge graph structure. These questions guide the distillation of evidence-based reports, which are synthesised into a concise summary that is used for veracity assessment by LLMs. Extensive evaluations on two real-world datasets (LIAR-RAW and RAWFC) demonstrate that our method achieves a new state-of-the-art in predictive performance. Comprehensive analyses validate in detail the effectiveness of our knowledge graph-based contrastive reasoning approach in improving LLMs' fact-checking capabilities.

</details>


### [28] [Dynamic Multi-Expert Projectors with Stabilized Routing for Multilingual Speech Recognition](https://arxiv.org/abs/2601.19451)
*Isha Pandey,Ashish Mittal,Vartul Bahuguna,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 该论文提出SMEAR-MoE，一种稳定的专家混合投影器，用于解决多语言ASR中单投影器无法捕捉多样化声学-语义映射的问题，在四种印度语言上实现了显著的WER降低。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based ASR方法在单语言场景有效，但在多语言场景中，单个投影器难以捕捉不同语言间多样化的声学到语义映射关系，需要更灵活的架构来支持多语言ASR。

Method: 提出SMEAR-MoE（稳定的专家混合投影器），通过确保所有专家获得密集梯度流来防止专家崩溃，同时支持跨语言共享。系统比较了单体、静态多投影器和动态MoE设计，在四种印度语言（印地语、马拉地语、泰米尔语、泰卢固语）上进行评估。

Result: SMEAR-MoE相比单投影器基线实现了最高7.6%的相对WER降低，同时保持可比的运行时效率。专家路由分析显示语言相关的专家共享模式，相关语言倾向于共享专家。

Conclusion: 稳定的多专家投影器是实现可扩展和鲁棒的多语言ASR的关键，SMEAR-MoE通过专家混合架构有效解决了多语言ASR中的声学-语义映射多样性问题。

Abstract: Recent advances in LLM-based ASR connect frozen speech encoders with Large Language Models (LLMs) via lightweight projectors. While effective in monolingual settings, a single projector struggles to capture the diverse acoustic-to-semantic mappings required for multilingual ASR. To address this, we propose SMEAR-MoE, a stabilized Mixture-of-Experts projector that ensures dense gradient flow to all experts, preventing expert collapse while enabling cross-lingual sharing. We systematically compare monolithic, static multi-projector, and dynamic MoE designs across four Indic languages (Hindi, Marathi, Tamil, Telugu). Our SMEAR-MoE achieves strong performance, delivering upto a 7.6% relative WER reduction over the single-projector baseline, while maintaining comparable runtime efficiency. Analysis of expert routing further shows linguistically meaningful specialization, with related languages sharing experts. These results demonstrate that stable multi-expert projectors are key to scalable and robust multilingual ASR.

</details>


### [29] [ClaimPT: A Portuguese Dataset of Annotated Claims in News Articles](https://arxiv.org/abs/2601.19490)
*Ricardo Campos,Raquel Sequeira,Sara Nerea,Inês Cantante,Diogo Folques,Luís Filipe Cunha,João Canavilhas,António Branco,Alípio Jorge,Sérgio Nunes,Nuno Guimarães,Purificação Silvano*

Main category: cs.CL

TL;DR: 提出ClaimPT数据集，包含1,308篇葡萄牙新闻文章和6,875个标注，用于自动化事实核查中的主张检测，填补葡萄牙语资源空白。


<details>
  <summary>Details</summary>
Motivation: 手动事实核查耗时且难以应对在线虚假信息的快速传播，而自动化事实核查需要主张检测作为关键第一步。葡萄牙语等低资源语言缺乏可访问的标注数据集，限制了相关研究和应用发展。

Method: 通过与葡萄牙新闻社LUSA合作收集新闻文章，提出新的标注方案，由两名训练有素的标注员对每篇文章进行标注，并由监督员验证所有标注，创建了ClaimPT数据集。

Result: 创建了包含1,308篇欧洲葡萄牙语新闻文章和6,875个标注的ClaimPT数据集，专注于新闻内容而非社交媒体或议会记录，并提供了主张检测的基线模型作为初始基准。

Conclusion: ClaimPT数据集填补了葡萄牙语事实核查资源的空白，为低资源语言的事实核查研究提供了基础，有助于促进新闻媒体中虚假信息的理解和检测应用发展。

Abstract: Fact-checking remains a demanding and time-consuming task, still largely dependent on manual verification and unable to match the rapid spread of misinformation online. This is particularly important because debunking false information typically takes longer to reach consumers than the misinformation itself; accelerating corrections through automation can therefore help counter it more effectively. Although many organizations perform manual fact-checking, this approach is difficult to scale given the growing volume of digital content. These limitations have motivated interest in automating fact-checking, where identifying claims is a crucial first step. However, progress has been uneven across languages, with English dominating due to abundant annotated data. Portuguese, like other languages, still lacks accessible, licensed datasets, limiting research, NLP developments and applications. In this paper, we introduce ClaimPT, a dataset of European Portuguese news articles annotated for factual claims, comprising 1,308 articles and 6,875 individual annotations. Unlike most existing resources based on social media or parliamentary transcripts, ClaimPT focuses on journalistic content, collected through a partnership with LUSA, the Portuguese News Agency. To ensure annotation quality, two trained annotators labeled each article, with a curator validating all annotations according to a newly proposed scheme. We also provide baseline models for claim detection, establishing initial benchmarks and enabling future NLP and IR applications. By releasing ClaimPT, we aim to advance research on low-resource fact-checking and enhance understanding of misinformation in news media.

</details>


### [30] [GradPruner: Gradient-Guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs](https://arxiv.org/abs/2601.19503)
*Wei Huang,Anda Cheng,Yinggui Wang*

Main category: cs.CL

TL;DR: GradPruner：一种基于梯度的LLM层剪枝方法，在微调早期阶段通过累积梯度信息评估层重要性，实现训练和推理效率的同时提升


<details>
  <summary>Details</summary>
Motivation: 传统LLM微调耗时昂贵，现有结构化剪枝方法需要额外训练、知识蒸馏等策略，难以同时提升训练和推理效率

Method: 在微调初期计算参数累积梯度，构建IGIA-Matrix评估层重要性进行剪枝，基于符号一致性稀疏化剪枝层并与剩余层合并

Result: 在两个LLM和八个下游数据集（医疗、金融、通用基准）上实验，实现40%参数减少，仅损失0.99%准确率

Conclusion: GradPruner能有效同时提升LLM下游任务微调的训练和推理效率，实现显著参数压缩而保持性能

Abstract: Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight downstream datasets. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is publicly available.

</details>


### [31] [Automated Safety Benchmarking: A Multi-agent Pipeline for LVLMs](https://arxiv.org/abs/2601.19507)
*Xiangyang Zhu,Yuan Tian,Zicheng Zhang,Qi Jia,Chunyi Li,Renrui Zhang,Heng Li,Zongrui Wang,Wei Sun*

Main category: cs.CL

TL;DR: VLSafetyBencher：首个自动化的大视觉语言模型安全基准测试系统，通过四个协作代理自动构建高质量安全测试样本，解决现有基准测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在跨模态任务中表现出色，但面临严重的安全挑战，影响其在实际应用中的可靠性。现有安全评估基准存在构建过程劳动密集、静态复杂性、判别能力有限等问题，难以跟上模型快速发展和新兴风险的步伐。

Method: 提出VLSafetyBencher系统，包含四个协作代理：数据预处理代理、生成代理、增强代理和选择代理，共同构建和选择高质量的安全测试样本。

Result: 实验验证VLSafetyBencher能在一周内以最小成本构建高质量安全基准。生成的基准能有效区分模型安全性，最安全与最不安全模型之间的安全率差异达70%。

Conclusion: VLSafetyBencher解决了现有LVLM安全基准测试的局限性，提供了自动化、高效且具有强判别力的安全评估解决方案，有助于提升大视觉语言模型在实际应用中的可靠性。

Abstract: Large vision-language models (LVLMs) exhibit remarkable capabilities in cross-modal tasks but face significant safety challenges, which undermine their reliability in real-world applications. Efforts have been made to build LVLM safety evaluation benchmarks to uncover their vulnerability. However, existing benchmarks are hindered by their labor-intensive construction process, static complexity, and limited discriminative power. Thus, they may fail to keep pace with rapidly evolving models and emerging risks. To address these limitations, we propose VLSafetyBencher, the first automated system for LVLM safety benchmarking. VLSafetyBencher introduces four collaborative agents: Data Preprocessing, Generation, Augmentation, and Selection agents to construct and select high-quality samples. Experiments validates that VLSafetyBencher can construct high-quality safety benchmarks within one week at a minimal cost. The generated benchmark effectively distinguish safety, with a safety rate disparity of 70% between the most and least safe models.

</details>


### [32] [Yunque DeepResearch Technical Report](https://arxiv.org/abs/2601.19578)
*Yuxuan Cai,Xinyi Lai,Peng Yuan,Weiting Liu,Huajian Li,Mingda Li,Xinghua Wang,Shengxie Zheng,Yanchao Hao,Yuyang Yin,Zheng Wei*

Main category: cs.CL

TL;DR: Yunque DeepResearch是一个分层、模块化、鲁棒的深度研究框架，通过多智能体编排、动态上下文管理和监督模块解决现有深度研究中的上下文噪声、脆弱性和扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究在自主智能体应用中面临三个关键挑战：1）长时程任务中上下文噪声不断累积；2）脆弱性导致级联错误；3）缺乏模块化扩展性。这些问题限制了大型语言模型在复杂开放任务中的潜力。

Method: 提出Yunque DeepResearch框架，包含三个核心组件：1）集中式多智能体编排系统，将子任务路由到原子能力池中的工具和专门子智能体；2）动态上下文管理机制，将完成的子目标结构化为语义摘要以缓解信息过载；3）主动监督模块，通过异常检测和上下文修剪确保鲁棒性。

Result: 在多个智能体深度研究基准测试中达到最先进性能，包括GAIA、BrowseComp、BrowseComp-ZH和Humanity's Last Exam。框架已开源，包含可复现实现和应用案例。

Conclusion: Yunque DeepResearch通过分层、模块化和鲁棒的架构设计，有效解决了深度研究中的关键限制，为自主智能体在复杂开放任务中的深度研究能力提供了强大框架。

Abstract: Deep research has emerged as a transformative capability for autonomous agents, empowering Large Language Models to navigate complex, open-ended tasks. However, realizing its full potential is hindered by critical limitations, including escalating contextual noise in long-horizon tasks, fragility leading to cascading errors, and a lack of modular extensibility. To address these challenges, we introduce Yunque DeepResearch, a hierarchical, modular, and robust framework. The architecture is characterized by three key components: (1) a centralized Multi-Agent Orchestration System that routes subtasks to an Atomic Capability Pool of tools and specialized sub-agents; (2) a Dynamic Context Management mechanism that structures completed sub-goals into semantic summaries to mitigate information overload; and (3) a proactive Supervisor Module that ensures resilience through active anomaly detection and context pruning. Yunque DeepResearch achieves state-of-the-art performance across a range of agentic deep research benchmarks, including GAIA, BrowseComp, BrowseComp-ZH, and Humanity's Last Exam. We open-source the framework, reproducible implementations, and application cases to empower the community.

</details>


### [33] [Decompose-and-Formalise: Recursively Verifiable Natural Language Inference](https://arxiv.org/abs/2601.19605)
*Xin Quan,Marco Valentino,Louise A. Dennis,André Freitas*

Main category: cs.CL

TL;DR: 提出分解-形式化框架，通过将前提-假设对分解为原子步骤的蕴含树，自底向上验证以隔离失败节点，并使用局部诊断引导的细化而非全局重新生成，显著提高了自然语言推理的解释验证率。


<details>
  <summary>Details</summary>
Motivation: 当前将大语言模型与定理证明器结合的神经符号方法在自然语言推理中存在两个主要问题：1）长而复杂的输入和多步推理放大了自动形式化错误，单个局部不匹配就会使证明无效；2）现有方法难以从证明器诊断中定位错误位置，通常需要代价高昂的全局重新生成。

Method: 提出分解-形式化框架：1）将前提-假设对分解为原子步骤的蕴含树；2）自底向上验证树结构以隔离失败到特定节点；3）执行局部诊断引导的细化而非重新生成整个解释。此外，引入事件逻辑形式中的θ-替换来确保一致的论元角色绑定，提高自动形式化的忠实度。

Result: 在五个大语言模型骨干上的一系列推理任务中，该方法实现了最高的解释验证率，相比最先进方法分别提高了26.2%、21.7%、21.6%和48.9%，同时减少了细化迭代次数和运行时间，并保持了强大的自然语言推理准确性。

Conclusion: 分解-形式化框架通过结构化分解、局部化失败和诊断引导的细化，有效解决了自然语言推理中自动形式化的可扩展性问题，显著提高了验证率并降低了计算成本。

Abstract: Recent work has shown that integrating large language models (LLMs) with theorem provers (TPs) in neuro-symbolic pipelines helps with entailment verification and proof-guided refinement of explanations for natural language inference (NLI). However, scaling such refinement to naturalistic NLI remains difficult: long, syntactically rich inputs and deep multi-step arguments amplify autoformalisation errors, where a single local mismatch can invalidate the proof. Moreover, current methods often handle failures via costly global regeneration due to the difficulty of localising the responsible span or step from prover diagnostics. Aiming to address these problems, we propose a decompose-and-formalise framework that (i) decomposes premise-hypothesis pairs into an entailment tree of atomic steps, (ii) verifies the tree bottom-up to isolate failures to specific nodes, and (iii) performs local diagnostic-guided refinement instead of regenerating the whole explanation. Moreover, to improve faithfulness of autoformalisation, we introduce $θ$-substitution in an event-based logical form to enforce consistent argument-role bindings. Across a range of reasoning tasks using five LLM backbones, our method achieves the highest explanation verification rates, improving over the state-of-the-art by 26.2%, 21.7%, 21.6% and 48.9%, while reducing refinement iterations and runtime and preserving strong NLI accuracy.

</details>


### [34] [Up to 36x Speedup: Mask-based Parallel Inference Paradigm for Key Information Extraction in MLLMs](https://arxiv.org/abs/2601.19613)
*Xinzhong Wang,Ya Guo,Jing Li,Huan Chen,Yi Tu,Yijie Hong,Gongshen Liu,Huijia Zhu*

Main category: cs.CL

TL;DR: 提出PIP并行推理范式，使用掩码标记同时生成所有目标值，相比自回归模型实现5-36倍推理加速，性能损失可忽略


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM/MLLM的视觉丰富文档关键信息提取方法依赖自回归推理，需要顺序生成输出，在处理多个语义独立字段时存在效率瓶颈

Method: 提出PIP并行推理范式：使用"[mask]"标记作为所有目标值的占位符，在单次前向传播中同时生成；开发专门的掩码预训练策略并构建大规模监督数据集

Result: PIP模型相比传统自回归基础模型实现5-36倍推理加速，性能退化可忽略不计

Conclusion: PIP通过显著提升效率同时保持高精度，为可扩展和实用的现实世界KIE解决方案铺平道路

Abstract: Key Information Extraction (KIE) from visually-rich documents (VrDs) is a critical task, for which recent Large Language Models (LLMs) and Multi-Modal Large Language Models (MLLMs) have demonstrated strong potential. However, their reliance on autoregressive inference, which generates outputs sequentially, creates a significant efficiency bottleneck, especially as KIE tasks often involve extracting multiple, semantically independent fields. To overcome this limitation, we introduce PIP: a Parallel Inference Paradigm for KIE. Our approach reformulates the problem by using "[mask]" tokens as placeholders for all target values, enabling their simultaneous generation in a single forward pass. To facilitate this paradigm, we develop a tailored mask pre-training strategy and construct large-scale supervised datasets. Experimental results show that our PIP-models achieve a 5-36x inference speedup with negligible performance degradation compared to traditional autoregressive base models. By substantially improving efficiency while maintaining high accuracy, PIP paves the way for scalable and practical real-world KIE solutions.

</details>


### [35] [RATE: Reviewer Profiling and Annotation-free Training for Expertise Ranking in Peer Review Systems](https://arxiv.org/abs/2601.19637)
*Weicong Liu,Zixuan Yang,Yibo Zhao,Xiang Li*

Main category: cs.CL

TL;DR: LR-bench是一个针对LLM时代审稿人分配问题的新基准，包含2024-2025年AI/NLP论文的五级熟悉度评分，并提出RATE框架通过关键词配置和弱偏好监督实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在LLM时代，审稿人分配面临挑战：快速的主题变化使得2023年前的基准过时，代理信号无法准确反映审稿人的真实熟悉度。需要高保真、最新的评估基准来解决这一瓶颈。

Method: 提出LR-bench基准，通过大规模邮件调查收集2024-2025年AI/NLP论文的五级自我评估熟悉度评分；提出RATE框架，将审稿人近期论文提炼为紧凑的关键词配置，并使用启发式检索信号构建的弱偏好监督微调嵌入模型。

Result: 在LR-bench和CMU黄金标准数据集上，该方法持续实现最先进的性能，明显优于强嵌入基线。

Conclusion: LR-bench为审稿人分配提供了最新的高质量基准，RATE框架通过审稿人中心的方法有效解决了匹配问题，并在多个数据集上验证了其优越性。

Abstract: Reviewer assignment is increasingly critical yet challenging in the LLM era, where rapid topic shifts render many pre-2023 benchmarks outdated and where proxy signals poorly reflect true reviewer familiarity. We address this evaluation bottleneck by introducing LR-bench, a high-fidelity, up-to-date benchmark curated from 2024-2025 AI/NLP manuscripts with five-level self-assessed familiarity ratings collected via a large-scale email survey, yielding 1055 expert-annotated paper-reviewer-score annotations. We further propose RATE, a reviewer-centric ranking framework that distills each reviewer's recent publications into compact keyword-based profiles and fine-tunes an embedding model with weak preference supervision constructed from heuristic retrieval signals, enabling matching each manuscript against a reviewer profile directly. Across LR-bench and the CMU gold-standard dataset, our approach consistently achieves state-of-the-art performance, outperforming strong embedding baselines by a clear margin. We release LR-bench at https://huggingface.co/datasets/Gnociew/LR-bench, and a GitHub repository at https://github.com/Gnociew/RATE-Reviewer-Assign.

</details>


### [36] [One Token Is Enough: Improving Diffusion Language Models with a Sink Token](https://arxiv.org/abs/2601.19657)
*Zihou Zhang,Zheyong Xie,Li Zhong,Haifeng Liu,Shaosheng Cao*

Main category: cs.CL

TL;DR: DLMs存在移动sink现象导致推理不稳定，通过添加一个特殊的额外sink token来稳定注意力机制，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然具有并行生成的优势，但存在移动sink现象这一关键不稳定性问题，sink token在Transformer值空间中具有低范数表示，移动sink现象是防止信息过度混合的保护机制，但其不可预测的位置会损害推理鲁棒性。

Method: 提出简单有效的额外sink token方法，通过修改注意力掩码实现：引入一个特殊token，该token只能关注自身，但对所有其他token全局可见。

Result: 实验结果表明，引入单个额外token能稳定注意力sink，显著提升模型性能。进一步分析确认该token的有效性与位置无关，且语义内容可忽略，验证其作为稳健专用结构sink的作用。

Conclusion: 通过添加专用结构sink token可以有效解决DLMs中的移动sink不稳定问题，提升模型推理鲁棒性和性能。

Abstract: Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.

</details>


### [37] [SynCABEL: Synthetic Contextualized Augmentation for Biomedical Entity Linking](https://arxiv.org/abs/2601.19667)
*Adam Remaki,Christel Gérardin,Eulàlia Farré-Maduell,Martin Krallinger,Xavier Tannier*

Main category: cs.CL

TL;DR: SynCABEL是一个利用大语言模型生成生物医学实体链接合成训练数据的框架，显著减少对人工标注的依赖，在多语言基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决生物医学实体链接中专家标注训练数据稀缺的核心瓶颈问题，降低对劳动密集型和昂贵专家标注的依赖

Method: 利用大语言模型为目标知识库中的所有候选概念生成上下文丰富的合成训练示例，结合仅解码器模型和引导推理

Result: 在MedMentions（英语）、QUAERO（法语）和SPACCC（西班牙语）三个多语言基准测试中达到新的SOTA；使用比全人工监督少60%的标注数据达到相同性能；通过LLM-as-a-judge协议显示显著提高了临床有效预测率

Conclusion: SynCABEL通过合成数据生成有效解决了生物医学实体链接的数据稀缺问题，大幅减少对人工标注的依赖，同时提高了临床有效性，为未来研究提供了可复现的框架和资源

Abstract: We present SynCABEL (Synthetic Contextualized Augmentation for Biomedical Entity Linking), a framework that addresses a central bottleneck in supervised biomedical entity linking (BEL): the scarcity of expert-annotated training data. SynCABEL leverages large language models to generate context-rich synthetic training examples for all candidate concepts in a target knowledge base, providing broad supervision without manual annotation. We demonstrate that SynCABEL, when combined with decoder-only models and guided inference establish new state-of-the-art results across three widely used multilingual benchmarks: MedMentions for English, QUAERO for French, and SPACCC for Spanish. Evaluating data efficiency, we show that SynCABEL reaches the performance of full human supervision using up to 60% less annotated data, substantially reducing reliance on labor-intensive and costly expert labeling. Finally, acknowledging that standard evaluation based on exact code matching often underestimates clinically valid predictions due to ontology redundancy, we introduce an LLM-as-a-judge protocol. This analysis reveals that SynCABEL significantly improves the rate of clinically valid predictions. Our synthetic datasets, models, and code are released to support reproducibility and future research.

</details>


### [38] [Component-Level Lesioning of Language Models Reveals Clinically Aligned Aphasia Phenotypes](https://arxiv.org/abs/2601.19723)
*Yifan Wang,Jichen Zheng,Jingyuan Sun,Yunhao Zhang,Chunyu Ye,Jixing Li,Chengqing Zong,Shaonan Wang*

Main category: cs.CL

TL;DR: LLMs可被选择性扰动以模拟失语症语言障碍，为语言认知研究和康复假设测试提供计算平台


<details>
  <summary>Details</summary>
Motivation: 探索LLMs能否系统性地模拟脑损伤后的失语症语言障碍，为语言康复假设测试和语言功能组织研究提供可控框架

Method: 提出临床基础的组件级框架，通过选择性扰动LLMs的功能组件模拟失语症；应用于模块化专家混合模型和密集Transformer；识别Broca和Wernicke失语症亚型相关组件，通过语言探测任务解释组件，逐步扰动top-k亚型相关组件，使用西方失语症成套测验评估结果

Result: 亚型靶向扰动比大小匹配的随机扰动产生更系统、更类似失语症的回归；MoE模块化支持更局部化和可解释的表型-组件映射；模块化LLMs结合临床信息组件扰动为模拟失语症语言产生和语言功能退化研究提供有前景的平台

Conclusion: 模块化LLMs结合临床信息组件扰动是模拟失语症语言产生和研究语言功能在靶向干扰下如何退化的有前景平台

Abstract: Large language models (LLMs) increasingly exhibit human-like linguistic behaviors and internal representations that they could serve as computational simulators of language cognition. We ask whether LLMs can be systematically manipulated to reproduce language-production impairments characteristic of aphasia following focal brain lesions. Such models could provide scalable proxies for testing rehabilitation hypotheses, and offer a controlled framework for probing the functional organization of language. We introduce a clinically grounded, component-level framework that simulates aphasia by selectively perturbing functional components in LLMs, and apply it to both modular Mixture-of-Experts models and dense Transformers using a unified intervention interface. Our pipeline (i) identifies subtype-linked components for Broca's and Wernicke's aphasia, (ii) interprets these components with linguistic probing tasks, and (iii) induces graded impairments by progressively perturbing the top-k subtype-linked components, evaluating outcomes with Western Aphasia Battery (WAB) subtests summarized by Aphasia Quotient (AQ). Across architectures and lesioning strategies, subtype-targeted perturbations yield more systematic, aphasia-like regressions than size-matched random perturbations, and MoE modularity supports more localized and interpretable phenotype-to-component mappings. These findings suggest that modular LLMs, combined with clinically informed component perturbations, provide a promising platform for simulating aphasic language production and studying how distinct language functions degrade under targeted disruptions.

</details>


### [39] [TokenSeek: Memory Efficient Fine Tuning via Instance-Aware Token Ditching](https://arxiv.org/abs/2601.19739)
*Runjia Zeng,Qifan Wang,Qiang Guan,Ruixiang Tang,Lifu Huang,Zhenting Wang,Xueling Zhang,Cheng Han,Dongfang Liu*

Main category: cs.CL

TL;DR: TokenSeek是一个通过实例感知的token选择和丢弃来显著减少大语言模型微调内存消耗的通用插件解决方案


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型微调方法内存消耗高，而现有的激活优化方法由于数据无关性导致效果不佳且不稳定，需要更有效的内存优化方案

Method: 提出TokenSeek插件，通过实例感知的token寻找和丢弃机制，智能选择重要的token进行处理，减少激活内存占用

Result: 在Llama3.2 1B等模型上仅需14.8%的内存，性能相当甚至更好，同时可解释的token选择过程揭示了其有效性原因

Conclusion: TokenSeek是一个高效的内存优化解决方案，为token效率研究提供了有价值的见解，能够显著降低大模型微调的内存需求

Abstract: Fine tuning has been regarded as a de facto approach for adapting large language models (LLMs) to downstream tasks, but the high training memory consumption inherited from LLMs makes this process inefficient. Among existing memory efficient approaches, activation-related optimization has proven particularly effective, as activations consistently dominate overall memory consumption. Although prior arts offer various activation optimization strategies, their data-agnostic nature ultimately results in ineffective and unstable fine tuning. In this paper, we propose TokenSeek, a universal plugin solution for various transformer-based models through instance-aware token seeking and ditching, achieving significant fine-tuning memory savings (e.g., requiring only 14.8% of the memory on Llama3.2 1B) with on-par or even better performance. Furthermore, our interpretable token seeking process reveals the underlying reasons for its effectiveness, offering valuable insights for future research on token efficiency. Homepage: https://runjia.tech/iclr_tokenseek/

</details>


### [40] [Strong Reasoning Isn't Enough: Evaluating Evidence Elicitation in Interactive Diagnosis](https://arxiv.org/abs/2601.19773)
*Zhuohan Long,Zhijie Bao,Zhongyu Wei*

Main category: cs.CL

TL;DR: 提出交互式医学咨询评估框架EviMed，引入信息覆盖率(ICR)量化证据收集完整性，发现诊断推理强不等于信息收集有效，提出REFINE策略通过诊断验证引导主动解决不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有医学咨询评估大多是静态或结果导向的，忽视了证据收集过程。交互式咨询需要在不确定性下主动获取缺失的临床证据，但缺乏对这一过程的系统性评估。

Method: 构建基于原子证据的模拟患者和模拟报告器，建立EviMed基准涵盖从常见症状到罕见疾病的多种情况。提出信息覆盖率(ICR)量化证据收集完整性，并设计REFINE策略利用诊断验证引导主动解决不确定性。

Result: 评估10个不同推理能力的模型，发现强大的诊断推理能力不能保证有效的信息收集，这是限制交互式性能的主要瓶颈。REFINE策略在多个数据集上持续优于基线，并促进有效的模型协作，使较小模型在强推理监督下获得更好性能。

Conclusion: 交互式医学咨询需要专门评估证据收集过程，信息覆盖率是重要指标。REFINE策略通过诊断验证引导主动解决不确定性，能有效提升交互式咨询性能，促进模型协作。

Abstract: Interactive medical consultation requires an agent to proactively elicit missing clinical evidence under uncertainty. Yet existing evaluations largely remain static or outcome-centric, neglecting the evidence-gathering process. In this work, we propose an interactive evaluation framework that explicitly models the consultation process using a simulated patient and a \rev{simulated reporter} grounded in atomic evidences. Based on this representation, we introduce Information Coverage Rate (ICR) to quantify how completely an agent uncovers necessary evidence during interaction. To support systematic study, we build EviMed, an evidence-based benchmark spanning diverse conditions from common complaints to rare diseases, and evaluate 10 models with varying reasoning abilities. We find that strong diagnostic reasoning does not guarantee effective information collection, and this insufficiency acts as a primary bottleneck limiting performance in interactive settings. To address this, we propose REFINE, a strategy that leverages diagnostic verification to guide the agent in proactively resolving uncertainties. Extensive experiments demonstrate that REFINE consistently outperforms baselines across diverse datasets and facilitates effective model collaboration, enabling smaller agents to achieve superior performance under strong reasoning supervision. Our code can be found at https://github.com/NanshineLoong/EID-Benchmark .

</details>


### [41] [LVLMs and Humans Ground Differently in Referential Communication](https://arxiv.org/abs/2601.19792)
*Peter Zeng,Weiling Li,Amie Paige,Zhengxiang Wang,Panagiotis Kaliosis,Dimitris Samaras,Gregory Zelinsky,Susan Brennan,Owen Rambow*

Main category: cs.CL

TL;DR: 研究通过参照沟通实验揭示大视觉语言模型在交互式解决指称表达方面的局限性，特别是缺乏共同基础建模能力


<details>
  <summary>Details</summary>
Motivation: 生成式AI代理要与人类用户有效合作，准确预测人类意图的能力至关重要，但目前受限于无法建模共同基础这一关键缺陷

Method: 采用因子设计的参照沟通实验，包含四种配对类型（人-人、人-AI、AI-人、AI-AI），多轮交互匹配无明确词汇标签的物体图片

Result: 收集了356个对话语料库（89对×4轮），揭示了LVLMs在交互式解决指称表达方面的局限性，这是人类语言使用的关键技能

Conclusion: 大视觉语言模型在共同基础建模方面存在显著不足，限制了其与人类有效协作的能力，需要进一步研究改进

Abstract: For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that interact with multiple turns in repeated rounds to match pictures of objects not associated with any obvious lexicalized labels. We release the online pipeline for data collection, the tools and analyses for accuracy, efficiency, and lexical overlap, and a corpus of 356 dialogues (89 pairs over 4 rounds each) that unmasks LVLMs' limitations in interactively resolving referring expressions, a crucial skill that underlies human language use.

</details>


### [42] [Zero-Shot Stance Detection in the Wild: Dynamic Target Generation and Multi-Target Adaptation](https://arxiv.org/abs/2601.19802)
*Aohua Li,Yuanshuo Zhang,Ge Gao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 提出零样本立场检测新任务DGTA，通过动态目标生成和多目标适应，在无先验目标知识下从文本自动识别多个目标-立场对，构建中文社交媒体数据集并设计多维度评估指标，微调LLMs取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测研究通常基于给定目标和文本进行预测，但现实社交媒体场景中目标既非预定义也非静态，而是复杂动态的。为解决这一挑战，需要开发能够自动识别多个目标-立场对的方法。

Method: 提出DGTA任务框架，包含动态目标生成和多目标适应。构建中文社交媒体立场检测数据集，设计多维度评估指标。探索集成和两阶段微调策略，评估多种基线模型，包括Qwen2.5-7B和DeepSeek-R1-Distill-Qwen-7B等LLMs。

Result: 实验结果表明微调LLMs在该任务上表现优异：两阶段微调的Qwen2.5-7B获得最高综合目标识别分数66.99%，集成微调的DeepSeek-R1-Distill-Qwen-7B达到立场检测F1分数79.26%。

Conclusion: 提出的DGTA任务有效解决了现实社交媒体中目标动态性的挑战，微调LLMs在该任务上展现出优越性能，为零样本立场检测提供了新方向。

Abstract: Current stance detection research typically relies on predicting stance based on given targets and text. However, in real-world social media scenarios, targets are neither predefined nor static but rather complex and dynamic. To address this challenge, we propose a novel task: zero-shot stance detection in the wild with Dynamic Target Generation and Multi-Target Adaptation (DGTA), which aims to automatically identify multiple target-stance pairs from text without prior target knowledge. We construct a Chinese social media stance detection dataset and design multi-dimensional evaluation metrics. We explore both integrated and two-stage fine-tuning strategies for large language models (LLMs) and evaluate various baseline models. Experimental results demonstrate that fine-tuned LLMs achieve superior performance on this task: the two-stage fine-tuned Qwen2.5-7B attains the highest comprehensive target recognition score of 66.99%, while the integrated fine-tuned DeepSeek-R1-Distill-Qwen-7B achieves a stance detection F1 score of 79.26%.

</details>


### [43] [When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering](https://arxiv.org/abs/2601.19827)
*Mahdi Astaraki,Mohammad Arshi Saloot,Ali Shiraee Kasmaee,Hamidreza Mahyar,Soheila Samiee*

Main category: cs.CL

TL;DR: 迭代检索增强生成（RAG）在科学多跳推理任务中显著优于静态RAG，即使与理想黄金上下文相比，性能提升可达25.6个百分点，主要优势在于减少后期跳失败、缓解上下文过载和纠正早期假设漂移。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究在科学领域（特别是化学知识图谱多跳推理）中，迭代检索-推理循环何时以及为何能超越静态RAG，尤其是在面对多跳推理、稀疏领域知识和异构证据的挑战时。

Method: 采用机制级诊断研究，在ChemKGMultiHopQA数据集上测试11个最先进的LLM，比较三种范式：无上下文（测试参数记忆）、黄金上下文（一次性提供所有证据）、迭代RAG（无训练控制器，交替进行检索、假设精炼和证据感知停止）。使用多种诊断指标分析行为。

Result: 迭代RAG在所有模型中一致优于黄金上下文，性能提升高达25.6个百分点，特别是对非推理微调模型效果更显著。分阶段检索减少了后期跳失败、缓解了上下文过载，并能动态纠正早期假设漂移。

Conclusion: 分阶段检索通常比仅仅提供理想证据更重要；研究为在专业科学场景中部署和诊断RAG系统提供了实用指导，并为构建更可靠、可控的迭代检索-推理框架奠定了基础。

Abstract: Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneous evidence. We provide the first controlled, mechanism-level diagnostic study of whether synchronized iterative retrieval and reasoning can surpass an idealized static upper bound (Gold Context) RAG. We benchmark eleven state-of-the-art LLMs under three regimes: (i) No Context, measuring reliance on parametric memory; (ii) Gold Context, where all oracle evidence is supplied at once; and (iii) Iterative RAG, a training-free controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping. Using the chemistry-focused ChemKGMultiHopQA dataset, we isolate questions requiring genuine retrieval and analyze behavior with diagnostics spanning retrieval coverage gaps, anchor-carry drop, query quality, composition fidelity, and control calibration. Across models, Iterative RAG consistently outperforms Gold Context, with gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models. Staged retrieval reduces late-hop failures, mitigates context overload, and enables dynamic correction of early hypothesis drift, but remaining failure modes include incomplete hop coverage, distractor latch trajectories, early stopping miscalibration, and high composition failure rates even with perfect retrieval. Overall, staged retrieval is often more influential than the mere presence of ideal evidence; we provide practical guidance for deploying and diagnosing RAG systems in specialized scientific settings and a foundation for more reliable, controllable iterative retrieval-reasoning frameworks.

</details>


### [44] [Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering](https://arxiv.org/abs/2601.19847)
*Fangan Dong,Zuming Yan,Xuri Ge,Zhiwei Xu,Mengqi Zhang,Xuanang Chen,Ben He,Xin Xin,Zhumin Chen,Ying Zhou*

Main category: cs.CL

TL;DR: AdaRAS是一个轻量级测试时框架，通过选择性干预神经元激活来提高LLM推理可靠性，无需额外训练或采样成本


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型具备强大的推理能力，但在复杂任务上获得可靠性能通常需要后训练或计算昂贵的采样策略，限制了实际效率。研究发现LLM中一小部分神经元与推理正确性存在强预测相关性。

Method: 提出AdaRAS框架：1）通过极性感知均值差异准则识别推理关键神经元（RCNs）；2）在推理过程中自适应地引导这些神经元的激活，增强错误推理轨迹，同时避免对已正确案例的退化。

Result: 在10个数学和编程基准测试中表现出一致的改进，包括在AIME-24和AIME-25上超过13%的提升。AdaRAS展现出跨数据集的强可迁移性和对更强模型的扩展性，优于后训练方法且无额外成本。

Conclusion: AdaRAS通过选择性神经元干预有效提高了LLM推理可靠性，提供了一种高效、轻量级的解决方案，无需额外训练或采样成本，具有实际应用价值。

Abstract: Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of neurons in LLMs exhibits strong predictive correlations with reasoning correctness. Based on this observation, we propose AdaRAS (Adaptive Reasoning Activation Steering), a lightweight test-time framework that improves reasoning reliability by selectively intervening on neuron activations. AdaRAS identifies Reasoning-Critical Neurons (RCNs) via a polarity-aware mean-difference criterion and adaptively steers their activations during inference, enhancing incorrect reasoning traces while avoiding degradation on already-correct cases. Experiments on 10 mathematics and coding benchmarks demonstrate consistent improvements, including over 13% gains on AIME-24 and AIME-25. Moreover, AdaRAS exhibits strong transferability across datasets and scalability to stronger models, outperforming post-training methods without additional training or sampling cost.

</details>


### [45] [Reflective Translation: Improving Low-Resource Machine Translation via Structured Self-Reflection](https://arxiv.org/abs/2601.19871)
*Nicholas Cheng*

Main category: cs.CL

TL;DR: 本文提出Reflective Translation框架，通过让模型生成初始翻译、进行结构化自我批评、然后生成改进翻译，在isiZulu和isiXhosa等低资源语言翻译中取得了显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如isiZulu和isiXhosa）由于平行数据和语言资源有限，在机器翻译中面临持续挑战。大语言模型的自反思能力可以提升推理质量和事实一致性，这为改进低资源语言翻译提供了新思路。

Method: 提出Reflective Translation框架：模型首先生成初始翻译，然后生成结构化自我批评，最后利用这些反思生成改进翻译。该方法无需微调，模型无关，并在英语-isiZulu和英语-isiXhosa翻译任务上使用多种提示策略和置信度阈值进行评估。

Result: 在OPUS-100和NTREX-African数据集上，第一轮和第二轮翻译之间BLEU和COMET分数均有持续改进，平均提升分别达到+0.22 BLEU和+0.18 COMET。配对非参数统计检验证实这些改进具有稳健性。

Conclusion: 结构化自我反思是提升低资源环境下翻译质量的实用有效机制。该方法无需微调，模型无关，并创建了反思增强数据集，可支持未来监督式或分析驱动的研究工作。

Abstract: Low-resource languages such as isiZulu and isiXhosa face persistent challenges in machine translation due to limited parallel data and linguistic resources. Recent advances in large language models suggest that self-reflection, prompting a model to critique and revise its own outputs, can improve reasoning quality and factual consistency. Building on this idea, this paper introduces Reflective Translation, a prompt-based framework in which a model generates an initial translation, produces a structured self-critique, and then uses this reflection to generate a refined translation. The approach is evaluated on English-isiZulu and English-isiXhosa translation using OPUS-100 and NTREX-African, across multiple prompting strategies and confidence thresholds. Results show consistent improvements in both BLEU and COMET scores between first- and second-pass translations, with average gains of up to +0.22 BLEU and +0.18 COMET. Statistical significance testing using paired nonparametric tests confirms that these improvements are robust. The proposed method is model-agnostic, requires no fine-tuning, and introduces a reflection-augmented dataset that can support future supervised or analysis-driven work. These findings demonstrate that structured self-reflection is a practical and effective mechanism for improving translation quality in low-resource settings.

</details>


### [46] [Evaluation of Oncotimia: An LLM based system for supporting tumour boards](https://arxiv.org/abs/2601.19899)
*Luis Lorenzo,Marcos Montana-Mendez,Sergio Figueiras,Miguel Boubeta,Cristobal Bernardo-Castineira*

Main category: cs.CL

TL;DR: ONCOTIMIA是一个结合生成式AI的临床工具，使用LLMs自动完成肺癌多学科肿瘤会诊表格，减少文档负担。


<details>
  <summary>Details</summary>
Motivation: 多学科肿瘤会诊在肿瘤学决策中起核心作用，但需要手动处理大量异构临床信息，导致严重的文档负担。

Method: 开发ONCOTIMIA系统，结合多层数据湖、混合关系/向量存储、检索增强生成和规则驱动的自适应表单模型，将非结构化临床文档转化为结构化标准化肿瘤会诊记录。评估了6个通过AWS Bedrock部署的LLM在10个肺癌病例上的表现。

Result: 最佳配置实现了80%的正确字段完成率，大多数LLM具有临床可接受的响应时间。更大、更新的模型表现出最佳准确性且延迟可接受。

Conclusion: LLM辅助的自动表单完成在技术上可行且操作上可行，有潜力显著减少文档负担同时保持数据质量。

Abstract: Multidisciplinary tumour boards (MDTBs) play a central role in oncology decision-making but require manual processes and structuring large volumes of heterogeneous clinical information, resulting in a substantial documentation burden. In this work, we present ONCOTIMIA, a modular and secure clinical tool designed to integrate generative artificial intelligence (GenAI) into oncology workflows and evaluate its application to the automatic completion of lung cancer tumour board forms using large language models (LLMs). The system combines a multi-layer data lake, hybrid relational and vector storage, retrieval-augmented generation (RAG) and a rule-driven adaptive form model to transform unstructured clinical documentation into structured and standardised tumour board records. We assess the performance of six LLMs deployed through AWS Bedrock on ten lung cancer cases, measuring both completion form accuracy and end-to-end latency. The results demonstrate high performance across models, with the best performing configuration achieving an 80% of correct field completion and clinically acceptable response time for most LLMs. Larger and more recent models exhibit best accuracies without incurring prohibitive latency. These findings provide empirical evidence that LLM- assisted autocompletion form is technically feasible and operationally viable in multidisciplinary lung cancer workflows and support its potential to significantly reduce documentation burden while preserving data quality.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [47] [Learning the Pareto Space of Multi-Objective Autonomous Driving: A Modular, Data-Driven Approach](https://arxiv.org/abs/2601.18913)
*Mohammad Elayan,Wissam Kontar*

Main category: cs.RO

TL;DR: 该研究提出一个从自然轨迹数据中学习自动驾驶安全、效率和交互权衡的经验框架，通过帕累托最优识别平衡性能的边界。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶设计需要平衡安全、效率和交互三个基本目标，但现有方法难以直接从真实驾驶数据中学习这些权衡关系。

Method: 建立统一目标空间，用复合分数表示每个时间步的安全、效率和交互表现，应用帕累托支配识别非支配状态，形成经验前沿。

Result: 仅0.23%的驾驶实例达到帕累托最优，最优状态在三个目标上均显著优于非最优状态，其中交互改善潜力最大。

Conclusion: 该框架仅需运动学和位置数据，具有最小侵入性和模块化特点，可扩展到其他多目标学习场景进行性能可视化。

Abstract: Balancing safety, efficiency, and interaction is fundamental to designing autonomous driving agents and to understanding autonomous vehicle (AV) behavior in real-world operation. This study introduces an empirical learning framework that derives these trade-offs directly from naturalistic trajectory data. A unified objective space represents each AV timestep through composite scores of safety, efficiency, and interaction. Pareto dominance is applied to identify non-dominated states, forming an empirical frontier that defines the attainable region of balanced performance.
  The proposed framework was demonstrated using the Third Generation Simulation (TGSIM) datasets from Foggy Bottom and I-395. Results showed that only 0.23\% of AV driving instances were Pareto-optimal, underscoring the rarity of simultaneous optimization across objectives. Pareto-optimal states showed notably higher mean scores for safety, efficiency, and interaction compared to non-optimal cases, with interaction showing the greatest potential for improvement.
  This minimally invasive and modular framework, which requires only kinematic and positional data, can be directly applied beyond the scope of this study to derive and visualize multi-objective learning surfaces

</details>


### [48] [DeFM: Learning Foundation Representations from Depth for Robotics](https://arxiv.org/abs/2601.18923)
*Manthan Patel,Jonas Frey,Mayank Mittal,Fan Yang,Alexander Hansson,Amir Bar,Cesar Cadena,Marco Hutter*

Main category: cs.RO

TL;DR: DeFM是一个专门为机器人应用设计的自监督深度图像基础模型，使用60M深度图像数据集训练，在多种深度感知任务上达到SOTA性能，并支持从仿真到真实环境的泛化。


<details>
  <summary>Details</summary>
Motivation: 深度传感器在机器人平台中广泛部署，但深度模态的表征学习相比RGB模态仍未被充分探索。尽管快速、高保真的深度仿真取得了进展，但缺乏专门针对深度图像的大规模基础模型，限制了深度感知在机器人任务中的应用。

Method: 1. 使用DINO风格的自蒸馏目标在60M深度图像数据集上训练；2. 引入新颖的输入归一化策略以保持多尺度下的度量感知；3. 将DeFM蒸馏为适合资源受限机器人系统的紧凑模型。

Result: DeFM在深度分类、分割、导航、运动、操作等基准测试中达到最先进性能，展示了从仿真到真实环境的强泛化能力。模型无需任务特定微调即可用于深度机器人学习。

Conclusion: DeFM填补了深度模态基础模型的空白，为机器人应用提供了强大的深度表征学习能力，支持跨环境、任务和传感器的泛化，并发布了预训练模型供直接使用。

Abstract: Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/

</details>


### [49] [Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot](https://arxiv.org/abs/2601.18963)
*Fauna Robotics,:,Diego Aldarondo,Ana Pervan,Daniel Corbalan,Dave Petrillo,Bolun Dai,Aadhithya Iyer,Nina Mortensen,Erik Pearson,Sridhar Pandian Arunachalam,Emma Reznick,David Weis,Jacob Davison,Samuel Patterson,Tess Carella,Michael Suguitan,David Ye,Oswaldo Ferro,Nilesh Suriyarachchi,Spencer Ling,Erik Su,Daniel Giebisch,Peter Traver,Sam Fonseca,Mack Mor,Rohan Singh,Sertac Guven,Kangni Liu,Yaswanth Kumar Orru,Ashiq Rahman Anwar Batcha,Shruthi Ravindranath,Silky Arora,Hugo Ponte,Dez Hernandez,Utsav Chaudhary,Zack Walker,Michael Kelberman,Ivan Veloz,Christina Santa Lucia,Kat Casale,Helen Han,Michael Gromis,Michael Mignatti,Jason Reisman,Kelleher Guerin,Dario Narvaez,Christopher Anderson,Anthony Moschella,Robert Cochran,Josh Merel*

Main category: cs.RO

TL;DR: Sprout是一个面向开发者的安全、可表达的人形机器人平台，旨在解决现有机器人难以在人类环境中长期安全部署的问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器人领域虽然在学习控制、大规模仿真和生成模型方面取得了进展，但缺乏适合在人类环境中安全、可表达、长期部署的平台。现有的人形机器人要么是封闭的工业系统，要么是难以在人群中部署和操作的学术原型，这限制了机器人技术的进步。

Method: Sprout采用轻量化设计，具有柔顺控制、有限的关节扭矩和柔软外壳以确保安全。平台集成了全身控制、集成夹爪的操纵功能以及基于虚拟现实的遥操作，形成统一的硬件-软件堆栈。平台还配备了富有表现力的头部以支持社交互动。

Result: Sprout通过降低物理和技术部署障碍，扩展了有能力的人形机器人平台的可及性，为在真实人类环境中开发具身智能提供了实用基础。

Conclusion: Sprout作为一个开发者平台，通过强调安全性、可表达性和开发者可访问性，解决了现有机器人平台的局限性，为在人类共享空间中安全部署人形机器人提供了可行的解决方案。

Abstract: Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.

</details>


### [50] [A Switching Nonlinear Model Predictive Control Strategy for Safe Collision Handling by an Underwater Vehicle-Manipulator System](https://arxiv.org/abs/2601.18971)
*Ioannis G. Polyzos,Konstantinos J. Kyriakopoulos*

Main category: cs.RO

TL;DR: 提出一种切换非线性模型预测控制策略，用于水下车辆-机械臂系统的安全碰撞处理，包括避免碰撞和利用机械臂推离障碍物


<details>
  <summary>Details</summary>
Motivation: 水下自主车辆在执行任务时可能面临与障碍物碰撞的风险，需要安全处理策略来保护车辆敏感区域

Method: 采用切换非线性模型预测控制策略，当无法避免碰撞时，利用机械臂推压障碍物实现偏转避碰

Result: 虚拟实验验证了算法能够成功检测碰撞，并有效避免碰撞或利用机械臂适当处理而不损坏车辆敏感区域

Conclusion: 提出的控制策略能够有效处理水下车辆-机械臂系统的碰撞情况，提高水下干预任务的安全性

Abstract: For active intervention tasks in underwater environments, the use of autonomous vehicles is just now emerging as an active area of research. During operation, for various reasons, the robot might find itself on a collision course with an obstacle in its environment. In this paper, a switching Nonlinear Model Predictive Control (NMPC) strategy is proposed to safely handle collisions for an Underwater Vehicle-Manipulator System (UVMS). When avoiding the collision is impossible, the control algorithm takes advantage of the manipulator, using it to push against the obstacle, and deflect away from the collision. Virtual experiments are performed to demonstrate the algorithm's capability to successfully detect collisions and either avoid them, or use the manipulator to handle them appropriately without damaging sensitive areas of the vehicle.

</details>


### [51] [Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing](https://arxiv.org/abs/2601.19079)
*Naqash Afzal,Niklas Funk,Erik Helmut,Jan Peters,Benjamin Ward-Cherrier*

Main category: cs.RO

TL;DR: 提出基于事件触觉传感器的连续盲文识别系统，实现高精度实时识别，模拟人类手指滑动扫描策略


<details>
  <summary>Details</summary>
Motivation: 传统盲文阅读器采用离散字符扫描，速度慢且不自然；基于视觉的方法计算量大、延迟高、在真实环境中性能下降

Method: 使用开源神经形态事件触觉传感器Evetac，结合时空分割和轻量级ResNet分类器处理稀疏事件流，支持连续滑动识别

Result: 在标准深度下达到接近完美准确率（≥98%），支持多种盲文板布局，快速扫描下保持良好性能，在实际盲文板上词级准确率超90%

Conclusion: 神经形态触觉感知为机器人盲文阅读提供了可扩展、低延迟的解决方案，对辅助技术和机器人触觉感知有广泛意义

Abstract: Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.

</details>


### [52] [SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers](https://arxiv.org/abs/2601.19098)
*Kurt Enkera,Josh Pinskier,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: SimTO框架通过从物理模拟器中自动提取负载情况，实现高分辨率拓扑优化，为特征丰富物体定制软体夹爪，无需手动指定负载。


<details>
  <summary>Details</summary>
Motivation: 现有软体夹爪难以抓取具有高拓扑变异性的特征丰富物体（如齿轮、珊瑚、西兰花等），这些物体缺乏明确的"最优"接触表面，容易受损。传统拓扑优化需要预定义负载情况，但软体夹爪与特征丰富物体交互时会产生数百种不可预测的接触力。

Method: 提出SimTO框架，通过接触式物理模拟器自动提取负载情况，实现高分辨率拓扑优化。给定任意特征丰富物体，SimTO生成高度定制的软体夹爪，具有与物体几何形状匹配的细粒度形态特征。

Result: 数值结果显示，SimTO设计的夹爪不仅对特征丰富物体具有高度专一性，还能泛化到未见过的物体。

Conclusion: SimTO框架通过自动提取负载情况，解决了拓扑优化在软体夹爪设计中的关键限制，能够为特征丰富物体生成高度定制化的软体夹爪，具有实际应用价值。

Abstract: Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear "optimal" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.

</details>


### [53] [Agree to Disagree: Consensus-Free Flocking under Constraints](https://arxiv.org/abs/2601.19119)
*Peter Travis Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 提出一种新的群体控制方法，允许智能体通过局部观察协商不同的期望间距，无需全局信息或通信，适用于目标冲突的半信任场景。


<details>
  <summary>Details</summary>
Motivation: 传统群体控制假设智能体具有统一的期望间距，但实际应用中智能体类型和配置多样，且常常在没有信任保证或安全通信的环境下工作，需要更灵活的方法。

Method: 通过新的约束集体势函数，允许智能体协商间距参数，仅通过局部观察实现，无需全局信息或智能体间通信。

Result: 该方法在目标冲突的半信任场景中具有鲁棒性，通过一系列仿真验证了其有效性。

Conclusion: 更新了传统群体控制框架，通过允许间距参数协商，为多样化、半信任环境中的多智能体系统提供了更灵活实用的解决方案。

Abstract: Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.

</details>


### [54] [Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity](https://arxiv.org/abs/2601.19144)
*Tzvika Geft,William Zhang,Jingjin Yu,Kostas Bekris*

Main category: cs.RO

TL;DR: 提出一个框架，在不确定性下提高自动化存储系统的运行效率，通过设计网格宽度和存储布局来最小化负载重定位。


<details>
  <summary>Details</summary>
Motivation: 在实际物流应用中（如最后一公里配送中心和船厂），检索序列可能在存储阶段后发生变化，这种不确定性导致需要负载重定位，影响系统效率。

Method: 研究k有界扰动下的存储检索问题，证明Θ(k)网格宽度是消除重定位的必要充分条件，提供高效求解器计算鲁棒的存储布局，并针对超出k的扰动提出最小化重定位策略。

Result: 当k达到网格宽度一半时，提出的框架基本消除重定位；当k达到全网格宽度时，重定位减少50%以上。

Conclusion: 通过适当设计网格宽度和存储布局，可以在不确定性下显著减少甚至消除负载重定位，提高自动化存储系统的运行效率。

Abstract: This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $Θ(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\%+$.

</details>


### [55] [iFAN Ecosystem: A Unified AI, Digital Twin, Cyber-Physical Security, and Robotics Environment for Advanced Nuclear Simulation and Operations](https://arxiv.org/abs/2601.19234)
*Youndo Do,Chad Meece,Marc Zebrowitz,Spencer Banks,Myeongjun Choi,Xiaoxu Diao,Kai Tan,Michael Doran,Jason Reed,Fan Zhang*

Main category: cs.RO

TL;DR: 开发了一个名为iFAN的沉浸式数字孪生框架，为核设施提供高保真虚拟测试平台，用于验证自主操作、网络安全和机器人操作等新兴技术。


<details>
  <summary>Details</summary>
Motivation: 随着核设施数字化转型和先进反应堆发展，AI集成、网络物理安全和自主机器人操作等技术日益重要，但缺乏专用虚拟测试平台阻碍了评估和部署。

Method: 开发了iFAN生态系统，这是一个包含真实3D环境和基于物理仿真的综合数字孪生框架，支持实时数据交换用于部署前验证。

Result: iFAN提供了高保真虚拟测试平台，支持工厂操作、网络安全、物理安全和机器人操作，核心功能包括虚拟现实、强化学习、辐射模拟和网络物理安全。

Conclusion: iFAN生态系统为验证下一代自主和网络弹性核操作提供了多功能且安全的架构，通过潜在操作场景展示了其应用价值。

Abstract: As nuclear facilities experience digital transformation and advanced reactor development, AI integration, cyber-physical security, and other emerging technologies such as autonomous robot operations are increasingly developed. However, evaluation and deployment is challenged by the lack of dedicated virtual testbeds. The Immersive Framework for Advanced Nuclear (iFAN) ecosystem is developed, a comprehensive digital twin framework with a realistic 3D environment with physics-based simulations. The iFAN ecosystem serves as a high-fidelity virtual testbed for plant operation, cybersecurity, physical security, and robotic operation, as it provides real-time data exchange for pre-deployment verification. Core features include virtual reality, reinforcement learning, radiation simulation, and cyber-physical security. In addition, the paper investigates various applications through potential operational scenarios. The iFAN ecosystem provides a versatile and secure architecture for validating the next generation of autonomous and cyber-resilient nuclear operations.

</details>


### [56] [Tactile Memory with Soft Robot: Robust Object Insertion via Masked Encoding and Soft Wrist](https://arxiv.org/abs/2601.19275)
*Tatsuya Kamijo,Mai Nishimura,Cristian C. Beltran-Hernandez,Nodoka Shibasaki,Masashi Hamaya*

Main category: cs.RO

TL;DR: 本文提出TaMeSo-bot系统，通过软体手腕和触觉记忆实现安全鲁棒的接触式操作，核心是MAT³模型，在多种peg-in-hole任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 触觉记忆对于接触丰富的任务（如不确定条件下的钥匙插入）至关重要。现有方法需要复制这种能力来实现安全且鲁棒的操作。

Method: 提出TaMeSo-bot系统：1）软体手腕实现安全接触探索；2）触觉记忆通过检索重用过去演示；3）核心MAT³模型通过掩码令牌预测联合建模机器人动作、分布式触觉反馈、力-扭矩测量和本体感觉信号。

Result: 在真实机器人实验中，MAT³在所有条件下都比基线方法获得更高的成功率，并展现出对未见过的peg和条件的显著适应能力。

Conclusion: TaMeSo-bot系统成功实现了触觉记忆能力，MAT³模型通过掩码令牌预测学习丰富的时空表示，在接触式操作任务中表现出优异的性能和适应性。

Abstract: Tactile memory, the ability to store and retrieve touch-based experience, is critical for contact-rich tasks such as key insertion under uncertainty. To replicate this capability, we introduce Tactile Memory with Soft Robot (TaMeSo-bot), a system that integrates a soft wrist with tactile retrieval-based control to enable safe and robust manipulation. The soft wrist allows safe contact exploration during data collection, while tactile memory reuses past demonstrations via retrieval for flexible adaptation to unseen scenarios. The core of this system is the Masked Tactile Trajectory Transformer (MAT$^\text{3}$), which jointly models spatiotemporal interactions between robot actions, distributed tactile feedback, force-torque measurements, and proprioceptive signals. Through masked-token prediction, MAT$^\text{3}$ learns rich spatiotemporal representations by inferring missing sensory information from context, autonomously extracting task-relevant features without explicit subtask segmentation. We validate our approach on peg-in-hole tasks with diverse pegs and conditions in real-robot experiments. Our extensive evaluation demonstrates that MAT$^\text{3}$ achieves higher success rates than the baselines over all conditions and shows remarkable capability to adapt to unseen pegs and conditions.

</details>


### [57] [Perception-to-Pursuit: Track-Centric Temporal Reasoning for Open-World Drone Detection and Autonomous Chasing](https://arxiv.org/abs/2601.19318)
*Venkatakrishna Reddy Oruganti*

Main category: cs.RO

TL;DR: P2P框架通过将无人机运动表示为8维token，使用因果transformer进行时序推理，在保持100%检测准确率的同时，将轨迹预测精度提升77%，拦截成功率提升597倍。


<details>
  <summary>Details</summary>
Motivation: 现有无人机跟踪方法只优化预测精度，忽略了实际拦截的可行性，导致99.9%的情况下无法实现物理上可行的拦截。需要一种能同时考虑检测和实际拦截规划的框架。

Method: 提出Perception-to-Pursuit (P2P)框架，将无人机运动表示为包含速度、加速度、尺度和平滑度的8维token，使用12帧因果transformer进行时序推理，预测未来行为并规划可行拦截。

Result: 在Anti-UAV-RGBT数据集的226个真实无人机序列上，P2P达到28.12像素平均位移误差和0.597拦截成功率，相比仅跟踪基线，轨迹预测提升77%，拦截可行性提升597倍，同时保持100%的无人机分类准确率。

Conclusion: 通过对运动模式的时序推理，P2P框架能够同时实现准确的轨迹预测和可行的拦截规划，为自主无人机追击提供了有效的解决方案。

Abstract: Autonomous drone pursuit requires not only detecting drones but also predicting their trajectories in a manner that enables kinematically feasible interception. Existing tracking methods optimize for prediction accuracy but ignore pursuit feasibility, resulting in trajectories that are physically impossible to intercept 99.9% of the time. We propose Perception-to-Pursuit (P2P), a track-centric temporal reasoning framework that bridges detection and actionable pursuit planning. Our method represents drone motion as compact 8-dimensional tokens capturing velocity, acceleration, scale, and smoothness, enabling a 12-frame causal transformer to reason about future behavior. We introduce the Intercept Success Rate (ISR) metric to measure pursuit feasibility under realistic interceptor constraints. Evaluated on the Anti-UAV-RGBT dataset with 226 real drone sequences, P2P achieves 28.12 pixel average displacement error and 0.597 ISR, representing a 77% improvement in trajectory prediction and 597x improvement in pursuit feasibility over tracking-only baselines, while maintaining perfect drone classification accuracy (100%). Our work demonstrates that temporal reasoning over motion patterns enables both accurate prediction and actionable pursuit planning.

</details>


### [58] [Self-Supervised Path Planning in Unstructured Environments via Global-Guided Differentiable Hard Constraint Projection](https://arxiv.org/abs/2601.19354)
*Ziqian Wang,Chenxi Fang,Zhen Zhang*

Main category: cs.RO

TL;DR: 提出自监督框架，通过可微分硬约束投影层实现运行时保证，解决自动驾驶中安全、数据稀缺和计算资源受限问题。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中部署深度学习自动驾驶代理面临安全、数据稀缺和计算资源受限三大挑战。传统求解器延迟高，而基于学习的方法难以保证确定性可行性。

Method: 1) 构建全局引导人工势场(G-APF)提供密集监督信号，无需人工标注；2) 采用自适应神经投影层，迭代修正网络输出到可行流形，满足执行器限制和几何约束。

Result: 在20,000个场景测试集上达到88.75%成功率，验证了操作安全性。CARLA闭环实验验证动态约束下路径的物理可实现性。NVIDIA Jetson Orin NX上推理延迟94ms，证明资源受限嵌入式硬件的实时可行性。

Conclusion: 该框架为将物理定律嵌入神经架构提供了通用范式，为解决机电系统中的约束优化问题提供了可行方向。

Abstract: Deploying deep learning agents for autonomous navigation in unstructured environments faces critical challenges regarding safety, data scarcity, and limited computational resources. Traditional solvers often suffer from high latency, while emerging learning-based approaches struggle to ensure deterministic feasibility. To bridge the gap from embodied to embedded intelligence, we propose a self-supervised framework incorporating a differentiable hard constraint projection layer for runtime assurance. To mitigate data scarcity, we construct a Global-Guided Artificial Potential Field (G-APF), which provides dense supervision signals without manual labeling. To enforce actuator limitations and geometric constraints efficiently, we employ an adaptive neural projection layer, which iteratively rectifies the coarse network output onto the feasible manifold. Extensive benchmarks on a test set of 20,000 scenarios demonstrate an 88.75\% success rate, substantiating the enhanced operational safety. Closed-loop experiments in CARLA further validate the physical realizability of the planned paths under dynamic constraints. Furthermore, deployment verification on an NVIDIA Jetson Orin NX confirms an inference latency of 94 ms, showing real-time feasibility on resource-constrained embedded hardware. This framework offers a generalized paradigm for embedding physical laws into neural architectures, providing a viable direction for solving constrained optimization in mechatronics. Source code is available at: https://github.com/wzq-13/SSHC.git.

</details>


### [59] [Teaching Machine Learning Fundamentals with LEGO Robotics](https://arxiv.org/abs/2601.19376)
*Viacheslav Sydora,Guner Dilsad Er,Michael Muehlebach*

Main category: cs.RO

TL;DR: 基于网页的平台Machine Learning with Bricks通过无编程的乐高机器人活动向12-17岁学生教授机器学习概念，结合可视化与机器人交互，显著提升了学生对ML算法的理解和学习兴趣。


<details>
  <summary>Details</summary>
Motivation: 让年轻学习者（12-17岁）能够接触和理解机器学习概念，通过无编程、可视化、机器人交互的方式降低学习门槛，激发对AI的兴趣。

Method: 开发开源网页平台Machine Learning with Bricks，结合乐高机器人和交互式可视化，教授KNN、线性回归和Q-learning三种核心算法。学生通过收集数据、训练模型、与机器人交互来学习，并配有为期两天的课程和视频教程。

Result: 对14名学生进行前后测调查显示：机器学习概念理解显著提升，对AI的认知态度积极转变，平台可用性高，学习动机增强。证明这种可视化、实体化的方法能有效向年轻学习者传授机器学习知识。

Conclusion: 可视化与机器人交互的实体化方法能够有效向年轻学习者传授机器学习概念，保持技术深度的同时提高可及性和参与度。该开源平台为青少年ML教育提供了实用工具。

Abstract: This paper presents the web-based platform Machine Learning with Bricks and an accompanying two-day course designed to teach machine learning concepts to students aged 12 to 17 through programming-free robotics activities. Machine Learning with Bricks is an open source platform and combines interactive visualizations with LEGO robotics to teach three core algorithms: KNN, linear regression, and Q-learning. Students learn by collecting data, training models, and interacting with robots via a web-based interface. Pre- and post-surveys with 14 students demonstrate significant improvements in conceptual understanding of machine learning algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning. This work demonstrates that tangible, visualization-based approaches can make machine learning concepts accessible and engaging for young learners while maintaining technical depth. The platform is freely available at https://learning-and-dynamics.github.io/ml-with-bricks/, with video tutorials guiding students through the experiments at https://youtube.com/playlist?list=PLx1grFu4zAcwfKKJZ1Ux4LwRqaePCOA2J.

</details>


### [60] [Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing](https://arxiv.org/abs/2601.19388)
*Yimin Tang,Sven Koenig,Erdem Bıyık*

Main category: cs.RO

TL;DR: Judgelight是一种后优化方法，通过压缩多智能体路径规划中的闭合子路径来减少冗余运动，在保持可行性的同时降低约20%的解决方案成本。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型MAPF求解器虽然快速且可扩展，但生成的轨迹往往包含不必要的或振荡的运动，不适合实际部署。需要一种方法来优化这些轨迹的质量。

Method: 提出Judgelight后优化方法，将MAPF-Collapse问题形式化为整数线性规划（ILP）问题，通过压缩智能体轨迹中的闭合子路径来移除冗余运动，同时保持所有可行性约束。

Result: 实验结果表明，Judgelight能持续减少约20%的解决方案成本，特别对学习型求解器效果显著，生成的轨迹更适合实际部署。

Conclusion: Judgelight作为一种有效的后优化方法，能够显著提高MAPF解决方案的质量，特别是对学习型求解器生成的轨迹进行优化，使其更适合实际应用。

Abstract: Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization method that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.

</details>


### [61] [Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.19406)
*Kaipeng Fang,Weiqing Liang,Yuyang Li,Ji Zhang,Pengpeng Zeng,Lianli Gao,Jingkuan Song,Heng Tao Shen*

Main category: cs.RO

TL;DR: SimHum：通过协同训练框架，同时从模拟机器人动作中提取运动学先验和从真实人类观察中提取视觉先验，实现数据高效且泛化性强的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 模拟数据和人类数据虽然可以规避机器人数据收集的高昂成本，但分别存在模拟到真实的视觉差距和人类到机器人的具身差距。研究发现这两种数据源存在天然的互补性：模拟提供机器人动作，人类数据提供真实世界观察。

Method: 提出SimHum协同训练框架，同时从模拟机器人动作中提取运动学先验，从真实人类观察中提取视觉先验，基于这两种互补先验实现数据高效的机器人操作。

Result: 在相同数据收集预算下，SimHum比基线方法性能提升高达40%；仅用80个真实数据就能达到62.5%的OOD成功率，比仅使用真实数据的基线方法高出7.1倍。

Conclusion: 通过利用模拟数据和人类数据的互补优势，SimHum框架能够实现数据高效且泛化性强的真实世界机器人操作，为解决机器人学习中的数据稀缺问题提供了有效方案。

Abstract: Synthetic simulation data and real-world human data provide scalable alternatives to circumvent the prohibitive costs of robot data collection. However, these sources suffer from the sim-to-real visual gap and the human-to-robot embodiment gap, respectively, which limits the policy's generalization to real-world scenarios. In this work, we identify a natural yet underexplored complementarity between these sources: simulation offers the robot action that human data lacks, while human data provides the real-world observation that simulation struggles to render. Motivated by this insight, we present SimHum, a co-training framework to simultaneously extract kinematic prior from simulated robot actions and visual prior from real-world human observations. Based on the two complementary priors, we achieve data-efficient and generalizable robotic manipulation in real-world tasks. Empirically, SimHum outperforms the baseline by up to $\mathbf{40\%}$ under the same data collection budget, and achieves a $\mathbf{62.5\%}$ OOD success with only 80 real data, outperforming the real only baseline by $7.1\times$. Videos and additional information can be found at \href{https://kaipengfang.github.io/sim-and-human}{project website}.

</details>


### [62] [Task-Centric Policy Optimization from Misaligned Motion Priors](https://arxiv.org/abs/2601.19411)
*Ziang Zheng,Kai Feng,Yi Nie,Shentao Qin*

Main category: cs.RO

TL;DR: TCMP提出任务优先对抗模仿框架，将模仿作为条件正则化器而非平等目标，在保持任务性能的同时获得自然运动风格


<details>
  <summary>Details</summary>
Motivation: 人类演示的运动先验常因具身差异、重定向误差和任务无关变化而次优或与机器人任务不对齐，导致单纯模仿降低任务性能；而仅基于任务的强化学习会产生不自然或不稳定的运动

Method: TCMP（任务中心运动先验）框架将模仿视为条件正则化器而非平等目标，仅在模仿信号与任务进展兼容时纳入，产生自适应、几何感知的更新，保持任务可行下降并抑制不对齐时的有害模仿

Result: 通过人形机器人控制实验验证，在噪声演示下实现了稳健的任务性能并保持了一致的运动风格

Conclusion: TCMP解决了对抗模仿学习中线性奖励混合的基本限制，通过任务优先方法在保持任务性能的同时获得自然运动风格

Abstract: Humanoid control often leverages motion priors from human demonstrations to encourage natural behaviors. However, such demonstrations are frequently suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations, causing naïve imitation to degrade task performance. Conversely, task-only reinforcement learning admits many task-optimal solutions, often resulting in unnatural or unstable motions. This exposes a fundamental limitation of linear reward mixing in adversarial imitation learning. We propose \emph{Task-Centric Motion Priors} (TCMP), a task-priority adversarial imitation framework that treats imitation as a conditional regularizer rather than a co-equal objective. TCMP maximizes task improvement while incorporating imitation signals only when they are compatible with task progress, yielding an adaptive, geometry-aware update that preserves task-feasible descent and suppresses harmful imitation under misalignment. We provide theoretical analysis of gradient conflict and task-priority stationary points, and validate our claims through humanoid control experiments demonstrating robust task performance with consistent motion style under noisy demonstrations.

</details>


### [63] [Self-Reconfiguration Planning for Deformable Quadrilateral Modular Robots](https://arxiv.org/abs/2601.19496)
*Jie Gu,Hongrun Gao,Zhihao Xia,Yirun Sun,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: 提出一种保证稳定连接的四边形模块化自重构机器人自重构规划算法，通过虚拟图表示构建可行连接/断开动作，使用依赖反向树组织执行序列，证明7个以上模块（非线形拓扑）的任意配置对存在满足运动特性的重构序列。


<details>
  <summary>Details</summary>
Motivation: 对于晶格型模块化自重构机器人，在重构过程中保持稳定连接对于物理可行性和可部署性至关重要。现有方法在保证连接稳定性方面存在不足。

Method: 1. 使用虚拟图表示构建可行的连接/断开动作；2. 通过依赖反向树（DRTree）组织这些动作形成有效执行序列，解决动作间的相互依赖关系。

Result: 1. 证明对于7个以上模块（排除线形拓扑）的任意配置对，存在满足运动特性的重构序列；2. 与改进的BiRRT算法比较显示本方法在效率和稳定性上更优；3. 在物理机器人平台上部署验证了实际可行性。

Conclusion: 提出的自重构规划算法能够保证四边形模块化自重构机器人在重构过程中的稳定连接，具有高效性、稳定性和实际可行性，为模块化机器人系统的可靠部署提供了有效解决方案。

Abstract: For lattice modular self-reconfigurable robots (MSRRs), maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability. This letter presents a novel self-reconfiguration planning algorithm for deformable quadrilateral MSRRs that guarantees stable connection. The method first constructs feasible connect/disconnect actions using a virtual graph representation, and then organizes these actions into a valid execution sequence through a Dependence-based Reverse Tree (DRTree) that resolves interdependencies. We also prove that reconfiguration sequences satisfying motion characteristics exist for any pair of configurations with seven or more modules (excluding linear topologies). Finally, comparisons with a modified BiRRT algorithm highlight the superior efficiency and stability of our approach, while deployment on a physical robotic platform confirms its practical feasibility.

</details>


### [64] [Reinforcement Learning Goal-Reaching Control with Guaranteed Lyapunov-Like Stabilizer for Mobile Robots](https://arxiv.org/abs/2601.19499)
*Mehdi Heydari Shahna,Seyed Adel Alizadeh Kolagar,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出一种结合强化学习与李雅普诺夫稳定器的控制框架，为轮式移动机器人在非结构化环境中提供形式化的目标到达保证，将成功率从84.6%提升至99.0%。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能有效学习目标到达策略，但缺乏形式化保证目标一定能到达。传统屏蔽机制虽然能提供安全约束，但容易导致学习过程过于保守，影响探索效率。因此需要一种既能提供形式化保证，又不影响强化学习探索能力的框架。

Method: 1. 设计包含15个奖励项的实时强化学习策略，鼓励机器人到达静态和动态目标，同时生成平滑的控制信号并满足安全规范；2. 在基准RL框架中集成李雅普诺夫类稳定器作为策略监督器，在保持状态动作空间有意义探索的同时，形式化增强目标到达控制。

Result: 实验结果表明，提出的李雅普诺夫类稳定器能持续改进基准RL策略，将目标到达率从84.6%提升至99.0%，显著减少失败率并提高效率。框架适合在挑战性环境中实时部署，提供形式化的收敛保证。

Conclusion: 该框架成功将强化学习与形式化保证相结合，为轮式移动机器人提供了既有效又安全的控制方案，在保持强化学习探索能力的同时，通过李雅普诺夫稳定器确保了目标到达的形式化保证。

Abstract: Reinforcement learning (RL) can be highly effective at learning goal-reaching policies, but it typically does not provide formal guarantees that the goal will always be reached. A common approach to provide formal goal-reaching guarantees is to introduce a shielding mechanism that restricts the agent to actions that satisfy predefined safety constraints. The main challenge here is integrating this mechanism with RL so that learning and exploration remain effective without becoming overly conservative. Hence, this paper proposes an RL-based control framework that provides formal goal-reaching guarantees for wheeled mobile robots operating in unstructured environments. We first design a real-time RL policy with a set of 15 carefully defined reward terms. These rewards encourage the robot to reach both static and dynamic goals while generating sufficiently smooth command signals that comply with predefined safety specifications, which is critical in practice. Second, a Lyapunov-like stabilizer layer is integrated into the benchmark RL framework as a policy supervisor to formally strengthen the goal-reaching control while preserving meaningful exploration of the state action space. The proposed framework is suitable for real-time deployment in challenging environments, as it provides a formal guarantee of convergence to the intended goal states and compensates for uncertainties by generating real-time control signals based on the current state, while respecting real-world motion constraints. The experimental results show that the proposed Lyapunov-like stabilizer consistently improves the benchmark RL policies, boosting the goal-reaching rate from 84.6% to 99.0%, sharply reducing failures, and improving efficiency.

</details>


### [65] [A DVL Aided Loosely Coupled Inertial Navigation Strategy for AUVs with Attitude Error Modeling and Variance Propagation](https://arxiv.org/abs/2601.19509)
*Jin Huang,Zichen Liu,Haoda Li,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 提出一种改进的SINS/DVL松耦合导航方法，通过姿态误差感知的DVL速度变换模型和协方差传播方法，显著提升长期导航精度。


<details>
  <summary>Details</summary>
Motivation: 传统SINS/DVL导航中，使用SINS估计的姿态将DVL速度从机体坐标系变换到导航坐标系时，姿态估计误差会累积并导致速度投影偏差，从而降低长期导航性能。

Method: 提出两种互补改进：1）建立姿态误差感知的DVL速度变换模型，在观测方程中引入姿态误差项以减少投影引起的速度偏差；2）开发基于协方差矩阵的方差传播方法，通过期望姿态误差补偿项实现统计一致的噪声建模。

Result: 仿真和现场实验结果表明，两种改进均能单独提升导航精度，联合应用时能有效抑制长期误差发散。现场实验显示，相比基线IMU+DVL方法，3D位置RMSE提升78.3%，最大分量位置误差减少71.8%。

Conclusion: 所提出的姿态误差感知DVL速度变换模型和协方差传播方法能有效解决SINS/DVL导航中长期姿态误差累积问题，显著提升导航精度，为长期水下导航提供了鲁棒解决方案。

Abstract: In underwater navigation systems, strap-down inertial navigation system/Doppler velocity log (SINS/DVL)-based loosely coupled architectures are widely adopted. Conventional approaches project DVL velocities from the body coordinate system to the navigation coordinate system using SINS-derived attitude; however, accumulated attitude estimation errors introduce biases into velocity projection and degrade navigation performance during long-term operation. To address this issue, two complementary improvements are introduced. First, a vehicle attitude error-aware DVL velocity transformation model is formulated by incorporating attitude error terms into the observation equation to reduce projection-induced velocity bias. Second, a covariance matrix-based variance propagation method is developed to transform DVL measurement uncertainty across coordinate systems, introducing an expectation-based attitude error compensation term to achieve statistically consistent noise modeling. Simulation and field experiment results demonstrate that both improvements individually enhance navigation accuracy and confirm that accumulated attitude errors affect both projected velocity measurements and their associated uncertainty. When jointly applied, long-term error divergence is effectively suppressed. Field experimental results show that the proposed approach achieves a 78.3% improvement in 3D position RMSE and a 71.8% reduction in the maximum component-wise position error compared with the baseline IMU+DVL method, providing a robust solution for improving long-term SINS/DVL navigation performance.

</details>


### [66] [ALRM: Agentic LLM for Robotic Manipulation](https://arxiv.org/abs/2601.19510)
*Vitor Gaboardi dos Santos,Ibrahim Khadraoui,Ibrahim Farhat,Hamza Yous,Samy Teffahi,Hakim Hacid*

Main category: cs.RO

TL;DR: ALRM是一个基于大语言模型的机器人操控代理框架，通过ReAct式推理循环整合策略生成与代理执行，支持代码即策略和工具即策略两种模式，并引入包含56个任务的新仿真基准进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在机器人控制中存在两个主要限制：1）缺乏模块化、代理化的执行机制，无法实现闭环的计划-反思-修订；2）现有操控任务基准侧重于低级控制，未能系统评估多步推理和语言多样性。

Method: 提出ALRM框架，通过ReAct式推理循环整合策略生成与代理执行，支持两种互补模式：代码即策略（直接生成可执行控制代码）和工具即策略（迭代规划和基于工具的动作执行）。同时创建包含56个任务的新仿真基准，涵盖语言多样性指令。

Result: 在10个LLM上的实验表明，ALRM提供了可扩展、可解释、模块化的方法，能够桥接自然语言推理与可靠机器人执行。Claude-4.1-Opus在代码即策略模式下表现最佳（闭源模型），Falcon-H1-7B在开源模型中表现最好。

Conclusion: ALRM框架成功解决了现有LLM在机器人控制中的局限性，通过代理化执行机制和系统评估基准，为自然语言推理与机器人执行的结合提供了有效解决方案。

Abstract: Large Language Models (LLMs) have recently empowered agentic frameworks to exhibit advanced reasoning and planning capabilities. However, their integration in robotic control pipelines remains limited in two aspects: (1) prior \ac{llm}-based approaches often lack modular, agentic execution mechanisms, limiting their ability to plan, reflect on outcomes, and revise actions in a closed-loop manner; and (2) existing benchmarks for manipulation tasks focus on low-level control and do not systematically evaluate multistep reasoning and linguistic variation. In this paper, we propose Agentic LLM for Robot Manipulation (ALRM), an LLM-driven agentic framework for robotic manipulation. ALRM integrates policy generation with agentic execution through a ReAct-style reasoning loop, supporting two complementary modes: Code-asPolicy (CaP) for direct executable control code generation, and Tool-as-Policy (TaP) for iterative planning and tool-based action execution. To enable systematic evaluation, we also introduce a novel simulation benchmark comprising 56 tasks across multiple environments, capturing linguistically diverse instructions. Experiments with ten LLMs demonstrate that ALRM provides a scalable, interpretable, and modular approach for bridging natural language reasoning with reliable robotic execution. Results reveal Claude-4.1-Opus as the top closed-source model and Falcon-H1-7B as the top open-source model under CaP.

</details>


### [67] [PALM: Enhanced Generalizability for Local Visuomotor Policies via Perception Alignment](https://arxiv.org/abs/2601.19514)
*Ruiyu Wang,Zheyu Zhuang,Danica Kragic,Florian T. Pokorny*

Main category: cs.RO

TL;DR: PALM通过利用局部动作分布在OOD和演示域之间的不变性，同时处理工作空间偏移、视角变化和跨具身转移等OOD挑战，无需额外输入模态、模型修改或数据收集。


<details>
  <summary>Details</summary>
Motivation: 当前基于图像的行为克隆方法在泛化到训练域之外时面临挑战，现有方法通常单独处理工作空间偏移、视角变化或跨具身转移等特定泛化问题，且依赖复杂流程。需要一种能同时处理多种OOD偏移的通用方法。

Method: PALM将操作策略模块化为粗粒度全局组件和细粒度局部策略。通过强制局部视觉聚焦和一致的本体感受表示，减少域内和OOD输入在局部策略层面的差异，使策略能在OOD条件下检索不变的局部动作。

Result: 实验表明，PALM将OOD性能下降限制在模拟环境中8%、真实世界24%，而基线方法分别为45%和77%，显著提升了泛化能力。

Conclusion: PALM利用局部动作分布的不变性，有效解决了多种OOD偏移问题，为基于图像的行为克隆提供了更好的泛化能力，且无需额外输入或数据收集。

Abstract: Generalizing beyond the training domain in image-based behavior cloning remains challenging. Existing methods address individual axes of generalization, workspace shifts, viewpoint changes, and cross-embodiment transfer, yet they are typically developed in isolation and often rely on complex pipelines. We introduce PALM (Perception Alignment for Local Manipulation), which leverages the invariance of local action distributions between out-of-distribution (OOD) and demonstrated domains to address these OOD shifts concurrently, without additional input modalities, model changes, or data collection. PALM modularizes the manipulation policy into coarse global components and a local policy for fine-grained actions. We reduce the discrepancy between in-domain and OOD inputs at the local policy level by enforcing local visual focus and consistent proprioceptive representation, allowing the policy to retrieve invariant local actions under OOD conditions. Experiments show that PALM limits OOD performance drops to 8% in simulation and 24% in the real world, compared to 45% and 77% for baselines.

</details>


### [68] [Rhombot: Rhombus-shaped Modular Robots for Stable, Medium-Independent Reconfiguration Motion](https://arxiv.org/abs/2601.19529)
*Jie Gu,Yirui Sun,Zhihao Xia,Tin Lun Lam,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: Rhombot是一种新型可变形平面晶格模块化自重构机器人，采用菱形模块设计，通过单个中央执行器实现折叠/展开，具有形态变化、对接和运动能力，控制复杂度低。


<details>
  <summary>Details</summary>
Motivation: 开发一种具有最小控制复杂度的模块化自重构机器人系统，能够在不同环境中实现连续稳定的重构过程，同时保持形态变化、对接和运动等基本功能。

Method: 设计菱形模块，采用平行四边形骨架和单个中央执行器实现沿对角线折叠/展开；提出morphpivoting运动原语用于重构，并制定连续执行策略。

Result: 物理实验验证了模块的稳定重构能力、位置精度和对接精度，系统能够在不同环境中可靠形成各种配置。

Conclusion: Rhombot通过简单设计实现了模块化自重构机器人的基本功能，提出的morphpivoting运动原语和连续执行策略为系统提供了有效的重构能力。

Abstract: In this paper, we present Rhombot, a novel deformable planar lattice modular self-reconfigurable robot (MSRR) with a rhombus shaped module. Each module consists of a parallelogram skeleton with a single centrally mounted actuator that enables folding and unfolding along its diagonal. The core design philosophy is to achieve essential MSRR functionalities such as morphing, docking, and locomotion with minimal control complexity. This enables a continuous and stable reconfiguration process that is independent of the surrounding medium, allowing the system to reliably form various configurations in diverse environments. To leverage the unique kinematics of Rhombot, we introduce morphpivoting, a novel motion primitive for reconfiguration that differs from advanced MSRR systems, and propose a strategy for its continuous execution. Finally, a series of physical experiments validate the module's stable reconfiguration ability, as well as its positional and docking accuracy.

</details>


### [69] [Enhancing Inverse Perspective Mapping for Automatic Vectorized Road Map Generation](https://arxiv.org/abs/2601.19536)
*Hongji Liu,Linwei Zheng,Yongjian Li,Mingkai Tang,Xiaoyang Yan,Ming Liu,Jun Ma*

Main category: cs.RO

TL;DR: 提出基于增强逆透视映射的低成本矢量化道路制图框架，使用Catmull-Rom样条表征车道线，多边形表征地面标记，通过实例分割优化控制点三维位置和IPM矩阵，实现厘米级精度制图。


<details>
  <summary>Details</summary>
Motivation: 传统逆透视映射(IPM)在矢量化道路制图中存在映射误差大、需要手动校准、受限于共面假设等问题，需要低成本、高精度的自动化制图解决方案。

Method: 1) 使用Catmull-Rom样条表征车道线，多边形表征其他地面标记；2) 利用实例分割结果优化样条控制点和多边形角点的三维位置；3) 同时优化IPM单应矩阵和车辆位姿；4) 解决IPM的共面假设限制。

Result: 在两个实际场景中测试，能够自动生成厘米级精度的高精度地图，优化的IPM矩阵达到与手动校准相当的精度，车辆位姿精度显著提升，大幅减少IPM映射误差。

Conclusion: 提出的框架为矢量化道路制图提供了低成本、高精度的解决方案，扩展了IPM的应用范围，能够处理所有常见地面标记和车道线，实现了自动化高精度制图。

Abstract: In this study, we present a low-cost and unified framework for vectorized road mapping leveraging enhanced inverse perspective mapping (IPM). In this framework, Catmull-Rom splines are utilized to characterize lane lines, and all the other ground markings are depicted using polygons uniformly. The results from instance segmentation serve as references to refine the three-dimensional position of spline control points and polygon corner points. In conjunction with this process, the homography matrix of IPM and vehicle poses are optimized simultaneously. Our proposed framework significantly reduces the mapping errors associated with IPM. It also improves the accuracy of the initial IPM homography matrix and the predicted vehicle poses. Furthermore, it addresses the limitations imposed by the coplanarity assumption in IPM. These enhancements enable IPM to be effectively applied to vectorized road mapping, which serves a cost-effective solution with enhanced accuracy. In addition, our framework generalizes road map elements to include all common ground markings and lane lines. The proposed framework is evaluated in two different practical scenarios, and the test results show that our method can automatically generate high-precision maps with near-centimeter-level accuracy. Importantly, the optimized IPM matrix achieves an accuracy comparable to that of manual calibration, while the accuracy of vehicle poses is also significantly improved.

</details>


### [70] [AC^2-VLA: Action-Context-Aware Adaptive Computation in Vision-Language-Action Models for Efficient Robotic Manipulation](https://arxiv.org/abs/2601.19634)
*Wenda Yu,Tianshi Wang,Fengling Li,Jingjing Li,Lei Zhu*

Main category: cs.RO

TL;DR: AC²-VLA：一种基于动作上下文的自适应计算框架，通过认知重用、token剪枝和选择性执行来加速VLA模型，在保持任务成功率的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中表现出色，但闭环部署时存在高延迟和高计算成本问题，因为需要在每个时间步重复运行大型视觉语言骨干网络。现有效率方法忽略了动作上下文的重要性，而动作上下文在具身任务中起着核心作用。

Method: 提出AC²-VLA框架，基于当前视觉观察、语言指令和先前动作状态来条件化计算。通过统一机制自适应执行：1）跨时间步的认知重用；2）token剪枝；3）模型组件的选择性执行。采用动作引导的自蒸馏训练方案，在保持密集VLA策略行为的同时实现结构化稀疏化。

Result: 在机器人操作基准测试中，AC²-VLA实现了最高1.79倍的加速，将FLOPs降低到密集基线的29.4%，同时保持可比较的任务成功率。

Conclusion: AC²-VLA通过利用动作上下文实现自适应计算，有效解决了VLA模型在闭环部署中的效率瓶颈，为具身AI系统的高效部署提供了可行方案。

Abstract: Vision-Language-Action (VLA) models have demonstrated strong performance in robotic manipulation, yet their closed-loop deployment is hindered by the high latency and compute cost of repeatedly running large vision-language backbones at every timestep. We observe that VLA inference exhibits structured redundancies across temporal, spatial, and depth dimensions, and that most existing efficiency methods ignore action context, despite its central role in embodied tasks. To address this gap, we propose Action-Context-aware Adaptive Computation for VLA models (AC^2-VLA), a unified framework that conditions computation on current visual observations, language instructions, and previous action states. Based on this action-centric context, AC^2-VLA adaptively performs cognition reuse across timesteps, token pruning, and selective execution of model components within a unified mechanism. To train the adaptive policy, we introduce an action-guided self-distillation scheme that preserves the behavior of the dense VLA policy while enabling structured sparsification that transfers across tasks and settings. Extensive experiments on robotic manipulation benchmarks show that AC^2-VLA achieves up to a 1.79\times speedup while reducing FLOPs to 29.4% of the dense baseline, with comparable task success.

</details>


### [71] [Enhancing Worker Safety in Harbors Using Quadruped Robots](https://arxiv.org/abs/2601.19643)
*Zoe Betta,Davide Corongiu,Carmine Tommaso Recchiuto,Antonio Sgorbissa*

Main category: cs.RO

TL;DR: 港口基础设施检查的机器人解决方案初步研究，使用四足机器人识别和检查关键区域


<details>
  <summary>Details</summary>
Motivation: 基础设施检查对工人安全至关重要，港口环境复杂，日常操作多样，需要机器人解决方案来应对挑战

Method: 分两阶段：首先识别港口环境中的关键区域，然后分析使用四足机器人检查这些关键区域的初步解决方案

Result: 提出了港口基础设施检查的初步框架，包括关键区域识别和四足机器人应用分析

Conclusion: 四足机器人在港口基础设施检查中具有应用潜力，为复杂环境下的机器人检查方案提供了初步探索

Abstract: Infrastructure inspection is becoming increasingly relevant in the field of robotics due to its significant impact on ensuring workers' safety. The harbor environment presents various challenges in designing a robotic solution for inspection, given the complexity of daily operations. This work introduces an initial phase to identify critical areas within the port environment. Following this, a preliminary solution using a quadruped robot for inspecting these critical areas is analyzed.

</details>


### [72] [SCOPE: Smooth Convex Optimization for Planned Evolution of Deformable Linear Objects](https://arxiv.org/abs/2601.19742)
*Ali Jnadi,Hadi Salloum,Yaroslav Kholodov,Alexander Gasnikov,Karam Almaghout*

Main category: cs.RO

TL;DR: SCOPE是一个用于建模和操纵可变形线性物体的快速高效框架，使用凸近似替代传统能量方法，在保持物理合理性的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于能量的可变形线性物体建模方法计算成本高，难以满足实时或近实时应用需求，需要一种更高效的替代方案。

Method: 采用凸近似方法替代传统的能量最小化方法，在速度和精度之间取得平衡，同时保持平滑和物理合理的变形。

Result: 通过综合仿真实验验证了框架的有效性，展示了在几何和长度约束下生成平滑形状轨迹的能力。

Conclusion: SCOPE框架在计算效率和变形质量之间取得了良好平衡，特别适用于需要实时响应的应用场景。

Abstract: We present SCOPE, a fast and efficient framework for modeling and manipulating deformable linear objects (DLOs). Unlike conventional energy-based approaches, SCOPE leverages convex approximations to significantly reduce computational cost while maintaining smooth and physically plausible deformations. This trade-off between speed and accuracy makes the method particularly suitable for applications requiring real-time or near-real-time response. The effectiveness of the proposed framework is demonstrated through comprehensive simulation experiments, highlighting its ability to generate smooth shape trajectories under geometric and length constraints.

</details>


### [73] [Reimagining Social Robots as Recommender Systems: Foundations, Framework, and Applications](https://arxiv.org/abs/2601.19761)
*Jin Huang,Fethiye Irmak Doğan,Hatice Gunes*

Main category: cs.RO

TL;DR: 该论文提出将推荐系统技术整合到社交机器人中，以解决现有方法在全面捕捉用户偏好方面的不足，并建立了一个模块化框架来增强社交机器人的个性化能力。


<details>
  <summary>Details</summary>
Motivation: 现有社交机器人个性化方法（如大语言模型和强化学习）无法全面捕捉用户的长短期偏好和细粒度特征，也不能有效利用这些偏好进行动作排序选择、主动个性化交互和确保伦理适应性。

Method: 通过三个步骤整合推荐系统技术：(1) 对齐社交机器人和推荐系统的基本范式，(2) 识别能增强社交机器人个性化的关键技术，(3) 将这些技术设计为模块化、即插即用的组件。

Result: 建立了一个将推荐系统技术整合到社交机器人中的框架，为推荐系统和人机交互社区之间的深度合作开辟了途径，加速了两个领域的创新。

Conclusion: 推荐系统技术能有效解决社交机器人个性化中的关键挑战，提出的模块化框架为整合这些技术提供了坚实基础，促进了跨学科合作和个性化社交机器人的发展。

Abstract: Personalization in social robots refers to the ability of the robot to meet the needs and/or preferences of an individual user. Existing approaches typically rely on large language models (LLMs) to generate context-aware responses based on user metadata and historical interactions or on adaptive methods such as reinforcement learning (RL) to learn from users' immediate reactions in real time. However, these approaches fall short of comprehensively capturing user preferences-including long-term, short-term, and fine-grained aspects-, and of using them to rank and select actions, proactively personalize interactions, and ensure ethically responsible adaptations. To address the limitations, we propose drawing on recommender systems (RSs), which specialize in modeling user preferences and providing personalized recommendations. To ensure the integration of RS techniques is well-grounded and seamless throughout the social robot pipeline, we (i) align the paradigms underlying social robots and RSs, (ii) identify key techniques that can enhance personalization in social robots, and (iii) design them as modular, plug-and-play components. This work not only establishes a framework for integrating RS techniques into social robots but also opens a pathway for deep collaboration between the RS and HRI communities, accelerating innovation in both fields.

</details>


### [74] [Whether We Care, How We Reason: The Dual Role of Anthropomorphism and Moral Foundations in Robot Abuse](https://arxiv.org/abs/2601.19826)
*Fan Yang,Renkai Ma,Yaxin Hu,Lingyao Li*

Main category: cs.RO

TL;DR: 机器人拟人化程度和道德基础影响人们对机器人虐待的反应，拟人化决定是否给予道德关怀，道德基础影响推理方式


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入日常生活，理解人们对机器人虐待的反应具有重要的伦理和设计意义，需要研究拟人化水平和道德基础如何影响这种反应

Method: 混合方法研究(N=201)，参与者观看不同拟人化程度机器人(蜘蛛、双足、人形)被物理虐待的视频，测量道德基础、愤怒和社会距离，并进行定性分析

Result: 拟人化程度决定人们是否将道德关怀延伸至机器人，道德基础影响推理方式；低进步主义个体使用基于性格的判断，高进步主义个体进行面向未来的道德审议

Conclusion: 研究结果为机器人设计和政策沟通提供了启示，拟人化水平和道德基础共同塑造人们对机器人虐待的反应模式

Abstract: As robots become increasingly integrated into daily life, understanding responses to robot mistreatment carries important ethical and design implications. This mixed-methods study (N = 201) examined how anthropomorphic levels and moral foundations shape reactions to robot abuse. Participants viewed videos depicting physical mistreatment of robots varying in humanness (Spider, Twofoot, Humanoid) and completed measures assessing moral foundations, anger, and social distance. Results revealed that anthropomorphism determines whether people extend moral consideration to robots, while moral foundations shape how they reason about such consideration. Qualitative analysis revealed distinct reasoning patterns: low-progressivism individuals employed character-based judgments, while high-progressivism individuals engaged in future-oriented moral deliberation. Findings offer implications for robot design and policy communication.

</details>


### [75] [Information-Theoretic Detection of Bimanual Interactions for Dual-Arm Robot Plan Generation](https://arxiv.org/abs/2601.19832)
*Elena Merlo,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出一种基于单次RGB视频演示的双臂机器人任务规划方法，利用信息论分析手部协调策略，生成模块化行为树执行计划。


<details>
  <summary>Details</summary>
Motivation: 通过演示编程简化机器人编程过程，但双臂任务的采用因手部协调复杂性而受限，现有方法难以处理双臂协调问题。

Method: 使用单次RGB视频演示，应用香农信息论分析场景元素间的信息流，利用场景图属性检测手部协调策略，生成模块化行为树执行计划。

Result: 通过多个主题视频演示和外部公开数据集验证，相比现有方法在生成双臂系统集中执行计划方面有显著改进。

Conclusion: 该方法能有效从单次演示中提取双臂协调策略，生成模块化行为树，为双臂机器人任务规划提供新解决方案。

Abstract: Programming by demonstration is a strategy to simplify the robot programming process for non-experts via human demonstrations. However, its adoption for bimanual tasks is an underexplored problem due to the complexity of hand coordination, which also hinders data recording. This paper presents a novel one-shot method for processing a single RGB video of a bimanual task demonstration to generate an execution plan for a dual-arm robotic system. To detect hand coordination policies, we apply Shannon's information theory to analyze the information flow between scene elements and leverage scene graph properties. The generated plan is a modular behavior tree that assumes different structures based on the desired arms coordination. We validated the effectiveness of this framework through multiple subject video demonstrations, which we collected and made open-source, and exploiting data from an external, publicly available dataset. Comparisons with existing methods revealed significant improvements in generating a centralized execution plan for coordinating two-arm systems.

</details>


### [76] [HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs](https://arxiv.org/abs/2601.19839)
*Jeanne Malécot,Hamed Rahimi,Jeanne Cattoni,Marie Samson,Mouad Abrini,Mahdi Khoramshahi,Maribel Pino,Mohamed Chetouani*

Main category: cs.RO

TL;DR: HARMONI是一个基于大语言模型的多模态个性化框架，使社交辅助机器人能够在多用户环境中进行长期个性化交互，通过四个模块实现感知、世界建模、用户建模和响应生成。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互系统缺乏在多用户环境中持续个性化和动态适应的机制，限制了其在现实世界部署中的有效性，特别是在需要长期个性化交互的场景如养老院等。

Method: 框架包含四个核心模块：1）感知模块识别活跃说话者并提取多模态输入；2）世界建模模块维护环境和短期对话上下文表示；3）用户建模模块更新长期说话者特定档案；4）生成模块产生上下文相关且符合伦理的响应。

Result: 在四个数据集上的广泛评估和消融研究，以及在养老院环境中的真实场景用户研究表明，HARMONI在说话者识别、在线记忆更新和伦理对齐个性化方面表现优异，在用户建模准确性、个性化质量和用户满意度方面优于基线LLM驱动方法。

Conclusion: HARMONI框架通过整合多模态感知、上下文建模和长期用户档案，实现了在多用户环境中持续、个性化和伦理对齐的人机交互，为社交辅助机器人在现实世界部署提供了有效解决方案。

Abstract: Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.

</details>


### [77] [Estimating Trust in Human-Robot Collaboration through Behavioral Indicators and Explainability](https://arxiv.org/abs/2601.19856)
*Giulio Campagna,Marta Lagomarsino,Marta Lorenzini,Dimitrios Chrysostomou,Matthias Rehm,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出基于行为指标的数据驱动框架评估人机协作中的信任度，在化工场景测试中机器学习模型分类准确率超80%


<details>
  <summary>Details</summary>
Motivation: 工业5.0强调以人为中心的人机协作，需要确保安全、舒适和信任。现有研究缺乏有效评估人机信任的方法，特别是基于行为指标的客观评估框架。

Method: 开发数据驱动框架：1) 使用基于偏好的优化算法根据操作员反馈生成增强信任的轨迹；2) 将反馈作为真实标签训练机器学习模型，从行为指标预测信任水平；3) 在化工混合场景中测试框架。

Result: 机器学习模型分类信任度准确率超过80%，其中投票分类器达到84.07%准确率和0.90的AUC-ROC分数，证明行为指标能有效预测人机信任动态。

Conclusion: 数据驱动方法能有效评估人机协作中的信任，行为指标在预测人类信任动态方面具有重要价值，为工业5.0的人机协作系统设计提供了实用框架。

Abstract: Industry 5.0 focuses on human-centric collaboration between humans and robots, prioritizing safety, comfort, and trust. This study introduces a data-driven framework to assess trust using behavioral indicators. The framework employs a Preference-Based Optimization algorithm to generate trust-enhancing trajectories based on operator feedback. This feedback serves as ground truth for training machine learning models to predict trust levels from behavioral indicators. The framework was tested in a chemical industry scenario where a robot assisted a human operator in mixing chemicals. Machine learning models classified trust with over 80\% accuracy, with the Voting Classifier achieving 84.07\% accuracy and an AUC-ROC score of 0.90. These findings underscore the effectiveness of data-driven methods in assessing trust within human-robot collaboration, emphasizing the valuable role behavioral indicators play in predicting the dynamics of human trust.

</details>
