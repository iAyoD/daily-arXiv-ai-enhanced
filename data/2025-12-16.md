<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 67]
- [cs.RO](#cs.RO) [Total: 62]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Urban Visual Place Recognition for Crowdsourced Flood Imagery via LLM-Guided Attention](https://arxiv.org/abs/2512.11811)
*Fengyi Xu,Jun Ma,Waishan Qiu,Cui Guo*

Main category: cs.CL

TL;DR: VPR-AttLLM是一个模型无关框架，通过LLM的语义推理和地理空间知识增强视觉地点识别，提升社交媒体洪水图像检索性能，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 社交媒体街景图像提供实时城市洪水等危机事件的视觉证据，但缺乏可靠的地理元数据。现有视觉地点识别模型在跨源场景中因视觉扭曲和领域偏移而性能显著下降。

Method: 提出VPR-AttLLM框架，将大型语言模型的语义推理和地理空间知识通过注意力引导的描述符增强集成到现有VPR流程中，利用LLM识别城市背景中的位置信息区域并抑制瞬态视觉噪声。

Result: 在扩展基准测试中，将VPR-AttLLM与三种SOTA VPR模型集成，召回性能一致提升，相对增益通常在1-3%，在最具挑战性的真实洪水图像上可达8%。

Conclusion: VPR-AttLLM为LLM引导的多模态融合在视觉检索系统中建立了可推广范式，将城市感知理论嵌入注意力机制，连接人类空间推理与现代VPR架构，具有即插即用设计、强跨源鲁棒性和可解释性。

Abstract: Crowdsourced street-view imagery from social media provides valuable real-time visual evidence of urban flooding and other crisis events, yet it often lacks reliable geographic metadata for emergency response. Existing Visual Place Recognition (VPR) models exhibit substantial performance degradation when applied to such imagery due to visual distortions and domain shifts inherent in cross-source scenarios. This paper presents VPR-AttLLM, a model-agnostic framework that integrates the semantic reasoning and geospatial knowledge of Large Language Models (LLMs) into established VPR pipelines through attention-guided descriptor enhancement. By leveraging LLMs to identify location-informative regions within the city context and suppress transient visual noise, VPR-AttLLM improves retrieval performance without requiring model retraining or additional data. Comprehensive evaluations are conducted on extended benchmarks including SF-XL enriched with real social-media flood images, synthetic flooding scenarios over established query sets and Mapillary photos, and a new HK-URBAN dataset capturing morphologically distinct cityscapes. Integrating VPR-AttLLM with three state-of-the-art VPR models-CosPlace, EigenPlaces, and SALAD-consistently improves recall performance, yielding relative gains typically between 1-3% and reaching up to 8% on the most challenging real flood imagery. Beyond measurable gains in retrieval accuracy, this study establishes a generalizable paradigm for LLM-guided multimodal fusion in visual retrieval systems. By embedding principles from urban perception theory into attention mechanisms, VPR-AttLLM bridges human-like spatial reasoning with modern VPR architectures. Its plug-and-play design, strong cross-source robustness, and interpretability highlight its potential for scalable urban monitoring and rapid geo-localization of crowdsourced crisis imagery.

</details>


### [2] [Reinforcement Learning for Latent-Space Thinking in LLMs](https://arxiv.org/abs/2512.11816)
*Enes Özeren,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 该论文研究了潜在空间思维方法的局限性，发现即使使用强化学习优化，在数学推理任务上仍无法超越传统的语言空间思维链方法。


<details>
  <summary>Details</summary>
Motivation: 传统思维链方法使用离散语言空间进行推理效率低下，因为许多生成的token只是执行语言规则而非推理所需。潜在空间思维使用连续嵌入空间进行思考，但现有方法在复杂任务（如数学推理）上表现不佳。

Method: 研究了监督微调方法Coconut的局限性，并探索了强化学习技术（包括GRPO和设计的新型Latent RL方法）来直接优化潜在思维步骤。

Result: 实验结果显示，即使使用强化学习训练的模型，在数学推理领域仍然落后于传统的语言空间思维链模型。

Conclusion: 潜在空间思维方法在复杂推理任务上仍存在根本性挑战，需要进一步研究来克服这些限制。

Abstract: Chain-of-Thought (CoT) reasoning typically utilizes the discrete language space for thinking, which is inherently inefficient, as many generated tokens only enforce linguistic rules that are not required for reasoning. To bypass this, latent-space thinking allows models to think using the continuous embedding space. While existing methods for training those models show domain-specific gains, they fail to maintain performance in complex tasks, such as mathematical reasoning. We experimentally demonstrate that the Coconut approach, a form of supervised fine-tuning for latent-space thinking, is highly sensitive to design choices and exhibits several inherent limitations. To address these issues, we investigate reinforcement learning (RL) techniques -- an underexplored direction in latent-space thinking -- including GRPO and design a novel Latent RL method for directly optimizing the latent thinking steps. Our experimental results reveal that these RL-trained models still lag behind traditional language-space CoT models in the mathematical reasoning domain. We make our codebase publicly available.

</details>


### [3] [KH-FUNSD: A Hierarchical and Fine-Grained Layout Analysis Dataset for Low-Resource Khmer Business Document](https://arxiv.org/abs/2512.11849)
*Nimol Thuon,Jun Du*

Main category: cs.CL

TL;DR: KH-FUNSD是首个公开可用的高棉语表单文档理解数据集，包含收据、发票和报价单，采用三级标注框架支持布局分析和信息提取。


<details>
  <summary>Details</summary>
Motivation: 高棉语作为柬埔寨超过1700万人使用的语言，在文档AI工具开发中受到较少关注，特别是商业文档资源严重缺乏，而这类文档对公共管理和私营企业都至关重要。

Method: 提出三级标注框架：1)区域检测（划分文档核心区域如页眉、表单字段、页脚）；2)FUNSD风格标注（区分问题、答案、标题等实体及其关系）；3)细粒度分类（分配具体语义角色如字段标签、值、页眉、页脚、符号）。

Result: 建立了首个公开可用的高棉语商业文档数据集KH-FUNSD，为多个领先模型提供了基准测试结果，首次为高棉语商业文档建立了基线性能。

Conclusion: KH-FUNSD填补了低资源非拉丁文字文档AI工具的空白，支持全面的布局分析和精确的信息提取，为高棉语商业文档处理提供了重要资源。

Abstract: Automated document layout analysis remains a major challenge for low-resource, non-Latin scripts. Khmer is a language spoken daily by over 17 million people in Cambodia, receiving little attention in the development of document AI tools. The lack of dedicated resources is particularly acute for business documents, which are critical for both public administration and private enterprise. To address this gap, we present \textbf{KH-FUNSD}, the first publicly available, hierarchically annotated dataset for Khmer form document understanding, including receipts, invoices, and quotations. Our annotation framework features a three-level design: (1) region detection that divides each document into core zones such as header, form field, and footer; (2) FUNSD-style annotation that distinguishes questions, answers, headers, and other key entities, together with their relationships; and (3) fine-grained classification that assigns specific semantic roles, such as field labels, values, headers, footers, and symbols. This multi-level approach supports both comprehensive layout analysis and precise information extraction. We benchmark several leading models, providing the first set of baseline results for Khmer business documents, and discuss the distinct challenges posed by non-Latin, low-resource scripts. The KH-FUNSD dataset and documentation will be available at URL.

</details>


### [4] [Direct Confidence Alignment: Aligning Verbalized Confidence with Internal Confidence In Large Language Models](https://arxiv.org/abs/2512.11998)
*Glenn Zhang,Treasure Mayowa,Jason Fan,Yicheng Fu,Aaron Sandoval,Sean O'Brien,Kevin Zhu*

Main category: cs.CL

TL;DR: 提出Direct Confidence Alignment (DCA)方法，使用直接偏好优化对齐大语言模型的言语化置信度与内部置信度，而非真实准确率，以增强模型透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用日益广泛，构建可信可靠的模型变得愈发重要。研究发现模型内部置信度（来自token概率）与言语化置信度不一致，导致不同校准方法产生误导性结果，需要解决这种不一致性。

Method: 提出Direct Confidence Alignment (DCA)方法，使用Direct Preference Optimization技术来对齐LLM的言语化置信度与内部置信度，而非与真实准确率对齐。同时引入了三种新的基于校准误差的评估指标。

Result: DCA在某些模型架构上改善了置信度对齐指标，减少了模型置信度表达的不一致性。但在其他模型上效果有限，表明需要更针对具体模型的校准方法。

Conclusion: DCA方法能有效改善某些LLM的置信度对齐，增强模型透明度和可靠性。但该方法在不同模型架构上的效果存在差异，强调了在追求更可解释和可信的LLM时需要更关注模型特性的方法。

Abstract: Producing trustworthy and reliable Large Language Models (LLMs) has become increasingly important as their usage becomes more widespread. Calibration seeks to achieve this by improving the alignment between the model's confidence and the actual likelihood of its responses being correct or desirable. However, it has been observed that the internal confidence of a model, derived from token probabilities, is not well aligned with its verbalized confidence, leading to misleading results with different calibration methods. In this paper, we propose Direct Confidence Alignment (DCA), a method using Direct Preference Optimization to align an LLM's verbalized confidence with its internal confidence rather than ground-truth accuracy, enhancing model transparency and reliability by ensuring closer alignment between the two confidence measures. We evaluate DCA across multiple open-weight LLMs on a wide range of datasets. To further assess this alignment, we also introduce three new calibration error-based metrics. Our results show that DCA improves alignment metrics on certain model architectures, reducing inconsistencies in a model's confidence expression. However, we also show that it can be ineffective on others, highlighting the need for more model-aware approaches in the pursuit of more interpretable and trustworthy LLMs.

</details>


### [5] [Hold Onto That Thought: Assessing KV Cache Compression On Reasoning](https://arxiv.org/abs/2512.12008)
*Minghui Liu,Aadi Palnitkar,Tahseen Rabbani,Hyunwoo Jae,Kyle Rui Sang,Dixi Yao,Shayan Shabihi,Fuheng Zhao,Tian Li,Ce Zhang,Furong Huang,Kunpeng Zhang*

Main category: cs.CL

TL;DR: 评估多种KV缓存压缩策略在长推理任务上的性能，发现对于推理模型，H2O和SnapKV的变体是最佳策略，揭示了缓存大小与推理成本之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文任务中表现出色，但受限于KV缓存线性增长的存储瓶颈。现有压缩策略主要针对预填充阶段，很少评估在需要长解码的推理任务上的性能，特别是像GSM8K和MATH500这样的短但复杂的提示，会产生数千token的推理序列。

Method: 在长推理任务上对多种流行的压缩策略进行基准测试，包括H2O和SnapKV的解码启用变体，分析不同策略在不同数据集类型上的表现，并研究低预算下的驱逐策略对推理轨迹长度的影响。

Result: 对于非推理模型Llama-3.1-8B-Instruct，没有单一策略适合所有情况，性能受数据集类型影响很大。对于推理模型，H2O和SnapKV的解码启用变体是主导策略，表明重击者跟踪对推理轨迹很有用。低预算下的驱逐策略可以产生更长的推理轨迹，揭示了缓存大小与推理成本之间的权衡。

Conclusion: KV缓存压缩策略的选择需要根据模型类型和任务特性进行调整，对于推理任务，基于重击者跟踪的策略（如H2O和SnapKV变体）表现最佳，同时需要在缓存大小和推理成本之间找到平衡点。

Abstract: Large language models (LLMs) have demonstrated remarkable performance on long-context tasks, but are often bottlenecked by memory constraints. Namely, the KV cache, which is used to significantly speed up attention computations, grows linearly with context length. A suite of compression algorithms has been introduced to alleviate cache growth by evicting unimportant tokens. However, several popular strategies are targeted towards the prefill phase, i.e., processing long prompt context, and their performance is rarely assessed on reasoning tasks requiring long decoding. In particular, short but complex prompts, such as those in benchmarks like GSM8K and MATH500, often benefit from multi-step reasoning and self-reflection, resulting in thinking sequences thousands of tokens long. In this work, we benchmark the performance of several popular compression strategies on long-reasoning tasks. For the non-reasoning Llama-3.1-8B-Instruct, we determine that no singular strategy fits all, and that performance is heavily influenced by dataset type. However, we discover that H2O and our decoding-enabled variant of SnapKV are dominant strategies for reasoning models, indicating the utility of heavy-hitter tracking for reasoning traces. We also find that eviction strategies at low budgets can produce longer reasoning traces, revealing a tradeoff between cache size and inference costs.

</details>


### [6] [Benchmarking Contextual Understanding for In-Car Conversational Systems](https://arxiv.org/abs/2512.12042)
*Philipp Habicht,Lev Sorokin,Abdullah Saydemir,Ken E. Friedl,Andrea Stocco*

Main category: cs.CL

TL;DR: 本文探索使用LLM评估车载对话问答系统的准确性，通过多种提示技术和代理方法测试13个不同规模的LLM，发现推理模型表现最佳，DeepSeek-R1达到F1分数0.99，而非推理模型DeepSeek-V3在效果与成本效率间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 车载对话问答系统能提升用户体验，但评估其准确性和可靠性仍具挑战。传统人工评估成本高且难以扩展，需要开发自动化的评估方法来测试系统响应是否符合用户意图和上下文理解。

Method: 使用LLM结合多种提示技术（输入输出、思维链、自洽性提示）和代理方法（单代理、多代理）评估车载ConvQA系统。通过合成生成用户话语及正确/包含错误的系统响应，在餐厅推荐案例中测试13个不同规模和提供商的LLM。

Result: 推理模型始终优于非推理模型，最佳性能来自单代理自洽性提示，DeepSeek-R1达到F1分数0.99（每次请求成本0.002美元）。非推理模型中，DeepSeek-V3在效果与成本时间效率间达到最佳平衡。多代理提示对小规模非推理模型提升最大。

Conclusion: LLM评估为车载ConvQA系统的上下文理解基准测试提供了可扩展且准确的替代方案，优于传统人工评估。推理模型表现最佳，但非推理模型在成本效率方面更具优势，DeepSeek-V3是平衡效果与效率的最佳选择。

Abstract: In-Car Conversational Question Answering (ConvQA) systems significantly enhance user experience by enabling seamless voice interactions. However, assessing their accuracy and reliability remains a challenge. This paper explores the use of Large Language Models (LLMs) alongside advanced prompting techniques and agent-based methods to evaluate the extent to which ConvQA system responses adhere to user utterances. The focus lies on contextual understanding and the ability to provide accurate venue recommendations considering user constraints and situational context. To evaluate utterance-response coherence using an LLM, we synthetically generate user utterances accompanied by correct and modified failure-containing system responses. We use input-output, chain-of-thought, self-consistency prompting, and multi-agent prompting techniques with 13 reasoning and non-reasoning LLMs of varying sizes and providers, including OpenAI, DeepSeek, Mistral AI, and Meta. We evaluate our approach on a case study involving restaurant recommendations. The most substantial improvements occur for small non-reasoning models when applying advanced prompting techniques, particularly multi-agent prompting. However, reasoning models consistently outperform non-reasoning models, with the best performance achieved using single-agent prompting with self-consistency. Notably, DeepSeek-R1 reaches an F1-score of 0.99 at a cost of 0.002 USD per request. Overall, the best balance between effectiveness and cost-time efficiency is reached with the non-reasoning model DeepSeek-V3. Our findings show that LLM-based evaluation offers a scalable and accurate alternative to traditional human evaluation for benchmarking contextual understanding in ConvQA systems.

</details>


### [7] [VOYAGER: A Training Free Approach for Generating Diverse Datasets using LLMs](https://arxiv.org/abs/2512.12072)
*Avinash Amballa,Yashas Malur Saidutta,Chi-Heng Lin,Vivek Kulkarni,Srinivas Chappidi*

Main category: cs.CL

TL;DR: Voyager是一种基于行列式点过程的迭代方法，用于生成多样化的LLM合成数据集，无需训练且适用于闭源模型，能提升1.5-3倍的多样性。


<details>
  <summary>Details</summary>
Motivation: 当前使用大型语言模型生成合成数据集的方法存在多样性不足的问题，这限制了数据集在下游模型评估和训练中的有效性。

Method: 提出Voyager方法：基于行列式点过程的迭代优化框架，直接优化数据集的数学多样性度量，无需训练且适用于闭源模型。

Result: Voyager在多样性方面显著优于现有基线方法，提供1.5-3倍的多样性提升，并通过综合实验验证了其有效性。

Conclusion: Voyager为生成多样化的LLM合成数据集提供了一种原则性的、可扩展的解决方案，解决了现有方法多样性不足的问题。

Abstract: Large language models (LLMs) are increasingly being used to generate synthetic datasets for the evaluation and training of downstream models. However, prior work has noted that such generated data lacks diversity. In this paper, we propose Voyager, a novel principled approach to generate diverse datasets. Our approach is iterative and directly optimizes a mathematical quantity that optimizes the diversity of the dataset using the machinery of determinantal point processes. Furthermore, our approach is training-free, applicable to closed-source models, and scalable. In addition to providing theoretical justification for the working of our method, we also demonstrate through comprehensive experiments that Voyager significantly outperforms popular baseline approaches by providing a 1.5-3x improvement in diversity.

</details>


### [8] [BLASST: Dynamic BLocked Attention Sparsity via Softmax Thresholding](https://arxiv.org/abs/2512.12087)
*Jiayi Yuan,Cameron Shinn,Kai Xu,Jingze Cui,George Klimiashvili,Guangxuan Xiao,Perkz Zheng,Bo Li,Yuxin Zhou,Zhouhai Ye,Weijie You,Tian Zheng,Dominic Brown,Pengbo Wang,Richard Cai,Julien Demouth,John D. Owens,Xia Hu,Song Han,Timmy Liu,Huizi Mao*

Main category: cs.CL

TL;DR: BLASST是一种无需预计算的动态稀疏注意力方法，通过固定阈值和在线softmax信息识别可忽略的注意力分数，跳过相关计算，实现长上下文推理加速。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型对长上下文推理需求的增长，标准注意力机制的计算和内存瓶颈日益突出，需要高效的稀疏注意力解决方案。

Method: 使用固定阈值和在线softmax的现有信息动态剪枝注意力矩阵，跳过可忽略注意力分数的softmax计算、Value块加载和矩阵乘法，无缝集成到FlashAttention内核设计中。

Result: 在现代GPU上，预填充阶段达到74.7%稀疏度时实现1.62倍加速，解码阶段达到73.2%稀疏度时实现1.48倍加速，同时保持高精度。

Conclusion: BLASST为长上下文推理提供了统一的加速解决方案，适用于所有注意力变体，并通过稀疏感知训练进一步提升精度-稀疏度边界。

Abstract: The growing demand for long-context inference capabilities in Large Language Models (LLMs) has intensified the computational and memory bottlenecks inherent to the standard attention mechanism. To address this challenge, we introduce BLASST, a drop-in sparse attention method that dynamically prunes the attention matrix without any pre-computation or proxy scores. Our method uses a fixed threshold and existing information from online softmax to identify negligible attention scores, skipping softmax computation, Value block loading, and the subsequent matrix multiplication. This fits seamlessly into existing FlashAttention kernel designs with negligible latency overhead. The approach is applicable to both prefill and decode stages across all attention variants (MHA, GQA, MQA, and MLA), providing a unified solution for accelerating long-context inference. We develop an automated calibration procedure that reveals a simple inverse relationship between optimal threshold and context length, enabling robust deployment across diverse scenarios. Maintaining high accuracy, we demonstrate a 1.62x speedup for prefill at 74.7% sparsity and a 1.48x speedup for decode at 73.2% sparsity on modern GPUs. Furthermore, we explore sparsity-aware training as a natural extension, showing that models can be trained to be inherently more robust to sparse attention patterns, pushing the accuracy-sparsity frontier even further.

</details>


### [9] [Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings](https://arxiv.org/abs/2512.12167)
*Yoav Gelberg,Koshi Eguchi,Takuya Akiba,Edoardo Cetin*

Main category: cs.CL

TL;DR: DroPE方法通过训练后丢弃位置嵌入，实现了语言模型的无微调零样本上下文扩展，突破了传统需要昂贵长上下文微调的限制。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要通过昂贵的微调来扩展语言模型的上下文长度，这成为一个关键瓶颈。作者发现位置嵌入在训练时很重要，但过度依赖它阻碍了模型对未见长度序列的泛化能力。

Method: 提出DroPE方法：在预训练后丢弃位置嵌入，经过短暂的重新校准阶段，使模型能够适应无位置嵌入的推理。该方法简单有效，无需长上下文微调。

Result: DroPE实现了无缝的零样本上下文扩展，不损害模型在原始训练上下文中的能力。在不同模型和数据集规模上都表现优异，远超之前的专门架构和旋转位置嵌入缩放方法。

Conclusion: 位置嵌入不是语言建模的内在要求，可以在预训练后安全移除。DroPE方法突破了上下文扩展的关键瓶颈，为语言模型的长上下文应用提供了简单有效的解决方案。

Abstract: So far, expensive finetuning beyond the pretraining sequence length has been a requirement for effectively extending the context of language models (LM). In this work, we break this key bottleneck by Dropping the Positional Embeddings of LMs after training (DroPE). Our simple method is motivated by three key theoretical and empirical observations. First, positional embeddings (PEs) serve a crucial role during pretraining, providing an important inductive bias that significantly facilitates convergence. Second, over-reliance on this explicit positional information is also precisely what prevents test-time generalization to sequences of unseen length, even when using popular PE-scaling methods. Third, positional embeddings are not an inherent requirement of effective language modeling and can be safely removed after pretraining, following a short recalibration phase. Empirically, DroPE yields seamless zero-shot context extension without any long-context finetuning, quickly adapting pretrained LMs without compromising their capabilities in the original training context. Our findings hold across different models and dataset sizes, far outperforming previous specialized architectures and established rotary positional embedding scaling methods.

</details>


### [10] [Diffusion Language Model Inference with Monte Carlo Tree Search](https://arxiv.org/abs/2512.12168)
*Zheng Huang,Kiran Ramnath,Yueyan Chen,Aosong Feng,Sangmin Woo,Balasubramaniam Srinivasan,Zhichao Xu,Kang Zhou,Shuai Wang,Haibo Ding,Lin Lee Cheong*

Main category: cs.CL

TL;DR: MEDAL框架将蒙特卡洛树搜索集成到扩散语言模型推理的初始化阶段，通过探索有前景的解码路径来提升推理性能，在多个基准测试中比现有方法提升达22.0%。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然具有并行生成和全局连贯性的优势，但在推理过程中确定哪些位置去掩码以及选择哪些标记是一个巨大的组合搜索问题。现有方法要么使用启发式近似（效果欠佳），要么依赖额外训练来指导标记选择，缺乏原则性的搜索机制。

Method: MEDAL框架在扩散语言模型推理的初始化阶段集成蒙特卡洛树搜索，通过限制搜索空间到高置信度动作，并优先选择能提高剩余掩码位置模型置信度的标记，探索有前景的去掩码轨迹，为后续细化提供稳健的起点。

Result: 在多个基准测试中，MEDAL相比现有的推理策略实现了高达22.0%的性能提升，为扩散语言模型建立了基于搜索推理的新范式。

Conclusion: MEDAL通过将蒙特卡洛树搜索集成到扩散语言模型推理中，提供了一种原则性的搜索机制，显著提升了推理性能，为扩散语言模型的推理优化开辟了新方向。

Abstract: Diffusion language models (DLMs) have recently emerged as a compelling alternative to autoregressive generation, offering parallel generation and improved global coherence. During inference, DLMs generate text by iteratively denoising masked sequences in parallel; however, determining which positions to unmask and which tokens to commit forms a large combinatorial search problem. Existing inference methods approximate this search using heuristics, which often yield suboptimal decoding paths; other approaches instead rely on additional training to guide token selection. To introduce a principled search mechanism for DLMs inference, we introduce MEDAL, a framework that integrates Monte Carlo Tree SEarch initialization for Diffusion LAnguage Model inference. We employ Monte Carlo Tree Search at the initialization stage to explore promising unmasking trajectories, providing a robust starting point for subsequent refinement. This integration is enabled by restricting the search space to high-confidence actions and prioritizing token choices that improve model confidence over remaining masked positions. Across multiple benchmarks, MEDAL achieves up to 22.0% improvement over existing inference strategies, establishing a new paradigm for search-based inference in diffusion language models.

</details>


### [11] [Semantic Distance Measurement based on Multi-Kernel Gaussian Processes](https://arxiv.org/abs/2512.12238)
*Yinzhu Cheng,Haihua Xie,Yaqing Wang,Miao He,Mingming Sun*

Main category: cs.CL

TL;DR: 提出基于多核高斯过程的语义距离度量方法，通过数据驱动的核参数学习替代传统固定方法，在细粒度情感分类任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统语义距离方法通常是固定的，难以适应特定数据分布和任务需求，需要更灵活、可自适应学习的数据驱动方法。

Method: 提出基于多核高斯过程的语义距离度量：将文本的潜在语义函数建模为高斯过程，使用结合Matérn核和多项式核的组合核函数，通过监督学习自动从数据中学习核参数。

Result: 在基于大语言模型的上下文学习设置下的细粒度情感分类任务中，实验结果表明所提出的语义距离度量方法有效。

Conclusion: 多核高斯过程方法能够通过数据驱动的方式学习语义距离，相比传统固定方法更具适应性和灵活性，在文本语义分析任务中表现出良好性能。

Abstract: Semantic distance measurement is a fundamental problem in computational linguistics, providing a quantitative characterization of similarity or relatedness between text segments, and underpinning tasks such as text retrieval and text classification. From a mathematical perspective, a semantic distance can be viewed as a metric defined on a space of texts or on a representation space derived from them. However, most classical semantic distance methods are essentially fixed, making them difficult to adapt to specific data distributions and task requirements. In this paper, a semantic distance measure based on multi-kernel Gaussian processes (MK-GP) was proposed. The latent semantic function associated with texts was modeled as a Gaussian process, with its covariance function given by a combined kernel combining Matérn and polynomial components. The kernel parameters were learned automatically from data under supervision, rather than being hand-crafted. This semantic distance was instantiated and evaluated in the context of fine-grained sentiment classification with large language models under an in-context learning (ICL) setup. The experimental results demonstrated the effectiveness of the proposed measure.

</details>


### [12] [Adversarially Probing Cross-Family Sound Symbolism in 27 Languages](https://arxiv.org/abs/2512.12245)
*Anika Sharma,Tianyi Niu,Emma Wrenn,Shashank Srivastava*

Main category: cs.CL

TL;DR: 首次大规模跨语言计算分析声音象征性在尺寸语义域的表现，发现语音形式能预测尺寸含义，且存在跨语系的声音象征性偏差


<details>
  <summary>Details</summary>
Motivation: 声音象征性（语音与意义的非任意映射）长期通过Bouba Kiki等轶事实验验证，但缺乏大规模系统性研究。本文旨在填补这一空白，首次在尺寸语义域进行跨语言计算分析

Method: 收集27种语言共810个形容词（每种语言30词），进行音位转写并用母语者音频验证。使用基于音段袋特征的可解释分类器，并训练对抗性擦除器来抑制语言身份同时保留尺寸信号

Result: 音位形式能显著预测尺寸语义，元音和辅音均有贡献。对抗性擦除后，语言预测降至机会水平以下，而尺寸预测仍显著高于机会水平，表明存在跨语系的声音象征性偏差

Conclusion: 研究证实了跨语言的声音象征性模式，特别是在尺寸语义域。提供了数据、代码和诊断工具，支持未来大规模象似性研究

Abstract: The phenomenon of sound symbolism, the non-arbitrary mapping between word sounds and meanings, has long been demonstrated through anecdotal experiments like Bouba Kiki, but rarely tested at scale. We present the first computational cross-linguistic analysis of sound symbolism in the semantic domain of size. We compile a typologically broad dataset of 810 adjectives (27 languages, 30 words each), each phonemically transcribed and validated with native-speaker audio. Using interpretable classifiers over bag-of-segment features, we find that phonological form predicts size semantics above chance even across unrelated languages, with both vowels and consonants contributing. To probe universality beyond genealogy, we train an adversarial scrubber that suppresses language identity while preserving size signal (also at family granularity). Language prediction averaged across languages and settings falls below chance while size prediction remains significantly above chance, indicating cross-family sound-symbolic bias. We release data, code, and diagnostic tools for future large-scale studies of iconicity.

</details>


### [13] [Market-Bench: Evaluating Large Language Models on Introductory Quantitative Trading and Market Dynamics](https://arxiv.org/abs/2512.12264)
*Abhay Srivastava,Sam Jung,Spencer Mateega*

Main category: cs.CL

TL;DR: MARKET-BENCH是一个评估大语言模型在量化交易任务上表现的基准测试，要求模型根据自然语言策略描述构建可执行的回测器，测试结果显示当前LLM能够搭建基本交易框架但在价格、库存和风险推理方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在金融领域的应用评估缺乏系统性，特别是在量化交易这种需要精确代码生成和金融推理的任务上。需要建立一个标准化的基准来评估LLM在将自然语言交易策略转化为可执行回测代码方面的能力。

Method: 创建MARKET-BENCH基准，包含三种经典交易策略：微软的定时交易、可口可乐和百事的配对交易、微软的Delta对冲。模型需要根据自然语言描述生成可执行代码，其盈亏、回撤和持仓路径必须与参考实现匹配。使用多轮pass@k指标评估，区分结构可靠性（代码能否运行）和数值准确性（回测指标的均方误差）。

Result: 评估了12个最先进的模型：大多数模型能可靠执行最简单的策略（平均pass@3为0.80），但不同模型和任务间的误差差异巨大。Gemini 3 Pro和Claude 4.5 Sonnet在简单策略上结合了强可靠性和低误差；GPT-5.1 Codex-Max在前两个策略上达到完美pass@1，在最简单任务上获得最低最佳运行误差；Qwen3 Max达到完美pass@3但有时产生不准确的盈亏路径。

Conclusion: 当前的大语言模型能够搭建基本的交易基础设施框架，但在价格、库存和风险方面的稳健推理能力仍然不足。研究团队发布了MARKET-BENCH基准和公开排行榜，以促进该领域的发展。

Abstract: We introduce MARKET-BENCH, a benchmark that evaluates large language models (LLMs) on introductory quantitative trading tasks by asking them to construct executable backtesters from natural-language strategy descriptions and market assumptions. Each instance specifies one of three canonical strategies -- scheduled trading on Microsoft (NASDAQ: MSFT), pairs trading on Coca-Cola (NASDAQ: KO) and Pepsi (NASDAQ: PEP), or delta hedging on MSFT -- and models must produce code whose P\&L, drawdown, and position paths match a verifiable reference implementation. We assess twelve state-of-the-art models using a multi-round pass@k metric that separates structural reliability (whether the backtest runs) from numerical accuracy (mean absolute error of the backtest metrics). While most models reliably execute the simplest strategy (average pass@3 of 0.80), errors vary by orders of magnitude across models and tasks: Gemini 3 Pro and Claude 4.5 Sonnet combine strong reliability with low error on simpler strategies, GPT-5.1 Codex-Max achieves perfect pass@1 on the first two strategies and the lowest best-run error on the easiest task, and Qwen3 Max attains perfect pass@3 yet sometimes produces inaccurate P\&L paths. These results show that current LLMs can scaffold basic trading infrastructure but still struggle to reason robustly about prices, inventory, and risk; we release MARKET-BENCH and a public leaderboard at https://marketbench.ai.

</details>


### [14] [F5-TTS-RO: Extending F5-TTS to Romanian TTS via Lightweight Input Adaptation](https://arxiv.org/abs/2512.12297)
*Radu-Gabriel Chivereanu,Tiberiu Boros*

Main category: cs.CL

TL;DR: 为F5-TTS模型引入轻量级输入适配器，支持罗马尼亚语，同时保持原有语音克隆、英语和中文能力。


<details>
  <summary>Details</summary>
Motivation: 扩展F5-TTS模型以支持罗马尼亚语，同时保持其原有的语音克隆、英语和中文能力，避免重新训练整个模型。

Method: 冻结原始模型权重，在文本编码器的文本嵌入矩阵后添加子网络，使用ConvNeXt模块建模新字符级嵌入的依赖关系，作为"软"字母到声音转换层。

Result: 模型保持了语音克隆能力，能在一定程度上实现罗马尼亚语-英语代码切换，但仍有残留的英语口音特征。

Conclusion: 轻量级输入适配器有效扩展了F5-TTS对罗马尼亚语的支持，同时保留了原有功能，为多语言TTS扩展提供了可行方案。

Abstract: This work introduces a lightweight input-level adapter for the F5-TTS model that enables Romanian Language support. To preserve the existing capabilities of the model (voice cloning, English and Chinese support), we keep the original weights frozen, append a sub-network to the model and train it as an extension for the textual embedding matrix of the text encoder. For simplicity, we rely on ConvNeXt module implemented in F5-TTS to also model the co-dependencies between the new character-level embeddings. The module serves as a ``soft`` letter-to-sound layer, converting Romanian text into a continuous representation that the F5-TTS model uses to produce naturally sounding Romanian utterances. We evaluate the model with a pool of 20 human listeners across three tasks: (a) audio similarity between reference and generated speech, (b) pronunciation and naturalness and (c) Romanian-English code-switching. The results indicate that our approach maintains voice cloning capabilities and enables, to a certain extent, code-switching within the same utterance; however, residual English accent characteristics remain. We open-source our code and provide example audio samples at https://github.com/racai-ro/Ro-F5TTS.

</details>


### [15] [SCIR: A Self-Correcting Iterative Refinement Framework for Enhanced Information Extraction Based on Schema](https://arxiv.org/abs/2512.12337)
*Yushen Fang,Jianjun Li,Mingqian Ding,Chang Liu,Xinchi Zou,Wenqi Yang*

Main category: cs.CL

TL;DR: 提出SCIR框架和MBSC数据集，通过自校正迭代优化降低LLM信息抽取的训练成本并提升性能


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的信息抽取系统存在两个主要问题：1）训练成本高；2）难以与LLM偏好对齐。需要一种更高效、更灵活的解决方案。

Method: 提出SCIR（自校正迭代优化）框架，包含双路径自校正模块和反馈驱动优化，实现与现有LLM和IE系统的即插即用兼容。同时构建MBSC（多任务双语自校正）数据集，包含10万+条目，通过间接蒸馏GPT-4能力来对齐偏好。

Result: SCIR在命名实体识别、关系抽取和事件抽取三个关键任务上优于现有最佳方法，span-based Micro-F1平均提升5.27%，同时训练成本比基线方法降低87%。

Conclusion: SCIR框架和MBSC数据集不仅提升了IE系统的灵活性和准确性，还为轻量级、高效的IE范式开辟了新途径。

Abstract: Although Large language Model (LLM)-powered information extraction (IE) systems have shown impressive capabilities, current fine-tuning paradigms face two major limitations: high training costs and difficulties in aligning with LLM preferences. To address these issues, we propose a novel universal IE paradigm, the Self-Correcting Iterative Refinement (SCIR) framework, along with a Multi-task Bilingual (Chinese-English) Self-Correcting (MBSC) dataset containing over 100,000 entries. The SCIR framework achieves plug-and-play compatibility with existing LLMs and IE systems through its Dual-Path Self-Correcting module and feedback-driven optimization, thereby significantly reducing training costs. Concurrently, the MBSC dataset tackles the challenge of preference alignment by indirectly distilling GPT-4's capabilities into IE result detection models. Experimental results demonstrate that SCIR outperforms state-of-the-art IE methods across three key tasks: named entity recognition, relation extraction, and event extraction, achieving a 5.27 percent average improvement in span-based Micro-F1 while reducing training costs by 87 percent compared to baseline approaches. These advancements not only enhance the flexibility and accuracy of IE systems but also pave the way for lightweight and efficient IE paradigms.

</details>


### [16] [Can GPT replace human raters? Validity and reliability of machine-generated norms for metaphors](https://arxiv.org/abs/2512.12444)
*Veronica Mangiaterra,Hamad Al-Azary,Chiara Barattieri di San Pietro,Paolo Canal,Valentina Bambini*

Main category: cs.CL

TL;DR: 评估GPT模型在生成隐喻属性评分（熟悉度、可理解性、形象性）方面的有效性和可靠性，发现较大模型与人类评分有良好相关性，并能预测行为反应，但处理常规性和多模态隐喻时表现较差。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在科学研究中的应用增加，其可信度问题变得至关重要。在心理语言学中，LLMs已被用于自动扩充人类评分数据集，但在复杂项目（如隐喻）的评分性能尚未探索。

Method: 使用三个GPT模型对687个来自意大利比喻档案和三个英语研究的隐喻项目生成熟悉度、可理解性和形象性评分。通过与人数据对齐度、预测行为和电生理反应能力进行全面验证。

Result: 机器生成评分与人类评分呈正相关：熟悉度评分在英语和意大利语隐喻中达到中等到强相关（高感觉运动负荷隐喻相关减弱）；形象性在英语中中等相关，意大利语中中等到强相关；英语隐喻可理解性相关最强。较大模型表现更好，机器评分能显著预测反应时间和EEG振幅，与人类评分预测强度相当。GPT评分在不同会话间高度稳定。

Conclusion: GPT（尤其是较大模型）可以有效可靠地替代或增强人类被试进行隐喻属性评分。但当处理隐喻意义的常规性和多模态方面时，LLMs与人类对齐较差，需要仔细考虑刺激性质。

Abstract: As Large Language Models (LLMs) are increasingly being used in scientific research, the issue of their trustworthiness becomes crucial. In psycholinguistics, LLMs have been recently employed in automatically augmenting human-rated datasets, with promising results obtained by generating ratings for single words. Yet, performance for ratings of complex items, i.e., metaphors, is still unexplored. Here, we present the first assessment of the validity and reliability of ratings of metaphors on familiarity, comprehensibility, and imageability, generated by three GPT models for a total of 687 items gathered from the Italian Figurative Archive and three English studies. We performed a thorough validation in terms of both alignment with human data and ability to predict behavioral and electrophysiological responses. We found that machine-generated ratings positively correlated with human-generated ones. Familiarity ratings reached moderate-to-strong correlations for both English and Italian metaphors, although correlations weakened for metaphors with high sensorimotor load. Imageability showed moderate correlations in English and moderate-to-strong in Italian. Comprehensibility for English metaphors exhibited the strongest correlations. Overall, larger models outperformed smaller ones and greater human-model misalignment emerged with familiarity and imageability. Machine-generated ratings significantly predicted response times and the EEG amplitude, with a strength comparable to human ratings. Moreover, GPT ratings obtained across independent sessions were highly stable. We conclude that GPT, especially larger models, can validly and reliably replace - or augment - human subjects in rating metaphor properties. Yet, LLMs align worse with humans when dealing with conventionality and multimodal aspects of metaphorical meaning, calling for careful consideration of the nature of stimuli.

</details>


### [17] [Large language models have learned to use language](https://arxiv.org/abs/2512.12447)
*Gary Lupyan*

Main category: cs.CL

TL;DR: 论文主张承认大语言模型已学会使用语言，这能开启语言科学突破，但需要放弃一些传统评估观念并接受后图灵测试时代


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在语言能力方面取得了显著进展，但传统语言科学评估方法可能已不适应新时代，需要重新思考如何评估语言知识

Method: 通过哲学和理论分析，提出需要放弃某些长期持有的语言知识评估观念，承认后图灵测试时代的到来

Result: 认识到大语言模型已真正学会使用语言，这为语言科学突破提供了新的可能性，但需要相应的理论和方法论转变

Conclusion: 为了在语言科学领域取得突破，必须接受大语言模型已具备语言能力的事实，并相应调整评估框架和研究范式，迎接后图灵测试时代

Abstract: Acknowledging that large language models have learned to use language can open doors to breakthrough language science. Achieving these breakthroughs may require abandoning some long-held ideas about how language knowledge is evaluated and reckoning with the difficult fact that we have entered a post-Turing test era.

</details>


### [18] [The American Ghost in the Machine: How language models align culturally and the effects of cultural prompting](https://arxiv.org/abs/2512.12488)
*James Luther,Donald Brown*

Main category: cs.CL

TL;DR: 研究使用VSM13国际调查和霍夫斯泰德文化维度分析主流大语言模型的文化对齐性，发现多数模型默认偏向美国文化，通过文化提示可以调整模型向目标文化对齐，但对中国和日本文化的对齐效果较差。


<details>
  <summary>Details</summary>
Motivation: 随着生成式大语言模型在人机交互领域的广泛应用，模型的文化对齐性变得至关重要。不同文化背景的用户需要模型能够理解和适应其文化价值观，但目前缺乏对主流LLM文化对齐性的系统性研究。

Method: 使用VSM13国际调查和霍夫斯泰德文化维度框架，评估DeepSeek-V3、GPT-5、Claude Opus 4等8个主流LLM的文化对齐性。通过文化提示技术，测试模型向中国、法国、印度、伊朗、日本和美国等目标文化调整的能力。

Result: 1. 未指定文化时，多数模型默认偏向美国文化；2. 使用文化提示后，8个模型中有7个能够向目标文化对齐；3. 模型对中国和日本文化的对齐效果较差，即使DeepSeek模型源自中国公司也表现不佳。

Conclusion: 大语言模型存在明显的文化偏向性，但可以通过提示工程进行调整。然而，模型对某些特定文化（特别是中国和日本）的适应能力有限，表明需要更深入的文化对齐研究和模型优化。

Abstract: Culture is the bedrock of human interaction; it dictates how we perceive and respond to everyday interactions. As the field of human-computer interaction grows via the rise of generative Large Language Models (LLMs), the cultural alignment of these models become an important field of study. This work, using the VSM13 International Survey and Hofstede's cultural dimensions, identifies the cultural alignment of popular LLMs (DeepSeek-V3, V3.1, GPT-5, GPT-4.1, GPT-4, Claude Opus 4, Llama 3.1, and Mistral Large). We then use cultural prompting, or using system prompts to shift the cultural alignment of a model to a desired country, to test the adaptability of these models to other cultures, namely China, France, India, Iran, Japan, and the United States. We find that the majority of the eight LLMs tested favor the United States when the culture is not specified, with varying results when prompted for other cultures. When using cultural prompting, seven of the eight models shifted closer to the expected culture. We find that models had trouble aligning with Japan and China, despite two of the models tested originating with the Chinese company DeepSeek.

</details>


### [19] [NagaNLP: Bootstrapping NLP for Low-Resource Nagamese Creole with Human-in-the-Loop Synthetic Data](https://arxiv.org/abs/2512.12537)
*Agniva Maiti,Manya Pandey,Murari Mandal*

Main category: cs.CL

TL;DR: NagaNLP是一个针对低资源语言Nagamese的开源NLP工具包，通过LLM生成+人工验证的合成数据方法构建了首个高质量数据集，并训练了SOTA的POS、NER和对话模型。


<details>
  <summary>Details</summary>
Motivation: 世界上大多数语言（特别是像Nagamese这样的克里奥尔语）在NLP领域严重缺乏资源，这阻碍了它们在数字技术中的代表性。需要为这些低资源语言开发可复现的解决方案。

Method: 采用专家指导的LLM（Gemini）生成候选语料库，然后由母语者进行精炼和标注的多阶段合成-混合方法。生成了10K对话对数据集和高质量标注语料库，用于训练判别式模型（XLM-RoBERTa-base）和生成式模型（Llama-3.2-3B）。

Result: XLM-RoBERTa-base模型在POS标注上达到93.81%准确率（0.90 F1-Macro），NER达到0.75 F1-Macro，大幅超越零样本基线。NagaLLaMA对话模型困惑度达到3.85，比少样本版本（96.76）提升了一个数量级。

Conclusion: NagaNLP为Nagamese提供了首个全面的NLP资源，同时为其他低资源语言提供了一个可复现的减少数据稀缺性的框架。所有数据集、模型和代码均已开源。

Abstract: The vast majority of the world's languages, particularly creoles like Nagamese, remain severely under-resourced in Natural Language Processing (NLP), creating a significant barrier to their representation in digital technology. This paper introduces NagaNLP, a comprehensive open-source toolkit for Nagamese, bootstrapped through a novel methodology that relies on LLM-driven but human-validated synthetic data generation. We detail a multi-stage pipeline where an expert-guided LLM (Gemini) generates a candidate corpus, which is then refined and annotated by native speakers. This synthetic-hybrid approach yielded a 10K pair conversational dataset and a high-quality annotated corpus for foundational tasks. To assess the effectiveness of our methodology, we trained both discriminative and generative models. Our fine-tuned XLM-RoBERTa-base model establishes a new benchmark for Nagamese, achieving a 93.81\% accuracy (0.90 F1-Macro) on Part-of-Speech tagging and a 0.75 F1-Macro on Named Entity Recognition, massively outperforming strong zero-shot baselines. Furthermore, we fine-tuned a Llama-3.2-3B Instruct model, named NagaLLaMA, which demonstrates superior performance on conversational tasks, achieving a Perplexity of 3.85, an order of magnitude improvement over its few-shot counterpart (96.76). We release the NagaNLP toolkit, including all datasets, models, and code, providing a foundational resource for a previously underserved language and a reproducible framework for reducing data scarcity in other low-resource contexts.

</details>


### [20] [HyperEdit: Unlocking Instruction-based Text Editing in LLMs via Hypernetworks](https://arxiv.org/abs/2512.12544)
*Yiming Zeng,Jinghan Cao,Zexin Li,Wanhao Yu,Zhankai Ye,Dawei Xiang,Ting Hua,Xin Liu,Shangqian Gao,Tingting Yu*

Main category: cs.CL

TL;DR: HyperEdit：基于超网络的动态适应和差异感知正则化方法，显著提升指令文本编辑性能，在修改区域比现有方法提升9%-30% BLEU分数


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在指令文本编辑任务中表现不佳，将编辑视为通用文本生成导致两个关键问题：难以忠实对齐用户意图，以及过度编辑未改变区域。这在代码编辑器等实际应用中尤为关键，因为即使是微小意外修改也可能破坏功能。

Method: 1. 基于超网络的动态适应：生成请求特定的参数，使模型能够根据每个指令定制编辑策略；2. 差异感知正则化：将监督集中在修改的文本片段上，防止过度编辑同时确保精确的最小化更改。

Result: HyperEdit在修改区域上比最先进的基线方法相对提升9%-30% BLEU分数，尽管仅使用30亿参数。

Conclusion: HyperEdit通过超网络动态适应和差异感知正则化，有效解决了指令文本编辑中的意图对齐和过度编辑问题，显著提升了编辑性能。

Abstract: Instruction-based text editing is increasingly critical for real-world applications such as code editors (e.g., Cursor), but Large Language Models (LLMs) continue to struggle with this task. Unlike free-form generation, editing requires faithfully implementing user instructions while preserving unchanged content, as even minor unintended modifications can break functionality. Existing approaches treat editing as generic text generation, leading to two key failures: they struggle to faithfully align edits with diverse user intents, and they often over-edit unchanged regions. We propose HyperEdit to address both issues. First, we introduce hypernetwork-based dynamic adaptation that generates request-specific parameters, enabling the model to tailor its editing strategy to each instruction. Second, we develop difference-aware regularization that focuses supervision on modified spans, preventing over-editing while ensuring precise, minimal changes. HyperEdit achieves a 9%--30% relative improvement in BLEU on modified regions over state-of-the-art baselines, despite utilizing only 3B parameters.

</details>


### [21] [Coupled Variational Reinforcement Learning for Language Model General Reasoning](https://arxiv.org/abs/2512.12576)
*Xueru Wen,Jie Lou,Yanjiang Liu,Hongyu Lin,Ben He,Xianpei Han,Le Sun,Yaojie Lu,Debing Zhang*

Main category: cs.CL

TL;DR: CoVRL提出了一种结合变分推断和强化学习的耦合变分强化学习方法，通过混合采样策略连接先验和后验分布，在无需验证器的情况下提升语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有无需验证器的强化学习方法通常仅基于问题采样推理轨迹，导致推理轨迹与最终答案分离，造成探索效率低下和轨迹-答案不一致的问题。

Method: CoVRL通过构建和优化整合先验和后验分布的复合分布，采用混合采样策略耦合这两个分布，实现高效探索并保持思维-答案一致性。

Result: 在数学和通用推理基准测试中，CoVRL相比基础模型性能提升12.4%，相比现有无需验证器的强化学习方法额外提升2.3%。

Conclusion: CoVRL为增强语言模型的通用推理能力提供了一个原则性框架，通过耦合变分推断和强化学习解决了现有方法在探索效率和一致性方面的局限性。

Abstract: While reinforcement learning have achieved impressive progress in language model reasoning, they are constrained by the requirement for verifiable rewards. Recent verifier-free RL methods address this limitation by utilizing the intrinsic probabilities of LLMs generating reference answers as reward signals. However, these approaches typically sample reasoning traces conditioned only on the question. This design decouples reasoning-trace sampling from answer information, leading to inefficient exploration and incoherence between traces and final answers. In this paper, we propose \textit{\b{Co}upled \b{V}ariational \b{R}einforcement \b{L}earning} (CoVRL), which bridges variational inference and reinforcement learning by coupling prior and posterior distributions through a hybrid sampling strategy. By constructing and optimizing a composite distribution that integrates these two distributions, CoVRL enables efficient exploration while preserving strong thought-answer coherence. Extensive experiments on mathematical and general reasoning benchmarks show that CoVRL improves performance by 12.4\% over the base model and achieves an additional 2.3\% improvement over strong state-of-the-art verifier-free RL baselines, providing a principled framework for enhancing the general reasoning capabilities of language models.

</details>


### [22] [Human-Inspired Learning for Large Language Models via Obvious Record and Maximum-Entropy Method Discovery](https://arxiv.org/abs/2512.12608)
*Hong Su*

Main category: cs.CL

TL;DR: 提出一种受人类学习启发的框架，通过显式记忆存储和最大熵方法发现机制，解决LLMs在罕见、低资源场景下的学习问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理罕见、低资源或未见过的场景时表现不佳，因为这些情况在训练数据中稀疏；同时LLMs主要依赖隐式参数记忆，限制了它们显式获取、回忆和精炼方法的能力，使其更像是直觉驱动的预测器而非方法导向的学习者。

Method: 提出两种互补机制：1) Obvious Record：显式存储因果（或问题-解决方案）关系作为符号记忆，支持从单次或罕见遭遇中持续学习；2) Maximum-Entropy Method Discovery：优先保留语义差异度高的方法，捕捉通常被下一个token预测忽略的多样化和代表性不足的策略。

Result: 在包含60个语义多样化问题-解决方案对的基准测试中，提出的熵引导方法比随机基线实现了更强的未见问题覆盖率和显著更高的内部多样性，证实了其在发现更通用和人类启发方法方面的有效性。

Conclusion: 该人类启发学习框架通过结合显式记忆存储和最大熵方法发现，有效解决了LLMs在罕见场景下的学习限制，使其能够从稀疏数据中学习并捕捉多样化策略，从而更像人类学习者而非单纯的预测器。

Abstract: Large Language Models (LLMs) excel at extracting common patterns from large-scale corpora, yet they struggle with rare, low-resource, or previously unseen scenarios-such as niche hardware deployment issues or irregular IoT device behaviors-because such cases are sparsely represented in training data. Moreover, LLMs rely primarily on implicit parametric memory, which limits their ability to explicitly acquire, recall, and refine methods, causing them to behave predominantly as intuition-driven predictors rather than deliberate, method-oriented learners. Inspired by how humans learn from rare experiences, this paper proposes a human-inspired learning framework that integrates two complementary mechanisms. The first, Obvious Record, explicitly stores cause--result (or question--solution) relationships as symbolic memory, enabling persistent learning even from single or infrequent encounters. The second, Maximum-Entropy Method Discovery, prioritizes and preserves methods with high semantic dissimilarity, allowing the system to capture diverse and underrepresented strategies that are typically overlooked by next-token prediction. Verification on a benchmark of 60 semantically diverse question--solution pairs demonstrates that the proposed entropy-guided approach achieves stronger coverage of unseen questions and significantly greater internal diversity than a random baseline, confirming its effectiveness in discovering more generalizable and human-inspired methods.

</details>


### [23] [StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning](https://arxiv.org/abs/2512.12613)
*Yucan Guo,Saiping Guan,Miao Su,Zeya Zhao,Xiaolong Jin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: 提出StruProKGR框架，通过距离引导路径收集和概率路径聚合，解决稀疏知识图谱推理中路径质量不一和结构信息利用不足的问题，在效果和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的知识图谱往往是稀疏的，现有基于路径的推理方法存在两个主要问题：1) 依赖计算密集的随机游走收集路径，路径质量参差不齐；2) 将路径独立处理，未能充分利用图的结构信息。

Method: 提出StruProKGR框架，包含两个核心组件：1) 距离引导的路径收集机制，显著降低计算成本并探索更相关的路径；2) 概率路径聚合，通过结构信息增强推理过程，优先考虑相互强化的路径。

Result: 在五个稀疏知识图谱推理基准测试上的广泛实验表明，StruProKGR在效果和效率上都超越了现有的基于路径的方法。

Conclusion: StruProKGR为稀疏知识图谱推理提供了一个有效、高效且可解释的解决方案，通过结合结构信息和概率方法解决了现有路径方法的局限性。

Abstract: Sparse Knowledge Graphs (KGs) are commonly encountered in real-world applications, where knowledge is often incomplete or limited. Sparse KG reasoning, the task of inferring missing knowledge over sparse KGs, is inherently challenging due to the scarcity of knowledge and the difficulty of capturing relational patterns in sparse scenarios. Among all sparse KG reasoning methods, path-based ones have attracted plenty of attention due to their interpretability. Existing path-based methods typically rely on computationally intensive random walks to collect paths, producing paths of variable quality. Additionally, these methods fail to leverage the structured nature of graphs by treating paths independently. To address these shortcomings, we propose a Structural and Probabilistic framework named StruProKGR, tailored for efficient and interpretable reasoning on sparse KGs. StruProKGR utilizes a distance-guided path collection mechanism to significantly reduce computational costs while exploring more relevant paths. It further enhances the reasoning process by incorporating structural information through probabilistic path aggregation, which prioritizes paths that reinforce each other. Extensive experiments on five sparse KG reasoning benchmarks reveal that StruProKGR surpasses existing path-based methods in both effectiveness and efficiency, providing an effective, efficient, and interpretable solution for sparse KG reasoning.

</details>


### [24] [Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives](https://arxiv.org/abs/2512.12620)
*Aheli Poddar,Saptarshi Sahoo,Sujata Ghosh*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型在演绎推理方面的能力，从逻辑和自然语言两个角度分析了14个LLM的三段论推理表现，发现虽然推理能力并非所有模型的普遍特性，但某些模型的完美符号推理表现引发了关于LLM是否正在成为形式推理机制而非模拟人类推理的思考。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索大型语言模型的基本推理能力，特别是三段论推理能力，从逻辑推理和自然语言理解两个维度评估LLM的推理表现，并了解该研究领域的发展方向。

Method: 使用14个大型语言模型，通过符号推理和自然语言理解两个维度来评估它们的三段论推理能力，分析模型在逻辑推理任务上的表现。

Result: 研究发现三段论推理能力并非所有LLM的普遍涌现特性，但某些模型在符号推理方面表现出完美性能，这引发了关于LLM是否正在演变为形式推理机制而非模拟人类推理细微差别的疑问。

Conclusion: LLM的三段论推理能力存在模型间差异，某些模型展现出强大的形式推理能力，这可能表明LLM正在向形式推理机制发展，而非完全模拟人类推理的复杂性。

Abstract: We study syllogistic reasoning in LLMs from the logical and natural language perspectives. In process, we explore fundamental reasoning capabilities of the LLMs and the direction this research is moving forward. To aid in our studies, we use 14 large language models and investigate their syllogistic reasoning capabilities in terms of symbolic inferences as well as natural language understanding. Even though this reasoning mechanism is not a uniform emergent property across LLMs, the perfect symbolic performances in certain models make us wonder whether LLMs are becoming more and more formal reasoning mechanisms, rather than making explicit the nuances of human reasoning.

</details>


### [25] [Which Pieces Does Unigram Tokenization Really Need?](https://arxiv.org/abs/2512.12641)
*Sander Land,Yuval Pinter*

Main category: cs.CL

TL;DR: 本文提供了Unigram分词算法的清晰实现指南，并提出了一种更简单的替代算法，在略微增加训练损失的同时提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: Unigram分词算法虽然理论上优雅，但实际实现复杂，限制了其在SentencePiece包之外的采用。本文旨在弥合理论与实践的差距。

Method: 提供了Unigram算法的清晰实现指南和参数选择建议，同时提出了一种更简单的替代算法，该算法接受稍高的训练损失以换取更好的压缩效果。

Result: 提出的简化算法在略微增加训练损失的情况下实现了更好的压缩效率，为实际应用提供了更实用的选择。

Conclusion: 通过提供清晰的实现指南和更简单的替代算法，本文使Unigram分词算法更易于实际应用，促进了该算法在更广泛场景中的采用。

Abstract: The Unigram tokenization algorithm offers a probabilistic alternative to the greedy heuristics of Byte-Pair Encoding. Despite its theoretical elegance, its implementation in practice is complex, limiting its adoption to the SentencePiece package and adapters thereof. We bridge this gap between theory and practice by providing a clear guide to implementation and parameter choices. We also identify a simpler algorithm that accepts slightly higher training loss in exchange for improved compression.

</details>


### [26] [LexRel: Benchmarking Legal Relation Extraction for Chinese Civil Cases](https://arxiv.org/abs/2512.12643)
*Yida Cai,Ranjuexiao Hu,Huiyuan Xie,Chenyang Li,Yun Liu,Yuxiao Ye,Zhenghao Liu,Weixing Shen,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 本文提出了LexRel，一个用于中文民事法律关系提取的专家标注基准，并评估了LLMs在该任务上的表现，发现当前模型在识别民事法律关系方面存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 法律关系是民法体系的重要分析框架，但在法律AI领域，中文民事案件的法律关系研究不足，主要原因是缺乏全面的模式定义。

Method: 首先引入包含层次分类和论据定义的综合模式，然后基于此模式制定法律关系提取任务，创建LexRel专家标注基准，并用其评估最先进的LLMs。

Result: 当前LLMs在准确识别民事法律关系方面存在显著局限性，但将法律关系信息整合到其他下游法律AI任务中能带来一致的性能提升。

Conclusion: 法律关系提取是法律AI的重要任务，LexRel基准为评估和改进模型提供了基础，未来需要开发更专业的法律AI系统来处理复杂的法律关系。

Abstract: Legal relations form a highly consequential analytical framework of civil law system, serving as a crucial foundation for resolving disputes and realizing values of the rule of law in judicial practice. However, legal relations in Chinese civil cases remain underexplored in the field of legal artificial intelligence (legal AI), largely due to the absence of comprehensive schemas. In this work, we firstly introduce a comprehensive schema, which contains a hierarchical taxonomy and definitions of arguments, for AI systems to capture legal relations in Chinese civil cases. Based on this schema, we then formulate legal relation extraction task and present LexRel, an expert-annotated benchmark for legal relation extraction in Chinese civil law. We use LexRel to evaluate state-of-the-art large language models (LLMs) on legal relation extractions, showing that current LLMs exhibit significant limitations in accurately identifying civil legal relations. Furthermore, we demonstrate that incorporating legal relations information leads to consistent performance gains on other downstream legal AI tasks.

</details>


### [27] [Modeling Authorial Style in Urdu Novels Using Character Interaction Graphs and Graph Neural Networks](https://arxiv.org/abs/2512.12654)
*Hassan Mujtaba,Hamza Naveed,Hanzlah Munir*

Main category: cs.CL

TL;DR: 提出基于图的框架，将乌尔都语小说建模为角色互动网络，通过叙事结构分析作者风格，在52部小说数据集上达到0.857准确率


<details>
  <summary>Details</summary>
Motivation: 传统作者分析主要关注文本的词汇和风格特征，而更高层次的叙事结构研究不足，特别是对于乌尔都语等低资源语言。需要探索是否仅从叙事结构就能推断作者风格。

Method: 提出基于图的框架，将乌尔都语小说建模为角色互动网络：节点对应角色，边表示在叙事邻近范围内的共现。系统比较多种图表示方法，包括全局结构特征、节点级语义摘要、无监督图嵌入和监督图神经网络。

Result: 在7位作者撰写的52部乌尔都语小说数据集上，学习的图表示显著优于手工制作和无监督基线方法，在严格的作者感知评估协议下达到0.857的准确率。

Conclusion: 叙事结构确实包含作者风格信息，基于图的表示方法能够有效捕捉这些特征，为低资源语言的作者分析提供了新视角。

Abstract: Authorship analysis has traditionally focused on lexical and stylistic cues within text, while higher-level narrative structure remains underexplored, particularly for low-resource languages such as Urdu. This work proposes a graph-based framework that models Urdu novels as character interaction networks to examine whether authorial style can be inferred from narrative structure alone. Each novel is represented as a graph where nodes correspond to characters and edges denote their co-occurrence within narrative proximity. We systematically compare multiple graph representations, including global structural features, node-level semantic summaries, unsupervised graph embeddings, and supervised graph neural networks. Experiments on a dataset of 52 Urdu novels written by seven authors show that learned graph representations substantially outperform hand-crafted and unsupervised baselines, achieving up to 0.857 accuracy under a strict author-aware evaluation protocol.

</details>


### [28] [Fine-Tuning Causal LLMs for Text Classification: Embedding-Based vs. Instruction-Based Approaches](https://arxiv.org/abs/2512.12677)
*Amirhossein Yousefiramandi,Ciaran Cooney*

Main category: cs.CL

TL;DR: 本文探索在资源受限下微调仅解码器LLM进行文本分类的高效策略，比较了嵌入分类头微调和指令微调两种方法，发现嵌入方法在F1分数上显著优于指令微调，且能与领域特定模型竞争。


<details>
  <summary>Details</summary>
Motivation: 在计算资源受限的情况下，如何高效地微调大型语言模型（LLM）进行下游文本分类任务，探索不同微调策略的性能差异和实用性。

Method: 研究两种微调策略：1) 在预训练因果LLM上附加分类头，使用最终token嵌入作为序列表示进行微调；2) 以提示->响应格式对LLM进行指令微调进行分类。采用4位模型量化和低秩适应（LoRA）实现单GPU上最高8B参数模型的参数高效训练。

Result: 在两个数据集（专有单标签数据集和公开WIPO-Alpha专利数据集）上的实验表明，基于嵌入的方法在F1分数上显著优于指令微调方法，并且与在相同任务上微调的领域特定模型（如BERT）相比非常有竞争力，甚至在某些情况下超越它们。

Conclusion: 直接利用因果LLM的内部表示，结合高效的微调技术，在有限计算资源下能实现令人印象深刻的分类性能。研究讨论了每种方法的优势，并为分类场景中优化LLM微调提供了实用指南和未来方向。

Abstract: We explore efficient strategies to fine-tune decoder-only Large Language Models (LLMs) for downstream text classification under resource constraints. Two approaches are investigated: (1) attaching a classification head to a pre-trained causal LLM and fine-tuning on the task (using the LLM's final token embedding as a sequence representation), and (2) instruction-tuning the LLM in a prompt->response format for classification. To enable single-GPU fine-tuning of models up to 8B parameters, we combine 4-bit model quantization with Low-Rank Adaptation (LoRA) for parameter-efficient training. Experiments on two datasets - a proprietary single-label dataset and the public WIPO-Alpha patent dataset (extreme multi-label classification) - show that the embedding-based method significantly outperforms the instruction-tuned method in F1-score, and is very competitive with - even surpassing - fine-tuned domain-specific models (e.g. BERT) on the same tasks. These results demonstrate that directly leveraging the internal representations of causal LLMs, along with efficient fine-tuning techniques, yields impressive classification performance under limited computational resources. We discuss the advantages of each approach while outlining practical guidelines and future directions for optimizing LLM fine-tuning in classification scenarios.

</details>


### [29] [CoDA: A Context-Decoupled Hierarchical Agent with Reinforcement Learning](https://arxiv.org/abs/2512.12716)
*Xuanzhang Liu,Jianglun Feng,Zhuoran Zhuang,Junzhe Zhao,Maofei Que,Jieting Li,Dianlei Wang,Hao Tong,Ye Chen,Pan Li*

Main category: cs.CL

TL;DR: CoDA是一个上下文解耦的分层智能体框架，通过将高层规划与低层执行分离来缓解LLM智能体中的"上下文爆炸"问题，使用单一共享LLM在不同上下文角色中操作，通过PECO强化学习方法联合优化，在复杂任务中显著提升性能并保持长上下文稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM智能体在强化学习中面临的"上下文爆炸"问题——长文本输出积累会淹没模型的上下文窗口，导致推理失败。现有方法在复杂多步任务中性能受限，需要更有效的上下文管理策略。

Method: 提出CoDA（Context-Decoupled hierarchical Agent）框架：1）使用单一共享LLM在不同上下文角色中操作：高层规划器在简洁战略上下文中分解任务，低层执行器在临时隔离工作空间中处理工具交互；2）采用PECO（Planner-Executor Co-Optimization）强化学习方法，通过轨迹级奖励联合优化两个角色，实现上下文依赖的策略更新。

Result: 在复杂多跳问答基准测试中显著优于现有最优基线；在长上下文场景中表现出强鲁棒性，当所有其他基线性能严重下降时仍能保持稳定性能，验证了分层设计在缓解上下文过载方面的有效性。

Conclusion: CoDA通过上下文解耦的分层设计有效解决了LLM智能体的上下文爆炸问题，实现了高层规划与低层执行的分离优化，为复杂多步任务提供了稳定高效的解决方案，展示了分层架构在长上下文场景中的优势。

Abstract: Large Language Model (LLM) agents trained with reinforcement learning (RL) show great promise for solving complex, multi-step tasks. However, their performance is often crippled by "Context Explosion", where the accumulation of long text outputs overwhelms the model's context window and leads to reasoning failures. To address this, we introduce CoDA, a Context-Decoupled hierarchical Agent, a simple but effective reinforcement learning framework that decouples high-level planning from low-level execution. It employs a single, shared LLM backbone that learns to operate in two distinct, contextually isolated roles: a high-level Planner that decomposes tasks within a concise strategic context, and a low-level Executor that handles tool interactions in an ephemeral, isolated workspace. We train this unified agent end-to-end using PECO (Planner-Executor Co-Optimization), a reinforcement learning methodology that applies a trajectory-level reward to jointly optimize both roles, fostering seamless collaboration through context-dependent policy updates. Extensive experiments demonstrate that CoDA achieves significant performance improvements over state-of-the-art baselines on complex multi-hop question-answering benchmarks, and it exhibits strong robustness in long-context scenarios, maintaining stable performance while all other baselines suffer severe degradation, thus further validating the effectiveness of our hierarchical design in mitigating context overload.

</details>


### [30] [NL2Repo-Bench: Towards Long-Horizon Repository Generation Evaluation of Coding Agents](https://arxiv.org/abs/2512.12730)
*Jingzhe Ding,Shengda Long,Changxin Pu,Huan Zhou,Hongwan Gao,Xiang Gao,Chao He,Yue Hou,Fei Hu,Zhaojian Li,Weiran Shi,Zaiyuan Wang,Daoguang Zan,Chenchen Zhang,Xiaoxu Zhang,Qizhi Chen,Xianfu Cheng,Bo Deng,Qingshui Gu,Kai Hua,Juntao Lin,Pai Liu,Mingchen Li,Xuanguang Pan,Zifan Peng,Yujia Qin,Yong Shan,Zhewen Tan,Weihao Xie,Zihan Wang,Yishuo Yuan,Jiayu Zhang,Enduo Zhao,Yunfei Zhao,He Zhu,Chenyang Zou,Ming Ding,Jianpeng Jiao,Jiaheng Liu,Minghao Liu,Qian Liu,Chongyao Tao,Jian Yang,Tong Yang,Zhaoxiang Zhang,Xinjie Chen,Wenhao Huang,Ge Zhang*

Main category: cs.CL

TL;DR: NL2Repo Bench：专为评估编码代理长时程仓库生成能力而设计的基准测试，要求代理仅凭自然语言需求文档在空工作空间中构建完整可安装的Python库，实验显示当前最先进代理成功率低于40%，揭示了长时程推理是自主编码代理的关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有编码代理基准主要关注局部代码生成、脚手架完成或短期修复任务，缺乏对构建完整软件系统所需的长时程能力的严格评估。需要新的基准来测试代理在真实世界仓库构建中所需的持续推理、规划和执行能力。

Method: 提出NL2Repo Bench基准，要求编码代理仅基于单个自然语言需求文档和空工作空间，自主完成架构设计、依赖管理、多模块逻辑实现，最终生成完全可安装的Python库。基准通过测试通过率等指标量化评估代理的长时程仓库生成能力。

Result: 实验表明长时程仓库生成问题远未解决：即使最先进的开放和闭源模型代理，平均测试通过率也低于40%，很少能正确完成整个仓库。分析揭示了关键失败模式：过早终止、全局一致性丢失、脆弱的跨文件依赖关系，以及在数百个交互步骤中规划不足。

Conclusion: NL2Repo Bench为衡量持续代理能力建立了严格可验证的测试平台，突显长时程推理是下一代自主编码代理的核心瓶颈。该基准填补了现有评估空白，为未来研究提供了重要方向。

Abstract: Recent advances in coding agents suggest rapid progress toward autonomous software development, yet existing benchmarks fail to rigorously evaluate the long-horizon capabilities required to build complete software systems. Most prior evaluations focus on localized code generation, scaffolded completion, or short-term repair tasks, leaving open the question of whether agents can sustain coherent reasoning, planning, and execution over the extended horizons demanded by real-world repository construction. To address this gap, we present NL2Repo Bench, a benchmark explicitly designed to evaluate the long-horizon repository generation ability of coding agents. Given only a single natural-language requirements document and an empty workspace, agents must autonomously design the architecture, manage dependencies, implement multi-module logic, and produce a fully installable Python library. Our experiments across state-of-the-art open- and closed-source models reveal that long-horizon repository generation remains largely unsolved: even the strongest agents achieve below 40% average test pass rates and rarely complete an entire repository correctly. Detailed analysis uncovers fundamental long-horizon failure modes, including premature termination, loss of global coherence, fragile cross-file dependencies, and inadequate planning over hundreds of interaction steps. NL2Repo Bench establishes a rigorous, verifiable testbed for measuring sustained agentic competence and highlights long-horizon reasoning as a central bottleneck for the next generation of autonomous coding agents.

</details>


### [31] [Curió-Edu 7B: Examining Data Selection Impacts in LLM Continued Pretraining](https://arxiv.org/abs/2512.12770)
*Thales Sales Almeida,Rodrigo Nogueira,Hélio Pedrini*

Main category: cs.CL

TL;DR: Curió 7B是基於LLaMA-2的70億參數模型，使用1000億葡萄牙語token進行持續預訓練。其變體Curió-Edu 7B僅使用教育/STEM領域的100億token，卻在評估中表現更好，證明數據質量比數量更重要。


<details>
  <summary>Details</summary>
Motivation: 研究持續預訓練在語言模型適應特定語言或領域時的效果，特別探討在數據有限的情況下，數據質量是否比數量更重要。針對葡萄牙語這一資源相對較少的語言，研究如何有效適應語言模型。

Method: 開發兩個模型：Curió 7B（使用1000億葡萄牙語token的完整ClassiCC-PT語料庫）和Curió-Edu 7B（僅使用教育/STEM領域的100億token子集）。比較兩者在相同參數規模（70億）下的表現，評估數據選擇對語言適應的影響。

Result: Curió-Edu 7B雖然只使用了10%的數據和20%的計算資源，但在評估中超越了使用完整語料庫的Curió 7B。這表明在語言適應任務中，精心選擇的高質量數據比大量普通數據更有效。

Conclusion: 數據質量在語言模型的持續預訓練中起決定性作用，特別是在適應資源有限的語言時。精心篩選的領域特定數據可以顯著提高模型性能，即使數據量大幅減少。這為資源有限語言的模型適應提供了高效策略。

Abstract: Continued pretraining extends a language model's capabilities by further exposing it to additional data, often tailored to a specific linguistic or domain context. This strategy has emerged as an efficient alternative to full retraining when adapting general-purpose models to new settings. In this work, we investigate this paradigm through Curió 7B, a 7-billion-parameter model derived from LLaMA-2 and trained on 100 billion Portuguese tokens from the ClassiCC-PT corpus - the most extensive Portuguese-specific continued-pretraining effort above the three-billion-parameter scale to date. Beyond scale, we investigate whether quantity alone suffices or whether data quality plays a decisive role in linguistic adaptation. To this end, we introduce Curió-Edu 7B, a variant trained exclusively on the educational and STEM-filtered subset of the same corpus, totaling just 10 billion tokens. Despite using only 10% of the data and 20% of the computation, Curió-Edu 7B surpasses the full-corpus model in our evaluations, demonstrating that data selection can be fundamental even when adapting models with limited prior exposure to the target language. The developed models are available at https://huggingface.co/collections/ClassiCC-Corpus/curio-edu

</details>


### [32] [Persistent Personas? Role-Playing, Instruction Following, and Safety in Extended Interactions](https://arxiv.org/abs/2512.12775)
*Pedro Henrique Luz de Araujo,Michael A. Hedderich,Ali Modarressi,Hinrich Schuetze,Benjamin Roth*

Main category: cs.CL

TL;DR: 该研究提出了一种结合长对话（超过100轮）和评估数据集的新评估协议，用于系统测量LLM在长对话中角色保真度、指令遵循和安全性的退化问题。


<details>
  <summary>Details</summary>
Motivation: 当前角色分配的大型语言模型（LLM）在真实应用场景中通常涉及长对话交互，但现有评估方法主要集中在短对话、单轮设置，无法反映实际使用情况，需要开发能测量长上下文效应的评估协议。

Method: 研究者引入了一种评估协议，结合长角色对话（超过100轮）和评估数据集，创建对话条件化基准，用于鲁棒地测量长上下文效应。然后研究了对话长度对7个最先进的开源和闭源LLM在角色保真度、指令遵循和安全性方面的影响。

Result: 研究发现：1）角色保真度在对话过程中会退化，特别是在目标导向对话中；2）存在角色保真度与指令遵循之间的权衡，非角色基线模型在初始阶段优于角色分配模型；3）随着对话进展和保真度衰减，角色响应逐渐变得与基线响应相似。

Conclusion: 研究揭示了角色应用在扩展交互中的脆弱性，提出的协议能够系统测量此类失败，为LLM在长对话场景中的可靠应用提供了重要评估框架。

Abstract: Persona-assigned large language models (LLMs) are used in domains such as education, healthcare, and sociodemographic simulation. Yet, they are typically evaluated only in short, single-round settings that do not reflect real-world usage. We introduce an evaluation protocol that combines long persona dialogues (over 100 rounds) and evaluation datasets to create dialogue-conditioned benchmarks that can robustly measure long-context effects. We then investigate the effects of dialogue length on persona fidelity, instruction-following, and safety of seven state-of-the-art open- and closed-weight LLMs. We find that persona fidelity degrades over the course of dialogues, especially in goal-oriented conversations, where models must sustain both persona fidelity and instruction following. We identify a trade-off between fidelity and instruction following, with non-persona baselines initially outperforming persona-assigned models; as dialogues progress and fidelity fades, persona responses become increasingly similar to baseline responses. Our findings highlight the fragility of persona applications in extended interactions and our work provides a protocol to systematically measure such failures.

</details>


### [33] [State over Tokens: Characterizing the Role of Reasoning Tokens](https://arxiv.org/abs/2512.12777)
*Mosh Levy,Zohar Elyoseph,Shauli Ravfogel,Yoav Goldberg*

Main category: cs.CL

TL;DR: 论文提出State over Tokens (SoT)框架，将LLM的推理token重新定义为外部化计算状态而非语言叙述，解释其为何能驱动正确推理却非忠实解释。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的推理token序列看似人类思考过程，但实证表明它们并非模型实际推理过程的忠实解释。需要弥合这种表象与功能之间的差距。

Method: 引入State over Tokens (SoT)概念框架，将推理token重新定义为外部化计算状态——这是模型无状态生成周期中唯一持久的信息载体。

Result: SoT框架解释了推理token如何在不作为忠实文本解释的情况下驱动正确推理，并揭示了之前被忽视的研究问题。

Conclusion: 要真正理解LLM的推理过程，研究必须超越将推理token作为文本来阅读，而应将其解码为状态。

Abstract: Large Language Models (LLMs) can generate reasoning tokens before their final answer to boost performance on complex tasks. While these sequences seem like human thought processes, empirical evidence reveals that they are not a faithful explanation of the model's actual reasoning process. To address this gap between appearance and function, we introduce the State over Tokens (SoT) conceptual framework. SoT reframes reasoning tokens not as a linguistic narrative, but as an externalized computational state -- the sole persistent information carrier across the model's stateless generation cycles. This explains how the tokens can drive correct reasoning without being a faithful explanation when read as text and surfaces previously overlooked research questions on these tokens. We argue that to truly understand the process that LLMs do, research must move beyond reading the reasoning tokens as text and focus on decoding them as state.

</details>


### [34] [Does Tone Change the Answer? Evaluating Prompt Politeness Effects on Modern LLMs: GPT, Gemini, LLaMA](https://arxiv.org/abs/2512.12812)
*Hanyu Cai,Binqi Shen,Lier Jin,Lan Hu,Xiaojing Fan*

Main category: cs.CL

TL;DR: 研究评估了不同语气（友好、中性、粗鲁）对三种主流LLM在MMMLU基准测试中表现的影响，发现语气敏感性因模型和领域而异，但现代LLM总体上对语气变化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管提示工程对LLM性能至关重要，但语言语气和礼貌等语用元素的影响尚未得到充分探索，特别是在不同模型家族之间。研究旨在系统评估交互语气如何影响模型准确性。

Method: 提出了系统评估框架，在MMMLU基准测试中评估三种LLM（GPT-4o mini、Gemini 2.0 Flash、Llama 4 Scout）在"非常友好"、"中性"和"非常粗鲁"三种语气变体下的表现，涵盖STEM和人文领域六个任务，并进行统计显著性检验。

Result: 语气敏感性是模型依赖和领域特定的：中性或友好提示通常比粗鲁提示准确率更高，但统计显著效应仅出现在部分人文任务中；粗鲁语气会降低GPT和Llama的准确率，而Gemini相对不敏感；跨任务聚合后语气效应减弱并失去统计显著性。

Conclusion: 虽然交互语气在特定解释性场景中可能重要，但现代LLM总体上对语气变化具有鲁棒性，为实际部署中的提示设计和模型选择提供了实用指导。

Abstract: Prompt engineering has emerged as a critical factor influencing large language model (LLM) performance, yet the impact of pragmatic elements such as linguistic tone and politeness remains underexplored, particularly across different model families. In this work, we propose a systematic evaluation framework to examine how interaction tone affects model accuracy and apply it to three recently released and widely available LLMs: GPT-4o mini (OpenAI), Gemini 2.0 Flash (Google DeepMind), and Llama 4 Scout (Meta). Using the MMMLU benchmark, we evaluate model performance under Very Friendly, Neutral, and Very Rude prompt variants across six tasks spanning STEM and Humanities domains, and analyze pairwise accuracy differences with statistical significance testing.
  Our results show that tone sensitivity is both model-dependent and domain-specific. Neutral or Very Friendly prompts generally yield higher accuracy than Very Rude prompts, but statistically significant effects appear only in a subset of Humanities tasks, where rude tone reduces accuracy for GPT and Llama, while Gemini remains comparatively tone-insensitive. When performance is aggregated across tasks within each domain, tone effects diminish and largely lose statistical significance. Compared with earlier researches, these findings suggest that dataset scale and coverage materially influence the detection of tone effects. Overall, our study indicates that while interaction tone can matter in specific interpretive settings, modern LLMs are broadly robust to tonal variation in typical mixed-domain use, providing practical guidance for prompt design and model selection in real-world deployments.

</details>


### [35] [Hindsight is 20/20: Building Agent Memory that Retains, Recalls, and Reflects](https://arxiv.org/abs/2512.12818)
*Chris Latimer,Nicoló Boschi,Andrew Neeser,Chris Bartholomew,Gaurav Srivastava,Xuan Wang,Naren Ramakrishnan*

Main category: cs.CL

TL;DR: Hindsight是一种新型智能体记忆架构，通过四个逻辑网络结构化组织记忆，支持保留、回忆和反思三种核心操作，显著提升长期对话记忆性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体记忆系统将记忆作为外部层处理，存在证据与推理界限模糊、长期信息组织困难、推理解释支持有限等问题，需要更结构化的记忆架构来支持长期推理。

Method: 提出Hindsight记忆架构，将记忆组织为四个逻辑网络：世界事实、智能体经验、合成实体摘要和演化信念。包含时间感知记忆层将对话流转化为结构化记忆库，反思层进行可追溯的推理和更新。

Result: 在LongMemEval和LoCoMo基准测试中，Hindsight将20B开源模型的准确率从39%提升到83.6%，超越完整上下文GPT-4o。进一步扩展模型可将性能提升至91.4%（LongMemEval）和89.61%（LoCoMo）。

Conclusion: Hindsight通过结构化记忆架构显著提升了智能体在长期对话中的记忆和推理能力，为构建更强大的会话智能体提供了有效框架。

Abstract: Agent memory has been touted as a dimension of growth for LLM-based applications, enabling agents that can accumulate experience, adapt across sessions, and move beyond single-shot question answering. The current generation of agent memory systems treats memory as an external layer that extracts salient snippets from conversations, stores them in vector or graph-based stores, and retrieves top-k items into the prompt of an otherwise stateless model. While these systems improve personalization and context carry-over, they still blur the line between evidence and inference, struggle to organize information over long horizons, and offer limited support for agents that must explain their reasoning. We present Hindsight, a memory architecture that treats agent memory as a structured, first-class substrate for reasoning by organizing it into four logical networks that distinguish world facts, agent experiences, synthesized entity summaries, and evolving beliefs. This framework supports three core operations -- retain, recall, and reflect -- that govern how information is added, accessed, and updated. Under this abstraction, a temporal, entity aware memory layer incrementally turns conversational streams into a structured, queryable memory bank, while a reflection layer reasons over this bank to produce answers and to update information in a traceable way. On key long-horizon conversational memory benchmarks like LongMemEval and LoCoMo, Hindsight with an open-source 20B model lifts overall accuracy from 39% to 83.6% over a full-context baseline with the same backbone and outperforms full context GPT-4o. Scaling the backbone further pushes Hindsight to 91.4% on LongMemEval and up to 89.61% on LoCoMo (vs. 75.78% for the strongest prior open system), consistently outperforming existing memory architectures on multi-session and open-domain questions.

</details>


### [36] [What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation](https://arxiv.org/abs/2512.12839)
*Dingyi Yang,Qin Jin*

Main category: cs.CL

TL;DR: 提出首个大规模长篇故事自动评估基准LongStoryEval，包含600本平均12.1万token的书籍，并开发了高效的摘要式评估框架和8B模型NovelCritique，在人类对齐方面优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 长篇故事（>10万token）的自动评估面临挑战，需要理解读者最关注哪些评估维度，并探索有效的长文本评估方法。

Method: 构建LongStoryEval基准（600本书籍，平均12.1万token），分析读者评论提出8个顶层评估标准，比较聚合式、增量更新式和摘要式三种评估方法，并基于摘要式框架开发8B模型NovelCritique。

Result: 聚合式和摘要式评估表现更好，前者在细节评估上更优，后者效率更高。NovelCritique在人类评估对齐方面优于GPT-4o等商业模型。

Conclusion: 该研究为长篇故事自动评估提供了首个大规模基准和有效方法，NovelCritique展示了高效评估框架的潜力，推动了长文本评估领域的发展。

Abstract: In this work, we conduct systematic research in a challenging area: the automatic evaluation of book-length stories (>100K tokens). Our study focuses on two key questions: (1) understanding which evaluation aspects matter most to readers, and (2) exploring effective methods for evaluating lengthy stories. We introduce the first large-scale benchmark, LongStoryEval, comprising 600 newly published books with an average length of 121K tokens (maximum 397K). Each book includes its average rating and multiple reader reviews, presented as critiques organized by evaluation aspects. By analyzing all user-mentioned aspects, we propose an evaluation criteria structure and conduct experiments to identify the most significant aspects among the 8 top-level criteria. For evaluation methods, we compare the effectiveness of three types: aggregation-based, incremental-updated, and summary-based evaluations. Our findings reveal that aggregation- and summary-based evaluations perform better, with the former excelling in detail assessment and the latter offering greater efficiency. Building on these insights, we further propose NovelCritique, an 8B model that leverages the efficient summary-based framework to review and score stories across specified aspects. NovelCritique outperforms commercial models like GPT-4o in aligning with human evaluations. Our datasets and codes are available at https://github.com/DingyiYang/LongStoryEval.

</details>


### [37] [Counting Clues: A Lightweight Probabilistic Baseline Can Match an LLM](https://arxiv.org/abs/2512.12868)
*Furong Jia,Yuan Pu,Finn Guo,Monica Agrawal*

Main category: cs.CL

TL;DR: LLMs在临床诊断基准上表现出色，但FBPR方法使用简单的概念-诊断共现统计就能达到相似性能，表明LLMs的性能并非完全来自概率推理


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在临床诊断任务中的性能是否真正反映了概率推理能力，还是仅仅基于训练数据中的频率统计

Method: 提出FBPR方法：使用平滑朴素贝叶斯对概念-诊断共现统计进行评分，从预训练语料中提取共现数据

Result: FBPR与对应LLMs性能相当，但两者正确回答的问题重叠度仅略高于随机，表明方法互补

Conclusion: 显式概率基线仍有价值：提供性能参考点和互补信号；LLMs性能机制不同于简单频率聚合，但传统专家系统方法仍占基准性能的重要部分

Abstract: Large language models (LLMs) excel on multiple-choice clinical diagnosis benchmarks, yet it is unclear how much of this performance reflects underlying probabilistic reasoning. We study this through questions from MedQA, where the task is to select the most likely diagnosis. We introduce the Frequency-Based Probabilistic Ranker (FBPR), a lightweight method that scores options with a smoothed Naive Bayes over concept-diagnosis co-occurrence statistics from a large corpus. When co-occurrence statistics were sourced from the pretraining corpora for OLMo and Llama, FBPR achieves comparable performance to the corresponding LLMs pretrained on that same corpus. Direct LLM inference and FBPR largely get different questions correct, with an overlap only slightly above random chance, indicating complementary strengths of each method. These findings highlight the continued value of explicit probabilistic baselines: they provide a meaningful performance reference point and a complementary signal for potential hybridization. While the performance of LLMs seems to be driven by a mechanism other than simple frequency aggregation, we show that an approach similar to the historically grounded, low-complexity expert systems still accounts for a substantial portion of benchmark performance.

</details>


### [38] [Building from Scratch: A Multi-Agent Framework with Human-in-the-Loop for Multilingual Legal Terminology Mapping](https://arxiv.org/abs/2512.12950)
*Lingyi Meng,Maolin Liu,Hao Wang,Yilan Cheng,Qi Yang,Idlkaid Mohanmmed*

Main category: cs.CL

TL;DR: 提出一种人机协作的多智能体框架，用于构建多语言法律术语数据库，特别针对中-日-英语言对，通过AI处理重复任务、专家提供监督的方式提高术语映射的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 中-日等语言存在大量同形异义词，现有资源和标准化工具有限，准确映射跨语言法律术语面临重大挑战。

Method: 采用人机协作的多智能体框架，AI代理处理OCR、文本分割、语义对齐和初始术语提取等重复任务，法律领域专家提供监督、审查和上下文知识判断，涵盖从原始文档预处理、篇章对齐到术语提取、映射和质量保证的全过程。

Result: 使用包含35部关键中国法规及其英、日译文的平行语料库进行测试，结果表明这种人机协作的多智能体工作流不仅提高了多语言法律术语映射的精确性和一致性，相比传统人工方法还具有更好的可扩展性。

Conclusion: 人机协作的多智能体框架能有效解决跨语言法律术语映射的挑战，通过合理分工实现质量与效率的平衡，为多语言法律术语数据库构建提供了可行方案。

Abstract: Accurately mapping legal terminology across languages remains a significant challenge, especially for language pairs like Chinese and Japanese, which share a large number of homographs with different meanings. Existing resources and standardized tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-agent framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment, to terminology extraction, mapping, and quality assurance. Unlike a single automated pipeline, our approach places greater emphasis on how human experts participate in this multi-agent system. Humans and AI agents take on different roles: AI agents handle specific, repetitive tasks, such as OCR, text segmentation, semantic alignment, and initial terminology extraction, while human experts provide crucial oversight, review, and supervise the outputs with contextual knowledge and legal judgment. We tested the effectiveness of this framework using a trilingual parallel corpus comprising 35 key Chinese statutes, along with their English and Japanese translations. The experimental results show that this human-in-the-loop, multi-agent workflow not only improves the precision and consistency of multilingual legal terminology mapping but also offers greater scalability compared to traditional manual methods.

</details>


### [39] [QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management](https://arxiv.org/abs/2512.12967)
*Weizhou Shen,Ziyi Yang,Chenliang Li,Zhiyuan Lu,Miao Peng,Huashan Sun,Yingcheng Shi,Shengyi Liao,Shaopeng Lai,Bo Zhang,Dayiheng Liu,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.CL

TL;DR: QwenLong-L1.5通过系统后训练创新实现卓越长上下文推理能力，包括长上下文数据合成、稳定强化学习和内存增强架构，在长上下文基准测试中达到GPT-5和Gemini-2.5-Pro水平。


<details>
  <summary>Details</summary>
Motivation: 现有模型在长上下文推理方面存在局限，需要超越简单检索任务，实现真正的长距离推理能力，并解决超长序列处理问题。

Method: 1) 长上下文数据合成管道：将文档分解为原子事实和关系，编程生成可验证推理问题；2) 稳定强化学习：任务平衡采样和自适应熵控制策略优化；3) 内存增强架构：多阶段融合RL训练，集成单次推理和迭代内存处理。

Result: 在长上下文推理基准上性能与GPT-5和Gemini-2.5-Pro相当，比基线平均提升9.90分；在超长任务(1M~4M tokens)上，内存代理框架比代理基线提升9.48分；长上下文推理能力也提升了科学推理、记忆工具使用和扩展对话等通用领域性能。

Conclusion: QwenLong-L1.5通过系统后训练创新成功实现了卓越的长上下文推理能力，其技术突破为处理超长序列和复杂推理任务提供了有效解决方案。

Abstract: We introduce QwenLong-L1.5, a model that achieves superior long-context reasoning capabilities through systematic post-training innovations. The key technical breakthroughs of QwenLong-L1.5 are as follows: (1) Long-Context Data Synthesis Pipeline: We develop a systematic synthesis framework that generates challenging reasoning tasks requiring multi-hop grounding over globally distributed evidence. By deconstructing documents into atomic facts and their underlying relationships, and then programmatically composing verifiable reasoning questions, our approach creates high-quality training data at scale, moving substantially beyond simple retrieval tasks to enable genuine long-range reasoning capabilities. (2) Stabilized Reinforcement Learning for Long-Context Training: To overcome the critical instability in long-context RL, we introduce task-balanced sampling with task-specific advantage estimation to mitigate reward bias, and propose Adaptive Entropy-Controlled Policy Optimization (AEPO) that dynamically regulates exploration-exploitation trade-offs. (3) Memory-Augmented Architecture for Ultra-Long Contexts: Recognizing that even extended context windows cannot accommodate arbitrarily long sequences, we develop a memory management framework with multi-stage fusion RL training that seamlessly integrates single-pass reasoning with iterative memory-based processing for tasks exceeding 4M tokens. Based on Qwen3-30B-A3B-Thinking, QwenLong-L1.5 achieves performance comparable to GPT-5 and Gemini-2.5-Pro on long-context reasoning benchmarks, surpassing its baseline by 9.90 points on average. On ultra-long tasks (1M~4M tokens), QwenLong-L1.5's memory-agent framework yields a 9.48-point gain over the agent baseline. Additionally, the acquired long-context reasoning ability translates to enhanced performance in general domains like scientific reasoning, memory tool using, and extended dialogue.

</details>


### [40] [Authors Should Annotate](https://arxiv.org/abs/2512.12976)
*Marcus Ma,Cole Johnson,Nolan Bridges,Jackson Trager,Georgios Chochlakis,Shrikanth Narayanan*

Main category: cs.CL

TL;DR: 作者标注：让文档作者在创作时直接标注数据的新方法，相比第三方标注在主观特征上质量更高、更快、更便宜


<details>
  <summary>Details</summary>
Motivation: 当前文本标注主要依赖第三方标注，但对于情感、信念等自我中心特征，直接从文档来源获取信息比第三方代理更优

Method: 引入作者标注技术，在文档创作时让作者直接标注数据；与拥有10,000+用户的商业聊天机器人合作，部署针对产品推荐主观特征的作者标注系统；该系统识别任务相关查询，实时生成标注问题并记录作者回答

Result: 训练并部署了在线学习模型架构用于产品推荐，持续从作者标注中改进，点击率比行业广告基准提高534%；与传统标注方法比较，作者标注在情感分析上质量更高、获取更快、成本更低

Conclusion: 作者标注对于自我中心和主观信念的标注质量显著高于第三方标注；为促进科研采用，发布了学术界的作者标注服务

Abstract: The status quo for labeling text is third-party annotation, but there are many cases where information directly from the document's source would be preferable over a third-person proxy, especially for egocentric features like sentiment and belief. We introduce author labeling, an annotation technique where the writer of the document itself annotates the data at the moment of creation. We collaborate with a commercial chatbot with over 10,000 users to deploy an author labeling annotation system for subjective features related to product recommendation. This system identifies task-relevant queries, generates on-the-fly labeling questions, and records authors' answers in real time. We train and deploy an online-learning model architecture for product recommendation that continuously improves from author labeling and find it achieved a 534% increase in click-through rate compared to an industry advertising baseline running concurrently. We then compare the quality and practicality of author labeling to three traditional annotation approaches for sentiment analysis and find author labeling to be higher quality, faster to acquire, and cheaper. These findings reinforce existing literature that annotations, especially for egocentric and subjective beliefs, are significantly higher quality when labeled by the author rather than a third party. To facilitate broader scientific adoption, we release an author labeling service for the research community at academic.echollm.io.

</details>


### [41] [An Open and Reproducible Deep Research Agent for Long-Form Question Answering](https://arxiv.org/abs/2512.13059)
*Ikuya Yamada,Wataru Ikeda,Ko Yoshida,Mengyu Ye,Hinata Sugimoto,Masatoshi Suzuki,Hisanori Ozaki,Jun Suzuki*

Main category: cs.CL

TL;DR: 提出一个用于长形式问答的开放深度研究系统，结合开源大语言模型与开放网络搜索API，通过迭代检索、推理和合成来提升回答质量，并在MMU-RAG竞赛中获奖。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界开放域设置中的长形式问答问题，需要系统能够进行有效的检索、推理和合成，同时确保回答的清晰性、洞察力和事实准确性。

Method: 结合开源大语言模型与开放网络搜索API，采用迭代检索、推理和合成的方法，并应用基于LLM-as-a-judge反馈的偏好调优来评估和提升回答的清晰性、洞察力和事实准确性。

Result: 实验结果表明，所提出的方法在所有三个评估方面（清晰性、洞察力和事实准确性）都能持续提升回答质量，并在NeurIPS 2025的MMU-RAG竞赛文本到文本赛道中获奖。

Conclusion: 该系统为开放域长形式问答提供了一个有效的解决方案，通过结合检索增强生成和基于偏好的调优，显著提升了回答质量，且代码已开源供社区使用。

Abstract: We present an open deep research system for long-form question answering, selected as a winning system in the text-to-text track of the MMU-RAG competition at NeurIPS 2025. The system combines an open-source large language model (LLM) with an open web search API to perform iterative retrieval, reasoning, and synthesis in real-world open-domain settings. To enhance reasoning quality, we apply preference tuning based on LLM-as-a-judge feedback that evaluates multiple aspects, including clarity, insightfulness, and factuality. Our experimental results show that the proposed method consistently improves answer quality across all three aspects. Our source code is publicly available at https://github.com/efficient-deep-research/efficient-deep-research.

</details>


### [42] [LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators](https://arxiv.org/abs/2512.13063)
*Cheril Shah,Akshit Agarwal,Kanak Garg,Mourad Heddaya*

Main category: cs.CL

TL;DR: 该研究提出了一个基于双曲正切曲线的让步动态统一数学模型，并引入爆发性τ和让步刚性指数(CRI)两个指标来量化报价轨迹。通过大规模实证比较人类谈判者与四种最先进的大语言模型(LLM)，发现LLM在谈判中存在系统性极端锚定、策略多样性有限、无法根据情境调整等根本性局限。


<details>
  <summary>Details</summary>
Motivation: 双边谈判是一个复杂的情境敏感任务，人类谈判者会根据权力不对称和非正式线索动态调整锚点、节奏和灵活性。当前需要理解大语言模型在谈判任务中的表现与人类有何差异，以及它们是否具备情境适应和对手推理能力。

Method: 1. 提出基于双曲正切曲线的让步动态统一数学模型；2. 引入爆发性τ和让步刚性指数(CRI)两个量化指标；3. 进行大规模实证比较：人类谈判者 vs 四种最先进LLM；4. 实验设置：自然语言和数字报价两种情境，有无丰富市场背景，以及六种受控的权力不对称场景。

Result: 1. 与人类能够平滑适应情境并推断对手立场和策略不同，LLM系统性地锚定在可能协议区的极端位置；2. LLM优化固定点，不考虑杠杆或情境；3. 定性分析显示LLM策略多样性有限，偶尔使用欺骗性策略；4. LLM的谈判能力不随模型改进而提升。

Conclusion: 当前LLM在谈判能力上存在根本性局限，需要开发能够更好内化对手推理和情境依赖策略的模型。LLM无法像人类那样动态适应权力不对称和情境变化，显示出在复杂社会互动任务中的不足。

Abstract: Bilateral negotiation is a complex, context-sensitive task in which human negotiators dynamically adjust anchors, pacing, and flexibility to exploit power asymmetries and informal cues. We introduce a unified mathematical framework for modeling concession dynamics based on a hyperbolic tangent curve, and propose two metrics burstiness tau and the Concession-Rigidity Index (CRI) to quantify the timing and rigidity of offer trajectories. We conduct a large-scale empirical comparison between human negotiators and four state-of-the-art large language models (LLMs) across natural-language and numeric-offers settings, with and without rich market context, as well as six controlled power-asymmetry scenarios. Our results reveal that, unlike humans who smoothly adapt to situations and infer the opponents position and strategies, LLMs systematically anchor at extremes of the possible agreement zone for negotiations and optimize for fixed points irrespective of leverage or context. Qualitative analysis further shows limited strategy diversity and occasional deceptive tactics used by LLMs. Moreover the ability of LLMs to negotiate does not improve with better models. These findings highlight fundamental limitations in current LLM negotiation capabilities and point to the need for models that better internalize opponent reasoning and context-dependent strategy.

</details>


### [43] [Uncovering the Role of Initial Saliency in U-Shaped Attention Bias: Scaling Initial Token Weight for Enhanced Long-Text Processing](https://arxiv.org/abs/2512.13109)
*Zewen Qiang,Sendong Zhao,Haochun Wang,Bing Qin,Ting Liu*

Main category: cs.CL

TL;DR: 本文发现大语言模型处理长文本时存在"中间迷失"问题，除了已知的位置编码偏差外，还首次识别出初始显著性因素，通过调整初始token与其他token的注意力权重，能提升长文本处理能力，最高在MDQA数据集上提升3.6%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言处理任务中表现优异，但在处理长文本序列时存在"中间迷失"现象，即注意力过度集中在文本开头和结尾，中间部分被忽视。虽然已有研究将此归因于位置编码偏差，但本文旨在探索其他潜在因素。

Method: 首先识别出初始显著性这一新因素：在注意力计算中，相对于初始token具有更高注意力权重的token，在预测下一个token时会获得更多关注。然后利用这一特性，通过缩放初始token与其他token之间的注意力权重来改进模型的长文本处理能力。

Result: 提出的方法在MDQA数据集上实现了最高3.6%的性能提升。当与现有的减少位置编码偏差的方法结合时，在KV-Retrieval任务中实现了最高3.4%的进一步性能提升。

Conclusion: 除了位置编码偏差外，初始显著性也是导致大语言模型"中间迷失"现象的重要因素。通过调整初始token与其他token的注意力权重，可以有效改善模型的长文本处理能力，且与现有方法结合能获得更好的效果。

Abstract: Large language models (LLMs) have demonstrated strong performance on a variety of natural language processing (NLP) tasks. However, they often struggle with long-text sequences due to the ``lost in the middle'' phenomenon. This issue has been shown to arise from a U-shaped attention bias, where attention is disproportionately focused on the beginning and end of a text, leaving the middle section underrepresented. While previous studies have attributed this bias to position encoding, our research first identifies an additional factor: initial saliency. It means that in the attention computation for each token, tokens with higher attention weights relative to the initial token tend to receive more attention in the prediction of the next token. We further find that utilizing this property by scaling attention weight between the initial token and others improves the model's ability to process long contexts, achieving a maximum improvement of 3.6\% in MDQA dataset. Moreover, combining this approach with existing methods to reduce position encoding bias further enhances performance, achieving a maximum improvement of 3.4\% in KV-Retrieval tasks.

</details>


### [44] [Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models](https://arxiv.org/abs/2512.13194)
*Chendong Sun*

Main category: cs.CL

TL;DR: EARS提出自适应拒绝采样方法，通过动态调整接受阈值来减少推测解码中的随机拒绝问题，显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统推测解码使用固定的随机阈值进行拒绝采样，在高不确定性生成场景中会导致大量合理的候选token因随机性被拒绝，从而降低推理效率。

Method: 提出高效自适应拒绝采样(EARS)，根据目标模型自身的预测不确定性(1 - max(P_target))动态调整接受阈值，引入与不确定性成比例的容忍项，在模型不确定时智能放宽接受标准。

Result: 在创意写作和开放域QA任务上的实验表明，EARS显著提升推测解码效率，在GSM8K基准上实现高达18.12%的吞吐量提升，准确率仅下降0.84%。

Conclusion: EARS无需修改模型架构，可无缝集成到现有推测解码框架中，通过减少随机拒绝有效提升大语言模型推理效率。

Abstract: Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant "random rejection" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as \(1 - \max(P_{\mathrm{target}})\). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.

</details>


### [45] [AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning](https://arxiv.org/abs/2512.13278)
*Jiaru Zou,Ling Yang,Yunzhe Qi,Sirui Chen,Mengting Ai,Ke Shen,Jingrui He,Mengdi Wang*

Main category: cs.CL

TL;DR: AutoTool框架让LLM代理具备动态工具选择能力，通过双阶段优化和KL正则化排名，在多个基准测试中显著优于现有方法，并能泛化到未见过的工具。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设固定工具集，限制了LLM代理对新工具或演化工具集的适应性，需要动态工具选择能力来提升代理的适应性和性能。

Method: 构建包含20万样本的数据集，涵盖1000+工具和100+任务；采用双阶段优化：监督和基于RL的轨迹稳定化，以及KL正则化Plackett-Luce排名来优化多步工具选择。

Result: 在十个不同基准测试中，AutoTool在数学科学推理提升6.4%，搜索QA提升4.5%，代码生成提升7.7%，多模态理解提升6.9%，且能动态利用推理过程中未见过的工具。

Conclusion: AutoTool通过动态工具选择显著提升了LLM代理的性能和泛化能力，为适应不断演化的工具集提供了有效解决方案。

Abstract: Agentic reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM agents' adaptability to new or evolving toolsets. We present AutoTool, a framework that equips LLM agents with dynamic tool-selection capabilities throughout their reasoning trajectories. We first construct a 200k dataset with explicit tool-selection rationales across 1,000+ tools and 100+ tasks spanning mathematics, science, code generation, and multimodal reasoning. Building on this data foundation, AutoTool employs a dual-phase optimization pipeline: (i) supervised and RL-based trajectory stabilization for coherent reasoning, and (ii) KL-regularized Plackett-Luce ranking to refine consistent multi-step tool selection. Across ten diverse benchmarks, we train two base models, Qwen3-8B and Qwen2.5-VL-7B, with AutoTool. With fewer parameters, AutoTool consistently outperforms advanced LLM agents and tool-integration methods, yielding average gains of 6.4% in math & science reasoning, 4.5% in search-based QA, 7.7% in code generation, and 6.9% in multimodal understanding. In addition, AutoTool exhibits stronger generalization by dynamically leveraging unseen tools from evolving toolsets during inference.

</details>


### [46] [AIR: Post-training Data Selection for Reasoning via Attention Head Influence](https://arxiv.org/abs/2512.13279)
*Jinrui Liu,Jeff Wu,Xuanguang Pan,Gavin Cheung,Shuai Ma,Chongyang Tao*

Main category: cs.CL

TL;DR: 提出AIR框架，利用注意力机制选择推理关键数据，提升LLM后训练蒸馏效率


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法（手动筛选、基于长度/熵/损失等启发式方法）无法捕捉推理步骤的因果重要性，限制了蒸馏效率

Method: AIR框架：1)识别现成模型的推理关键注意力头；2)构建禁用头部影响的弱化参考模型；3)量化损失差异作为注意力影响分数，支持步骤级加权微调和全局样本选择

Result: 在多个推理基准测试中，AIR持续提升推理准确率，超越启发式基线方法，有效识别最关键步骤和样本

Conclusion: 建立了一种机制驱动、数据高效的方法用于LLM的推理蒸馏

Abstract: LLMs achieve remarkable multi-step reasoning capabilities, yet effectively transferring these skills via post-training distillation remains challenging. Existing data selection methods, ranging from manual curation to heuristics based on length, entropy, or overall loss, fail to capture the causal importance of individual reasoning steps, limiting distillation efficiency. To address this, we propose Attention Influence for Reasoning (AIR), a principled, unsupervised and training-free framework that leverages mechanistic insights of the retrieval head to select high-value post-training data. AIR first identifies reasoning-critical attention heads of an off-the-shelf model, then constructs a weakened reference model with disabled head influence, and finally quantifies the resulting loss divergence as the Attention Influence Score. This score enables fine-grained assessment at both the step and sample levels, supporting step-level weighted fine-tuning and global sample selection. Experiments across multiple reasoning benchmarks show that AIR consistently improves reasoning accuracy, surpassing heuristic baselines and effectively isolating the most critical steps and samples. Our work establishes a mechanism-driven, data-efficient approach for reasoning distillation in LLMs.

</details>


### [47] [Integrating Causal Reasoning into Automated Fact-Checking](https://arxiv.org/abs/2512.13286)
*Youssra Rebboud,Pasquale Lisena,Raphael Troncy*

Main category: cs.CL

TL;DR: 提出结合事件关系提取、语义相似度计算和规则推理的方法，将细粒度因果事件关系整合到事实核查中，提升判决预测的可解释性


<details>
  <summary>Details</summary>
Motivation: 当前自动事实核查方法缺乏专门的因果推理机制，无法有效检测事件间的错误因果关系，错失了语义丰富的可解释性机会

Method: 结合事件关系提取、语义相似度计算和基于规则的推理，检测声明和证据中事件链之间的逻辑不一致性

Result: 在两个事实核查数据集上评估，该方法为整合细粒度因果事件关系建立了首个基准，并增强了判决预测的可解释性

Conclusion: 提出的方法填补了事实核查中因果推理的空白，为检测事件间错误因果关系提供了有效的解决方案，并提升了系统的可解释性

Abstract: In fact-checking applications, a common reason to reject a claim is to detect the presence of erroneous cause-effect relationships between the events at play. However, current automated fact-checking methods lack dedicated causal-based reasoning, potentially missing a valuable opportunity for semantically rich explainability. To address this gap, we propose a methodology that combines event relation extraction, semantic similarity computation, and rule-based reasoning to detect logical inconsistencies between chains of events mentioned in a claim and in an evidence. Evaluated on two fact-checking datasets, this method establishes the first baseline for integrating fine-grained causal event relationships into fact-checking and enhance explainability of verdict prediction.

</details>


### [48] [MiniLingua: A Small Open-Source LLM for European Languages](https://arxiv.org/abs/2512.13298)
*Anna Aksenova,Boris Zverkov,Nicola Dainese,Alexander Nikitin,Pekka Marttinen*

Main category: cs.CL

TL;DR: MiniLingua是一个10亿参数的多语言开源大语言模型，专门为13种欧洲语言设计，在多项任务上超越了更大训练预算的EuroLLM，并与先进模型在开放生成任务上保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在计算成本高、隐私问题和英语中心化训练的限制。小型高效模型（约10亿参数）已显示出强大性能并支持设备端使用，但需要专门的多语言模型来平衡语言覆盖范围和指令跟随能力。

Method: 从零开始训练10亿参数的多语言开源LLM，覆盖13种欧洲语言。采用指令调优版本，并发布了模型权重、分词器以及数据处理和模型训练的源代码。

Result: 指令调优版的MiniLingua在摘要、分类、开放和闭卷问答任务上超越了训练预算更大的EuroLLM。在开放生成任务上与更先进的SOTA模型保持竞争力。

Conclusion: MiniLingua证明了小型高效多语言模型的可行性，为计算资源有限、隐私敏感和多语言需求的应用场景提供了实用解决方案，并开源了完整工具链。

Abstract: Large language models are powerful but often limited by high computational cost, privacy concerns, and English-centric training. Recent progress demonstrates that small, efficient models with around one billion parameters can deliver strong results and enable on-device use. This paper introduces MiniLingua, a multilingual open-source LLM of one billion parameters trained from scratch for 13 European languages, designed to balance coverage and instruction-following capabilities. Based on evaluation results, the instruction-tuned version of MiniLingua outperforms EuroLLM, a model with a similar training approach but a larger training budget, on summarization, classification and both open- and closed-book question answering. Moreover, it remains competitive with more advanced state-of-the-art models on open-ended generation tasks. We release model weights, tokenizer and source code used for data processing and model training.

</details>


### [49] [FIN-bench-v2: A Unified and Robust Benchmark Suite for Evaluating Finnish Large Language Models](https://arxiv.org/abs/2512.13330)
*Joona Kytöniemi,Jousia Piha,Akseli Reunamo,Fedor Vitiugin,Farrokh Mehryary,Sampo Pyysalo*

Main category: cs.CL

TL;DR: FIN-bench-v2是一个统一的芬兰语大语言模型评估基准套件，整合了多个芬兰语基准测试，覆盖阅读理解、常识推理、情感分析、世界知识和对齐等多个任务类型。


<details>
  <summary>Details</summary>
Motivation: 需要为芬兰语大语言模型提供一个统一的评估基准，整合现有的芬兰语基准测试资源，并确保数据质量和评估的可靠性。

Method: 1) 整合芬兰语版本的广泛使用基准测试和原始FIN-bench的更新扩展版本；2) 将所有数据集转换为HuggingFace格式，包含完形填空和多项选择题提示的五个变体；3) 对机器翻译资源进行人工标注或审查；4) 使用2.15B参数的自回归模型通过学习曲线分析任务质量，保留满足单调性、信噪比、非随机性能和模型排序一致性的任务。

Result: 创建了一个统一、格式一致的芬兰语评估基准套件，包含经过质量筛选的任务，并评估了多个大型指令调优模型在不同任务和提示格式下的性能。所有数据集、提示和评估配置都已公开。

Conclusion: FIN-bench-v2为芬兰语大语言模型评估提供了一个全面、可靠的基准套件，通过严格的质量筛选确保了评估的有效性，有助于推动芬兰语NLP研究的发展。

Abstract: We introduce FIN-bench-v2, a unified benchmark suite for evaluating large language models in Finnish. FIN-bench-v2 consolidates Finnish versions of widely used benchmarks together with an updated and expanded version of the original FIN-bench into a single, consistently formatted collection, covering multiple-choice and generative tasks across reading comprehension, commonsense reasoning, sentiment analysis, world knowledge, and alignment. All datasets are converted to HuggingFace Datasets, which include both cloze and multiple-choice prompt formulations with five variants per task, and we incorporate human annotation or review for machine-translated resources such as GoldenSwag and XED. To select robust tasks, we pretrain a set of 2.15B-parameter decoder-only models and use their learning curves to compute monotonicity, signal-to-noise, non-random performance, and model ordering consistency, retaining only tasks that satisfy all criteria. We further evaluate a set of larger instruction-tuned models to characterize performance across tasks and prompt formulations. All datasets, prompts, and evaluation configurations are publicly available via our fork of the Language Model Evaluation Harness at https://github.com/LumiOpen/lm-evaluation-harness. Supplementary resources are released in a separate repository at https://github.com/TurkuNLP/FIN-bench-v2.

</details>


### [50] [Detecting Emotion Drift in Mental Health Text Using Pre-Trained Transformers](https://arxiv.org/abs/2512.13363)
*Shibani Sankpal*

Main category: cs.CL

TL;DR: 该研究提出"情绪漂移"概念，分析心理健康相关文本中情绪状态的变化，使用预训练Transformer模型检测句子级情绪并计算漂移分数


<details>
  <summary>Details</summary>
Motivation: 传统情感分析通常将整条消息分类为积极、消极或中性，忽略了消息内部情绪的微妙变化。在心理健康对话中，理解情绪如何随时间演变对于识别情绪升级或缓解模式至关重要

Method: 使用预训练的Transformer模型（DistilBERT和RoBERTa）检测句子级情绪，然后计算情绪漂移分数来衡量单个文本中情绪状态的变化

Result: 研究结果揭示了心理健康对话中情绪升级或缓解的模式，为理解情绪动态提供了新的洞察

Conclusion: 该方法能够更好地理解文本内容中的情绪动态，特别是在心理健康相关消息中，有助于识别情绪变化模式并支持更精细的情感分析

Abstract: This study investigates emotion drift: the change in emotional state across a single text, within mental health-related messages. While sentiment analysis typically classifies an entire message as positive, negative, or neutral, the nuanced shift of emotions over the course of a message is often overlooked. This study detects sentence-level emotions and measures emotion drift scores using pre-trained transformer models such as DistilBERT and RoBERTa. The results provide insights into patterns of emotional escalation or relief in mental health conversations. This methodology can be applied to better understand emotional dynamics in content.

</details>


### [51] [Large language models are not about language](https://arxiv.org/abs/2512.13441)
*Johan J. Bolhuis,Andrea Moro,Stephen Crain,Sandiway Fong*

Main category: cs.CL

TL;DR: 该论文认为大语言模型对语言学无用，因为它们是依赖大量数据的概率模型，而人类语言基于内在计算系统，能递归生成层次化思维结构。


<details>
  <summary>Details</summary>
Motivation: 作者旨在批判当前将大语言模型应用于语言学研究的趋势，强调人类语言能力的内在本质与统计模型的根本差异。

Method: 通过理论对比分析：比较大语言模型（数据驱动的概率模型）与人类语言能力（内在计算系统）的本质区别。

Result: 论证了大语言模型无法捕捉人类语言的核心特征——递归生成层次结构的能力，且无法像人类那样区分真实语言与不可能语言。

Conclusion: 大语言模型不适合用于语言学研究，因为它们无法模拟人类语言的内在计算本质，而只是对外部化词串的统计建模。

Abstract: Large Language Models are useless for linguistics, as they are probabilistic models that require a vast amount of data to analyse externalized strings of words. In contrast, human language is underpinned by a mind-internal computational system that recursively generates hierarchical thought structures. The language system grows with minimal external input and can readily distinguish between real language and impossible languages.

</details>


### [52] [Scaling Laws for Code: Every Programming Language Matters](https://arxiv.org/abs/2512.13472)
*Jian Yang,Shawn Guo,Lin Jing,Wei Zhang,Aishan Liu,Chuan Hao,Zhoujun Li,Wayne Xin Zhao,Xianglong Liu,Weifeng Lv,Bryan Dai*

Main category: cs.CL

TL;DR: 本文首次系统探索了多语言代码预训练的缩放定律，通过1000+实验发现解释型语言（如Python）比编译型语言（如Rust）更能从模型规模和数据增长中受益，并提出基于比例的多语言缩放定律来优化训练token分配。


<details>
  <summary>Details</summary>
Motivation: 现有代码大语言模型（Code LLMs）的训练成本高昂，且现有缩放定律未能考虑不同编程语言在预训练中的差异影响，导致性能预测不准确。同时，现有研究多关注语言无关设置，忽视了现代软件开发的多语言本质。

Method: 进行了超过1000个实验（相当于336,000+ H800 GPU小时），涵盖多种编程语言、模型规模（0.2B到14B参数）和数据集规模（1T tokens）。建立了全面的多语言代码LLM缩放定律，并提出了并行配对预训练策略（将代码片段与其翻译版本拼接）。

Result: 发现解释型语言（如Python）比编译型语言（如Rust）更能从模型规模和数据增长中受益；多语言预训练具有协同效应，特别是在语法相似的编程语言之间；并行配对策略显著增强了跨语言能力；提出的比例依赖多语言缩放定律在相同计算预算下比均匀分配获得更优的平均性能。

Conclusion: 首次系统建立了多语言代码预训练的缩放定律，揭示了不同编程语言的训练特性差异，提出的优化token分配策略能够有效提升多语言代码LLM的整体性能，为高效训练多语言代码模型提供了理论指导。

Abstract: Code large language models (Code LLMs) are powerful but costly to train, with scaling laws predicting performance from model size, data, and compute. However, different programming languages (PLs) have varying impacts during pre-training that significantly affect base model performance, leading to inaccurate performance prediction. Besides, existing works focus on language-agnostic settings, neglecting the inherently multilingual nature of modern software development. Therefore, it is first necessary to investigate the scaling laws of different PLs, and then consider their mutual influences to arrive at the final multilingual scaling law. In this paper, we present the first systematic exploration of scaling laws for multilingual code pre-training, conducting over 1000+ experiments (Equivalent to 336,000+ H800 hours) across multiple PLs, model sizes (0.2B to 14B parameters), and dataset sizes (1T tokens). We establish comprehensive scaling laws for code LLMs across multiple PLs, revealing that interpreted languages (e.g., Python) benefit more from increased model size and data than compiled languages (e.g., Rust). The study demonstrates that multilingual pre-training provides synergistic benefits, particularly between syntactically similar PLs. Further, the pre-training strategy of the parallel pairing (concatenating code snippets with their translations) significantly enhances cross-lingual abilities with favorable scaling properties. Finally, a proportion-dependent multilingual scaling law is proposed to optimally allocate training tokens by prioritizing high-utility PLs (e.g., Python), balancing high-synergy pairs (e.g., JavaScript-TypeScript), and reducing allocation to fast-saturating languages (Rust), achieving superior average performance across all PLs compared to uniform distribution under the same compute budget.

</details>


### [53] [Non-Resolution Reasoning: A Framework for Preserving Semantic Ambiguity in Language Models](https://arxiv.org/abs/2512.13478)
*Kei Saito*

Main category: cs.CL

TL;DR: 提出了非消解推理(NRR)框架，通过多向量嵌入、非坍缩注意力和上下文身份追踪来防止语言模型过早语义坍缩，将歧义保留为显式表示状态而非错误模式。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型存在过早语义坍缩的核心架构限制——在上下文不足时过早承诺单一含义，导致推理脆弱和上下文失败。Softmax驱动的竞争和贪婪解码使模型在获得足够上下文前丢弃有效解释。

Method: 引入非消解推理(NRR)框架，包含三个组件：1) 多向量嵌入：为每个token维护多个可行解释；2) 非坍缩注意力：防止跨层的赢家通吃动态；3) 上下文身份追踪(CIT)：为重复实体分配上下文特定身份。这些机制通过外部消解算子ρ统一，使语义承诺变得显式、可控且任务依赖。

Result: 合成评估显示NRR能有效保留歧义和追踪上下文：CIT增强模型在分布外身份转移任务上达到90.9%准确率，而Transformer基线仅为9.1%。NRR将表示与消解分离，允许单个模型在不同推理模式间切换而无需重新训练。

Conclusion: NRR为过早坍缩提供了原则性替代方案，将歧义重构为显式表示状态而非失败模式。关键问题不是AI是否应该消解歧义，而是何时、如何以及在谁的控制下进行消解。

Abstract: Premature semantic collapse -- the forced early commitment to a single meaning -- remains a core architectural limitation of current language models. Softmax-driven competition and greedy decoding cause models to discard valid interpretations before sufficient context is available, resulting in brittle reasoning and context failures. We introduce Non-Resolution Reasoning (NRR), a general computational framework that preserves semantic ambiguity during inference and performs resolution only when explicitly required. NRR integrates three components: (1) Multi-Vector Embeddings that maintain multiple viable interpretations per token, (2) Non-Collapsing Attention that prevents winner-take-all dynamics across layers, and (3) Contextual Identity Tracking (CIT), which assigns context-specific identities to recurring entities (e.g., distinguishing "Dr. Smith the cardiologist" from "Dr. Smith the researcher"). These mechanisms are unified by an external Resolution Operator $ρ$ that makes semantic commitment explicit, controllable, and task-dependent. Unlike standard architectures, NRR separates representation from resolution, allowing a single model to shift between creative, factual, and ambiguity-preserving reasoning without retraining. A synthetic evaluation demonstrates NRR's ability to preserve ambiguity and track context: CIT-enhanced models achieve 90.9% accuracy on out-of-distribution identity-shift tasks, compared to 9.1% for transformer baselines. NRR provides a principled alternative to premature collapse, reframing ambiguity as an explicit representational state rather than a failure mode. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.

</details>


### [54] [Advancing Bangla Machine Translation Through Informal Datasets](https://arxiv.org/abs/2512.13487)
*Ayon Roy,Risat Rahaman,Sadat Shibly,Udoy Saha Joy,Abdulla Al Kafi,Farig Yousuf Sadeque*

Main category: cs.CL

TL;DR: 该研究针对孟加拉语机器翻译的不足，特别是非正式语言的翻译问题，通过构建社交媒体和对话文本数据集来改进孟加拉语翻译模型。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为全球第六大语言，拥有约2.34亿母语者，但开源机器翻译进展有限。现有研究主要关注正式语言，忽略了更常用的非正式语言，导致数百万孟加拉语使用者无法充分获取在线信息。

Method: 研究探索当前最先进的翻译模型，并从社交媒体和对话文本等非正式来源开发孟加拉语-英语配对数据集，以改进对自然、非正式孟加拉语的翻译能力。

Result: 论文未提供具体实验结果，但研究目标是开发改进的数据集和模型，以更好地处理非正式孟加拉语翻译。

Conclusion: 通过专注于非正式语言翻译并改进数据集，这项研究旨在推进孟加拉语机器翻译，提高孟加拉语使用者在数字世界中的信息可及性。

Abstract: Bangla is the sixth most widely spoken language globally, with approximately 234 million native speakers. However, progress in open-source Bangla machine translation remains limited. Most online resources are in English and often remain untranslated into Bangla, excluding millions from accessing essential information. Existing research in Bangla translation primarily focuses on formal language, neglecting the more commonly used informal language. This is largely due to the lack of pairwise Bangla-English data and advanced translation models. If datasets and models can be enhanced to better handle natural, informal Bangla, millions of people will benefit from improved online information access. In this research, we explore current state-of-the-art models and propose improvements to Bangla translation by developing a dataset from informal sources like social media and conversational texts. This work aims to advance Bangla machine translation by focusing on informal language translation and improving accessibility for Bangla speakers in the digital world.

</details>


### [55] [SkipCat: Rank-Maximized Low-Rank Compression of Large Language Models via Shared Projection and Block Skipping](https://arxiv.org/abs/2512.13494)
*Yu-Chen Lu,Sheng-Feng Yu,Hui-Hsien Weng,Pei-Shuo Wang,Yu-Fang Hu,Liang Hung-Chun,Hung-Yueh Chiang,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SkipCat是一种新颖的低秩压缩框架，通过层内共享低秩投影和块跳过技术，在相同压缩率下保留更多有效秩，显著提升压缩模型性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数规模庞大，难以部署在计算和内存资源有限的边缘设备上。传统低秩压缩方法需要大幅降低保留秩才能获得效率提升，但这样会导致严重的性能下降，需要在压缩效率和模型性能之间寻找更好的平衡

Method: 提出SkipCat框架：1）层内共享低秩投影 - 多个共享相同输入的矩阵使用共同投影，减少冗余；2）块跳过技术 - 在低秩分解中省略选定子块的计算和内存传输。这两种技术共同使压缩模型在相同压缩预算下保留更多有效秩

Result: 实验结果显示，在相同压缩率下，无需额外微调，该方法比先前低秩压缩方法在零样本任务上准确率提升7%。这证明了在严格资源约束下，秩最大化压缩策略在保持模型性能方面的有效性

Conclusion: SkipCat通过创新的低秩压缩方法，在保持相同压缩率的同时显著提升了压缩模型的性能，为大语言模型在资源受限环境中的部署提供了更有效的解决方案

Abstract: Large language models (LLM) have achieved remarkable performance across a wide range of tasks. However, their substantial parameter sizes pose significant challenges for deployment on edge devices with limited computational and memory resources. Low-rank compression is a promising approach to address this issue, as it reduces both computational and memory costs, making LLM more suitable for resource-constrained environments. Nonetheless, naïve low-rank compression methods require a significant reduction in the retained rank to achieve meaningful memory and computation savings. For a low-rank model, the ranks need to be reduced by more than half to yield efficiency gains. Such aggressive truncation, however, typically results in substantial performance degradation. To address this trade-off, we propose SkipCat, a novel low-rank compression framework that enables the use of higher ranks while achieving the same compression rates. First, we introduce an intra-layer shared low-rank projection method, where multiple matrices that share the same input use a common projection. This reduces redundancy and improves compression efficiency. Second, we propose a block skipping technique that omits computations and memory transfers for selected sub-blocks within the low-rank decomposition. These two techniques jointly enable our compressed model to retain more effective ranks under the same compression budget. Experimental results show that, without any additional fine-tuning, our method outperforms previous low-rank compression approaches by 7% accuracy improvement on zero-shot tasks under the same compression rate. These results highlight the effectiveness of our rank-maximized compression strategy in preserving model performance under tight resource constraints.

</details>


### [56] [PrahokBART: A Pre-trained Sequence-to-Sequence Model for Khmer Natural Language Generation](https://arxiv.org/abs/2512.13552)
*Hour Kaing,Raj Dabre,Haiyue Song,Van-Hien Tran,Hideki Tanaka,Masao Utiyama*

Main category: cs.CL

TL;DR: 提出PrahokBART，一个专门为高棉语从头训练的紧凑型序列到序列预训练模型，通过融入分词和规范化等语言学组件解决现有多语言模型忽略的高棉语语言问题，在机器翻译、文本摘要和标题生成任务上优于mBART50。


<details>
  <summary>Details</summary>
Motivation: 现有多语言模型忽略高棉语的语言学特性，特别是在预训练语料质量和语言处理方面存在问题。需要专门针对高棉语开发预训练模型，解决分词、规范化等语言处理挑战。

Method: 使用精心筛选的高棉语和英语语料从头训练紧凑型序列到序列模型，融入分词和规范化等语言学组件，专门处理高棉语的语言特性。

Result: 在机器翻译、文本摘要和标题生成三个生成任务上，PrahokBART的表现优于强大的多语言预训练模型mBART50。分析还揭示了各语言学模块的影响，并评估了模型处理空格的有效性，这对高棉语文本的自然性至关重要。

Conclusion: 专门针对高棉语设计的预训练模型PrahokBART通过融入语言学组件，能够有效处理高棉语的语言特性，在多个生成任务上优于通用多语言模型，为低资源语言建模提供了有价值的见解。

Abstract: This work introduces {\it PrahokBART}, a compact pre-trained sequence-to-sequence model trained from scratch for Khmer using carefully curated Khmer and English corpora. We focus on improving the pre-training corpus quality and addressing the linguistic issues of Khmer, which are ignored in existing multilingual models, by incorporating linguistic components such as word segmentation and normalization. We evaluate PrahokBART on three generative tasks: machine translation, text summarization, and headline generation, where our results demonstrate that it outperforms mBART50, a strong multilingual pre-trained model. Additionally, our analysis provides insights into the impact of each linguistic module and evaluates how effectively our model handles space during text generation, which is crucial for the naturalness of texts in Khmer.

</details>


### [57] [Verifying Rumors via Stance-Aware Structural Modeling](https://arxiv.org/abs/2512.13559)
*Gibson Nkhata,Uttamasha Anjally Oyshi,Quan Mai,Susan Gauch*

Main category: cs.CL

TL;DR: 提出一种基于立场感知的结构化建模方法，用于社交媒体谣言验证，通过结合立场信号、对话结构和层次深度显著提升谣言真实性预测性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体谣言验证对遏制虚假信息传播至关重要。现有模型难以同时捕捉语义内容、立场信息和对话结构，特别是在基于Transformer的编码器序列长度限制下。

Method: 提出立场感知结构化建模：1) 用立场信号编码每个帖子；2) 按立场类别聚合回复嵌入，实现可扩展且语义丰富的线程表示；3) 引入立场分布和层次深度作为协变量，捕捉立场不平衡和回复深度的影响。

Result: 在基准数据集上的广泛实验表明，该方法在预测谣言真实性方面显著优于现有方法，同时证明模型在早期检测和跨平台泛化方面具有良好适应性。

Conclusion: 提出的立场感知结构化建模方法有效整合了语义内容、立场信息和对话结构，为社交媒体谣言验证提供了更强大的解决方案，具有实际应用价值。

Abstract: Verifying rumors on social media is critical for mitigating the spread of false information. The stances of conversation replies often provide important cues to determine a rumor's veracity. However, existing models struggle to jointly capture semantic content, stance information, and conversation strructure, especially under the sequence length constraints of transformer-based encoders. In this work, we propose a stance-aware structural modeling that encodes each post in a discourse with its stance signal and aggregates reply embedddings by stance category enabling a scalable and semantically enriched representation of the entire thread. To enhance structural awareness, we introduce stance distribution and hierarchical depth as covariates, capturing stance imbalance and the influence of reply depth. Extensive experiments on benchmark datasets demonstrate that our approach significantly outperforms prior methods in the ability to predict truthfulness of a rumor. We also demonstrate that our model is versatile for early detection and cross-platfrom generalization.

</details>


### [58] [Memory in the Age of AI Agents](https://arxiv.org/abs/2512.13564)
*Yuyang Hu,Shichun Liu,Yanwei Yue,Guibin Zhang,Boyang Liu,Fangyi Zhu,Jiahang Lin,Honglin Guo,Shihan Dou,Zhiheng Xi,Senjie Jin,Jiejun Tan,Yanbin Yin,Jiongnan Liu,Zeyu Zhang,Zhongxiang Sun,Yutao Zhu,Hao Sun,Boci Peng,Zhenrong Cheng,Xuanbo Fan,Jiaxin Guo,Xinlei Yu,Zhenhong Zhou,Zewen Hu,Jiahao Huo,Junhao Wang,Yuwei Niu,Yu Wang,Zhenfei Yin,Xiaobin Hu,Yue Liao,Qiankun Li,Kun Wang,Wangchunshu Zhou,Yixin Liu,Dawei Cheng,Qi Zhang,Tao Gui,Shirui Pan,Yan Zhang,Philip Torr,Zhicheng Dou,Ji-Rong Wen,Xuanjing Huang,Yu-Gang Jiang,Shuicheng Yan*

Main category: cs.CL

TL;DR: 该论文对智能体记忆研究进行了系统综述，提出了基于形式、功能和动态的三维分析框架，并总结了当前进展与未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着基于基础模型的智能体研究迅速发展，记忆作为其核心能力受到广泛关注，但该领域存在概念模糊、分类混乱、评价标准不统一等问题，需要系统性的梳理和概念澄清。

Method: 通过三维分析框架：1) 形式维度：识别token级、参数化和潜在记忆三种实现方式；2) 功能维度：提出事实记忆、经验记忆和工作记忆的细粒度分类；3) 动态维度：分析记忆的形成、演化和检索过程。

Result: 建立了清晰的智能体记忆概念边界，区分了LLM记忆、RAG和上下文工程等相关概念；提供了全面的记忆基准测试和开源框架总结；识别了当前研究的关键实现方式。

Conclusion: 该综述不仅为现有工作提供参考，更重要的是为重新思考记忆作为未来智能体设计的一等公民提供了概念基础，并指出了记忆自动化、强化学习集成、多模态记忆、多智能体记忆和可信度等前沿研究方向。

Abstract: Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.

</details>


### [59] [ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding](https://arxiv.org/abs/2512.13586)
*Jia-Nan Li,Jian Guan,Wei Wu,Chongxuan Li*

Main category: cs.CL

TL;DR: ReFusion提出了一种新的掩码扩散模型，通过将并行解码从token级别提升到slot级别，采用"规划-填充"的两阶段解码过程，解决了传统掩码扩散模型的计算开销大和生成不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 自回归模型存在顺序推理慢的问题，而掩码扩散模型虽然提供并行替代方案，但存在两个关键缺陷：1）由于无法使用KV缓存导致计算开销高；2）在难以处理的token组合空间上学习依赖关系导致生成不连贯。

Method: ReFusion采用slot级别的并行解码，每个slot是固定长度的连续子序列。使用两阶段解码过程：1）基于扩散的规划步骤识别一组弱依赖的slot；2）自回归填充步骤并行解码这些选定的slot。slot设计实现了KV缓存重用，并将学习复杂度从token组合空间降低到可管理的slot排列空间。

Result: 在七个不同基准测试上的广泛实验表明，ReFusion不仅以34%的性能提升和超过18倍的平均加速显著超越先前的掩码扩散模型，而且在保持2.33倍平均加速的同时，缩小了与强自回归模型的性能差距。

Conclusion: ReFusion通过slot级别的并行解码设计，有效解决了掩码扩散模型的计算效率和生成质量问题，在性能和速度之间取得了良好平衡，为并行文本生成提供了有前景的解决方案。

Abstract: Autoregressive models (ARMs) are hindered by slow sequential inference. While masked diffusion models (MDMs) offer a parallel alternative, they suffer from critical drawbacks: high computational overhead from precluding Key-Value (KV) caching, and incoherent generation arising from learning dependencies over an intractable space of token combinations. To address these limitations, we introduce ReFusion, a novel masked diffusion model that achieves superior performance and efficiency by elevating parallel decoding from the token level to a higher slot level, where each slot is a fixed-length, contiguous sub-sequence. This is achieved through an iterative ``plan-and-infill'' decoding process: a diffusion-based planning step first identifies a set of weakly dependent slots, and an autoregressive infilling step then decodes these selected slots in parallel. The slot-based design simultaneously unlocks full KV cache reuse with a unified causal framework and reduces the learning complexity from the token combination space to a manageable slot-level permutation space. Extensive experiments on seven diverse benchmarks show that ReFusion not only overwhelmingly surpasses prior MDMs with 34% performance gains and an over 18$\times$ speedup on average, but also bridges the performance gap to strong ARMs while maintaining a 2.33$\times$ average speedup.

</details>


### [60] [Textual Gradients are a Flawed Metaphor for Automatic Prompt Optimization](https://arxiv.org/abs/2512.13598)
*Daniel Melcer,Qi Chen,Wen-Hao Chiang,Shweta Garg,Pranav Garg,Christian Bock*

Main category: cs.CL

TL;DR: 文本梯度方法能提升LLM性能，但梯度类比并不能准确解释其行为机制


<details>
  <summary>Details</summary>
Motivation: 研究自动提示优化技术中的文本梯度方法，探究其实际工作原理是否如梯度类比所描述

Method: 通过一系列实验和案例研究，分析文本梯度方法的实际行为表现

Result: 文本梯度方法通常能提升性能，但梯度类比并不能准确解释其行为机制

Conclusion: 研究结果可为提示优化策略的选择和新方法的开发提供参考

Abstract: A well-engineered prompt can increase the performance of large language models; automatic prompt optimization techniques aim to increase performance without requiring human effort to tune the prompts. One leading class of prompt optimization techniques introduces the analogy of textual gradients. We investigate the behavior of these textual gradient methods through a series of experiments and case studies. While such methods often result in a performance improvement, our experiments suggest that the gradient analogy does not accurately explain their behavior. Our insights may inform the selection of prompt optimization strategies, and development of new approaches.

</details>


### [61] [Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models](https://arxiv.org/abs/2512.13607)
*Boxin Wang,Chankyu Lee,Nayeon Lee,Sheng-Chieh Lin,Wenliang Dai,Yang Chen,Yangyi Chen,Zhuolin Yang,Zihan Liu,Mohammad Shoeybi,Bryan Catanzaro,Wei Ping*

Main category: cs.CL

TL;DR: 提出Cascade RL方法训练通用推理模型Nemotron-Cascade，通过顺序域强化学习解决跨域异质性问题，在多个基准上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在处理跨域推理任务时面临异质性挑战，包括响应长度差异大、验证延迟不同等问题，导致基础设施复杂、训练缓慢、课程设计和超参数选择困难

Method: 提出级联域强化学习(Cascade RL)，采用顺序域RL而非混合异质提示，先进行RLHF对齐提升推理能力，再进行域RLVR阶段，保持或提升先前域的性能

Result: 14B模型在RL后超越其SFT教师DeepSeek-R1-0528，在LiveCodeBench v5/v6/Pro上表现优异，在2025年IOI中获得银牌成绩

Conclusion: Cascade RL能有效解决跨域异质性问题，简化工程复杂度，实现通用推理模型的SOTA性能，并公开分享了训练和数据方案

Abstract: Building general-purpose reasoning models with reinforcement learning (RL) entails substantial cross-domain heterogeneity, including large variation in inference-time response lengths and verification latency. Such variability complicates the RL infrastructure, slows training, and makes training curriculum (e.g., response length extension) and hyperparameter selection challenging. In this work, we propose cascaded domain-wise reinforcement learning (Cascade RL) to develop general-purpose reasoning models, Nemotron-Cascade, capable of operating in both instruct and deep thinking modes. Departing from conventional approaches that blend heterogeneous prompts from different domains, Cascade RL orchestrates sequential, domain-wise RL, reducing engineering complexity and delivering state-of-the-art performance across a wide range of benchmarks. Notably, RLHF for alignment, when used as a pre-step, boosts the model's reasoning ability far beyond mere preference optimization, and subsequent domain-wise RLVR stages rarely degrade the benchmark performance attained in earlier domains and may even improve it (see an illustration in Figure 1). Our 14B model, after RL, outperforms its SFT teacher, DeepSeek-R1-0528, on LiveCodeBench v5/v6/Pro and achieves silver-medal performance in the 2025 International Olympiad in Informatics (IOI). We transparently share our training and data recipes.

</details>


### [62] [Temporal Tokenization Strategies for Event Sequence Modeling with Large Language Models](https://arxiv.org/abs/2512.13618)
*Zefang Liu,Nam Nguyen,Yinzhu Quan,Austin Zhang*

Main category: cs.CL

TL;DR: 本文首次对事件序列的时间标记化进行实证研究，比较了五种编码策略在不同统计分布数据上的表现，发现没有单一最优策略，性能取决于标记器与数据统计特性的匹配程度。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型建模时间事件序列时，连续时间表示是一个关键但研究不足的挑战。现有策略如字节级表示或日历标记等，但最优方法仍不明确，特别是考虑到现实世界事件数据具有多样化的统计分布（从平滑的对数正态分布到离散的尖峰模式）。

Method: 比较五种不同的时间编码策略：朴素数字字符串、高精度字节级表示、人类语义日历标记、经典均匀分箱和自适应残差标量量化。通过在体现这些多样化分布的真实世界数据集上微调大型语言模型来评估这些策略。

Result: 分析表明没有单一策略是普遍最优的；预测性能很大程度上取决于标记器与数据统计特性的对齐程度。基于对数的策略在偏斜分布上表现优异，而人类中心格式在混合模态上表现出鲁棒性。

Conclusion: 时间标记化策略的选择应基于数据的统计特性进行匹配，没有适用于所有情况的通用最优方法。对数策略适合偏斜分布，人类语义格式适合混合模态。

Abstract: Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte-level representations, human-semantic calendar tokens, classic uniform binning, and adaptive residual scalar quantization. We evaluate these strategies by fine-tuning LLMs on real-world datasets that exemplify these diverse distributions. Our analysis reveals that no single strategy is universally superior; instead, prediction performance depends heavily on aligning the tokenizer with the data's statistical properties, with log-based strategies excelling on skewed distributions and human-centric formats proving robust for mixed modalities.

</details>


### [63] [Large-Language Memorization During the Classification of United States Supreme Court Cases](https://arxiv.org/abs/2512.13654)
*John E. Ortega,Dhruv D. Joshi,Matt P. Borkowski*

Main category: cs.CL

TL;DR: 该论文研究了大型语言模型在最高法院判决分类任务中的记忆准确性，发现基于提示的模型比传统BERT模型表现更好


<details>
  <summary>Details</summary>
Motivation: 研究LLM在分类任务中的记忆策略和准确性，特别是针对具有挑战性的最高法院判决分类任务，以理解LLM如何响应和处理复杂领域特定内容

Method: 使用最新的LLM微调和检索方法，包括参数高效微调、自动建模等，在两个最高法院判决分类任务（15个标签主题和279个标签主题）上进行实验

Result: 基于提示的模型（如DeepSeek）比之前的BERT模型更稳健，在两个任务上都比非提示模型高出约2分

Conclusion: 基于提示的模型在复杂法律文本分类任务中表现出更好的记忆准确性和鲁棒性，为LLM在专业领域应用提供了有价值的见解

Abstract: Large-language models (LLMs) have been shown to respond in a variety of ways for classification tasks outside of question-answering. LLM responses are sometimes called "hallucinations" since the output is not what is ex pected. Memorization strategies in LLMs are being studied in detail, with the goal of understanding how LLMs respond. We perform a deep dive into a classification task based on United States Supreme Court (SCOTUS) decisions. The SCOTUS corpus is an ideal classification task to study for LLM memory accuracy because it presents significant challenges due to extensive sentence length, complex legal terminology, non-standard structure, and domain-specific vocabulary. Experimentation is performed with the latest LLM fine tuning and retrieval-based approaches, such as parameter-efficient fine-tuning, auto-modeling, and others, on two traditional category-based SCOTUS classification tasks: one with 15 labeled topics and another with 279. We show that prompt-based models with memories, such as DeepSeek, can be more robust than previous BERT-based models on both tasks scoring about 2 points better than previous models not based on prompting.

</details>


### [64] [Comparative Analysis of LLM Abliteration Methods: A Cross-Architecture Evaluation](https://arxiv.org/abs/2512.13655)
*Richard J. Young*

Main category: cs.CL

TL;DR: 评估四种去拒绝化工具（Heretic、DECCP、ErisForge、FailSpy）在16个指令调优模型上的效果，发现单次通过方法在能力保留上表现更好，而贝叶斯优化方法产生可变分布偏移，数学推理能力对去拒绝化干预最敏感。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全对齐机制通过学习的拒绝行为防止对有害查询的响应，但这些机制也阻碍了包括认知建模、对抗测试和安全分析在内的合法研究应用。虽然去拒绝化技术能够通过方向正交化手术式地移除拒绝表示，但现有实现方法的相对效果尚未被系统评估。

Method: 本研究评估了四种去拒绝化工具（Heretic、DECCP、ErisForge、FailSpy）在16个指令调优模型（7B-14B参数）上的表现。报告了所有16个模型的工具兼容性，并根据工具支持情况在子集上报告了定量指标。评估了单次通过方法和贝叶斯优化去拒绝化方法的效果。

Result: 单次通过方法在基准子集上表现出更好的能力保留（三个模型的平均GSM8K变化：ErisForge -0.28 pp；DECCP -0.13 pp）。贝叶斯优化去拒绝化产生可变的分布偏移（KL散度：0.043-1.646），具有模型依赖的能力影响。数学推理能力对去拒绝化干预最敏感，GSM8K变化范围从+1.51 pp到-18.81 pp（相对-26.5%），具体取决于工具选择和模型架构。

Conclusion: 研究结果为研究人员提供了基于证据的去拒绝化工具选择标准，适用于不同的模型架构。主要发现表明数学推理能力对去拒绝化干预最为敏感，工具选择和模型架构对能力保留有显著影响。

Abstract: Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B-14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support. Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K change across three models: ErisForge -0.28 pp; DECCP -0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.043-1.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to -18.81 pp (-26.5% relative) depending on tool selection and model architecture.

</details>


### [65] [A stylometric analysis of speaker attribution from speech transcripts](https://arxiv.org/abs/2512.13667)
*Cristina Aggazzotti,Elizabeth Allyn Smith*

Main category: cs.CL

TL;DR: 本文提出了一种名为StyloSpeaker的说话人归属方法，将作者归属的文体计量学方法应用于语音转录文本，通过分析说话内容而非声音特征来识别说话人。


<details>
  <summary>Details</summary>
Motivation: 当说话人伪装声音或使用文本转语音软件时，传统的声学语音识别方法可能失效，此时只能依赖语言内容进行分析。需要开发基于内容的说话人归属方法。

Method: 提出StyloSpeaker方法，从文体计量学文献中提取字符、单词、标记、句子和风格特征，评估两个转录文本是否由同一说话人产生。比较两种转录格式（规范书面文本格式和标准化格式）和不同话题控制条件下的性能。

Result: 在标准化转录格式下获得更高的归属性能，但在最强话题控制条件下整体性能最高。与黑盒神经方法相比，这种可解释的文体计量模型表现良好，并识别出最能区分说话人的风格特征。

Conclusion: 基于内容的说话人归属方法在语音转录文本中有效，特别是在标准化转录格式和适当话题控制条件下。StyloSpeaker提供了一种可解释的替代方案，能够识别区分说话人的关键风格特征。

Abstract: Forensic scientists often need to identify an unknown speaker or writer in cases such as ransom calls, covert recordings, alleged suicide notes, or anonymous online communications, among many others. Speaker recognition in the speech domain usually examines phonetic or acoustic properties of a voice, and these methods can be accurate and robust under certain conditions. However, if a speaker disguises their voice or employs text-to-speech software, vocal properties may no longer be reliable, leaving only their linguistic content available for analysis. Authorship attribution methods traditionally use syntactic, semantic, and related linguistic information to identify writers of written text (authorship attribution). In this paper, we apply a content-based authorship approach to speech that has been transcribed into text, using what a speaker says to attribute speech to individuals (speaker attribution). We introduce a stylometric method, StyloSpeaker, which incorporates character, word, token, sentence, and style features from the stylometric literature on authorship, to assess whether two transcripts were produced by the same speaker. We evaluate this method on two types of transcript formatting: one approximating prescriptive written text with capitalization and punctuation and another normalized style that removes these conventions. The transcripts' conversation topics are also controlled to varying degrees. We find generally higher attribution performance on normalized transcripts, except under the strongest topic control condition, in which overall performance is highest. Finally, we compare this more explainable stylometric model to black-box neural approaches on the same data and investigate which stylistic features most effectively distinguish speakers.

</details>


### [66] [Towards Effective Model Editing for LLM Personalization](https://arxiv.org/abs/2512.13676)
*Baixiang Huang,Limeng Cui,Jiapeng Liu,Haoran Wang,Jiawei Xu,Zhuiyue Tan,Yutong Chen,Chen Luo,Yi Liu,Kai Shu*

Main category: cs.CL

TL;DR: 论文提出Personalization Editing框架，将个性化视为模型编辑任务，通过聚类偏好表示指导局部编辑，实现精确偏好对齐同时保持模型整体能力，并在新基准UPQA上验证效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM个性化方法存在计算成本高、数据密集、易发生灾难性遗忘、多轮交互或处理隐式查询时性能下降等问题。现有基准多依赖LLM间对话而非真实用户交互，且偏重风格模仿而忽视需要准确回忆用户偏好的信息寻求任务。

Method: 将个性化概念化为模型编辑任务，提出Personalization Editing框架，通过聚类偏好表示指导局部编辑，实现精确的偏好对齐更新，同时保持模型整体能力。引入UPQA数据集，基于真实用户查询构建短答案QA数据集，直接评估模型回忆和应用特定用户偏好的能力。

Result: Personalization Editing在编辑准确性和计算效率方面优于微调方法，在多轮对话和隐式偏好问题设置中优于基于提示的基线方法。

Conclusion: 将个性化视为模型编辑任务并通过聚类偏好表示指导局部编辑是有效的解决方案，能够实现精确偏好对齐同时保持模型能力，UPQA数据集为评估个性化能力提供了更真实的基准。

Abstract: Personalization is becoming indispensable for LLMs to align with individual user preferences and needs. Yet current approaches are often computationally expensive, data-intensive, susceptible to catastrophic forgetting, and prone to performance degradation in multi-turn interactions or when handling implicit queries. To address these challenges, we conceptualize personalization as a model editing task and introduce Personalization Editing, a framework that applies localized edits guided by clustered preference representations. This design enables precise preference-aligned updates while preserving overall model capabilities. In addition, existing personalization benchmarks frequently rely on persona-based dialogs between LLMs rather than user-LLM interactions, or focus primarily on stylistic imitation while neglecting information-seeking tasks that require accurate recall of user-specific preferences. We introduce User Preference Question Answering (UPQA), a short-answer QA dataset constructed from in-situ user queries with varying levels of difficulty. Unlike prior benchmarks, UPQA directly evaluates a model's ability to recall and apply specific user preferences. Across experimental settings, Personalization Editing achieves higher editing accuracy and greater computational efficiency than fine-tuning, while outperforming prompting-based baselines in multi-turn conversations and implicit preference questions settings.

</details>


### [67] [Beyond surface form: A pipeline for semantic analysis in Alzheimer's Disease detection from spontaneous speech](https://arxiv.org/abs/2512.13685)
*Dylan Phelps,Rodrigo Wilkens,Edward Gow-Smith,Lilian Hubner,Bárbara Malcorra,César Rennó-Costa,Marco Idiart,Maria-Cruz Villa-Uriol,Aline Villavicencio*

Main category: cs.CL

TL;DR: 该研究提出了一种通过语义保持的文本转换方法，评估语言模型在阿尔茨海默病检测中是否真正捕捉语义特征而非表面文本模式，发现仅凭语义信息模型仍能有效检测AD。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）会导致语言能力下降，语言模型有望用于AD筛查，但其可解释性有限，难以区分真正的认知衰退语言标记与表面文本模式。需要评估模型是否真正捕捉底层语义指标。

Method: 提出新颖方法：通过改变句法和词汇但保持语义内容来转换文本表面形式。使用BLEU、chrF和语义相似度评分验证转换效果。同时研究图片描述语言是否包含足够细节用于图像重建，并分析图像转换对分类的影响。

Result: 文本转换显著改变了结构和词汇内容（低BLEU/chrF评分），但保持了底层语义（高语义相似度）。模型在转换文本上的表现与原始文本相似（仅微小F1偏差）。图像转换会添加大量噪声降低分类准确率。仅使用语义信息，基于语言模型的分类器仍能检测AD。

Conclusion: 该方法提供了一种新颖视角来分析影响模型预测的特征，能够消除可能的虚假相关性。研究表明难以检测的语义损伤可以被识别，这解决了语言退化中被忽视的特征，为早期检测系统开辟了新途径。

Abstract: Alzheimer's Disease (AD) is a progressive neurodegenerative condition that adversely affects cognitive abilities. Language-related changes can be automatically identified through the analysis of outputs from linguistic assessment tasks, such as picture description. Language models show promise as a basis for screening tools for AD, but their limited interpretability poses a challenge in distinguishing true linguistic markers of cognitive decline from surface-level textual patterns. To address this issue, we examine how surface form variation affects classification performance, with the goal of assessing the ability of language models to represent underlying semantic indicators. We introduce a novel approach where texts surface forms are transformed by altering syntax and vocabulary while preserving semantic content. The transformations significantly modify the structure and lexical content, as indicated by low BLEU and chrF scores, yet retain the underlying semantics, as reflected in high semantic similarity scores, isolating the effect of semantic information, and finding models perform similarly to if they were using the original text, with only small deviations in macro-F1. We also investigate whether language from picture descriptions retains enough detail to reconstruct the original image using generative models. We found that image-based transformations add substantial noise reducing classification accuracy. Our methodology provides a novel way of looking at what features influence model predictions, and allows the removal of possible spurious correlations. We find that just using semantic information, language model based classifiers can still detect AD. This work shows that difficult to detect semantic impairment can be identified, addressing an overlooked feature of linguistic deterioration, and opening new pathways for early detection systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [68] [Benchmarking Tesla's Traffic Light and Stop Sign Control: Field Dataset and Behavior Insights](https://arxiv.org/abs/2512.11802)
*Zheng Li,Peng Zhang,Shixiao Liang,Hang Zhou,Chengyuan Ma,Handong Yao,Qianwen Li,Xiaopeng Li*

Main category: cs.RO

TL;DR: 研究特斯拉交通灯和停车标志控制系统(TLSSC)与交通控制设备(TCD)的交互行为，通过实地实验收集数据，建立行为分类并校准FVDM模型，发现跟车阈值约90米等新见解。


<details>
  <summary>Details</summary>
Motivation: 高级驾驶辅助系统(ADAS)与交通控制设备(TCD)的交互对交通运行评估至关重要，但这一领域缺乏深入的实证研究。特斯拉的TLSSC系统作为成熟的ADAS，其与TCD的交互行为需要系统分析。

Method: 设计并执行不同限速和TCD类型的实验，收集同步的高分辨率车辆轨迹数据和驾驶员视角视频。基于数据建立TLSSC-TCD交互行为分类（停车、加速、跟车），并校准全速度差模型(FVDM)来定量表征每种行为模式。

Result: 发现跟车阈值约90米的新经验见解。校准结果显示：停车行为对期望速度偏差和相对速度都有强烈响应；加速行为更为保守；交叉口跟车行为比标准跟车行为具有更平滑的动态特性和更小的车头时距。

Conclusion: 建立的数据集、行为定义和模型表征为未来ADAS-TCD交互逻辑的仿真、安全评估和设计提供了基础。数据集已在GitHub上公开。

Abstract: Understanding how Advanced Driver-Assistance Systems (ADAS) interact with Traffic Control Devices (TCDs) is critical for assessing their influence on traffic operations, yet this interaction has received little focused empirical study. This paper presents a field dataset and behavioral analysis of Tesla's Traffic Light and Stop Sign Control (TLSSC), a mature ADAS that perceives traffic lights and stop signs. We design and execute experiments across varied speed limits and TCD types, collecting synchronized high-resolution vehicle trajectory data and driver-perspective video. From these data, we develop a taxonomy of TLSSC-TCD interaction behaviors (i.e., stopping, accelerating, and car following) and calibrate the Full Velocity Difference Model (FVDM) to quantitatively characterize each behavior mode. A novel empirical insight is the identification of a car-following threshold (~90 m). Calibration results reveal that stopping behavior is driven by strong responsiveness to both desired speed deviation and relative speed, whereas accelerating behavior is more conservative. Intersection car-following behavior exhibits smoother dynamics and tighter headways compared to standard car-following behaviors. The established dataset, behavior definitions, and model characterizations together provide a foundation for future simulation, safety evaluation, and design of ADAS-TCD interaction logic. Our dataset is available at GitHub.

</details>


### [69] [ReGlove: A Soft Pneumatic Glove for Activities of Daily Living Assistance via Wrist-Mounted Vision](https://arxiv.org/abs/2512.11824)
*Rosh Ho,Jian Zhang*

Main category: cs.RO

TL;DR: ReGlove将低成本商业气动康复手套改造为视觉引导辅助矫形器，通过手腕摄像头和边缘计算实现无需可靠肌肉信号的上下文感知抓握，成本低于250美元。


<details>
  <summary>Details</summary>
Motivation: 慢性上肢障碍影响全球数百万人，现有辅助技术要么过于昂贵，要么依赖不可靠的生物信号，需要更经济、可靠的解决方案。

Method: 整合手腕摄像头与边缘计算推理引擎（Raspberry Pi 5），采用实时YOLO计算机视觉模型，将低成本商业气动康复手套改造为视觉引导辅助系统。

Result: 实现96.73%的抓握分类准确率，端到端延迟低于40毫秒；在YCB物体操作测试中达到82.71%成功率，在27项日常生活活动任务中表现可靠。

Conclusion: ReGlove为基于视觉的上肢辅助提供了技术基础，成本低于250美元，使用全商业组件，可惠及被传统EMG控制设备排除在外的人群。

Abstract: This paper presents ReGlove, a system that converts low-cost commercial pneumatic rehabilitation gloves into vision-guided assistive orthoses. Chronic upper-limb impairment affects millions worldwide, yet existing assistive technologies remain prohibitively expensive or rely on unreliable biological signals. Our platform integrates a wrist-mounted camera with an edge-computing inference engine (Raspberry Pi 5) to enable context-aware grasping without requiring reliable muscle signals. By adapting real-time YOLO-based computer vision models, the system achieves \SI{96.73}{\percent} grasp classification accuracy with sub-\SI{40.00}{\milli\second} end-to-end latency. Physical validation using standardized benchmarks shows \SI{82.71}{\percent} success on YCB object manipulation and reliable performance across \SI{27.00}{} Activities of Daily Living (ADL) tasks. With a total cost under \$\SI{250.00}{} and exclusively commercial components, ReGlove provides a technical foundation for accessible, vision-based upper-limb assistance that could benefit populations excluded from traditional EMG-controlled devices.

</details>


### [70] [WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2512.11872)
*Mingwang Xu,Jiahao Cui,Feipeng Cai,Hanlin Shang,Zhihao Zhu,Shan Luan,Yifang Xu,Neng Zhang,Yaoyi Li,Jia Cai,Siyu Zhu*

Main category: cs.RO

TL;DR: WAM-Diff是一个基于掩码扩散的视觉-语言-动作自动驾驶框架，采用离散序列迭代优化未来轨迹，在NAVSIM基准上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统主要使用自回归大语言模型和连续扩散策略，而离散掩码扩散在轨迹生成方面的潜力尚未充分探索。本文旨在探索掩码扩散作为自回归和扩散策略的替代方案。

Method: 提出WAM-Diff框架：1）系统地将掩码扩散适配到自动驾驶，支持灵活的非因果解码顺序；2）通过稀疏MoE架构联合训练运动预测和驾驶导向的视觉问答；3）使用GSPO在线强化学习优化序列级驾驶奖励。

Result: 在NAVSIM-v1上达到91.0 PDMS，在NAVSIM-v2上达到89.7 EPDMS，证明了掩码扩散在自动驾驶中的有效性。

Conclusion: 掩码扩散为自动驾驶轨迹生成提供了有前景的替代方案，支持场景感知的解码策略，是自回归和扩散策略的有效补充。

Abstract: End-to-end autonomous driving systems based on vision-language-action (VLA) models integrate multimodal sensor inputs and language instructions to generate planning and control signals. While autoregressive large language models and continuous diffusion policies are prevalent, the potential of discrete masked diffusion for trajectory generation remains largely unexplored. This paper presents WAM-Diff, a VLA framework that employs masked diffusion to iteratively refine a discrete sequence representing future ego-trajectories. Our approach features three key innovations: a systematic adaptation of masked diffusion for autonomous driving that supports flexible, non-causal decoding orders; scalable model capacity via a sparse MoE architecture trained jointly on motion prediction and driving-oriented visual question answering (VQA); and online reinforcement learning using Group Sequence Policy Optimization (GSPO) to optimize sequence-level driving rewards. Remarkably, our model achieves 91.0 PDMS on NAVSIM-v1 and 89.7 EPDMS on NAVSIM-v2, demonstrating the effectiveness of masked diffusion for autonomous driving. The approach provides a promising alternative to autoregressive and diffusion-based policies, supporting scenario-aware decoding strategies for trajectory generation. The code for this paper will be released publicly at: https://github.com/fudan-generative-vision/WAM-Diff

</details>


### [71] [Audio-Based Tactile Human-Robot Interaction Recognition](https://arxiv.org/abs/2512.11873)
*Antonia Yepes,Marie Charbonneau*

Main category: cs.RO

TL;DR: 使用机器人身体上的麦克风通过触摸硬壳产生的声音来检测触觉交互，作为传统关节扭矩或6轴力/扭矩传感器的替代方案


<details>
  <summary>Details</summary>
Motivation: 传统触觉检测方法（如关节扭矩传感器或6轴力/扭矩传感器）成本高且复杂，需要探索更简单、成本更低的替代方案

Method: 在机器人躯干上安装两个Adafruit I2S MEMS麦克风，通过Raspberry Pi 4采集机器人手臂上不同触摸类型（敲击、轻敲、摩擦、抚摸、抓挠、按压）产生的声音信号，使用卷积神经网络对336个预处理样本进行分类

Result: 模型在具有明显声学主频的触摸类型之间显示出高分类准确率

Conclusion: 基于声音的触觉检测是传统触觉传感器的可行替代方案，特别是在具有明显声学特征的触摸类型识别方面表现良好

Abstract: This study explores the use of microphones placed on a robot's body to detect tactile interactions via sounds produced when the hard shell of the robot is touched. This approach is proposed as an alternative to traditional methods using joint torque sensors or 6-axis force/torque sensors. Two Adafruit I2S MEMS microphones integrated with a Raspberry Pi 4 were positioned on the torso of a Pollen Robotics Reachy robot to capture audio signals from various touch types on the robot arms (tapping, knocking, rubbing, stroking, scratching, and pressing). A convolutional neural network was trained for touch classification on a dataset of 336 pre-processed samples (48 samples per touch type). The model shows high classification accuracy between touch types with distinct acoustic dominant frequencies.

</details>


### [72] [Traversability Aware Autonomous Navigation for Multi-Modal Mobility Morphobot (M4)](https://arxiv.org/abs/2512.11876)
*Hrigved Mahesh Suryawanshi*

Main category: cs.RO

TL;DR: 提出一个基于学习的可通行性感知导航框架，用于M4机器人平台，通过LiDAR生成2.5D高程图，CNN评估地形难度，A*规划器结合地形成本和能耗规划路径，在非结构化环境中平衡效率与安全。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，机器人需要实时评估地形难度，规划既能保证安全又高效的路径。现有导航方法往往只考虑几何距离，忽略了地形可通行性和能耗因素，导致在实际复杂地形中性能不佳。

Method: 1) 使用FAST-LIO进行实时定位；2) 从LiDAR点云生成2.5D高程图；3) 基于CNN的模型处理高程图估计可通行性分数；4) 将可通行性分数转换为导航成本；5) 定制A*规划器结合几何距离、能耗和地形成本规划路径；6) 前期进行了LiDAR与相机SLAM的对比研究，验证了LiDAR的厘米级精度优势。

Result: 实验结果表明，系统成功避开了低可通行性区域，虽然路径长度略有增加，但显著降低了地形成本。LiDAR-based mapping达到厘米级精度，而相机方法误差较大。完整系统集成了FAST-LIO定位、GPU加速高程映射、CNN可通行性估计和Nav2导航。

Conclusion: 该研究建立了一个智能地形感知导航框架，适用于多模态机器人平台，能够在非结构化环境中实现安全高效的自主导航，通过接受适度路径长度增加来显著改善地形质量。

Abstract: Autonomous navigation in unstructured environments requires robots to assess terrain difficulty in real-time and plan paths that balance efficiency with safety. This thesis presents a traversability-aware navigation framework for the M4 robot platform that uses learned terrain analysis to generate energy-efficient paths avoiding difficult terrain.Our approach uses FAST-LIO for real-time localization, generating 2.5D elevation maps from LiDAR point clouds. A CNN-based model processes these elevation maps to estimate traversability scores, which are converted into navigation costs for path planning. A custom A* planner incorporates these costs alongside geometric distance and energy consumption to find paths that trade modest distance increases for substantial terrain quality improvements. Before system development, a platform-agnostic study compared LiDAR-based and camera-based SLAM using OptiTrack ground truth. Point cloud comparison through ICP alignment and cloud-to-mesh distance analysis demonstrated that LiDAR-based mapping achieves centimeter-level precision essential for elevation mapping, while camera-based approaches exhibited significantly higher geometric error. These findings directly resulted in the selection of LiDAR as the primary sensor to generate elevation maps. The complete pipeline integrates FAST-LIO localization, GPU-accelerated elevation mapping, CNN-based traversability estimation, and Nav2 navigation with a custom traversability-aware planner. Experimental results demonstrate that the system successfully avoids low traversability regions and accepts a few longer paths to achieve a reduction in terrain cost. This work establishes a foundation for intelligent terrain-aware navigation applicable to multi-modal robotic platforms.

</details>


### [73] [Enabling Autonomous Navigation in a Snake Robot through Visual-Inertial Odometry and Closed-Loop Trajectory Tracking Control](https://arxiv.org/abs/2512.11886)
*Mohammed Irfan Ali*

Main category: cs.RO

TL;DR: 开发了用于蛇形机器人COBRA的完整自主导航系统，结合视觉惯性SLAM、降阶状态估计和闭环轨迹跟踪，实现自主航点导航


<details>
  <summary>Details</summary>
Motivation: 蛇形机器人在极端地形中具有卓越的机动性，但高度关节化的身体在没有外部跟踪基础设施的环境中面临自主导航的基本挑战。现有研究完全依赖开环遥操作，需要开发完整的自主导航系统

Method: 集成机载视觉惯性SLAM、降阶状态估计和闭环轨迹跟踪。使用深度相机和边缘计算进行实时定位，通过降阶框架估计质心位姿，采用闭环控制器通过距离相关的偏航误差混合调制CPG步态参数

Result: 物理实验验证了完整系统的有效性，展示了精确的多航点跟踪能力，为蛇形机器人自主导航奠定了基础。系统通过运动捕捉地面真实验证了定位精度和漂移行为

Conclusion: 成功开发了蛇形机器人COBRA的完整自主导航管道，集成了SLAM、状态估计和闭环控制，实现了自主航点导航，为行星探索等应用中的蛇形机器人自主导航奠定了基础

Abstract: Snake robots offer exceptional mobility across extreme terrain inaccessible to conventional rovers, yet their highly articulated bodies present fundamental challenges for autonomous navigation in environments lacking external tracking infrastructure. This thesis develops a complete autonomy pipeline for COBRA, an 11 degree-of-freedom modular snake robot designed for planetary exploration. While the robot's biologically inspired serpentine gaits achieve impressive mobility, prior work has relied entirely on open-loop teleoperation. This approach integrates onboard visual-inertial SLAM, reduced-order state estimation, and closed-loop trajectory tracking to enable autonomous waypoint navigation. A depth camera paired with edge computing performs real-time localization during dynamic locomotion, validated against motion-capture ground truth to characterize drift behavior and failure modes unique to snake robot platforms. A reduced-order framework estimates Center-of-Mass pose, driving a closed-loop controller that modulates CPG gait parameters through distance-dependent yaw error blending. Physical experiments validate the complete system, demonstrating accurate multi-waypoint tracking and establishing foundations for autonomous snake robot navigation.

</details>


### [74] [VLSA: Vision-Language-Action Models with Plug-and-Play Safety Constraint Layer](https://arxiv.org/abs/2512.11891)
*Songqiao Hu,Zeyi Liu,Shuang Liu,Jun Cen,Zihan Meng,Xiao He*

Main category: cs.RO

TL;DR: 提出AEGIS架构，在VLA模型中集成基于控制屏障函数的安全约束层，提高机器人操作的安全性和任务成功率


<details>
  <summary>Details</summary>
Motivation: VLA模型在多样化机器人操作任务中表现出色，但在非结构化环境中部署时面临安全挑战，特别是需要同时保证任务执行和防止碰撞

Method: 提出VLSA架构AEGIS，包含基于控制屏障函数的即插即用安全约束层，可直接集成到现有VLA模型中，提供理论保证的安全改进

Result: 在构建的SafeLIBERO基准测试中，AEGIS相比现有方法在障碍物避免率上提升59.16%，任务执行成功率提升17.25%

Conclusion: AEGIS架构有效提升了VLA模型在非结构化环境中的安全性，同时保持原有的指令跟随性能，为安全机器人操作提供了可靠解决方案

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in generalizing across diverse robotic manipulation tasks. However, deploying these models in unstructured environments remains challenging due to the critical need for simultaneous task compliance and safety assurance, particularly in preventing potential collisions during physical interactions. In this work, we introduce a Vision-Language-Safe Action (VLSA) architecture, named AEGIS, which contains a plug-and-play safety constraint (SC) layer formulated via control barrier functions. AEGIS integrates directly with existing VLA models to improve safety with theoretical guarantees, while maintaining their original instruction-following performance. To evaluate the efficacy of our architecture, we construct a comprehensive safety-critical benchmark SafeLIBERO, spanning distinct manipulation scenarios characterized by varying degrees of spatial complexity and obstacle intervention. Extensive experiments demonstrate the superiority of our method over state-of-the-art baselines. Notably, AEGIS achieves a 59.16% improvement in obstacle avoidance rate while substantially increasing the task execution success rate by 17.25%. To facilitate reproducibility and future research, we make our code, models, and the benchmark datasets publicly available at https://vlsa-aegis.github.io/.

</details>


### [75] [Data-driven Interpretable Hybrid Robot Dynamics](https://arxiv.org/abs/2512.11900)
*Christopher E. Mower,Rui Zong,Haitham Bou-Ammar*

Main category: cs.RO

TL;DR: 使用符号回归和稀疏识别方法从机器人关节数据中学习可解释的残余动力学模型，替代黑盒神经网络，获得更准确、泛化性更好的紧凑解析表达式。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过数据驱动方法识别可解释的混合机器人动力学模型，在解析刚体动力学模型基础上学习残余扭矩项，以提供比黑盒函数逼近器更紧凑、准确且具有物理意义的替代方案。

Method: 采用符号回归和稀疏非线性动力学识别(SINDy)方法，从关节空间数据中恢复残余扭矩的紧凑闭式表达式，将解析刚体动力学模型与学习到的残余项相结合。

Result: 在7自由度Franka机械臂仿真中，可解释模型准确恢复了惯性、科里奥利、重力和粘性效应，相对误差很小，在准确性和泛化性上均优于神经网络基线。在真实7自由度WAM机械臂数据上，符号回归残余模型比SINDy和神经网络泛化能力显著更好，后者容易过拟合，并提出了扩展名义动力学模型的候选闭式公式。

Conclusion: 可解释的残余动力学模型为扭矩预测提供了紧凑、准确且具有物理意义的替代方案，优于黑盒函数逼近器，能够从数据中发现扩展名义模型的新闭式公式。

Abstract: We study data-driven identification of interpretable hybrid robot dynamics, where an analytical rigid-body dynamics model is complemented by a learned residual torque term. Using symbolic regression and sparse identification of nonlinear dynamics (SINDy), we recover compact closed-form expressions for this residual from joint-space data. In simulation on a 7-DoF Franka arm with known dynamics, these interpretable models accurately recover inertial, Coriolis, gravity, and viscous effects with very small relative error and outperform neural-network baselines in both accuracy and generalization. On real data from a 7-DoF WAM arm, symbolic-regression residuals generalize substantially better than SINDy and neural networks, which tend to overfit, and suggest candidate new closed-form formulations that extend the nominal dynamics model for this robot. Overall, the results indicate that interpretable residual dynamics models provide compact, accurate, and physically meaningful alternatives to black-box function approximators for torque prediction.

</details>


### [76] [Aion: Towards Hierarchical 4D Scene Graphs with Temporal Flow Dynamics](https://arxiv.org/abs/2512.11903)
*Iacopo Catalano,Eduardo Montijano,Javier Civera,Julio A. Placed,Jorge Pena-Queralta*

Main category: cs.RO

TL;DR: Aion框架将时间流动态嵌入到分层3D场景图中，结合了语义结构和运动模式，用于动态环境中的自主导航。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图主要关注静态语义结构，而动态地图通常基于网格离散化且缺乏语义意识，两者都难以同时捕捉语义结构和时间演化，限制了在复杂动态环境中的导航能力。

Method: Aion采用基于图的稀疏动态地图表示，捕捉任意时间间隔内的运动流，并将这些动态信息附加到场景图的导航节点上，形成层次化的时空表示。

Result: 该方法产生了更可解释和可扩展的预测，能够改善在复杂动态环境中的规划和交互能力。

Conclusion: Aion框架成功地将时间维度整合到层次化3D场景图中，为动态环境中的自主导航提供了更有效的时空表示。

Abstract: Autonomous navigation in dynamic environments requires spatial representations that capture both semantic structure and temporal evolution. 3D Scene Graphs (3DSGs) provide hierarchical multi-resolution abstractions that encode geometry and semantics, but existing extensions toward dynamics largely focus on individual objects or agents. In parallel, Maps of Dynamics (MoDs) model typical motion patterns and temporal regularities, yet are usually tied to grid-based discretizations that lack semantic awareness and do not scale well to large environments. In this paper we introduce Aion, a framework that embeds temporal flow dynamics directly within a hierarchical 3DSG, effectively incorporating the temporal dimension. Aion employs a graph-based sparse MoD representation to capture motion flows over arbitrary time intervals and attaches them to navigational nodes in the scene graph, yielding more interpretable and scalable predictions that improve planning and interaction in complex dynamic environments.

</details>


### [77] [Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models](https://arxiv.org/abs/2512.11908)
*Heng Zhang,Rui Dai,Gokhan Solak,Pokuang Zhou,Yu She,Arash Ajoudani*

Main category: cs.RO

TL;DR: 该综述全面回顾了机器人接触丰富任务中的安全学习控制方法，涵盖安全探索与安全执行两大领域，并特别关注了视觉语言模型等基础模型带来的新安全机遇与挑战。


<details>
  <summary>Details</summary>
Motivation: 接触丰富任务存在不确定性、复杂动力学和高损伤风险等挑战，学习控制方法虽能帮助机器人掌握复杂操作技能，但确保探索和执行过程中的安全性仍是实际部署的关键瓶颈。

Method: 将现有方法分为安全探索和安全执行两大领域，综述了约束强化学习、风险敏感优化、不确定性感知建模、控制屏障函数、模型预测安全屏蔽等关键技术，并探讨了这些方法与视觉语言模型等基础模型的结合。

Result: 系统梳理了接触丰富任务中安全学习控制的技术体系，分析了不同方法的优势与局限，特别指出了基础模型带来的语言级约束规范、多模态安全信号接地等新机遇，以及相应的风险与评估挑战。

Conclusion: 该领域需要在现有基础上进一步发展，以实现可靠、安全对齐且基于基础模型的机器人在复杂接触环境中的部署，未来方向包括改进安全评估、增强模型鲁棒性和探索新的安全规范方法。

Abstract: Contact-rich tasks pose significant challenges for robotic systems due to inherent uncertainty, complex dynamics, and the high risk of damage during interaction. Recent advances in learning-based control have shown great potential in enabling robots to acquire and generalize complex manipulation skills in such environments, but ensuring safety, both during exploration and execution, remains a critical bottleneck for reliable real-world deployment. This survey provides a comprehensive overview of safe learning-based methods for robot contact-rich tasks. We categorize existing approaches into two main domains: safe exploration and safe execution. We review key techniques, including constrained reinforcement learning, risk-sensitive optimization, uncertainty-aware modeling, control barrier functions, and model predictive safety shields, and highlight how these methods incorporate prior knowledge, task structure, and online adaptation to balance safety and efficiency. A particular emphasis of this survey is on how these safe learning principles extend to and interact with emerging robotic foundation models, especially vision-language models (VLMs) and vision-language-action models (VLAs), which unify perception, language, and control for contact-rich manipulation. We discuss both the new safety opportunities enabled by VLM/VLA-based methods, such as language-level specification of constraints and multimodal grounding of safety signals, and the amplified risks and evaluation challenges they introduce. Finally, we outline current limitations and promising future directions toward deploying reliable, safety-aligned, and foundation-model-enabled robots in complex contact-rich environments. More details and materials are available at our \href{ https://github.com/jack-sherman01/Awesome-Learning4Safe-Contact-rich-tasks}{Project GitHub Repository}.

</details>


### [78] [Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control](https://arxiv.org/abs/2512.11921)
*Abdullah Yahya Abdullah Omaisan,Ibrahim Sheikh Mohamed*

Main category: cs.RO

TL;DR: 该论文提出了一种高效的微调方法，使大型视觉-语言-动作模型能在低成本机器人平台上部署，通过LoRA和量化技术让31亿参数模型在8GB显存的消费级GPU上运行。


<details>
  <summary>Details</summary>
Motivation: 大规模VLA模型在机器人操作中表现出色，但部署到低成本机器人平台面临计算资源限制和新机器人本体适配的挑战。需要解决如何在有限计算资源和少量演示数据下有效适配预训练模型的问题。

Method: 提出基于低秩适应（LoRA）和量化技术的高效微调策略，重点研究冻结与解冻视觉编码器的权衡。在SO101机械臂上进行真实世界部署测试，使用200个演示片段进行训练。

Result: 方法成功将31亿参数VLA模型部署到8GB显存的消费级GPU上，在按钮按压任务中实现有效操作性能。分析了部署挑战、失败模式以及训练数据量与真实世界性能的关系。

Conclusion: 通过适当的微调方法，VLA模型可以成功部署到经济实惠的机器人平台，使先进的操控能力超越昂贵的研究机器人，变得更加普及。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in robotic manipulation,enabling robots to execute natural language commands through end-to-end learning from visual observations.However, deploying large-scale VLA models on affordable robotic platforms remains challenging due to computational constraints and the need for efficient adaptation to new robot embodiments. This paper presents an efficient fine-tuning methodology and real-world deployment analysis for adapting VLA models to low-cost robotic manipulation systems.We propose a resource-efficient fine-tuning strategy using Low-Rank Adaptation (LoRA) and quantization techniques that enable multi-billion parameter VLA models ( 3.1B parameters) to run on consumer-grade GPUs with 8GB VRAM. Our methodology addresses the critical challenge of adapting pre-trained VLA models to new robot embodiments with limited demonstration data, focusing on the trade-offs between frozen and unfrozen vision encoders. Through real-world deployment on the SO101 robotic arm for a button-pressing manipulation task, we demonstrate that our approach achieves effective manipulation performance while maintaining computational efficiency. We provide detailed analysis of deployment challenges, failure modes, and the relationship between training data quantity and real-world performance,trained on 200 demonstration episodes. Our results show that with proper fine-tuning methodology, VLA models can be successfully deployed on affordable robotic platforms,making advanced manipulation capabilities accessible beyond expensive research robots.

</details>


### [79] [A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach](https://arxiv.org/abs/2512.11944)
*Jia Hu,Yang Chang,Haoran Wang*

Main category: cs.RO

TL;DR: 该论文提出数据驱动的最优控制范式作为统一框架，将经典控制的可验证结构与机器学习的自适应能力相结合，以解决自动驾驶运动规划中透明性与适应性之间的根本矛盾。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶运动规划面临根本性矛盾：传统流水线方法透明但脆弱，而现代学习系统适应性强但缺乏透明度（"黑箱"特性）。这种持久困境阻碍了真正可信赖系统的发展。

Method: 通过全面回顾基于学习的运动规划方法，提出数据驱动的最优控制范式作为统一框架。该框架将经典控制的可验证结构与机器学习的自适应能力相结合，利用真实世界数据持续优化系统动力学、成本函数和安全约束等关键组件。

Result: 该框架有望实现三个关键下一代能力：1)"以人为中心"的定制化；2)"平台自适应"的动态适应；3)通过自调优实现"系统自优化"。为开发同时具备安全性、可解释性和类人自主性的智能交通系统提供了新范式。

Conclusion: 数据驱动的最优控制范式为解决自动驾驶运动规划中的透明性与适应性矛盾提供了有前景的解决方案。该框架融合了经典控制的理论严谨性和机器学习的自适应能力，为实现安全、可解释且具备类人自主性的智能交通系统指明了未来研究方向。

Abstract: Motion planning for high-level autonomous driving is constrained by a fundamental trade-off between the transparent, yet brittle, nature of pipeline methods and the adaptive, yet opaque, "black-box" characteristics of modern learning-based systems. This paper critically synthesizes the evolution of the field -- from pipeline methods through imitation learning, reinforcement learning, and generative AI -- to demonstrate how this persistent dilemma has hindered the development of truly trustworthy systems. To resolve this impasse, we conduct a comprehensive review of learning-based motion planning methods. Based on this review, we outline a data-driven optimal control paradigm as a unifying framework that synergistically integrates the verifiable structure of classical control with the adaptive capacity of machine learning, leveraging real-world data to continuously refine key components such as system dynamics, cost functions, and safety constraints. We explore this framework's potential to enable three critical next-generation capabilities: "Human-Centric" customization, "Platform-Adaptive" dynamics adaptation, and "System Self-Optimization" via self-tuning. We conclude by proposing future research directions based on this paradigm, aimed at developing intelligent transportation systems that are simultaneously safe, interpretable, and capable of human-like autonomy.

</details>


### [80] [Modified Hybrid A* Collision-Free Path-Planning for Automated Reverse Parking](https://arxiv.org/abs/2512.12021)
*Xincheng Cao,Haochong Chen,Bilin Aksun-Guvenc,Levent Guvenc*

Main category: cs.RO

TL;DR: 提出一种改进的Hybrid-A*路径规划算法，用于在狭窄空间中的车辆泊车，结合运动学可行性和静态障碍物避障


<details>
  <summary>Details</summary>
Motivation: 在狭窄空间泊车具有挑战性，因为既需要路径可行又需要避免碰撞。现有方法难以同时保证这两点。

Method: 1. 推导运动学单轨模型描述车辆低速运动；2. 将模型集成到改进的Hybrid-A*算法中生成可行运动基元；3. 利用车辆中心线重建和膨胀二值占据地图实现静态障碍物避障

Result: 通过仿真研究和动画测试，证明该算法能持续提供运动学可行且无碰撞的轨迹

Conclusion: 提出的改进Hybrid-A*算法能有效解决狭窄空间泊车问题，同时保证路径可行性和碰撞避免

Abstract: Parking a vehicle in tight spaces is a challenging task to perform due to the scarcity of feasible paths that are also collision-free. This paper presents a strategy to tackle this kind of maneuver with a modified Hybrid-A* path-planning algorithm that combines the feasibility guarantee inherent in the standard Hybrid A* algorithm with the addition of static obstacle collision avoidance. A kinematic single-track model is derived to describe the low-speed motion of the vehicle, which is subsequently used as the motion model in the Hybrid A* path-planning algorithm to generate feasible motion primitive branches. The model states are also used to reconstruct the vehicle centerline, which, in conjunction with an inflated binary occupancy map, facilitates static obstacle collision avoidance functions. Simulation study and animation are set up to test the efficacy of the approach, and the proposed algorithm proves to consistently provide kinematically feasible trajectories that are also collision-free.

</details>


### [81] [A Stochastic Approach to Terrain Maps for Safe Lunar Landing](https://arxiv.org/abs/2512.12058)
*Anja Sheppard,Chris Reale,Katherine A. Skinner*

Main category: cs.RO

TL;DR: 提出一种基于高斯过程的两阶段方法，利用LRO数字高程模型置信度数据生成月球南极区域随机高程地图，为安全着陆提供更准确的异方差不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 月球南极区域存在阴影，传统视觉危险检测不可靠，而LiDAR技术未经验证。该区域资源价值高，需要安全着陆方案。LRO数据包含丰富表面信息，但现有方法未充分利用DEM置信度数据中的异方差噪声信息。

Method: 采用两阶段高斯过程模型：第一阶段使用次级GP从DEM置信度数据学习空间变化的噪声特性；第二阶段使用主GP建模月球地形，并将异方差噪声信息作为噪声参数。采用随机变分GP实现可扩展训练。

Result: 该方法能更准确地建模异方差传感器噪声对高程地图的影响，生成更具信息量的地形不确定性估计，可用于危险检测和安全着陆点选择等下游任务。

Conclusion: 提出的两阶段GP方法充分利用LRO DEM置信度数据，为月球南极着陆任务提供更可靠的地形不确定性估计，提高了自主航天任务的安全性和可靠性。

Abstract: Safely landing on the lunar surface is a challenging task, especially in the heavily-shadowed South Pole region where traditional vision-based hazard detection methods are not reliable. The potential existence of valuable resources at the lunar South Pole has made landing in that region a high priority for many space agencies and commercial companies. However, relying on a LiDAR for hazard detection during descent is risky, as this technology is fairly untested in the lunar environment.
  There exists a rich log of lunar surface data from the Lunar Reconnaissance Orbiter (LRO), which could be used to create informative prior maps of the surface before descent. In this work, we propose a method for generating stochastic elevation maps from LRO data using Gaussian processes (GPs), which are a powerful Bayesian framework for non-parametric modeling that produce accompanying uncertainty estimates. In high-risk environments such as autonomous spaceflight, interpretable estimates of terrain uncertainty are critical. However, no previous approaches to stochastic elevation mapping have taken LRO Digital Elevation Model (DEM) confidence maps into account, despite this data containing key information about the quality of the DEM in different areas.
  To address this gap, we introduce a two-stage GP model in which a secondary GP learns spatially varying noise characteristics from DEM confidence data. This heteroscedastic information is then used to inform the noise parameters for the primary GP, which models the lunar terrain. Additionally, we use stochastic variational GPs to enable scalable training. By leveraging GPs, we are able to more accurately model the impact of heteroscedastic sensor noise on the resulting elevation map. As a result, our method produces more informative terrain uncertainty, which can be used for downstream tasks such as hazard detection and safe landing site selection.

</details>


### [82] [B-ActiveSEAL: Scalable Uncertainty-Aware Active Exploration with Tightly Coupled Localization-Mapping](https://arxiv.org/abs/2512.12194)
*Min-Won Seo,Aamodh Suresh,Carlos Nieto-Granda,Solmaz S. Kia*

Main category: cs.RO

TL;DR: B-ActiveSEAL：一种可扩展的信息论主动探索框架，通过行为熵（BE）在紧密耦合的定位-建图不确定性下实现自适应探索-利用平衡。


<details>
  <summary>Details</summary>
Motivation: 在长期大规模环境中，主动机器人探索需要处理定位和建图之间紧密耦合的不确定性，但现有方法在计算上难以处理这些相互依赖的不确定性。

Method: 提出B-ActiveSEAL框架，使用行为熵（BE）作为信息度量，自适应平衡地图不确定性（探索）和定位不确定性（利用），支持广义熵度量，建立耦合不确定性传播的理论基础。

Result: 在开源地图和ROS-Unity仿真实验中验证了方法的有效性，实现了良好的探索-利用平衡，在不同复杂环境中产生多样化的自适应探索行为，优于代表性基线方法。

Conclusion: B-ActiveSEAL为紧密耦合的定位-建图不确定性下的主动探索提供了可扩展的解决方案，行为熵作为有效的信息度量实现了直观的自适应决策。

Abstract: Active robot exploration requires decision-making processes that integrate localization and mapping under tightly coupled uncertainty. However, managing these interdependent uncertainties over long-term operations in large-scale environments rapidly becomes computationally intractable. To address this challenge, we propose B-ActiveSEAL, a scalable information-theoretic active exploration framework that explicitly accounts for coupled uncertainties-from perception through mapping-into the decision-making process. Our framework (i) adaptively balances map uncertainty (exploration) and localization uncertainty (exploitation), (ii) accommodates a broad class of generalized entropy measures, enabling flexible and uncertainty-aware active exploration, and (iii) establishes Behavioral entropy (BE) as an effective information measure for active exploration by enabling intuitive and adaptive decision-making under coupled uncertainties. We establish a theoretical foundation for propagating coupled uncertainties and integrating them into general entropy formulations, enabling uncertainty-aware active exploration under tightly coupled localization-mapping. The effectiveness of the proposed approach is validated through rigorous theoretical analysis and extensive experiments on open-source maps and ROS-Unity simulations across diverse and complex environments. The results demonstrate that B-ActiveSEAL achieves a well-balanced exploration-exploitation trade-off and produces diverse, adaptive exploration behaviors across environments, highlighting clear advantages over representative baselines.

</details>


### [83] [Navigation Around Unknown Space Objects Using Visible-Thermal Image Fusion](https://arxiv.org/abs/2512.12203)
*Eric J. Elias,Michael Esswein,Jonathan P. How,David W. Miller*

Main category: cs.RO

TL;DR: 热红外与可见光图像融合提升太空目标导航性能


<details>
  <summary>Details</summary>
Motivation: 在轨操作需求增长，需要精确导航未知空间目标。传统相机在阴影期性能受限，激光雷达笨重耗电，热红外相机虽能在恶劣光照下工作但分辨率低。需要结合两者优势。

Method: 对低地球轨道目标卫星进行可见光和热红外波段的光真实模拟，使用像素级融合方法创建可见光/热红外复合图像，在不同光照和轨迹条件下比较单目SLAM算法的导航误差。

Result: 融合图像在导航性能上显著优于仅使用可见光或仅使用热红外的方法。

Conclusion: 可见光与热红外图像融合能有效结合两者优势，为太空目标导航提供更优解决方案。

Abstract: As the popularity of on-orbit operations grows, so does the need for precise navigation around unknown resident space objects (RSOs) such as other spacecraft, orbital debris, and asteroids. The use of Simultaneous Localization and Mapping (SLAM) algorithms is often studied as a method to map out the surface of an RSO and find the inspector's relative pose using a lidar or conventional camera. However, conventional cameras struggle during eclipse or shadowed periods, and lidar, though robust to lighting conditions, tends to be heavier, bulkier, and more power-intensive. Thermal-infrared cameras can track the target RSO throughout difficult illumination conditions without these limitations. While useful, thermal-infrared imagery lacks the resolution and feature-richness of visible cameras. In this work, images of a target satellite in low Earth orbit are photo-realistically simulated in both visible and thermal-infrared bands. Pixel-level fusion methods are used to create visible/thermal-infrared composites that leverage the best aspects of each camera. Navigation errors from a monocular SLAM algorithm are compared between visible, thermal-infrared, and fused imagery in various lighting and trajectories. Fused imagery yields substantially improved navigation performance over visible-only and thermal-only methods.

</details>


### [84] [Measuring What Matters: Scenario-Driven Evaluation for Trajectory Predictors in Autonomous Driving](https://arxiv.org/abs/2512.12211)
*Longchao Da,David Isele,Hua Wei,Manish Saroya*

Main category: cs.RO

TL;DR: 提出一个自适应评估轨迹预测器性能的管道，从准确性和多样性两个维度动态评估，比传统误差指标更能反映预测器对自动驾驶车辆实际驾驶性能的影响。


<details>
  <summary>Details</summary>
Motivation: 当前轨迹预测评估主要依赖ADE、FDE等误差指标，这些指标只关注事后准确性，忽略了预测器对自动驾驶车辆在复杂交互场景中的实际影响。高质量预测器不仅需要准确性，还应捕捉邻居车辆所有可能的运动方向，以支持自动驾驶车辆的谨慎决策。

Method: 提出一个综合评估管道，从两个维度自适应评估预测器性能：准确性和多样性。基于驾驶场景的关键性，这两个维度被动态组合，最终得出预测器性能评分。在闭环基准测试中使用真实世界数据集进行广泛实验。

Result: 实验表明，该评估管道比传统指标产生更合理的评估结果，能更好地反映预测器评估与自动驾驶车辆驾驶性能之间的相关性。该管道提供了一种稳健的方法来选择对自动驾驶车辆驾驶性能贡献最大的预测器。

Conclusion: 提出的评估管道能够更全面地评估轨迹预测器性能，不仅考虑准确性，还考虑多样性，从而更好地支持自动驾驶车辆在复杂交互场景中的决策制定，为选择最优预测器提供了更有效的评估框架。

Abstract: Being able to anticipate the motion of surrounding agents is essential for the safe operation of autonomous driving systems in dynamic situations. While various methods have been proposed for trajectory prediction, the current evaluation practices still rely on error-based metrics (e.g., ADE, FDE), which reveal the accuracy from a post-hoc view but ignore the actual effect the predictor brings to the self-driving vehicles (SDVs), especially in complex interactive scenarios: a high-quality predictor not only chases accuracy, but should also captures all possible directions a neighbor agent might move, to support the SDVs' cautious decision-making. Given that the existing metrics hardly account for this standard, in our work, we propose a comprehensive pipeline that adaptively evaluates the predictor's performance by two dimensions: accuracy and diversity. Based on the criticality of the driving scenario, these two dimensions are dynamically combined and result in a final score for the predictor's performance. Extensive experiments on a closed-loop benchmark using real-world datasets show that our pipeline yields a more reasonable evaluation than traditional metrics by better reflecting the correlation of the predictors' evaluation with the autonomous vehicles' driving performance. This evaluation pipeline shows a robust way to select a predictor that potentially contributes most to the SDV's driving performance.

</details>


### [85] [Semantic Zone based 3D Map Management for Mobile Robot](https://arxiv.org/abs/2512.12228)
*Huichang Yun,Seungho Yoo*

Main category: cs.RO

TL;DR: 提出基于语义分区的3D地图管理方法，将环境划分为有意义的空间单元（如大厅、走廊），作为内存管理的基本单位，动态加载任务相关区域到工作内存，卸载非活跃区域到长期内存，实现稳定的内存使用。


<details>
  <summary>Details</summary>
Motivation: 大规模室内环境（如医院、物流中心）中的移动机器人需要精确的3D空间表示，但3D地图占用大量内存，难以在有限计算资源中维护完整地图数据。现有SLAM框架通常依赖几何距离或时间指标进行内存管理，在空间分隔环境中导致数据检索效率低下。

Method: 提出语义分区基础的3D地图管理方法，将环境划分为有意义的空间单元（语义区域），将这些区域作为内存管理的主要单位。系统动态地将任务相关区域加载到工作内存（WM），将非活跃区域卸载到长期内存（LTM），严格强制执行用户定义的内存阈值。该方法在RTAB-Map框架中实现。

Result: 与标准方法相比，该方法显著减少了不必要的签名加载/卸载周期和累积内存使用。结果证实基于语义分区的管理确保了稳定、可预测的内存使用，同时保持了导航所需的地图可用性。

Conclusion: 语义分区基础的3D地图管理方法有效解决了大规模室内环境中3D地图内存消耗大的问题，通过从几何中心转向语义中心的控制范式，实现了高效的内存管理和数据检索。

Abstract: Mobile robots in large-scale indoor environments, such as hospitals and logistics centers, require accurate 3D spatial representations. However, 3D maps consume substantial memory, making it difficult to maintain complete map data within limited computational resources. Existing SLAM frameworks typically rely on geometric distance or temporal metrics for memory management, often resulting in inefficient data retrieval in spatially compartmentalized environments. To address this, we propose a semantic zone-based 3D map management method that shifts the paradigm from geometry-centric to semantics-centric control. Our approach partitions the environment into meaningful spatial units (e.g., lobbies, hallways) and designates these zones as the primary unit for memory management. By dynamically loading only task-relevant zones into Working Memory (WM) and offloading inactive zones to Long-Term Memory (LTM), the system strictly enforces user-defined memory thresholds. Implemented within the RTAB-Map framework, our method demonstrates substantial reductions in unnecessary signature load/unload cycles and cumulative memory utilization compared to standard approaches. The results confirm that semantic zone-based management ensures stable, predictable memory usage while preserving map availability for navigation. Code is available at: https://github.com/huichangs/rtabmap/tree/segment

</details>


### [86] [Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy](https://arxiv.org/abs/2512.12230)
*Jonathan Spraggett*

Main category: cs.RO

TL;DR: 提出一个统一的深度强化学习策略，能让七种不同形态的人形机器人从跌倒中恢复，无需为每个机器人单独训练。


<details>
  <summary>Details</summary>
Motivation: 在RoboCup等动态环境中，人形机器人跌倒恢复是关键技能。现有深度强化学习方法需要为每种机器人形态训练单独策略，这限制了实用性和可扩展性。

Method: 使用CrossQ训练一个统一的DRL策略，覆盖七种不同高度、重量和动力学特性的人形机器人。通过留一法实验、形态缩放分析和多样性消融研究来验证方法。

Result: 统一策略在未见过的机器人形态上实现了零样本迁移，成功率高达86±7%（95%置信区间[81,89]）。在某些情况下，共享策略甚至超过了专门训练的基线模型。

Conclusion: 研究表明，通过有针对性的形态覆盖可以改善零样本泛化能力，为形态无关的人形机器人控制奠定了基础，展示了通用人形控制的实用性。

Abstract: Fall recovery is a critical skill for humanoid robots in dynamic environments such as RoboCup, where prolonged downtime often decides the match. Recent techniques using deep reinforcement learning (DRL) have produced robust get-up behaviors, yet existing methods require training of separate policies for each robot morphology. This paper presents a single DRL policy capable of recovering from falls across seven humanoid robots with diverse heights (0.48 - 0.81 m), weights (2.8 - 7.9 kg), and dynamics. Trained with CrossQ, the unified policy transfers zero-shot up to 86 +/- 7% (95% CI [81, 89]) on unseen morphologies, eliminating the need for robot-specific training. Comprehensive leave-one-out experiments, morph scaling analysis, and diversity ablations show that targeted morphological coverage improves zero-shot generalization. In some cases, the shared policy even surpasses the specialist baselines. These findings illustrate the practicality of morphology-agnostic control for fall recovery, laying the foundation for generalist humanoid control. The software is open-source and available at: https://github.com/utra-robosoccer/unified-humanoid-getup

</details>


### [87] [Robust Underwater Localization of Buoyancy Driven microFloats Using Acoustic Time-of-Flight Measurements](https://arxiv.org/abs/2512.12233)
*Murad Mehrab Abrar,Trevor W. Harrison*

Main category: cs.RO

TL;DR: 提出一种低成本、鲁棒的水下声学定位方法，通过双向ToF测量和几何成本/CRLB滤波，在沿海水域实现4米中值定位精度


<details>
  <summary>Details</summary>
Motivation: 低成本自主平台需要高频位置更新，但准确的水下定位仍然具有挑战性。现有方法在沿海水域受多径效应和声学误差影响，需要提高定位鲁棒性和频率

Method: 采用双向声学飞行时间(ToF)定位框架，结合浮标到浮体和浮体到浮标的双向传输增加可用测量。集成非线性三边测量，并基于几何成本和克拉美罗下界(CRLB)对计算的位置估计进行滤波，去除多径效应和声学误差导致的异常值

Result: 在美国华盛顿州普吉特湾的两次实地部署中，定位管道实现了相对于GPS位置的中值定位误差低于4米。滤波技术将平均误差从139.29米降低到12.07米，轨迹与GPS路径的对齐度显著改善。还展示了未回收浮体的到达时间差(TDoA)定位

Conclusion: 通过精心设计的算法，基于距离的声学定位技术可以提高定位频率和鲁棒性。双向ToF框架结合几何/CRLB滤波能有效处理多径效应，为低成本微浮体在沿海水域提供可靠定位解决方案

Abstract: Accurate underwater localization remains a challenge for inexpensive autonomous platforms that require highfrequency position updates. In this paper, we present a robust, low-cost localization pipeline for buoyancy-driven microFloats operating in coastal waters. We build upon previous work by introducing a bidirectional acoustic Time-of-Flight (ToF) localization framework, which incorporates both float-to-buoy and buoy-to-float transmissions, thereby increasing the number of usable measurements. The method integrates nonlinear trilateration with a filtering of computed position estimates based on geometric cost and Cramer-Rao Lower Bounds (CRLB). This approach removes outliers caused by multipath effects and other acoustic errors from the ToF estimation and improves localization robustness without relying on heavy smoothing. We validate the framework in two field deployments in Puget Sound, Washington, USA. The localization pipeline achieves median positioning errors below 4 m relative to GPS positions. The filtering technique shows a reduction in mean error from 139.29 m to 12.07 m, and improved alignment of trajectories with GPS paths. Additionally, we demonstrate a Time-Difference-of-Arrival (TDoA) localization for unrecovered floats that were transmitting during the experiment. Range-based acoustic localization techniques are widely used and generally agnostic to hardware-this work aims to maximize their utility by improving positioning frequency and robustness through careful algorithmic design.

</details>


### [88] [CAR-CHASE: Car-Like Robot Conflict-Aware Heuristic Adaptive Search Enhancement](https://arxiv.org/abs/2512.12243)
*HT To,S Nguyen,NH Pham*

Main category: cs.RO

TL;DR: 提出CAR-CHASE方法，通过冲突感知启发式缓存和自适应混合启发式，显著提升类车机器人多智能体路径规划的计算效率，在保持最优性的同时获得2.46倍几何平均加速。


<details>
  <summary>Details</summary>
Motivation: 传统类车机器人MAPF算法（如CL-CBS）面临计算挑战，主要因为昂贵的运动学启发式计算。传统启发式缓存假设启发函数仅依赖于状态，这在CBS中不成立，因为冲突解决引入的约束使搜索空间具有上下文依赖性。

Method: 提出CAR-CHASE方法：1) 冲突感知启发式缓存，基于状态和相关约束上下文缓存启发值；2) 自适应混合启发式，智能切换快速近似和精确计算；3) 紧凑的冲突指纹编码约束影响；4) 空间、时间和几何相关性的过滤；5) 具有理论质量界的自适应切换策略。

Result: 在480个基准实例上评估，几何平均加速2.46倍，成功率从77.9%提升至84.8%（+6.9个百分点），总运行时间减少70.1%，解决了33个先前超时的实例。性能提升随问题复杂度增加，在30智能体障碍场景中达到4.06倍加速。

Conclusion: CAR-CHASE通过冲突感知启发式缓存和自适应混合启发式，显著提升了类车机器人MAPF的计算效率，同时保持解的最优性。该方法具有通用性，可应用于其他CBS变体。

Abstract: Multi-Agent Path Finding (MAPF) for car-like robots, addressed by algorithms such as Conflict-Based Search with Continuous Time (CL-CBS), faces significant computational challenges due to expensive kinematic heuristic calculations. Traditional heuristic caching assumes that the heuristic function depends only on the state, which is incorrect in CBS where constraints from conflict resolution make the search space context-dependent. We propose \textbf{CAR-CHASE} (Car-Like Robot Conflict-Aware Heuristic Adaptive Search Enhancement), a novel approach that combines \textbf{conflict-aware heuristic caching} -- which caches heuristic values based on both state and relevant constraint context -- with an \textbf{adaptive hybrid heuristic} that intelligently switches between fast approximate and exact computations. Our key innovations are (1) a compact \emph{conflict fingerprint} that efficiently encodes which constraints affect a state's heuristic, (2) a relevance filter using spatial, temporal, and geometric criteria, and (3) an adaptive switching strategy with theoretical quality bounds. Experimental evaluation on 480 benchmark instances with varying agent counts (10 to 30) and obstacle densities (0\% and 50\%) demonstrates a geometric mean speedup of 2.46$\times$ over the baseline CL-CBS implementation while maintaining solution optimality. The optimizations improve success rate from 77.9\% to 84.8\% (+6.9 percentage points), reduce total runtime by 70.1\%, and enable solving 33 additional instances that previously timed out. Performance gains scale with problem complexity, reaching up to 4.06$\times$ speedup for challenging 30-agent obstacle scenarios. Our techniques are general and applicable to other CBS variants.

</details>


### [89] [Programmable Deformation Design of Porous Soft Actuator through Volumetric-Pattern-Induced Anisotropy](https://arxiv.org/abs/2512.12320)
*Canqi Meng,Weibang Bai*

Main category: cs.RO

TL;DR: 提出一种通过在多孔泡沫体上切割特定图案来实现可编程变形的软多孔致动器设计方法，利用真空驱动实现弯曲、倾斜和扭转等多种变形模式。


<details>
  <summary>Details</summary>
Motivation: 传统软气动致动器存在结构支撑不足、需要针对不同功能进行昂贵的几何重新设计等问题。虽然多孔材料可以提供结构稳定性，但如何通过调控多孔体本身实现可编程变形仍缺乏探索。

Method: 在多孔泡沫圆柱体上切割特定图案（横向、纵向、对角线），通过引入局部结构各向异性来引导材料在全局真空输入下的变形。建立有限元分析模型研究切口图案方法的机理，并通过实验验证不同图案阵列数量下的变形能力。

Result: 实验表明，通过优化图案阵列数量，致动器可实现高达80°的弯曲（N=2）、18°的倾斜（N=1）和115°的扭转（N=8）。方法具有图案可转移性、可扩展性和无需模具的快速原型制作能力。

Conclusion: 该方法为多功能软多孔机器人设计提供了新的、高效且可扩展的范式，通过将人手褶皱图转化为功能性切口图案，成功创建了具有类人自适应抓取能力的仿生软机器人手。

Abstract: Conventional soft pneumatic actuators, typically based on hollow elastomeric chambers, often suffer from small structural support and require costly geometry-specific redesigns for multimodal functionality. Porous materials such as foam, filled into chambers, can provide structural stability for the actuators. However, methods to achieve programmable deformation by tailoring the porous body itself remain underexplored. In this paper, a novel design method is presented to realize soft porous actuators with programmable deformation by incising specific patterns into the porous foam body. This approach introduces localized structural anisotropy of the foam guiding the material's deformation under a global vacuum input. Furthermore, three fundamental patterns on a cylindrical foam substrate are discussed: transverse for bending, longitudinal for tilting, and diagonal for twisting. A computational model is built with Finite Element Analysis (FEA), to investigate the mechanism of the incision-patterning method. Experiments demonstrate that with a potential optimal design of the pattern array number N, actuators can achieve bending up to $80^{\circ}$ (N=2), tilting of $18^{\circ}$ (N=1), and twisting of $115^{\circ}$ (N=8). The versatility of our approach is demonstrated via pattern transferability, scalability, and mold-less rapid prototyping of complex designs. As a comprehensive application, we translate the human hand crease map into a functional incision pattern, creating a bio-inspired soft robot hand capable of human-like adaptive grasping. Our work provides a new, efficient, and scalable paradigm for the design of multi-functional soft porous robots.

</details>


### [90] [INDOOR-LiDAR: Bridging Simulation and Reality for Robot-Centric 360 degree Indoor LiDAR Perception -- A Robot-Centric Hybrid Dataset](https://arxiv.org/abs/2512.12377)
*Haichuan Li,Changda Tian,Panos Trahanias,Tomi Westerlund*

Main category: cs.RO

TL;DR: INDOOR-LIDAR是一个混合室内3D LiDAR点云数据集，结合仿真和真实扫描数据，提供一致的覆盖和真实传感器行为，支持多种机器人感知任务。


<details>
  <summary>Details</summary>
Motivation: 现有室内LiDAR数据集存在规模有限、标注格式不一致、数据收集过程中人为变异性等问题，需要更全面、一致的数据集来推进机器人感知研究。

Method: 通过集成仿真环境和自主地面机器人采集的真实世界扫描数据，提供密集点云数据，包含强度测量和KITTI风格标注，涵盖多种室内场景和物体类别。

Result: 创建了一个包含仿真和真实子集的混合数据集，仿真部分支持灵活配置布局、点密度和遮挡，真实部分捕捉了真实室内环境的传感器噪声、杂乱和特定领域伪影。

Conclusion: INDOOR-LIDAR通过弥合合成数据和真实世界数据之间的差距，为复杂室内环境中的机器人感知研究建立了可扩展、真实且可重复的基准。

Abstract: We present INDOOR-LIDAR, a comprehensive hybrid dataset of indoor 3D LiDAR point clouds designed to advance research in robot perception. Existing indoor LiDAR datasets often suffer from limited scale, inconsistent annotation formats, and human-induced variability during data collection. INDOOR-LIDAR addresses these limitations by integrating simulated environments with real-world scans acquired using autonomous ground robots, providing consistent coverage and realistic sensor behavior under controlled variations. Each sample consists of dense point cloud data enriched with intensity measurements and KITTI-style annotations. The annotation schema encompasses common indoor object categories within various scenes. The simulated subset enables flexible configuration of layouts, point densities, and occlusions, while the real-world subset captures authentic sensor noise, clutter, and domain-specific artifacts characteristic of real indoor settings. INDOOR-LIDAR supports a wide range of applications including 3D object detection, bird's-eye-view (BEV) perception, SLAM, semantic scene understanding, and domain adaptation between simulated and real indoor domains. By bridging the gap between synthetic and real-world data, INDOOR-LIDAR establishes a scalable, realistic, and reproducible benchmark for advancing robotic perception in complex indoor environments.

</details>


### [91] [Unifying Quadrotor Motion Planning and Control by Chaining Different Fidelity Models](https://arxiv.org/abs/2512.12427)
*Rudolf Reiter,Chao Qin,Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: Unique提出了一种统一MPC框架，通过级联不同保真度模型实现四旋翼的即时反应性和长时域规划，在相同计算预算下将闭环跟踪性能提升高达75%。


<details>
  <summary>Details</summary>
Motivation: 四旋翼空中任务需要同时具备即时反应性和长时域规划能力。高保真模型控制精确但计算量大，低保真模型可扩展但闭环性能差，现有方法难以兼顾两者。

Method: 1) 在单一优化中级联不同保真度模型：短时域高保真模型用于精确控制，长时域低保真模型用于规划；2) 对齐跨时域成本函数；3) 推导点质量模型的可行性保持约束；4) 引入状态、推力加速度和急动-体速率关系的过渡约束；5) 提出3D渐进平滑调度处理非平滑障碍物；6) 部署并行随机初始化MPC求解器发现更低成本局部最小值。

Result: 在仿真和真实飞行中，在相同计算预算下，相比标准MPC和分层规划器-跟踪器基线，Unique将闭环位置或速度跟踪性能提升高达75%。消融实验和帕累托分析证实了该方法在不同时域变化、约束近似和平滑调度下的鲁棒增益。

Conclusion: Unique通过级联不同保真度模型的统一MPC框架，有效解决了四旋翼同时需要即时反应性和长时域规划的难题，在有限计算资源下显著提升了闭环性能。

Abstract: Many aerial tasks involving quadrotors demand both instant reactivity and long-horizon planning. High-fidelity models enable accurate control but are too slow for long horizons; low-fidelity planners scale but degrade closed-loop performance. We present Unique, a unified MPC that cascades models of different fidelity within a single optimization: a short-horizon, high-fidelity model for accurate control, and a long-horizon, low-fidelity model for planning. We align costs across horizons, derive feasibility-preserving thrust and body-rate constraints for the point-mass model, and introduce transition constraints that match the different states, thrust-induced acceleration, and jerk-body-rate relations. To prevent local minima emerging from nonsmooth clutter, we propose a 3D progressive smoothing schedule that morphs norm-based obstacles along the horizon. In addition, we deploy parallel randomly initialized MPC solvers to discover lower-cost local minima on the long, low-fidelity horizon. In simulation and real flights, under equal computational budgets, Unique improves closed-loop position or velocity tracking by up to 75% compared with standard MPC and hierarchical planner-tracker baselines. Ablations and Pareto analyses confirm robust gains across horizon variations, constraint approximations, and smoothing schedules.

</details>


### [92] [Sim2Real Reinforcement Learning for Soccer skills](https://arxiv.org/abs/2512.12437)
*Jonathan Spraggett*

Main category: cs.RO

TL;DR: 该论文提出了一种使用课程学习和对抗运动先验技术来更高效训练人形机器人控制任务的强化学习方法，在模拟环境中取得了比传统方法更好的动态性和适应性，但未能成功迁移到真实世界。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在适应真实世界环境、处理复杂性和生成自然运动方面存在局限，需要更有效的训练方法来提升人形机器人控制任务的性能。

Method: 采用课程训练和对抗运动先验技术来改进强化学习训练过程，针对踢球、行走和跳跃等控制任务开发强化学习策略。

Result: 开发的强化学习策略在模拟环境中表现出更好的动态性和适应性，在踢球、行走和跳跃任务上超越了先前方法，但未能成功迁移到真实机器人。

Conclusion: 虽然提出的方法在模拟环境中显著提升了人形机器人控制任务的性能，但模拟到真实的迁移失败揭示了当前强化学习方法在完全适应真实世界场景方面的局限性。

Abstract: This thesis work presents a more efficient and effective approach to training control-related tasks for humanoid robots using Reinforcement Learning (RL). The traditional RL methods are limited in adapting to real-world environments, complexity, and natural motions, but the proposed approach overcomes these limitations by using curriculum training and Adversarial Motion Priors (AMP) technique. The results show that the developed RL policies for kicking, walking, and jumping are more dynamic, and adaptive, and outperformed previous methods. However, the transfer of the learned policy from simulation to the real world was unsuccessful, highlighting the limitations of current RL methods in fully adapting to real-world scenarios.

</details>


### [93] [Autonomously Unweaving Multiple Cables Using Visual Feedback](https://arxiv.org/abs/2512.12468)
*Tina Tian,Xinyu Wang,Andrew L. Orekhov,Fujun Ruan,Lu Li,Oliver Kroemer,Howie Choset*

Main category: cs.RO

TL;DR: 提出一种基于视觉反馈的多线缆解交织方法，将线缆解交织建模为抓取放置问题，使用图结构表示线缆状态，通过状态转移模型预测未来状态并选择动作，实验成功率84%


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注单根线缆的解结，而实际电缆管理任务中常涉及多根线缆的交织缠绕。多线缆解交织是电缆管理的重要子任务，需要将交织的多根线缆分离以便后续操作。

Method: 1) 将线缆解交织建模为抓取放置问题；2) 使用基于图的线缆状态表示，编码拓扑和几何信息；3) 提出状态转移模型预测线缆在操作中的伸直和弯曲；4) 通过状态转移模型选择高层动作基元并计算预测成本以优化底层动作。

Result: 在电源线和鞋带等线缆上进行实验，平均成功率84%，验证了所提感知-规划-动作迭代方法的有效性。

Conclusion: 该方法能够有效解决多线缆解交织问题，为自动化电缆管理提供了新的解决方案，通过视觉反馈和状态预测实现了对可变形线缆的智能操作。

Abstract: Many cable management tasks involve separating out the different cables and removing tangles. Automating this task is challenging because cables are deformable and can have combinations of knots and multiple interwoven segments. Prior works have focused on untying knots in one cable, which is one subtask of cable management. However, in this paper, we focus on a different subtask called multi-cable unweaving, which refers to removing the intersections among multiple interwoven cables to separate them and facilitate further manipulation. We propose a method that utilizes visual feedback to unweave a bundle of loosely entangled cables. We formulate cable unweaving as a pick-and-place problem, where the grasp position is selected from discrete nodes in a graph-based cable state representation. Our cable state representation encodes both topological and geometric information about the cables from the visual image. To predict future cable states and identify valid actions, we present a novel state transition model that takes into account the straightening and bending of cables during manipulation. Using this state transition model, we select between two high-level action primitives and calculate predicted immediate costs to optimize the lower-level actions. We experimentally demonstrate that iterating the above perception-planning-action process enables unweaving electric cables and shoelaces with an 84% success rate on average.

</details>


### [94] [Optimized Conflict Management for Urban Air Mobility Using Swarm UAV Networks](https://arxiv.org/abs/2512.12632)
*Rishit Agnihotri,Sandeep Kumar Sharma*

Main category: cs.RO

TL;DR: 该论文提出了一种基于边缘AI的去中心化无人机群架构，用于城市空中交通的实时冲突检测与解决，相比传统集中式控制模型，冲突解决时间最多减少3.8倍。


<details>
  <summary>Details</summary>
Motivation: 随着城市空中交通（UAM）的发展，密集城市走廊中的无人机密度不断增加，带来了前所未有的交通协调挑战，需要低延迟的实时决策系统。

Method: 采用控制算法构建数学模型，设计边缘AI驱动的去中心化群架构，利用轻量级神经网络在边缘节点进行分布式冲突检测与解决，并开发了仿真平台进行验证。

Result: 仿真结果表明，该架构在不同无人机密度下都能显著提升性能，冲突解决时间最多减少3.8倍，准确率也优于传统集中式控制模型。

Conclusion: 提出的边缘AI去中心化架构为未来UAM系统提供了可扩展、高效且安全的空中交通管理方案，具有很高的应用前景。

Abstract: Urban Air Mobility (UAM) poses unprecedented traffic coordination challenges, especially with increasing UAV densities in dense urban corridors. This paper introduces a mathematical model using a control algorithm to optimize an Edge AI-driven decentralized swarm architecture for intelligent conflict resolution, enabling real-time decision-making with low latency. Using lightweight neural networks, the system leverages edge nodes to perform distributed conflict detection and resolution. A simulation platform was developed to evaluate the scheme under various UAV densities. Results indicate that the conflict resolution time is dramatically minimized up to 3.8 times faster, and accuracy is enhanced compared to traditional centralized control models. The proposed architecture is highly promising for scalable, efficient, and safe aerial traffic management in future UAM systems.

</details>


### [95] [Bayesian Optimization Parameter Tuning Framework for a Lyapunov Based Path Following Controller](https://arxiv.org/abs/2512.12649)
*Zhewen Zheng,Wenjing Cao,Hongkang Yu,Mo Chen,Takashi Suzuki*

Main category: cs.RO

TL;DR: 使用贝叶斯优化框架自动调整非线性路径跟随控制器的增益参数，在真实机器人平台上通过有限次实验实现高效调参


<details>
  <summary>Details</summary>
Motivation: 实际硬件实验中参数调整受限于有限的评估预算。非线性几何控制器中多个增益通过耦合非线性项影响系统动态，这种相互依赖使得手动调参效率低下，难以在有限试验次数内获得满意性能

Method: 提出贝叶斯优化框架，将闭环系统视为黑盒，使用高斯过程代理模型选择控制器增益。BO提供无模型探索、量化不确定性和数据高效搜索，适合评估成本高的调参任务

Result: 在Honda AI-Formula三轮机器人上实现，通过在固定测试轨道上重复全圈实验评估。结果显示BO在32次试验（包括15次预热初始评估）内改善了控制器性能，表明其能在真实条件下高效定位参数空间的高性能区域

Conclusion: 贝叶斯优化为真实机器人平台上的非线性路径跟随控制器提供了实用、可靠且数据高效的调参方法

Abstract: Parameter tuning in real-world experiments is constrained by the limited evaluation budget available on hardware. The path-following controller studied in this paper reflects a typical situation in nonlinear geometric controller, where multiple gains influence the dynamics through coupled nonlinear terms. Such interdependence makes manual tuning inefficient and unlikely to yield satisfactory performance within a practical number of trials. To address this challenge, we propose a Bayesian optimization (BO) framework that treats the closed-loop system as a black box and selects controller gains using a Gaussian-process surrogate. BO offers model-free exploration, quantified uncertainty, and data-efficient search, making it well suited for tuning tasks where each evaluation is costly. The framework is implemented on Honda's AI-Formula three-wheeled robot and assessed through repeated full-lap experiments on a fixed test track. The results show that BO improves controller performance within 32 trials, including 15 warm-start initial evaluations, indicating that it can efficiently locate high-performing regions of the parameter space under real-world conditions. These findings demonstrate that BO provides a practical, reliable, and data-efficient tuning approach for nonlinear path-following controllers on real robotic platforms.

</details>


### [96] [HMPCC: Human-Aware Model Predictive Coverage Control](https://arxiv.org/abs/2512.12717)
*Mattia Catellani,Marta Gabbi,Lorenzo Sabattini*

Main category: cs.RO

TL;DR: 提出基于模型预测控制的人类感知覆盖框架HMPCC，通过预测人类轨迹来协调机器人团队在未知环境中的安全覆盖


<details>
  <summary>Details</summary>
Motivation: 传统覆盖策略通常依赖简化假设（如已知或凸环境、静态密度函数），难以适应现实场景，特别是在涉及人类的情况下。需要一种能够安全协调机器人团队、避免与非合作代理（如人类）碰撞的覆盖方法。

Method: 提出HMPCC框架：1) 将人类运动预测集成到MPC规划过程中，在MPC时间范围内预测人类轨迹；2) 使用高斯混合模型(GMM)表示感兴趣区域；3) 机器人团队完全去中心化运行，无需显式通信，适应敌对或通信受限场景

Result: 人类轨迹预测使覆盖更高效和自适应，改善了人类与机器人代理之间的协调。机器人能够主动协调行动，避免冗余探索，适应动态条件

Conclusion: HMPCC框架通过集成人类运动预测到MPC规划中，实现了在未知环境中机器人团队的安全、高效覆盖，特别适用于涉及人类交互的现实场景

Abstract: We address the problem of coordinating a team of robots to cover an unknown environment while ensuring safe operation and avoiding collisions with non-cooperative agents. Traditional coverage strategies often rely on simplified assumptions, such as known or convex environments and static density functions, and struggle to adapt to real-world scenarios, especially when humans are involved. In this work, we propose a human-aware coverage framework based on Model Predictive Control (MPC), namely HMPCC, where human motion predictions are integrated into the planning process. By anticipating human trajectories within the MPC horizon, robots can proactively coordinate their actions %avoid redundant exploration, and adapt to dynamic conditions. The environment is modeled as a Gaussian Mixture Model (GMM), representing regions of interest. Team members operate in a fully decentralized manner, without relying on explicit communication, an essential feature in hostile or communication-limited scenarios. Our results show that human trajectory forecasting enables more efficient and adaptive coverage, improving coordination between human and robotic agents.

</details>


### [97] [Making Robots Play by the Rules: The ROS 2 CLIPS-Executive](https://arxiv.org/abs/2512.12722)
*Tarik Viehmann,Daniel Swoboda,Samridhi Kalra,Himanshu Grover,Gerhard Lakemeyer*

Main category: cs.RO

TL;DR: 将CLIPS规则编程语言集成到ROS机器人系统中，并展示了与PDDL规划框架的集成


<details>
  <summary>Details</summary>
Motivation: CLIPS作为基于规则的知识驱动编程语言，非常适合协调自主机器人的复杂任务，但需要更好地集成到主流的ROS生态系统中

Method: 受Fawkes机器人框架中CLIPS-Executive的启发，将CLIPS集成到ROS生态系统，并描述基于PDDL的规划框架集成方案

Result: 成功实现了CLIPS在ROS生态系统中的集成，展示了CLIPS的灵活性，特别是与PDDL规划框架的集成能力

Conclusion: CLIPS可以有效地集成到ROS生态系统中，为机器人协调任务提供强大的知识驱动编程能力，同时展示了与规划框架的良好兼容性

Abstract: CLIPS is a rule-based programming language for building knowledge-driven applications, well suited for the complex task of coordinating autonomous robots. Inspired by the CLIPS-Executive originally developed for the lesser known Fawkes robotics framework, we present an Integration of CLIPS into the ROS ecosystem. Additionally, we show the flexibility of CLIPS by describing a PDDL-based planning framework integration.

</details>


### [98] [VLG-Loc: Vision-Language Global Localization from Labeled Footprint Maps](https://arxiv.org/abs/2512.12793)
*Mizuho Aoki,Kohei Honda,Yasuhiro Yoshimura,Takeshi Ishita,Ryo Yonetani*

Main category: cs.RO

TL;DR: VLG-Loc是一种新颖的全局定位方法，使用仅包含视觉地标名称和区域的人类可读足迹地图，通过视觉语言模型在多方向图像中搜索地图地标，并在蒙特卡洛定位框架中评估位姿假设。


<details>
  <summary>Details</summary>
Motivation: 人类能够使用简单的地标名称和区域地图进行定位，但机器人系统难以在没有几何和外观细节的情况下建立观测地标与地图之间的对应关系，这限制了机器人使用此类地图的能力。

Method: 使用视觉语言模型在机器人的多方向图像观测中搜索地图中标注的地标，然后在蒙特卡洛定位框架中，利用找到的地标评估每个位姿假设的似然度，实现全局定位。

Result: 在模拟和真实零售环境中的实验验证表明，该方法相比现有的基于扫描的方法具有更好的鲁棒性，特别是在环境变化情况下。通过视觉和扫描定位的概率融合进一步提高了性能。

Conclusion: VLG-Loc成功实现了使用简单人类可读地图的机器人全局定位，通过视觉语言模型建立地标对应关系，在环境变化下表现出优越的鲁棒性，为机器人定位提供了新思路。

Abstract: This paper presents Vision-Language Global Localization (VLG-Loc), a novel global localization method that uses human-readable labeled footprint maps containing only names and areas of distinctive visual landmarks in an environment. While humans naturally localize themselves using such maps, translating this capability to robotic systems remains highly challenging due to the difficulty of establishing correspondences between observed landmarks and those in the map without geometric and appearance details. To address this challenge, VLG-Loc leverages a vision-language model (VLM) to search the robot's multi-directional image observations for the landmarks noted in the map. The method then identifies robot poses within a Monte Carlo localization framework, where the found landmarks are used to evaluate the likelihood of each pose hypothesis. Experimental validation in simulated and real-world retail environments demonstrates superior robustness compared to existing scan-based methods, particularly under environmental changes. Further improvements are achieved through the probabilistic fusion of visual and scan-based localization.

</details>


### [99] [SAGA: Open-World Mobile Manipulation via Structured Affordance Grounding](https://arxiv.org/abs/2512.12842)
*Kuan Fang,Yuxin Chen,Xinghao Zhu,Farzad Niroui,Lingfeng Sun,Jiuguang Wang*

Main category: cs.RO

TL;DR: SAGA是一个通用的自适应视觉运动控制框架，通过将高层语义意图与低层视觉运动控制解耦，使用基于可供性的任务表示，并利用多模态基础模型将任务表示接地为3D可供性热图，从而在各种环境、任务目标和用户规范中实现泛化。


<details>
  <summary>Details</summary>
Motivation: 为了解决视觉运动控制在多样化环境、任务目标和用户规范中的泛化问题，需要一种能够解耦高层语义意图与低层控制的结构化方法，以克服外观变化对泛化的阻碍。

Method: 使用基于可供性的任务表示统一表达复杂行为；利用多模态基础模型将任务表示接地为3D可供性热图，突出任务相关实体；在多任务演示数据上训练条件策略进行全身控制；支持语言指令、选择点和示例演示等多种任务指定方式。

Result: 在四足机械臂上实现SAGA，并在11个真实世界任务中进行广泛实验。SAGA始终显著优于端到端和模块化基线方法，展示了结构化可供性接地为通用移动操作提供了可扩展且有效的途径。

Conclusion: 结构化可供性接地为通用移动操作提供了一个可扩展且有效的途径，能够实现零样本执行和少样本适应，解决多种形式的任务指定。

Abstract: We present SAGA, a versatile and adaptive framework for visuomotor control that can generalize across various environments, task objectives, and user specifications. To efficiently learn such capability, our key idea is to disentangle high-level semantic intent from low-level visuomotor control by explicitly grounding task objectives in the observed environment. Using an affordance-based task representation, we express diverse and complex behaviors in a unified, structured form. By leveraging multimodal foundation models, SAGA grounds the proposed task representation to the robot's visual observation as 3D affordance heatmaps, highlighting task-relevant entities while abstracting away spurious appearance variations that would hinder generalization. These grounded affordances enable us to effectively train a conditional policy on multi-task demonstration data for whole-body control. In a unified framework, SAGA can solve tasks specified in different forms, including language instructions, selected points, and example demonstrations, enabling both zero-shot execution and few-shot adaptation. We instantiate SAGA on a quadrupedal manipulator and conduct extensive experiments across eleven real-world tasks. SAGA consistently outperforms end-to-end and modular baselines by substantial margins. Together, these results demonstrate that structured affordance grounding offers a scalable and effective pathway toward generalist mobile manipulation.

</details>


### [100] [MPC-Guided Safe Reinforcement Learning and Lipschitz-Based Filtering for Structured Nonlinear Systems](https://arxiv.org/abs/2512.12855)
*Patrick Kostelac,Xuerui Wang,Anahita Jamshidnejad*

Main category: cs.RO

TL;DR: 提出一个结合MPC与RL的集成框架，将MPC的稳定性、安全性保证与RL的适应性相结合，通过MPC定义安全控制边界引导RL训练，部署时使用轻量级安全滤波器确保实时约束满足。


<details>
  <summary>Details</summary>
Motivation: 现代工程系统（如自动驾驶车辆、柔性机器人、智能航空航天平台）需要能够应对不确定性、适应环境变化并在实时约束下保证安全的控制器。RL虽然具有强大的数据驱动适应性，但缺乏动态约束满足机制；MPC具有结构化约束处理能力，但依赖精确模型且在线计算负担重。

Method: 提出MPC-RL集成框架：训练阶段，MPC定义安全控制边界来引导RL组件，实现约束感知的策略学习；部署阶段，学习到的策略实时运行，并基于Lipschitz连续性的轻量级安全滤波器确保约束满足，无需繁重的在线优化。

Result: 在非线性气动弹性翼系统上验证，展示了改进的扰动抑制、减少的作动器努力以及在湍流下的鲁棒性能。该架构可推广到其他具有结构化非线性和有界扰动的领域。

Conclusion: 该框架为工程应用中的安全人工智能驱动控制提供了可扩展的解决方案，结合了MPC的稳定性安全保证与RL的适应性优势，实现了实时约束满足而无需繁重在线计算。

Abstract: Modern engineering systems, such as autonomous vehicles, flexible robotics, and intelligent aerospace platforms, require controllers that are robust to uncertainties, adaptive to environmental changes, and safety-aware under real-time constraints. RL offers powerful data-driven adaptability for systems with nonlinear dynamics that interact with uncertain environments. RL, however, lacks built-in mechanisms for dynamic constraint satisfaction during exploration. MPC offers structured constraint handling and robustness, but its reliance on accurate models and computationally demanding online optimization may pose significant challenges. This paper proposes an integrated MPC-RL framework that combines stability and safety guarantees of MPC with the adaptability of RL. During training, MPC defines safe control bounds that guide the RL component and that enable constraint-aware policy learning. At deployment, the learned policy operates in real time with a lightweight safety filter based on Lipschitz continuity to ensure constraint satisfaction without heavy online optimizations. The approach, which is validated on a nonlinear aeroelastic wing system, demonstrates improved disturbance rejection, reduced actuator effort, and robust performance under turbulence. The architecture generalizes to other domains with structured nonlinearities and bounded disturbances, offering a scalable solution for safe artificial-intelligence-driven control in engineering applications.

</details>


### [101] [SLIM-VDB: A Real-Time 3D Probabilistic Semantic Mapping Framework](https://arxiv.org/abs/2512.12945)
*Anja Sheppard,Parker Ewen,Joey Wilson,Advaith V. Sethuraman,Benard Adewole,Anran Li,Yuzhen Chen,Ram Vasudevan,Katherine A. Skinner*

Main category: cs.RO

TL;DR: SLIM-VDB是一个轻量级语义建图系统，利用OpenVDB数据结构，支持封闭集和开放集语义融合，显著降低内存使用和建图时间。


<details>
  <summary>Details</summary>
Motivation: 现有语义建图系统存在两个主要问题：1) 未充分利用计算机图形学中高效的OpenVDB数据结构；2) 缺乏同时支持固定类别和开放语言标签预测的统一框架。

Method: 提出基于OpenVDB数据结构的3D语义建图系统，采用统一的贝叶斯更新框架，同时支持封闭集和开放集语义融合。

Result: 相比现有最先进的语义建图方法，SLIM-VDB在保持可比建图精度的同时，显著减少了内存使用和建图时间。

Conclusion: SLIM-VDB成功将OpenVDB数据结构应用于语义建图，提供了一个高效、轻量级且支持封闭/开放集语义融合的统一框架。

Abstract: This paper introduces SLIM-VDB, a new lightweight semantic mapping system with probabilistic semantic fusion for closed-set or open-set dictionaries. Advances in data structures from the computer graphics community, such as OpenVDB, have demonstrated significantly improved computational and memory efficiency in volumetric scene representation. Although OpenVDB has been used for geometric mapping in robotics applications, semantic mapping for scene understanding with OpenVDB remains unexplored. In addition, existing semantic mapping systems lack support for integrating both fixed-category and open-language label predictions within a single framework. In this paper, we propose a novel 3D semantic mapping system that leverages the OpenVDB data structure and integrates a unified Bayesian update framework for both closed- and open-set semantic fusion. Our proposed framework, SLIM-VDB, achieves significant reduction in both memory and integration times compared to current state-of-the-art semantic mapping approaches, while maintaining comparable mapping accuracy. An open-source C++ codebase with a Python interface is available at https://github.com/umfieldrobotics/slim-vdb.

</details>


### [102] [Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning](https://arxiv.org/abs/2512.12987)
*Amin Jalal Aghdasian,Farzaneh Abdollahi,Ali Kamali Iglie*

Main category: cs.RO

TL;DR: 提出两种基于深度强化学习的雪地车道保持算法：AR-RDPG（感知-控制分离）和AR-CADPG（端到端注意力机制），在CARLA模拟和真实Jetson Nano车辆上验证，AR-CADPG表现更优。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在雪地道路条件下存在不确定性和打滑问题，传统车道保持系统难以应对，需要开发能处理这些挑战的鲁棒算法。

Method: 提出两种基于深度强化学习的动作鲁棒方法：1) AR-RDPG：感知层使用多尺度神经网络去噪，预训练DCNN提取中心线系数，与控制层结合；2) AR-CADPG：端到端方法，将CNN和注意力机制集成到DRL框架中。

Result: 在CARLA模拟器中训练并在多种雪地场景验证，Jetson Nano真实车辆实验证实了学习策略的可行性和稳定性。AR-CADPG在路径跟踪精度和鲁棒性方面表现更优。

Conclusion: 结合时间记忆、对抗鲁棒性和注意力机制的AR-CADPG方法在雪地车道保持中效果最佳，证明了深度强化学习在恶劣天气自动驾驶中的有效性。

Abstract: This paper proposes two new algorithms for the lane keeping system (LKS) in autonomous vehicles (AVs) operating under snowy road conditions. These algorithms use deep reinforcement learning (DRL) to handle uncertainties and slippage. They include Action-Robust Recurrent Deep Deterministic Policy Gradient (AR-RDPG) and end-to-end Action-Robust convolutional neural network Attention Deterministic Policy Gradient (AR-CADPG), two action-robust approaches for decision-making. In the AR-RDPG method, within the perception layer, camera images are first denoised using multi-scale neural networks. Then, the centerline coefficients are extracted by a pre-trained deep convolutional neural network (DCNN). These coefficients, concatenated with the driving characteristics, are used as input to the control layer. The AR-CADPG method presents an end-to-end approach in which a convolutional neural network (CNN) and an attention mechanism are integrated within a DRL framework. Both methods are first trained in the CARLA simulator and validated under various snowy scenarios. Real-world experiments on a Jetson Nano-based autonomous vehicle confirm the feasibility and stability of the learned policies. Among the two models, the AR-CADPG approach demonstrates superior path-tracking accuracy and robustness, highlighting the effectiveness of combining temporal memory, adversarial resilience, and attention mechanisms in AVs.

</details>


### [103] [Learning Terrain Aware Bipedal Locomotion via Reduced Dimensional Perceptual Representations](https://arxiv.org/abs/2512.12993)
*Guillermo A. Castillo,Himanshu Lodha,Ayonga Hereid*

Main category: cs.RO

TL;DR: 提出分层地形感知双足运动策略，结合降维感知表示增强强化学习高层策略，通过CNN-VAE提取地形潜在编码，优化运动决策过程


<details>
  <summary>Details</summary>
Motivation: 传统端到端方法在复杂地形双足运动控制中效率低且鲁棒性差，需要更高效的地形感知和决策框架来提升学习效率和硬件部署可行性

Method: 1) 使用CNN-VAE提取地形潜在编码；2) 结合降阶机器人动力学构建紧凑状态空间；3) 引入历史感知机制，整合近期地形观测序列；4) 提出从深度相机图像学习潜在表示的蒸馏方法；5) 在高保真Agility Robotics模拟器中验证

Result: 系统分析了潜在空间维度对学习效率和策略鲁棒性的影响，方法展现出良好的鲁棒性和适应性，通过模拟与真实传感器数据对比验证了硬件部署潜力

Conclusion: 该分层地形感知框架有效提升了双足运动控制的效率和鲁棒性，为硬件部署提供了可行方案，展示了在复杂地形中实时步态生成的潜力

Abstract: This work introduces a hierarchical strategy for terrain-aware bipedal locomotion that integrates reduced-dimensional perceptual representations to enhance reinforcement learning (RL)-based high-level (HL) policies for real-time gait generation. Unlike end-to-end approaches, our framework leverages latent terrain encodings via a Convolutional Variational Autoencoder (CNN-VAE) alongside reduced-order robot dynamics, optimizing the locomotion decision process with a compact state. We systematically analyze the impact of latent space dimensionality on learning efficiency and policy robustness. Additionally, we extend our method to be history-aware, incorporating sequences of recent terrain observations into the latent representation to improve robustness. To address real-world feasibility, we introduce a distillation method to learn the latent representation directly from depth camera images and provide preliminary hardware validation by comparing simulated and real sensor data. We further validate our framework using the high-fidelity Agility Robotics (AR) simulator, incorporating realistic sensor noise, state estimation, and actuator dynamics. The results confirm the robustness and adaptability of our method, underscoring its potential for hardware deployment.

</details>


### [104] [K-VARK: Kernelized Variance-Aware Residual Kalman Filter for Sensorless Force Estimation in Collaborative Robots](https://arxiv.org/abs/2512.13009)
*Oğuzhan Akbıyık,Naseem Alhousani,Fares J. Abu-Dakka*

Main category: cs.RO

TL;DR: K-VARK是一种用于机器人无传感器力估计的新方法，通过核化概率模型和自适应卡尔曼滤波器，在6自由度协作机械臂上实现了比现有方法超过20%的RMSE降低。


<details>
  <summary>Details</summary>
Motivation: 机器人安全精确地与无结构环境交互需要可靠的接触力估计，但由于建模误差、复杂残余动力学和摩擦，准确的无传感器力估计仍然具有挑战性。

Method: 提出K-VARK方法，将关节残余扭矩的核化概率模型集成到自适应卡尔曼滤波器框架中。通过基于优化激励轨迹训练的核化运动基元，捕捉残余扭矩的预测均值和输入依赖的异方差方差，这些统计信息通过增强测量噪声协方差来通知方差感知的虚拟测量更新，同时过程噪声协方差通过变分贝叶斯优化在线适应以处理动态扰动。

Result: 在6自由度协作机械臂上的实验验证表明，K-VARK相比最先进的无传感器力估计方法实现了超过20%的RMSE降低，为抛光和装配等高级任务提供了鲁棒准确的外部力/扭矩估计。

Conclusion: K-VARK通过集成核化概率模型和自适应卡尔曼滤波器，有效解决了机器人无传感器力估计中的建模误差和复杂动态问题，显著提高了估计精度和鲁棒性。

Abstract: Reliable estimation of contact forces is crucial for ensuring safe and precise interaction of robots with unstructured environments. However, accurate sensorless force estimation remains challenging due to inherent modeling errors and complex residual dynamics and friction. To address this challenge, in this paper, we propose K-VARK (Kernelized Variance-Aware Residual Kalman filter), a novel approach that integrates a kernelized, probabilistic model of joint residual torques into an adaptive Kalman filter framework. Through Kernelized Movement Primitives trained on optimized excitation trajectories, K-VARK captures both the predictive mean and input-dependent heteroscedastic variance of residual torques, reflecting data variability and distance-to-training effects. These statistics inform a variance-aware virtual measurement update by augmenting the measurement noise covariance, while the process noise covariance adapts online via variational Bayesian optimization to handle dynamic disturbances. Experimental validation on a 6-DoF collaborative manipulator demonstrates that K-VARK achieves over 20% reduction in RMSE compared to state-of-the-art sensorless force estimation methods, yielding robust and accurate external force/torque estimation suitable for advanced tasks such as polishing and assembly.

</details>


### [105] [Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos](https://arxiv.org/abs/2512.13080)
*Yicheng Feng,Wanpeng Zhang,Ye Wang,Hao Luo,Haoqi Yuan,Sipeng Zheng,Zongqing Lu*

Main category: cs.RO

TL;DR: 提出空间感知的VLA预训练范式，通过2D视觉与3D空间的显式对齐，解决现有VLA模型在3D物理环境中感知与动作的鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型大多依赖2D视觉输入在3D物理环境中执行动作，导致感知与动作之间存在显著差距。需要弥合2D视觉观察与3D空间推理之间的鸿沟。

Method: 提出空间感知VLA预训练范式：1) 利用大规模人类演示视频提取3D视觉和3D动作标注；2) 构建VIPA-VLA双编码器架构，包含3D视觉编码器增强语义视觉表示；3) 在预训练期间显式对齐视觉空间与物理空间。

Result: VIPA-VLA在下游机器人任务中显著改善了2D视觉与3D动作之间的接地性，产生了更鲁棒和可泛化的机器人策略。

Conclusion: 通过空间感知预训练范式，VLA模型能够在机器人策略学习前获得3D空间理解能力，有效弥合了感知与动作之间的鸿沟。

Abstract: Vision-Language-Action (VLA) models provide a promising paradigm for robot learning by integrating visual perception with language-guided policy learning. However, most existing approaches rely on 2D visual inputs to perform actions in 3D physical environments, creating a significant gap between perception and action grounding. To bridge this gap, we propose a Spatial-Aware VLA Pretraining paradigm that performs explicit alignment between visual space and physical space during pretraining, enabling models to acquire 3D spatial understanding before robot policy learning. Starting from pretrained vision-language models, we leverage large-scale human demonstration videos to extract 3D visual and 3D action annotations, forming a new source of supervision that aligns 2D visual observations with 3D spatial reasoning. We instantiate this paradigm with VIPA-VLA, a dual-encoder architecture that incorporates a 3D visual encoder to augment semantic visual representations with 3D-aware features. When adapted to downstream robot tasks, VIPA-VLA achieves significantly improved grounding between 2D vision and 3D action, resulting in more robust and generalizable robotic policies.

</details>


### [106] [Multi-Robot Motion Planning from Vision and Language using Heat-Inspired Diffusion](https://arxiv.org/abs/2512.13090)
*Jebeom Chae,Junwoo Chang,Seungho Yeom,Yujin Kim,Jongeun Choi*

Main category: cs.RO

TL;DR: LCHD是一个端到端的视觉语言条件扩散规划框架，通过结合CLIP语义先验和碰撞避免扩散核，实现了无需显式环境表示的机器人轨迹生成，显著提高了成功率和规划效率。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在机器人运动规划中面临三个主要限制：1）难以扩展到多机器人场景和灵活的语言条件任务规范；2）推理时计算成本高；3）需要显式环境表示且缺乏几何可达性推理机制，导致泛化能力不足。

Method: 提出LCHD框架，整合CLIP语义先验作为语言理解模块，设计碰撞避免扩散核作为物理归纳偏置，使规划器能在可达工作空间内严格解释语言指令。该框架无需推理时提供显式障碍物信息，通过引导机器人朝向语义意图匹配的可达替代方案来处理分布外场景。

Result: 在多样化的真实世界启发地图和真实机器人实验中，LCHD在成功率上持续优于现有扩散规划器，同时显著降低了规划延迟。

Conclusion: LCHD通过结合语义理解和物理约束，实现了高效的语言条件机器人轨迹规划，能够处理可达性相关的分布外场景，为多机器人系统的灵活任务规范提供了有效解决方案。

Abstract: Diffusion models have recently emerged as powerful tools for robot motion planning by capturing the multi-modal distribution of feasible trajectories. However, their extension to multi-robot settings with flexible, language-conditioned task specifications remains limited. Furthermore, current diffusion-based approaches incur high computational cost during inference and struggle with generalization because they require explicit construction of environment representations and lack mechanisms for reasoning about geometric reachability. To address these limitations, we present Language-Conditioned Heat-Inspired Diffusion (LCHD), an end-to-end vision-based framework that generates language-conditioned, collision-free trajectories. LCHD integrates CLIP-based semantic priors with a collision-avoiding diffusion kernel serving as a physical inductive bias that enables the planner to interpret language commands strictly within the reachable workspace. This naturally handles out-of-distribution scenarios -- in terms of reachability -- by guiding robots toward accessible alternatives that match the semantic intent, while eliminating the need for explicit obstacle information at inference time. Extensive evaluations on diverse real-world-inspired maps, along with real-robot experiments, show that LCHD consistently outperforms prior diffusion-based planners in success rate, while reducing planning latency.

</details>


### [107] [PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations](https://arxiv.org/abs/2512.13093)
*Mingqi Yuan,Tao Yu,Haolin Song,Bo Li,Xin Jin,Hua Chen,Wenjun Zeng*

Main category: cs.RO

TL;DR: 提出PvP框架，通过本体感知与特权状态对比学习提升人形机器人强化学习效率，并开发SRL4Humanoid评估框架，实验证明在速度和运动模仿任务中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 人形机器人全身控制需要高效鲁棒的方法，但强化学习面临样本效率低下的挑战，主要由于机器人复杂动力学和部分可观测性。现有方法需要大量样本且缺乏系统评估框架。

Method: 提出PvP（本体感知-特权对比学习）框架，利用本体感知状态与特权状态的内在互补性学习紧凑任务相关潜在表示，无需手工数据增强。同时开发SRL4Humanoid统一模块化框架，集成代表性状态表示学习方法。

Result: 在LimX Oli机器人上进行速度跟踪和运动模仿任务实验，PvP相比基线SRL方法显著提升样本效率和最终性能。为数据高效的人形机器人学习提供实用指导。

Conclusion: PvP框架通过对比学习有效解决人形机器人强化学习样本效率问题，SRL4Humanoid框架为系统评估提供支持，为人形机器人全身控制的数据高效学习提供有价值指导。

Abstract: Achieving efficient and robust whole-body control (WBC) is essential for enabling humanoid robots to perform complex tasks in dynamic environments. Despite the success of reinforcement learning (RL) in this domain, its sample inefficiency remains a significant challenge due to the intricate dynamics and partial observability of humanoid robots. To address this limitation, we propose PvP, a Proprioceptive-Privileged contrastive learning framework that leverages the intrinsic complementarity between proprioceptive and privileged states. PvP learns compact and task-relevant latent representations without requiring hand-crafted data augmentations, enabling faster and more stable policy learning. To support systematic evaluation, we develop SRL4Humanoid, the first unified and modular framework that provides high-quality implementations of representative state representation learning (SRL) methods for humanoid robot learning. Extensive experiments on the LimX Oli robot across velocity tracking and motion imitation tasks demonstrate that PvP significantly improves sample efficiency and final performance compared to baseline SRL methods. Our study further provides practical insights into integrating SRL with RL for humanoid WBC, offering valuable guidance for data-efficient humanoid robot learning.

</details>


### [108] [Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation](https://arxiv.org/abs/2512.13094)
*Xiang Li,Gang Liu,Weitao Zhou,Hongyi Zhu,Zhong Cao*

Main category: cs.RO

TL;DR: SoE方法通过时序专家序列策略提升模仿学习在自动驾驶中的闭环性能，无需增加模型规模或数据需求，在nuPlan基准测试中达到SOTA


<details>
  <summary>Details</summary>
Motivation: 模仿学习在自动驾驶中表现出色，但在闭环环境中由于微小误差的累积导致性能下降。现有方法主要关注单时间点的状态级鲁棒性，而自动驾驶是连续时间过程，需要从时间尺度上增强鲁棒性

Method: 提出Sequence of Experts (SoE)方法，一种时序交替策略，通过时间尺度上的专家序列来增强闭环性能，不增加模型规模或数据需求

Result: 在大型自动驾驶基准nuPlan上的实验表明，SoE方法能一致且显著提升所有评估模型的性能，并达到最先进的性能水平

Conclusion: SoE模块为提升自动驾驶模型训练效率提供了关键且广泛适用的支持，通过时间尺度增强鲁棒性为解决模仿学习中的误差累积问题提供了新视角

Abstract: Imitation learning (IL) has emerged as a central paradigm in autonomous driving. While IL excels in matching expert behavior in open-loop settings by minimizing per-step prediction errors, its performance degrades unexpectedly in closed-loop due to the gradual accumulation of small, often imperceptible errors over time.Over successive planning cycles, these errors compound, potentially resulting in severe failures.Current research efforts predominantly rely on increasingly sophisticated network architectures or high-fidelity training datasets to enhance the robustness of IL planners against error accumulation, focusing on the state-level robustness at a single time point. However, autonomous driving is inherently a continuous-time process, and leveraging the temporal scale to enhance robustness may provide a new perspective for addressing this issue.To this end, we propose a method termed Sequence of Experts (SoE), a temporal alternation policy that enhances closed-loop performance without increasing model size or data requirements. Our experiments on large-scale autonomous driving benchmarks nuPlan demonstrate that SoE method consistently and significantly improves the performance of all the evaluated models, and achieves state-of-the-art performance.This module may provide a key and widely applicable support for improving the training efficiency of autonomous driving models.

</details>


### [109] [OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning](https://arxiv.org/abs/2512.13100)
*Guanhua Ji,Harsha Polavaram,Lawrence Yunliang Chen,Sandeep Bajamahal,Zehan Ma,Simeon Adebola,Chenfeng Xu,Ken Goldberg*

Main category: cs.RO

TL;DR: 提出AugE-Toolkit机器人增强流水线和OXE-AugE数据集，通过增加9种机器人形态将OXE数据集扩大3倍以上，改善跨形态学习效果


<details>
  <summary>Details</summary>
Motivation: 现有机器人数据集（如OXE）存在严重不平衡问题，前四种机器人类型占真实数据的85%以上，容易导致对特定机器人-场景组合的过拟合，需要更平衡多样的数据集来训练通用机器人策略

Method: 开发了AugE-Toolkit可扩展机器人增强流水线，创建了OXE-AugE高质量开源数据集，在原有OXE基础上增加了9种不同的机器人形态，包含超过440万条轨迹

Result: 增强数据集不仅提高了在增强机器人上的策略性能，还能提升在未见过的机器人上的泛化能力，甚至对原始机器人在分布偏移下的表现也有改善。OpenVLA和π0等先进通用策略在OXE-AugE上微调后，在未见过的机器人-夹爪组合上的成功率提高了24-45%

Conclusion: 通过机器人数据增强扩展数据集多样性可以显著提升跨形态学习效果，为训练更通用的机器人策略提供了有效的数据解决方案

Abstract: Large and diverse datasets are needed for training generalist robot policies that have potential to control a variety of robot embodiments -- robot arm and gripper combinations -- across diverse tasks and environments. As re-collecting demonstrations and retraining for each new hardware platform are prohibitively costly, we show that existing robot data can be augmented for transfer and generalization. The Open X-Embodiment (OXE) dataset, which aggregates demonstrations from over 60 robot datasets, has been widely used as the foundation for training generalist policies. However, it is highly imbalanced: the top four robot types account for over 85\% of its real data, which risks overfitting to robot-scene combinations. We present AugE-Toolkit, a scalable robot augmentation pipeline, and OXE-AugE, a high-quality open-source dataset that augments OXE with 9 different robot embodiments. OXE-AugE provides over 4.4 million trajectories, more than triple the size of the original OXE. We conduct a systematic study of how scaling robot augmentation impacts cross-embodiment learning. Results suggest that augmenting datasets with diverse arms and grippers improves policy performance not only on the augmented robots, but also on unseen robots and even the original robots under distribution shifts. In physical experiments, we demonstrate that state-of-the-art generalist policies such as OpenVLA and $π_0$ benefit from fine-tuning on OXE-AugE, improving success rates by 24-45% on previously unseen robot-gripper combinations across four real-world manipulation tasks. Project website: https://OXE-AugE.github.io/.

</details>


### [110] [START: Traversing Sparse Footholds with Terrain Reconstruction](https://arxiv.org/abs/2512.13153)
*Ruiqi Yu,Qianshi Wang,Hongyi Li,Zheng Jun,Zhicheng Wang,Jun Wu,Qiuguo Zhu*

Main category: cs.RO

TL;DR: START：一种单阶段学习框架，仅使用低成本机载视觉和本体感知来重建局部地形高度图，实现四足机器人在稀疏立足点地形上的敏捷稳定运动。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在稀疏立足点地形上运动需要精确的环境感知和敏捷控制。现有方法存在局限性：基于模型的分层控制器泛化能力有限且行为保守；端到端学习方法要么依赖噪声高度图，要么从深度图像隐式推断地形特征，缺少精确几何线索，导致学习效率低和步态僵硬。

Method: 提出START单阶段学习框架，仅使用低成本机载视觉和本体感知准确重建局部地形高度图，提供明确的中间表示来传达稀疏立足点区域的关键特征，支持全面的环境理解和精确地形评估。

Result: 实验结果表明START实现了在多样化真实场景中的零样本迁移，展现出卓越的适应性、精确的立足点放置和鲁棒的运动能力。

Conclusion: START通过显式地形重建克服了现有方法的局限性，减少了探索成本，加速了技能获取，为四足机器人在稀疏立足点地形上的敏捷稳定运动提供了有效解决方案。

Abstract: Traversing terrains with sparse footholds like legged animals presents a promising yet challenging task for quadruped robots, as it requires precise environmental perception and agile control to secure safe foot placement while maintaining dynamic stability. Model-based hierarchical controllers excel in laboratory settings, but suffer from limited generalization and overly conservative behaviors. End-to-end learning-based approaches unlock greater flexibility and adaptability, but existing state-of-the-art methods either rely on heightmaps that introduce noise and complex, costly pipelines, or implicitly infer terrain features from egocentric depth images, often missing accurate critical geometric cues and leading to inefficient learning and rigid gaits. To overcome these limitations, we propose START, a single-stage learning framework that enables agile, stable locomotion on highly sparse and randomized footholds. START leverages only low-cost onboard vision and proprioception to accurately reconstruct local terrain heightmap, providing an explicit intermediate representation to convey essential features relevant to sparse foothold regions. This supports comprehensive environmental understanding and precise terrain assessment, reducing exploration cost and accelerating skill acquisition. Experimental results demonstrate that START achieves zero-shot transfer across diverse real-world scenarios, showcasing superior adaptability, precise foothold placement, and robust locomotion.

</details>


### [111] [Iterative Tuning of Nonlinear Model Predictive Control for Robotic Manufacturing Tasks](https://arxiv.org/abs/2512.13170)
*Deepak Ingole,Valentin Bhend,Shiva Ganesh Murali,Oliver Dobrich,Alisa Rupenayan*

Main category: cs.RO

TL;DR: 提出基于迭代学习的非线性模型预测控制权重矩阵自动调优框架，通过任务级性能反馈自适应调整权重，在4次在线重复中达到接近离线贝叶斯优化的性能


<details>
  <summary>Details</summary>
Motivation: 制造过程常受环境漂移和系统磨损影响，即使在重复操作中也需要重新调整控制参数。传统方法需要大量离线评估或复杂的梯度计算。

Method: 受范数最优迭代学习控制启发，构建经验灵敏度矩阵，无需通过NMPC求解器进行微分，实现结构化的权重更新。在UR10e机器人碳纤维缠绕任务上进行仿真验证。

Result: 该方法在仅4次在线重复中收敛到接近离线贝叶斯优化的跟踪性能（RMSE在BO的0.3%以内），而BO算法需要100次离线评估。

Conclusion: 为重复机器人任务中的自适应NMPC调优提供了实用解决方案，结合了精心优化控制器的精度和在线适应的灵活性。

Abstract: Manufacturing processes are often perturbed by drifts in the environment and wear in the system, requiring control re-tuning even in the presence of repetitive operations. This paper presents an iterative learning framework for automatic tuning of Nonlinear Model Predictive Control (NMPC) weighting matrices based on task-level performance feedback. Inspired by norm-optimal Iterative Learning Control (ILC), the proposed method adaptively adjusts NMPC weights Q and R across task repetitions to minimize key performance indicators (KPIs) related to tracking accuracy, control effort, and saturation. Unlike gradient-based approaches that require differentiating through the NMPC solver, we construct an empirical sensitivity matrix, enabling structured weight updates without analytic derivatives. The framework is validated through simulation on a UR10e robot performing carbon fiber winding on a tetrahedral core. Results demonstrate that the proposed approach converges to near-optimal tracking performance (RMSE within 0.3% of offline Bayesian Optimization (BO)) in just 4 online repetitions, compared to 100 offline evaluations required by BO algorithm. The method offers a practical solution for adaptive NMPC tuning in repetitive robotic tasks, combining the precision of carefully optimized controllers with the flexibility of online adaptation.

</details>


### [112] [Efficient Generation of Smooth Paths with Curvature Guarantees by Mollification](https://arxiv.org/abs/2512.13183)
*Alfredo González-Calvin,Juan F. Jiménez,Héctor García de Marina*

Main category: cs.RO

TL;DR: 提出一种通过mollification正则化非可微路径的方法，生成可微路径并控制曲率，适用于实时微控制器实现


<details>
  <summary>Details</summary>
Motivation: 移动机器人路径跟踪算法通常要求路径至少二阶连续可微，但实际任务中常使用分段连续的非可微路径。现有平滑方法要么产生复杂轨迹，要么计算成本高。

Method: 使用mollification技术将任意路径近似为可微函数，可任意精度收敛到原路径。提供系统方法限制生成路径的曲率，特别适用于由航点序列连接的分段路径。

Result: 方法计算高效，可在微控制器上实时实现，与标准轨迹跟踪和路径跟随算法兼容。

Conclusion: 提出的mollification方法能有效正则化非可微路径，生成可微且曲率可控的可行路径，解决了现有平滑方法的复杂性和计算成本问题。

Abstract: Most path following and trajectory tracking algorithms in mobile robotics require the desired path or trajectory to be defined by at least twice continuously differentiable functions to guarantee key properties such as global convergence, especially for nonholonomic robots like unicycles with speed constraints. Consequently, these algorithms typically exclude continuous but non-differentiable paths, such as piecewise functions. Despite this exclusion, such paths provide convenient high-level inputs for describing robot missions or behavior. While techniques such as spline interpolation or optimization-based methods are commonly used to smooth non-differentiable paths or create feasible ones from sequences of waypoints, they either can produce unnecessarily complex trajectories or are computationally expensive. In this work, we present a method to regularize non-differentiable functions and generate feasible paths through mollification. Specifically, we approximate an arbitrary path with a differentiable function that can converge to it with arbitrary precision. Additionally, we provide a systematic method for bounding the curvature of generated paths, which we demonstrate by applying it to paths resulting from linking a sequence of waypoints with segments. The proposed approach is computationally efficient, enabling real-time implementation on microcontrollers and compatibility with standard trajectory tracking and path following algorithms.

</details>


### [113] [ALBATROSS: A robotised system for high-throughput electrolyte screening via automated electrolyte formulation, coin-cell fabrication, and electrochemical evaluation](https://arxiv.org/abs/2512.13198)
*Hyun-Gi Lee,Jaekyeong Han,Minjun Kwon,Hyeonuk Kwon,Jooha Park,Hoe Jin Ha,Dong-Hwa Seo*

Main category: cs.RO

TL;DR: 开发了全自动锂离子电池测试机器人系统ALBATROSS，能够在手套箱内自动完成电解液配制、纽扣电池组装和电化学测试，实现高通量电池研究。


<details>
  <summary>Details</summary>
Motivation: 随着电池技术向更高稳定性和能量密度发展，需要对不同组件配置进行大量电池级测试。传统的纽扣电池组装和测试过程需要研究人员投入大量时间和精力，阻碍了高通量筛选研究。

Method: 开发了ALBATROSS全自动系统，集成在氩气填充的手套箱内，包含定制设计的机器人夹爪和3D打印结构，用于精确电池处理。系统能够自动完成电解液配制、纽扣电池组装和电化学测试，最多可处理48个电池而无需人工干预。

Result: 系统实现了高组装可靠性：NCM811||Li半电池的放电容量相对标准偏差小于1.2%，EIS测量标准偏差小于3Ω。系统能够获得高质量的纽扣电池数据集。

Conclusion: ALBATROSS凭借其高可靠性和自动化能力，能够获得高质量的纽扣电池数据集，有望加速下一代电解液的开发。

Abstract: As battery technologies advance toward higher stability and energy density, the need for extensive cell-level testing across various component configurations becomes critical. To evaluate performance and understand the operating principles of batteries in laboratory scale, fabrication and evaluation of coin cells are essential processes. However, the conventional coin-cell assembly and testing processes require significant time and labor from researchers, posing challenges to high-throughput screening research. In this study, we introduce an Automated Li-ion BAttery Testing RObot SyStem (ALBATROSS), an automated system capable of electrolyte formulation, coin-cell assembly, and electrochemical evaluation. The system, integrated within a argon-filled glovebox, enables fully automated assembly and testing of up to 48 cells without researcher intervention. By incorporating custom-designed robot gripper and 3D-printed structures optimized for precise cell handling, ALBATROSS achieved high assembly reliability, yielding a relative standard deviation (RSD) of less than 1.2% in discharge capacity and a standard deviation of less than 3 Ω in EIS measurements for NCM811||Li half cells. Owing to its high reliability and automation capability, ALBATROSS allows for the acquisition of high-quality coin-cell datasets, which are expected to accelerate the development of next-generation electrolytes.

</details>


### [114] [Differentiable Material Point Method for the Control of Deformable Objects](https://arxiv.org/abs/2512.13214)
*Diego Bolliger,Gabriele Fadini,Markus Bambach,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 提出可微分MPM模拟器用于柔性物体控制，在超弹性绳索主动阻尼问题中比基线MPPI方法快2倍、能耗低20%、计算时间仅需3%


<details>
  <summary>Details</summary>
Motivation: 柔性物体控制具有挑战性，因为其非线性动力学和高维配置空间。现有方法难以高效优化控制轨迹。

Method: 开发可微分材料点法（MPM）模拟器，利用其可微性在超弹性绳索主动阻尼问题中优化控制轨迹。

Result: 模拟器使绳索动能最小化，比基线MPPI方法快约2倍，达到的动能水平低20%，计算时间仅需约3%。

Conclusion: 可微分MPM模拟器为柔性物体控制提供高效解决方案，显著优于传统方法，在计算效率和性能上都有明显优势。

Abstract: Controlling the deformation of flexible objects is challenging due to their non-linear dynamics and high-dimensional configuration space. This work presents a differentiable Material Point Method (MPM) simulator targeted at control applications. We exploit the differentiability of the simulator to optimize a control trajectory in an active damping problem for a hyperelastic rope. The simulator effectively minimizes the kinetic energy of the rope around 2$\times$ faster than a baseline MPPI method and to a 20% lower energy level, while using about 3% of the computation time.

</details>


### [115] [Multi-directional Safe Rectangle Corridor-Based MPC for Nonholonomic Robots Navigation in Cluttered Environment](https://arxiv.org/abs/2512.13215)
*Yinsong Qu,Yunxiang Li,Shanlin Zhong*

Main category: cs.RO

TL;DR: 提出改进的顺序模型预测控制导航框架，通过多方向安全矩形走廊和顺序MPC实现密集半结构化环境中的AMR导航


<details>
  <summary>Details</summary>
Motivation: AMR在密集、杂乱、半结构化环境中的导航面临挑战，包括非完整车辆动力学、静态/动态障碍物交互以及非凸约束空间等问题

Method: 提出ISMPC导航框架：1) MDSRC算法通过矩形凸区域编码自由空间避免静态障碍物碰撞；2) 顺序MPC框架集成走廊约束和屏障函数约束实现动静障碍物避障

Result: 自由空间利用率提高41.05%，平均走廊生成延迟仅3ms，保持实时计算性能，简化了传统导航算法架构

Conclusion: ISMPC框架有效解决了AMR在复杂环境中的导航挑战，在计算效率和避障性能方面表现优越

Abstract: Autonomous Mobile Robots (AMRs) have become indispensable in industrial applications due to their operational flexibility and efficiency. Navigation serves as a crucial technical foundation for accomplishing complex tasks. However, navigating AMRs in dense, cluttered, and semi-structured environments remains challenging, primarily due to nonholonomic vehicle dynamics, interactions with mixed static/dynamic obstacles, and the non-convex constrained nature of such operational spaces. To solve these problems, this paper proposes an Improved Sequential Model Predictive Control (ISMPC) navigation framework that systematically reformulates navigation tasks as sequential switched optimal control problems. The framework addresses the aforementioned challenges through two key innovations: 1) Implementation of a Multi-Directional Safety Rectangular Corridor (MDSRC) algorithm, which encodes the free space through rectangular convex regions to avoid collision with static obstacles, eliminating redundant computational burdens and accelerating solver convergence; 2) A sequential MPC navigation framework that integrates corridor constraints with barrier function constraints is proposed to achieve static and dynamic obstacle avoidance. The ISMPC navigation framework enables direct velocity generation for AMRs, simplifying traditional navigation algorithm architectures. Comparative experiments demonstrate the framework's superiority in free-space utilization ( an increase of 41.05$\%$ in the average corridor area) while maintaining real-time computational performance (average corridors generation latency of 3 ms).

</details>


### [116] [A Unified Framework for Automated Assembly Sequence and Production Line Planning using Graph-based Optimization](https://arxiv.org/abs/2512.13219)
*Christoph Hartmann,Marios Demetriades,Kevin Prüfer,Zichen Zhang,Klaus Spindler,Stefan Weltge*

Main category: cs.RO

TL;DR: PyCAALP是一个基于Python的计算机辅助装配线规划框架，采用图论方法建模组件和连接，通过集成运动学边界条件和几何约束来自动化装配序列规划与生产线规划。


<details>
  <summary>Details</summary>
Motivation: 解决装配序列规划（ASP）和生产线规划（PLP）中的高组合复杂性问题，确保自动化装配规划的可行性，同时平衡规划质量与计算效率。

Method: 采用图论方法建模组件和连接，集成运动学边界条件（如部件碰撞检测），使用启发式方法（如单件流装配）优化解空间，将PLP阶段建模为混合整数规划（MIP）问题。

Result: 开发了开源框架PyCAALP，能够计算所有可行的生产序列，支持工程约束定制化，在ASP和PLP之间实现灵活权衡，显著减少MIP计算时间。

Conclusion: PyCAALP框架为复杂装配的自动化规划提供了有效解决方案，通过开源方式促进工业和生产研究领域的进一步合作与应用。

Abstract: This paper presents PyCAALP (Python-based Computer-Aided Assembly Line Planning), a framework for automated Assembly Sequence Planning (ASP) and Production Line Planning (PLP), employing a graph-based approach to model components and joints within production modules. The framework integrates kinematic boundary conditions, such as potential part collisions, to guarantee the feasibility of automated assembly planning. The developed algorithm computes all feasible production sequences, integrating modules for detecting spatial relationships and formulating geometric constraints. The algorithm incorporates additional attributes, including handling feasibility, tolerance matching, and joint compatibility, to manage the high combinatorial complexity inherent in assembly sequence generation. Heuristics, such as Single-Piece Flow assembly and geometrical constraint enforcement, are utilized to further refine the solution space, facilitating more efficient planning for complex assemblies. The PLP stage is formulated as a Mixed-Integer Program (MIP), balancing the total times of a fixed number of manufacturing stations. While some complexity reduction techniques may sacrifice optimality, they significantly reduce the MIPs computational time. Furthermore, the framework enables customization of engineering constraints and supports a flexible trade-off between ASP and PLP. The open-source nature of the framework, available at https://github.com/TUM-utg/PyCAALP, promotes further collaboration and adoption in both industrial and production research applications.

</details>


### [117] [Post-Training and Test-Time Scaling of Generative Agent Behavior Models for Interactive Autonomous Driving](https://arxiv.org/abs/2512.13262)
*Hyunki Seong,Jeong-Kyun Lee,Heesoo Myeong,Yongho Shin,Hyun-Mook Cho,Duck Hoon Kim,Pranav Desai,Monu Surana*

Main category: cs.RO

TL;DR: 提出GRBO强化学习后训练方法和Warm-K采样策略，提升多智能体交互运动行为的安全性和一致性


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习模型存在数据集偏差问题，在安全关键场景下鲁棒性不足，且大多数研究采用开环评估，忽略了闭环执行中的累积误差

Method: 1. GRBO：基于群体相对优势最大化和人类正则化的强化学习后训练方法，微调预训练行为模型；2. Warm-K：基于热启动的Top-K采样策略，平衡运动选择的一致性和多样性

Result: GRBO仅使用10%训练数据即可提升40%以上的安全性能，同时保持行为真实性；Warm-K方法在测试时增强行为一致性和反应性，无需重新训练

Conclusion: 通过GRBO和Warm-K两种互补策略，有效解决了自动驾驶中多智能体交互运动行为的安全性和闭环执行问题

Abstract: Learning interactive motion behaviors among multiple agents is a core challenge in autonomous driving. While imitation learning models generate realistic trajectories, they often inherit biases from datasets dominated by safe demonstrations, limiting robustness in safety-critical cases. Moreover, most studies rely on open-loop evaluation, overlooking compounding errors in closed-loop execution. We address these limitations with two complementary strategies. First, we propose Group Relative Behavior Optimization (GRBO), a reinforcement learning post-training method that fine-tunes pretrained behavior models via group relative advantage maximization with human regularization. Using only 10% of the training dataset, GRBO improves safety performance by over 40% while preserving behavioral realism. Second, we introduce Warm-K, a warm-started Top-K sampling strategy that balances consistency and diversity in motion selection. Our Warm-K method-based test-time scaling enhances behavioral consistency and reactivity at test time without retraining, mitigating covariate shift and reducing performance discrepancies. Demo videos are available in the supplementary material.

</details>


### [118] [Lightweight Dynamic Modeling of Cable-Driven Continuum Robots Based on Actuation-Space Energy Formulation](https://arxiv.org/abs/2512.13271)
*Fangju Yang,Hang Yang,Ibrahim Alsarraj,Yuhao Wang,Ke Wu*

Main category: cs.RO

TL;DR: 提出LASEM框架，通过驱动空间能量建模实现轻量级实时动态建模，计算效率提升62.3%


<details>
  <summary>Details</summary>
Motivation: 电缆驱动连续体机器人需要准确、实时的动态模型用于高速动态预测或基于模型的控制，这是当前迫切需求

Method: 提出轻量级驱动空间能量建模框架，直接在驱动空间表述驱动势能，通过变分推导将控制动态简化为单一偏微分方程，避免显式计算电缆-骨架接触力

Result: 框架支持力和位移两种驱动模式，通过Galerkin时空模态离散化，计算速度比现有实时动态建模方法平均提升62.3%

Conclusion: LASEM框架为电缆驱动连续体机器人提供了轻量级、准确、高效的动态建模方法，显著提升计算效率

Abstract: Cable-driven continuum robots (CDCRs) require accurate, real-time dynamic models for high-speed dynamics prediction or model-based control, making such capability an urgent need. In this paper, we propose the Lightweight Actuation-Space Energy Modeling (LASEM) framework for CDCRs, which formulates actuation potential energy directly in actuation space to enable lightweight yet accurate dynamic modeling. Through a unified variational derivation, the governing dynamics reduce to a single partial differential equation (PDE), requiring only the Euler moment balance while implicitly incorporating the Newton force balance. By also avoiding explicit computation of cable-backbone contact forces, the formulation simplifies the model structure and improves computational efficiency while preserving geometric accuracy and physical consistency. Importantly, the proposed framework for dynamic modeling natively supports both force-input and displacement-input actuation modes, a capability seldom achieved in existing dynamic formulations. Leveraging this lightweight structure, a Galerkin space-time modal discretization with analytical time-domain derivatives of the reduced state further enables an average 62.3% computational speedup over state-of-the-art real-time dynamic modeling approaches.

</details>


### [119] [Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration](https://arxiv.org/abs/2512.13293)
*Hao Fua,Wei Liu,Shuai Zhoua*

Main category: cs.RO

TL;DR: 提出一种基于内在动机探索的多机器人强化学习算法，用于解决社交编队导航中机器人协调探索效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人社交编队导航对于实现人机共存至关重要，但行人行为的不可预测性和非合作性给机器人协调探索带来挑战，现有强化学习方法在探索效率方面存在局限。

Method: 提出协调探索多机器人强化学习算法，核心是自学习内在奖励机制来缓解策略保守性；采用集中训练分散执行框架下的双采样模式，通过两时间尺度更新规则解耦参数更新。

Result: 在社交编队导航基准测试中，该算法在关键指标上优于现有最先进方法。

Conclusion: 提出的基于内在动机探索的协调多机器人强化学习算法能有效提升社交编队导航性能，为人机共存场景提供了更优的解决方案。

Abstract: This paper investigates the application of reinforcement learning (RL) to multi-robot social formation navigation, a critical capability for enabling seamless human-robot coexistence. While RL offers a promising paradigm, the inherent unpredictability and often uncooperative dynamics of pedestrian behavior pose substantial challenges, particularly concerning the efficiency of coordinated exploration among robots. To address this, we propose a novel coordinated-exploration multi-robot RL algorithm introducing an intrinsic motivation exploration. Its core component is a self-learning intrinsic reward mechanism designed to collectively alleviate policy conservatism. Moreover, this algorithm incorporates a dual-sampling mode within the centralized training and decentralized execution framework to enhance the representation of both the navigation policy and the intrinsic reward, leveraging a two-time-scale update rule to decouple parameter updates. Empirical results on social formation navigation benchmarks demonstrate the proposed algorithm's superior performance over existing state-of-the-art methods across crucial metrics. Our code and video demos are available at: https://github.com/czxhunzi/CEMRRL.

</details>


### [120] [Humanoid Robot Running Through Random Stepping Stones and Jumping Over Obstacles: Step Adaptation Using Spring-Mass Trajectories](https://arxiv.org/abs/2512.13304)
*Sait Sovukluk,Johannes Englsberger,Christian Ott*

Main category: cs.RO

TL;DR: 提出一个基于弹簧质量轨迹和死区控制增益库的跑步步态自适应框架，通过全身体控制实现各种敏捷行为


<details>
  <summary>Details</summary>
Motivation: 开发一个能够应对复杂地形和不确定性的跑步控制框架，使双足机器人能够执行各种敏捷行为，如随机踏石、跳跃障碍、急转弯等

Method: 包含四个主要部分：1) 自动生成弹簧质量轨迹库；2) 通过主动控制模板模型生成死区控制增益库；3) 开发步态自适应轨迹选择策略；4) 通过全身体控制框架将弹簧质量轨迹映射到人形机器人模型

Result: 在MuJoCo物理模拟器中展示了框架的包容性和鲁棒性，能够执行多种挑战性行为，包括随机踏石、跳跃障碍、急转弯等，所有行为使用单一库和相同控制参数，无需额外调优

Conclusion: 提出的框架能够有效处理现实世界挑战，包括信号噪声、不精确性、建模误差和延迟，为双足机器人跑步控制提供了鲁棒且高效的解决方案

Abstract: This study proposes a step adaptation framework for running through spring-mass trajectories and deadbeat control gain libraries. It includes four main parts: (1) Automatic spring-mass trajectory library generation; (2) Deadbeat control gain library generation through an actively controlled template model that resembles the whole-body dynamics well; (3) Trajectory selection policy development for step adaptation; (4) Mapping spring-mass trajectories to a humanoid model through a whole-body control (WBC) framework also accounting for closed-kinematic chain systems, self collisions, and reactive limb swinging. We show the inclusiveness and the robustness of the proposed framework through various challenging and agile behaviors such as running through randomly generated stepping stones, jumping over random obstacles, performing slalom motions, changing the running direction suddenly with a random leg, and rejecting significant disturbances and uncertainties through the MuJoCo physics simulator. We also perform additional simulations under a comprehensive set of uncertainties and noise to better justify the proposed method's robustness to real-world challenges, including signal noise, imprecision, modeling errors, and delays. All the aforementioned behaviors are performed with a single library and the same set of WBC control parameters without additional tuning. The spring-mass and the deadbeat control gain library are automatically computed in 4.5 seconds in total for 315 different trajectories.

</details>


### [121] [Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)](https://arxiv.org/abs/2512.13356)
*Zeyad Gamal,Youssef Mahran,Ayman El-Badawy*

Main category: cs.RO

TL;DR: 使用TD3强化学习算法控制双旋翼气动系统，实现角度稳定和轨迹跟踪，相比传统PID在抗干扰方面表现更好


<details>
  <summary>Details</summary>
Motivation: 双旋翼气动系统(TRAS)具有复杂的非线性动力学特性，传统控制算法难以有效控制。近年来强化学习在多旋翼控制领域展现出潜力，因此探索RL在TRAS控制中的应用。

Method: 采用Twin Delayed Deep Deterministic Policy Gradient (TD3)算法训练RL智能体，该算法适用于连续状态和动作空间的环境，且不需要系统模型。通过仿真验证方法有效性，并与传统PID控制器进行对比测试。

Result: 仿真结果表明RL控制方法有效。在风扰等外部干扰测试中，RL控制器相比传统PID控制器表现更优。实验室实际装置实验进一步证实了控制器在现实应用中的有效性。

Conclusion: 强化学习框架能够有效控制复杂的双旋翼气动系统，TD3算法在连续控制任务中表现出色，为多旋翼系统的智能控制提供了有前景的解决方案。

Abstract: This paper proposes a reinforcement learning (RL) framework for controlling and stabilizing the Twin Rotor Aerodynamic System (TRAS) at specific pitch and azimuth angles and tracking a given trajectory. The complex dynamics and non-linear characteristics of the TRAS make it challenging to control using traditional control algorithms. However, recent developments in RL have attracted interest due to their potential applications in the control of multirotors. The Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm was used in this paper to train the RL agent. This algorithm is used for environments with continuous state and action spaces, similar to the TRAS, as it does not require a model of the system. The simulation results illustrated the effectiveness of the RL control method. Next, external disturbances in the form of wind disturbances were used to test the controller's effectiveness compared to conventional PID controllers. Lastly, experiments on a laboratory setup were carried out to confirm the controller's effectiveness in real-world applications.

</details>


### [122] [Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles](https://arxiv.org/abs/2512.13359)
*Sümer Tunçay,Alain Andres,Ignacio Carlucho*

Main category: cs.RO

TL;DR: 提出基于JAX和MJX的GPU加速RL训练框架，实现2分钟内完成AUV六自由度位置控制策略训练，并在真实水下实验中验证了零样本迁移效果


<details>
  <summary>Details</summary>
Motivation: 传统AUV控制器在未建模动态和环境扰动下性能下降，而传统RL训练速度慢且仿真到真实迁移困难，需要更高效的训练方法

Method: 使用JAX和MuJoCo-XLA构建GPU加速的RL训练管道，通过联合JIT编译大规模并行物理仿真和学习更新，实现快速训练

Result: 训练时间缩短至2分钟以内，在真实水下实验中实现了鲁棒的六自由度轨迹跟踪和扰动抑制，策略从仿真零样本迁移成功

Conclusion: 首次在真实世界中展示了基于RL的AUV六自由度位置控制，证明了快速训练和零样本迁移的可行性

Abstract: Autonomous Underwater Vehicles (AUVs) require reliable six-degree-of-freedom (6-DOF) position control to operate effectively in complex and dynamic marine environments. Traditional controllers are effective under nominal conditions but exhibit degraded performance when faced with unmodeled dynamics or environmental disturbances. Reinforcement learning (RL) provides a powerful alternative but training is typically slow and sim-to-real transfer remains challenging. This work introduces a GPU-accelerated RL training pipeline built in JAX and MuJoCo-XLA (MJX). By jointly JIT-compiling large-scale parallel physics simulation and learning updates, we achieve training times of under two minutes.Through systematic evaluation of multiple RL algorithms, we show robust 6-DOF trajectory tracking and effective disturbance rejection in real underwater experiments, with policies transferred zero-shot from simulation. Our results provide the first explicit real-world demonstration of RL-based AUV position control across all six degrees of freedom.

</details>


### [123] [Universal Dexterous Functional Grasping via Demonstration-Editing Reinforcement Learning](https://arxiv.org/abs/2512.13380)
*Chuan Mao,Haoqi Yuan,Ziye Huang,Chaoyi Xu,Kai Ma,Zongqing Lu*

Main category: cs.RO

TL;DR: DemoFunGrasp：通过演示编辑和条件分解实现通用灵巧功能抓取，将功能抓取条件分解为抓取风格和可供性，利用单次演示进行一步演示编辑，提高样本效率，实现未见物体、可供性和抓取风格的泛化。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在灵巧抓取方面取得了成功，但精细化的功能抓取（对下游操作任务至关重要）仍面临挑战：为不同物体的功能抓取指定目标和奖励函数复杂，多任务强化学习探索困难，以及仿真到现实迁移的挑战。

Method: 将功能抓取条件分解为抓取风格和可供性两个互补组件，集成到强化学习框架中；利用单次抓取演示，将强化学习问题重新表述为一步演示编辑，大幅提高样本效率和性能；结合视觉语言模型进行规划。

Result: 在仿真和现实世界中，DemoFunGrasp能够泛化到未见过的物体、可供性和抓取风格组合，在成功率和功能抓取准确性方面优于基线方法；具备强大的仿真到现实迁移能力，通过视觉语言模型实现自主指令跟随抓取执行。

Conclusion: DemoFunGrasp通过条件分解和演示编辑的方法，有效解决了通用灵巧功能抓取的挑战，实现了对多样化功能抓取条件的泛化，为下游操作任务提供了可靠的基础。

Abstract: Reinforcement learning (RL) has achieved great success in dexterous grasping, significantly improving grasp performance and generalization from simulation to the real world. However, fine-grained functional grasping, which is essential for downstream manipulation tasks, remains underexplored and faces several challenges: the complexity of specifying goals and reward functions for functional grasps across diverse objects, the difficulty of multi-task RL exploration, and the challenge of sim-to-real transfer. In this work, we propose DemoFunGrasp for universal dexterous functional grasping. We factorize functional grasping conditions into two complementary components - grasping style and affordance - and integrate them into an RL framework that can learn to grasp any object with any functional grasping condition. To address the multi-task optimization challenge, we leverage a single grasping demonstration and reformulate the RL problem as one-step demonstration editing, substantially enhancing sample efficiency and performance. Experimental results in both simulation and the real world show that DemoFunGrasp generalizes to unseen combinations of objects, affordances, and grasping styles, outperforming baselines in both success rate and functional grasping accuracy. In addition to strong sim-to-real capability, by incorporating a vision-language model (VLM) for planning, our system achieves autonomous instruction-following grasp execution.

</details>


### [124] [Evaluating the Navigation Capabilities of a Modified COAST Guidewire Robot in an Anatomical Phantom Model](https://arxiv.org/abs/2512.13477)
*Timothy A. Brumfiel,Revanth Konda,Drew Elliott,Jaydev P. Desai*

Main category: cs.RO

TL;DR: 本研究评估了简化版COAST导丝机器人（从三管结构改为两管）在脉动血流解剖模型中的导航性能，证明了其在复杂血管结构中导航的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决血管内介入手术中手动操作导丝的问题，医疗机器人研究致力于开发机器人可操纵导丝，以增强导丝的可操作性和导航能力。COAST导丝机器人能够产生多种运动模式，但需要简化设计以评估其实际性能。

Method: 本研究采用简化版的COAST导丝机器人（从三管结构简化为两管结构），在具有脉动血流的解剖模型中进行导航实验，评估其性能。

Result: 实验结果表明，简化版COAST导丝机器人能够有效导航复杂的模型血管结构，证明了其在实际应用中的可行性。

Conclusion: 简化版COAST导丝机器人在脉动血流解剖模型中展现出良好的导航性能，为血管内介入手术的机器人辅助导航提供了有效解决方案。

Abstract: To address the issues that arise due to the manual navigation of guidewires in endovascular interventions, research in medical robotics has taken a strong interest in developing robotically steerable guidewires, which offer the possibility of enhanced maneuverability and navigation, as the tip of the guidewire can be actively steered. The COaxially Aligned STeerable (COAST) guidewire robot has the ability to generate a wide variety of motions including bending motion with different bending lengths, follow-the-leader motion, and feedforward motion. In our past studies, we have explored different designs of the COAST guidewire robot and developed modeling, control, and sensing strategies for the COAST guidewire robot. In this study, the performance of a modified COAST guidewire robot is evaluated by conducting navigation experiments in an anatomical phantom model with pulsatile flow. The modified COAST guidewire robot is a simplified version of the COAST guidewire robot and consists of two tubes as opposed to three tubes. Through this study, we demonstrate the effectiveness of the modified COAST guidewire robot in navigating the tortuous phantom vasculature.

</details>


### [125] [Reinforcement Learning based 6-DoF Maneuvers for Microgravity Intravehicular Docking: A Simulation Study with Int-Ball2 in ISS-JEM](https://arxiv.org/abs/2512.13514)
*Aman Arora,Matteo El-Hariry,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 使用强化学习框架在JAXA Int-Ball2机器人上实现6自由度精确对接，在高保真模拟环境中训练控制器，研究推进物理对微重力环境下对接性能的影响


<details>
  <summary>Details</summary>
Motivation: 国际空间站内自主飞行器的精确对接面临传感噪声、执行器微小不匹配和环境变化等挑战，需要可靠的控制方法

Method: 使用近端策略优化（PPO）强化学习框架，在高保真Isaac Sim模拟的日本实验舱环境中训练6自由度对接控制器，采用领域随机化动力学和有界观测噪声，明确建模螺旋桨阻力扭矩效应和极性结构

Result: 学习到的策略在各种条件下实现了稳定可靠的对接，为未来扩展奠定了基础

Conclusion: 该研究为Int-Ball2机器人在碰撞感知导航、安全强化学习、推进精确的模拟到真实转移以及基于视觉的端到端对接等未来扩展奠定了基础

Abstract: Autonomous free-flyers play a critical role in intravehicular tasks aboard the International Space Station (ISS), where their precise docking under sensing noise, small actuation mismatches, and environmental variability remains a nontrivial challenge. This work presents a reinforcement learning (RL) framework for six-degree-of-freedom (6-DoF) docking of JAXA's Int-Ball2 robot inside a high-fidelity Isaac Sim model of the Japanese Experiment Module (JEM). Using Proximal Policy Optimization (PPO), we train and evaluate controllers under domain-randomized dynamics and bounded observation noise, while explicitly modeling propeller drag-torque effects and polarity structure. This enables a controlled study of how Int-Ball2's propulsion physics influence RL-based docking performance in constrained microgravity interiors. The learned policy achieves stable and reliable docking across varied conditions and lays the groundwork for future extensions pertaining to Int-Ball2 in collision-aware navigation, safe RL, propulsion-accurate sim-to-real transfer, and vision-based end-to-end docking.

</details>


### [126] [Near-Field Perception for Safety Enhancement of Autonomous Mobile Robots in Manufacturing Environments](https://arxiv.org/abs/2512.13561)
*Li-Wei Shih,Ruo-Syuan Mei,Jesse Heidrich,Hui-Ping Wang,Joel Hooton,Joshua Solomon,Jorge Arinez,Guangze Li,Chenhui Shao*

Main category: cs.RO

TL;DR: 本文提出了一种用于自主移动机器人近场感知的三层框架，包括光间断检测、光位移测量和基于计算机视觉的对象检测，在Raspberry Pi 5上实现实时性能，为制造环境中的AMR提供可扩展的安全感知解决方案。


<details>
  <summary>Details</summary>
Motivation: 在制造环境中，自主移动机器人需要可靠的近场感知以确保安全操作。传统的测距传感器（如LiDAR和超声波设备）虽然能提供广泛的情境感知，但往往无法检测到机器人底座附近的小物体，存在安全隐患。

Method: 提出三层近场感知框架：1）光间断检测：通过激光条纹投影到近场区域，检测条纹中断来实现快速二进制障碍物存在检测；2）光位移测量：通过分析投影条纹在相机图像中的几何位移来估计物体高度，提供定量障碍物高度信息；3）基于计算机视觉的对象检测：在嵌入式AI硬件上运行对象检测模型，对物体进行分类，实现语义感知和情境感知的安全决策。所有方法均在Raspberry Pi 5系统上实现。

Result: 系统实现了25或50帧/秒的实时性能。实验评估和比较分析表明，所提出的层次结构在精度、计算和成本之间取得了平衡，为制造环境中的AMR安全操作提供了可扩展的感知解决方案。

Conclusion: 该三层近场感知框架通过结合快速二进制检测、定量高度测量和语义分类，为自主移动机器人提供了全面的近场感知能力，在保持实时性能的同时平衡了精度和计算成本，适用于制造环境的安全操作需求。

Abstract: Near-field perception is essential for the safe operation of autonomous mobile robots (AMRs) in manufacturing environments. Conventional ranging sensors such as light detection and ranging (LiDAR) and ultrasonic devices provide broad situational awareness but often fail to detect small objects near the robot base. To address this limitation, this paper presents a three-tier near-field perception framework. The first approach employs light-discontinuity detection, which projects a laser stripe across the near-field zone and identifies interruptions in the stripe to perform fast, binary cutoff sensing for obstacle presence. The second approach utilizes light-displacement measurement to estimate object height by analyzing the geometric displacement of a projected stripe in the camera image, which provides quantitative obstacle height information with minimal computational overhead. The third approach employs a computer vision-based object detection model on embedded AI hardware to classify objects, enabling semantic perception and context-aware safety decisions. All methods are implemented on a Raspberry Pi 5 system, achieving real-time performance at 25 or 50 frames per second. Experimental evaluation and comparative analysis demonstrate that the proposed hierarchy balances precision, computation, and cost, thereby providing a scalable perception solution for enabling safe operations of AMRs in manufacturing environments.

</details>


### [127] [World Models Can Leverage Human Videos for Dexterous Manipulation](https://arxiv.org/abs/2512.13644)
*Raktim Gautam Goswami,Amir Bar,David Fan,Tsung-Yen Yang,Gaoyue Zhou,Prashanth Krishnamurthy,Michael Rabbat,Farshad Khorrami,Yann LeCun*

Main category: cs.RO

TL;DR: DexWM是一个灵巧操作世界模型，通过预测环境潜在状态来提升机器人灵巧操作能力，在未见过的操作任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作具有挑战性，需要理解细微的手部动作如何通过物体接触影响环境。现有灵巧操作数据集稀缺，且仅预测视觉特征不足以实现精细灵巧操作。

Method: 提出DexWM模型，基于过去状态和灵巧动作预测环境的下一个潜在状态。使用超过900小时的人类和非灵巧机器人视频进行训练。引入辅助手部一致性损失来确保准确的手部配置。

Result: DexWM在预测未来状态方面优于基于文本、导航和全身动作的先前世界模型。在Franka Panda机械臂和Allegro夹爪上的零样本泛化实验中，在抓取、放置和到达任务上平均比Diffusion Policy高出50%以上。

Conclusion: DexWM通过世界模型方法和手部一致性损失，有效解决了灵巧操作中的挑战，在未见过的操作技能上表现出强大的泛化能力。

Abstract: Dexterous manipulation is challenging because it requires understanding how subtle hand motion influences the environment through contact with objects. We introduce DexWM, a Dexterous Manipulation World Model that predicts the next latent state of the environment conditioned on past states and dexterous actions. To overcome the scarcity of dexterous manipulation datasets, DexWM is trained on over 900 hours of human and non-dexterous robot videos. To enable fine-grained dexterity, we find that predicting visual features alone is insufficient; therefore, we introduce an auxiliary hand consistency loss that enforces accurate hand configurations. DexWM outperforms prior world models conditioned on text, navigation, and full-body actions, achieving more accurate predictions of future states. DexWM also demonstrates strong zero-shot generalization to unseen manipulation skills when deployed on a Franka Panda arm equipped with an Allegro gripper, outperforming Diffusion Policy by over 50% on average in grasping, placing, and reaching tasks.

</details>


### [128] [RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics](https://arxiv.org/abs/2512.13660)
*Enshen Zhou,Cheng Chi,Yibo Li,Jingkun An,Jiayuan Zhang,Shanyu Rong,Yi Han,Yuheng Ji,Mengzhen Liu,Pengwei Wang,Zhongyuan Wang,Lu Sheng,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboTracer：首个实现3D空间指代与测量的3D感知视觉语言模型，通过空间编码器和回归监督解码器增强尺度感知，结合强化微调实现多步度量推理，在空间追踪任务上大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 空间追踪作为机器人基本交互能力，需要多步度量推理、复杂空间指代和真实世界度量测量，现有方法难以应对这种组合任务。

Method: 提出RoboTracer 3D感知VLM：1）通用空间编码器和回归监督解码器实现3D空间指代与测量；2）强化微调（RFT）配合度量敏感过程奖励，监督关键中间感知线索；3）构建TraceSpatial大规模数据集（30M QA对）和TraceSpatial-Bench基准。

Result: RoboTracer在空间理解、测量和指代方面超越基线，平均成功率79.1%；在TraceSpatial-Bench上大幅领先，比Gemini-2.5-Pro准确率高36%；可集成多种控制策略，在杂乱真实场景中执行长时程动态任务。

Conclusion: RoboTracer通过创新的3D感知架构和强化微调方法，首次实现了机器人空间追踪的完整能力，为机器人复杂空间交互提供了有效解决方案。

Abstract: Spatial tracing, as a fundamental embodied interaction ability for robots, is inherently challenging as it requires multi-step metric-grounded reasoning compounded with complex spatial referring and real-world metric measurement. However, existing methods struggle with this compositional task. To this end, we propose RoboTracer, a 3D-aware VLM that first achieves both 3D spatial referring and measuring via a universal spatial encoder and a regression-supervised decoder to enhance scale awareness during supervised fine-tuning (SFT). Moreover, RoboTracer advances multi-step metric-grounded reasoning via reinforcement fine-tuning (RFT) with metric-sensitive process rewards, supervising key intermediate perceptual cues to accurately generate spatial traces. To support SFT and RFT training, we introduce TraceSpatial, a large-scale dataset of 30M QA pairs, spanning outdoor/indoor/tabletop scenes and supporting complex reasoning processes (up to 9 steps). We further present TraceSpatial-Bench, a challenging benchmark filling the gap to evaluate spatial tracing. Experimental results show that RoboTracer surpasses baselines in spatial understanding, measuring, and referring, with an average success rate of 79.1%, and also achieves SOTA performance on TraceSpatial-Bench by a large margin, exceeding Gemini-2.5-Pro by 36% accuracy. Notably, RoboTracer can be integrated with various control policies to execute long-horizon, dynamic tasks across diverse robots (UR5, G1 humanoid) in cluttered real-world scenes.

</details>


### [129] [NL2SpaTiaL: Generating Geometric Spatio-Temporal Logic Specifications from Natural Language for Manipulation Tasks](https://arxiv.org/abs/2512.13670)
*Licheng Luo,Yu Xia,Kaier Liang,Mingyu Cai*

Main category: cs.RO

TL;DR: 提出了NL2SpaTiaL数据集和翻译验证框架，将自然语言指令转换为时空逻辑公式，以更好地表达机器人操作任务中的空间关系。


<details>
  <summary>Details</summary>
Motivation: 现有基于标准时序逻辑的方法主要关注机器人轨迹，忽略了物体层面的空间交互关系，而机器人操作任务的成功高度依赖几何空间约束（如物体位置、邻接关系、姿态约束等）。现有数据集缺乏对多层次空间关系的表达。

Method: 1) 提出数据集生成框架，合成时空逻辑(SpaTiaL)规范并通过确定性、语义保持的反向翻译过程转换为自然语言描述，创建NL2SpaTiaL数据集；2) 提出翻译验证框架，配备基于语言的语义检查器，确保生成的SpaTiaL公式准确编码输入描述的语义。

Result: 实验表明，基于SpaTiaL的表示在多种操作任务中能够提供更可解释、可验证和可组合的指令基础，更好地反映操作任务的组合结构。

Conclusion: 时空逻辑为机器人操作任务提供了更丰富的空间关系表达形式，NL2SpaTiaL数据集和翻译验证框架能够有效对齐自然语言与多层次空间关系和时序目标，提升指令跟随的可解释性和可靠性。

Abstract: Spatio-Temporal Logic (SpaTiaL) offers a principled formalism for expressing geometric spatial requirements-an essential component of robotic manipulation, where object locations, neighborhood relations, pose constraints, and interactions directly determine task success. Yet prior works have largely relied on standard temporal logic (TL), which models only robot trajectories and overlooks object-level interactions. Existing datasets built from randomly generated TL formulas paired with natural-language descriptions therefore cover temporal operators but fail to represent the layered spatial relations that manipulation tasks depend on. To address this gap, we introduce a dataset generation framework that synthesizes SpaTiaL specifications and converts them into natural-language descriptions through a deterministic, semantics-preserving back-translation procedure. This pipeline produces the NL2SpaTiaL dataset, aligning natural language with multi-level spatial relations and temporal objectives to reflect the compositional structure of manipulation tasks. Building on this foundation, we propose a translation-verification framework equipped with a language-based semantic checker that ensures the generated SpaTiaL formulas faithfully encode the semantics specified by the input description. Experiments across a suite of manipulation tasks show that SpaTiaL-based representations yield more interpretable, verifiable, and compositional grounding for instruction following. Project website: https://sites.google.com/view/nl2spatial

</details>
