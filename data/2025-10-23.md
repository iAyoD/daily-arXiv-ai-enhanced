<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Towards Proprioceptive Terrain Mapping with Quadruped Robots for Exploration in Planetary Permanently Shadowed Regions](https://arxiv.org/abs/2510.18986)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人的地形映射框架，通过内部传感在运动过程中估计高程、足部滑移、能量成本和稳定性裕度，并在模拟月球环境中评估了其性能。


<details>
  <summary>Details</summary>
Motivation: 月球极地永久阴影区地形复杂，适合使用腿式机器人进行探索，但现有外感受传感器无法量化地形与机器人的物理交互，需要基于本体感受的地形映射方法。

Method: 开发了一个地形映射框架，从机器人的内部传感数据中增量估计地形交互指标，并整合到多层2.5D网格地图中，在模拟月球环境中使用Aliengo四足机器人进行评估。

Result: 在模拟月球重力和地形条件下，系统显示出稳定的映射性能，能够有效估计地形高程、滑移、能量消耗和稳定性等关键指标。

Conclusion: 提出的基于本体感受的地形映射框架为四足机器人在挑战性环境（如月球永久阴影区）中的自主导航提供了有效解决方案。

Abstract: Permanently Shadowed Regions (PSRs) near the lunar poles are of interest for
future exploration due to their potential to contain water ice and preserve
geological records. Their complex, uneven terrain favors the use of legged
robots, which can traverse challenging surfaces while collecting in-situ data,
and have proven effective in Earth analogs, including dark caves, when equipped
with onboard lighting. While exteroceptive sensors like cameras and lidars can
capture terrain geometry and even semantic information, they cannot quantify
its physical interaction with the robot, a capability provided by
proprioceptive sensing. We propose a terrain mapping framework for quadruped
robots, which estimates elevation, foot slippage, energy cost, and stability
margins from internal sensing during locomotion. These metrics are
incrementally integrated into a multi-layer 2.5D gridmap that reflects terrain
interaction from the robot's perspective. The system is evaluated in a
simulator that mimics a lunar environment, using the 21 kg quadruped robot
Aliengo, showing consistent mapping performance under lunar gravity and terrain
conditions.

</details>


### [2] [Underwater Dense Mapping with the First Compact 3D Sonar](https://arxiv.org/abs/2510.18991)
*Chinmay Burgul,Yewei Huang,Michalis Chatzispyrou,Ioannis Rekleitis,Alberto Quattrini Li,Marios Xanthidis*

Main category: cs.RO

TL;DR: 本文首次研究了紧凑型3D声纳的性能、容量和应用机会，提出了3D声纳与相机的标定方法，开发了新颖的建图和SLAM系统，并在水下洞穴等挑战性环境中进行了测试。


<details>
  <summary>Details</summary>
Motivation: 水下环境中电磁波传播受限，传统2D声纳提供的信息有限且存在空间模糊性，需要探索3D声纳在水下状态估计中的潜力。

Method: 开发了3D声纳与相机的标定程序，研究了不同表面和材料的声学响应特性，构建了新颖的建图和SLAM系统。

Result: 3D声纳能够在水下洞穴等挑战性环境中捕获一致的空间信息，实现数百米范围内的详细重建和定位。

Conclusion: 3D声纳在水下状态估计中具有独特优势，但仍面临声波传播相关的挑战，相关数据集将公开以促进进一步研究。

Abstract: In the past decade, the adoption of compact 3D range sensors, such as LiDARs,
has driven the developments of robust state-estimation pipelines, making them a
standard sensor for aerial, ground, and space autonomy. Unfortunately, poor
propagation of electromagnetic waves underwater, has limited the
visibility-independent sensing options of underwater state-estimation to
acoustic range sensors, which provide 2D information including, at-best,
spatially ambiguous information. This paper, to the best of our knowledge, is
the first study examining the performance, capacity, and opportunities arising
from the recent introduction of the first compact 3D sonar. Towards that
purpose, we introduce calibration procedures for extracting the extrinsics
between the 3D sonar and a camera and we provide a study on acoustic response
in different surfaces and materials. Moreover, we provide novel mapping and
SLAM pipelines tested in deployments in underwater cave systems and other
geometrically and acoustically challenging underwater environments. Our
assessment showcases the unique capacity of 3D sonars to capture consistent
spatial information allowing for detailed reconstructions and localization in
datasets expanding to hundreds of meters. At the same time it highlights
remaining challenges related to acoustic propagation, as found also in other
acoustic sensors. Datasets collected for our evaluations would be released and
shared with the community to enable further research advancements.

</details>


### [3] [SHRUMS: Sensor Hallucination for Real-time Underwater Motion Planning with a Compact 3D Sonar](https://arxiv.org/abs/2510.18996)
*Susheel Vadakkekuruppath,Herman B. Amundsen,Jason M. O'Kane,Marios Xanthidis*

Main category: cs.RO

TL;DR: SHRUMS是首个集成3D声纳的水下自主导航系统，通过传感器幻觉概念在复杂3D环境中实现鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 水下机器人缺乏类似LiDAR的紧凑3D传感器，最近出现的3D声纳为解决水下3D自主导航问题提供了新机会。

Method: 提出传感器幻觉概念，从不存在但参数可定制的虚拟传感器生成测量数据，以适应新型传感器数据流并实现实时局部最优性能。

Result: 系统在能见度极差的复杂3D环境中表现出强鲁棒性，使用真实3D声纳数据在挑战性环境中验证了概念。

Conclusion: SHRUMS是首个集成3D声纳的水下导航系统，通过创新的传感器幻觉方法解决了水下3D导航的挑战，野外部署计划近期进行。

Abstract: Autonomous navigation in 3D is a fundamental problem for autonomy. Despite
major advancements in terrestrial and aerial settings due to improved range
sensors including LiDAR, compact sensors with similar capabilities for
underwater robots have only recently become available, in the form of 3D
sonars. This paper introduces a novel underwater 3D navigation pipeline, called
SHRUMS (Sensor Hallucination for Robust Underwater Motion planning with 3D
Sonar). To the best of the authors' knowledge, SHRUMS is the first underwater
autonomous navigation stack to integrate a 3D sonar. The proposed pipeline
exhibits strong robustness while operating in complex 3D environments in spite
of extremely poor visibility conditions. To accommodate the intricacies of the
novel sensor data stream while achieving real-time locally optimal performance,
SHRUMS introduces the concept of hallucinating sensor measurements from
non-existent sensors with convenient arbitrary parameters, tailored to
application specific requirements. The proposed concepts are validated with
real 3D sonar sensor data, utilizing real inputs in challenging settings and
local maps constructed in real-time. Field deployments validating the proposed
approach in full are planned in the very near future.

</details>


### [4] [$\nabla$-SDF: Learning Euclidean Signed Distance Functions Online with Gradient-Augmented Octree Interpolation and Neural Residual](https://arxiv.org/abs/2510.18999)
*Zhirui Dai,Qihao Qian,Tianxing Fan,Nikolay Atanasov*

Main category: cs.RO

TL;DR: ∇-SDF是一种结合显式梯度增强八叉树插值和隐式神经残差的混合方法，用于从点云数据重建非截断的有符号距离函数，在计算效率和精度之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：基于离散体素的方法影响SDF估计的连续性和可微性，而神经网络方法虽然精度高但效率低、存在灾难性遗忘和内存限制问题，且通常仅限于截断SDF。

Method: 提出混合方法∇-SDF，结合梯度增强八叉树插值提供的显式先验和隐式神经残差，实现非截断欧几里得SDF重建。

Result: 该方法在计算和内存效率上可与体素方法相媲美，在可微性和精度上可与神经网络方法相媲美，在准确性和效率方面优于现有技术。

Conclusion: ∇-SDF为机器人和计算机视觉中的下游任务提供了可扩展的解决方案，在效率和精度之间实现了良好平衡。

Abstract: Estimation of signed distance functions (SDFs) from point cloud data has been
shown to benefit many robot autonomy capabilities, including localization,
mapping, motion planning, and control. Methods that support online and
large-scale SDF reconstruction tend to rely on discrete volumetric data
structures, which affect the continuity and differentiability of the SDF
estimates. Recently, using implicit features, neural network methods have
demonstrated high-fidelity and differentiable SDF reconstruction but they tend
to be less efficient, can experience catastrophic forgetting and memory
limitations in large environments, and are often restricted to truncated SDFs.
This work proposes $\nabla$-SDF, a hybrid method that combines an explicit
prior obtained from gradient-augmented octree interpolation with an implicit
neural residual. Our method achieves non-truncated (Euclidean) SDF
reconstruction with computational and memory efficiency comparable to
volumetric methods and differentiability and accuracy comparable to neural
network methods. Extensive experiments demonstrate that \methodname{}
outperforms the state of the art in terms of accuracy and efficiency, providing
a scalable solution for downstream tasks in robotics and computer vision.

</details>


### [5] [Motion Planning and Control of an Overactuated 4-Wheel Drive with Constrained Independent Steering](https://arxiv.org/abs/2510.19054)
*Shiyu Liu,Ilija Hadzic,Akshay Gupta,Aliasghar Arab*

Main category: cs.RO

TL;DR: 本文提出了一种针对四轮独立转向驱动系统(4WIS)的运动规划与控制方法，该系统存在机械约束限制车轮不能进行360度旋转。通过数学建模转向约束，设计考虑不连续性平面的运动规划器，并开发能够处理不连续性穿越的控制器。


<details>
  <summary>Details</summary>
Motivation: 四轮独立转向驱动系统存在机械约束，导致配置空间受限并包含不连续性，影响机器人运动的平滑性。需要解决这些约束和不连续性对运动规划与控制的影响。

Method: 引入转向约束的数学公式化，推导分割速度空间的不连续性平面，设计考虑转向约束和速度过渡平滑性的运动规划器，以及使用局部反馈生成驱动并处理不连续性穿越的控制器。

Result: 将提出的运动规划器作为ROS导航包的扩展实现，并在仿真和物理机器人上进行了系统评估。

Conclusion: 该方法能够有效处理四轮独立转向驱动系统的机械约束和不连续性，实现平滑高效的运动规划与控制。

Abstract: This paper addresses motion planning and con- trol of an overactuated 4-wheel
drive train with independent steering (4WIS) where mechanical constraints
prevent the wheels from executing full 360-degree rotations (swerve). The
configuration space of such a robot is constrained and contains discontinuities
that affect the smoothness of the robot motion. We introduce a mathematical
formulation of the steering constraints and derive discontinuity planes that
partition the velocity space into regions of smooth and efficient motion. We
further design the motion planner for path tracking and ob- stacle avoidance
that explicitly accounts for swerve constraints and the velocity transition
smoothness. The motion controller uses local feedback to generate actuation
from the desired velocity, while properly handling the discontinuity crossing
by temporarily stopping the motion and repositioning the wheels. We implement
the proposed motion planner as an extension to ROS Navigation package and
evaluate the system in simulation and on a physical robot.

</details>


### [6] [Convex Maneuver Planning for Spacecraft Collision Avoidance](https://arxiv.org/abs/2510.19058)
*Fausto Vega,Jon Arrizabalaga,Ryan Watson,Zachary Manchester*

Main category: cs.RO

TL;DR: 提出了一种用于航天器碰撞规避的低推力机动规划算法，将非凸优化问题转化为凸优化问题求解，确保在最近接近点达到期望的碰撞概率。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星密度增加，传统的手动碰撞规避规划效率低下，需要自主化解决方案。

Method: 将碰撞规避问题建模为非凸二次约束二次规划问题，通过Shor松弛转化为凸半定规划问题求解。

Result: 经验证明松弛是紧致的，能够恢复原问题的全局最优解，在高保真仿真中验证了算法的有效性。

Conclusion: 该算法能够生成最小能量解，在无法满足期望碰撞概率时提供最小风险解，适用于短期交会事件的自主碰撞规避。

Abstract: Conjunction analysis and maneuver planning for spacecraft collision avoidance
remains a manual and time-consuming process, typically involving repeated
forward simulations of hand-designed maneuvers. With the growing density of
satellites in low-Earth orbit (LEO), autonomy is becoming essential for
efficiently evaluating and mitigating collisions. In this work, we present an
algorithm to design low-thrust collision-avoidance maneuvers for short-term
conjunction events. We first formulate the problem as a nonconvex
quadratically-constrained quadratic program (QCQP), which we then relax into a
convex semidefinite program (SDP) using Shor's relaxation. We demonstrate
empirically that the relaxation is tight, which enables the recovery of
globally optimal solutions to the original nonconvex problem. Our formulation
produces a minimum-energy solution while ensuring a desired probability of
collision at the time of closest approach. Finally, if the desired probability
of collision cannot be satisfied, we relax this constraint into a penalty,
yielding a minimum-risk solution. We validate our algorithm with a
high-fidelity simulation of a satellite conjunction in low-Earth orbit with a
simulated conjunction data message (CDM), demonstrating its effectiveness in
reducing collision risk.

</details>


### [7] [A Learning-based Model Reference Adaptive Controller Implemented on a Prosthetic Hand Wrist](https://arxiv.org/abs/2510.19068)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络模型参考自适应控制器的计算高效方法，用于控制肌腱驱动软连续体手腕假肢，提高了运动精度和响应速度。


<details>
  <summary>Details</summary>
Motivation: 当前假肢手腕控制策略缺乏适应性且计算成本高，阻碍了辅助机器人的实时部署，需要开发更高效的自适应控制方法。

Method: 使用Timoshenko梁理论进行手腕动力学建模，提出NN-MRAC控制器，通过在线自适应从偏转误差估计所需肌腱力并最小化与参考模型的偏差。

Result: 仿真结果显示RMSE为6.14×10⁻⁴米，稳定时间3.2秒；实验验证平均RMSE为5.66×10⁻³米，稳态误差8.05×10⁻³米，稳定时间1.58秒。

Conclusion: 该控制器能够显著提高软假肢系统的运动精度和响应性，推进自适应智能控制在可穿戴辅助设备中的集成。

Abstract: The functionality and natural motion of prosthetic hands remain limited by
the challenges in controlling compliant wrist mechanisms. Current control
strategies often lack adaptability and incur high computational costs, which
impedes real-time deployment in assistive robotics. To address this gap, this
study presents a computationally efficient Neural Network (NN)-based Model
Reference Adaptive Controller (MRAC) for a tendon-driven soft continuum wrist
integrated with a prosthetic hand. The dynamic modeling of the wrist is
formulated using Timoshenko beam theory, capturing both shear and bending
deformations. The proposed NN-MRAC estimates the required tendon forces from
deflection errors and minimizes deviation from a reference model through online
adaptation. Simulation results demonstrate improved precision with a root mean
square error (RMSE) of $6.14 \times 10^{-4}$ m and a settling time of $3.2$s.
Experimental validations confirm real-time applicability, with an average RMSE
of $5.66 \times 10^{-3}$ m, steady-state error of $8.05 \times 10^{-3}$ m, and
settling time of $1.58$ s. These results highlight the potential of the
controller to enhance motion accuracy and responsiveness in soft prosthetic
systems, thereby advancing the integration of adaptive intelligent control in
wearable assistive devices.

</details>


### [8] [Sample-Based Hybrid Mode Control: Asymptotically Optimal Switching of Algorithmic and Non-Differentiable Control Modes](https://arxiv.org/abs/2510.19074)
*Yilang Liu,Haoxiang You,Ian Abraham*

Main category: cs.RO

TL;DR: 提出了一种基于采样的混合模式控制解决方案，通过整数优化选择控制模式、切换时机和持续时间，在机器人任务中实现复杂算法合成和反应式切换。


<details>
  <summary>Details</summary>
Motivation: 解决非可微分和算法混合模式下的混合控制问题，需要在长期规划和高频控制之间进行反应式切换。

Method: 将混合控制模式建模为整数优化问题，通过基于采样的变体在整数域中高效搜索最优解，选择控制模式、切换时机和持续时间。

Result: 该方法在多个机器人相关任务中表现出强大的性能保证，能够合成复杂算法和政策来实现复合行为并完成挑战性任务。

Conclusion: 该方法在需要长期规划和高频控制之间反应式切换的实际机器人应用中表现出有效性。

Abstract: This paper investigates a sample-based solution to the hybrid mode control
problem across non-differentiable and algorithmic hybrid modes. Our approach
reasons about a set of hybrid control modes as an integer-based optimization
problem where we select what mode to apply, when to switch to another mode, and
the duration for which we are in a given control mode. A sample-based variation
is derived to efficiently search the integer domain for optimal solutions. We
find our formulation yields strong performance guarantees that can be applied
to a number of robotics-related tasks. In addition, our approach is able to
synthesize complex algorithms and policies to compound behaviors and achieve
challenging tasks. Last, we demonstrate the effectiveness of our approach in
real-world robotic examples that require reactive switching between long-term
planning and high-frequency control.

</details>


### [9] [Kinematic Analysis and Integration of Vision Algorithms for a Mobile Manipulator Employed Inside a Self-Driving Laboratory](https://arxiv.org/abs/2510.19081)
*Shifa Sulaiman,Tobias Busk Jensen,Stefan Hein Bengtson,Simon Bøgh*

Main category: cs.RO

TL;DR: 开发用于自主实验室环境的移动机械臂，具备精确操作和可靠抓取纹理物体的能力，通过视觉算法实现实时物体检测和姿态估计。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自主系统的发展，实验室中机器人的应用范围扩大，需要开发能够协助人类操作员的移动机械臂，以支持自主实验和人类-机器人协作。

Method: 基于Denavit Hartenberg约定进行机械臂运动学建模，求解逆运动学；实现结合特征检测和单应性姿态估计的视觉方法，利用深度信息将物体姿态表示为3D空间中的2D平面投影。

Result: 开发出具备精确自适应操作能力的移动机械臂系统，能够可靠抓取纹理物体，在动态抓取和跟随任务中表现稳健。

Conclusion: 这项工作通过实现自主实验和人类-机器人协作，为下一代化学实验室的可扩展性和可重复性做出了贡献。

Abstract: Recent advances in robotics and autonomous systems have broadened the use of
robots in laboratory settings, including automated synthesis, scalable reaction
workflows, and collaborative tasks in self-driving laboratories (SDLs). This
paper presents a comprehensive development of a mobile manipulator designed to
assist human operators in such autonomous lab environments. Kinematic modeling
of the manipulator is carried out based on the Denavit Hartenberg (DH)
convention and inverse kinematics solution is determined to enable precise and
adaptive manipulation capabilities. A key focus of this research is enhancing
the manipulator ability to reliably grasp textured objects as a critical
component of autonomous handling tasks. Advanced vision-based algorithms are
implemented to perform real-time object detection and pose estimation, guiding
the manipulator in dynamic grasping and following tasks. In this work, we
integrate a vision method that combines feature-based detection with
homography-driven pose estimation, leveraging depth information to represent an
object pose as a $2$D planar projection within $3$D space. This adaptive
capability enables the system to accommodate variations in object orientation
and supports robust autonomous manipulation across diverse environments. By
enabling autonomous experimentation and human-robot collaboration, this work
contributes to the scalability and reproducibility of next-generation chemical
laboratories

</details>


### [10] [Safe Active Navigation and Exploration for Planetary Environments Using Proprioceptive Measurements](https://arxiv.org/abs/2510.19101)
*Matthew Jiang,Shipeng Liu,Feifei Qian*

Main category: cs.RO

TL;DR: SAEGT是一个用于腿式机器人在未知颗粒地形中安全探索的导航框架，使用本体感知来估计地形可穿越性，特别适用于视觉输入无法捕捉地形变形性的场景。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人虽然能通过力交互感知地形，但在高度可变形或不稳定地形中仍面临挑战，需要一种仅依赖本体感知的安全探索方法。

Method: 使用高斯过程回归从腿-地形交互中在线估计安全区域和边界区域，结合反应式控制器进行实时安全探索和导航。

Result: 在仿真中，SAEGT仅使用本体感知估计的可穿越性成功实现了安全探索和向指定目标的导航。

Conclusion: SAEGT框架为腿式机器人在未知颗粒地形中的安全探索提供了有效解决方案，特别是在视觉感知失效的情况下。

Abstract: Legged robots can sense terrain through force interactions during locomotion,
offering more reliable traversability estimates than remote sensing and serving
as scouts for guiding wheeled rovers in challenging environments. However, even
legged scouts face challenges when traversing highly deformable or unstable
terrain. We present Safe Active Exploration for Granular Terrain (SAEGT), a
navigation framework that enables legged robots to safely explore unknown
granular environments using proprioceptive sensing, particularly where visual
input fails to capture terrain deformability. SAEGT estimates the safe region
and frontier region online from leg-terrain interactions using Gaussian Process
regression for traversability assessment, with a reactive controller for
real-time safe exploration and navigation. SAEGT demonstrated its ability to
safely explore and navigate toward a specified goal using only proprioceptively
estimated traversability in simulation.

</details>


### [11] [A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model](https://arxiv.org/abs/2510.19128)
*Mehran Ghafarian Tamizi,Homayoun Honari,Amir Mehdi Soufi Enayati,Aleksey Nozdryn-Plotnicki,Homayoun Najjaran*

Main category: cs.RO

TL;DR: 提出GADGET框架，基于扩散模型生成机器人关节空间轨迹，通过双条件机制结合环境感知和安全约束，实现零样本迁移到新环境和机器人硬件。


<details>
  <summary>Details</summary>
Motivation: 解决高维复杂环境中机器人路径规划的计算效率、安全性和泛化性问题，传统方法计算耗时且需要大量参数调优，现有学习方法泛化能力不足。

Method: 使用扩散模型生成关节空间轨迹，条件包括体素化场景表示及起始目标配置；创新性地结合无分类器引导的场景编码和基于控制屏障函数的安全整形，在去噪过程中集成环境感知和实时碰撞避免。

Result: 在球形障碍、箱体拾取和货架环境中实现高成功率且碰撞强度低，CBF引导进一步提升安全性；相比采样和学习基线表现优异，可跨Franka Panda、Kinova Gen3和UR5机器人迁移，物理执行验证了真实环境中的安全无碰撞轨迹生成。

Conclusion: GADGET框架成功实现了无需重新训练即可泛化到未见环境和机器人硬件的路径规划，通过混合双条件机制有效整合了环境感知和实时安全约束。

Abstract: Path planning for a robotic system in high-dimensional cluttered environments
needs to be efficient, safe, and adaptable for different environments and
hardware. Conventional methods face high computation time and require extensive
parameter tuning, while prior learning-based methods still fail to generalize
effectively. The primary goal of this research is to develop a path planning
framework capable of generalizing to unseen environments and new robotic
manipulators without the need for retraining. We present GADGET (Generalizable
and Adaptive Diffusion-Guided Environment-aware Trajectory generation), a
diffusion-based planning model that generates joint-space trajectories
conditioned on voxelized scene representations as well as start and goal
configurations. A key innovation is GADGET's hybrid dual-conditioning mechanism
that combines classifier-free guidance via learned scene encoding with
classifier-guided Control Barrier Function (CBF) safety shaping, integrating
environment awareness with real-time collision avoidance directly in the
denoising process. This design supports zero-shot transfer to new environments
and robotic embodiments without retraining. Experimental results show that
GADGET achieves high success rates with low collision intensity in
spherical-obstacle, bin-picking, and shelf environments, with CBF guidance
further improving safety. Moreover, comparative evaluations indicate strong
performance relative to both sampling-based and learning-based baselines.
Furthermore, GADGET provides transferability across Franka Panda, Kinova Gen3
(6/7-DoF), and UR5 robots, and physical execution on a Kinova Gen3 demonstrates
its ability to generate safe, collision-free trajectories in real-world
settings.

</details>


### [12] [GRASPLAT: Enabling dexterous grasping through novel view synthesis](https://arxiv.org/abs/2510.19200)
*Matteo Bortolon,Nuno Ferreira Duarte,Plinio Moreno,Fabio Poiesi,José Santos-Victor,Alessio Del Bue*

Main category: cs.RO

TL;DR: GRASPLAT是一个新颖的抓取框架，仅使用RGB图像训练，通过3D高斯泼溅生成高质量的手-物体交互视图，显著提升多指机械手抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖完整3D扫描来预测抓取姿态，但在现实场景中获取高质量3D数据困难，限制了实际应用。

Method: 利用3D高斯泼溅合成手抓取物体的物理合理图像，回归对应的手部关节；引入光度损失来优化抓取预测，最小化渲染图像与真实图像的差异。

Result: 在合成和真实世界抓取数据集上的实验表明，GRASPLAT相比现有基于图像的方法，抓取成功率提升高达36.9%。

Conclusion: GRASPLAT证明了仅使用RGB图像就能有效学习多指抓取策略，为实际机器人抓取应用提供了更实用的解决方案。

Abstract: Achieving dexterous robotic grasping with multi-fingered hands remains a
significant challenge. While existing methods rely on complete 3D scans to
predict grasp poses, these approaches face limitations due to the difficulty of
acquiring high-quality 3D data in real-world scenarios. In this paper, we
introduce GRASPLAT, a novel grasping framework that leverages consistent 3D
information while being trained solely on RGB images. Our key insight is that
by synthesizing physically plausible images of a hand grasping an object, we
can regress the corresponding hand joints for a successful grasp. To achieve
this, we utilize 3D Gaussian Splatting to generate high-fidelity novel views of
real hand-object interactions, enabling end-to-end training with RGB data.
Unlike prior methods, our approach incorporates a photometric loss that refines
grasp predictions by minimizing discrepancies between rendered and real images.
We conduct extensive experiments on both synthetic and real-world grasping
datasets, demonstrating that GRASPLAT improves grasp success rates up to 36.9%
over existing image-based methods. Project page:
https://mbortolon97.github.io/grasplat/

</details>


### [13] [Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models](https://arxiv.org/abs/2510.19268)
*Mingen Li,Houjian Yu,Yixuan Huang,Youngjin Hong,Changhyun Choi*

Main category: cs.RO

TL;DR: 提出了一种完全自主的分层框架，用于解决可变形线性物体（DLOs）的长时程路由任务，结合视觉语言模型进行高层推理和强化学习训练的低层技能执行。


<details>
  <summary>Details</summary>
Motivation: 工业装配线和日常生活中常见的DLOs长时程路由任务具有挑战性，需要适应非线性动力学、分解抽象路由目标并生成多步骤计划，这需要准确的高层推理。

Method: 使用分层框架：利用视觉语言模型进行上下文高层推理合成可行计划，通过强化学习训练的低层技能执行计划，并引入故障恢复机制提高鲁棒性。

Result: 在长时程路由场景中，该方法比次优基线方法性能提升近50%，总体成功率达到92.5%。

Conclusion: 该分层框架能够泛化到涉及物体属性、空间描述和隐式语言命令的多样化场景，有效解决了DLOs长时程路由任务的挑战。

Abstract: Long-horizon routing tasks of deformable linear objects (DLOs), such as
cables and ropes, are common in industrial assembly lines and everyday life.
These tasks are particularly challenging because they require robots to
manipulate DLO with long-horizon planning and reliable skill execution.
Successfully completing such tasks demands adapting to their nonlinear
dynamics, decomposing abstract routing goals, and generating multi-step plans
composed of multiple skills, all of which require accurate high-level reasoning
during execution. In this paper, we propose a fully autonomous hierarchical
framework for solving challenging DLO routing tasks. Given an implicit or
explicit routing goal expressed in language, our framework leverages
vision-language models~(VLMs) for in-context high-level reasoning to synthesize
feasible plans, which are then executed by low-level skills trained via
reinforcement learning. To improve robustness in long horizons, we further
introduce a failure recovery mechanism that reorients the DLO into
insertion-feasible states. Our approach generalizes to diverse scenes involving
object attributes, spatial descriptions, as well as implicit language commands.
It outperforms the next best baseline method by nearly 50% and achieves an
overall success rate of 92.5% across long-horizon routing scenarios.

</details>


### [14] [TARMAC: A Taxonomy for Robot Manipulation in Chemistry](https://arxiv.org/abs/2510.19289)
*Kefeng Huang,Jonathon Pipe,Alice E. Martin,Tianyuan Wang,Barnabas A. Franklin,Andy M. Tyrrell,Ian J. S. Fairlamb,Jihong Zhu*

Main category: cs.RO

TL;DR: 提出了TARMAC分类法，用于系统化定义和分类化学实验室中的机器人操作技能，支持技能复用和可扩展的自动化工作流程。


<details>
  <summary>Details</summary>
Motivation: 现有化学实验室自动化系统仍依赖人工干预，缺乏对机器人操作技能的系统化表示，限制了自主性和技能迁移能力。

Method: 基于标注的教学实验室演示开发TARMAC分类法，按功能角色和物理执行要求对操作进行分类，可实例化为机器人可执行原语。

Result: TARMAC提供了结构化的操作技能表示，支持技能复用和组合成高级宏操作，实现更灵活自主的实验室自动化。

Conclusion: TARMAC为化学实验室机器人操作提供了系统化基础，支持更灵活和自主的自动化解决方案。

Abstract: Chemistry laboratory automation aims to increase throughput, reproducibility,
and safety, yet many existing systems still depend on frequent human
intervention. Advances in robotics have reduced this dependency, but without a
structured representation of the required skills, autonomy remains limited to
bespoke, task-specific solutions with little capacity to transfer beyond their
initial design. Current experiment abstractions typically describe
protocol-level steps without specifying the robotic actions needed to execute
them. This highlights the lack of a systematic account of the manipulation
skills required for robots in chemistry laboratories. To address this gap, we
introduce TARMAC - a Taxonomy for Robot Manipulation in Chemistry - a
domain-specific framework that defines and organizes the core manipulations
needed in laboratory practice. Based on annotated teaching-lab demonstrations
and supported by experimental validation, TARMAC categorizes actions according
to their functional role and physical execution requirements. Beyond serving as
a descriptive vocabulary, TARMAC can be instantiated as robot-executable
primitives and composed into higher-level macros, enabling skill reuse and
supporting scalable integration into long-horizon workflows. These
contributions provide a structured foundation for more flexible and autonomous
laboratory automation. More information is available at
https://tarmac-paper.github.io/

</details>


### [15] [Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model](https://arxiv.org/abs/2510.19356)
*Yu Fang,Xinyu Wang,Xuehe Zhang,Wanli Xue,Mingwei Zhang,Shengyong Chen,Jie Zhao*

Main category: cs.RO

TL;DR: 提出一种用于机器人模仿学习的一步捷径方法，通过多步集成平衡推理速度和性能，解决流匹配方法推理时间高的问题。


<details>
  <summary>Details</summary>
Motivation: 流匹配方法在机器人模仿学习中应用广泛，但面临推理时间高的问题。现有的蒸馏方法和一致性方法性能难以与原始扩散模型和流匹配模型竞争。

Method: 在捷径模型基础上扩展多步一致性损失，将一步损失拆分为多步损失；提出自适应梯度分配方法解决多步损失和原始流匹配损失优化不稳定的问题。

Result: 在两个仿真基准和五个真实环境任务中评估，实验结果验证了算法的有效性。

Conclusion: 该方法在保持推理速度的同时提高了性能，解决了流匹配方法的高推理时间问题。

Abstract: The wide application of flow-matching methods has greatly promoted the
development of robot imitation learning. However, these methods all face the
problem of high inference time. To address this issue, researchers have
proposed distillation methods and consistency methods, but the performance of
these methods still struggles to compete with that of the original diffusion
models and flow-matching models. In this article, we propose a one-step
shortcut method with multi-step integration for robot imitation learning. To
balance the inference speed and performance, we extend the multi-step
consistency loss on the basis of the shortcut model, split the one-step loss
into multi-step losses, and improve the performance of one-step inference.
Secondly, to solve the problem of unstable optimization of the multi-step loss
and the original flow-matching loss, we propose an adaptive gradient allocation
method to enhance the stability of the learning process. Finally, we evaluate
the proposed method in two simulation benchmarks and five real-world
environment tasks. The experimental results verify the effectiveness of the
proposed algorithm.

</details>


### [16] [ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling](https://arxiv.org/abs/2510.19364)
*Golnaz Raja,Ruslan Agishev,Miloš Prágr,Joni Pajarinen,Karel Zimmermann,Arun Kumar Singh,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 提出了一种高效的概率框架，用于机器人运动预测，通过建模空间相关的随机不确定性并利用可微分物理引擎进行概率轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 在非结构化越野环境中，地形异质性和感知不确定性高，现有方法通常忽略3D空间数据的局部相关性，产生不可靠的预测。

Method: 使用结构化卷积算子建模空间相关的随机不确定性作为概率世界模型，并通过可微分物理引擎传播不确定性进行概率轨迹预测。

Result: 在公开数据集上的实验显示，相比随机不确定性估计基线方法，显著改善了不确定性估计和轨迹预测精度。

Conclusion: 该方法能够有效处理越野环境中的空间相关不确定性，为下游可穿越性估计和安全自主导航提供可靠支持。

Abstract: Uncertainty-aware robot motion prediction is crucial for downstream
traversability estimation and safe autonomous navigation in unstructured,
off-road environments, where terrain is heterogeneous and perceptual
uncertainty is high. Most existing methods assume deterministic or spatially
independent terrain uncertainties, ignoring the inherent local correlations of
3D spatial data and often producing unreliable predictions. In this work, we
introduce an efficient probabilistic framework that explicitly models spatially
correlated aleatoric uncertainty over terrain parameters as a probabilistic
world model and propagates this uncertainty through a differentiable physics
engine for probabilistic trajectory forecasting. By leveraging structured
convolutional operators, our approach provides high-resolution multivariate
predictions at manageable computational cost. Experimental evaluation on a
publicly available dataset shows significantly improved uncertainty estimation
and trajectory prediction accuracy over aleatoric uncertainty estimation
baselines.

</details>


### [17] [Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets](https://arxiv.org/abs/2510.19373)
*Basavasagar Patil,Sydney Belt,Jayjun Lee,Nima Fazeli,Bernadette Bucher*

Main category: cs.RO

TL;DR: 提出一种简单的采样策略来解决机器人任务数据集中物理动作不平衡问题，只需几行代码即可集成到现有代码库中，提高模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人任务数据集虽然任务描述不同，但许多涉及相似的物理动作序列，导致数据集在物理动作表示上存在显著不平衡。

Method: 提出一种简单的采样策略，在策略训练中缓解这种不平衡问题，该方法易于集成到现有代码库中。

Result: 在预训练小模型和微调大型基础模型上都取得了显著改进，在低资源任务上相比现有SOTA方法有大幅提升，且不影响高资源任务的性能。

Conclusion: 该方法能够更有效地利用多任务策略的模型容量，并在真实机器人平台上得到验证。

Abstract: Increasingly large datasets of robot actions and sensory observations are
being collected to train ever-larger neural networks. These datasets are
collected based on tasks and while these tasks may be distinct in their
descriptions, many involve very similar physical action sequences (e.g., 'pick
up an apple' versus 'pick up an orange'). As a result, many datasets of robotic
tasks are substantially imbalanced in terms of the physical robotic actions
they represent. In this work, we propose a simple sampling strategy for policy
training that mitigates this imbalance. Our method requires only a few lines of
code to integrate into existing codebases and improves generalization. We
evaluate our method in both pre-training small models and fine-tuning large
foundational models. Our results show substantial improvements on low-resource
tasks compared to prior state-of-the-art methods, without degrading performance
on high-resource tasks. This enables more effective use of model capacity for
multi-task policies. We also further validate our approach in a real-world
setup on a Franka Panda robot arm across a diverse set of tasks.

</details>


### [18] [Risk Assessment of an Autonomous Underwater Snake Robot in Confined Operations](https://arxiv.org/abs/2510.19415)
*Abdelrahman Sayed Sayed*

Main category: cs.RO

TL;DR: 提出一种贝叶斯方法来评估仿鳗鱼水下机器人在两种任务场景中的丢失风险，旨在提高机器人性能和任务成功率


<details>
  <summary>Details</summary>
Motivation: 海洋勘探需求增长需要在受限环境中进行检测和干预，仿鳗鱼机器人的细长形态和可变形能力适合此类环境，但面临不确定环境、极端条件和导航能力受限等挑战

Method: 采用贝叶斯方法评估机器人丢失风险，并进行敏感性分析

Result: 通过敏感性分析识别出对机器人丢失影响最大的因素

Conclusion: 该方法有助于提高仿鳗鱼水下机器人的性能和任务成功率

Abstract: The growing interest in ocean discovery imposes a need for inspection and
intervention in confined and demanding environments. Eely's slender shape, in
addition to its ability to change its body configurations, makes articulated
underwater robots an adequate option for such environments. However, operation
of Eely in such environments imposes demanding requirements on the system, as
it must deal with uncertain and unstructured environments, extreme
environmental conditions, and reduced navigational capabilities. This paper
proposes a Bayesian approach to assess the risks of losing Eely during two
mission scenarios. The goal of this work is to improve Eely's performance and
the likelihood of mission success. Sensitivity analysis results are presented
in order to demonstrate the causes having the highest impact on losing Eely.

</details>


### [19] [GigaBrain-0: A World Model-Powered Vision-Language-Action Model](https://arxiv.org/abs/2510.19430)
*GigaBrain Team,Angen Ye,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Haoyun Li,Jie Li,Jiagang Zhu,Lv Feng,Peng Li,Qiuping Deng,Runqi Ouyang,Wenkang Qin,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yilong Li,Yiran Ding,Yuan Xu,Yun Ye,Yukun Zhou,Zhehao Dong,Zhenan Wang,Zhichao Liu,Zheng Zhu*

Main category: cs.RO

TL;DR: GigaBrain-0是一个利用世界模型生成数据来训练视觉-语言-动作模型的新方法，显著减少对真实机器人数据的依赖，同时提升跨任务泛化能力和策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-语言-动作模型训练需要大量真实机器人数据，收集成本高且效率低，限制了模型的扩展性和泛化能力。

Method: 使用世界模型生成多样化数据（视频生成、真实到真实迁移、人类迁移、视角迁移、仿真到真实迁移），结合RGBD输入建模和具身思维链监督来提升策略鲁棒性。

Result: 在灵巧操作、长时程任务和移动操作任务中取得显著性能提升，在外观、物体位置和相机视角变化下表现出优越的泛化能力。

Conclusion: GigaBrain-0通过世界模型生成数据有效解决了真实数据收集瓶颈，为通用机器人VLA模型训练提供了高效可扩展的解决方案。

Abstract: Training Vision-Language-Action (VLA) models for generalist robots typically
requires large-scale real-world robot data, which is expensive and
time-consuming to collect. The inefficiency of physical data collection
severely limits the scalability, and generalization capacity of current VLA
systems. To address this challenge, we introduce GigaBrain-0, a novel VLA
foundation model empowered by world model-generated data (e.g., video
generation, real2real transfer, human transfer, view transfer, sim2real
transfer data). By leveraging world models to generate diverse data at scale,
GigaBrain-0 significantly reduces reliance on real robot data while improving
cross-task generalization. Our approach further improves policy robustness
through RGBD input modeling and embodied Chain-of-Thought (CoT) supervision,
enabling the model to reason about spatial geometry, object states, and
long-horizon dependencies during task execution. This leads to substantial
gains in real-world performance on dexterous, long-horizon, and mobile
manipulation tasks. Extensive experiments demonstrate that GigaBrain-0 achieves
superior generalization across variations in appearances (e.g., textures,
colors), object placements, and camera viewpoints. Additionally, we present
GigaBrain-0-Small, an optimized lightweight variant designed to run efficiently
on devices such as the NVIDIA Jetson AGX Orin.

</details>


### [20] [Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning](https://arxiv.org/abs/2510.19495)
*Kevin Huang,Rosario Scalise,Cleah Winston,Ayush Agrawal,Yunchu Zhang,Rohan Baijal,Markus Grotz,Byron Boots,Benjamin Burchfiel,Hongkai Dai,Masha Itkina,Paarth Shah,Abhishek Gupta*

Main category: cs.RO

TL;DR: 本文提出通过离线强化学习来有效利用非专家数据增强模仿学习性能，通过简单的算法修改扩展策略分布支持，显著提升任务恢复能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习依赖高质量专家数据，限制了在多样化现实场景中的适应性。非专家数据（如游戏数据、次优演示等）覆盖范围更广且收集成本更低，但传统模仿学习方法无法有效利用这类数据。

Method: 采用离线强化学习作为工具来利用非专家数据，通过简单的算法修改扩展策略分布的支持范围，而不需要额外的强假设。

Result: 在操作任务中，该方法显著扩大了学习策略成功的初始条件范围，能够有效利用所有收集的数据（包括部分或次优演示）来增强任务导向策略性能。

Conclusion: 算法技术对于利用非专家数据进行鲁棒策略学习在机器人领域具有重要意义，该方法展示了通过离线RL增强模仿学习可以显著提升恢复能力和泛化行为。

Abstract: Imitation learning has proven effective for training robots to perform
complex tasks from expert human demonstrations. However, it remains limited by
its reliance on high-quality, task-specific data, restricting adaptability to
the diverse range of real-world object configurations and scenarios. In
contrast, non-expert data -- such as play data, suboptimal demonstrations,
partial task completions, or rollouts from suboptimal policies -- can offer
broader coverage and lower collection costs. However, conventional imitation
learning approaches fail to utilize this data effectively. To address these
challenges, we posit that with right design decisions, offline reinforcement
learning can be used as a tool to harness non-expert data to enhance the
performance of imitation learning policies. We show that while standard offline
RL approaches can be ineffective at actually leveraging non-expert data under
the sparse data coverage settings typically encountered in the real world,
simple algorithmic modifications can allow for the utilization of this data,
without significant additional assumptions. Our approach shows that broadening
the support of the policy distribution can allow imitation algorithms augmented
by offline RL to solve tasks robustly, showing considerably enhanced recovery
and generalization behavior. In manipulation tasks, these innovations
significantly increase the range of initial conditions where learned policies
are successful when non-expert data is incorporated. Moreover, we show that
these methods are able to leverage all collected data, including partial or
suboptimal demonstrations, to bolster task-directed policy performance. This
underscores the importance of algorithmic techniques for using non-expert data
for robust policy learning in robotics.

</details>


### [21] [Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach](https://arxiv.org/abs/2510.19541)
*Francesco Schetter,Shifa Sulaiman,Shoby George,Paolino De Risi,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究在肌腱驱动假手上实现模型预测控制(MPC)策略，用于调节软连续腕部运动，以较低计算成本提升假手的适应性和性能。


<details>
  <summary>Details</summary>
Motivation: 将先进控制策略集成到假手中对于提高其适应性和性能至关重要，MPC在增强假手功能和响应性方面发挥关键作用。

Method: 使用欧拉-伯努利梁进行运动学建模，拉格朗日方法进行动力学建模，实施模型预测控制策略来调节软连续腕部运动。

Result: 通过仿真和实验验证，证明MPC在优化腕部关节和用户控制方面的有效性，显著提高假手的灵巧性，使运动更加自然直观。

Conclusion: 这项研究为智能假肢系统提供了一个有前景的方向，对机器人学和生物医学工程领域做出贡献。

Abstract: The integration of advanced control strategies into prosthetic hands is
essential to improve their adaptability and performance. In this study, we
present an implementation of a Model Predictive Control (MPC) strategy to
regulate the motions of a soft continuum wrist section attached to a
tendon-driven prosthetic hand with less computational effort. MPC plays a
crucial role in enhancing the functionality and responsiveness of prosthetic
hands. By leveraging predictive modeling, this approach enables precise
movement adjustments while accounting for dynamic user interactions. This
advanced control strategy allows for the anticipation of future movements and
adjustments based on the current state of the prosthetic device and the
intentions of the user. Kinematic and dynamic modelings are performed using
Euler-Bernoulli beam and Lagrange methods respectively. Through simulation and
experimental validations, we demonstrate the effectiveness of MPC in optimizing
wrist articulation and user control. Our findings suggest that this technique
significantly improves the prosthetic hand dexterity, making movements more
natural and intuitive. This research contributes to the field of robotics and
biomedical engineering by offering a promising direction for intelligent
prosthetic systems.

</details>


### [22] [LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments](https://arxiv.org/abs/2510.19655)
*Hongyu Ding,Ziming Xu,Yudong Fang,You Wu,Zixuan Chen,Jieqi Shi,Jing Huo,Yifan Zhang,Yang Gao*

Main category: cs.RO

TL;DR: LaViRA是一个零样本视觉语言导航框架，通过语言-视觉-机器人的层次化动作分解，在未见环境中实现基于自然语言指令的导航，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决零样本视觉语言导航中环境特定路径点预测器限制场景泛化能力，以及大模型推理能力在导航中未充分利用的问题。

Method: 采用粗到细的层次化动作分解：语言动作用于高层规划，视觉动作用于感知接地，机器人动用于鲁棒导航，利用不同规模多模态大语言模型的优势。

Result: 在VLN-CE基准测试中显著优于现有最先进方法，在未见环境中展现出优越的泛化能力。

Conclusion: LaViRA框架通过模块化分解有效结合不同规模MLLM的优势，实现了强大的推理、接地和实际控制能力，具有实际部署的透明性和效率。

Abstract: Zero-shot Vision-and-Language Navigation in Continuous Environments (VLN-CE)
requires an agent to navigate unseen environments based on natural language
instructions without any prior training. Current methods face a critical
trade-off: either rely on environment-specific waypoint predictors that limit
scene generalization, or underutilize the reasoning capabilities of large
models during navigation. We introduce LaViRA, a simple yet effective zero-shot
framework that addresses this dilemma by decomposing action into a
coarse-to-fine hierarchy: Language Action for high-level planning, Vision
Action for perceptual grounding, and Robot Action for robust navigation. This
modular decomposition allows us to leverage the distinct strengths of different
scales of Multimodal Large Language Models (MLLMs) at each stage, creating a
system that is powerful in its reasoning, grounding and practical control.
LaViRA significantly outperforms existing state-of-the-art methods on the
VLN-CE benchmark, demonstrating superior generalization capabilities in unseen
environments, while maintaining transparency and efficiency for real-world
deployment.

</details>


### [23] [Fast Marker Detection for UV-Based Visual Relative Localisation in Agile UAV Swarms](https://arxiv.org/abs/2510.19663)
*Vojtěch Vrba,Viktor Walter,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种用于无人机群视觉相对定位的快速机载孤立标记检测方法，包含CPU优化、GPU着色器程序和FPGA流架构三种创新方案，处理速度比现有技术快2-3个数量级。


<details>
  <summary>Details</summary>
Motivation: 为敏捷无人机群的实时定位系统提供快速机载检测解决方案，满足低端无人机和微型飞行器的应用需求。

Method: 开发了三种功能等效的架构：CPU优化程序、GPU着色器程序和FPGA流架构，用于快速检测视觉相对定位中的孤立标记。

Result: CPU和GPU解决方案的处理速度比现有技术快2-3个数量级，FPGA架构在从相机曝光到检测结果的总延迟方面提供了最显著的加速效果。

Conclusion: 该方法已成为敏捷无人机群的关键使能技术，在各种32位和64位嵌入式平台上验证了其效率和可行性。

Abstract: A novel approach for the fast onboard detection of isolated markers for
visual relative localisation of multiple teammates in agile UAV swarms is
introduced in this paper. As the detection forms a key component of real-time
localisation systems, a three-fold innovation is presented, consisting of an
optimised procedure for CPUs, a GPU shader program, and a functionally
equivalent FPGA streaming architecture. For the proposed CPU and GPU solutions,
the mean processing time per pixel of input camera frames was accelerated by
two to three orders of magnitude compared to the state of the art. For the
localisation task, the proposed FPGA architecture offered the most significant
overall acceleration by minimising the total delay from camera exposure to
detection results. Additionally, the proposed solutions were evaluated on
various 32-bit and 64-bit embedded platforms to demonstrate their efficiency,
as well as their feasibility for applications using low-end UAVs and MAVs.
Thus, it has become a crucial enabling technology for agile UAV swarming.

</details>


### [24] [Learning Affordances at Inference-Time for Vision-Language-Action Models](https://arxiv.org/abs/2510.19752)
*Ameesh Shah,William Chen,Adwait Godbole,Federico Mora,Sanjit A. Seshia,Sergey Levine*

Main category: cs.RO

TL;DR: LITEN方法将VLA低级策略与高级VLM连接，通过在上下文中包含过去经验来学习低级VLA的能力，通过推理阶段和执行评估阶段的迭代来改进机器人任务执行。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型(VLAs)缺乏在任务失败时动态调整行为的能力，无法像人类那样从错误中学习并改进策略。

Method: 连接低级VLA策略与高级VLM，在推理阶段生成和执行计划，在评估阶段反思执行结果并提取有用结论用于未来推理上下文。

Result: 实验结果表明LITEN能够有效从过去经验中学习，生成使用高可用性指令来完成长时程任务的计划。

Conclusion: LITEN通过连接高低级模型并利用执行时学习，能够使机器人系统从失败中学习并改进任务执行策略。

Abstract: Solving complex real-world control tasks often takes multiple tries: if we
fail at first, we reflect on what went wrong, and change our strategy
accordingly to avoid making the same mistake. In robotics,
Vision-Language-Action models (VLAs) offer a promising path towards solving
complex control tasks, but lack the ability to contextually and dynamically
readjust behavior when they fail to accomplish a task. In this work, we
introduce Learning from Inference-Time Execution (LITEN), which connects a VLA
low-level policy to a high-level VLM that conditions on past experiences by
including them in-context, allowing it to learn the affordances and
capabilities of the low-level VLA. Our approach iterates between a reasoning
phase that generates and executes plans for the low-level VLA, and an
assessment phase that reflects on the resulting execution and draws useful
conclusions to be included in future reasoning contexts. Unlike similar
approaches to self-refinement in non-robotics domains, LITEN must reflect on
unstructured real-world robot trajectories (e.g., raw videos), which requires
structured guiderails during assessment. Our experimental results demonstrate
LITEN is able to effectively learn from past experience to generate plans that
use high-affordance instructions to accomplish long-horizon tasks.

</details>


### [25] [SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas](https://arxiv.org/abs/2510.19766)
*Hongyu Ding,Xinyue Liang,Yudong Fang,You Wu,Jieqi Shi,Jing Huo,Wenbin Li,Jing Wu,Yu-Kun Lai,Yang Gao*

Main category: cs.RO

TL;DR: SEA是一种基于语义地图预测和强化学习的分层探索策略，通过迭代预测-探索框架和新型奖励机制，显著提升了机器人主动探索的效率和全局地图覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法主要依赖单步路径点预测，缺乏对环境长期理解的能力，导致探索效率不高。本文旨在通过增强智能体对环境的长期理解来促进更高效的探索。

Method: 提出迭代预测-探索框架，基于当前观测显式预测地图缺失区域；利用实际累积地图与预测全局地图的差异指导探索；设计基于强化学习的新型奖励机制来更新长期探索策略。

Result: 实验结果表明，该方法在相同时间限制下显著优于现有最先进的探索策略，实现了更优越的全局地图覆盖范围。

Conclusion: SEA方法通过语义地图预测和强化学习的分层探索策略，能够构建准确的语义地图，在有限步数内实现高效的机器人主动探索。

Abstract: In this paper, we propose SEA, a novel approach for active robot exploration
through semantic map prediction and a reinforcement learning-based hierarchical
exploration policy. Unlike existing learning-based methods that rely on
one-step waypoint prediction, our approach enhances the agent's long-term
environmental understanding to facilitate more efficient exploration. We
propose an iterative prediction-exploration framework that explicitly predicts
the missing areas of the map based on current observations. The difference
between the actual accumulated map and the predicted global map is then used to
guide exploration. Additionally, we design a novel reward mechanism that
leverages reinforcement learning to update the long-term exploration
strategies, enabling us to construct an accurate semantic map within limited
steps. Experimental results demonstrate that our method significantly
outperforms state-of-the-art exploration strategies, achieving superior
coverage ares of the global map within the same time constraints.

</details>
