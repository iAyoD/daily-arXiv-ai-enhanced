<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 74]
- [cs.RO](#cs.RO) [Total: 36]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents](https://arxiv.org/abs/2601.20975)
*Nikita Gupta,Riju Chatterjee,Lukas Haas,Connie Tao,Andrew Wang,Chang Liu,Hidekazu Oiwa,Elena Gribovskaya,Jan Ackermann,John Blitzer,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: DeepSearchQA是一个包含900个提示的基准测试，用于评估智能体在17个不同领域的复杂多步信息搜索任务上的表现，重点关注系统信息整合、去重和停止标准判断能力。


<details>
  <summary>Details</summary>
Motivation: 传统基准测试主要关注单一答案检索或广泛事实性评估，缺乏对智能体在复杂、多步骤信息搜索任务中能力的系统评估。需要一个新的基准来测试智能体执行复杂搜索计划、整合碎片化信息、去重和判断停止标准等关键能力。

Method: 创建了一个包含900个手工制作的挑战性任务的基准测试，涵盖17个不同领域。任务设计为因果链结构，每个步骤的完成依赖于前一步的成功执行。所有任务都基于开放网络，具有客观可验证的答案集。

Result: 对最先进的智能体架构进行全面评估发现显著性能限制：即使最先进的模型也难以平衡高召回率和精确度。观察到不同的失败模式，包括过早停止（检索不足）和过度泛化行为（通过低置信度答案人为提高召回率）。

Conclusion: DeepSearchQA揭示了当前智能体设计中的关键改进空间，并定位为一个重要的诊断工具，可推动未来研究朝着更强大的深度研究能力发展。

Abstract: We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepSearchQA features a dataset of challenging, handcrafted tasks designed to evaluate an agent's ability to execute complex search plans to generate exhaustive answer lists. This shift in design explicitly tests three critical, yet under-evaluated capabilities: 1) systematic collation of fragmented information from disparate sources, 2) de-duplication and entity resolution to ensure precision, and 3) the ability to reason about stopping criteria within an open-ended search space. Each task is structured as a causal chain, where discovering information for one step is dependent on the successful completion of the previous one, stressing long-horizon planning and context retention. All tasks are grounded in the open web with objectively verifiable answer sets. Our comprehensive evaluation of state-of-the-art agent architectures reveals significant performance limitations: even the most advanced models struggle to balance high recall with precision. We observe distinct failure modes ranging from premature stopping (under-retrieval) to hedging behaviors, where agents cast an overly wide net of low-confidence answers to artificially boost recall. These findings highlight critical headroom in current agent designs and position DeepSearchQA as an essential diagnostic tool for driving future research toward more robust, deep-research capabilities.

</details>


### [2] [asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation](https://arxiv.org/abs/2601.20992)
*Oleg Sedukhin,Andrey Kostin*

Main category: cs.CL

TL;DR: 提出语音识别评估的改进方法：支持多参考标注、任意长度插入和更好词对齐的字符串对齐算法；收集俄语长格式语音数据集DiverseSpeech-Ru；开发流式语音识别评估工具和可视化对比工具。


<details>
  <summary>Details</summary>
Motivation: 当前语音识别评估存在不足，特别是在非拉丁语系、词汇形态丰富的语言中，以及处理杂乱或长格式语音时。现有方法难以支持多参考标注和准确的词对齐，导致评估结果可能产生误导。

Method: 1. 提出新的字符串对齐算法，支持多参考标注、任意长度插入和更好的词对齐；2. 收集俄语长格式野外语音数据集DiverseSpeech-Ru并进行多参考标注；3. 对流行俄语测试集进行多参考重新标注；4. 开发流式语音识别评估工具和可视化对比工具；5. 提供多种离线和流式语音识别模型的统一封装。

Result: 研究表明模型经常适应数据集特定的标注方式，导致指标改善的假象。改进的词对齐方法能更准确地评估语音识别性能，特别是在非拉丁语系语言中。工具和数据集为俄语语音识别研究提供了更好的评估基础。

Conclusion: 提出的改进方法显著提升了语音识别评估的准确性和可靠性，特别是在处理复杂语言和长格式语音时。多参考标注和更好的对齐算法有助于避免评估偏差，而新的数据集和工具为研究社区提供了有价值的资源。

Abstract: We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.

</details>


### [3] [UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop](https://arxiv.org/abs/2601.21000)
*Muhammad Ali Shafique,Areej Mehboob,Layba Fiaz,Muhammad Usman Qadeer,Hamza Farooq*

Main category: cs.CL

TL;DR: 提出一种上下文集成翻译框架，通过多翻译系统结合人工验证，将主流推理基准翻译为乌尔都语，创建UrduBench评估LLM在低资源语言中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在低资源语言（如乌尔都语）中的推理能力评估缺乏标准化基准，现有方法受机器翻译敏感性和通用任务导向限制，需要开发专门针对推理的评估框架。

Method: 提出上下文集成翻译框架，结合多种翻译系统和人工验证，保持上下文和结构完整性，将MGSM、MATH-500、CommonSenseQA和OpenBookQA等推理基准翻译为乌尔都语，创建UrduBench数据集。

Result: 评估显示：1）多步和符号推理任务在乌尔都语中挑战显著；2）稳定语言对齐是稳健推理的关键前提；3）不同数据集、任务难度、模型架构、规模设置和语言一致性测试存在性能差异。

Conclusion: 建立了乌尔都语标准化推理评估的可扩展方法，为多语言推理失败提供了实证见解，该框架可推广到其他低资源语言，代码和数据集将公开。

Abstract: Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluation has been limited by the sensitivity of machine translation and an emphasis on general language tasks rather than reasoning benchmarks. In this paper, we propose a contextually ensembled translation framework with human-in-the-loop validation that leverages multiple translation systems to develop Urdu reasoning benchmarks while preserving contextual and structural integrity. Using this framework, we translate widely adopted reasoning and question-answering benchmarks, including MGSM, MATH-500, CommonSenseQA, and OpenBookQA, into Urdu, collectively referred to as UrduBench, and conduct a comprehensive evaluation of both reasoning-oriented and instruction-tuned LLMs across multiple prompting strategies. Our analysis reveals performance differences across (1) four datasets, (2) five task difficulty levels, (3) diverse model architectures, (4) multiple model scaling settings, and (5) language consistency tests. We find that multi-step and symbolic reasoning tasks pose significant challenges in Urdu, and that stable language alignment is a critical prerequisite for robust reasoning. Overall, our work establishes a scalable methodology for standardized reasoning evaluation in Urdu and provides empirical insights into multilingual reasoning failures. This experimental setup is also broadly applicable to other low-resource languages. The code and datasets will be publicly released.

</details>


### [4] [Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations](https://arxiv.org/abs/2601.21084)
*Amit Meghanani,Thomas Hain*

Main category: cs.CL

TL;DR: 研究发现SSL模型微调时MSE损失会过度利用位置嵌入而非内容信息，提出两种位置不变微调策略，其中基于soft-DTW的方法效果最佳


<details>
  <summary>Details</summary>
Motivation: 当前前端语音增强模型与SSL模型结合时，通常使用MSE损失微调，但MSE容易过度利用SSL模型中的位置嵌入信息，而不是学习内容相关信息，这限制了模型在噪声条件下的下游任务性能

Method: 提出两种位置不变微调策略：1) 零填充方法（在SSL预训练中已有研究，但在微调场景下重新考察）；2) 速度扰动结合soft-DTW损失的方法

Result: 实验表明，基于soft-DTW的方法实现了更快的收敛速度和更好的下游任务性能，验证了位置不变微调在SSL语音建模中的重要性

Conclusion: SSL表示微调存在位置嵌入过度利用的普遍问题，通过位置不变微调策略（特别是soft-DTW方法）可以有效解决，提升语音增强模型与SSL模型集成的效果

Abstract: Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.

</details>


### [5] [ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference](https://arxiv.org/abs/2601.21109)
*Ketan Thakkar,Maitreyi Chatterjee,Ramasubramanian Balasubramanian,Achyuthan Jootoo,Rajendra Ugrani*

Main category: cs.CL

TL;DR: ChunkWise LoRA：一种动态自适应方法，根据token复杂度将序列划分为变长块，为每个块分配定制化的低秩配置，显著降低延迟和内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA方法对所有输入token采用静态秩配置，忽略了token复杂度和计算需求的差异，导致效率低下。

Method: 1. 运行时调度器估计token难度并进行自适应分块；2. 使用秩阶梯机制为每个块选择LoRA秩和缩放；3. 引入边界安全组合模块保持输出一致性；4. 集成策略驱动的KV缓存策略。

Result: 在Wikitext-103和SQuAD基准测试中，相比基线LoRA，延迟降低达34%，内存减少38%，同时保持或改善BLEU、EM和困惑度等任务性能指标。

Conclusion: ChunkWise LoRA提供了一种实用的参数高效LLM部署解决方案，完全兼容现有transformer架构和推理框架，在保持性能的同时显著提升效率。

Abstract: Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computational requirements. In this work, we propose ChunkWise LoRA, a dynamic and adaptive approach that partitions sequences into variable-length chunks based on token complexity and assigns each chunk a tailored low-rank configuration. Our system introduces a runtime scheduler that estimates token difficulty, performs adaptive chunking, and selects per-chunk LoRA rank and scaling using a rank-ladder mechanism. To preserve output consistency, we further introduce a boundary-safe composition module and integrate policy-driven KV-cache strategies. Experiments on benchmark datasets such as Wikitext-103 and SQuAD demonstrate that ChunkWise LoRA achieves up to 34\% lower latency and 38% memory reduction compared to baseline LoRA, while maintaining or improving task performance metrics like BLEU, EM, and perplexity. The proposed framework remains fully compatible with existing transformer architectures and inference frameworks, providing a practical solution for real-world deployment of parameter-efficient LLMs.

</details>


### [6] [Multi-task Code LLMs: Data Mix or Model Merge?](https://arxiv.org/abs/2601.21115)
*Mingzhi Zhu,Boris Sobolev,Rahul Krishna,Raju Pavuluri,Stacy Patterson,Michele Merler*

Main category: cs.CL

TL;DR: 比较两种创建小型多任务代码LLM的方法：数据混合 vs 模型合并。实验表明在较大规模（7B参数）时模型合并效果更好，能保留96%的专业模型性能；在较小规模（2B参数）时数据混合更优。


<details>
  <summary>Details</summary>
Motivation: 研究如何在资源受限的部署场景中，通过高效的多任务学习策略平衡性能、约束和成本，创建小型、专业化的代码LLM用于智能体框架。

Method: 比较数据混合和模型合并两种方法，在Qwen Coder和DeepSeek Coder两个模型系列的2B和7B参数规模上进行实验，针对代码生成和代码摘要任务进行微调，并在HumanEval、MBPP和CodeXGlue基准上评估。

Result: 在较大规模（7B）时，模型合并表现最佳，能保留96%的专业模型性能，甚至超越单独微调的模型（Qwen Coder 7B在HumanEval上达到92.7% Pass@1 vs 90.9%）。在较小规模（2B）时，数据混合更优。通过权重分析技术理解不同任务对模型参数的影响。

Conclusion: 精心设计的合并和混合策略能有效结合任务特定能力而不显著降低性能，适合资源受限的部署场景。模型合并在大规模时更有效，而数据混合在小规模时更优。

Abstract: Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two approaches for creating small, multi-task code LLMs: data mixing versus model merging. We conduct extensive experiments across two model families (Qwen Coder and DeepSeek Coder) at two scales (2B and 7B parameters), fine-tuning them for code generation and code summarization tasks. Our evaluation on HumanEval, MBPP, and CodeXGlue benchmarks reveals that model merging achieves the best overall performance at larger scale across model families, retaining 96% of specialized model performance on code generation tasks while maintaining summarization capabilities. Notably, merged models can even surpass individually fine-tuned models, with our best configuration of Qwen Coder 2.5 7B model achieving 92.7% Pass@1 on HumanEval compared to 90.9% for its task-specific fine-tuned equivalent. At a smaller scale we find instead data mixing to be a preferred strategy. We further introduce a weight analysis technique to understand how different tasks affect model parameters and their implications for merging strategies. The results suggest that careful merging and mixing strategies can effectively combine task-specific capabilities without significant performance degradation, making them ideal for resource-constrained deployment scenarios.

</details>


### [7] [Large Language Models Naively Recover Ethnicity from Individual Records](https://arxiv.org/abs/2601.21132)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: LLM能从姓名推断种族/民族，准确率超过传统BISG方法，无需额外训练数据，适用于美国以外地区，并能减少收入偏见。


<details>
  <summary>Details</summary>
Motivation: 传统种族推断方法如BISG存在局限性：仅适用于美国，需要额外训练数据，对富裕社区少数族裔有系统性误分类偏见。需要一种更通用、准确且无偏的姓名种族推断方法。

Method: 使用大型语言模型（包括Gemini 3 Flash、GPT-4o、DeepSeek v3.2、GLM-4.7等）从姓名推断种族/民族。采用分层样本验证，包括美国选民文件、黎巴嫩宗教派别、印度议员选区、印度土地记录等。还测试了扩展推理和元数据（如政党注册）的影响，并微调小型Transformer模型用于大规模部署。

Result: LLM分类准确率高达84.7%，显著超过BISG的68.2%。扩展推理可提升1-3个百分点，加入政党注册元数据可达86.7%。在黎巴嫩宗教派别分类达64.3%，印度保留选区议员分类达99.2%，印度种姓分类达74.0%。LLM减少了BISG中的收入偏见，且微调后的小模型能实现本地零成本部署。

Conclusion: LLM提供了一种准确、通用且无偏的姓名种族推断方法，优于传统BISG，适用于全球多种文化背景，并能通过微调小型模型实现大规模低成本部署。

Abstract: I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appropriate classification categories. Using stratified samples from Florida and North Carolina voter files with self-reported race, LLM-based classification achieves up to 84.7% accuracy, outperforming BISG (68.2%) on balanced samples. I test six models including Gemini 3 Flash, GPT-4o, and open-source alternatives such as DeepSeek v3.2 and GLM-4.7. Enabling extended reasoning can improve accuracy by 1-3 percentage points, though effects vary across contexts; including metadata such as party registration reaches 86.7%. LLM classification also reduces the income bias inherent in BISG, where minorities in wealthier neighborhoods are systematically misclassified as White. I further validate using Lebanese voter registration with religious sect (64.3% accuracy), Indian MPs from reserved constituencies (99.2%), and Indian land records with caste classification (74.0%). Aggregate validation across India, Uganda, Nepal, Armenia, Chile, and Costa Rica using original full-count voter rolls demonstrates that the method recovers known population distributions where naming conventions are distinctive. For large-scale applications, small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment at no cost.

</details>


### [8] [EnsembleLink: Accurate Record Linkage Without Training Data](https://arxiv.org/abs/2601.21138)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: EnsembleLink是一种无需训练标签的高精度记录链接方法，利用预训练语言模型学习语义关系，在多个基准测试中表现优于需要大量标注的方法。


<details>
  <summary>Details</summary>
Motivation: 记录链接在社会科学研究中至关重要，但现有方法要么准确性低，要么需要大量标注数据，且研究者通常将其视为预处理步骤而未量化链接错误带来的不确定性。

Method: 利用预训练语言模型学习语义关系（如地理位置、组织名称等），无需训练标签，在本地开源模型上运行，无需外部API调用。

Result: 在城市名称、人名、组织、多语言政党和文献记录等多个基准测试中，EnsembleLink的表现与需要大量标注的方法相当或更好，典型链接任务可在几分钟内完成。

Conclusion: EnsembleLink提供了一种无需标注数据的高精度记录链接解决方案，解决了现有方法在准确性和数据需求方面的局限性，为社会科学研究提供了更可靠的记录链接工具。

Abstract: Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules without quantifying the uncertainty that linkage errors introduce into downstream analyses. Existing methods either achieve low accuracy or require substantial labeled training data. I present EnsembleLink, a method that achieves high accuracy without any training labels. EnsembleLink leverages pre-trained language models that have learned semantic relationships (e.g., that "South Ozone Park" is a neighborhood in "New York City" or that "Lutte ouvriere" refers to the Trotskyist "Workers' Struggle" party) from large text corpora. On benchmarks spanning city names, person names, organizations, multilingual political parties, and bibliographic records, EnsembleLink matches or exceeds methods requiring extensive labeling. The method runs locally on open-source models, requiring no external API calls, and completes typical linkage tasks in minutes.

</details>


### [9] [Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space](https://arxiv.org/abs/2601.21169)
*Tobias Materzok*

Main category: cs.CL

TL;DR: OS-Search将LLM生成转化为端点搜索：在冻结编码器定义的3D输出空间中选择目标点，通过检索增强策略生成接近该目标的输出，实现并行扫描和黑盒优化。


<details>
  <summary>Details</summary>
Motivation: 传统LLM生成存在路径依赖的token/程序搜索问题，无法进行高效的并行扫描和黑盒优化。需要一种方法将生成过程转化为在结构化输出空间中的搜索问题。

Method: 1. 定义冻结编码器的3D输出空间Z；2. 外层循环选择目标点z*；3. 使用序列级RL训练的检索增强策略生成输出，使其在标准自回归解码下坐标接近z*；4. 支持在Z空间进行并行扫描和贝叶斯优化。

Result: 1. 在故事生成中，扫描Z空间比提示链方法获得3.1倍更高的LLM评分多样性；2. 在代码生成中，对Z空间进行贝叶斯优化能在匹配推理预算下改进控制器未知的目标函数，同时保持代码有效性。

Conclusion: OS-Search成功将LLM生成转化为输出空间搜索问题，实现了高效的并行探索和黑盒优化，在文本和代码生成任务上均表现出优越性能。

Abstract: We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.

</details>


### [10] [From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning](https://arxiv.org/abs/2601.21191)
*Xiulin Yang,Heidi Getz,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 论文通过跨语言语料分析发现功能词具有高频、与句法结构可靠关联、与短语边界对齐三大分布特性，并通过建模实验证明保留这些特性的语言变体更易被神经网络学习，其中频率和结构关联比边界对齐更重要。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索支持从线性输入中学习层次结构的统计条件，特别关注功能词在语言习得中的作用。功能词因其独特的分布特性（高频、与句法结构关联、与短语边界对齐）被认为在语言习得中起关键作用。

Method: 采用跨语言语料分析（涵盖186种语言）验证功能词的三大分布特性，然后通过反事实语言建模和消融实验，比较不同语言变体（保留/去除特定特性）对神经网络学习的影响，并进行探测和消融分析。

Result: 1) 三大特性在所有186种语言中都存在；2) 保留所有特性的语言变体更容易被神经网络学习；3) 频率和结构关联比边界对齐更重要；4) 不同学习条件导致对功能词的依赖方式不同，相似性能可能源于不同的内部机制。

Conclusion: 功能词的统计分布特性（特别是高频和结构关联）支持从线性输入中学习层次结构，但不同学习条件会导致不同的学习机制，表明语言习得过程具有多样性。

Abstract: What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.

</details>


### [11] [Scaling Embeddings Outperforms Scaling Experts in Language Models](https://arxiv.org/abs/2601.21204)
*Hong Liu,Jiaqi Zhang,Chao Wang,Xing Hu,Linkun Lyu,Jiaqi Sun,Xurui Yang,Bo Wang,Fengcun Li,Yulei Qian,Lingtong Si,Yerui Sun,Rumei Li,Peng Pei,Yuchen Xie,Xunliang Cai*

Main category: cs.CL

TL;DR: 论文提出嵌入缩放作为混合专家架构的替代稀疏扩展维度，通过系统优化实现推理加速，并构建了LongCat-Flash-Lite模型在编码和智能体任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 混合专家架构在大型语言模型稀疏扩展中面临收益递减和系统瓶颈问题，需要探索正交的扩展维度来提升效率。

Method: 采用嵌入缩放作为稀疏扩展新维度，系统分析架构因素，结合定制化系统优化和推测解码技术，构建LongCat-Flash-Lite模型（68.5B参数，激活约3B）。

Result: 嵌入缩放在特定场景下比专家缩放具有更优的帕累托前沿；LongCat-Flash-Lite模型超越参数相当的MoE基线，在编码和智能体任务上表现出色。

Conclusion: 嵌入缩放是有效的稀疏扩展新维度，通过系统优化可转化为实际推理加速，为大型语言模型扩展提供了新方向。

Abstract: While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.

</details>


### [12] [Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling](https://arxiv.org/abs/2601.21205)
*Eunjung Yeo,Julie M. Liss,Visar Berisha,David R. Mortensen*

Main category: cs.CL

TL;DR: 提出多语言音素产生评估框架，结合通用音素识别与语言特定音素解释，用于跨语言构音障碍智能评估


<details>
  <summary>Details</summary>
Motivation: 神经系统疾病导致的构音障碍日益普遍，需要跨语言的自动化智能评估方法。现有方法大多限于单一语言或未能捕捉影响智能的语言特定因素。

Method: 提出多语言音素产生评估框架，整合通用音素识别与语言特定音素解释，使用对比音系特征距离进行音素到音位映射和序列对齐

Result: 在英语、西班牙语、意大利语和泰米尔语上的分析显示：PER受益于映射和对齐的组合，PFER仅受益于对齐，PhonCov受益于映射。框架能捕捉与构音障碍语音退化一致的临床有意义模式

Conclusion: 提出的多语言音素产生评估框架能有效捕捉跨语言构音障碍语音的智能退化模式，为临床评估提供可靠工具

Abstract: The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.

</details>


### [13] [Scaling Reasoning Hop Exposes Weaknesses: Demystifying and Improving Hop Generalization in Large Language Models](https://arxiv.org/abs/2601.21214)
*Zhaoyi Li,Jiatong Li,Gangwei Jiang,Linqi Song,Defu Lian,Ying Wei*

Main category: cs.CL

TL;DR: 该论文研究了LLMs在推理步数超出训练分布时的性能下降问题，发现错误集中在少数关键错误类型的token位置，源于注意力头内部竞争机制，并提出了一种轻量级的推理时校正方法。


<details>
  <summary>Details</summary>
Motivation: 当前CoT推理范式在推理步数泛化场景中存在显著性能下降，但导致这种失败的内部机制尚不清楚。研究旨在理解LLMs在超出训练分布推理步数时的失败机制，并提出解决方案。

Method: 通过系统研究多个领域的任务，识别错误集中在特定token位置；发现错误源于注意力头内部竞争机制（错误处理头ep heads）；提出推理时校正方法，动态识别并停用ep heads。

Result: 研究发现错误集中在少数关键错误类型的token位置而非均匀分布；ep heads通过放大错误推理轨迹、抑制正确轨迹导致错误；移除单个ep heads常能恢复正确预测；提出的校正方法在不同任务和LLMs上均能提升推理步数泛化性能。

Conclusion: 该研究揭示了LLMs推理步数泛化失败的内部机制，并提出了一种有效的轻量级干预方法，为理解和改进LLMs的推理能力提供了新视角。

Abstract: Chain-of-thought (CoT) reasoning has become the standard paradigm for enabling Large Language Models (LLMs) to solve complex problems. However, recent studies reveal a sharp performance drop in reasoning hop generalization scenarios, where the required number of reasoning steps exceeds training distributions while the underlying algorithm remains unchanged. The internal mechanisms driving this failure remain poorly understood. In this work, we conduct a systematic study on tasks from multiple domains, and find that errors concentrate at token positions of a few critical error types, rather than being uniformly distributed. Closer inspection reveals that these token-level erroneous predictions stem from internal competition mechanisms: certain attention heads, termed erroneous processing heads (ep heads), tip the balance by amplifying incorrect reasoning trajectories while suppressing correct ones. Notably, removing individual ep heads during inference can often restore the correct predictions. Motivated by these insights, we propose test-time correction of reasoning, a lightweight intervention method that dynamically identifies and deactivates ep heads in the reasoning process. Extensive experiments across different tasks and LLMs show that it consistently improves reasoning hop generalization, highlighting both its effectiveness and potential.

</details>


### [14] [Parametric Knowledge is Not All You Need: Toward Honest Large Language Models via Retrieval of Pretraining Data](https://arxiv.org/abs/2601.21218)
*Christopher Adrian Kusuma,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 该论文提出了一个更鲁棒的LLM诚实性评估基准，利用公开可用的预训练数据（Pythia模型），并提出了一种利用预训练数据构建更诚实LLM的新方法。


<details>
  <summary>Details</summary>
Motivation: LLM经常不知道自己的知识边界，会在缺乏足够知识的主题上生成事实错误的回答（幻觉）。现有方法评估不够鲁棒，没有考虑LLM在预训练中摄入的知识。

Method: 1) 利用Pythia（真正开源的LLM，预训练数据公开可用）构建更鲁棒的诚实性评估基准数据集；2) 提出一种利用预训练数据构建更诚实LLM的新方法。

Result: 提出了一个更鲁棒的评估基准，能够考虑LLM在预训练中实际摄入的知识，从而更准确地评估LLM的诚实性。

Conclusion: 通过利用公开的预训练数据，可以构建更鲁棒的LLM诚实性评估基准，并提出有效方法来提高LLM在知识边界问题上的诚实性。

Abstract: Large language models (LLMs) are highly capable of answering questions, but they are often unaware of their own knowledge boundary, i.e., knowing what they know and what they don't know. As a result, they can generate factually incorrect responses on topics they do not have enough knowledge of, commonly known as hallucination. Rather than hallucinating, a language model should be more honest and respond with "I don't know" when it does not have enough knowledge about a topic. Many methods have been proposed to improve LLM honesty, but their evaluations lack robustness, as they do not take into account the knowledge that the LLM has ingested during its pretraining. In this paper, we propose a more robust evaluation benchmark dataset for LLM honesty by utilizing Pythia, a truly open LLM with publicly available pretraining data. In addition, we also propose a novel method for harnessing the pretraining data to build a more honest LLM.

</details>


### [15] [MGSM-Pro: A Simple Strategy for Robust Multilingual Mathematical Reasoning Evaluation](https://arxiv.org/abs/2601.21225)
*Tianyi Xu,Kosei Uemura,Alfred Malengo Kondoro,Tadesse Destaw Belay,Catherine Nana Nyaah Essuman,Ifeoma Okoh,Ganiyat Afolabi,Ayodele Awokoya,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: MGSM-Pro扩展了MGSM数据集，采用GSM-Symbolic方法为每个问题提供5种不同实例化（改变名称、数字和无关上下文），在多语言评估中发现低资源语言在数字变化时性能大幅下降，建议每个问题至少用5种数字变化实例化进行更稳健的数学推理评估。


<details>
  <summary>Details</summary>
Motivation: 当前多语言数学推理评估基准在难度和时效性上落后于英语，且GSM-Symbolic研究表明同一问题的不同实例化会导致模型性能高方差，但该研究仅限于英语。需要扩展多语言评估以了解模型在不同语言和问题实例化下的稳健性。

Method: 扩展MGSM数据集为MGSM-Pro，采用GSM-Symbolic方法为每个MGSM问题创建5种不同实例化，通过改变名称、数字和无关上下文。在9种语言上评估各种模型，分析不同实例化（特别是数字变化）对模型性能的影响。

Result: 许多低资源语言在数字实例化不同于原始测试集时性能大幅下降。专有模型中，Gemini 2.5 Flash和GPT-4.1对数字实例化较不稳健，而Claude 4.0 Sonnet更稳健。开源模型中，GPT-OSS 120B和DeepSeek V3表现出更强的稳健性。

Conclusion: 为获得更稳健和真实的数学推理评估，建议每个问题至少使用5种数字变化的实例化进行测试，特别是在多语言评估中需要考虑不同实例化对模型性能的影响。

Abstract: Large language models have made substantial progress in mathematical reasoning. However, benchmark development for multilingual evaluation has lagged behind English in both difficulty and recency. Recently, GSM-Symbolic showed a strong evidence of high variance when models are evaluated on different instantiations of the same question; however, the evaluation was conducted only in English. In this paper, we introduce MGSM-Pro, an extension of MGSM dataset with GSM-Symbolic approach. Our dataset provides five instantiations per MGSM question by varying names, digits and irrelevant context. Evaluations across nine languages reveal that many low-resource languages suffer large performance drops when tested on digit instantiations different from those in the original test set. We further find that some proprietary models, notably Gemini 2.5 Flash and GPT-4.1, are less robust to digit instantiation, whereas Claude 4.0 Sonnet is more robust. Among open models, GPT-OSS 120B and DeepSeek V3 show stronger robustness. Based on these findings, we recommend evaluating each problem using at least five digit-varying instantiations to obtain a more robust and realistic assessment of math reasoning.

</details>


### [16] [SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models](https://arxiv.org/abs/2601.21235)
*Alok Abhishek,Tushar Bandopadhyay,Lisa Erickson*

Main category: cs.CL

TL;DR: SHARP框架用于多维度、分布感知的社会危害评估，通过风险敏感统计和CVaR95指标揭示LLMs的尾部风险差异，超越传统标量平均评估。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估基准将复杂社会风险简化为均值中心的标量分数，掩盖了分布结构、跨维度交互和最坏情况行为，而LLMs在高风险领域部署需要更全面的风险评估。

Method: 提出SHARP框架，将危害建模为多元随机变量，整合偏见、公平、伦理和认知可靠性的显式分解，采用联合失败聚合重新参数化为加性累积对数风险，并使用风险敏感分布统计（以CVaR95为主要指标）。

Result: 在11个前沿LLMs上应用SHARP评估901个社会敏感提示，发现相似平均风险的模型在尾部暴露和波动性上存在两倍以上差异；不同危害维度的尾部严重性不同，偏见维度最强，伦理对齐最低，揭示了传统标量基准无法捕捉的异质性失败结构。

Conclusion: LLMs的负责任评估和治理需要超越标量平均值，转向多维度、尾部敏感的风险分析，SHARP框架为此提供了系统方法。

Abstract: Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.

</details>


### [17] [MoCo: A One-Stop Shop for Model Collaboration Research](https://arxiv.org/abs/2601.21257)
*Shangbin Feng,Yuyang Bai,Ziyuan Yang,Yike Wang,Zhaoxuan Tan,Jiajie Yan,Zhenyu Lei,Wenxuan Ding,Weijia Shi,Haojin Wang,Zhenting Qi,Yuru Jiang,Heng Wang,Chengsong Huang,Yu Fei,Jihan Yao,Yilun Du,Luke Zettlemoyer,Yejin Choi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: MoCo是一个用于模型协作的Python库，集成了26种协作方法、25个评估数据集，实验表明协作策略在61%的情况下优于单模型，最佳方法提升达25.8%。


<details>
  <summary>Details</summary>
Motivation: 现有模型协作研究分散、缺乏统一比较，需要整合现有研究并建立模型协作作为一个独立的研究方向，促进开放、模块化、去中心化的AI协作发展。

Method: 开发MoCo Python库，集成26种模型协作方法（涵盖路由、文本、logit、模型参数等不同层级的跨模型信息交换），整合25个评估数据集（推理、QA、代码、安全等领域），支持用户自定义数据。

Result: 大多数协作策略在61.0%的（模型，数据）设置中平均优于无协作模型，最有效的方法提升达25.8%。分析了协作策略的扩展性、训练/推理效率，并展示了协作系统能解决单模型难以处理的问题。

Conclusion: MoCo作为模型协作的工具包，有助于推动开放、模块化、去中心化和协作的AI未来发展，为模型协作研究提供了统一平台和基准。

Abstract: Advancing beyond single monolithic language models (LMs), recent research increasingly recognizes the importance of model collaboration, where multiple LMs collaborate, compose, and complement each other. Existing research on this topic has mostly been disparate and disconnected, from different research communities, and lacks rigorous comparison. To consolidate existing research and establish model collaboration as a school of thought, we present MoCo: a one-stop Python library of executing, benchmarking, and comparing model collaboration algorithms at scale. MoCo features 26 model collaboration methods, spanning diverse levels of cross-model information exchange such as routing, text, logit, and model parameters. MoCo integrates 25 evaluation datasets spanning reasoning, QA, code, safety, and more, while users could flexibly bring their own data. Extensive experiments with MoCo demonstrate that most collaboration strategies outperform models without collaboration in 61.0% of (model, data) settings on average, with the most effective methods outperforming by up to 25.8%. We further analyze the scaling of model collaboration strategies, the training/inference efficiency of diverse methods, highlight that the collaborative system solves problems where single LMs struggle, and discuss future work in model collaboration, all made possible by MoCo. We envision MoCo as a valuable toolkit to facilitate and turbocharge the quest for an open, modular, decentralized, and collaborative AI future.

</details>


### [18] [CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding](https://arxiv.org/abs/2601.21262)
*Jiahao Huo,Yu Huang,Yibo Yan,Ye Pan,Yi Cao,Mingdong Ou,Philip S. Yu,Xuming Hu*

Main category: cs.CL

TL;DR: CausalEmbed提出自回归生成方法构建多向量嵌入，通过迭代边界损失训练，用仅几十个视觉token实现高效视觉文档检索，token数量减少30-155倍，性能保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉文档检索中表现出色，但使用数千个视觉token表示一页文档导致存储开销巨大，限制了实际应用。

Method: 提出自回归生成方法CausalEmbed，在对比训练中引入迭代边界损失，学习紧凑且结构良好的表示，仅需几十个视觉token。

Result: 在多种骨干网络和基准测试中，token数量减少30-155倍，同时保持高度竞争力的性能，实现了训练效率和测试时扩展性的优势。

Conclusion: CausalEmbed为多向量视觉文档检索表示提供了灵活的测试时扩展策略，揭示了多模态文档检索中的生成范式潜力。

Abstract: Although Multimodal Large Language Models (MLLMs) have shown remarkable potential in Visual Document Retrieval (VDR) through generating high-quality multi-vector embeddings, the substantial storage overhead caused by representing a page with thousands of visual tokens limits their practicality in real-world applications. To address this challenge, we propose an auto-regressive generation approach, CausalEmbed, for constructing multi-vector embeddings. By incorporating iterative margin loss during contrastive training, CausalEmbed encourages the embedding models to learn compact and well-structured representations. Our method enables efficient VDR tasks using only dozens of visual tokens, achieving a 30-155x reduction in token count while maintaining highly competitive performance across various backbones and benchmarks. Theoretical analysis and empirical results demonstrate the unique advantages of auto-regressive embedding generation in terms of training efficiency and scalability at test time. As a result, CausalEmbed introduces a flexible test-time scaling strategy for multi-vector VDR representations and sheds light on the generative paradigm within multimodal document retrieval.

</details>


### [19] [Qwen3-ASR Technical Report](https://arxiv.org/abs/2601.21337)
*Xian Shi,Xiong Wang,Zhifang Guo,Yongqi Wang,Pei Zhang,Xinyu Zhang,Zishan Guo,Hongkun Hao,Yu Xi,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: Qwen3-ASR系列包含两个多语言语音识别模型和一个非自回归强制对齐模型，其中1.7B版本在开源ASR模型中达到SOTA性能，0.6B版本在精度和效率间取得最佳平衡，所有模型均以Apache 2.0协议开源。


<details>
  <summary>Details</summary>
Motivation: 当前ASR模型在开源基准测试中差异不大，但在实际场景中质量差异显著。需要开发既能支持多语言识别，又能提供准确时间戳对齐的实用ASR系统，同时兼顾性能和效率。

Method: 基于Qwen3-Omni基础模型的音频理解能力，利用大规模语音训练数据构建ASR模型。开发了1.7B和0.6B两个版本的ASR模型支持52种语言/方言，以及基于LLM的非自回归强制对齐模型支持11种语言的时间戳预测。

Result: 1.7B版本在开源ASR模型中达到SOTA性能，与最强商业API竞争；0.6B版本平均TTFT低至92ms，并发128时1秒可转录2000秒语音；强制对齐模型在时间戳准确性和效率方面优于现有最强模型。

Conclusion: Qwen3-ASR系列提供了高性能、高效率的多语言语音识别解决方案，填补了开源ASR模型在实际应用场景中的质量差距，并通过Apache 2.0协议开源加速社区研究。

Abstract: In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.

</details>


### [20] [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/abs/2601.21343)
*Ellen Xiaoqing Tan,Shehzaad Dhuliawala,Jing Xu,Ping Yu,Sainbayar Sukhbaatar,Jason Weston,Olga Golovneva*

Main category: cs.CL

TL;DR: 提出一种新的预训练方法，使用强化学习在预训练阶段提升语言模型的事实性、安全性和生成质量，避免后期难以纠正的问题


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要通过昂贵的微调和对齐来解决安全性、事实性和质量问题，但这种方法无法纠正预训练阶段学习到的错误模式。需要在预训练阶段就解决这些问题，因为预训练塑造了模型的核心行为，防止不安全或幻觉输出被深度嵌入

Method: 提出新的预训练方法：流式处理文档，使用强化学习改进每一步生成的下K个token。使用一个经过后训练的强模型来评估候选生成（包括模型rollout、原始后缀和重写后缀）的质量、安全性和事实性。训练早期依赖原始和重写后缀，随着模型改进，强化学习奖励高质量的rollout

Result: 相比标准预训练，该方法在事实性方面获得36.2%的相对改进，在安全性方面获得18.5%的相对改进，在整体生成质量方面获得高达86.3%的胜率改进

Conclusion: 该方法能够从基础开始构建更高质量、更安全、更事实的模型，通过在预训练阶段使用强化学习来提升语言模型的核心质量指标

Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.

</details>


### [21] [The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation](https://arxiv.org/abs/2601.21360)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Vinay Chamola,Dhruv Kumar*

Main category: cs.CL

TL;DR: LLMs在代码评分中存在严重漏洞：过度追求指令遵循导致忽略代码逻辑，即使功能错误的代码也能获得高分


<details>
  <summary>Details</summary>
Motivation: 当前教育评估中广泛使用LLMs进行自动评分，但存在一个未经验证的假设：指令遵循能力能直接转化为客观评判能力。作者发现这个假设存在根本性缺陷。

Method: 提出了SPACI框架和AST-ASIP协议，通过在抽象语法树的无关节点中嵌入对抗性指令，利用语法-语义间隙来测试模型。评估了9个SOTA模型在25,000个Python、C、C++和Java提交上的表现。

Result: 发现高容量开源模型（如DeepSeek-V3）的灾难性失败率超过95%，模型系统性地优先考虑隐藏的格式约束而非代码正确性。通过三部分框架量化了这种失败。

Conclusion: 当前的对齐范式在自动评分中创造了"特洛伊"漏洞，需要从标准RLHF转向领域特定的裁决鲁棒性，让模型优先考虑证据而非指令遵循。

Abstract: The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread "False Certification" of functionally broken code. Our findings suggest that current alignment paradigms create a "Trojan" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.

</details>


### [22] [User-Centric Evidence Ranking for Attribution and Fact Verification](https://arxiv.org/abs/2601.21387)
*Guy Alt,Eran Hirsch,Serwar Basch,Ido Dagan,Oren Glickman*

Main category: cs.CL

TL;DR: 论文提出证据排序新任务，旨在通过优先呈现充分信息来减少用户阅读负担，同时保持所有证据可访问，并引入新的评估框架和基准数据集。


<details>
  <summary>Details</summary>
Motivation: 当前自动系统和大型语言模型在事实核查中检索证据时，往往提供信息不足或过度冗余，导致验证效率低下且容易出错，需要更有效的信息呈现方式。

Method: 提出证据排序任务，比较一次性排序和增量排序两种方法，引入基于信息检索指标的新评估框架，并整合现有事实核查数据集构建统一基准。

Result: 实验表明增量排序策略能更好捕捉互补证据，基于LLM的方法优于浅层基线，但仍面临平衡充分性和冗余性的挑战；用户研究显示证据排序能减少阅读负担并提高验证准确性。

Conclusion: 证据排序任务为实现更可解释、高效且用户对齐的信息验证系统提供了基础性进展，未来需要进一步优化平衡充分性和冗余性的方法。

Abstract: Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.

</details>


### [23] [Conversation for Non-verifiable Learning: Self-Evolving LLMs through Meta-Evaluation](https://arxiv.org/abs/2601.21464)
*Yuan Sui,Bryan Hooi*

Main category: cs.CL

TL;DR: CoNL框架通过多智能体自博弈统一生成、评估和元评估，利用"好的批评能帮助他人改进解决方案"的洞察，在没有外部评估者或真实标签的情况下联合优化生成和评判能力。


<details>
  <summary>Details</summary>
Motivation: 训练大型语言模型进行不可验证任务（如创意写作、对话、伦理推理）面临缺乏真实标签的挑战。LLM-as-Judge方法虽然提供可扩展的替代方案，但受到评估者自身质量的限制：如果评判者无法识别好的解决方案，就无法提供有用的训练信号，且评估偏见（如偏好冗长而非质量）无法解决。这促使需要元评估能力来评估和改进评估者本身。

Method: CoNL框架通过多智能体自博弈统一生成、评估和元评估。多个共享相同策略的智能体参与结构化对话，提出、批评和修订解决方案。关键洞察：批评质量可以通过它是否帮助他人改进解决方案来衡量。能够促成解决方案改进的批评获得诊断奖励，为元评估创建明确的监督，并通过自博弈实现生成和评判能力的联合优化，无需外部评估者或真实标签。

Result: 在五个基准测试上的实验表明，CoNL相比自我奖励基线实现了持续改进，同时保持稳定的训练。

Conclusion: CoNL框架通过多智能体自博弈解决了LLM训练中评估者质量限制的问题，利用"批评帮助改进"的元评估机制，在没有外部监督的情况下联合优化生成和评判能力，为不可验证任务的训练提供了有效解决方案。

Abstract: Training large language models (LLMs) for non-verifiable tasks, such as creative writing, dialogue, and ethical reasoning, remains challenging due to the absence of ground-truth labels. While LLM-as-Judge approaches offer a scalable alternative to human feedback, they face a fundamental limitation: performance is constrained by the evaluator's own quality. If the judge cannot recognize good solutions, it cannot provide useful training signals, and evaluation biases (e.g., favoring verbosity over quality) remain unaddressed. This motivates meta-evaluation: the ability to evaluate and improve the evaluator itself. We introduce CoNL, a framework that unifies generation, evaluation, and meta-evaluation through multi-agent self-play. Our key insight: critique quality can be measured by whether it helps others improve their solutions. In CoNL, multiple agents sharing the same policy engage in structured conversations to propose, critique, and revise solutions. Critiques that enable solution improvements earn a diagnostic reward, creating explicit supervision for meta-evaluation and enabling joint optimization of generation and judging capabilities through self-play, without external judges or ground truth. Experiments on five benchmarks show that CoNL achieves consistent improvements over self-rewarding baselines while maintaining stable training.

</details>


### [24] [SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.21476)
*Lei Yang,Wei Bi,Chenxi Sun,Renren Jin,Deyi Xiong*

Main category: cs.CL

TL;DR: SOUP是一个将离线和在线策略学习统一在单个样本级别的RL框架，通过限制离线策略只影响生成序列的前缀部分，有效解决了策略不匹配和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 当前用于语言模型后训练的在线RL方法（如GRPO）存在探索有限和早期饱和的问题，而现有混合离线数据的方法由于混合整个轨迹导致严重的策略不匹配和不稳定性。

Method: 提出SOUP框架，在单个样本的token级别统一离线和在线策略学习：序列前缀从历史策略中离线采样，而延续部分则在线生成，通过token级重要性比率有效利用离线信息。

Result: 大量实验表明，SOUP在性能上持续优于标准的在线训练和现有的离线扩展方法，能够同时改善探索能力和最终性能。

Conclusion: 细粒度的单样本混合策略训练可以有效提升LLM RL的探索性和最终性能，SOUP框架为解决策略不匹配问题提供了有效的解决方案。

Abstract: On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\textbf{S}$ingle-sample Mix-p$\textbf{O}$licy $\textbf{U}$nified $\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.

</details>


### [25] [DimStance: Multilingual Datasets for Dimensional Stance Analysis](https://arxiv.org/abs/2601.21483)
*Jonas Becker,Liang-Chih Yu,Shamsuddeen Hassan Muhammad,Jan Philip Wahle,Terry Ruas,Idris Abdulmumin,Lung-Hao Lee,Wen-Ni Liu,Tzu-Mi Lin,Zhe-Yu Xu,Ying-Lung Lin,Jin Wang,Maryam Ibrahim Mukhtar,Bela Gipp,Saif M. Mohammed*

Main category: cs.CL

TL;DR: 该论文提出了DimStance，首个包含情感维度（效价-唤醒度）标注的立场检测资源，涵盖5种语言和2个领域，用于细粒度立场分析。


<details>
  <summary>Details</summary>
Motivation: 传统立场检测仅使用分类标签（支持/中立/反对），无法捕捉立场表达背后的细微情感状态。作者希望利用情感科学中的维度框架（效价和唤醒度）来实现更细粒度的立场分析。

Method: 1. 创建DimStance资源：包含11,746个目标方面、7,365篇文本，涵盖5种语言（英语、德语、中文、尼日利亚皮钦语、斯瓦希里语）和2个领域（政治和环境保护），并标注效价-唤醒度维度。
2. 制定维度立场回归任务：预测立场在效价和唤醒度上的连续值。
3. 评估方法：在回归和提示设置下，对预训练模型和大语言模型进行基准测试。

Result: 1. 微调后的LLM回归器表现出有竞争力的性能。
2. 低资源语言（如尼日利亚皮钦语、斯瓦希里语）仍面临持续挑战。
3. 基于token的生成方法存在局限性。

Conclusion: DimStance为多语言、情感感知的立场分析和基准测试奠定了基础，推动了超越分类标签的细粒度立场分析研究。

Abstract: Stance detection is an established task that classifies an author's attitude toward a specific target into categories such as Favor, Neutral, and Against. Beyond categorical stance labels, we leverage a long-established affective science framework to model stance along real-valued dimensions of valence (negative-positive) and arousal (calm-active). This dimensional approach captures nuanced affective states underlying stance expressions, enabling fine-grained stance analysis. To this end, we introduce DimStance, the first dimensional stance resource with valence-arousal (VA) annotations. This resource comprises 11,746 target aspects in 7,365 texts across five languages (English, German, Chinese, Nigerian Pidgin, and Swahili) and two domains (politics and environmental protection). To facilitate the evaluation of stance VA prediction, we formulate the dimensional stance regression task, analyze cross-lingual VA patterns, and benchmark pretrained and large language models under regression and prompting settings. Results show competitive performance of fine-tuned LLM regressors, persistent challenges in low-resource languages, and limitations of token-based generation. DimStance provides a foundation for multilingual, emotion-aware, stance analysis and benchmarking.

</details>


### [26] [MURAD: A Large-Scale Multi-Domain Unified Reverse Arabic Dictionary Dataset](https://arxiv.org/abs/2601.21512)
*Serry Sibaee,Yasser Alhabashi,Nadia Sibai,Yara Farouk,Adel Ammar,Sawsan AlHalawani,Wadii Boulila*

Main category: cs.CL

TL;DR: 构建了包含96,243个词条定义对的阿拉伯语多领域统一反向词典数据集MURAD，支持计算语言学和词典学研究


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语词汇丰富，涵盖科学、宗教、文学等多个领域，但大规模连接阿拉伯语词汇与精确定义的数据集仍然有限，需要构建全面的阿拉伯语词典资源

Method: 采用混合处理流程，整合直接文本解析、光学字符识别和自动重建技术，从可信的参考著作和教育资源中提取数据，确保准确性和清晰度

Result: 创建了MURAD数据集，包含96,243个词条定义对，每个记录包含目标词、标准化阿拉伯语定义和来源领域元数据，涵盖语言学、伊斯兰研究、数学、物理、心理学和工程学等多个领域

Conclusion: 通过发布这一资源，旨在推进阿拉伯语自然语言处理研究，促进阿拉伯语词汇语义学的可重复研究，支持反向词典建模、语义检索和教育工具等应用

Abstract: Arabic is a linguistically and culturally rich language with a vast vocabulary that spans scientific, religious, and literary domains. Yet, large-scale lexical datasets linking Arabic words to precise definitions remain limited. We present MURAD (Multi-domain Unified Reverse Arabic Dictionary), an open lexical dataset with 96,243 word-definition pairs. The data come from trusted reference works and educational sources. Extraction used a hybrid pipeline integrating direct text parsing, optical character recognition, and automated reconstruction. This ensures accuracy and clarity. Each record aligns a target word with its standardized Arabic definition and metadata that identifies the source domain. The dataset covers terms from linguistics, Islamic studies, mathematics, physics, psychology, and engineering. It supports computational linguistics and lexicographic research. Applications include reverse dictionary modeling, semantic retrieval, and educational tools. By releasing this resource, we aim to advance Arabic natural language processing and promote reproducible research on Arabic lexical semantics.

</details>


### [27] [LMK > CLS: Landmark Pooling for Dense Embeddings](https://arxiv.org/abs/2601.21525)
*Meet Doshi,Aashka Trivedi,Vishwajeet Kumar,Parul Awasthy,Yulong Li,Jaydeep Sen,Radu Florian,Sachindra Joshi*

Main category: cs.CL

TL;DR: 提出Landmark (LMK) pooling方法，通过将序列分块并在块间插入landmark tokens，然后对landmark token embeddings进行mean pooling，解决了传统[CLS]和mean pooling在长上下文任务中的系统性问题。


<details>
  <summary>Details</summary>
Motivation: 现有序列编码器通常使用[CLS] token或mean pooling将变长token序列压缩为单个向量，但这些方法存在系统弱点：[CLS]倾向于将信息集中在序列初始位置，可能无法充分表示分布式证据；mean pooling可能稀释重要的局部信号，在短上下文任务中表现不佳。

Method: 提出Landmark (LMK) pooling方法：1) 将序列分割成多个chunks；2) 在chunks之间插入landmark tokens；3) 对landmark token embeddings进行mean pooling形成最终表示。这种方法通过引入少量特殊token，在保持局部显著特征的同时改善长上下文外推能力。

Result: 实验证明：LMK pooling在短上下文检索任务上与现有方法表现相当，在长上下文任务上带来显著改进，成为一种实用且可扩展的pooling方法替代方案。

Conclusion: LMK pooling有效解决了传统pooling策略的系统弱点，在保持短上下文性能的同时显著提升长上下文任务表现，为序列表示学习提供了更优的pooling机制。

Abstract: Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.

</details>


### [28] [inversedMixup: Data Augmentation via Inverting Mixed Embeddings](https://arxiv.org/abs/2601.21543)
*Fanshuang Kong,Richong Zhang,Qiyu Sun,Zhijie Nie,Ting Deng,Chunming Hu*

Main category: cs.CL

TL;DR: 提出inversedMixup框架，结合Mixup的可控性和LLM的可解释性，通过三阶段训练对齐任务模型与LLM的嵌入空间，生成可读的增强文本并解决流形入侵问题。


<details>
  <summary>Details</summary>
Motivation: 传统Mixup在嵌入层面操作，生成的样本不可解释；而基于LLM的增强方法在token层面生成可读文本，但控制性有限。需要结合两者的优势，同时解决文本Mixup中的流形入侵问题。

Method: 采用三阶段训练：1) 对齐任务模型输出嵌入与LLM输入嵌入空间；2) 使用可控制混合比例重构混合嵌入为可解释句子；3) 引入简单策略缓解流形入侵现象。

Result: 在少样本和全监督场景下的广泛实验证明了方法的有效性和泛化能力，显著提升了增强性能，并首次为文本Mixup中的流形入侵现象提供了实证证据。

Conclusion: inversedMixup成功统一了Mixup的可控性和LLM的可解释性，通过嵌入空间对齐实现了可读的文本增强，同时解决了流形入侵问题，为文本数据增强提供了新思路。

Abstract: Mixup generates augmented samples by linearly interpolating inputs and labels with a controllable ratio. However, since it operates in the latent embedding level, the resulting samples are not human-interpretable. In contrast, LLM-based augmentation methods produce sentences via prompts at the token level, yielding readable outputs but offering limited control over the generation process. Inspired by recent advances in LLM inversion, which reconstructs natural language from embeddings and helps bridge the gap between latent embedding space and discrete token space, we propose inversedMixup, a unified framework that combines the controllability of Mixup with the interpretability of LLM-based generation. Specifically, inversedMixup adopts a three-stage training procedure to align the output embedding space of a task-specific model with the input embedding space of an LLM. Upon successful alignment, inversedMixup can reconstruct mixed embeddings with a controllable mixing ratio into human-interpretable augmented sentences, thereby improving the augmentation performance. Additionally, inversedMixup provides the first empirical evidence of the manifold intrusion phenomenon in text Mixup and introduces a simple yet effective strategy to mitigate it. Extensive experiments demonstrate the effectiveness and generalizability of our approach in both few-shot and fully supervised scenarios.

</details>


### [29] [Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes](https://arxiv.org/abs/2601.21551)
*Yang Zhou,Zhenting Sheng,Mingrui Tan,Yuting Song,Jun Zhou,Yu Heng Kwan,Lian Leng Low,Yang Bai,Yong Liu*

Main category: cs.CL

TL;DR: 提出Note2Chat框架，通过医疗记录生成医患对话数据，采用三阶段微调策略，将病史采集重构为单轮推理问题，显著提升临床推理能力


<details>
  <summary>Details</summary>
Motivation: 临床病史采集是临床推理的基础但研究不足，现有大语言模型在静态基准上表现良好，但在需要迭代提问和假设优化的动态多轮诊断场景中表现不佳

Method: 提出Note2Chat框架：1) 使用决策树引导的生成和优化管道将真实医疗记录转化为高质量医患对话；2) 采用三阶段微调策略（监督学习、模拟数据增强、偏好学习）；3) 提出新颖的单轮推理范式，将病史采集重构为一系列单轮推理问题

Result: 方法显著改善临床推理能力，相比GPT-4o提升了16.9 F1分数和21.0 Top-1诊断准确率

Conclusion: Note2Chat框架通过利用广泛可得的医疗记录，有效解决了临床病史采集中的动态推理挑战，提供了一种可解释、高效且适应性强的解决方案

Abstract: Effective clinical history taking is a foundational yet underexplored component of clinical reasoning. While large language models (LLMs) have shown promise on static benchmarks, they often fall short in dynamic, multi-turn diagnostic settings that require iterative questioning and hypothesis refinement. To address this gap, we propose \method{}, a note-driven framework that trains LLMs to conduct structured history taking and diagnosis by learning from widely available medical notes. Instead of relying on scarce and sensitive dialogue data, we convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline. We then propose a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning. Furthermore, we propose a novel single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems. This design enhances interpretability and enables local supervision, dynamic adaptation, and greater sample efficiency. Experimental results show that our method substantially improves clinical reasoning, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o. Our code and dataset can be found at https://github.com/zhentingsheng/Note2Chat.

</details>


### [30] [ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas](https://arxiv.org/abs/2601.21558)
*Xiaoyu Tian,Haotian Wang,Shuaiting Chen,Hao Zhou,Kaichi Yu,Yudian Zhang,Jade Ouyang,Junxi Yin,Jiong Chen,Baoyan Guo,Lei Zhang,Junjie Tao,Yuansheng Song,Ming Cui,Chengwei Liu*

Main category: cs.CL

TL;DR: ASTRA是一个用于训练工具增强语言模型代理的自动化端到端框架，通过可扩展数据合成和可验证强化学习解决现有方法的局限性，在多个工具使用基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前训练工具增强语言模型代理的方法存在多个问题：需要人工干预、依赖不可验证的模拟环境、仅使用监督微调或强化学习、难以实现稳定的长视野多轮学习。需要一种更自动化和可靠的训练框架。

Method: ASTRA包含两个核心组件：1）基于工具调用图静态拓扑的数据合成管道，生成多样化的结构化轨迹；2）环境合成框架，将分解的问题-答案轨迹转换为独立的、可代码执行且规则可验证的环境，支持确定性多轮强化学习。结合监督微调和在线强化学习的统一训练方法。

Result: 在多个代理工具使用基准测试中，ASTRA训练的模型在可比规模下达到最先进性能，接近闭源系统，同时保持核心推理能力。

Conclusion: ASTRA提供了一个完全自动化的端到端框架，通过可扩展数据合成和可验证强化学习有效训练工具增强语言模型代理，解决了现有方法的多个挑战，为构建稳健的工具使用代理提供了新途径。

Abstract: Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.

</details>


### [31] [KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices](https://arxiv.org/abs/2601.21579)
*Wuyang Zhou,Yuxuan Gu,Giorgos Iacovides,Danilo Mandic*

Main category: cs.CL

TL;DR: 提出KromHC方法，通过小双随机矩阵的Kronecker积参数化残差矩阵，解决现有超连接方法在双随机性和参数复杂度方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有超连接方法存在训练不稳定和可扩展性受限问题。mHC方法虽然通过Birkhoff多面体投影缓解了这些问题，但仍面临两个挑战：1) Sinkhorn-Knopp算法不能总是产生精确的双随机残差矩阵；2) 参数复杂度高达O(n³C)。mHC-lite虽然保证双随机性，但参数复杂度呈阶乘爆炸。

Method: 提出KromHC方法，使用小双随机矩阵的Kronecker积来参数化残差矩阵。通过对张量化残差流的每个模态的因子残差矩阵施加流形约束，KromHC保证残差矩阵的精确双随机性，同时将参数复杂度降低到O(n²C)。

Result: 综合实验表明，KromHC匹配甚至优于最先进的mHC变体，同时需要显著更少的可训练参数。

Conclusion: KromHC成功解决了现有超连接方法在双随机性和参数复杂度方面的挑战，提供了一种高效且性能优越的替代方案。

Abstract: The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive $\mathcal{O}(n^3C)$ parameter complexity with $n$ as the width of the residual stream and $C$ as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, $\mathcal{O} \left( nC \cdot n! \right)$. To address both challenges, we propose \textbf{KromHC}, which uses the \underline{Kro}necker products of smaller doubly stochastic matrices to parametrize the residual matrix in \underline{mHC}. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to $\mathcal{O}(n^2C)$. Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at \texttt{https://github.com/wz1119/KromHC}.

</details>


### [32] [Language Models as Artificial Learners: Investigating Crosslinguistic Influence](https://arxiv.org/abs/2601.21587)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 使用语言模型作为受控统计学习器来系统模拟跨语言影响，研究L1语言优势、L2熟练度、句法距离等因素对跨语言影响的作用机制。


<details>
  <summary>Details</summary>
Motivation: 人类研究中跨语言影响(CLI)的结果常存在矛盾，需要更受控的方法来系统研究其驱动因素。语言模型可作为统计学习器来模拟CLI，提供更一致的实验环境。

Method: 使用语言模型作为受控统计学习器，通过控制L2暴露年龄来操纵L2熟练度，研究不同句法距离的L1预训练影响，采用跨语言启动范式分析L1结构激活对L2处理的影响。

Result: 结果与心理语言学证据一致：语言优势和熟练度是CLI的强预测因子；语法结构启动是双向的，但非语法结构启动对语言优势敏感；L1在L2处理中被共同激活并直接影响L2神经回路。

Conclusion: 语言模型可作为计算框架来验证人类CLI理论，为跨语言影响提供机制性证据，证明L1在L2处理中的共同激活和直接影响作用。

Abstract: Despite the centrality of crosslinguistic influence (CLI) to bilingualism research, human studies often yield conflicting results due to inherent experimental variance. We address these inconsistencies by using language models (LMs) as controlled statistical learners to systematically simulate CLI and isolate its underlying drivers. Specifically, we study the effect of varying the L1 language dominance and the L2 language proficiency, which we manipulate by controlling the L2 age of exposure -- defined as the training step at which the L2 is introduced. Furthermore, we investigate the impact of pretraining on L1 languages with varying syntactic distance from the L2. Using cross-linguistic priming, we analyze how activating L1 structures impacts L2 processing. Our results align with evidence from psycholinguistic studies, confirming that language dominance and proficiency are strong predictors of CLI. We further find that while priming of grammatical structures is bidirectional, the priming of ungrammatical structures is sensitive to language dominance. Finally, we provide mechanistic evidence of CLI in LMs, demonstrating that the L1 is co-activated during L2 processing and directly influences the neural circuitry recruited for the L2. More broadly, our work demonstrates that LMs can serve as a computational framework to inform theories of human CLI.

</details>


### [33] [ILRR: Inference-Time Steering Method for Masked Diffusion Language Models](https://arxiv.org/abs/2601.21647)
*Eden Avrahami,Eliya Nachmani*

Main category: cs.CL

TL;DR: 提出ILRR框架，通过单参考序列在推理时控制离散扩散语言模型，实现属性引导生成


<details>
  <summary>Details</summary>
Motivation: 离散扩散语言模型在推理时控制机制相对未充分探索，现有方法包括采样级引导或轨迹优化，需要更有效的控制框架

Method: 提出ILRR（迭代潜在表示细化）框架，通过动态对齐生成序列与参考序列的内部激活来引导生成，并引入空间调制引导扩展以长文本控制

Result: 在LLaDA和MDLM架构上实现有效属性引导，计算开销小（每去噪步骤仅需额外一次并行前向传播），相同计算预算下属性准确率比基线提高10-60%

Conclusion: ILRR为离散扩散语言模型提供了一种学习自由、计算高效的推理时控制框架，能够有效引导文本属性同时保持高质量生成

Abstract: Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\%$ to 60$\%$ points, while maintaining high generation quality.

</details>


### [34] [AdaptBPE: From General Purpose to Specialized Tokenizers](https://arxiv.org/abs/2601.21665)
*Vijini Liyanage,François Yvon*

Main category: cs.CL

TL;DR: 提出一种后训练自适应方法，通过选择性替换低效用token来优化BPE分词器，使其在特定领域或语言中更高效。


<details>
  <summary>Details</summary>
Motivation: 标准的通用分词器在处理特定领域或语言时存在效率低下的问题，需要一种轻量级自适应机制来优化分词效果。

Method: 提出后训练自适应策略，基于适应语料库中token的频率，选择性替换低效用token为更相关的token，算法识别出最能有效编码适应语料库的token库。

Result: 在多种语言的生成和分类任务上的实验表明，自适应分词器在相同词汇量下比基线方法能更有效地压缩测试语料库。

Conclusion: 该方法作为一种轻量级自适应机制，类似于词汇微调过程，能够为特定领域或任务优化分词器，提高模型效率和性能。

Abstract: Subword tokenization methods, such as Byte-Pair Encoding (BPE), significantly impact the performance and efficiency of large language models (LLMs). The standard approach involves training a general-purpose tokenizer that uniformly processes all textual data during both training and inference. However, the use of a generic set of tokens can incur inefficiencies when applying the model to specific domains or languages. To address this limitation, we propose a post-training adaptation strategy that selectively replaces low-utility tokens with more relevant ones based on their frequency in an adaptation corpus. Our algorithm identifies the token inventory that most effectively encodes the adaptation corpus for a given target vocabulary size. Extensive experiments on generation and classification tasks across multiple languages demonstrate that our adapted tokenizers compress test corpora more effectively than baselines using the same vocabulary size. This method serves as a lightweight adaptation mechanism, akin to a vocabulary fine-tuning process, enabling optimized tokenization for specific domains or tasks. Our code and data are available at https://github.com/vijini/Adapt-BPE.git.

</details>


### [35] [Scale-Dependent Semantic Dynamics Revealed by Allan Deviation](https://arxiv.org/abs/2601.21678)
*Debayan Dasgupta*

Main category: cs.CL

TL;DR: 使用Allan偏差分析文本语义动态，发现人类文本与LLM在语义稳定性上的差异


<details>
  <summary>Details</summary>
Motivation: 理解语言语义进展的底层动态机制，将文本语义进展视为高维状态空间中的随机轨迹

Method: 使用精密计量学中的Allan偏差工具，将有序句子嵌入视为位移信号，分析语义稳定性

Result: 发现两个动态机制：短时幂律标度区分创意文学与技术文本，长时交叉到稳定性限制的噪声基底；LLM能模仿人类文本的局部标度统计，但稳定性视界系统性降低

Conclusion: 语义连贯性是可测量的物理属性，为区分人类认知的微妙动态与算法模型生成模式提供了框架

Abstract: While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.

</details>


### [36] [FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682)
*Xiaoyu Xu,Minxin Du,Kun Fang,Zi Liang,Yaxin Xiao,Zhicong Huang,Cheng Hong,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: FIT是一个持续遗忘框架，通过数据过滤、重要性感知更新和针对性层归因，处理大量删除请求，在保持模型效用的同时实现有效遗忘，解决了现有LLM遗忘方法在连续高容量删除请求下的性能退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM遗忘方法很少考虑现实世界中删除请求的持续性和高容量特性，随着请求累积会导致效用退化和灾难性遗忘。需要一种能够处理大量删除请求同时保持模型鲁棒性的方法。

Method: FIT框架采用三种核心技术：1) 严格的数据过滤；2) 重要性感知更新；3) 针对性层归因。同时提出了PCH基准测试，涵盖个人信息、版权和有害内容三类删除场景，以及两个对称指标：遗忘度(F.D.)和保留效用(R.U.)。

Result: 在四个开源LLM上进行数百个删除请求的实验表明，FIT在F.D.和R.U.之间取得了最佳平衡，在MMLU、CommonsenseQA和GSM8K等基准测试上超越了现有方法，并且对重新学习和量化恢复攻击具有抵抗力。

Conclusion: FIT框架能够有效处理大规模连续删除请求，在保持模型效用的同时实现有效遗忘，解决了现有LLM遗忘方法在现实场景中的局限性，为LLM的安全部署提供了实用解决方案。

Abstract: Large language models (LLMs) demonstrate impressive capabilities across diverse tasks but raise concerns about privacy, copyright, and harmful materials. Existing LLM unlearning methods rarely consider the continual and high-volume nature of real-world deletion requests, which can cause utility degradation and catastrophic forgetting as requests accumulate. To address this challenge, we introduce \fit, a framework for continual unlearning that handles large numbers of deletion requests while maintaining robustness against both catastrophic forgetting and post-unlearning recovery. \fit mitigates degradation through rigorous data \underline{F}iltering, \underline{I}mportance-aware updates, and \underline{T}argeted layer attribution, enabling stable performance across long sequences of unlearning operations and achieving a favorable balance between forgetting effectiveness and utility retention. To support realistic evaluation, we present \textbf{PCH}, a benchmark covering \textbf{P}ersonal information, \textbf{C}opyright, and \textbf{H}armful content in sequential deletion scenarios, along with two symmetric metrics, Forget Degree (F.D.) and Retain Utility (R.U.), which jointly assess forgetting quality and utility preservation. Extensive experiments on four open-source LLMs with hundreds of deletion requests show that \fit achieves the strongest trade-off between F.D. and R.U., surpasses existing methods on MMLU, CommonsenseQA, and GSM8K, and remains resistant against both relearning and quantization recovery attacks.

</details>


### [37] [Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.21684)
*Xinglin Wang,Jiayi Shi,Shaoxiong Feng,Peiwen Yuan,Yiwei Li,Yueqi Zhang,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.CL

TL;DR: RSE是一种训练免费的自引导策略，通过将原始轨迹提炼到共享经验库中，实现中间结论的正向回收和失败模式的负向回收，显著提升测试时搜索效率。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法将每次推理尝试视为独立样本，丢弃了宝贵的中间见解，导致大量计算冗余，模型反复重新推导已发现的结论并重访已知的死胡同。

Method: 提出Recycling Search Experience (RSE)策略，主动将原始轨迹提炼到共享经验库中，实现正向回收（利用中间结论跳过冗余推导）和负向回收（利用失败模式修剪死胡同），形成累积式搜索过程。

Result: 在HMMT24、HMMT25、IMO-Bench和HLE等基准测试中，RSE在相同计算成本下持续超越强基线方法，实现了最先进的扩展效率。

Conclusion: RSE通过将测试时搜索从孤立试验转变为累积过程，有效解决了现有方法中的计算冗余问题，显著提升了大型语言模型在复杂推理任务中的效率。

Abstract: Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.

</details>


### [38] [Can David Beat Goliath? On Multi-Hop Reasoning with Resource-Constrained Agents](https://arxiv.org/abs/2601.21699)
*Hojae Han,Heeyun Jung,Jongyoon Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: DAVID-GRPO：针对资源受限小语言模型的多跳推理强化学习框架，通过最小监督稳定早期学习、基于证据召回分配检索信用、重采样截断轨迹改进探索，在有限计算资源下实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖大规模模型和密集探索，但在实际资源约束下（小模型、有限计算），小语言模型陷入低成本-低精度困境：有限探索预算导致稀疏探索、稀疏信用分配和不稳定训练。需要打破这种权衡。

Method: 提出DAVID-GRPO框架：1）用最小监督稳定早期学习；2）基于证据召回分配检索信用；3）通过重采样截断的"近失"轨迹改进探索。专为资源受限环境设计（如4张RTX 3090 GPU训练1.5B参数模型）。

Result: 在六个多跳QA基准测试中，DAVID-GRPO持续优于先前为大规模设置设计的RL方法。小至1.5B参数的模型在有限计算资源下（4张RTX 3090）表现出强大的多跳推理能力。

Conclusion: 通过正确的归纳偏置，小模型代理可以在低成本训练的同时实现高精度，打破了资源约束下低成本-低精度的权衡，为资源受限环境中的高效RL训练提供了可行方案。

Abstract: While reinforcement learning (RL) has empowered multi-turn reasoning agents with retrieval and tools, existing successes largely depend on extensive on-policy rollouts in high-cost, high-accuracy regimes. Under realistic resource constraints that cannot support large models or dense explorations, however, small language model agents fall into a low-cost, low-accuracy regime, where limited rollout budgets lead to sparse exploration, sparse credit assignment, and unstable training. In this work, we challenge this trade-off and show that small language models can achieve strong multi-hop reasoning under resource constraints. We introduce DAVID-GRPO, a budget-efficient RL framework that (i) stabilizes early learning with minimal supervision, (ii) assigns retrieval credit based on evidence recall, and (iii) improves exploration by resampling truncated near-miss trajectories. Evaluated on agents up to 1.5B parameters trained on only four RTX 3090 GPUs, DAVID-GRPO consistently outperforms prior RL methods designed for large-scale settings on six multi-hop QA benchmarks. These results show that with the right inductive biases, small agents can achieve low training cost with high accuracy.

</details>


### [39] [Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning](https://arxiv.org/abs/2601.21700)
*Wonduk Seo,Wonseok Choi,Junseo Koh,Juhyeon Lee,Hyunjin An,Minhyeong Yu,Jian Park,Qingshan Zhou,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: OG-MAR框架通过本体引导的多智能体推理，利用世界价值观调查数据构建文化本体，结合人口统计相似性来提升LLMs的文化对齐和推理透明度。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在文化敏感决策中存在偏差，主要原因是预训练数据倾斜且缺乏结构化价值表示。现有方法缺乏人口统计基础，将价值观视为独立、非结构化信号，导致一致性和可解释性不足。

Method: 提出OG-MAR框架：1) 从世界价值观调查中提取受访者特定价值观；2) 通过能力问题在固定分类法上构建全球文化本体；3) 推理时检索本体一致关系和人口统计相似档案，实例化多个价值-人格智能体；4) 由判断智能体综合输出，强制本体一致性和人口统计接近性。

Result: 在四个LLM骨干网络上对区域社会调查基准进行实验，OG-MAR相比竞争基线显著提高了文化对齐和鲁棒性，同时产生更透明的推理轨迹。

Conclusion: OG-MAR框架通过结构化本体表示和人口统计基础，有效解决了LLMs文化对齐问题，提高了决策的一致性和可解释性，为跨文化AI系统提供了新方法。

Abstract: Large Language Models (LLMs) increasingly support culturally sensitive decision making, yet often exhibit misalignment due to skewed pretraining data and the absence of structured value representations. Existing methods can steer outputs, but often lack demographic grounding and treat values as independent, unstructured signals, reducing consistency and interpretability. We propose OG-MAR, an Ontology-Guided Multi-Agent Reasoning framework. OG-MAR summarizes respondent-specific values from the World Values Survey (WVS) and constructs a global cultural ontology by eliciting relations over a fixed taxonomy via competency questions. At inference time, it retrieves ontology-consistent relations and demographically similar profiles to instantiate multiple value-persona agents, whose outputs are synthesized by a judgment agent that enforces ontology consistency and demographic proximity. Experiments on regional social-survey benchmarks across four LLM backbones show that OG-MAR improves cultural alignment and robustness over competitive baselines, while producing more transparent reasoning traces.

</details>


### [40] [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709)
*Qingyue Yang,Jie Wang,Xing Li,Yinqi Bai,Xialiang Tong,Huiling Zhen,Jianye Hao,Mingxuan Yuan,Bin Li*

Main category: cs.CL

TL;DR: TAPPA提出一个统一框架，通过时间连续视角分析注意力模式的数学公式，将模式分为可预测和不可预测两类，并应用于KV缓存压缩和LLM剪枝任务。


<details>
  <summary>Details</summary>
Motivation: 现有研究识别了检索头、汇头、对角线轨迹等注意力模式，但这些观察是零散的，缺乏统一解释。需要建立一个框架来统一解释多样化的注意力模式。

Method: 提出TAPPA框架，从时间连续视角分析注意力模式的数学公式，将模式分为可预测（具有清晰规律）和不可预测（看似随机）两类。通过查询在时间维度上的自相似性程度来解释这种区分，并对三个代表性案例进行详细的数学分析（考虑查询、键和RoPE的联合效应）。

Result: TAPPA的见解应用于KV缓存压缩和LLM剪枝任务，基于TAPPA启发的简单指标在这些任务中持续优于基线方法。

Conclusion: TAPPA提供了一个统一框架来解释多样化的注意力模式，不仅加深了对注意力行为的理解，还指导了推理加速方法。该框架在压缩和剪枝任务中表现出实用价值。

Abstract: Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce \textbf{Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations} from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.

</details>


### [41] [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711)
*Huiyuan Lai,Malvina Nissim*

Main category: cs.CL

TL;DR: TACLer：一种模型定制的课程强化学习框架，通过渐进式增加数据复杂度来提升LLMs的推理效率，减少计算成本同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在复杂推理任务中通常需要大规模RL训练来生成长链式思维，但这会导致过度思考（冗余中间步骤）和计算效率低下。需要一种方法在保持或提升性能的同时，提高学习和推理效率。

Method: 提出TACLer框架，包含两个核心组件：1）定制化课程学习：根据模型在多阶段RL训练中的熟练程度，渐进式增加数据复杂度；2）混合Thinking/NoThinking推理范式：通过启用或禁用思考模式来平衡准确性和效率。

Result: TACLer在学习和推理方面带来双重优势：1）减少计算成本：训练计算量比长思考模型减少50%以上，推理token使用量比基础模型减少42%以上；2）提高准确性：在基础模型上提升9%以上，在四个数学数据集上持续优于最先进的NoThinking和Thinking基线。

Conclusion: TACLer通过模型定制的课程强化学习，有效解决了LLMs在复杂推理任务中的过度思考和计算效率问题，实现了准确性提升和计算成本降低的双重优化。

Abstract: Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.

</details>


### [42] [Enhancing Language Models for Robust Greenwashing Detection](https://arxiv.org/abs/2601.21722)
*Neil Heinrich Braun,Keane Ong,Rui Mao,Erik Cambria,Gianmarco Mengaldo*

Main category: cs.CL

TL;DR: 提出一个参数高效的框架，通过结合对比学习和序数排序目标来结构化LLM潜在空间，以区分具体行动与模糊声明，提高ESG报告评估的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: ESG评估中的可持续发展报告存在"洗绿"和模糊声明问题，现有NLP模型缺乏对这些实践的鲁棒性，通常依赖表层模式且泛化能力差。

Method: 结合对比学习和序数排序目标来结构化LLM潜在空间，捕捉具体行动与模糊声明之间的分级区别；采用门控特征调制过滤披露噪声，使用MetaGradNorm稳定多目标优化。

Result: 在跨类别设置中的实验表明，该方法在标准基准上表现出优越的鲁棒性，同时揭示了表示刚性与泛化之间的权衡关系。

Conclusion: 提出的参数高效框架能有效提高ESG报告评估的鲁棒性，通过结构化LLM潜在空间来更好地区分具体行动与模糊声明，为可持续发展报告分析提供了更可靠的方法。

Abstract: Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.

</details>


### [43] [Procedural Pretraining: Warming Up Language Models with Abstract Data](https://arxiv.org/abs/2601.21725)
*Liangze Jiang,Zachary Shinnick,Anton van den Hengel,Hemanth Saratchandran,Damien Teney*

Main category: cs.CL

TL;DR: 论文提出在语言模型预训练前加入抽象结构化数据（如形式语言生成的程序数据），能显著提升模型算法能力并加速训练，仅需0.1%的程序数据就能超越传统自然语言预训练效果。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型直接在网络规模语料上预训练是主流范式，但作者认为人类学习是从简单逻辑和数学开始，再到高级推理。因此研究在预训练前先接触抽象结构化数据是否能帮助模型更好地获取语义知识。

Method: 使用形式语言和其他简单算法生成的程序数据作为抽象数据源。首先诊断不同程序数据能提升哪些算法技能，然后在更大模型（最大13亿参数）上研究这些增益，分析程序预训练如何影响模型内部结构（注意力层和MLP层），并探索多种程序数据组合的方法。

Result: 1. 程序数据能显著提升算法技能：如在上下文回忆任务上，使用Dyck序列（平衡括号）预训练后准确率从10%提升到98%。2. 仅加入0.1%程序数据就能超越标准预训练（C4、CodeParrot、DeepMind-Math数据集），达到相同损失值只需原始数据的55%、67%、86%。3. 程序预训练在注意力层和MLP层都注入了非平凡结构，前者对结构化领域（如代码）特别重要，后者对语言重要。

Conclusion: 程序预训练是一种简单轻量的方法，能提高性能并加速语言模型预训练，最终表明在LLMs中将知识获取与推理解耦具有前景。

Abstract: Pretraining directly on web-scale corpora is the de facto paradigm for building language models. We study an alternative setting where the model is initially exposed to abstract structured data, as a means to ease the subsequent acquisition of rich semantic knowledge, much like humans learn simple logic and mathematics before higher reasoning. We specifically focus on procedural data, generated by formal languages and other simple algorithms, as such abstract data.
  We first diagnose the algorithmic skills that different forms of procedural data can improve, often significantly. For example, on context recall (Needle-in-a-haystack), the accuracy jumps from 10 to 98% when pretraining on Dyck sequences (balanced brackets). Second, we study how these gains are reflected in pretraining larger models (up to 1.3B). We find that front-loading as little as 0.1% procedural data significantly outperforms standard pretraining on natural language, code, and informal mathematics (C4, CodeParrot, and DeepMind-Math datasets). Notably, this procedural pretraining enables the models to reach the same loss value with only 55, 67, 86% of the original data. Third, we explore the mechanisms behind and find that procedural pretraining instils non-trivial structure in both attention and MLP layers. The former is particularly important for structured domains (e.g. code), and the latter for language. Finally, we lay a path for combining multiple forms of procedural data. Our results show that procedural pretraining is a simple, lightweight means to improving performance and accelerating language model pretraining, ultimately suggesting the promise of disentangling knowledge acquisition from reasoning in LLMs.

</details>


### [44] [CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering](https://arxiv.org/abs/2601.21733)
*Jiayin Lan,Jiaqi Li,Baoxin Wang,Ming Liu,Dayong Wu,Shijin Wang,Bing Qin,Guoping Hu*

Main category: cs.CL

TL;DR: 提出CE-GOCD方法，通过建模学术知识图谱中的语义子结构来增强LLM的科学问答能力，在三个NLP文献问答数据集上优于现有检索增强基线。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强方法通常依赖孤立的文本块或概念，忽略了论文之间更深层的语义连接，这损害了LLM对科学文献的理解，影响了回答的全面性和针对性。

Method: 提出CE-GOCD方法：1) 利用论文标题作为中心实体进行针对性子图检索；2) 通过子图剪枝和补全增强隐式语义发现；3) 应用社区检测提取具有共同主题的连贯论文组。

Result: 在三个NLP文献问答数据集上评估，该方法优于其他检索增强基线方法，证实了框架的有效性。

Conclusion: 通过显式建模和利用学术知识图谱中的语义子结构，CE-GOCD方法能够有效增强LLM在科学问答中的表现，解决了现有方法忽略深层语义连接的问题。

Abstract: Large Language Models (LLMs) are increasingly used for question answering over scientific research papers. Existing retrieval augmentation methods often rely on isolated text chunks or concepts, but overlook deeper semantic connections between papers. This impairs the LLM's comprehension of scientific literature, hindering the comprehensiveness and specificity of its responses. To address this, we propose Central Entity-Guided Graph Optimization for Community Detection (CE-GOCD), a method that augments LLMs' scientific question answering by explicitly modeling and leveraging semantic substructures within academic knowledge graphs. Our approach operates by: (1) leveraging paper titles as central entities for targeted subgraph retrieval, (2) enhancing implicit semantic discovery via subgraph pruning and completion, and (3) applying community detection to distill coherent paper groups with shared themes. We evaluated the proposed method on three NLP literature-based question-answering datasets, and the results demonstrate its superiority over other retrieval-augmented baseline approaches, confirming the effectiveness of our framework.

</details>


### [45] [Temporal Guidance for Large Language Models](https://arxiv.org/abs/2601.21744)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CL

TL;DR: 提出Temporal Guidance (TeGu)方法，通过时间维度对比解码提升LLM生成质量，利用多词预测构建弱预测进行自对比，引入轻量级cMTPP模块，在保持低开销的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有对比解码方法需要辅助模型带来显著计算开销，而内部自对比方法（如DoLa）依赖层间差异，在小型模型上不稳定。基于LLM表现出局部偏好的观察，需要更稳定高效的对比解码方法。

Method: 提出时间维度对比指导策略TeGu：1）利用多词预测构建弱预测作为业余预测进行模型自对比；2）引入轻量级条件多词预测投影器cMTPP，避免维护多个独立网络；3）在时间维度进行对比解码。

Result: 在各种模型系列和基准测试中，TeGu实现了显著的性能提升，同时保持了低额外内存消耗和计算开销。

Conclusion: TeGu通过时间维度的对比指导策略，有效提升了LLM生成质量，解决了现有对比解码方法的计算开销和稳定性问题，为高效对比解码提供了新思路。

Abstract: Contrastive Decoding (CD) enhances the generation quality of large language models (LLMs) but incurs significant additional computational overhead due to the need for an auxiliary model. Existing internal self-contrastive decoding methods, such as Decoding by Contrasting Layers (DoLa), focus on discrepancies across different layers, which are notably unstable on small-scale models. In this work, based on the observation that LLMs exhibit local preferences, we propose a novel contrastive guidance strategy along the temporal dimension, namely Temporal Guidance (TeGu). Our method ingeniously leverages Multi-Token Prediction (MTP) to construct weaker amateur predictions for model self-contrast. To standardize the implementation of this mechanism, we further introduce a lightweight Conditional MTP Projector (cMTPP), which avoids maintaining multiple independent networks as required by other MTP modules. Across various model series and benchmarks, TeGu achieves significant performance improvements while maintaining low additional memory consumption and computational overhead.

</details>


### [46] [CoFrGeNet: Continued Fraction Architectures for Language Generation](https://arxiv.org/abs/2601.21766)
*Amit Dhurandhar,Vijil Chenthamarakshan,Dennis Wei,Tejaswini Pedapati,Karthikeyan Natesan Ramamurthy,Rahul Nair*

Main category: cs.CL

TL;DR: 提出基于连分数的新函数类CoFrGeNets，替代Transformer中的多头注意力和前馈网络，参数减少1/2-1/3，性能保持竞争力


<details>
  <summary>Details</summary>
Motivation: Transformer是语言生成的首选架构，但参数量大、训练成本高。受连分数启发，希望设计更高效的替代组件来减少参数和训练时间

Method: 引入基于连分数的新函数类CoFrGeNets，设计替代多头注意力和前馈网络的组件，推导定制梯度公式优化训练，保持与Transformer的插件式兼容性

Result: 在GPT2-xl和Llama3上测试，下游分类、问答、推理和文本理解任务表现竞争力强，有时优于原模型，参数减少1/2-1/3，预训练时间更短

Conclusion: CoFrGeNets是Transformer的高效替代方案，易于集成到现有工业流程，未来硬件定制实现将进一步提升其潜力

Abstract: Transformers are arguably the preferred architecture for language generation. In this paper, inspired by continued fractions, we introduce a new function class for generative modeling. The architecture family implementing this function class is named CoFrGeNets - Continued Fraction Generative Networks. We design novel architectural components based on this function class that can replace Multi-head Attention and Feed-Forward Networks in Transformer blocks while requiring much fewer parameters. We derive custom gradient formulations to optimize the proposed components more accurately and efficiently than using standard PyTorch-based gradients. Our components are a plug-in replacement requiring little change in training or inference procedures that have already been put in place for Transformer-based models thus making our approach easy to incorporate in large industrial workflows. We experiment on two very different transformer architectures GPT2-xl (1.5B) and Llama3 (3.2B), where the former we pre-train on OpenWebText and GneissWeb, while the latter we pre-train on the docling data mix which consists of nine different datasets. Results show that the performance on downstream classification, Q\& A, reasoning and text understanding tasks of our models is competitive and sometimes even superior to the original models with $\frac{2}{3}$ to $\frac{1}{2}$ the parameters and shorter pre-training time. We believe that future implementations customized to hardware will further bring out the true potential of our architectures.

</details>


### [47] [Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond](https://arxiv.org/abs/2601.21767)
*Wei Zhu*

Main category: cs.CL

TL;DR: ChatGPT在医学信息抽取任务上表现不及微调模型，但能提供高质量解释，存在过度自信问题，对原文忠实度较高，生成不确定性影响信息抽取结果


<details>
  <summary>Details</summary>
Motivation: 评估ChatGPT在医学信息抽取任务中的整体能力，包括性能、可解释性、置信度、忠实度和不确定性等方面，探索其在医疗NLP任务中的应用潜力

Method: 在6个基准数据集上对ChatGPT进行4种不同医学信息抽取任务的系统评估，测量其性能、可解释性、置信度、忠实度和不确定性

Result: ChatGPT在MedIE任务上的性能得分低于微调基线模型；能提供高质量决策解释但存在过度自信；多数情况下对原文有较高忠实度；生成不确定性导致信息抽取结果不确定性

Conclusion: ChatGPT在医学信息抽取任务中表现有限，生成不确定性可能阻碍其在MedIE任务中的应用，需要进一步改进以提升医疗NLP任务的可靠性

Abstract: Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.

</details>


### [48] [Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention](https://arxiv.org/abs/2601.21768)
*Alon Rozental*

Main category: cs.CL

TL;DR: Zonkey是一个分层扩散模型，通过可微分的分词器和概率注意力机制，实现从原始字符到文档级表示的端到端训练，解决了传统LLM固定分词器的限制。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型受限于固定、不可微的分词器（如BPE），阻碍了端到端优化和对噪声或领域特定数据的适应性。

Method: 提出Zonkey模型：1）可微分分词器学习概率性的序列开始决策；2）概率注意力机制支持无限序列的软掩码；3）分层结构将序列压缩为更高抽象；4）去噪扩散混合模型进行稳定去噪；5）Stitcher确保跨片段重叠不变性。

Result: 在Wikipedia上端到端训练后，Zonkey能从噪声生成连贯、可变长度的文本，显示出涌现的分层结构，相比基于熵的可学习分词器有更好的数据分布对齐。

Conclusion: 该方法推动了完全基于梯度的LLM发展，具有更好的领域适应性和可扩展生成潜力，为端到端优化的语言模型提供了新方向。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical diffusion model that addresses these limitations through a fully trainable pipeline from raw characters to document-level representations. At its core is a differentiable tokenizer (Segment Splitter) that learns probabilistic beginning-of-sequence (BOS) decisions, enabling adaptive splits that emerge as linguistically meaningful (e.g., word boundaries at spaces, sentence starts at periods) without explicit supervision. This differentiability is enabled by our novel Probabilistic Attention mechanism, which incorporates position-specific existence probabilities to simulate soft masking over theoretically infinite sequences while preserving gradients. Sequences decay probabilistically rather than relying on end-of-sequence tokens, supporting variable-length outputs. Hierarchical levels compress sequences into higher abstractions (e.g., character n-grams to word-like vectors, then sentence-like), with reconstruction via our Denoising Diffusion Mixed Model (DDMM) for stable and efficient denoising in latent space. A Stitcher ensures overlap invariance across segments. Trained end-to-end on Wikipedia, Zonkey generates coherent, variable-length text from noise, demonstrating emergent hierarchies and promising qualitative alignment to data distributions compared to entropy-based learnable tokenizers. Our approach advances toward fully gradient-based LLMs, with potential for better domain adaptation and scalable generation. We release the source code for training and reproducing our experiments.

</details>


### [49] [KID: Knowledge-Injected Dual-Head Learning for Knowledge-Grounded Harmful Meme Detection](https://arxiv.org/abs/2601.21796)
*Yaocong Li,Leihan Zhang,Le Zhang,Qiang Yan*

Main category: cs.CL

TL;DR: KID框架通过知识注入和双头学习，结合标签约束蒸馏和结构化推理链，在多语言有害表情包检测任务上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有表情包检测方法主要关注模态内和模态间信号分析，但隐式有害内容的理解往往依赖表情包本身未明确包含的背景知识，这给自动化内容审核带来挑战

Method: 提出KID（知识注入双头学习）框架：1）采用标签约束蒸馏范式，将复杂表情包理解分解为连接视觉证据、背景知识和分类标签的结构化推理链；2）使用双头架构联合优化语义生成和分类目标，实现对齐的语言推理同时保持稳定决策边界

Result: 在英语、中文和低资源孟加拉语的五个多语言数据集上，KID在二元和多标签有害表情包检测任务上均达到SOTA性能，相比之前最佳方法在主要评估指标上提升2.1%-19.7%

Conclusion: 知识注入和双头联合学习对鲁棒且可泛化的表情包理解具有互补贡献，消融研究证实了这些组件的有效性

Abstract: Internet memes have become pervasive carriers of digital culture on social platforms. However, their heavy reliance on metaphors and sociocultural context also makes them subtle vehicles for harmful content, posing significant challenges for automated content moderation. Existing approaches primarily focus on intra-modal and inter-modal signal analysis, while the understanding of implicit toxicity often depends on background knowledge that is not explicitly present in the meme itself. To address this challenge, we propose KID, a Knowledge-Injected Dual-Head Learning framework for knowledge-grounded harmful meme detection. KID adopts a label-constrained distillation paradigm to decompose complex meme understanding into structured reasoning chains that explicitly link visual evidence, background knowledge, and classification labels. These chains guide the learning process by grounding external knowledge in meme-specific contexts. In addition, KID employs a dual-head architecture that jointly optimizes semantic generation and classification objectives, enabling aligned linguistic reasoning while maintaining stable decision boundaries. Extensive experiments on five multilingual datasets spanning English, Chinese, and low-resource Bengali demonstrate that KID achieves SOTA performance on both binary and multi-label harmful meme detection tasks, improving over previous best methods by 2.1%--19.7% across primary evaluation metrics. Ablation studies further confirm the effectiveness of knowledge injection and dual-head joint learning, highlighting their complementary contributions to robust and generalizable meme understanding. The code and data are available at https://github.com/PotatoDog1669/KID.

</details>


### [50] [Enhancing Conversational Agents via Task-Oriented Adversarial Memory Adaptation](https://arxiv.org/abs/2601.21797)
*Yimin Deng,Yuqing Fu,Derong Xu,Yejing Wang,Wei Ni,Jingtong Gao,Xiaopeng Li,Chengxu Liu,Xiao Han,Guoshuai Zhao,Xiangyu Zhao,Li Zhu,Xueming Qian*

Main category: cs.CL

TL;DR: 提出对抗性记忆适应机制(AMA)，通过模拟任务执行来对齐记忆构建与更新，解决现有记忆系统离线阶段与任务需求不匹配的问题


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆系统在离线阶段采用固定、任务无关的构建和更新方式，导致记忆准备与下游任务需求不匹配，影响任务性能

Method: 提出AMA机制：1)挑战者代理基于原始对话生成问答对；2)用构建的记忆回答这些问题模拟下游推理；3)评估者代理评估响应并进行错误分析；4)适配器代理分析错误案例并对构建策略和内容进行双重更新

Result: 在长对话基准LoCoMo上的广泛实验证明了AMA的有效性，该机制可以集成到各种现有记忆系统中

Conclusion: AMA通过在离线阶段提供任务感知的监督信号，增强了记忆系统对下游任务的适应性，解决了记忆构建与任务需求不匹配的问题

Abstract: Conversational agents struggle to handle long conversations due to context window limitations. Therefore, memory systems are developed to leverage essential historical information. Existing memory systems typically follow a pipeline of offline memory construction and update, and online retrieval. Despite the flexible online phase, the offline phase remains fixed and task-independent. In this phase, memory construction operates under a predefined workflow and fails to emphasize task relevant information. Meanwhile, memory updates are guided by generic metrics rather than task specific supervision. This leads to a misalignment between offline memory preparation and task requirements, which undermines downstream task performance. To this end, we propose an Adversarial Memory Adaptation mechanism (AMA) that aligns memory construction and update with task objectives by simulating task execution. Specifically, first, a challenger agent generates question answer pairs based on the original dialogues. The constructed memory is then used to answer these questions, simulating downstream inference. Subsequently, an evaluator agent assesses the responses and performs error analysis. Finally, an adapter agent analyzes the error cases and performs dual level updates on both the construction strategy and the content. Through this process, the memory system receives task aware supervision signals in advance during the offline phase, enhancing its adaptability to downstream tasks. AMA can be integrated into various existing memory systems, and extensive experiments on long dialogue benchmark LoCoMo demonstrate its effectiveness.

</details>


### [51] [RAG-E: Quantifying Retriever-Generator Alignment and Failure Modes](https://arxiv.org/abs/2601.21803)
*Korbinian Randl,Guido Rocchietti,Aron Henriksson,Ziawasch Abedjan,Tony Lindgren,John Pavlopoulos*

Main category: cs.CL

TL;DR: RAG-E是一个端到端的可解释性框架，通过数学基础的归因方法量化检索器与生成器的对齐程度，揭示RAG系统中组件交互的关键错位问题。


<details>
  <summary>Details</summary>
Motivation: RAG系统将密集检索器和语言模型结合，使LLM输出基于检索文档，但组件交互的不透明性给高风险领域部署带来挑战，需要可解释性框架来理解系统内部工作。

Method: 提出RAG-E框架：1) 采用集成梯度方法分析检索器；2) 引入PMCSHAP（蒙特卡洛稳定Shapley值近似）进行生成器归因；3) 提出WARG（加权归因-相关性差距）指标衡量生成器文档使用与检索器排名的对齐程度。

Result: 在TREC CAsT和FoodSafeSum数据集上的实证分析显示严重错位：47.4%-66.7%的查询中生成器忽略检索器排名最高的文档，48.1%-65.9%的查询依赖相关性较低的文档，表明RAG输出质量不仅取决于单个组件性能，更取决于组件间的交互。

Conclusion: RAG-E能够审计RAG系统中检索器与生成器的交互，揭示关键错位模式，为高风险领域部署提供必要的可解释性工具，确保系统可靠性和透明度。

Abstract: Retrieval-Augmented Generation (RAG) systems combine dense retrievers and language models to ground LLM outputs in retrieved documents. However, the opacity of how these components interact creates challenges for deployment in high-stakes domains. We present RAG-E, an end-to-end explainability framework that quantifies retriever-generator alignment through mathematically grounded attribution methods. Our approach adapts Integrated Gradients for retriever analysis, introduces PMCSHAP, a Monte Carlo-stabilized Shapley Value approximation, for generator attribution, and introduces the Weighted Attribution-Relevance Gap (WARG) metric to measure how well a generator's document usage aligns with a retriever's ranking. Empirical analysis on TREC CAsT and FoodSafeSum reveals critical misalignments: for 47.4% to 66.7% of queries, generators ignore the retriever's top-ranked documents, while 48.1% to 65.9% rely on documents ranked as less relevant. These failure modes demonstrate that RAG output quality depends not solely on individual component performance but on their interplay, which can be audited via RAG-E.

</details>


### [52] [Distribution-Aware Reward Estimation for Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.21804)
*Bodong Du,Xuanqi Huang,Xiaomeng Li*

Main category: cs.CL

TL;DR: DARE提出了一种分布感知的奖励估计方法，通过利用完整的经验rollout分布而非多数投票结果，结合探索奖励和分布剪枝机制，显著提升了测试时强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有TTRL方法依赖多数投票产生确定性奖励，但这种方法存在缺陷：丢弃了非多数但正确的动作信息，导致系统性的奖励估计偏差。需要更鲁棒和更具信息量的奖励估计方法。

Method: 提出分布感知奖励估计(DARE)：1) 从单一多数结果转向完整的经验rollout分布；2) 添加探索奖励鼓励非多数rollout探索；3) 使用分布剪枝机制进行奖励去噪。

Result: 在具有挑战性的推理基准测试中，DARE相比现有基线方法显著提升了优化稳定性和最终性能，在AIME 2024上相对提升25.3%，在AMC上提升5.3%。

Conclusion: 利用完整的rollout分布而非多数投票结果进行奖励估计，结合探索奖励和分布剪枝，能够提供更信息丰富且鲁棒的奖励信号，显著提升TTRL方法的性能。

Abstract: Test-time reinforcement learning (TTRL) enables large language models (LLMs) to self-improve on unlabeled inputs, but its effectiveness critically depends on how reward signals are estimated without ground-truth supervision. Most existing TTRL methods rely on majority voting (MV) over rollouts to produce deterministic rewards, implicitly assuming that the majority rollout provides a reliable learning signal. We show that this assumption is fragile: MV reduces the rollout distribution into a single outcome, discarding information about non-majority but correct actions candidates, and yields systematically biased reward estimates. To address this, we propose Distribution-AwareReward Estimation (DARE), which shifts reward estimation from a single majority outcome to the full empirical rollout distribution. DARE further augments this distribution-based reward with an exploration bonus and a distribution pruning mechanism for non-majority rollout exploration and reward denoise, yielding a more informative and robust reward estimation. Extensive experiments on challenging reasoning benchmarks show that DARE improves optimization stability and final performance over recent baselines, achieving relative improvements of 25.3% on challenging AIME 2024 and 5.3% on AMC.

</details>


### [53] [Mil-SCORE: Benchmarking Long-Context Geospatial Reasoning and Planning in Large Language Models](https://arxiv.org/abs/2601.21826)
*Aadi Palnitkar,Mingyang Mao,Nicholas Waytowich,Vinicius G. Goecks,Tinoosh Mohsenin,Xiaomin Lin*

Main category: cs.CL

TL;DR: MilSCORE是首个基于军事规划场景的多模态长上下文推理基准，用于评估大语言模型在复杂军事规划任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用于更长的复杂任务，需要真实的长上下文基准来评估模型在选择性阅读和整合异构多模态信息方面的能力，特别是在需要快速准确推理地图、命令、情报报告等分布式数据的军事规划问题中。

Method: 创建了MilSCORE基准数据集，包含专家编写的多跳问题，基于用于训练的复杂模拟军事规划场景。设计了七类问题类型，涵盖事实回忆和多步推理，并提供评估协议。

Result: 对一系列当代视觉语言模型进行了基线评估，结果显示当前系统在现实场景级长上下文规划任务上表现不佳，存在显著的改进空间。

Conclusion: MilSCORE为未来工作提供了一个具有挑战性的测试平台，突显了当前系统在现实场景级长上下文规划方面的局限性，并强调了该基准在评估高风险决策和规划能力方面的重要性。

Abstract: As large language models (LLMs) are applied to increasingly longer and more complex tasks, there is a growing need for realistic long-context benchmarks that require selective reading and integration of heterogeneous, multi-modal information sources. This need is especially acute for geospatial planning problems, such as those found in planning for large-scale military operations, which demand fast and accurate reasoning over maps, orders, intelligence reports, and other distributed data. To address this gap, we present MilSCORE (Military Scenario Contextual Reasoning), to our knowledge the first scenario-level dataset of expert-authored, multi-hop questions grounded in a complex, simulated military planning scenario used for training. MilSCORE is designed to evaluate high-stakes decision-making and planning, probing LLMs' ability to combine tactical and spatial reasoning across multiple sources and to reason over long-horizon, geospatially rich context. The benchmark includes a diverse set of question types across seven categories targeting both factual recall and multi-step reasoning about constraints, strategy, and spatial analysis. We provide an evaluation protocol and report baseline results for a range of contemporary vision-language models. Our findings highlight substantial headroom on MilSCORE, indicating that current systems struggle with realistic, scenario-level long-context planning, and positioning MilSCORE as a challenging testbed for future work.

</details>


### [54] [Embodied Task Planning via Graph-Informed Action Generation with Large Lanaguage Model](https://arxiv.org/abs/2601.21841)
*Xiang Li,Ning Yan,Masood Mortazavi*

Main category: cs.CL

TL;DR: GiG框架通过图内图架构和符号化前瞻模块，显著提升具身智能体在长时程规划任务中的性能，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在零样本推理方面表现出色，但作为具身智能体部署时，在长时程规划方面仍面临根本性挑战。标准LLM规划器经常因上下文窗口限制而无法保持策略连贯性，或产生违反约束的幻觉转换。

Method: 提出GiG规划框架，采用图内图架构组织智能体记忆：使用图神经网络编码环境状态为嵌入，构建动作连接的执行轨迹图存储在经验记忆库中。通过聚类图嵌入实现结构感知先验检索，并引入有界前瞻模块利用符号化转换逻辑增强规划能力。

Result: 在三个具身规划基准测试中表现优异：Robotouille同步任务提升22%，异步任务提升37%，ALFWorld提升15%，且计算成本相当或更低。

Conclusion: GiF框架通过结构化记忆组织和符号化前瞻，有效解决了具身智能体在长时程规划中的策略连贯性问题，显著提升了规划性能。

Abstract: While Large Language Models (LLMs) have demonstrated strong zero-shot reasoning capabilities, their deployment as embodied agents still faces fundamental challenges in long-horizon planning. Unlike open-ended text generation, embodied agents must decompose high-level intent into actionable sub-goals while strictly adhering to the logic of a dynamic, observed environment. Standard LLM planners frequently fail to maintain strategy coherence over extended horizons due to context window limitation or hallucinate transitions that violate constraints. We propose GiG, a novel planning framework that structures embodied agents' memory using a Graph-in-Graph architecture. Our approach employs a Graph Neural Network (GNN) to encode environmental states into embeddings, organizing these embeddings into action-connected execution trace graphs within an experience memory bank. By clustering these graph embeddings, the framework enables retrieval of structure-aware priors, allowing agents to ground current decisions in relevant past structural patterns. Furthermore, we introduce a novel bounded lookahead module that leverages symbolic transition logic to enhance the agents' planning capabilities through the grounded action projection. We evaluate our framework on three embodied planning benchmarks-Robotouille Synchronous, Robotouille Asynchronous, and ALFWorld. Our method outperforms state-of-the-art baselines, achieving Pass@1 performance gains of up to 22% on Robotouille Synchronous, 37% on Asynchronous, and 15% on ALFWorld with comparable or lower computational cost.

</details>


### [55] [Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text](https://arxiv.org/abs/2601.21895)
*Hongyi Zhou,Jin Zhu,Erhan Xu,Kai Ye,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 提出一种基于重写的自适应距离学习算法，用于检测LLM生成内容，相比基线方法在多数场景下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型能生成高度拟人文本，引发对虚假信息和学术诚信的担忧，亟需可靠的检测算法。

Method: 首先通过几何方法解析重写检测算法的原理，然后提出自适应学习原始文本与重写文本之间距离的新算法。

Result: 在100多种设置下实验，新方法在多数场景下优于基线算法，对不同目标LLM的相对改进达57.8%至80.6%。

Conclusion: 自适应学习距离函数比固定距离更有效，提出的算法为LLM生成内容检测提供了更优解决方案。

Abstract: Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\% to 80.6\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).

</details>


### [56] [SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching](https://arxiv.org/abs/2601.21927)
*Hong Chen,Xiang Liu,Bo Wang,Yuxuan Fan,Yuanlin Chu,Zongluo Li,Xiaowen Chu,Xuming Hu*

Main category: cs.CL

TL;DR: SONIC是一个基于学习的KV缓存压缩框架，通过将历史对话段压缩为紧凑的Nexus令牌来减少内存占用，在保持对话连贯性的同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 多轮对话中KV缓存的线性增长是LLM部署的主要瓶颈。现有KV缓存压缩方法通常忽略多轮对话的结构特性，依赖启发式淘汰策略，容易丢失关键上下文信息。

Method: 提出SONIC学习框架，将历史对话段压缩为紧凑且语义丰富的Nexus令牌。采用动态预算训练，无需重新训练即可灵活适应不同的内存约束。

Result: 在80%和50%的压缩比下，SONIC在四个多轮对话基准测试中持续优于H2O和StreamingLLM等基线方法。在MTBench101基准测试中，平均得分比最先进基线提升35.55%，推理过程整体加速50.1%。

Conclusion: SONIC通过基于学习的KV缓存压缩有效解决了多轮对话中的内存瓶颈问题，在保持对话连贯性的同时显著提升了部署效率和推理速度。

Abstract: The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \textbf{SONIC}, a learning-based framework that compresses historical segments into compact and semantically rich \textbf{Nexus} tokens. By integrating dynamic budget training, SONIC allows flexible adaptation to varying memory constraints without retraining. Experiments show that at compression ratios of 80\% and 50\%, SONIC consistently outperforms baselines such as H2O and StreamingLLM on four diverse multi-turn benchmarks. Specifically, on the widely used MTBench101 benchmark, SONIC achieves an average score improvement of 35.55\% over state-of-the-art baselines, validating its effectiveness in sustaining coherent multi-turn dialogues. Furthermore, SONIC enhances deployment efficiency, accelerating the overall inference process by 50.1\% compared to full-context generation.

</details>


### [57] [From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes](https://arxiv.org/abs/2601.21955)
*Fariba Afrin Irany*

Main category: cs.CL

TL;DR: 提出基于GPT的选择性微调架构，用于临床文本分类，通过冻结大部分参数仅训练最后一层，在计算效率和分类性能间取得平衡


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中非结构化临床叙述日益增多，为疾病表征、队列识别和临床决策支持提供了新机会。但长领域特定临床文本建模面临标注数据有限、类别严重不平衡以及大型预训练模型适应计算成本高的挑战

Method: 采用GPT-based架构进行临床文本分类，使用选择性微调策略：冻结GPT-2主干的大部分参数，仅训练最后的Transformer块、最后一层归一化层和轻量级分类头，显著减少可训练参数数量

Result: 在MIMIC-IV-Note数据集的放射学报告上进行评估，使用不确定性感知的CheXpert风格标签。模型在不同数据集规模下表现出稳定的收敛行为和强大的分类性能，特别是在非提及和否定发现占主导的场景中表现优异

Conclusion: 选择性微调预训练生成语言模型为临床文本分类提供了高效有效的途径，能够在显著降低计算复杂度的同时实现对真实世界电子健康记录数据的可扩展适应

Abstract: The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.

</details>


### [58] [OVD: On-policy Verbal Distillation](https://arxiv.org/abs/2601.21968)
*Jing Xiong,Hui Shen,Shansan Gong,Yuxin Cheng,Jianghan Shen,Chaofan Tao,Haochen Tan,Haoli Bai,Lifeng Shang,Ngai Wong*

Main category: cs.CL

TL;DR: OVD提出了一种基于轨迹匹配的在线知识蒸馏框架，用离散语言评分替代token级概率匹配，显著降低内存消耗，提升学生模型性能


<details>
  <summary>Details</summary>
Motivation: 现有token级在线蒸馏方法需要学生模型与教师模型token级对齐，限制了学生模型的探索能力，无法有效利用交互环境反馈，且在强化学习中存在严重内存瓶颈

Method: 提出在线语言蒸馏(OVD)框架，用离散语言评分(0-9)的轨迹匹配替代token级概率匹配，避免token级对齐，允许学生模型自由探索输出空间

Result: 在Web问答和数学推理任务上显著优于现有方法，Web Q&A任务平均EM提升高达12.9%，数学基准提升高达25.7%(仅使用一个随机样本训练)，同时训练效率更高

Conclusion: OVD通过轨迹匹配和离散语言评分有效解决了token级在线蒸馏的内存瓶颈和探索限制问题，为知识蒸馏提供了更高效灵活的框架

Abstract: Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io

</details>


### [59] [Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding](https://arxiv.org/abs/2601.21969)
*Yifan Zhu,Huiqiang Rong,Haoran Luo*

Main category: cs.CL

TL;DR: Token-Guard：基于自检解码的token级幻觉控制方法，通过内部验证、潜在空间评估和迭代修剪来减少LLM幻觉


<details>
  <summary>Details</summary>
Motivation: LLM经常产生幻觉内容，现有方法如RAG和RLHF需要大量资源，而基于解码的方法缺乏明确的幻觉控制机制

Method: 提出Token-Guard方法：1) 在推理步骤进行内部验证检测幻觉token；2) 在潜在空间对候选片段进行显式幻觉风险评分；3) 迭代修剪和重新生成动态纠正错误

Result: 在HALU数据集上的实验显示，Token-Guard显著减少了幻觉并提高了生成准确性

Conclusion: Token-Guard提供了一个可扩展、模块化的解决方案，用于实现可靠的LLM输出，代码已公开

Abstract: Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.

</details>


### [60] [Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units](https://arxiv.org/abs/2601.21996)
*Jianhui Chen,Yuzhang Luo,Liangming Pan*

Main category: cs.CL

TL;DR: MDA框架利用影响函数将可解释电路追溯到训练数据，通过干预高影响力样本验证了数据对可解释头形成的因果作用，发现重复结构数据是机制催化剂，并建立了归纳头与上下文学习的功能联系。


<details>
  <summary>Details</summary>
Motivation: 尽管机制可解释性已在LLMs中识别出可解释电路，但这些电路在训练数据中的因果起源仍然不清楚。需要建立可扩展的框架来追溯可解释单元到具体训练样本。

Method: 提出机制数据归因（MDA）框架，使用影响函数将可解释单元追溯到特定训练样本。在Pythia模型家族上进行实验，通过移除或增强高影响力样本进行针对性干预，并与随机干预对比。

Result: 针对性干预显著调节可解释头的出现，而随机干预无效。重复结构数据（如LaTeX、XML）作为机制催化剂。干预归纳头形成会同时改变模型的上下文学习能力，为归纳头与ICL的功能联系提供了直接因果证据。

Conclusion: 提出的机制数据增强流程能一致加速不同规模模型的电路收敛，为引导LLMs发展轨迹提供了原则性方法。MDA框架揭示了训练数据在形成可解释机制中的因果作用。

Abstract: While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.

</details>


### [61] [When "Better" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications](https://arxiv.org/abs/2601.22025)
*Daniel Commey*

Main category: cs.CL

TL;DR: 论文提出了一种针对LLM应用的评估驱动工作流程（定义、测试、诊断、修复），并引入了最小可行评估套件（MVES），通过实验展示了通用提示模板可能在不同任务表现间产生权衡，强调了评估驱动迭代的重要性。


<details>
  <summary>Details</summary>
Motivation: LLM应用评估与传统软件测试不同，因为输出具有随机性、高维性且对提示和模型变化敏感。需要一种系统化的评估方法来应对这些挑战，将评估转化为可重复的工程循环。

Method: 提出了评估驱动的工作流程（定义、测试、诊断、修复），引入了最小可行评估套件（MVES），包含通用LLM应用、RAG和智能体工具使用工作流的层级评估组件。综合了自动检查、人工评估和LLM作为评判者等方法，并讨论了评判者失败模式。通过可复现实验（使用Ollama、Llama 3 8B Instruct和Qwen 2.5 7B Instruct）验证方法。

Result: 实验发现通用"改进"提示模板会在不同行为间产生权衡：在小型结构化测试套件中，当用通用规则替换任务特定提示时，Llama 3的提取通过率从100%降至90%，RAG合规性从93.3%降至80%，但指令遵循能力有所提升。这些发现表明需要评估驱动的提示迭代和谨慎的声明校准。

Conclusion: 评估驱动的提示迭代比通用提示配方更重要。需要系统化的评估工作流程来管理LLM应用的复杂性，MVES提供了实用的评估框架。所有测试套件、工具和结果都已开源以确保可复现性。

Abstract: Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.
  We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.
  In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic "improved" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.
  All test suites, harnesses, and results are included for reproducibility.

</details>


### [62] [Causal Autoregressive Diffusion Language Model](https://arxiv.org/abs/2601.22031)
*Junhao Ruan,Bei Li,Yongjing Yin,Pengcheng Huang,Xin Chen,Jingang Wang,Xunliang Cai,Tong Xiao,JingBo Zhu*

Main category: cs.CL

TL;DR: CARD是一种结合自回归模型训练效率和扩散模型高吞吐推理的新框架，通过因果注意力掩码实现单次前向传播的密集监督，支持动态并行解码，训练延迟比块扩散方法降低3倍。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练效率和推理吞吐量之间存在权衡：自回归模型（ARMs）训练高效但推理慢，扩散模型推理快但训练成本高。需要一种能同时获得两者优势的框架。

Method: 提出Causal Autoregressive Diffusion (CARD)框架：1) 在严格因果注意力掩码下重新表述扩散过程，实现单次前向传播的密集监督；2) 引入软尾掩码模式保留局部上下文；3) 基于信噪比原理设计上下文感知重加权机制；4) 利用KV缓存实现自适应可变长度序列的动态并行解码。

Result: CARD在性能上优于现有离散扩散基线，训练延迟比块扩散方法降低3倍，实现了ARM级别的数据效率，同时获得了并行生成的延迟优势。

Conclusion: CARD建立了一个强大的下一代高效LLM范式，成功统一了自回归模型的训练效率和扩散模型的并行推理优势，为高效语言模型提供了新的解决方案。

Abstract: In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervision in a single forward pass. To address the optimization instability of causal diffusion, we introduce a soft-tailed masking schema to preserve local context and a context-aware reweighting mechanism derived from signal-to-noise principles. This design enables dynamic parallel decoding, where the model leverages KV-caching to adaptively generate variable-length token sequences based on confidence. Empirically, CARD outperforms existing discrete diffusion baselines while reducing training latency by 3 $\times$ compared to block diffusion methods. Our results demonstrate that CARD achieves ARM-level data efficiency while unlocking the latency benefits of parallel generation, establishing a robust paradigm for next-generation efficient LLMs.

</details>


### [63] [Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models](https://arxiv.org/abs/2601.22035)
*Longxuan Yu,Yu Fu,Shaorong Zhang,Hui Liu,Mukund Varma T,Greg Ver Steeg,Yue Dong*

Main category: cs.CL

TL;DR: MDLM模型在输出顺序与自然推理不一致时（如先答案后推理）比AR模型更稳健，能保持性能稳定，而AR模型性能大幅下降。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型强制左到右生成顺序，当输出结构要求与自然推理顺序冲突时（如先输出答案后推理），模型必须过早提交答案，导致性能下降。需要研究能解耦计算顺序与输出结构的模型。

Method: 使用掩码扩散语言模型（MDLM），它能并行迭代优化所有token，解耦计算顺序与输出结构。在GSM8K、Math500和自建的ReasonOrderQA基准上测试，比较AR模型与MDLM在不同输出顺序下的表现。

Result: 当提示要求先答案后推理时，AR模型相比标准推理顺序准确率大幅下降（相对下降达67%），而MDLM保持稳定（相对下降≤14%）。MDLM通过让简单token（推理步骤）在扩散过程中比复杂token（最终答案）更早稳定，实现顺序稳健性。

Conclusion: MDLM在输出顺序与自然推理不一致时具有"顺序稳健性"，能保持性能稳定。研究还识别了这种优势减弱的失败条件，界定了顺序稳健性的限制。

Abstract: Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\leq$14% relative drop), a property we term "order robustness". Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.

</details>


### [64] [A Separable Architecture for Continuous Token Representation in Language Models](https://arxiv.org/abs/2601.22040)
*Reza T. Batley,Sourav Saha*

Main category: cs.CL

TL;DR: Leviathan架构用连续嵌入生成器替代传统离散查找表，在小语言模型中显著提升参数效率，表现相当于参数增加1.47-2.11倍


<details>
  <summary>Details</summary>
Motivation: 传统Transformer缩放定律将参数视为可互换的，但在十亿参数以下的小语言模型中，嵌入矩阵占据了大部分参数预算，这种分配既次优又违反直觉

Method: 提出Leviathan架构，使用连续嵌入生成器替代传统的离散查找表，在等参数设置下与标准LLaMA风格架构进行比较

Result: 在Pile数据集上，Leviathan始终优于标准架构，经验幂律拟合显示其具有显著优越的有效参数容量，表现相当于参数增加1.47-2.11倍

Conclusion: 通过用连续嵌入生成器替代离散查找表，Leviathan架构在小语言模型中实现了更优的参数分配，显著提升了模型的有效容量和性能

Abstract: Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \times$ more parameters.

</details>


### [65] [On the Paradoxical Interference between Instruction-Following and Task Solving](https://arxiv.org/abs/2601.22047)
*Yunjia Qi,Hao Peng,Xintong Shi,Amy Xin,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 论文揭示指令跟随可能干扰LLMs任务解决能力，提出SUSTAINSCORE量化这种干扰，实验显示添加自明约束会导致性能显著下降


<details>
  <summary>Details</summary>
Motivation: 指令跟随旨在让LLMs与人类意图对齐，但研究发现指令跟随可能反而干扰模型的任务解决能力，需要量化这种干扰现象

Method: 提出SUSTAINSCORE指标，在指令中插入自明约束（从原始成功输出中提取的自然满足的约束），测量任务性能下降；在数学、多跳QA和代码生成任务上测试当前LLMs；分析失败模式并研究干扰机制

Result: 添加自明约束导致性能显著下降，即使是Claude-Sonnet-4.5等先进模型也受影响；干扰在不同约束类型和规模上具有普遍性；失败案例对约束分配更多注意力；不同后训练范式对干扰影响不同

Conclusion: 指令跟随可能干扰LLMs任务解决能力，SUSTAINSCORE能有效量化这种干扰，为当前对齐策略提供实证观察，促进进一步研究

Abstract: Instruction following aims to align Large Language Models (LLMs) with human intent by specifying explicit constraints on how tasks should be performed. However, we reveal a counterintuitive phenomenon: instruction following can paradoxically interfere with LLMs' task-solving capability. We propose a metric, SUSTAINSCORE, to quantify the interference of instruction following with task solving. It measures task performance drop after inserting into the instruction a self-evident constraint, which is naturally met by the original successful model output and extracted from it. Experiments on current LLMs in mathematics, multi-hop QA, and code generation show that adding the self-evident constraints leads to substantial performance drops, even for advanced models such as Claude-Sonnet-4.5. We validate the generality of the interference across constraint types and scales. Furthermore, we identify common failure patterns, and by investigating the mechanisms of interference, we observe that failed cases allocate significantly more attention to constraints compared to successful ones. Finally, we use SUSTAINSCORE to conduct an initial investigation into how distinct post-training paradigms affect the interference, presenting empirical observations on current alignment strategies. We will release our code and data to facilitate further research

</details>


### [66] [MasalBench: A Benchmark for Contextual and Cross-Cultural Understanding of Persian Proverbs in LLMs](https://arxiv.org/abs/2601.22050)
*Ghazal Kalhor,Behnam Bahrak*

Main category: cs.CL

TL;DR: MasalBench是一个评估LLMs对波斯谚语上下文理解和跨文化理解的基准测试，发现LLMs在识别波斯谚语方面表现良好（准确率>0.90），但在识别等效英语谚语方面表现较差（最佳模型0.79准确率），揭示了LLMs在文化知识和类比推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在日常生活中变得越来越重要，需要掌握对话语言规则以有效与用户沟通。虽然之前的研究评估了LLMs对高资源语言中比喻语言的理解，但它们在低资源语言中的表现仍然未被充分探索。波斯语作为一种低资源语言，其谚语是对话的关键组成部分，需要专门评估。

Method: 研究者开发了MasalBench，一个全面的基准测试，用于评估LLMs对波斯谚语的上下文和跨文化理解。该基准测试了八个最先进的LLMs，包括识别波斯谚语在上下文中的能力，以及识别等效英语谚语的能力。

Result: LLMs在识别上下文中的波斯谚语方面表现良好，准确率超过0.90。但在识别等效英语谚语方面表现显著下降，最佳模型仅达到0.79准确率。这表明当前LLMs在文化知识和类比推理方面存在局限性。

Conclusion: 研究强调了当前LLMs在跨文化理解和类比推理方面的不足，特别是对于低资源语言。MasalBench为评估其他低资源语言的跨文化理解提供了一个框架，有助于改进LLMs的文化适应能力。

Abstract: In recent years, multilingual Large Language Models (LLMs) have become an inseparable part of daily life, making it crucial for them to master the rules of conversational language in order to communicate effectively with users. While previous work has evaluated LLMs' understanding of figurative language in high-resource languages, their performance in low-resource languages remains underexplored. In this paper, we introduce MasalBench, a comprehensive benchmark for assessing LLMs' contextual and cross-cultural understanding of Persian proverbs, which are a key component of conversation in this low-resource language. We evaluate eight state-of-the-art LLMs on MasalBench and find that they perform well in identifying Persian proverbs in context, achieving accuracies above 0.90. However, their performance drops considerably when tasked with identifying equivalent English proverbs, with the best model achieving 0.79 accuracy. Our findings highlight the limitations of current LLMs in cultural knowledge and analogical reasoning, and they provide a framework for assessing cross-cultural understanding in other low-resource languages. MasalBench is available at https://github.com/kalhorghazal/MasalBench.

</details>


### [67] [$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA](https://arxiv.org/abs/2601.22055)
*Yaxin Du,Junru Song,Yifan Zhou,Cheng Wang,Jiahao Gu,Zimeng Chen,Menglan Chen,Wen Yao,Yang Yang,Ying Wen,Siheng Chen*

Main category: cs.CL

TL;DR: G²-Reader：一种双图系统，通过内容图和规划图解决多模态文档问答中的结构保持和检索导航问题，在VisDoMBench上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在多模态长文档问答中存在两个主要问题：1）平面分块破坏了文档原生结构和跨模态对齐，导致语义片段难以独立理解；2）迭代检索在长上下文中容易陷入局部证据循环或漂移到无关部分，缺乏全局搜索状态跟踪。

Method: 提出G²-Reader双图系统：1）内容图用于保持文档原生结构和跨模态语义；2）规划图作为子问题的有向无环图，跟踪中间发现并指导逐步导航以完成证据收集。

Result: 在VisDoMBench的五个多模态领域上，G²-Reader配合Qwen3-VL-32B-Instruct达到66.21%的平均准确率，显著优于强基线方法和独立的GPT-5（53.08%）。

Conclusion: G²-Reader通过双图架构有效解决了多模态长文档问答中的结构保持和检索导航问题，为跨模态信息整合提供了系统性的解决方案。

Abstract: Retrieval-augmented generation is a practical paradigm for question answering over long documents, but it remains brittle for multimodal reading where text, tables, and figures are interleaved across many pages. First, flat chunking breaks document-native structure and cross-modal alignment, yielding semantic fragments that are hard to interpret in isolation. Second, even iterative retrieval can fail in long contexts by looping on partial evidence or drifting into irrelevant sections as noise accumulates, since each step is guided only by the current snippet without a persistent global search state. We introduce $G^2$-Reader, a dual-graph system, to address both issues. It evolves a Content Graph to preserve document-native structure and cross-modal semantics, and maintains a Planning Graph, an agentic directed acyclic graph of sub-questions, to track intermediate findings and guide stepwise navigation for evidence completion. On VisDoMBench across five multimodal domains, $G^2$-Reader with Qwen3-VL-32B-Instruct reaches 66.21\% average accuracy, outperforming strong baselines and a standalone GPT-5 (53.08\%).

</details>


### [68] [VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning](https://arxiv.org/abs/2601.22069)
*Yibo Wang,Yongcheng Jing,Shunyu Liu,Hao Guan,Rong-cheng Tu,Chengyu Wang,Jun Huang,Dacheng Tao*

Main category: cs.CL

TL;DR: VTC-R1是一种新的高效推理范式，通过将中间推理段渲染为紧凑图像作为"光学记忆"，实现3.4倍token压缩和2.7倍推理加速，在多个数学推理基准上优于标准长上下文推理。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理虽然增强了LLM处理复杂任务的能力，但带来了严重的效率瓶颈。现有方法通常需要复杂的额外训练或依赖外部模型进行压缩，这限制了可扩展性并丢弃了关键的细粒度信息。

Method: 提出VTC-R1范式，将视觉-文本压缩集成到推理过程中。将中间推理段渲染为紧凑图像，作为"光学记忆"迭代反馈给视觉语言模型。基于OpenR1-Math-220K构建训练数据集，并对Glyph和Qwen3-VL等代表性VLM进行微调。

Result: 实现了3.4倍的token压缩，在MATH500、AIME25、AMC23和GPQA-D等基准测试中持续优于标准长上下文推理。推理效率显著提升，端到端延迟实现了2.7倍加速。

Conclusion: VTC-R1通过视觉-文本压缩范式有效解决了长上下文推理的效率瓶颈，在保持性能的同时大幅提升推理速度，为推理密集型应用提供了可扩展的解决方案。

Abstract: Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as "optical memory." We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.

</details>


### [69] [ECO: Quantized Training without Full-Precision Master Weights](https://arxiv.org/abs/2601.22101)
*Mahdi Nikdan,Amir Zandieh,Dan Alistarh,Vahab Mirrokni*

Main category: cs.CL

TL;DR: ECO优化器通过消除主权重缓冲区，直接将更新应用到量化参数，显著减少内存占用，特别是对于稀疏混合专家模型。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法仍需在训练过程中维护高精度主权重缓冲区，这带来了显著的内存开销，特别是在稀疏混合专家模型中，模型参数和优化器状态占据了大部分内存使用。

Method: ECO优化器在每一步后量化权重，并将量化误差精心注入优化器动量中，形成一个无需额外内存的误差反馈循环，从而消除主权重缓冲区。

Result: ECO在理论证明上能收敛到最优解的常数半径邻域内，而简单移除主权重会导致与学习率成反比的误差。实验表明ECO在FP8量化的30-800M Transformer、Gemma-3 1B模型、2.1B参数稀疏MoE模型以及INT4精度的DeepSeek-MoE-16B微调中，都能达到接近无损的精度。

Conclusion: ECO优化器通过消除主权重缓冲区，显著改善了静态内存与验证损失的帕累托前沿，为大规模语言模型训练提供了更高效的内存优化方案。

Abstract: Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.

</details>


### [70] [A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine](https://arxiv.org/abs/2601.22124)
*Anran Li,Yuanyuan Chen,Wenjun Long,Yu Yin,Yan Hu,Hyunjae Kim,Weipeng Zhou,Yujia Zhou,Hongyi Peng,Yang Ren,Xuguang Ai,Zhenyue Qin,Ming Hu,Xiaoxiao Li,Han Yu,Yih-Chung Tham,Lucila Ohno-Machado,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: 提出Fed-MedLoRA框架，通过联邦学习高效适配医学LLM，解决通信开销和数据异构问题，在临床信息抽取任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 医学LLM通常基于单一机构数据训练，存在泛化性和安全性限制。联邦学习虽可实现跨机构协作，但传统FL方法对大规模LLM通信开销大，且假设数据同质，而真实临床数据高度异构。

Method: 提出Fed-MedLoRA框架：1) 仅传输低秩适配器参数，减少通信计算开销；2) Fed-MedLoRA+进一步引入自适应、数据感知的聚合策略，提升异构数据下的收敛性能。应用于临床信息抽取任务。

Result: 在五个患者队列中评估，与BERT、LLaMA-3、DeepSeek-R1、GPT-4o等模型比较。评估设置包括：1) 域内训练测试；2) 独立队列外部验证；3) 低资源新站点适应场景（使用耶鲁纽黑文医疗系统真实临床记录）。

Conclusion: Fed-MedLoRA框架能有效解决医学LLM联邦学习中的通信开销和数据异构问题，为跨机构协作的临床AI应用提供可行方案。

Abstract: Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical LLMs are trained on data from a single institution, which faces limitations in generalizability and safety in heterogeneous systems. Federated learning (FL) is a promising solution for enabling collaborative model development across healthcare institutions. Yet applying FL to LLMs in medicine remains fundamentally limited. First, conventional FL requires transmitting the full model during each communication round, which becomes impractical for multi-billion-parameter LLMs given the limited computational resources. Second, many FL algorithms implicitly assume data homogeneity, whereas real-world clinical data are highly heterogeneous across patients, diseases, and institutional practices. We introduce the model-agnostic and parameter-efficient federated learning framework for adapting LLMs to medical applications. Fed-MedLoRA transmits only low-rank adapter parameters, reducing communication and computation overhead, while Fed-MedLoRA+ further incorporates adaptive, data-aware aggregation to improve convergence under cross-site heterogeneity. We apply the framework to clinical information extraction (IE), which transforms patient narratives into structured medical entities and relations. Accuracy was assessed across five patient cohorts through comparisons with BERT models, and LLaMA-3 and DeepSeek-R1, GPT-4o models. Evaluation settings included (1) in-domain training and testing, (2) external validation on independent cohorts, and (3) a low-resource new-site adaptation scenario using real-world clinical notes from the Yale New Haven Health System.

</details>


### [71] [Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers](https://arxiv.org/abs/2601.22139)
*Xin Chen,Feng Jiang,Yiqian Zhang,Hardy Chen,Shuo Yan,Wenya Xie,Min Yang,Shujian Huang*

Main category: cs.CL

TL;DR: PIR是一种新的推理范式，让LLM从被动思考转变为主动询问，通过用户交互解决前提和意图层面的不确定性，显著提升推理性能并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有CoT推理的LLM存在"盲目自我思考"的局限，当关键信息缺失或模糊时仍进行大量内部推理。需要一种能主动与用户交互澄清前提和意图的新范式。

Method: 提出PIR框架，包含两个核心组件：1) 不确定性感知的监督微调，赋予模型交互推理能力；2) 基于用户模拟器的策略优化框架，使用复合奖励对齐用户意图。

Result: 在数学推理、代码生成和文档编辑任务上，PIR显著优于基线方法，准确率提升32.70%，通过率提升22.90%，BLEU提升41.36，同时减少近一半推理计算和不必要交互轮次。

Conclusion: PIR成功将LLM从被动求解器转变为主动询问者，有效解决前提和意图不确定性，在多个领域展现出强大的泛化能力和鲁棒性，为交互式推理开辟了新方向。

Abstract: Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\% higher accuracy, 22.90\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}

</details>


### [72] [FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale](https://arxiv.org/abs/2601.22146)
*Ajay Patel,Colin Raffel,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 提出FineInstructions方法，将互联网规模的预训练文档转化为数十亿个合成指令-答案训练对，使LLM可以从头开始仅使用指令调优目标进行预训练


<details>
  <summary>Details</summary>
Motivation: 由于监督训练数据有限，LLM通常通过自监督的"预测下一个词"目标在大量无结构文本数据上进行预训练。为了让模型对用户有用，还需要在较少的"指令调优"数据上进行进一步训练。需要克服监督数据有限的问题。

Method: 提出FineInstructions方法：使用约1800万个从真实用户查询和提示创建的指令模板，将这些模板与无结构预训练语料库中的人工编写源文档匹配并实例化，生成大规模的合成指令-答案训练对。

Result: 在FineInstructions上进行预训练优于标准预训练和其他提出的合成预训练技术，在衡量自由形式响应质量的标准基准测试中表现更好。

Conclusion: 通过将预训练文档知识转化为大规模合成指令数据，可以使LLM仅使用指令调优目标从头开始预训练，这更符合LLM预期下游使用场景（响应用户提示）。

Abstract: Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised "predict the next word" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of "instruction-tuning" data comprised of supervised training examples of instructions and responses. To overcome the limited amount of supervised data, we propose a procedure that can transform the knowledge in internet-scale pre-training documents into billions of synthetic instruction and answer training pairs. The resulting dataset, called FineInstructions, uses ~18M instruction templates created from real user-written queries and prompts. These instruction templates are matched to and instantiated with human-written source documents from unstructured pre-training corpora. With "supervised" synthetic training data generated at this scale, an LLM can be pre-trained from scratch solely with the instruction-tuning objective, which is far more in-distribution with the expected downstream usage of LLMs (responding to user prompts). We conduct controlled token-for-token training experiments and find pre-training on FineInstructions outperforms standard pre-training and other proposed synthetic pre-training techniques on standard benchmarks measuring free-form response quality. Our resources can be found at https://huggingface.co/fineinstructions .

</details>


### [73] [DynaWeb: Model-Based Reinforcement Learning of Web Agents](https://arxiv.org/abs/2601.22149)
*Hang Ding,Peidong Liu,Junqiao Wang,Ziwei Ji,Meng Cao,Rongzhao Zhang,Lynn Ai,Eric Yang,Tianyu Shi,Lei Yu*

Main category: cs.CL

TL;DR: DynaWeb是一个基于模型强化学习（MBRL）的框架，通过训练网页世界模型来预测网页表示，使网络代理能在模拟环境中进行高效训练，显著提升了在WebArena和WebVoyager基准测试上的性能。


<details>
  <summary>Details</summary>
Motivation: 训练自主网络代理面临与实时互联网交互的低效、昂贵和风险问题。基于模型的强化学习（MBRL）通过学习环境的世界模型来实现模拟交互，为解决这些问题提供了有前景的方案。

Method: DynaWeb框架训练一个网页世界模型来预测给定代理动作后的自然化网页表示。该模型作为合成网页环境，代理策略可以在此环境中通过生成大量轨迹进行高效在线强化学习。同时，框架将真实专家轨迹与策略轨迹随机交错训练，提高稳定性和样本效率。

Result: 在具有挑战性的WebArena和WebVoyager基准测试中，DynaWeb一致且显著地提升了最先进的开源网络代理模型的性能，证明了通过想象训练网络代理的可行性。

Conclusion: DynaWeb为网络代理训练提供了可扩展且高效的方法，通过基于模型的强化学习框架，使代理能在模拟网页环境中进行想象训练，克服了实时互联网交互的限制，推动了在线代理强化学习的规模化发展。

Abstract: The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.

</details>


### [74] [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](https://arxiv.org/abs/2601.22156)
*Yingfa Chen,Zhen Leng Thai,Zihan Zhou,Zhu Zhang,Xingyu Shen,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: HALO方法将Transformer蒸馏为RNN-注意力混合模型，HypeNet架构通过HyPE位置编码实现优异长度泛化，仅需2.3B tokens即可将Qwen3转换为性能相当但长上下文效率更高的混合模型


<details>
  <summary>Details</summary>
Motivation: 现有混合Transformer架构（结合softmax注意力块和RNN）在长上下文建模中展现出良好的性能-吞吐量权衡，但大规模从头预训练成本过高。现有转换方法需要大量训练数据（超过100亿tokens），且生成的混合模型在长上下文场景中表现不佳，而这正是混合模型相比Transformer具有显著推理加速优势的场景

Method: 提出HALO（Hybrid Attention via Layer Optimization）管道，用于将Transformer模型蒸馏为RNN-注意力混合模型。提出HypeNet混合架构，采用新型位置编码方案HyPE和各种架构修改，实现优异的长度泛化能力。使用HALO将Qwen3系列转换为HypeNet

Result: 转换后的HypeNet模型性能与原始Transformer模型相当，同时展现出优异的长上下文性能和效率。转换过程仅需23亿tokens，不到其预训练数据的0.01%

Conclusion: HALO和HypeNet提供了一种高效的方法，能够以极低的训练成本将预训练Transformer转换为性能相当但长上下文效率更高的混合模型，解决了现有转换方法需要大量数据和长上下文性能差的问题

Abstract: Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [75] [Quick Heuristic Validation of Edges in Dynamic Roadmap Graphs](https://arxiv.org/abs/2601.20968)
*Yulie Arad,Stav Ashur,Nancy M. Amato*

Main category: cs.RO

TL;DR: 提出Red-Green-Gray范式改进SPITE方法，通过廉价启发式检查快速更新机器人运动规划路线图，适应非静态环境


<details>
  <summary>Details</summary>
Motivation: 解决机器人运动规划中路线图对非静态环境的适应性问题，传统方法在动态环境中更新效率低

Method: 基于SPITE方法改进，引入红-绿-灰分类范式，使用简单计算几何方法近似机器人扫掠体积，进行懒惰碰撞检查，将边标记为无效(红)、有效(绿)或未知(灰)

Result: 相比Leven和Hutchinson的成熟技术，本方法提高了准确性，能正确标记无效边，同时保持可比的更新运行时间

Conclusion: Red-Green-Gray范式能有效处理非静态环境中的机器人运动规划，通过快速半懒惰路线图更新提高规划效率

Abstract: In this paper we tackle the problem of adjusting roadmap graphs for robot motion planning to non-static environments. We introduce the "Red-Green-Gray" paradigm, a modification of the SPITE method, capable of classifying the validity status of nodes and edges using cheap heuristic checks, allowing fast semi-lazy roadmap updates. Given a roadmap, we use simple computational geometry methods to approximate the swept volumes of robots and perform lazy collision checks, and label a subset of the edges as invalid (red), valid (green), or unknown (gray). We present preliminary experimental results comparing our method to the well-established technique of Leven and Hutchinson, and showing increased accuracy as well as the ability to correctly label edges as invalid while maintaining comparable update runtimes.

</details>


### [76] [Meta-ROS: A Next-Generation Middleware Architecture for Adaptive and Scalable Robotic Systems](https://arxiv.org/abs/2601.21011)
*Anshul Ranjan,Anoosh Damodar,Neha Chougule,Dhruva S Nayak,Anantharaman P. N,Shylaja S S*

Main category: cs.RO

TL;DR: Meta-ROS是一个新型机器人中间件，旨在解决ROS2等现有框架的复杂性和互操作性问题，通过简化集成、提升性能、确保跨平台兼容性，为现代实时机器人AI应用提供理想解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器人领域面临现有中间件框架（如ROS2）复杂性和互操作性挑战，这些框架对新开发者难以采用，需要更简单、高效、兼容的解决方案。

Method: 提出Meta-ROS中间件，利用现代通信协议（如Zenoh和ZeroMQ）实现高效低延迟通信，支持多种数据类型（音频、图像、视频），并采用开发者中心设计。

Result: Meta-ROS性能优于ROS2，吞吐量提升高达30%，显著降低消息延迟，优化资源使用，同时具备强大的硬件支持和易用性。

Conclusion: Meta-ROS通过简化集成、提升性能和确保跨平台兼容性，成为现代实时机器人AI应用的理想中间件解决方案。

Abstract: The field of robotics faces significant challenges related to the complexity and interoperability of existing middleware frameworks, like ROS2, which can be difficult for new developers to adopt. To address these issues, we propose Meta-ROS, a novel middleware solution designed to streamline robotics development by simplifying integration, enhancing performance, and ensuring cross-platform compatibility. Meta-ROS leverages modern communication protocols, such as Zenoh and ZeroMQ, to enable efficient and low-latency communication across diverse hardware platforms, while also supporting various data types like audio, images, and video. We evaluated Meta-ROS's performance through comprehensive testing, comparing it with existing middleware frameworks like ROS1 and ROS2. The results demonstrated that Meta-ROS outperforms ROS2, achieving up to 30% higher throughput, significantly reducing message latency, and optimizing resource usage. Additionally, its robust hardware support and developer-centric design facilitate seamless integration and ease of use, positioning Meta-ROS as an ideal solution for modern, real-time robotics AI applications.

</details>


### [77] [Track-centric Iterative Learning for Global Trajectory Optimization in Autonomous Racing](https://arxiv.org/abs/2601.21027)
*Youngim Nam,Jungbin Kim,Kyungtae Kang,Cheolhyeon Kwon*

Main category: cs.RO

TL;DR: 提出一个用于自动驾驶赛车轨迹优化的全局框架，通过贝叶斯优化在参数空间中探索全时域轨迹，结合迭代学习动态模型来最小化圈时。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在跟踪层面学习动态模型，而不更新轨迹本身以适应学习到的动态特性。全局轨迹优化计算成本高，且由于动态不确定性，在现实世界中难以保证全局最优性。

Method: 1) 使用小波变换将轨迹表示为赛道无关的参数空间；2) 采用贝叶斯优化高效探索该空间，通过仿真评估候选轨迹的圈时；3) 将优化嵌入迭代学习框架，用优化轨迹收集真实数据更新动态模型，逐步精炼轨迹。

Result: 通过仿真和真实实验验证了框架有效性，相比基准方法圈时提升最高达20.7%，并持续优于现有最先进方法。

Conclusion: 提出的赛道中心方法能够直接学习和优化全时域轨迹，通过迭代学习动态模型和轨迹优化，在不确定动态条件下有效提升自动驾驶赛车性能。

Abstract: This paper presents a global trajectory optimization framework for minimizing lap time in autonomous racing under uncertain vehicle dynamics. Optimizing the trajectory over the full racing horizon is computationally expensive, and tracking such a trajectory in the real world hardly assures global optimality due to uncertain dynamics. Yet, existing work mostly focuses on dynamics learning at the tracking level, without updating the trajectory itself to account for the learned dynamics. To address these challenges, we propose a track-centric approach that directly learns and optimizes the full-horizon trajectory. We first represent trajectories through a track-agnostic parametric space in light of the wavelet transform. This space is then efficiently explored using Bayesian optimization, where the lap time of each candidate is evaluated by running simulations with the learned dynamics. This optimization is embedded in an iterative learning framework, where the optimized trajectory is deployed to collect real-world data for updating the dynamics, progressively refining the trajectory over the iterations. The effectiveness of the proposed framework is validated through simulations and real-world experiments, demonstrating lap time improvement of up to 20.7% over a nominal baseline and consistently outperforming state-of-the-art methods.

</details>


### [78] [Multi-Robot Decentralized Collaborative SLAM in Planetary Analogue Environments: Dataset, Challenges, and Lessons Learned](https://arxiv.org/abs/2601.21063)
*Pierre-Yves Lajoie,Karthik Soma,Haechan Mark Bong,Alice Lemieux-Bourque,Rongge Zhang,Vivek Shankar Varadharajan,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 本文分享了在火星模拟地形上进行的去中心化协作SLAM实验经验，分析了受限通信对性能的影响，并发布了包含实时机器人间通信测量的新数据集。


<details>
  <summary>Details</summary>
Motivation: 去中心化协作SLAM对于多机器人任务在未知环境中的执行至关重要，特别是在月球、火星等行星探索中。需要研究受限通信环境下的实际挑战。

Method: 在火星模拟地形上进行三机器人实验，使用自组织网络通信，分析间歇性和受限通信对C-SLAM性能的影响，并收集实时点对点通信吞吐量和延迟数据。

Result: 获得了关于受限通信对协作SLAM性能影响的实际见解，识别了行星环境中独特的定位挑战，并创建了包含实时机器人间通信测量的新数据集。

Conclusion: 去中心化C-SLAM在行星探索中具有关键作用，受限通信是主要挑战。发布的通信数据集将支持未来通信受限环境下的多机器人系统研究。

Abstract: Decentralized collaborative simultaneous localization and mapping (C-SLAM) is essential to enable multirobot missions in unknown environments without relying on preexisting localization and communication infrastructure. This technology is anticipated to play a key role in the exploration of the Moon, Mars, and other planets. In this article, we share insights and lessons learned from C-SLAM experiments involving three robots operating on a Mars analogue terrain and communicating over an ad hoc network. We examine the impact of limited and intermittent communication on C-SLAM performance, as well as the unique localization challenges posed by planetary-like environments. Additionally, we introduce a novel dataset collected during our experiments, which includes real-time peer-to-peer inter-robot throughput and latency measurements. This dataset aims to support future research on communication-constrained, decentralized multirobot operations.

</details>


### [79] [WheelArm-Sim: A Manipulation and Navigation Combined Multimodal Synthetic Data Generation Simulator for Unified Control in Assistive Robotics](https://arxiv.org/abs/2601.21129)
*Guangping Liu,Tipu Sultan,Vittorio Di Giorgio,Nick Hawkins,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 提出WheelArm-Sim仿真框架用于收集轮椅与机械臂集成控制的多模态数据集，并验证其可用于数据驱动的机器学习模型


<details>
  <summary>Details</summary>
Motivation: 目前辅助机器人领域对轮椅和机械臂的集成统一控制研究不足，需要数据收集来开发集成控制系统模型

Method: 开发WheelArm-Sim仿真框架（基于Isaac Sim），收集包含13个任务、232条轨迹、67,783个样本的多模态数据集，并实现基线模型进行动作预测

Result: 成功收集了大规模多模态数据集，基线模型在芥末拾取任务中的动作预测表明仿真数据可用于数据驱动的机器学习模型

Conclusion: WheelArm-Sim仿真框架能够有效收集用于轮椅-机械臂集成控制的数据，为开发数据驱动的集成控制系统奠定了基础

Abstract: Wheelchairs and robotic arms enhance independent living by assisting individuals with upper-body and mobility limitations in their activities of daily living (ADLs). Although recent advancements in assistive robotics have focused on Wheelchair-Mounted Robotic Arms (WMRAs) and wheelchairs separately, integrated and unified control of the combination using machine learning models remains largely underexplored. To fill this gap, we introduce the concept of WheelArm, an integrated cyber-physical system (CPS) that combines wheelchair and robotic arm controls. Data collection is the first step toward developing WheelArm models. In this paper, we present WheelArm-Sim, a simulation framework developed in Isaac Sim for synthetic data collection. We evaluate its capability by collecting a manipulation and navigation combined multimodal dataset, comprising 13 tasks, 232 trajectories, and 67,783 samples. To demonstrate the potential of the WheelArm dataset, we implement a baseline model for action prediction in the mustard-picking task. The results illustrate that data collected from WheelArm-Sim is feasible for a data-driven machine learning model for integrated control.

</details>


### [80] [InspecSafe-V1: A Multimodal Benchmark for Safety Assessment in Industrial Inspection Scenarios](https://arxiv.org/abs/2601.21173)
*Zeyi Liu,Shuang Liu,Jihai Min,Zhaoheng Zhang,Jun Cen,Pengyu Han,Songqiao Hu,Zihan Meng,Xiao He,Donghua Zhou*

Main category: cs.RO

TL;DR: InspecSafe-V1是首个用于工业巡检安全评估的多模态基准数据集，包含真实工业环境中5种场景的5,013个巡检实例，提供7种同步感知模态数据和像素级分割标注。


<details>
  <summary>Details</summary>
Motivation: 工业智能化和无人巡检快速发展，但现有数据集存在模拟数据、单模态感知、缺乏细粒度标注等问题，限制了工业基础模型的鲁棒场景理解和多模态安全推理能力。

Method: 从真实工业环境中41个轮式和轨道式巡检机器人的2,239个有效巡检点收集数据，涵盖隧道、电力设施、烧结设备、石油化工、煤炭输送栈桥5种场景，提供7种同步感知模态（可见光、红外视频、音频、深度点云、雷达点云、气体测量、温湿度）和像素级分割标注。

Result: 构建了包含5,013个巡检实例的InspecSafe-V1数据集，每个实例包含像素级分割标注、语义场景描述和安全等级标签，支持多模态异常识别、跨模态融合和综合安全评估。

Conclusion: InspecSafe-V1填补了工业巡检安全评估领域真实多模态数据集的空白，为工业基础模型的发展提供了重要基准，支持更可靠的感知和安全评估能力。

Abstract: With the rapid development of industrial intelligence and unmanned inspection, reliable perception and safety assessment for AI systems in complex and dynamic industrial sites has become a key bottleneck for deploying predictive maintenance and autonomous inspection. Most public datasets remain limited by simulated data sources, single-modality sensing, or the absence of fine-grained object-level annotations, which prevents robust scene understanding and multimodal safety reasoning for industrial foundation models. To address these limitations, InspecSafe-V1 is released as the first multimodal benchmark dataset for industrial inspection safety assessment that is collected from routine operations of real inspection robots in real-world environments. InspecSafe-V1 covers five representative industrial scenarios, including tunnels, power facilities, sintering equipment, oil and gas petrochemical plants, and coal conveyor trestles. The dataset is constructed from 41 wheeled and rail-mounted inspection robots operating at 2,239 valid inspection sites, yielding 5,013 inspection instances. For each instance, pixel-level segmentation annotations are provided for key objects in visible-spectrum images. In addition, a semantic scene description and a corresponding safety level label are provided according to practical inspection tasks. Seven synchronized sensing modalities are further included, including infrared video, audio, depth point clouds, radar point clouds, gas measurements, temperature, and humidity, to support multimodal anomaly recognition, cross-modal fusion, and comprehensive safety assessment in industrial environments.

</details>


### [81] [Disturbance-Aware Flight Control of Robotic Gliding Blimp via Moving Mass Actuation](https://arxiv.org/abs/2601.21188)
*Hao Cheng,Feitian Zhang*

Main category: cs.RO

TL;DR: 提出基于移动质量驱动的飞艇风扰动估计与控制框架，结合MHE实时估计风扰和MPC进行轨迹与航向控制，显著提升抗风性能。


<details>
  <summary>Details</summary>
Motivation: 飞艇等轻于空气(LTA)飞行器具有长航时和本质安全优势，但对风扰动高度敏感。现有控制框架缺乏对风扰的显式建模与补偿能力。

Method: 采用移动水平估计器(MHE)实时推断风扰动，将估计值提供给模型预测控制器(MPC)。利用二自由度移动质量机构同时产生惯性力矩和空气动力力矩，实现姿态和航向控制。

Result: 在顶风和侧风条件下的飞行实验表明，MHE-MPC集成框架显著优于基准PID控制，证明其在扰动感知LTA飞行中的有效性。

Conclusion: 提出的扰动感知控制框架通过显式建模和补偿风致效应，增强了飞艇在扰动环境中的飞行稳定性，为LTA平台提供了有效的抗风控制解决方案。

Abstract: Robotic blimps, as lighter-than-air (LTA) aerial systems, offer long endurance and inherently safe operation but remain highly susceptible to wind disturbances. Building on recent advances in moving mass actuation, this paper addresses the lack of disturbance-aware control frameworks for LTA platforms by explicitly modeling and compensating for wind-induced effects. A moving horizon estimator (MHE) infers real-time wind perturbations and provides these estimates to a model predictive controller (MPC), enabling robust trajectory and heading regulation under varying wind conditions. The proposed approach leverages a two-degree-of-freedom (2-DoF) moving-mass mechanism to generate both inertial and aerodynamic moments for attitude and heading control, thereby enhancing flight stability in disturbance-prone environments. Extensive flight experiments under headwind and crosswind conditions show that the integrated MHE-MPC framework significantly outperforms baseline PID control, demonstrating its effectiveness for disturbance-aware LTA flight.

</details>


### [82] [Abstracting Robot Manipulation Skills via Mixture-of-Experts Diffusion Policies](https://arxiv.org/abs/2601.21251)
*Ce Hao,Xuanran Zhai,Yaohua Liu,Harold Soh*

Main category: cs.RO

TL;DR: SMP是一种基于扩散模型的专家混合策略，通过紧凑正交技能基和粘性路由实现高效多任务操作，显著降低推理成本


<details>
  <summary>Details</summary>
Motivation: 基于扩散的策略在机器人操作中表现良好，但扩展到多任务场景时面临模型规模和演示成本高的挑战，需要更高效的架构

Method: 提出技能专家混合策略(SMP)：学习紧凑正交技能基，使用粘性路由在每一步仅激活少量任务相关专家，采用变分训练目标，推理时自适应专家激活

Result: 在仿真和真实双臂平台上验证，SMP在多任务学习和迁移学习任务中比大型扩散基线获得更高成功率，同时显著降低推理成本

Conclusion: SMP为可扩展、可迁移的多任务操作提供了实用路径：一次性学习可重用技能，仅激活所需部分，任务变化时快速适应

Abstract: Diffusion-based policies have recently shown strong results in robot manipulation, but their extension to multi-task scenarios is hindered by the high cost of scaling model size and demonstrations. We introduce Skill Mixture-of-Experts Policy (SMP), a diffusion-based mixture-of-experts policy that learns a compact orthogonal skill basis and uses sticky routing to compose actions from a small, task-relevant subset of experts at each step. A variational training objective supports this design, and adaptive expert activation at inference yields fast sampling without oversized backbones. We validate SMP in simulation and on a real dual-arm platform with multi-task learning and transfer learning tasks, where SMP achieves higher success rates and markedly lower inference cost than large diffusion baselines. These results indicate a practical path toward scalable, transferable multi-task manipulation: learn reusable skills once, activate only what is needed, and adapt quickly when tasks change.

</details>


### [83] [Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter](https://arxiv.org/abs/2601.21297)
*Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出Deep QP Safety Filter，一种完全数据驱动的安全层，用于黑盒动力系统。该方法结合Hamilton-Jacobi可达性与无模型学习，无需模型知识即可学习QP安全过滤器。


<details>
  <summary>Details</summary>
Motivation: 为黑盒动力系统提供无模型的安全控制方法，解决传统方法需要系统模型知识的问题，同时减少学习过程中的安全违规。

Method: 结合Hamilton-Jacobi可达性与无模型学习，构建基于收缩的损失函数，训练两个神经网络分别学习安全值及其导数，最终学习QP安全过滤器。

Result: 在精确设置下，学习的critic收敛到粘性解及其导数（即使对于非光滑值）。在多种动力系统（包括混合系统）和多个RL任务中，显著减少了收敛前的失败，同时加速学习获得更高回报。

Conclusion: Deep QP Safety Filter为安全、无模型控制提供了一种原理性和实用的途径，在保证安全的同时提升学习性能。

Abstract: We introduce Deep QP Safety Filter, a fully data-driven safety layer for black-box dynamical systems. Our method learns a Quadratic-Program (QP) safety filter without model knowledge by combining Hamilton-Jacobi (HJ) reachability with model-free learning. We construct contraction-based losses for both the safety value and its derivatives, and train two neural networks accordingly. In the exact setting, the learned critic converges to the viscosity solution (and its derivative), even for non-smooth values. Across diverse dynamical systems -- even including a hybrid system -- and multiple RL tasks, Deep QP Safety Filter substantially reduces pre-convergence failures while accelerating learning toward higher returns than strong baselines, offering a principled and practical route to safe, model-free control.

</details>


### [84] [HPTune: Hierarchical Proactive Tuning for Collision-Free Model Predictive Control](https://arxiv.org/abs/2601.21346)
*Wei Zuo,Chengyang Li,Yikun Wang,Bingyang Cheng,Zeyi Ren,Shuai Wang,Derrick Wing Kwan Ng,Yik-Chung Wu*

Main category: cs.RO

TL;DR: 提出分层主动调优框架HPTune，通过评估已执行和未执行动作来高效调优MPC运动规划器参数，结合激光雷达速度信息实现安全敏捷的避障策略。


<details>
  <summary>Details</summary>
Motivation: 现有MPC参数调优方法通常只评估已执行动作，导致参数更新效率低下，因为失败事件（如障碍物接近或碰撞）稀疏。需要更全面的评估方法来提高调优效率。

Method: 提出分层主动调优框架HPTune：1）快速级调优使用预测接近速度和预测接近距离的风险指标；2）慢速级调优利用扩展评估损失进行闭环反向传播。同时整合多普勒激光雷达提供障碍物速度信息以增强运动预测。

Result: 在高保真模拟器上的大量实验表明，HPTune实现了高效的MPC调优，在复杂环境中优于各种基线方案。能够制定安全、敏捷的碰撞避免策略，实现情境定制的运动规划。

Conclusion: HPTune通过扩展评估范围到未执行动作，结合分层调优和激光雷达速度信息，显著提高了MPC运动规划器的参数调优效率和适应性，实现了更安全敏捷的避障性能。

Abstract: Parameter tuning is a powerful approach to enhance adaptability in model predictive control (MPC) motion planners. However, existing methods typically operate in a myopic fashion that only evaluates executed actions, leading to inefficient parameter updates due to the sparsity of failure events (e.g., obstacle nearness or collision). To cope with this issue, we propose to extend evaluation from executed to non-executed actions, yielding a hierarchical proactive tuning (HPTune) framework that combines both a fast-level tuning and a slow-level tuning. The fast one adopts risk indicators of predictive closing speed and predictive proximity distance, and the slow one leverages an extended evaluation loss for closed-loop backpropagation. Additionally, we integrate HPTune with the Doppler LiDAR that provides obstacle velocities apart from position-only measurements for enhanced motion predictions, thus facilitating the implementation of HPTune. Extensive experiments on high-fidelity simulator demonstrate that HPTune achieves efficient MPC tuning and outperforms various baseline schemes in complex environments. It is found that HPTune enables situation-tailored motion planning by formulating a safe, agile collision avoidance strategy.

</details>


### [85] [Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control](https://arxiv.org/abs/2601.21363)
*Weidong Huang,Zhehan Li,Hangxin Liu,Biao Hou,Yao Su,Jingwen Zhang*

Main category: cs.RO

TL;DR: 提出结合SAC大规模预训练与模型微调的方法，实现人形机器人零样本部署与高效适应


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人控制中，on-policy方法（如PPO）样本效率低，难以安全适应新环境；off-policy和模型方法虽有改进，但大规模预训练与高效微调间仍存在差距

Method: 1) 使用SAC（大批次更新、高UTD比）进行大规模预训练，实现零样本部署；2) 在新环境中，使用模型方法微调SAC预训练策略，分离确定性策略执行与基于物理世界模型的随机探索

Result: SAC大规模预训练成功实现人形机器人零样本部署；预训练策略可通过模型方法高效适应新环境和分布外任务，降低随机探索风险

Conclusion: 该方法结合了大规模预训练的时钟效率与模型微调的样本效率，为人形机器人控制提供了从大规模仿真到高效适应的完整解决方案

Abstract: Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency, the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model. This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning.

</details>


### [86] [Towards Space-Based Environmentally-Adaptive Grasping](https://arxiv.org/abs/2601.21394)
*Leonidas Askianakis,Aleksandr Artemov*

Main category: cs.RO

TL;DR: 该论文提出了一种在学习的潜在流形中直接学习控制策略的方法，用于空间环境中的抓取任务，通过融合多模态信息实现更高效的强化学习。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作系统在非结构化环境中面临高维动作空间、稀疏奖励和泛化能力差的问题，特别是在空间环境等极端条件下。需要开发更高效、鲁棒的抓取方法。

Method: 1. 学习一个融合多模态信息的潜在流形表示；2. 在该潜在空间中直接学习控制策略；3. 使用GPU加速的物理仿真；4. 采用Soft Actor-Critic (SAC)强化学习算法；5. 在单次操作任务设置下进行训练。

Result: 在不到100万环境步数内达到超过95%的任务成功率，在连续变化的抓取条件下从第一步开始就表现出色。相比现有视觉基线方法，收敛速度更快，对新颖物体、夹爪几何、环境杂乱和传感器配置具有更好的鲁棒性。

Conclusion: 在潜在空间中进行显式推理能够实现更样本高效的学习和更强的鲁棒性。该方法为极端空间条件下的自适应和可泛化抓取提供了有前景的方向，但仍存在局限性需要进一步研究。

Abstract: Robotic manipulation in unstructured environments requires reliable execution under diverse conditions, yet many state-of-the-art systems still struggle with high-dimensional action spaces, sparse rewards, and slow generalization beyond carefully curated training scenarios. We study these limitations through the example of grasping in space environments. We learn control policies directly in a learned latent manifold that fuses (grammarizes) multiple modalities into a structured representation for policy decision-making. Building on GPU-accelerated physics simulation, we instantiate a set of single-shot manipulation tasks and achieve over 95% task success with Soft Actor-Critic (SAC)-based reinforcement learning in less than 1M environment steps, under continuously varying grasping conditions from step 1. This empirically shows faster convergence than representative state-of-the-art visual baselines under the same open-loop single-shot conditions. Our analysis indicates that explicitly reasoning in latent space yields more sample-efficient learning and improved robustness to novel object and gripper geometries, environmental clutter, and sensor configurations compared to standard baselines. We identify remaining limitations and outline directions toward fully adaptive and generalizable grasping in the extreme conditions of space.

</details>


### [87] [DSCD-Nav: Dual-Stance Cooperative Debate for Object Navigation](https://arxiv.org/abs/2601.21409)
*Weitao An,Qi Liu,Chenghao Xu,Jiayi Chai,Xu Yang,Kun Wei,Cheng Deng*

Main category: cs.RO

TL;DR: DSCD-Nav提出了一种双立场协作辩论导航机制，通过任务-场景理解与安全-信息平衡两个立场的交叉验证，结合导航共识仲裁来提升室内导航的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有导航系统依赖单次评分决策，容易产生过度自信的长时程错误和冗余探索。在部分可观测环境下，需要更可靠的决策机制来提升家用服务机器人在陌生室内环境中的自适应导航能力。

Method: 提出双立场协作辩论导航机制：1)构建两个互补立场：任务-场景理解立场（关注目标进展和场景布局线索）和安全-信息平衡立场（关注风险和信息的价值）；2)两个立场进行协作辩论，通过基于线索的论证交叉验证候选动作；3)引入导航共识仲裁代理，整合双方理由和证据，必要时触发轻量级微探测来验证不确定选择。

Result: 在HM3Dv1、HM3Dv2和MP3D数据集上的实验表明，该方法在成功率和路径效率方面取得一致改进，同时减少了探索冗余。

Conclusion: DSCD-Nav通过双立场协作辩论和证据感知仲裁机制，有效提升了部分可观测环境下导航决策的可靠性，为家用服务机器人的自适应导航提供了新思路。

Abstract: Adaptive navigation in unfamiliar indoor environments is crucial for household service robots. Despite advances in zero-shot perception and reasoning from vision-language models, existing navigation systems still rely on single-pass scoring at the decision layer, leading to overconfident long-horizon errors and redundant exploration. To tackle these problems, we propose Dual-Stance Cooperative Debate Navigation (DSCD-Nav), a decision mechanism that replaces one-shot scoring with stance-based cross-checking and evidence-aware arbitration to improve action reliability under partial observability. Specifically, given the same observation and candidate action set, we explicitly construct two stances by conditioning the evaluation on diverse and complementary objectives: a Task-Scene Understanding (TSU) stance that prioritizes goal progress from scene-layout cues, and a Safety-Information Balancing (SIB) stance that emphasizes risk and information value. The stances conduct a cooperative debate and make policy by cross-checking their top candidates with cue-grounded arguments. Then, a Navigation Consensus Arbitration (NCA) agent is employed to consolidate both sides' reasons and evidence, optionally triggering lightweight micro-probing to verify uncertain choices, preserving NCA's primary intent while disambiguating. Experiments on HM3Dv1, HM3Dv2, and MP3D demonstrate consistent improvements in success and path efficiency while reducing exploration redundancy.

</details>


### [88] [Singularity-Free Lie Group Integration and Geometrically Consistent Evaluation of Multibody System Models Described in Terms of Standard Absolute Coordinates](https://arxiv.org/abs/2601.21413)
*Andreas Mueller*

Main category: cs.RO

TL;DR: 提出一个框架，将李群积分器与标准多体系统方程对接，同时提出一种方法在绝对坐标中保持刚体运动几何结构，使用局部-全局转换映射实现坐标更新。


<details>
  <summary>Details</summary>
Motivation: 传统多体系统建模使用绝对坐标，但空间运动缺乏无奇异性参数化。李群积分方法能无奇异性积分并保持运动几何结构，但与标准方程不兼容，难以在现有仿真代码中实现。

Method: 1) 提出李群积分器与标准方程对接框架，允许用各种绝对坐标描述多体系统同时使用李群积分方案；2) 提出在绝对坐标中一致融入刚体运动几何结构的方法，使用SO(3)×R3和SE(3)群表示刚体运动，核心是局部-全局转换映射。

Result: 建立了李群积分器与标准多体系统方程之间的接口框架，实现了在绝对坐标描述下使用李群积分方案，同时保持了刚体运动的几何结构完整性。

Conclusion: 该框架解决了李群积分方法与标准多体系统方程的不兼容问题，使现有仿真代码能够利用李群积分的优势，同时保持了刚体运动的几何特性。

Abstract: A classical approach to the multibody systems (MBS) modeling is to use absolute coordinates, i.e., a set of (possibly redundant) coordinates that describe the absolute position and orientation of the individual bodies with respect to an inertial frame (IFR). A well-known problem for the time integration of the equations of motion (EOM) is the lack of a singularity-free parameterization of spatial motions, which is usually tackled by using unit quaternions. Lie group integration methods were proposed as an alternative approach to the singularity-free time integration. At the same time, Lie group formulations of EOM naturally respect the geometry of spatial motions during integration. Lie group integration methods, operating directly on the configuration space Lie group, are incompatible with standard formulations of the EOM, and cannot be implemented in existing MBS simulation codes without a major restructuring. The contribution of this paper is twofold: (1) A framework for interfacing Lie group integrators to standard EOM formulations is presented. It allows describing MBS in terms of various absolute coordinates and at the same using Lie group integration schemes. (2) A method for consistently incorporating the geometry of rigid body motions into the evaluation of EOM in absolute coordinates integrated with standard vector space integration schemes. The direct product group and the semidirect product group SO(3)xR3 and the semidirect product group SE(3) are used for representing rigid body motions. The key element is the local-global transitions (LGT) transition map, which facilitates the update of (global) absolute coordinates in terms of the (local) coordinates on the Lie group. This LGT map is specific to the absolute coordinates, the local coordinates on the Lie group, and the Lie group used to represent rigid body configurations.

</details>


### [89] [Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation](https://arxiv.org/abs/2601.21416)
*Alexandre Chapin,Bruno Machado,Emmanuel Dellandréa,Liming Chen*

Main category: cs.RO

TL;DR: SBOCR（基于槽的对象中心表示）在机器人操作任务中比全局特征和密集特征具有更好的泛化能力，特别是在光照、纹理变化和干扰物存在的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作策略使用的视觉表示（全局特征和密集特征）混合了任务相关和无关信息，导致在分布变化（如光照、纹理变化、干扰物）下泛化能力差。

Method: 提出使用基于槽的对象中心表示（SBOCR），将密集特征分组为有限的对象类实体，减少噪声同时保留足够任务信息。在模拟和真实世界的机器人操作任务中，对比了全局特征、密集特征和SBOCR的泛化性能。

Result: SBOCR策略在泛化设置中优于基于密集特征和全局特征的策略，即使没有任务特定的预训练。在各种视觉条件变化下（光照、纹理、干扰物）都表现出更好的泛化能力。

Conclusion: SBOCR是设计在动态真实世界机器人环境中有效泛化的视觉系统的有前景方向，通过结构化表示平衡信息保留和噪声减少。

Abstract: The generalization capabilities of robotic manipulation policies are heavily influenced by the choice of visual representations. Existing approaches typically rely on representations extracted from pre-trained encoders, using two dominant types of features: global features, which summarize an entire image via a single pooled vector, and dense features, which preserve a patch-wise embedding from the final encoder layer. While widely used, both feature types mix task-relevant and irrelevant information, leading to poor generalization under distribution shifts, such as changes in lighting, textures, or the presence of distractors. In this work, we explore an intermediate structured alternative: Slot-Based Object-Centric Representations (SBOCR), which group dense features into a finite set of object-like entities. This representation permits to naturally reduce the noise provided to the robotic manipulation policy while keeping enough information to efficiently perform the task. We benchmark a range of global and dense representations against intermediate slot-based representations, across a suite of simulated and real-world manipulation tasks ranging from simple to complex. We evaluate their generalization under diverse visual conditions, including changes in lighting, texture, and the presence of distractors. Our findings reveal that SBOCR-based policies outperform dense and global representation-based policies in generalization settings, even without task-specific pretraining. These insights suggest that SBOCR is a promising direction for designing visual systems that generalize effectively in dynamic, real-world robotic environments.

</details>


### [90] [Nimbus: A Unified Embodied Synthetic Data Generation Framework](https://arxiv.org/abs/2601.21449)
*Zeyu He,Yuchang Zhang,Yuanzhen Zhou,Miao Tao,Hengjie Li,Yang Tian,Jia Zeng,Tai Wang,Wenzhe Cai,Yilun Chen,Ning Gao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: Nimbus是一个统一的合成数据生成框架，通过模块化四层架构和异步执行模型，将异构导航和操作管道集成，实现大规模分布式环境下的高效稳定数据生成。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据生成管道分散且任务特定，导致工程效率低下和系统不稳定，无法支持基础模型训练所需的高吞吐量持续数据生成。

Method: 提出Nimbus框架，采用模块化四层架构，将轨迹规划、渲染和存储解耦为异步阶段，实现动态管道调度、全局负载均衡、分布式容错和后端特定渲染优化。

Result: Nimbus相比未优化基线实现了2-3倍的端到端吞吐量提升，确保在大型分布式环境中的稳健长期运行，作为InternData套件的生产骨干。

Conclusion: Nimbus框架解决了合成数据生成的碎片化和低效问题，为跨领域数据合成提供了统一解决方案，支持大规模基础模型训练的数据需求。

Abstract: Scaling data volume and diversity is critical for generalizing embodied intelligence. While synthetic data generation offers a scalable alternative to expensive physical data acquisition, existing pipelines remain fragmented and task-specific. This isolation leads to significant engineering inefficiency and system instability, failing to support the sustained, high-throughput data generation required for foundation model training. To address these challenges, we present Nimbus, a unified synthetic data generation framework designed to integrate heterogeneous navigation and manipulation pipelines. Nimbus introduces a modular four-layer architecture featuring a decoupled execution model that separates trajectory planning, rendering, and storage into asynchronous stages. By implementing dynamic pipeline scheduling, global load balancing, distributed fault tolerance, and backend-specific rendering optimizations, the system maximizes resource utilization across CPU, GPU, and I/O resources. Our evaluation demonstrates that Nimbus achieves a 2-3X improvement in end-to-end throughput compared to unoptimized baselines and ensuring robust, long-term operation in large-scale distributed environments. This framework serves as the production backbone for the InternData suite, enabling seamless cross-domain data synthesis.

</details>


### [91] [4D-CAAL: 4D Radar-Camera Calibration and Auto-Labeling for Autonomous Driving](https://arxiv.org/abs/2601.21454)
*Shanliang Yao,Zhuoxiao Li,Runwei Guan,Kebin Cao,Meng Xia,Fuping Hu,Sen Xu,Yong Yue,Xiaohui Zhu,Weiping Ding,Ryan Wen Liu*

Main category: cs.RO

TL;DR: 4D-CAAL是一个统一的4D雷达-相机标定和自动标注框架，通过双用途标定目标和特征匹配算法实现高精度标定，并利用几何投影将相机标注自动转移到雷达点云。


<details>
  <summary>Details</summary>
Motivation: 4D雷达在自动驾驶中至关重要，但现有标定方法使用分离的目标，难以建立对应关系；同时，手动标注稀疏雷达数据既费力又不可靠。

Method: 提出双用途标定目标设计（正面棋盘格用于相机检测，背面中心角反射器用于雷达检测），开发鲁棒的对应匹配算法，并构建自动标注流水线，通过几何投影和多特征优化将相机分割标注转移到雷达点云。

Result: 大量实验表明，该方法实现了高标定精度，同时显著减少了手动标注工作量，加速了自动驾驶鲁棒多模态感知系统的开发。

Conclusion: 4D-CAAL框架有效解决了4D雷达-相机标定和雷达数据标注的挑战，为自动驾驶多模态感知系统的发展提供了实用解决方案。

Abstract: 4D radar has emerged as a critical sensor for autonomous driving, primarily due to its enhanced capabilities in elevation measurement and higher resolution compared to traditional 3D radar. Effective integration of 4D radar with cameras requires accurate extrinsic calibration, and the development of radar-based perception algorithms demands large-scale annotated datasets. However, existing calibration methods often employ separate targets optimized for either visual or radar modalities, complicating correspondence establishment. Furthermore, manually labeling sparse radar data is labor-intensive and unreliable. To address these challenges, we propose 4D-CAAL, a unified framework for 4D radar-camera calibration and auto-labeling. Our approach introduces a novel dual-purpose calibration target design, integrating a checkerboard pattern on the front surface for camera detection and a corner reflector at the center of the back surface for radar detection. We develop a robust correspondence matching algorithm that aligns the checkerboard center with the strongest radar reflection point, enabling accurate extrinsic calibration. Subsequently, we present an auto-labeling pipeline that leverages the calibrated sensor relationship to transfer annotations from camera-based segmentations to radar point clouds through geometric projection and multi-feature optimization. Extensive experiments demonstrate that our method achieves high calibration accuracy while significantly reducing manual annotation effort, thereby accelerating the development of robust multi-modal perception systems for autonomous driving.

</details>


### [92] [DexTac: Learning Contact-aware Visuotactile Policies via Hand-by-hand Teaching](https://arxiv.org/abs/2601.21474)
*Xingyu Zhang,Chaofan Zhang,Boyue Zhang,Zhinan Peng,Shaowei Cui,Shuo Wang*

Main category: cs.RO

TL;DR: DexTac是一个基于动觉教学的视觉-触觉操作学习框架，通过从人类演示中捕捉多维触觉数据，使灵巧手在复杂交互中自主选择和保持最佳接触区域，在注射任务上达到91.67%成功率。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧操作的数据收集和技能学习系统通常存在触觉信息维度低的问题，无法生成全面的触觉感知运动策略。接触密集型任务需要能够产生全面触觉感知运动的策略。

Method: 提出DexTac框架，基于动觉教学从人类演示中捕捉多维触觉数据（包括接触力分布和空间接触区域），将这些丰富的触觉模态整合到策略网络中，使灵巧手能够在复杂交互中自主选择和保持最佳接触区域。

Result: 在具有挑战性的单手注射任务上评估，DexTac达到91.67%的成功率。在涉及小规模注射器的高精度场景中，该方法比仅使用力的基线方法高出31.67%。

Conclusion: 从人类演示中学习多维触觉先验对于在接触丰富的环境中实现稳健、类人的灵巧操作至关重要。DexTac框架通过整合丰富的触觉模态，使灵巧手能够自主选择最佳接触区域，显著提升了操作性能。

Abstract: For contact-intensive tasks, the ability to generate policies that produce comprehensive tactile-aware motions is essential. However, existing data collection and skill learning systems for dexterous manipulation often suffer from low-dimensional tactile information. To address this limitation, we propose DexTac, a visuo-tactile manipulation learning framework based on kinesthetic teaching. DexTac captures multi-dimensional tactile data-including contact force distributions and spatial contact regions-directly from human demonstrations. By integrating these rich tactile modalities into a policy network, the resulting contact-aware agent enables a dexterous hand to autonomously select and maintain optimal contact regions during complex interactions. We evaluate our framework on a challenging unimanual injection task. Experimental results demonstrate that DexTac achieves a 91.67% success rate. Notably, in high-precision scenarios involving small-scale syringes, our approach outperforms force-only baselines by 31.67%. These results underscore that learning multi-dimensional tactile priors from human demonstrations is critical for achieving robust, human-like dexterous manipulation in contact-rich environments.

</details>


### [93] [Don't double it: Efficient Agent Prediction in Occlusions](https://arxiv.org/abs/2601.21504)
*Anna Rothenhäusler,Markus Mazzola,Andreas Look,Raghu Rajan,Joschka Bödecker*

Main category: cs.RO

TL;DR: MatchInformer：基于Transformer的交通参与者预测方法，通过匈牙利匹配减少冗余预测，解耦航向与运动提升轨迹精度，使用MCC评估解决类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，被遮挡的交通参与者（如行人或车辆）可能突然出现，现有学习方法虽然能推断隐藏参与者，但会产生冗余的占用预测（单个参与者被多次识别），这增加了下游规划和计算负担。

Method: 1. 基于最先进的SceneInformer架构，提出MatchInformer方法；2. 将目标检测中的匈牙利匹配算法集成到训练过程中，强制预测与真实值之间的一一对应关系；3. 解耦参与者的航向与运动，提高轨迹预测的准确性和可解释性；4. 使用马修斯相关系数（MCC）评估占用预测，解决类别不平衡问题。

Result: 在Waymo Open Motion Dataset上的实验表明，该方法能够改善对遮挡区域的推理能力，并产生比现有方法更准确的轨迹预测。

Conclusion: MatchInformer通过匈牙利匹配减少冗余预测，解耦航向与运动提升轨迹精度，使用MCC评估解决类别不平衡，为自动驾驶中的遮挡参与者预测提供了更有效的解决方案。

Abstract: Occluded traffic agents pose a significant challenge for autonomous vehicles, as hidden pedestrians or vehicles can appear unexpectedly, yet this problem remains understudied. Existing learning-based methods, while capable of inferring the presence of hidden agents, often produce redundant occupancy predictions where a single agent is identified multiple times. This issue complicates downstream planning and increases computational load. To address this, we introduce MatchInformer, a novel transformer-based approach that builds on the state-of-the-art SceneInformer architecture. Our method improves upon prior work by integrating Hungarian Matching, a state-of-the-art object matching algorithm from object detection, into the training process to enforce a one-to-one correspondence between predictions and ground truth, thereby reducing redundancy. We further refine trajectory forecasts by decoupling an agent's heading from its motion, a strategy that improves the accuracy and interpretability of predicted paths. To better handle class imbalances, we propose using the Matthews Correlation Coefficient (MCC) to evaluate occupancy predictions. By considering all entries in the confusion matrix, MCC provides a robust measure even in sparse or imbalanced scenarios. Experiments on the Waymo Open Motion Dataset demonstrate that our approach improves reasoning about occluded regions and produces more accurate trajectory forecasts than prior methods.

</details>


### [94] [IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation](https://arxiv.org/abs/2601.21506)
*Joonhee Lee,Hyunseung Shin,Jeonggil Ko*

Main category: cs.RO

TL;DR: IROS是一个实时室内导航框架，结合VLM级上下文推理与轻量感知模块，在低成本设备上实现高效导航，决策准确率提升且延迟降低66%。


<details>
  <summary>Details</summary>
Motivation: 现有室内机器人导航方法存在局限性：传统几何方法（如SLAM）依赖详细地图且无法理解人类语义线索；VLA模型仅基于可见帧反应式决策，无法预见未见的交叉口或推理远处文本线索；VLMs计算延迟高，不适合嵌入式平台实时操作。需要一种既能提供丰富语义理解又能实时响应的解决方案。

Method: IROS框架受双过程理论启发，将快速反射决策（系统一）与缓慢审慎推理（系统二）分离，仅在必要时调用VLM。通过增强紧凑型VLMs的空间和文本线索，实现类人导航。在低成本设备硬件上结合VLM级上下文推理与轻量感知模块。

Result: 在五个真实世界建筑中，IROS相比连续基于VLM的导航，提高了决策准确率并将延迟降低了66%。

Conclusion: IROS框架成功实现了实时室内导航，将VLM级语义理解与轻量感知模块的高效性结合，在保持低延迟的同时提供鲁棒的类人导航能力。

Abstract: Indoor mobile robot navigation requires fast responsiveness and robust semantic understanding, yet existing methods struggle to provide both. Classical geometric approaches such as SLAM offer reliable localization but depend on detailed maps and cannot interpret human-targeted cues (e.g., signs, room numbers) essential for indoor reasoning. Vision-Language-Action (VLA) models introduce semantic grounding but remain strictly reactive, basing decisions only on visible frames and failing to anticipate unseen intersections or reason about distant textual cues. Vision-Language Models (VLMs) provide richer contextual inference but suffer from high computational latency, making them unsuitable for real-time operation on embedded platforms. In this work, we present IROS, a real-time navigation framework that combines VLM-level contextual reasoning with the efficiency of lightweight perceptual modules on low-cost, on-device hardware. Inspired by Dual Process Theory, IROS separates fast reflexive decisions (System One) from slow deliberative reasoning (System Two), invoking the VLM only when necessary. Furthermore, by augmenting compact VLMs with spatial and textual cues, IROS delivers robust, human-like navigation with minimal latency. Across five real-world buildings, IROS improves decision accuracy and reduces latency by 66% compared to continuous VLM-based navigation.

</details>


### [95] [Training slow silicon neurons to control extremely fast robots with spiking reinforcement learning](https://arxiv.org/abs/2601.21548)
*Irene Ambrosini,Ingo Blakowski,Dmitrii Zendrikov,Cristiano Capone,Luna Gava,Giacomo Indiveri,Chiara De Luca,Chiara Bartolozzi*

Main category: cs.RO

TL;DR: 使用脉冲神经网络在神经形态处理器上实现空气曲棍球实时学习，通过硬件算法协同设计实现快速强化学习


<details>
  <summary>Details</summary>
Motivation: 空气曲棍球需要在高速度下做出快速决策，传统方法难以应对。研究旨在将神经科学启发的硬件与真实世界机器人控制相结合，展示大脑启发方法能够处理快速交互任务并支持持续学习

Method: 采用混合信号模拟/数字神经形态处理器上的脉冲神经网络，通过硬件算法协同设计。使用固定随机连接捕获任务时间结构，在读出层采用局部e-prop学习规则，利用事件驱动活动实现快速高效学习。通过计算机和神经形态芯片组成的实时学习系统进行强化学习训练

Result: 系统在极少试验次数内成功实现冰球交互，展示了实时学习能力。神经形态芯片能够支持脉冲神经网络的实际训练，为机器人自主系统提供可行方案

Conclusion: 这项研究成功将神经科学启发的硬件与真实世界机器人控制连接起来，证明大脑启发方法能够处理快速交互任务，同时支持智能机器中的持续学习，为机器人自主系统开辟了新途径

Abstract: Air hockey demands split-second decisions at high puck velocities, a challenge we address with a compact network of spiking neurons running on a mixed-signal analog/digital neuromorphic processor. By co-designing hardware and learning algorithms, we train the system to achieve successful puck interactions through reinforcement learning in a remarkably small number of trials. The network leverages fixed random connectivity to capture the task's temporal structure and adopts a local e-prop learning rule in the readout layer to exploit event-driven activity for fast and efficient learning. The result is real-time learning with a setup comprising a computer and the neuromorphic chip in-the-loop, enabling practical training of spiking neural networks for robotic autonomous systems. This work bridges neuroscience-inspired hardware with real-world robotic control, showing that brain-inspired approaches can tackle fast-paced interaction tasks while supporting always-on learning in intelligent machines.

</details>


### [96] [AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation](https://arxiv.org/abs/2601.21602)
*Jianli Sun,Bin Tian,Qiyao Zhang,Chengxiang Li,Zihan Song,Zhiyong Cui,Yisheng Lv,Yonglin Tian*

Main category: cs.RO

TL;DR: AIR-VLA是首个针对空中操作系统的视觉-语言-动作基准测试，包含物理仿真环境和3000个手动遥操作演示数据集，用于评估主流VLA模型在无人机移动、机械臂控制和高级规划方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在地面实体智能中取得显著成功，但在空中操作系统中的应用仍未被充分探索。空中操作系统的浮动基座动力学、无人机与机械臂的强耦合特性，以及多步骤、长时程的操作任务特性，对现有为静态或2D移动基座设计的VLA范式构成了严峻挑战。

Method: 构建了基于物理的仿真环境，并发布了包含3000个手动遥操作演示的高质量多模态数据集，涵盖基座操作、物体与空间理解、语义推理和长时程规划。利用该平台系统评估了主流VLA模型和最先进的VLM模型。

Result: 实验不仅验证了将VLA范式迁移到空中系统的可行性，还通过针对空中任务的多维度指标，揭示了当前模型在无人机移动性、机械臂控制和高级规划方面的能力边界。

Conclusion: AIR-VLA为通用空中机器人研究建立了标准化测试平台和数据基础，填补了VLA模型在空中操作领域的空白。

Abstract: While Vision-Language-Action (VLA) models have achieved remarkable success in ground-based embodied intelligence, their application to Aerial Manipulation Systems (AMS) remains a largely unexplored frontier. The inherent characteristics of AMS, including floating-base dynamics, strong coupling between the UAV and the manipulator, and the multi-step, long-horizon nature of operational tasks, pose severe challenges to existing VLA paradigms designed for static or 2D mobile bases. To bridge this gap, we propose AIR-VLA, the first VLA benchmark specifically tailored for aerial manipulation. We construct a physics-based simulation environment and release a high-quality multimodal dataset comprising 3000 manually teleoperated demonstrations, covering base manipulation, object & spatial understanding, semantic reasoning, and long-horizon planning. Leveraging this platform, we systematically evaluate mainstream VLA models and state-of-the-art VLM models. Our experiments not only validate the feasibility of transferring VLA paradigms to aerial systems but also, through multi-dimensional metrics tailored to aerial tasks, reveal the capabilities and boundaries of current models regarding UAV mobility, manipulator control, and high-level planning. AIR-VLA establishes a standardized testbed and data foundation for future research in general-purpose aerial robotics. The resource of AIR-VLA will be available at https://anonymous.4open.science/r/AIR-VLA-dataset-B5CC/.

</details>


### [97] [From Instruction to Event: Sound-Triggered Mobile Manipulation](https://arxiv.org/abs/2601.21667)
*Hao Ju,Shaofei Huang,Hongyu Li,Zihan Ding,Si Liu,Meng Wang,Zhedong Zheng*

Main category: cs.RO

TL;DR: 提出声音触发的移动操作新范式，让智能体主动感知声音并操作发声物体，无需显式指令


<details>
  <summary>Details</summary>
Motivation: 当前移动操作研究主要依赖预定义文本指令，限制了智能体的自主性和对动态环境事件的响应能力

Method: 开发Habitat-Echo数据平台（集成声学渲染与物理交互），提出包含高层任务规划器和低层策略模型的基线系统

Result: 智能体能够主动检测和响应听觉事件，无需逐案指令；在挑战性双声源场景中，能隔离主声源并先后操作两个物体

Conclusion: 声音触发移动操作增强了智能体自主性，提出的基线系统在复杂声学环境中表现出鲁棒性

Abstract: Current mobile manipulation research predominantly follows an instruction-driven paradigm, where agents rely on predefined textual commands to execute tasks. However, this setting confines agents to a passive role, limiting their autonomy and ability to react to dynamic environmental events. To address these limitations, we introduce sound-triggered mobile manipulation, where agents must actively perceive and interact with sound-emitting objects without explicit action instructions. To support these tasks, we develop Habitat-Echo, a data platform that integrates acoustic rendering with physical interaction. We further propose a baseline comprising a high-level task planner and low-level policy models to complete these tasks. Extensive experiments show that the proposed baseline empowers agents to actively detect and respond to auditory events, eliminating the need for case-by-case instructions. Notably, in the challenging dual-source scenario, the agent successfully isolates the primary source from overlapping acoustic interference to execute the first interaction, and subsequently proceeds to manipulate the secondary object, verifying the robustness of the baseline.

</details>


### [98] [CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation](https://arxiv.org/abs/2601.21712)
*Xuanran Zhai,Binkai Ou,Yemin Wang,Hui Yi Leong,Qiaojun Yu,Ce Hao,Yaohua Liu*

Main category: cs.RO

TL;DR: CoFreeVLA：增强VLA模型的双臂操作安全性，通过短时域自碰撞风险估计器预测碰撞风险，门控危险指令并引导安全恢复


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作（VLA）模型在双臂操作中存在安全隐患，因为未充分建模双臂之间及抓取物体间的自碰撞风险，可能导致实际部署中的安全问题

Method: 在端到端VLA基础上增加短时域自碰撞风险估计器，该估计器从本体感知、视觉嵌入和计划动作预测碰撞概率；通过门控机制过滤危险指令，风险引导调整恢复安全状态，并用于策略精炼；采用基于模型的碰撞标签预训练，并在真实机器人上后训练校准

Result: 在PiPER机器人臂的五个双臂任务中，CoFreeVLA相比RDT和APEX方法减少了自碰撞，提高了任务成功率

Conclusion: CoFreeVLA通过集成自碰撞风险估计器有效提升了双臂操作的安全性，为VLA模型在实际机器人部署中的安全应用提供了可行方案

Abstract: Vision Language Action (VLA) models enable instruction following manipulation, yet dualarm deployment remains unsafe due to under modeled selfcollisions between arms and grasped objects. We introduce CoFreeVLA, which augments an endtoend VLA with a short horizon selfcollision risk estimator that predicts collision likelihood from proprioception, visual embeddings, and planned actions. The estimator gates risky commands, recovers to safe states via risk-guided adjustments, and shapes policy refinement for safer rollouts. It is pre-trained with model-based collision labels and posttrained on real robot rollouts for calibration. On five bimanual tasks with the PiPER robot arm, CoFreeVLA reduces selfcollisions and improves success rates versus RDT and APEX.

</details>


### [99] [Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations](https://arxiv.org/abs/2601.21713)
*Donatien Delehelle,Fei Chen,Darwin Caldwell*

Main category: cs.RO

TL;DR: 本文质疑了布料操作中常见的端到端学习方法，提出了一种高效、模块化的强化学习方案，显著减小了模型规模并缩短了训练时间，同时在仿真和真实世界都取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 布料操作是机器人学中的开放挑战，传统端到端学习方法虽然能实现仿真到真实的迁移，但依赖大型模型和长训练时间，计算成本高昂。本文质疑这种常见设计选择，探索更高效、模块化的强化学习方案。

Method: 通过精心设计选择，在仿真中学习时显著减小模型规模和训练时间。采用模块化方法替代端到端学习，避免了基于高度信息损失的环境状态表示进行训练。展示了如何将仿真训练的模型迁移到真实世界。

Result: 在SoftGym基准测试中，相比现有基线方法，在相同任务上取得了显著性能提升，同时使用了显著更小的模型。

Conclusion: 通过质疑布料操作中常见的端到端学习设计选择，本文展示了高效、模块化的强化学习方法能够显著降低计算成本，同时保持甚至提升性能，为布料操作策略开发提供了更实用的解决方案。

Abstract: Cloth manipulation is a ubiquitous task in everyday life, but it remains an open challenge for robotics. The difficulties in developing cloth manipulation policies are attributed to the high-dimensional state space, complex dynamics, and high propensity to self-occlusion exhibited by fabrics. As analytical methods have not been able to provide robust and general manipulation policies, reinforcement learning (RL) is considered a promising approach to these problems. However, to address the large state space and complex dynamics, data-based methods usually rely on large models and long training times. The resulting computational cost significantly hampers the development and adoption of these methods. Additionally, due to the challenge of robust state estimation, garment manipulation policies often adopt an end-to-end learning approach with workspace images as input. While this approach enables a conceptually straightforward sim-to-real transfer via real-world fine-tuning, it also incurs a significant computational cost by training agents on a highly lossy representation of the environment state. This paper questions this common design choice by exploring an efficient and modular approach to RL for cloth manipulation. We show that, through careful design choices, model size and training time can be significantly reduced when learning in simulation. Furthermore, we demonstrate how the resulting simulation-trained model can be transferred to the real world. We evaluate our approach on the SoftGym benchmark and achieve significant performance improvements over available baselines on our task, while using a substantially smaller model.

</details>


### [100] [Flocking behavior for dynamic and complex swarm structures](https://arxiv.org/abs/2601.21772)
*Carmen D. R. Pita-Romero,Pedro Arias-Perez,Miguel Fernandez-Cortizas,Rafael Perez-Segui,Pascual Campoy*

Main category: cs.RO

TL;DR: 提出基于虚拟质心的无人机集群编队算法，简化复杂结构形成与轨迹跟踪


<details>
  <summary>Details</summary>
Motivation: 多无人机保持复杂编队结构并实现复杂轨迹跟踪仍面临重大挑战，需要更简单有效的控制方法

Method: 基于虚拟质心概念的集群行为算法，在经典虚拟行为基础上构建理论框架，动态控制智能体数量和编队结构

Result: 通过仿真测试和真实实验验证，算法即使在复杂编队和复杂轨迹下也表现出简单性

Conclusion: 虚拟质心方法为无人机集群编队控制提供了有效的解决方案，简化了复杂结构的形成与维护

Abstract: Maintaining the formation of complex structures with multiple UAVs and achieving complex trajectories remains a major challenge. This work presents an algorithm for implementing the flocking behavior of UAVs based on the concept of Virtual Centroid to easily develop a structure for the flock. The approach builds on the classical virtual-based behavior, providing a theoretical framework for incorporating enhancements to dynamically control both the number of agents and the formation of the structure. Simulation tests and real-world experiments were conducted, demonstrating its simplicity even with complex formations and complex trajectories.

</details>


### [101] [GAZELOAD A Multimodal Eye-Tracking Dataset for Mental Workload in Industrial Human-Robot Collaboration](https://arxiv.org/abs/2601.21829)
*Bsher Karbouj,Baha Eddin Gaaloul,Jorg Kruger*

Main category: cs.RO

TL;DR: GAZELOAD是一个用于工业人机协作中脑力负荷估计的多模态数据集，包含26名参与者在与协作机器人交互时的眼动追踪、环境测量和任务上下文数据。


<details>
  <summary>Details</summary>
Motivation: 在工业人机协作场景中，准确估计操作员的脑力负荷对于优化人机交互、提高工作效率和安全性至关重要。当前缺乏包含眼动追踪与环境因素同步的多模态数据集来支持这一领域的研究。

Method: 在实验室装配测试平台中，26名参与者佩戴Meta ARIA智能眼镜与两台协作机器人（UR5和Franka Emika Panda）交互。数据集时间同步了多种数据：眼动信号（瞳孔直径、注视点、扫视、眼动轨迹、注视转移熵、注视分散指数）、环境实时连续测量（照度）、任务和机器人上下文（工作台、任务块、诱导故障），并在任务难度和环境条件的受控操作下收集。

Result: 为每个参与者和按脑力负荷分级的任务块提供了CSV文件，包含以250毫秒窗口聚合的眼动指标、环境日志以及1-10李克特量表的自评脑力负荷评分，按参与者特定文件夹组织并附带文档。

Conclusion: GAZELOAD数据集可用于开发和基准测试脑力负荷估计算法、特征提取和时间建模，支持在真实工业人机协作场景中的研究，并可用于调查环境因素（如照明）对基于眼动的脑力负荷指标的影响。

Abstract: This article describes GAZELOAD, a multimodal dataset for mental workload estimation in industrial human-robot collaboration. The data were collected in a laboratory assembly testbed where 26 participants interacted with two collaborative robots (UR5 and Franka Emika Panda) while wearing Meta ARIA smart glasses. The dataset time-synchronizes eye-tracking signals (pupil diameter, fixations, saccades, eye gaze, gaze transition entropy, fixation dispersion index) with environmental real-time and continuous measurements (illuminance) and task and robot context (bench, task block, induced faults), under controlled manipulations of task difficulty and ambient conditions. For each participant and workload-graded task block, we provide CSV files with ocular metrics aggregated into 250 ms windows, environmental logs, and self-reported mental workload ratings on a 1-10 Likert scale, organized in participant-specific folders alongside documentation. These data can be used to develop and benchmark algorithms for mental workload estimation, feature extraction, and temporal modeling in realistic industrial HRC scenarios, and to investigate the influence of environmental factors such as lighting on eye-based workload markers.

</details>


### [102] [LLM-Driven Scenario-Aware Planning for Autonomous Driving](https://arxiv.org/abs/2601.21876)
*He Li,Zhaowei Chen,Rui Gao,Guoliang Li,Qi Hao,Shuai Wang,Chengzhong Xu*

Main category: cs.RO

TL;DR: LAP：基于大语言模型的自动驾驶混合规划器切换框架，通过LLM场景理解和联合优化，在复杂交通中实现高速驾驶效率和精确操控的平衡


<details>
  <summary>Details</summary>
Motivation: 现有混合规划器切换框架在密集交通中难以实现可靠模式切换和持续高效驾驶，主要受限于启发式场景识别和低频控制更新

Method: 提出LAP方法：1）利用LLM进行场景理解；2）将LLM推理集成到模式配置和运动规划的联合优化中；3）使用树搜索模型预测控制和交替最小化求解优化问题；4）基于ROS的Python实现

Result: 高保真仿真结果显示，LAP在驾驶时间和成功率方面均优于其他基准方法

Conclusion: LAP通过LLM驱动的自适应规划，成功解决了混合规划器切换框架在密集交通环境中的局限性，实现了高速驾驶效率与安全精确操控的有效平衡

Abstract: Hybrid planner switching framework (HPSF) for autonomous driving needs to reconcile high-speed driving efficiency with safe maneuvering in dense traffic. Existing HPSF methods often fail to make reliable mode transitions or sustain efficient driving in congested environments, owing to heuristic scene recognition and low-frequency control updates. To address the limitation, this paper proposes LAP, a large language model (LLM) driven, adaptive planning method, which switches between high-speed driving in low-complexity scenes and precise driving in high-complexity scenes, enabling high qualities of trajectory generation through confined gaps. This is achieved by leveraging LLM for scene understanding and integrating its inference into the joint optimization of mode configuration and motion planning. The joint optimization is solved using tree-search model predictive control and alternating minimization. We implement LAP by Python in Robot Operating System (ROS). High-fidelity simulation results show that the proposed LAP outperforms other benchmarks in terms of both driving time and success rate.

</details>


### [103] [Multi-Modular MANTA-RAY: A Modular Soft Surface Platform for Distributed Multi-Object Manipulation](https://arxiv.org/abs/2601.21884)
*Pratik Ingle,Jørn Lambertsen,Kasper Støy,Andres Faina*

Main category: cs.RO

TL;DR: 多模块MANTA-RAY平台通过分布式模块化设计，在降低执行器密度的同时保持操控性能，实现了脆弱异质物体的可扩展并行操控。


<details>
  <summary>Details</summary>
Motivation: 现有密集执行器阵列虽然能产生复杂变形，但自由度太高导致系统复杂且难以扩展。单模块MANTA-RAY（4个执行器）已证明可行性，但多模块配置的可行性和优势尚未探索。

Method: 提出分布式模块化可扩展的MANTA-RAY平台，采用模块间物体传递策略和几何变换驱动的PID控制器，直接将倾斜角度控制输出映射到执行器命令，无需大量数据驱动或黑盒训练。

Result: 在3x3和4x4配置的仿真中评估性能，并通过2x2硬件原型验证可行性。系统成功操控了鸡蛋、苹果等具有不同几何形状、质量和质地的脆弱物体，并实现了并行操控。

Conclusion: 多模块MANTA-RAY提高了可扩展性，实现了大区域内多个物体的协调操控，展现了实际应用的潜力。

Abstract: Manipulation surfaces control objects by actively deforming their shape rather than directly grasping them. While dense actuator arrays can generate complex deformations, they also introduce high degrees of freedom (DOF), increasing system complexity and limiting scalability. The MANTA-RAY (Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation densitY) platform addresses these challenges by leveraging a soft, fabric-based surface with reduced actuator density to manipulate fragile and heterogeneous objects. Previous studies focused on single-module implementations supported by four actuators, whereas the feasibility and benefits of a scalable, multi-module configuration remain unexplored. In this work, we present a distributed, modular, and scalable variant of the MANTA-RAY platform that maintains manipulation performance with a reduced actuator density. The proposed multi-module MANTA-RAY platform and control strategy employs object passing between modules and a geometric transformation driven PID controller that directly maps tilt-angle control outputs to actuator commands, eliminating the need for extensive data-driven or black-box training. We evaluate system performance in simulation across surface configurations of varying modules (3x3 and 4x4) and validate its feasibility through experiments on a physical 2x2 hardware prototype. The system successfully manipulates objects with diverse geometries, masses, and textures including fragile items such as eggs and apples as well as enabling parallel manipulation. The results demonstrate that the multi-module MANTA-RAY improves scalability and enables coordinated manipulation of multiple objects across larger areas, highlighting its potential for practical, real-world applications.

</details>


### [104] [Information Filtering via Variational Regularization for Robot Manipulation](https://arxiv.org/abs/2601.21926)
*Jinhao Zhang,Wenlong Xia,Yaojia Wang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: 提出Variational Regularization (VR)方法，通过时间步条件高斯分布和KL散度正则化形成自适应信息瓶颈，减少扩散视觉运动策略中主干特征的冗余噪声，提升性能


<details>
  <summary>Details</summary>
Motivation: 现有基于3D视觉表示的扩散视觉运动策略使用过大的去噪解码器，虽然增加模型容量能改善去噪，但会引入中间特征块的冗余和噪声。研究发现推理时随机掩码主干特征能提升性能，证实了中间特征中存在任务无关噪声

Method: 提出Variational Regularization (VR)轻量模块，对主干特征施加时间步条件高斯分布，应用KL散度正则化器，形成自适应信息瓶颈，减少中间特征的冗余噪声

Result: 在三个仿真基准测试(RoboTwin2.0、Adroit、MetaWorld)上，相比基线DP3，成功率分别提升6.1%、4.1%和4.1%，达到新的最先进结果。真实世界实验也验证了方法的实际部署效果

Conclusion: VR方法通过自适应信息瓶颈有效减少扩散视觉运动策略中主干特征的冗余噪声，显著提升性能，在仿真和真实世界环境中都表现出色

Abstract: Diffusion-based visuomotor policies built on 3D visual representations have achieved strong performance in learning complex robotic skills. However, most existing methods employ an oversized denoising decoder. While increasing model capacity can improve denoising, empirical evidence suggests that it also introduces redundancy and noise in intermediate feature blocks. Crucially, we find that randomly masking backbone features at inference time (without changing training) can improve performance, confirming the presence of task-irrelevant noise in intermediate features. To this end, we propose Variational Regularization (VR), a lightweight module that imposes a timestep-conditioned Gaussian over backbone features and applies a KL-divergence regularizer, forming an adaptive information bottleneck. Extensive experiments on three simulation benchmarks (RoboTwin2.0, Adroit, and MetaWorld) show that, compared to the baseline DP3, our approach improves the success rate by 6.1% on RoboTwin2.0 and by 4.1% on Adroit and MetaWorld, achieving new state-of-the-art results. Real-world experiments further demonstrate that our method performs well in practical deployments. Code will released.

</details>


### [105] [MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts](https://arxiv.org/abs/2601.21971)
*Lorenzo Mazza,Ariel Rodriguez,Rayan Younis,Martin Lelis,Ortrun Hellig,Chenpan Li,Sebastian Bodenstedt,Martin Wagner,Stefanie Speidel*

Main category: cs.RO

TL;DR: 提出一种用于手术机器人模仿学习的监督混合专家架构，仅需不到150个演示即可从立体内窥镜图像学习复杂手术操作，在肠道抓取任务中表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 手术机器人模仿学习面临数据稀缺、工作空间受限、安全要求高等挑战，现有方法需要多摄像头或数千演示，难以实用化

Method: 提出监督混合专家架构，可集成到任何自主策略上，配合轻量级动作解码器策略，仅使用立体内窥镜图像和不到150个演示学习复杂手术操作

Result: 在肠道抓取任务中，该方法显著优于通用VLA模型和标准ACT基线，在分布内和分布外场景（新抓取位置、光照变化、遮挡）均表现更好，并能零样本迁移到离体猪组织

Conclusion: 监督MoE架构为手术机器人模仿学习提供了有效解决方案，仅需少量演示即可实现复杂操作，展现了向体内手术部署的潜力

Abstract: Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability. We present a supervised Mixture-of-Experts (MoE) architecture designed for phase-structured surgical manipulation tasks, which can be added on top of any autonomous policy. Unlike prior surgical robot learning approaches that rely on multi-camera setups or thousands of demonstrations, we show that a lightweight action decoder policy like Action Chunking Transformer (ACT) can learn complex, long-horizon manipulation from less than 150 demonstrations using solely stereo endoscopic images, when equipped with our architecture. We evaluate our approach on the collaborative surgical task of bowel grasping and retraction, where a robot assistant interprets visual cues from a human surgeon, executes targeted grasping on deformable tissue, and performs sustained retraction. We benchmark our method against state-of-the-art Vision-Language-Action (VLA) models and the standard ACT baseline. Our results show that generalist VLAs fail to acquire the task entirely, even under standard in-distribution conditions. Furthermore, while standard ACT achieves moderate success in-distribution, adopting a supervised MoE architecture significantly boosts its performance, yielding higher success rates in-distribution and demonstrating superior robustness in out-of-distribution scenarios, including novel grasp locations, reduced illumination, and partial occlusions. Notably, it generalizes to unseen testing viewpoints and also transfers zero-shot to ex vivo porcine tissue without additional training, offering a promising pathway toward in vivo deployment. To support this, we present qualitative preliminary results of policy roll-outs during in vivo porcine surgery.

</details>


### [106] [Macro-Scale Electrostatic Origami Motor](https://arxiv.org/abs/2601.21976)
*Alex S. Miller,Leo McElroy,Jeffrey H. Lang*

Main category: cs.RO

TL;DR: 开发了首个宏观尺度的可折叠折纸旋转电机，使用电晕放电产生扭矩，可折叠平整后展开运行


<details>
  <summary>Details</summary>
Motivation: 现有可折叠机器人要么在结构中嵌入线性执行器，要么附加非折叠旋转电机，且所有嵌入折叠介质的执行器都只产生线性或折叠运动，尚未有宏观尺度的可折叠连续旋转执行器

Method: 采用折纸结构设计旋转电机，利用电晕放电产生扭矩，实现可折叠平整后展开运行的功能

Result: 原型电机实现了2.5:1的扩展比，在-29 kV驱动下达到1440 rpm的最高转速，最大输出扭矩超过0.15 mN·m，主动部件扭矩密度为0.04 Nm/kg

Conclusion: 成功开发了首个宏观尺度的可折叠折纸旋转电机，为可折叠机器人提供了连续旋转运动的新解决方案

Abstract: Foldable robots have been an active area of robotics research due to their high volume-to-mass ratio, easy packability, and shape adaptability. For locomotion, previously developed foldable robots have either embedded linear actuators in, or attached non-folding rotary motors to, their structure. Further, those actuators directly embedded in the structure of the folding medium all contributed to linear or folding motion, not to continuous rotary motion. On the macro-scale there has not yet been a folding continuous rotary actuator. This paper details the development and testing of the first macro-scale origami rotary motor that can be folded flat, and then unfurled to operate. Using corona discharge for torque production, the prototype motor achieved an expansion ratio of 2.5:1, reached a top speed of 1440 rpm when driven at -29 kV, and exhibited a maximum output torque over 0.15 mN m with an active component torque density of 0.04 Nm/kg.

</details>


### [107] [PocketDP3: Efficient Pocket-Scale 3D Visuomotor Policy](https://arxiv.org/abs/2601.22018)
*Jinhao Zhang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Wenlong Xia,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: PocketDP3：一种轻量级3D扩散策略，用Diffusion Mixer替代传统U-Net解码器，参数减少99%以上，支持两步推理，在多个仿真基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉扩散策略存在架构不匹配问题：小型点云编码器搭配庞大的解码器，导致解码器参数浪费严重。需要更高效的架构设计。

Method: 提出PocketDP3，用基于MLP-Mixer块的轻量级Diffusion Mixer替代传统条件U-Net解码器，实现时间和通道维度的高效融合。

Result: 在RoboTwin2.0、Adroit和MetaWorld三个仿真基准上达到SOTA性能，参数少于之前方法的1%，推理速度更快，无需一致性蒸馏即可支持两步推理。

Conclusion: PocketDP3通过轻量级架构设计解决了参数浪费问题，在保持高性能的同时大幅减少模型规模，提高了实时部署的实用性，并在真实世界实验中验证了可迁移性。

Abstract: Recently, 3D vision-based diffusion policies have shown strong capability in learning complex robotic manipulation skills. However, a common architectural mismatch exists in these models: a tiny yet efficient point-cloud encoder is often paired with a massive decoder. Given a compact scene representation, we argue that this may lead to substantial parameter waste in the decoder. Motivated by this observation, we propose PocketDP3, a pocket-scale 3D diffusion policy that replaces the heavy conditional U-Net decoder used in prior methods with a lightweight Diffusion Mixer (DiM) built on MLP-Mixer blocks. This architecture enables efficient fusion across temporal and channel dimensions, significantly reducing model size. Notably, without any additional consistency distillation techniques, our method supports two-step inference without sacrificing performance, improving practicality for real-time deployment. Across three simulation benchmarks--RoboTwin2.0, Adroit, and MetaWorld--PocketDP3 achieves state-of-the-art performance with fewer than 1% of the parameters of prior methods, while also accelerating inference. Real-world experiments further demonstrate the practicality and transferability of our method in real-world settings. Code will be released.

</details>


### [108] [mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning](https://arxiv.org/abs/2601.22074)
*Kevin Zakka,Qiayuan Liao,Brent Yi,Louis Le Lay,Koushil Sreenath,Pieter Abbeel*

Main category: cs.RO

TL;DR: mjlab是一个轻量级开源机器人学习框架，结合GPU加速模拟、可组合环境和最小化设置复杂度


<details>
  <summary>Details</summary>
Motivation: 提供易于安装、依赖少、能直接访问MuJoCo原生数据结构的机器人学习框架，降低使用门槛

Method: 采用Isaac Lab引入的基于管理器的API，结合MuJoCo Warp进行GPU加速物理模拟，用户可组合模块化构建块

Result: 实现单命令安装、最小依赖、直接访问MuJoCo原生数据结构，提供速度跟踪、运动模仿和操作任务的参考实现

Conclusion: mjlab为机器人学习提供了一个轻量级、易用且高效的框架，特别适合需要GPU加速模拟的研究和应用

Abstract: We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, rewards, and events, and pairs it with MuJoCo Warp for GPU-accelerated physics. The result is a framework installable with a single command, requiring minimal dependencies, and providing direct access to native MuJoCo data structures. mjlab ships with reference implementations of velocity tracking, motion imitation, and manipulation tasks.

</details>


### [109] [ReactEMG Stroke: Healthy-to-Stroke Few-shot Adaptation for sEMG-Based Intent Detection](https://arxiv.org/abs/2601.22090)
*Runsheng Wang,Katelyn Lee,Xinyue Zhu,Lauren Winterbottom,Dawn M. Nilsen,Joel Stein,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 利用健康人群sEMG预训练模型，通过少量卒中患者数据微调，显著提升卒中后手部康复意图检测的准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 卒中后手部康复的表面肌电信号(sEMG)意图检测通常需要冗长的特定患者校准，且对信号变化敏感。现有方法在零样本迁移或仅使用卒中数据训练时性能有限，需要更高效、鲁棒的解决方案。

Method: 提出健康到卒中的适应管道：首先在大型健康人群sEMG数据集上预训练意图检测模型，然后使用少量卒中患者特定数据进行微调。比较了三种适应策略：仅头部调优、参数高效的LoRA适配器和端到端微调。

Result: 在包含三名慢性卒中患者的新数据集上测试，健康预训练适应方法在多种分布偏移条件下（会话内漂移、姿势变化、臂带重新定位）均优于零样本迁移和仅使用卒中数据训练。最佳适应方法将平均过渡准确率从0.42提升到0.61，原始准确率从0.69提升到0.78。

Conclusion: 迁移可重复使用的健康领域EMG表示可以减少校准负担，同时提高卒中后实时意图检测的鲁棒性，为辅助康复提供更实用的解决方案。

Abstract: Surface electromyography (sEMG) is a promising control signal for assist-as-needed hand rehabilitation after stroke, but detecting intent from paretic muscles often requires lengthy, subject-specific calibration and remains brittle to variability. We propose a healthy-to-stroke adaptation pipeline that initializes an intent detector from a model pretrained on large-scale able-bodied sEMG, then fine-tunes it for each stroke participant using only a small amount of subject-specific data. Using a newly collected dataset from three individuals with chronic stroke, we compare adaptation strategies (head-only tuning, parameter-efficient LoRA adapters, and full end-to-end fine-tuning) and evaluate on held-out test sets that include realistic distribution shifts such as within-session drift, posture changes, and armband repositioning. Across conditions, healthy-pretrained adaptation consistently improves stroke intent detection relative to both zero-shot transfer and stroke-only training under the same data budget; the best adaptation methods improve average transition accuracy from 0.42 to 0.61 and raw accuracy from 0.69 to 0.78. These results suggest that transferring a reusable healthy-domain EMG representation can reduce calibration burden while improving robustness for real-time post-stroke intent detection.

</details>


### [110] [DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation](https://arxiv.org/abs/2601.22153)
*Haozhe Xie,Beichen Wen,Jiarui Zheng,Zhaoxi Chen,Fangzhou Hong,Haiwen Diao,Ziwei Liu*

Main category: cs.RO

TL;DR: DynamicVLA是一个用于动态物体操作的VLA框架，通过紧凑模型架构、连续推理和潜在感知动作流式传输来解决动态场景中的感知、时序预测和连续控制挑战，并在新构建的DOM基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在静态操作中表现良好，但在需要快速感知、时序预测和连续控制的动态场景中表现不佳。动态物体操作是一个开放挑战，缺乏专门的基准数据集。

Method: 提出DynamicVLA框架，包含三个关键设计：1) 使用卷积视觉编码器的紧凑0.4B VLA模型；2) 连续推理实现重叠推理和执行；3) 潜在感知动作流式传输确保时序对齐的动作执行。同时构建了DOM基准数据集。

Result: 在响应速度、感知能力和泛化能力方面取得显著改进，DynamicVLA成为跨具身智能的统一动态物体操作框架。DOM数据集包含200K合成episodes和2K真实世界episodes。

Conclusion: DynamicVLA通过整合时序推理和闭环适应，成功解决了动态物体操作的挑战，为通用动态操作提供了一个统一的框架，并在新构建的DOM基准上验证了其有效性。

Abstract: Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.

</details>
