<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing](https://arxiv.org/abs/2510.05213)
*Yixiao Wang,Mingxiao Huo,Zhixuan Liang,Yushi Du,Lingfeng Sun,Haotian Lin,Jinghuan Shang,Chensheng Peng,Mohit Bansal,Mingyu Ding,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: VER是一个用于机器人学习的视觉专家变换器，通过将多个预训练视觉基础模型蒸馏到专家库中，并使用轻量级路由网络动态选择任务相关专家，实现跨任务的通用视觉表示。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉基础模型通常在特定领域表现优异，但缺乏跨任务的通用性。将多个模型蒸馏为统一表示可以缓解这个问题，但传统方法存在特征选择不灵活和重新训练成本高的问题。

Method: 提出VER框架：1）预训练阶段将多个VFMs蒸馏到视觉专家库；2）微调阶段仅训练轻量级路由网络（<0.4%参数）动态选择专家；3）引入补丁级专家路由和课程Top-K退火策略；4）支持参数高效微调。

Result: 在17个多样化机器人任务和多种策略头上，VER实现了最先进的性能。它减少了任务无关区域的大范数异常值，并集中在任务关键区域。

Conclusion: VER通过动态专家选择和高效微调机制，成功解决了多视觉基础模型在机器人学习中的通用性问题，实现了优异的跨任务性能。

Abstract: Pretrained vision foundation models (VFMs) advance robotic learning via rich
visual representations, yet individual VFMs typically excel only in specific
domains, limiting generality across tasks. Distilling multiple VFMs into a
unified representation for policy can mitigate this limitation but often yields
inflexible task-specific feature selection and requires costly full re-training
to incorporate robot-domain knowledge. We propose VER, a Vision Expert
transformer for Robot learning. During pretraining, VER distills multiple VFMs
into a vision expert library. It then fine-tunes only a lightweight routing
network (fewer than 0.4% of parameters) to dynamically select task-relevant
experts from the pretrained library for downstream robot tasks. We further
introduce Patchwise Expert Routing with Curriculum Top-K Annealing to improve
both flexibility and precision of dynamic expert selection. Moreover, VER
supports parameter-efficient finetuning for scalable expert utilization and
adaptive robot-domain knowledge integration. Across 17 diverse robotic tasks
and multiple policy heads, VER achieves state-of-the-art performance. We find
that VER reduces large-norm outliers in task-irrelevant regions (e.g.,
background) and concentrates on task-critical regions. Visualizations and codes
can be found in https://yixiaowang7.github.io/ver_page/.

</details>


### [2] [Adaptive Dynamics Planning for Robot Navigation](https://arxiv.org/abs/2510.05330)
*Lu Yuanjie,Mao Mingyang,Xu Tong,Wang Linji,Lin Xiaomin,Xiao Xuesu*

Main category: cs.RO

TL;DR: 提出自适应动力学规划(ADP)，通过强化学习动态调整机器人动力学特性，使规划器能适应不同环境复杂度，提高导航成功率、安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统分层规划中全局规划不考虑动力学，局部规划强制执行动力学约束，这种动力学不连续性在受限环境中容易导致轨迹跟踪失败。现有方法采用固定方案降低动力学保真度，无法适应环境复杂度的变化。

Method: 使用强化学习动态调整机器人动力学属性，将ADP集成到三种不同规划器中，并设计了独立的ADP导航系统进行基准测试。

Result: 在仿真和真实世界测试中，ADP持续提高了导航成功率、安全性和效率。

Conclusion: ADP通过学习增强的范式有效解决了传统规划方法在动力学处理上的不足，实现了跨环境的自适应规划。

Abstract: Autonomous robot navigation systems often rely on hierarchical planning,
where global planners compute collision-free paths without considering
dynamics, and local planners enforce dynamics constraints to produce executable
commands. This discontinuity in dynamics often leads to trajectory tracking
failure in highly constrained environments. Recent approaches integrate
dynamics within the entire planning process by gradually decreasing its
fidelity, e.g., increasing integration steps and reducing collision checking
resolution, for real-time planning efficiency. However, they assume that the
fidelity of the dynamics should decrease according to a manually designed
scheme. Such static settings fail to adapt to environmental complexity
variations, resulting in computational overhead in simple environments or
insufficient dynamics consideration in obstacle-rich scenarios. To overcome
this limitation, we propose Adaptive Dynamics Planning (ADP), a
learning-augmented paradigm that uses reinforcement learning to dynamically
adjust robot dynamics properties, enabling planners to adapt across diverse
environments. We integrate ADP into three different planners and further design
a standalone ADP-based navigation system, benchmarking them against other
baselines. Experiments in both simulation and real-world tests show that ADP
consistently improves navigation success, safety, and efficiency.

</details>


### [3] [A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation](https://arxiv.org/abs/2510.05382)
*Zhuowei Xu,Zilin Si,Kevin Zhang,Oliver Kroemer,Zeynep Temel*

Main category: cs.RO

TL;DR: 提出了一种低成本、易制造、适应性强的机器人指尖设计，集成多模态触觉传感器，包括应变片传感器和接触式麦克风传感器，用于提升机器人操作的精确性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 触觉感知在提升机器人操作精度和多功能性方面具有巨大潜力，但由于传感器成本高、制造和集成困难以及从信号中提取可靠信息的挑战，其在机器人手中的应用仍然有限。

Method: 设计了一种紧凑的指尖结构，集成应变片传感器用于捕捉静态力，接触式麦克风传感器用于测量高频振动。所有传感器都内置在指尖内部，不易受到直接磨损。

Result: 传感器特性测试显示，应变片传感器在0-5N范围内提供可重复的二维平面力测量，接触式麦克风传感器能够区分接触材料特性。在三个灵巧操作任务中，触觉传感器单独或与视觉观察结合使用，显著提升了任务性能。

Conclusion: 多模态触觉传感器设计能够灵活应用于不同操作阶段，仅使用触觉或与视觉结合都能提高任务完成率，例如从堆叠中精确计数和取下指定数量的纸杯，成功率可达100%。

Abstract: Tactile sensing holds great promise for enhancing manipulation precision and
versatility, but its adoption in robotic hands remains limited due to high
sensor costs, manufacturing and integration challenges, and difficulties in
extracting expressive and reliable information from signals. In this work, we
present a low-cost, easy-to-make, adaptable, and compact fingertip design for
robotic hands that integrates multi-modal tactile sensors. We use strain gauge
sensors to capture static forces and a contact microphone sensor to measure
high-frequency vibrations during contact. These tactile sensors are integrated
into a compact design with a minimal sensor footprint, and all sensors are
internal to the fingertip and therefore not susceptible to direct wear and tear
from interactions. From sensor characterization, we show that strain gauge
sensors provide repeatable 2D planar force measurements in the 0-5 N range and
the contact microphone sensor has the capability to distinguish contact
material properties. We apply our design to three dexterous manipulation tasks
that range from zero to full visual occlusion. Given the expressiveness and
reliability of tactile sensor readings, we show that different tactile sensing
modalities can be used flexibly in different stages of manipulation, solely or
together with visual observations to achieve improved task performance. For
instance, we can precisely count and unstack a desired number of paper cups
from a stack with 100\% success rate which is hard to achieve with vision only.

</details>


### [4] [Towards Online Robot Interaction Adaptation to Human Upper-limb Mobility Impairments in Return-to-Work Scenarios](https://arxiv.org/abs/2510.05425)
*Marta Lagomarsino,Francesco Tassi*

Main category: cs.RO

TL;DR: 提出了一种新型在线自适应人机交互框架，专门针对上肢残疾用户，通过整合关节活动度限制模型到分层最优控制器中，使机器人能够实时生成适应性的行为。


<details>
  <summary>Details</summary>
Motivation: 传统的人机协作方法假设用户身体健全，无法满足上肢残疾人士的工作环境需求，因此需要开发能够适应不同上肢活动障碍的包容性交互系统。

Method: 将特定关节活动度限制模型整合到分层最优控制器中，使机器人能够在线生成反应性、活动度感知的行为，并引导用户利用残余功能活动度。

Result: 在涉及不同上肢活动障碍的手递手任务中测试，结果表明该框架能够个性化交互以适应用户的受损活动范围，并根据功能限制严重程度鼓励关节使用。

Conclusion: 该框架能够有效促进上肢残疾用户的积极参与工作，通过适应性交互提升工作环境的包容性。

Abstract: Work environments are often inadequate and lack inclusivity for individuals
with upper-body disabilities. This paper presents a novel online framework for
adaptive human-robot interaction (HRI) that accommodates users' arm mobility
impairments, ultimately aiming to promote active work participation. Unlike
traditional human-robot collaboration approaches that assume able-bodied users,
our method integrates a mobility model for specific joint limitations into a
hierarchical optimal controller. This allows the robot to generate reactive,
mobility-aware behaviour online and guides the user's impaired limb to exploit
residual functional mobility. The framework was tested in handover tasks
involving different upper-limb mobility impairments (i.e., emulated elbow and
shoulder arthritis, and wrist blockage), under both standing and seated
configurations with task constraints using a mobile manipulator, and
complemented by quantitative and qualitative comparisons with state-of-the-art
ergonomic HRI approaches. Preliminary results indicated that the framework can
personalise the interaction to fit within the user's impaired range of motion
and encourage joint usage based on the severity of their functional
limitations.

</details>


### [5] [Active Semantic Perception](https://arxiv.org/abs/2510.05430)
*Huayi Tang,Pratik Chaudhari*

Main category: cs.RO

TL;DR: 提出了一种主动语义感知方法，通过构建层次化多图层场景图来表示室内环境，并利用LLM采样未观测区域的合理场景图来计算信息增益，从而更快速准确地确定环境语义。


<details>
  <summary>Details</summary>
Motivation: 开发能够利用场景语义进行探索等任务的主动感知方法，解决复杂室内环境中语义理解的问题。

Method: 构建紧凑的层次化多图层场景图表示环境，使用LLM基于部分观测采样未观测区域的合理场景图，计算信息增益进行空间推理。

Result: 在复杂3D室内环境模拟中验证，相比基线方法能更快更准确地确定环境语义。

Conclusion: 该方法通过结合场景图和LLM采样，有效提升了主动语义感知的性能，在复杂室内环境中表现出色。

Abstract: We develop an approach for active semantic perception which refers to using
the semantics of the scene for tasks such as exploration. We build a compact,
hierarchical multi-layer scene graph that can represent large, complex indoor
environments at various levels of abstraction, e.g., nodes corresponding to
rooms, objects, walls, windows etc. as well as fine-grained details of their
geometry. We develop a procedure based on large language models (LLMs) to
sample plausible scene graphs of unobserved regions that are consistent with
partial observations of the scene. These samples are used to compute an
information gain of a potential waypoint for sophisticated spatial reasoning,
e.g., the two doors in the living room can lead to either a kitchen or a
bedroom. We evaluate this approach in complex, realistic 3D indoor environments
in simulation. We show using qualitative and quantitative experiments that our
approach can pin down the semantics of the environment quicker and more
accurately than baseline approaches.

</details>


### [6] [AD-NODE: Adaptive Dynamics Learning with Neural ODEs for Mobile Robots Control](https://arxiv.org/abs/2510.05443)
*Shao-Yi Yu,Jen-Wei Wang,Maya Horii,Vikas Garg,Tarek Zohdi*

Main category: cs.RO

TL;DR: 提出了一种自适应动力学模型，通过从状态-动作历史推断操作环境，无需直接环境知识即可适应变化的环境条件，并与模型预测控制集成。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在不确定环境中需要能够响应环境变化的动力学模型，特别是在难以直接获取环境信息的情况下。

Method: 基于神经常微分方程构建自适应动力学模型，采用两阶段训练程序学习潜在环境表示，通过状态-动作历史推断环境变化。

Result: 在三个机器人平台上验证了方法的有效性：2D差动轮式机器人、3D四旋翼飞行器和Sphero BOLT机器人，能够处理时间和空间上的环境变化。

Conclusion: 该方法能够在仿真和真实系统中有效处理环境变化，为移动机器人在不确定环境中的自适应控制提供了可行方案。

Abstract: Mobile robots, such as ground vehicles and quadrotors, are becoming
increasingly important in various fields, from logistics to agriculture, where
they automate processes in environments that are difficult to access for
humans. However, to perform effectively in uncertain environments using
model-based controllers, these systems require dynamics models capable of
responding to environmental variations, especially when direct access to
environmental information is limited. To enable such adaptivity and facilitate
integration with model predictive control, we propose an adaptive dynamics
model which bypasses the need for direct environmental knowledge by inferring
operational environments from state-action history. The dynamics model is based
on neural ordinary equations, and a two-phase training procedure is used to
learn latent environment representations. We demonstrate the effectiveness of
our approach through goal-reaching and path-tracking tasks on three robotic
platforms of increasing complexity: a 2D differential wheeled robot with
changing wheel contact conditions, a 3D quadrotor in variational wind fields,
and the Sphero BOLT robot under two contact conditions for real-world
deployment. Empirical results corroborate that our method can handle temporally
and spatially varying environmental changes in both simulation and real-world
systems.

</details>


### [7] [Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation](https://arxiv.org/abs/2510.05536)
*Mahboubeh Zarei,Robin Chhabra,Farrokh Janabi-Sharifi*

Main category: cs.RO

TL;DR: 提出了一种用于机器人操作器的去中心化双视角融合方法，通过手眼和固定视觉传感器配置来估计目标物体的位姿和速度。


<details>
  <summary>Details</summary>
Motivation: 精确的位姿和速度估计对于机器人操作器的空间任务规划至关重要，传统集中式传感器融合方法存在局限性。

Method: 使用两个独立的自适应扩展卡尔曼滤波器在矩阵李群上运行，预测位姿和速度，并通过相关性感知融合规则在SE(3)流形上融合状态。

Result: 在配备Intel RealSense相机的UFactory xArm 850上进行实验，验证了该方法的有效性和鲁棒性，相比现有方法有持续改进。

Conclusion: 提出的去中心化双视角估计框架能够有效估计目标物体的位姿和速度，在机器人操作任务中表现出优越性能。

Abstract: Accurate pose and velocity estimation is essential for effective spatial task
planning in robotic manipulators. While centralized sensor fusion has
traditionally been used to improve pose estimation accuracy, this paper
presents a novel decentralized fusion approach to estimate both pose and
velocity. We use dual-view measurements from an eye-in-hand and an eye-to-hand
vision sensor configuration mounted on a manipulator to track a target object
whose motion is modeled as random walk (stochastic acceleration model). The
robot runs two independent adaptive extended Kalman filters formulated on a
matrix Lie group, developed as part of this work. These filters predict poses
and velocities on the manifold $\mathbb{SE}(3) \times \mathbb{R}^3 \times
\mathbb{R}^3$ and update the state on the manifold $\mathbb{SE}(3)$. The final
fused state comprising the fused pose and velocities of the target is obtained
using a correlation-aware fusion rule on Lie groups. The proposed method is
evaluated on a UFactory xArm 850 equipped with Intel RealSense cameras,
tracking a moving target. Experimental results validate the effectiveness and
robustness of the proposed decentralized dual-view estimation framework,
showing consistent improvements over state-of-the-art methods.

</details>


### [8] [ARRC: Advanced Reasoning Robot Control - Knowledge-Driven Autonomous Manipulation Using Retrieval-Augmented Generation](https://arxiv.org/abs/2510.05547)
*Eugene Vorobiov,Ammar Jaleel Mahmood,Salim Rezvani,Robin Chhabra*

Main category: cs.RO

TL;DR: ARRC系统结合检索增强生成与RGB-D感知，通过安全门控执行将自然语言指令转换为机器人动作计划，在低成本机械臂上实现桌面扫描、接近和拾取放置任务。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言指令到安全本地机器人控制的连接问题，通过结合RAG技术提高计划的有效性和适应性，同时保持感知和底层控制的本地化。

Method: 使用向量数据库索引机器人知识，检索任务相关上下文，通过大语言模型生成JSON结构化动作计划，在UFactory xArm 850机械臂上执行，采用AprilTag检测与深度融合进行感知，通过软件安全门控确保执行安全。

Result: 实验结果表明该方法能有效提高计划的有效性和适应性，在桌面任务中表现良好。

Conclusion: 基于RAG的规划可以显著改善计划的有效性和适应性，同时保持感知和底层控制的本地化，为自然语言指令到机器人控制的连接提供了实用解决方案。

Abstract: We present ARRC (Advanced Reasoning Robot Control), a practical system that
connects natural-language instructions to safe local robotic control by
combining Retrieval-Augmented Generation (RAG) with RGB-D perception and
guarded execution on an affordable robot arm. The system indexes curated robot
knowledge (movement patterns, task templates, and safety heuristics) in a
vector database, retrieves task-relevant context for each instruction, and
conditions a large language model (LLM) to produce JSON-structured action
plans. Plans are executed on a UFactory xArm 850 fitted with a Dynamixel-driven
parallel gripper and an Intel RealSense D435 camera. Perception uses AprilTag
detections fused with depth to produce object-centric metric poses. Execution
is enforced via software safety gates: workspace bounds, speed and force caps,
timeouts, and bounded retries. We describe the architecture, knowledge design,
integration choices, and a reproducible evaluation protocol for tabletop scan,
approach, and pick-place tasks. Experimental results demonstrate the efficacy
of the proposed approach. Our design shows that RAG-based planning can
substantially improve plan validity and adaptability while keeping perception
and low-level control local to the robot.

</details>


### [9] [GO-Flock: Goal-Oriented Flocking in 3D Unknown Environments with Depth Maps](https://arxiv.org/abs/2510.05553)
*Yan Rui Tan,Wenqi Liu,Wai Lun Leong,John Guan Zhong Tan,Wayne Wen Huei Yong,Fan Shi,Rodney Swee Huat Teo*

Main category: cs.RO

TL;DR: GO-Flock是一个混合群体控制框架，结合规划与反应式人工势场控制，解决了传统APF方法在障碍物环境中容易陷入局部最小值和死锁的问题。


<details>
  <summary>Details</summary>
Motivation: 传统人工势场方法在群体控制中存在局部最小值和死锁问题，现有解决方案多为被动式，导致群体导航效率低下，且大多只在无障碍环境或简化模拟中验证。

Method: GO-Flock包含上游感知模块（处理深度图提取路径点和虚拟代理用于避障）和下游群体导航模块（应用新型APF策略实现有效群体行为）。

Result: 与被动APF方法相比，GO-Flock在障碍物密集环境中表现出更好的群体行为和克服局部最小值的能力，成功在森林环境中控制了9架无人机（6架实体+3架虚拟）的群体飞行。

Conclusion: GO-Flock通过整合规划与反应式控制，有效解决了传统APF方法在复杂环境中的局限性，实现了在障碍物密集环境中的高效群体导航。

Abstract: Artificial Potential Field (APF) methods are widely used for reactive
flocking control, but they often suffer from challenges such as deadlocks and
local minima, especially in the presence of obstacles. Existing solutions to
address these issues are typically passive, leading to slow and inefficient
collective navigation. As a result, many APF approaches have only been
validated in obstacle-free environments or simplified, pseudo 3D simulations.
This paper presents GO-Flock, a hybrid flocking framework that integrates
planning with reactive APF-based control. GO-Flock consists of an upstream
Perception Module, which processes depth maps to extract waypoints and virtual
agents for obstacle avoidance, and a downstream Collective Navigation Module,
which applies a novel APF strategy to achieve effective flocking behavior in
cluttered environments. We evaluate GO-Flock against passive APF-based
approaches to demonstrate their respective merits, such as their flocking
behavior and the ability to overcome local minima. Finally, we validate
GO-Flock through obstacle-filled environment and also hardware-in-the-loop
experiments where we successfully flocked a team of nine drones, six physical
and three virtual, in a forest environment.

</details>


### [10] [DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation](https://arxiv.org/abs/2510.05662)
*Taeyeop Lee,Gyuree Kang,Bowen Wen,Youngho Kim,Seunghyeok Back,In So Kweon,David Hyunchul Shim,Kuk-Jin Yoon*

Main category: cs.RO

TL;DR: DeLTa框架通过整合深度估计、6D姿态估计和视觉语言规划，实现了对透明物体的精确长时程操作，仅需单次演示即可泛化到新物体。


<details>
  <summary>Details</summary>
Motivation: 透明物体操作研究目前局限于短时程任务和基本抓取能力，现有方法对新物体的泛化性不足，难以实现精确的长时程操作。

Method: 提出DeLTa框架，结合深度估计、6D姿态估计和视觉语言规划，采用单次演示方法将6D轨迹泛化到新透明物体，无需类别先验或额外训练。

Result: 综合评估表明，该方法在长时程场景中显著优于现有透明物体操作方法，特别是在需要精确操作能力的任务中。

Conclusion: DeLTa框架成功解决了透明物体长时程精确操作的挑战，展示了在单次演示下对新物体的良好泛化能力。

Abstract: Despite the prevalence of transparent object interactions in human everyday
life, transparent robotic manipulation research remains limited to
short-horizon tasks and basic grasping capabilities.Although some methods have
partially addressed these issues, most of them have limitations in
generalizability to novel objects and are insufficient for precise long-horizon
robot manipulation. To address this limitation, we propose DeLTa (Demonstration
and Language-Guided Novel Transparent Object Manipulation), a novel framework
that integrates depth estimation, 6D pose estimation, and vision-language
planning for precise long-horizon manipulation of transparent objects guided by
natural task instructions. A key advantage of our method is its
single-demonstration approach, which generalizes 6D trajectories to novel
transparent objects without requiring category-level priors or additional
training. Additionally, we present a task planner that refines the
VLM-generated plan to account for the constraints of a single-arm, eye-in-hand
robot for long-horizon object manipulation tasks. Through comprehensive
evaluation, we demonstrate that our method significantly outperforms existing
transparent object manipulation approaches, particularly in long-horizon
scenarios requiring precise manipulation capabilities. Project page:
https://sites.google.com/view/DeLTa25/

</details>


### [11] [Verifier-free Test-Time Sampling for Vision Language Action Models](https://arxiv.org/abs/2510.05681)
*Suhyeok Jang,Dongyoung Kim,Changyeon Kim,Youngsuk Kim,Jinwoo Shin*

Main category: cs.RO

TL;DR: 提出了MG-Select方法，通过利用VLA模型的内部特性，在测试时使用KL散度作为置信度指标来选择最优动作，无需额外训练或外部模块。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在需要高精度的任务中存在根本性限制，而基于外部验证器的测试时缩放方法需要额外训练且无法泛化到未见条件。

Method: 使用随机掩码状态和语言条件生成的参考分布来计算KL散度，并引入联合训练策略让模型学习条件和非条件分布。

Result: 在真实世界任务中，分布内/分布外任务分别提升28%/35%，在RoboCasa拾放任务上相对增益达168%。

Conclusion: MG-Select框架显著提升了VLA模型的性能，特别是在需要高精度的机器人控制任务中。

Abstract: Vision-Language-Action models (VLAs) have demonstrated remarkable performance
in robot control. However, they remain fundamentally limited in tasks that
require high precision due to their single-inference paradigm. While test-time
scaling approaches using external verifiers have shown promise, they require
additional training and fail to generalize to unseen conditions. We propose
Masking Distribution Guided Selection (MG-Select), a novel test-time scaling
framework for VLAs that leverages the model's internal properties without
requiring additional training or external modules. Our approach utilizes KL
divergence from a reference action token distribution as a confidence metric
for selecting the optimal action from multiple candidates. We introduce a
reference distribution generated by the same VLA but with randomly masked
states and language conditions as inputs, ensuring maximum uncertainty while
remaining aligned with the target task distribution. Additionally, we propose a
joint training strategy that enables the model to learn both conditional and
unconditional distributions by applying dropout to state and language
conditions, thereby further improving the quality of the reference
distribution. Our experiments demonstrate that MG-Select achieves significant
performance improvements, including a 28%/35% improvement in real-world
in-distribution/out-of-distribution tasks, along with a 168% relative gain on
RoboCasa pick-and-place tasks trained with 30 demonstrations.

</details>


### [12] [Oracle-Guided Masked Contrastive Reinforcement Learning for Visuomotor Policies](https://arxiv.org/abs/2510.05692)
*Yuhang Zhang,Jiaping Xiao,Chao Yan,Mir Feroskhan*

Main category: cs.RO

TL;DR: OMC-RL是一种新颖的视觉运动策略学习框架，通过两阶段学习（上游表示学习和下游策略学习）解决高维视觉输入和敏捷动作输出带来的样本效率低和仿真到现实差距大的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法直接将高维视觉观察映射到动作命令存在样本效率低和显著的仿真到现实差距问题，需要更有效的学习框架。

Method: 采用两阶段学习：上游阶段使用带掩码的Transformer模块进行时序建模和对比学习提取任务相关表示；下游阶段使用具有全局状态信息的oracle教师策略在早期训练中提供指导，并逐步减少指导以促进独立探索。

Result: 在仿真和真实环境中的广泛实验表明，OMC-RL实现了优越的样本效率和渐进策略性能，同时提高了在多样化和感知复杂场景中的泛化能力。

Conclusion: OMC-RL框架通过解耦表示学习和策略学习，结合教师指导和对比学习，有效提升了视觉运动策略学习的效率和性能。

Abstract: A prevailing approach for learning visuomotor policies is to employ
reinforcement learning to map high-dimensional visual observations directly to
action commands. However, the combination of high-dimensional visual inputs and
agile maneuver outputs leads to long-standing challenges, including low sample
efficiency and significant sim-to-real gaps. To address these issues, we
propose Oracle-Guided Masked Contrastive Reinforcement Learning (OMC-RL), a
novel framework designed to improve the sample efficiency and asymptotic
performance of visuomotor policy learning. OMC-RL explicitly decouples the
learning process into two stages: an upstream representation learning stage and
a downstream policy learning stage. In the upstream stage, a masked Transformer
module is trained with temporal modeling and contrastive learning to extract
temporally-aware and task-relevant representations from sequential visual
inputs. After training, the learned encoder is frozen and used to extract
visual representations from consecutive frames, while the Transformer module is
discarded. In the downstream stage, an oracle teacher policy with privileged
access to global state information supervises the agent during early training
to provide informative guidance and accelerate early policy learning. This
guidance is gradually reduced to allow independent exploration as training
progresses. Extensive experiments in simulated and real-world environments
demonstrate that OMC-RL achieves superior sample efficiency and asymptotic
policy performance, while also improving generalization across diverse and
perceptually complex scenarios.

</details>


### [13] [Stable Robot Motions on Manifolds: Learning Lyapunov-Constrained Neural Manifold ODEs](https://arxiv.org/abs/2510.05707)
*David Boetius,Abdelrahman Abdelnaby,Ashok Kumar,Stefan Leue,Abdalla Swikir,Fares J. Abu-Dakka*

Main category: cs.RO

TL;DR: 提出了一种在黎曼流形上学习稳定动力系统的通用框架，使用神经常微分方程保证李雅普诺夫稳定性，适用于机器人运动规划。


<details>
  <summary>Details</summary>
Motivation: 从数据中学习稳定动力系统对机器人运动规划至关重要，但将稳定性保证扩展到黎曼流形上的轨迹面临几何约束的挑战。

Method: 使用神经常微分方程，通过投影神经向量场使其严格满足李雅普诺夫稳定性准则，利用灵活的神经参数化表示基向量场和李雅普诺夫函数。

Result: 在单位四元数(S^3)和对称正定矩阵流形上解决了黎曼LASA数据集，并在真实机器人实验中验证了性能。

Conclusion: 该方法在黎曼流形上实现了稳定动力系统的学习，具有良好的性能、可扩展性和实际应用价值。

Abstract: Learning stable dynamical systems from data is crucial for safe and reliable
robot motion planning and control. However, extending stability guarantees to
trajectories defined on Riemannian manifolds poses significant challenges due
to the manifold's geometric constraints. To address this, we propose a general
framework for learning stable dynamical systems on Riemannian manifolds using
neural ordinary differential equations. Our method guarantees stability by
projecting the neural vector field evolving on the manifold so that it strictly
satisfies the Lyapunov stability criterion, ensuring stability at every system
state. By leveraging a flexible neural parameterisation for both the base
vector field and the Lyapunov function, our framework can accurately represent
complex trajectories while respecting manifold constraints by evolving
solutions directly on the manifold. We provide an efficient training strategy
for applying our framework and demonstrate its utility by solving Riemannian
LASA datasets on the unit quaternion (S^3) and symmetric positive-definite
matrix manifolds, as well as robotic motions evolving on \mathbb{R}^3 \times
S^3. We demonstrate the performance, scalability, and practical applicability
of our approach through extensive simulations and by learning robot motions in
a real-world experiment.

</details>


### [14] [Federated Split Learning for Resource-Constrained Robots in Industrial IoT: Framework Comparison, Optimization Strategies, and Future Directions](https://arxiv.org/abs/2510.05713)
*Wanli Ni,Hui Tian,Shuai Wang,Chengyang Li,Lei Sun,Zhaohui Yang*

Main category: cs.RO

TL;DR: 本文对联邦分割学习(FedSL)框架在工业物联网中的资源受限机器人应用进行了全面研究，比较了同步、异步、分层和异构框架，并系统分类了三种令牌融合策略及其优化技术。


<details>
  <summary>Details</summary>
Motivation: 工业物联网系统特别是智能工厂中，数据隐私、通信效率和设备异构性是关键问题，需要为资源受限的机器人开发合适的FedSL框架。

Method: 比较了同步、异步、分层和异构FedSL框架的工作流程、可扩展性和适应性；将令牌融合策略分为输入级、中间级和输出级三类；提出了模型压缩、分割层选择、计算频率分配和无线资源管理等优化技术。

Result: 仿真结果验证了这些框架在工业检测场景下的性能表现。

Conclusion: 概述了FedSL在未来智能制造系统中的开放问题和研究方向。

Abstract: Federated split learning (FedSL) has emerged as a promising paradigm for
enabling collaborative intelligence in industrial Internet of Things (IoT)
systems, particularly in smart factories where data privacy, communication
efficiency, and device heterogeneity are critical concerns. In this article, we
present a comprehensive study of FedSL frameworks tailored for
resource-constrained robots in industrial scenarios. We compare synchronous,
asynchronous, hierarchical, and heterogeneous FedSL frameworks in terms of
workflow, scalability, adaptability, and limitations under dynamic industrial
conditions. Furthermore, we systematically categorize token fusion strategies
into three paradigms: input-level (pre-fusion), intermediate-level
(intra-fusion), and output-level (post-fusion), and summarize their respective
strengths in industrial applications. We also provide adaptive optimization
techniques to enhance the efficiency and feasibility of FedSL implementation,
including model compression, split layer selection, computing frequency
allocation, and wireless resource management. Simulation results validate the
performance of these frameworks under industrial detection scenarios. Finally,
we outline open issues and research directions of FedSL in future smart
manufacturing systems.

</details>


### [15] [Precise and Efficient Collision Prediction under Uncertainty in Autonomous Driving](https://arxiv.org/abs/2510.05729)
*Marc Kaufeld,Johannes Betz*

Main category: cs.RO

TL;DR: 提出两种高效方法估计自动驾驶中规划轨迹的碰撞风险，考虑感知噪声、定位误差和交通参与者预测不确定性，实现实时风险感知轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 确定性碰撞检查在不确定驾驶条件下往往不准确或过于保守，需要能够处理感知噪声、定位误差和交通参与者预测不确定性的碰撞概率估计方法。

Method: 提出两种半解析方法：第一种评估自动驾驶车辆与周围障碍物的空间重叠概率，第二种基于随机边界交叉估计碰撞概率。两种方法都包含完整状态不确定性。

Result: 仿真验证表明，所提方法与蒙特卡洛结果高度匹配，同时提供显著的运行时间优势，适合实时规划应用。

Conclusion: 这两种方法能够准确高效地估计碰撞概率，为风险感知轨迹规划提供了实用工具，并已作为开源软件发布。

Abstract: This research introduces two efficient methods to estimate the collision risk
of planned trajectories in autonomous driving under uncertain driving
conditions. Deterministic collision checks of planned trajectories are often
inaccurate or overly conservative, as noisy perception, localization errors,
and uncertain predictions of other traffic participants introduce significant
uncertainty into the planning process. This paper presents two semi-analytic
methods to compute the collision probability of planned trajectories with
arbitrary convex obstacles. The first approach evaluates the probability of
spatial overlap between an autonomous vehicle and surrounding obstacles, while
the second estimates the collision probability based on stochastic boundary
crossings. Both formulations incorporate full state uncertainties, including
position, orientation, and velocity, and achieve high accuracy at computational
costs suitable for real-time planning. Simulation studies verify that the
proposed methods closely match Monte Carlo results while providing significant
runtime advantages, enabling their use in risk-aware trajectory planning. The
collision estimation methods are available as open-source software:
https://github.com/TUM-AVS/Collision-Probability-Estimation

</details>


### [16] [Human-in-the-loop Optimisation in Robot-assisted Gait Training](https://arxiv.org/abs/2510.05780)
*Andreas Christou,Andreas Sochopoulos,Elliot Lister,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 该论文研究了人机协同优化在步态训练中提供个性化辅助的潜力，使用CMA-ES算法优化下肢外骨骼的辅助控制器，发现虽然算法能收敛到个性化参数，但对受试者表现没有显著影响。


<details>
  <summary>Details</summary>
Motivation: 由于步行模式存在显著的人际和个体内变异性，需要设计能够适应个体独特特征的机器人控制器，以提供个性化步态训练辅助。

Method: 采用协方差矩阵自适应进化策略(CMA-ES)持续优化下肢外骨骼的按需辅助控制器，并在六名健康个体上进行为期两天的实验。

Result: CMA-ES算法似乎能为每个个体收敛到独特的刚度参数集，但在验证试验中未观察到对受试者表现的显著影响。

Conclusion: 人机协同适应和人类行为变异性的影响可能大于个性化基于规则的辅助控制器的潜在益处，这揭示了当前个性化方法在外骨骼辅助步态康复中的局限性。

Abstract: Wearable robots offer a promising solution for quantitatively monitoring gait
and providing systematic, adaptive assistance to promote patient independence
and improve gait. However, due to significant interpersonal and intrapersonal
variability in walking patterns, it is important to design robot controllers
that can adapt to the unique characteristics of each individual. This paper
investigates the potential of human-in-the-loop optimisation (HILO) to deliver
personalised assistance in gait training. The Covariance Matrix Adaptation
Evolution Strategy (CMA-ES) was employed to continuously optimise an
assist-as-needed controller of a lower-limb exoskeleton. Six healthy
individuals participated over a two-day experiment. Our results suggest that
while the CMA-ES appears to converge to a unique set of stiffnesses for each
individual, no measurable impact on the subjects' performance was observed
during the validation trials. These findings highlight the impact of
human-robot co-adaptation and human behaviour variability, whose effect may be
greater than potential benefits of personalising rule-based assistive
controllers. Our work contributes to understanding the limitations of current
personalisation approaches in exoskeleton-assisted gait rehabilitation and
identifies key challenges for effective implementation of human-in-the-loop
optimisation in this domain.

</details>


### [17] [VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation](https://arxiv.org/abs/2510.05827)
*Haoran Zhang,Shuanghao Bai,Wanqi Zhou,Yuedi Zhang,Qi Zhang,Pengxiang Ding,Cheng Chi,Donglin Wang,Badong Chen*

Main category: cs.RO

TL;DR: VCoT-Grasp是一个端到端的抓取基础模型，通过视觉思维链推理增强视觉理解，在杂乱环境中实现高成功率的抓取生成。


<details>
  <summary>Details</summary>
Motivation: 现有语言驱动抓取方法缺乏足够的推理和泛化能力，或依赖复杂模块化流程，且过度强调对话和对象语义，导致性能不佳且仅限于单对象抓取。

Method: 采用多轮处理范式，动态聚焦视觉输入并提供可解释的推理轨迹，使用包含167K合成图像和400+真实图像的大规模数据集VCoT-GraspSet进行训练。

Result: 在VCoT-GraspSet和真实机器人实验中显著提高了抓取成功率，并能有效泛化到未见过的物体、背景和干扰物。

Conclusion: VCoT-Grasp通过视觉思维链推理保持了强大的推理能力和泛化性，在杂乱环境中表现出色。

Abstract: Robotic grasping is one of the most fundamental tasks in robotic
manipulation, and grasp detection/generation has long been the subject of
extensive research. Recently, language-driven grasp generation has emerged as a
promising direction due to its practical interaction capabilities. However,
most existing approaches either lack sufficient reasoning and generalization
capabilities or depend on complex modular pipelines. Moreover, current grasp
foundation models tend to overemphasize dialog and object semantics, resulting
in inferior performance and restriction to single-object grasping. To maintain
strong reasoning ability and generalization in cluttered environments, we
propose VCoT-Grasp, an end-to-end grasp foundation model that incorporates
visual chain-of-thought reasoning to enhance visual understanding for grasp
generation. VCoT-Grasp adopts a multi-turn processing paradigm that dynamically
focuses on visual inputs while providing interpretable reasoning traces. For
training, we refine and introduce a large-scale dataset, VCoT-GraspSet,
comprising 167K synthetic images with over 1.36M grasps, as well as 400+
real-world images with more than 1.2K grasps, annotated with intermediate
bounding boxes. Extensive experiments on both VCoT-GraspSet and real robot
demonstrate that our method significantly improves grasp success rates and
generalizes effectively to unseen objects, backgrounds, and distractors. More
details can be found at https://zhanghr2001.github.io/VCoT-Grasp.github.io.

</details>


### [18] [A Co-Design Framework for Energy-Aware Monoped Jumping with Detailed Actuator Modeling](https://arxiv.org/abs/2510.05923)
*Aman Singh,Aastha Mishra,Deepak Kapa,Suryank Joshi,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出了一种三阶段协同设计优化框架，同时最大化单足机器人跳跃高度并最小化机械能耗，包含真实执行器质量模型和变速箱优化，自动生成可直接制造的CAD模型。


<details>
  <summary>Details</summary>
Motivation: 现有协同设计框架通常只优化最大高度或最小能耗，忽略了二者的权衡关系，且经常省略变速箱参数优化，使用过于简化的执行器质量模型，导致设计难以实际复制。

Method: 三阶段协同设计优化框架，联合优化机械设计（包括变速箱）和控制参数，采用真实执行器质量模型，自动生成参数化CAD模型。

Result: 实验评估显示，与基线设计相比机械能耗降低50%，同时实现0.8m的跳跃高度。

Conclusion: 该框架能够有效平衡跳跃高度与能耗的权衡，生成可直接制造的设计方案，显著减少手动设计迭代。

Abstract: A monoped's jump height and energy consumption depend on both, its mechanical
design and control strategy. Existing co-design frameworks typically optimize
for either maximum height or minimum energy, neglecting their trade-off. They
also often omit gearbox parameter optimization and use oversimplified actuator
mass models, producing designs difficult to replicate in practice. In this
work, we introduce a novel three-stage co-design optimization framework that
jointly maximizes jump height while minimizing mechanical energy consumption of
a monoped. The proposed method explicitly incorporates realistic actuator mass
models and optimizes mechanical design (including gearbox) and control
parameters within a unified framework. The resulting design outputs are then
used to automatically generate a parameterized CAD model suitable for direct
fabrication, significantly reducing manual design iterations. Our experimental
evaluations demonstrate a 50 percent reduction in mechanical energy consumption
compared to the baseline design, while achieving a jump height of 0.8m. Video
presentation is available at http://y2u.be/XW8IFRCcPgM

</details>


### [19] [Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion](https://arxiv.org/abs/2510.05957)
*Vaughn Gzenda,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出基于模型强化学习框架，利用传感器推断的潜在动力学作为预测模型，指导actor-critic算法优化软体爬行机器人的运动策略。


<details>
  <summary>Details</summary>
Motivation: 软体爬行机器人的控制策略设计面临模型不准确、传感器噪声和运动步态发现等挑战，需要开发能够仅基于噪声传感器反馈实现自适应运动的方法。

Method: 使用模型强化学习框架，从机载传感器推断潜在动力学作为预测模型，结合actor-critic算法优化运动策略，在仿真中评估使用IMU和飞行时间传感器的效果。

Result: 学习的潜在动力学能够实现短时程运动预测，actor-critic算法发现了有效的运动策略，证明了该方法的可行性。

Conclusion: 基于潜在动力学的模型强化学习方法展示了仅依靠噪声传感器反馈实现软体机器人自适应运动的潜力。

Abstract: Soft robotic crawlers are mobile robots that utilize soft body deformability
and compliance to achieve locomotion through surface contact. Designing control
strategies for such systems is challenging due to model inaccuracies, sensor
noise, and the need to discover locomotor gaits. In this work, we present a
model-based reinforcement learning (MB-RL) framework in which latent dynamics
inferred from onboard sensors serve as a predictive model that guides an
actor-critic algorithm to optimize locomotor policies. We evaluate the
framework on a minimal crawler model in simulation using inertial measurement
units and time-of-flight sensors as observations. The learned latent dynamics
enable short-horizon motion prediction while the actor-critic discovers
effective locomotor policies. This approach highlights the potential of
latent-dynamics MB-RL for enabling embodied soft robotic adaptive locomotion
based solely on noisy sensor feedback.

</details>


### [20] [The DISTANT Design for Remote Transmission and Steering Systems for Planetary Robotics](https://arxiv.org/abs/2510.05981)
*Cristina Luna,Alba Guerra,Almudena Moreno,Manuel Esquer,Willy Roa,Mateusz Krawczak,Robert Popela,Piotr Osica,Davide Nicolis*

Main category: cs.RO

TL;DR: DISTANT设计将火星车的牵引和转向执行器从车轮位置移至车身内的热保护箱，通过双横臂悬架、万向节和绞盘驱动转向系统，解决长距离任务中的热循环、灰尘污染和机械磨损问题。


<details>
  <summary>Details</summary>
Motivation: 行星探测任务需要能在极端环境中长期运行的稳健移动系统，传统车轮安装执行器面临热循环、灰尘污染和机械磨损等挑战。

Method: 采用双横臂悬架配置，配合万向节和绞盘驱动转向系统，将所有电机化组件置于受保护环境内，实现独立车轮牵引、转向控制和悬架管理。

Result: 设计满足50公里穿越要求且性能不退化，集成了灰尘保护机制和热管理解决方案，计划于2026年Q1进行1:3比例样机制造和测试验证。

Conclusion: DISTANT设计通过重新定位执行器到热保护箱，为长距离行星探测任务提供了更可靠、耐用的移动系统解决方案。

Abstract: Planetary exploration missions require robust locomotion systems capable of
operating in extreme environments over extended periods. This paper presents
the DISTANT (Distant Transmission and Steering Systems) design, a novel
approach for relocating rover traction and steering actuators from
wheel-mounted positions to a thermally protected warm box within the rover
body. The design addresses critical challenges in long-distance traversal
missions by protecting sensitive components from thermal cycling, dust
contamination, and mechanical wear. A double wishbone suspension configuration
with cardan joints and capstan drive steering has been selected as the optimal
architecture following comprehensive trade-off analysis. The system enables
independent wheel traction, steering control, and suspension management whilst
maintaining all motorisation within the protected environment. The design meets
a 50 km traverse requirement without performance degradation, with integrated
dust protection mechanisms and thermal management solutions. Testing and
validation activities are planned for Q1 2026 following breadboard
manufacturing at 1:3 scale.

</details>


### [21] [AI-Enabled Capabilities to Facilitate Next-Generation Rover Surface Operations](https://arxiv.org/abs/2510.05985)
*Cristina Luna,Robert Field,Steven Kay*

Main category: cs.RO

TL;DR: 本文提出了集成AI系统，通过三个组件显著提高行星探测车的自主性：快速障碍物检测、多机器人协作框架和深度学习地形分类，在火星模拟环境中验证了技术成熟度，为下一代行星任务提供了可衡量的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前行星探测车的行驶速度约为10厘米/秒，这从根本上限制了探索效率，需要开发更先进的自主系统来提高探测能力。

Method: 开发了三个集成AI系统组件：FASTNAV远距离障碍物检测器（使用计算机视觉实现持续1.0米/秒速度）、CISRU多机器人协作框架（支持人机协作进行原位资源利用）以及ViBEKO和AI基于深度学习的AXR地形分类研究。

Result: 在火星模拟环境中进行现场验证，技术成熟度达到4级，在行驶速度、分类准确性和操作安全性方面提供了可衡量的改进。

Conclusion: 这些集成AI系统显著提高了行星探测的自主性和效率，为下一代行星任务提供了可行的技术解决方案。

Abstract: Current planetary rovers operate at traverse speeds of approximately 10 cm/s,
fundamentally limiting exploration efficiency. This work presents integrated AI
systems which significantly improve autonomy through three components: (i) the
FASTNAV Far Obstacle Detector (FOD), capable of facilitating sustained 1.0 m/s
speeds via computer vision-based obstacle detection; (ii) CISRU, a multi-robot
coordination framework enabling human-robot collaboration for in-situ resource
utilisation; and (iii) the ViBEKO and AIAXR deep learning-based terrain
classification studies. Field validation in Mars analogue environments
demonstrated these systems at Technology Readiness Level 4, providing
measurable improvements in traverse speed, classification accuracy, and
operational safety for next-generation planetary missions.

</details>


### [22] [Coordinate-Consistent Localization via Continuous-Time Calibration and Fusion of UWB and SLAM Observations](https://arxiv.org/abs/2510.05992)
*Tien-Dat Nguyen,Thien-Minh Nguyen,Vinh-Hao Nguyen*

Main category: cs.RO

TL;DR: 提出一种两阶段方法，通过融合UWB和SLAM数据实现坐标系一致且精确的定位，解决了SLAM每次运行坐标系重置和UWB锚点坐标标定的问题。


<details>
  <summary>Details</summary>
Motivation: SLAM每次运行会重置坐标系原点，而UWB定位需要精确的锚点坐标标定，两者单独使用都有局限性。需要一种方法能在同一环境中实现坐标系一致且精确的定位。

Method: 第一阶段：使用一次完整运行的测距和里程计数据，通过连续时间批量优化恢复锚点的3D位置。第二阶段：在后续运行中使用滑动窗口优化方案融合UWB和SLAM数据。

Result: 在NTU VIRAL数据集上的六种无人机飞行场景实验表明，仅使用一次运行数据进行标定就足以在其余运行中实现精确定位。

Conclusion: 该方法成功解决了SLAM和UWB融合中的坐标系一致性问题，实现了跨会话的精确定位，代码已开源。

Abstract: Onboard simultaneous localization and mapping (SLAM) methods are commonly
used to provide accurate localization information for autonomous robots.
However, the coordinate origin of SLAM estimate often resets for each run. On
the other hand, UWB-based localization with fixed anchors can ensure a
consistent coordinate reference across sessions; however, it requires an
accurate assignment of the anchor nodes' coordinates. To this end, we propose a
two-stage approach that calibrates and fuses UWB data and SLAM data to achieve
coordinate-wise consistent and accurate localization in the same environment.
In the first stage, we solve a continuous-time batch optimization problem by
using the range and odometry data from one full run, incorporating height
priors and anchor-to-anchor distance factors to recover the anchors' 3D
positions. For the subsequent runs in the second stage, a sliding-window
optimization scheme fuses the UWB and SLAM data, which facilitates accurate
localization in the same coordinate system. Experiments are carried out on the
NTU VIRAL dataset with six scenarios of UAV flight, and we show that
calibration using data in one run is sufficient to enable accurate localization
in the remaining runs. We release our source code to benefit the community at
https://github.com/ntdathp/slam-uwb-calibration.

</details>


### [23] [Cross-Embodiment Dexterous Hand Articulation Generation via Morphology-Aware Learning](https://arxiv.org/abs/2510.06068)
*Heng Zhang,Kevin Yuchen Ma,Mike Zheng Shou,Weisi Lin,Yan Wu*

Main category: cs.RO

TL;DR: 提出了一种基于特征抓握的端到端框架，用于跨具身抓握生成，通过形态嵌入和特征抓握集实现多指手抓握的快速推理和跨具身泛化。


<details>
  <summary>Details</summary>
Motivation: 多指手灵巧抓握面临高维关节空间和优化流程成本高的挑战，现有端到端方法需要针对特定手进行大规模训练，缺乏跨具身泛化能力。

Method: 从手部形态描述推导形态嵌入和特征抓握集，基于对象点云和手腕姿态，通过振幅预测器在低维空间回归关节系数，解码为完整关节动作，使用运动学感知关节损失进行监督。

Result: 在三个灵巧手的未见对象上达到91.9%平均抓握成功率，推理时间小于0.4秒；通过少样本适应未见手，在仿真中达到85.6%成功率，真实世界实验达到87%成功率。

Conclusion: 该框架实现了高效的跨具身灵巧抓握生成，在仿真和真实世界中都表现出色，为多指手抓握提供了通用解决方案。

Abstract: Dexterous grasping with multi-fingered hands remains challenging due to
high-dimensional articulations and the cost of optimization-based pipelines.
Existing end-to-end methods require training on large-scale datasets for
specific hands, limiting their ability to generalize across different
embodiments. We propose an eigengrasp-based, end-to-end framework for
cross-embodiment grasp generation. From a hand's morphology description, we
derive a morphology embedding and an eigengrasp set. Conditioned on these,
together with the object point cloud and wrist pose, an amplitude predictor
regresses articulation coefficients in a low-dimensional space, which are
decoded into full joint articulations. Articulation learning is supervised with
a Kinematic-Aware Articulation Loss (KAL) that emphasizes fingertip-relevant
motions and injects morphology-specific structure. In simulation on unseen
objects across three dexterous hands, our model attains a 91.9% average grasp
success rate with less than 0.4 seconds inference per grasp. With few-shot
adaptation to an unseen hand, it achieves 85.6% success on unseen objects in
simulation, and real-world experiments on this few-shot generalized hand
achieve an 87% success rate. The code and additional materials will be made
available upon publication on our project website
https://connor-zh.github.io/cross_embodiment_dexterous_grasping.

</details>


### [24] [Multi-Robot Distributed Optimization for Exploration and Mapping of Unknown Environments using Bioinspired Tactile-Sensor](https://arxiv.org/abs/2510.06085)
*Roman Ibrahimov,Jannik Matthias Heinen*

Main category: cs.RO

TL;DR: 提出一种基于分布式优化的仿生多机器人系统，用于未知环境的高效探索和建图。机器人采用壁面跟随行为，通过触觉传感器自主探索环境，记录碰撞点而非避开障碍物，最终整合局部地图形成全局2D地图。


<details>
  <summary>Details</summary>
Motivation: 受蟑螂触角启发，开发一种去中心化的多机器人探索策略，旨在提高未知环境探索效率，应用于搜救、工业检测和环境监测等领域。

Method: 使用分布式优化方法，每个机器人配备触觉传感器模拟蟑螂触角，采用壁面跟随行为自主探索，记录碰撞点而非避开障碍物，最后整合局部地图形成全局2D地图。

Result: 在1.5×1.5米模拟环境中使用e-puck机器人进行实验验证，结果显示系统能实现高覆盖率、最小化碰撞次数，并构建准确的2D地图。

Conclusion: 该仿生多机器人系统通过分布式优化和壁面跟随行为，能够有效探索未知环境并构建准确地图，验证了去中心化控制策略在任务分配和环境探索中的有效性。

Abstract: This project proposes a bioinspired multi-robot system using Distributed
Optimization for efficient exploration and mapping of unknown environments.
Each robot explores its environment and creates a map, which is afterwards put
together to form a global 2D map of the environment. Inspired by wall-following
behaviors, each robot autonomously explores its neighborhood based on a tactile
sensor, similar to the antenna of a cockroach, mounted on the surface of the
robot. Instead of avoiding obstacles, robots log collision points when they
touch obstacles. This decentralized control strategy ensures effective task
allocation and efficient exploration of unknown terrains, with applications in
search and rescue, industrial inspection, and environmental monitoring. The
approach was validated through experiments using e-puck robots in a simulated
1.5 x 1.5 m environment with three obstacles. The results demonstrated the
system's effectiveness in achieving high coverage, minimizing collisions, and
constructing accurate 2D maps.

</details>


### [25] [Towards Autonomous Tape Handling for Robotic Wound Redressing](https://arxiv.org/abs/2510.06127)
*Xiao Liang,Lu Shen,Peihan Zhang,Soofiyan Atar,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 本文提出了一个用于伤口护理中胶带操作的自主框架，包括胶带初始分离和安全粘贴两个关键能力，通过力反馈模仿学习和轨迹优化方法实现可靠的胶带操作。


<details>
  <summary>Details</summary>
Motivation: 慢性伤口护理在美国影响超过650万患者，年成本超过250亿美元，目前完全依赖人工操作。作者希望通过机器人自动化来降低成本和改善患者治疗效果。

Method: 使用力反馈模仿学习处理胶带初始分离的复杂粘附动力学，开发基于数值轨迹优化的方法确保平滑粘贴和无皱褶应用。

Result: 通过大量实验验证了方法的可靠性，在定量评估和集成伤口护理流程中都表现出良好性能。

Conclusion: 胶带操作是实现实用机器人伤口护理自动化的关键步骤。

Abstract: Chronic wounds, such as diabetic, pressure, and venous ulcers, affect over
6.5 million patients in the United States alone and generate an annual cost
exceeding \$25 billion. Despite this burden, chronic wound care remains a
routine yet manual process performed exclusively by trained clinicians due to
its critical safety demands. We envision a future in which robotics and
automation support wound care to lower costs and enhance patient outcomes. This
paper introduces an autonomous framework for one of the most fundamental yet
challenging subtasks in wound redressing: adhesive tape manipulation.
Specifically, we address two critical capabilities: tape initial detachment
(TID) and secure tape placement. To handle the complex adhesive dynamics of
detachment, we propose a force-feedback imitation learning approach trained
from human teleoperation demonstrations. For tape placement, we develop a
numerical trajectory optimization method based to ensure smooth adhesion and
wrinkle-free application across diverse anatomical surfaces. We validate these
methods through extensive experiments, demonstrating reliable performance in
both quantitative evaluations and integrated wound redressing pipelines. Our
results establish tape manipulation as an essential step toward practical
robotic wound care automation.

</details>


### [26] [Vision-Guided Targeted Grasping and Vibration for Robotic Pollination in Controlled Environments](https://arxiv.org/abs/2510.06146)
*Jaehwan Jeong,Tuan-Anh Vu,Radha Lahoti,Jiawen Wang,Vivek Alumootil,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 开发了一种视觉引导的机器人授粉框架，通过3D植物重建、目标抓取规划和基于物理的振动建模，实现精确的机器人授粉。


<details>
  <summary>Details</summary>
Motivation: 在受控农业环境中，风媒授粉缺失且商业传粉者使用受限，机器人授粉成为替代人工和熊蜂授粉的有前景方案。

Method: 使用末端执行器RGB-D传感器数据进行3D植物重建，结合离散弹性杆模型预测振动参数与花朵动态关系，软抓手抓取茎干并施加受控振动。

Result: 实验显示主茎抓取成功率92.5%，通过仿真优化振动参数验证了方法的可行性，机器人能够安全有效地执行授粉而不损伤花朵。

Conclusion: 这是首个将视觉抓取和振动建模集成用于自动化精确授粉的机器人系统，展示了机器人授粉的实用性和有效性。

Abstract: Robotic pollination offers a promising alternative to manual labor and
bumblebee-assisted methods in controlled agriculture, where wind-driven
pollination is absent and regulatory restrictions limit the use of commercial
pollinators. In this work, we present and validate a vision-guided robotic
framework that uses data from an end-effector mounted RGB-D sensor and combines
3D plant reconstruction, targeted grasp planning, and physics-based vibration
modeling to enable precise pollination. First, the plant is reconstructed in 3D
and registered to the robot coordinate frame to identify obstacle-free grasp
poses along the main stem. Second, a discrete elastic rod model predicts the
relationship between actuation parameters and flower dynamics, guiding the
selection of optimal pollination strategies. Finally, a manipulator with soft
grippers grasps the stem and applies controlled vibrations to induce pollen
release. End-to-end experiments demonstrate a 92.5\% main-stem grasping success
rate, and simulation-guided optimization of vibration parameters further
validates the feasibility of our approach, ensuring that the robot can safely
and effectively perform pollination without damaging the flower. To our
knowledge, this is the first robotic system to jointly integrate vision-based
grasping and vibration modeling for automated precision pollination.

</details>


### [27] [A Preview of HoloOcean 2.0](https://arxiv.org/abs/2510.06160)
*Blake Romrell,Abigail Austin,Braden Meyers,Ryan Anderson,Carter Noh,Joshua G. Mangelson*

Main category: cs.RO

TL;DR: HoloOcean 2.0是一个基于Unreal Engine 5.3的海洋机器人模拟器，集成了先进的车辆动力学模型和ROS2支持，旨在为海洋自主机器人开发提供高保真度的仿真环境。


<details>
  <summary>Details</summary>
Motivation: 随着海洋机器人领域的发展，需要更高保真度的传感器、物理和视觉渲染仿真来支持自主海洋机器人的开发和验证。

Method: 迁移到Unreal Engine 5.3，采用Fossen的先进车辆动力学模型，开发自定义ROS2桥接，并正在开发基于光线追踪的声纳实现、语义传感器、环境生成工具等功能。

Result: 开发了HoloOcean 2.0这一通用海洋模拟器，具备最先进的功能，能够支持多种任务。

Conclusion: HoloOcean 2.0为海洋机器人系统开发提供了强大的仿真平台，未来将继续扩展功能以提供更真实的海洋环境模拟。

Abstract: Marine robotics simulators play a fundamental role in the development of
marine robotic systems. With increased focus on the marine robotics field in
recent years, there has been significant interest in developing higher
fidelitysimulation of marine sensors, physics, and visual rendering
capabilities to support autonomous marine robot development and validation.
HoloOcean 2.0, the next major release of HoloOcean, brings state-of-the-art
features under a general marine simulator capable of supporting a variety of
tasks. New features in HoloOcean 2.0 include migration to Unreal Engine (UE)
5.3, advanced vehicle dynamics using models from Fossen, and support for ROS2
using a custom bridge. Additional features are currently in development,
including significantly more efficient ray tracing-based sidescan,
forward-looking, and bathymetric sonar implementations; semantic sensors;
environment generation tools; volumetric environmental effects; and realistic
waves.

</details>


### [28] [DYMO-Hair: Generalizable Volumetric Dynamics Modeling for Robot Hair Manipulation](https://arxiv.org/abs/2510.06199)
*Chengyang Zhao,Uksang Yoo,Arkadeep Narayan Chaudhury,Giljoo Nam,Jonathan Francis,Jeffrey Ichnowski,Jean Oh*

Main category: cs.RO

TL;DR: DYMO-Hair是一个基于模型的机器人护发系统，通过新颖的动态学习范式和3D潜在空间，实现了对未见发型的视觉目标条件发型设计，在模拟和真实世界中都表现出色。


<details>
  <summary>Details</summary>
Motivation: 日常护发对行动不便者难以实现，且由于头发的细粒度物理结构和复杂动态特性，对自主机器人系统具有挑战性。

Method: 采用基于动作条件的潜在状态编辑机制和紧凑的3D潜在空间，使用新型头发物理模拟器进行大规模预训练，结合MPPI规划器进行视觉目标条件发型设计。

Result: 在模拟中，DYMO-Hair的动态模型在捕捉未见发型的局部变形方面优于基线，闭环发型设计任务中几何误差降低22%，成功率提高42%。在真实假发上实现零样本迁移。

Conclusion: 该研究为基于模型的机器人护发奠定了基础，朝着在无约束物理环境中实现更通用、灵活和可访问的机器人发型设计迈进。

Abstract: Hair care is an essential daily activity, yet it remains inaccessible to
individuals with limited mobility and challenging for autonomous robot systems
due to the fine-grained physical structure and complex dynamics of hair. In
this work, we present DYMO-Hair, a model-based robot hair care system. We
introduce a novel dynamics learning paradigm that is suited for volumetric
quantities such as hair, relying on an action-conditioned latent state editing
mechanism, coupled with a compact 3D latent space of diverse hairstyles to
improve generalizability. This latent space is pre-trained at scale using a
novel hair physics simulator, enabling generalization across previously unseen
hairstyles. Using the dynamics model with a Model Predictive Path Integral
(MPPI) planner, DYMO-Hair is able to perform visual goal-conditioned hair
styling. Experiments in simulation demonstrate that DYMO-Hair's dynamics model
outperforms baselines on capturing local deformation for diverse, unseen
hairstyles. DYMO-Hair further outperforms baselines in closed-loop hair styling
tasks on unseen hairstyles, with an average of 22% lower final geometric error
and 42% higher success rate than the state-of-the-art system. Real-world
experiments exhibit zero-shot transferability of our system to wigs, achieving
consistent success on challenging unseen hairstyles where the state-of-the-art
system fails. Together, these results introduce a foundation for model-based
robot hair care, advancing toward more generalizable, flexible, and accessible
robot hair styling in unconstrained physical environments. More details are
available on our project page: https://chengyzhao.github.io/DYMOHair-web/.

</details>


### [29] [EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model](https://arxiv.org/abs/2510.06207)
*Zefu Lin,Rongxu Cui,Chen Hanning,Xiangyu Wang,Junjia Xu,Xiaojuan Jin,Chen Wenbo,Hui Zhou,Lue Fan,Wenling Li,Zhaoxiang Zhang*

Main category: cs.RO

TL;DR: EmbodiedCoder是一个无需训练的开源框架，利用编码模型直接生成可执行的机器人轨迹，实现开放世界移动机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人控制方法依赖大型标注数据集且可解释性有限，难以扩展到多样化环境。需要一种无需额外数据收集或微调的方法来连接感知与操作。

Method: 通过将高级指令基于代码进行接地，实现灵活的对象几何参数化和操作轨迹合成，提供透明且可泛化的感知-操作连接方式。

Result: 在真实移动机器人上的实验表明，EmbodiedCoder在多样化长期任务中表现稳健，并能有效泛化到新对象和环境。

Conclusion: 该方法提供了一种可解释的方式连接高级推理与低级控制，超越固定原语向多功能机器人智能发展。

Abstract: Recent advances in control robot methods, from end-to-end
vision-language-action frameworks to modular systems with predefined
primitives, have advanced robots' ability to follow natural language
instructions. Nonetheless, many approaches still struggle to scale to diverse
environments, as they often rely on large annotated datasets and offer limited
interpretability.In this work, we introduce EmbodiedCoder, a training-free
framework for open-world mobile robot manipulation that leverages coding models
to directly generate executable robot trajectories. By grounding high-level
instructions in code, EmbodiedCoder enables flexible object geometry
parameterization and manipulation trajectory synthesis without additional data
collection or fine-tuning.This coding-based paradigm provides a transparent and
generalizable way to connect perception with manipulation. Experiments on real
mobile robots show that EmbodiedCoder achieves robust performance across
diverse long-term tasks and generalizes effectively to novel objects and
environments.Our results demonstrate an interpretable approach for bridging
high-level reasoning and low-level control, moving beyond fixed primitives
toward versatile robot intelligence. See the project page at:
https://anonymous.4open.science/w/Embodied-Coder/

</details>
