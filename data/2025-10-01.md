<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [When and How to Express Empathy in Human-Robot Interaction Scenarios](https://arxiv.org/abs/2509.25200)
*Christian Arzate Cruz,Edwin C. Montiel-Vazquez,Chikara Maeda,Randy Gomez*

Main category: cs.RO

TL;DR: whEE框架使社交机器人能够检测何时需要表达同理心并生成适当回应，利用大语言模型识别人类互动中的行为同理心线索


<details>
  <summary>Details</summary>
Motivation: 将同理心行为融入机器人可以提高其社交有效性和互动质量

Method: 使用大语言模型识别人类互动中的关键行为同理心线索，通过whEE框架检测何时需要同理心并生成回应

Result: 在与人形机器人Haru的人机互动场景中评估，whEE能有效识别和回应同理心线索

Conclusion: 为设计能够根据不同互动情境自适应调节同理心水平的社交机器人提供了有价值的见解

Abstract: Incorporating empathetic behavior into robots can improve their social
effectiveness and interaction quality. In this paper, we present whEE (when and
how to express empathy), a framework that enables social robots to detect when
empathy is needed and generate appropriate responses. Using large language
models, whEE identifies key behavioral empathy cues in human interactions. We
evaluate it in human-robot interaction scenarios with our social robot, Haru.
Results show that whEE effectively identifies and responds to empathy cues,
providing valuable insights for designing social robots capable of adaptively
modulating their empathy levels across various interaction contexts.

</details>


### [2] [BEV-VLM: Trajectory Planning via Unified BEV Abstraction](https://arxiv.org/abs/2509.25249)
*Guancheng Chen,Sheng Yang,Tong Zhan,Jian Wang*

Main category: cs.RO

TL;DR: BEV-VLM是一个用于自动驾驶轨迹规划的新框架，利用鸟瞰图特征作为视觉语言模型的视觉输入，相比传统方法显著提升了规划精度和碰撞避免能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖原始视觉数据如相机图像进行轨迹规划，但BEV表示能提供更压缩和信息丰富的场景描述，与高清地图对齐后形成几何一致的环境表示。

Method: 通过融合多模态传感器数据（相机和激光雷达）生成BEV特征，并与高清地图对齐形成统一的BEV-HD Map格式，作为VLM的视觉输入进行轨迹规划。

Result: 在nuScenes数据集上的实验结果显示，规划精度提升了44.8%，并实现了完全碰撞避免。

Conclusion: 研究表明视觉语言模型能够有效解释处理过的视觉表示如BEV特征，扩展了其在轨迹规划中超越原始图像的应用范围。

Abstract: This paper introduces BEV-VLM, a novel framework for trajectory planning in
autonomous driving that leverages Vision-Language Models (VLMs) with Bird's-Eye
View (BEV) feature maps as visual inputs. Unlike conventional approaches that
rely solely on raw visual data such as camera images, our method utilizes
highly compressed and informative BEV representations, which are generated by
fusing multi-modal sensor data (e.g., camera and LiDAR) and aligning them with
HD Maps. This unified BEV-HD Map format provides a geometrically consistent and
rich scene description, enabling VLMs to perform accurate trajectory planning.
Experimental results on the nuScenes dataset demonstrate 44.8% improvements in
planning accuracy and complete collision avoidance. Our work highlights that
VLMs can effectively interpret processed visual representations like BEV
features, expanding their applicability beyond raw images in trajectory
planning.

</details>


### [3] [SRMP: Search-Based Robot Motion Planning Library](https://arxiv.org/abs/2509.25352)
*Itamar Mishani,Yorai Shaoul,Ramkumar Natarajan,Jiaoyang Li,Maxim Likhachev*

Main category: cs.RO

TL;DR: SRMP是一个专为机器人操作设计的运动规划软件框架，能够生成一致可靠的轨迹，是首个支持多机器人操作任务运动规划算法的工具


<details>
  <summary>Details</summary>
Motivation: 现有运动规划框架在高风险应用中缺乏足够的可预测性和可重复性，无法满足工业安全和高质量运动数据集创建的需求

Method: 开发了SRMP框架，提供Python和C++ API，支持与MuJoCo、Sapien、Genesis、PyBullet等主流模拟器集成，包含专门的MoveIt!插件

Result: SRMP不仅满足工业和安全性关键应用的严格要求，还在不同机器人系统中为运动规划的一致性设定了新标准

Conclusion: SRMP填补了现有运动规划工具在可靠性和一致性方面的不足，特别适合多机器人操作任务和高风险应用场景

Abstract: Motion planning is a critical component in any robotic system. Over the
years, powerful tools like the Open Motion Planning Library (OMPL) have been
developed, offering numerous motion planning algorithms. However, existing
frameworks often struggle to deliver the level of predictability and
repeatability demanded by high-stakes applications -- ranging from ensuring
safety in industrial environments to the creation of high-quality motion
datasets for robot learning. Complementing existing tools, we introduce SRMP
(Search-based Robot Motion Planning), a new software framework tailored for
robotic manipulation. SRMP distinguishes itself by generating consistent and
reliable trajectories, and is the first software tool to offer motion planning
algorithms for multi-robot manipulation tasks. SRMP easily integrates with
major simulators, including MuJoCo, Sapien, Genesis, and PyBullet via a Python
and C++ API. SRMP includes a dedicated MoveIt! plugin that enables immediate
deployment on robot hardware and seamless integration with existing pipelines.
Through extensive evaluations, we demonstrate in this paper that SRMP not only
meets the rigorous demands of industrial and safety-critical applications but
also sets a new standard for consistency in motion planning across diverse
robotic systems. Visit srmp.readthedocs.io for SRMP documentation and
tutorials.

</details>


### [4] [SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation](https://arxiv.org/abs/2509.25358)
*Qianzhong Chen,Justin Yu,Mac Schwager,Pieter Abbeel,Fred Shentu,Philipp Wu*

Main category: cs.RO

TL;DR: 提出了一种基于视频的阶段感知奖励建模框架，通过联合预测高级任务阶段和细粒度进度来解决长时程接触式操作中的演示质量不一致问题，并在此基础上提出了奖励对齐的行为克隆方法。


<details>
  <summary>Details</summary>
Motivation: 大规模机器人学习在处理长时程、接触丰富的操作任务（如可变形物体处理）时面临演示质量不一致的挑战，奖励建模可以提供稳定的进度信号来改进学习效果。

Method: 开发了阶段感知的视频奖励建模框架，自动从自然语言子任务注释中推导奖励标签，克服了变长演示中的帧索引标注问题。基于此提出了奖励对齐行为克隆(RA-BC)，通过奖励过滤高质量数据并重新加权样本。

Result: 奖励模型在验证和真实机器人测试中优于基线方法。RA-BC在折叠T恤任务中，从平整状态达到83%成功率，从皱褶状态达到67%成功率，远超仅8%和0%的普通行为克隆。

Conclusion: 奖励建模是实现可扩展、注释高效且鲁棒的长时程操作模仿学习的关键推动因素。

Abstract: Large-scale robot learning has recently shown promise for enabling robots to
perform complex tasks by integrating perception, control, and language
understanding. Yet, it struggles with long-horizon, contact-rich manipulation
such as deformable object handling, where demonstration quality is
inconsistent. Reward modeling offers a natural solution: by providing grounded
progress signals, it transforms noisy demonstrations into stable supervision
that generalizes across diverse trajectories. We introduce a stage-aware,
video-based reward modeling framework that jointly predicts high-level task
stages and fine-grained progress. Reward labels are automatically derived from
natural language subtask annotations, ensuring consistent progress estimation
across variable-length demonstrations. This design overcomes frame-index
labeling, which fails in variable-duration tasks like folding a T-shirt. Our
reward model demonstrates robustness to variability, generalization to
out-of-distribution settings, and strong utility for policy training. Building
on it, we propose Reward-Aligned Behavior Cloning (RA-BC), which filters
high-quality data and reweights samples by reward. Experiments show the reward
model alone outperforms baselines on validation and real robot rollouts.
Integrated into RA-BC, our approach achieves 83\% success on folding T-shirts
from the flattened state and 67\% from the crumpled state -- far surpassing
vanilla behavior cloning, which attains only 8\% and 0\% success. Overall, our
results highlight reward modeling as a key enabler for scalable,
annotation-efficient, and robust imitation learning in long-horizon
manipulation.

</details>


### [5] [Parallel Heuristic Search as Inference for Actor-Critic Reinforcement Learning Models](https://arxiv.org/abs/2509.25402)
*Hanlan Yang,Itamar Mishani,Luca Pivetti,Zachary Kingston,Maxim Likhachev*

Main category: cs.RO

TL;DR: 提出P-ACHS算法，一种利用演员-评论家架构的并行最佳优先搜索方法，用于机器人操作任务的推理阶段


<details>
  <summary>Details</summary>
Motivation: 现有的演员-批评家模型部署策略过于简单，通常仅依赖直接演员策略展开，未能充分利用评论家网络提供的价值估计信息

Method: 设计并行最佳优先搜索算法，利用演员网络批量生成动作，评论家网络提供成本估计指导搜索，采用动作和成本估计批量生成、图扩展多线程并行化

Result: 在机器人操作任务中验证有效性，包括无碰撞运动规划和接触丰富的非抓握推动交互

Conclusion: P-ACHS算法能够有效利用演员-评论家架构的两个组件，在推理阶段实现更高效的搜索性能

Abstract: Actor-Critic models are a class of model-free deep reinforcement learning
(RL) algorithms that have demonstrated effectiveness across various robot
learning tasks. While considerable research has focused on improving training
stability and data sampling efficiency, most deployment strategies have
remained relatively simplistic, typically relying on direct actor policy
rollouts. In contrast, we propose \pachs{} (\textit{P}arallel
\textit{A}ctor-\textit{C}ritic \textit{H}euristic \textit{S}earch), an
efficient parallel best-first search algorithm for inference that leverages
both components of the actor-critic architecture: the actor network generates
actions, while the critic network provides cost-to-go estimates to guide the
search. Two levels of parallelism are employed within the search -- actions and
cost-to-go estimates are generated in batches by the actor and critic networks
respectively, and graph expansion is distributed across multiple threads. We
demonstrate the effectiveness of our approach in robotic manipulation tasks,
including collision-free motion planning and contact-rich interactions such as
non-prehensile pushing. Visit p-achs.github.io for demonstrations and examples.

</details>


### [6] [CoTaP: Compliant Task Pipeline and Reinforcement Learning of Its Controller with Compliance Modulation](https://arxiv.org/abs/2509.25443)
*Zewen He,Chenyuan Chen,Dilshod Azizov,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 提出Compliant Task Pipeline (CoTaP)，一种结合学习结构和基于模型合规控制的人形机器人控制方法，通过两阶段强化学习框架实现可调节的任务空间合规性。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类运动数据的学习控制方法缺乏力数据，位置控制难以在真实环境中实现适当的合规性，需要解决人形机器人与环境交互时的合规控制问题。

Method: 采用两阶段双智能体强化学习框架：第一阶段训练基于位置控制的基础策略；第二阶段将上半身策略与基于模型的合规控制结合，下半身由基础策略指导，通过SPD流形上的合规调制确保系统稳定性。

Result: 在仿真中验证了策略的可行性，主要比较了不同合规设置下对外部扰动的响应。

Conclusion: CoTaP管道能够有效整合学习控制与合规控制，为人形机器人提供可调节的任务空间合规性，增强环境交互能力。

Abstract: Humanoid whole-body locomotion control is a critical approach for humanoid
robots to leverage their inherent advantages. Learning-based control methods
derived from retargeted human motion data provide an effective means of
addressing this issue. However, because most current human datasets lack
measured force data, and learning-based robot control is largely
position-based, achieving appropriate compliance during interaction with real
environments remains challenging. This paper presents Compliant Task Pipeline
(CoTaP): a pipeline that leverages compliance information in the learning-based
structure of humanoid robots. A two-stage dual-agent reinforcement learning
framework combined with model-based compliance control for humanoid robots is
proposed. In the training process, first a base policy with a position-based
controller is trained; then in the distillation, the upper-body policy is
combined with model-based compliance control, and the lower-body agent is
guided by the base policy. In the upper-body control, adjustable task-space
compliance can be specified and integrated with other controllers through
compliance modulation on the symmetric positive definite (SPD) manifold,
ensuring system stability. We validated the feasibility of the proposed
strategy in simulation, primarily comparing the responses to external
disturbances under different compliance settings.

</details>


### [7] [Online Mapping for Autonomous Driving: Addressing Sensor Generalization and Dynamic Map Updates in Campus Environments](https://arxiv.org/abs/2509.25542)
*Zihan Zhang,Abhijit Ravichandran,Pragnya Korti,Luobin Wang,Henrik I. Christensen*

Main category: cs.RO

TL;DR: 在校园高尔夫球车上部署的实时在线高精地图生成系统，通过双摄像头和LiDAR传感器，实现校园环境3D高精地图标注、SemVecMap模型集成与泛化，以及增量式地图更新。


<details>
  <summary>Details</summary>
Motivation: 传统高精地图制作成本高、维护困难，难以适应动态环境变化，需要开发实时在线地图生成系统。

Method: 在配备双前摄像头和LiDAR传感器的校园高尔夫球车平台上部署在线地图系统，使用校园特定数据微调SemVecMap模型，实现增量式地图生成和更新。

Result: 系统能够准确预测地图并支持持续更新，在真实自动驾驶场景中展现了实用价值。

Conclusion: 该在线地图系统有效解决了传统高精地图制作和维护的挑战，为自动驾驶提供了实用的实时地图解决方案。

Abstract: High-definition (HD) maps are essential for autonomous driving, providing
precise information such as road boundaries, lane dividers, and crosswalks to
enable safe and accurate navigation. However, traditional HD map generation is
labor-intensive, expensive, and difficult to maintain in dynamic environments.
To overcome these challenges, we present a real-world deployment of an online
mapping system on a campus golf cart platform equipped with dual front cameras
and a LiDAR sensor. Our work tackles three core challenges: (1) labeling a 3D
HD map for campus environment; (2) integrating and generalizing the SemVecMap
model onboard; and (3) incrementally generating and updating the predicted HD
map to capture environmental changes. By fine-tuning with campus-specific data,
our pipeline produces accurate map predictions and supports continual updates,
demonstrating its practical value in real-world autonomous driving scenarios.

</details>


### [8] [Exhaustive-Serve-Longest Control for Multi-robot Scheduling Systems](https://arxiv.org/abs/2509.25556)
*Mohammad Merati,David Castañón*

Main category: cs.RO

TL;DR: 提出ESL策略用于多机器人多队列系统的在线任务分配，证明其最优性，并在不同服务器-位置比和负载下表现优于基准策略。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人多队列系统中存在随机到达和切换延迟的在线任务分配问题，需要设计简单实用的实时调度策略。

Method: 提出ESL策略：当前位置非空时彻底服务，空闲时切换到最长未被占用的非空位置。与固定驻留循环策略和先到先服务策略进行比较。

Result: ESL策略在所有服务器-位置比和负载下都产生更低的折扣持有成本和更小的平均队列长度，行动时间分配显示更多服务和受限的切换。

Conclusion: ESL策略的简单性和鲁棒性使其成为实时多机器人调度系统的实用默认选择。

Abstract: We study online task allocation for multi-robot, multi-queue systems with
stochastic arrivals and switching delays. Time is slotted; each location can
host at most one robot per slot; service consumes one slot; switching between
locations incurs a one-slot travel delay; and arrivals are independent
Bernoulli processes. We formulate a discounted-cost Markov decision process and
propose Exhaustive-Serve-Longest (ESL), a simple real-time policy that serves
exhaustively when the current location is nonempty and, when idle, switches to
a longest unoccupied nonempty location, and we prove the optimality of this
policy. As baselines, we tune a fixed-dwell cyclic policy via a discrete-time
delay expression and implement a first-come-first-serve policy. Across
server-to-location ratios and loads, ESL consistently yields lower discounted
holding cost and smaller mean queue lengths, with action-time fractions showing
more serving and restrained switching. Its simplicity and robustness make ESL a
practical default for real-time multi-robot scheduling systems.

</details>


### [9] [Field Calibration of Hyperspectral Cameras for Terrain Inference](https://arxiv.org/abs/2509.25663)
*Nathaniel Hanson,Benjamin Pyatski,Samuel Hibbard,Gary Lvov,Oscar De La Garza,Charles DiMarzio,Kristen L. Dorsey,Taşkın Padır*

Main category: cs.RO

TL;DR: 提出了一个名为HYPER DRIVE的系统架构，用于在移动机器人上收集和配准多波长高光谱图像，并开发了在不同光照条件下进行反射率校准的方法，以识别类内地形差异如土壤水分含量。


<details>
  <summary>Details</summary>
Motivation: RGB视觉系统可能无法区分影响车辆通过能力的类内地形差异（如水分含量），而近红外光谱能提供有用的类内识别信息，但准确分析依赖于环境光照条件。

Method: 开发了收集和配准移动机器人多波长高光谱图像的系统架构，并描述了在不同光照条件下对相机进行反射率校准的方法。

Result: 展示了系统能够从移动机器人平台计算植被健康指数和土壤水分含量，验证了其实际应用价值。

Conclusion: HYPER DRIVE系统通过高光谱成像和反射率校准，能够有效识别类内地形差异，为移动机器人的地形感知提供了超越RGB视觉的能力。

Abstract: Intra-class terrain differences such as water content directly influence a
vehicle's ability to traverse terrain, yet RGB vision systems may fail to
distinguish these properties. Evaluating a terrain's spectral content beyond
red-green-blue wavelengths to the near infrared spectrum provides useful
information for intra-class identification. However, accurate analysis of this
spectral information is highly dependent on ambient illumination. We
demonstrate a system architecture to collect and register multi-wavelength,
hyperspectral images from a mobile robot and describe an approach to
reflectance calibrate cameras under varying illumination conditions. To
showcase the practical applications of our system, HYPER DRIVE, we demonstrate
the ability to calculate vegetative health indices and soil moisture content
from a mobile robot platform.

</details>


### [10] [dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.25681)
*Junjie Wen,Minjie Zhu,Jiaming Liu,Zhiyuan Liu,Yicun Yang,Linfeng Zhang,Shanghang Zhang,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: dVLA是一个基于扩散模型的视觉-语言-动作统一框架，通过多模态思维链整合视觉感知、语言推理和机器人控制，在仿真和真实机器人任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型需要统一视觉感知、语言理解和机器人控制，以增强跨模态推理能力并提升对新指令和物体的泛化性能。

Method: 采用扩散目标联合优化感知、语言理解和动作，引入前缀注意力掩码和KV缓存两种加速策略减少推理延迟。

Result: 在LIBERO基准测试中达到96.4%的平均成功率，超越离散和连续动作策略；在真实Franka机器人上成功完成包括需要多步规划的复杂分拣任务在内的多样化任务。

Conclusion: 统一的扩散框架为实用高性能的VLA机器人技术展现了巨大潜力。

Abstract: Vision-Language-Action (VLA) models are emerging as a next-generation
paradigm for robotics. We introduce dVLA, a diffusion-based VLA that leverages
a multimodal chain-of-thought to unify visual perception, language reasoning,
and robotic control in a single system. dVLA jointly optimizes perception,
language understanding, and action under a single diffusion objective, enabling
stronger cross-modal reasoning and better generalization to novel instructions
and objects. For practical deployment, we mitigate inference latency by
incorporating two acceleration strategies, a prefix attention mask and KV
caching, yielding up to around times speedup at test-time inference. We
evaluate dVLA in both simulation and the real world: on the LIBERO benchmark,
it achieves state-of-the-art performance with a 96.4% average success rate,
consistently surpassing both discrete and continuous action policies; on a real
Franka robot, it succeeds across a diverse task suite, including a challenging
bin-picking task that requires multi-step planning, demonstrating robust
real-world performance. Together, these results underscore the promise of
unified diffusion frameworks for practical, high-performance VLA robotics.

</details>


### [11] [Hierarchical Diffusion Motion Planning with Task-Conditioned Uncertainty-Aware Priors](https://arxiv.org/abs/2509.25685)
*Amelie Minji Kim,Anqi Wu,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种新颖的分层扩散规划器，将任务和运动结构直接嵌入到噪声模型中，使用任务条件化的结构化高斯噪声替代标准各向同性高斯噪声，提高了规划的成功率和轨迹质量。


<details>
  <summary>Details</summary>
Motivation: 标准扩散规划器使用零均值各向同性高斯噪声，缺乏对任务和运动结构的显式建模。本文旨在通过结构化噪声模型更好地捕捉任务语义和运动约束。

Method: 将稀疏的任务中心关键状态或其时间作为高斯过程运动规划的噪声观测，生成先验实例。采用分层结构：上层实例化任务条件化结构化高斯，下层在该固定先验下对完整轨迹进行去噪。

Result: 在Maze2D目标到达和KUKA积木堆叠任务中，相比各向同性基线方法，获得了更高的成功率、更平滑的轨迹和更强的任务对齐性。消融研究表明结构化噪声过程提供了超越简单神经网络条件化的优势。

Conclusion: 该方法将先验概率质量集中在可行、平滑且语义有意义的轨迹附近，同时保持了可处理性，为扩散规划提供了更有效的结构化噪声建模方法。

Abstract: We propose a novel hierarchical diffusion planner that embeds task and motion
structure directly in the noise model. Unlike standard diffusion-based planners
that use zero-mean, isotropic Gaussian noise, we employ a family of
task-conditioned structured Gaussians whose means and covariances are derived
from Gaussian Process Motion Planning (GPMP): sparse, task-centric key states
or their associated timings (or both) are treated as noisy observations to
produce a prior instance. We first generalize the standard diffusion process to
biased, non-isotropic corruption with closed-form forward and posterior
expressions. Building on this, our hierarchy separates prior instantiation from
trajectory denoising: the upper level instantiates a task-conditioned
structured Gaussian (mean and covariance), and the lower level denoises the
full trajectory under that fixed prior. Experiments on Maze2D goal-reaching and
KUKA block stacking show improved success rates, smoother trajectories, and
stronger task alignment compared to isotropic baselines. Ablation studies
indicate that explicitly structuring the corruption process offers benefits
beyond simply conditioning the neural network. Overall, our method concentrates
probability mass of prior near feasible, smooth, and semantically meaningful
trajectories while maintaining tractability. Our project page is available at
https://hta-diffusion.github.io.

</details>


### [12] [OmniNav: A Unified Framework for Prospective Exploration and Visual-Language Navigation](https://arxiv.org/abs/2509.25687)
*Xinda Xue,Junjun Hu,Minghua Luo,Xie Shichao,Jintao Chen,Zixun Xie,Quan Kuichen,Guo Wei,Mu Xu,Zedong Chu*

Main category: cs.RO

TL;DR: OmniNav是一个统一的机器人导航框架，支持指令导航、目标导航、点导航和前沿探索等多种导航范式，采用快慢模块协作架构，通过大规模多任务训练提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有导航模型缺乏统一的解决方案，在多样化导航场景中成功率低、泛化能力有限，需要开发能够同时处理多种导航任务的通用框架。

Method: 采用快慢系统设计：快速模块基于短时视觉上下文生成连续空间路径点，慢速模块进行长时规划选择子目标；集成大规模通用数据集进行多任务联合训练。

Result: 在多个导航基准测试中达到最先进性能，支持5Hz实时控制，路径效率和轨迹一致性显著提升，成功率和鲁棒性大幅改善。

Conclusion: OmniNav为具身导航提供了实用解决方案，通过统一架构和多任务学习实现了高度泛化的机器人智能，为可扩展的通用导航系统指明了方向。

Abstract: Embodied navigation presents a core challenge for intelligent robots,
requiring the comprehension of visual environments, natural language
instructions, and autonomous exploration. Existing models often fall short in
offering a unified solution across diverse navigation paradigms, resulting in
low success rates and limited generalization. We introduce OmniNav, a unified
framework addressing instruct-goal, object-goal, point-goal navigation, and
frontier-based exploration within a single architecture. Our approach features
a lightweight, low-latency policy that accurately predicts continuous-space
waypoints (coordinates and orientations). This policy surpasses action-chunk
methods in precision and supports real-world deployment at control frequencies
up to 5 Hz. Architecturally, OmniNav employs a fast-slow system design: a fast
module generates waypoints using short-horizon visual context and subtasks,
while a slow module performs deliberative planning with long-horizon
observations and candidate frontiers to select subsequent subgoals and
subtasks. This collaboration enhances path efficiency and maintains trajectory
coherence, particularly in exploration and memory-intensive scenarios.
Crucially, we identify that the primary bottleneck isn't merely navigation
policy learning, but a robust understanding of general instructions and
objects. To boost generalization, OmniNav integrates large-scale,
general-purpose training datasets, including those for image captioning and
visual recognition, into a joint multi-task regimen. This significantly
improves success rates and robustness. Extensive experiments confirm OmniNav's
state-of-the-art performance across various navigation benchmarks, with
real-world deployment further validating its efficacy. OmniNav provides
practical insights for embodied navigation, charting a scalable path towards
versatile, highly generalizable robotic intelligence.

</details>


### [13] [VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning](https://arxiv.org/abs/2509.25718)
*Si-Cheng Wang,Tian-Yu Xiang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Ao-Qun Jin,Zeng-Guang Hou*

Main category: cs.RO

TL;DR: 提出了一种基于动作分块的PPO强化学习方法，结合行为克隆来改进视觉-语言-动作模型的训练后优化，解决了稀疏奖励和不稳定训练的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习在视觉-语言-动作模型训练后优化中面临稀疏奖励和训练不稳定的挑战，阻碍了实际部署。

Method: 采用动作分块的PPO方法，结合行为克隆损失，使用自收集的演示数据，并动态调整PPO目标与行为克隆损失的权重比例。

Result: 在MetaWorld基准测试中表现优于监督微调，达到93%的成功率和平均42.17步完成任务的效率。

Conclusion: 证明了强化学习在VLA训练后优化中的可行性，为下游VLA应用奠定了基础。

Abstract: Reinforcement learning (RL) is a promising avenue for post-training
vision-language-action (VLA) models, but practical deployment is hindered by
sparse rewards and unstable training. This work mitigates these challenges by
introducing an action chunk based on proximal policy optimization (PPO) with
behavior cloning using self-collected demonstrations. Aggregating consecutive
actions into chunks improves the temporal consistency of the policy and the
density of informative feedback. In addition, an auxiliary behavior cloning
loss is applied with a dynamically updated demonstration buffer that
continually collects high-quality task trials during training. The relative
weight between the action-chunked PPO objective and the self behavior clone
auxiliary loss is adapted online to stabilize the post-training process.
Experiments on the MetaWorld benchmark indicate improved performance over
supervised fine-tuning, achieving a high success rate (0.93) and few steps to
success (42.17). These results demonstrate the viability of RL for VLA
post-training and help lay the groundwork for downstream VLA applications.

</details>


### [14] [TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses](https://arxiv.org/abs/2509.25746)
*Shuaijun Wang,Haoran Zhou,Diyun Xiang,Yangwei You*

Main category: cs.RO

TL;DR: 提出TacRefineNet，一种仅使用触觉的框架，通过多指尖触觉传感实现已知物体在任意目标姿态下的精细手内姿态精炼。


<details>
  <summary>Details</summary>
Motivation: 传统灵巧抓取流程和VLA方法在执行阶段存在姿态不准确问题，特别是在长时程任务中，这影响了整体性能。需要解决这个"最后一英里"挑战。

Method: 设计多分支策略网络，融合多指触觉输入和本体感知来预测精确控制更新。结合MuJoCo中基于物理的触觉模型的大规模模拟数据和物理系统收集的真实数据进行训练。

Result: 在模拟数据上预训练并用少量真实数据微调显著优于仅使用模拟训练。真实世界实验验证了方法的有效性，仅使用触觉输入实现了毫米级抓取精度。

Conclusion: 这是首个仅通过多指触觉传感实现任意手内姿态精炼的方法，为解决抓取执行阶段的姿态不准确问题提供了有效解决方案。

Abstract: Despite progress in both traditional dexterous grasping pipelines and recent
Vision-Language-Action (VLA) approaches, the grasp execution stage remains
prone to pose inaccuracies, especially in long-horizon tasks, which undermines
overall performance. To address this "last-mile" challenge, we propose
TacRefineNet, a tactile-only framework that achieves fine in-hand pose
refinement of known objects in arbitrary target poses using multi-finger
fingertip sensing. Our method iteratively adjusts the end-effector pose based
on tactile feedback, aligning the object to the desired configuration. We
design a multi-branch policy network that fuses tactile inputs from multiple
fingers along with proprioception to predict precise control updates. To train
this policy, we combine large-scale simulated data from a physics-based tactile
model in MuJoCo with real-world data collected from a physical system.
Comparative experiments show that pretraining on simulated data and fine-tuning
with a small amount of real data significantly improves performance over
simulation-only training. Extensive real-world experiments validate the
effectiveness of the method, achieving millimeter-level grasp accuracy using
only tactile input. To our knowledge, this is the first method to enable
arbitrary in-hand pose refinement via multi-finger tactile sensing alone.
Project website is available at https://sites.google.com/view/tacrefinenet

</details>


### [15] [Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real](https://arxiv.org/abs/2509.25747)
*Jialei Huang,Zhaoheng Yin,Yingdong Hu,Shuo Wang,Xingyu Lin,Yang Gao*

Main category: cs.RO

TL;DR: 提出解耦感知与控制的sim-to-real框架，在仿真中训练控制策略，在真实部署时仅适配感知模块，大幅减少真实数据需求


<details>
  <summary>Details</summary>
Motivation: 解决端到端学习中感知与控制纠缠导致的sim-to-real迁移难题

Method: 在仿真中用特权状态训练控制策略掌握空间布局和操作动态，部署时仅适配感知模块将真实观测映射到冻结的控制策略

Result: 仅需10-20个真实演示就能实现强性能，在桌面操作任务中表现出优越的数据效率和分布外泛化能力

Conclusion: 解耦感知与控制从根本上改善了sim-to-real迁移，学习到的策略能处理超出训练分布的物体位置和尺度

Abstract: Sim-to-real transfer remains a fundamental challenge in robot manipulation
due to the entanglement of perception and control in end-to-end learning. We
present a decoupled framework that learns each component where it is most
reliable: control policies are trained in simulation with privileged state to
master spatial layouts and manipulation dynamics, while perception is adapted
only at deployment to bridge real observations to the frozen control policy.
Our key insight is that control strategies and action patterns are universal
across environments and can be learned in simulation through systematic
randomization, while perception is inherently domain-specific and must be
learned where visual observations are authentic. Unlike existing end-to-end
approaches that require extensive real-world data, our method achieves strong
performance with only 10-20 real demonstrations by reducing the complex
sim-to-real problem to a structured perception alignment task. We validate our
approach on tabletop manipulation tasks, demonstrating superior data efficiency
and out-of-distribution generalization compared to end-to-end baselines. The
learned policies successfully handle object positions and scales beyond the
training distribution, confirming that decoupling perception from control
fundamentally improves sim-to-real transfer.

</details>


### [16] [SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling](https://arxiv.org/abs/2509.25756)
*Yixian Zhang,Shu'ang Yu,Tonghe Zhang,Mo Guang,Haojia Hui,Kaiwen Long,Yu Wang,Chao Yu,Wenbo Ding*

Main category: cs.RO

TL;DR: 提出两种稳定的流策略架构（Flow-G和Flow-T）来解决基于流的强化学习策略训练不稳定的问题，通过重新参数化速度网络并开发SAC算法实现端到端训练。


<details>
  <summary>Details</summary>
Motivation: 基于流的策略在离策略强化学习中训练不稳定，这种不稳定性源于流展开过程与残差循环计算的代数等价性，导致梯度消失和爆炸问题。

Method: 重新参数化速度网络，引入两种稳定架构：Flow-G（门控速度）和Flow-T（解码速度），开发基于SAC的算法，使用噪声增强的展开过程实现端到端训练。

Result: 在连续控制和机器人操作基准测试中达到最先进性能，支持从头开始学习和离线到在线学习。

Conclusion: 该方法消除了对策略蒸馏或替代目标等常见变通方法的需求，为流策略提供了稳定高效的训练框架。

Abstract: Training expressive flow-based policies with off-policy reinforcement
learning is notoriously unstable due to gradient pathologies in the multi-step
action sampling process. We trace this instability to a fundamental connection:
the flow rollout is algebraically equivalent to a residual recurrent
computation, making it susceptible to the same vanishing and exploding
gradients as RNNs. To address this, we reparameterize the velocity network
using principles from modern sequential models, introducing two stable
architectures: Flow-G, which incorporates a gated velocity, and Flow-T, which
utilizes a decoded velocity. We then develop a practical SAC-based algorithm,
enabled by a noise-augmented rollout, that facilitates direct end-to-end
training of these policies. Our approach supports both from-scratch and
offline-to-online learning and achieves state-of-the-art performance on
continuous control and robotic manipulation benchmarks, eliminating the need
for common workarounds like policy distillation or surrogate objectives.

</details>


### [17] [Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies](https://arxiv.org/abs/2509.25822)
*Jing Wang,Weiting Peng,Jing Tang,Zeyu Gong,Xihua Wang,Bo Tao,Li Cheng*

Main category: cs.RO

TL;DR: 提出DP-AG方法，通过动作引导的扩散策略统一感知与行动表示学习，利用变分推理和SDE建模感知-行动动态交互，在仿真和真实机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法将感知和行动解耦，忽视了人类行为中感知表示与行动执行之间的因果互惠关系，这限制了自适应行为的学习能力。

Method: 使用变分推理将观测编码为高斯后验，通过动作引导的SDE演化潜变量，其中扩散策略的噪声预测的VJP作为结构化随机力驱动潜变量更新，并引入循环一致性对比损失促进感知-行动双向学习。

Result: 在仿真基准测试和真实UR5机械臂操作任务中，DP-AG显著优于现有最先进方法。

Conclusion: DP-AG为连接生物适应性与人工策略学习提供了有前景的一步，通过统一表示学习建模感知与行动之间的动态交互。

Abstract: Existing imitation learning methods decouple perception and action, which
overlooks the causal reciprocity between sensory representations and action
execution that humans naturally leverage for adaptive behaviors. To bridge this
gap, we introduce Action--Guided Diffusion Policy (DP--AG), a unified
representation learning that explicitly models a dynamic interplay between
perception and action through probabilistic latent dynamics. DP--AG encodes
latent observations into a Gaussian posterior via variational inference and
evolves them using an action-guided SDE, where the Vector-Jacobian Product
(VJP) of the diffusion policy's noise predictions serves as a structured
stochastic force driving latent updates. To promote bidirectional learning
between perception and action, we introduce a cycle--consistent contrastive
loss that organizes the gradient flow of the noise predictor into a coherent
perception--action loop, enforcing mutually consistent transitions in both
latent updates and action refinements. Theoretically, we derive a variational
lower bound for the action-guided SDE, and prove that the contrastive objective
enhances continuity in both latent and action trajectories. Empirically, DP--AG
significantly outperforms state--of--the--art methods across simulation
benchmarks and real-world UR5 manipulation tasks. As a result, our DP--AG
offers a promising step toward bridging biological adaptability and artificial
policy learning.

</details>


### [18] [Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation](https://arxiv.org/abs/2509.25852)
*Zitong Bo,Yue Hu,Jinming Ma,Mingliang Zhou,Junhui Yin,Yachen Kang,Yuqi Liu,Tong Wu,Diyun Xiang,Hao Chen*

Main category: cs.RO

TL;DR: REVER框架通过训练RoboFarseer视觉语言模型，解决了机器人执行自然语言长时程操作任务的两个关键问题：缺乏大规模序列操作数据和密集可解释奖励。该模型能生成和验证物理合理、逻辑连贯的操作计划，在真实场景中显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人执行自然语言长时程操作任务的两个主要障碍：(i)缺乏大规模序列操作数据，(ii)缺乏用于微调视觉语言模型的密集可解释奖励。

Method: 提出REVER框架，训练RoboFarseer视觉语言模型进行时空推理，生成链式思维。利用通用操作界面框架收集硬件无关的原子技能演示，通过自动标注引擎生成视觉-指令-计划三元组，并引入可验证奖励机制评估生成计划的质量。

Result: RoboFarseer性能匹配或超越大数量级的专有模型，在开放式规划上比最佳基线提升40%以上。在真实世界长时程任务中，完整系统比无规划器的低级控制器提升约60%的整体成功率。

Conclusion: REVER框架成功解决了机器人自然语言操作规划的关键挑战，通过可验证奖励和链式思维推理，实现了物理合理且逻辑连贯的长时程操作计划生成与验证。

Abstract: Enabling robots to execute long-horizon manipulation tasks from free-form
language instructions remains a fundamental challenge in embodied AI. While
vision-language models (VLMs) have shown promise as high-level planners, their
deployment in the real world is hindered by two gaps: (i) the scarcity of
large-scale, sequential manipulation data that couples natural language with
multi-step action plans, and (ii) the absence of dense, interpretable rewards
for fine-tuning VLMs on planning objectives. To address these issues, we
propose REVER, a framework that empowers VLMs to generate and validate
long-horizon manipulation plans from natural language instructions in
real-world scenarios. Under REVER we train and release RoboFarseer, a VLM
incentivized to emit chain-of-thought that perform temporal and spatial
reasoning, ensuring physically plausible and logically coherent plans. To
obtain training data, we leverage the Universal Manipulation Interface
framework to capture hardware-agnostic demonstrations of atomic skills. An
automated annotation engine converts each demonstration into
vision-instruction-plan triplet. We introduce a verifiable reward that scores
the generated plan by its ordered bipartite matching overlap with the
ground-truth skill sequence. At run time, the fine-tuned VLM functions both as
a planner and as a monitor, verifying step-wise completion. RoboFarseer matches
or exceeds the performance of proprietary models that are orders of magnitude
larger, while on open-ended planning it surpasses the best baseline by more
than 40%. In real-world, long-horizon tasks, the complete system boosts overall
success by roughly 60% compared with the same low-level controller without the
planner. We will open-source both the dataset and the trained model upon
publication.

</details>


### [19] [State Estimation for Compliant and Morphologically Adaptive Robots](https://arxiv.org/abs/2509.25945)
*Valentin Yuryev,Max Polzin,Josie Hughes*

Main category: cs.RO

TL;DR: 提出了一种用于具有主动或被动柔顺性的移动机器人的状态估计方法，能够同时估计典型刚体状态和柔顺相关状态，如软体机器人在不同形态和运动模式下的形状。


<details>
  <summary>Details</summary>
Motivation: 柔顺性机器人缺乏刚体假设且形态变化导致运动学改变，使得状态估计具有挑战性，但这类机器人在农业、研究和环境产业中具有应用前景。

Method: 使用基于神经网络的状态估计器，利用状态历史记录和直接影响不可靠传感器的机制，在GOAT平台上进行测试，并在考虑形态相关状态的新型柔顺中心坐标系中使用运动捕捉数据进行训练。

Result: 预测形状相关测量值在机器人尺寸的4.2%以内，线速度和角速度分别在前最高速度的6.3%和2.4%以内，方向在1.5度以内。在电机故障时使用该估计器进行闭环自主户外操作，行程范围增加了300%。

Conclusion: 该方法能够有效估计柔顺机器人的状态，在极端户外地形中表现出鲁棒性，特别是在传感器不可靠或发生故障的情况下。

Abstract: Locomotion robots with active or passive compliance can show robustness to
uncertain scenarios, which can be promising for agricultural, research and
environmental industries. However, state estimation for these robots is
challenging due to the lack of rigid-body assumptions and kinematic changes
from morphing. We propose a method to estimate typical rigid-body states
alongside compliance-related states, such as soft robot shape in different
morphologies and locomotion modes. Our neural network-based state estimator
uses a history of states and a mechanism to directly influence unreliable
sensors. We test our framework on the GOAT platform, a robot capable of passive
compliance and active morphing for extreme outdoor terrain. The network is
trained on motion capture data in a novel compliance-centric frame that
accounts for morphing-related states. Our method predicts shape-related
measurements within 4.2% of the robot's size, velocities within 6.3% and 2.4%
of the top linear and angular speeds, respectively, and orientation within 1.5
degrees. We also demonstrate a 300% increase in travel range during a motor
malfunction when using our estimator for closed-loop autonomous outdoor
operation.

</details>


### [20] [Towards Intuitive Human-Robot Interaction through Embodied Gesture-Driven Control with Woven Tactile Skins](https://arxiv.org/abs/2509.25951)
*ChunPing Lam,Xiangjia Chen,Chenming Wu,Hao Chen,Binzhi Sun,Guoxin Fang,Charlie C. L. Wang,Chengkai Dai,Yeung Yam*

Main category: cs.RO

TL;DR: 提出了一种基于电容式编织触觉皮肤的人机交互框架，通过手势控制实现直观的机器人操作，相比传统面板和示教器，任务完成时间最多减少57%。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制界面依赖面板或手持设备，缺乏直观性和自然交互。需要一种能无缝集成到机器人曲面、缩小人类意图与机器人响应差距的交互方式。

Method: 开发编织触觉皮肤，结合织物柔性和结构稳定性，通过交织导电线程实现密集多通道传感。定义了14种单点和多点触控手势，采用轻量级卷积-Transformer模型进行实时手势识别。

Result: 手势识别准确率接近100%，优于现有基线方法。在机器人臂任务（如拾放和倾倒）中，相比键盘面板和示教器，任务完成时间最多减少57%。

Conclusion: 该框架为实现更自然高效的人机交互提供了实用途径，通过编织触觉皮肤和手势控制显著提升了交互体验。

Abstract: This paper presents a novel human-robot interaction (HRI) framework that
enables intuitive gesture-driven control through a capacitance-based woven
tactile skin. Unlike conventional interfaces that rely on panels or handheld
devices, the woven tactile skin integrates seamlessly with curved robot
surfaces, enabling embodied interaction and narrowing the gap between human
intent and robot response. Its woven design combines fabric-like flexibility
with structural stability and dense multi-channel sensing through the
interlaced conductive threads. Building on this capability, we define a
gesture-action mapping of 14 single- and multi-touch gestures that cover
representative robot commands, including task-space motion and auxiliary
functions. A lightweight convolution-transformer model designed for gesture
recognition in real time achieves an accuracy of near-100%, outperforming prior
baseline approaches. Experiments on robot arm tasks, including pick-and-place
and pouring, demonstrate that our system reduces task completion time by up to
57% compared with keyboard panels and teach pendants. Overall, our proposed
framework demonstrates a practical pathway toward more natural and efficient
embodied HRI.

</details>


### [21] [MUVLA: Learning to Explore Object Navigation via Map Understanding](https://arxiv.org/abs/2509.25966)
*Peilong Han,Fan Jia,Min Zhang,Yutao Qiu,Hongyao Tang,Yan Zheng,Tiancai Wang,Jianye Hao*

Main category: cs.RO

TL;DR: MUVLA是一个用于物体导航的地图理解视觉-语言-动作模型，通过语义地图抽象统一历史信息，采用三阶段训练流程，在HM3D和Gibson基准测试中表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决物体导航任务中历史信息整合和探索策略优化的问题，需要开发能够统一结构化历史信息并学习有效探索行为的模型。

Method: 利用语义地图抽象编码空间上下文，采用三阶段训练流程：学习地图级空间理解、从混合质量演示中模仿行为、奖励放大，通过奖励引导的回报建模增强监督。

Result: 在HM3D和Gibson基准测试中，MUVLA实现了良好的泛化能力，能够从低质量或部分成功的轨迹中学习有效的探索行为。

Conclusion: MUVLA通过语义地图抽象和三阶段训练策略，成功统一了多样化演示并生成了更合理的探索策略，在物体导航任务中表现出色。

Abstract: In this paper, we present MUVLA, a Map Understanding Vision-Language-Action
model tailored for object navigation. It leverages semantic map abstractions to
unify and structure historical information, encoding spatial context in a
compact and consistent form. MUVLA takes the current and history observations,
as well as the semantic map, as inputs and predicts the action sequence based
on the description of goal object. Furthermore, it amplifies supervision
through reward-guided return modeling based on dense short-horizon progress
signals, enabling the model to develop a detailed understanding of action value
for reward maximization. MUVLA employs a three-stage training pipeline:
learning map-level spatial understanding, imitating behaviors from
mixed-quality demonstrations, and reward amplification. This strategy allows
MUVLA to unify diverse demonstrations into a robust spatial representation and
generate more rational exploration strategies. Experiments on HM3D and Gibson
benchmarks demonstrate that MUVLA achieves great generalization and learns
effective exploration behaviors even from low-quality or partially successful
trajectories.

</details>


### [22] [S$^3$E: Self-Supervised State Estimation for Radar-Inertial System](https://arxiv.org/abs/2509.25984)
*Shengpeng Wang,Yulong Xie,Qing Liao,Wei Wang*

Main category: cs.RO

TL;DR: S^3E是一个自监督状态估计器，通过融合毫米波雷达信号频谱和惯性数据，在无需地面真值监督的情况下实现准确的状态估计。


<details>
  <summary>Details</summary>
Motivation: 现有基于雷达点云的定位解决方案存在点云稀疏、多径效应产生的鬼点以及单啁啾雷达角度分辨率有限等问题，严重影响了状态估计性能。

Method: 提出S^3E方法，利用更丰富的雷达信号频谱绕过稀疏点云，融合互补的惯性信息；采用跨融合技术通过利用异构数据间的细微旋转偏移相关性来增强空间结构信息。

Result: 实验结果表明该方法在不依赖定位地面真值监督的情况下实现了鲁棒且准确的性能。

Conclusion: 这是首次尝试以互补的自监督方式融合雷达频谱和惯性数据来实现状态估计的工作。

Abstract: Millimeter-wave radar for state estimation is gaining significant attention
for its affordability and reliability in harsh conditions. Existing
localization solutions typically rely on post-processed radar point clouds as
landmark points. Nonetheless, the inherent sparsity of radar point clouds,
ghost points from multi-path effects, and limited angle resolution in
single-chirp radar severely degrade state estimation performance. To address
these issues, we propose S$^3$E, a \textbf{S}elf-\textbf{S}upervised
\textbf{S}tate \textbf{E}stimator that employs more richly informative radar
signal spectra to bypass sparse points and fuses complementary inertial
information to achieve accurate localization. S$^3$E fully explores the
association between \textit{exteroceptive} radar and \textit{proprioceptive}
inertial sensor to achieve complementary benefits. To deal with limited angle
resolution, we introduce a novel cross-fusion technique that enhances spatial
structure information by exploiting subtle rotational shift correlations across
heterogeneous data. The experimental results demonstrate our method achieves
robust and accurate performance without relying on localization ground truth
supervision. To the best of our knowledge, this is the first attempt to achieve
state estimation by fusing radar spectra and inertial data in a complementary
self-supervised manner.

</details>


### [23] [Emotionally Expressive Robots: Implications for Children's Behavior toward Robot](https://arxiv.org/abs/2509.25986)
*Elisabetta Zibetti,Sureya Waheed Palmer,Rebecca Stower,Salvatore M Anzalone*

Main category: cs.RO

TL;DR: 研究探索机器人情感表达对儿童行为的影响，发现儿童会调整行为以适应机器人情绪状态，但更高的表达水平并未增强这种调整效应。


<details>
  <summary>Details</summary>
Motivation: 随着具有人工情感表达能力的机器人发展，需要研究其情感表达对儿童共情反应的影响程度和适当性。

Method: 在22名7-11岁儿童参与的试点研究中，使用QTRobot在合作轮换游戏中展示不同表达水平（仅身体、仅面部、身体和面部）的基本情绪（快乐和悲伤）。

Result: 儿童会调整行为以适应机器人推断的情绪状态，但更高的表达水平并未导致更强的行为调整。

Conclusion: 这些初步结果为思考机器人表达性及其在未来塑造儿童对机器人作为社交伙伴的社会情感行为中的作用提供了起点。

Abstract: The growing development of robots with artificial emotional expressiveness
raises important questions about their persuasive potential in children's
behavior. While research highlights the pragmatic value of emotional
expressiveness in human social communication, the extent to which robotic
expressiveness can or should influence empathic responses in children is
grounds for debate. In a pilot study with 22 children (aged 7-11) we begin to
explore the ways in which different levels of embodied expressiveness (body
only, face only, body and face) of two basic emotions (happiness and sadness)
displayed by an anthropomorphic robot (QTRobot) might modify children's
behavior in a child-robot cooperative turn-taking game. We observed that
children aligned their behavior to the robot's inferred emotional state.
However, higher levels of expressiveness did not result in increased alignment.
The preliminary results reported here provide a starting point for reflecting
on robotic expressiveness and its role in shaping children's social-emotional
behavior toward robots as social peers in the near future.

</details>


### [24] [On the Conic Complementarity of Planar Contacts](https://arxiv.org/abs/2509.25999)
*Yann de Mont-Marin,Louis Montaut,Jean Ponce,Martial Hebert,Justin Carpentier*

Main category: cs.RO

TL;DR: 本文提出了平面Signorini条件，将点接触的Signorini定律与中心压力概念统一起来，为刚体平面接触建模提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 连接机器人学中两个基础原理：防止物体穿透的Signorini定律和用于优化控制中的中心压力概念，弥散离散与连续接触模型之间的差距。

Method: 提出平面Signorini条件的锥互补公式，证明其与在整个接触面上执行点Signorini定律等价，并给出几何解释。

Result: 建立了统一的互补结构，自然捕捉粘附、分离和倾斜三种物理状态，扩展了经典中心压力概念。

Conclusion: 为处理平面接触提供了数学一致且计算可行的基础，对接触动力学精确仿真和高级控制优化算法设计具有重要意义。

Abstract: We present a unifying theoretical result that connects two foundational
principles in robotics: the Signorini law for point contacts, which underpins
many simulation methods for preventing object interpenetration, and the center
of pressure (also known as the zero-moment point), a key concept used in, for
instance, optimization-based locomotion control. Our contribution is the planar
Signorini condition, a conic complementarity formulation that models general
planar contacts between rigid bodies. We prove that this formulation is
equivalent to enforcing the punctual Signorini law across an entire contact
surface, thereby bridging the gap between discrete and continuous contact
models. A geometric interpretation reveals that the framework naturally
captures three physical regimes -sticking, separating, and tilting-within a
unified complementarity structure. This leads to a principled extension of the
classical center of pressure, which we refer to as the extended center of
pressure. By establishing this connection, our work provides a mathematically
consistent and computationally tractable foundation for handling planar
contacts, with implications for both the accurate simulation of contact
dynamics and the design of advanced control and optimization algorithms in
locomotion and manipulation.

</details>


### [25] [Conflict-Based Search and Prioritized Planning for Multi-Agent Path Finding Among Movable Obstacles](https://arxiv.org/abs/2509.26050)
*Shaoli Hu,Shizhe Zhao,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 本文研究了多智能体可移动障碍物路径规划问题，提出了融合CBS、PP和PAMO*的方法来解决该问题，并在大规模场景中进行了性能评估。


<details>
  <summary>Details</summary>
Motivation: 在物流和仓库环境中，移动机器人在意外可移动物体中导航的需求日益增长，而现有的多智能体路径规划和单智能体可移动障碍物规划方法无法有效解决这一复杂问题。

Method: 首次尝试将冲突搜索、优先级规划和PAMO*单智能体规划器进行融合，以应对包含可移动障碍物的多智能体路径规划挑战。

Result: 在最多20个智能体和数百个可移动障碍物的场景下进行了性能比较，展示了各种方法的优缺点。

Conclusion: 成功开发了解决M-PAMO问题的初步方法，为多智能体在可移动障碍物环境中的路径规划提供了有效解决方案。

Abstract: This paper investigates Multi-Agent Path Finding Among Movable Obstacles
(M-PAMO), which seeks collision-free paths for multiple agents from their start
to goal locations among static and movable obstacles. M-PAMO arises in
logistics and warehouses where mobile robots are among unexpected movable
objects. Although Multi-Agent Path Finding (MAPF) and single-agent Path
planning Among Movable Obstacles (PAMO) were both studied, M-PAMO remains
under-explored. Movable obstacles lead to new fundamental challenges as the
state space, which includes both agents and movable obstacles, grows
exponentially with respect to the number of agents and movable obstacles. In
particular, movable obstacles often closely couple agents together spatially
and temporally. This paper makes a first attempt to adapt and fuse the popular
Conflict-Based Search (CBS) and Prioritized Planning (PP) for MAPF, and a
recent single-agent PAMO planner called PAMO*, together to address M-PAMO. We
compare their performance with up to 20 agents and hundreds of movable
obstacles, and show the pros and cons of these approaches.

</details>


### [26] [Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance](https://arxiv.org/abs/2509.26082)
*Tianyi Jin,Melya Boukheddimi,Rohit Kumar,Gabriele Fadini,Frank Kirchner*

Main category: cs.RO

TL;DR: EA-CoRL框架结合强化学习和进化策略，实现机器人硬件设计和控制策略的协同优化，在RH5人形机器人的高动态引体向上任务中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统机器人设计采用顺序流程，硬件设计完成后才开发控制算法，这种分离方法限制了机器人充分发挥硬件潜力。需要并行优化设计和控制来最大化机器人能力。

Method: EA-CoRL框架包含两个核心组件：设计进化（使用进化算法探索硬件配置）和策略持续适应（在演化设计中微调任务特定的控制策略以最大化性能奖励）。

Result: 在RH5人形机器人的高动态引体向上任务中，EA-CoRL相比最先进的基于RL的协同设计方法获得了更高的适应度分数和更广泛的设计空间探索，成功解决了之前因执行器限制而不可行的任务。

Conclusion: EA-CoRL证明了持续策略适应在机器人协同设计中的关键作用，为机器人硬件和控制系统的集成优化提供了有效框架。

Abstract: Humanoid robots have seen significant advancements in both design and
control, with a growing emphasis on integrating these aspects to enhance
overall performance. Traditionally, robot design has followed a sequential
process, where control algorithms are developed after the hardware is
finalized. However, this can be myopic and prevent robots to fully exploit
their hardware capabilities. Recent approaches advocate for co-design,
optimizing both design and control in parallel to maximize robotic
capabilities. This paper presents the Evolutionary Continuous Adaptive RL-based
Co-Design (EA-CoRL) framework, which combines reinforcement learning (RL) with
evolutionary strategies to enable continuous adaptation of the control policy
to the hardware. EA-CoRL comprises two key components: Design Evolution, which
explores the hardware choices using an evolutionary algorithm to identify
efficient configurations, and Policy Continuous Adaptation, which fine-tunes a
task-specific control policy across evolving designs to maximize performance
rewards. We evaluate EA-CoRL by co-designing the actuators (gear ratios) and
control policy of the RH5 humanoid for a highly dynamic chin-up task,
previously unfeasible due to actuator limitations. Comparative results against
state-of-the-art RL-based co-design methods show that EA-CoRL achieves higher
fitness score and broader design space exploration, highlighting the critical
role of continuous policy adaptation in robot co-design.

</details>


### [27] [Autonomous Multi-Robot Infrastructure for AI-Enabled Healthcare Delivery and Diagnostics](https://arxiv.org/abs/2509.26106)
*Nakhul Kalaivanan,Senthil Arumugam Muthukumaraswamy,Girish Balasubramanian*

Main category: cs.RO

TL;DR: 开发了一个基于群体智能的多机器人系统，用于住院护理，通过可穿戴传感器、RF通信和AI决策支持实现患者监测、药物配送和紧急援助。


<details>
  <summary>Details</summary>
Motivation: 旨在通过自动化技术提高医院护理效率、降低人工成本，并确保患者安全，特别是在监测异常健康状况和提供及时援助方面。

Method: 采用领导者-跟随者群体配置，使用Arduino、Raspberry Pi、NRF24L01 RF模块和HuskyLens AI相机构建硬件系统，结合可穿戴传感器收集生理参数，并通过AI决策支持协调任务。

Result: 实验显示传感器准确率超过94%，任务成功率92%，通信可靠性96%，AI决策支持能提前预警异常健康状况。

Conclusion: 该系统展示了作为医院自动化和患者安全保障的成本效益解决方案的潜力，群体智能策略提升了通信可靠性和持续监测能力。

Abstract: This research presents a multi-robot system for inpatient care, designed
using swarm intelligence principles and incorporating wearable health sensors,
RF-based communication, and AI-driven decision support. Within a simulated
hospital environment, the system adopts a leader-follower swarm configuration
to perform patient monitoring, medicine delivery, and emergency assistance. Due
to ethical constraints, live patient trials were not conducted; instead,
validation was carried out through controlled self-testing with wearable
sensors. The Leader Robot acquires key physiological parameters, including
temperature, SpO2, heart rate, and fall detection, and coordinates other robots
when required. The Assistant Robot patrols corridors for medicine delivery,
while a robotic arm provides direct drug administration. The swarm-inspired
leader-follower strategy enhanced communication reliability and ensured
continuous monitoring, including automated email alerts to healthcare staff.
The system hardware was implemented using Arduino, Raspberry Pi, NRF24L01 RF
modules, and a HuskyLens AI camera. Experimental evaluation showed an overall
sensor accuracy above 94%, a 92% task-level success rate, and a 96%
communication reliability rate, demonstrating system robustness. Furthermore,
the AI-enabled decision support was able to provide early warnings of abnormal
health conditions, highlighting the potential of the system as a cost-effective
solution for hospital automation and patient safety.

</details>


### [28] [Side Scan Sonar-based SLAM for Autonomous Algae Farm Monitoring](https://arxiv.org/abs/2509.26121)
*Julian Valdez,Ignacio Torroba,John Folkesson,Ivan Stenius*

Main category: cs.RO

TL;DR: 提出了一种基于侧扫声纳的SLAM框架，用于海藻养殖场中自主水下航行器的安全导航，通过将结构绳索建模为单个地标序列而非组合成延伸表示，在真实海藻养殖场实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 海藻养殖向工业化规模转型需要自动化智能养殖，自主水下航行器(AUV)是实现作物和结构检查自动化的关键，但目前部署的瓶颈是确保在养殖场内的安全导航，这需要准确的在线AUV位姿和基础设施地图估计。

Method: 提出高效的侧扫声纳(SSS)同时定位与地图构建(SLAM)框架，利用海藻养殖场的几何结构，在后端将结构绳索建模为每个SSS探测的单个地标序列，而不是将探测组合成延伸表示。

Result: 在真实海藻养殖场的硬件在环(HIL)实验中，该方法优于现有最先进解决方案。

Conclusion: 该框架和数据集可在GitHub上获取，为海藻养殖场中AUV的安全导航提供了有效解决方案。

Abstract: The transition of seaweed farming to an alternative food source on an
industrial scale relies on automating its processes through smart farming,
equivalent to land agriculture. Key to this process are autonomous underwater
vehicles (AUVs) via their capacity to automate crop and structural inspections.
However, the current bottleneck for their deployment is ensuring safe
navigation within farms, which requires an accurate, online estimate of the AUV
pose and map of the infrastructure. To enable this, we propose an efficient
side scan sonar-based (SSS) simultaneous localization and mapping (SLAM)
framework that exploits the geometry of kelp farms via modeling structural
ropes in the back-end as sequences of individual landmarks from each SSS ping
detection, instead of combining detections into elongated representations. Our
method outperforms state of the art solutions in hardware in the loop (HIL)
experiments on a real AUV survey in a kelp farm. The framework and dataset can
be found at https://github.com/julRusVal/sss_farm_slam.

</details>


### [29] [Terrain-Awared LiDAR-Inertial Odometry for Legged-Wheel Robots Based on Radial Basis Function Approximation](https://arxiv.org/abs/2509.26222)
*Yizhe Liu,Han Zhang*

Main category: cs.RO

TL;DR: 提出了一种面向足轮机器人的地形感知LiDAR-惯性里程计框架，使用径向基函数自适应建模地形几何，通过软约束缓解z轴姿态漂移问题，并在GPU上实现实时计算。


<details>
  <summary>Details</summary>
Motivation: 现有方法在非结构化地形（如颠簸道路和楼梯）中运行时，由于忽略地形几何信息，常常出现姿态漂移问题。

Method: 使用径向基函数(RBF)近似地形，自适应选择中心点并递归更新权重，创建平滑地形流形，在里程计优化中施加软约束来缓解z轴漂移，并通过GPU并行化确保实时性能。

Result: 在非结构化地形上的实验表明，该方法在定位精度上优于现有最先进基线方法，特别是在连续高度变化或特征稀疏且发生急剧高度变化的场景中表现更优。

Conclusion: 所提出的地形感知LiDAR-惯性里程计框架通过有效建模地形几何，显著提高了足轮机器人在非结构化环境中的定位精度和鲁棒性。

Abstract: An accurate odometry is essential for legged-wheel robots operating in
unstructured terrains such as bumpy roads and staircases. Existing methods
often suffer from pose drift due to their ignorance of terrain geometry. We
propose a terrain-awared LiDAR-Inertial odometry (LIO) framework that
approximates the terrain using Radial Basis Functions (RBF) whose centers are
adaptively selected and weights are recursively updated. The resulting smooth
terrain manifold enables ``soft constraints" that regularize the odometry
optimization and mitigates the $z$-axis pose drift under abrupt elevation
changes during robot's maneuver. To ensure the LIO's real-time performance, we
further evaluate the RBF-related terms and calculate the inverse of the sparse
kernel matrix with GPU parallelization. Experiments on unstructured terrains
demonstrate that our method achieves higher localization accuracy than the
state-of-the-art baselines, especially in the scenarios that have continuous
height changes or sparse features when abrupt height changes occur.

</details>


### [30] [ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm](https://arxiv.org/abs/2509.26236)
*Benjamin A. Richardson,Felix Grüninger,Lukas Mack,Joerg Stueckler,Katherine J. Kuchenbecker*

Main category: cs.RO

TL;DR: 介绍了ISyHand开源机器人手，这是一种低成本、易于制造、高灵巧度的机器人手，采用关节式手掌设计，在保持人形特征的同时提升了灵巧性。通过强化学习在模拟环境中训练立方体重定向任务，并在真实硬件上验证了性能。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人和定制制造解决方案的快速发展，灵巧操作成为现代机器人学的关键。虽然市场上已有昂贵的灵巧手，但硬件设计的进步使得低成本开源手成为可能。大多数手为了使用标准工具而采用人形设计，但提升灵巧性往往牺牲人形特征。

Method: 开发了ISyHand开源机器人手，使用现成的Dynamixel电机、紧固件和3D打印部件，可在4小时内组装完成。采用独特的关节式手掌设计，在保持人形特征的同时提升整体灵巧性。使用强化学习在模拟环境中训练立方体重定向任务。

Result: ISyHand总材料成本约1300美元。模拟实验显示，在早期训练阶段优于两个最可比的手，收敛后三者性能相似，但显著优于固定手掌版本。在真实硬件上成功部署了立方体重定向策略。

Conclusion: ISyHand证明了低成本、易于制造的机器人手能够实现高灵巧度操作。关节式手掌设计在保持人形特征的同时有效提升了灵巧性，为灵巧操作研究提供了实用的硬件平台。

Abstract: The rapid increase in the development of humanoid robots and customized
manufacturing solutions has brought dexterous manipulation to the forefront of
modern robotics. Over the past decade, several expensive dexterous hands have
come to market, but advances in hardware design, particularly in servo motors
and 3D printing, have recently facilitated an explosion of cheaper open-source
hands. Most hands are anthropomorphic to allow use of standard human tools, and
attempts to increase dexterity often sacrifice anthropomorphism. We introduce
the open-source ISyHand (pronounced easy-hand), a highly dexterous, low-cost,
easy-to-manufacture, on-joint servo-driven robot hand. Our hand uses
off-the-shelf Dynamixel motors, fasteners, and 3D-printed parts, can be
assembled within four hours, and has a total material cost of about 1,300 USD.
The ISyHands's unique articulated-palm design increases overall dexterity with
only a modest sacrifice in anthropomorphism. To demonstrate the utility of the
articulated palm, we use reinforcement learning in simulation to train the hand
to perform a classical in-hand manipulation task: cube reorientation. Our
novel, systematic experiments show that the simulated ISyHand outperforms the
two most comparable hands in early training phases, that all three perform
similarly well after policy convergence, and that the ISyHand significantly
outperforms a fixed-palm version of its own design. Additionally, we deploy a
policy trained on cube reorientation on the real hand, demonstrating its
ability to perform real-world dexterous manipulation.

</details>


### [31] [Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation](https://arxiv.org/abs/2509.26308)
*Niklas Grambow,Lisa-Marie Fenner,Felipe Kempkes,Philip Hotz,Dingyuan Wan,Jörg Krüger,Kevin Haninger*

Main category: cs.RO

TL;DR: 该论文研究了基于自编码器的异常检测方法在工业机器人任务中的应用，验证了其在多种控制策略和任务类型间的可迁移性，在电缆布线和拧螺丝任务中实现了高精度异常检测。


<details>
  <summary>Details</summary>
Motivation: 机器人操作中的分布外状态会导致不可预测行为或任务失败，需要异常检测来触发安全机制和恢复策略。现有方法在跨控制策略和任务类型的可迁移性尚未得到验证。

Method: 构建了三种工业机器人任务场景（电缆布线、拧螺丝、打磨），收集多模态时间序列数据，比较了多种基于自编码器的异常检测方法，评估了在扩散策略、位置控制和阻抗控制等不同控制方法下的泛化能力。

Result: 在电缆布线和拧螺丝任务中实现了可靠的异常检测（AUROC超过0.93），能检测零件错误、错位和目标受阻等故障。在打磨任务中仅能可靠检测严重故障，较细微的故障类型未被检测到。

Conclusion: 基于自编码器的异常检测方法在工业机器人任务中具有较好的可迁移性，特别是在电缆布线和拧螺丝任务中表现优异，但在检测细微故障方面仍需改进。

Abstract: Out-of-distribution states in robot manipulation often lead to unpredictable
robot behavior or task failure, limiting success rates and increasing risk of
damage. Anomaly detection (AD) can identify deviations from expected patterns
in data, which can be used to trigger failsafe behaviors and recovery
strategies. Prior work has applied data-driven AD to time series data in
specific robotic tasks, but its transferability across control strategies and
task types has not been shown. Leveraging time series data, such as
force/torque signals, allows to directly capture robot-environment
interactions, crucial for manipulation and online failure detection. Their
broad availability, high sampling rates, and low dimensionality enable high
temporal resolution and efficient processing. As robotic tasks can have widely
signal characteristics and requirements, AD methods which can be applied in the
same way to a wide range of tasks is needed, ideally with good data efficiency.
We examine three industrial robotic tasks, each presenting several anomalies.
Test scenarios in robotic cabling, screwing, and sanding are built, and
multimodal time series data is gathered. Several autoencoder-based methods are
compared, evaluating generalization across tasks and control methods (diffusion
policy, position, and impedance control). This allows us to validate the
integration of AD in complex tasks involving tighter tolerances and variation
from both the robot and its environment. Additionally, we evaluate data
efficiency, detection latency, and task characteristics which support robust
detection. The results indicate reliable detection with AUROC exceeding 0.93 in
failures in the cabling and screwing task, such as incorrect or misaligned
parts and obstructed targets. In the polishing task, only severe failures were
reliably detected, while more subtle failure types remained undetected.

</details>


### [32] [LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search](https://arxiv.org/abs/2509.26324)
*Ruiyang Wang,Haolun Tsu,David Hunt,Shaocheng Luo,Jiwoo Kim,Miroslav Pajic*

Main category: cs.RO

TL;DR: LLM-MCoX框架利用大型语言模型协调多机器人系统进行自主探索和对象搜索，相比传统方法显著提升了探索效率和搜索性能。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人系统在未知室内环境中的探索和对象搜索存在协调不足的问题，需要更智能的协调策略来提升效率。

Method: 结合实时LiDAR扫描处理（前沿聚类提取和门道检测）与多模态LLM推理，基于共享环境地图和机器人状态生成协调的航点分配。

Result: 在6个机器人的大型环境中，相比贪婪和Voronoi规划器，探索时间加快22.7%，搜索效率提升50%，并支持自然语言对象搜索。

Conclusion: LLM-MCoX通过LLM智能协调实现了多机器人系统的高效探索和语义搜索能力，为传统算法无法处理的自然语言指导提供了解决方案。

Abstract: Autonomous exploration and object search in unknown indoor environments
remain challenging for multi-robot systems (MRS). Traditional approaches often
rely on greedy frontier assignment strategies with limited inter-robot
coordination. In this work, we introduce LLM-MCoX (LLM-based Multi-robot
Coordinated Exploration and Search), a novel framework that leverages Large
Language Models (LLMs) for intelligent coordination of both homogeneous and
heterogeneous robot teams tasked with efficient exploration and target object
search. Our approach combines real-time LiDAR scan processing for frontier
cluster extraction and doorway detection with multimodal LLM reasoning (e.g.,
GPT-4o) to generate coordinated waypoint assignments based on shared
environment maps and robot states. LLM-MCoX demonstrates superior performance
compared to existing methods, including greedy and Voronoi-based planners,
achieving 22.7% faster exploration times and 50% improved search efficiency in
large environments with 6 robots. Notably, LLM-MCoX enables natural
language-based object search capabilities, allowing human operators to provide
high-level semantic guidance that traditional algorithms cannot interpret.

</details>


### [33] [Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models](https://arxiv.org/abs/2509.26339)
*Eric R. Damm,Thomas M. Howard*

Main category: cs.RO

TL;DR: 该论文提出了一种在多假设世界模型中进行运动规划的方法GEGRH，通过跟踪历史世界模型并调整节点成本，在不确定环境中生成更安全的路径规划。


<details>
  <summary>Details</summary>
Motivation: 移动地面机器人在未知环境中需要依赖传感器数据建模，但由于噪声和算法限制，障碍物识别可能不一致，导致安全运动规划困难。需要解决成本地图中区域在障碍物和自由空间之间切换的问题。

Method: 提出了三种迭代方法：PEH（为每个跨越分歧点的节点扩展调用子搜索）、GEH和GEGRH（将子搜索推迟到边扩展到目标区域后）。GEGRH还增加了基于每个世界中分歧节点修订图的步骤。

Result: GEGRH在非结构化越野环境中的现场实验表明，相比VEH方法，它能找到成本更低的轨迹且平均规划时间更快。相比单假设搜索，GEGRH生成更保守的规划，平均规划时间略有增加。

Conclusion: GEGRH方法在多假设世界模型下能够有效平衡规划质量和计算效率，在不确定环境中提供更安全的运动规划解决方案。

Abstract: Mobile ground robots lacking prior knowledge of an environment must rely on
sensor data to develop a model of their surroundings. In these scenarios,
consistent identification of obstacles and terrain features can be difficult
due to noise and algorithmic shortcomings, which can make it difficult for
motion planning systems to generate safe motions. One particular difficulty to
overcome is when regions of the cost map switch between being marked as
obstacles and free space through successive planning cycles. One potential
solution to this, which we refer to as Valid in Every Hypothesis (VEH), is for
the planning system to plan motions that are guaranteed to be safe through a
history of world models. Another approach is to track a history of world
models, and adjust node costs according to the potential penalty of needing to
reroute around previously hazardous areas. This work discusses three major
iterations on this idea. The first iteration, called PEH, invokes a sub-search
for every node expansion that crosses through a divergence point in the world
models. The second and third iterations, called GEH and GEGRH respectively,
defer the sub-search until after an edge expands into the goal region. GEGRH
uses an additional step to revise the graph based on divergent nodes in each
world. Initial results showed that, although PEH and GEH find more optimistic
solutions than VEH, they are unable to generate solutions in less than
one-second, which exceeds our requirements for field deployment. Analysis of
results from a field experiment in an unstructured, off-road environment on a
Clearpath Robotics Warthog UGV indicate that GEGRH finds lower cost
trajectories and has faster average planning times than VEH. Compared to
single-hypothesis (SH) search, where only the latest world model is considered,
GEGRH generates more conservative plans with a small increase in average
planning time.

</details>


### [34] [SDA-PLANNER: State-Dependency Aware Adaptive Planner for Embodied Task Planning](https://arxiv.org/abs/2509.26375)
*Zichao Shen,Chen Gao,Jiaqi Yuan,Tianchen Zhu,Xingcheng Fu,Qingyun Sun*

Main category: cs.RO

TL;DR: SDA-PLANNER是一个用于具身任务规划的新方法，通过状态依赖图和错误自适应重规划机制，解决了现有LLM规划器在规划范式、动作序列约束和错误处理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的具身任务规划方法存在三个主要限制：固定的规划范式、缺乏动作序列约束以及对错误的忽视。需要开发能够自适应规划、考虑状态依赖关系并能处理执行错误的方法。

Method: 提出SDA-PLANNER，引入状态依赖图来显式建模动作前提条件和效果，指导动态修订。采用错误自适应重规划策略，包括错误回溯与诊断以及自适应动作子树生成，基于当前环境状态局部重建受影响的部分计划。

Result: 实验表明SDA-PLANNER在成功率和目标完成度方面持续优于基线方法，特别是在各种错误条件下表现更佳。

Conclusion: SDA-PLANNER通过自适应规划范式、状态依赖感知和错误感知机制，为具身任务规划提供了更全面的解决方案，显著提升了规划性能。

Abstract: Embodied task planning requires agents to produce executable actions in a
close-loop manner within the environment. With progressively improving
capabilities of LLMs in task decomposition, planning, and generalization,
current embodied task planning methods adopt LLM-based architecture.However,
existing LLM-based planners remain limited in three aspects, i.e., fixed
planning paradigms, lack of action sequence constraints, and error-agnostic. In
this work, we propose SDA-PLANNER, enabling an adaptive planning paradigm,
state-dependency aware and error-aware mechanisms for comprehensive embodied
task planning. Specifically, SDA-PLANNER introduces a State-Dependency Graph to
explicitly model action preconditions and effects, guiding the dynamic
revision. To handle execution error, it employs an error-adaptive replanning
strategy consisting of Error Backtrack and Diagnosis and Adaptive Action
SubTree Generation, which locally reconstructs the affected portion of the plan
based on the current environment state. Experiments demonstrate that
SDA-PLANNER consistently outperforms baselines in success rate and goal
completion, particularly under diverse error conditions.

</details>


### [35] [Real-time Velocity Profile Optimization for Time-Optimal Maneuvering with Generic Acceleration Constraints](https://arxiv.org/abs/2509.26428)
*Mattia Piazza,Mattia Piccinini,Sebastiano Taddei,Francesco Biral,Enrico Bertolazzi*

Main category: cs.RO

TL;DR: FBGA是一种新的前向-后向算法，用于在给定路径上计算时间最优速度剖面，支持通用加速度约束，在保持高精度的同时显著降低计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么支持任意加速度约束但计算成本高，要么使用保守的箱式约束以提高计算效率。需要一种既能处理复杂加速度约束又计算高效的方法。

Method: FBGA通过前向和后向传递在短离散路径段上最大化速度剖面，同时满足用户定义的性能限制。支持复杂非凸加速度约束的自定义公式。

Result: 在五个赛道和两种车辆类别上测试，FBGA与最优控制基准的圈时误差在0.11%-0.36%之间，计算速度提升高达三个数量级。即使在粗离散化下仍保持高精度。

Conclusion: FBGA实现了高精度和低计算时间的平衡，非常适合在线多查询轨迹规划。已提供开源C++实现。

Abstract: The computation of time-optimal velocity profiles along prescribed paths,
subject to generic acceleration constraints, is a crucial problem in robot
trajectory planning, with particular relevance to autonomous racing. However,
the existing methods either support arbitrary acceleration constraints at high
computational cost or use conservative box constraints for computational
efficiency. We propose FBGA, a new \underline{F}orward-\underline{B}ackward
algorithm with \underline{G}eneric \underline{A}cceleration constraints, which
achieves both high accuracy and low computation time. FBGA operates forward and
backward passes to maximize the velocity profile in short, discretized path
segments, while satisfying user-defined performance limits. Tested on five
racetracks and two vehicle classes, FBGA handles complex, non-convex
acceleration constraints with custom formulations. Its maneuvers and lap times
closely match optimal control baselines (within $0.11\%$-$0.36\%$), while being
up to three orders of magnitude faster. FBGA maintains high accuracy even with
coarse discretization, making it well-suited for online multi-query trajectory
planning. Our open-source \texttt{C++} implementation is available at:
https://anonymous.4open.science/r/FB_public_RAL.

</details>


### [36] [Unwinding Rotations Reduces VR Sickness in Nonsimulated Immersive Telepresence](https://arxiv.org/abs/2509.26439)
*Filip Kulisiewicz,Basak Sakcak,Evan G. Center,Juho Kalliokoski,Katherine J. Mimnaugh,Steven M. LaValle,Timo Ojala*

Main category: cs.RO

TL;DR: 本文研究了在沉浸式机器人远程临场系统中，通过解耦机器人旋转与用户视角旋转来减少VR晕动症的方法，并在真实环境中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 沉浸式机器人远程临场系统中，机器人运动会导致相机旋转，从而引发VR晕动症，影响用户体验。虽然已有研究表明解耦旋转可以增加舒适度，但这些研究基于虚拟环境和模拟机器人，需要在真实环境中验证。

Method: 进行了用户研究（n=36），比较了在真实全景相机安装在机械臂上的任务中，解耦旋转方法与耦合旋转方法的效果。在涉及三维平移和旋转的检查任务中，测试了解耦旋转对用户性能的影响。

Result: 用户认为解耦旋转方法更舒适、更受欢迎，并且可以在不影响任务性能的情况下显著降低VR晕动症水平。

Conclusion: 解耦机器人旋转的方法在真实环境中同样有效，能够提高用户舒适度并减少VR晕动症，且不会显著影响任务性能。

Abstract: Immersive telepresence, when a user views the video stream of a $360^\circ$
camera in a remote environment using a Head Mounted Display (HMD), has great
potential to improve the sense of being in a remote environment. In most cases
of immersive robotic telepresence, the camera is mounted on a mobile robot
which increases the portion of the environment that the remote user can
explore. However, robot motions can induce unpleasant symptoms associated with
Virtual Reality (VR) sickness, degrading the overall user experience. Previous
research has shown that unwinding the rotations of the robot, that is,
decoupling the rotations that the camera undergoes due to robot motions from
what is seen by the user, can increase user comfort and reduce VR sickness.
However, that work considered a virtual environment and a simulated robot. In
this work, to test whether the same hypotheses hold when the video stream from
a real camera is used, we carried out a user study $(n=36)$ in which the
unwinding rotations method was compared against coupled rotations in a task
completed through a panoramic camera mounted on a robotic arm. Furthermore,
within an inspection task which involved translations and rotations in three
dimensions, we tested whether unwinding the robot rotations impacted the
performance of users. The results show that the users found the unwinding
rotations method to be more comfortable and preferable, and that a reduced
level of VR sickness can be achieved without a significant impact on task
performance.

</details>


### [37] [Analytic Conditions for Differentiable Collision Detection in Trajectory Optimization](https://arxiv.org/abs/2509.26459)
*Akshay Jaitly,Devesh K. Jha,Kei Ota,Yuki Shirai*

Main category: cs.RO

TL;DR: 提出了一种在优化过程中高效执行非穿透约束的方法，适用于碰撞感知轨迹优化问题，通过引入可微条件和将多面体近似为光滑半代数集来实现。


<details>
  <summary>Details</summary>
Motivation: 基于优化的方法在复杂任务中应用广泛，但需要强制执行物体间的非穿透约束，这导致问题复杂且计算昂贵，限制了优化方法在规划和控制中的应用。

Method: 引入具有解析表达式的可微条件来执行非穿透约束，并提出将多面体近似为光滑半代数集的方法来处理非光滑物体间的非碰撞问题。

Result: 通过多个数值实验验证了所提方法的性能，并与文献中其他基线方法进行了比较。

Conclusion: 该方法能够高效地在优化过程中执行非穿透约束，为碰撞感知轨迹优化等应用提供了有效的解决方案。

Abstract: Optimization-based methods are widely used for computing fast, diverse
solutions for complex tasks such as collision-free movement or planning in the
presence of contacts. However, most of these methods require enforcing
non-penetration constraints between objects, resulting in a non-trivial and
computationally expensive problem. This makes the use of optimization-based
methods for planning and control challenging. In this paper, we present a
method to efficiently enforce non-penetration of sets while performing
optimization over their configuration, which is directly applicable to problems
like collision-aware trajectory optimization. We introduce novel differentiable
conditions with analytic expressions to achieve this. To enforce non-collision
between non-smooth bodies using these conditions, we introduce a method to
approximate polytopes as smooth semi-algebraic sets. We present several
numerical experiments to demonstrate the performance of the proposed method and
compare the performance with other baseline methods recently proposed in the
literature.

</details>


### [38] [Learning from Hallucinating Critical Points for Navigation in Dynamic Environments](https://arxiv.org/abs/2509.26513)
*Saad Abdul Ghani,Kameron Lee,Xuesu Xiao*

Main category: cs.RO

TL;DR: 提出LfH-CP自监督框架，通过幻觉关键点生成多样化动态障碍物数据集，无需专家演示或试错探索


<details>
  <summary>Details</summary>
Motivation: 在动态障碍物环境中生成大规模多样化数据集具有挑战性，因为障碍物轨迹空间巨大

Method: 将幻觉分解为两个阶段：识别关键点（障碍物必须出现的时间和位置），然后程序化生成通过这些点且避免碰撞的多样化轨迹

Result: LfH-CP比现有基线产生更多样化的训练数据，仿真实验显示使用LfH-CP数据集训练的规划器成功率更高

Conclusion: LfH-CP框架能有效生成丰富的动态障碍物数据集，提高运动规划性能

Abstract: Generating large and diverse obstacle datasets to learn motion planning in
environments with dynamic obstacles is challenging due to the vast space of
possible obstacle trajectories. Inspired by hallucination-based data synthesis
approaches, we propose Learning from Hallucinating Critical Points (LfH-CP), a
self-supervised framework for creating rich dynamic obstacle datasets based on
existing optimal motion plans without requiring expensive expert demonstrations
or trial-and-error exploration. LfH-CP factorizes hallucination into two
stages: first identifying when and where obstacles must appear in order to
result in an optimal motion plan, i.e., the critical points, and then
procedurally generating diverse trajectories that pass through these points
while avoiding collisions. This factorization avoids generative failures such
as mode collapse and ensures coverage of diverse dynamic behaviors. We further
introduce a diversity metric to quantify dataset richness and show that LfH-CP
produces substantially more varied training data than existing baselines.
Experiments in simulation demonstrate that planners trained on LfH-CP datasets
achieves higher success rates compared to a prior hallucination method.

</details>


### [39] [Memory-Efficient 2D/3D Shape Assembly of Robot Swarms](https://arxiv.org/abs/2509.26518)
*Shuoyu Yue,Pengpeng Li,Yang Xu,Kunrui Ze,Xingjian Long,Huazi Cao,Guibin Sun*

Main category: cs.RO

TL;DR: 提出一种基于树形图表示的记忆高效机器人群体形状组装方法，相比现有均值漂移方法显著降低内存使用并提高组装速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于均值漂移的机器人群体形状组装方法使用图像表示目标形状，导致高内存开销，特别是在高分辨率或3D形状时变得不可行。

Method: 使用分层编码用户指定形状的树形图表示，设计基于行为的分布式控制器，实现无分配的形状组装。

Result: 2D和3D模拟显示内存使用降低1-2个数量级，形状进入速度快2-3倍，同时保持相当的均匀性。物理实验验证了实际可行性。

Conclusion: 提出的树形图表示方法有效解决了现有均值漂移方法的内存瓶颈问题，在保持性能的同时显著提升了效率。

Abstract: Mean-shift-based approaches have recently emerged as the most effective
methods for robot swarm shape assembly tasks. These methods rely on image-based
representations of target shapes to compute local density gradients and perform
mean-shift exploration, which constitute their core mechanism. However, such
image representations incur substantial memory overhead, which can become
prohibitive for high-resolution or 3D shapes. To overcome this limitation, we
propose a memory-efficient tree map representation that hierarchically encodes
user-specified shapes and is applicable to both 2D and 3D scenarios. Building
on this representation, we design a behavior-based distributed controller that
enables assignment-free shape assembly. Comparative 2D and 3D simulations
against a state-of-the-art mean-shift algorithm demonstrate one to two orders
of magnitude lower memory usage and two to three times faster shape entry while
maintaining comparable uniformity. Finally, we validate the framework through
physical experiments with 6 to 7 UAVs, confirming its real-world practicality.

</details>


### [40] [Radio-based Multi-Robot Odometry and Relative Localization](https://arxiv.org/abs/2509.26558)
*Andrés Martínez-Silva,David Alejo,Luis Merino,Fernando Caballero*

Main category: cs.RO

TL;DR: 提出了一种基于UWB和雷达的多机器人UGV-UAV相对定位系统，通过非线性优化和位姿图优化框架实现空中机器人相对于地面机器人的位置估计，在噪声环境下优于现有闭式方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于无线电的方法如UWB和雷达在机器人领域应用有限，但由于其对恶劣环境和杂乱环境的鲁棒性，正重新受到关注。需要开发低成本、易获取的多机器人相对定位系统。

Method: 系统采用两阶段方法：第一阶段使用非线性优化框架对UWB测距数据进行三边定位，以及雷达预处理模块；第二阶段将预处理雷达数据和相对变换输入到位姿图优化框架中，包含里程计和机器人间约束。

Result: 该系统在SITL仿真和真实世界数据集中得到验证，在噪声环境下优于最先进的闭式方法，并且系统可扩展至完整SLAM。

Conclusion: 提出的相对定位模块在噪声鲁棒性方面表现优异，系统代码和实验数据已公开，支持可重复性和基准测试。

Abstract: Radio-based methods such as Ultra-Wideband (UWB) and RAdio Detection And
Ranging (radar), which have traditionally seen limited adoption in robotics,
are experiencing a boost in popularity thanks to their robustness to harsh
environmental conditions and cluttered environments. This work proposes a
multi-robot UGV-UAV localization system that leverages the two technologies
with inexpensive and readily-available sensors, such as Inertial Measurement
Units (IMUs) and wheel encoders, to estimate the relative position of an aerial
robot with respect to a ground robot. The first stage of the system pipeline
includes a nonlinear optimization framework to trilaterate the location of the
aerial platform based on UWB range data, and a radar pre-processing module with
loosely coupled ego-motion estimation which has been adapted for a multi-robot
scenario. Then, the pre-processed radar data as well as the relative
transformation are fed to a pose-graph optimization framework with odometry and
inter-robot constraints. The system, implemented for the Robotic Operating
System (ROS 2) with the Ceres optimizer, has been validated in
Software-in-the-Loop (SITL) simulations and in a real-world dataset. The
proposed relative localization module outperforms state-of-the-art closed-form
methods which are less robust to noise. Our SITL environment includes a custom
Gazebo plugin for generating realistic UWB measurements modeled after real
data. Conveniently, the proposed factor graph formulation makes the system
readily extensible to full Simultaneous Localization And Mapping (SLAM).
Finally, all the code and experimental data is publicly available to support
reproducibility and to serve as a common open dataset for benchmarking.

</details>


### [41] [Graphite: A GPU-Accelerated Mixed-Precision Graph Optimization Framework](https://arxiv.org/abs/2509.26581)
*Shishir Gopinath,Karthik Dantu,Steven Y. Ko*

Main category: cs.RO

TL;DR: Graphite是一个GPU加速的非线性图优化框架，提供CUDA C++接口，支持内存优化技术，在捆绑调整问题上性能与专用求解器相当，在视觉-惯性捆绑调整中比CPU基准快59倍。


<details>
  <summary>Details</summary>
Motivation: 开发一个通用的GPU加速非线性图优化框架，既能保持高性能，又能减少内存使用，适用于实时应用如SLAM系统。

Method: 提供CUDA C++接口支持代码共享，采用内存优化技术包括原地优化、多浮点类型支持、混合精度模式和动态计算雅可比矩阵。

Result: 在捆绑调整问题上与专用求解器MegBA性能相当但内存使用更少；在视觉-惯性捆绑调整中比CPU基准快59倍。

Conclusion: Graphite能够在桌面和资源受限设备上实现更快的大规模优化，同时保持通用性和内存效率。

Abstract: We present Graphite, a GPU-accelerated nonlinear graph optimization
framework. It provides a CUDA C++ interface to enable the sharing of code
between a realtime application, such as a SLAM system, and its optimization
tasks. The framework supports techniques to reduce memory usage, including
in-place optimization, support for multiple floating point types and
mixed-precision modes, and dynamically computed Jacobians. We evaluate Graphite
on well-known bundle adjustment problems and find that it achieves similar
performance to MegBA, a solver specialized for bundle adjustment, while
maintaining generality and using less memory. We also apply Graphite to global
visual-inertial bundle adjustment on maps generated from stereo-inertial SLAM
datasets, and observe speed ups of up to 59x compared to a CPU baseline. Our
results indicate that our solver enables faster large-scale optimization on
both desktop and resource-constrained devices.

</details>


### [42] [OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction](https://arxiv.org/abs/2509.26633)
*Lujie Yang,Xiaoyu Huang,Zhen Wu,Angjoo Kanazawa,Pieter Abbeel,Carmelo Sferrazza,C. Karen Liu,Rocky Duan,Guanya Shi*

Main category: cs.RO

TL;DR: OmniRetarget是一个基于交互网格的运动重定向引擎，能够保持人类与机器人之间的空间和接触关系，生成高质量的机器人运动轨迹数据。


<details>
  <summary>Details</summary>
Motivation: 现有的运动重定向方法存在显著的具身差距问题，产生脚滑和穿透等物理上不可行的伪影，且忽视了人类-物体和环境交互对于表达性运动和操作的重要性。

Method: 通过最小化人类和机器人网格之间的拉普拉斯变形同时强制执行运动学约束，OmniRetarget生成运动学可行的轨迹。保持任务相关交互支持从单一演示到不同机器人具身、地形和物体配置的高效数据增强。

Result: 从OMOMO、LAFAN1和内部MoCap数据集重定向运动，生成了超过8小时的轨迹，在运动学约束满足和接触保持方面优于广泛使用的基线方法。

Conclusion: 高质量数据使本体感知强化学习策略能够在Unitree G1人形机器人上成功执行长时程（长达30秒）的跑酷和运动操作技能，仅使用5个奖励项和简单的领域随机化，无需任何学习课程。

Abstract: A dominant paradigm for teaching humanoid robots complex skills is to
retarget human motions as kinematic references to train reinforcement learning
(RL) policies. However, existing retargeting pipelines often struggle with the
significant embodiment gap between humans and robots, producing physically
implausible artifacts like foot-skating and penetration. More importantly,
common retargeting methods neglect the rich human-object and human-environment
interactions essential for expressive locomotion and loco-manipulation. To
address this, we introduce OmniRetarget, an interaction-preserving data
generation engine based on an interaction mesh that explicitly models and
preserves the crucial spatial and contact relationships between an agent, the
terrain, and manipulated objects. By minimizing the Laplacian deformation
between the human and robot meshes while enforcing kinematic constraints,
OmniRetarget generates kinematically feasible trajectories. Moreover,
preserving task-relevant interactions enables efficient data augmentation, from
a single demonstration to different robot embodiments, terrains, and object
configurations. We comprehensively evaluate OmniRetarget by retargeting motions
from OMOMO, LAFAN1, and our in-house MoCap datasets, generating over 8-hour
trajectories that achieve better kinematic constraint satisfaction and contact
preservation than widely used baselines. Such high-quality data enables
proprioceptive RL policies to successfully execute long-horizon (up to 30
seconds) parkour and loco-manipulation skills on a Unitree G1 humanoid, trained
with only 5 reward terms and simple domain randomization shared by all tasks,
without any learning curriculum.

</details>


### [43] [MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation](https://arxiv.org/abs/2509.26642)
*Zhuoyang Liu,Jiaming Liu,Jiadong Xu,Nuowei Han,Chenyang Gu,Hao Chen,Kaichen Zhou,Renrui Zhang,Kai Chin Hsieh,Kun Wu,Zhengping Che,Jian Tang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了多感官语言-动作（MLA）模型，通过协同感知异构感官模态并预测未来多感官目标来增强物理世界建模能力，在复杂接触式任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型主要关注视觉和语言解释来生成动作，但机器人需要在空间物理世界中感知和交互，缺乏对机器人特定多感官信息的全面理解，这对实现复杂接触式控制至关重要。

Method: 1）提出无编码器的多模态对齐方案，将大语言模型重新用作感知模块，通过位置对应直接解释2D图像、3D点云和触觉标记；2）设计未来多感官生成后训练策略，使模型能够推理语义、几何和交互信息。

Result: MLA模型在复杂接触式真实世界任务中分别比最先进的2D和3D VLA方法提高了12%和24%的性能，同时展现出对未见配置的更好泛化能力。

Conclusion: 多感官语言-动作模型通过创新的多模态对齐和未来感官生成策略，显著提升了机器人在物理世界中的感知和交互能力，为复杂接触式控制提供了更鲁棒的条件。

Abstract: Vision-language-action models (VLAs) have shown generalization capabilities
in robotic manipulation tasks by inheriting from vision-language models (VLMs)
and learning action generation. Most VLA models focus on interpreting vision
and language to generate actions, whereas robots must perceive and interact
within the spatial-physical world. This gap highlights the need for a
comprehensive understanding of robotic-specific multisensory information, which
is crucial for achieving complex and contact-rich control. To this end, we
introduce a multisensory language-action (MLA) model that collaboratively
perceives heterogeneous sensory modalities and predicts future multisensory
objectives to facilitate physical world modeling. Specifically, to enhance
perceptual representations, we propose an encoder-free multimodal alignment
scheme that innovatively repurposes the large language model itself as a
perception module, directly interpreting multimodal cues by aligning 2D images,
3D point clouds, and tactile tokens through positional correspondence. To
further enhance MLA's understanding of physical dynamics, we design a future
multisensory generation post-training strategy that enables MLA to reason about
semantic, geometric, and interaction information, providing more robust
conditions for action generation. For evaluation, the MLA model outperforms the
previous state-of-the-art 2D and 3D VLA methods by 12% and 24% in complex,
contact-rich real-world tasks, respectively, while also demonstrating improved
generalization to unseen configurations. Project website:
https://sites.google.com/view/open-mla

</details>
