<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search](https://arxiv.org/abs/2511.19648)
*Manil Shrestha,Edward Kim*

Main category: cs.CL

TL;DR: 提出了两种混合算法解决知识图谱多跳问答的效率与可验证性问题：LLM引导规划使用单次LLM调用预测关系序列，嵌入引导神经搜索完全消除LLM调用，通过轻量级边评分器实现100倍加速。


<details>
  <summary>Details</summary>
Motivation: 解决知识图谱多跳问答中的组合爆炸问题，减少昂贵的LLM推理开销，确保答案在结构化知识中的可验证性。

Method: 1) LLM引导规划：单次LLM调用预测关系序列，通过广度优先搜索执行；2) 嵌入引导神经搜索：融合文本和图嵌入的轻量级边评分器；3) 知识蒸馏：将规划能力压缩到4B参数模型中。

Result: 在MetaQA上评估，LLM引导规划达到接近完美的准确率（micro-F1 > 0.90），嵌入引导神经搜索实现100倍加速且保持竞争力准确率，结构化规划比直接答案生成更具可迁移性。

Conclusion: 可验证的多跳推理不需要在推理时使用大规模模型，而是需要结合符号结构与学习表示的适当架构归纳偏置。

Abstract: Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.

</details>


### [2] [Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian](https://arxiv.org/abs/2511.19719)
*Mobina Mehrazar,Mohammad Amin Yousefi,Parisa Abolfath Beygi,Behnam Bahrak*

Main category: cs.CL

TL;DR: 评估波斯语情感分类中LLM生成解释的忠实性，发现模型解释与人类判断存在分歧，提示策略对忠实性影响有限。


<details>
  <summary>Details</summary>
Motivation: LLM在低资源语言中生成自解释的忠实性令人担忧，需要评估其在波斯语情感分类中的解释可靠性。

Method: 通过比较LLM识别的影响词与人类标注，使用基于词级对数概率的置信度评估忠实性，测试两种提示策略（先预测后解释 vs 先解释后预测）。

Result: LLM分类性能强但生成解释与忠实推理偏离，模型间解释一致性高于与人类判断的一致性。

Conclusion: 当前解释方法和指标存在局限，需要更稳健的方法来确保LLM在多语言和低资源环境中的可靠性。

Abstract: Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.

</details>


### [3] [Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation](https://arxiv.org/abs/2511.19739)
*Richard J. Young,Alice M. Matthews*

Main category: cs.CL

TL;DR: 本研究比较了10种基于transformer的嵌入模型在心脏病学领域的表现，发现编码器架构（特别是BioLinkBERT）在领域特定性能上优于更大的解码器模型，且计算资源需求更少。


<details>
  <summary>Details</summary>
Motivation: 领域特定的文本嵌入对临床自然语言处理至关重要，但不同模型架构之间的系统比较仍然有限。

Method: 使用Low-Rank Adaptation (LoRA)微调方法，在106,535对心脏病学文本对上适配了10种transformer嵌入模型，这些文本对来自权威医学教科书。

Result: 编码器架构（特别是BioLinkBERT）在领域特定性能上表现最佳（分离得分：0.510），优于更大的解码器模型，同时计算资源需求显著减少。

Conclusion: 研究结果挑战了更大语言模型必然产生更好领域特定嵌入的假设，为临床NLP系统开发提供了实用指导，所有模型和资源已公开以支持可重复研究。

Abstract: Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.

</details>


### [4] [What does it mean to understand language?](https://arxiv.org/abs/2511.19757)
*Colton Casto,Anna Ivanova,Evelina Fedorenko,Nancy Kanwisher*

Main category: cs.CL

TL;DR: 该论文提出语言理解需要将信息从核心语言系统导出到其他大脑区域，以构建丰富的心理模型。


<details>
  <summary>Details</summary>
Motivation: 语言理解不仅是提取语言输入的表层意义，还需要构建所描述情境的丰富心理模型。由于大脑核心语言系统的处理能力有限，需要将信息导出到其他脑区。

Method: 回顾现有证据支持这一假设，并利用认知神经科学的最新进展来直接测试该假设。

Result: 论文认为认知神经科学的进展为直接检验这一假设提供了概念基础和方法。

Conclusion: 这一研究策略为揭示语言理解的认知和神经机制开辟了新途径。

Abstract: Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.

</details>


### [5] [Gender Bias in Emotion Recognition by Large Language Models](https://arxiv.org/abs/2511.19785)
*Maureen Herbert,Katie Sun,Angelica Lim,Yasaman Etesam*

Main category: cs.CL

TL;DR: 本文研究大语言模型在情感心智理论中的性别偏见问题，并评估了多种去偏策略，发现基于训练的方法比推理时提示工程更有效。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在日常生活中的广泛应用，评估和确保其公平性变得至关重要。本研究关注情感心智理论领域的性别偏见问题。

Method: 通过描述人物及其环境，询问模型"这个人感觉如何？"来检测性别偏见，并提出了多种去偏策略进行对比评估。

Result: 研究表明，仅依靠推理时的提示工程方法无法有效减少偏见，而基于训练的去偏干预才能实现有意义的偏见减少。

Conclusion: 在大语言模型的公平性研究中，需要采用基于训练的去偏策略，而不能仅仅依赖推理时的提示调整来消除性别偏见。

Abstract: The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, "How does this person feel?". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.

</details>


### [6] [Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions](https://arxiv.org/abs/2511.19816)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 本文提出了NRC VAD Lexicon v2，这是一个包含10,000个英语多词表达及其组成词的效价、唤醒度和支配度人工评分的词典，扩展了2018年发布的v1版本，新增了25,000个单词条目。


<details>
  <summary>Details</summary>
Motivation: 现有词典如2018年发布的NRC VAD Lexicon只包含单词的VAD关联评分，缺乏对多词表达的情感分析支持，且需要更新2018年后更常见的词汇。

Method: 通过人工评分方法收集10,000个多词表达及其组成词的效价、唤醒度和支配度评分，并扩展了25,000个单词的覆盖范围。

Result: 新词典包含10,000个多词表达和25,000个单词条目，评分具有高度可靠性，可用于分析多词表达的情感特征和情感组合性。

Conclusion: NRC VAD Lexicon v2支持NLP、心理学、公共卫生、数字人文和社会科学等多个领域的研究，可通过项目网页免费获取。

Abstract: Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html

</details>


### [7] [Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana](https://arxiv.org/abs/2511.19818)
*Koena Ronny Mabokela,Tim Schlippe,Mpho Raborife,Turgay Celik*

Main category: cs.CL

TL;DR: 提出了一种基于表情符号和情感词汇的自动情感标注方法，用于解决非洲低资源语言的情感分析问题，在英语、Sepedi和Setswana语言上分别达到66%、69%和63%的标注准确率。


<details>
  <summary>Details</summary>
Motivation: 许多非洲语言由于缺乏标注数据而被归类为低资源语言，手动标注文本数据耗时且昂贵，需要自动化的快速标注流程来减少人工工作量。

Method: 利用表情符号和情感词汇信息，开发了一种语言无关的自动情感标注方法，在包含英语、Sepedi和Setswana推文的SAfriSenti多语言情感语料库上进行实验。

Result: 英语推文标注准确率为66%，Sepedi推文为69%，Setswana推文为63%，平均只需修正34%的自动生成标签。

Conclusion: 该方法能够有效减少人工标注工作量，为低资源语言的情感分析提供了实用的自动化解决方案。

Abstract: Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.

</details>


### [8] [Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs](https://arxiv.org/abs/2511.19852)
*Shi-Wei Dai,Yan-Wei Shie,Tsung-Huan Yang,Lun-Wei Ku,Yung-Hui Li*

Main category: cs.CL

TL;DR: 提出PersonaPulse框架，通过动态优化角色扮演提示来增强LLM的个性化表达，利用情境响应基准进行评分指导优化过程


<details>
  <summary>Details</summary>
Motivation: 现有研究使用提示来激发LLM的特定个性特征，但未优化这些提示以最大化个性表达

Method: 利用LLM对个性特征的固有知识迭代增强角色扮演提示，同时整合情境响应基准作为评分工具，确保更真实和情境化的评估来指导优化过程

Result: 定量评估显示PersonaPulse生成的提示优于基于心理学研究设计的先前工作，探索了模型大小与个性建模的关系，发现某些个性特征的激发程度可通过暂停优化过程部分控制

Conclusion: 提示优化在塑造LLM个性表达中具有重要性，为未来自适应AI交互研究提供有价值见解

Abstract: Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.

</details>


### [9] [A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction](https://arxiv.org/abs/2511.19858)
*Farzad Ahmed,Joniel Augustine Jerome,Meliha Yetisgen,Özlem Uzuner*

Main category: cs.CL

TL;DR: 评估了三种提示策略（零样本、静态随机示例、检索增强动态提示）在医疗错误处理任务中的表现，发现检索增强动态提示在减少假阳性、提高召回率和生成更准确修正方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 临床文档中存在可能影响患者安全的事实性、诊断性和管理性错误，大型语言模型可能帮助检测和修正这些错误，但不同提示策略下的行为表现尚不明确。

Method: 使用MEDEC数据集评估9个指令调优的LLM，比较零样本提示、静态随机示例提示和检索增强动态提示在错误标记检测、错误句子检测和错误修正三个子任务中的表现。

Result: 检索增强动态提示在所有9个LLM中表现最佳，将假阳性率降低约15%，在错误句子检测中召回率提高5-10%，并生成更符合上下文的修正。

Conclusion: 检索增强动态提示优于零样本和静态随机示例提示，使用检索示例可提高检测准确性、减少假阳性并增强医疗错误修正的可靠性。

Abstract: Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.
  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.
  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.
  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.

</details>


### [10] [AppSelectBench: Application-Level Tool Selection Benchmark](https://arxiv.org/abs/2511.19957)
*Tianyi Chen,Michael Solodko,Sen Wang,Jongwoo Ko,Junheng Hao,Colby Banbury,Sara Abdali,Saeed Amizadeh,Qing Xiao,Yinheng Li,Tianyu Ding,Kamran Ghasedi Dizaji,Suzhen Zheng,Hao Fan,Justin Wagle,Pashmina Cameron,Kazuhito Koishida*

Main category: cs.CL

TL;DR: 提出了AppSelectBench基准，用于评估计算机使用代理（CUA）的应用选择能力，包含10万个真实多样的用户任务，覆盖100个桌面应用。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估细粒度API选择，缺乏对跨应用推理能力的评估，而应用选择是CUA有效运作的基础能力。

Method: 开发了用户任务生成流水线，创建真实、多样、语义基础的用户意图，并提供统一的评估协议（随机、启发式、零样本、少样本、检索增强）。

Result: 实验显示即使最先进的模型在跨应用推理方面仍存在系统性弱点，难以做出一致的应用选择。

Conclusion: AppSelectBench为研究和推进智能CUA的应用级推理能力奠定了基础，这是一个重要但尚未充分探索的能力。

Abstract: Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.

</details>


### [11] [$\text{R}^2\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers](https://arxiv.org/abs/2511.19987)
*Xinyu Wang,Hanwei Wu,Qingchen Hu,Zhenghan Tai,Jingrui Tian,Lei Ding,Jijun Chi,Hailin He,Tung Sum Thomas Kwok,Yufei Cui,Sicheng Lyu,Muzhi Li,Mingze Li,Xinyue Yu,Ling Zhou,Peng Lu*

Main category: cs.CL

TL;DR: R2R是一个领域感知的检索增强生成框架，通过动态专家路由和两阶段训练策略解决领域专业化问题，避免表面形式过拟合和灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 通用模型在金融、法律等高风险领域缺乏领域特定知识，而简单微调会导致表面形式过拟合和灾难性遗忘。

Method: 结合动态专家路由和两阶段训练策略（EAG），通过掩码最具预测性的表面线索，强制重排序器学习领域不变的相关性模式。使用轻量级潜在语义路由器从冻结的解码器中选择最优LoRA专家。

Result: 在多个领域（法律、医疗、金融）和不同重排序器骨干上的实验表明，R2R始终优于通用模型和单领域微调基线。

Conclusion: R2R是一种模型无关的模块化方法，具有强大的跨领域鲁棒性，能有效实现领域专业化。

Abstract: Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.

</details>


### [12] [Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test](https://arxiv.org/abs/2511.19997)
*Mihir Sahasrabudhe*

Main category: cs.CL

TL;DR: 本文通过合成基准测试发现，即使在没有语言先验的纯合成数据上，因果Transformer模型仍表现出显著的方向性优化差距，表明方向性学习困难是架构本身固有的问题。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型在自然语言处理中观察到的"反转诅咒"问题，澄清这种方向性失败是源于语言统计特性还是架构本身。

Method: 使用具有可调分支因子K的随机字符串映射构建合成基准，创建零条件熵的前向任务和具有分析确定熵下限的逆向任务，在不同模型架构上进行对比实验。

Result: 实验显示从头训练的GPT-2模型存在显著的方向性优化差距（如K=5时1.16 nats），远大于在相同数据上训练的MLP；预训练初始化改变了优化行为但未消除差距；LoRA在高熵逆向映射上遇到容量瓶颈。

Conclusion: 研究分离出了一个与语义无关的最小方向性摩擦特征，表明即使移除语言先验、词频和语料级时间不对称性，因果Transformer训练中固有的方向性偏见仍然存在。

Abstract: Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a "reversal curse," and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.

</details>


### [13] [A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media](https://arxiv.org/abs/2511.20001)
*Edward Ajayi,Martha Kachweka,Mawuli Deku,Emily Aiken*

Main category: cs.CL

TL;DR: 本文提出了一个统一的多类别分类框架，用于从社交媒体数据中检测十种不同的心理健康和网络欺凌类别。通过比较多种模型，发现领域适应的MentalBERT表现最佳，并开发了结合SHAPLLM解释性框架的原型仪表板。


<details>
  <summary>Details</summary>
Motivation: 数字空间中日益严重的心理健康挑战和网络欺凌问题需要可扩展且可解释的检测系统。

Method: 从Twitter和Reddit收集数据，采用"分割后平衡"流程，在平衡数据上训练，在现实不平衡测试集上评估。比较了传统词汇模型、混合方法和多种端到端微调transformer模型。

Result: 端到端微调对性能至关重要，领域适应的MentalBERT成为最佳模型，准确率达到0.92，宏观F1分数为0.76，超越了通用对应模型和零样本LLM基线。

Conclusion: 该系统被定位为人工参与循环的筛查辅助工具而非诊断工具。未来需要在在线安全和计算心理健康的交叉领域开发多标签、临床验证的数据集。

Abstract: Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.

</details>


### [14] [Online-PVLM: Advancing Personalized VLMs with Online Concept Learning](https://arxiv.org/abs/2511.20056)
*Huiyu Bai,Runze Wang,Zhuoyun Du,Yiyang Zhao,Fengji Zhang,Haoyu Chen,Xiaoyong Zhu,Bo Zheng,Xuejiao Zhao*

Main category: cs.CL

TL;DR: 提出了Online-PVLM框架，通过双曲表示实现个性化视觉语言模型的在线概念学习，无需训练即可在测试时生成概念嵌入，解决了现有方法无法支持实时适应和大规模场景的问题。


<details>
  <summary>Details</summary>
Motivation: 现有个性化视觉语言模型方法需要为每个新概念学习单独的嵌入，无法支持测试时的实时适应，在大规模场景下无法高效检索概念嵌入。

Method: 利用双曲表示开发了Online-PVLM框架，采用免训练的概念嵌入生成范式，在测试时进行在线概念学习。

Result: 在包含1,292个概念和超过30K高质量实例的OP-Eval基准测试中表现出最先进的性能。

Conclusion: 提出的框架使个性化视觉语言模型的使用既具有可扩展性又高效，解决了实时适应和大规模场景下的挑战。

Abstract: Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.

</details>


### [15] [MTA: A Merge-then-Adapt Framework for Personalized Large Language Model](https://arxiv.org/abs/2511.20072)
*Xiaopeng Li,Yuanjin Zheng,Wanyu Wang,wenlin zhang,Pengyue Jia,Yiqi Wang,Maolin Wang,Xuetao Wei,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 提出了MTA框架解决个性化大语言模型存储成本高和稀疏数据性能差的问题，通过元LoRA银行、自适应LoRA融合和LoRA堆叠实现可扩展的个性化。


<details>
  <summary>Details</summary>
Motivation: 现有方法为每个用户微调单独模块导致存储成本线性增长且对稀疏数据用户效果不佳，需要更高效可扩展的个性化方案。

Method: 三阶段框架：1)构建共享元LoRA银行预训练元个性化特征；2)自适应LoRA融合动态合并相关锚点元LoRA；3)LoRA堆叠在合并LoRA上添加超低秩模块进行少样本微调。

Result: 在LaMP基准测试中超越现有SOTA方法，在多个任务上表现优异。

Conclusion: MTA框架有效解决了PLLMs的存储扩展性和稀疏数据性能问题，实现了高效可扩展的个性化。

Abstract: Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.

</details>


### [16] [More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering](https://arxiv.org/abs/2511.20086)
*Duc Anh Vu,Thong Nguyen,Cong-Duy Nguyen,Viet Anh Nguyen,Anh Tuan Luu*

Main category: cs.CL

TL;DR: BiasPrompting是一个新颖的推理框架，通过引导LLMs生成并批判性评估所有可能答案选项的推理，来提升多项选择题任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多项选择题任务中存在关键限制：答案选项通常没有上下文基础或解释，导致无法完整探索所有可能答案，从而降低模型的推理能力。

Method: BiasPrompting包含两个组件：1) 推理生成阶段，模型为每个答案选项生成支持性推理；2) 推理引导一致性阶段，综合生成的推理来选择最合理的答案。

Result: 在五个广泛使用的多项选择题基准测试中，BiasPrompting显示出显著改进，特别是在现有方法表现不佳的复杂和具有挑战性的问题设置中。

Conclusion: BiasPrompting增强了LLMs的推理能力，并为处理复杂挑战性问题提供了坚实基础。

Abstract: With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.

</details>


### [17] [SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space](https://arxiv.org/abs/2511.20102)
*Zhenyi Shen,Junru Lu,Lin Gui,Jiazheng Li,Yulan He,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: SSA是一个统一的稀疏注意力训练框架，通过双向对齐稀疏和全注意力，在保持梯度流动的同时促进更强的稀疏性，在稀疏和全注意力推理下都达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法存在梯度更新缺陷：被排除的低秩键值对无法获得梯度更新，导致无法学习适当的抑制，产生稀疏性低于全注意力的悖论。

Method: 提出SSA框架，同时考虑稀疏和全注意力，在每一层强制执行双向对齐，保持所有token的梯度流动，并显式鼓励稀疏注意力输出与其全注意力对应物对齐。

Result: SSA在多个常识基准测试中，在稀疏和全注意力推理下都达到最先进性能；能够平滑适应不同的稀疏预算；性能随着可关注token数量增加而持续提升；展现出最强的长上下文外推能力。

Conclusion: SSA通过解决梯度更新缺陷，实现了高效的稀疏注意力训练，支持灵活的计算-性能权衡，并改善了长上下文外推能力。

Abstract: The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.

</details>


### [18] [EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning](https://arxiv.org/abs/2511.20106)
*Xingfeng Li,Xiaohan Shi,Junjie Li,Yongwei Li,Masashi Unoki,Tomoki Toda,Masato Akagi*

Main category: cs.CL

TL;DR: EM2LDL是一个新颖的多语言语音语料库，采用标签分布学习方法推进混合情感识别，包含英语、普通话和粤语的情感表达，支持32个情感类别的细粒度标注。


<details>
  <summary>Details</summary>
Motivation: 解决现有语料库主要限于单语言和单标签情感识别的问题，这些语料库限制了语言多样性、无法建模混合情感且缺乏生态效度。

Method: 构建包含英语、普通话和粤语表达性话语的多语言语料库，捕捉语内语码转换现象，整合来自在线平台的自发情感表达，并使用自监督学习模型进行实验基线评估。

Result: 实验基线显示，在说话者独立、性别、年龄和人格评估中表现出稳健性能，HuBERT-large-EN模型取得最优结果。

Conclusion: EM2LDL通过整合语言多样性和生态效度，为多语言环境中复杂情感动态的探索提供了平台，为开发适应性强的共情系统提供了多功能测试平台。

Abstract: This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.

</details>


### [19] [Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach](https://arxiv.org/abs/2511.20107)
*Huu Tuong Tu,Ha Viet Khanh,Tran Tien Dat,Vu Huan,Thien Van Luong,Nguyen Tien Cuong,Nguyen Thi Thu Trang*

Main category: cs.CL

TL;DR: 提出了一种无需训练的发音错误检测与诊断框架，利用预训练ASR模型和检索技术，避免了传统方法需要训练音素级模型或评分模型的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统发音错误检测方法需要训练音素级模型或评分模型，过程复杂且需要大量标注数据，希望开发一种无需额外训练的更简单有效的方法。

Method: 基于预训练自动语音识别模型，结合检索技术构建训练免费框架，无需音素特定建模或任务特定训练。

Result: 在L2-ARCTIC数据集上实验显示，该方法达到69.60%的F1分数，优于传统方法且避免了模型训练的复杂性。

Conclusion: 该方法证明了利用预训练ASR模型和检索技术可以实现高效的发音错误检测与诊断，无需复杂训练过程。

Abstract: Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.

</details>


### [20] ["When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings](https://arxiv.org/abs/2511.20120)
*Somsubhra De,Harsh Kumar,Arun Prakash A*

Main category: cs.CL

TL;DR: 使用大型语言模型（GPT-4.1、Gemini-2.5、LLaMA-4）通过提示工程方法解决印度语言语法错误校正问题，在低资源环境下取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 印度语言的语法错误校正面临资源有限、语言多样性和复杂形态学等挑战，传统方法难以有效处理。

Method: 采用基于提示的方法，包括零样本和少样本策略，结合精心设计的提示和轻量级适配来优化大型语言模型。

Result: 在共享任务中取得领先成绩：泰米尔语第1名（GLEU: 91.57）、印地语第1名（GLEU: 85.69）、泰卢固语第2名（GLEU: 85.22）、孟加拉语第4名（GLEU: 92.86）、马拉雅拉姆语第5名（GLEU: 92.97）。

Conclusion: 提示驱动的NLP技术非常有效，大型语言模型具有卓越的多语言泛化能力，能够弥合多语言语法错误校正中的资源差距。

Abstract: Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.

</details>


### [21] [SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models](https://arxiv.org/abs/2511.20143)
*Wen-Fang Su,Hsiao-Wei Chou,Wen-Yang Lin*

Main category: cs.CL

TL;DR: 提出了一种结合图像数据增强技术的网格标注方法，用于改进不连续命名实体识别，解决了传统方法在跨句子不连续实体上的分割和遗漏问题。


<details>
  <summary>Details</summary>
Motivation: 命名实体识别中不连续实体识别具有挑战性，传统方法在文本分割时容易错误分割或完全遗漏跨句子的不连续实体，严重影响识别准确性。

Method: 基于网格标注方法，整合图像数据增强技术（如裁剪、缩放和填充）到网格模型中，增强对不连续实体的识别能力和处理分割挑战的能力。

Result: 在CADEC、ShARe13和ShARe14数据集上的实验显示，传统分割方法无法有效捕捉跨句子不连续实体，而增强网格模型整体F1分数提升1-2.5%，不连续实体识别提升3.7-8.4%。

Conclusion: 该方法有效解决了不连续实体识别中的分割和遗漏问题，验证了图像数据增强技术在网格模型中的有效性。

Abstract: Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.

</details>


### [22] [KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP](https://arxiv.org/abs/2511.20182)
*Adilet Metinov,Gulida M. Kudakeeva,Gulnara D. Kabaeva*

Main category: cs.CL

TL;DR: 本文介绍了KyrgyzBERT，这是首个公开可用的吉尔吉斯语单语BERT语言模型，包含3590万参数和定制分词器，在情感分析任务上表现与5倍大的mBERT模型相当。


<details>
  <summary>Details</summary>
Motivation: 吉尔吉斯语作为低资源语言，缺乏基础NLP工具，需要开发专门的预训练语言模型来支持该语言的NLP研究。

Method: 构建了KyrgyzBERT模型，使用定制分词器适应语言形态结构，并通过翻译和人工标注创建了kyrgyz-sst2情感分析基准数据集。

Result: KyrgyzBERT在情感分析任务上达到F1分数0.8280，与规模大5倍的mBERT模型性能相当。

Conclusion: KyrgyzBERT为吉尔吉斯语NLP研究提供了重要基础，所有模型、数据和代码均已公开发布以支持后续研究。

Abstract: Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.

</details>


### [23] [REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance](https://arxiv.org/abs/2511.20233)
*Chuyi Kong,Gao Wei,Jing Ma,Hongzhan Lin,Zhiyuan Fan*

Main category: cs.CL

TL;DR: REFLEX是一个用于自动事实核查的即插即用范式，通过角色扮演对话和对比激活对来提升判决准确性和解释质量，仅需465个训练样本就能达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的事实核查方法过度依赖外部知识源，导致延迟和幻觉问题，影响可靠性、可解释性和实时性。

Method: 将事实核查重构为角色扮演对话，联合训练判决预测和解释生成，通过对比激活对构建引导向量来分离真相的风格和实质。

Result: 在真实数据集上的实验显示，REFLEX优于先前方法，仅用465个自精炼训练样本就达到最先进性能，解释信号能提升事实推理能力达7.57%。

Conclusion: 内部解释信号在事实核查中具有双重作用：既能解释又能增强事实推理，REFLEX范式能有效处理人类未知的微妙真相。

Abstract: The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.

</details>


### [24] [Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios](https://arxiv.org/abs/2511.20340)
*Luohe Shi,Zuchao Li,Lefei Zhang,Baoyuan Qi,Guoming Liu,Hai Zhao*

Main category: cs.CL

TL;DR: SpecFormer是一种新的架构，结合单向和双向注意力机制，在低验证资源和调度成本下实现LLM推理加速，无需依赖大型前缀树。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法假设有大量可用计算资源，但在批处理等主流推理系统中，可用空闲计算能力被压缩，因此需要低资源、低成本的推测解码方案。

Method: 提出SpecFormer架构，集成单向和双向注意力机制，结合自回归模型从完整输入序列提取信息的能力和非自回归模型的并行生成优势。

Result: 在各种规模模型的实验中，SpecFormer为LLM推理扩展设定了新标准，训练需求更低，计算成本更少。

Conclusion: SpecFormer通过新颖的架构设计，在低资源环境下实现一致的加速效果，为大规模LLM推理提供了更高效的解决方案。

Abstract: Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.

</details>


### [25] [The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2511.20344)
*Taewhoo Lee,Minju Song,Chanwoong Yoon,Jungwoo Park,Jaewoo Kang*

Main category: cs.CL

TL;DR: LLMs能够编码类比实体间的关系，但在将关系信息应用于新实体时存在困难。通过策略性地修补隐藏表示可以在一定程度上改善信息传递。成功的类比推理需要强结构对齐，失败则通常源于对齐退化或错位。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否能够编码高层次关系概念并通过结构化比较将其应用于新情境，这是人类认知的核心能力。

Method: 使用比例类比和故事类比任务，分析LLMs在不同层级的隐藏表示，并通过策略性修补隐藏表示来研究信息传递。

Result: LLMs能够有效编码类比实体间的关系，关系信息在中上层传播；但在应用关系信息到新实体时存在困难；策略性修补隐藏表示可改善信息传递；成功的类比推理需要强结构对齐。

Conclusion: LLMs在编码和应用高层次关系概念方面展现出初步但有限的能力，与人类认知存在相似性和差距。

Abstract: Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.

</details>


### [26] [BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali](https://arxiv.org/abs/2511.20399)
*Abdullah Al Sefat*

Main category: cs.CL

TL;DR: BengaliFig是一个针对孟加拉语的挑战数据集，包含435个来自孟加拉口头和文学传统的谜语，用于评估LLM在低资源文化背景下的比喻和文化推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言基准测试中表现出色，但在比喻和文化推理方面，尤其是在低资源语境下的评估仍然不足。

Method: 构建包含435个独特谜语的孟加拉语数据集，每个项目沿五个正交维度进行注释，并通过约束感知的AI辅助管道自动转换为多项选择格式。

Result: 评估八个前沿LLM在零样本和少样本思维链提示下的表现，揭示了在隐喻和文化特定推理方面的一致弱点。

Conclusion: BengaliFig为评估LLM在低资源文化背景下的鲁棒性提供了诊断工具，并朝着包容性和传承意识的NLP评估迈出了一步。

Abstract: Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.

</details>


### [27] [A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines](https://arxiv.org/abs/2511.20409)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 提出了一种新颖的面向任务的词干提取方法评估框架，包含SES、MPD和ANLD三个指标，用于区分词干提取的效率增益和语义保持能力。


<details>
  <summary>Details</summary>
Motivation: 当前词干提取方法的评估方法有限，无法捕捉过度词干提取可能造成的危害，需要开发新的评估方法。

Method: 提出了包含三个方面的综合评估框架：(1)词干提取效用(SES)、(2)对下游任务的影响(MPD)、(3)词干化前后词语的语义相似度(ANLD)。

Result: 应用该框架比较孟加拉语和英语词干提取器，发现孟加拉语词干提取器虽然SES高(1.67)，但ANLD显示存在有害的过度词干提取(0.26)，导致下游性能下降；英语词干提取器SES适中(1.31)但语义距离安全(ANLD=0.14)，对下游性能有积极贡献。

Conclusion: 该研究提供了区分词干提取效率增益和语义保持能力的有价值工具，表明高SES并不总是有益的，需要结合ANLD来评估词干提取器的可靠性。

Abstract: Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).

</details>


### [28] [Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts](https://arxiv.org/abs/2511.20459)
*Mosab Rezaei,Mina Rajaei Moghadam,Abdul Rahman Shaikh,Hamed Alhoori,Reva Freedman*

Main category: cs.CL

TL;DR: 提出了一个使用大语言模型生成和评估19世纪小说家风格文本的框架，通过微调模型和基于transformer的检测器来分析写作风格。


<details>
  <summary>Details</summary>
Motivation: 解决在没有配对数据时训练生成模型以及不依赖人类判断评估风格文本的挑战。

Method: 使用最小化单token提示微调大语言模型生成特定作者风格的文本，并训练基于transformer的检测器进行分类和风格解释。

Result: 生成的文本反映了作者的独特模式，AI评估为人类评估提供了可靠替代方案。

Conclusion: 该框架成功实现了风格文本的生成和评估，所有工作成果已在线发布。

Abstract: Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.

</details>


### [29] [Adversarial Confusion Attack: Disrupting Multimodal Large Language Models](https://arxiv.org/abs/2511.20494)
*Jakub Hoscilowicz,Artur Janicki*

Main category: cs.CL

TL;DR: 提出了一种针对多模态大语言模型的新型对抗攻击——对抗性混淆攻击，旨在系统性地破坏模型使其生成不连贯或自信的错误输出，可用于阻止MLLM代理的可靠运行。


<details>
  <summary>Details</summary>
Motivation: 现有攻击主要关注越狱或定向错误分类，而本文旨在开发能系统破坏MLLM可靠性的新型威胁，通过在网站中嵌入对抗图像来阻止MLLM代理的正常运行。

Method: 使用开源MLLM小集合，通过最大化下一令牌熵的基本对抗技术（PGD）生成对抗图像，在完整图像和对抗CAPTCHA两种设置下进行攻击。

Result: 在自盒设置下，单个对抗图像能破坏集合中所有模型，生成的扰动能迁移到未见过的开源模型（如Qwen3-VL）和专有模型（如GPT-5.1）。

Conclusion: 对抗性混淆攻击是一种有效的新型威胁，即使使用基本对抗技术也能产生可迁移的扰动，严重威胁MLLM系统的可靠性。

Abstract: We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Applications include embedding adversarial images into websites to prevent MLLM-powered agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.

</details>


### [30] [The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models](https://arxiv.org/abs/2511.20507)
*Nathan Roll,Jill Kries,Flora Jin,Catherine Wang,Ann Marie Finley,Meghan Sumner,Cory Shain,Laura Gwilliams*

Main category: cs.CL

TL;DR: 本文提出了文本失语症评估量表(TAB)，这是一个基于临床失语症评估改编的文本基准，用于评估大语言模型中的失语症样缺陷。


<details>
  <summary>Details</summary>
Motivation: 大语言模型为研究语言障碍提供了新机会，但传统临床评估方法不适合评估LLMs，因为它们预设了人类语用压力并探测人工架构中不存在的认知过程。

Method: 从快速失语症评估量表(QAB)改编开发了TAB，包含四个子测试：连贯文本、单词理解、句子理解和重复。验证了使用Gemini 2.5 Flash的自动评估协议。

Result: 自动评估协议达到了与专家人类评分者相当的可靠性（模型-共识一致性Cohen's kappa = 0.255 vs 人-人一致性0.286）。

Conclusion: TAB作为一个基于临床的、可扩展的框架发布，用于分析人工系统中的语言缺陷。

Abstract: Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.

</details>


### [31] [Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup for Equitable Speech Recognition](https://arxiv.org/abs/2511.20534)
*Wesley Bian,Xiaofeng Lin,Guang Cheng*

Main category: cs.CL

TL;DR: 提出了一种新的语音数据增强技术，旨在改善低资源语言的语音识别性能差距


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型在英语等资源丰富语言上表现优越，但在低资源语言上由于数据收集困难且成本高昂，存在不公平的性能差距

Method: 引入了一种新颖的语音语料库数据增强技术

Result: 该方法显著提高了自动语音识别系统在低资源语言上的性能，并且优于现有的增强策略

Conclusion: 该技术为增强代表性不足语言社区的语音技术提供了实用解决方案

Abstract: Modern machine learning models for audio tasks often exhibit superior performance on English and other well-resourced languages, primarily due to the abundance of available training data. This disparity leads to an unfair performance gap for low-resource languages, where data collection is both challenging and costly. In this work, we introduce a novel data augmentation technique for speech corpora designed to mitigate this gap. Through comprehensive experiments, we demonstrate that our method significantly improves the performance of automatic speech recognition systems on low-resource languages. Furthermore, we show that our approach outperforms existing augmentation strategies, offering a practical solution for enhancing speech technology in underrepresented linguistic communities.

</details>


### [32] [From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding](https://arxiv.org/abs/2511.20547)
*Farjana Sultana Mim,Shuchin Aeron,Eric Miller,Kristen Wendell*

Main category: cs.CL

TL;DR: 本文介绍了教育对话数据集和基线模型，用于自动检测学生对话中的知识建构和任务产出话语特征，但现有大语言模型在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 手动分析学生对话中的话语特征耗时费力，限制了研究规模。利用NLP技术可以自动检测这些特征，为教育研究提供可扩展的数据驱动洞察。

Method: 创建了标注的教育对话数据集，包含知识建构和任务产出话语特征，并使用GPT-3.5和Llama-3.1等预训练大语言模型建立基线预测模型。

Result: 实验结果表明，这些最先进的模型在此任务上表现不佳，表明未来研究有改进空间。

Conclusion: 虽然自动检测教育对话中的话语特征具有潜力，但现有大语言模型在此任务上仍需改进，为未来研究指明了方向。

Abstract: Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.

</details>


### [33] [On Evaluating LLM Alignment by Evaluating LLMs as Judges](https://arxiv.org/abs/2511.20604)
*Yixin Liu,Pengfei Liu,Arman Cohan*

Main category: cs.CL

TL;DR: 本文研究了LLMs的生成能力与评估能力在人类偏好对齐方面的一致性，提出了AlignEval基准，通过评估LLMs作为评判者的能力来间接衡量其对齐性能，无需直接评估生成输出。


<details>
  <summary>Details</summary>
Motivation: 传统评估LLMs对齐需要直接评估其开放生成结果，需要人工标注或强LLM评判者。本文探索LLMs生成与评估能力之间的关系，寻找更高效的评估方法。

Method: 首先分析各种LLMs的生成-评估一致性，发现两者存在强相关性。基于此提出AlignEval基准，通过评估LLMs作为评判者的能力来间接衡量其对齐性能。

Result: AlignEval基准在捕捉人类偏好排名LLMs方面，匹配或超越了AlpacaEval和Arena-Hard等广泛使用的自动评估基准。

Conclusion: 研究揭示了LLMs生成与评估能力之间的联系，并提出了无需直接评估模型输出的对齐评估基准，为LLM评估提供了新视角。

Abstract: Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.

</details>


### [34] [Latent Collaboration in Multi-Agent Systems](https://arxiv.org/abs/2511.20639)
*Jiaru Zou,Xiyuan Yang,Ruizhong Qiu,Gaotang Li,Katherine Tieu,Pan Lu,Ke Shen,Hanghang Tong,Yejin Choi,Jingrui He,James Zou,Mengdi Wang,Ling Yang*

Main category: cs.CL

TL;DR: LatentMAS是一个无需训练的端到端框架，通过在连续潜在空间中直接协作，实现LLM智能体之间的纯潜在协作，相比基于文本的多智能体系统具有更高表达能力和无损信息交换。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体依赖基于文本的中介进行推理和通信，作者希望让模型在连续潜在空间中直接协作，提升系统级智能。

Method: 每个智能体通过最后一层隐藏嵌入进行自回归潜在思维生成，共享潜在工作内存保存和传输内部表示，确保无损信息交换。

Result: 在9个基准测试中，LatentMAS比单模型和基于文本的MAS基线准确率提高14.6%，输出token减少70.8%-83.7%，端到端推理速度提升4-4.3倍。

Conclusion: 潜在协作框架在无需额外训练的情况下，显著提升系统级推理质量并带来效率增益。

Abstract: Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [35] [Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories](https://arxiv.org/abs/2511.19528)
*Rushuai Yang,Zhiyuan Feng,Tianxiang Zhang,Kaixin Wang,Chuheng Zhang,Li Zhao,Xiu Su,Yi Chen,Jiang Bian*

Main category: cs.RO

TL;DR: 提出DLR框架，通过信息论模式发现生成多样化、高成功率的机器人行为轨迹，用于视觉语言动作模型预训练，相比标准强化学习方法能产生更丰富的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言动作模型预训练需要大量多样化、高质量的操作轨迹数据，但人工遥操作成本高且难以扩展。强化学习虽然能通过自主探索学习技能，但标准RL训练会收敛到单一执行模式，限制了其在大规模预训练中的效用。

Method: 提出Discover, Learn and Reinforce (DLR)框架，这是一个基于信息论的模式发现方法，能够生成多个不同但高成功率的行为模式用于VLA预训练。

Result: 在LIBERO基准测试中，DLR生成了明显更多样化的轨迹语料库，为同一任务学习多种不同且高成功率的策略，覆盖了更广泛的状态-动作空间。在下游任务中，使用DLR数据预训练的VLA模型表现优于使用等量标准RL数据训练的模型。

Conclusion: 多模式强化学习可作为实用的、可扩展的具身基础模型数据引擎，DLR展现出正的数据缩放特性，而单模式RL缺乏这种特性。

Abstract: Scaling vision-language-action (VLA) model pre-training requires large volumes of diverse, high-quality manipulation trajectories. Most current data is obtained via human teleoperation, which is expensive and difficult to scale. Reinforcement learning (RL) methods learn useful skills through autonomous exploration, making them a viable approach for generating data. However, standard RL training collapses to a narrow execution pattern, limiting its utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce (DLR), an information-theoretic pattern discovery framework that generates multiple distinct, high-success behavioral patterns for VLA pretraining. Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO. Specifically, it learns multiple distinct, high-success strategies for the same task where standard RL discovers only one, and hence it covers substantially broader regions of the state-action space. When adapted to unseen downstream task suites, VLA models pretrained on our diverse RL data surpass counterparts trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive data-scaling behavior that single-pattern RL lacks. These results position multi-pattern RL as a practical, scalable data engine for embodied foundation models.

</details>


### [36] [A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers](https://arxiv.org/abs/2511.19543)
*Omar Faris,Sławomir Tadeja,Fulvio Forni*

Main category: cs.RO

TL;DR: 提出了一种基于虚拟模型控制和增强现实的人机物体交接方法，能够适应交接过程中的动态变化和不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决人机物体交接过程中物体姿态复杂变化带来的挑战，确保机器人动作的适应性和鲁棒性。

Method: 使用虚拟模型控制创建交互层来控制机器人并适应交接过程的动态变化，同时利用增强现实促进人机双向通信。

Result: 控制器在各种不确定性条件下表现出良好的鲁棒性，用户研究显示参与者普遍偏好所提出的方法。

Conclusion: 该方法为人机物体交接提供了有效的解决方案，研究结果可为未来人机交互适应性发展提供指导。

Abstract: Object handover is a common form of interaction that is widely present in collaborative tasks. However, achieving it efficiently remains a challenge. We address the problem of ensuring resilient robotic actions that can adapt to complex changes in object pose during human-to-robot object handovers. We propose the use of Virtual Model Control to create an interaction layer that controls the robot and adapts to the dynamic changes in the handover process. Additionally, we propose the use of augmented reality to facilitate bidirectional communication between humans and robots during handovers. We assess the performance of our controller in a set of experiments that demonstrate its resilience to various sources of uncertainties, including complex changes to the object's pose during the handover. Finally, we performed a user study with 16 participants to understand human preferences for different robot control profiles and augmented reality visuals in object handovers. Our results showed a general preference for the proposed approach and revealed insights that can guide further development in adapting the interaction with the user.

</details>


### [37] [Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation](https://arxiv.org/abs/2511.19647)
*Jennifer Grannen,Michelle Pan,Kenneth Llontop,Cherie Ho,Mark Zolotas,Jeannette Bohg,Dorsa Sadigh*

Main category: cs.RO

TL;DR: 提出了机器人驱动的数据飞轮框架，将机器人从基础模型消费者转变为数据生成器，通过在真实环境中部署机器人收集数据来改进基础模型的领域适应和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基础模型依赖互联网预训练数据，在非结构化真实世界环境中表现脆弱。机器人作为具身智能体，能够收集大规模真实世界数据来弥补这一差距。

Method: 开发了Scanford移动机械臂，在图书馆部署2周自主扫描书架，使用视觉语言模型识别书籍，并利用图书馆目录自动标注图像。

Result: 从2103个书架收集数据，将书籍识别准确率从32.0%提升至71.8%，多语言OCR准确率从24.8%提升至46.6%（英文）和30.8%提升至38.0%（中文），节省约18.7小时人工时间。

Conclusion: 机器人驱动的数据飞轮既能减少实际部署中的人工努力，又能为基础模型持续适应现实复杂性开辟新途径。

Abstract: Foundation models (FM) have unlocked powerful zero-shot capabilities in vision and language, yet their reliance on internet pretraining data leaves them brittle in unstructured, real-world settings. The messy, real-world data encountered during deployment (e.g. occluded or multilingual text) remains massively underrepresented in existing corpora. Robots, as embodied agents, are uniquely positioned to close this gap: they can act in physical environments to collect large-scale, real-world data that enriches FM training with precisely the examples current models lack. We introduce the Robot-Powered Data Flywheel, a framework that transforms robots from FM consumers into data generators. By deploying robots equipped with FMs in the wild, we enable a virtuous cycle: robots perform useful tasks while collecting real-world data that improves both domain-specific adaptation and domain-adjacent generalization. We instantiate this framework with Scanford, a mobile manipulator deployed in the East Asia Library for 2 weeks. Scanford autonomously scans shelves, identifies books using a vision-language model (VLM), and leverages the library catalog to label images without human annotation. This deployment both aids librarians and produces a dataset to finetune the underlying VLM, improving performance on the domain-specific in-the-wild library setting and on domain-adjacent multilingual OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM performance on book identification from 32.0% to 71.8% and boosts domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to 38.0% (Chinese), while saving an ~18.7 hrs of human time. These results highlight how robot-powered data flywheels can both reduce human effort in real deployments and unlock new pathways for continually adapting FMs to the messiness of reality. More details are at: https://scanford-robot.github.io

</details>


### [38] [Online Learning-Enhanced High Order Adaptive Safety Control](https://arxiv.org/abs/2511.19651)
*Lishuo Pan,Mattia Catellani,Thales C. Silva,Lorenzo Sabattini,Nora Ayanian*

Main category: cs.RO

TL;DR: 提出了一种基于神经ODE的在线学习增强高阶自适应控制屏障函数方法，能够在复杂时变模型扰动下实时提高CBF认证系统的安全性，并在38g纳米四旋翼上成功验证，在18km/h风速下保持与障碍物的安全距离。


<details>
  <summary>Details</summary>
Motivation: 控制屏障函数(CBFs)是保证系统安全性的有效工具，但其安全保证的成功转移到现实系统严重依赖于模型精度。有效载荷或风扰动等复杂时变扰动会显著影响飞行器动力学并使安全保证失效。

Method: 提出了一种高效的在线学习增强高阶自适应控制屏障函数方法，使用神经ODE来适应复杂时变模型扰动，实现混合自适应CBF控制器。

Result: 在38g纳米四旋翼上成功部署该混合自适应CBF控制器，在18km/h风速下能够保持与障碍物的安全距离。

Conclusion: 该方法能够在线学习增强CBF的安全性，有效应对复杂时变模型扰动，为现实世界系统的安全控制提供了可行方案。

Abstract: Control barrier functions (CBFs) are an effective model-based tool to formally certify the safety of a system. With the growing complexity of modern control problems, CBFs have received increasing attention in both optimization-based and learning-based control communities as a safety filter, owing to their provable guarantees. However, success in transferring these guarantees to real-world systems is critically tied to model accuracy. For example, payloads or wind disturbances can significantly influence the dynamics of an aerial vehicle and invalidate the safety guarantee. In this work, we propose an efficient yet flexible online learning-enhanced high-order adaptive control barrier function using Neural ODEs. Our approach improves the safety of a CBF-certified system on the fly, even under complex time-varying model perturbations. In particular, we deploy our hybrid adaptive CBF controller on a 38g nano quadrotor, keeping a safe distance from the obstacle, against 18km/h wind.

</details>


### [39] [Flow-Based Path Planning for Multiple Homogenous UAVs for Outdoor Formation-Flying](https://arxiv.org/abs/2511.19653)
*Mahmud Suhaimi Ibrahim,Shantanu Rahman,Muhammad Samin Hasan,Minhaj Uddin Ahmad,Abdullah Abrar*

Main category: cs.RO

TL;DR: 使用流网络方法为多无人机编队飞行规划无碰撞路径，包括构建流网络图、寻找最小成本路径和实现最大流路径分配。


<details>
  <summary>Details</summary>
Motivation: 多无人机编队飞行中，无碰撞路径规划是最关键的组成部分，需要解决无人机间的碰撞问题。

Method: 1) 从物理GPS坐标构建流网络图；2) 使用图路径算法寻找最小成本路径；3) 应用Ford-Fulkerson方法寻找最大流路径（无碰撞）。

Result: 对最多64架无人机进行了各种编队模拟，并用3架四旋翼无人机进行了实际实验，验证了方法的可行性和物理合理性。

Conclusion: 该方法能够有效生成安全的无碰撞路径，证明了其在多无人机编队飞行中的实用性。

Abstract: Collision-free path planning is the most crucial component in multi-UAV formation-flying (MFF). We use unlabeled homogenous quadcopters (UAVs) to demonstrate the use of a flow network to create complete (inter-UAV) collision-free paths. This procedure has three main parts: 1) Creating a flow network graph from physical GPS coordinates, 2) Finding a path of minimum cost (least distance) using any graph-based path-finding algorithm, and 3) Implementing the Ford-Fulkerson Method to find the paths with the maximum flow (no collision). Simulations of up to 64 UAVs were conducted for various formations, followed by a practical experiment with 3 quadcopters for testing physical plausibility and feasibility. The results of these tests show the efficacy of this method's ability to produce safe, collision-free paths.

</details>


### [40] [Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection](https://arxiv.org/abs/2511.19655)
*Shantanu Rahman,Nayeb Hasin,Mainul Islam*

Main category: cs.RO

TL;DR: 提出了一种结合车道识别与模型预测控制(MPC)的方法，用于提高自动驾驶车辆轨迹跟踪的精度和稳定性，在仿真中使轨迹跟踪误差降低了27.65%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在道路导航中需要高精度的轨迹跟踪控制，现有的Ackermann转向机制车辆需要更稳定和精确的低级控制器。

Method: 使用边缘识别、滑动窗口直线识别进行车道线提取，结合动态感兴趣区域(ROI)提取，然后基于自行车车辆动力学模型构建MPC控制器来跟踪识别出的车道线。

Result: 在ROS Gazebo仿真环境中测试，最优跟踪轨迹与目标轨迹之间的均方根误差降低了27.65%，控制器表现出高鲁棒性和灵活性。

Conclusion: 所提出的车道识别与MPC结合的方法能有效提高自动驾驶车辆的轨迹跟踪精度和稳定性，在仿真环境中验证了其性能优势。

Abstract: Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.

</details>


### [41] [Multi-Agent gatekeeper: Safe Flight Planning and Formation Control for Urban Air Mobility](https://arxiv.org/abs/2511.19691)
*Thomas Marshall Vielmetti,Devansh R Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出Multi-Agent gatekeeper框架，为3D复杂环境中的领导者-跟随者编队控制提供可证明的安全保证，通过领导者预计算安全轨迹作为共享备份，确保跟随者始终有安全避障策略。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临权衡：在线规划器和控制器缺乏形式化安全保证，而离线规划器无法适应代理数量或期望编队的变化。需要一种既能保证安全又具备适应性的解决方案。

Method: 采用混合架构：单个领导者跟踪预计算的安全轨迹作为共享轨迹备份集，跟随者执行名义编队跟踪控制器，始终拥有沿领导者路径的已知安全备份机动策略。

Result: 在模拟3D城市环境中，100次随机试验中实现了100%的避碰成功率，显著优于基线CBF和NMPC方法，并在四旋翼无人机团队上验证了轨迹的物理可行性。

Conclusion: 该框架成功将单智能体gatekeeper扩展到多智能体系统，为领导者-跟随者编队控制提供了可证明的安全协调机制，是gatekeeper框架在3D环境中的首次应用。

Abstract: We present Multi-Agent gatekeeper, a framework that provides provable safety guarantees for leader-follower formation control in cluttered 3D environments. Existing methods face a trad-off: online planners and controllers lack formal safety guarantees, while offline planners lack adaptability to changes in the number of agents or desired formation. To address this gap, we propose a hybrid architecture where a single leader tracks a pre-computed, safe trajectory, which serves as a shared trajectory backup set for all follower agents. Followers execute a nominal formation-keeping tracking controller, and are guaranteed to remain safe by always possessing a known-safe backup maneuver along the leader's path. We formally prove this method ensures collision avoidance with both static obstacles and other agents. The primary contributions are: (1) the multi-agent gatekeeper algorithm, which extends our single-agent gatekeeper framework to multi-agent systems; (2) the trajectory backup set for provably safe inter-agent coordination for leader-follower formation control; and (3) the first application of the gatekeeper framework in a 3D environment. We demonstrate our approach in a simulated 3D urban environment, where it achieved a 100% collision-avoidance success rate across 100 randomized trials, significantly outperforming baseline CBF and NMPC methods. Finally, we demonstrate the physical feasibility of the resulting trajectories on a team of quadcopters.

</details>


### [42] [Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation](https://arxiv.org/abs/2511.19709)
*Lukas Molnar,Jin Cheng,Gabriele Fadini,Dongho Kang,Fatemeh Zargarbashi,Stelian Coros*

Main category: cs.RO

TL;DR: 提出了一个全身模型预测控制框架，通过全阶逆动力学直接优化关节扭矩，在单个预测层中实现统一的运动和力规划与执行，在四足机器人上实现了80Hz的实时性能。


<details>
  <summary>Details</summary>
Motivation: 全身运动操作需要协调的全身运动来有效操纵物体，同时保持运动稳定性，这对规划和控制都提出了重大挑战。

Method: 使用全身模型预测控制框架，通过全阶逆动力学直接优化关节扭矩，采用Pinocchio、CasADi软件框架和Fatrop内点求解器实现。

Result: 在配备机械臂的Unitree B2四足机器人上实现了80Hz的实时性能，成功完成了拉动重物、推箱子和擦白板等实际交互任务。

Conclusion: 该MPC框架能够实现物理一致的全身行为，考虑了系统动力学和物理约束，在实时全身运动操作任务中表现出色。

Abstract: Loco-manipulation demands coordinated whole-body motion to manipulate objects effectively while maintaining locomotion stability, presenting significant challenges for both planning and control. In this work, we propose a whole-body model predictive control (MPC) framework that directly optimizes joint torques through full-order inverse dynamics, enabling unified motion and force planning and execution within a single predictive layer. This approach allows emergent, physically consistent whole-body behaviors that account for the system's dynamics and physical constraints. We implement our MPC formulation using open software frameworks (Pinocchio and CasADi), along with the state-of-the-art interior-point solver Fatrop. In real-world experiments on a Unitree B2 quadruped equipped with a Unitree Z1 manipulator arm, our MPC formulation achieves real-time performance at 80 Hz. We demonstrate loco-manipulation tasks that demand fine control over the end-effector's position and force to perform real-world interactions like pulling heavy loads, pushing boxes, and wiping whiteboards.

</details>


### [43] [Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation](https://arxiv.org/abs/2511.19859)
*Xiangkai Ma,Lekai Xing,Han Zhang,Wenzhong Li,Sanglu Lu*

Main category: cs.RO

TL;DR: VITA框架通过构建视觉和动作的共享离散潜空间，解决了视觉观察与低级动作之间的模态差距问题，在多个基准测试中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决文本CoT在复杂空间环境中难以充分捕捉场景细节的问题，以及现有方法面临的视觉观察与低级动作之间的模态差距、视觉预测与动作生成目标冲突等挑战。

Method: 提出Vision-Integrated Trajectory Alignment框架，学习视觉和动作的共享离散潜空间，通过隐式视觉CoT同时解码未来帧预测和机器人动作，将视觉动态内化为运动规划的归纳偏置。

Result: 在CALVIN、LIBERO和SimplerEnv基准测试中分别比现有基线提升14.5%、9.6%和12.1%，在六项真实世界任务中平均成功率达到80.5%。

Conclusion: VITA展示了作为通用机器人操作模型的潜力，通过联合建模感知和运动控制，有效解决了视觉-语言-动作模型中的关键挑战。

Abstract: Vision-Language-Action (VLA) models built upon Chain-of-Thought (CoT) have achieved remarkable success in advancing general-purpose robotic agents, owing to its significant perceptual comprehension. Recently, since text-only CoT struggles to adequately capture scene details in complex spatial environments, a highly promising strategy involves leveraging visual priors to guide robotic action generation. Nevertheless, these strategies face two inherent challenges: (i) a modality gap between visual observations and low-level actions, and (ii) unstable training due to competing objectives between visual prediction and action generation. To address these challenges, we propose a Vision-Integrated Trajectory Alignment (VITA) framework that learns a shared discrete latent space for vision and action, enabling joint modeling of perception and motor control. VITA introduces a implicit visual CoT: autoregressively generated tokens is simultaneously decoded into future frames predictions and robot actions, thereby internalizing visual dynamics as an inductive bias for motion planning. Extensive experiments on simulated and real-world environments demonstrate state-of-the-art performance. VITA improves 14.5\%, 9.6\% and 12.1\% over existing baselines on CALVIN, LIBERO and SimplerEnv. Furthermore, VITA attains an average success rate of 80.5\% across six real-world tasks, demonstrating its potential as a generalist robotic manipulation model.

</details>


### [44] [Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function](https://arxiv.org/abs/2511.19869)
*Eito Sato,Takahiro Wada*

Main category: cs.RO

TL;DR: 提出了一种结合独立自主控制器与触觉共享控制的协作框架，通过控制屏障函数在安全区域内忽略操纵杆输入，在虚拟环境实验中提升了水下机器人遥操作的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统触觉共享控制在最大化控制强度时受到操纵杆和人体手臂动力学的影响，限制了自主控制性能的提升。

Method: 开发了协作框架，将独立于操纵杆的自主控制器与触觉共享控制结合，使用控制屏障函数在安全区域内忽略操纵杆输入，其他情况下启用触觉共享控制。

Result: 在虚拟环境中的水下机器人遥操作模拟任务中，相比传统触觉共享控制，精度提高且所需时间减少。

Conclusion: 所提出的协作框架有效克服了传统触觉共享控制的局限性，在遥操作任务中实现了更好的性能表现。

Abstract: Haptic shared control (HSC) is effective in teleoperation when full autonomy is limited by uncertainty or sensing constraints. However, autonomous control performance achieved by maximizing HSC strength is limited because the dynamics of the joystick and human arm affect the robot's behavior. We propose a cooperative framework coupling a joystick-independent autonomous controller with HSC. A control barrier function ignores joystick inputs within a safe region determined by the human operator in real-time, while HSC is engaged otherwise. A pilot experiment on simulated tasks with tele-operated underwater robot in virtual environment demonstrated improved accuracy and reduced required time over conventional HSC.

</details>


### [45] [CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model](https://arxiv.org/abs/2511.19914)
*Dapeng Zhang,Fei Shen,Rui Zhao,Yinda Chen,Peng Zhi,Chenyang Li,Rui Zhou,Qingguo Zhou*

Main category: cs.RO

TL;DR: 提出CoC-VLA框架，通过对抗迁移学习将模拟环境中的长尾场景处理能力转移到真实世界自动驾驶系统中


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖真实世界数据，要么使用模拟数据，但很少能有效整合两者的互补优势。需要解决模拟到真实世界的长尾场景处理能力迁移问题

Method: 基于VLM的端到端对抗迁移框架，包含教师VLM、学生VLM和判别器。使用共享的CoC VLM架构集成时序信息，支持链式因果推理

Result: 框架能够将模拟环境中的长尾处理能力有效迁移到真实世界部署中

Conclusion: CoC-VLA框架成功解决了模拟与真实世界数据整合的挑战，提升了自动驾驶系统在复杂长尾场景下的处理能力

Abstract: Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.

</details>


### [46] [Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine](https://arxiv.org/abs/2511.19932)
*Lidi Zhang,Han Wu,Liyu Zhang,Ruofeng Liu,Haotian Wang,Chao Li,Desheng Zhang,Yunhuai Liu,Tian He*

Main category: cs.RO

TL;DR: 提出了一种混合强化学习框架，通过物理模拟与真实世界数据反馈相结合，解决3D装箱问题中的模拟到现实差距问题，显著降低了包装坍塌率。


<details>
  <summary>Details</summary>
Motivation: 现有的3D装箱方法通常将其建模为离散静态过程，而实际应用涉及连续重力驱动交互，这种理想化简化导致实践中出现不可行部署（如不稳定包装）。物理模拟虽能模拟重力效应，但仍存在模拟到现实的差距。

Method: 采用混合强化学习框架：1）在模拟中应用领域随机化，让智能体接触各种物理参数以增强泛化能力；2）利用真实世界部署反馈对RL智能体进行微调，进一步降低坍塌率。

Result: 实验表明该方法在模拟和真实场景中都实现了更低的坍塌率。在物流系统中的大规模部署验证了实际效果，与基线方法相比包装坍塌减少了35%。

Conclusion: 提出的混合RL框架有效解决了3D装箱问题中的模拟到现实差距，通过结合物理模拟和真实数据反馈，显著提高了包装稳定性，在工业应用中具有重要价值。

Abstract: The 3D bin packing problem, with its diverse industrial applications, has garnered significant research attention in recent years. Existing approaches typically model it as a discrete and static process, while real-world applications involve continuous gravity-driven interactions. This idealized simplification leads to infeasible deployments (e.g., unstable packing) in practice. Simulations with physical engine offer an opportunity to emulate continuous gravity effects, enabling the training of reinforcement learning (RL) agents to address such limitations and improve packing stability. However, a simulation-to-reality gap persists due to dynamic variations in physical properties of real-world objects, such as various friction coefficients, elasticity, and non-uniform weight distributions. To bridge this gap, we propose a hybrid RL framework that collaborates with physical simulation with real-world data feedback. Firstly, domain randomization is applied during simulation to expose agents to a spectrum of physical parameters, enhancing their generalization capability. Secondly, the RL agent is fine-tuned with real-world deployment feedback, further reducing collapse rates. Extensive experiments demonstrate that our method achieves lower collapse rates in both simulated and real-world scenarios. Large-scale deployments in logistics systems validate the practical effectiveness, with a 35\% reduction in packing collapse compared to baseline methods.

</details>


### [47] [ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation](https://arxiv.org/abs/2511.19955)
*Jinxuan Zhu,Zihao Yan,Yangyu Xiao,Jingxiang Guo,Chenrui Tie,Xinyi Cao,Yuhang Zheng,Lin Shao*

Main category: cs.RO

TL;DR: ShapeForce是一个低成本、即插即用的软手腕，通过将外力扭矩转换为可测量的形变来提供类似力的信号，用于接触丰富的机器人操作，性能可与六维力扭矩传感器相媲美但成本极低。


<details>
  <summary>Details</summary>
Motivation: 六维力扭矩传感器虽然常用于获取接触反馈，但成本高且易碎，限制了在接触丰富任务中的应用。需要提供更经济易用的接触反馈方案。

Method: 设计软手腕，将外力扭矩转换为柔顺核心的形变，通过基于标记的姿态跟踪估计形变，转换为类似力的信号。无需校准或专用电子设备即可获得足够用于接触操作的变化信号。

Result: 在多种接触丰富任务和操作策略上的广泛实验表明，ShapeForce能以极低成本提供与六维力扭矩传感器相当的性能。

Conclusion: ShapeForce为接触丰富的机器人操作提供了一种低成本、易获取的接触反馈解决方案，无需精确力值而专注于捕捉足够的变化信号。

Abstract: Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six-axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.

</details>


### [48] [Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification](https://arxiv.org/abs/2511.20050)
*Yan Li,Yingzhao Li,Gim Hee Lee*

Main category: cs.RO

TL;DR: 提出了一种主动探索框架，通过多层级不确定性空间和不确定性驱动的运动规划器实现高保真3D重建，融合神经场与高斯基元的混合表示，在挑战性基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法在主动探索和不确定性量化方面存在不足，需要一种能够同时捕捉全局结构先验和局部观测细节，并能智能选择最佳观测视角的框架。

Method: 采用混合隐式-显式表示融合神经场与高斯基元，构建分层不确定性体积量化全局结构质量和局部表面置信度，提出不确定性驱动的关键帧选择和风险敏感路径规划器。

Result: 在挑战性基准测试中一致实现最先进的精度、完整性和渲染质量，证明了在真实世界主动重建和机器人感知任务中的有效性。

Conclusion: 该主动探索框架通过不确定性驱动的视角选择和混合表示，显著提升了3D重建的质量和效率，为机器人感知任务提供了有效解决方案。

Abstract: In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.

</details>


### [49] [Hibikino-Musashi@Home 2025 Team Description Paper](https://arxiv.org/abs/2511.20180)
*Ryohei Kobayashi,Kosei Isomoto,Kosei Yamao,Soma Fumoto,Koshun Arimura,Naoki Yamaguchi,Akinobu Mizutani,Tomoya Shiba,Kouki Kimizuka,Yuta Ohno,Ryo Terashima,Hiromasa Yamaguchi,Tomoaki Fujino,Ryoga Maruno,Wataru Yoshimura,Kazuhito Mine,Tang Phu Thien Nhan,Yuga Yano,Yuichiro Tanaka,Takeshi Nishida,Takashi Morie,Hakaru Tamukoh*

Main category: cs.RO

TL;DR: Hibikino-Musashi@Home团队开发了用于机器人视觉系统训练的数据集生成器、基于大语言模型的任务规划器、脑启发记忆模型和导航系统，旨在为家庭环境提供个性化辅助服务。


<details>
  <summary>Details</summary>
Motivation: 设计能够在家庭环境中为人类提供辅助服务的家用服务机器人，并通过持续参加比赛来评估和改进系统性能。

Method: 开发数据集生成器训练机器人视觉系统；创建开源开发环境运行在HSR模拟器上；使用大语言模型驱动的任务规划器选择原始技能；研究脑启发记忆模型以适应个体家庭环境；重用Pumas在RoboCup2024开发的导航系统。

Result: 构建了完整的家庭服务机器人系统，包括视觉训练、任务规划、环境适应和导航等核心功能模块。

Conclusion: 该团队通过多技术融合的方法开发了面向家庭环境的服务机器人系统，并通过竞赛持续优化系统性能，为实现个性化家庭辅助服务奠定了基础。

Abstract: This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator. The large-language-model-powered task planner selects appropriate primitive skills to perform the task requested by the user. Moreover, the team has focused on research involving brain-inspired memory models for adaptation to individual home environments. This approach aims to provide intuitive and personalized assistance. Additionally, the team contributed to the reusability of the navigation system developed by Pumas in RoboCup2024. The team aimed to design a home service robot to assist humans in their homes and continuously attend competitions to evaluate and improve the developed system.

</details>


### [50] [Toward generic control for soft robotic systems](https://arxiv.org/abs/2511.20226)
*Yu Sun,Yaosheng Deng,Wenjie Mei,Xiaogang Xiong,Yang Bai,Masaki Ogura,Zeyu Zhou,Mir Feroskhan,Michael Yu Wang,Qiyang Zuo,Yao Li,Yunjiang Lou*

Main category: cs.RO

TL;DR: 提出了一种基于控制柔顺性的通用软体机器人控制框架，通过利用而非抑制近似动作表示，实现跨形态和驱动机制的稳定、安全控制。


<details>
  <summary>Details</summary>
Motivation: 软体机器人控制方法碎片化，不同形态和驱动方案需要特定控制器。刚性控制逻辑依赖精确模型和严格执行，不适合软体机器人。受人类运动控制启发，需要从抑制柔顺性转向显式利用柔顺性。

Method: 基于控制柔顺性的通用软体机器人控制框架，通过高层运动倾向表达意图，反射和生物力学机制自主解决局部细节。

Result: 在多种形态和驱动机制的机器人上验证，展示了稳定、安全且跨平台可转移的行为。

Conclusion: 接受而非抵抗控制柔顺性，可能为统一软体机器人控制提供广泛应用基础。

Abstract: Soft robotics has advanced rapidly, yet its control methods remain fragmented: different morphologies and actuation schemes still require task-specific controllers, hindering theoretical integration and large-scale deployment. A generic control framework is therefore essential, and a key obstacle lies in the persistent use of rigid-body control logic, which relies on precise models and strict low-level execution. Such a paradigm is effective for rigid robots but fails for soft robots, where the ability to tolerate and exploit approximate action representations, i.e., control compliance, is the basis of robustness and adaptability rather than a disturbance to be eliminated. Control should thus shift from suppressing compliance to explicitly exploiting it. Human motor control exemplifies this principle: instead of computing exact dynamics or issuing detailed muscle-level commands, it expresses intention through high-level movement tendencies, while reflexes and biomechanical mechanisms autonomously resolve local details. This architecture enables robustness, flexibility, and cross-task generalization. Motivated by this insight, we propose a generic soft-robot control framework grounded in control compliance and validate it across robots with diverse morphologies and actuation mechanisms. The results demonstrate stable, safe, and cross-platform transferable behavior, indicating that embracing control compliance, rather than resisting it, may provide a widely applicable foundation for unified soft-robot control.

</details>


### [51] [HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments](https://arxiv.org/abs/2511.20275)
*Chenhui Dong,Haozhe Xu,Wenhao Feng,Zhipeng Wang,Yanmin Zhou,Yifei Zhao,Bin He*

Main category: cs.RO

TL;DR: HAFO是一个双智能体强化学习控制框架，通过耦合训练同时优化稳健的步态策略和精确的上半身操作策略，在强外力交互环境下实现人形机器人的稳定控制。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习控制器在人形机器人步态和轻负载操作方面取得进展，但在强外力交互下实现稳健精确运动仍面临挑战。

Method: 提出双智能体强化学习框架，通过弹簧-阻尼系统显式建模外部拉力干扰，采用非对称Actor-Critic架构，Critic网络访问特权弹簧-阻尼力信息指导Actor网络学习通用稳健策略。

Result: HAFO在各种强外力交互下实现人形机器人稳定控制，在负载任务中表现优异，并在绳索拉力干扰下确保机器人稳定运行。

Conclusion: 该框架成功解决了强外力交互下人形机器人的控制挑战，展示了在复杂环境中的鲁棒性和适应性。

Abstract: Reinforcement learning controllers have made impressive progress in humanoid locomotion and light load manipulation. However, achieving robust and precise motion with strong force interaction remains a significant challenge. Based on the above limitations, this paper proposes HAFO, a dual-agent reinforcement learning control framework that simultaneously optimizes both a robust locomotion strategy and a precise upper-body manipulation strategy through coupled training under external force interaction environments. Simultaneously, we explicitly model the external pulling disturbances through a spring-damper system and achieve fine-grained force control by manipulating the virtual spring. During this process, the reinforcement-learning policy spontaneously generates disturbance-rejection response by exploiting environmental feedback. Moreover, HAFO employs an asymmetric Actor-Critic framework in which the Critic-network access to privileged spring-damping forces guides the actor-network to learn a generalizable, robust policy for resisting external disturbances. The experimental results demonstrate that HAFO achieves stable control of humanoid robot under various strong force interactions, showing remarkable performance in load tasks and ensuring stable robot operation under rope tension disturbances. Project website: hafo-robot.github.io.

</details>


### [52] [Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes](https://arxiv.org/abs/2511.20292)
*Dong Wang,Daniel Casado Herraez,Stefan May,Andreas Nüchter*

Main category: cs.RO

TL;DR: Dynamic-ICP是一种基于多普勒感知的激光雷达里程计方法，通过结合几何残差和多普勒残差，在高度动态环境中实现稳健的扫描配准。


<details>
  <summary>Details</summary>
Motivation: 传统ICP方法假设场景静态，在动态环境中性能下降，特别是在重复纹理或低纹理几何中。需要一种能够在动态环境中可靠工作的里程计方法。

Method: 1) 通过稳健回归从多普勒速度估计自身运动并构建速度滤波器；2) 聚类动态物体并从自身补偿的径向测量重建物体平移速度；3) 使用恒定速度模型预测动态点；4) 结合点对面几何残差和旋转不变的多普勒残差进行扫描配准。

Result: 在三个数据集上的评估表明，Dynamic-ICP在旋转稳定性和平移精度上持续优于现有最先进方法，能够实时运行且易于集成到现有流程中。

Conclusion: Dynamic-ICP提供了一种轻量级解决方案，无需外部传感器或传感器-车辆标定，直接在FMCW激光雷达距离和多普勒速度上操作，为动态环境中的稳健配准提供了有效方法。

Abstract: Reliable odometry in highly dynamic environments remains challenging when it relies on ICP-based registration: ICP assumes near-static scenes and degrades in repetitive or low-texture geometry. We introduce Dynamic-ICP, a Doppler-aware registration framework. The method (i) estimates ego motion from per-point Doppler velocity via robust regression and builds a velocity filter, (ii) clusters dynamic objects and reconstructs object-wise translational velocities from ego-compensated radial measurements, (iii) predicts dynamic points with a constant-velocity model, and (iv) aligns scans using a compact objective that combines point-to-plane geometry residual with a translation-invariant, rotation-only Doppler residual. The approach requires no external sensors or sensor-vehicle calibration and operates directly on FMCW LiDAR range and Doppler velocities. We evaluate Dynamic-ICP on three datasets-HeRCULES, HeLiPR, AevaScenes-focusing on highly dynamic scenes. Dynamic-ICP consistently improves rotational stability and translation accuracy over the state-of-the-art methods. Our approach is also simple to integrate into existing pipelines, runs in real time, and provides a lightweight solution for robust registration in dynamic environments. To encourage further research, the code is available at: https://github.com/JMUWRobotics/Dynamic-ICP.

</details>


### [53] [How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks](https://arxiv.org/abs/2511.20299)
*Róisín Keenan,Joost C. Dessing*

Main category: cs.RO

TL;DR: 研究使用VR探索人机协作中的物体交接任务，发现人类受益于机器人提供早期视觉信息和类人平滑轨迹，这能提高预测准确性和同步性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统越来越多地融入人类工作场所，需要优化人机协调协作，特别是在物体交接等交互任务中。

Method: 通过VR机器人交接模拟，在受控环境中分别测试四个影响因素：任务启动控制和机器人运动同步性、伙伴外观、机器人速度曲线、物体旋转运动时机。

Result: 实验表明，机器人提供早期视觉信息和类人平滑轨迹能显著改善人类预测准确性和交互同步性。

Conclusion: 人机交互设计应让人类能够利用其生物运动检测的自然能力，这可以减少机器人计算成本和人类认知适应负担。

Abstract: Recent advancements in robotics have increased the possibilities for integrating robotic systems into human-involved workplaces, highlighting the need to examine and optimize human-robot coordination in collaborative settings. This study explores human-robot interactions during handover tasks using Virtual Reality (VR) to investigate differences in human motor performance across various task dynamics and robot kinematics. A VR-based robot handover simulation afforded safe and controlled assessments of human-robot interactions. In separate experiments, four potential influences on human performance were examined (1) control over task initiation and robot movement synchrony (temporal and spatiotemporal); (2) partner appearance (human versus robotic); (3) robot velocity profiles (minimum jerk, constant velocity, constant acceleration, and biphasic); and (4) the timing of rotational object motion. Findings across experiments emphasize humans benefit from robots providing early and salient visual information about task-relevant object motion, and advantages of human-like smooth robot trajectories. To varying degrees, these manipulations improved predictive accuracy and synchronization during interaction. This suggests that human-robot interactions should be designed to allow humans to leverage their natural capabilities for detecting biological motion, which conversely may reduce the need for costly robotic computations or added cognitive adaptation on the human side.

</details>


### [54] [ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation](https://arxiv.org/abs/2511.20330)
*Yuhan Wu,Tiantian Wei,Shuo Wang,ZhiChao Wang,Yanyong Zhang,Daniel Cremers,Yan Xia*

Main category: cs.RO

TL;DR: 提出了ArtiBench基准测试和ArtiBrain框架，用于解决关节物体操作中的泛化挑战，通过结合高层推理和自适应底层控制，显著提升了操作的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言和基于扩散的策略在跨部件、实例和类别的关节物体操作中泛化能力不足，需要解决长时程、多步骤交互中的物理一致性问题。

Method: 提出ArtiBrain模块化框架，使用基于VLM的任务推理器分解和验证子目标，结合几何感知关键帧执行和可供性引导扩散的混合控制器，并通过可供性记忆库积累和传播成功执行经验。

Result: 在ArtiBench基准测试上的广泛实验表明，ArtiBrain在鲁棒性和泛化能力上显著优于最先进的多模态和基于扩散的方法。

Conclusion: ArtiBrain框架通过统一高层推理和自适应底层控制，有效解决了关节物体操作的泛化挑战，为交互式关节操作提供了新的解决方案。

Abstract: Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.

</details>


### [55] [Quality-guided UAV Surface Exploration for 3D Reconstruction](https://arxiv.org/abs/2511.20353)
*Benjamin Sportich,Kenza Boubakri,Olivier Simonin,Alessandro Renzaglia*

Main category: cs.RO

TL;DR: 提出了一种用于空中机器人的模块化Next-Best-View规划框架，通过重建质量目标指导探索规划，在覆盖范围、3D地图质量和路径效率方面优于传统NBV策略。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在未知环境中的建图需求广泛，但在规划策略开发中常被忽视。快速信息收集和建筑物全面结构评估有不同的要求，需要不同的方法。

Method: 提出模块化NBV规划框架，使用重建质量目标指导探索规划；引入新的高效视图生成和视点候选选择方法，适应于用户定义的质量要求；充分利用TSDF表示中编码的不确定性。

Result: 在真实环境中的广泛仿真验证表明，该方法成功根据用户目标调整行为，在覆盖范围、最终3D地图质量和路径效率方面持续优于传统NBV策略。

Conclusion: 该方法能够根据预定目标做出知情且高效的探索决策，为不同建图需求提供了有效的解决方案。

Abstract: Reasons for mapping an unknown environment with autonomous robots are wide-ranging, but in practice, they are often overlooked when developing planning strategies. Rapid information gathering and comprehensive structural assessment of buildings have different requirements and therefore necessitate distinct methodologies. In this paper, we propose a novel modular Next-Best-View (NBV) planning framework for aerial robots that explicitly uses a reconstruction quality objective to guide the exploration planning. In particular, our approach introduces new and efficient methods for view generation and selection of viewpoint candidates that are adaptive to the user-defined quality requirements, fully exploiting the uncertainty encoded in a Truncated Signed Distance field (TSDF) representation of the environment. This results in informed and efficient exploration decisions tailored towards the predetermined objective. Finally, we validate our method via extensive simulations in realistic environments. We demonstrate that it successfully adjusts its behavior to the user goal while consistently outperforming conventional NBV strategies in terms of coverage, quality of the final 3D map and path efficiency.

</details>


### [56] [Improved adaptive wind driven optimization algorithm for real-time path planning](https://arxiv.org/abs/2511.20394)
*Shiqian Liu,Azlan Mohd Zain,Le-le Mao*

Main category: cs.RO

TL;DR: 提出了一种多层级自适应风驱动优化算法(MAWDO)，通过分层引导机制改进动态环境中的适应性和鲁棒性，在路径规划中实现了更短、更平滑的无碰撞轨迹。


<details>
  <summary>Details</summary>
Motivation: 动态环境中实时适应性是自主导航的关键挑战，风驱动优化算法因其物理可解释的搜索动态而具有潜力，但存在不稳定和早熟收敛问题。

Method: 基于风驱动优化原理，提出多层级自适应变体MAWDO，采用分层引导机制将种群划分为多个组，由个体、区域和全局领导者引导，平衡探索与利用。

Result: 在16个基准函数上MAWDO获得优越的优化精度、收敛稳定性和适应性；在动态路径规划中，路径长度缩短至469.28像素，比MEWDO、AWDO和WDO分别提升3.51%、11.63%和14.93%，最优性差距最小(1.01)，平滑度为0.71。

Conclusion: MAWDO能够生成更平滑、更短的无碰撞轨迹，证实了其在复杂环境中实时路径规划的有效性。

Abstract: Recently, path planning has achieved remarkable progress in enhancing global search capability and convergence accuracy through heuristic and learning-inspired optimization frameworks. However, real-time adaptability in dynamic environments remains a critical challenge for autonomous navigation, particularly when robots must generate collision-free, smooth, and efficient trajectories under complex constraints. By analyzing the difficulties in dynamic path planning, the Wind Driven Optimization (WDO) algorithm emerges as a promising framework owing to its physically interpretable search dynamics. Motivated by these observations, this work revisits the WDO principle and proposes a variant formulation, Multi-hierarchical adaptive wind driven optimization(MAWDO), that improves adaptability and robustness in time-varying environments. To mitigate instability and premature convergence, a hierarchical-guidance mechanism divides the population into multiple groups guided by individual, regional, and global leaders to balance exploration and exploitation. Extensive evaluations on sixteen benchmark functions show that MAWDO achieves superior optimization accuracy, convergence stability, and adaptability over state-of-the art metaheuristics. In dynamic path planning, MAWDO shortens the path length to 469.28 pixels, improving over Multi-strategy ensemble wind driven optimization(MEWDO), Adaptive wind driven optimization(AWDO) and WDO by 3.51\%, 11.63\% and 14.93\%, and achieves the smallest optimality gap (1.01) with smoothness 0.71 versus 13.50 and 15.67 for AWDO and WDO, leading to smoother, shorter, and collision-free trajectories that confirm its effectiveness for real-time path planning in complex environments.

</details>


### [57] [Power-Efficient Autonomous Mobile Robots](https://arxiv.org/abs/2511.20467)
*Liangkai Liu,Weisong Shi,Kang G. Shin*

Main category: cs.RO

TL;DR: pNav是一个创新的功率管理系统，通过联合优化自主移动机器人的物理/机械和网络子系统，显著提高了功率/能量效率。


<details>
  <summary>Details</summary>
Motivation: 通过分析AMR的功率消耗，发现实现CPS功率效率面临三个挑战：系统功率消耗分解的变异性、环境感知导航的局部性、以及网络和物理子系统的协调。

Method: 采用多层面方法：集成毫秒级功率消耗预测、实时建模和监控导航时空局部性、动态协调软件和硬件配置。

Result: 在真实机器人和Gazebo环境中的评估显示，功率消耗预测准确率>96%，功率消耗减少38.1%，且不影响导航精度和安全性。

Conclusion: pNav系统有效解决了AMR功率效率问题，通过联合优化网络和物理子系统实现了显著的功率节省。

Abstract: This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.

</details>


### [58] [Kleinkram: Open Robotic Data Management](https://arxiv.org/abs/2511.20492)
*Cyrill Püntener,Johann Schwabe,Dominique Garmier,Jonas Frey,Marco Hutter*

Main category: cs.RO

TL;DR: Kleinkram是一个免费开源的机器人数据管理系统，用于管理大规模非结构化机器人数据集，提供可扩展存储、索引和共享功能。


<details>
  <summary>Details</summary>
Motivation: 解决管理大规模非结构化机器人数据集的挑战，支持从个体实验到大规模研究数据集的统一管理。

Method: 采用模块化本地云解决方案，集成ROS bags和MCAP标准格式，使用S3兼容存储，并包含基于Docker的自定义工作流执行器。

Result: 成功管理了超过30TB来自不同机器人系统的数据，通过现代化Web界面和强大CLI简化了研究生命周期。

Conclusion: Kleinkram提供了一个有效的机器人数据管理解决方案，支持数据验证、整理和基准测试，促进了机器人研究的数据管理效率。

Abstract: We introduce Kleinkram, a free and open-source system designed to solve the challenge of managing massive, unstructured robotic datasets. Designed as a modular, on-premises cloud solution, Kleinkram enables scalable storage, indexing, and sharing of datasets, ranging from individual experiments to large-scale research collections. Kleinkram natively integrates with standard formats such as ROS bags and MCAP and utilises S3-compatible storage for flexibility. Beyond storage, Kleinkram features an integrated "Action Runner" that executes customizable Docker-based workflows for data validation, curation, and benchmarking. Kleinkram has successfully managed over 30 TB of data from diverse robotic systems, streamlining the research lifecycle through a modern web interface and a robust Command Line Interface (CLI).

</details>


### [59] [Metric, inertially aligned monocular state estimation via kinetodynamic priors](https://arxiv.org/abs/2511.20496)
*Jiaxin Liu,Min Li,Wanting Xu,Liang Li,Jiaqi Yang,Laurent Kneip*

Main category: cs.RO

TL;DR: 提出了一种将刚性位姿估计方法扩展到非刚性系统的框架，通过学习的变形-力模型和连续时间B样条运动模型，建立视觉轨迹加速度与变形诱导加速度之间的物理联系。


<details>
  <summary>Details</summary>
Motivation: 解决柔性机器人系统的精确状态估计问题，特别是对于动态变形结构使刚体假设失效的平台。

Method: 使用多层感知机学习可逆的变形-力模型，结合连续时间B样条运动模型，通过牛顿第二定律建立视觉轨迹加速度与预测变形加速度的物理联系。

Result: 方法不仅能在非刚性平台上实现鲁棒准确的位姿估计，还能通过正确建模的平台物理激发惯性传感特性，在简单弹簧-相机系统上验证了可行性。

Conclusion: 该方法能够稳健地解决单目视觉里程计中度量尺度和重力恢复这一通常不适定的问题。

Abstract: Accurate state estimation for flexible robotic systems poses significant challenges, particular for platforms with dynamically deforming structures that invalidate rigid-body assumptions. This paper tackles this problem and allows to extend existing rigid-body pose estimation methods to non-rigid systems. Our approach hinges on two core assumptions: first, the elastic properties are captured by an injective deformation-force model, efficiently learned via a Multi-Layer Perceptron; second, we solve the platform's inherently smooth motion using continuous-time B-spline kinematic models. By continuously applying Newton's Second Law, our method establishes a physical link between visually-derived trajectory acceleration and predicted deformation-induced acceleration. We demonstrate that our approach not only enables robust and accurate pose estimation on non-rigid platforms, but that the properly modeled platform physics instigate inertial sensing properties. We demonstrate this feasibility on a simple spring-camera system, and show how it robustly resolves the typically ill-posed problem of metric scale and gravity recovery in monocular visual odometry.

</details>


### [60] [Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics](https://arxiv.org/abs/2511.20570)
*Tasha Kim,Oiwi Parker Jones*

Main category: cs.RO

TL;DR: GUARDIAN是一个用于神经信号控制机器人的实时神经符号验证框架，通过结合置信度校准的脑信号解码与符号目标基础和双层级运行时监控，确保逻辑安全和生理信任。


<details>
  <summary>Details</summary>
Motivation: 安全关键的辅助系统需要从神经信号直接解码用户意图，这要求严格的可靠性和信任保证。

Method: GUARDIAN框架结合置信度校准的脑信号解码、符号目标基础和双层级运行时监控，在BNCI2014运动想象EEG数据集上进行验证。

Result: 系统在9名受试者和5,184次试验中实现了94-97%的高安全率，即使使用轻量级解码器架构（测试准确率27-46%，ECE置信度校准误差0.22-0.41）。在模拟噪声测试中，正确干预次数比基线提高1.7倍。监控器以100Hz频率运行，决策延迟低于毫秒级。

Conclusion: GUARDIAN展示了针对信号退化的渐进响应，并生成从意图、计划到行动的可审计轨迹，有助于将神经证据与可验证的机器人行动联系起来。

Abstract: Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.

</details>


### [61] [Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning](https://arxiv.org/abs/2511.20593)
*Allen Emmanuel Binny,Mahathi Anand,Hugo T. M. Kussaba,Lingyun Chen,Shreenabh Agrawal,Fares J. Abu-Dakka,Abdalla Swikir*

Main category: cs.RO

TL;DR: S²-NNDS是一个从演示中学习机器人运动的框架，同时学习神经动力学系统以及神经李雅普诺夫稳定性和障碍安全证书，提供概率安全保证。


<details>
  <summary>Details</summary>
Motivation: 在复杂、非线性任务中从演示中学习安全稳定的机器人运动仍然具有挑战性，特别是在动态、障碍丰富的环境中。

Method: 利用神经网络捕捉复杂机器人运动，通过分裂保形预测在学习证书中提供概率保证，不同于传统限制性多项式参数化方法。

Result: 在多种2D和3D数据集上的实验结果表明，S²-NNDS能够从潜在不安全的演示中学习到鲁棒、安全且稳定的运动。

Conclusion: S²-NNDS框架有效解决了从演示中学习安全稳定机器人运动的挑战，特别是在复杂动态环境中。

Abstract: Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.

</details>


### [62] [Reinforcing Action Policies by Prophesying](https://arxiv.org/abs/2511.20633)
*Jiahui Zhang,Ze Huang,Chun Gu,Zipei Ma,Li Zhang*

Main category: cs.RO

TL;DR: ProphRL是一个用于视觉-语言-动作策略后训练的框架，通过世界模型和强化学习解决模仿学习的过拟合问题，在公开基准上提升5-17%成功率，在真实机器人上提升24-30%成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作策略主要通过模仿学习训练，容易过拟合演示数据且在分布偏移时表现脆弱。强化学习能直接优化任务奖励但真实机器人交互成本高，传统模拟器难以构建和迁移。

Method: 提出ProphRL框架：1) Prophet - 在大规模异构机器人数据上预训练的动作到视频世界模型，可快速适应新机器人、物体和环境；2) FA-GRPO - 针对流式动作头的强化学习算法；3) FlowScale - 逐步重加权方法，重新缩放流头的每步梯度。

Result: 在公开基准测试中实现5-17%的成功率提升，在真实机器人上实现24-30%的成功率提升，验证了方法的有效性和实用性。

Conclusion: ProphRL提供了一个实用、数据和计算效率高的视觉-语言-动作策略后训练路径，通过世界模型和专门的强化学习算法有效解决了模仿学习的局限性。

Abstract: Vision-Language-Action (VLA) policies excel in aligning language, perception, and robot control. However, most VLAs are trained purely by imitation, which overfits to demonstrations, and is brittle under distribution shift. Reinforcement learning (RL) directly optimizes task reward and thus addresses this misalignment, but real-robot interaction is expensive and conventional simulators are hard to engineer and transfer. We address both data efficiency and optimization stability in VLA post-training via a learned world model and an RL procedure tailored to flow-based action heads. Specifically, we introduce Prophet, a unified action-to-video robot actuation pretrained across large-scale, heterogeneous robot data to learn reusable action-outcome dynamics. It is able to few-shot adapt to new robots, objects, and environments, yielding a rollout-ready simulator. Upon Prophet, we reinforce action policies with Flow-action-GRPO (FA-GRPO), which adapts Flow-GRPO to operate on VLA actions, and with FlowScale, a stepwise reweighting that rescales per-step gradients in the flow head. Together, Prophet, FA-GRPO, and FlowScale constitute ProphRL, a practical, data- and compute-efficient path to VLA post-training. Experiments show 5-17% success gains on public benchmarks and 24-30% gains on real robots across different VLA variants.

</details>
