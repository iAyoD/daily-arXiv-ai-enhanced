<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer](https://arxiv.org/abs/2510.03342)
*Abbas Abdolmaleki,Saminda Abeyruwan,Joshua Ainslie,Jean-Baptiste Alayrac,Montserrat Gonzalez Arenas,Ashwin Balakrishna,Nathan Batchelor,Alex Bewley,Jeff Bingham,Michael Bloesch,Konstantinos Bousmalis,Philemon Brakel,Anthony Brohan,Thomas Buschmann,Arunkumar Byravan,Serkan Cabi,Ken Caluwaerts,Federico Casarini,Christine Chan,Oscar Chang,London Chappellet-Volpini,Jose Enrique Chen,Xi Chen,Hao-Tien Lewis Chiang,Krzysztof Choromanski,Adrian Collister,David B. D'Ambrosio,Sudeep Dasari,Todor Davchev,Meet Kirankumar Dave,Coline Devin,Norman Di Palo,Tianli Ding,Carl Doersch,Adil Dostmohamed,Yilun Du,Debidatta Dwibedi,Sathish Thoppay Egambaram,Michael Elabd,Tom Erez,Xiaolin Fang,Claudio Fantacci,Cody Fong,Erik Frey,Chuyuan Fu,Ruiqi Gao,Marissa Giustina,Keerthana Gopalakrishnan,Laura Graesser,Oliver Groth,Agrim Gupta,Roland Hafner,Steven Hansen,Leonard Hasenclever,Sam Haves,Nicolas Heess,Brandon Hernaez,Alex Hofer,Jasmine Hsu,Lu Huang,Sandy H. Huang,Atil Iscen,Mithun George Jacob,Deepali Jain,Sally Jesmonth,Abhishek Jindal,Ryan Julian,Dmitry Kalashnikov,M. Emre Karagozler,Stefani Karp,Matija Kecman,J. Chase Kew,Donnie Kim,Frank Kim,Junkyung Kim,Thomas Kipf,Sean Kirmani,Ksenia Konyushkova,Li Yang Ku,Yuheng Kuang,Thomas Lampe,Antoine Laurens,Tuan Anh Le,Isabel Leal,Alex X. Lee,Tsang-Wei Edward Lee,Guy Lever,Jacky Liang,Li-Heng Lin,Fangchen Liu,Shangbang Long,Caden Lu,Sharath Maddineni,Anirudha Majumdar,Kevis-Kokitsi Maninis,Andrew Marmon,Sergio Martinez,Assaf Hurwitz Michaely,Niko Milonopoulos,Joss Moore,Robert Moreno,Michael Neunert,Francesco Nori,Joy Ortiz,Kenneth Oslund,Carolina Parada,Emilio Parisotto,Amaris Paryag,Acorn Pooley,Thomas Power,Alessio Quaglino,Haroon Qureshi,Rajkumar Vasudeva Raju,Helen Ran,Dushyant Rao,Kanishka Rao,Isaac Reid,David Rendleman,Krista Reymann,Miguel Rivas,Francesco Romano,Yulia Rubanova,Peter Pastor Sampedro,Pannag R Sanketi,Dhruv Shah,Mohit Sharma,Kathryn Shea,Mohit Shridhar,Charles Shu,Vikas Sindhwani,Sumeet Singh,Radu Soricut,Rachel Sterneck,Ian Storz,Razvan Surdulescu,Jie Tan,Jonathan Tompson,Saran Tunyasuvunakool,Jake Varley,Grace Vesom,Giulia Vezzani,Maria Bauza Villalonga,Oriol Vinyals,René Wagner,Ayzaan Wahid,Stefan Welker,Paul Wohlhart,Chengda Wu,Markus Wulfmeier,Fei Xia,Ted Xiao,Annie Xie,Jinyu Xie,Peng Xu,Sichun Xu,Ying Xu,Zhuo Xu,Jimmy Yan,Sherry Yang,Skye Yang,Yuxiang Yang,Hiu Hong Yu,Wenhao Yu,Wentao Yuan,Yuan Yuan,Jingwei Zhang,Tingnan Zhang,Zhiyuan Zhang,Allan Zhou,Guangyao Zhou,Yuxiang Zhou*

Main category: cs.RO

TL;DR: Gemini Robotics 1.5是一个多具身视觉-语言-动作模型，具有运动转移机制和内部推理过程；Gemini Robotics-ER 1.5是最先进的具身推理模型，共同推动物理智能体发展。


<details>
  <summary>Details</summary>
Motivation: 通用机器人需要深度理解物理世界、高级推理能力和通用灵巧控制能力，现有模型在这些方面存在局限。

Method: 采用新颖架构和运动转移机制从异构多具身机器人数据中学习；在自然语言中交错进行多级内部推理；开发专门用于具身推理的模型。

Result: 模型能够学习异构多具身数据，使VLA更通用；通过"先思考后行动"显著提高复杂多步骤任务的分解和执行能力；在具身推理方面达到最先进水平。

Conclusion: 这一系列模型向物理智能体时代迈进了一步，使机器人能够感知、思考然后行动，解决复杂多步骤任务。

Abstract: General-purpose robots need a deep understanding of the physical world,
advanced reasoning, and general and dexterous control. This report introduces
the latest generation of the Gemini Robotics model family: Gemini Robotics 1.5,
a multi-embodiment Vision-Language-Action (VLA) model, and Gemini Robotics-ER
1.5, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together
three major innovations. First, Gemini Robotics 1.5 features a novel
architecture and a Motion Transfer (MT) mechanism, which enables it to learn
from heterogeneous, multi-embodiment robot data and makes the VLA more general.
Second, Gemini Robotics 1.5 interleaves actions with a multi-level internal
reasoning process in natural language. This enables the robot to "think before
acting" and notably improves its ability to decompose and execute complex,
multi-step tasks, and also makes the robot's behavior more interpretable to the
user. Third, Gemini Robotics-ER 1.5 establishes a new state-of-the-art for
embodied reasoning, i.e., for reasoning capabilities that are critical for
robots, such as visual and spatial understanding, task planning, and progress
estimation. Together, this family of models takes us a step towards an era of
physical agents-enabling robots to perceive, think and then act so they can
solve complex multi-step tasks.

</details>


### [2] [Optimal swimming with body compliance in an overdamped medium](https://arxiv.org/abs/2510.03457)
*Jianfeng Lin,Tianyu Wang,Baxi Chong,Matthew Fernandez,Zhaochen Xu,Daniel I. Goldman*

Main category: cs.RO

TL;DR: 本文扩展了几何力学框架，用于预测和优化柔性波动游泳机器人的运动性能，通过引入关节弹簧的柔性三连杆游泳器模型，在颗粒介质中验证了准确的性能预测和优化。


<details>
  <summary>Details</summary>
Motivation: 现有几何力学方法假设精确执行预设步态，但实践中环境与柔性体的相互作用会干扰实际轨迹，需要扩展框架来处理柔性波动游泳器的运动控制问题。

Method: 在Purcell三连杆游泳器基础上引入串联弹簧实现柔性扩展，结合阻力理论推导身体动力学，将几何力学融入运动预测和优化框架，识别实现最大位移的控制策略。

Result: 在物理电缆驱动的三连杆无肢机器人上验证了框架，在颗粒介质中准确预测和优化了不同编程状态相关柔性下的运动性能。

Conclusion: 建立了一个系统的基于物理的方法来建模和控制柔性游泳运动，突显了柔性作为设计特征可在同质和异质环境中用于鲁棒运动。

Abstract: Elongate animals and robots use undulatory body waves to locomote through
diverse environments. Geometric mechanics provides a framework to model and
optimize such systems in highly damped environments, connecting a prescribed
shape change pattern (gait) with locomotion displacement. However, existing
approaches assume precise execution of prescribed gaits, whereas in practice
environmental interactions with compliant bodies of animals or robots
frequently perturb the realized trajectories. In this work, we extend geometric
mechanics to predict locomotor performance and search for optimal swimming
strategy of compliant undulators. We introduce a compliant extension of
Purcell's three-link swimmer by incorporating series-connected springs at the
joints. Body dynamics are derived with resistive force theory. Geometric
mechanics is incorporated into movement prediction and into an optimization
framework that identifies strategies for controlling compliant swimmers to
achieve maximal displacement. We validate our framework on a physical
cable-driven three-link limbless robot, and demonstrate accurate prediction and
optimization of locomotor performance under varied programmed, state-dependent
compliance in a granular medium. Our results establish a systematic
physics-based approach for modeling and controlling compliant swimming
locomotion, highlighting compliance as a design feature that can be exploited
for robust movement in homogeneous and heterogeneous environments.

</details>


### [3] [Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching](https://arxiv.org/abs/2510.03460)
*Sibo Tian,Minghui Zheng,Xiao Liang*

Main category: cs.RO

TL;DR: 提出一种基于流匹配模型的学习方法，利用单视角点云生成优化初始化轨迹，提高人机协作中机器人运动规划的效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决采样式运动规划器在高维配置空间中扩展性差、需要后处理的问题，以及优化式规划器对初始化敏感、易陷入局部最优的挑战。

Method: 使用条件流匹配模型，基于单视角点云学习接近最优的优化初始化解，无需环境先验知识，直接从深度相机输入生成可行轨迹。

Result: 在UR5e机械臂的仿真实验中，该方法单独使用具有高成功率，显著提升轨迹优化的成功率，减少优化迭代次数，并在未见环境中表现出强泛化能力。

Conclusion: 所提出的生成式初始化器在人机协作运动规划中表现出优越性能，为实时机器人运动生成提供了有效解决方案。

Abstract: Rapid robot motion generation is critical in Human-Robot Collaboration (HRC)
systems, as robots need to respond to dynamic environments in real time by
continuously observing their surroundings and replanning their motions to
ensure both safe interactions and efficient task execution. Current
sampling-based motion planners face challenges in scaling to high-dimensional
configuration spaces and often require post-processing to interpolate and
smooth the generated paths, resulting in time inefficiency in complex
environments. Optimization-based planners, on the other hand, can incorporate
multiple constraints and generate smooth trajectories directly, making them
potentially more time-efficient. However, optimization-based planners are
sensitive to initialization and may get stuck in local minima. In this work, we
present a novel learning-based method that utilizes a Flow Matching model
conditioned on a single-view point cloud to learn near-optimal solutions for
optimization initialization. Our method does not require prior knowledge of the
environment, such as obstacle locations and geometries, and can generate
feasible trajectories directly from single-view depth camera input. Simulation
studies on a UR5e robotic manipulator in cluttered workspaces demonstrate that
the proposed generative initializer achieves a high success rate on its own,
significantly improves the success rate of trajectory optimization compared
with traditional and learning-based benchmark initializers, requires fewer
optimization iterations, and exhibits strong generalization to unseen
environments.

</details>


### [4] [A Simulation Evaluation Suite for Robust Adaptive Quadcopter Control](https://arxiv.org/abs/2510.03471)
*Dingqi Zhang,Ran Tao,Sheng Cheng,Naira Hovakimyan,Mark W. Mueller*

Main category: cs.RO

TL;DR: 提出一个基于RotorPy的模块化四旋翼控制仿真测试平台，用于在多种干扰条件下系统评估自适应控制方法，提供统一的评估框架和控制器库。


<details>
  <summary>Details</summary>
Motivation: 四旋翼控制方法在外部干扰和模型不确定性下的评估分散在不同任务、仿真器和实现中，缺乏系统性比较。

Method: 构建易部署的模块化仿真测试平台，包含代表性自适应和非自适应控制器库，支持风扰、负载变化、旋翼故障和控制延迟等多种干扰场景。

Result: 测试平台能够进行可重复的控制器评估，提供任务相关指标来评估跟踪精度和鲁棒性，并通过多种干扰场景和轨迹类型验证了其多功能性。

Conclusion: 该统一模块化环境消除了组件重复实现，为系统分析四旋翼控制方法提供了实用工具，代码已开源。

Abstract: Robust adaptive control methods are essential for maintaining quadcopter
performance under external disturbances and model uncertainties. However,
fragmented evaluations across tasks, simulators, and implementations hinder
systematic comparison of these methods. This paper introduces an
easy-to-deploy, modular simulation testbed for quadcopter control, built on
RotorPy, that enables evaluation under a wide range of disturbances such as
wind, payload shifts, rotor faults, and control latency. The framework includes
a library of representative adaptive and non-adaptive controllers and provides
task-relevant metrics to assess tracking accuracy and robustness. The unified
modular environment enables reproducible evaluation across control methods and
eliminates redundant reimplementation of components such as disturbance models,
trajectory generators, and analysis tools. We illustrate the testbed's
versatility through examples spanning multiple disturbance scenarios and
trajectory types, including automated stress testing, to demonstrate its
utility for systematic analysis. Code is available at
https://github.com/Dz298/AdaptiveQuadBench.

</details>


### [5] [Destination-to-Chutes Task Mapping Optimization for Multi-Robot Coordination in Robotic Sorting Systems](https://arxiv.org/abs/2510.03472)
*Yulun Zhang,Alexandre O. G. Barbosa,Federico Pecora,Jiaoyang Li*

Main category: cs.RO

TL;DR: 本文研究机器人分拣系统中目的地到滑槽的任务映射优化问题，通过进化算法和混合整数线性规划方法提高系统吞吐量，并在不同系统设置下验证优化效果。


<details>
  <summary>Details</summary>
Motivation: 优化目的地到滑槽的任务映射对于提高机器人分拣系统吞吐量至关重要，但由于系统复杂性（包括机器人目标分配、路径规划、滑槽关闭时间以及下游处理影响）而具有挑战性。

Method: 使用进化算法和混合整数线性规划来优化任务映射，并开发了机器人分拣系统模拟器来评估不同映射方案。

Result: 优化的任务映射在各种系统设置（不同地图大小、滑槽数量和目的地）下均优于贪婪生成的映射，显著提高了系统吞吐量。

Conclusion: 通过质量多样性算法分析多样化的任务映射，证明了优化任务映射对机器人分拣系统性能的重要提升作用。

Abstract: We study optimizing a destination-to-chutes task mapping to improve
throughput in Robotic Sorting Systems (RSS), where a team of robots sort
packages on a sortation floor by transporting them from induct workstations to
eject chutes based on their shipping destinations (e.g. Los Angeles or
Pittsburgh). The destination-to-chutes task mapping is used to determine which
chutes a robot can drop its package. Finding a high-quality task mapping is
challenging because of the complexity of a real-world RSS. First, optimizing
task mapping is interdependent with robot target assignment and path planning.
Second, chutes will be CLOSED for a period of time once they receive sufficient
packages to allow for downstream processing. Third, task mapping quality
directly impacts the downstream processing, as scattered chutes for the same
destination increase package handling time. In this paper, we first formally
define task mappings and the problem of Task Mapping Optimization (TMO). We
then present a simulator of RSS to evaluate task mappings. We then present a
simple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear
Programming, demonstrating the advantage of our optimized task mappings over
the greedily generated ones in various RSS setups with different map sizes,
numbers of chutes, and destinations. Finally, we use Quality Diversity
algorithms to analyze the throughput of a diverse set of task mappings. Our
code is available online at https://github.com/lunjohnzhang/tmo_public.

</details>


### [6] [Robust Permissive Controller Synthesis for Interval MDPs](https://arxiv.org/abs/2510.03481)
*Khang Vo Huynh,David Parker,Lu Feng*

Main category: cs.RO

TL;DR: 提出首个针对区间马尔可夫决策过程(IMDPs)的鲁棒宽松控制器合成框架，保证所有符合合成多策略的策略在所有允许转移下满足可达性或基于奖励的规范。


<details>
  <summary>Details</summary>
Motivation: 解决机器人系统在不确定动态下的鲁棒控制问题，传统控制器合成方法通常产生单一确定性策略，限制了适应性。IMDPs通过区间转移概率捕捉感知噪声、执行不精确和系统抽象带来的认知不确定性。

Method: 将问题建模为混合整数线性规划(MILP)，提出两种编码方法：基于顶点枚举的基线方法和避免显式枚举的可扩展对偶方法。

Result: 在四个基准领域上的实验表明，两种方法都能合成鲁棒、最大宽松的控制器，并能扩展到具有数十万状态的大型IMDPs。

Conclusion: 该框架首次实现了IMDPs上的鲁棒宽松控制器合成，为机器人系统在不确定性下的灵活和弹性控制提供了有效解决方案。

Abstract: We address the problem of robust permissive controller synthesis for robots
operating under uncertain dynamics, modeled as Interval Markov Decision
Processes (IMDPs). IMDPs generalize standard MDPs by allowing transition
probabilities to vary within intervals, capturing epistemic uncertainty from
sensing noise, actuation imprecision, and coarse system abstractions-common in
robotics. Traditional controller synthesis typically yields a single
deterministic strategy, limiting adaptability. In contrast, permissive
controllers (multi-strategies) allow multiple actions per state, enabling
runtime flexibility and resilience. However, prior work on permissive
controller synthesis generally assumes exact transition probabilities, which is
unrealistic in many robotic applications. We present the first framework for
robust permissive controller synthesis on IMDPs, guaranteeing that all
strategies compliant with the synthesized multi-strategy satisfy reachability
or reward-based specifications under all admissible transitions. We formulate
the problem as mixed-integer linear programs (MILPs) and propose two encodings:
a baseline vertex-enumeration method and a scalable duality-based method that
avoids explicit enumeration. Experiments on four benchmark domains show that
both methods synthesize robust, maximally permissive controllers and scale to
large IMDPs with up to hundreds of thousands of states.

</details>


### [7] [Digital-Twin Evaluation for Proactive Human-Robot Collision Avoidance via Prediction-Guided A-RRT*](https://arxiv.org/abs/2510.03496)
*Vadivelan Murugesan,Rajasundaram Mathiazhagan,Sanjana Joshi,Aliasghar Arab*

Main category: cs.RO

TL;DR: 提出了一种基于预测的安全规划框架，通过数字孪生验证的细粒度人体运动预测来主动避免碰撞，实现了100%的避障成功率和亚秒级重规划。


<details>
  <summary>Details</summary>
Motivation: 人机协作需要长期精确预测人体运动以实现主动避碰，现有规划器仅依赖运动学模型存在局限性。

Method: 使用深度相机提取3D骨骼姿态，CNN-BiLSTM模型预测关节轨迹，胶囊基人工势场转换预测为碰撞风险指标，触发自适应RRT*规划器，通过数字孪生模型验证轨迹。

Result: 在50次试验中，实现了100%的主动避障，安全距离大于250毫米，重规划时间小于2秒。

Conclusion: 该方法通过预测性人体建模与数字孪生验证的结合，在精度和可靠性上优于仅基于运动学的规划器。

Abstract: Human-robot collaboration requires precise prediction of human motion over
extended horizons to enable proactive collision avoidance. Unlike existing
planners that rely solely on kinodynamic models, we present a prediction-driven
safe planning framework that leverages granular, joint-by-joint human motion
forecasting validated in a physics-based digital twin. A capsule-based
artificial potential field (APF) converts these granular predictions into
collision risk metrics, triggering an Adaptive RRT* (A-RRT*) planner when
thresholds are exceeded. The depth camera is used to extract 3D skeletal poses
and a convolutional neural network-bidirectional long short-term memory
(CNN-BiLSTM) model to predict individual joint trajectories ahead of time. A
digital twin model integrates real-time human posture prediction placed in
front of a simulated robot to evaluate motions and physical contacts. The
proposed method enables validation of planned trajectories ahead of time and
bridging potential latency gaps in updating planned trajectories in real-time.
In 50 trials, our method achieved 100% proactive avoidance with > 250 mm
clearance and sub-2 s replanning, demonstrating superior precision and
reliability compared to existing kinematic-only planners through the
integration of predictive human modeling with digital twin validation.

</details>


### [8] [Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning](https://arxiv.org/abs/2510.03504)
*Yutong Wang,Yichun Qu,Tengxiang Wang,Lishuo Pan,Nora Ayanian*

Main category: cs.RO

TL;DR: 提出了一种实时分布式多机器人导航框架，使用高阶控制屏障函数保证连接性，结合控制Lyapunov函数实现连接恢复，在障碍物丰富环境中提供鲁棒连接。


<details>
  <summary>Details</summary>
Motivation: 多机器人应用中保持连接性至关重要，但容易受到障碍物和视觉遮挡的影响而中断。

Method: 采用统一的MPC-CLF-CBF框架，通过Bezier参数化轨迹生成平滑曲线，结合高阶控制屏障函数控制机器人间距以保持连接，同时避免碰撞。

Result: 通过大量仿真和4架Crazyflie纳米四旋翼的物理实验验证了该框架的有效性。

Conclusion: 该框架能够在障碍物丰富的环境中为多机器人系统提供连接维护和恢复的连续时间轨迹生成与控制方法。

Abstract: Maintaining connectivity is crucial in many multi-robot applications, yet
fragile to obstacles and visual occlusions. We present a real-time distributed
framework for multi-robot navigation certified by high-order control barrier
functions (HOCBFs) that controls inter-robot proximity to maintain connectivity
while avoiding collisions. We incorporate control Lyapunov functions to enable
connectivity recovery from initial disconnected configurations and temporary
losses, providing robust connectivity during navigation in obstacle-rich
environments. Our trajectory generation framework concurrently produces
planning and control through a Bezier-parameterized trajectory, which naturally
provides smooth curves with arbitrary degree of derivatives. The main
contribution is the unified MPC-CLF-CBF framework, a continuous-time trajectory
generation and control method for connectivity maintenance and recovery of
multi-robot systems. We validate the framework through extensive simulations
and a physical experiment with 4 Crazyflie nano-quadrotors.

</details>


### [9] [LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy](https://arxiv.org/abs/2510.03529)
*Zekai Liang,Xiao Liang,Soofiyan Atar,Sreyan Das,Zoe Chiu,Peihan Zhang,Florian Richter,Shanglei Liu,Michael C. Yip*

Main category: cs.RO

TL;DR: LapSurgie是首个基于人形机器人的腹腔镜远程操作框架，通过逆向映射策略控制标准腹腔镜工具，无需额外设置即可实现精确的手到工具控制。


<details>
  <summary>Details</summary>
Motivation: 解决手术机器人系统在资源匮乏地区部署困难的问题，缩小医疗资源差距，利用人形机器人无需改造现有手术室环境的优势。

Method: 采用逆向映射策略控制手动腕式腹腔镜器械，遵守远程运动中心约束，配备立体视觉系统的控制台提供实时视觉反馈。

Result: 跨平台的综合用户研究证明了该框架的有效性，初步验证了人形机器人在腹腔镜手术中部署的可行性。

Conclusion: 人形机器人系统为将手术机器人技术扩展到资源匮乏地区提供了有前景的解决方案，LapSurgie框架展示了其实际应用潜力。

Abstract: Robotic laparoscopic surgery has gained increasing attention in recent years
for its potential to deliver more efficient and precise minimally invasive
procedures. However, adoption of surgical robotic platforms remains largely
confined to high-resource medical centers, exacerbating healthcare disparities
in rural and low-resource regions. To close this gap, a range of solutions has
been explored, from remote mentorship to fully remote telesurgery. Yet, the
practical deployment of surgical robotic systems to underserved communities
remains an unsolved challenge. Humanoid systems offer a promising path toward
deployability, as they can directly operate in environments designed for humans
without extensive infrastructure modifications -- including operating rooms. In
this work, we introduce LapSurgie, the first humanoid-robot-based laparoscopic
teleoperation framework. The system leverages an inverse-mapping strategy for
manual-wristed laparoscopic instruments that abides to remote center-of-motion
constraints, enabling precise hand-to-tool control of off-the-shelf surgical
laparoscopic tools without additional setup requirements. A control console
equipped with a stereo vision system provides real-time visual feedback.
Finally, a comprehensive user study across platforms demonstrates the
effectiveness of the proposed framework and provides initial evidence for the
feasibility of deploying humanoid robots in laparoscopic procedures.

</details>


### [10] [Efficient Surgical Robotic Instrument Pose Reconstruction in Real World Conditions Using Unified Feature Detection](https://arxiv.org/abs/2510.03532)
*Zekai Liang,Kazuya Miyata,Xiao Liang,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: 提出了一种新颖的相机-机器人标定框架，通过共享编码统一检测几何基元（关键点和轴边缘），在具有挑战性的手术环境中实现快速且最先进的精度。


<details>
  <summary>Details</summary>
Motivation: 微创手术机器人具有长运动链和部分自由度可见性，传统标定方法假设刚性机器人和良好可见性，难以应对这些挑战。现有方法在特征检测一致性或推理时间方面存在不足。

Method: 通过共享编码统一检测关键点和轴边缘几何基元，在单次推理中同时检测两者，使用大规模合成数据和投影标注进行训练，通过投影几何实现高效位姿估计。

Result: 在特征检测和位姿估计方面均进行了评估，定性和定量结果显示在挑战性手术环境中具有快速性能和最先进的精度。

Conclusion: 该框架在具有挑战性的手术环境中实现了快速且高精度的相机-机器人标定，解决了长运动链和部分可见性带来的问题。

Abstract: Accurate camera-to-robot calibration is essential for any vision-based
robotic control system and especially critical in minimally invasive surgical
robots, where instruments conduct precise micro-manipulations. However, MIS
robots have long kinematic chains and partial visibility of their degrees of
freedom in the camera, which introduces challenges for conventional
camera-to-robot calibration methods that assume stiff robots with good
visibility. Previous works have investigated both keypoint-based and
rendering-based approaches to address this challenge in real-world conditions;
however, they often struggle with consistent feature detection or have long
inference times, neither of which are ideal for online robot control. In this
work, we propose a novel framework that unifies the detection of geometric
primitives (keypoints and shaft edges) through a shared encoding, enabling
efficient pose estimation via projection geometry. This architecture detects
both keypoints and edges in a single inference and is trained on large-scale
synthetic data with projective labeling. This method is evaluated across both
feature detection and pose estimation, with qualitative and quantitative
results demonstrating fast performance and state-of-the-art accuracy in
challenging surgical environments.

</details>


### [11] [Shape-Space Graphs: Fast and Collision-Free Path Planning for Soft Robots](https://arxiv.org/abs/2510.03547)
*Carina Veil,Moritz Flaschel,Ellen Kuhl*

Main category: cs.RO

TL;DR: 提出了一种基于图搜索的软体机器人路径规划方法，通过预计算形状库和构建k近邻图，实现快速避障和能量高效的路径规划。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有极高的灵活性，但在杂乱环境中运动规划面临挑战，因为其高度非线性和无限维运动学特性。

Method: 使用生物力学模型预计算形状库，构建形状空间的k近邻图，利用符号距离函数修剪与障碍物碰撞的节点和边，定义基于几何距离和驱动力的多目标边成本。

Result: 算法能在毫秒级时间内从预计算图中可靠避障并生成可行路径，包含能量成本可显著减少驱动力需求（但会增加末端轨迹长度）。

Conclusion: 形状空间图搜索为软体机器人提供了快速可靠的路径规划方法，为手术、工业和辅助领域的实时应用铺平了道路。

Abstract: Soft robots, inspired by elephant trunks or octopus arms, offer extraordinary
flexibility to bend, twist, and elongate in ways that rigid robots cannot.
However, their motion planning remains a challenge, especially in cluttered
environments with obstacles, due to their highly nonlinear and
infinite-dimensional kinematics. Here, we present a graph-based path planning
tool for an elephant-trunk-inspired soft robotic arm designed with three
artificial muscle fibers that allow for multimodal continuous deformation
through contraction. Using a biomechanical model inspired by morphoelasticity
and active filament theory, we precompute a shape library and construct a
$k$-nearest neighbor graph in \emph{shape space}, ensuring that each node
corresponds to a mechanically accurate and physically valid robot shape. For
the graph, we use signed distance functions to prune nodes and edges colliding
with obstacles, and define multi-objective edge costs based on geometric
distance and actuation effort, enabling energy-efficient planning with
collision avoidance. We demonstrate that our algorithm reliably avoids
obstacles and generates feasible paths within milliseconds from precomputed
graphs using Dijkstra's algorithm. We show that including energy costs can
drastically reduce the actuation effort compared to geometry-only planning, at
the expense of longer tip trajectories. Our results highlight the potential of
shape-space graph search for fast and reliable path planning in the field of
soft robotics, paving the way for real-time applications in surgical,
industrial, and assistive settings.

</details>


### [12] [Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning](https://arxiv.org/abs/2510.03599)
*Shafeef Omar,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出了一个基于接触显式表示的统一多任务运动与操作策略学习框架，通过定义接触目标序列来统一任务描述，使单一策略能执行多种接触丰富的任务。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为不同任务设计不同策略，缺乏共享结构。本文旨在利用接触目标的共享特性，开发能处理多样化任务的统一策略框架。

Method: 使用目标条件强化学习训练策略来实现给定的接触计划，通过接触位置、时间和活动末端执行器的序列来定义任务。

Result: 在多种机器人形态和任务上验证了框架有效性：四足机器人多种步态、人形机器人双足和四足步态、双手物体操作任务，均由单一策略控制。

Conclusion: 显式接触推理显著提高了对未见场景的泛化能力，接触显式策略学习为可扩展的运动操作提供了有前景的基础。

Abstract: We present a unified framework for multi-task locomotion and manipulation
policy learning grounded in a contact-explicit representation. Instead of
designing different policies for different tasks, our approach unifies the
definition of a task through a sequence of contact goals-desired contact
positions, timings, and active end-effectors. This enables leveraging the
shared structure across diverse contact-rich tasks, leading to a single policy
that can perform a wide range of tasks. In particular, we train a
goal-conditioned reinforcement learning (RL) policy to realise given contact
plans. We validate our framework on multiple robotic embodiments and tasks: a
quadruped performing multiple gaits, a humanoid performing multiple biped and
quadrupedal gaits, and a humanoid executing different bimanual object
manipulation tasks. Each of these scenarios is controlled by a single policy
trained to execute different tasks grounded in contacts, demonstrating
versatile and robust behaviours across morphologically distinct systems. Our
results show that explicit contact reasoning significantly improves
generalisation to unseen scenarios, positioning contact-explicit policy
learning as a promising foundation for scalable loco-manipulation.

</details>


### [13] [Safety-Oriented Dynamic Path Planning for Automated Vehicles](https://arxiv.org/abs/2510.03640)
*Mostafa Emam,Matthias Gerdts*

Main category: cs.RO

TL;DR: 提出了一种用于自动驾驶车辆的双层控制框架，通过时间相关的障碍物网格投影增强道路边界，实现精确的自适应路径规划。主控制环使用非线性模型预测控制进行实时路径优化，并采用同伦约束松弛提高最优控制问题的可解性。同时运行独立备份环提供安全回退轨迹，增强系统安全性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中确保自动驾驶车辆的安全需要先进的路径规划和障碍物避让能力，特别是在复杂动态环境中实现实时安全控制。

Method: 采用双层控制框架：主控制环使用非线性模型预测控制(NMPC)进行实时路径优化，结合同伦约束松弛技术；独立备份环在主控制环无法及时计算最优轨迹时提供安全回退轨迹。通过时间相关的障碍物网格投影增强道路边界建模。

Result: 评估显示该方法在各种驾驶场景中表现出色，具有实时适用性和鲁棒性，能够有效处理动态环境中的路径规划和障碍物避让问题。

Conclusion: 该框架代表了在复杂动态环境中实现更安全、更可靠自动驾驶的重要进展，通过双层控制结构和实时优化技术显著提升了系统的安全性和性能。

Abstract: Ensuring safety in autonomous vehicles necessitates advanced path planning
and obstacle avoidance capabilities, particularly in dynamic environments. This
paper introduces a bi-level control framework that efficiently augments road
boundaries by incorporating time-dependent grid projections of obstacle
movements, thus enabling precise and adaptive path planning. The main control
loop utilizes Nonlinear Model Predictive Control (NMPC) for real-time path
optimization, wherein homotopy-based constraint relaxation is employed to
improve the solvability of the optimal control problem (OCP). Furthermore, an
independent backup loop runs concurrently to provide safe fallback trajectories
when an optimal trajectory cannot be computed by the main loop within a
critical time frame, thus enhancing safety and real-time performance. Our
evaluation showcases the benefits of the proposed methods in various driving
scenarios, highlighting the real-time applicability and robustness of our
approach. Overall, the framework represents a significant step towards safer
and more reliable autonomous driving in complex and dynamic environments.

</details>


### [14] [Geometrically Exact Hard Magneto-Elastic Cosserat Shells: Static Formulation for Shape Morphing](https://arxiv.org/abs/2510.03644)
*Mohammadjavad Javadi,Robin Chhabra*

Main category: cs.RO

TL;DR: 本文提出了一种基于Cosserat壳理论的硬磁壳静态模型，用于分析大宽长比的软磁机器人，解决了传统1D杆模型不适用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有Cosserat杆理论主要适用于1D细长结构，而现代软机器人（如抓取器和行走机器人）往往具有大宽长比，属于2D壳结构，需要新的建模方法。

Method: 基于特殊欧几里得群(SE(3))开发了坐标无关的Cosserat壳理论，将壳视为具有六自由度的2D流形，采用基于李群结构的局部变形梯度定义，推导了平衡方程的强形式和弱形式。

Result: 提出的有限元方法避免了壳结构建模中的奇点和锁定现象，在壳经历大旋转和位移时表现出优越的有效性，并通过测试案例进行了分析和实验验证。

Conclusion: 该模型为硬磁壳结构提供了一种高效的分析和形状变形控制方法，特别适用于大变形情况下的软磁机器人应用。

Abstract: Cosserat rod theory is the popular approach to modeling ferromagnetic soft
robots as 1-Dimensional (1D) slender structures in most applications, such as
biomedical. However, recent soft robots designed for locomotion and
manipulation often exhibit a large width-to-length ratio that categorizes them
as 2D shells. For analysis and shape-morphing control purposes, we develop an
efficient coordinate-free static model of hard-magnetic shells found in soft
magnetic grippers and walking soft robots. The approach is based on a novel
formulation of Cosserat shell theory on the Special Euclidean group
($\mathbf{SE}(3)$). The shell is assumed to be a 2D manifold of material points
with six degrees of freedom (position & rotation) suitable for capturing the
behavior of a uniformly distributed array of spheroidal hard magnetic particles
embedded in the rheological elastomer. The shell's configuration manifold is
the space of all smooth embeddings $\mathbb{R}^2\rightarrow\mathbf{SE}(3)$.
According to a novel definition of local deformation gradient based on the Lie
group structure of $\mathbf{SE}(3)$, we derive the strong and weak forms of
equilibrium equations, following the principle of virtual work. We extract the
linearized version of the weak form for numerical implementations. The
resulting finite element approach can avoid well-known challenges such as
singularity and locking phenomenon in modeling shell structures. The proposed
model is analytically and experimentally validated through a series of test
cases that demonstrate its superior efficacy, particularly when the shell
undergoes severe rotations and displacements.

</details>


### [15] [An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion](https://arxiv.org/abs/2510.03660)
*Mohammadjavad Javadi,Charlie Wadds,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种受尺蠖启发的完全无束缚软体机器人，通过磁力驱动实现多模态运动，包括行走、转向、游泳和有效载荷运输。


<details>
  <summary>Details</summary>
Motivation: 开发无束缚软体机器人对于在多样化、多任务环境中推进软体机器人系统的实际部署至关重要。

Method: 采用弯曲柔性结构，通过磁力驱动，配备紧凑轻量化的板载控制电路实现无线命令传输，集成摄像头进行环境感知。

Result: 机器人总质量102.63克，最大行走速度3.74厘米/秒，游泳速度0.82厘米/秒，成功实现了行走、转向、游泳和有效载荷运输功能。

Conclusion: 通过结构优化和系统级集成，该机器人能够在无需外部基础设施的情况下实现动态性能和运动能力，为软体机器人的实际应用提供了重要进展。

Abstract: Untethered soft robots are essential for advancing the real-world deployment
of soft robotic systems in diverse and multitasking environments. Inspired by
soft-bodied inchworm, we present a fully untethered soft robot with a curved,
flexible structure actuated by magnetic forces. The robot has a total mass of
102.63 g and demonstrates multimodal locomotion, achieving a maximum walking
speed of 3.74 cm/s and a swimming speed of 0.82 cm/s. A compact and lightweight
onboard control circuit enables wireless command transmission, while an
integrated camera provides environmental perception. Through structural
optimization and system-level integration, the robot successfully performs
walking, steering, swimming, and payload transport without reliance on external
infrastructure. The robot's dynamic performance and locomotion capabilities are
systematically validated through experimental characterization.

</details>


### [16] [Robust Visual Embodiment: How Robots Discover Their Bodies in Real Environments](https://arxiv.org/abs/2510.03677)
*Salim Rezvani,Ammar Jaleel Mahmood,Robin Chhabra*

Main category: cs.RO

TL;DR: 本文系统研究了视觉退化（模糊、椒盐噪声、高斯噪声）对机器人自建模的影响，并提出了任务感知去噪框架和语义分割方法，显著提升了自建模在真实环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自主建模管道在真实感知条件（如噪声图像和杂乱背景）下仍然脆弱，需要提升机器人视觉自建模在不可预测现实环境中的适应性。

Method: 引入任务感知去噪框架，结合经典恢复方法和形态保持约束；集成语义分割以从杂乱场景中稳健地分离机器人。

Result: 在仿真和物理实验中，该方法恢复了接近基准的性能，而现有管道显著退化。

Conclusion: 这些贡献推进了视觉自建模的鲁棒性，并为在不可预测现实环境中部署自感知机器人建立了实用基础。

Abstract: Robots with internal visual self-models promise unprecedented adaptability,
yet existing autonomous modeling pipelines remain fragile under realistic
sensing conditions such as noisy imagery and cluttered backgrounds. This paper
presents the first systematic study quantifying how visual
degradations--including blur, salt-and-pepper noise, and Gaussian noise--affect
robotic self-modeling. Through both simulation and physical experiments, we
demonstrate their impact on morphology prediction, trajectory planning, and
damage recovery in state-of-the-art pipelines. To overcome these challenges, we
introduce a task-aware denoising framework that couples classical restoration
with morphology-preserving constraints, ensuring retention of structural cues
critical for self-modeling. In addition, we integrate semantic segmentation to
robustly isolate robots from cluttered and colorful scenes. Extensive
experiments show that our approach restores near-baseline performance across
simulated and physical platforms, while existing pipelines degrade
significantly. These contributions advance the robustness of visual
self-modeling and establish practical foundations for deploying self-aware
robots in unpredictable real-world environments.

</details>


### [17] [EmbodiSwap for Zero-Shot Robot Imitation Learning](https://arxiv.org/abs/2510.03706)
*Eadom Dessalene,Pavan Mantripragada,Michael Maynord,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: EmbodiSwap是一种在人类视频上生成逼真机器人覆盖的方法，用于零样本模仿学习，通过V-JEPA视觉骨干网络在合成机器人视频上进行训练，在真实世界测试中达到82%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决在野外自我中心人类视频与目标机器人实体之间的实体化差距问题，实现零样本模仿学习。

Method: 使用EmbodiSwap在人类视频上生成逼真的机器人覆盖，将V-JEPA视觉骨干网络从视频理解领域重新用于在合成机器人视频上进行模仿学习。

Result: 在真实世界测试中，零样本训练的V-JEPA模型达到82%的成功率，优于few-shot训练的π₀网络以及基于EmbodiSwap数据训练的π₀网络。

Conclusion: EmbodiSwap方法有效，V-JEPA在机器人视觉任务中表现优于传统视觉骨干网络，发布了相关代码、数据集和模型以促进可重复研究。

Abstract: We introduce EmbodiSwap - a method for producing photorealistic synthetic
robot overlays over human video. We employ EmbodiSwap for zero-shot imitation
learning, bridging the embodiment gap between in-the-wild ego-centric human
video and a target robot embodiment. We train a closed-loop robot manipulation
policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a
visual backbone, repurposing V-JEPA from the domain of video understanding to
imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms
alternative vision backbones more conventionally used within robotics. In
real-world tests, our zero-shot trained V-JEPA model achieves an $82\%$ success
rate, outperforming a few-shot trained $\pi_0$ network as well as $\pi_0$
trained over data produced by EmbodiSwap. We release (i) code for generating
the synthetic robot overlays which takes as input human videos and an arbitrary
robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize
over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference
code, to facilitate reproducible research and broader adoption.

</details>


### [18] [Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics](https://arxiv.org/abs/2510.03768)
*Aydin Ahmadi,Baris Akgun*

Main category: cs.RO

TL;DR: 提出基于学习的模型预测控制框架，使用单一GRU模型处理多种桌面推动任务，无需重新训练即可实现精确定位、轨迹跟踪和避障等功能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的平面推动方法功能单一（如侧向切换、精确定位或单任务训练），限制了更广泛的应用。需要一种通用框架来支持多种任务。

Method: 采用基于GRU的循环架构和非线性层学习物体-环境动力学，结合MPPI模型预测控制生成自适应动作。使用领域随机化训练支持仿真到实物的迁移。

Result: 在仿真和真实实验中展示了高精确定位成功率、强轨迹跟踪性能和避障能力。通过改变控制器目标函数即可解决不同任务，无需重新训练模型。

Conclusion: 该框架成功实现了单一模型处理多种推动任务的能力，支持可变推动长度和不同目标，为机器人非抓取操作提供了灵活有效的解决方案。

Abstract: Data-driven planar pushing methods have recently gained attention as they
reduce manual engineering effort and improve generalization compared to
analytical approaches. However, most prior work targets narrow capabilities
(e.g., side switching, precision, or single-task training), limiting broader
applicability. We present a model-based framework for non-prehensile tabletop
pushing that uses a single learned model to address multiple tasks without
retraining. Our approach employs a recurrent GRU-based architecture with
additional non-linear layers to capture object-environment dynamics while
ensuring stability. A tailored state-action representation enables the model to
generalize across uncertain dynamics, variable push lengths, and diverse tasks.
For control, we integrate the learned dynamics with a sampling-based Model
Predictive Path Integral (MPPI) controller, which generates adaptive,
task-oriented actions. This framework supports side switching, variable-length
pushes, and objectives such as precise positioning, trajectory following, and
obstacle avoidance. Training is performed in simulation with domain
randomization to support sim-to-real transfer. We first evaluate the
architecture through ablation studies, showing improved prediction accuracy and
stable rollouts. We then validate the full system in simulation and real-world
experiments using a Franka Panda robot with markerless tracking. Results
demonstrate high success rates in precise positioning under strict thresholds
and strong performance in trajectory tracking and obstacle avoidance. Moreover,
multiple tasks are solved simply by changing the controller's objective
function, without retraining. While our current focus is on a single object
type, we extend the framework by training on wider push lengths and designing a
balanced controller that reduces the number of steps for longer-horizon goals.

</details>


### [19] [Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets](https://arxiv.org/abs/2510.03776)
*Tiago Rodrigues de Almeida,Yufei Zhu,Andrey Rudenko,Tomasz P. Kucner,Johannes A. Stork,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 该论文研究了类别条件轨迹预测方法，在机器人学和室外数据集上评估了基于模式和深度学习的基线方法，发现在考虑类别标签时能提高预测准确性，特别是在数据不平衡或有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 在复杂动态环境中，机器人需要预测周围智能体的未来动作和意图以实现高效导航和避碰。由于智能体的动态特性取决于其任务、角色或可观察标签，类别条件运动预测成为减少预测不确定性和提高异构智能体预测准确性的有前景方法。

Method: 提出了基于条件模式的高效深度学习基线方法，并在THÖR-MAGNI和斯坦福无人机数据集上评估了不同的类别条件轨迹预测方法。

Result: 实验表明，在考虑类别标签时，所有方法在大多数设置下都能提高准确性。深度学习在平衡数据集上表现更好，但在数据有限或类别不平衡的应用中，基于模式的方法可能更优。

Conclusion: 类别条件轨迹预测能显著提高预测性能，特别是在数据不平衡或新环境中数据不足的情况下。方法选择应基于数据集特性和应用场景，深度学习适合平衡数据集，模式方法适合数据有限场景。

Abstract: Robots and other intelligent systems navigating in complex dynamic
environments should predict future actions and intentions of surrounding agents
to reach their goals efficiently and avoid collisions. The dynamics of those
agents strongly depends on their tasks, roles, or observable labels.
Class-conditioned motion prediction is thus an appealing way to reduce forecast
uncertainty and get more accurate predictions for heterogeneous agents.
However, this is hardly explored in the prior art, especially for mobile robots
and in limited data applications. In this paper, we analyse different
class-conditioned trajectory prediction methods on two datasets. We propose a
set of conditional pattern-based and efficient deep learning-based baselines,
and evaluate their performance on robotics and outdoors datasets (TH\"OR-MAGNI
and Stanford Drone Dataset). Our experiments show that all methods improve
accuracy in most of the settings when considering class labels. More
importantly, we observe that there are significant differences when learning
from imbalanced datasets, or in new environments where sufficient data is not
available. In particular, we find that deep learning methods perform better on
balanced datasets, but in applications with limited data, e.g., cold start of a
robot in a new environment, or imbalanced classes, pattern-based methods may be
preferable.

</details>


### [20] [COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments](https://arxiv.org/abs/2510.03875)
*Niranjan Kumar Ilampooranan,Constantinos Chamzas*

Main category: cs.RO

TL;DR: COVER是一个在准静态环境中构建覆盖验证路线图的框架，通过分区障碍物配置空间并验证每个分区内的可行性，为机器人系统提供固定时间内的运动规划保证。


<details>
  <summary>Details</summary>
Motivation: 在准静态环境中，大多数障碍物保持静态但部分障碍物可能变化，这种结构化变异性可以系统性地利用，为运动规划问题提供比一般情况更强的保证。现有方法要么缺乏形式化保证，要么依赖限制性的障碍物配置离散化，限制了在实际领域的应用。

Method: COVER框架增量构建覆盖验证路线图，通过分区障碍物配置空间并在每个分区内求解可行路径，系统验证路线图在每个分区内的可行性，保证在已验证区域内实现固定时间运动规划查询。

Result: 在7自由度模拟Panda机器人执行桌面和货架任务的验证中，COVER比先前工作实现了更广泛的覆盖范围和更高的查询成功率。

Conclusion: COVER框架能够有效处理准静态环境中的运动规划问题，提供形式化保证并优于现有方法，适用于实际机器人部署场景。

Abstract: Having the ability to answer motion-planning queries within a fixed time
budget is critical for the widespread deployment of robotic systems.
Semi-static environments, where most obstacles remain static but a limited set
can vary across queries, exhibit structured variability that can be
systematically exploited to provide stronger guarantees than in general
motion-planning problems. However, prior approaches in this setting either lack
formal guarantees or rely on restrictive discretizations of obstacle
configurations, limiting their applicability in realistic domains. This paper
introduces COVER, a novel framework that incrementally constructs a
coverage-verified roadmap in semi-static environments. By partitioning the
obstacle configuration space and solving for feasible paths within each
partition, COVER systematically verifies feasibility of the roadmap in each
partition and guarantees fixed-time motion planning queries within the verified
regions. We validate COVER with a 7-DOF simulated Panda robot performing table
and shelf tasks, demonstrating that COVER achieves broader coverage with higher
query success rates than prior works.

</details>


### [21] [Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning](https://arxiv.org/abs/2510.03885)
*Sunghwan Kim,Woojeh Chung,Zhirui Dai,Dwait Bhatt,Arth Shukla,Hao Su,Yulun Tian,Nikolay Atanasov*

Main category: cs.RO

TL;DR: SBP提出了一种基于3D潜在地图的移动操作策略，相比仅依赖图像的策略具有更强的空间和时间推理能力，在场景级移动操作和顺序桌面操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的策略缺乏全局场景理解和长期记忆能力，无法有效处理需要空间推理和长期观察的任务。

Method: SBP构建端到端策略学习框架，通过多视角观察增量融合到场景特定的潜在特征网格中，使用预训练解码器重建目标嵌入，并利用3D特征聚合器获取全局上下文。

Result: SBP在分布内和未见场景中均优于基于图像的策略，在顺序操作任务中成功率提高25%，能够进行全局场景推理并利用地图作为长期记忆。

Conclusion: 3D潜在地图为移动操作提供了更强的空间和时间推理能力，是实现复杂场景理解和长期任务执行的有效方法。

Abstract: In this paper, we demonstrate that mobile manipulation policies utilizing a
3D latent map achieve stronger spatial and temporal reasoning than policies
relying solely on images. We introduce Seeing the Bigger Picture (SBP), an
end-to-end policy learning approach that operates directly on a 3D map of
latent features. In SBP, the map extends perception beyond the robot's current
field of view and aggregates observations over long horizons. Our mapping
approach incrementally fuses multiview observations into a grid of
scene-specific latent features. A pre-trained, scene-agnostic decoder
reconstructs target embeddings from these features and enables online
optimization of the map features during task execution. A policy, trainable
with behavior cloning or reinforcement learning, treats the latent map as a
state variable and uses global context from the map obtained via a 3D feature
aggregator. We evaluate SBP on scene-level mobile manipulation and sequential
tabletop manipulation tasks. Our experiments demonstrate that SBP (i) reasons
globally over the scene, (ii) leverages the map as long-horizon memory, and
(iii) outperforms image-based policies in both in-distribution and novel
scenes, e.g., improving the success rate by 25% for the sequential manipulation
task.

</details>


### [22] [NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation](https://arxiv.org/abs/2510.03895)
*Zheng Huang,Mingyu Liu,Xiaoyi Lin,Muzhi Zhu,Canyu Zhao,Zongze Du,Xiaoman Li,Yiduo Jia,Hao Zhong,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 提出了NoTVLA框架，通过稀疏轨迹规划解决VLA模型的灾难性遗忘问题，在计算效率、零样本泛化和多任务性能方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在现实部署中面临的灾难性遗忘问题，该问题源于对连续动作序列的过度依赖导致的知识隔离。

Method: 采用稀疏轨迹规划策略，聚焦机器人末端执行器轨迹而非目标物体轨迹，通过时间压缩和空间推理剪枝，使用稀疏轨迹而非密集动作轨迹进行训练。

Result: 在多任务评估中，NoTVLA性能优于pi0，计算资源消耗降低一个数量级，无需腕部摄像头，操作精度接近单任务专家模型，保持语言能力并支持零样本泛化。

Conclusion: NoTVLA框架有效解决了VLA模型的灾难性遗忘问题，实现了高效的多任务学习和跨平台部署，为具身智能的实际应用提供了可行方案。

Abstract: Vision-Language-Action (VLA) models represent a pivotal advance in embodied
intelligence, yet they confront critical barriers to real-world deployment,
most notably catastrophic forgetting. This issue stems from their overreliance
on continuous action sequences or action chunks, which inadvertently create
isolated data silos that disrupt knowledge retention across tasks. To tackle
these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA)
framework: a novel approach that narrows its focus to sparse trajectories,
thereby avoiding the catastrophic forgetting associated with dense trajectory
fine-tuning. A key innovation of NoTVLA lies in its trajectory planning
strategy: instead of centering on the target object's trajectory, it leverages
temporal compression and spatial reasoning pruning specifically for the robot
end effector's trajectory. Furthermore, training is conducted using these
sparse trajectories rather than dense action trajectories, an optimization that
delivers remarkable practical advantages with better performance in zero-shot.
In multi-task evaluation scenarios, NoTVLA achieves superior performance and
generalization compared to pi0 while operating under two critical constraints:
it uses over an order of magnitude less computing power than pi0 and requires
no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy
closely approximates that of single-task expert models. Crucially, it also
preserves the model's inherent language capabilities, enabling zero-shot
generalization in specific scenarios, supporting unified model deployment
across multiple robot platforms, and fostering a degree of generalization even
when perceiving tasks from novel perspectives.

</details>


### [23] [WAFFLE: A Wearable Approach to Bite Timing Estimation in Robot-Assisted Feeding](https://arxiv.org/abs/2510.03910)
*Akhil Padmanabha,Jessie Yuan,Tanisha Mehta,Rajat Kumar Jenamani,Eric Hu,Victoria de León,Anthony Wertz,Janavi Gupta,Ben Dodson,Yunting Yan,Carmel Majidi,Tapomayukh Bhattacharjee,Zackory Erickson*

Main category: cs.RO

TL;DR: WAFFLE是一个基于可穿戴传感器的喂食系统，通过学习用户自然行为（如头部移动、咀嚼和说话）来准确预测咬合时机，提高喂食机器人的反应性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决喂食机器人广泛采用的技术挑战，特别是准确估计咬合时机的问题，以增强残障人士的自主性和生活质量，减轻护理人员负担。

Method: 使用可穿戴传感器数据训练监督回归模型预测咬合时机，结合用户可调节的主动性阈值将预测转换为继续或停止指令。

Result: 在15名无运动障碍参与者的研究中，WAFFLE在控制感、机器人理解和工作量等指标上表现优于或与基线方法相当，大多数参与者更喜欢WAFFLE。在2名运动障碍参与者的家庭环境中也验证了其泛化能力。

Conclusion: WAFFLE能够实现自然、反应灵敏的咬合时机预测，适用于不同用户、机器人硬件、位置、喂食轨迹、食物类型以及个人和社交用餐场景。

Abstract: Millions of people around the world need assistance with feeding. Robotic
feeding systems offer the potential to enhance autonomy and quality of life for
individuals with impairments and reduce caregiver workload. However, their
widespread adoption has been limited by technical challenges such as estimating
bite timing, the appropriate moment for the robot to transfer food to a user's
mouth. In this work, we introduce WAFFLE: Wearable Approach For Feeding with
LEarned bite timing, a system that accurately predicts bite timing by
leveraging wearable sensor data to be highly reactive to natural user cues such
as head movements, chewing, and talking. We train a supervised regression model
on bite timing data from 14 participants and incorporate a user-adjustable
assertiveness threshold to convert predictions into proceed or stop commands.
In a study with 15 participants without motor impairments with the Obi feeding
robot, WAFFLE performs statistically on par with or better than baseline
methods across measures of feeling of control, robot understanding, and
workload, and is preferred by the majority of participants for both individual
and social dining. We further demonstrate WAFFLE's generalizability in a study
with 2 participants with motor impairments in their home environments using a
Kinova 7DOF robot. Our findings support WAFFLE's effectiveness in enabling
natural, reactive bite timing that generalizes across users, robot hardware,
robot positioning, feeding trajectories, foods, and both individual and social
dining contexts.

</details>


### [24] [TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry](https://arxiv.org/abs/2510.03919)
*Matthew Lisondra,Junseo Kim,Glenn Takashi Shimoda,Kourosh Zareinia,Sajad Saeedi*

Main category: cs.RO

TL;DR: TCB-VIO是一个基于多状态约束卡尔曼滤波的紧耦合6自由度视觉惯性里程计系统，在250FPS高帧率和400Hz IMU频率下运行，在FPSP传感器上实现，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决视觉惯性里程计中视觉位姿估计带来的空间漂移和惯性测量带来的时间漂移问题，利用FPSP传感器的高帧率特性来匹配IMU的高频输出。

Method: 使用多状态约束卡尔曼滤波(MSCKF)实现紧耦合6自由度VIO，在FPSP传感器上以250FPS高帧率运行，IMU测量频率为400Hz。

Result: TCB-VIO在性能上超越了当前最先进的方法，包括ROVIO、VINS-Mono和ORB-SLAM3。

Conclusion: 在FPSP传感器上实现高帧率VIO系统能有效减少空间和时间漂移，TCB-VIO展示了优越的性能表现。

Abstract: Vision algorithms can be executed directly on the image sensor when
implemented on the next-generation sensors known as focal-plane
sensor-processor arrays (FPSP)s, where every pixel has a processor. FPSPs
greatly improve latency, reducing the problems associated with the bottleneck
of data transfer from a vision sensor to a processor. FPSPs accelerate
vision-based algorithms such as visual-inertial odometry (VIO). However, VIO
frameworks suffer from spatial drift due to the vision-based pose estimation,
whilst temporal drift arises from the inertial measurements. FPSPs circumvent
the spatial drift by operating at a high frame rate to match the high-frequency
output of the inertial measurements. In this paper, we present TCB-VIO, a
tightly-coupled 6 degrees-of-freedom VIO by a Multi-State Constraint Kalman
Filter (MSCKF), operating at a high frame-rate of 250 FPS and from IMU
measurements obtained at 400 Hz. TCB-VIO outperforms state-of-the-art methods:
ROVIO, VINS-Mono, and ORB-SLAM3.

</details>


### [25] [A Real-Time Framework for Intermediate Map Construction and Kinematically Feasible Off-Road Planning Without OSM](https://arxiv.org/abs/2510.03948)
*Otobong Jerome,Geesara Prathap Kulathunga,Devitt Dmitry,Eugene Murawjow,Alexandr Klimchik*

Main category: cs.RO

TL;DR: 提出了一种专门针对越野环境的全局路径规划方法，通过构建中间地图、图路径规划、运动学可行性检查和路径平滑三个子问题，在保证实时性能的同时确保运动学可行性和内存效率。


<details>
  <summary>Details</summary>
Motivation: 传统全局路径规划方法在越野环境中表现不佳，无法处理大规模地图，且忽略了实时性能、运动学可行性和内存效率等关键因素。

Method: 首先在像素坐标系中构建包含地理特征的中间地图，然后将规划问题分解为图路径规划、运动学可行性检查和路径平滑三个子问题。

Result: 在多种越野环境中测试，地图规模达数平方公里，平均1.5秒找到可行路径，极端条件下内存使用约1.5GB。

Conclusion: 该方法框架通用性强，适用于搜救任务和农业作业等多种越野自主导航任务。

Abstract: Off-road environments present unique challenges for autonomous navigation due
to their complex and unstructured nature. Traditional global path-planning
methods, which typically aim to minimize path length and travel time, perform
poorly on large-scale maps and fail to account for critical factors such as
real-time performance, kinematic feasibility, and memory efficiency. This paper
introduces a novel global path-planning method specifically designed for
off-road environments, addressing these essential factors. The method begins by
constructing an intermediate map within the pixel coordinate system,
incorporating geographical features like off-road trails, waterways, restricted
and passable areas, and trees. The planning problem is then divided into three
sub-problems: graph-based path planning, kinematic feasibility checking, and
path smoothing. This approach effectively meets real-time performance
requirements while ensuring kinematic feasibility and efficient memory use. The
method was tested in various off-road environments with large-scale maps up to
several square kilometers in size, successfully identifying feasible paths in
an average of 1.5 seconds and utilizing approximately 1.5GB of memory under
extreme conditions. The proposed framework is versatile and applicable to a
wide range of off-road autonomous navigation tasks, including search and rescue
missions and agricultural operations.

</details>


### [26] [SITCOM: Scaling Inference-Time COMpute for VLAs](https://arxiv.org/abs/2510.04041)
*Ayudh Saxena,Harsh Shah,Sandeep Routray,Rishi Rajesh Shah,Esha Pahwa*

Main category: cs.RO

TL;DR: SITCOM框架通过模型预测控制增强预训练的视觉-语言-动作模型，利用学习到的动力学模型进行多步动作推演来选择最佳执行计划，显著提升长时域任务的完成率。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在动态任务中缺乏前瞻性机制和累积误差的问题，提升机器人控制的鲁棒性和长时域规划能力。

Method: 结合模型预测控制思想，使用基于Transformer的动力学模型进行多步动作推演，并通过模拟器奖励对候选轨迹进行评分选择。

Result: 在SIMPLER环境中，SITCOM结合良好奖励函数可将任务完成率从48%提升至72%。

Conclusion: SITCOM成功将一次性VLA模型转变为鲁棒的长时域规划器，显著提高了机器人控制性能。

Abstract: Learning robust robotic control policies remains a major challenge due to the
high cost of collecting labeled data, limited generalization to unseen
environments, and difficulties in planning over long horizons. While
Vision-Language-Action (VLA) models offer a promising solution by grounding
natural language instructions into single-step control commands, they often
lack mechanisms for lookahead and struggle with compounding errors in dynamic
tasks. In this project, we introduce Scaling Inference-Time COMpute for VLAs
(SITCOM), a framework that augments any pretrained VLA with model-based
rollouts and reward-based trajectory selection, inspired by Model Predictive
Control algorithm. SITCOM leverages a learned dynamics model to simulate
multi-step action rollouts to select the best candidate plan for real-world
execution, transforming one-shot VLAs into robust long-horizon planners. We
develop an efficient transformer-based dynamics model trained on large-scale
BridgeV2 data and fine-tuned on SIMPLER environments to bridge the Real2Sim
gap, and score candidate rollouts using rewards from simulator. Through
comprehensive evaluation across multiple tasks and settings in the SIMPLER
environment, we demonstrate that SITCOM when combined with a good reward
function can significantly improve task completion rate from 48% to 72% using
trained dynamics model.

</details>


### [27] [Feedback Matters: Augmenting Autonomous Dissection with Visual and Topological Feedback](https://arxiv.org/abs/2510.04074)
*Chung-Pang Wang,Changwei Chen,Xiao Liang,Soofiyan Atar,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 提出了一种用于自主组织解剖的反馈驱动框架，通过内窥镜图像推理拓扑变化，结合可见性度量和最优控制器设计，显著提升手术自主性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有手术机器人反馈机制在处理组织解剖的拓扑和感知挑战方面存在局限，需要能够适应动态环境变化的反馈系统。

Method: 提出反馈驱动框架，通过内窥镜图像分析拓扑变化，引入可见性度量量化组织暴露程度，设计最优控制器主动操纵组织以最大化可见性，并与规划和基于学习的方法集成。

Result: 实验证明该反馈机制显著增强了自主性，减少了错误，在复杂手术场景中提高了鲁棒性。

Conclusion: 反馈机制对于自主手术系统在动态环境中适应组织特性和视觉线索变化至关重要，提出的框架有效解决了现有方法的局限性。

Abstract: Autonomous surgical systems must adapt to highly dynamic environments where
tissue properties and visual cues evolve rapidly. Central to such adaptability
is feedback: the ability to sense, interpret, and respond to changes during
execution. While feedback mechanisms have been explored in surgical robotics,
ranging from tool and tissue tracking to error detection, existing methods
remain limited in handling the topological and perceptual challenges of tissue
dissection. In this work, we propose a feedback-enabled framework for
autonomous tissue dissection that explicitly reasons about topological changes
from endoscopic images after each dissection action. This structured feedback
guides subsequent actions, enabling the system to localize dissection progress
and adapt policies online. To improve the reliability of such feedback, we
introduce visibility metrics that quantify tissue exposure and formulate
optimal controller designs that actively manipulate tissue to maximize
visibility. Finally, we integrate these feedback mechanisms with both
planning-based and learning-based dissection methods, and demonstrate
experimentally that they significantly enhance autonomy, reduce errors, and
improve robustness in complex surgical scenarios.

</details>


### [28] [From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents](https://arxiv.org/abs/2510.04076)
*Amin Vahidi-Moghaddam,Sayed Pedram Haeri Boroujeni,Iman Jebellat,Ehsan Jebellat,Niloufar Mehrabi,Zhaojian Li*

Main category: cs.RO

TL;DR: 本文综述了现代控制应用中数据驱动控制策略面临的挑战，特别是计算复杂度和响应速度问题，并提出了八种降低计算复杂度的技术方法。


<details>
  <summary>Details</summary>
Motivation: 现代控制应用（如机器人和车辆运动控制）需要准确、快速且安全的运动控制。虽然数据驱动方法（如MPC、RL、DeePC和LLM代理）能减少对精确模型的依赖，但它们通常存在响应慢、计算需求高和内存占用大的问题，限制了在实时系统中的应用。

Method: 提出了八种降低计算复杂度的技术：降阶建模、函数逼近策略学习和凸松弛等方法，并在真实应用场景（机械臂、软体机器人、车辆运动控制）中进行验证。

Result: 这些方法在实际应用中表现出有效性，能够显著降低计算复杂度，使数据驱动控制策略更适合具有快速动态、有限计算资源或严格内存约束的实时系统。

Conclusion: 通过提出的八种技术方法，成功解决了数据驱动控制策略在实时应用中的计算复杂度问题，为在资源受限系统中部署高性能控制策略提供了可行方案。

Abstract: One of the main challenges in modern control applications, particularly in
robot and vehicle motion control, is achieving accurate, fast, and safe
movement. To address this, optimal control policies have been developed to
enforce safety while ensuring high performance. Since basic first-principles
models of real systems are often available, model-based controllers are widely
used. Model predictive control (MPC) is a leading approach that optimizes
performance while explicitly handling safety constraints. However, obtaining
accurate models for complex systems is difficult, which motivates data-driven
alternatives. ML-based MPC leverages learned models to reduce reliance on
hand-crafted dynamics, while reinforcement learning (RL) can learn near-optimal
policies directly from interaction data. Data-enabled predictive control
(DeePC) goes further by bypassing modeling altogether, directly learning safe
policies from raw input-output data. Recently, large language model (LLM)
agents have also emerged, translating natural language instructions into
structured formulations of optimal control problems. Despite these advances,
data-driven policies face significant limitations. They often suffer from slow
response times, high computational demands, and large memory needs, making them
less practical for real-world systems with fast dynamics, limited onboard
computing, or strict memory constraints. To address this, various technique,
such as reduced-order modeling, function-approximated policy learning, and
convex relaxations, have been proposed to reduce computational complexity. In
this paper, we present eight such approaches and demonstrate their
effectiveness across real-world applications, including robotic arms, soft
robots, and vehicle motion control.

</details>


### [29] [HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments](https://arxiv.org/abs/2510.04161)
*Longrui Yang,Yiyu Wang,Jingfan Tang,Yunpeng Lv,Shizhe Zhao,Chao Cao,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 提出HEHA框架解决异构机器人自主探索路径规划问题，通过分层规划和PEAF路由算法最小化最大路径长度，实验显示比基线方法减少30%探索时间。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人（无人机、轮式、腿式机器人）在未知环境中探索时的智能分配问题，需要考虑不同机器人的地形通过能力约束，这是一个需要快速迭代求解的大规模约束优化问题。

Method: 提出HEHA分层探索框架：全局规划使用PEAF（部分随时焦点搜索）路由算法快速找到有界次优解；局部规划考虑异构性避免重复探索。

Result: 实验结果表明，HEHA相比基线方法能够减少高达30%的探索时间。

Conclusion: HEHA框架通过分层规划和PEAF算法有效解决了异构机器人探索中的路径规划问题，显著提升了探索效率。

Abstract: This paper considers the path planning problem for autonomous exploration of
an unknown environment using multiple heterogeneous robots such as drones,
wheeled, and legged robots, which have different capabilities to traverse
complex terrains. A key challenge there is to intelligently allocate the robots
to the unknown areas to be explored and determine the visiting order of those
spaces subject to traversablity constraints, which leads to a large scale
constrained optimization problem that needs to be quickly and iteratively
solved every time when new space are explored. To address the challenge, we
propose HEHA (Hierarchical Exploration with Heterogeneous Agents) by leveraging
a recent hierarchical method that decompose the exploration into global
planning and local planning. The major contribution in HEHA is its global
planning, where we propose a new routing algorithm PEAF (Partial Anytime Focal
search) that can quickly find bounded sub-optimal solutions to minimize the
maximum path length among the agents subject to traversability constraints.
Additionally, the local planner in HEHA also considers heterogeneity to avoid
repeated and duplicated exploration among the robots. The experimental results
show that, our HEHA can reduce up to 30% of the exploration time than the
baselines.

</details>


### [30] [Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation](https://arxiv.org/abs/2510.04168)
*Amirmasoud Molaei,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 提出了一种完全数据驱动的控制框架，使用强化学习实现挖掘机自主抓取岩石，无需对岩石或土壤属性进行显式建模。


<details>
  <summary>Details</summary>
Motivation: 传统挖掘机抓取岩石需要熟练操作员，现有自主挖掘方法主要针对连续介质或依赖专用夹具，难以应用于真实建筑工地的非结构化环境。

Method: 在AGX Dynamics模拟器中使用PPO算法训练模型无关的强化学习智能体，通过广泛的领域随机化增强鲁棒性，直接输出关节速度命令控制挖掘机。

Result: 学习到的策略能够很好地泛化到未见过的岩石和不同土壤条件，实现了与人类参与者相当的高成功率，同时保持机器稳定性。

Conclusion: 证明了基于学习的方法可以在不需要专用硬件或详细材料模型的情况下，实现离散物体操作的可行性。

Abstract: Rock capturing with standard excavator buckets is a challenging task
typically requiring the expertise of skilled operators. Unlike soil digging, it
involves manipulating large, irregular rocks in unstructured environments where
complex contact interactions with granular material make model-based control
impractical. Existing autonomous excavation methods focus mainly on continuous
media or rely on specialized grippers, limiting their applicability to
real-world construction sites. This paper introduces a fully data-driven
control framework for rock capturing that eliminates the need for explicit
modeling of rock or soil properties. A model-free reinforcement learning agent
is trained in the AGX Dynamics simulator using the Proximal Policy Optimization
(PPO) algorithm and a guiding reward formulation. The learned policy outputs
joint velocity commands directly to the boom, arm, and bucket of a CAT365
excavator model. Robustness is enhanced through extensive domain randomization
of rock geometry, density, and mass, as well as the initial configurations of
the bucket, rock, and goal position. To the best of our knowledge, this is the
first study to develop and evaluate an RL-based controller for the rock
capturing task. Experimental results show that the policy generalizes well to
unseen rocks and varying soil conditions, achieving high success rates
comparable to those of human participants while maintaining machine stability.
These findings demonstrate the feasibility of learning-based excavation
strategies for discrete object manipulation without requiring specialized
hardware or detailed material models.

</details>


### [31] [VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs](https://arxiv.org/abs/2510.04171)
*Lakshadeep Naik,Adam Fischer,Daniel Duberg,Danica Kragic*

Main category: cs.RO

TL;DR: VBM-NET是一个基于学习的移动机器人基座姿态选择方法，使用俯视正交投影和强化学习来优化抓取任务中的基座位置规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖精确的状态信息（如物体位姿和环境模型），但在实际应用中这些信息往往不可靠。本文研究直接从场景的俯视正交投影进行基座姿态规划，提供全局视角并保持空间结构。

Method: 使用等变TransporterNet利用空间对称性高效学习候选基座姿态，采用图神经网络表示可变数量的候选姿态，并通过强化学习从中选择最优基座姿态。

Result: VBM-NET能在显著减少计算时间的情况下产生与传统方法相当的解决方案，并在仿真到实物的迁移中成功部署到真实移动操作任务中。

Conclusion: 该方法证明了直接从视觉输入进行基座姿态规划的有效性，实现了高效的计算性能和成功的仿真到实物迁移。

Abstract: In Mobile Manipulation, selecting an optimal mobile base pose is essential
for successful object grasping. Previous works have addressed this problem
either through classical planning methods or by learning state-based policies.
They assume access to reliable state information, such as the precise object
poses and environment models. In this work, we study base pose planning
directly from top-down orthographic projections of the scene, which provide a
global overview of the scene while preserving spatial structure. We propose
VBM-NET, a learning-based method for base pose selection using such top-down
orthographic projections. We use equivariant TransporterNet to exploit spatial
symmetries and efficiently learn candidate base poses for grasping. Further, we
use graph neural networks to represent a varying number of candidate base poses
and use Reinforcement Learning to determine the optimal base pose among them.
We show that VBM-NET can produce comparable solutions to the classical methods
in significantly less computation time. Furthermore, we validate sim-to-real
transfer by successfully deploying a policy trained in simulation to real-world
mobile manipulation.

</details>


### [32] [Using Robotics to Improve Transcatheter Edge-to-Edge Repair of the Mitral Valve](https://arxiv.org/abs/2510.04178)
*Léa Pistorius,Namrata U. Nayar,Phillip Tran,Sammy Elmariah,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 本文研究使用机器人系统辅助经导管二尖瓣修复手术，通过游戏控制器实现直观的关节控制，相比手动操作能减少手术时间和运动误差，提高夹子放置精度。


<details>
  <summary>Details</summary>
Motivation: 经导管瓣膜修复手术面临机械限制和陡峭的学习曲线挑战，需要更可靠和用户友好的平台来改善手术效果。

Method: 将临床修复设备的复杂手柄控制替换为通过游戏控制器实现的直观机器人关节控制，在心脏和血管系统的体模模型中分析手动与机器人性能，比较手术时间和夹子放置精度等指标。

Result: 机器人系统能够减少手术时间和运动误差，同时提高夹子放置的准确性。

Conclusion: 机器人辅助可以解决手动系统的关键限制，为复杂的经导管手术提供更可靠和用户友好的平台。

Abstract: Transcatheter valve repair presents significant challenges due to the
mechanical limitations and steep learning curve associated with manual catheter
systems. This paper investigates the use of robotics to facilitate
transcatheter procedures in the context of mitral valve edge-to-edge repair.
The complex handle-based control of a clinical repair device is replaced by
intuitive robotic joint-based control via a game controller. Manual versus
robotic performance is analyzed by decomposing the overall device delivery task
into motion-specific steps and comparing capabilities on a step-by-step basis
in a phantom model of the heart and vasculature. Metrics include procedure
duration and clip placement accuracy. Results demonstrate that the robotic
system can reduce procedural time and motion errors while also improving
accuracy of clip placement. These findings suggest that robotic assistance can
address key limitations of manual systems, offering a more reliable and
user-friendly platform for complex transcatheter procedures.

</details>


### [33] [Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification](https://arxiv.org/abs/2510.04190)
*Jian-jie Zheng,Chih-kai Yang,Po-han Chen,Lyn Chao-ling Chen*

Main category: cs.RO

TL;DR: 该研究开发了一个使用GPT-4o多模态模型进行实时车牌识别和非法停车检测的社交巡逻机器人系统，能够在室内停车场自动导航并发送Line消息通知管理员。


<details>
  <summary>Details</summary>
Motivation: 解决停车场非法停车问题，通过社交机器人提供实时监控和通知服务，验证多模态深度学习方法在车牌识别中的有效性。

Method: 采用GPT-4o多模态模型进行车牌识别，无需预处理；机器人自动调整摄像头角度捕捉车牌图像，在模拟停车场环境中进行导航实验。

Result: 实现了高精度的车牌识别，能够实时检测非法停车并立即通过Line消息通知系统管理员。

Conclusion: 该工作验证了新型多模态深度学习方法在车牌识别中的高准确性，提供了可在真实场景中解决问题的社交辅助机器人，适用于室内停车场应用。

Abstract: In the study, the social robot act as a patrol to recognize and notify
illegal parking in real-time. Dual-model pipeline method and large multimodal
model were compared, and the GPT-4o multimodal model was adopted in license
plate recognition without preprocessing. For moving smoothly on a flat ground,
the robot navigated in a simulated parking lot in the experiments. The robot
changes angle view of the camera automatically to capture the images around
with the format of license plate number. From the captured images of the robot,
the numbers on the plate are recognized through the GPT-4o model, and
identifies legality of the numbers. When an illegal parking is detected, the
robot sends Line messages to the system manager immediately. The contribution
of the work is that a novel multimodal deep learning method has validated with
high accuracy in license plate recognition, and a social assistive robot is
also provided for solving problems in a real scenario, and can be applied in an
indoor parking lot.

</details>


### [34] [Flexible Locomotion Learning with Diffusion Model Predictive Control](https://arxiv.org/abs/2510.04234)
*Runhan Huang,Haldun Balim,Heng Yang,Yilun Du*

Main category: cs.RO

TL;DR: 提出Diffusion-MPC方法，利用学习的生成扩散模型作为规划中的近似动力学先验，通过奖励和约束优化实现灵活的测试时适应


<details>
  <summary>Details</summary>
Motivation: 腿式运动需要既鲁棒又适应性强的控制器，但模型自由强化学习方法难以适应新行为，而经典MPC依赖精确动力学模型

Method: 使用扩散模型作为动力学先验进行规划，在反向步骤中结合奖励规划和约束投影，并通过交互式训练算法更新去噪器

Result: 在真实世界中验证了Diffusion-MPC，展示了强大的运动能力和灵活的适应性

Conclusion: Diffusion-MPC实现了强大的测试时适应性，允许规划器在不重新训练的情况下适应新的奖励规范

Abstract: Legged locomotion demands controllers that are both robust and adaptable,
while remaining compatible with task and safety considerations. However,
model-free reinforcement learning (RL) methods often yield a fixed policy that
can be difficult to adapt to new behaviors at test time. In contrast, Model
Predictive Control (MPC) provides a natural approach to flexible behavior
synthesis by incorporating different objectives and constraints directly into
its optimization process. However, classical MPC relies on accurate dynamics
models, which are often difficult to obtain in complex environments and
typically require simplifying assumptions. We present Diffusion-MPC, which
leverages a learned generative diffusion model as an approximate dynamics prior
for planning, enabling flexible test-time adaptation through reward and
constraint based optimization. Diffusion-MPC jointly predicts future states and
actions; at each reverse step, we incorporate reward planning and impose
constraint projection, yielding trajectories that satisfy task objectives while
remaining within physical limits. To obtain a planning model that adapts beyond
imitation pretraining, we introduce an interactive training algorithm for
diffusion based planner: we execute our reward-and-constraint planner in
environment, then filter and reweight the collected trajectories by their
realized returns before updating the denoiser. Our design enables strong
test-time adaptability, allowing the planner to adjust to new reward
specifications without retraining. We validate Diffusion-MPC on real world,
demonstrating strong locomotion and flexible adaptation.

</details>


### [35] [ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context](https://arxiv.org/abs/2510.04246)
*Huiwon Jang,Sihyun Yu,Heeseung Kwon,Hojin Jeon,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: ContextVLA是一种通过有效利用多帧观测来提升机器人任务性能的策略模型，它将过去观测压缩为单个上下文token，在保持多帧训练优势的同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法在使用多帧观测时性能提升不一致，而视觉-语言-动作模型(VLA)能更有效地利用多帧观测生成动作，但视频输入的高维度带来了显著的计算开销。

Method: 提出ContextVLA模型，将过去观测压缩为单个上下文token，使策略能够高效利用时间上下文生成动作，同时减少训练和推理时间。

Result: 实验表明ContextVLA相比单帧VLA持续改进，实现了完整多帧训练的优势，但训练和推理时间更短。

Conclusion: ContextVLA通过压缩多帧观测为上下文token，在保持性能优势的同时有效解决了VLA模型的计算效率问题。

Abstract: Leveraging temporal context is crucial for success in partially observable
robotic tasks. However, prior work in behavior cloning has demonstrated
inconsistent performance gains when using multi-frame observations. In this
paper, we introduce ContextVLA, a policy model that robustly improves robotic
task performance by effectively leveraging multi-frame observations. Our
approach is motivated by the key observation that Vision-Language-Action models
(VLA), i.e., policy models built upon a Vision-Language Model (VLM), more
effectively utilize multi-frame observations for action generation. This
suggests that VLMs' inherent temporal understanding capability enables them to
extract more meaningful context from multi-frame observations. However, the
high dimensionality of video inputs introduces significant computational
overhead, making VLA training and inference inefficient. To address this,
ContextVLA compresses past observations into a single context token, allowing
the policy to efficiently leverage temporal context for action generation. Our
experiments show that ContextVLA consistently improves over single-frame VLAs
and achieves the benefits of full multi-frame training but with reduced
training and inference times.

</details>


### [36] [Integrated Planning and Control on Manifolds: Factor Graph Representation and Toolkit](https://arxiv.org/abs/2510.04278)
*Peiwen Yang,Weisong Wen,Runqiu Yang,Yuanyuan Zhang,Jiahao Hu,Yingming Chen,Naigui Xiao,Jiaqi Zhao*

Main category: cs.RO

TL;DR: FactorMPC是一个基于因子图的MPC工具包，专门处理非线性流形上的系统控制问题，通过统一系统动力学、约束和目标到模块化优化结构中，实现实时性能和安全关键应用。


<details>
  <summary>Details</summary>
Motivation: 传统MPC在非线性流形系统（如机器人姿态动力学）中存在奇点、过参数化和收敛困难等问题，需要几何一致且高效的解决方案。

Method: 采用因子图方法，支持流形值状态和切空间高斯不确定性建模，设计基于速度扩展流形控制屏障函数的避障因子，实现模块化优化结构。

Result: 在四旋翼无人机上的仿真和实验结果表明，相比基线方法具有更优的轨迹跟踪和避障性能，实现实时高性能控制。

Conclusion: FactorMPC通过连接图模型与安全关键MPC，为集成规划与控制提供了可扩展且几何一致的框架，并提供了开源实现。

Abstract: Model predictive control (MPC) faces significant limitations when applied to
systems evolving on nonlinear manifolds, such as robotic attitude dynamics and
constrained motion planning, where traditional Euclidean formulations struggle
with singularities, over-parameterization, and poor convergence. To overcome
these challenges, this paper introduces FactorMPC, a factor-graph based MPC
toolkit that unifies system dynamics, constraints, and objectives into a
modular, user-friendly, and efficient optimization structure. Our approach
natively supports manifold-valued states with Gaussian uncertainties modeled in
tangent spaces. By exploiting the sparsity and probabilistic structure of
factor graphs, the toolkit achieves real-time performance even for
high-dimensional systems with complex constraints. The velocity-extended
on-manifold control barrier function (CBF)-based obstacle avoidance factors are
designed for safety-critical applications. By bridging graphical models with
safety-critical MPC, our work offers a scalable and geometrically consistent
framework for integrated planning and control. The simulations and experimental
results on the quadrotor demonstrate superior trajectory tracking and obstacle
avoidance performance compared to baseline methods. To foster research
reproducibility, we have provided open-source implementation offering
plug-and-play factors.

</details>


### [37] [Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation](https://arxiv.org/abs/2510.04353)
*Stephen McCrory,Romeo Orsolino,Dhruv Thanki,Luigi Penco,Robert Griffin*

Main category: cs.RO

TL;DR: 提出了一种基于质心稳定性的重定向方法，在遥操作过程中动态调整接触点和姿态，以增强在复杂接触场景下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 遥操作在涉及手部接触和非共面表面的复杂场景中面临挑战，容易导致电机扭矩饱和或通过滑动失去稳定性。

Method: 采用高效的质心稳定性梯度解析计算方法，识别对稳定性敏感的遥操作设定点，并局部调整这些设定点。

Result: 在仿真和硬件实验中验证了该框架，展示了稳定性裕度的提升，并且更高的稳定性裕度与更好的脉冲抗性和关节扭矩裕度相关。

Conclusion: 所提出的稳定性重定向方法有效提高了人形机器人在复杂接触场景下的稳定性和鲁棒性。

Abstract: Teleoperation is a powerful method to generate reference motions and enable
humanoid robots to perform a broad range of tasks. However, teleoperation
becomes challenging when using hand contacts and non-coplanar surfaces, often
leading to motor torque saturation or loss of stability through slipping. We
propose a centroidal stability-based retargeting method that dynamically
adjusts contact points and posture during teleoperation to enhance stability in
these difficult scenarios. Central to our approach is an efficient analytical
calculation of the stability margin gradient. This gradient is used to identify
scenarios for which stability is highly sensitive to teleoperation setpoints
and inform the local adjustment of these setpoints. We validate the framework
in simulation and hardware by teleoperating manipulation tasks on a humanoid,
demonstrating increased stability margins. We also demonstrate empirically that
higher stability margins correlate with improved impulse resilience and joint
torque margin.

</details>


### [38] [Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators](https://arxiv.org/abs/2510.04354)
*Apurva Badithela,David Snyder,Lihan Zha,Joseph Mikhail,Matthew O'Kelly,Anushri Dixit,Anirudha Majumdar*

Main category: cs.RO

TL;DR: SureSim框架通过结合大规模仿真和小规模真实世界测试，为机器人策略性能提供可靠的统计推断，可节省20-25%的硬件评估成本。


<details>
  <summary>Details</summary>
Motivation: 当前机器人策略评估通常依赖少量硬件试验，缺乏统计保证，需要更可靠的评估方法。

Method: 将真实与仿真评估结合问题形式化为预测驱动的推理问题，使用少量配对真实和仿真评估来纠正大规模仿真的偏差，并利用非渐近均值估计算法提供策略性能的置信区间。

Result: 在物理仿真中评估扩散策略和多任务微调策略，该方法可节省20-25%的硬件评估工作量，同时获得相似的性能边界。

Conclusion: SureSim框架能够有效结合仿真和真实测试，为机器人策略性能评估提供统计可靠的推断，显著降低硬件测试成本。

Abstract: Rapid progress in imitation learning, foundation models, and large-scale
datasets has led to robot manipulation policies that generalize to a wide-range
of tasks and environments. However, rigorous evaluation of these policies
remains a challenge. Typically in practice, robot policies are often evaluated
on a small number of hardware trials without any statistical assurances. We
present SureSim, a framework to augment large-scale simulation with relatively
small-scale real-world testing to provide reliable inferences on the real-world
performance of a policy. Our key idea is to formalize the problem of combining
real and simulation evaluations as a prediction-powered inference problem, in
which a small number of paired real and simulation evaluations are used to
rectify bias in large-scale simulation. We then leverage non-asymptotic mean
estimation algorithms to provide confidence intervals on mean policy
performance. Using physics-based simulation, we evaluate both diffusion policy
and multi-task fine-tuned \(\pi_0\) on a joint distribution of objects and
initial conditions, and find that our approach saves over \(20-25\%\) of
hardware evaluation effort to achieve similar bounds on policy performance.

</details>


### [39] [PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization](https://arxiv.org/abs/2510.04436)
*Jushan Chen,Santiago Paternain*

Main category: cs.RO

TL;DR: 提出了一种基于模型扩散的直接轨迹优化方法，通过无梯度投影机制确保动态可行性，在四旋翼无人机导航任务中实现了零动态可行性误差和4倍成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的轨迹优化方法采用单次射击方式，无法显式约束状态并经常导致次优解，特别是在处理非线性等式约束（动态可行性）方面存在挑战。

Method: 提出直接轨迹优化方法，通过模型扩散直接生成状态序列，在反向扩散过程中融入无梯度投影机制来确保动态可行性。

Result: 相比现有最优基线方法，在四旋翼无人机航点导航场景中实现了零动态可行性误差和约4倍的成功率提升。

Conclusion: 所提出的基于模型扩散的直接轨迹优化方法能有效处理非线性等式约束，显著提高轨迹优化的动态可行性和成功率。

Abstract: Recently, diffusion models have gained popularity and attention in trajectory
optimization due to their capability of modeling multi-modal probability
distributions. However, addressing nonlinear equality constraints, i.e, dynamic
feasi- bility, remains a great challenge in diffusion-based trajectory
optimization. Recent diffusion-based trajectory optimization frameworks rely on
a single-shooting style approach where the denoised control sequence is applied
to forward propagate the dynamical system, which cannot explicitly enforce
constraints on the states and frequently leads to sub-optimal solutions. In
this work, we propose a novel direct trajectory optimization approach via
model-based diffusion, which directly generates a sequence of states. To ensure
dynamic feasibility, we propose a gradient-free projection mechanism that is
incorporated into the reverse diffusion process. Our results show that,
compared to a recent state-of-the-art baseline, our approach leads to zero
dynamic feasibility error and approximately 4x higher success rate in a
quadrotor waypoint navigation scenario involving dense static obstacles.

</details>


### [40] [Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads](https://arxiv.org/abs/2510.04509)
*Huanqing Wang,Kaixiang Zhang,Kyungjoon Lee,Yu Mei,Vaibhav Srivastava,Jun Sheng,Ziyou Song,Zhaojian Li*

Main category: cs.RO

TL;DR: 提出了一种新颖的速度形式数据驱动预测控制框架，用于在未知负载下实现软体机器人的鲁棒和最优控制。


<details>
  <summary>Details</summary>
Motivation: 在物体操作任务中，未知的外部负载和干扰会显著改变系统动力学和行为，导致偏移误差和控制性能下降。

Method: 利用增量表示的输入输出数据来减轻未知负载引起的性能下降，无需加权数据集或干扰估计器。

Result: 在平面软体机器人上进行了实验验证，证明其在涉及未知负载的场景中相比标准DeePC具有优越性能。

Conclusion: 所提出的速度形式DeePC框架能够有效处理未知负载，提高软体机器人的控制鲁棒性。

Abstract: Data-driven control methods such as data-enabled predictive control (DeePC)
have shown strong potential in efficient control of soft robots without
explicit parametric models. However, in object manipulation tasks, unknown
external payloads and disturbances can significantly alter the system dynamics
and behavior, leading to offset error and degraded control performance. In this
paper, we present a novel velocity-form DeePC framework that achieves robust
and optimal control of soft robots under unknown payloads. The proposed
framework leverages input-output data in an incremental representation to
mitigate performance degradation induced by unknown payloads, eliminating the
need for weighted datasets or disturbance estimators. We validate the method
experimentally on a planar soft robot and demonstrate its superior performance
compared to standard DeePC in scenarios involving unknown payloads.

</details>


### [41] [Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation](https://arxiv.org/abs/2510.04585)
*Jianshu Zhou,Jing Shu,Tianle Pan,Puchen Zhu,Jiajun An,Huayu Zhang,Junda Huang,Upinder Kaur,Xin Ma,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种结合分布式表面吸附和内部颗粒堵塞的软体抓取器，能够跨尺度和跨状态（固体和液体）抓取物体，无需气密密封。


<details>
  <summary>Details</summary>
Motivation: 解决软体机器人中单一抓取器处理不同尺寸和物理状态（固体和液体）物体的基本挑战。

Method: 集成分布式表面吸附与内部颗粒堵塞，结合液体检测和压力反馈的触觉感知框架，以及基于触觉推断的抓取模式选择算法。

Result: 能够抓取从0.2 mm²到62,000 mm²的物体，比自身接触面积小3500倍和大88倍，在水下抓取、易碎物体处理和液体捕获等任务中表现稳健可重复。

Conclusion: 这是首个使用统一柔性架构可靠抓取跨尺度固体和液体物体的软体抓取器。

Abstract: Grasping objects across vastly different sizes and physical states-including
both solids and liquids-with a single robotic gripper remains a fundamental
challenge in soft robotics. We present the Everything-Grasping (EG) Gripper, a
soft end-effector that synergistically integrates distributed surface suction
with internal granular jamming, enabling cross-scale and cross-state
manipulation without requiring airtight sealing at the contact interface with
target objects. The EG Gripper can handle objects with surface areas ranging
from sub-millimeter scale 0.2 mm2 (glass bead) to over 62,000 mm2 (A4 sized
paper and woven bag), enabling manipulation of objects nearly 3,500X smaller
and 88X larger than its own contact area (approximated at 707 mm2 for a 30
mm-diameter base). We further introduce a tactile sensing framework that
combines liquid detection and pressure-based suction feedback, enabling
real-time differentiation between solid and liquid targets. Guided by the
actile-Inferred Grasping Mode Selection (TIGMS) algorithm, the gripper
autonomously selects grasping modes based on distributed pressure and voltage
signals. Experiments across diverse tasks-including underwater grasping,
fragile object handling, and liquid capture-demonstrate robust and repeatable
performance. To our knowledge, this is the first soft gripper to reliably grasp
both solid and liquid objects across scales using a unified compliant
architecture.

</details>


### [42] [MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation](https://arxiv.org/abs/2510.04592)
*Yilin Mei,Peng Qiu,Wei Zhang,WenChao Zhang,Wenjie Song*

Main category: cs.RO

TL;DR: MobRT是一个基于数字孪生的框架，用于生成移动机械臂复杂全身任务的多样化演示数据，显著提升策略泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 移动机械臂需要在动态、部分可观察的高维环境中协调基座移动和手臂操作，但高质量演示数据收集困难，导致现有研究多局限于简单桌面场景。

Method: 通过虚拟运动学控制和全身运动规划集成，自主生成多样化和真实的演示，模拟与铰接物体交互和移动基座拾放操作两类复杂任务。

Result: 在多个基线算法上评估生成数据质量，建立综合基准，实验表明任务成功率与生成轨迹数量强相关，模拟和真实世界演示显著提升策略性能。

Conclusion: MobRT框架有效解决了移动机械臂演示数据稀缺问题，实现了在模拟和真实环境中的鲁棒性能，推动了移动操作领域的发展。

Abstract: Recent advances in robotics have been largely driven by imitation learning,
which depends critically on large-scale, high-quality demonstration data.
However, collecting such data remains a significant challenge-particularly for
mobile manipulators, which must coordinate base locomotion and arm manipulation
in high-dimensional, dynamic, and partially observable environments.
Consequently, most existing research remains focused on simpler tabletop
scenarios, leaving mobile manipulation relatively underexplored. To bridge this
gap, we present \textit{MobRT}, a digital twin-based framework designed to
simulate two primary categories of complex, whole-body tasks: interaction with
articulated objects (e.g., opening doors and drawers) and mobile-base
pick-and-place operations. \textit{MobRT} autonomously generates diverse and
realistic demonstrations through the integration of virtual kinematic control
and whole-body motion planning, enabling coherent and physically consistent
execution. We evaluate the quality of \textit{MobRT}-generated data across
multiple baseline algorithms, establishing a comprehensive benchmark and
demonstrating a strong correlation between task success and the number of
generated trajectories. Experiments integrating both simulated and real-world
demonstrations confirm that our approach markedly improves policy
generalization and performance, achieving robust results in both simulated and
real-world environments.

</details>


### [43] [OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS](https://arxiv.org/abs/2510.04612)
*Simon Boche,Jaehyung Jung,Sebastián Barbas Laina,Stefan Leutenegger*

Main category: cs.RO

TL;DR: OKVIS2-X是一个先进的多传感器SLAM系统，能够构建密集体素占用地图，在大规模环境中实时运行，并在多个基准测试中达到最先进的精度。


<details>
  <summary>Details</summary>
Motivation: 为移动机器人提供可用的地图以及最高的状态估计精度和鲁棒性，通过统一框架集成多种传感器模态，并采用密集体素地图表示来充分利用深度或距离感知能力。

Method: 采用高效子地图策略实现大规模环境扩展，通过地图对齐因子紧密耦合估计器和子地图，支持在线相机外参标定，集成视觉、惯性、深度、LiDAR和GNSS等多种传感器。

Result: 在EuRoC数据集中达到最高轨迹精度，在Hilti22 VI-only基准中超越所有竞争对手，在LiDAR版本中具有竞争力，在VBR数据集的大规模序列中展示出最先进精度。

Conclusion: OKVIS2-X是一个功能强大且可扩展的多传感器SLAM系统，能够生成全局一致的地图，直接适用于自主导航任务，在各种基准测试中表现出优越性能。

Abstract: To empower mobile robots with usable maps as well as highest state estimation
accuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor
Simultaneous Localization and Mapping (SLAM) system building dense volumetric
occupancy maps, while scalable to large environments and operating in realtime.
Our unified SLAM framework seamlessly integrates different sensor modalities:
visual, inertial, measured or learned depth, LiDAR and Global Navigation
Satellite System (GNSS) measurements. Unlike most state-of-the-art SLAM
systems, we advocate using dense volumetric map representations when leveraging
depth or range-sensing capabilities. We employ an efficient submapping strategy
that allows our system to scale to large environments, showcased in sequences
of up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by
tightly-coupling the estimator and submaps through map alignment factors. Our
system provides globally consistent maps, directly usable for autonomous
navigation. To further improve the accuracy of OKVIS2-X, we also incorporate
the option of performing online calibration of camera extrinsics. Our system
achieves the highest trajectory accuracy in EuRoC against state-of-the-art
alternatives, outperforms all competitors in the Hilti22 VI-only benchmark,
while also proving competitive in the LiDAR version, and showcases state of the
art accuracy in the diverse and large-scale sequences from the VBR dataset.

</details>


### [44] [Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies](https://arxiv.org/abs/2510.04692)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.RO

TL;DR: 开发了一个仿生机器人平台，模拟雌性波斑鸨的形态和外观，用于野外生态研究和动物保护。


<details>
  <summary>Details</summary>
Motivation: 研究野生鸟类行为面临挑战，需要高度逼真的形态、耐用的户外操作和适应非受控环境的智能感知能力。

Method: 采用全数字化可复制制造流程，包括高分辨率结构光3D扫描、参数化CAD建模、关节式3D打印和逼真UV纹理乙烯基饰面，结合六轮摇臂底盘和嵌入式NVIDIA Jetson模块实现实时感知和自主视觉伺服。

Result: 沙漠鸟舍现场试验显示，系统能以15-22 FPS实时运行，延迟低于100毫秒，并能引发活体波斑鸨的自然识别和互动反应。

Conclusion: 该集成框架通过结合可复制的数字制造、具身视觉智能和生态验证，推进了仿生野外机器人技术，为动物-机器人交互研究、保护机器人和公众参与提供了可转移的蓝图。

Abstract: Biomimetic intelligence and robotics are transforming field ecology by
enabling lifelike robotic surrogates that interact naturally with animals under
real world conditions. Studying avian behavior in the wild remains challenging
due to the need for highly realistic morphology, durable outdoor operation, and
intelligent perception that can adapt to uncontrolled environments. We present
a next generation bio inspired robotic platform that replicates the morphology
and visual appearance of the female Houbara bustard to support controlled
ethological studies and conservation oriented field research. The system
introduces a fully digitally replicable fabrication workflow that combines high
resolution structured light 3D scanning, parametric CAD modelling, articulated
3D printing, and photorealistic UV textured vinyl finishing to achieve
anatomically accurate and durable robotic surrogates. A six wheeled rocker
bogie chassis ensures stable mobility on sand and irregular terrain, while an
embedded NVIDIA Jetson module enables real time RGB and thermal perception,
lightweight YOLO based detection, and an autonomous visual servoing loop that
aligns the robot's head toward detected targets without human intervention. A
lightweight thermal visible fusion module enhances perception in low light
conditions. Field trials in desert aviaries demonstrated reliable real time
operation at 15 to 22 FPS with latency under 100 ms and confirmed that the
platform elicits natural recognition and interactive responses from live
Houbara bustards under harsh outdoor conditions. This integrated framework
advances biomimetic field robotics by uniting reproducible digital fabrication,
embodied visual intelligence, and ecological validation, providing a
transferable blueprint for animal robot interaction research, conservation
robotics, and public engagement.

</details>


### [45] [Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly](https://arxiv.org/abs/2510.04696)
*Alexander L. Mitchell,Joe Watson,Ingmar Posner*

Main category: cs.RO

TL;DR: 提出了一种基于梯度的分散式框架，使用自适应势函数的自动组合来生成分段连续能量函数，用于解决双臂装配中的快速重规划问题。


<details>
  <summary>Details</summary>
Motivation: 双臂装配面临高层序列规划、多机器人协调和接触丰富的操作等挑战。传统任务与运动规划方法在需要新任务序列时收敛缓慢，且显式定义任务序列限制了重规划时的灵活性。

Method: 使用自适应势函数自动组合构建分段连续能量函数，通过近视优化而非长视距规划生成子目标，实现快速重规划。

Result: 该方法能够扩展到物理双臂装配任务，构建紧密公差装配件，并自发产生自动重试、协调运动和自主交接行为。

Conclusion: 基于梯度的快速重规划框架通过能量函数的结构和自适应性，有效解决了长视距任务，在紧密公差装配中表现出色。

Abstract: There are many challenges in bimanual assembly, including high-level
sequencing, multi-robot coordination, and low-level, contact-rich operations
such as component mating. Task and motion planning (TAMP) methods, while
effective in this domain, may be prohibitively slow to converge when adapting
to disturbances that require new task sequencing and optimisation. These events
are common during tight-tolerance assembly, where difficult-to-model dynamics
such as friction or deformation require rapid replanning and reattempts.
Moreover, defining explicit task sequences for assembly can be cumbersome,
limiting flexibility when task replanning is required. To simplify this
planning, we introduce a decentralised gradient-based framework that uses a
piecewise continuous energy function through the automatic composition of
adaptive potential functions. This approach generates sub-goals using only
myopic optimisation, rather than long-horizon planning. It demonstrates
effectiveness at solving long-horizon tasks due to the structure and adaptivity
of the energy function. We show that our approach scales to physical bimanual
assembly tasks for constructing tight-tolerance assemblies. In these
experiments, we discover that our gradient-based rapid replanning framework
generates automatic retries, coordinated motions and autonomous handovers in an
emergent fashion.

</details>


### [46] [Performance-guided Task-specific Optimization for Multirotor Design](https://arxiv.org/abs/2510.04724)
*Etor Arza,Welf Rehberg,Philipp Weiss,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习、贝叶斯优化和协方差矩阵自适应进化策略的多旋翼微型飞行器任务特定设计优化方法，通过闭环性能优化电机姿态配置，在敏捷航点导航任务中优于传统设计。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼设计通常采用标准配置，缺乏针对特定任务的优化。本文旨在开发一种系统化方法，仅基于闭环任务性能来优化飞行器设计。

Method: 结合强化学习、贝叶斯优化和协方差矩阵自适应进化策略，在考虑可制造性约束和最小空气动力学干扰的前提下，系统探索电机姿态配置的设计空间。

Result: 优化设计在敏捷航点导航任务中表现出优于传统多旋翼配置的性能，甚至超越了文献中的全驱动设计。通过实际建造和测试验证了模拟到现实的迁移能力。

Conclusion: 该方法能够有效优化多旋翼飞行器的任务特定设计，通过闭环性能指导的设计优化可以产生超越传统配置的性能表现，且具有良好的现实应用可行性。

Abstract: This paper introduces a methodology for task-specific design optimization of
multirotor Micro Aerial Vehicles. By leveraging reinforcement learning,
Bayesian optimization, and covariance matrix adaptation evolution strategy, we
optimize aerial robot designs guided exclusively by their closed-loop
performance in a considered task. Our approach systematically explores the
design space of motor pose configurations while ensuring manufacturability
constraints and minimal aerodynamic interference. Results demonstrate that
optimized designs achieve superior performance compared to conventional
multirotor configurations in agile waypoint navigation tasks, including against
fully actuated designs from the literature. We build and test one of the
optimized designs in the real world to validate the sim2real transferability of
our approach.

</details>


### [47] [Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy](https://arxiv.org/abs/2510.04774)
*Weixu Zhu,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: SoNS为机器人群体提供了行为设计简便性和全局配置估计，能够自动请求外部LLM生成代码以解决任务卡顿问题，在6个真实机器人和30+模拟机器人中达到85%任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人群体在任务执行过程中容易卡顿的问题，同时简化群体行为设计流程，实现群体配置和环境的全局感知。

Method: 采用自组织神经系统(SoNS)架构，当群体卡顿时自动向外部大型语言模型(LLM)请求生成代码并即时执行。

Result: 在6个真实机器人和超过30个模拟机器人的实验中，系统能够自动生成代码解决卡顿问题，任务完成成功率达到85%。

Conclusion: SoNS结合LLM代码生成能够有效提升机器人群体在复杂环境中的自主性和任务完成能力。

Abstract: Our recently introduced self-organizing nervous system (SoNS) provides robot
swarms with 1) ease of behavior design and 2) global estimation of the swarm
configuration and its collective environment, facilitating the implementation
of online automatic code generation for robot swarms. In a demonstration with 6
real robots and simulation trials with >30 robots, we show that when a
SoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code
generated by an external LLM on the fly, completing its mission with an 85%
success rate.

</details>


### [48] [TAG-K: Tail-Averaged Greedy Kaczmarz for Computationally Efficient and Performant Online Inertial Parameter Estimation](https://arxiv.org/abs/2510.04839)
*Shuo Sha,Anupam Bhakta,Zhenyuan Jiang,Kevin Qiu,Ishaan Mahajan,Gabriel Bravo,Brian Plancher*

Main category: cs.RO

TL;DR: TAG-K是一种轻量级的Kaczmarz方法扩展，结合贪心随机行选择和尾部平均，用于在线惯性参数估计，在动态环境中实现快速稳定的参数适应。


<details>
  <summary>Details</summary>
Motivation: 传统方法如递归最小二乘法和卡尔曼滤波器在跟踪突变参数变化时表现不佳或计算成本高，限制了在动态环境和计算受限机器人系统中的有效性。

Method: TAG-K结合贪心随机行选择实现快速收敛，使用尾部平均在噪声和不一致性下保持鲁棒性，同时保持Kaczmarz框架的低每迭代复杂度。

Result: 在合成基准测试和四旋翼跟踪任务中，TAG-K在笔记本电脑CPU上实现1.5x-1.9x更快的求解时间，在嵌入式微控制器上实现4.8x-20.7x更快的求解时间，同时提高对测量噪声的鲁棒性，估计误差减少25%，端到端跟踪性能提升近2倍。

Conclusion: TAG-K为自适应机器人控制提供了一种高效、鲁棒的在线惯性参数估计方法，在计算效率和跟踪性能方面均优于传统方法。

Abstract: Accurate online inertial parameter estimation is essential for adaptive
robotic control, enabling real-time adjustment to payload changes,
environmental interactions, and system wear. Traditional methods such as
Recursive Least Squares (RLS) and the Kalman Filter (KF) often struggle to
track abrupt parameter shifts or incur high computational costs, limiting their
effectiveness in dynamic environments and for computationally constrained
robotic systems. As such, we introduce TAG-K, a lightweight extension of the
Kaczmarz method that combines greedy randomized row selection for rapid
convergence with tail averaging for robustness under noise and inconsistency.
This design enables fast, stable parameter adaptation while retaining the low
per-iteration complexity inherent to the Kaczmarz framework. We evaluate TAG-K
in synthetic benchmarks and quadrotor tracking tasks against RLS, KF, and other
Kaczmarz variants. TAG-K achieves 1.5x-1.9x faster solve times on laptop-class
CPUs and 4.8x-20.7x faster solve times on embedded microcontrollers. More
importantly, these speedups are paired with improved resilience to measurement
noise and a 25% reduction in estimation error, leading to nearly 2x better
end-to-end tracking performance.

</details>


### [49] [CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery](https://arxiv.org/abs/2510.04883)
*Nathan Shankar,Pawel Ladosz,Hujun Yin*

Main category: cs.RO

TL;DR: 提出一种基于U-Net架构的方法，从带有发射器噪声的红外图像中重建干净图像，提升机器人在黑暗环境中的视觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 红外流在低光条件下比RGB流更抗噪声，但受主动发射器模式干扰，影响物体检测、跟踪和定位等高级任务。

Method: 使用U-Net架构从带有发射器噪声的红外输入中重建干净的IR图像。

Result: 该方法优于现有的增强技术，能够在从良好光照到极端低光场景的各种光照条件下实现可靠的视觉驱动机器人系统操作。

Conclusion: 提出的方法有效解决了红外图像中的发射器噪声问题，显著提升了机器人在黑暗环境中的感知性能。

Abstract: This paper presents a novel approach for enabling robust robotic perception
in dark environments using infrared (IR) stream. IR stream is less susceptible
to noise than RGB in low-light conditions. However, it is dominated by active
emitter patterns that hinder high-level tasks such as object detection,
tracking and localisation. To address this, a U-Net-based architecture is
proposed that reconstructs clean IR images from emitter-populated input,
improving both image quality and downstream robotic performance. This approach
outperforms existing enhancement techniques and enables reliable operation of
vision-driven robotic systems across illumination conditions from well-lit to
extreme low-light scenes.

</details>


### [50] [HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks](https://arxiv.org/abs/2510.04898)
*Zheng Xiong,Kang Li,Zilin Wang,Matthew Jackson,Jakob Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: HyperVLA提出了一种基于超网络的视觉-语言-动作模型架构，显著降低了推理成本，同时保持了多任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型存在极高的推理成本问题，需要一种既能保持模型容量又能降低推理开销的解决方案。

Method: 采用超网络架构，仅在推理时激活小型任务特定策略，同时保留训练时的高模型容量；包含利用视觉基础模型先验知识、超网络归一化和动作生成策略等关键技术。

Result: 相比单体VLA模型，在零样本泛化和少样本适应方面达到相似或更高的成功率；相比OpenVLA，激活参数量减少90倍，推理速度提升120倍。

Conclusion: HyperVLA成功解决了VLA模型的高推理成本问题，在保持性能的同时显著提升了效率。

Abstract: Built upon language and vision foundation models with strong generalization
ability and trained on large-scale robotic data, Vision-Language-Action (VLA)
models have recently emerged as a promising approach to learning generalist
robotic policies. However, a key drawback of existing VLAs is their extremely
high inference costs. In this paper, we propose HyperVLA to address this
problem. Unlike existing monolithic VLAs that activate the whole model during
both training and inference, HyperVLA uses a novel hypernetwork (HN)-based
architecture that activates only a small task-specific policy during inference,
while still retaining the high model capacity needed to accommodate diverse
multi-task behaviors during training. Successfully training an HN-based VLA is
nontrivial so HyperVLA contains several key algorithm design features that
improve its performance, including properly utilizing the prior knowledge from
existing vision foundation models, HN normalization, and an action generation
strategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even
higher success rate for both zero-shot generalization and few-shot adaptation,
while significantly reducing inference costs. Compared to OpenVLA, a
state-of-the-art VLA model, HyperVLA reduces the number of activated parameters
at test time by $90\times$, and accelerates inference speed by $120\times$.
Code is publicly available at https://github.com/MasterXiong/HyperVLA

</details>


### [51] [Efficient Navigation in Unknown Indoor Environments with Vision-Language Models](https://arxiv.org/abs/2510.04991)
*D. Schwartz,K. Kondo,J. P. How*

Main category: cs.RO

TL;DR: 提出了一种利用视觉语言模型进行高层规划的框架，通过零样本推理占据地图来选择更有效的子目标，提高未知室内环境中的自主导航效率。


<details>
  <summary>Details</summary>
Motivation: 传统探索方法由于全局推理能力有限和依赖局部启发式，在存在许多死胡同的未知室内环境中往往采取低效路径。

Method: 将3D占据网格转换为部分2D地图，生成候选子目标，使用VLM对子目标进行零样本评估和排序，并与DYNUS轨迹规划器集成。

Result: 在仿真中实现了约10%的平均路径缩短，减少了常见的贪婪失败（如绕进小房间）。

Conclusion: VLM能够从不完整地图中推断结构模式，平衡向目标前进与进入未知空间的风险，显著提高导航效率。

Abstract: We present a novel high-level planning framework that leverages
vision-language models (VLMs) to improve autonomous navigation in unknown
indoor environments with many dead ends. Traditional exploration methods often
take inefficient routes due to limited global reasoning and reliance on local
heuristics. In contrast, our approach enables a VLM to reason directly about an
occupancy map in a zero-shot manner, selecting subgoals that are likely to lead
to more efficient paths. At each planning step, we convert a 3D occupancy grid
into a partial 2D map of the environment, and generate candidate subgoals. Each
subgoal is then evaluated and ranked against other candidates by the model. We
integrate this planning scheme into DYNUS \cite{kondo2025dynus}, a
state-of-the-art trajectory planner, and demonstrate improved navigation
efficiency in simulation. The VLM infers structural patterns (e.g., rooms,
corridors) from incomplete maps and balances the need to make progress toward a
goal against the risk of entering unknown space. This reduces common greedy
failures (e.g., detouring into small rooms) and achieves about 10\% shorter
paths on average.

</details>


### [52] [Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot](https://arxiv.org/abs/2510.05001)
*Aditya Sripada,Abhishek Warrier*

Main category: cs.RO

TL;DR: TARS3D将电影《星际穿越》中的方块机器人TARS转化为现实研究平台，通过分析建模和深度强化学习探索了其丰富的运动模式，包括双足行走和高速滚动等生物超越形态的多种运动方式。


<details>
  <summary>Details</summary>
Motivation: 传统机器人运动研究多受生物启发，但许多工程场景需要非人形设计。受电影《星际穿越》中TARS机器人启发，探索方块形态机器人的运动潜力。

Method: 构建了TARS3D机器人平台（0.25m，0.99kg，7个驱动自由度），为两种主要步态建立降阶模型并推导闭式极限环条件，同时使用深度强化学习在仿真中探索未开发运动空间。

Result: 实验验证机器人遵守±150度髋关节限制，左右交替接触无干扰，在滚动模式中维持八步混合极限环。学习策略能恢复分析步态并发现新行为。

Conclusion: TARS3D的虚构生物超越形态能实现多种未探索运动模式，结合分析合成和强化学习为多模态机器人开辟了有前景的路径。

Abstract: Robotic locomotion research typically draws from biologically inspired leg
designs, yet many human-engineered settings can benefit from
non-anthropomorphic forms. TARS3D translates the block-shaped 'TARS' robot from
Interstellar into a 0.25 m, 0.99 kg research platform with seven actuated
degrees of freedom. The film shows two primary gaits: a bipedal-like walk and a
high-speed rolling mode. For TARS3D, we build reduced-order models for each,
derive closed-form limit-cycle conditions, and validate the predictions on
hardware. Experiments confirm that the robot respects its +/-150 degree hip
limits, alternates left-right contacts without interference, and maintains an
eight-step hybrid limit cycle in rolling mode. Because each telescopic leg
provides four contact corners, the rolling gait is modeled as an eight-spoke
double rimless wheel. The robot's telescopic leg redundancy implies a far
richer gait repertoire than the two limit cycles treated analytically. So, we
used deep reinforcement learning (DRL) in simulation to search the unexplored
space. We observed that the learned policy can recover the analytic gaits under
the right priors and discover novel behaviors as well. Our findings show that
TARS3D's fiction-inspired bio-transcending morphology can realize multiple
previously unexplored locomotion modes and that further learning-driven search
is likely to reveal more. This combination of analytic synthesis and
reinforcement learning opens a promising pathway for multimodal robotics.

</details>


### [53] [StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation](https://arxiv.org/abs/2510.05057)
*Mingyu Liu,Jiuhe Shu,Hui Chen,Zeju Li,Canyu Zhao,Jiange Yang,Shenyuan Gao,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 提出了一种无监督方法StaMo，通过轻量级编码器和预训练DiT解码器学习高度压缩的双token状态表示，该表示不仅高效可解释，还能自然地产生有效的潜在动作。


<details>
  <summary>Details</summary>
Motivation: 现有方法在具身智能中难以平衡状态表示的表达性和紧凑性，要么过于冗余，要么缺乏任务关键信息。

Method: 使用轻量级编码器和预训练扩散变换器解码器学习压缩的双token状态表示，通过潜在插值获得潜在动作。

Result: 在LIBERO上性能提升14.3%，真实世界任务成功率提升30%，潜在动作增强策略协同训练，性能提升10.4%。

Conclusion: StaMo方法能够从静态图像学习通用机器人运动，挑战了依赖复杂架构和视频数据学习潜在动作的主流方法，具有良好的可扩展性。

Abstract: A fundamental challenge in embodied intelligence is developing expressive and
compact state representations for efficient world modeling and decision making.
However, existing methods often fail to achieve this balance, yielding
representations that are either overly redundant or lacking in task-critical
information. We propose an unsupervised approach that learns a highly
compressed two-token state representation using a lightweight encoder and a
pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong
generative prior. Our representation is efficient, interpretable, and
integrates seamlessly into existing VLA-based models, improving performance by
14.3% on LIBERO and 30% in real-world task success with minimal inference
overhead. More importantly, we find that the difference between these tokens,
obtained via latent interpolation, naturally serves as a highly effective
latent action, which can be further decoded into executable robot actions. This
emergent capability reveals that our representation captures structured
dynamics without explicit supervision. We name our method StaMo for its ability
to learn generalizable robotic Motion from compact State representation, which
is encoded from static images, challenging the prevalent dependence to learning
latent action on complex architectures and video data. The resulting latent
actions also enhance policy co-training, outperforming prior methods by 10.4%
with improved interpretability. Moreover, our approach scales effectively
across diverse data sources, including real-world robot data, simulation, and
human egocentric video.

</details>


### [54] [Automaton Constrained Q-Learning](https://arxiv.org/abs/2510.05061)
*Anastasios Manganaris,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出ACQL算法，结合目标条件值学习和自动机引导强化学习，解决机器人任务中时序目标达成和时间变化安全约束的问题。


<details>
  <summary>Details</summary>
Motivation: 现实机器人任务需要达成序列目标并遵守时变安全约束，但标准RL方法在此类设置中存在根本限制。现有LTL目标RL方法在复杂连续环境中表现不佳，缺乏同时支持时序目标和安全约束的可扩展方法。

Method: ACQL算法结合目标条件值学习和自动机引导强化学习，利用LTL任务规范的自动机表示，显式编码阶段化目标进展以及静态和非静态安全约束。

Result: ACQL在连续控制任务中优于现有方法，包括先前方法无法满足目标达成或安全约束的情况。在6-DOF机械臂的真实世界应用中验证了其有效性。

Conclusion: ACQL是根据丰富时序规范学习机器人行为的鲁棒且可扩展的解决方案。

Abstract: Real-world robotic tasks often require agents to achieve sequences of goals
while respecting time-varying safety constraints. However, standard
Reinforcement Learning (RL) paradigms are fundamentally limited in these
settings. A natural approach to these problems is to combine RL with
Linear-time Temporal Logic (LTL), a formal language for specifying complex,
temporally extended tasks and safety constraints. Yet, existing RL methods for
LTL objectives exhibit poor empirical performance in complex and continuous
environments. As a result, no scalable methods support both temporally ordered
goals and safety simultaneously, making them ill-suited for realistic robotics
scenarios. We propose Automaton Constrained Q-Learning (ACQL), an algorithm
that addresses this gap by combining goal-conditioned value learning with
automaton-guided reinforcement. ACQL supports most LTL task specifications and
leverages their automaton representation to explicitly encode stage-wise goal
progression and both stationary and non-stationary safety constraints. We show
that ACQL outperforms existing methods across a range of continuous control
tasks, including cases where prior methods fail to satisfy either goal-reaching
or safety constraints. We further validate its real-world applicability by
deploying ACQL on a 6-DOF robotic arm performing a goal-reaching task in a
cluttered, cabinet-like space with safety constraints. Our results demonstrate
that ACQL is a robust and scalable solution for learning robotic behaviors
according to rich temporal specifications.

</details>


### [55] [ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning](https://arxiv.org/abs/2510.05070)
*Siheng Zhao,Yanjie Ze,Yue Wang,C. Karen Liu,Pieter Abbeel,Guanya Shi,Rocky Duan*

Main category: cs.RO

TL;DR: ResMimic是一个两阶段残差学习框架，用于从人类运动数据中实现精确且富有表现力的人形机器人控制。它结合了通用运动跟踪策略和精确的残差策略，提升了人形机器人的运动精度和物体交互能力。


<details>
  <summary>Details</summary>
Motivation: 虽然通用运动跟踪(GMT)技术已能让人形机器人复现多样的人类动作，但这些策略缺乏精确性和物体感知能力，无法满足移动操作任务的需求。

Method: 采用两阶段残差学习框架：首先训练基于大规模人类运动数据的GMT策略作为基础，然后学习高效的残差策略来精炼GMT输出，提升运动能力并融入物体交互。设计了点云物体跟踪奖励、接触奖励和基于课程的虚拟物体控制器来优化训练。

Result: 在仿真和真实Unitree G1人形机器人上的评估显示，相比强基线方法，ResMimic在任务成功率、训练效率和鲁棒性方面都有显著提升。

Conclusion: ResMimic框架成功解决了人形机器人移动操作任务中的精确控制和物体交互问题，为日常服务和仓储任务提供了有效的解决方案。

Abstract: Humanoid whole-body loco-manipulation promises transformative capabilities
for daily service and warehouse tasks. While recent advances in general motion
tracking (GMT) have enabled humanoids to reproduce diverse human motions, these
policies lack the precision and object awareness required for
loco-manipulation. To this end, we introduce ResMimic, a two-stage residual
learning framework for precise and expressive humanoid control from human
motion data. First, a GMT policy, trained on large-scale human-only motion,
serves as a task-agnostic base for generating human-like whole-body movements.
An efficient but precise residual policy is then learned to refine the GMT
outputs to improve locomotion and incorporate object interaction. To further
facilitate efficient training, we design (i) a point-cloud-based object
tracking reward for smoother optimization, (ii) a contact reward that
encourages accurate humanoid body-object interactions, and (iii) a
curriculum-based virtual object controller to stabilize early training. We
evaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results
show substantial gains in task success, training efficiency, and robustness
over strong baselines. Videos are available at https://resmimic.github.io/ .

</details>
