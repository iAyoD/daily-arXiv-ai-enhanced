<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 43]
- [cs.RO](#cs.RO) [Total: 17]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Human-Level and Beyond: Benchmarking Large Language Models Against Clinical Pharmacists in Prescription Review](https://arxiv.org/abs/2512.02024)
*Yan Yang,Mouxiao Bian,Peiling Li,Bingjian Wen,Ruiyao Chen,Kangkun Mao,Xiaojun Ye,Tianbin Li,Pengcheng Chen,Bing Han,Jie Xu,Kaifeng Qiu,Junyan Wu*

Main category: cs.CL

TL;DR: RxBench是一个针对处方审核的全面基准测试，包含多种题型，评估了18个先进LLM，发现领先模型在某些任务上可匹敌或超越人类药师，并通过微调使中等模型达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在临床决策支持中的快速应用，特别是在处方审核领域，需要系统化、细粒度的评估框架来检验模型能力。目前缺乏覆盖常见处方错误类型、基于权威药学参考的标准化基准。

Method: 开发了RxBench基准，涵盖常见处方审核类别，整合了14种常见处方错误类型（来自权威药学参考）。包含1,150个单选题、230个多选题和879个简答题，所有题目均由经验丰富的临床药师审核。评估了18个最先进的LLM，并与持证药师进行比较。基于基准评估的洞察，对中等模型进行针对性微调。

Result: 发现模型性能在不同任务上呈现明显分层：Gemini-2.5-pro-preview-05-06、Grok-4-0709和DeepSeek-R1-0528始终处于第一梯队，在准确性和鲁棒性上优于其他模型。领先LLM在某些任务上可匹敌或超越人类药师表现。通过针对性微调，中等模型在简答题任务上达到与领先通用LLM相当的水平。

Conclusion: RxBench建立了一个标准化、错误类型导向的评估框架，不仅揭示了前沿LLM在处方审核中的能力和局限，还为构建更可靠、专业的临床工具提供了基础资源。研究表明LLM在处方审核中具有巨大潜力，可通过专门化进一步提升性能。

Abstract: The rapid advancement of large language models (LLMs) has accelerated their integration into clinical decision support, particularly in prescription review. To enable systematic and fine-grained evaluation, we developed RxBench, a comprehensive benchmark that covers common prescription review categories and consolidates 14 frequent types of prescription errors drawn from authoritative pharmacy references. RxBench consists of 1,150 single-choice, 230 multiple-choice, and 879 short-answer items, all reviewed by experienced clinical pharmacists. We benchmarked 18 state-of-the-art LLMs and identified clear stratification of performance across tasks. Notably, Gemini-2.5-pro-preview-05-06, Grok-4-0709, and DeepSeek-R1-0528 consistently formed the first tier, outperforming other models in both accuracy and robustness. Comparisons with licensed pharmacists indicated that leading LLMs can match or exceed human performance in certain tasks. Furthermore, building on insights from our benchmark evaluation, we performed targeted fine-tuning on a mid-tier model, resulting in a specialized model that rivals leading general-purpose LLMs in performance on short-answer question tasks. The main contribution of RxBench lies in establishing a standardized, error-type-oriented framework that not only reveals the capabilities and limitations of frontier LLMs in prescription review but also provides a foundational resource for building more reliable and specialized clinical tools.

</details>


### [2] [Deep Research: A Systematic Survey](https://arxiv.org/abs/2512.02038)
*Zhengliang Shi,Yiqun Chen,Haitao Li,Weiwei Sun,Shiyu Ni,Yougang Lyu,Run-Ze Fan,Bowen Jin,Yixuan Weng,Minjun Zhu,Qiujie Xie,Xinyu Guo,Qu Yang,Jiayi Wu,Jujia Zhao,Xiaqiang Tang,Xinbei Ma,Cunxiang Wang,Jiaxin Mao,Qingyao Ai,Jen-Tse Huang,Wenxuan Wang,Yue Zhang,Yiming Yang,Zhaopeng Tu,Zhaochun Ren*

Main category: cs.CL

TL;DR: 这篇论文是关于深度研究系统的综述，系统梳理了LLM作为研究代理完成复杂开放任务的方法、组件、优化技术和挑战。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽然强大，但许多开放任务需要批判性思维、多源信息和可验证输出，这超出了单次提示或标准检索增强生成的能力。深度研究旨在结合LLM的推理能力和外部工具，使LLM能够作为研究代理完成复杂任务。

Method: 提出了一个系统性的综述框架：1) 形式化三阶段路线图并区分深度研究与相关范式；2) 介绍四个关键组件（查询规划、信息获取、记忆管理、答案生成）及其细分子分类；3) 总结优化技术（提示工程、监督微调、代理强化学习）；4) 整合评估标准和开放挑战。

Result: 提供了一个全面系统的深度研究系统概述，包括清晰的路线图、基础组件、实践实现技术、重要挑战和未来方向，为未来研究提供指导和便利。

Conclusion: 深度研究是一个快速发展的领域，将LLM的推理能力与外部工具结合，使其能够作为研究代理完成复杂开放任务。该综述将持续更新以反映最新进展。

Abstract: Large language models (LLMs) have rapidly evolved from text generators into powerful problem solvers. Yet, many open tasks demand critical thinking, multi-source, and verifiable outputs, which are beyond single-shot prompting or standard retrieval-augmented generation. Recently, numerous studies have explored Deep Research (DR), which aims to combine the reasoning capabilities of LLMs with external tools, such as search engines, thereby empowering LLMs to act as research agents capable of completing complex, open-ended tasks. This survey presents a comprehensive and systematic overview of deep research systems, including a clear roadmap, foundational components, practical implementation techniques, important challenges, and future directions. Specifically, our main contributions are as follows: (i) we formalize a three-stage roadmap and distinguish deep research from related paradigms; (ii) we introduce four key components: query planning, information acquisition, memory management, and answer generation, each paired with fine-grained sub-taxonomies; (iii) we summarize optimization techniques, including prompting, supervised fine-tuning, and agentic reinforcement learning; and (iv) we consolidate evaluation criteria and open challenges, aiming to guide and facilitate future development. As the field of deep research continues to evolve rapidly, we are committed to continuously updating this survey to reflect the latest progress in this area.

</details>


### [3] [Mirror, Mirror on the Wall -- Which is the Best Model of Them All?](https://arxiv.org/abs/2512.02043)
*Dina Sayed,Heiko Schuldt*

Main category: cs.CL

TL;DR: 该论文提出了一种模型选择方法学（MSM），通过分析当前LLM排行榜和基准测试，帮助用户基于定量维度选择最适合特定用例的模型，并以医疗领域为例进行说明。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在各领域的广泛应用，选择最适合特定用例的基础模型变得越来越复杂。现有模型选择主要依赖定性信息（如模型卡片）和定量性能（如排行榜），但缺乏系统的方法来指导用户基于定量维度进行模型选择。

Method: 论文通过分析当前LLM排行榜和基准测试，探索模型选择的定量维度。以医疗领域为案例研究，展示定量评估的演变、现状和实际意义。最后提出模型选择方法学（MSM），这是一个系统化的方法，指导用户导航、优先级排序和选择最适合特定用例的模型。

Result: 论文展示了医疗领域LLM排行榜和基准测试的分析结果，揭示了定量评估的演变趋势和当前格局。提出的MSM方法为模型选择提供了一个系统化的框架，帮助用户基于定量性能指标做出更明智的决策。

Conclusion: 模型选择需要考虑定性和定量两个维度。通过分析当前排行榜和基准测试，特别是以医疗领域为例，论文展示了定量评估的重要性。提出的MSM方法为系统化模型选择提供了实用指导，有助于用户选择最适合特定用例的LLM模型。

Abstract: Large Language Models (LLMs) have become one of the most transformative tools across many applications, as they have significantly boosted productivity and achieved impressive results in various domains such as finance, healthcare, education, telecommunications, and law, among others. Typically, state-of-the-art (SOTA) foundation models are developed by large corporations based on large data collections and substantial computational and financial resources required to pretrain such models from scratch. These foundation models then serve as the basis for further development and domain adaptation for specific use cases or tasks. However, given the dynamic and fast-paced nature of launching new foundation models, the process of selecting the most suitable model for a particular use case, application, or domain becomes increasingly complex. We argue that there are two main dimensions that need to be taken into consideration when selecting a model for further training: a qualitative dimension (which model is best suited for a task based on information, for instance, taken from model cards) and a quantitative dimension (which is the best performing model). The quantitative performance of models is assessed through leaderboards, which rank models based on standardized benchmarks and provide a consistent framework for comparing different LLMs. In this work, we address the analysis of the quantitative dimension by exploring the current leaderboards and benchmarks. To illustrate this analysis, we focus on the medical domain as a case study, demonstrating the evolution, current landscape, and practical significance of this quantitative evaluation dimension. Finally, we propose a Model Selection Methodology (MSM), a systematic approach designed to guide the navigation, prioritization, and selection of the model that best aligns with a given use case.

</details>


### [4] [Beyond Confidence: Adaptive and Coherent Decoding for Diffusion Language Models](https://arxiv.org/abs/2512.02044)
*Kecheng Chen,Ziru Liu,Xijia Tao,Hui Liu,Xinyu Fu,Suiyun Zhang,Dandan Tu,Lingpeng Kong,Rui Liu,Haoliang Li*

Main category: cs.CL

TL;DR: 提出CCD框架，通过轨迹修正机制和历史上下文增强序列连贯性，结合自适应采样策略，在DLMs中同时提升推理速度和质量。


<details>
  <summary>Details</summary>
Motivation: 现有DLMs推理方法依赖局部即时指标（如置信度、熵），缺乏可靠视角，导致采样轨迹不一致和生成质量次优。

Method: 提出CCD框架：1) 轨迹修正机制利用历史上下文增强序列连贯性，早期拒绝次优路径；2) 自适应采样策略根据一致性指标动态调整每一步的解码预算。

Result: 在Dream和LLaDA基准测试中，推理速度提升最高达3.48倍，性能提升3.91%，实现了速度和性能的同时提升。

Conclusion: CCD通过历史上下文连贯性和自适应采样，有效解决了DLMs推理中的轨迹不一致问题，显著提升了生成质量和效率。

Abstract: Diffusion Language Models (DLMs) have recently achieved significant success due to their any-order generation capabilities. However, existing inference methods typically rely on local, immediate-step metrics such as confidence or entropy which inherently lack a more reliable perspective. This limitation frequently leads to inconsistent sampling trajectories and suboptimal generation quality. To address this, we propose Coherent Contextual Decoding (CCD), a novel inference framework built upon two core innovations. First, CCD employs a trajectory rectification mechanism that leverages historical context to enhance sequence coherence, enabling the early rejection of suboptimal paths. We demonstrate that this mechanism is theoretically equivalent to modeling the consistency of historical steps via the conditional mutual information between context and token predictions. Building on this theoretical insight, we further address the inefficiency of conventional uniform decoding budgets. Instead of rigid allocations based on diffusion steps, we introduce an adaptive sampling strategy that dynamically adjusts the unmasking budget for each step according to our consistency metric. Consequently, our method significantly improves the quality of generation trajectories while accelerating the sampling process. Empirically, our method achieves a simultaneous enhancement in both inference speed and performance across diverse benchmarks on Dream and LLaDA, delivering up to 3.48x speedup alongside 3.91% performance improvement.

</details>


### [5] [Reversing Large Language Models for Efficient Training and Fine-Tuning](https://arxiv.org/abs/2512.02056)
*Eshed Gal,Moshe Eliasof,Javier Turek,Uri Ascher,Eran Treister,Eldad Haber*

Main category: cs.CL

TL;DR: 提出基于可逆架构的LLM内存优化方法，通过时间可逆动力学减少激活值存储，显著降低内存消耗并提升训练效率。


<details>
  <summary>Details</summary>
Motivation: LLM训练成本高昂且耗时，通常需要对预训练模型进行微调。现有架构需要存储所有中间激活值，导致内存消耗巨大，限制了批处理大小和训练效率。

Method: 1. 受对称和辛微分方程启发，设计内存高效的可逆LLM架构；2. 利用时间可逆动力学在反向传播时重新计算隐藏状态，无需存储激活值；3. 提出将现有非可逆LLM转换为可逆架构的微调方法。

Result: 在多个数据集和基准测试上，使用多个LLM模型获得了可比或改进的性能；显著降低内存消耗，允许在相同内存下处理更大的批处理大小，提高吞吐量。

Conclusion: 提出的可逆架构为降低LLM从头训练和微调的内存与计算成本提供了可扩展且高效的路径，同时保持了模型性能。

Abstract: Large Language Models (LLMs) are known for their expensive and time-consuming training. Thus, oftentimes, LLMs are fine-tuned to address a specific task, given the pretrained weights of a pre-trained LLM considered a foundation model. In this work, we introduce memory-efficient, reversible architectures for LLMs, inspired by symmetric and symplectic differential equations, and investigate their theoretical properties. Different from standard, baseline architectures that store all intermediate activations, the proposed models use time-reversible dynamics to retrieve hidden states during backpropagation, relieving the need to store activations. This property allows for a drastic reduction in memory consumption, allowing for the processing of larger batch sizes for the same available memory, thereby offering improved throughput. In addition, we propose an efficient method for converting existing, non-reversible LLMs into reversible architectures through fine-tuning, rendering our approach practical for exploiting existing pre-trained models. Our results show comparable or improved performance on several datasets and benchmarks, on several LLMs, building a scalable and efficient path towards reducing the memory and computational costs associated with both training from scratch and fine-tuning of LLMs.

</details>


### [6] [Dialect Identification Using Resource-Efficient Fine-Tuning Approaches](https://arxiv.org/abs/2512.02074)
*Zirui Lin,Haris Gulzar,Monnika Roslianna Busto,Akiko Masaki,Takeharu Eda,Kazuhiro Nakadai*

Main category: cs.CL

TL;DR: 该论文探索了内存高效微调（MEFT）方法在语音模型方言识别任务中的应用，相比传统微调和参数高效微调，能显著减少GPU内存使用并加速训练，同时保持准确率。


<details>
  <summary>Details</summary>
Motivation: 方言识别（DI）有助于改善下游语音任务，但微调语音模型计算成本和内存需求高。现有的参数高效微调（PEFT）方法参数效率高，但在内存效率和训练速度方面改进有限。

Method: 探索并应用最初为语言处理设计的内存高效微调（MEFT）方法到通用预训练语音模型，全面分析不同MEFT方法的GPU内存使用和微调速度。以Whisper模型和KeSpeech数据集的六种普通话子方言识别为案例研究。

Result: 相比传统微调，GPU内存使用减少高达73.25%，训练速度提升2.1倍，同时准确率与vanilla微调和PEFT方法相当。

Conclusion: MEFT方法在语音模型方言识别任务中能显著提高内存效率和训练速度，为资源受限环境下的语音模型微调提供了有效解决方案。

Abstract: Dialect Identification (DI) is a task to recognize different dialects within the same language from a speech signal. DI can help to improve the downstream speech related tasks even when speakers have a strong dialect. However, fine-tuning a speech model for tasks like DI is expensive in terms of computation cost and memory requirement. Recent studies have explored fine-tuning pre-trained speech models for tasks like DI using Parameter-Efficient Fine-Tuning (PEFT) methods, which offer parameter efficiency but limited improvement in memory efficiency and training speed. To address these challenges, we explore Memory-Efficient Fine-Tuning (MEFT) methods, originally proposed for language processing, and apply them to the general-purpose pre-trained speech model. We then comprehensively analyze the GPU memory usage and fine-tuning speed based on various MEFT methods. As a case study, we fine-tune the Whisper model to identify six Mandarin subdialects from the KeSpeech dataset, reducing GPU memory usage by up to 73.25% and accelerating training speed by a factor of 2.1, while maintaining accuracy comparable to vanilla fine-tuning and PEFT methods.

</details>


### [7] [Feature Selection Empowered BERT for Detection of Hate Speech with Vocabulary Augmentation](https://arxiv.org/abs/2512.02141)
*Pritish N. Desai,Tanay Kewalramani,Srimanta Mandal*

Main category: cs.CL

TL;DR: 提出一种数据高效的BERT微调策略，通过TF-IDF样本选择和词汇表增强，在减少75%训练数据的同时保持仇恨言论检测性能


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的辱骂性言论持续演变，新俚语和规避性词汇不断出现，现有检测系统难以有效应对。传统方法需要大量标注数据，计算成本高。

Method: 1) 使用TF-IDF样本选择机制，仅保留最具信息量的75%训练样本；2) 增强BERT词汇表，添加领域特定的俚语和词汇变体；3) 在仇恨言论数据集上微调BERT模型

Result: 在广泛使用的仇恨言论数据集上，该方法在显著减少训练数据量的情况下，仍能保持竞争力的检测性能，同时提高了计算效率

Conclusion: 该方法为可扩展和自适应的辱骂内容审核提供了有效解决方案，通过数据高效策略和词汇表增强，能够更好地应对不断演变的仇恨言论

Abstract: Abusive speech on social media poses a persistent and evolving challenge, driven by the continuous emergence of novel slang and obfuscated terms designed to circumvent detection systems. In this work, we present a data efficient strategy for fine tuning BERT on hate speech classification by significantly reducing training set size without compromising performance. Our approach employs a TF IDF-based sample selection mechanism to retain only the most informative 75 percent of examples, thereby minimizing training overhead. To address the limitations of BERT's native vocabulary in capturing evolving hate speech terminology, we augment the tokenizer with domain-specific slang and lexical variants commonly found in abusive contexts. Experimental results on a widely used hate speech dataset demonstrate that our method achieves competitive performance while improving computational efficiency, highlighting its potential for scalable and adaptive abusive content moderation.

</details>


### [8] [Think Before You Prune: Self-Reflective Structured Pruning for Reasoning Language Models](https://arxiv.org/abs/2512.02185)
*Ziyan Wang,Enmao Diao,Qi Le,Pu Wang,Guanchu Wang,Minwoo Lee,Shu-ping Yeh,Li Yang*

Main category: cs.CL

TL;DR: RESP是一种自反思结构化剪枝框架，针对推理大语言模型，通过自生成校准、解码梯度重要性估计和渐进再生，在保持高精度下实现20-40%稀疏度。


<details>
  <summary>Details</summary>
Motivation: 推理大语言模型（如OpenAI o1、DeepSeek-R1、Qwen3）虽然推理能力强，但模型大、推理输出长，部署成本高且不适合资源受限环境。现有剪枝方法对推理LLMs效果差，即使中等稀疏度（如20%）也会导致精度崩溃和推理连贯性破坏。

Method: RESP框架包含三个关键组件：1）自生成校准：使用模型自身生成推理轨迹作为校准数据；2）解码梯度重要性估计：基于解码过程梯度评估参数重要性；3）渐进再生：随着稀疏度增加保持校准保真度。

Result: 在Qwen3-8B上实验显示，RESP在GSM8K和MathQA上显著优于现有结构化剪枝方法。在20-30%稀疏度下保持接近密集模型精度，在40%稀疏度下GSM8K达到81.3%准确率，MathQA达到59.6%，分别比最强基线提升66.87%和47%。

Conclusion: RESP通过将剪枝决策与模型推理动态对齐，有效解决了推理LLMs剪枝的挑战，为在资源受限环境中部署高效推理模型提供了可行方案。

Abstract: Reasoning LLMs (RLMs) such as OpenAI o1, DeepSeek-R1, and Qwen3 deliver strong multi-step reasoning through chain-of-thought generation, but their large model sizes and lengthy decode-time outputs make them costly to deploy and unsuitable for resource-constrained settings. To reduce computing and memory cost, pruning offers a promising solution by removing unimportant parameters. However, despite their success on standard LLMs, existing pruning methods severely damage RLMs, as even moderate sparsity (e.g., 20%) can collapse accuracy and completely disrupt the model's reasoning coherence. We begin by analyzing why existing pruning pipelines fail on reasoning LLMs and find that their brittleness largely stems from a mismatch between the calibration data, the pruning objective, and the model's decode-time reasoning behavior. Our study further shows that the most reliable calibration signal comes not from human-written labels but from the model's own self-generated reasoning traces, which more accurately reflect its inference distribution. Guided by these insights, we introduce RESP, a self-reflective structured pruning framework that aligns pruning decisions with the model's reasoning dynamics through self-generated calibration, decode-only gradient-based importance estimation, and progressive regeneration that maintains calibration fidelity as sparsity increases. Experiments on Qwen3-8B demonstrate that RESP markedly outperforms existing structured pruning methods on both GSM8K and MathQA, preserving near-dense accuracy at 20-30% sparsity and substantially mitigating performance collapse at higher sparsity levels. At 40% sparsity, RESP attains 81.3% accuracy on GSM8K and 59.6% on MathQA, surpassing the strongest baselines by 66.87% and 47%, respectively.

</details>


### [9] [A Knowledge-Based Language Model: Deducing Grammatical Knowledge in a Multi-Agent Language Acquisition Simulation](https://arxiv.org/abs/2512.02195)
*David Ph. Shakouri,Crit Cremers,Niels O. Schiller*

Main category: cs.CL

TL;DR: MODOMA系统是一个用于无监督语言习得实验的计算多智能体实验室环境，通过成年和儿童智能体之间的交互实现语言习得，能够获取和表示功能性和内容性语法范畴。


<details>
  <summary>Details</summary>
Motivation: 为语言习得研究提供一个可参数化、可控的计算实验环境，使研究人员能够明确表示和查询习得的语法知识，为计算语言习得实验提供新的可能性。

Method: 使用多智能体系统框架，包含成年智能体和儿童智能体，结合统计和基于规则的程序进行无监督语言习得。研究人员可以控制实验的所有方面，习得的语法知识被明确表示。

Result: 儿童智能体能够基于成年智能体生成的不同数量的训练和测试数据，成功获取和表示功能性和内容性语法范畴。机器生成的数据中发现了与人类生成数据相似的模式。

Conclusion: 实验证实了MODOMA方法在建模语言习得方面的有效性，儿童智能体成功获取了离散的语法范畴，为计算语言习得研究提供了新的实验平台。

Abstract: This paper presents an initial study performed by the MODOMA system. The MODOMA is a computational multi-agent laboratory environment for unsupervised language acquisition experiments such that acquisition is based on the interaction between two language models, an adult and a child agent. Although this framework employs statistical as well as rule-based procedures, the result of language acquisition is a knowledge-based language model, which can be used to generate and parse new utterances of the target language. This system is fully parametrized and researchers can control all aspects of the experiments while the results of language acquisition, that is, the acquired grammatical knowledge, are explicitly represented and can be consulted. Thus, this system introduces novel possibilities for conducting computational language acquisition experiments. The experiments presented by this paper demonstrate that functional and content categories can be acquired and represented by the daughter agent based on training and test data containing different amounts of exemplars generated by the adult agent. Interestingly, similar patterns, which are well-established for human-generated data, are also found for these machine-generated data. As the procedures resulted in the successful acquisition of discrete grammatical categories by the child agent, these experiments substantiate the validity of the MODOMA approach to modelling language acquisition.

</details>


### [10] [Swivuriso: The South African Next Voices Multilingual Speech Dataset](https://arxiv.org/abs/2512.02201)
*Vukosi Marivatee,Kayode Olaleye,Sitwala Mundia,Andinda Bakainga,Unarine Netshifhefhe,Mahmooda Milanzie,Tsholofelo Hope Mogale,Thapelo Sindane,Zainab Abdulrasaq,Kesego Mokgosi,Chijioke Okorie,Nia Zion Van Wyk,Graham Morrissey,Dale Dunbar,Francois Smit,Tsosheletso Chidi,Rooweither Mabuya,Andiswa Bukula,Respect Mlambo,Tebogo Macucwa,Idris Abdulmumin,and Seani Rananga*

Main category: cs.CL

TL;DR: Swivuriso是一个3000小时的多语言语音数据集，支持7种南非语言的ASR技术开发和基准测试，涵盖农业、医疗和通用领域。


<details>
  <summary>Details</summary>
Motivation: 解决现有ASR数据集在多种南非语言上的显著空白，支持非洲语言的语音识别技术发展。

Method: 设计了数据收集原则、伦理考虑和采集流程，创建了涵盖农业、医疗和通用领域的多语言语音数据集。

Result: 提供了3000小时的多语言语音数据，建立了ASR模型的基线结果，并与其他相关语言的ASR数据集进行了比较。

Conclusion: Swivuriso数据集填补了南非语言ASR资源的空白，为相关语言的语音识别技术发展提供了重要支持。

Abstract: This paper introduces Swivuriso, a 3000-hour multilingual speech dataset developed as part of the African Next Voices project, to support the development and benchmarking of automatic speech recognition (ASR) technologies in seven South African languages. Covering agriculture, healthcare, and general domain topics, Swivuriso addresses significant gaps in existing ASR datasets. We describe the design principles, ethical considerations, and data collection procedures that guided the dataset creation. We present baseline results of training/finetuning ASR models with this data and compare to other ASR datasets for the langauges concerned.

</details>


### [11] [Lightweight Latent Reasoning for Narrative Tasks](https://arxiv.org/abs/2512.02240)
*Alexander Gurung,Nikolay Malkin,Mirella Lapata*

Main category: cs.CL

TL;DR: LiteReason是一种轻量级潜在推理方法，通过连续潜在令牌帮助模型"跳过"推理步骤，在保持性能的同时大幅减少推理长度（77-92%）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过生成长推理链处理复杂任务，但使用强化学习优化推理能力计算成本高昂，特别是在涉及大量令牌处理的叙事相关任务中。

Method: 提出LiteReason方法，包含轻量级推理投影器模块，生成连续潜在令牌帮助模型跳过推理步骤。在强化学习中，策略模型决定何时激活投影器，在潜在推理和离散推理之间切换。

Result: 在情节漏洞检测和书籍章节生成任务上，LiteReason优于潜在推理基线方法，接近非潜在强化学习训练的性能，同时减少最终推理长度77-92%。

Conclusion: LiteReason引导强化学习训练达到性能-计算权衡曲线上更高效的部分，为复杂任务推理提供了计算效率更高的解决方案。

Abstract: Large language models (LLMs) tackle complex tasks by generating long chains of thought or "reasoning traces" that act as latent variables in the generation of an output given a query. A model's ability to generate such traces can be optimized with reinforcement learning (RL) to improve their utility in predicting an answer. This optimization comes at a high computational cost, especially for narrative-related tasks that involve retrieving and processing many tokens. To this end, we propose LiteReason, a latent reasoning method that can be interleaved with standard token sampling and easily combined with RL techniques. LiteReason employs a lightweight Reasoning Projector module, trained to produce continuous latent tokens that help the model 'skip' reasoning steps. During RL, the policy model decides when to activate the projector, switching between latent and discrete reasoning as needed. Experimental results on plot hole detection and book chapter generation show that our method outperforms latent reasoning baselines and comes close to matching non-latent RL training, while reducing final reasoning length by 77-92%. Overall, LiteReason guides RL training to a more efficient part of the performance-computation tradeoff curve.

</details>


### [12] [DETAIL Matters: Measuring the Impact of Prompt Specificity on Reasoning in Large Language Models](https://arxiv.org/abs/2512.02246)
*Olivia Kim*

Main category: cs.CL

TL;DR: 论文提出DETAIL框架，用于评估大语言模型在不同提示词具体程度下的性能表现，发现更具体的提示能提升准确性，尤其对小模型和流程性任务效果更明显。


<details>
  <summary>Details</summary>
Motivation: 提示词设计对大语言模型的推理性能至关重要，但提示词的具体程度（详细或模糊）对模型性能的影响尚未得到充分研究，需要系统性的评估框架。

Method: 提出DETAIL框架：1) 使用GPT-4生成多层次的提示词；2) 通过困惑度量化提示词的具体程度；3) 使用基于GPT的语义等价性评估回答正确性；在30个新颖推理任务上对GPT-4和O3-mini进行实验。

Result: 实验表明：1) 提示词越具体，模型准确性越高；2) 这种提升对小模型（如O3-mini）效果更显著；3) 流程性任务比概念性任务受益更大；4) 需要自适应的提示策略。

Conclusion: 提示词的具体程度显著影响LLM性能，需要根据模型大小和任务类型采用自适应提示策略。研究提供了评估工具和数据集支持进一步研究。

Abstract: Prompt design plays a critical role in the reasoning performance of large language models (LLMs), yet the impact of prompt specificity - how detailed or vague a prompt is - remains understudied. This paper introduces DETAIL, a framework for evaluating LLM performance across varying levels of prompt specificity. We generate multi-level prompts using GPT-4, quantify specificity via perplexity, and assess correctness using GPT-based semantic equivalence. Experiments on 30 novel reasoning tasks across GPT-4 and O3-mini reveal that specificity improves accuracy, especially for smaller models and procedural tasks. Our results highlight the need for adaptive prompting strategies and provide tools and data to support further research.

</details>


### [13] [CAIRNS: Balancing Readability and Scientific Accuracy in Climate Adaptation Question Answering](https://arxiv.org/abs/2512.02251)
*Liangji Kong,Aditya Joshi,Sarvnaz Karimi*

Main category: cs.CL

TL;DR: CAIRNS是一个气候适应问答框架，帮助农业专家从网络证据源获取可信的初步答案，通过结构化提示增强可读性和引用可靠性，无需微调或强化学习。


<details>
  <summary>Details</summary>
Motivation: 气候适应策略对维持粮食生产至关重要，但相关信息分散在非结构化（如科学文献）和结构化（如政府API）数据中，专家难以快速获取可信答案。

Method: 提出CAIRNS框架，包含结构化ScholarGuide提示增强可读性和引用可靠性，以及基于一致性加权的混合评估器，利用模型间共识与专家判断进行鲁棒评估。

Result: 在专家策划的数据集上，CAIRNS在大多数指标上优于基线方法，消融研究在所有指标上确认了结果，LLM评估与人工判断具有相关性。

Conclusion: CAIRNS框架能够提供可读、可验证且领域基础的气候适应问答，无需微调或强化学习，为农业专家提供了有效的决策支持工具。

Abstract: Climate adaptation strategies are proposed in response to climate change. They are practised in agriculture to sustain food production. These strategies can be found in unstructured data (for example, scientific literature from the Elsevier website) or structured (heterogeneous climate data via government APIs). We present Climate Adaptation question-answering with Improved Readability and Noted Sources (CAIRNS), a framework that enables experts -- farmer advisors -- to obtain credible preliminary answers from complex evidence sources from the web. It enhances readability and citation reliability through a structured ScholarGuide prompt and achieves robust evaluation via a consistency-weighted hybrid evaluator that leverages inter-model agreement with experts. Together, these components enable readable, verifiable, and domain-grounded question-answering without fine-tuning or reinforcement learning. Using a previously reported dataset of expert-curated question-answers, we show that CAIRNS outperforms the baselines on most of the metrics. Our thorough ablation study confirms the results on all metrics. To validate our LLM-based evaluation, we also report an analysis of correlations against human judgment.

</details>


### [14] [HealthContradict: Evaluating Biomedical Knowledge Conflicts in Language Models](https://arxiv.org/abs/2512.02299)
*Boya Zhang,Alban Bornet,Rui Yang,Nan Liu,Douglas Teodoro*

Main category: cs.CL

TL;DR: 该论文提出了HealthContradict数据集，用于评估语言模型在长且矛盾的生物医学上下文中的推理能力，发现微调后的生物医学模型既能利用正确上下文又能抵抗错误上下文。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何使用上下文信息回答健康问题，以及当上下文存在矛盾时模型的表现如何。现有医学问答评估基准在区分模型上下文推理能力方面不足，需要更精细的评估工具。

Method: 创建了HealthContradict数据集，包含920个专家验证的实例，每个实例包括健康问题、科学证据支持的事实答案以及两个立场矛盾的文档。设计了多种提示设置（正确、错误或矛盾上下文），测量它们对模型输出的影响。

Result: HealthContradict相比现有医学问答基准能更好地区分语言模型的上下文推理能力。实验表明，微调后的生物医学语言模型的优势不仅在于预训练获得的参数知识，还在于它们利用正确上下文同时抵抗错误上下文的能力。

Conclusion: 该研究强调了评估语言模型在矛盾信息中推理能力的重要性，HealthContradict数据集为此提供了有效的评估工具，揭示了生物医学语言模型在上下文利用和抵抗方面的双重能力。

Abstract: How do language models use contextual information to answer health questions? How are their responses impacted by conflicting contexts? We assess the ability of language models to reason over long, conflicting biomedical contexts using HealthContradict, an expert-verified dataset comprising 920 unique instances, each consisting of a health-related question, a factual answer supported by scientific evidence, and two documents presenting contradictory stances. We consider several prompt settings, including correct, incorrect or contradictory context, and measure their impact on model outputs. Compared to existing medical question-answering evaluation benchmarks, HealthContradict provides greater distinctions of language models' contextual reasoning capabilities. Our experiments show that the strength of fine-tuned biomedical language models lies not only in their parametric knowledge from pretraining, but also in their ability to exploit correct context while resisting incorrect context.

</details>


### [15] [When Does Verification Pay Off? A Closer Look at LLMs as Solution Verifiers](https://arxiv.org/abs/2512.02304)
*Jack Lu,Ryan Teehan,Jinran Jin,Mengye Ren*

Main category: cs.CL

TL;DR: 该研究系统分析了37个LLM在9个基准测试上的验证能力，发现跨模型族验证效果最好，后训练会降低自我改进但增强跨族改进，数学和逻辑任务具有最高的可验证性。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM作为问题求解器和解决方案验证器的交互作用研究有限，主要关注自我验证，很少考察验证器如何判断来自同族或不同族模型的输出。现代LLM经过大量后训练，但其对验证能力的影响尚不清楚。

Method: 研究涵盖37个模型，跨越多个模型族、不同规模以及基础版与后训练变体，在9个基准测试上进行评估，覆盖逻辑推理、结构化谜题、符号计算、数学、常识、事实回忆和领域知识。比较自我验证、同族验证和跨族验证，并引入经验验证的"验证器增益"指标来预测基于拒绝采样的性能改进。

Result: 1) 跨模型族验证特别有效；2) 后训练会降低自我改进但增强跨族改进；3) 数学和逻辑任务表现出最高的固有可验证性；4) 分析了验证器增益和误报率如何随模型规模和后训练而变化，并描述了数据集可验证性的差异。

Conclusion: 该研究为LLM验证能力提供了系统分析，揭示了跨模型族验证的优势、后训练对验证能力的影响以及不同任务类型的可验证性差异，为优化LLM验证策略提供了重要见解。

Abstract: Large language models (LLMs) can act as both problem solvers and solution verifiers, with verifiers improving solver performance by selecting high-quality answers from a pool of candidates. However, prior studies of solver-verifier interactions have been limited, focusing mainly on self-verification and rarely examining how verifiers judge outputs from models in their own or in another model family. Modern LLMs also undergo extensive post-training, but its effect on verification remains unclear. We present a systematic study across 37 models spanning multiple families, sizes, and base vs. post-trained variants, evaluated on 9 benchmarks covering logical reasoning, structured puzzles, symbolic computation, mathematics, commonsense, factual recall, and domain knowledge. We compare self-verification with verification within the same family and across different families. To support this, we introduce and empirically validate verifier gain, a metric that predicts the performance improvements from test-time verifier-based rejection sampling. We analyze how metrics like verifier gain and false positive rate scale with model size and post-training, and characterize differences in dataset verifiability. Our findings show that cross-family verification is especially effective; post-training reduces self-improvement but strengthens cross-family improvement; and mathematical and logical tasks exhibit the highest inherent verifiability.

</details>


### [16] [Memory-Augmented Knowledge Fusion with Safety-Aware Decoding for Domain-Adaptive Question Answering](https://arxiv.org/abs/2512.02363)
*Lei Fu,Xiang Chen,Kaige Gao Xinyue Huang,Kejian Tong*

Main category: cs.CL

TL;DR: KARMA框架通过双编码器融合结构化与非结构化知识、门控记忆单元动态调节外部知识、安全感知可控解码器，提升服务领域QA的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 服务领域QA系统面临整合异构知识源同时确保准确性和安全性的挑战，现有大语言模型在医疗政策、政府福利等敏感领域存在事实一致性和上下文对齐问题。

Method: 提出KARMA框架：1) 双编码器架构融合结构化与非结构化知识源；2) 门控记忆单元动态调节外部知识整合；3) 安全感知可控解码器，通过安全分类和引导生成技术减少不安全输出。

Result: 在专有QA数据集上的广泛实验表明，KARMA在答案质量和安全性方面均优于强基线模型。

Conclusion: 该研究为服务场景中构建可信赖且自适应的QA系统提供了全面解决方案。

Abstract: Domain-specific question answering (QA) systems for services face unique challenges in integrating heterogeneous knowledge sources while ensuring both accuracy and safety. Existing large language models often struggle with factual consistency and context alignment in sensitive domains such as healthcare policies and government welfare. In this work, we introduce Knowledge-Aware Reasoning and Memory-Augmented Adaptation (KARMA), a novel framework designed to enhance QA performance in care scenarios. KARMA incorporates a dual-encoder architecture to fuse structured and unstructured knowledge sources, a gated memory unit to dynamically regulate external knowledge integration, and a safety-aware controllable decoder that mitigates unsafe outputs using safety classification and guided generation techniques. Extensive experiments on a proprietary QA dataset demonstrate that KARMA outperforms strong baselines in both answer quality and safety. This study offers a comprehensive solution for building trustworthy and adaptive QA systems in service contexts.

</details>


### [17] [TaleFrame: An Interactive Story Generation System with Fine-Grained Control and Large Language Models](https://arxiv.org/abs/2512.02402)
*Yunchao Wang,Guodao Sun,Zihang Fu,Zhehao Liu,Kaixing Du,Haidong Gao,Ronghua Liang*

Main category: cs.CL

TL;DR: TaleFrame是一个结合LLM与HCI的故事生成系统，通过将故事结构分解为实体、事件、关系和故事大纲四个基本单元，实现结构化数据到连贯故事的转换，提供直观的交互界面和迭代优化功能。


<details>
  <summary>Details</summary>
Motivation: 当前故事生成系统难以准确将用户意图转化为满意的故事输出，主要原因是缺乏细粒度控制和输入规范不明确，限制了系统的实用性。

Method: 提出TaleFrame系统，将故事结构分解为四个基本单元：实体、事件、关系和故事大纲。利用Tinystories数据集构建包含9,851个JSON格式条目的偏好数据集，用于微调本地Llama模型。采用JSON2Story方法将结构化数据转换为连贯故事，并提供支持拖放、连接等交互操作的直观界面。

Result: 构建了包含9,851个JSON条目的数据集，开发了支持结构化故事生成的交互系统。通过七个维度（如创造力、结构完整性）评估生成的故事，并提供改进建议。定量评估和用户研究表明TaleFrame具有实用性。

Conclusion: TaleFrame通过结合LLM与HCI，实现了对故事生成过程的精确控制，解决了现有系统在意图翻译和细粒度控制方面的不足，为创意故事生成提供了有效的结构化方法。

Abstract: With the advancement of natural language generation (NLG) technologies, creative story generation systems have gained increasing attention. However, current systems often fail to accurately translate user intent into satisfactory story outputs due to a lack of fine-grained control and unclear input specifications, limiting their applicability. To address this, we propose TaleFrame, a system that combines large language models (LLMs) with human-computer interaction (HCI) to generate stories through structured information, enabling precise control over the generation process. The innovation of TaleFrame lies in decomposing the story structure into four basic units: entities, events, relationships, and story outline. We leverage the Tinystories dataset, parsing and constructing a preference dataset consisting of 9,851 JSON-formatted entries, which is then used to fine-tune a local Llama model. By employing this JSON2Story approach, structured data is transformed into coherent stories. TaleFrame also offers an intuitive interface that supports users in creating and editing entities and events and generates stories through the structured framework. Users can control these units through simple interactions (e.g., drag-and-drop, attach, and connect), thus influencing the details and progression of the story. The generated stories can be evaluated across seven dimensions (e.g., creativity, structural integrity), with the system providing suggestions for refinement based on these evaluations. Users can iteratively adjust the story until a satisfactory result is achieved. Finally, we conduct quantitative evaluation and user studies that demonstrate the usefulness of TaleFrame. Dataset available at https://huggingface.co/datasets/guodaosun/tale-frame.

</details>


### [18] [A Concise Review of Hallucinations in LLMs and their Mitigation](https://arxiv.org/abs/2512.02527)
*Parth Pulkundwar,Vivek Dhanawade,Rohit Yadav,Minal Sonkar,Medha Asurlekar,Sarita Rathod*

Main category: cs.CL

TL;DR: 本文综述了语言模型中的幻觉问题，分析了不同类型幻觉的成因，并总结了缓解方法，为理解这一关键挑战提供了全面资源。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型面临幻觉问题的严重挑战，这一问题对自然语言处理领域构成了重大威胁。理解当前存在的各种幻觉类型、其产生原因以及减少方法变得至关重要。

Method: 本文采用综述研究方法，系统性地整理和分析语言模型中的幻觉现象。通过文献回顾和综合分析，对幻觉进行分类、溯源，并总结现有的缓解策略。

Result: 提供了关于语言模型幻觉问题的全面概述，包括不同类型的幻觉分类、产生原因的系统分析，以及有效的缓解方法总结。

Conclusion: 该文档作为理解语言模型幻觉问题的一站式资源，为研究人员和从业者提供了关于这一关键挑战的简明而全面的指导，有助于推动更可靠的语言模型发展。

Abstract: Traditional language models face a challenge from hallucinations. Their very presence casts a large, dangerous shadow over the promising realm of natural language processing. It becomes crucial to understand the various kinds of hallucinations that occur nowadays, their origins, and ways of reducing them. This document provides a concise and straightforward summary of that. It serves as a one-stop resource for a general understanding of hallucinations and how to mitigate them.

</details>


### [19] [What Signals Really Matter for Misinformation Tasks? Evaluating Fake-News Detection and Virality Prediction under Real-World Constraints](https://arxiv.org/abs/2512.02552)
*Francesco Paolo Savatteri,Chahan Vidal-Gorène,Florian Cafiero*

Main category: cs.CL

TL;DR: 该研究评估了在线虚假信息检测的两个实际任务：假新闻检测和传播预测，比较了文本嵌入与轻量级数值特征的性能，发现文本内容对假新闻检测效果显著，而传播预测更具挑战性且对标签构建敏感。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于评估在线虚假信息处理的两个实际任务（假新闻检测和传播预测）在操作环境中的性能，考虑到需要快速响应的现实需求，比较不同方法的实用性和局限性。

Method: 使用EVONS和FakeNewsNet数据集，比较了文本嵌入方法（RoBERTa、Mistral）与轻量级数值特征（时间、粉丝数、验证状态、点赞数）以及序列模型（GRU、门控架构、Transformer编码器）。采用中位数分割法定义"传播"标签，并进行了降维分析（t-SNE vs PCA）。

Result: 文本内容单独使用对假新闻检测效果显著；数值特征管道在语言模型不可用或计算受限时仍可行；传播预测比假新闻检测困难得多，对标签构建高度敏感；降维分析显示非线性结构对传播预测比假新闻检测更有信息量；RoBERTa和Mistral嵌入的差异不大。

Conclusion: 文本嵌入是假新闻检测的强大工具，而传播预测需要更谨慎的评估设计。研究强调了现实操作约束对结果的影响，提供了数据集分割、代码和指标选择指导，呼吁关注评估设计的实际可行性。

Abstract: We present an evaluation-driven study of two practical tasks regarding online misinformation: (i) fake-news detection and (ii) virality prediction in the context of operational settings, with the necessity for rapid reaction. Using the EVONS and FakeNewsNet datasets, we compare textual embeddings (RoBERTa; with a control using Mistral) against lightweight numeric features (timing, follower counts, verification, likes) and sequence models (GRU, gating architectures, Transformer encoders). We show that textual content alone is a strong discriminator for fake-news detection, while numeric-only pipelines remain viable when language models are unavailable or compute is constrained. Virality prediction is markedly harder than fake-news detection and is highly sensitive to label construction; in our setup, a median-based ''viral'' split (<50 likes) is pragmatic but underestimates real-world virality, and time-censoring for engagement features is desirable yet difficult under current API limits. Dimensionality-reduction analyses suggest non-linear structure is more informative for virality than for fake-news detection (t-SNE > PCA on numeric features). Swapping RoBERTa for Mistral embeddings yields only modest deltas, leaving conclusions unchanged. We discuss implications for evaluation design and report reproducibility constraints that realistically affect the field. We release splits and code where possible and provide guidance for metric selection.

</details>


### [20] [ADORE: Autonomous Domain-Oriented Relevance Engine for E-commerce](https://arxiv.org/abs/2512.02555)
*Zheng Fang,Donghao Xie,Ming Pang,Chunyuan Yuan,Xue Jiang,Changping Peng,Zhangang Lin,Zheng Luo*

Main category: cs.CL

TL;DR: ADORE是一个自持的电商搜索相关性建模框架，通过LLM生成意图对齐的训练数据、自动合成对抗样本、以及知识蒸馏，解决传统方法语义鸿沟和神经网络样本稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 电商搜索相关性建模面临两个主要挑战：基于术语匹配的方法（如BM25）存在语义鸿沟，而神经模型依赖稀缺的领域特定困难样本。需要一种资源高效、认知对齐的解决方案。

Method: ADORE框架包含三个创新模块：1) 规则感知相关性判别模块：使用思维链LLM生成意图对齐的训练数据，并通过Kahneman-Tversky优化对齐用户行为；2) 错误类型感知数据合成模块：自动生成对抗样本来增强鲁棒性；3) 关键属性增强知识蒸馏模块：将领域特定属性层次注入可部署的学生模型。

Result: 大规模实验和在线A/B测试验证了ADORE的有效性。该框架为工业应用中的资源高效、认知对齐的相关性建模建立了新范式。

Conclusion: ADORE通过自动化标注、对抗生成和蒸馏，克服了数据稀缺问题，同时增强了推理能力，为电商搜索相关性建模提供了创新的自持解决方案。

Abstract: Relevance modeling in e-commerce search remains challenged by semantic gaps in term-matching methods (e.g., BM25) and neural models' reliance on the scarcity of domain-specific hard samples. We propose ADORE, a self-sustaining framework that synergizes three innovations: (1) A Rule-aware Relevance Discrimination module, where a Chain-of-Thought LLM generates intent-aligned training data, refined via Kahneman-Tversky Optimization (KTO) to align with user behavior; (2) An Error-type-aware Data Synthesis module that auto-generates adversarial examples to harden robustness; and (3) A Key-attribute-enhanced Knowledge Distillation module that injects domain-specific attribute hierarchies into a deployable student model. ADORE automates annotation, adversarial generation, and distillation, overcoming data scarcity while enhancing reasoning. Large-scale experiments and online A/B testing verify the effectiveness of ADORE. The framework establishes a new paradigm for resource-efficient, cognitively aligned relevance modeling in industrial applications.

</details>


### [21] [DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models](https://arxiv.org/abs/2512.02556)
*DeepSeek-AI,Aixin Liu,Aoxue Mei,Bangcai Lin,Bing Xue,Bingxuan Wang,Bingzheng Xu,Bochao Wu,Bowei Zhang,Chaofan Lin,Chen Dong,Chengda Lu,Chenggang Zhao,Chengqi Deng,Chenhao Xu,Chong Ruan,Damai Dai,Daya Guo,Dejian Yang,Deli Chen,Erhang Li,Fangqi Zhou,Fangyun Lin,Fucong Dai,Guangbo Hao,Guanting Chen,Guowei Li,H. Zhang,Hanwei Xu,Hao Li,Haofen Liang,Haoran Wei,Haowei Zhang,Haowen Luo,Haozhe Ji,Honghui Ding,Hongxuan Tang,Huanqi Cao,Huazuo Gao,Hui Qu,Hui Zeng,Jialiang Huang,Jiashi Li,Jiaxin Xu,Jiewen Hu,Jingchang Chen,Jingting Xiang,Jingyang Yuan,Jingyuan Cheng,Jinhua Zhu,Jun Ran,Junguang Jiang,Junjie Qiu,Junlong Li,Junxiao Song,Kai Dong,Kaige Gao,Kang Guan,Kexin Huang,Kexing Zhou,Kezhao Huang,Kuai Yu,Lean Wang,Lecong Zhang,Lei Wang,Liang Zhao,Liangsheng Yin,Lihua Guo,Lingxiao Luo,Linwang Ma,Litong Wang,Liyue Zhang,M. S. Di,M. Y Xu,Mingchuan Zhang,Minghua Zhang,Minghui Tang,Mingxu Zhou,Panpan Huang,Peixin Cong,Peiyi Wang,Qiancheng Wang,Qihao Zhu,Qingyang Li,Qinyu Chen,Qiushi Du,Ruiling Xu,Ruiqi Ge,Ruisong Zhang,Ruizhe Pan,Runji Wang,Runqiu Yin,Runxin Xu,Ruomeng Shen,Ruoyu Zhang,S. H. Liu,Shanghao Lu,Shangyan Zhou,Shanhuang Chen,Shaofei Cai,Shaoyuan Chen,Shengding Hu,Shengyu Liu,Shiqiang Hu,Shirong Ma,Shiyu Wang,Shuiping Yu,Shunfeng Zhou,Shuting Pan,Songyang Zhou,Tao Ni,Tao Yun,Tian Pei,Tian Ye,Tianyuan Yue,Wangding Zeng,Wen Liu,Wenfeng Liang,Wenjie Pang,Wenjing Luo,Wenjun Gao,Wentao Zhang,Xi Gao,Xiangwen Wang,Xiao Bi,Xiaodong Liu,Xiaohan Wang,Xiaokang Chen,Xiaokang Zhang,Xiaotao Nie,Xin Cheng,Xin Liu,Xin Xie,Xingchao Liu,Xingkai Yu,Xingyou Li,Xinyu Yang,Xinyuan Li,Xu Chen,Xuecheng Su,Xuehai Pan,Xuheng Lin,Xuwei Fu,Y. Q. Wang,Yang Zhang,Yanhong Xu,Yanru Ma,Yao Li,Yao Li,Yao Zhao,Yaofeng Sun,Yaohui Wang,Yi Qian,Yi Yu,Yichao Zhang,Yifan Ding,Yifan Shi,Yiliang Xiong,Ying He,Ying Zhou,Yinmin Zhong,Yishi Piao,Yisong Wang,Yixiao Chen,Yixuan Tan,Yixuan Wei,Yiyang Ma,Yiyuan Liu,Yonglun Yang,Yongqiang Guo,Yongtong Wu,Yu Wu,Yuan Cheng,Yuan Ou,Yuanfan Xu,Yuduan Wang,Yue Gong,Yuhan Wu,Yuheng Zou,Yukun Li,Yunfan Xiong,Yuxiang Luo,Yuxiang You,Yuxuan Liu,Yuyang Zhou,Z. F. Wu,Z. Z. Ren,Zehua Zhao,Zehui Ren,Zhangli Sha,Zhe Fu,Zhean Xu,Zhenda Xie,Zhengyan Zhang,Zhewen Hao,Zhibin Gou,Zhicheng Ma,Zhigang Yan,Zhihong Shao,Zhixian Huang,Zhiyu Wu,Zhuoshu Li,Zhuping Zhang,Zian Xu,Zihao Wang,Zihui Gu,Zijia Zhu,Zilin Li,Zipeng Zhang,Ziwei Xie,Ziyi Gao,Zizheng Pan,Zongqing Yao,Bei Feng,Hui Li,J. L. Cai,Jiaqi Ni,Lei Xu,Meng Li,Ning Tian,R. J. Chen,R. L. Jin,S. S. Li,Shuang Zhou,Tianyu Sun,X. Q. Li,Xiangyue Jin,Xiaojin Shen,Xiaosha Chen,Xinnan Song,Xinyi Zhou,Y. X. Zhu,Yanping Huang,Yaohui Li,Yi Zheng,Yuchen Zhu,Yunxian Ma,Zhen Huang,Zhipeng Xu,Zhongyu Zhang,Dongjie Ji,Jian Liang,Jianzhong Guo,Jin Chen,Leyi Xia,Miaojun Wang,Mingming Li,Peng Zhang,Ruyi Chen,Shangmian Sun,Shaoqing Wu,Shengfeng Ye,T. Wang,W. L. Xiao,Wei An,Xianzu Wang,Xiaowen Sun,Xiaoxiang Wang,Ying Tang,Yukun Zha,Zekai Zhang,Zhe Ju,Zhen Zhang,Zihua Qu*

Main category: cs.CL

TL;DR: DeepSeek-V3.2是一个高效推理模型，通过稀疏注意力机制和强化学习框架，在数学和信息学竞赛中达到顶尖水平，并具备强大的工具使用能力。


<details>
  <summary>Details</summary>
Motivation: 解决大模型计算效率与推理性能之间的平衡问题，开发一个既能高效计算又具备优秀推理和智能体性能的模型。

Method: 1. 提出DeepSeek稀疏注意力机制(DSA)，降低计算复杂度同时保持长上下文性能；2. 构建可扩展的强化学习框架，通过大规模后训练计算提升性能；3. 开发大规模智能体任务合成管道，系统生成训练数据以增强工具使用能力。

Result: DeepSeek-V3.2-Speciale版本超越GPT-5，推理能力与Gemini-3.0-Pro相当，在2025年国际数学奥林匹克(IMO)和国际信息学奥林匹克(IOI)中获得金牌表现。

Conclusion: DeepSeek-V3.2成功实现了计算效率与推理性能的平衡，通过创新的注意力机制和训练框架，在数学推理和智能体任务中达到顶尖水平，为高效大模型发展提供了新方向。

Abstract: We introduce DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance. The key technical breakthroughs of DeepSeek-V3.2 are as follows: (1) DeepSeek Sparse Attention (DSA): We introduce DSA, an efficient attention mechanism that substantially reduces computational complexity while preserving model performance in long-context scenarios. (2) Scalable Reinforcement Learning Framework: By implementing a robust reinforcement learning protocol and scaling post-training compute, DeepSeek-V3.2 performs comparably to GPT-5. Notably, our high-compute variant, DeepSeek-V3.2-Speciale, surpasses GPT-5 and exhibits reasoning proficiency on par with Gemini-3.0-Pro, achieving gold-medal performance in both the 2025 International Mathematical Olympiad (IMO) and the International Olympiad in Informatics (IOI). (3) Large-Scale Agentic Task Synthesis Pipeline: To integrate reasoning into tool-use scenarios, we developed a novel synthesis pipeline that systematically generates training data at scale. This methodology facilitates scalable agentic post-training, yielding substantial improvements in generalization and instruction-following robustness within complex, interactive environments.

</details>


### [22] [From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks](https://arxiv.org/abs/2512.02580)
*Changpeng Yang,Jinyang Wu,Yuchen Liu,Shuai Zhang,Yang Li,Qiliang Liang,Hongzhen Wang,Shuai Nie,Jiaming Xu,Runyu Shi,Ying Huang,Guoquan Zhang*

Main category: cs.CL

TL;DR: CAPO提出基于优势信号的课程学习机制，先使用正优势样本进行模仿学习建立基础，再引入负信号培养判别能力，提升复杂场景泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在训练早期不加区分地混合正负优势信号，可能导致模糊指导和有限收益，需要更精细的训练策略

Method: CAPO采用自适应课程机制：1) 启动阶段仅使用正优势样本进行模仿学习建立坚实基础；2) 后续阶段逐步引入负优势信号培养判别能力；3) 兼容多种优化方法如GRPO、PPO、RLOO、Reinforce++

Result: 在数学推理任务上实现稳定显著提升，并有效泛化到多模态GUI推理场景，证明其作为通用优化框架的鲁棒性

Conclusion: CAPO通过基于优势信号的课程学习机制，解决了现有方法中正负信号混合导致的训练问题，为强化学习优化大语言模型提供了更有效和通用的框架

Abstract: Reinforcement learning has emerged as a paradigm for post-training large language models, boosting their reasoning capabilities. Such approaches compute an advantage value for each sample, reflecting better or worse performance than expected, thereby yielding both positive and negative signals for training. However, the indiscriminate mixing of the two signals in existing methods, especially from the early stages, may lead to ambiguous guidance and limited gains. To address this issue, we propose **CAPO** (**C**urriculum **A**dvantage **P**olicy **O**ptimization), an adaptive curriculum mechanism based on advantage signals. The proposed mechanism bootstraps imitation learning with positive-only advantage samples to establish robust foundations, and subsequently introduces negative signals to cultivate discriminative capabilities, thereby improving generalization across complex scenarios. Compatible with diverse optimization methods including GRPO, PPO, RLOO, and Reinforce++, our method consistently achieves stable and significant improvements in mathematical reasoning tasks, and further generalizes effectively to multimodal Graphical User Interface (GUI) reasoning scenarios, establishing itself as a versatile and robust optimization framework.

</details>


### [23] [Spoken Conversational Agents with Large Language Models](https://arxiv.org/abs/2512.02593)
*Chao-Han Huck Yang,Andreas Stolcke,Larry Heck*

Main category: cs.CL

TL;DR: 该教程总结了从级联ASR/NLU系统到端到端、检索和视觉增强的语音对话代理的发展路径，提供了实用方法和系统级路线图。


<details>
  <summary>Details</summary>
Motivation: 随着语音对话代理向原生语音大语言模型发展，需要系统性地总结从传统级联架构到现代端到端方法的演进路径，为研究者和从业者提供清晰的路线图。

Method: 教程框架包括：文本LLM到音频的适配、跨模态对齐、联合语音文本训练；回顾数据集、评估指标、口音鲁棒性；比较级联vs端到端、ASR后修正、流式处理等设计选择。

Result: 建立了工业助手与当前开放域和任务导向代理的联系，突出了可复现的基线方法，并提供了实用配方和系统级路线图。

Conclusion: 教程为参与者提供了语音对话代理发展的全面视角，同时指出了隐私、安全和评估等开放性问题，为未来研究指明了方向。

Abstract: Spoken conversational agents are converging toward voice-native LLMs. This tutorial distills the path from cascaded ASR/NLU to end-to-end, retrieval-and vision-grounded systems. We frame adaptation of text LLMs to audio, cross-modal alignment, and joint speech-text training; review datasets, metrics, and robustness across accents and compare design choices (cascaded vs. E2E, post-ASR correction, streaming). We link industrial assistants to current open-domain and task-oriented agents, highlight reproducible baselines, and outline open problems in privacy, safety, and evaluation. Attendees leave with practical recipes and a clear systems-level roadmap.

</details>


### [24] [Input Order Shapes LLM Semantic Alignment in Multi-Document Summarization](https://arxiv.org/abs/2512.02665)
*Jing Ma*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在生成多文档摘要时存在显著的首位效应，即更倾向于与最先看到的文档保持语义对齐，这可能影响AI概览和智能体系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在Google AI概览等多文档摘要场景中的广泛应用，需要了解模型是否对所有输入文档给予同等权重，特别是可能存在的顺序偏见对摘要质量的影响。

Method: 构建40个支持-中立-反对立场的新闻文章三元组，每个三元组进行6种输入顺序排列，使用Gemini 2.5 Flash生成中立概览。通过ROUGE-L（词汇重叠）、BERTScore（语义相似度）和SummaC（事实一致性）评估摘要与源文档的对应关系，并进行单因素方差分析和成对比较。

Result: BERTScore分析显示在所有立场中都存在显著的首位效应，摘要与最先看到的文章语义对齐度更高。成对比较表明位置1与位置2、3有显著差异，而位置2和3之间无差异，确认了模型对第一个文档的选择性偏好。

Conclusion: LLM在多文档摘要中存在首位偏见，这可能对依赖AI概览的应用和智能体系统构成风险，因为涉及LLM的步骤可能不成比例地影响下游行动，需要采取措施减轻这种顺序偏见。

Abstract: Large language models (LLMs) are now used in settings such as Google's AI Overviews, where it summarizes multiple long documents. However, it remains unclear whether they weight all inputs equally. Focusing on abortion-related news, we construct 40 pro-neutral-con article triplets, permute each triplet into six input orders, and prompt Gemini 2.5 Flash to generate a neutral overview. We evaluate each summary against its source articles using ROUGE-L (lexical overlap), BERTScore (semantic similarity), and SummaC (factual consistency). One-way ANOVA reveals a significant primacy effect for BERTScore across all stances, indicating that summaries are more semantically aligned with the first-seen article. Pairwise comparisons further show that Position 1 differs significantly from Positions 2 and 3, while the latter two do not differ from each other, confirming a selective preference for the first document. The findings present risks for applications that rely on LLM-generated overviews and for agentic AI systems, where the steps involving LLMs can disproportionately influence downstream actions.

</details>


### [25] [An Empirical Survey of Model Merging Algorithms for Social Bias Mitigation](https://arxiv.org/abs/2512.02689)
*Daiki Shirafuji,Tatsuhiko Saito,Yasutomo Kimura*

Main category: cs.CL

TL;DR: 对7种模型合并算法在减轻LLM社会偏见方面的实证研究，发现偏见减少与下游性能之间存在权衡，SLERP在中等插值权重下表现最平衡


<details>
  <summary>Details</summary>
Motivation: 大型语言模型会继承和放大预训练语料中的社会偏见，威胁公平性和社会信任。虽然已有研究探索通过编辑LLM参数来减轻偏见，但缺乏对不同模型合并算法的实证比较。

Method: 实证调查7种模型合并算法（Linear、Karcher Mean、SLERP、NuSLERP、TIES、DELLA、Nearswap），应用于GPT、LLaMA和Qwen家族的13个开源权重模型。使用3个偏见数据集（BBQ、BOLD、HONEST）进行综合评估，并在SuperGLUE基准测试中测量这些技术对下游任务性能的影响。

Result: 发现偏见减少与下游性能之间存在权衡：实现更大偏见缓解的方法会降低准确性，特别是在需要阅读理解、常识和因果推理的任务上。在合并算法中，Linear、SLERP和Nearswap在保持整体性能的同时持续减少偏见，其中中等插值权重的SLERP是最平衡的选择。

Conclusion: 模型合并算法在偏见缓解方面具有潜力，但过度的去偏见化或不适当的合并方法可能导致重要语言能力的退化。SLERP在中等插值权重下提供了偏见减少与性能保持的最佳平衡。

Abstract: Large language models (LLMs) are known to inherit and even amplify societal biases present in their pre-training corpora, threatening fairness and social trust. To address this issue, recent work has explored ``editing'' LLM parameters to mitigate social bias with model merging approaches; however, there is no empirical comparison. In this work, we empirically survey seven algorithms: Linear, Karcher Mean, SLERP, NuSLERP, TIES, DELLA, and Nearswap, applying 13 open weight models in the GPT, LLaMA, and Qwen families. We perform a comprehensive evaluation using three bias datasets (BBQ, BOLD, and HONEST) and measure the impact of these techniques on LLM performance in downstream tasks of the SuperGLUE benchmark. We find a trade-off between bias reduction and downstream performance: methods achieving greater bias mitigation degrade accuracy, particularly on tasks requiring reading comprehension and commonsense and causal reasoning. Among the merging algorithms, Linear, SLERP, and Nearswap consistently reduce bias while maintaining overall performance, with SLERP at moderate interpolation weights emerging as the most balanced choice. These results highlight the potential of model merging algorithms for bias mitigation, while indicating that excessive debiasing or inappropriate merging methods may lead to the degradation of important linguistic abilities.

</details>


### [26] [CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer](https://arxiv.org/abs/2512.02711)
*Lavish Bansal,Naman Mishra*

Main category: cs.CL

TL;DR: CREST是一个参数高效的多语言安全分类模型，仅用0.5B参数支持100种语言，通过在13种高资源语言上训练，利用基于聚类的跨语言迁移实现对新语言的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全护栏主要针对高资源语言，导致使用低资源语言的大量人口代表性不足，需要开发支持多语言的通用安全系统。

Method: 提出CREST模型，通过仅在13种高资源语言上训练，利用基于聚类的跨语言迁移技术，将安全知识从少数语言扩展到100种语言，包括未见的高资源和低资源语言。

Result: 在六个安全基准测试中，CREST优于同规模的最先进护栏，并与参数量大得多的模型（2.5B参数及以上）取得竞争性结果。

Conclusion: 语言特定安全护栏存在局限性，需要开发能够有效扩展以服务全球人口的通用、语言无关的安全系统。

Abstract: Ensuring content safety in large language models (LLMs) is essential for their deployment in real-world applications. However, existing safety guardrails are predominantly tailored for high-resource languages, leaving a significant portion of the world's population underrepresented who communicate in low-resource languages. To address this, we introduce CREST (CRoss-lingual Efficient Safety Transfer), a parameter-efficient multilingual safety classification model that supports 100 languages with only 0.5B parameters. By training on a strategically chosen subset of only 13 high-resource languages, our model utilizes cluster-based cross-lingual transfer from a few to 100 languages, enabling effective generalization to both unseen high-resource and low-resource languages. This approach addresses the challenge of limited training data in low-resource settings. We conduct comprehensive evaluations across six safety benchmarks to demonstrate that CREST outperforms existing state-of-the-art guardrails of comparable scale and achieves competitive results against models with significantly larger parameter counts (2.5B parameters and above). Our findings highlight the limitations of language-specific guardrails and underscore the importance of developing universal, language-agnostic safety systems that can scale effectively to serve global populations.

</details>


### [27] [Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs](https://arxiv.org/abs/2512.02719)
*Julian Ma,Jun Wang,Zafeirios Fountas*

Main category: cs.CL

TL;DR: LLMs在显式推理表现出色，但隐式计算策略未充分探索。研究通过心理物理学范式评估LLMs是否表现出类似人类的贝叶斯最优多模态整合能力，发现准确率与贝叶斯一致性存在分离。


<details>
  <summary>Details</summary>
Motivation: 人类在感知任务中能直觉地使用接近最优的贝叶斯策略处理噪声信号，但LLMs的隐式计算策略是否表现出类似行为尚不清楚。研究旨在探索LLMs是否能在未经显式训练或指导的情况下进行最优多模态整合。

Method: 采用心理物理学范式，创建BayesBench基准：包含长度、位置、距离和持续时间四个文本和图像的量级估计任务。评估9个不同LLMs并与人类判断对比。通过控制噪声、上下文和指令提示的消融实验，测量多模态线索整合的性能、行为和效率。引入贝叶斯一致性分数来检测贝叶斯一致的行为变化。

Result: 虽然能力强的模型通常以贝叶斯一致的方式适应，但准确率不能保证鲁棒性。GPT-5 Mini在文本任务上达到完美准确率，但在视觉线索整合上效率低下。这表明能力与策略存在关键分离，准确率中心的基准可能高估性能而忽略了脆弱的确定性处理。

Conclusion: 研究发现LLMs在处理不确定性方面出现了原则性方法，准确率与贝叶斯倾向存在相关性。研究发布的心理物理学基准和一致性指标可作为评估工具，并为未来多模态架构设计提供信息。

Abstract: Large language models (LLMs) excel at explicit reasoning, but their implicit computational strategies remain underexplored. Decades of psychophysics research show that humans intuitively process and integrate noisy signals using near-optimal Bayesian strategies in perceptual tasks. We ask whether LLMs exhibit similar behaviour and perform optimal multimodal integration without explicit training or instruction. Adopting the psychophysics paradigm, we infer computational principles of LLMs from systematic behavioural studies. We introduce a behavioural benchmark - BayesBench: four magnitude estimation tasks (length, location, distance, and duration) over text and image, inspired by classic psychophysics, and evaluate a diverse set of nine LLMs alongside human judgments for calibration. Through controlled ablations of noise, context, and instruction prompts, we measure performance, behaviour and efficiency in multimodal cue-combination. Beyond accuracy and efficiency metrics, we introduce a Bayesian Consistency Score that detects Bayes-consistent behavioural shifts even when accuracy saturates. Our results show that while capable models often adapt in Bayes-consistent ways, accuracy does not guarantee robustness. Notably, GPT-5 Mini achieves perfect text accuracy but fails to integrate visual cues efficiently. This reveals a critical dissociation between capability and strategy, suggesting accuracy-centric benchmarks may over-index on performance while missing brittle uncertainty handling. These findings reveal emergent principled handling of uncertainty and highlight the correlation between accuracy and Bayesian tendencies. We release our psychophysics benchmark and consistency metric (https://bayes-bench.github.io) as evaluation tools and to inform future multimodal architecture designs.

</details>


### [28] [SurveyEval: Towards Comprehensive Evaluation of LLM-Generated Academic Surveys](https://arxiv.org/abs/2512.02763)
*Jiahao Zhao,Shuaixing Zhang,Nan Xu,Lei Wang*

Main category: cs.CL

TL;DR: SurveyEval是一个用于评估LLM自动生成调研报告的综合基准，从整体质量、大纲连贯性和参考文献准确性三个维度进行评估，通过7个学科领域的测试发现专用调研生成系统比通用长文本系统表现更好。


<details>
  <summary>Details</summary>
Motivation: 随着LLM自动调研系统的发展，这些系统能够整合检索、组织和内容合成到端到端生成流程中。然而，如何评估这种复杂系统仍然是一个重大挑战，现有研究主要关注开发新的生成流程，缺乏系统性的评估方法。

Method: 提出了SurveyEval基准，从三个维度评估自动生成的调研报告：整体质量、大纲连贯性和参考文献准确性。在7个不同学科领域进行扩展评估，并增强LLM-as-a-Judge框架，加入人类参考以加强评估与人类判断的一致性。

Result: 评估结果显示，通用长文本或论文写作系统倾向于生成质量较低的调研报告，而专门的调研生成系统能够提供显著更高质量的成果。SurveyEval能够有效区分不同系统的性能差异。

Conclusion: SurveyEval作为一个可扩展的测试平台，有助于理解和改进跨不同学科和评估标准的自动调研系统，为未来研究提供了系统性的评估框架。

Abstract: LLM-based automatic survey systems are transforming how users acquire information from the web by integrating retrieval, organization, and content synthesis into end-to-end generation pipelines. While recent works focus on developing new generation pipelines, how to evaluate such complex systems remains a significant challenge. To this end, we introduce SurveyEval, a comprehensive benchmark that evaluates automatically generated surveys across three dimensions: overall quality, outline coherence, and reference accuracy. We extend the evaluation across 7 subjects and augment the LLM-as-a-Judge framework with human references to strengthen evaluation-human alignment. Evaluation results show that while general long-text or paper-writing systems tend to produce lower-quality surveys, specialized survey-generation systems are able to deliver substantially higher-quality results. We envision SurveyEval as a scalable testbed to understand and improve automatic survey systems across diverse subjects and evaluation criteria.

</details>


### [29] [PEFT-Factory: Unified Parameter-Efficient Fine-Tuning of Autoregressive Large Language Models](https://arxiv.org/abs/2512.02764)
*Robert Belanec,Ivan Srba,Maria Bielikova*

Main category: cs.CL

TL;DR: PEFT-Factory是一个统一的参数高效微调框架，提供19种PEFT方法、27个数据集和专用评估指标，旨在解决PEFT方法难以复现、部署和比较的问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模增大，参数高效微调方法变得重要，但现有方法难以复现、部署和相互比较，需要统一框架来解决这些问题。

Method: 基于LLaMA-Factory开发PEFT-Factory框架，采用模块化设计，原生支持19种PEFT方法、27个分类和文本生成数据集，并提供标准及PEFT专用评估指标。

Result: PEFT-Factory提供了一个即用、可控且稳定的环境，显著提高了PEFT方法的可复现性和基准测试能力。

Conclusion: PEFT-Factory作为统一框架，有效解决了PEFT方法在复现、部署和比较方面的挑战，为参数高效微调研究提供了标准化工具。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods address the increasing size of Large Language Models (LLMs). Currently, many newly introduced PEFT methods are challenging to replicate, deploy, or compare with one another. To address this, we introduce PEFT-Factory, a unified framework for efficient fine-tuning LLMs using both off-the-shelf and custom PEFT methods. While its modular design supports extensibility, it natively provides a representative set of 19 PEFT methods, 27 classification and text generation datasets addressing 12 tasks, and both standard and PEFT-specific evaluation metrics. As a result, PEFT-Factory provides a ready-to-use, controlled, and stable environment, improving replicability and benchmarking of PEFT methods. PEFT-Factory is a downstream framework that originates from the popular LLaMA-Factory, and is publicly available at https://github.com/kinit-sk/PEFT-Factory

</details>


### [30] [Towards Unification of Hallucination Detection and Fact Verification for Large Language Models](https://arxiv.org/abs/2512.02772)
*Weihang Su,Jianming Long,Changyue Wang,Shiyu Lin,Jingyan Xu,Ziyi Ye,Qingyao Ai,Yiqun Liu*

Main category: cs.CL

TL;DR: UniFact是一个统一评估框架，用于直接比较事实验证和幻觉检测两种方法，发现两者互补，混合方法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常产生幻觉（看似流畅但事实错误的输出），这影响了实际应用。目前存在模型中心的幻觉检测和文本中心的事实验证两种研究范式，但它们各自独立发展，缺乏统一比较，阻碍了进展。

Method: 提出UniFact统一评估框架，通过动态生成模型输出和相应的事实标签，实现事实验证和幻觉检测在实例级别的直接比较。在多个LLM家族和检测方法上进行大规模实验。

Result: 三个关键发现：1) 没有哪种范式普遍更优；2) 幻觉检测和事实验证捕捉了事实错误的不同方面，具有互补性；3) 整合两种方法的混合方法始终达到最先进的性能。

Conclusion: 需要一个新的整合研究议程，将幻觉检测和事实验证统一起来。两种方法的分歧有深层原因，但实证证据支持它们的统一。开源了所有代码、数据和基准实现。

Abstract: Large Language Models (LLMs) frequently exhibit hallucinations, generating content that appears fluent and coherent but is factually incorrect. Such errors undermine trust and hinder their adoption in real-world applications. To address this challenge, two distinct research paradigms have emerged: model-centric Hallucination Detection (HD) and text-centric Fact Verification (FV). Despite sharing the same goal, these paradigms have evolved in isolation, using distinct assumptions, datasets, and evaluation protocols. This separation has created a research schism that hinders their collective progress. In this work, we take a decisive step toward bridging this divide. We introduce UniFact, a unified evaluation framework that enables direct, instance-level comparison between FV and HD by dynamically generating model outputs and corresponding factuality labels. Through large-scale experiments across multiple LLM families and detection methods, we reveal three key findings: (1) No paradigm is universally superior; (2) HD and FV capture complementary facets of factual errors; and (3) hybrid approaches that integrate both methods consistently achieve state-of-the-art performance. Beyond benchmarking, we provide the first in-depth analysis of why FV and HD diverged, as well as empirical evidence supporting the need for their unification. The comprehensive experimental results call for a new, integrated research agenda toward unifying Hallucination Detection and Fact Verification in LLMs.
  We have open-sourced all the code, data, and baseline implementation at: https://github.com/oneal2000/UniFact/

</details>


### [31] [Making Dialogue Grounding Data Rich: A Three-Tier Data Synthesis Framework for Generalized Referring Expression Comprehension](https://arxiv.org/abs/2512.02791)
*Juexi Shao,Siyou Li,Yujian Gan,Chris Madge,Vanja Karan,Massimo Poesio*

Main category: cs.CL

TL;DR: 提出三层次数据合成方法解决对话式广义指代表达理解中的分布偏移问题，通过平衡真实性和可控性生成可扩展的监督数据，显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 对话式广义指代表达理解（GREC）需要在复杂视觉场景中定位表达和无限目标，同时解决长对话上下文中的共指问题。现有系统在训练和评估领域之间的分布偏移上表现不佳，且标注对话接地数据稀缺加剧了这一挑战

Method: 采用三层次数据合成方法，平衡真实性和可控性，为对话条件接地生成可扩展的监督数据

Result: 在合成数据上微调模型，相比先前方法在标准评估指标上取得一致且显著的改进

Conclusion: 提出的数据合成方法有效解决了对话式GREC中的分布偏移和数据稀缺问题，为模型提供了可扩展的监督信号，显著提升了性能

Abstract: Dialogue-Based Generalized Referring Expressions Comprehension (GREC) requires models to ground the expression and unlimited targets in complex visual scenes while resolving coreference across a long dialogue context. However, existing systems struggle under distribution shift between training and evaluation domains, a gap exacerbated by the scarcity of annotated dialogue grounding data. We address this challenge with a three-tier data-synthesis method that balances realism and controllability to produce scalable supervision for dialogue-conditioned grounding. Fine-tuning on the synthesized data yields consistent, substantial improvements over prior approaches across standard evaluation metrics.

</details>


### [32] [TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages](https://arxiv.org/abs/2512.02799)
*Mike Nkongolo,Hilton Vorster,Josh Warren,Trevor Naick,Deandre Vanmali,Masana Mashapha,Luke Brand,Alyssa Fernandes,Janco Calitz,Sibusiso Makhoba*

Main category: cs.CL

TL;DR: TriLex框架通过三阶段检索增强方法扩展低资源非洲语言的情感词典，提升情感分析性能，AfroXLMR在isiXhosa和isiZulu上F1分数超过80%。


<details>
  <summary>Details</summary>
Motivation: 低资源非洲语言在情感分析中代表性不足，限制了多语言NLP系统的词汇覆盖和性能，需要系统化的词典扩展方法。

Method: 提出TriLex三阶段框架：1) 基于语料库的提取；2) 跨语言映射；3) 检索增强生成驱动的词汇精炼。使用扩展后的词典评估AfroXLMR和AfriBERTa两种非洲预训练语言模型。

Result: AfroXLMR表现最佳，在isiXhosa和isiZulu上F1分数超过80%，跨语言稳定性强。AfriBERTa虽未在目标语言上预训练，仍能达到约64%的F1分数。两种模型均优于传统机器学习基线，集成分析进一步提升了精度和鲁棒性。

Conclusion: TriLex是扩展低资源南非语言多语言情感词典和情感建模的可扩展有效框架，为低资源语言NLP提供了实用解决方案。

Abstract: Low-resource African languages remain underrepresented in sentiment analysis, limiting both lexical coverage and the performance of multilingual Natural Language Processing (NLP) systems. This study proposes TriLex, a three-stage retrieval augmented framework that unifies corpus-based extraction, cross lingual mapping, and retrieval augmented generation (RAG) driven lexical refinement to systematically expand sentiment lexicons for low-resource languages. Using the enriched lexicon, the performance of two prominent African pretrained language models (AfroXLMR and AfriBERTa) is evaluated across multiple case studies. Results demonstrate that AfroXLMR delivers superior performance, achieving F1-scores above 80% for isiXhosa and isiZulu and exhibiting strong cross-lingual stability. Although AfriBERTa lacks pre-training on these target languages, it still achieves reliable F1-scores around 64%, validating its utility in computationally constrained settings. Both models outperform traditional machine learning baselines, and ensemble analyses further enhance precision and robustness. The findings establish TriLex as a scalable and effective framework for multilingual sentiment lexicon expansion and sentiment modeling in low-resource South African languages.

</details>


### [33] [SR-GRPO: Stable Rank as an Intrinsic Geometric Reward for Large Language Model Alignment](https://arxiv.org/abs/2512.02807)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 提出stable rank作为无需人工标注的LLM质量信号，通过测量隐藏状态的有效维度来评估回答质量，并基于此开发了SR-GRPO强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法依赖外部监督存在局限：人工标注稀缺且主观，奖励模型易受奖励攻击，自评估方法存在提示敏感性和偏见。需要寻找无需外部监督的内在质量信号。

Method: 提出stable rank概念，通过计算总方差与主导方向方差的比率来测量隐藏状态的有效维度，捕捉信息在表示维度上的分布。基于此开发Stable Rank Group Relative Policy Optimization (SR-GRPO)，使用stable rank作为强化学习的奖励信号。

Result: stable rank在RewardBench上达到84.04%准确率，通过Best-of-N采样比贪婪解码平均提高11.3个百分点任务准确率。SR-GRPO无需外部监督将Qwen2.5-1.5B-Instruct在STEM任务上提升10%，数学推理提升19%，优于学习奖励模型和自评估基线。

Conclusion: 质量信号可以从模型内部几何结构中提取，为无需外部监督的可扩展对齐提供了新路径，stable rank作为内在、无需标注的质量信号在多个基准上表现优异。

Abstract: Aligning Large Language Models (LLMs) with human preferences typically relies on external supervision, which faces critical limitations: human annotations are scarce and subjective, reward models are vulnerable to reward hacking, and self-evaluation methods suffer from prompt sensitivity and biases. In this work, we propose stable rank, an intrinsic, annotation-free quality signal derived from model representations. Stable rank measures the effective dimensionality of hidden states by computing the ratio of total variance to dominant-direction variance, capturing quality through how information distributes across representation dimensions. Empirically, stable rank achieves 84.04% accuracy on RewardBench and improves task accuracy by an average of 11.3 percentage points over greedy decoding via Best-of-N sampling. Leveraging this insight, we introduce Stable Rank Group Relative Policy Optimization (SR-GRPO), which uses stable rank as a reward signal for reinforcement learning. Without external supervision, SR-GRPO improves Qwen2.5-1.5B-Instruct by 10% on STEM and 19% on mathematical reasoning, outperforming both learned reward models and self-evaluation baselines. Our findings demonstrate that quality signals can be extracted from internal model geometry, offering a path toward scalable alignment without external supervision.

</details>


### [34] [A benchmark dataset for evaluating Syndrome Differentiation and Treatment in large language models](https://arxiv.org/abs/2512.02816)
*Kunning Li,Jianbin Guo,Zhaoyang Shang,Yiqing Liu,Hongmin Du,Lingling Liu,Yuping Zhao,Lifeng Dong*

Main category: cs.CL

TL;DR: 本文提出了TCM-BEST4SDT基准，用于评估大语言模型在中医辨证论治临床应用中的能力，包含四个任务和三种评估机制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在中医领域的应用日益增多，但现有评估方法局限于知识问答或证候诊断准确性，缺乏对治疗决策能力的评估。中医"辨证论治"具有个体化、整体性和多样性的特点，需要更全面的临床能力评估基准。

Method: 提出基于临床病例的综合基准TCM-BEST4SDT，包含中医基础知识、医学伦理、LLM内容安全和辨证论治四个任务。采用三种评估机制：选择题评估、评判模型评估和专门设计的奖励模型评估（用于量化处方-证候一致性）。数据标注遵循严格流程，由中医专家主导。

Result: 在15个主流大语言模型（包括通用和中医领域模型）上验证了TCM-BEST4SDT的有效性。基准已公开可用，以促进智能中医研究发展。

Conclusion: TCM-BEST4SDT是一个全面、临床案例驱动的基准，能够有效评估LLMs在中医辨证论治中的临床应用能力，填补了现有评估在治疗决策方面的空白。

Abstract: The emergence of Large Language Models (LLMs) within the Traditional Chinese Medicine (TCM) domain presents an urgent need to assess their clinical application capabilities. However, such evaluations are challenged by the individualized, holistic, and diverse nature of TCM's "Syndrome Differentiation and Treatment" (SDT). Existing benchmarks are confined to knowledge-based question-answering or the accuracy of syndrome differentiation, often neglecting assessment of treatment decision-making. Here, we propose a comprehensive, clinical case-based benchmark spearheaded by TCM experts, and a specialized reward model employed to quantify prescription-syndrome congruence. Data annotation follows a rigorous pipeline. This benchmark, designated TCM-BEST4SDT, encompasses four tasks, including TCM Basic Knowledge, Medical Ethics, LLM Content Safety, and SDT. The evaluation framework integrates three mechanisms, namely selected-response evaluation, judge model evaluation, and reward model evaluation. The effectiveness of TCM-BEST4SDT was corroborated through experiments on 15 mainstream LLMs, spanning both general and TCM domains. To foster the development of intelligent TCM research, TCM-BEST4SDT is now publicly available.

</details>


### [35] [BOOM: Beyond Only One Modality KIT's Multimodal Multilingual Lecture Companion](https://arxiv.org/abs/2512.02817)
*Sai Koneru,Fabian Retkowski,Christian Huber,Lukas Hilgert,Seymanur Akti,Enes Yavuz Ugan,Alexander Waibel,Jan Niehues*

Main category: cs.CL

TL;DR: BOOM是一个多模态多语言讲座伴侣，能同时翻译讲座音频和幻灯片，生成同步的文本、本地化幻灯片和合成语音输出。


<details>
  <summary>Details</summary>
Motivation: 教育全球化和在线学习的快速增长使得教育内容本地化成为关键挑战。讲座材料本质上是多模态的（音频+视觉幻灯片），需要能处理多种输入模态的系统。为了提供完整的学习体验，翻译必须保留所有模态：文本、幻灯片和语音。

Method: 提出BOOM多模态多语言讲座伴侣，采用端到端方法联合翻译讲座音频和幻灯片，生成同步的三种模态输出：翻译文本、保留视觉元素的本地化幻灯片、合成语音。该方法还利用幻灯片感知的转录本，对下游任务（如摘要和问答）产生级联效益。

Result: 实验表明，幻灯片感知的转录本对下游任务（如摘要和问答）有级联效益。作者发布了Slide Translation代码并集成到Lecture Translator中。

Conclusion: BOOM系统能为学生提供母语访问讲座的完整体验，同时保留原始内容的完整性。这种端到端的多模态翻译方法在教育本地化方面具有重要价值。

Abstract: The globalization of education and rapid growth of online learning have made localizing educational content a critical challenge. Lecture materials are inherently multimodal, combining spoken audio with visual slides, which requires systems capable of processing multiple input modalities. To provide an accessible and complete learning experience, translations must preserve all modalities: text for reading, slides for visual understanding, and speech for auditory learning. We present \textbf{BOOM}, a multimodal multilingual lecture companion that jointly translates lecture audio and slides to produce synchronized outputs across three modalities: translated text, localized slides with preserved visual elements, and synthesized speech. This end-to-end approach enables students to access lectures in their native language while aiming to preserve the original content in its entirety. Our experiments demonstrate that slide-aware transcripts also yield cascading benefits for downstream tasks such as summarization and question answering. We release our Slide Translation code at https://github.com/saikoneru/image-translator and integrate it in Lecture Translator at https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline}\footnote{All released code and models are licensed under the MIT License.

</details>


### [36] [promptolution: A Unified, Modular Framework for Prompt Optimization](https://arxiv.org/abs/2512.02840)
*Tom Zehle,Timo Heiß,Moritz Schlager,Matthias Aßenmacher,Matthias Feurer*

Main category: cs.CL

TL;DR: promptolution：一个统一、模块化的开源框架，用于提示优化，整合多种离散提示优化器，与底层LLM实现无关


<details>
  <summary>Details</summary>
Motivation: 尽管许多研究论文证明了提示优化的有效性，但实际应用受到阻碍，因为现有实现通常依赖于未维护和孤立的研究代码库。需要统一的框架来促进提示优化的实际采用。

Method: 开发promptolution框架，这是一个统一、模块化的开源系统，集成了多种当代离散提示优化器，同时保持与底层LLM实现的无关性，为从业者和研究人员提供可扩展的组件。

Result: 创建了一个完整的提示优化框架，将所有必要组件整合到单个可扩展系统中，支持多种离散提示优化器，并保持与不同LLM实现的兼容性。

Conclusion: promptolution框架解决了提示优化研究代码分散和难以维护的问题，为研究者和实践者提供了一个统一、可扩展的平台，促进了提示优化技术的实际应用。

Abstract: Prompt optimization has become crucial for enhancing the performance of large language models (LLMs) across a broad range of tasks. Although many research papers show its effectiveness, practical adoption is hindered as existing implementations are often tied to unmaintained and isolated research codebases. To address this, we introduce promptolution, a unified and modular open-source framework that provides all components required for prompt optimization within a single extensible system for both practitioners and researchers. It integrates multiple contemporary discrete prompt optimizers while remaining agnostic to the underlying LLM implementation.

</details>


### [37] [Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages](https://arxiv.org/abs/2512.02841)
*Lechen Zhang,Yusheng Zhou,Tolga Ergen,Lajanugen Logeswaran,Moontae Lee,David Jurgens*

Main category: cs.CL

TL;DR: 本文提出一个评估框架，通过大规模实验发现某些提示组件与稳健的多语言行为相关，并开发了多语言提示优化框架，可自动发现能提升5-10%性能的提示。


<details>
  <summary>Details</summary>
Motivation: 系统提示为大型语言模型提供轻量级但强大的推理时条件机制。现有研究主要集中在英语环境，而实际部署需要单一提示能在多种语言中可靠工作。本文旨在研究不同系统提示如何引导模型实现准确和稳健的跨语言行为。

Method: 提出统一的四维评估框架来评估多语言环境中的系统提示。通过五个语言、三个LLM和三个基准的大规模实验，分析提示组件与多语言行为的相关性。开发多语言提示优化框架，并分析超过1000万个推理单元。

Result: 发现某些提示组件（如CoT、情感和场景）与稳健的多语言行为相关。提示优化框架能自动发现提升所有指标5-10%的提示。更有效的系统提示能诱导更结构化、一致性的推理模式，同时减少不必要的语言切换。

Conclusion: 系统提示优化是实现准确和稳健多语言LLM行为的可扩展路径。研究强调了通过优化系统提示来提升跨语言性能的重要性。

Abstract: System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.

</details>


### [38] [Bangla Hate Speech Classification with Fine-tuned Transformer Models](https://arxiv.org/abs/2512.02845)
*Yalda Keivan Jafari,Krishno Dey*

Main category: cs.CL

TL;DR: 该研究针对孟加拉语仇恨言论检测任务，复现了官方基线方法并测试了多种Transformer模型，发现语言特定预训练的BanglaBERT在低资源孟加拉语任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的仇恨言论检测面临数据集不足、拼写异质性和语言多样性等挑战。孟加拉语作为拥有超过2.3亿使用者的语言，在计算资源方面代表性严重不足，而社交媒体平台对自动化内容审核的需求日益增长。

Method: 研究BLP 2025共享任务的子任务1A和1B，复现官方基线方法（多数投票、随机、支持向量机），并增加了逻辑回归、随机森林和决策树作为基线。同时使用了基于Transformer的模型，包括DistilBERT、BanglaBERT、m-BERT和XLM-RoBERTa进行仇恨言论分类。

Result: 所有基于Transformer的模型（除DistilBERT外）在子任务中都优于基线方法。在Transformer模型中，BanglaBERT在两个子任务中都取得了最佳性能。尽管规模较小，BanglaBERT的表现超过了m-BERT和XLM-RoBERTa。

Conclusion: 语言特定的预训练对于低资源语言任务至关重要。研究结果强调了预训练语言模型在低资源孟加拉语中的潜力和必要性，BanglaBERT的成功表明针对特定语言进行预训练能显著提升性能。

Abstract: Hate speech recognition in low-resource languages remains a difficult problem due to insufficient datasets, orthographic heterogeneity, and linguistic variety. Bangla is spoken by more than 230 million people of Bangladesh and India (West Bengal). Despite the growing need for automated moderation on social media platforms, Bangla is significantly under-represented in computational resources. In this work, we study Subtask 1A and Subtask 1B of the BLP 2025 Shared Task on hate speech detection. We reproduce the official baselines (e.g., Majority, Random, Support Vector Machine) and also produce and consider Logistic Regression, Random Forest, and Decision Tree as baseline methods. We also utilized transformer-based models such as DistilBERT, BanglaBERT, m-BERT, and XLM-RoBERTa for hate speech classification. All the transformer-based models outperformed baseline methods for the subtasks, except for DistilBERT. Among the transformer-based models, BanglaBERT produces the best performance for both subtasks. Despite being smaller in size, BanglaBERT outperforms both m-BERT and XLM-RoBERTa, which suggests language-specific pre-training is very important. Our results highlight the potential and need for pre-trained language models for the low-resource Bangla language.

</details>


### [39] [Think in Parallel, Answer as One: Logit Averaging for Open-Ended Reasoning](https://arxiv.org/abs/2512.02874)
*Haonan Wang,Chao Du,Kenji Kawaguchi,Tianyu Pang*

Main category: cs.CL

TL;DR: ThinkMerge是一种无需训练的解码策略，通过并行推理轨迹的logit平均来提升开放端推理任务性能，优于多数投票方法


<details>
  <summary>Details</summary>
Motivation: 多数投票在封闭式问答中有效，但不适用于代码生成和网络深度研究等开放式推理任务，因为在这些任务中"多数"完整解决方案难以定义

Method: 提出ThinkMerge解码策略：运行K个并行推理轨迹，在同步点平均它们的下一个token logits，产生单个连贯输出；与vLLM/SGLang无缝集成，兼容Top-p/Top-k等标准解码技术

Result: 在AIME和GPQA上匹配或超越多数投票；在LiveCodeBench（hard）上，DeepCoder-14B-Preview的pass@1提升+8.28%，Qwen3-8B提升+7.58%；在GAIA、BrowseComp-en/zh和XbenchDeepSearch上提升网络深度研究代理性能

Conclusion: 并行测试时扩展可以在不依赖完整输出投票的情况下有益于开放式推理，ThinkMerge为开放端任务提供了有效的解码策略

Abstract: Majority voting has proven effective for close-ended question answering by aggregating parallel reasoning traces. However, it is not directly applicable to open-ended reasoning, such as code generation and web-based deep research, where a "majority" over complete solutions is ill-defined. We introduce ThinkMerge, a training-free, plug-and-play decoding strategy that runs K parallel reasoning traces and averages their next-token logits at synchronization points to produce a single coherent output. ThinkMerge integrates seamlessly with vLLM/SGLang and remains compatible with standard decoding techniques such as Top-p/Top-k. Empirically, it matches or surpasses majority voting on AIME and GPQA, while delivering consistent gains on open-ended coding tasks: on LiveCodeBench (hard), pass@1 improves by +8.28% for DeepCoder-14B-Preview and +7.58% for Qwen3-8B. Beyond code, we further show that ThinkMerge improves web-based deep-research agents (e.g., WebSailor-7B/32B) across GAIA, BrowseComp-en/zh, and XbenchDeepSearch. These results demonstrate that parallel test-time scaling can benefit open-ended reasoning without relying on voting over complete outputs.

</details>


### [40] [Fast-Decoding Diffusion Language Models via Progress-Aware Confidence Schedules](https://arxiv.org/abs/2512.02892)
*Amr Mohamed,Yang Zhang,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.CL

TL;DR: SchED是一种无需训练、模型无关的早期退出算法，通过聚合全跨度logit边际并在满足平滑的进度相关置信度阈值时停止解码，显著加速扩散大语言模型的推理速度，同时保持接近原始模型的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型(dLLMs)相比自回归模型有潜力，但其迭代采样过程缓慢，严重限制了实际应用。需要一种能够在不牺牲性能的前提下加速dLLM推理的方法。

Method: SchED是一种训练免费、模型无关的早期退出算法。它聚合全跨度logit边际，当满足平滑的进度相关置信度阈值时停止解码。算法不依赖特定模型训练，可应用于各种dLLM。

Result: 在指令调优模型上，SchED实现3.8-4.0倍加速，同时保持99.8-100%的基准分数。在基础模型上，获得一致的速度提升和99.1-100%性能保持，激进设置下可达2.34倍加速。在惩罚质量损失的保守速度指标(QPS, γ=4)下，SchED明显优于先前基于置信度的早期退出方法。

Conclusion: SchED通过将真实的置信度稳定转化为计算节省，使dLLM解码显著更高效。指令调优加速了预测熵的衰减，进一步提升了SchED的效果。该方法为扩散大语言模型的实用化提供了有效的加速解决方案。

Abstract: Diffusion large language models (dLLMs) offer a promising alternative to autoregressive models, but their practical utility is severely hampered by slow, iterative sampling. We present SchED, a training-free, model-agnostic early-exit algorithm that aggregates full-span logit margins and halts decoding once a smooth, progress-dependent confidence threshold is met. We evaluated SchED on two dLLM families (Dream and LLaDA), in base and instruction-tuned variants across ten benchmarks spanning downstream tasks including multiple-choice question answering (MCQ), math, long-form QA/summarization, and translation. SchED delivers large, stable accelerations: on instruction-tuned models, it achieves $3.8$-$4.0\times$ speedups while retaining $99.8$-$100\%$ of the baseline score on average. On base models, SchED yields consistent speedup gains with $99.1$-$100\%$ performance retention, with up to $2.34\times$ under more aggressive settings. Using a conservative speed metric that heavily penalizes quality loss (QPS, $γ{=}4$), we show that SchED is robust and clearly outperforms prior confidence-based early-exit methods, which break down on long-form generation. An entropy analysis of the model's token predictions reveals that instruction tuning speeds up the decay of predictive entropy. By turning genuine confidence stabilization into computational savings, SchED makes dLLM decoding substantially more efficient.

</details>


### [41] [AutoNeural: Co-Designing Vision-Language Models for NPU Inference](https://arxiv.org/abs/2512.02924)
*Wei Chen,Liangmin Wu,Yunhai Hu,Zhiyuan Li,Zhiyuan Cheng,Yicheng Qian,Lingyue Zhu,Zhipeng Hu,Luoyi Liang,Qiang Tang,Zhen Liu,Han Yang*

Main category: cs.CL

TL;DR: AutoNeural：专为NPU设计的视觉-语言模型架构，通过替换ViT为MobileNetV5风格主干和集成SSM的混合语言模型，实现整数推理和线性时间复杂度，显著提升边缘AI效率。


<details>
  <summary>Details</summary>
Motivation: 当前为GPU设计的视觉-语言模型在NPU上表现不佳，主要原因是ViT的量化脆弱性和自回归注意力机制的I/O限制，无法充分利用NPU的高算术吞吐量。

Method: 提出NPU原生的AutoNeural架构：1) 用MobileNetV5风格的深度可分离卷积替换ViT编码器，确保激活分布有界以支持稳定INT4/8/16量化；2) 语言主干集成状态空间模型原理与Transformer层，使用门控卷积实现线性时间复杂度，消除KV缓存的内存I/O开销。

Result: 相比传统基线：视觉编码器量化误差降低7倍，端到端延迟降低14倍，解码速度提升3倍，上下文窗口长度提升4倍。在高通SA8295P SoC上的真实汽车案例验证了座舱应用的实时性能。

Conclusion: 为NPU约束重新设计模型拓扑是实现鲁棒多模态边缘智能的先决条件，AutoNeural展示了硬件-模型协同设计的有效性。

Abstract: While Neural Processing Units (NPUs) offer high theoretical efficiency for edge AI, state-of-the-art Vision--Language Models (VLMs) tailored for GPUs often falter on these substrates. We attribute this hardware-model mismatch to two primary factors: the quantization brittleness of Vision Transformers (ViTs) and the I/O-bound nature of autoregressive attention mechanisms, which fail to utilize the high arithmetic throughput of NPUs. To bridge this gap, we propose AutoNeural, an NPU-native VLM architecture co-designed for integer-only inference. We replace the standard ViT encoder with a MobileNetV5-style backbone utilizing depthwise separable convolutions, which ensures bounded activation distributions for stable INT4/8/16 quantization. Complementing this, our language backbone integrates State-Space Model (SSM) principles with Transformer layers, employing efficient gated convolutions to achieve linear-time complexity. This hybrid design eliminates the heavy memory I/O overhead of Key-Value caching during generation. Our approach delivers substantial efficiency gains, reducing quantization error of vision encoder by up to 7x and end-to-end latency by 14x compared to conventional baselines. The AutoNeural also delivers 3x decoding speed and 4x longer context window than the baseline. We validate these improvements via a real-world automotive case study on the Qualcomm SA8295P SoC, demonstrating real-time performance for cockpit applications. Our results highlight that rethinking model topology specifically for NPU constraints is a prerequisite for robust multi-modal edge intelligence.

</details>


### [42] [Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic](https://arxiv.org/abs/2512.02987)
*Muyu Pan,Dheeraj Kodakandla,Mahfuza Farooque*

Main category: cs.CL

TL;DR: 提出一个结合传统NLP技术、自定义语法和微调语言模型的新框架，将英文句子转换为逻辑表达式再转为CNF形式，以减少LLM在逻辑翻译中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: LLM在自然语言到形式逻辑的自动翻译中存在幻觉问题，而逻辑翻译任务需要高精度，这阻碍了在自动推理、软件规范验证等领域的应用

Method: 结合传统NLP技术（自定义语法）、符号计算库和微调的语言模型，构建一个将英文句子转换为逻辑表达式，再翻译为CNF形式的框架

Result: 微调后的模型能够有意识地纠正原始模型的相同类型幻觉，提供可靠的CNF生成

Conclusion: 该框架通过结合传统NLP技术和微调LLM，有效减少了逻辑翻译中的幻觉问题，为自动推理和软件验证提供了可靠的形式逻辑生成

Abstract: Recent advances in natural language processing (NLP), particularly large language models (LLMs), have motivated the automatic translation of natural language statements into formal logic without human intervention. This enables automated reasoning and facilitates debugging, finding loop invariants, and adhering to specifications in software systems. However, hallucinations-incorrect outputs generated by LLMs are challenging, particularly for logical translation tasks requiring precision. This work introduces a novel framework that inputs English sentences, converts them into logical expressions, and then translates them into Conjunctive Normal Form (CNF) for satisfiability solving. It employs classical NLP techniques with self-defined grammar, symbolic computation libraries, and a fine-tuned language model to reduce hallucinations. In the early experiments, we observed that the fine-tuned model, trained on different grammar settings, could intentionally correct the same types of hallucinations made by the original model. Thus, it provides reliable CNF generation.

</details>


### [43] [The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models](https://arxiv.org/abs/2512.03026)
*Saeid Jamshidi,Kawser Wazed Nafi,Arghavan Moradi Dakhel,Negar Shahabi,Foutse Khomh*

Main category: cs.CL

TL;DR: MoCoP是一个无数据集、闭环的道德一致性评估框架，用于持续评估和解释LLMs的道德稳定性，揭示道德一致性与语言安全性之间的强负相关关系。


<details>
  <summary>Details</summary>
Motivation: 现有对齐框架依赖静态数据集和后验评估，无法捕捉道德推理在不同上下文或时间尺度上的演变，需要动态、持续的道德一致性评估方法。

Method: 提出Moral Consistency Pipeline (MoCoP)，包含三个支持层：(i)词汇完整性分析，(ii)语义风险估计，(iii)基于推理的判断建模，在自维持架构中自主生成、评估和优化伦理场景。

Result: 在GPT-4-Turbo和DeepSeek上的实证结果显示：道德维度与毒性维度呈强负相关(rET = -0.81, p<0.001)，与响应延迟几乎无关联(rEL≈0)，表明道德一致性和语言安全性是模型行为的稳定可解释特征。

Conclusion: MoCoP将伦理评估重新定义为动态、模型无关的道德内省形式，为可扩展的持续审计提供了可重复的基础，推进了自主AI系统中计算道德的研究。

Abstract: The rapid advancement and adaptability of Large Language Models (LLMs) highlight the need for moral consistency, the capacity to maintain ethically coherent reasoning across varied contexts. Existing alignment frameworks, structured approaches designed to align model behavior with human ethical and social norms, often rely on static datasets and post-hoc evaluations, offering limited insight into how ethical reasoning may evolve across different contexts or temporal scales. This study presents the Moral Consistency Pipeline (MoCoP), a dataset-free, closed-loop framework for continuously evaluating and interpreting the moral stability of LLMs. MoCoP combines three supporting layers: (i) lexical integrity analysis, (ii) semantic risk estimation, and (iii) reasoning-based judgment modeling within a self-sustaining architecture that autonomously generates, evaluates, and refines ethical scenarios without external supervision. Our empirical results on GPT-4-Turbo and DeepSeek suggest that MoCoP effectively captures longitudinal ethical behavior, revealing a strong inverse relationship between ethical and toxicity dimensions (correlation rET = -0.81, p value less than 0.001) and a near-zero association with response latency (correlation rEL approximately equal to 0). These findings demonstrate that moral coherence and linguistic safety tend to emerge as stable and interpretable characteristics of model behavior rather than short-term fluctuations. Furthermore, by reframing ethical evaluation as a dynamic, model-agnostic form of moral introspection, MoCoP offers a reproducible foundation for scalable, continuous auditing and advances the study of computational morality in autonomous AI systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [44] [Reinforcement Learning for Robotic Safe Control with Force Sensing](https://arxiv.org/abs/2512.02022)
*Nan Lin,Linrui Zhang,Yuxuan Chen,Zhenrui Chen,Yujun Zhu,Ruoxi Chen,Peichen Wu,Xiaoping Chen*

Main category: cs.RO

TL;DR: 论文提出将力与触觉感知融入强化学习，以提升机器人在非结构化环境中复杂操作任务的安全性和可靠性，特别是在仿真到现实的迁移中。


<details>
  <summary>Details</summary>
Motivation: 传统手工编码方法在非结构化环境中的复杂操作任务中效果有限，而强化学习虽然能提供更通用的策略，但其稳定性和可靠性难以保证，存在安全隐患，且仿真到现实的迁移会带来不可预测的情况。

Method: 引入力与触觉感知到强化学习中，利用力与触觉感知在机器人动态控制和人机交互中的关键作用，开发基于力的强化学习方法。

Result: 在物体推动任务中，实验结果表明该策略在仿真和现实世界中都更安全、更高效，特别是在仿真到现实的迁移中表现出更好的适应性。

Conclusion: 基于力的强化学习方法能增强机器人的安全性和可靠性，在仿真到现实迁移中更具适应性，具有广泛的机器人应用前景。

Abstract: For the task with complicated manipulation in unstructured environments, traditional hand-coded methods are ineffective, while reinforcement learning can provide more general and useful policy. Although the reinforcement learning is able to obtain impressive results, its stability and reliability is hard to guarantee, which would cause the potential safety threats. Besides, the transfer from simulation to real world also will lead in unpredictable situations. To enhance the safety and reliability of robots, we introduce the force and haptic perception into reinforcement learning. Force and tactual sensation play key roles in robotic dynamic control and human-robot interaction. We demonstrate that the force-based reinforcement learning method can be more adaptive to environment, especially in sim-to-real transfer. Experimental results show in object pushing task, our strategy is safer and more efficient in both simulation and real world, thus it holds prospects for a wide variety of robotic applications.

</details>


### [45] [Robust Geospatial Coordination of Multi-Agent Communications Networks Under Attrition](https://arxiv.org/abs/2512.02079)
*Jonathan S. Kent,Eliana Stefani,Brian K. Plancher*

Main category: cs.RO

TL;DR: 本文提出了一种用于极端环境下无人机通信网络鲁棒性维护的物理启发拓扑算法ΦIREMAN，解决了存在损耗情况下的多智能体网络鲁棒任务连接问题。


<details>
  <summary>Details</summary>
Motivation: 在野火等紧急响应中，需要快速高效的通信。虽然可以使用无人机群构建临时通信网络，但极端环境可能导致单个无人机损坏，从而中断整个网络通信。现有方法缺乏对主动冗余和损耗恢复的明确处理。

Method: 提出了鲁棒任务网络在损耗下的问题形式化(RTNUA)，并开发了ΦIREMAN算法——一种基于物理启发势场的拓扑算法，通过主动冗余和损耗恢复机制来维持网络连接。

Result: 在25种问题配置的仿真中，ΦIREMAN始终优于DCCRS基线方法。在包含100个任务和500架无人机的大规模问题上，尽管存在显著损耗，仍能维持>99.9%的任务正常运行时间。

Conclusion: ΦIREMAN算法在极端环境下为多智能体无人机网络提供了有效且可扩展的鲁棒性解决方案，能够应对个体损坏带来的网络中断风险，确保紧急响应通信的连续性。

Abstract: Fast, efficient, robust communication during wildfire and other emergency responses is critical. One way to achieve this is by coordinating swarms of autonomous aerial vehicles carrying communications equipment to form an ad-hoc network connecting emergency response personnel to both each other and central command. However, operating in such extreme environments may lead to individual networking agents being damaged or rendered inoperable, which could bring down the network and interrupt communications.
  To overcome this challenge and enable multi-agent UAV networking in difficult environments, this paper introduces and formalizes the problem of Robust Task Networking Under Attrition (RTNUA), which extends connectivity maintenance in multi-robot systems to explicitly address proactive redundancy and attrition recovery. We introduce Physics-Informed Robust Employment of Multi-Agent Networks ($Φ$IREMAN), a topological algorithm leveraging physics-inspired potential fields to solve this problem. Through simulation across 25 problem configurations, $Φ$IREMAN consistently outperforms the DCCRS baseline, and on large-scale problems with up to 100 tasks and 500 drones, maintains $>99.9\%$ task uptime despite substantial attrition, demonstrating both effectiveness and scalability.

</details>


### [46] [VIGS-SLAM: Visual Inertial Gaussian Splatting SLAM](https://arxiv.org/abs/2512.02293)
*Zihan Zhu,Wei Zhang,Norbert Haala,Marc Pollefeys,Daniel Barath*

Main category: cs.RO

TL;DR: VIGS-SLAM是一个视觉-惯性3D高斯溅射SLAM系统，实现了鲁棒的实时跟踪和高保真重建，通过紧密耦合视觉和惯性线索解决运动模糊、低纹理和曝光变化问题。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的3DGS-based SLAM方法实现了密集和逼真的建图，但纯视觉设计在运动模糊、低纹理和曝光变化下性能下降。需要结合惯性测量单元(IMU)来提高鲁棒性。

Method: 在统一的优化框架中紧密耦合视觉和惯性线索，联合优化相机位姿、深度和IMU状态。系统包含鲁棒的IMU初始化、时变偏差建模以及具有一致高斯更新的闭环检测。

Result: 在四个具有挑战性的数据集上的实验表明，该方法优于最先进的方法。

Conclusion: VIGS-SLAM通过视觉-惯性融合实现了鲁棒的实时SLAM和高保真重建，解决了纯视觉方法在挑战性场景下的局限性。

Abstract: We present VIGS-SLAM, a visual-inertial 3D Gaussian Splatting SLAM system that achieves robust real-time tracking and high-fidelity reconstruction. Although recent 3DGS-based SLAM methods achieve dense and photorealistic mapping, their purely visual design degrades under motion blur, low texture, and exposure variations. Our method tightly couples visual and inertial cues within a unified optimization framework, jointly refining camera poses, depths, and IMU states. It features robust IMU initialization, time-varying bias modeling, and loop closure with consistent Gaussian updates. Experiments on four challenging datasets demonstrate our superiority over state-of-the-art methods. Project page: https://vigs-slam.github.io

</details>


### [47] [Vehicle Dynamics Embedded World Models for Autonomous Driving](https://arxiv.org/abs/2512.02417)
*Huiqian Li,Wei Pan,Haodong Zhang,Jin Huang,Zhihua Zhong*

Main category: cs.RO

TL;DR: VDD方法通过解耦自车动力学与环境动力学建模，提升自动驾驶世界模型的泛化能力和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有世界模型方法通常从图像输入中联合学习自车动力学和环境过渡动力学，导致效率低下且对车辆动力学变化缺乏鲁棒性

Method: 提出VDD方法，将自车动力学与环境过渡动力学解耦建模；引入PAD（部署时策略调整）和PAT（训练时策略增强）两种策略增强鲁棒性

Result: 在模拟环境中，VDD方法显著提升了驾驶性能和车辆动力学变化的鲁棒性，优于现有方法

Conclusion: 通过解耦自车动力学与环境动力学建模，VDD方法能够有效泛化到不同参数的车辆，为自动驾驶世界模型提供了更鲁棒的解决方案

Abstract: World models have gained significant attention as a promising approach for autonomous driving. By emulating human-like perception and decision-making processes, these models can predict and adapt to dynamic environments. Existing methods typically map high-dimensional observations into compact latent spaces and learn optimal policies within these latent representations. However, prior work usually jointly learns ego-vehicle dynamics and environmental transition dynamics from the image input, leading to inefficiencies and a lack of robustness to variations in vehicle dynamics. To address these issues, we propose the Vehicle Dynamics embedded Dreamer (VDD) method, which decouples the modeling of ego-vehicle dynamics from environmental transition dynamics. This separation allows the world model to generalize effectively across vehicles with diverse parameters. Additionally, we introduce two strategies to further enhance the robustness of the learned policy: Policy Adjustment during Deployment (PAD) and Policy Augmentation during Training (PAT). Comprehensive experiments in simulated environments demonstrate that the proposed model significantly improves both driving performance and robustness to variations in vehicle dynamics, outperforming existing approaches.

</details>


### [48] [AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning](https://arxiv.org/abs/2512.02535)
*Jeric Lew,Yuhong Cao,Derek Ming Siang Tan,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: AID：基于扩散模型的去中心化多智能体信息路径规划框架，通过非自回归方式生成长时轨迹，相比现有方法实现4倍加速和17%信息增益提升


<details>
  <summary>Details</summary>
Motivation: 大规模或时间关键场景（如环境监测、搜救）需要多智能体系统在有限时间内实现广泛覆盖。现有基于学习的MAIPP方法使用自回归意图预测器，但存在计算成本高和误差累积问题，需要更有效的协调方法

Method: 提出AID框架：1）使用扩散模型以非自回归方式生成长时轨迹；2）两阶段训练：先在现有MAIPP规划器轨迹上进行行为克隆，然后通过DPPO（扩散策略策略优化）进行强化学习微调

Result: 实验表明AID持续优于其训练的MAIPP规划器，实现高达4倍的执行加速和17%的信息增益提升，并能有效扩展到更多智能体

Conclusion: 扩散模型作为表达性强的长时程策略，能够有效解决MAIPP中的协调问题，AID框架通过非自回归轨迹生成和两阶段训练，在效率和性能上都超越了现有方法

Abstract: Information gathering in large-scale or time-critical scenarios (e.g., environmental monitoring, search and rescue) requires broad coverage within limited time budgets, motivating the use of multi-agent systems. These scenarios are commonly formulated as multi-agent informative path planning (MAIPP), where multiple agents must coordinate to maximize information gain while operating under budget constraints. A central challenge in MAIPP is ensuring effective coordination while the belief over the environment evolves with incoming measurements. Recent learning-based approaches address this by using distributions over future positions as "intent" to support coordination. However, these autoregressive intent predictors are computationally expensive and prone to compounding errors. Inspired by the effectiveness of diffusion models as expressive, long-horizon policies, we propose AID, a fully decentralized MAIPP framework that leverages diffusion models to generate long-term trajectories in a non-autoregressive manner. AID first performs behavior cloning on trajectories produced by existing MAIPP planners and then fine-tunes the policy using reinforcement learning via Diffusion Policy Policy Optimization (DPPO). This two-stage pipeline enables the policy to inherit expert behavior while learning improved coordination through online reward feedback. Experiments demonstrate that AID consistently improves upon the MAIPP planners it is trained from, achieving up to 4x faster execution and 17% increased information gain, while scaling effectively to larger numbers of agents. Our implementation is publicly available at https://github.com/marmotlab/AID.

</details>


### [49] [Robotic capabilities framework: A boundary object and intermediate-level knowledge artifact for co-designing robotic processes](https://arxiv.org/abs/2512.02549)
*Alessandro Ianniello,Dave Murray-Rust,Sara Muscolo,Olger Siebinga,Nicky Mol,Denis Zatyagov,Eva Verhoef,Deborah Forster,David Abbink*

Main category: cs.RO

TL;DR: 提出了一个机器人能力框架，作为跨学科协作的词汇表，帮助设计人类与机器人协作的未来工作方式，重点关注任务分配而非机器人内部技术细节。


<details>
  <summary>Details</summary>
Motivation: 当前机器人设计通常采用单一学科方法，忽视了跨学科知识和最终与机器人协作的工人的经验知识，导致人类-机器人协作设计不够有效。

Method: 开发了机器人能力框架作为中间层知识工具和边界对象，通过反思性和迭代性过程构建，并在两个场景中应用：让机器人专家用该词汇描述现有商业机器人，以及与机器人相关项目学生进行设计活动。

Result: 该框架成功作为连接技术和经验领域的桥梁，能够引导设计师、赋能工人，并促进更公正和协作的未来工作方式。

Conclusion: 机器人能力框架是一个有效的跨学科协作工具，通过关注高级能力而非技术细节，帮助有意义地塑造机器人系统融入工作场所的未来工作方式。

Abstract: As robots become more adaptable, responsive, and capable of interacting with humans, the design of effective human-robot collaboration becomes critical. Yet, this design process is typically led by monodisciplinary approaches, often overlooking interdisciplinary knowledge and the experiential knowledge of workers who will ultimately share tasks with these systems. To address this gap, we introduce the robotic capabilities framework, a vocabulary that enables transdisciplinary collaborations to meaningfully shape the future of work when robotic systems are integrated into the workplace. Rather than focusing on the internal workings of robots, the framework centers discussion on high-level capabilities, supporting dialogue around which elements of a task should remain human-led and which can be delegated to robots. We developed the framework through reflexive and iterative processes, and applied it in two distinct settings: by engaging roboticists in describing existing commercial robots using its vocabulary, and through a design activity with students working on robotics-related projects. The framework emerges as an intermediate-level knowledge artifact and a boundary object that bridges technical and experiential domains, guiding designers, empowering workers, and contributing to more just and collaborative futures of work.

</details>


### [50] [SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction](https://arxiv.org/abs/2512.02609)
*Shengkai Wu,Jinrong Yang,Wenqiu Luo,Linfeng Gao,Chaohui Shang,Meiyu Zhi,Mingshan Sun,Fangping Yang,Liangliang Ren,Yong Zhao*

Main category: cs.RO

TL;DR: SAM2Grasp通过将多模态抓取任务转化为单模态、提示条件预测问题，利用SAM2的视觉时序跟踪能力，解决模仿学习中多目标场景下的冲突训练信号问题。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人抓取中面临多模态问题：当场景包含多个有效目标时，对不同物体的抓取演示会产生冲突的训练信号，导致标准模仿学习策略平均这些不同动作而产生无效动作。

Method: 提出SAM2Grasp框架，利用冻结的SAM2模型提供强大的视觉时序跟踪能力，引入轻量级可训练动作头与原生分割头并行工作。仅训练动作头处理SAM2预计算的时序视觉特征。推理时通过初始提示（如边界框）指定特定物体，动作头预测唯一明确的抓取轨迹。

Result: 在杂乱多物体抓取任务中实现了最先进的性能，有效消除了视觉运动策略的歧义。

Conclusion: 通过将多模态抓取任务重新表述为单模态提示条件预测问题，并利用SAM2的时序跟踪能力，SAM2Grasp成功解决了模仿学习中的多模态冲突问题，为机器人抓取提供了有效的解决方案。

Abstract: Imitation learning for robotic grasping is often plagued by the multimodal problem: when a scene contains multiple valid targets, demonstrations of grasping different objects create conflicting training signals. Standard imitation learning policies fail by averaging these distinct actions into a single, invalid action. In this paper, we introduce SAM2Grasp, a novel framework that resolves this issue by reformulating the task as a uni-modal, prompt-conditioned prediction problem. Our method leverages the frozen SAM2 model to use its powerful visual temporal tracking capability and introduces a lightweight, trainable action head that operates in parallel with its native segmentation head. This design allows for training only the small action head on pre-computed temporal-visual features from SAM2. During inference, an initial prompt, such as a bounding box provided by an upstream object detection model, designates the specific object to be grasped. This prompt conditions the action head to predict a unique, unambiguous grasp trajectory for that object alone. In all subsequent video frames, SAM2's built-in temporal tracking capability automatically maintains stable tracking of the selected object, enabling our model to continuously predict the grasp trajectory from the video stream without further external guidance. This temporal-prompted approach effectively eliminates ambiguity from the visuomotor policy. We demonstrate through extensive experiments that SAM2Grasp achieves state-of-the-art performance in cluttered, multi-object grasping tasks.

</details>


### [51] [RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning](https://arxiv.org/abs/2512.02729)
*Yuhong Zhang,Zihan Gao,Shengpeng Li,Ling-Hao Chen,Kaisheng Liu,Runqing Cheng,Xiao Lin,Junjia Liu,Zhuoheng Li,Jingyi Feng,Ziyan He,Jintian Lin,Zheyan Huang,Zhifang Liu,Haoqian Wang*

Main category: cs.RO

TL;DR: Robowheel：将人类手-物交互视频转换为跨形态机器人学习监督的数据引擎，通过物理约束重建、跨具身重定向和仿真增强生成训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中监督数据获取困难的问题，特别是跨不同形态机器人（机械臂、灵巧手、人形机器人）的学习。传统遥操作成本高且难以扩展，而人类手-物交互视频丰富但缺乏物理合理性和跨具身适应性。

Method: 1. 从单目RGB或RGB-D输入进行高精度手-物交互重建；2. 使用强化学习优化器在接触和穿透约束下细化相对位姿；3. 将重建轨迹重定向到不同机器人形态；4. 在Isaac Sim中构建仿真增强框架，通过领域随机化丰富数据分布。

Result: 生成的数据在主流视觉语言动作和模仿学习架构上验证有效，轨迹稳定性与遥操作相当，能带来持续性能提升。首次定量证明手-物交互模态可作为机器人学习的有效监督。

Conclusion: Robowheel提供了一种轻量级、通用的跨具身运动表示方法，仅需单目相机即可提取可重定向的运动表示，比遥操作更高效。构建了大规模多模态数据集，为具身模型训练和评估提供了新资源。

Abstract: We introduce Robowheel, a data engine that converts human hand object interaction (HOI) videos into training-ready supervision for cross morphology robotic learning. From monocular RGB or RGB-D inputs, we perform high precision HOI reconstruction and enforce physical plausibility via a reinforcement learning (RL) optimizer that refines hand object relative poses under contact and penetration constraints. The reconstructed, contact rich trajectories are then retargeted to cross-embodiments, robot arms with simple end effectors, dexterous hands, and humanoids, yielding executable actions and rollouts. To scale coverage, we build a simulation-augmented framework on Isaac Sim with diverse domain randomization (embodiments, trajectories, object retrieval, background textures, hand motion mirroring), which enriches the distributions of trajectories and observations while preserving spatial relationships and physical plausibility. The entire data pipeline forms an end to end pipeline from video,reconstruction,retargeting,augmentation data acquisition. We validate the data on mainstream vision language action (VLA) and imitation learning architectures, demonstrating that trajectories produced by our pipeline are as stable as those from teleoperation and yield comparable continual performance gains. To our knowledge, this provides the first quantitative evidence that HOI modalities can serve as effective supervision for robotic learning. Compared with teleoperation, Robowheel is lightweight, a single monocular RGB(D) camera is sufficient to extract a universal, embodiment agnostic motion representation that could be flexibly retargeted across embodiments. We further assemble a large scale multimodal dataset combining multi-camera captures, monocular videos, and public HOI corpora for training and evaluating embodied models.

</details>


### [52] [CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy](https://arxiv.org/abs/2512.02777)
*Heye Huang,Yibin Yang,Mingfeng Fan,Haoran Wang,Xiaocong Zhao,Jianqiang Wang*

Main category: cs.RO

TL;DR: CogDrive提出了一种认知驱动的多模态预测与规划框架，通过显式模态推理与安全感知轨迹优化，解决自动驾驶在混合交通中的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法难以捕捉罕见但安全关键的行为，而基于规则的系统在复杂交互中缺乏适应性。混合交通中的安全自动驾驶需要统一理解多模态交互和不确定性下的动态规划。

Method: 1) 预测模块：基于拓扑运动语义和最近邻关系编码的认知交互模态表示，使用可微分模态损失和多模态高斯解码学习稀疏不平衡交互行为；2) 规划模块：引入应急响应概念，优化安全稳定轨迹，短期一致分支确保重规划周期内的安全，长期分支支持低概率切换模态下的平滑无碰撞运动。

Result: 在Argoverse2和INTERACTION数据集上，CogDrive在轨迹精度和漏检率方面表现优异；闭环仿真验证了在汇入和交叉口场景中的自适应行为。

Conclusion: 通过结合认知多模态预测与安全导向规划，CogDrive为复杂交通中的安全自动驾驶提供了一个可解释且可靠的范式。

Abstract: Safe autonomous driving in mixed traffic requires a unified understanding of multimodal interactions and dynamic planning under uncertainty. Existing learning based approaches struggle to capture rare but safety critical behaviors, while rule based systems often lack adaptability in complex interactions. To address these limitations, CogDrive introduces a cognition driven multimodal prediction and planning framework that integrates explicit modal reasoning with safety aware trajectory optimization. The prediction module adopts cognitive representations of interaction modes based on topological motion semantics and nearest neighbor relational encoding. With a differentiable modal loss and multimodal Gaussian decoding, CogDrive learns sparse and unbalanced interaction behaviors and improves long horizon trajectory prediction. The planning module incorporates an emergency response concept and optimizes safety stabilized trajectories, where short term consistent branches ensure safety during replanning cycles and long term branches support smooth and collision free motion under low probability switching modes. Experiments on Argoverse2 and INTERACTION datasets show that CogDrive achieves strong performance in trajectory accuracy and miss rate, while closed loop simulations confirm adaptive behavior in merge and intersection scenarios. By combining cognitive multimodal prediction with safety oriented planning, CogDrive offers an interpretable and reliable paradigm for safe autonomy in complex traffic.

</details>


### [53] [Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols](https://arxiv.org/abs/2512.02787)
*Xianchao Zeng,Xinyu Zhou,Youcheng Li,Jiayou Shi,Tianle Li,Liangming Chen,Lei Ren,Yong-Lu Li*

Main category: cs.RO

TL;DR: ViFailback是一个用于机器人操作失败诊断和纠正的框架，包含大规模真实世界数据集、评估基准和8B参数VLM模型，能够生成文本和视觉纠正指导。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在失败诊断和学习方面存在局限，且现有失败数据集多为仿真生成，难以泛化到真实世界。需要开发能够诊断机器人操作失败并提供纠正指导的系统。

Method: 提出ViFailback框架，使用显式视觉符号提高标注效率；发布包含58,126个VQA对和5,202个真实世界操作轨迹的数据集；建立包含11个细粒度VQA任务的评估基准；构建ViFailback-8B VLM模型。

Result: ViFailback-8B在评估基准上取得显著性能提升，能够生成纠正动作的视觉符号；与VLA模型集成后，在真实世界机器人实验中成功帮助模型从失败中恢复。

Conclusion: ViFailback框架有效解决了机器人操作失败诊断和纠正的问题，通过真实世界数据集、评估基准和专用VLM模型，显著提升了VLA模型从失败中恢复的能力。

Abstract: Vision-Language-Action (VLA) models have recently achieved remarkable progress in robotic manipulation, yet they remain limited in failure diagnosis and learning from failures. Additionally, existing failure datasets are mostly generated programmatically in simulation, which limits their generalization to the real world. In light of these, we introduce ViFailback, a framework designed to diagnose robotic manipulation failures and provide both textual and visual correction guidance. Our framework utilizes explicit visual symbols to enhance annotation efficiency. We further release the ViFailback dataset, a large-scale collection of 58,126 Visual Question Answering (VQA) pairs along with their corresponding 5,202 real-world manipulation trajectories. Based on the dataset, we establish ViFailback-Bench, a benchmark of 11 fine-grained VQA tasks designed to assess the failure diagnosis and correction abilities of Vision-Language Models (VLMs), featuring ViFailback-Bench Lite for closed-ended and ViFailback-Bench Hard for open-ended evaluation. To demonstrate the effectiveness of our framework, we built the ViFailback-8B VLM, which not only achieves significant overall performance improvement on ViFailback-Bench but also generates visual symbols for corrective action guidance. Finally, by integrating ViFailback-8B with a VLA model, we conduct real-world robotic experiments demonstrating its ability to assist the VLA model in recovering from failures. Project Website: https://x1nyuzhou.github.io/vifailback.github.io/

</details>


### [54] [Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms](https://arxiv.org/abs/2512.02810)
*Shyam prasad reddy Kaitha,Hongrui Yu*

Main category: cs.RO

TL;DR: 本文提出基于LangGraph的任务分配代理(LTAA)，这是一个LLM驱动的多机器人任务分配框架，在建筑自动化场景中通过动态提示和分层验证机制，显著降低了计算成本，并在任务完成率和负载均衡方面优于传统优化方法。


<details>
  <summary>Details</summary>
Motivation: 尽管最近LLM方法在建筑机器人领域显示出潜力，但缺乏与传统算法的系统比较和严格验证。本研究旨在填补这一空白，验证LLM在任务分配中的可行性，并解决实际实施中的挑战。

Method: 提出LangGraph-based Task Allocation Agent (LTAA)框架，结合自然语言推理和结构化验证机制，采用阶段自适应分配策略、多阶段分层重试验证和动态提示技术。通过Self-Corrective Agent Architecture解决实施挑战，并在TEACh人机协作数据集上评估。

Result: LTAA显著降低了计算成本：令牌使用减少94.6%，分配时间减少86%。在Heavy Excels设置中（机器人具有强任务专业化），LTAA实现了77%的任务完成率，并具有优越的负载均衡，优于所有传统方法（动态规划、Q-learning、DQN）。

Conclusion: LLM基于推理结合结构化验证能够匹配传统优化算法，同时提供额外优势：可解释性、适应性以及无需重新训练即可更新任务逻辑的能力。这为建筑自动化中的多机器人任务分配提供了新的有效方法。

Abstract: Multi-robot task allocation in construction automation has traditionally relied on optimization methods such as Dynamic Programming and Reinforcement Learning. This research introduces the LangGraph-based Task Allocation Agent (LTAA), an LLM-driven framework that integrates phase-adaptive allocation strategies, multi-stage validation with hierarchical retries, and dynamic prompting for efficient robot coordination. Although recent LLM approaches show potential for construction robotics, they largely lack rigorous validation and benchmarking against established algorithms. This paper presents the first systematic comparison of LLM-based task allocation with traditional methods in construction scenarios.The study validates LLM feasibility through SMART-LLM replication and addresses implementation challenges using a Self-Corrective Agent Architecture. LTAA leverages natural-language reasoning combined with structured validation mechanisms, achieving major computational gains reducing token usage by 94.6% and allocation time by 86% through dynamic prompting. The framework adjusts its strategy across phases: emphasizing execution feasibility early and workload balance in later allocations.The authors evaluate LTAA against Dynamic Programming, Q-learning, and Deep Q-Network (DQN) baselines using construction operations from the TEACh human-robot collaboration dataset. In the Heavy Excels setting, where robots have strong task specializations, LTAA achieves 77% task completion with superior workload balance, outperforming all traditional methods. These findings show that LLM-based reasoning with structured validation can match established optimization algorithms while offering additional advantages such as interpretability, adaptability, and the ability to update task logic without retraining.

</details>


### [55] [Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach](https://arxiv.org/abs/2512.02834)
*Siyuan Yang,Yang Zhang,Haoran He,Ling Pan,Xiu Li,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 提出TACO框架，通过测试时缩放和伪计数估计器解决VLA模型微调后的推理不稳定性问题，提高下游任务适应成功率


<details>
  <summary>Details</summary>
Motivation: VLA模型在预训练阶段整合了多种数据模式，而微调数据集往往包含运动学上不理想或不良的演示数据，导致存在与下游任务成功模式无关的冗余动作模式，造成推理时的不稳定性

Method: 提出TACO测试时缩放框架，使用轻量级伪计数估计器作为动作块的高保真验证器，选择具有最大伪计数的动作块执行，防止分布偏移同时保持VLA的泛化能力

Result: 在四个仿真基准（RoboTwin2.0、Robotwin、LIBERO、SimplerEnv）和双臂平台上进行广泛实验，证明该方法显著提高了推理稳定性和下游任务适应成功率

Conclusion: TACO框架有效解决了VLA模型微调后的推理不稳定性问题，通过测试时约束防止分布偏移，同时保持模型泛化能力，相比RL更新具有显著计算优势

Abstract: Vision-Language-Action (VLA) models, trained via flow-matching or diffusion objectives, excel at learning complex behaviors from large-scale, multi-modal datasets (e.g., human teleoperation, scripted policies). However, since VLAs incorporate diverse data modes in the pre-training stage, and the finetuning dataset often contains demonstration data collected in a kinematically suboptimal or undesirable way, it exists redundant action modes that are irrelevant to the success action modes of the downstream task. Specifically, we observe a critical inference-time fragility among various sampled noises after supervised finetuning of pre-trained VLAs. In this paper, we attribute this instability to the distribution shift between the VLA policy and the policy induced by stable success modes of the downstream task dataset. Thus, we propose \textbf{TACO}, a test-time-scaling (TTS) framework that applies a lightweight pseudo-count estimator as a high-fidelity verifier of action chunks. The VLA models integrated with TACO can execute the actions with maximum pseudo-count from all sampled action chunks, thereby preventing distribution shifts while preserving the generalization ability of VLAs since the constraint is applied only during inference. Our method resembles the classical anti-exploration principle in offline reinforcement learning (RL), and being gradient-free, it incurs significant computational benefits compared to RL update, especially for flow or diffusion-based VLAs which are difficult to perform RL update due to denoising process. Extensive experiments across four simulation benchmarks (RoboTwin2.0, Robotwin, LIBERO, SimplerEnv) and a dual-arm platform demonstrate that our method significantly improves the inference stability and success rates in downstream-task adaptations.

</details>


### [56] [VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion](https://arxiv.org/abs/2512.02844)
*Xinzheng Wu,Junyi Chen,Naiting Zhong,Yong Shen*

Main category: cs.RO

TL;DR: 提出一个结合视觉语言模型(VLM)和自适应引导扩散模型的安全关键测试场景生成框架，用于高效生成逼真、多样且高度交互的自动驾驶测试场景。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统(ADS)的安全部署需要全面测试，但现实世界中能有效暴露系统漏洞的安全关键场景极其稀少。现有场景生成方法难以高效构建同时保证保真度、关键性和交互性的长尾场景，尤其缺乏对被测车辆(VUT)的实时动态响应能力。

Method: 提出三层分层架构：战略层使用VLM确定场景生成目标，战术层制定引导函数，操作层执行引导扩散。首先建立学习真实驾驶场景数据分布的基础扩散模型，然后设计自适应引导扩散方法实现对背景车辆(BVs)的实时精确控制，最后结合VLM通过深度场景理解和风险推理自主生成场景目标和引导函数。

Result: 实验结果表明，该方法能高效生成逼真、多样且高度交互的安全关键测试场景。案例研究验证了方法的适应性和VLM引导生成性能。

Conclusion: 该框架成功整合了VLM的高层语义理解能力和自适应引导扩散模型的细粒度生成能力，解决了现有方法在保真度、关键性、交互性和实时响应方面的挑战，为自动驾驶系统安全测试提供了有效的场景生成解决方案。

Abstract: The safe deployment of autonomous driving systems (ADSs) relies on comprehensive testing and evaluation. However, safety-critical scenarios that can effectively expose system vulnerabilities are extremely sparse in the real world. Existing scenario generation methods face challenges in efficiently constructing long-tail scenarios that ensure fidelity, criticality, and interactivity, while particularly lacking real-time dynamic response capabilities to the vehicle under test (VUT). To address these challenges, this paper proposes a safety-critical testing scenario generation framework that integrates the high-level semantic understanding capabilities of Vision Language Models (VLMs) with the fine-grained generation capabilities of adaptive guided diffusion models. The framework establishes a three-layer hierarchical architecture comprising a strategic layer for VLM-directed scenario generation objective determination, a tactical layer for guidance function formulation, and an operational layer for guided diffusion execution. We first establish a high-quality fundamental diffusion model that learns the data distribution of real driving scenarios. Next, we design an adaptive guided diffusion method that enables real-time, precise control of background vehicles (BVs) in closed-loop simulation. The VLM is then incorporated to autonomously generate scenario generation objectives and guidance functions through deep scenario understanding and risk reasoning, ultimately guiding the diffusion model to achieve VLM-directed scenario generation. Experimental results demonstrate that the proposed method can efficiently generate realistic, diverse, and highly interactive safety-critical testing scenarios. Furthermore, case studies validate the adaptability and VLM-directed generation performance of the proposed method.

</details>


### [57] [SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots](https://arxiv.org/abs/2512.02851)
*Iana Zhura,Sausar Karaf,Faryal Batool,Nipun Dhananjaya Weerakkodi Mudalige,Valerii Serpiva,Ali Alridha Abdulkarim,Aleksey Fedoseev,Didar Seyidov,Amjad Hajira,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: SwarmDiffusion：一个轻量级端到端扩散模型，从单张RGB图像联合预测可通行性并生成可行轨迹，无需人工提示工程或外部规划器，实现跨平台可迁移的自主导航。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的可通行性估计方法依赖人工设计的提示，跨平台泛化能力差，且仅输出可通行性地图，需要依赖缓慢的外部规划器生成轨迹。

Method: 提出无规划器的轨迹构建流程：随机路径点采样、贝塞尔曲线平滑，以及强制执行连通性、安全性、方向性和路径细度的正则化。利用VLM监督无需提示工程，通过紧凑的机器人状态条件化扩散过程。

Result: 在室内环境和两种机器人平台（四足和空中）上实现80-100%导航成功率，0.09秒推理时间。仅需500个额外视觉样本即可适应新机器人，在仿真和真实环境中可靠泛化到未见环境。

Conclusion: SwarmDiffusion提供了一种可扩展、无需提示的统一可通行性推理和轨迹生成方法，能够跨平台迁移并实现快速端到端导航。

Abstract: Visual traversability estimation is critical for autonomous navigation, but existing VLM-based methods rely on hand-crafted prompts, generalize poorly across embodiments, and output only traversability maps, leaving trajectory generation to slow external planners. We propose SwarmDiffusion, a lightweight end-to-end diffusion model that jointly predicts traversability and generates a feasible trajectory from a single RGB image. To remove the need for annotated or planner-produced paths, we introduce a planner-free trajectory construction pipeline based on randomized waypoint sampling, Bezier smoothing, and regularization enforcing connectivity, safety, directionality, and path thinness. This enables learning stable motion priors without demonstrations. SwarmDiffusion leverages VLM-derived supervision without prompt engineering and conditions the diffusion process on a compact embodiment state, producing physically consistent, traversable paths that transfer across different robot platforms. Across indoor environments and two embodiments (quadruped and aerial), the method achieves 80-100\% navigation success and 0.09 s inference, and adapts to a new robot using only-500 additional visual samples. It generalizes reliably to unseen environments in simulation and real-world trials, offering a scalable, prompt-free approach to unified traversability reasoning and trajectory generation.

</details>


### [58] [VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling](https://arxiv.org/abs/2512.02902)
*Weiqi Li,Quande Zhang,Ruifeng Zhai,Liang Lin,Guangrun Wang*

Main category: cs.RO

TL;DR: VLA模型在分布外场景下性能下降严重，研究发现主要源于空间建模而非物理建模的错位。作者提出一次性适配框架，通过轻量级参数更新校准视觉表示，显著提升视角泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在训练分布内表现良好，但在新相机视角和视觉扰动下性能急剧下降。作者发现这种脆弱性主要源于空间建模的错位，而非物理建模问题，因此需要针对性解决方案。

Method: 提出一次性适配框架，包含两种轻量级方法：1) 特征令牌调制：对视觉令牌应用全局仿射变换；2) 特征线性适配：在ViT编码器中引入低秩更新。两种方法都只需极少参数即可校准视觉表示。

Result: FTM仅用4K参数就将Libero视角准确率从48.5%提升到87.1%；FLA用4.7M参数达到90.8%成功率，与LoRA规模微调相当但成本更低。证明预训练VLA模型具有大量未开发的鲁棒性潜力。

Conclusion: VLA模型的分布外脆弱性主要源于空间建模错位，通过有针对性的最小视觉适配即可恢复视角泛化能力。轻量级参数更新能显著提升模型鲁棒性，为实际部署提供了高效解决方案。

Abstract: Vision-language-action (VLA) models achieve strong in-distribution performance but degrade sharply under novel camera viewpoints and visual perturbations. We show that this brittleness primarily arises from misalignment in Spatial Modeling, rather than Physical Modeling. To address this, we propose a one-shot adaptation framework that recalibrates visual representations through lightweight, learnable updates. Our first method, Feature Token Modulation (FTM), applies a global affine transformation to visual tokens and improves Libero viewpoint accuracy from 48.5% to 87.1% with only 4K parameters. Building on this, Feature Linear Adaptation (FLA) introduces low-rank updates to the ViT encoder, achieving 90.8% success with 4.7M parameters -- matching LoRA-scale finetuning at far lower cost. Together, these results reveal substantial untapped robustness in pretrained VLA models and demonstrate that targeted, minimal visual adaptation is sufficient to restore viewpoint generalization.

</details>


### [59] [Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger](https://arxiv.org/abs/2512.02951)
*Nicholas Baiata,Nilanjan Chakraborty*

Main category: cs.RO

TL;DR: 本文提出了一种三自由度连杆驱动串并联机器人手指，实现了任务空间轨迹的毫米级精度跟踪控制。


<details>
  <summary>Details</summary>
Motivation: 任务空间控制对于灵巧操作至关重要，因为操作目标通常以指尖运动和施加力来指定，而不是单个关节角度。虽然任务空间规划和控制已在较大的臂级机械臂中得到广泛研究，但在紧凑的多自由度机器人手指中实现精确任务空间轨迹跟踪的演示仍然很少。

Method: 开发了三自由度连杆驱动串并联机器人手指，具有解析正向运动学和闭式雅可比矩阵。采用解析运动速率控制（RMRC）方案实现闭环任务空间轨迹跟踪。

Result: 通过实验评估指尖在各种轨迹（包括直线、圆形和更复杂曲线）上的跟踪性能，实现了毫米级精度。这是首次系统性地演示连杆驱动机器人手指的精确任务空间轨迹跟踪。

Conclusion: 这项工作为未来旨在实现灵巧手内操作的设计建立了基准，展示了在紧凑多自由度机器人手指中实现精确任务空间控制的可行性。

Abstract: Task-space control of robotic fingers is a critical enabler of dexterous manipulation, as manipulation objectives are most naturally specified in terms of fingertip motions and applied forces rather than individual joint angles. While task-space planning and control have been extensively studied for larger, arm-scale manipulators, demonstrations of precise task-space trajectory tracking in compact, multi-DoF robotic fingers remain scarce. In this paper, we present the physical prototyping and experimental characterization of a three-degree-of-freedom, linkage-driven, series-parallel robotic finger with analytic forward kinematics and a closed-form Jacobian. A resolved motion rate control (RMRC) scheme is implemented to achieve closed-loop task-space trajectory tracking. We experimentally evaluate the fingertip tracking performance across a variety of trajectories, including straight lines, circles, and more complex curves, and report millimeter-level accuracy. To the best of our knowledge, this work provides one of the first systematic experimental demonstrations of precise task-space trajectory tracking in a linkage-driven robotic finger, thereby establishing a benchmark for future designs aimed at dexterous in-hand manipulation.

</details>


### [60] [Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling](https://arxiv.org/abs/2512.03044)
*Yueru Jia,Jiaming Liu,Shengbang Liu,Rui Zhou,Wanhe Yu,Yuyang Yan,Xiaowei Chi,Yandong Guo,Boxin Shi,Shanghang Zhang*

Main category: cs.RO

TL;DR: Video2Act：利用视频扩散模型的时空表示指导机器人动作学习，通过异步双系统设计提升效率和稳定性，在仿真和真实任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用视频扩散模型增强机器人策略，但忽略了VDM中跨帧编码的连贯且物理一致的运动表示。需要更有效地利用这些时空表示来指导机器人动作学习。

Method: 1) 从VDM中提取前景边界和帧间运动变化，过滤背景噪声和任务无关偏差；2) 将这些精炼表示作为扩散变换器动作头的额外条件输入；3) 采用异步双系统设计：VDM作为慢速System 2，DiT头作为快速System 1协同工作。

Result: 在仿真任务中平均成功率比先前最先进的VLA方法提高7.7%，在真实世界任务中提高21.7%，展现出强大的泛化能力。

Conclusion: Video2Act通过显式整合VDM的时空和运动感知表示，有效指导机器人动作学习，异步双系统设计解决了推理效率问题，显著提升了机器人策略的性能和稳定性。

Abstract: Robust perception and dynamics modeling are fundamental to real-world robotic policy learning. Recent methods employ video diffusion models (VDMs) to enhance robotic policies, improving their understanding and modeling of the physical world. However, existing approaches overlook the coherent and physically consistent motion representations inherently encoded across frames in VDMs. To this end, we propose Video2Act, a framework that efficiently guides robotic action learning by explicitly integrating spatial and motion-aware representations. Building on the inherent representations of VDMs, we extract foreground boundaries and inter-frame motion variations while filtering out background noise and task-irrelevant biases. These refined representations are then used as additional conditioning inputs to a diffusion transformer (DiT) action head, enabling it to reason about what to manipulate and how to move. To mitigate inference inefficiency, we propose an asynchronous dual-system design, where the VDM functions as the slow System 2 and the DiT head as the fast System 1, working collaboratively to generate adaptive actions. By providing motion-aware conditions to System 1, Video2Act maintains stable manipulation even with low-frequency updates from the VDM. For evaluation, Video2Act surpasses previous state-of-the-art VLA methods by 7.7% in simulation and 21.7% in real-world tasks in terms of average success rate, further exhibiting strong generalization capabilities.

</details>
