<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 73]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps](https://arxiv.org/abs/2510.21732)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.RO

TL;DR: 提出了一种用于水陷阱中害虫计数的机器人搅拌方法，通过轨迹优化和自适应速度控制来解决害虫遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的害虫计数方法在处理害虫遮挡情况时存在局限性，需要一种能够改变害虫分布以揭示被遮挡个体的解决方案。

Method: 开发基于机械臂的自动搅拌系统，研究六种不同搅拌轨迹（圆形、方形、三角形、螺旋形、四个小圆形和随机线）对计数性能的影响，并设计基于计数置信度的闭环控制系统实现自适应速度搅拌。

Result: 通过比较不同搅拌轨迹在各种害虫密度场景下的平均计数误差和计数置信度，确定了最优轨迹。

Conclusion: 这是首个研究动态液体环境中不同搅拌轨迹对物体计数影响并实现自适应速度搅拌的研究，实验结果表明该方法能有效提高害虫计数准确性。

Abstract: Accurate monitoring of pest population dynamics is crucial for informed
decision-making in precision agriculture. Currently, mainstream image-based
pest counting methods primarily rely on image processing combined with machine
learning or deep learning for pest counting. However, these methods have
limitations and struggle to handle situations involving pest occlusion. To
address this issue, this paper proposed a robotic stirring method with
trajectory optimization and adaptive speed control for accurate pest counting
in water traps. First, we developed an automated stirring system for pest
counting in yellow water traps based on a robotic arm. Stirring alters the
distribution of pests in the yellow water trap, making some of the occluded
individuals visible for detection and counting. Then, we investigated the
impact of different stirring trajectories on pest counting performance and
selected the optimal trajectory for pest counting. Specifically, we designed
six representative stirring trajectories, including circle, square, triangle,
spiral, four small circles, and random lines, for the robotic arm to stir. And
by comparing the overall average counting error and counting confidence of
different stirring trajectories across various pest density scenarios, we
determined the optimal trajectory. Finally, we proposed a counting
confidence-driven closed-loop control system to achieve adaptive-speed
stirring. It uses changes in pest counting confidence between consecutive
frames as feedback to adjust the stirring speed. To the best of our knowledge,
this is the first study dedicated to investigating the effects of different
stirring trajectories on object counting in the dynamic liquid environment and
to implement adaptive-speed stirring for this type of task. Experimental
results show ...

</details>


### [2] [Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing](https://arxiv.org/abs/2510.21734)
*Giovanni Battista Regazzo,Wim-Alexander Beckers,Xuan Thao Ha,Mouloud Ourak,Johan Vlekken,Emmanuel Vander Poorten*

Main category: cs.RO

TL;DR: 提出了一种基于力传感导管和电磁跟踪的机器人辅助左心耳封堵术新方法，能够实时测量交互力并识别关键手术步骤，无需电离辐射。


<details>
  <summary>Details</summary>
Motivation: 传统左心耳封堵术依赖手动导管控制和荧光透视成像，存在辐射暴露和定位精度有限的问题，需要更安全精确的手术方法。

Method: 使用集成光纤布拉格光栅的力传感输送鞘结合电磁跟踪，在解剖模型中进行机器人辅助封堵器部署，通过力-位移曲线分析部署动态。

Result: 力分布显示低幅度的交互力，表明对周围解剖结构机械应力最小，该方法能提供增强的术中反馈。

Conclusion: 该方法有望改善左心耳封堵术的部署效果，未来工作将聚焦于自动化步骤分类和在动态真实环境中验证传感策略。

Abstract: Atrial fibrillation (AF) increases the risk of thromboembolic events due to
impaired function of the left atrial appendage (LAA). Left atrial appendage
closure (LAAC) is a minimally invasive intervention designed to reduce stroke
risk by sealing the LAA with an expandable occluder device. Current deployment
relies on manual catheter control and imaging modalities like fluoroscopy and
transesophageal echocardiography, which carry limitations including radiation
exposure and limited positioning precision. In this study, we leverage a
previously developed force-sensing delivery sheath integrating fiber Bragg
gratings (FBGs) at the interface between the catheter and the occluder.
Combined with electromagnetic (EM) tracking, this setup enables real-time
measurement of interaction forces and catheter tip position during
robot-assisted LAAC deployment in an anatomical phantom. We present a novel
force-displacement profiling method that characterizes occluder deployment
dynamics and identifies key procedural steps without relying on ionizing
radiation. The force profiles reveal low-magnitude interaction forces,
suggesting minimal mechanical stress on the surrounding anatomy. This approach
shows promise in providing clinicians with enhanced intraoperative feedback,
improving deployment outcome. Future work will focus on automating deployment
steps classification and validating the sensing strategy in dynamic, realistic
environments.

</details>


### [3] [A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data](https://arxiv.org/abs/2510.21735)
*Yuhui Liu,Shian Wang,Ansel Panicker,Kate Embry,Ayana Asanova,Tianyi Li*

Main category: cs.RO

TL;DR: 开发了一个针对电动汽车的相位感知AI跟车模型，通过结合传统物理模型和AI组件来识别不同驾驶阶段，显著提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统微观模型能有效描述内燃机车辆行为，但缺乏准确描述电动汽车独特跟车动力学的建模框架。随着电动汽车在交通中日益增多，开发易用且准确的分析模型至关重要。

Method: 提出了相位感知AI跟车模型，在传统物理框架基础上增强AI组件，能够识别和适应快速加速、再生制动等不同驾驶阶段。使用配备自适应巡航控制的车辆真实轨迹数据进行全面仿真验证。

Result: 数值结果表明，PAAI模型相比传统跟车模型显著提高了预测准确性，为交通仿真中准确表示电动汽车行为提供了有效工具。

Conclusion: 该研究成功开发并验证了专门针对电动汽车的相位感知AI跟车模型，填补了现有建模框架的空白，为准确模拟电动汽车在交通中的行为提供了有效解决方案。

Abstract: Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit
distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors
producing peak power across a wider speed range, and achieve swift deceleration
through regenerative braking. While existing microscopic models effectively
capture the driving behavior of ICE vehicles, a modeling framework that
accurately describes the unique car-following dynamics of EVs is lacking.
Developing such a model is essential given the increasing presence of EVs in
traffic, yet creating an easy-to-use and accurate analytical model remains
challenging.
  To address these gaps, this study develops and validates a Phase-Aware AI
(PAAI) car-following model specifically for EVs. The proposed model enhances
traditional physics-based frameworks with an AI component that recognizes and
adapts to different driving phases, such as rapid acceleration and regenerative
braking. Using real-world trajectory data from vehicles equipped with adaptive
cruise control (ACC), we conduct comprehensive simulations to validate the
model's performance. The numerical results demonstrate that the PAAI model
significantly improves prediction accuracy over traditional car-following
models, providing an effective tool for accurately representing EV behavior in
traffic simulations.

</details>


### [4] [Learn2Drive: A neural network-based framework for socially compliant automated vehicle control](https://arxiv.org/abs/2510.21736)
*Yuhui Liu,Samannita Halder,Shian Wang,Tianyi Li*

Main category: cs.RO

TL;DR: 提出基于LSTM网络和物理约束的自适应巡航控制框架，通过社会价值取向(SVO)使自动驾驶车辆考虑对人类驾驶车辆和交通流的影响，提升交通效率和降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶控制策略主要关注单个车辆或车队的性能优化，忽略了与人类驾驶车辆的交互及其对整体交通流的影响，这可能导致拥堵加剧和系统效率降低。

Method: 采用神经网络基础的社会合规自动驾驶控制框架，结合社会价值取向(SVO)，定义自动驾驶车辆和人类驾驶车辆的效用函数，通过SVO平衡车辆自身控制目标与交通流考量。

Result: 当自动驾驶车辆控制模式从优先考虑能耗转向优化交通流效率时，跟随车队中的车辆个体能耗至少增加58.99%，同时个体平均速度至少提升38.39%，表明交通动态显著改善。

Conclusion: 所提出的方法能有效适应不同交通条件，通过将自动驾驶车辆作为移动交通调节器，促进适应性驾驶行为，减少拥堵、提高交通效率并降低能耗。

Abstract: This study introduces a novel control framework for adaptive cruise control
(ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks
and physics-informed constraints. As automated vehicles (AVs) adopt advanced
features like ACC, transportation systems are becoming increasingly intelligent
and efficient. However, existing AV control strategies primarily focus on
optimizing the performance of individual vehicles or platoons, often neglecting
their interactions with human-driven vehicles (HVs) and the broader impact on
traffic flow. This oversight can exacerbate congestion and reduce overall
system efficiency. To address this critical research gap, we propose a neural
network-based, socially compliant AV control framework that incorporates social
value orientation (SVO). This framework enables AVs to account for their
influence on HVs and traffic dynamics. By leveraging AVs as mobile traffic
regulators, the proposed approach promotes adaptive driving behaviors that
reduce congestion, improve traffic efficiency, and lower energy consumption.
Within this framework, we define utility functions for both AVs and HVs, which
are optimized based on the SVO of each AV to balance its own control objectives
with broader traffic flow considerations. Numerical results demonstrate the
effectiveness of the proposed method in adapting to varying traffic conditions,
thereby enhancing system-wide efficiency. Specifically, when the AV's control
mode shifts from prioritizing energy consumption to optimizing traffic flow
efficiency, vehicles in the following platoon experience at least a 58.99%
increase in individual energy consumption alongside at least a 38.39%
improvement in individual average speed, indicating significant enhancements in
traffic dynamics.

</details>


### [5] [Next-Generation LLM for UAV: From Natural Language to Autonomous Flight](https://arxiv.org/abs/2510.21739)
*Liangqi Yuan,Chuhao Deng,Dong-Jun Han,Inseok Hwang,Sabine Brunswicker,Christopher G. Brinton*

Main category: cs.RO

TL;DR: 提出了NeLV系统，这是一个将大语言模型集成到多尺度无人机操作中的综合演示和自动化路线图，通过五个关键技术组件处理自然语言指令来编排短、中、长程无人机任务。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要局限于小规模无人机应用，缺乏对中长程无人机系统在真实操作环境中的全面研究。大型无人机平台带来了独特的挑战，包括严格的机场起降程序、复杂法规框架遵循以及具有更高任务期望的专业操作能力。

Method: NeLV系统包含五个关键技术组件：LLM解析器用于指令解释、路线规划器用于兴趣点确定、路径规划器用于航点生成、控制平台用于可执行轨迹实施、以及无人机监控。通过三个代表性用例验证系统可行性。

Result: 通过三个代表性用例（多无人机巡逻、多兴趣点交付、多跳迁移）展示了系统的可行性，涵盖了不同的操作规模。

Conclusion: 建立了五级自动化分类法，从当前的LLM解析器能力（第1级）演进到完全自主的LLM自动驾驶系统（第5级），识别了每个阶段的技术先决条件和研究挑战。

Abstract: With the rapid advancement of Large Language Models (LLMs), their
capabilities in various automation domains, particularly Unmanned Aerial
Vehicle (UAV) operations, have garnered increasing attention. Current research
remains predominantly constrained to small-scale UAV applications, with most
studies focusing on isolated components such as path planning for toy drones,
while lacking comprehensive investigation of medium- and long-range UAV systems
in real-world operational contexts. Larger UAV platforms introduce distinct
challenges, including stringent requirements for airport-based take-off and
landing procedures, adherence to complex regulatory frameworks, and specialized
operational capabilities with elevated mission expectations. This position
paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive
demonstration and automation roadmap for integrating LLMs into multi-scale UAV
operations. The NeLV system processes natural language instructions to
orchestrate short-, medium-, and long-range UAV missions through five key
technical components: (i) LLM-as-Parser for instruction interpretation, (ii)
Route Planner for Points of Interest (POI) determination, (iii) Path Planner
for waypoint generation, (iv) Control Platform for executable trajectory
implementation, and (v) UAV monitoring. We demonstrate the system's feasibility
through three representative use cases spanning different operational scales:
multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the
current implementation, we establish a five-level automation taxonomy that
charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully
autonomous LLM-as-Autopilot systems (Level 5), identifying technical
prerequisites and research challenges at each stage.

</details>


### [6] [FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation](https://arxiv.org/abs/2510.21744)
*Yanjia Huang,Shuo Liu,Sheng Liu,Qingxiao Xu,Mingyang Wu,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.RO

TL;DR: FORGE-Tree是一个插件控制层，通过阶段对齐的扩散强制头和测试时蒙特卡洛树扩散来解决VLA策略在长时程机器人操作任务中的漂移和暴露偏差问题。


<details>
  <summary>Details</summary>
Motivation: 长时程机器人操作任务对VLA策略具有挑战性，因为漂移和暴露偏差会导致几何误差在阶段间累积，且缺乏在紧密间隙处分配额外计算资源的机制。

Method: 使用冻结的VLA编码器，扩散强制头将时间步与子任务阶段对齐；在推理时仅部分去噪目标段而保持其他标记冻结，将轨迹优化转化为局部编辑序列。然后应用蒙特卡洛树扩散选择下一个要优化的段。

Result: 在LIBERO评估中，FORGE-Tree相比原生VLA基线（OpenVLA和Octo-Base）将成功率提高了13.4到17.2个百分点，在可比较的计算预算下保持一致的增益，特别是在长时程变体上。

Conclusion: FORGE-Tree通过树结构去噪方法有效解决了VLA策略在长时程机器人操作中的挑战，性能随搜索预算扩展而提升，同时保留已执行的前缀。

Abstract: Long-horizon robot manipulation tasks remain challenging for
Vision-Language-Action (VLA) policies due to drift and exposure bias, often
denoise the entire trajectory with fixed hyperparameters, causing small
geometric errors to compound across stages and offering no mechanism to
allocate extra test-time compute where clearances are tight. To address these
challenges, we introduce FORGE-Tree, a plug-in control layer that couples a
stage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree
Diffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask
stages; during inference we partially denoise only a target segment while
keeping other tokens frozen, turning trajectory refinement into a sequence of
local edits. We then apply Monte Carlo Tree Diffusion to select the next
segment to refine. A scene graph supplies priors for expansion and geometry
relation-aware scoring for rollouts, yielding tree-structured denoising whose
performance scales with search budget while preserving the executed prefix.
Evaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over
the native VLA baselines with both OpenVLA and Octo-Base. Gains remain
consistent under comparable compute budgets, especially on long-horizon
variants. Videos available at: https://taco-group.github.io/FORGE-Tree/

</details>


### [7] [Avi: Action from Volumetric Inference](https://arxiv.org/abs/2510.21746)
*Harris Song,Long Le*

Main category: cs.RO

TL;DR: Avi是一个新颖的3D视觉-语言-动作架构，将机器人动作生成重新定义为3D感知和空间推理问题，而非低级策略学习。它利用3D点云和基于语言的场景理解，通过经典几何变换计算动作。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要基于2D视觉输入，通过端到端训练学习特定任务的动作策略。Avi旨在通过3D感知和空间推理来弥合高级语言指令与低级执行之间的差距，避免不透明的策略学习。

Method: 基于3D多模态大语言模型生成下一个点云，通过经典几何变换显式计算动作。不训练动作标记，而是将机器人决策过程视为对3D表示的结构化推理任务。

Result: 该方法实现了对遮挡、相机姿态变化和视角变化的鲁棒性，能够产生可泛化的行为。初步结果显示了3D视觉语言推理作为可扩展、鲁棒机器人系统基础的潜力。

Conclusion: Avi通过将机器人动作生成重新定义为3D感知和空间推理问题，为构建可扩展、鲁棒的机器人系统提供了一种有前景的方法，避免了传统策略学习的不透明性。

Abstract: We propose Avi, a novel 3D Vision-Language-Action (VLA) architecture that
reframes robotic action generation as a problem of 3D perception and spatial
reasoning, rather than low-level policy learning. While existing VLA models
primarily operate on 2D visual inputs and are trained end-to-end on
task-specific action policies, Avi leverages 3D point clouds and
language-grounded scene understanding to compute actions through classical
geometric transformations. Most notably, Avi does not train on previous action
tokens, rather, we build upon a 3D Multi-modal Large Language Model (MLLM) to
generate the next point cloud and explicitly calculate the actions through
classical transformations. This approach enables generalizable behaviors that
are robust to occlusions, camera pose variations, and changes in viewpoint. By
treating the robotic decision-making process as a structured reasoning task
over 3D representations, Avi bridges the gap between high-level language
instructions and low-level actuation without requiring opaque policy learning.
Our preliminary results highlight the potential of 3D vision-language reasoning
as a foundation for scalable, robust robotic systems. Check it out at
https://avi-3drobot.github.io/.

</details>


### [8] [Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning](https://arxiv.org/abs/2510.21751)
*Van Nam Dinh,Van Vy Phan,Thai Son Dang,Van Du Phan,The Anh Mai,Van Chuong Le,Sy Phuong Ho,Dinh Tu Duong,Hung Cuong Ta*

Main category: cs.RO

TL;DR: 提出了一种基于混合整数二次规划和模型预测控制的自动驾驶轨迹规划方法，专门优化通过减速带时的乘客舒适度


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆在复杂城市环境中处理减速带时的轨迹规划挑战，需要同时考虑乘客舒适度和实时计算效率

Method: 使用混合整数二次规划(MIQP)框架和模型预测控制(MPC)，开发了模拟人类驾驶行为的减速带处理约束条件

Result: 在多种城市驾驶环境中的仿真表明，该方法能够实现平滑的减速带通过，同时保持适合实时部署的计算效率

Conclusion: 该方法能够同时处理静态道路特征和动态约束，结合专家人类驾驶行为，代表了城市轨迹规划的重要进展

Abstract: This paper proposes a novel methodology for trajectory planning in autonomous
vehicles (AVs), addressing the complex challenge of negotiating speed bumps
within a unified Mixed-Integer Quadratic Programming (MIQP) framework. By
leveraging Model Predictive Control (MPC), we develop trajectories that
optimize both the traversal of speed bumps and overall passenger comfort. A key
contribution of this work is the formulation of speed bump handling constraints
that closely emulate human driving behavior, seamlessly integrating these with
broader road navigation requirements. Through extensive simulations in varied
urban driving environments, we demonstrate the efficacy of our approach,
highlighting its ability to ensure smooth speed transitions over speed bumps
while maintaining computational efficiency suitable for real-time deployment.
The method's capability to handle both static road features and dynamic
constraints, alongside expert human driving, represents a significant step
forward in trajectory planning for urban

</details>


### [9] [Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review](https://arxiv.org/abs/2510.21758)
*Kumater Ter,RexCharles Donatus,Ore-Ofe Ajayi,Daniel Udekwe*

Main category: cs.RO

TL;DR: 这篇论文对强化学习在机器人领域的应用进行了全面综述，涵盖了从MDP基础到现代深度强化学习算法的理论发展和实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习在动态不确定环境中实现智能机器人行为的重要性日益增长，需要系统地总结RL原理、深度强化学习算法及其在机器人控制系统中的集成应用。

Method: 采用结构化分类法，从马尔可夫决策过程形式化开始，分析agent-environment交互要素，探讨actor-critic方法、基于价值的学习和策略梯度等核心算法策略，重点关注DDPG、TD3、PPO和SAC等现代DRL技术。

Result: 构建了涵盖运动、操作、多智能体协调和人机交互等领域的RL应用分类体系，总结了训练方法和部署准备度等级，综合了最新研究进展、技术趋势和设计模式。

Conclusion: 强化学习在真实世界机器人应用中日益成熟，本综述旨在连接理论进展与实际实现，为自主机器人系统中RL的演进作用提供整合视角。

Abstract: Reinforcement learning (RL) has become a foundational approach for enabling
intelligent robotic behavior in dynamic and uncertain environments. This work
presents an in-depth review of RL principles, advanced deep reinforcement
learning (DRL) algorithms, and their integration into robotic and control
systems. Beginning with the formalism of Markov Decision Processes (MDPs), the
study outlines essential elements of the agent-environment interaction and
explores core algorithmic strategies including actor-critic methods,
value-based learning, and policy gradients. Emphasis is placed on modern DRL
techniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving
high-dimensional, continuous control tasks. A structured taxonomy is introduced
to categorize RL applications across domains such as locomotion, manipulation,
multi-agent coordination, and human-robot interaction, along with training
methodologies and deployment readiness levels. The review synthesizes recent
research efforts, highlighting technical trends, design patterns, and the
growing maturity of RL in real-world robotics. Overall, this work aims to
bridge theoretical advances with practical implementations, providing a
consolidated perspective on the evolving role of RL in autonomous robotic
systems.

</details>


### [10] [J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception](https://arxiv.org/abs/2510.21761)
*Jesse Atuhurra,Hidetaka Kamigaito,Taro Watanabe,Koichiro Yoshino*

Main category: cs.RO

TL;DR: J-ORA是一个新颖的多模态数据集，通过提供日语人机对话场景中的详细物体属性标注，填补了机器人感知领域的空白。该数据集支持物体识别、指代消解和下一动作预测三个关键感知任务。


<details>
  <summary>Details</summary>
Motivation: 解决机器人感知中缺乏详细物体属性标注的问题，特别是在日语人机对话场景中，需要丰富的上下文敏感属性标注来提升多模态感知性能。

Method: 构建包含详细物体属性模板（如类别、颜色、形状、大小、材质和空间关系）的J-ORA数据集，并使用专有和开源视觉语言模型进行广泛评估。

Result: 实验表明，加入详细物体属性能显著提升多模态感知性能，但专有模型与开源模型之间仍存在差距。不同模型在理解物体功能性和上下文关系方面表现出不同能力。

Conclusion: 丰富的上下文敏感属性标注对于提升动态环境中机器人感知能力至关重要，J-ORA数据集为这一领域提供了重要资源。

Abstract: We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot
perception by providing detailed object attribute annotations within Japanese
human-robot dialogue scenarios. J-ORA is designed to support three critical
perception tasks, object identification, reference resolution, and next-action
prediction, by leveraging a comprehensive template of attributes (e.g.,
category, color, shape, size, material, and spatial relations). Extensive
evaluations with both proprietary and open-source Vision Language Models (VLMs)
reveal that incorporating detailed object attributes substantially improves
multimodal perception performance compared to without object attributes.
Despite the improvement, we find that there still exists a gap between
proprietary and open-source VLMs. In addition, our analysis of object
affordances demonstrates varying abilities in understanding object
functionality and contextual relationships across different VLMs. These
findings underscore the importance of rich, context-sensitive attribute
annotations in advancing robot perception in dynamic environments. See project
page at https://jatuhurrra.github.io/J-ORA/.

</details>


### [11] [Improving the performance of AI-powered Affordable Robotics for Assistive Tasks](https://arxiv.org/abs/2510.21771)
*Dharunish Yugeswardeenoo*

Main category: cs.RO

TL;DR: 开发低成本机器人手臂用于辅助护理任务，通过模仿学习实现90%任务准确率，相比基线提升40%，模型尺寸减少5倍


<details>
  <summary>Details</summary>
Motivation: 到2050年全球辅助护理需求将达35亿人，远超人类护理人员供应，现有机器人方案昂贵且需要技术专长

Method: 使用模仿学习从演示视频学习，无需任务特定编程；采用PACT模型捕捉时间依赖性和分割运动动态，TE方法优化轨迹；通过遥操作收集50,000帧数据

Result: 在五个模型尺寸和四种架构评估中，系统实现超过90%任务准确率，比基线高40%；PACT使模型尺寸减少5倍同时保持75%准确率

Conclusion: 该系统为低成本辅助护理机器人提供了可行方案，未来将探索双手操作和移动性以扩展辅助能力

Abstract: By 2050, the global demand for assistive care is expected to reach 3.5
billion people, far outpacing the availability of human caregivers. Existing
robotic solutions remain expensive and require technical expertise, limiting
accessibility. This work introduces a low-cost robotic arm for assistive tasks
such as feeding, cleaning spills, and fetching medicine. The system uses
imitation learning from demonstration videos, requiring no task-specific
programming or manual labeling. The robot consists of six servo motors, dual
cameras, and 3D-printed grippers. Data collection via teleoperation with a
leader arm yielded 50,000 video frames across the three tasks. A novel Phased
Action Chunking Transformer (PACT) captures temporal dependencies and segments
motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to
improve accuracy and smoothness. Evaluated across five model sizes and four
architectures, with ten hours of real-world testing, the system achieved over
90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model
size reduction while maintaining 75% accuracy. Saliency analysis showed
reliance on key visual cues, and phase token gradients peaked at critical
trajectory moments, indicating effective temporal reasoning. Future work will
explore bimanual manipulation and mobility for expanded assistive capabilities.

</details>


### [12] [Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots](https://arxiv.org/abs/2510.21773)
*Van Nam Dinh*

Main category: cs.RO

TL;DR: 本文对足式机器人中使用的二次规划求解器进行了全面的分析和基准测试，比较了四种主要算法在计算时间、约束满足和鲁棒性方面的性能，为不同应用场景提供求解器选择指导。


<details>
  <summary>Details</summary>
Motivation: 二次规划在足式机器人实时控制中至关重要，但嵌入式平台存在严格的时序、能耗和计算限制，需要可靠的求解器来支持逆动力学、模型预测控制和全身控制等关键模块。

Method: 将求解器分为四大类：内点法、有效集法、算子分裂法和增广拉格朗日法，分析每种算法的结构、计算特性、利用问题结构和热启动的能力，使用公开基准测试评估性能。

Result: 研究发现不同求解器在速度、精度和能效方面存在权衡，稀疏内点法适合长时域MPC，密集有效集法适合高频WBC，强调求解器、任务和硬件的协同作用。

Conclusion: 通过特征表和比较提供了实用的求解器选择指导，强调了算法与任务、硬件的匹配关系，为推进敏捷自主足式系统的发展提供支持，并展望了非凸和分布式QP的扩展应用。

Abstract: Quadratic programming (QP) underpins real-time robotics by enabling
efficient, constrained optimization in state estimation, motion planning, and
control. In legged locomotion and manipulation, essential modules like inverse
dynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are
inherently QP-based, demanding reliable solutions amid tight timing, energy,
and computational limits on embedded platforms. This paper presents a
comprehensive analysis and benchmarking study of cutting-edge QP solvers for
legged robotics. We begin by formulating the standard convex QP and classify
solvers into four principal algorithmic approaches, including interior-point
methods, active-set strategies, operator splitting schemes, and augmented
Lagrangian approaches. Each solver is examined in terms of algorithmic
structure, computational characteristics, and its ability to exploit problem
structure and warm-starting. Performance is evaluated using publicly available
benchmarks, focusing on metrics such as computation time, constraint
satisfaction, and robustness under perturbations. Feature tables and
comparisons yield practical guidance for solver selection, underscoring
trade-offs in speed, accuracy, and energy efficiency. Our findings emphasize
the synergy between solver, task, and hardware, sparse IPMs for long-horizon
MPC, and dense active-set for high frequency WBC to advance agile, autonomous
legged systems, with emerging extensions to nonconvex and distributed QP.

</details>


### [13] [VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting](https://arxiv.org/abs/2510.21817)
*Xiaoyu Liu,Chaoyou Fu,Chi Yan,Chu Wu,Haihan Gao,Yi-Fan Zhang,Shaoqi Dong,Cheng Qian,Bin Luo,Xiuyong Yang,Guanwu Li,Yusheng Cai,Yunhang Shen,Deqiang Jiang,Haoyu Cao,Xing Sun,Caifeng Shan,Ran He*

Main category: cs.RO

TL;DR: VITA-E是一个支持行为并发和实时中断的具身交互框架，采用双模型架构实现观察、聆听、说话和行动的并行处理，模拟人类多任务能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型受限于僵化的静态交互范式，无法同时观察、聆听、说话和行动，也无法处理实时用户中断，阻碍了无缝的具身协作。

Method: 采用双模型架构，两个并行VLA实例分别作为'主动模型'和'待机模型'，并提出'模型即控制器'范式，通过微调VLM生成特殊令牌作为系统级命令。

Result: 在物理人形平台上进行的实验表明，VITA-E能可靠处理复杂交互场景，在紧急停止和语音中断方面达到极高成功率，并能成功执行并发语音和动作。

Conclusion: 该框架代表了向更自然、更强大的具身助手迈出的重要一步，兼容多种双系统VLA模型。

Abstract: Current Vision-Language-Action (VLA) models are often constrained by a rigid,
static interaction paradigm, which lacks the ability to see, hear, speak, and
act concurrently as well as handle real-time user interruptions dynamically.
This hinders seamless embodied collaboration, resulting in an inflexible and
unresponsive user experience. To address these limitations, we introduce
VITA-E, a novel embodied interaction framework designed for both behavioral
concurrency and nearly real-time interruption. The core of our approach is a
dual-model architecture where two parallel VLA instances operate as an ``Active
Model'' and a ``Standby Model'', allowing the embodied agent to observe its
environment, listen to user speech, provide verbal responses, and execute
actions, all concurrently and interruptibly, mimicking human-like multitasking
capabilities. We further propose a ``model-as-controller'' paradigm, where we
fine-tune the VLM to generate special tokens that serve as direct system-level
commands, coupling the model's reasoning with the system's behavior.
Experiments conducted on a physical humanoid platform demonstrate that VITA-E
can reliably handle complex interactive scenarios. Our framework is compatible
with various dual-system VLA models, achieving an extremely high success rate
on emergency stops and speech interruptions while also successfully performing
concurrent speech and action. This represents a significant step towards more
natural and capable embodied assistants.

</details>


### [14] [A Literature Review On Stewart-Gough Platform Calibrations A Literature Review On Stewart-Gough Platform Calibrations](https://arxiv.org/abs/2510.21854)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了Stewart-Gough平台（六足平台）的标定技术，重点关注基于逆运动学的标定方法，分析了不同标定策略及其在提高平台位置和方向精度方面的效果。


<details>
  <summary>Details</summary>
Motivation: Stewart-Gough平台在医疗、工程机械、空间研究等关键应用中需要微米和纳米级的运动控制精度，因此精确的标定对于这些并行机器人至关重要。

Method: 通过使用外部仪器、约束系统运动、添加额外传感器等方法实施不同的标定技术，特别关注基于逆运动学的并行机器人标定方法。

Result: 研究发现研究人员主要关注提高平台位置和方向精度，考虑单一或多重误差源，包括运动学和结构误差，在无负载条件下进行标定。

Conclusion: 本文综述了Stewart-Gough平台标定领域的最新技术现状，重点突出了标定过程中考虑的过程和误差因素。

Abstract: Researchers have studied Stewart-Gough platforms, also known as Gough-Stewart
platforms or hexapod platforms extensively for their inherent fine control
characteristics. Their studies led to the potential deployment opportunities of
Stewart-Gough Platforms in many critical applications such as the medical
field, engineering machines, space research, electronic chip manufacturing,
automobile manufacturing, etc. Some of these applications need micro and
nano-level movement control in 3D space for the motions to be precise,
complicated, and repeatable; a Stewart-Gough platform fulfills these challenges
smartly. For this, the platform must be more accurate than the specified
application accuracy level and thus proper calibration for a parallel robot is
crucial. Forward kinematics-based calibration for these hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To experiment with different calibration techniques, various
calibration approaches were implemented by using external instruments,
constraining one or more motions of the system, and using extra sensors for
auto or self-calibration. This survey paid attention to those key
methodologies, their outcome, and important details related to inverse
kinematic-based parallel robot calibrations. It was observed during this study
that the researchers focused on improving the accuracy of the platform position
and orientation considering the errors contributed by one source or multiple
sources. The error sources considered are mainly kinematic and structural, in
some cases, environmental factors also are reviewed, however, those
calibrations are done under no-load conditions. This study aims to review the
present state of the art in this field and highlight the processes and errors
considered for the calibration of Stewart-Gough platforms.

</details>


### [15] [Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence](https://arxiv.org/abs/2510.21860)
*Callum Sharrock,Lukas Petersson,Hanna Petersson,Axel Backlund,Axel Wennström,Kristoffer Nordström,Elias Aronsson*

Main category: cs.RO

TL;DR: Butter-Bench是一个评估大语言模型控制机器人实际智能的基准测试，发现人类表现（95%）远超最佳LLM（40%），特别是在多步空间规划和社会理解方面。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在物理世界实际智能中的表现，当前机器人系统采用分层架构，但LLM在高层推理中的能力尚未得到充分评估。

Method: 开发Butter-Bench基准，将LLM与视觉语言动作模型分离，单独评估LLM在机器人控制中的高层推理能力。

Result: 人类平均得分95%，而最佳LLM仅得40%；LLM在多步空间规划和社会理解方面表现最差；针对具身推理的微调并未改善性能。

Conclusion: 尽管LLM在分析智能方面超越人类，但在物理世界实际智能方面仍远落后于人类，特别是在空间规划和社会理解任务上。

Abstract: We present Butter-Bench, a benchmark evaluating large language model (LLM)
controlled robots for practical intelligence, defined as the ability to
navigate the messiness of the physical world. Current state-of-the-art robotic
systems use a hierarchical architecture with LLMs in charge of high-level
reasoning, and a Vision Language Action (VLA) model for low-level control.
Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs
have repeatedly surpassed humans in evaluations requiring analytical
intelligence, we find humans still outperform LLMs on Butter-Bench. The best
LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs
struggled the most with multi-step spatial planning and social understanding.
We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude
that this training does not improve their score on Butter-Bench.

</details>


### [16] [A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments](https://arxiv.org/abs/2510.21874)
*Shuning Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于物理信息神经网络(PINN)的无人机轨迹规划框架，将无人机动力学、风扰和避障约束直接嵌入学习过程，无需监督数据即可生成动态可行且无碰撞的轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统规划器如A*和Kino-RRT*由于离散化和采样限制，往往产生次优或不平滑的路径，无法在动态风场中生成安全且节能的轨迹。

Method: 使用PINN框架，通过最小化物理残差和风险感知目标来学习轨迹，无需监督数据，直接嵌入无人机动力学、风扰和避障约束。

Result: 比较仿真显示，该方法在控制能量、平滑度和安全裕度方面优于A*和Kino-RRT*，同时保持相似的飞行效率。

Conclusion: 物理信息学习有潜力统一基于模型和数据驱动的规划，为无人机轨迹优化提供可扩展且物理一致的框架。

Abstract: Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must
generate safe and energy-efficient trajectories under physical and
environmental constraints. Traditional planners, such as A* and kinodynamic
RRT*, often yield suboptimal or non-smooth paths due to discretization and
sampling limitations. This paper presents a physics-informed neural network
(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle
avoidance directly into the learning process. Without requiring supervised
data, the PINN learns dynamically feasible and collision-free trajectories by
minimizing physical residuals and risk-aware objectives. Comparative
simulations show that the proposed method outperforms A* and Kino-RRT* in
control energy, smoothness, and safety margin, while maintaining similar flight
efficiency. The results highlight the potential of physics-informed learning to
unify model-based and data-driven planning, providing a scalable and physically
consistent framework for UAV trajectory optimization.

</details>


### [17] [Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising](https://arxiv.org/abs/2510.21991)
*Mateo Clemente,Leo Brunswic,Rui Heng Yang,Xuan Zhao,Yasser Khalil,Haoyu Lei,Amir Rasouli,Yinchuan Li*

Main category: cs.RO

TL;DR: 本文提出了一种针对机器人控制任务优化的扩散策略，通过定制化去噪过程和遗传去噪采样策略，仅需2-5次神经网络评估即可高效解决复杂操作任务。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在机器人控制领域直接沿用视觉任务的推理策略，未能针对控制任务中动作分布的结构化和低维特性进行优化。

Method: 提出遗传去噪采样策略，通过选择低分布外风险的去噪轨迹来提升性能和稳定性；针对具体任务特性定制去噪过程。

Result: 在14个机器人操作任务上评估，仅需2次神经网络评估即可解决挑战性任务，性能提升达20%，在200万次评估中始终优于标准扩散策略。

Conclusion: 通过针对控制任务特性优化扩散策略，可以显著减少推理步骤同时提升性能，为机器人控制中的扩散模型应用提供了高效解决方案。

Abstract: Diffusion models, such as diffusion policy, have achieved state-of-the-art
results in robotic manipulation by imitating expert demonstrations. While
diffusion models were originally developed for vision tasks like image and
video generation, many of their inference strategies have been directly
transferred to control domains without adaptation. In this work, we show that
by tailoring the denoising process to the specific characteristics of embodied
AI tasks -- particularly structured, low-dimensional nature of action
distributions -- diffusion policies can operate effectively with as few as 5
neural function evaluations (NFE).
  Building on this insight, we propose a population-based sampling strategy,
genetic denoising, which enhances both performance and stability by selecting
denoising trajectories with low out-of-distribution risk. Our method solves
challenging tasks with only 2 NFE while improving or matching performance. We
evaluate our approach across 14 robotic manipulation tasks from D4RL and
Robomimic, spanning multiple action horizons and inference budgets. In over 2
million evaluations, our method consistently outperforms standard
diffusion-based policies, achieving up to 20\% performance gains with
significantly fewer inference steps.

</details>


### [18] [Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems](https://arxiv.org/abs/2510.22030)
*Harsha Karunanayaka,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 通过分析模型参数和系统固有频率对最小步频的影响，研究双足系统在额状面的前馈稳定性机制，提出预测最小步频的方法。


<details>
  <summary>Details</summary>
Motivation: 目前对双足系统额状面稳定性的关键参数（质量、刚度、腿长、髋宽）如何影响稳定性和维持稳定所需的最小步频理解有限。

Method: 分析个体模型参数和系统固有频率对最小步频的影响，提出预测最小步频的方法，并与随机生成模型的实际值进行比较。

Result: 研究结果提供了对额状面稳定性机制和如何利用前馈稳定来减少控制努力的更好理解。

Conclusion: 前馈稳定机制可以降低控制努力和能量消耗，提高运动鲁棒性，为双足系统设计提供了重要指导。

Abstract: Stability of bipedal systems in frontal plane is affected by the hip offset,
to the extent that adjusting stride time using feedforward retraction and
extension of the legs can lead to stable oscillations without feedback control.
This feedforward stabilization can be leveraged to reduce the control effort
and energy expenditure and increase the locomotion robustness. However, there
is limited understanding of how key parameters, such as mass, stiffness, leg
length, and hip width, affect stability and the minimum stride frequency needed
to maintain it. This study aims to address these gaps through analyzing how
individual model parameters and the system's natural frequency influence the
minimum stride frequency required to maintain a stable cycle. We propose a
method to predict the minimum stride frequency, and compare the predicted
stride frequencies with actual values for randomly generated models. The
findings of this work provide a better understanding of the frontal plane
stability mechanisms and how feedforward stabilization can be leveraged to
reduce the control effort.

</details>


### [19] [RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation](https://arxiv.org/abs/2510.22113)
*Zitiantao Lin,Yongpeng Sang,Yang Ye*

Main category: cs.RO

TL;DR: 提出了一种基于混合现实头显的以自我为中心的注视引导机器人操控界面，通过自然注视和增强视觉提示来改善辅助机器人的直观性和可访问性。


<details>
  <summary>Details</summary>
Motivation: 传统操纵杆控制界面精度要求高且参考框架不直观，现有解决方案依赖外部屏幕或限制性控制方案，限制了直观性和可访问性。

Method: 利用可穿戴混合现实头显，从第一人称视角通过自然注视与真实世界物体交互，提供增强视觉提示确认意图，并使用预训练视觉模型和机械臂进行意图识别和物体操控。

Result: 实验结果显示该方法显著提高了操控精度，降低了系统延迟，在多个真实场景中单次意图和物体识别准确率超过88%。

Conclusion: 该系统有效增强了直观性和可访问性，在辅助机器人应用中具有重要实践意义。

Abstract: Robotic manipulators are increasingly used to assist individuals with
mobility impairments in object retrieval. However, the predominant
joystick-based control interfaces can be challenging due to high precision
requirements and unintuitive reference frames. Recent advances in human-robot
interaction have explored alternative modalities, yet many solutions still rely
on external screens or restrictive control schemes, limiting their
intuitiveness and accessibility. To address these challenges, we present an
egocentric, gaze-guided robotic manipulation interface that leverages a
wearable Mixed Reality (MR) headset. Our system enables users to interact
seamlessly with real-world objects using natural gaze fixation from a
first-person perspective, while providing augmented visual cues to confirm
intent and leveraging a pretrained vision model and robotic arm for intent
recognition and object manipulation. Experimental results demonstrate that our
approach significantly improves manipulation accuracy, reduces system latency,
and achieves single-pass intention and object recognition accuracy greater than
88% across multiple real-world scenarios. These results demonstrate the
system's effectiveness in enhancing intuitiveness and accessibility,
underscoring its practical significance for assistive robotics applications.

</details>


### [20] [EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control](https://arxiv.org/abs/2510.22126)
*Guanwen Xie,Jingzehua Xu,Jiwei Tang,Yubo Huang,Shuai Zhang,Xiaofan Li*

Main category: cs.RO

TL;DR: EasyUUV是一个基于大语言模型增强的轻量级仿真到实景强化学习框架，用于无人水下航行器的鲁棒姿态控制，结合并行RL训练和混合控制架构，通过自适应S-Surface控制器和LLM参数调优实现训练自由的自适应控制。


<details>
  <summary>Details</summary>
Motivation: 解决现有UUV姿态控制方法在泛化性、对真实世界扰动的鲁棒性以及高效部署方面的不足。

Method: 采用并行化强化学习训练与混合控制架构，学习策略输出高层姿态修正，由自适应S-Surface控制器执行，并集成多模态LLM根据视觉和文本反馈自适应调整控制器参数。

Result: 广泛的仿真和真实世界实验验证了EasyUUV在不同水下条件下实现鲁棒和自适应UUV姿态控制的有效性和卓越性能。

Conclusion: EasyUUV框架通过LLM增强和仿真到实景的强化学习方法，成功解决了UUV姿态控制的泛化性、鲁棒性和部署效率问题。

Abstract: Despite recent advances in Unmanned Underwater Vehicle (UUV) attitude
control, existing methods still struggle with generalizability, robustness to
real-world disturbances, and efficient deployment. To address the above
challenges, this paper presents EasyUUV, a Large Language Model (LLM)-enhanced,
universal, and lightweight simulation-to-reality reinforcement learning (RL)
framework for robust attitude control of UUVs. EasyUUV combines parallelized RL
training with a hybrid control architecture, where a learned policy outputs
high-level attitude corrections executed by an adaptive S-Surface controller. A
multimodal LLM is further integrated to adaptively tune controller parameters
at runtime using visual and textual feedback, enabling training-free adaptation
to unmodeled dynamics. Also, we have developed a low-cost 6-DoF UUV platform
and applied an RL policy trained through efficient parallelized simulation.
Extensive simulation and real-world experiments validate the effectiveness and
outstanding performance of EasyUUV in achieving robust and adaptive UUV
attitude control across diverse underwater conditions. The source code is
available from the following website: https://360zmem.github.io/easyuuv/

</details>


### [21] [LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons](https://arxiv.org/abs/2510.22164)
*Jianeng Wang,Matias Mattamala,Christina Kassab,Nived Chebrolu,Guillaume Burger,Fabio Elnecave,Marine Petriaux,Maurice Fallon*

Main category: cs.RO

TL;DR: LT-Exosense是一个面向外骨骼用户的视觉中心多会话映射系统，支持长期（半）自主导航，通过增量融合多会话空间知识、检测环境变化和更新持久全局地图来实现智能路径规划。


<details>
  <summary>Details</summary>
Motivation: 为下肢残疾人士提供可靠长期运行的自平衡外骨骼需要能在变化环境中有效工作的感知系统。

Method: 扩展单会话映射能力，通过增量融合多会话空间知识、检测环境变化、更新持久全局地图，实现智能路径规划。

Result: 在真实世界实验中验证了可扩展的多会话地图，与地面真实激光扫描相比，平均点对点误差低于5厘米，展示了在动态变化室内环境中自适应路径规划的潜力。

Conclusion: LT-Exosense系统能够有效支持外骨骼用户的长期自主导航，在动态环境中实现可靠的地图构建和路径规划。

Abstract: Self-balancing exoskeletons offer a promising mobility solution for
individuals with lower-limb disabilities. For reliable long-term operation,
these exoskeletons require a perception system that is effective in changing
environments. In this work, we introduce LT-Exosense, a vision-centric,
multi-session mapping system designed to support long-term (semi)-autonomous
navigation for exoskeleton users. LT-Exosense extends single-session mapping
capabilities by incrementally fusing spatial knowledge across multiple
sessions, detecting environmental changes, and updating a persistent global
map. This representation enables intelligent path planning, which can adapt to
newly observed obstacles and can recover previous routes when obstructions are
removed. We validate LT-Exosense through several real-world experiments,
demonstrating a scalable multi-session map that achieves an average
point-to-point error below 5 cm when compared to ground-truth laser scans. We
also illustrate the potential application of adaptive path planning in
dynamically changing indoor environments.

</details>


### [22] [ACG: Action Coherence Guidance for Flow-based VLA models](https://arxiv.org/abs/2510.22201)
*Minho Park,Kinam Kim,Junha Hyung,Hyojin Jang,Hoiyeong Jin,Jooyeol Yun,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 提出了一种名为Action Coherence Guidance (ACG)的训练时无需调整的测试时指导算法，用于提升VLA模型的动作连贯性，从而提高在精细操作任务中的成功率。


<details>
  <summary>Details</summary>
Motivation: 扩散和流匹配模型作为机器人策略时，在模仿学习中容易受到人类演示数据中噪声（如抖动、暂停等）的影响，导致动作不连贯，进而引发部署时的不稳定和轨迹漂移，这在需要精确操作的精细操作任务中是灾难性的。

Method: ACG是一种训练时无需调整的测试时指导算法，通过在测试时对模型输出进行指导来提升动作的连贯性。

Result: 在RoboCasa、DexMimicGen和真实世界SO-101任务上的评估表明，ACG能够持续提升动作连贯性，并在多种操作任务中提高成功率。

Conclusion: ACG算法有效解决了VLA模型在模仿学习中因数据噪声导致的动作不连贯问题，显著提升了模型在精细操作任务中的性能。

Abstract: Diffusion and flow matching models have emerged as powerful robot policies,
enabling Vision-Language-Action (VLA) models to generalize across diverse
scenes and instructions. Yet, when trained via imitation learning, their high
generative capacity makes them sensitive to noise in human demonstrations:
jerks, pauses, and jitter which reduce action coherence. Reduced action
coherence causes instability and trajectory drift during deployment, failures
that are catastrophic in fine-grained manipulation where precision is crucial.
In this paper, we present Action Coherence Guidance (ACG) for VLA models, a
training-free test-time guidance algorithm that improves action coherence and
thereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and
real-world SO-101 tasks, ACG consistently improves action coherence and boosts
success rates across diverse manipulation tasks. Code and project page are
available at https://github.com/DAVIAN-Robotics/ACG and
https://DAVIAN-Robotics.github.io/ACG , respectively.

</details>


### [23] [Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments](https://arxiv.org/abs/2510.22204)
*Weixian Qian,Sebastian Schroder,Yao Deng,Jiaohong Yao,Linfeng Liang,Xiao Cheng,Richard Han,Xi Zheng*

Main category: cs.RO

TL;DR: NeuroSymLand是一个神经符号框架，结合了离线知识合成和在线推理，用于无人机在非结构化环境中的自主着陆，通过符号推理提高可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决纯视觉或深度学习模型在无人机自主着陆中存在的协变量偏移问题和可解释性不足的挑战。

Method: 采用双管道设计：离线管道使用LLM和人工精炼合成可验证的符号知识；在线管道使用轻量级基础模型生成概率事实，结合几何计算构建语义场景图进行实时推理。

Result: 在多个数据集、仿真环境和真实无人机硬件上的评估表明，NeuroSymLand在准确性、鲁棒性和效率方面优于现有方法。

Conclusion: NeuroSymLand通过神经符号方法显著提升了无人机在紧急响应、监视和配送任务中的安全性和可靠性。

Abstract: Autonomous landing in unstructured (cluttered, uneven, and map-poor)
environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet
purely vision-based or deep learning models often falter under covariate shift
and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic
framework that tightly couples two complementary pipelines: (i) an offline
pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement
synthesize Scallop code from diverse landing scenarios, distilling
generalizable and verifiable symbolic knowledge; and (ii) an online pipeline,
where a compact foundation-based semantic segmentation model generates
probabilistic Scallop facts that are composed into semantic scene graphs for
real-time deductive reasoning. This design combines the perceptual strengths of
lightweight foundation models with the interpretability and verifiability of
symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations
(adjacency, containment, proximity) are computed with geometric routines rather
than learned, avoiding the data dependence and latency of train-time graph
builders. The resulting Scallop program encodes landing principles (avoid water
and obstacles; prefer large, flat, accessible regions) and yields calibrated
safety scores with ranked Regions of Interest (ROIs) and human-readable
justifications. Extensive evaluations across datasets, diverse simulation maps,
and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger
robustness to covariate shift, and superior efficiency compared with
state-of-the-art baselines, while advancing UAV safety and reliability in
emergency response, surveillance, and delivery missions.

</details>


### [24] [Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis](https://arxiv.org/abs/2510.22313)
*Chen Zhiqiang,Le Gentil Cedric,Lin Fuling,Lu Minghao,Qiao Qiyuan,Xu Bowen,Qi Yuhua,Lu Peng*

Main category: cs.RO

TL;DR: 提出了一种动态感知的激光雷达-惯性里程计方法，通过将动态感知直接集成到点云配准过程中，解决了传统方法在动态环境中性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 传统LIO方法在动态环境中表现不佳，特别是在几何稀疏场景中，因为其基于静态世界假设。现有动态LIO方法面临循环依赖问题：精确定位需要可靠的静态特征识别，而区分动态对象又需要精确的位姿估计。

Method: 提出了动态感知的迭代最近点算法，利用时空法向量分析，并辅以高效的空间一致性验证方法来增强静态地图构建。

Result: 实验评估表明，在具有有限几何结构的挑战性动态环境中，该方法相比最先进的LIO系统有显著性能提升。

Conclusion: 通过打破循环依赖，将动态感知直接集成到点云配准过程中，有效解决了动态环境下的LIO定位问题。

Abstract: This paper addresses the challenge of Lidar-Inertial Odometry (LIO) in
dynamic environments, where conventional methods often fail due to their
static-world assumptions. Traditional LIO algorithms perform poorly when
dynamic objects dominate the scenes, particularly in geometrically sparse
environments. Current approaches to dynamic LIO face a fundamental challenge:
accurate localization requires a reliable identification of static features,
yet distinguishing dynamic objects necessitates precise pose estimation. Our
solution breaks this circular dependency by integrating dynamic awareness
directly into the point cloud registration process. We introduce a novel
dynamic-aware iterative closest point algorithm that leverages spatio-temporal
normal analysis, complemented by an efficient spatial consistency verification
method to enhance static map construction. Experimental evaluations demonstrate
significant performance improvements over state-of-the-art LIO systems in
challenging dynamic environments with limited geometric structure. The code and
dataset are available at https://github.com/thisparticle/btsa.

</details>


### [25] [Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery](https://arxiv.org/abs/2510.22336)
*Bo Yue,Sheng Xu,Kui Jia,Guiliang Liu*

Main category: cs.RO

TL;DR: RoboCraft是一个可扩展的人形机器人协同设计框架，通过控制策略和形态学的耦合更新迭代提升跌倒恢复性能，平均性能提升44.55%。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在人类工作空间具有天然部署优势，跌倒恢复能力对安全性和自主性至关重要，脑体协同设计是实现这一潜力的有前景方法。

Method: 通过共享策略在多设计上预训练，然后在高性能形态上逐步微调；形态搜索受人类启发先验和优化算法指导，使用优先级缓冲区平衡候选重新评估和新设计探索。

Result: 在7个公共人形机器人上平均性能提升44.55%，形态优化在4个机器人协同设计中贡献了至少40%的改进。

Conclusion: 人形机器人协同设计在提升跌倒恢复性能中发挥关键作用，形态优化是性能提升的重要驱动力。

Abstract: Humanoid robots represent a central frontier in embodied intelligence, as
their anthropomorphic form enables natural deployment in humans' workspace.
Brain-body co-design for humanoids presents a promising approach to realizing
this potential by jointly optimizing control policies and physical morphology.
Within this context, fall recovery emerges as a critical capability. It not
only enhances safety and resilience but also integrates naturally with
locomotion systems, thereby advancing the autonomy of humanoids. In this paper,
we propose RoboCraft, a scalable humanoid co-design framework for fall recovery
that iteratively improves performance through the coupled updates of control
policy and morphology. A shared policy pretrained across multiple designs is
progressively finetuned on high-performing morphologies, enabling efficient
adaptation without retraining from scratch. Concurrently, morphology search is
guided by human-inspired priors and optimization algorithms, supported by a
priority buffer that balances reevaluation of promising candidates with the
exploration of novel designs. Experiments show that \ourmethod{} achieves an
average performance gain of 44.55% on seven public humanoid robots, with
morphology optimization drives at least 40% of improvements in co-designing
four humanoid robots, underscoring the critical role of humanoid co-design.

</details>


### [26] [Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks](https://arxiv.org/abs/2510.22339)
*Enyi Wang,Zhen Deng,Chuanchuan Pan,Bingwei He,Jianwei Zhang*

Main category: cs.RO

TL;DR: 提出基于学习的柔性连续体机器人3D形状估计方法，融合多模态输入（肌腱位移数据和RGB图像）通过时空神经网络生成点云，再拟合Bézier曲线实现连续3D形状重建。


<details>
  <summary>Details</summary>
Motivation: 准确估计受外部载荷作用的柔性连续体机器人的3D形状，解决在加载条件下的精确形状感知问题。

Method: 使用时空神经网络架构，融合当前和历史肌腱位移数据及RGB图像，包含循环神经网络模块提取时间特征、编码模块提取空间特征，以及多模态融合模块结合视觉空间特征和驱动器输入的时间依赖性。

Result: 实验验证显示高精度表现，平均形状估计误差为0.08毫米（无负载）和0.22毫米（有负载），优于现有最先进的TDCR形状感知方法。

Conclusion: 深度学习为基础的时空数据融合方法在加载条件下实现精确形状估计的有效性得到验证。

Abstract: This paper presents a learning-based approach for accurately estimating the
3D shape of flexible continuum robots subjected to external loads. The proposed
method introduces a spatiotemporal neural network architecture that fuses
multi-modal inputs, including current and historical tendon displacement data
and RGB images, to generate point clouds representing the robot's deformed
configuration. The network integrates a recurrent neural module for temporal
feature extraction, an encoding module for spatial feature extraction, and a
multi-modal fusion module to combine spatial features extracted from visual
data with temporal dependencies from historical actuator inputs. Continuous 3D
shape reconstruction is achieved by fitting B\'ezier curves to the predicted
point clouds. Experimental validation demonstrates that our approach achieves
high precision, with mean shape estimation errors of 0.08 mm (unloaded) and
0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for
TDCRs. The results validate the efficacy of deep learning-based spatiotemporal
data fusion for precise shape estimation under loading conditions.

</details>


### [27] [BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles](https://arxiv.org/abs/2510.22370)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: BLIP-FusePPO是一种多模态强化学习框架，通过将视觉语言模型生成的语义嵌入与几何状态、LiDAR观测和PID控制反馈融合，实现自动驾驶车道保持任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅使用语义模型来塑造奖励，而本文旨在直接将语义特征嵌入状态表示中，减少昂贵的运行时推理，确保语义指导始终可用。

Method: 提出BLIP-FusePPO框架，将VLM生成的语义嵌入与几何状态、LiDAR观测和PID控制反馈在智能体观测空间中直接融合，使用包含语义对齐、车道保持精度、障碍物避免和速度调节的混合奖励函数。

Result: 仿真结果表明，该模型在多种困难驾驶场景下，比最佳基于视觉和多模态强化学习基线在车道保持稳定性和适应性方面表现更好。

Conclusion: 该方法通过融合语义、几何和控制感知表示，使策略学习更加鲁棒，提高了学习效率和泛化能力。

Abstract: In this paper, we propose Bootstrapped Language-Image Pretraining-driven
Fused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a
novel multimodal reinforcement learning (RL) framework for autonomous
lane-keeping (LK), in which semantic embeddings generated by a vision-language
model (VLM) are directly fused with geometric states, LiDAR observations, and
Proportional-Integral-Derivative-based (PID) control feedback within the agent
observation space. The proposed method lets the agent learn driving rules that
are aware of their surroundings and easy to understand by combining high-level
scene understanding from the VLM with low-level control and spatial signals.
Our architecture brings together semantic, geometric, and control-aware
representations to make policy learning more robust. A hybrid reward function
that includes semantic alignment, LK accuracy, obstacle avoidance, and speed
regulation helps learning to be more efficient and generalizable. Our method is
different from the approaches that only use semantic models to shape rewards.
Instead, it directly embeds semantic features into the state representation.
This cuts down on expensive runtime inference and makes sure that semantic
guidance is always available. The simulation results show that the proposed
model is better at LK stability and adaptability than the best vision-based and
multimodal RL baselines in a wide range of difficult driving situations. We
make our code publicly available.

</details>


### [28] [A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems](https://arxiv.org/abs/2510.22420)
*Mohammad Ali Labbaf Khaniki,Fateme Taroodi,Benyamin Safizadeh*

Main category: cs.RO

TL;DR: 提出了MTLHRL框架，通过分层策略和Lyapunov约束解决高维随机系统的控制问题，在超混沌系统和机器人控制中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决高维随机系统控制中的维度灾难、缺乏时间抽象和随机稳定性保证不足的问题。

Method: 结合分层策略（高层策略用于战略规划，低层策略用于反应控制）和神经Lyapunov函数，通过拉格朗日松弛和多时间尺度actor-critic更新确保稳定性。

Result: 在8D超混沌系统和5-DOF机器人操作器上的仿真显示，MTLHRL在稳定性和性能上显著优于基线方法，获得最低误差指数（IAE：3.912和1.623），收敛更快且具有优越的抗干扰能力。

Conclusion: MTLHRL为复杂随机系统的鲁棒控制提供了理论可靠且实际可行的解决方案。

Abstract: Controlling high-dimensional stochastic systems, critical in robotics,
autonomous vehicles, and hyperchaotic systems, faces the curse of
dimensionality, lacks temporal abstraction, and often fails to ensure
stochastic stability. To overcome these limitations, this study introduces the
Multi-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning
(MTLHRL) framework. MTLHRL integrates a hierarchical policy within a
semi-Markov Decision Process (SMDP), featuring a high-level policy for
strategic planning and a low-level policy for reactive control, which
effectively manages complex, multi-timescale decision-making and reduces
dimensionality overhead. Stability is rigorously enforced using a neural
Lyapunov function optimized via Lagrangian relaxation and multi-timescale
actor-critic updates, ensuring mean-square boundedness or asymptotic stability
in the face of stochastic dynamics. The framework promotes efficient and
reliable learning through trust-region constraints and decoupled optimization.
Extensive simulations on an 8D hyperchaotic system and a 5-DOF robotic
manipulator demonstrate MTLHRL's empirical superiority. It significantly
outperforms baseline methods in both stability and performance, recording the
lowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in
hyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence,
and exhibiting superior disturbance rejection. MTLHRL offers a theoretically
grounded and practically viable solution for robust control of complex
stochastic systems.

</details>


### [29] [A short methodological review on social robot navigation benchmarking](https://arxiv.org/abs/2510.22448)
*Pranup Chhetri,Alejandro Torrejon,Sergio Eslava,Luis J. Manso*

Main category: cs.RO

TL;DR: 该论文回顾了2020年1月至2025年7月期间社交机器人导航领域的基准测试趋势，分析了85篇相关论文，重点关注基准测试指标、算法、人类调查使用以及结论推导方式。


<details>
  <summary>Details</summary>
Motivation: 社交机器人导航领域缺乏统一的基准测试标准，这阻碍了该领域的发展并可能导致相互矛盾的结论。

Method: 通过IEEE Xplore搜索识别了130篇论文，最终分析了符合标准的85篇论文，系统回顾了基准测试的指标、算法、人类调查使用和结论推导方式。

Result: 识别了社交机器人导航基准测试中使用的各种指标、算法，以及人类调查在基准测试中的应用情况。

Conclusion: 社交机器人导航领域需要建立统一的基准测试标准，以促进该领域的健康发展。

Abstract: Social Robot Navigation is the skill that allows robots to move efficiently
in human-populated environments while ensuring safety, comfort, and trust.
Unlike other areas of research, the scientific community has not yet achieved
an agreement on how Social Robot Navigation should be benchmarked. This is
notably important, as the lack of a de facto standard to benchmark Social Robot
Navigation can hinder the progress of the field and may lead to contradicting
conclusions. Motivated by this gap, we contribute with a short review focused
exclusively on benchmarking trends in the period from January 2020 to July
2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed
the 85 papers that met the criteria of the review. This review addresses the
metrics used in the literature for benchmarking purposes, the algorithms
employed in such benchmarks, the use of human surveys for benchmarking, and how
conclusions are drawn from the benchmarking results, when applicable.

</details>


### [30] [Forward Kinematics Solution For A General Stewart Platform Through Iteration Based Simulation](https://arxiv.org/abs/2510.22465)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出了一种为通用Stewart平台生成可行、唯一正向运动学解的方法，使用逆运动学获取有效工作空间数据，通过改进的Denavit-Hartenberg约定和迭代算法获得单一可行解。


<details>
  <summary>Details</summary>
Motivation: Stewart平台等并联运动机构的正向运动学复杂且会产生多个解，需要手动验证，这限制了其在六自由度材料测试系统中的应用。

Method: 使用逆运动学获取有效工作空间数据和对应的执行器长度，采用改进的Denavit-Hartenberg约定和简单迭代算法。

Result: 该方法为每个有效位姿生成单一可行的正向运动学解，无需手动验证，可直接用于进一步计算。

Conclusion: 该方法解决了Stewart平台正向运动学多解问题，为六自由度材料测试系统提供了可靠的解决方案，能够实现高精度力控制。

Abstract: This paper presents a method to generate feasible, unique forward-kinematic
solutions for a general Stewart platform. This is done by using inverse
kinematics to obtain valid workspace data and corresponding actuator lengths
for the moving platform. For parallel kinematic machines, such as the Stewart
Platform, inverse kinematics are straight forward, but the forward kinematics
are complex and generates multiple solutions due to the closed loop structure
of the kinematic links. In this research, a simple iterative algorithm has been
used employing modified Denavit-Hartenberg convention. The outcome is
encouraging as this method generates a single feasible forward kinematic
solution for each valid pose with the solved DH parameters and unlike earlier
forward kinematics solutions, this unique solution does not need to be manually
verified. Therefore, the forward kinematic solutions can be used directly for
further calculations without the need for manual pose verification. This
capability is essential for the six degree of freedom materials testing system
developed by the authors in their laboratory. The developed system is aimed at
characterizing additively manufactured materials under complex combined
multiple loading conditions. The material characterization is done by enabling
high precision force control on the moving platform via in situ calibration of
the as-built kinematics of the Stewart Gough Platform.

</details>


### [31] [On Steerability Factors for Growing Vine Robots](https://arxiv.org/abs/2510.22504)
*Ciera McFarland,Antonio Alvarez,Sarah Taher,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: 该研究探讨了藤蔓机器人的转向性能如何受尖端负载、压力、长度、直径和制造方法的影响，发现转向性能随尖端负载增加而降低，在中等腔压时最佳，随长度增加而提高，且基本不受直径影响。


<details>
  <summary>Details</summary>
Motivation: 藤蔓机器人具有在复杂环境中导航的潜力，但其性能受到附加传感器/工具重量以及其他设计和控制选择的限制，需要研究影响其转向性能的关键因素。

Method: 进行两组实验：研究在重力支撑下的尖端负载、腔压、长度和直径的影响；研究在地面支撑下的制造方法和执行器与腔压比例的影响。

Result: 外部附着执行器的机器人在低压比时开始弯曲，但高压力比时曲率饱和；集成执行器的机器人需要更高压力比开始弯曲但总体曲率更高。优化参数的机器人在移动任务中表现优于临时参数。

Conclusion: 通过系统研究确定了影响藤蔓机器人转向性能的关键设计参数，为优化机器人性能提供了指导原则。

Abstract: Vine robots extend their tubular bodies by everting material from the tip,
enabling navigation in complex environments with a minimalist soft body.
Despite their promise for field applications, especially in the urban search
and rescue domain, performance is constrained by the weight of attached sensors
or tools, as well as other design and control choices. This work investigates
how tip load, pressure, length, diameter, and fabrication method shape vine
robot steerability--the ability to maneuver with controlled curvature--for
robots that steer with series pouch motor-style pneumatic actuators. We conduct
two groups of experiments: (1) studying tip load, chamber pressure, length, and
diameter in a robot supporting itself against gravity, and (2) studying
fabrication method and ratio of actuator to chamber pressure in a robot
supported on the ground. Results show that steerability decreases with
increasing tip load, is best at moderate chamber pressure, increases with
length, and is largely unaffected by diameter. Robots with actuators attached
on their exterior begin curving at low pressure ratios, but curvature saturates
at high pressure ratios; those with actuators integrated into the robot body
require higher pressure ratios to begin curving but achieve higher curvature
overall. We demonstrate that robots optimized with these principles outperform
those with ad hoc parameters in a mobility task that involves maximizing upward
and horizontal curvatures.

</details>


### [32] [Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines](https://arxiv.org/abs/2510.22524)
*Shenbagaraj Kannapiran,Elena Oikonomou,Albert Chu,Spring Berman,Theodore P. Pavlic*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In natural systems, emergent structures often arise to balance competing
demands. Army ants, for example, form temporary "walls" that prevent
interference between foraging trails. Inspired by this behavior, we developed
two decentralized controllers for heterogeneous robotic swarms to maintain
spatial separation while executing concurrent tasks. The first is a
finite-state machine (FSM)-based controller that uses encounter-triggered
transitions to create rigid, stable walls. The second integrates FSM states
with a Deep Q-Network (DQN), dynamically optimizing separation through emergent
"demilitarized zones." In simulation, both controllers reduce mixing between
subgroups, with the DQN-enhanced controller improving adaptability and reducing
mixing by 40-50% while achieving faster convergence.

</details>


### [33] [SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions](https://arxiv.org/abs/2510.22568)
*Onur Akgün*

Main category: cs.RO

TL;DR: SPIRAL是一种用于训练自主无人机在多智能体竞赛中的自博弈增量学习算法，通过自博弈机制逐步培养复杂的竞赛行为。


<details>
  <summary>Details</summary>
Motivation: 为了解决自主无人机在多智能体竞赛环境中需要从基础飞行控制到复杂协作策略的渐进学习问题，开发一个能够自主生成适当挑战的自适应学习框架。

Method: 采用自博弈机制，让无人机与越来越强的自身版本竞争，逐步提升竞赛难度。该方法设计灵活，可与任何先进的深度强化学习算法集成。

Result: 仿真实验证明了SPIRAL的显著优势，并对各种深度强化学习算法在其框架内的性能进行了基准测试。

Conclusion: SPIRAL为自主无人机竞赛领域提供了一个通用、可扩展且自我改进的学习框架，其通过自博弈动态自主生成适当和升级挑战的能力，为在多智能体环境中开发鲁棒和自适应竞赛策略提供了有前景的方向。

Abstract: This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for
Learning), a novel approach for training autonomous drones in multi-agent
racing competitions. SPIRAL distinctively employs a self-play mechanism to
incrementally cultivate complex racing behaviors within a challenging, dynamic
environment. Through this self-play core, drones continuously compete against
increasingly proficient versions of themselves, naturally escalating the
difficulty of competitive interactions. This progressive learning journey
guides agents from mastering fundamental flight control to executing
sophisticated cooperative multi-drone racing strategies. Our method is designed
for versatility, allowing integration with any state-of-the-art Deep
Reinforcement Learning (DRL) algorithms within its self-play framework.
Simulations demonstrate the significant advantages of SPIRAL and benchmark the
performance of various DRL algorithms operating within it. Consequently, we
contribute a versatile, scalable, and self-improving learning framework to the
field of autonomous drone racing. SPIRAL's capacity to autonomously generate
appropriate and escalating challenges through its self-play dynamic offers a
promising direction for developing robust and adaptive racing strategies in
multi-agent environments. This research opens new avenues for enhancing the
performance and reliability of autonomous racing drones in increasingly complex
and competitive scenarios.

</details>


### [34] [Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing](https://arxiv.org/abs/2510.22570)
*Onur Akgün*

Main category: cs.RO

TL;DR: CRUISE是一个基于课程学习和自我博弈的强化学习框架，用于解决多无人机竞速中的可扩展性问题，在仿真中显著优于基准方法和最先进的博弈论规划器。


<details>
  <summary>Details</summary>
Motivation: 解决多自主智能体在高速竞争环境中的协调问题，特别是在多无人机竞速这一具有挑战性的领域中，克服现有方法的可扩展性限制。

Method: 结合渐进难度课程学习和高效自我博弈机制，通过强化学习训练策略，在具有真实四旋翼动力学的高保真仿真中进行验证。

Result: CRUISE策略显著优于标准强化学习基线和最先进的博弈论规划器，平均竞速速度接近规划器的两倍，保持高成功率，且随着智能体密度增加展现出稳健的可扩展性。

Conclusion: 课程结构是实现性能飞跃的关键组件，CRUISE为动态竞争任务中的自主系统开发提供了可扩展且有效的训练方法，可作为未来实际部署的蓝图。

Abstract: The coordination of multiple autonomous agents in high-speed, competitive
environments represents a significant engineering challenge. This paper
presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone
Racing), a reinforcement learning framework designed to solve this challenge in
the demanding domain of multi-drone racing. CRUISE overcomes key scalability
limitations by synergistically combining a progressive difficulty curriculum
with an efficient self-play mechanism to foster robust competitive behaviors.
Validated in high-fidelity simulation with realistic quadrotor dynamics, the
resulting policies significantly outperform both a standard reinforcement
learning baseline and a state-of-the-art game-theoretic planner. CRUISE
achieves nearly double the planner's mean racing speed, maintains high success
rates, and demonstrates robust scalability as agent density increases. Ablation
studies confirm that the curriculum structure is the critical component for
this performance leap. By providing a scalable and effective training
methodology, CRUISE advances the development of autonomous systems for dynamic,
competitive tasks and serves as a blueprint for future real-world deployment.

</details>


### [35] [RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience](https://arxiv.org/abs/2510.22600)
*Huilin Yin,Zhaolin Yang,Linchuan Zhang,Gerhard Rigoll,Johannes Betz*

Main category: cs.RO

TL;DR: RoGER-SLAM是一种针对噪声和低光照环境设计的鲁棒3D高斯溅射SLAM系统，通过结构保持融合、自适应跟踪和CLIP增强模块，在恶劣成像条件下显著提升轨迹精度和重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统3DGS SLAM系统在视觉输入存在噪声和低光照的复合退化环境下表现脆弱，原始3DGS渲染管道作为隐式低通滤波器会过度平滑细节，需要专门设计来应对这些挑战。

Method: 1) 结构保持鲁棒融合机制，耦合渲染外观、深度和边缘线索；2) 带残差平衡正则化的自适应跟踪目标；3) CLIP增强模块，在复合退化条件下选择性激活以恢复语义和结构保真度。

Result: 在Replica、TUM和真实世界序列上的综合实验表明，RoGER-SLAM相比其他3DGS-SLAM系统，在恶劣成像条件下持续提高了轨迹精度和重建质量。

Conclusion: RoGER-SLAM通过创新的融合机制和增强模块，有效解决了3DGS SLAM在噪声和低光照环境中的脆弱性问题，为恶劣条件下的鲁棒SLAM提供了有效解决方案。

Abstract: The reliability of Simultaneous Localization and Mapping (SLAM) is severely
constrained in environments where visual inputs suffer from noise and low
illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM
frameworks achieve high-fidelity mapping under clean conditions, they remain
vulnerable to compounded degradations that degrade mapping and tracking
performance. A key observation underlying our work is that the original 3DGS
rendering pipeline inherently behaves as an implicit low-pass filter,
attenuating high-frequency noise but also risking over-smoothing. Building on
this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for
noise and low-light resilience. The framework integrates three innovations: a
Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples
rendered appearance, depth, and edge cues; an adaptive tracking objective with
residual balancing regularization; and a Contrastive Language-Image Pretraining
(CLIP)-based enhancement module, selectively activated under compounded
degradations to restore semantic and structural fidelity. Comprehensive
experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM
consistently improves trajectory accuracy and reconstruction quality compared
with other 3DGS-SLAM systems, especially under adverse imaging conditions.

</details>


### [36] [Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead](https://arxiv.org/abs/2510.22680)
*Shireen Kudukkil Manchingal,Armand Amaritei,Mihir Gohad,Maryam Sultana,Julian F. P. Kooij,Fabio Cuzzolin,Andrew Bradley*

Main category: cs.RO

TL;DR: 该研究将随机集神经网络集成到自动驾驶系统中，通过显式量化预测不确定性来提高安全性，在不确定场景下动态调节车速。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知系统在面对罕见事件或样本外数据时容易产生过度自信的预测错误，需要让车辆能够识别自身的不确定性。

Method: 使用随机集神经网络作为不确定性感知图像分类器，预测类别集的置信函数，并将其集成到基于ROS的自动驾驶赛车软件栈中。

Result: 与传统CNN和贝叶斯神经网络相比，RS-NN实现了显著更高的准确率和更优的不确定性校准，能够动态调节车速以平衡性能与安全。

Conclusion: 不确定性感知神经网络，特别是RS-NN，是实现更安全、更鲁棒自动驾驶的实用解决方案。

Abstract: Autonomous Vehicle (AV) perception systems have advanced rapidly in recent
years, providing vehicles with the ability to accurately interpret their
environment. Perception systems remain susceptible to errors caused by
overly-confident predictions in the case of rare events or out-of-sample data.
This study equips an autonomous vehicle with the ability to 'know when it is
uncertain', using an uncertainty-aware image classifier as part of the AV
software stack. Specifically, the study exploits the ability of Random-Set
Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike
traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets
of classes, allowing the system to identify and signal uncertainty clearly in
novel or ambiguous scenarios. The system is tested in a real-world autonomous
racing vehicle software stack, with the RS-NN classifying the layout of the
road ahead and providing the associated uncertainty of the prediction.
Performance of the RS-NN under a range of road conditions is compared against
traditional CNN and Bayesian neural networks, with the RS-NN achieving
significantly higher accuracy and superior uncertainty calibration. This
integration of RS-NNs into Robot Operating System (ROS)-based vehicle control
pipeline demonstrates that predictive uncertainty can dynamically modulate
vehicle speed, maintaining high-speed performance under confident predictions
while proactively improving safety through speed reductions in uncertain
scenarios. These results demonstrate the potential of uncertainty-aware neural
networks - in particular RS-NNs - as a practical solution for safer and more
robust autonomous driving.

</details>


### [37] [RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets](https://arxiv.org/abs/2510.22699)
*Matteo El-Hariry,Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: RL-AVIST是一个基于强化学习的自主空间目标视觉检查框架，使用DreamerV3等算法在6-DOF航天器动力学模拟中训练智能体，实现3D近距离机动任务。


<details>
  <summary>Details</summary>
Motivation: 传统控制系统在模型不确定性、多航天器配置或动态任务环境下适应性不足，需要智能航天器来支持在轨自主服务。

Method: 利用Space Robotics Bench模拟高保真6-DOF航天器动力学，使用DreamerV3模型强化学习算法，以PPO和TD3作为无模型基准，训练通用和专用智能体。

Result: 基于模型的强化学习在轨迹保真度和样本效率方面表现出色，能够适应多种航天器形态和任务领域。

Conclusion: 基于模型的强化学习为未来空间操作提供了可扩展、可重训练的控制解决方案。

Abstract: The growing need for autonomous on-orbit services such as inspection,
maintenance, and situational awareness calls for intelligent spacecraft capable
of complex maneuvers around large orbital targets. Traditional control systems
often fall short in adaptability, especially under model uncertainties,
multi-spacecraft configurations, or dynamically evolving mission contexts. This
paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous
Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB),
we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using
DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as
model-free baselines. Our investigation focuses on 3D proximity maneuvering
tasks around targets such as the Lunar Gateway and other space assets. We
evaluate task performance under two complementary regimes: generalized agents
trained on randomized velocity vectors, and specialized agents trained to
follow fixed trajectories emulating known inspection orbits. Furthermore, we
assess the robustness and generalization of policies across multiple spacecraft
morphologies and mission domains. Results demonstrate that model-based RL
offers promising capabilities in trajectory fidelity, and sample efficiency,
paving the way for scalable, retrainable control solutions for future space
operations

</details>


### [38] [SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping](https://arxiv.org/abs/2510.22738)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 提出了两种基于槽约束自适应连杆(SCAL)的环境自适应夹持手指：SCAL-R（旋转驱动）和SCAL-L（线性驱动），能够在最小传感和控制下实现薄型或低轮廓物体的稳定夹持和提升。


<details>
  <summary>Details</summary>
Motivation: 解决传统夹持器在夹持薄型、低轮廓或弱特征物体时的困难，实现环境自适应夹持，减少对复杂传感和控制的需求。

Method: 开发了两种SCAL手指：SCAL-R通过旋转驱动和主动指尖折叠形成包络；SCAL-L通过线性驱动和被动张开跨越宽或弱特征物体。两种设计都将表面跟随转换为向上提升分支，同时保持指尖方向。

Result: 通过PLA 3D打印制造双指夹持器，在数十次试验中对小零件、盒子、罐子和胶带卷等物体实现了一致的夹持效果，两种设计在不同操作场景下表现出互补性能。

Conclusion: SCAL-R和SCAL-L提供了互补的操作机制，为使用简单驱动实现稳健的环境自适应夹持提供了实用路径，准静态分析为设计和操作提供了几何感知指导。

Abstract: This paper presents environment-adaptive pinch-lifting built on a
slot-constrained adaptive linkage (SCAL) and instantiated in two complementary
fingers: SCAL-R, a rotational-drive design with an active fingertip that folds
inward after contact to form an envelope, and SCAL-L, a linear-drive design
that passively opens on contact to span wide or weak-feature objects. Both
fingers convert surface following into an upward lifting branch while
maintaining fingertip orientation, enabling thin or low-profile targets to be
raised from supports with minimal sensing and control. Two-finger grippers are
fabricated via PLA-based 3D printing. Experiments evaluate (i)
contact-preserving sliding and pinch-lifting on tabletops, (ii) ramp
negotiation followed by lift, and (iii) handling of bulky objects via active
enveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across
dozens of trials on small parts, boxes, jars, and tape rolls, both designs
achieve consistent grasps with limited tuning. A quasi-static analysis provides
closed-form fingertip-force models for linear parallel pinching and two-point
enveloping, offering geometry-aware guidance for design and operation. Overall,
the results indicate complementary operating regimes and a practical path to
robust, environment-adaptive grasping with simple actuation.

</details>


### [39] [Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM](https://arxiv.org/abs/2510.22740)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出了一种基于多智能体强化学习(MARL)的分布式位姿图优化(PGO)框架，通过将PGO建模为部分可观测马尔可夫博弈，使用图神经网络编码器和混合策略来优化位姿估计，显著提升了优化效果和推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统的分布式PGO方法通过线性化高度非凸的优化目标，需要重复求解正规方程，容易陷入局部最小值并产生次优估计。需要一种更鲁棒、可扩展的解决方案。

Method: 将分布式PGO建模为部分可观测马尔可夫博弈，使用图分割器分解全局位姿图，每个机器人运行带自适应边门控的循环图神经网络编码器来去噪边。通过混合策略利用先验动作记忆和图嵌入来顺序优化位姿，最后通过共识方案协调机器人间差异。

Result: 在综合合成和真实数据集上的评估表明，学习的MARL智能体比最先进的分布式PGO框架平均减少37.5%的全局目标，同时推理效率提升至少6倍。智能体复制允许单一学习策略无需重新训练即可扩展到更大机器人团队。

Conclusion: 基于MARL的分布式PGO框架在优化效果和效率方面都显著优于传统方法，具有良好的可扩展性和鲁棒性，为多机器人SLAM中的轨迹估计提供了有效解决方案。

Abstract: We consider the distributed pose-graph optimization (PGO) problem, which is
fundamental in accurate trajectory estimation in multi-robot simultaneous
localization and mapping (SLAM). Conventional iterative approaches linearize a
highly non-convex optimization objective, requiring repeated solving of normal
equations, which often converge to local minima and thus produce suboptimal
estimates. We propose a scalable, outlier-robust distributed planar PGO
framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed
PGO as a partially observable Markov game defined on local pose-graphs, where
each action refines a single edge's pose estimate. A graph partitioner
decomposes the global pose graph, and each robot runs a recurrent
edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating
to denoise noisy edges. Robots sequentially refine poses through a hybrid
policy that utilizes prior action memory and graph embeddings. After local
graph correction, a consensus scheme reconciles inter-robot disagreements to
produce a globally consistent estimate. Our extensive evaluations on a
comprehensive suite of synthetic and real-world datasets demonstrate that our
learned MARL-based actors reduce the global objective by an average of 37.5%
more than the state-of-the-art distributed PGO framework, while enhancing
inference efficiency by at least 6X. We also demonstrate that actor replication
allows a single learned policy to scale effortlessly to substantially larger
robot teams without any retraining. Code is publicly available at
https://github.com/herolab-uga/policies-over-poses.

</details>


### [40] [TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments](https://arxiv.org/abs/2510.22754)
*Chunyu Li,Shoubin Chen,Dong Li,Weixing Xue,Qingquan Li*

Main category: cs.RO

TL;DR: TWC-SLAM是一个多智能体协同SLAM框架，通过集成文本语义和WiFi信号特征来提升在重复结构室内环境中的位置识别和闭环检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协同SLAM在相似室内环境（如走廊和房间）中由于重复结构导致的共享位置识别不准确问题。

Method: 基于FAST-LIO2的单智能体前端里程计模块，结合文本语义和WiFi特征的位置识别与闭环检测模块，以及全局建图模块。通过文本信息和WiFi信号关联建立共同位置。

Result: 在具有相似走廊、房间和文本标志的室内数据集上评估，TWC-SLAM显著提升了在复杂重复结构环境中的协同SLAM系统性能。

Conclusion: TWC-SLAM通过融合文本语义和WiFi信号特征，有效解决了重复结构环境中的位置识别挑战，提高了多智能体协同SLAM的准确性和鲁棒性。

Abstract: Multi-agent cooperative SLAM often encounters challenges in similar indoor
environments characterized by repetitive structures, such as corridors and
rooms. These challenges can lead to significant inaccuracies in shared location
identification when employing point cloud-based techniques. To mitigate these
issues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that
integrates text semantics and WiFi signal features to enhance location
identification and loop closure detection. TWC-SLAM comprises a single-agent
front-end odometry module based on FAST-LIO2, a location identification and
loop closure detection module that leverages text semantics and WiFi features,
and a global mapping module. The agents are equipped with sensors capable of
capturing textual information and detecting WiFi signals. By correlating these
data sources, TWC-SLAM establishes a common location, facilitating point cloud
alignment across different agents' maps. Furthermore, the system employs loop
closure detection and optimization modules to achieve global optimization and
cohesive mapping. We evaluated our approach using an indoor dataset featuring
similar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM
significantly improves the performance of cooperative SLAM systems in complex
environments with repetitive architectural features.

</details>


### [41] [PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language](https://arxiv.org/abs/2510.22784)
*Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: PIP-LLM是一个基于语言的多机器人协调框架，通过PDDL团队级规划和整数规划机器人级规划的结合，解决了多机器人协调中的任务分解、可扩展性和协调效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多机器人协调时面临任务分解脆弱、可扩展性差和协调效率低的问题，需要一种更好的方法来执行自然语言命令。

Method: 首先将命令翻译为团队级PDDL问题并求解，获得团队级计划；然后将计划转换为依赖图；最后使用整数规划进行机器人级任务分配，优化旅行成本和工作负载。

Result: 实验显示PIP-LLM提高了计划成功率，减少了最大和平均旅行成本，并实现了更好的负载平衡。

Conclusion: PIP-LLM通过将规划与分配分离，避免了基于语法分解的缺陷，能够扩展到更大的团队，在多机器人协调方面表现出色。

Abstract: Enabling robot teams to execute natural language commands requires
translating high-level instructions into feasible, efficient multi-robot plans.
While Large Language Models (LLMs) combined with Planning Domain Description
Language (PDDL) offer promise for single-robot scenarios, existing approaches
struggle with multi-robot coordination due to brittle task decomposition, poor
scalability, and low coordination efficiency.
  We introduce PIP-LLM, a language-based coordination framework that consists
of PDDL-based team-level planning and Integer Programming (IP) based
robot-level planning. PIP-LLMs first decomposes the command by translating the
command into a team-level PDDL problem and solves it to obtain a team-level
plan, abstracting away robot assignment. Each team-level action represents a
subtask to be finished by the team. Next, this plan is translated into a
dependency graph representing the subtasks' dependency structure. Such a
dependency graph is then used to guide the robot-level planning, in which each
subtask node will be formulated as an IP-based task allocation problem,
explicitly optimizing travel costs and workload while respecting robot
capabilities and user-defined constraints. This separation of planning from
assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition
and scale to larger teams. Experiments across diverse tasks show that PIP-LLM
improves plan success rate, reduces maximum and average travel costs, and
achieves better load balancing compared to state-of-the-art baselines.

</details>


### [42] [Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning](https://arxiv.org/abs/2510.22789)
*Abhijeet M. Kulkarni,Ioannis Poulakakis,Guoquan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于学习的观测器-预测器框架，用于准确预测四足机器人的全身运动，解决了简化运动学模型无法捕捉复杂闭环动态的问题。


<details>
  <summary>Details</summary>
Motivation: 精确的全身运动预测对于足式机器人在复杂环境中的安全自主导航至关重要，但简化运动学模型无法准确捕捉机器人及其底层控制器的复杂闭环动态。

Method: 采用基于学习的观测器-预测器框架，包括具有可证明UUB保证的神经观测器，以及计算高效的预测器，用于快速并行评估数千条潜在轨迹。

Result: 在Vision 60四足机器人上集成神经预测器到MPPI规划器中，硬件实验成功展示了在狭窄通道和小障碍物环境中的有效肢体感知运动规划。

Conclusion: 该系统为动态机器人平台上的高性能碰撞感知规划提供了稳健基础，能够实现复杂的肢体级碰撞检查。

Abstract: Accurate full-body motion prediction is essential for the safe, autonomous
navigation of legged robots, enabling critical capabilities like limb-level
collision checking in cluttered environments. Simplified kinematic models often
fail to capture the complex, closed-loop dynamics of the robot and its
low-level controller, limiting their predictions to simple planar motion. To
address this, we present a learning-based observer-predictor framework that
accurately predicts this motion. Our method features a neural observer with
provable UUB guarantees that provides a reliable latent state estimate from a
history of proprioceptive measurements. This stable estimate initializes a
computationally efficient predictor, designed for the rapid, parallel
evaluation of thousands of potential trajectories required by modern
sampling-based planners. We validated the system by integrating our neural
predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware
experiments successfully demonstrated effective, limb-aware motion planning in
a challenging, narrow passage and over small objects, highlighting our system's
ability to provide a robust foundation for high-performance, collision-aware
planning on dynamic robotic platforms.

</details>


### [43] [Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors](https://arxiv.org/abs/2510.22821)
*Ricardo Vega,Connor Mattson,Kevin Zhu,Daniel S. Brown,Cameron Nowzari*

Main category: cs.RO

TL;DR: 提出了Analytical Swarm Chemistry框架，将工程学、基于代理的研究和人工生命概念与化学原理结合，通过宏观状态定义和相图分析来系统探索群体参数如何影响涌现行为。


<details>
  <summary>Details</summary>
Motivation: 群体机器人技术具有广泛应用潜力，但由于难以预测简单局部交互产生的涌现行为，实际部署仍然稀少。传统工程方法在理想条件下设计控制器，而基于代理的研究则以自下而上的方式探索涌现现象。

Method: 结合宏观状态定义与相图分析，将参数视为热力学变量，可视化参数空间中产生特定行为的区域。应用于具有最小可行能力的代理，识别产生特定行为（如旋转和扩散）的充分条件。

Result: 识别了产生旋转和扩散等行为的充分条件，发现了参数空间中可靠产生这些行为的区域。在真实机器人上的初步验证表明这些区域在实践中对应可观察的行为。

Conclusion: 该框架为现实世界群体系统中可预测和可靠的涌现行为奠定了基础，提供了一种原则性、可解释的方法。

Abstract: Swarm robotics has potential for a wide variety of applications, but
real-world deployments remain rare due to the difficulty of predicting emergent
behaviors arising from simple local interactions. Traditional engineering
approaches design controllers to achieve desired macroscopic outcomes under
idealized conditions, while agent-based and artificial life studies explore
emergent phenomena in a bottom-up, exploratory manner. In this work, we
introduce Analytical Swarm Chemistry, a framework that integrates concepts from
engineering, agent-based and artificial life research, and chemistry. This
framework combines macrostate definitions with phase diagram analysis to
systematically explore how swarm parameters influence emergent behavior.
Inspired by concepts from chemistry, the framework treats parameters like
thermodynamic variables, enabling visualization of regions in parameter space
that give rise to specific behaviors. Applying this framework to agents with
minimally viable capabilities, we identify sufficient conditions for behaviors
such as milling and diffusion and uncover regions of the parameter space that
reliably produce these behaviors. Preliminary validation on real robots
demonstrates that these regions correspond to observable behaviors in practice.
By providing a principled, interpretable approach, this framework lays the
groundwork for predictable and reliable emergent behavior in real-world swarm
systems.

</details>


### [44] [Kinematically Controllable Cable Robots with Reconfigurable End-effectors](https://arxiv.org/abs/2510.22825)
*Nan Zhang*

Main category: cs.RO

TL;DR: 设计可重构末端执行器以解决缆绳驱动机器人旋转工作空间受限和张力解非唯一的问题，通过弹簧-螺旋轴机构将线性运动转换为旋转运动，并引入轴承消除冗余度。


<details>
  <summary>Details</summary>
Motivation: 增加缆绳数量虽然能扩大平移工作空间，但会导致缆绳干涉减少旋转工作空间，且张力解非唯一给运动控制带来困难。

Method: 使用弹簧、螺旋槽轴和匹配螺母的可重构末端执行器，将组件间的相对线性运动转换为相对旋转运动，并引入轴承提供额外旋转自由度。

Result: 扩展了机构的旋转工作空间，使机构非冗余，机器人运动可通过纯运动学控制而无需额外的张力传感和控制。

Conclusion: 所设计的可重构末端执行器有效解决了缆绳机器人的工作空间和运动控制问题，实现了纯运动学控制。

Abstract: To enlarge the translational workspace of cable-driven robots, one common
approach is to increase the number of cables. However, this introduces two
challenges: (1) cable interference significantly reduces the rotational
workspace, and (2) the solution of tensions in cables becomes non-unique,
resulting in difficulties for kinematic control of the robot. In this work, we
design structurally simple reconfigurable end-effectors for cable robots. By
incorporating a spring, a helical-grooved shaft, and a matching nut, relative
linear motions between end-effector components are converted into relative
rotations, thereby expanding the rotational workspace of the mechanism.
Meanwhile, a bearing is introduced to provide an additional rotational degree
of freedom, making the mechanism non-redundant. As a result, the robot's motion
can be controlled purely through kinematics without additional tension sensing
and control.

</details>


### [45] [Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning](https://arxiv.org/abs/2510.22892)
*Jingzehua Xu,Yangyang Li,Yangfei Chen,Guanwen Xie,Shuai Zhang*

Main category: cs.RO

TL;DR: 提出自适应虚拟模型控制方法，结合大语言模型和Lyapunov强化学习，在保持物理可解释性的同时实现稳定性保证的在线适应


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制方法在不确定环境中变得僵化和脆弱，虚拟模型控制虽然能实现柔顺行为，但依赖固定参数且虚拟组件间协调有限，限制了适应性和稳定性

Method: 结合大语言模型提供结构化先验和高层推理来增强虚拟组件协调，同时使用Lyapunov强化学习强制执行理论稳定性约束

Result: 在7自由度Panda机械臂上的大量仿真表明，该方法在动态任务中有效平衡竞争目标，实现优越性能

Conclusion: 该方法展示了LLM引导和Lyapunov约束适应的协同优势，为不确定环境中的机器人控制提供了稳定可靠的自适应解决方案

Abstract: Robotic arms are increasingly deployed in uncertain environments, yet
conventional control pipelines often become rigid and brittle when exposed to
perturbations or incomplete information. Virtual Model Control (VMC) enables
compliant behaviors by embedding virtual forces and mapping them into joint
torques, but its reliance on fixed parameters and limited coordination among
virtual components constrains adaptability and may undermine stability as task
objectives evolve. To address these limitations, we propose Adaptive VMC with
Large Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL),
which preserves the physical interpretability of VMC while supporting
stability-guaranteed online adaptation. The LLM provides structured priors and
high-level reasoning that enhance coordination among virtual components,
improve sample efficiency, and facilitate flexible adjustment to varying task
requirements. Complementarily, Lyapunov-based RL enforces theoretical stability
constraints, ensuring safe and reliable adaptation under uncertainty. Extensive
simulations on a 7-DoF Panda arm demonstrate that our approach effectively
balances competing objectives in dynamic tasks, achieving superior performance
while highlighting the synergistic benefits of LLM guidance and
Lyapunov-constrained adaptation.

</details>


### [46] [HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment](https://arxiv.org/abs/2510.22917)
*Zecheng Yin,Hao Zhao,Zhen Li*

Main category: cs.RO

TL;DR: 提出HyPerNav方法，利用视觉语言模型融合第一人称视角和俯视地图的混合感知能力，在未知环境中实现更有效的目标导向导航。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多只关注单一感知源，很少整合第一人称视角和俯视地图这两种互补的感知模式，而人类自然同时关注这两种信息。

Method: 利用视觉语言模型的强大推理和视觉语言理解能力，联合感知局部和全局信息，通过混合感知方法增强未知环境导航的有效性和智能性。

Result: 在大规模仿真评估和真实世界验证中，我们的方法相对于流行基线达到了最先进的性能，能够更有效地捕捉丰富线索并找到目标物体。

Conclusion: 混合感知方法通过同时利用第一人称视角观察和俯视地图的信息理解，显著提升了导航性能，消融研究进一步证明两种感知方式都对导航性能有贡献。

Abstract: Objective-oriented navigation(ObjNav) enables robot to navigate to target
object directly and autonomously in an unknown environment. Effective
perception in navigation in unknown environment is critical for autonomous
robots. While egocentric observations from RGB-D sensors provide abundant local
information, real-time top-down maps offer valuable global context for ObjNav.
Nevertheless, the majority of existing studies focus on a single source, seldom
integrating these two complementary perceptual modalities, despite the fact
that humans naturally attend to both. With the rapid advancement of
Vision-Language Models(VLMs), we propose Hybrid Perception Navigation
(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding
capabilities to jointly perceive both local and global information to enhance
the effectiveness and intelligence of navigation in unknown environments. In
both massive simulation evaluation and real-world validation, our methods
achieved state-of-the-art performance against popular baselines. Benefiting
from hybrid perception approach, our method captures richer cues and finds the
objects more effectively, by simultaneously leveraging information
understanding from egocentric observations and the top-down map. Our ablation
study further proved that either of the hybrid perception contributes to the
navigation performance.

</details>


### [47] [End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control](https://arxiv.org/abs/2510.22949)
*Benedictus C. G. Cinun,Tua A. Tamba,Immanuel R. Santjoko,Xiaofeng Wang,Michael A. Gunarso,Bin Hu*

Main category: cs.RO

TL;DR: 设计了一个低成本Stewart平台原型，集成了硬件、软件和控制算法，通过实验验证了其作为经济高效的研究和教育工具的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一个经济实惠但功能完整的六自由度Stewart平台，为研究和教育提供一个集成的硬件-软件测试平台，克服以往只关注建模或控制等孤立方面的局限性。

Method: 结合现成组件、3D打印和定制零件构建硬件平台；采用基于反馈线性化和LQR方案的鲁棒轨迹跟踪控制器；使用扩展卡尔曼滤波器融合IMU和执行器编码器数据进行状态估计；在统一框架下集成动态建模、数据采集和实时控制。

Result: 实验结果表明平台能够有效进行轨迹跟踪和实时状态估计，在静态和动态轨迹上均表现出良好性能。

Conclusion: 该低成本Stewart平台原型是一个经济高效且多功能的工具，适用于高级研究和教育应用，展示了完整的硬件-软件集成解决方案的可行性。

Abstract: This paper presents the complete design, control, and experimental validation
of a low-cost Stewart platform prototype developed as an affordable yet capable
robotic testbed for research and education. The platform combines off the shelf
components with 3D printed and custom fabricated parts to deliver full six
degrees of freedom motions using six linear actuators connecting a moving
platform to a fixed base. The system software integrates dynamic modeling, data
acquisition, and real time control within a unified framework. A robust
trajectory tracking controller based on feedback linearization, augmented with
an LQR scheme, compensates for the platform's nonlinear dynamics to achieve
precise motion control. In parallel, an Extended Kalman Filter fuses IMU and
actuator encoder feedback to provide accurate and reliable state estimation
under sensor noise and external disturbances. Unlike prior efforts that
emphasize only isolated aspects such as modeling or control, this work delivers
a complete hardware-software platform validated through both simulation and
experiments on static and dynamic trajectories. Results demonstrate effective
trajectory tracking and real-time state estimation, highlighting the platform's
potential as a cost effective and versatile tool for advanced research and
educational applications.

</details>


### [48] [An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control](https://arxiv.org/abs/2510.23003)
*ZhengKai Huang,YiKun Wang,ChenYu Hui,XiaoCheng*

Main category: cs.RO

TL;DR: 开发智能节水灌溉系统，集成计算机视觉、机器人控制和实时稳定技术，通过多传感器融合实现精准农业灌溉，在多种模拟农业环境中节水30-50%，用水效率超过92%。


<details>
  <summary>Details</summary>
Motivation: 解决精准农业中的水资源浪费和地形适应性差等关键挑战，提高灌溉效率和节水能力。

Method: 采用轻量级YOLO模型在嵌入式视觉处理器上实现实时植物容器检测，简化手眼标定算法确保精确定位，基于STM32主控芯片和惯性测量数据的主动调平系统实现坡度稳定。

Result: 植物容器检测准确率超过96%，末端执行器定位成功率超过90%，在10度坡度上响应时间1.8秒，相比传统漫灌节水30-50%，用水效率超过92%。

Conclusion: 该系统成功实现了高效节水的智能灌溉，在多种农业环境中表现出优越的性能和适应性。

Abstract: This paper introduces an intelligent water-saving irrigation system designed
to address critical challenges in precision agriculture, such as inefficient
water use and poor terrain adaptability. The system integrates advanced
computer vision, robotic control, and real-time stabilization technologies via
a multi-sensor fusion approach. A lightweight YOLO model, deployed on an
embedded vision processor (K210), enables real-time plant container detection
with over 96% accuracy under varying lighting conditions. A simplified hand-eye
calibration algorithm-designed for 'handheld camera' robot arm
configurations-ensures that the end effector can be precisely positioned, with
a success rate exceeding 90%. The active leveling system, driven by the
STM32F103ZET6 main control chip and JY901S inertial measurement data, can
stabilize the irrigation platform on slopes up to 10 degrees, with a response
time of 1.8 seconds. Experimental results across three simulated agricultural
environments (standard greenhouse, hilly terrain, complex lighting) demonstrate
a 30-50% reduction in water consumption compared to conventional flood
irrigation, with water use efficiency exceeding 92% in all test cases.

</details>


### [49] [ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation](https://arxiv.org/abs/2510.23016)
*Zhuo Li,Junjia Liu,Dianxi Li,Tao Teng,Miao Li,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 提出了ManiDP方法，通过提取双手机器人的可操作性特征并结合黎曼概率模型，在扩散策略中优化双臂配置以满足姿势相关的任务要求，显著提高了双手机器人操作的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了姿势相关任务特征的学习，而这些特征对于双手机器人适应特定力和速度要求至关重要。

Method: 从专家演示中提取双手机器人可操作性，使用黎曼概率模型编码姿势特征，并将其整合到条件扩散过程中指导生成任务兼容的双臂运动序列。

Result: 在六个真实世界双手机器人任务中，平均操作成功率提高了39.33%，任务兼容性提高了0.45。

Conclusion: 将姿势相关的机器人先验知识整合到双手机器人技能扩散中，能够实现类人的适应性和灵巧性。

Abstract: Recent work has demonstrated the potential of diffusion models in robot
bimanual skill learning. However, existing methods ignore the learning of
posture-dependent task features, which are crucial for adapting dual-arm
configurations to meet specific force and velocity requirements in dexterous
bimanual manipulation. To address this limitation, we propose
Manipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning
method that not only generates plausible bimanual trajectories, but also
optimizes dual-arm configurations to better satisfy posture-dependent task
requirements. ManiDP achieves this by extracting bimanual manipulability from
expert demonstrations and encoding the encapsulated posture features using
Riemannian-based probabilistic models. These encoded posture features are then
incorporated into a conditional diffusion process to guide the generation of
task-compatible bimanual motion sequences. We evaluate ManiDP on six real-world
bimanual tasks, where the experimental results demonstrate a 39.33$\%$ increase
in average manipulation success rate and a 0.45 improvement in task
compatibility compared to baseline methods. This work highlights the importance
of integrating posture-relevant robotic priors into bimanual skill diffusion to
enable human-like adaptability and dexterity.

</details>


### [50] [Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation](https://arxiv.org/abs/2510.23057)
*Oskar Natan,Jun Miura*

Main category: cs.RO

TL;DR: Seq-DeepIPC是一个用于腿式机器人导航的序列化端到端感知-控制模型，通过整合多模态感知（RGB-D+GNSS）与时间融合，在边缘设备上实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 将端到端导航从轮式机器人扩展到更通用、具有时间感知能力的腿式机器人系统，提升智能感知能力。

Method: 使用EfficientNet-B0编码器减少计算量；通过连续GNSS位置直接计算航向角，避免噪声IMU；联合预测语义分割和深度估计；在更大更多样化的数据集上训练。

Result: 序列输入改善了感知和控制性能，模型在机器人狗上验证有效，在开放区域GNSS航向估计稳健，在高层建筑附近可靠性较低。

Conclusion: Seq-DeepIPC在合理模型大小下取得竞争性或更好的结果，为腿式机器人导航提供了有效的端到端解决方案。

Abstract: We present Seq-DeepIPC, a sequential end-to-end perception-to-control model
for legged robot navigation in realworld environments. Seq-DeepIPC advances
intelligent sensing for autonomous legged navigation by tightly integrating
multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The
model jointly predicts semantic segmentation and depth estimation, giving
richer spatial features for planning and control. For efficient deployment on
edge devices, we use EfficientNet-B0 as the encoder, reducing computation while
maintaining accuracy. Heading estimation is simplified by removing the noisy
IMU and instead computing the bearing angle directly from consecutive GNSS
positions. We collected a larger and more diverse dataset that includes both
road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative
and ablation studies show that sequential inputs improve perception and control
in our models, while other baselines do not benefit. Seq-DeepIPC achieves
competitive or better results with reasonable model size; although GNSS-only
heading is less reliable near tall buildings, it is robust in open areas.
Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to
more versatile and temporally-aware systems. To support future research, we
will release the codes to our GitHub repository at
https://github.com/oskarnatan/Seq-DeepIPC.

</details>


### [51] [Awakening Facial Emotional Expressions in Human-Robot](https://arxiv.org/abs/2510.23059)
*Yongtong Zhu,Lei Li,Iggy Qian,WenBin Zhou,Ye Yuan,Qingdu Li,Na Liu,Jianwei Zhang*

Main category: cs.RO

TL;DR: 开发了基于KAN和注意力机制的端到端学习框架，使人形社交机器人能够通过自训练自主获取类人表情生成能力，实现了准确多样的面部模仿。


<details>
  <summary>Details</summary>
Motivation: 当前人形社交机器人的面部表情生成依赖预编程行为模式，人工编码成本高。为了实现自然的人机交互，需要让机器人具备自主学习和生成类人表情的能力。

Method: 设计高仿生机器人面部，开发基于KAN和注意力机制的端到端学习框架，并构建了首个开源的人形社交机器人面部数据集，采用基于面部运动基元的专家策略进行自动化数据收集。

Result: 综合评估表明，该方法在不同测试对象上实现了准确多样的面部模仿效果。

Conclusion: 该研究为人形社交机器人提供了自主获取表情生成能力的新途径，通过仿生设计和端到端学习框架实现了自然的表情模仿。

Abstract: The facial expression generation capability of humanoid social robots is
critical for achieving natural and human-like interactions, playing a vital
role in enhancing the fluidity of human-robot interactions and the accuracy of
emotional expression. Currently, facial expression generation in humanoid
social robots still relies on pre-programmed behavioral patterns, which are
manually coded at high human and time costs. To enable humanoid robots to
autonomously acquire generalized expressive capabilities, they need to develop
the ability to learn human-like expressions through self-training. To address
this challenge, we have designed a highly biomimetic robotic face with
physical-electronic animated facial units and developed an end-to-end learning
framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.
Unlike previous humanoid social robots, we have also meticulously designed an
automated data collection system based on expert strategies of facial motion
primitives to construct the dataset. Notably, to the best of our knowledge,
this is the first open-source facial dataset for humanoid social robots.
Comprehensive evaluations indicate that our approach achieves accurate and
diverse facial mimicry across different test subjects.

</details>


### [52] [Breaking the Circle: An Autonomous Control-Switching Strategy for Stable Orographic Soaring in MAVs](https://arxiv.org/abs/2510.23084)
*Sunyou Hwang,Christophe De Wagter,Bart Remes,Guido de Croon*

Main category: cs.RO

TL;DR: 提出SAOS控制切换方法，通过选择性控制水平或垂直轴来减轻滑翔中的盘旋行为，将系统从欠驱动转变为全驱动，提高能量效率和飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 地形滑翔可显著延长微型飞行器续航时间，但盘旋行为会增加能耗和发散风险，需要解决控制冲突问题。

Method: 采用控制切换方法SAOS，选择性控制水平或垂直轴，并在INDI控制器中加入攻角以改进力估计。

Result: 仿真和风洞实验表明，SAOS改善了位置收敛，减少了油门使用，减轻了俯仰-滚转耦合引起的滚转振荡。

Conclusion: SAOS方法在受限滑翔环境中提高了能量效率和飞行稳定性。

Abstract: Orographic soaring can significantly extend the endurance of micro aerial
vehicles (MAVs), but circling behavior, arising from control conflicts between
the longitudinal and vertical axes, increases energy consumption and the risk
of divergence. We propose a control switching method, named SAOS: Switched
Control for Autonomous Orographic Soaring, which mitigates circling behavior by
selectively controlling either the horizontal or vertical axis, effectively
transforming the system from underactuated to fully actuated during soaring.
Additionally, the angle of attack is incorporated into the INDI controller to
improve force estimation. Simulations with randomized initial positions and
wind tunnel experiments on two MAVs demonstrate that the SAOS improves position
convergence, reduces throttle usage, and mitigates roll oscillations caused by
pitch-roll coupling. These improvements enhance energy efficiency and flight
stability in constrained soaring environments.

</details>


### [53] [An Automated Tape Laying System Employing a Uniaxial Force Control Device](https://arxiv.org/abs/2510.23109)
*Bernhard Rameder,Hubert Gattringer,Ronald Naderer,Andreas Mueller*

Main category: cs.RO

TL;DR: 设计了一种具有集成单轴力控制和精确温度控制的成本效益型自动铺带系统，用于确保适当的压实力和胶带熔化，通过特殊机器人控制概念处理紧凑复杂形状。


<details>
  <summary>Details</summary>
Motivation: 需要控制基板和即将铺设的胶带达到特定温度水平，以确保产品不同层之间的最佳固结质量。

Method: 系统包含胶带存储卷轴、导向辊、处理单元、加热区和固结单元等多个模块，采用固定铺带装置、通过机器人移动形状的特殊控制方法。

Result: 使用碳纤维增强HDPE胶带进行的实验验证了子系统功能和铺带过程的有效性。

Conclusion: 开发的ATL系统能够成功处理紧凑复杂形状，并确保铺带过程中的适当压实和温度控制。

Abstract: This paper deals with the design of a cost effective automated tape laying
system (ATL system) with integrated uniaxial force control to ensure the
necessary compaction forces as well as with an accurate temperature control to
guarantee the used tape being melted appropriate. It is crucial to control the
substrate and the oncoming tape onto a specific temperature level to ensure an
optimal consolidation between the different layers of the product. Therefore,
it takes several process steps from the spooled tape on the coil until it is
finally tacked onto the desired mold. The different modules are divided into
the tape storage spool, a tape-guiding roller, a tape processing unit, a
heating zone and the consolidation unit. Moreover, a special robot control
concept for testing the ATL system is presented. In contrast to many other
systems, with this approach, the tape laying device is spatially fixed and the
shape is moved accordingly by the robot, which allows for handling of rather
compact and complex shapes. The functionality of the subsystems and the taping
process itself was finally approved in experimental results using a carbon
fiber reinforced HDPE tape.

</details>


### [54] [OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback](https://arxiv.org/abs/2510.23119)
*Yi-Lin Wei,Zhexi Luo,Yuhao Lin,Mu Lin,Zhizhao Liang,Shuoyu Chen,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: OmniDexGrasp是一个通用框架，通过结合基础模型与传递控制策略，实现用户提示、灵巧操作和抓取任务的全能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在不同物体或任务间泛化，基础模型提供了增强泛化的新途径，但直接利用它们生成可行机器人动作仍存在挑战。

Method: 集成三个关键模块：(i)使用基础模型生成支持全能力用户提示和任务的人类抓取图像；(ii)人类图像到机器人动作传递策略；(iii)力感知自适应抓取策略。

Result: 仿真和真实机器人实验验证了OmniDexGrasp在不同用户提示、抓取任务和灵巧手上的有效性，并展示了其在灵巧操作任务中的可扩展性。

Conclusion: 该框架成功解决了基础模型知识与物理机器人执行之间的差距，实现了全能力的灵巧抓取和操作。

Abstract: Enabling robots to dexterously grasp and manipulate objects based on human
commands is a promising direction in robotics. However, existing approaches are
challenging to generalize across diverse objects or tasks due to the limited
scale of semantic dexterous grasp datasets. Foundation models offer a new way
to enhance generalization, yet directly leveraging them to generate feasible
robotic actions remains challenging due to the gap between abstract model
knowledge and physical robot execution. To address these challenges, we propose
OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user
prompting, dexterous embodiment, and grasping tasks by combining foundation
models with the transfer and control strategies. OmniDexGrasp integrates three
key modules: (i) foundation models are used to enhance generalization by
generating human grasp images supporting omni-capability of user prompt and
task; (ii) a human-image-to-robot-action transfer strategy converts human
demonstrations into executable robot actions, enabling omni dexterous
embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable
grasp execution. Experiments in simulation and on real robots validate the
effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous
hands, and further results show its extensibility to dexterous manipulation
tasks.

</details>


### [55] [Reliable Robotic Task Execution in the Face of Anomalies](https://arxiv.org/abs/2510.23121)
*Bharath Santhanam,Alex Mitrevski,Santosh Thoduka,Sebastian Houben,Teena Hassan*

Main category: cs.RO

TL;DR: 提出一个结合学习策略与视觉异常检测的框架，通过三级恢复过程处理执行失败，提高机器人策略的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 学习到的机器人策略虽然灵活，但在开放环境中缺乏处理复杂性的机制，容易导致执行失败，需要能够识别和应对失败的机制。

Method: 训练异常检测模型使用策略正常执行时的数据，在线执行时检测异常并触发三级恢复过程：暂停执行、局部状态扰动、重置到安全状态。

Result: 在两个不同场景（门把手到达任务和物体放置任务）中验证，集成异常检测和恢复机制显著提高了在存在各种异常情况下的执行成功率。

Conclusion: 将策略执行与异常检测和恢复相结合，能够有效提高机器人策略在复杂环境中的可靠性和安全性。

Abstract: Learned robot policies have consistently been shown to be versatile, but they
typically have no built-in mechanism for handling the complexity of open
environments, making them prone to execution failures; this implies that
deploying policies without the ability to recognise and react to failures may
lead to unreliable and unsafe robot behaviour. In this paper, we present a
framework that couples a learned policy with a method to detect visual
anomalies during policy deployment and to perform recovery behaviours when
necessary, thereby aiming to prevent failures. Specifically, we train an
anomaly detection model using data collected during nominal executions of a
trained policy. This model is then integrated into the online policy execution
process, so that deviations from the nominal execution can trigger a
three-level sequential recovery process that consists of (i) pausing the
execution temporarily, (ii) performing a local perturbation of the robot's
state, and (iii) resetting the robot to a safe state by sampling from a learned
execution success model. We verify our proposed method in two different
scenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a
policy trained in simulation and transferred to the real robot, and (ii) an
object placing task with a UFactory xArm 6 using a general-purpose policy
model. Our results show that integrating policy execution with anomaly
detection and recovery increases the execution success rate in environments
with various anomalies, such as trajectory deviations and adversarial human
interventions.

</details>


### [56] [Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots](https://arxiv.org/abs/2510.23129)
*Sabino Francesco Roselli,Ze Zhang,Knut Åkesson*

Main category: cs.RO

TL;DR: 提出一个用于工业移动机器人车队协调的两层框架，结合高层调度和低层控制，确保安全无碰撞操作并支持快速重调度。


<details>
  <summary>Details</summary>
Motivation: 工业环境中移动机器人的物料搬运需要在大规模动态车队中进行可扩展的协调。

Method: 使用ComSat算法进行任务分配和调度，生成时间参数化路径；然后通过分布式模型预测控制（MPC）实时计算局部参考轨迹，考虑静态和动态障碍物。

Result: 在模拟2D环境中评估，显示高任务完成率和在拥堵情况下的鲁棒行为。

Conclusion: 该框架的模块化结构保证了计算可行性和灵活性，适用于复杂的真实工业场景部署。

Abstract: The deployment of mobile robots for material handling in industrial
environments requires scalable coordination of large fleets in dynamic
settings. This paper presents a two-layer framework that combines high-level
scheduling with low-level control. Tasks are assigned and scheduled using the
compositional algorithm ComSat, which generates time-parameterized routes for
each robot. These schedules are then used by a distributed Model Predictive
Control (MPC) system in real time to compute local reference trajectories,
accounting for static and dynamic obstacles. The approach ensures safe,
collision-free operation, and supports rapid rescheduling in response to
disruptions such as robot failures or environmental changes. We evaluate the
method in simulated 2D environments with varying road capacities and traffic
conditions, demonstrating high task completion rates and robust behavior even
under congestion. The modular structure of the framework allows for
computational tractability and flexibility, making it suitable for deployment
in complex, real-world industrial scenarios.

</details>


### [57] [TARC: Time-Adaptive Robotic Control](https://arxiv.org/abs/2510.23176)
*Arnav Sukhija,Lenart Treven,Jin Cheng,Florian Dörfler,Stelian Coros,Andreas Krause*

Main category: cs.RO

TL;DR: 提出一种强化学习方法，让机器人能够自主调整控制频率以适应不同情境需求，在保持性能的同时显著降低控制频率。


<details>
  <summary>Details</summary>
Motivation: 固定频率控制在机器人学中存在效率与鲁棒性的权衡，而生物系统能够自适应调整控制频率，这启发了可变频率控制的研究。

Method: 使用强化学习方法，策略同时选择控制动作及其应用持续时间，使机器人能够根据情境需求自主调节控制频率。

Result: 在两个硬件平台（高速遥控车和四足机器人）上进行了零样本仿真到真实环境的实验验证，方法在奖励方面匹配或优于固定频率基线，同时显著降低了控制频率，并在真实条件下表现出自适应频率控制能力。

Conclusion: 该方法成功实现了机器人控制频率的自适应调节，解决了固定频率控制中效率与鲁棒性的权衡问题，为机器人控制提供了更灵活高效的解决方案。

Abstract: Fixed-frequency control in robotics imposes a trade-off between the
efficiency of low-frequency control and the robustness of high-frequency
control, a limitation not seen in adaptable biological systems. We address this
with a reinforcement learning approach in which policies jointly select control
actions and their application durations, enabling robots to autonomously
modulate their control frequency in response to situational demands. We
validate our method with zero-shot sim-to-real experiments on two distinct
hardware platforms: a high-speed RC car and a quadrupedal robot. Our method
matches or outperforms fixed-frequency baselines in terms of rewards while
significantly reducing the control frequency and exhibiting adaptive frequency
control under real-world conditions.

</details>


### [58] [If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task](https://arxiv.org/abs/2510.23204)
*Giulia Pusceddu,Giulio Antonio Abbo,Francesco Rea,Tony Belpaeme,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 研究探讨了当机器人被感知为价值意识（理解人类原则）时，其意见是否更可能影响人类决策。实验发现参与者能区分价值意识和非价值意识机器人，对价值意识机器人注视更多，认为其更忠诚，且当两个机器人都反对参与者时会引起决策犹豫。


<details>
  <summary>Details</summary>
Motivation: 研究机器人价值意识对人类决策的影响，探索机器人是否可能被滥用于不道德目的，或帮助用户在模糊情境中反思。

Method: 设计实验让参与者与两个Furhat机器人互动（一个价值意识，一个非价值意识），在图像标注任务中观察参与者的选择、注视行为和感知评价。

Result: 参与者能区分两种机器人，对价值意识机器人注视更多，认为其更忠诚。当两个机器人都反对参与者时，约1/4试验发生从众行为，参与者确认响应时间更长。

Conclusion: 价值意识可能增强机器人感知忠诚度，两个机器人表达异议会引起决策犹豫。这既显示机器人可能被滥用的风险，也表明社交机器人可能帮助用户在模糊情境中反思。

Abstract: This study investigates whether the opinions of robotic agents are more
likely to influence human decision-making when the robots are perceived as
value-aware (i.e., when they display an understanding of human principles). We
designed an experiment in which participants interacted with two Furhat robots
- one programmed to be Value-Aware and the other Non-Value-Aware - during a
labeling task for images representing human values. Results indicate that
participants distinguished the Value-Aware robot from the Non-Value-Aware one.
Although their explicit choices did not indicate a clear preference for one
robot over the other, participants directed their gaze more toward the
Value-Aware robot. Additionally, the Value-Aware robot was perceived as more
loyal, suggesting that value awareness in a social robot may enhance its
perceived commitment to the group. Finally, when both robots disagreed with the
participant, conformity occurred in about one out of four trials, and
participants took longer to confirm their responses, suggesting that two robots
expressing dissent may introduce hesitation in decision-making. On one hand,
this highlights the potential risk that robots, if misused, could manipulate
users for unethical purposes. On the other hand, it reinforces the idea that
social robots might encourage reflection in ambiguous situations and help users
avoid scams.

</details>


### [59] [Workspace Registration and Collision Detection for Industrial Robotics Applications](https://arxiv.org/abs/2510.23227)
*Klaus Zauner,Josef El Dib,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 比较不同传感器在机器人运动规划中的应用，展示从环境检测到完整碰撞环境的处理流程，并检测机器人与环境之间的碰撞。


<details>
  <summary>Details</summary>
Motivation: 机器人运动规划需要精确的环境知识来定义限制区域和考虑碰撞物体，通过获取环境点云数据来实现这一目标。

Method: 使用各种传感器获取环境点云，通过区域生长分割和VCCS算法识别碰撞物体，然后对点簇进行近似处理。

Result: 建立了从环境检测到碰撞环境构建的完整流程，能够有效识别碰撞物体并检测机器人与环境的碰撞。

Conclusion: 该研究为机器人运动规划提供了可靠的环境感知和碰撞检测方法，通过传感器比较和环境建模实现了精确的碰撞避免。

Abstract: Motion planning for robotic manipulators relies on precise knowledge of the
environment in order to be able to define restricted areas and to take
collision objects into account. To capture the workspace, point clouds of the
environment are acquired using various sensors. The collision objects are
identified by region growing segmentation and VCCS algorithm. Subsequently the
point clusters are approximated. The aim of the present paper is to compare
different sensors, to illustrate the process from detection to the finished
collision environment and to detect collisions between the robot and this
environment.

</details>


### [60] [Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation](https://arxiv.org/abs/2510.23234)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种弹性连杆机器人机械臂寿命估计方法，用于优化柔性串联机械臂的几何设计，在拾放操作中平衡重量和振动幅度，通过疲劳分析和帕累托前沿选择最佳几何结构。


<details>
  <summary>Details</summary>
Motivation: 轻量化设计和时间能量最优控制是实现可持续工业自动化的关键，需要同时考虑机械柔顺性的控制和动态需求的设计优化。

Method: 使用雨流计数算法和临界切割平面法进行疲劳分析，采用Tresca假设构建等效应力，假设线性损伤累积，通过帕累托前沿权衡寿命和振动特性选择最终几何结构。

Result: 该方法应用于三自由度关节型机器人机械臂的几何优化，实现了重量和振动幅度的平衡优化。

Conclusion: 提出的寿命估计方法为弹性连杆机器人机械臂的设计优化提供了基础，能够有效平衡结构轻量化和振动控制需求。

Abstract: Resourceful operation and design of robots is key for sustainable industrial
automation. This will be enabled by lightweight design along with time and
energy optimal control of robotic manipulators. Design and control of such
systems is intertwined as the control must take into account inherent
mechanical compliance while the design must accommodate the dynamic
requirements demanded by the control. As basis for such design optimization, a
method for estimating the lifetime of elastic link robotic manipulators is
presented. This is applied to the geometry optimization of flexible serial
manipulators performing pick-and-place operations, where the optimization
objective is a combination of overall weight and vibration amplitudes. The
lifetime estimation draws from a fatigue analysis combining the rainflow
counting algorithm and the method of critical cutting plane. Tresca hypothesis
is used to formulate an equivalent stress, and linear damage accumulation is
assumed. The final robot geometry is selected from a Pareto front as a tradeoff
of lifetime and vibration characteristic. The method is illustrated for a three
degrees of freedom articulated robotic manipulator.

</details>


### [61] [Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation](https://arxiv.org/abs/2510.23258)
*Riko Yokozawa,Kentaro Fujii,Yuta Nomura,Shingo Murata*

Main category: cs.RO

TL;DR: 提出了一种基于深度主动推理的机器人导航框架，通过扩散策略和多时间尺度状态空间模型，在真实环境中实现了探索和目标导向导航的统一。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的自主机器人导航需要同时进行环境探索和指定目标导航，主动推理框架能够通过最小化期望自由能来统一这两种行为。

Method: 集成扩散策略作为策略模型和多时间尺度循环状态空间模型作为世界模型，通过潜在想象预测动作的长期后果，选择最小化期望自由能的动作。

Result: 真实世界导航实验表明，该框架相比基线方法具有更高的成功率和更少的碰撞，特别是在需要探索的场景中表现更优。

Conclusion: 基于期望自由能最小化的主动推理能够有效统一真实世界机器人环境中的探索和目标导向导航。

Abstract: Autonomous robotic navigation in real-world environments requires exploration
to acquire environmental information as well as goal-directed navigation in
order to reach specified targets. Active inference (AIF) based on the
free-energy principle provides a unified framework for these behaviors by
minimizing the expected free energy (EFE), thereby combining epistemic and
extrinsic values. To realize this practically, we propose a deep AIF framework
that integrates a diffusion policy as the policy model and a multiple timescale
recurrent state-space model (MTRSSM) as the world model. The diffusion policy
generates diverse candidate actions while the MTRSSM predicts their
long-horizon consequences through latent imagination, enabling action selection
that minimizes EFE. Real-world navigation experiments demonstrated that our
framework achieved higher success rates and fewer collisions compared with the
baselines, particularly in exploration-demanding scenarios. These results
highlight how AIF based on EFE minimization can unify exploration and
goal-directed navigation in real-world robotic settings.

</details>


### [62] [Precise Time Delay Measurement and Compensation for Tightly Coupled Underwater SINS/piUSBL Navigation](https://arxiv.org/abs/2510.23286)
*Jin Huang,Yingqiang Wang,Haoda Li,Zichen Liu,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 提出了一种紧密耦合的水下导航框架，通过精确时间同步集成piUSBL声学定位系统、SINS和深度计，将时间延迟重新定义为可量化参数进行估计和补偿，显著提高了导航精度。


<details>
  <summary>Details</summary>
Motivation: 解决多传感器系统中时间同步的挑战，特别是在包含声学定位的水下集成导航系统中，时间延迟会显著降低测量和融合的准确性。

Method: 采用紧密耦合导航框架，融合piUSBL的方位角和斜距数据与深度数据，避免平面阵列垂直角可观测性差的问题；引入新的延迟测量策略，结合同步定时和声学信号处理，将延迟重新定义为可量化参数。

Result: 仿真和现场实验验证了方法的可行性，延迟补偿后的导航使RMSE降低了40.45%，最大误差降低了32.55%。

Conclusion: 精确的延迟测量和补偿不仅提高了水下导航精度，还为声学定位集成建立了可推广的框架，为延迟敏感的多传感器系统提供了时间对齐和数据融合的宝贵见解。

Abstract: In multi-sensor systems, time synchronization between sensors is a
significant challenge, and this issue is particularly pronounced in underwater
integrated navigation systems incorporating acoustic positioning. Such systems
are highly susceptible to time delay, which can significantly degrade accuracy
when measurement and fusion moments are misaligned. To address this challenge,
this paper introduces a tightly coupled navigation framework that integrates a
passive inverted ultra-short baseline (piUSBL) acoustic positioning system, a
strapdown inertial navigation system (SINS), and a depth gauge under precise
time synchronization. The framework fuses azimuth and slant range from the
piUSBL with depth data, thereby avoiding poor vertical-angle observability in
planar arrays. A novel delay measurement strategy is introduced, combining
synchronized timing with acoustic signal processing, which redefines
delay-traditionally an unobservable error-into a quantifiable parameter,
enabling explicit estimation of both acoustic propagation and system processing
delays. Simulations and field experiments confirm the feasibility of the
proposed method, with delay-compensated navigation reducing RMSE by 40.45% and
maximum error by 32.55%. These findings show that precise delay measurement and
compensation not only enhance underwater navigation accuracy but also establish
a generalizable framework for acoustic positioning integration, offering
valuable insights into time alignment and data fusion in latency-sensitive
multi-sensor systems.

</details>


### [63] [Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon](https://arxiv.org/abs/2510.23329)
*Shreya Santra,Thomas Robbins,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 该研究探索了深度强化学习策略在视觉和地形特征不同的模拟环境间的泛化能力，通过在陆地环境中训练导航策略，并在零样本情况下在月球环境中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决非结构化环境中自主导航的挑战，传统方法需要大量环境特定调优，限制了在新领域的可扩展性。深度强化学习提供了一种数据驱动的替代方案。

Method: 开发了农业漫游车的3D模拟环境，使用近端策略优化算法训练目标导向导航和避障策略，然后在月球模拟环境中进行零样本评估。

Result: 在陆地条件下训练的策略在月球模拟环境中保持了较高有效性，无需额外训练和微调即可达到接近50%的成功率。

Conclusion: 跨领域深度强化学习策略迁移为未来行星探索任务开发适应性强的自主导航系统提供了有前景的方法，同时能最小化重新训练成本。

Abstract: Autonomous navigation in unstructured environments is essential for field and
planetary robotics, where robots must efficiently reach goals while avoiding
obstacles under uncertain conditions. Conventional algorithmic approaches often
require extensive environment-specific tuning, limiting scalability to new
domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,
allowing robots to acquire navigation strategies through direct interactions
with their environment. This work investigates the feasibility of DRL policy
generalization across visually and topographically distinct simulated domains,
where policies are trained in terrestrial settings and validated in a zero-shot
manner in extraterrestrial environments. A 3D simulation of an agricultural
rover is developed and trained using Proximal Policy Optimization (PPO) to
achieve goal-directed navigation and obstacle avoidance in farmland settings.
The learned policy is then evaluated in a lunar-like simulated environment to
assess transfer performance. The results indicate that policies trained under
terrestrial conditions retain a high level of effectiveness, achieving close to
50\% success in lunar simulations without the need for additional training and
fine-tuning. This underscores the potential of cross-domain DRL-based policy
transfer as a promising approach to developing adaptable and efficient
autonomous navigation for future planetary exploration missions, with the added
benefit of minimizing retraining costs.

</details>


### [64] [Large language model-based task planning for service robots: A review](https://arxiv.org/abs/2510.23357)
*Shaohan Bian,Ying Zhang,Guohui Tian,Zhiqiang Miao,Edmond Q. Wu,Simon X. Yang,Changchun Hua*

Main category: cs.RO

TL;DR: 本文综述了大型语言模型在服务机器人任务规划中的应用，包括LLM基础技术、作为机器人认知核心的作用、多模态输入下的任务规划进展，以及当前挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM和机器人技术的快速发展，服务机器人在复杂环境中提供多样化服务需要强大准确的任务规划能力。本文旨在全面概述LLM如何增强服务机器人的任务规划能力。

Method: 回顾LLM的基础技术（预训练、微调、RAG、提示工程），分析LLM作为服务机器人认知核心的作用，探讨多模态输入下的任务规划方法。

Result: 系统梳理了LLM在服务机器人任务规划中的最新进展，包括文本、视觉、音频和多模态输入的处理能力。

Conclusion: 总结了当前研究的关键挑战和局限性，提出了在复杂非结构化家庭环境中推进服务机器人任务规划能力的未来研究方向。

Abstract: With the rapid advancement of large language models (LLMs) and robotics,
service robots are increasingly becoming an integral part of daily life,
offering a wide range of services in complex environments. To deliver these
services intelligently and efficiently, robust and accurate task planning
capabilities are essential. This paper presents a comprehensive overview of the
integration of LLMs into service robotics, with a particular focus on their
role in enhancing robotic task planning. First, the development and
foundational techniques of LLMs, including pre-training, fine-tuning,
retrieval-augmented generation (RAG), and prompt engineering, are reviewed. We
then explore the application of LLMs as the cognitive core-`brain'-of service
robots, discussing how LLMs contribute to improved autonomy and
decision-making. Furthermore, recent advancements in LLM-driven task planning
across various input modalities are analyzed, including text, visual, audio,
and multimodal inputs. Finally, we summarize key challenges and limitations in
current research and propose future directions to advance the task planning
capabilities of service robots in complex, unstructured domestic environments.
This review aims to serve as a valuable reference for researchers and
practitioners in the fields of artificial intelligence and robotics.

</details>


### [65] [T-ESKF: Transformed Error-State Kalman Filter for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2510.23359)
*Chungeng Tian,Ning Hao,Fenghua He*

Main category: cs.RO

TL;DR: 提出Transformed ESKF (T-ESKF)方法，通过线性时变变换解决视觉惯性导航系统中的可观测性不匹配问题，确保系统可观测性不随线性化点变化，并在性能和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决视觉惯性导航系统(VINS)中由于可观测性不匹配导致的估计不一致问题，传统方法在状态估计时会因线性化点变化而破坏系统的可观测性结构。

Method: 在误差状态卡尔曼滤波器(ESKF)中应用线性时变变换到误差状态，使得变换后误差状态系统的不可观测子空间与状态无关，从而保持正确的可观测性。开发了基于变换关系的高效协方差传播技术。

Result: 通过大量仿真和实验验证，所提方法在性能上优于或至少与最先进方法相当，同时提供了更高效的计算实现。

Conclusion: T-ESKF是一种一致的VINS估计器，有效解决了可观测性不匹配问题，在保持估计一致性的同时提供了优异的性能表现。

Abstract: This paper presents a novel approach to address the inconsistency problem
caused by observability mismatch in visual-inertial navigation systems (VINS).
The key idea involves applying a linear time-varying transformation to the
error-state within the Error-State Kalman Filter (ESKF). This transformation
ensures that \textrr{the unobservable subspace of the transformed error-state
system} becomes independent of the state, thereby preserving the correct
observability of the transformed system against variations in linearization
points. We introduce the Transformed ESKF (T-ESKF), a consistent VINS estimator
that performs state estimation using the transformed error-state system.
Furthermore, we develop an efficient propagation technique to accelerate the
covariance propagation based on the transformation relationship between the
transition and accumulated matrices of T-ESKF and ESKF. We validate the
proposed method through extensive simulations and experiments, demonstrating
better (or competitive at least) performance compared to state-of-the-art
methods. The code is available at github.com/HITCSC/T-ESKF.

</details>


### [66] [Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.23386)
*Alvaro Paz,Mahdi Hejrati,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种用于重型液压机械臂的非线性模型预测控制框架，能够在1kHz实时控制频率下保证约束满足，结合多射击策略和虚拟分解控制，实现高精度轨迹跟踪同时严格遵守安全约束。


<details>
  <summary>Details</summary>
Motivation: 重型液压机械臂由于尺寸大、功率高、非线性动力学复杂，需要在严格物理和安全约束下运行，但现有实时控制框架对关节级和末端执行器轨迹约束的保证研究不足。

Method: 采用非线性模型预测控制框架，结合多射击策略和实时传感器反馈，并基于虚拟分解控制的鲁棒底层控制器实现精确关节跟踪。

Result: 在全尺寸液压机械臂上的实验验证表明，该框架不仅能在关节级强制执行约束，还能确保末端执行器在笛卡尔空间中的约束合规运动。

Conclusion: 该方法能够提供高精度轨迹跟踪同时严格尊重安全关键限制，为大型液压系统的实时控制设立了新基准。

Abstract: Heavy-duty hydraulic manipulators (HHMs) operate under strict physical and
safety-critical constraints due to their large size, high power, and complex
nonlinear dynamics. Ensuring that both joint-level and end-effector
trajectories remain compliant with actuator capabilities, such as force,
velocity, and position limits, is essential for safe and reliable operation,
yet remains largely underexplored in real-time control frameworks. This paper
presents a nonlinear model predictive control (NMPC) framework designed to
guarantee constraint satisfaction throughout the full nonlinear dynamics of
HHMs, while running at a real-time control frequency of 1 kHz. The proposed
method combines a multiple-shooting strategy with real-time sensor feedback,
and is supported by a robust low-level controller based on virtual
decomposition control (VDC) for precise joint tracking. Experimental validation
on a full-scale hydraulic manipulator shows that the NMPC framework not only
enforces actuator constraints at the joint level, but also ensures
constraint-compliant motion in Cartesian space for the end-effector. These
results demonstrate the method's capability to deliver high-accuracy trajectory
tracking while strictly respecting safety-critical limits, setting a new
benchmark for real-time control in large-scale hydraulic systems.

</details>


### [67] [COOPERA: Continual Open-Ended Human-Robot Assistance](https://arxiv.org/abs/2510.23495)
*Chenyang Ma,Kai Lu,Ruta Desai,Xavier Puig,Andrew Markham,Niki Trigoni*

Main category: cs.RO

TL;DR: COOPERA是一个用于持续、开放式人机协作的新框架，通过模拟具有心理特征和长期意图的人类，使机器人能够在复杂环境中学习个性化协作行为。


<details>
  <summary>Details</summary>
Motivation: 现有机器人助手主要关注结构化环境中的预定义任务，缺乏学习人类特质、习惯和长期活动的能力，无法实现真正的人机协作。

Method: 引入COOPERA框架，集成持续的人类反馈，通过模拟具有心理特征和长期意图的人类，在复杂环境中研究长期开放式人机协作。

Result: 实验验证了模拟人类行为的真实性，并证明了推断和个性化人类意图对于开放式长期人机协作的价值。

Conclusion: COOPERA框架首次实现了在不同时间尺度上研究长期开放式人机协作，为个性化机器人协作提供了有效方法。

Abstract: To understand and collaborate with humans, robots must account for individual
human traits, habits, and activities over time. However, most robotic
assistants lack these abilities, as they primarily focus on predefined tasks in
structured environments and lack a human model to learn from. This work
introduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot
Assistance, where simulated humans, driven by psychological traits and
long-term intentions, interact with robots in complex environments. By
integrating continuous human feedback, our framework, for the first time,
enables the study of long-term, open-ended human-robot collaboration (HRC) in
different collaborative tasks across various time-scales. Within COOPERA, we
introduce a benchmark and an approach to personalize the robot's collaborative
actions by learning human traits and context-dependent intents. Experiments
validate the extent to which our simulated humans reflect realistic human
behaviors and demonstrate the value of inferring and personalizing to human
intents for open-ended and long-term HRC. Project Page:
https://dannymcy.github.io/coopera/

</details>


### [68] [Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model](https://arxiv.org/abs/2510.23509)
*Weizheng Wang,Obi Ike,Soyun Choi,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: NaviWM是一个社交感知的机器人导航世界模型，通过结合结构化世界模型和逻辑驱动的思维链过程来增强LLM推理能力，解决单纯依赖LLM在动态人类空间中导航时的不可预测和不安全行为问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的社交机器人导航在动态人类空间中存在不可预测和不安全行为，主要原因是缺乏物理基础和逻辑一致性。需要一种方法能够将社会规范编码为可解释和可验证的推理过程。

Method: NaviWM包含两个主要组件：(1) 时空世界模型，捕捉环境中代理的位置、速度和活动；(2) 演绎推理模块，通过多步骤、基于逻辑的推理过程指导LLM。将社会规范编码为一阶逻辑，实现可解释推理。

Result: 实验表明NaviWM提高了导航成功率并减少了社交违规行为，特别是在拥挤环境中。相比仅使用提示或微调的方法表现更优。

Conclusion: 将形式推理与LLM结合能够实现更稳健的社交导航，NaviWM通过结构化世界模型和逻辑驱动的推理过程解决了LLM在物理基础和逻辑一致性方面的局限性。

Abstract: Social robot navigation increasingly relies on large language models for
reasoning, path planning, and enabling movement in dynamic human spaces.
However, relying solely on LLMs for planning often leads to unpredictable and
unsafe behaviors, especially in dynamic human spaces, due to limited physical
grounding and weak logical consistency. In this work, we introduce NaviWM, a
socially-aware robot Navigation World Model that augments LLM reasoning with a
structured world model and a logic-driven chain-of-thought process. NaviWM
consists of two main components: (1) a spatial-temporal world model that
captures the positions, velocities, and activities of agents in the
environment, and (2) a deductive reasoning module that guides LLMs through a
multi-step, logic-based inference process. This integration enables the robot
to generate navigation decisions that are both socially compliant and
physically safe, under well-defined constraints such as personal space,
collision avoidance, and timing. Unlike previous methods based on prompting or
fine-tuning, NaviWM encodes social norms as first-order logic, enabling
interpretable and verifiable reasoning. Experiments show that NaviWM improves
success rates and reduces social violations, particularly in crowded
environments. These results demonstrate the benefit of combining formal
reasoning with LLMs for robust social navigation. Additional experimental
details and demo videos for this work can be found at:
https://sites.google.com/view/NaviWM.

</details>


### [69] [Dexbotic: Open-Source Vision-Language-Action Toolbox](https://arxiv.org/abs/2510.23511)
*Bin Xie,Erjin Zhou,Fan Jia,Hao Shi,Haoqiang Fan,Haowei Zhang,Hebei Li,Jianjian Sun,Jie Bin,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Lin Sun,Meng Zhang,Peilong Han,Ruitao Hao,Ruitao Zhang,Saike Huang,Songhan Xie,Tiancai Wang,Tianle Liu,Wenbin Tang,Wenqi Zhu,Yang Chen,Yingfei Liu,Yizhuang Zhou,Yu Liu,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yuxiang Chen,Ze Chen,Zeming Li,Zhao Wu,Ziheng Zhang,Ziming Liu,Ziwei Yan,Ziyu Zhang*

Main category: cs.RO

TL;DR: Dexbotic是一个基于PyTorch的开源视觉-语言-动作模型工具箱，为具身智能领域提供一站式VLA研究服务，支持多种主流VLA策略，具有实验导向的设计理念。


<details>
  <summary>Details</summary>
Motivation: 为具身智能领域的研究人员提供一个统一的VLA研究平台，解决现有工具分散、环境配置复杂的问题，促进VLA方法的研究和复现。

Method: 构建基于PyTorch的代码库，支持多种主流VLA策略并行运行，采用实验导向的设计，用户只需修改Exp脚本即可快速开发新实验，并提供更强的预训练模型。

Result: 开发了Dexbotic工具箱，实现了单一环境配置下复现多种VLA方法的能力，显著提升了最先进VLA策略的性能表现。

Conclusion: Dexbotic为VLA研究提供了高效统一的解决方案，将持续更新集成最新的预训练基础模型和前沿VLA模型，推动具身智能领域的发展。

Abstract: In this paper, we present Dexbotic, an open-source Vision-Language-Action
(VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA
research service for professionals in the field of embodied intelligence. It
offers a codebase that supports multiple mainstream VLA policies
simultaneously, allowing users to reproduce various VLA methods with just a
single environment setup. The toolbox is experiment-centric, where the users
can quickly develop new VLA experiments by simply modifying the Exp script.
Moreover, we provide much stronger pretrained models to achieve great
performance improvements for state-of-the-art VLA policies. Dexbotic will
continuously update to include more of the latest pre-trained foundation models
and cutting-edge VLA models in the industry.

</details>


### [70] [Localising under the drape: proprioception in the era of distributed surgical robotic system](https://arxiv.org/abs/2510.23512)
*Martin Huber,Nicola A. Cavalcanti,Ayoob Davoodi,Ruixuan Li,Christopher E. Mower,Fabio Carrillo,Christoph J. Laux,Francois Teyssere,Thibault Chandanson,Antoine Harlé,Elie Saghbiny,Mazda Farshad,Guillaume Morel,Emmanuel Vander Poorten,Philipp Fürnstahl,Sébastien Ourselin,Christos Bergeles,Tom Vercauteren*

Main category: cs.RO

TL;DR: 提出了一种无需标记物的手术机器人本体感知方法，仅使用轻量级立体RGB摄像头和基于transformer的深度学习模型，能够在无菌覆盖下精确定位手术机器人。


<details>
  <summary>Details</summary>
Motivation: 现有手术机器人缺乏空间感知能力，导致碰撞、系统恢复和工作流程中断问题。现有跟踪系统依赖笨重的红外摄像头和反射标记，视野有限且增加手术室硬件负担。

Method: 基于最大的多中心空间机器人手术数据集（140万张自注释图像），使用轻量级立体RGB摄像头和新型transformer深度学习模型，通过跟踪整个机器人和手术场景而非单个标记来实现定位。

Result: 在体内呼吸补偿中展示了潜在临床益处，能够观察组织动态；在多机器人系统中准确定位；相比现有系统消除标记物并提高25%的跟踪可见性。

Conclusion: 这是首个针对完全覆盖手术机器人的无标记本体感知演示，减少了设置复杂性，提高了安全性，为模块化和自主机器人手术铺平了道路。

Abstract: Despite their mechanical sophistication, surgical robots remain blind to
their surroundings. This lack of spatial awareness causes collisions, system
recoveries, and workflow disruptions, issues that will intensify with the
introduction of distributed robots with independent interacting arms. Existing
tracking systems rely on bulky infrared cameras and reflective markers,
providing only limited views of the surgical scene and adding hardware burden
in crowded operating rooms. We present a marker-free proprioception method that
enables precise localisation of surgical robots under their sterile draping
despite associated obstruction of visual cues. Our method solely relies on
lightweight stereo-RGB cameras and novel transformer-based deep learning
models. It builds on the largest multi-centre spatial robotic surgery dataset
to date (1.4M self-annotated images from human cadaveric and preclinical in
vivo studies). By tracking the entire robot and surgical scene, rather than
individual markers, our approach provides a holistic view robust to occlusions,
supporting surgical scene understanding and context-aware control. We
demonstrate an example of potential clinical benefits during in vivo breathing
compensation with access to tissue dynamics, unobservable under state of the
art tracking, and accurately locate in multi-robot systems for future
intelligent interaction. In addition, and compared with existing systems, our
method eliminates markers and improves tracking visibility by 25%. To our
knowledge, this is the first demonstration of marker-free proprioception for
fully draped surgical robots, reducing setup complexity, enhancing safety, and
paving the way toward modular and autonomous robotic surgery.

</details>


### [71] [Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation](https://arxiv.org/abs/2510.23521)
*Anthony Opipari,Aravindhan K Krishnan,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo,Arnie Sen,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: 该论文提出了一种使用显式3D高斯泼溅(3DGS)记忆来改进类无关视频分割算法的方法，开发了FastSAM-Splat和SAM2-Splat两种融合技术，通过3DGS存储历史对象分割结果，提高了分割的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频分割算法要么不使用对象级记忆(如FastSAM)，要么使用循环神经网络特征的隐式记忆(如SAM2)。为了改进分割的准确性和一致性，需要开发显式的3D记忆机制来存储历史分割结果。

Method: 开发了在线3D高斯泼溅(3DGS)技术来存储整个视频过程中预测的对象级分割结果。基于此3DGS表示，开发了FastSAM-Splat和SAM2-Splat融合技术，使用显式3DGS记忆来改进各自基础模型的预测。

Result: 消融实验验证了所提技术的设计和超参数设置。真实世界和模拟基准测试结果表明，使用显式3D记忆的模型比不使用记忆或仅使用隐式神经网络记忆的模型产生更准确和一致的分割结果。

Conclusion: 显式3D高斯泼溅记忆能够有效提升视频分割算法的准确性和一致性，为类无关视频分割提供了新的记忆增强解决方案。

Abstract: Remembering where object segments were predicted in the past is useful for
improving the accuracy and consistency of class-agnostic video segmentation
algorithms. Existing video segmentation algorithms typically use either no
object-level memory (e.g. FastSAM) or they use implicit memories in the form of
recurrent neural network features (e.g. SAM2). In this paper, we augment both
types of segmentation models using an explicit 3D memory and show that the
resulting models have more accurate and consistent predictions. For this, we
develop an online 3D Gaussian Splatting (3DGS) technique to store predicted
object-level segments generated throughout the duration of a video. Based on
this 3DGS representation, a set of fusion techniques are developed, named
FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve
their respective foundation models' predictions. Ablation experiments are used
to validate the proposed techniques' design and hyperparameter settings.
Results from both real-world and simulated benchmarking experiments show that
models which use explicit 3D memories result in more accurate and consistent
predictions than those which use no memory or only implicit neural network
memories. Project Page: https://topipari.com/projects/FastSAM-Splat/

</details>


### [72] [RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation](https://arxiv.org/abs/2510.23571)
*Yash Jangir,Yidi Zhang,Kashu Yamazaki,Chenyu Zhang,Kuan-Hsun Tu,Tsung-Wei Ke,Lei Ke,Yonatan Bisk,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 提出了一个用于评估机器人通用智能体的新基准框架，通过将视觉语言动作模型评估转移到大规模模拟环境中，并加入在线人类反馈来解决现实世界测试的限制。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人策略测试存在劳动密集、缓慢、不安全且难以复现的问题，现有模拟基准也局限于相同合成域内的训练和测试，无法评估从真实世界演示训练的模型。

Method: 利用视觉语言模型、2D到3D生成建模和可微分渲染技术，将广泛使用的机器人数据集中的视频演示自动转换为模拟对应物，在数字孪生环境中使用自动化VLM引导评分和可扩展的人类偏好判断来评估策略。

Result: 创建了一个持续演进、可复现且可扩展的基准，用于评估真实世界训练的机器人操作策略，通过系统性地扰动模拟环境来测试策略在受控变化下的泛化能力。

Conclusion: 该框架解决了当前机器人领域中关键缺失的能力，为机器人通用智能体的评估提供了更高效、安全和可扩展的解决方案。

Abstract: The pursuit of robot generalists - instructable agents capable of performing
diverse tasks across diverse environments - demands rigorous and scalable
evaluation. Yet real-world testing of robot policies remains fundamentally
constrained: it is labor-intensive, slow, unsafe at scale, and difficult to
reproduce. Existing simulation benchmarks are similarly limited, as they train
and test policies within the same synthetic domains and cannot assess models
trained from real-world demonstrations or alternative simulation environments.
As policies expand in scope and complexity, these barriers only intensify,
since defining "success" in robotics often hinges on nuanced human judgments of
execution quality. In this paper, we introduce a new benchmarking framework
that overcomes these challenges by shifting VLA evaluation into large-scale
simulated environments augmented with online human feedback. Leveraging
advances in vision-language models, 2D-to-3D generative modeling, and
differentiable rendering, our approach automatically converts video
demonstrations from widely used robot datasets into simulated counterparts.
Within these digital twins, we assess VLA policies using both automated
VLM-guided scoring and scalable human preference judgments collected from
crowdworkers, transforming human involvement from tedious scene setup,
resetting, and safety supervision into lightweight preference comparisons. To
measure robustness, we systematically perturb simulated environments along
multiple axes, such as textures and object placements, stress-testing policy
generalization under controlled variation. The result is a continuously
evolving, reproducible, and scalable benchmark for real-world trained robot
manipulation policies, addressing a critical missing capability in today's
robotics landscape.

</details>


### [73] [UrbanVLA: A Vision-Language-Action Model for Urban Micromobility](https://arxiv.org/abs/2510.23576)
*Anqi Li,Zhiyong Wang,Jiazhao Zhang,Minghan Li,Yunpeng Qi,Zhibo Chen,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: UrbanVLA是一个用于城市微移动导航的视觉-语言-动作框架，通过两阶段训练在模拟和真实数据上实现大规模城市环境下的可靠导航。


<details>
  <summary>Details</summary>
Motivation: 城市微移动应用需要在大规模动态城市环境中进行可靠导航，但现有方法主要针对短距离可控场景，缺乏处理长距离路线指令和城市环境复杂性的能力。

Method: 提出UrbanVLA框架，将噪声路线点与视觉观察对齐并规划轨迹，采用两阶段训练：先在模拟环境和网络视频轨迹上进行监督微调，然后在混合数据上进行强化微调。

Result: 在MetaUrban的SocialNav任务中比基线方法提升55%以上，在真实世界中展示了大规模城市环境下的可扩展性和对不确定性的鲁棒性。

Conclusion: UrbanVLA能够有效解决城市微移动导航的挑战，实现了大规模城市环境下的可靠导航，证明了视觉-语言-动作框架在城市导航任务中的有效性。

Abstract: Urban micromobility applications, such as delivery robots, demand reliable
navigation across large-scale urban environments while following long-horizon
route instructions. This task is particularly challenging due to the dynamic
and unstructured nature of real-world city areas, yet most existing navigation
methods remain tailored to short-scale and controllable scenarios. Effective
urban micromobility requires two complementary levels of navigation skills:
low-level capabilities such as point-goal reaching and obstacle avoidance, and
high-level capabilities, such as route-visual alignment. To this end, we
propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework
designed for scalable urban navigation. Our method explicitly aligns noisy
route waypoints with visual observations during execution, and subsequently
plans trajectories to drive the robot. To enable UrbanVLA to master both levels
of navigation, we employ a two-stage training pipeline. The process begins with
Supervised Fine-Tuning (SFT) using simulated environments and trajectories
parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on
a mixture of simulation and real-world data, which enhances the model's safety
and adaptability in real-world settings. Experiments demonstrate that UrbanVLA
surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.
Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both
scalability to large-scale urban environments and robustness against real-world
uncertainties.

</details>
