<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 72]
- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EmbeddingRWKV: State-Centric Retrieval with Reusable States](https://arxiv.org/abs/2601.07861)
*Haowen Hou,Jie Yang*

Main category: cs.CL

TL;DR: 提出State-Centric Retrieval统一检索范式，通过状态表示学习将RWKV-based LLM转换为EmbeddingRWKV，作为嵌入模型和状态骨干，实现检索和重排的高效统一，显著提升系统效率。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统的两阶段流水线（嵌入模型+重排器）存在效率低下问题，因为两个阶段之间缺乏信息共享，导致大量冗余计算。

Method: 1. 状态表示学习：微调RWKV-based LLM为EmbeddingRWKV，作为统一的嵌入模型和状态骨干，提取紧凑可重用的状态；2. 基于状态的重排器设计：重排时仅处理查询token，解耦推理成本与文档长度；3. 统一层选择策略：仅保留必要中间层状态。

Result: 1. 重排阶段实现5.4-44.8倍加速；2. 仅使用25%的层即可保持98.62%的完整模型性能；3. 在广泛实验中实现高质量检索和重排结果，同时显著提升系统效率。

Conclusion: State-Centric Retrieval通过状态桥接嵌入模型和重排器，解决了传统RAG系统的效率瓶颈，在保持高性能的同时大幅提升计算效率，为检索增强生成系统提供了更高效的统一范式。

Abstract: Current Retrieval-Augmented Generation (RAG) systems typically employ a traditional two-stage pipeline: an embedding model for initial retrieval followed by a reranker for refinement. However, this paradigm suffers from significant inefficiency due to the lack of shared information between stages, leading to substantial redundant computation. To address this limitation, we propose \textbf{State-Centric Retrieval}, a unified retrieval paradigm that utilizes "states" as a bridge to connect embedding models and rerankers. First, we perform state representation learning by fine-tuning an RWKV-based LLM, transforming it into \textbf{EmbeddingRWKV}, a unified model that serves as both an embedding model and a state backbone for extracting compact, reusable states. Building upon these reusable states, we further design a state-based reranker to fully leverage precomputed information. During reranking, the model processes only query tokens, decoupling inference cost from document length and yielding a 5.4$\times$--44.8$\times$ speedup. Furthermore, we observe that retaining all intermediate layer states is unnecessary; with a uniform layer selection strategy, our model maintains 98.62\% of full-model performance using only 25\% of the layers. Extensive experiments demonstrate that State-Centric Retrieval achieves high-quality retrieval and reranking results while significantly enhancing overall system efficiency. Code is available at \href{https://github.com/howard-hou/EmbeddingRWKV}{our GitHub repository}.

</details>


### [2] [A Human-Centric Pipeline for Aligning Large Language Models with Chinese Medical Ethics](https://arxiv.org/abs/2601.07954)
*Haoan Jin,Han Ying,Jiacheng Ji,Hanhui Xu,Mengyue Wu*

Main category: cs.CL

TL;DR: 提出了MedES基准和guardian-in-the-loop框架，通过监督微调和领域特定偏好优化，在中文医疗伦理场景下对齐7B参数LLM，性能优于更大基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在医疗任务中应用广泛，但在复杂现实场景下与医疗伦理的细致要求对齐仍然不足，特别是在中文医疗伦理领域缺乏专门研究。

Method: 1) 构建MedES基准：从260个权威中文医疗、伦理和法律来源创建动态场景中心基准；2) 提出guardian-in-the-loop框架：使用自动化评估器（准确率>97%）生成针对性提示并提供结构化伦理反馈；3) 通过监督微调和领域特定偏好优化对齐7B参数LLM。

Result: 在中文医疗伦理背景下，对齐后的模型在核心伦理任务上显著优于更大的基线模型，在质量和综合评估指标上均有提升。

Conclusion: 该工作为中文医疗领域LLM与医疗伦理对齐提供了实用且可适应的框架，并表明通过模块化替换底层规范语料，类似对齐流程可在其他法律和文化环境中实例化。

Abstract: Recent advances in large language models have enabled their application to a range of healthcare tasks. However, aligning LLMs with the nuanced demands of medical ethics, especially under complex real world scenarios, remains underexplored. In this work, we present MedES, a dynamic, scenario-centric benchmark specifically constructed from 260 authoritative Chinese medical, ethical, and legal sources to reflect the challenges in clinical decision-making. To facilitate model alignment, we introduce a guardian-in-the-loop framework that leverages a dedicated automated evaluator (trained on expert-labeled data and achieving over 97% accuracy within our domain) to generate targeted prompts and provide structured ethical feedback. Using this pipeline, we align a 7B-parameter LLM through supervised fine-tuning and domain-specific preference optimization. Experimental results, conducted entirely within the Chinese medical ethics context, demonstrate that our aligned model outperforms notably larger baselines on core ethical tasks, with observed improvements in both quality and composite evaluation metrics. Our work offers a practical and adaptable framework for aligning LLMs with medical ethics in the Chinese healthcare domain, and suggests that similar alignment pipelines may be instantiated in other legal and cultural environments through modular replacement of the underlying normative corpus.

</details>


### [3] [Knowing But Not Doing: Convergent Morality and Divergent Action in LLMs](https://arxiv.org/abs/2601.07972)
*Jen-tse Huang,Jiantong Qin,Xueli Qiu,Sharon Levy,Michelle R. Kaufman,Mark Dredze*

Main category: cs.CL

TL;DR: 该研究通过ValAct-15k数据集评估LLMs在现实决策场景中的价值对齐表现，发现模型间高度一致但与人差异大，且存在知识-行动差距和角色扮演厌恶现象。


<details>
  <summary>Details</summary>
Motivation: 价值对齐对AI安全和社会兼容性至关重要，但LLMs如何在现实决策中体现和执行人类价值观仍不清楚。研究者希望探索LLMs的价值表征与实际行动之间的差距。

Method: 创建ValAct-15k数据集（3000个Reddit建议寻求场景，基于Schwartz基本人类价值观理论），评估10个前沿LLMs（中美各5个）和55名人类参与者，使用场景问题和传统价值观问卷。

Result: 1. 模型间决策高度一致（Pearson r≈1.0），而人类差异大（r∈[-0.79,0.98]）；2. 人类和LLMs都显示自我报告与实际行动价值观弱相关（r=0.4,0.3）；3. 当被要求"持有"特定价值观时，LLMs性能下降达6.6%。

Conclusion: 对齐训练虽然实现了规范性价值趋同，但未能消除类似人类的知识与行动不一致问题，LLMs存在角色扮演厌恶，揭示了价值对齐的深层挑战。

Abstract: Value alignment is central to the development of safe and socially compatible artificial intelligence. However, how Large Language Models (LLMs) represent and enact human values in real-world decision contexts remains under-explored. We present ValAct-15k, a dataset of 3,000 advice-seeking scenarios derived from Reddit, designed to elicit ten values defined by Schwartz Theory of Basic Human Values. Using both the scenario-based questions and the traditional value questionnaire, we evaluate ten frontier LLMs (five from U.S. companies, five from Chinese ones) and human participants ($n = 55$). We find near-perfect cross-model consistency in scenario-based decisions (Pearson $r \approx 1.0$), contrasting sharply with the broad variability observed among humans ($r \in [-0.79, 0.98]$). Yet, both humans and LLMs show weak correspondence between self-reported and enacted values ($r = 0.4, 0.3$), revealing a systematic knowledge-action gap. When instructed to "hold" a specific value, LLMs' performance declines up to $6.6%$ compared to merely selecting the value, indicating a role-play aversion. These findings suggest that while alignment training yields normative value convergence, it does not eliminate the human-like incoherence between knowing and acting upon values.

</details>


### [4] [Explaining Generalization of AI-Generated Text Detectors Through Linguistic Analysis](https://arxiv.org/abs/2601.07974)
*Yuxi Xia,Kinga Stańczak,Benjamin Roth*

Main category: cs.CL

TL;DR: AI文本检测器在跨提示、跨模型、跨领域泛化时性能下降，本文通过系统性的语言特征分析揭示了泛化性能与特定语言特征（如时态使用和代词频率）之间的关联。


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测器在领域内基准测试中表现良好，但在面对不同生成条件（如未见过的提示、模型家族或领域）时泛化能力不足。虽然先前研究已报告了这些泛化差距，但对根本原因的理解有限。

Method: 构建了一个全面的基准测试，涵盖6种提示策略、7个大语言模型和4个领域数据集，生成了多样的人类和AI生成文本。在不同生成设置上微调基于分类的检测器，评估其跨提示、跨模型和跨数据集的泛化能力。通过计算80个语言特征在训练和测试条件之间的特征偏移与泛化准确率的相关性，解释性能差异。

Result: 分析显示，特定检测器和评估条件的泛化性能与语言特征（如时态使用和代词频率）显著相关。这些发现为理解AI文本检测器的泛化行为提供了系统性解释。

Conclusion: 通过语言特征分析可以解释AI文本检测器的泛化性能差异，特定语言特征（如时态和代词使用）与检测器在不同生成条件下的泛化能力密切相关。这为改进检测器的泛化性能提供了重要见解。

Abstract: AI-text detectors achieve high accuracy on in-domain benchmarks, but often struggle to generalize across different generation conditions such as unseen prompts, model families, or domains. While prior work has reported these generalization gaps, there are limited insights about the underlying causes. In this work, we present a systematic study aimed at explaining generalization behavior through linguistic analysis. We construct a comprehensive benchmark that spans 6 prompting strategies, 7 large language models (LLMs), and 4 domain datasets, resulting in a diverse set of human- and AI-generated texts. Using this dataset, we fine-tune classification-based detectors on various generation settings and evaluate their cross-prompt, cross-model, and cross-dataset generalization. To explain the performance variance, we compute correlations between generalization accuracies and feature shifts of 80 linguistic features between training and test conditions. Our analysis reveals that generalization performance for specific detectors and evaluation conditions is significantly associated with linguistic features such as tense usage and pronoun frequency.

</details>


### [5] [Cross-Cultural Expert-Level Art Critique Evaluation with Vision-Language Models](https://arxiv.org/abs/2601.07984)
*Haorui Yu,Ramon Ruiz-Dolz,Xuehang Wen,Fengrui Zhang,Qiufeng Yi*

Main category: cs.CL

TL;DR: 提出三层评估框架，用于评估视觉语言模型在跨文化艺术评论中的文化理解能力，通过校准评分减少误差，发现自动指标不可靠且存在西方样本偏见。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉感知方面表现出色，但其在艺术中解释文化意义的能力尚未得到充分验证。需要系统评估模型对跨文化艺术的理解深度和文化敏感性。

Method: 提出三层评估框架：第一层离线计算自动覆盖度和风险指标；第二层使用单一主评委按五个维度进行基于量规的评分；第三层通过等渗回归将第二层总分校准到人类评分，减少误差。

Result: 在152个样本的保留集上，MAE减少了5.2%。评估了15个VLM在294个专家锚点（涵盖六种文化传统）上的表现。发现自动指标不可靠，西方样本评分高于非西方样本，跨评委尺度不匹配使得简单平均不可靠。

Conclusion: 该框架输出校准后的文化理解分数，用于模型选择和文化差距诊断，同时提供维度级诊断和风险指标。强调需要单一主评委和显式校准来解决评分尺度不匹配问题。

Abstract: Vision-Language Models (VLMs) excel at visual perception, yet their ability to interpret cultural meaning in art remains under-validated. We present a tri-tier evaluation framework for cross-cultural art-critique assessment: Tier I computes automated coverage and risk indicators offline; Tier II applies rubric-based scoring using a single primary judge across five dimensions; and Tier III calibrates the Tier II aggregate score to human ratings via isotonic regression, yielding a 5.2% reduction in MAE on a 152-sample held-out set. The framework outputs a calibrated cultural-understanding score for model selection and cultural-gap diagnosis, together with dimension-level diagnostics and risk indicators. We evaluate 15 VLMs on 294 expert anchors spanning six cultural traditions. Key findings are that (i) automated metrics are unreliable proxies for cultural depth, (ii) Western samples score higher than non-Western samples under our sampling and rubric, and (iii) cross-judge scale mismatch makes naive score averaging unreliable, motivating a single primary judge with explicit calibration. Dataset and code are available in the supplementary materials.

</details>


### [6] [Multilingual, Multimodal Pipeline for Creating Authentic and Structured Fact-Checked Claim Dataset](https://arxiv.org/abs/2601.07985)
*Z. Melce Hüsünbeyi,Virginie Mouilleron,Leonie Uhling,Daniel Foppe,Tatjana Scheffler,Djamé Seddah*

Main category: cs.CL

TL;DR: 该论文提出了一种构建多语言多模态事实核查数据集的新方法，通过聚合ClaimReview数据、抓取完整辟谣文章、标准化裁决结果，并利用大语言模型进行证据提取和理由生成，创建了法语和德语的事实核查数据集。


<details>
  <summary>Details</summary>
Motivation: 在线平台上的虚假信息迅速扩散，迫切需要强大、最新、可解释且多语言的事实核查资源。现有数据集范围有限，通常缺乏多模态证据、结构化标注以及声明、证据和裁决之间的详细联系。

Method: 开发了全面的数据收集和处理流程：聚合ClaimReview数据源，抓取完整辟谣文章，标准化异质声明裁决，并用结构化元数据和对齐的视觉内容进行丰富。使用最先进的大语言模型和多模态大语言模型进行：(i) 预定义证据类别下的证据提取；(ii) 将证据与裁决联系起来的理由生成。

Result: 通过G-Eval和人工评估表明，该流程能够对不同组织或媒体市场的事实核查实践进行细粒度比较，有助于开发更可解释和基于证据的事实核查模型，并为未来多语言多模态虚假信息验证研究奠定基础。

Conclusion: 该研究提出的多语言多模态事实核查数据集构建方法，解决了现有数据集的局限性，为开发更强大、可解释的事实核查系统提供了重要资源，推动了多语言多模态虚假信息验证研究的发展。

Abstract: The rapid proliferation of misinformation across online platforms underscores the urgent need for robust, up-to-date, explainable, and multilingual fact-checking resources. However, existing datasets are limited in scope, often lacking multimodal evidence, structured annotations, and detailed links between claims, evidence, and verdicts. This paper introduces a comprehensive data collection and processing pipeline that constructs multimodal fact-checking datasets in French and German languages by aggregating ClaimReview feeds, scraping full debunking articles, normalizing heterogeneous claim verdicts, and enriching them with structured metadata and aligned visual content. We used state-of-the-art large language models (LLMs) and multimodal LLMs for (i) evidence extraction under predefined evidence categories and (ii) justification generation that links evidence to verdicts. Evaluation with G-Eval and human assessment demonstrates that our pipeline enables fine-grained comparison of fact-checking practices across different organizations or media markets, facilitates the development of more interpretable and evidence-grounded fact-checking models, and lays the groundwork for future research on multilingual, multimodal misinformation verification.

</details>


### [7] [VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding](https://arxiv.org/abs/2601.07986)
*Haorui Yu,Ramon Ruiz-Dolz,Diji Yang,Hang He,Fengrui Zhang,Qiufeng Yi*

Main category: cs.CL

TL;DR: VULCA-Bench是一个多文化艺术评论基准，用于评估视觉语言模型在超越表面视觉感知的文化理解能力，包含7,410个图像-评论对，涵盖八种文化传统，采用五层文化理解框架进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有VLM基准主要评估L1-L2能力（物体识别、场景描述和事实问答），而低估了高阶文化解释能力。需要建立一个专门评估VLM文化理解能力的基准。

Method: 创建包含7,410个匹配图像-评论对的数据集，涵盖八种文化传统，支持中英双语。采用五层文化理解框架（L1-L5：从视觉感知到哲学美学），实例化为225个文化特定维度，并由专家撰写双语评论。

Result: 初步结果表明，高层推理（L3-L5）比视觉和技术分析（L1-L2）更具挑战性。数据集、评估脚本和标注工具已在补充材料中以CC BY 4.0许可提供。

Conclusion: VULCA-Bench填补了VLM文化理解评估的空白，为评估模型超越表面视觉感知的文化解释能力提供了系统框架和资源。

Abstract: We introduce VULCA-Bench, a multicultural art-critique benchmark for evaluating Vision-Language Models' (VLMs) cultural understanding beyond surface-level visual perception. Existing VLM benchmarks predominantly measure L1-L2 capabilities (object recognition, scene description, and factual question answering) while under-evaluate higher-order cultural interpretation. VULCA-Bench contains 7,410 matched image-critique pairs spanning eight cultural traditions, with Chinese-English bilingual coverage. We operationalise cultural understanding using a five-layer framework (L1-L5, from Visual Perception to Philosophical Aesthetics), instantiated as 225 culture-specific dimensions and supported by expert-written bilingual critiques. Our pilot results indicate that higher-layer reasoning (L3-L5) is consistently more challenging than visual and technical analysis (L1-L2). The dataset, evaluation scripts, and annotation tools are available under CC BY 4.0 in the supplementary materials.

</details>


### [8] [From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP](https://arxiv.org/abs/2601.07988)
*Adithya V Ganesan,Vasudha Varadarajan,Oscar NE Kjell,Whitney R Ringwald,Scott Feltman,Benjamin J Luft,Roman Kotov,Ryan L Boyd,H Andrew Schwartz*

Main category: cs.CL

TL;DR: 论文提出纵向建模与评估范式，针对嵌套于作者且按时间排序的行为序列，更新NLP管道的四个部分：评估划分、准确度指标、序列输入和模型内部结构。


<details>
  <summary>Details</summary>
Motivation: 传统NLP将文档视为独立无序样本，但在纵向研究中，文档嵌套于作者并按时间排序形成行为序列，需要更符合生态效度的建模与评估方法。

Method: 提出纵向建模评估范式，更新四个部分：1) 按人群(横断面)和时间(前瞻性)划分评估；2) 分离个体间差异与个体内动态的准确度指标；3) 默认包含历史的序列输入；4) 支持不同粒度潜在状态的模型内部结构。

Result: 在包含238名参与者的17k篇日记转录与PTSD症状严重程度数据上，传统文档级评估与提出的生态效度建模评估得出显著不同甚至相反的结论。

Conclusion: 需要从词序列评估转向行为序列范式，推动NLP向更符合现实世界纵向数据特性的方向发展。

Abstract: While NLP typically treats documents as independent and unordered samples, in longitudinal studies, this assumption rarely holds: documents are nested within authors and ordered in time, forming person-indexed, time-ordered $\textit{behavioral sequences}$. Here, we demonstrate the need for and propose a longitudinal modeling and evaluation paradigm that consequently updates four parts of the NLP pipeline: (1) evaluation splits aligned to generalization over people ($\textit{cross-sectional}$) and/or time ($\textit{prospective}$); (2) accuracy metrics separating between-person differences from within-person dynamics; (3) sequence inputs to incorporate history by default; and (4) model internals that support different $\textit{coarseness}$ of latent state over histories (pooled summaries, explicit dynamics, or interaction-based models). We demonstrate the issues ensued by traditional pipeline and our proposed improvements on a dataset of 17k daily diary transcripts paired with PTSD symptom severity from 238 participants, finding that traditional document-level evaluation can yield substantially different and sometimes reversed conclusions compared to our ecologically valid modeling and evaluation. We tie our results to a broader discussion motivating a shift from word-sequence evaluation toward $\textit{behavior-sequence}$ paradigms for NLP.

</details>


### [9] [DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs](https://arxiv.org/abs/2601.07994)
*Nayoung Choi,Jonathan Zhang,Jinho D. Choi*

Main category: cs.CL

TL;DR: DyCP是一种轻量级上下文管理方法，通过动态分割和检索相关记忆来提升长对话中LLM的响应质量和速度。


<details>
  <summary>Details</summary>
Motivation: 随着对话长度增加，LLM的响应延迟增加且答案质量下降。现有方法要么需要额外的LLM调用来构建记忆，要么离线构建记忆而不考虑当前用户话语，导致效率低下或破坏对话连续性。

Method: DyCP在查询时动态分割和检索相关记忆，保留对话的顺序结构而不需要预定义主题边界，支持高效、自适应的上下文检索。

Result: 在三个长对话基准测试（LoCoMo、MT-Bench+、SCM4LLMs）和多个LLM上，DyCP一致提高了答案质量并减少了响应延迟。

Conclusion: 现代LLM虽然扩展了上下文窗口，但实际长上下文处理能力仍有差距，因此有效的上下文管理仍然至关重要。DyCP为此提供了一种有效的解决方案。

Abstract: Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows, making effective context management essential. However, existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. We introduce DyCP, a lightweight context management method that dynamically segment and retrieve relevant memory at query time. It preserves the sequential structure of dialogue without predefined topic boundaries and supports efficient, adaptive context retrieval. Across three long-form dialogue benchmarks, LoCoMo, MT-Bench+, and SCM4LLMs, and multiple LLMs, DyCP consistently improves answer quality while reducing response latency. We also examine the gap between modern LLMs' expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management.

</details>


### [10] [Is Sentiment Banana-Shaped? Exploring the Geometry and Portability of Sentiment Concept Vectors](https://arxiv.org/abs/2601.07995)
*Laurits Lyngbaek,Pascale Feldkamp,Yuri Bizzoni,Kristoffer L. Nielbo,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: CVP方法在跨领域情感分析中表现良好，但其线性假设仅是近似成立，有进一步改进空间


<details>
  <summary>Details</summary>
Motivation: 人文领域的情感分析需要情境化、连续的情感分数，CVP方法虽然提供了解决方案，但其跨领域可移植性和基本假设尚未充分研究

Method: 评估CVP在不同体裁、历史时期、语言和情感维度上的表现，并检验其线性假设的有效性

Result: CVP在一个语料库上训练的概念向量能很好地迁移到其他语料库，性能损失很小；但线性假设仅是近似成立

Conclusion: CVP是一种可移植的方法，能有效捕捉可泛化的模式，但其线性假设仅是近似成立，表明有进一步发展的潜力

Abstract: Use cases of sentiment analysis in the humanities often require contextualized, continuous scores. Concept Vector Projections (CVP) offer a recent solution: by modeling sentiment as a direction in embedding space, they produce continuous, multilingual scores that align closely with human judgments. Yet the method's portability across domains and underlying assumptions remain underexplored. We evaluate CVP across genres, historical periods, languages, and affective dimensions, finding that concept vectors trained on one corpus transfer well to others with minimal performance loss. To understand the patterns of generalization, we further examine the linearity assumption underlying CVP. Our findings suggest that while CVP is a portable approach that effectively captures generalizable patterns, its linearity assumption is approximate, pointing to potential for further development.

</details>


### [11] [LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback](https://arxiv.org/abs/2601.08003)
*Weiyue Li,Mingxiao Song,Zhenda Shen,Dachuan Zhao,Yunfan Long,Yi Li,Yongce Li,Ruyi Yang,Mengyu Wang*

Main category: cs.CL

TL;DR: LLM Review框架通过盲审机制解决多智能体协作中的创意同质化问题，在科幻写作任务上超越基线方法，小模型配合该框架可超越大模型


<details>
  <summary>Details</summary>
Motivation: 大语言模型在创意生成上表现不佳，而现有的多智能体框架虽然能提升推理能力，却会导致内容同质化，反而抑制了创造力

Method: 提出LLM Review框架，采用盲审机制：智能体交换针对性反馈但独立修改，保持创意轨迹的多样性；同时构建SciFi-100科幻写作数据集，结合LLM评分、人工标注和基于规则的新颖性指标进行综合评估

Result: 实验表明LLM Review持续优于多智能体基线方法，较小的模型配合该框架可以超越较大的单智能体模型，表明交互结构可以替代模型规模

Conclusion: 通过适当的交互结构设计，可以解决多智能体协作中的创意同质化问题，提升创意生成质量，且交互结构的重要性可能超过模型规模本身

Abstract: Large Language Models (LLMs) often struggle with creative generation, and multi-agent frameworks that improve reasoning through interaction can paradoxically hinder creativity by inducing content homogenization. We introduce LLM Review, a peer-review-inspired framework implementing Blind Peer Review: agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. To enable rigorous evaluation, we propose SciFi-100, a science fiction writing dataset with a unified framework combining LLM-as-a-judge scoring, human annotation, and rule-based novelty metrics. Experiments demonstrate that LLM Review consistently outperforms multi-agent baselines, and smaller models with our framework can surpass larger single-agent models, suggesting interaction structure may substitute for model scale.

</details>


### [12] [Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models](https://arxiv.org/abs/2601.08058)
*Zhenghao He,Guangzhi Xiong,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: 研究发现大语言模型的推理能力可以通过干预内部表征来激活，CoT提示只是其中一种有效方式而非必要条件。


<details>
  <summary>Details</summary>
Motivation: 尽管CoT提示提高了大语言模型的推理性能，但尚不清楚其工作原理以及是否为触发推理的唯一机制。

Method: 使用稀疏自编码器分析并干预大语言模型的内部表征，识别与推理行为因果相关的潜在特征。

Result: 通过干预单个推理相关潜在特征即可显著提高准确性，无需显式CoT提示；对于大模型，潜在特征引导能达到与标准CoT相当的性能且输出更高效。

Conclusion: 大语言模型的多步推理由可外部激活的潜在内部激活支持，CoT提示是激活此机制的有效但非唯一方式。

Abstract: Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in large language models. In this work, we study this question by directly analyzing and intervening on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features that are causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, we find that steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. We further observe that this reasoning-oriented internal state is triggered early in generation and can override prompt-level instructions that discourage explicit reasoning. Overall, our results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism rather than its necessary cause.

</details>


### [13] [Universal computation is intrinsic to language model decoding](https://arxiv.org/abs/2601.08061)
*Alex Lewandowski,Marlos C. Machado,Dale Schuurmans*

Main category: cs.CL

TL;DR: 语言模型通过自回归链式输出可实现通用计算，即使随机初始化的模型在训练前就具备这种能力，训练主要改善可编程性而非计算表达能力。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型的计算能力边界，澄清关于语言模型是否能执行通用计算的科学争议，理解训练对模型计算能力的影响。

Method: 证明语言模型的自回归输出链式组合足以执行通用计算，通过理论证明和实验展示随机初始化语言模型在训练前就能模拟任何算法执行。

Result: 语言模型具备通用计算能力，这种能力在随机初始化时已存在，训练主要改善可编程性（即找到合适提示的难易程度），而非创造计算表达能力。

Conclusion: 语言模型本质上是通用计算器，训练的作用是使其计算能力更容易通过自然语言接口访问，而非赋予计算能力本身。

Abstract: Language models now provide an interface to express and often solve general problems in natural language, yet their ultimate computational capabilities remain a major topic of scientific debate. Unlike a formal computer, a language model is trained to autoregressively predict successive elements in human-generated text. We prove that chaining a language model's autoregressive output is sufficient to perform universal computation. That is, a language model can simulate the execution of any algorithm on any input. The challenge of eliciting desired computational behaviour can thus be reframed in terms of programmability: the ease of finding a suitable prompt. Strikingly, we demonstrate that even randomly initialized language models are capable of universal computation before training. This implies that training does not give rise to computational expressiveness -- rather, it improves programmability, enabling a natural language interface for accessing these intrinsic capabilities.

</details>


### [14] [Calibration Is Not Enough: Evaluating Confidence Estimation Under Language Variations](https://arxiv.org/abs/2601.08064)
*Yuxi Xia,Dennis Ulmer,Terra Blevins,Yihong Liu,Hinrich Schütze,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文提出一个全面的置信度估计评估框架，包含三个新维度：对提示扰动的鲁棒性、对语义等价答案的稳定性、以及对语义不同答案的敏感性，发现现有方法在这些方面存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法主要关注校准和区分能力，但忽视了在LLM和语言变体环境下的重要问题：置信度应该在语义等价的提示或答案变化下保持一致，而在答案含义不同时应该变化。

Method: 提出一个综合评估框架，从三个新维度评估置信度估计质量：1) 对提示扰动的鲁棒性；2) 对语义等价答案的稳定性；3) 对语义不同答案的敏感性。

Result: 研究发现，即使在校准和区分方面表现良好的常见置信度估计方法，也往往在提示扰动下不够鲁棒，或对答案变化不够敏感，存在明显缺陷。

Conclusion: 该框架揭示了现有置信度估计评估在真实世界LLM应用中的局限性，为选择和设计更可靠的置信度估计方法提供了实用指导。

Abstract: Confidence estimation (CE) indicates how reliable the answers of large language models (LLMs) are, and can impact user trust and decision-making. Existing work evaluates CE methods almost exclusively through calibration, examining whether stated confidence aligns with accuracy, or discrimination, whether confidence is ranked higher for correct predictions than incorrect ones. However, these facets ignore pitfalls of CE in the context of LLMs and language variation: confidence estimates should remain consistent under semantically equivalent prompt or answer variations, and should change when the answer meaning differs. Therefore, we present a comprehensive evaluation framework for CE that measures their confidence quality on three new aspects: robustness of confidence against prompt perturbations, stability across semantic equivalent answers, and sensitivity to semantically different answers. In our work, we demonstrate that common CE methods for LLMs often fail on these metrics: methods that achieve good performance on calibration or discrimination are not robust to prompt variations or are not sensitive to answer changes. Overall, our framework reveals limitations of existing CE evaluations relevant for real-world LLM use cases and provides practical guidance for selecting and designing more reliable CE methods.

</details>


### [15] [AdaJudge: Adaptive Multi-Perspective Judging for Reward Modeling](https://arxiv.org/abs/2601.08097)
*Yongliang Miao,Yangyang Liang,Mengnan Du*

Main category: cs.CL

TL;DR: AdaJudge是一个用于奖励建模的统一框架，通过联合适应表示和聚合来解决传统静态池化策略的问题，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前奖励建模主要依赖静态池化策略将序列压缩为标量分数，存在两个关键限制：1）静态归纳偏置与任务依赖的偏好信号不匹配；2）表示不匹配，因为骨干网络是为生成而非细粒度判别优化的。

Method: AdaJudge框架联合适应表示和聚合：1）通过门控细化块将骨干表示精炼为面向判别的空间；2）用自适应多视图池化模块替换静态读出，动态路由和组合证据。

Result: 在RM-Bench和JudgeBench上的广泛实验表明，AdaJudge优于强大的现成奖励模型和传统池化基线。

Conclusion: AdaJudge通过联合适应表示和聚合，有效解决了传统奖励建模中的静态池化限制，为对齐大语言模型与人类偏好提供了更有效的框架。

Abstract: Reward modeling is essential for aligning large language models with human preferences, yet predominant architectures rely on a static pooling strategy to condense sequences into scalar scores. This paradigm, however, suffers from two key limitations: a static inductive bias that misaligns with task-dependent preference signals, and a representational mismatch, as the backbone is optimized for generation rather than fine-grained discrimination. To address this, we propose AdaJudge, a unified framework that jointly adapts representation and aggregation. AdaJudge first refines backbone representations into a discrimination-oriented space via gated refinement blocks. It then replaces the static readout with an adaptive multi-view pooling module that dynamically routes and combines evidence. Extensive experiments on RM-Bench and JudgeBench show that AdaJudge outperforms strong off-the-shelf reward models and traditional pooling baselines.

</details>


### [16] [Query Suggestion for Retrieval-Augmented Generation via Dynamic In-Context Learning](https://arxiv.org/abs/2601.08105)
*Fabian Spaeh,Tianyi Chen,Chen-Hao Chiang,Bin Shen*

Main category: cs.CL

TL;DR: 该论文首次研究面向智能RAG的查询建议问题，当用户问题超出知识范围时，系统会生成相似且可回答的查询建议，通过动态少样本学习提升建议质量。


<details>
  <summary>Details</summary>
Motivation: 当前智能RAG系统在处理超出知识范围的问题时容易产生幻觉，虽然有护栏框架阻止不可回答的问题，但缺乏为用户提供可回答查询建议的研究，这限制了用户与RAG系统的交互体验。

Method: 提出鲁棒动态少样本学习方法，从相关工作流中检索示例，系统可以自学习（如基于历史用户查询），无需大量标注数据即可在实际中应用。

Result: 在三个基准数据集上评估，基于两个真实世界用户查询收集的无标注问题数据集，实验表明该方法能产生更相关且可回答的建议，优于少样本和仅检索的基线方法。

Conclusion: 该研究首次系统探索了智能RAG的查询建议问题，提出的方法能生成更优质的建议，使与智能RAG的用户交互更安全有效，为实际应用提供了可行方案。

Abstract: Retrieval-augmented generation with tool-calling agents (agentic RAG) has become increasingly powerful in understanding, processing, and responding to user queries. However, the scope of the grounding knowledge is limited and asking questions that exceed this scope may lead to issues like hallucination. While guardrail frameworks aim to block out-of-scope questions (Rodriguez et al., 2024), no research has investigated the question of suggesting answerable queries in order to complete the user interaction.
  In this paper, we initiate the study of query suggestion for agentic RAG. We consider the setting where user questions are not answerable, and the suggested queries should be similar to aid the user interaction. Such scenarios are frequent for tool-calling LLMs as communicating the restrictions of the tools or the underlying datasets to the user is difficult, and adding query suggestions enhances the interaction with the RAG agent. As opposed to traditional settings for query recommendations such as in search engines, ensuring that the suggested queries are answerable is a major challenge due to the RAG's multi-step workflow that demands a nuanced understanding of the RAG as a whole, which the executing LLM lacks. As such, we introduce robust dynamic few-shot learning which retrieves examples from relevant workflows. We show that our system can be self-learned, for instance on prior user queries, and is therefore easily applicable in practice. We evaluate our approach on three benchmark datasets based on two unlabeled question datasets collected from real-world user queries. Experiments on real-world datasets confirm that our method produces more relevant and answerable suggestions, outperforming few-shot and retrieval-only baselines, and thus enable safer, more effective user interaction with agentic RAG.

</details>


### [17] [Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought](https://arxiv.org/abs/2601.08108)
*Bowen Li,Ziqi Xu,Jing Ren,Renqiang Luo,Xikun Zhang,Xiuzhen Zhang,Yongli Ren,Feng Xia*

Main category: cs.CL

TL;DR: ACPS框架通过因果推断自适应选择干预策略，用简洁的Sketch-of-Thought替代冗长的Chain-of-Thought，在多种推理任务中实现高效、准确且通用的推理。


<details>
  <summary>Details</summary>
Motivation: 现有提示方法（如Chain-of-Thought）存在token使用过多和跨任务泛化能力有限的问题，需要更高效、通用的推理框架。

Method: 提出自适应因果提示框架ACPS，利用结构因果模型推断查询对答案的因果效应，自适应选择标准前门或条件前门调整干预策略，并用简洁的Sketch-of-Thought替代冗长的CoT。

Result: 在多个推理基准测试和LLMs上的实验表明，ACPS在准确性、鲁棒性和计算效率方面持续优于现有提示基线方法。

Conclusion: ACPS框架通过因果推理和自适应干预选择，实现了跨异构任务的高效通用推理，显著减少了token使用和推理成本。

Abstract: Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention (i.e., standard front-door and conditional front-door adjustments). This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.

</details>


### [18] [Attention Projection Mixing and Exogenous Anchors](https://arxiv.org/abs/2601.08131)
*Jonathan Su*

Main category: cs.CL

TL;DR: ExoFormer通过引入外部锚定投影解耦Transformer中早期层同时作为稳定参考和计算模块的冲突，在保持性能的同时提高了数据效率和注意力稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer中早期层注意力投影被重复用作残差连接时面临根本矛盾：第一层必须同时作为所有深层稳定参考和有效计算模块。这种双重角色限制了模型性能。

Method: 提出ExoFormer，在序列层栈外学习专用的外部锚定投影，将锚定角色与计算细化解耦。采用统一的归一化混合框架，研究不同系数粒度（元素级、头级、标量级）在所有注意力路径（查询、键、值、门控逻辑）中的应用。

Result: ExoFormer变体在性能上始终优于内部锚定对应模型，动态变体在下游任务准确率上比基线提高2.13个百分点，数据效率更高（用1.84倍更少的token达到相同验证损失），注意力下沉减少2倍。但所有变体都表现出表征崩溃迹象。

Conclusion: ExoFormer通过外部锚定机制有效解决了Transformer中的角色冲突问题，外部锚定保留了必要的token身份信息，使各层能专注于计算细化。表征崩溃现象支持了"卸载假设"：外部锚定承担了身份保持功能。

Abstract: Transformers that reuse early-layer attention projections as residuals face a fundamental tension: the first layer must simultaneously serve as a stable reference for all deeper layers and as an effective computational block. To resolve this, we propose ExoFormer, which learns dedicated exogenous anchor projections outside the sequential layer stack, decoupling the anchor role from computational refinement. Through a unified normalized mixing framework (studying different coefficient granularities: elementwise, headwise, scalar) across all attention pathways (queries, keys, values, and gate logits), ExoFormer variants consistently outperform their internal-anchor counterparts. Moreover, the dynamic variant achieves a 2.13-point increase in downstream accuracy over the baseline and demonstrates superior data efficiency, matching baseline validation loss with 1.84x fewer tokens. ExoFormer also achieves a 2x reduction in attention sink compared to standard Gated Attention. Paradoxically, all ExoFormer variants exhibit signs of representation collapse. We explain this via an Offloading Hypothesis: external anchors preserve essential token identity, allowing layers to specialize exclusively in computational refinement. We release codes and models to facilitate future research.

</details>


### [19] [How Reliable are Confidence Estimators for Large Reasoning Models? A Systematic Benchmark on High-Stakes Domains](https://arxiv.org/abs/2601.08134)
*Reza Khanmohammadi,Erfan Miahi,Simerjot Kaur,Ivan Brugere,Charese H. Smiley,Kundan Thind,Mohammad M. Ghassemi*

Main category: cs.CL

TL;DR: 论文提出了RMCB基准，用于评估大型推理模型的置信度估计方法，发现文本编码器在区分能力上最优，而结构感知模型在校准上最优，两者存在权衡关系。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在关键领域的误校准问题降低了其可靠性，需要准确估计其长格式、多步骤输出的置信度，但目前缺乏全面的评估基准。

Method: 构建了RMCB基准，包含347,496个推理轨迹，来自6个不同架构的大型推理模型，涵盖临床、金融、法律、数学推理等关键领域。评估了十多种基于表示的方法，包括序列、图基和文本基架构。

Result: 发现区分能力（AUROC）和校准（ECE）之间存在权衡：文本编码器获得最佳AUROC（0.672），而结构感知模型获得最佳ECE（0.148），没有单一方法在两方面都占优。增加架构复杂性并不总是优于简单序列基线。

Conclusion: 这项工作为置信度估计任务提供了最全面的基准，建立了严格的基线，并展示了当前基于表示的方法范式的局限性。

Abstract: The miscalibration of Large Reasoning Models (LRMs) undermines their reliability in high-stakes domains, necessitating methods to accurately estimate the confidence of their long-form, multi-step outputs. To address this gap, we introduce the Reasoning Model Confidence estimation Benchmark (RMCB), a public resource of 347,496 reasoning traces from six popular LRMs across different architectural families. The benchmark is constructed from a diverse suite of datasets spanning high-stakes domains, including clinical, financial, legal, and mathematical reasoning, alongside complex general reasoning benchmarks, with correctness annotations provided for all samples. Using RMCB, we conduct a large-scale empirical evaluation of over ten distinct representation-based methods, spanning sequential, graph-based, and text-based architectures. Our central finding is a persistent trade-off between discrimination (AUROC) and calibration (ECE): text-based encoders achieve the best AUROC (0.672), while structurally-aware models yield the best ECE (0.148), with no single method dominating both. Furthermore, we find that increased architectural complexity does not reliably outperform simpler sequential baselines, suggesting a performance ceiling for methods relying solely on chunk-level hidden states. This work provides the most comprehensive benchmark for this task to date, establishing rigorous baselines and demonstrating the limitations of current representation-based paradigms.

</details>


### [20] [Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training](https://arxiv.org/abs/2601.08141)
*Muhammad Taimoor Hassan,Jawad Ahmed,Muhammad Awais*

Main category: cs.CL

TL;DR: Qalb：针对乌尔都语优化的语言模型，通过两阶段训练显著提升乌尔都语NLP任务性能


<details>
  <summary>Details</summary>
Motivation: 乌尔都语作为2.3亿人使用的语言，在多语言模型中表现不佳，现有模型难以处理其复杂的形态、从右到左的Nastaliq文字和丰富的文学传统，需要专门的语言模型

Method: 两阶段方法：1）在LLaMA 3.1 8B基础上，使用19.7亿token（18.4亿乌尔都语+1.4亿英语）进行持续预训练；2）在Alif Urdu-instruct数据集上进行监督微调

Result: Qalb在乌尔都语基准测试中加权平均得分90.34，比之前的SOTA模型Alif-1.0-Instruct（87.1）提高3.24分，比基础LLaMA-3.1 8B-Instruct提高44.64分，在七项任务中达到最先进水平

Conclusion: 在多样化高质量语言数据上进行持续预训练，结合有针对性的指令微调，能有效将基础模型适配到低资源语言，为乌尔都语NLP提供了强大的解决方案

Abstract: Despite remarkable progress in large language models, Urdu-a language spoken by over 230 million people-remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks, struggling with the language's complex morphology, right-to-left Nastaliq script, and rich literary traditions. Even the base LLaMA-3.1 8B-Instruct model shows limited capability in generating fluent, contextually appropriate Urdu text. We introduce Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Starting from LLaMA 3.1 8B, we perform continued pre-training on a dataset of 1.97 billion tokens. This corpus comprises 1.84 billion tokens of diverse Urdu text-spanning news archives, classical and contemporary literature, government documents, and social media-combined with 140 million tokens of English Wikipedia data to prevent catastrophic forgetting. We then fine-tune the resulting model on the Alif Urdu-instruct dataset. Through extensive evaluation on Urdu-specific benchmarks, Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model (87.1) by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance with comprehensive evaluation across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning. Our results demonstrate that continued pre-training on diverse, high-quality language data, combined with targeted instruction fine-tuning, effectively adapts foundation models to low-resource languages.

</details>


### [21] [Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning](https://arxiv.org/abs/2601.08146)
*Khumaisa Nur'aini,Ayu Purwarianti,Alham Fikri Aji,Derry Wijaya*

Main category: cs.CL

TL;DR: CT-SFT：一种针对低资源语言的LLM适配方法，通过识别任务相关注意力头并仅更新这些头（加LayerNorm）进行跨语言迁移学习，减少灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 低资源语言适配LLM面临三大挑战：标注数据稀缺、全模型微调不稳定、跨语言持续微调可能导致灾难性遗忘。需要一种更高效、稳定的适配方法。

Method: CT-SFT方法：1) 使用标签平衡均值基线和任务方向相关性评分识别代理语言检查点中任务相关的稀疏注意力头集合；2) 通过头级梯度掩码仅更新这些识别出的注意力头（加上LayerNorm）进行目标语言迁移学习

Result: 在NusaX-Senti和XNLI任务上，CT-SFT相比持续全模型微调提高了跨语言准确率，同时仅更新少量模型参数。发现编辑-保留权衡：困难迁移偏向编辑电路头，简单迁移偏向近零更新（低相关性头），保留源机制。显著减少灾难性遗忘。

Conclusion: CT-SFT为低资源语言LLM适配提供了一种高效解决方案，通过选择性更新任务相关注意力头实现更好的跨语言性能，同时保持源语言能力，减少灾难性遗忘。

Abstract: Adapting LLMs to low-resource languages is difficult: labeled data is scarce, full-model fine-tuning is unstable, and continued cross-lingual tuning can cause catastrophic forgetting. We propose Circuit-Targeted Supervised Fine-Tuning (CT-SFT): a counterfactual-free adaptation of CD-T (Contextual Decomposition Transformer) that uses a label-balanced mean baseline and task-directional relevance scoring to identify a sparse set of task-relevant attention heads in a proxy-language checkpoint, then transfer learns to a target language by updating only those heads (plus LayerNorm) via head-level gradient masking. Across NusaX-Senti and XNLI, CT-SFT improves cross-lingual accuracy over continued full fine-tuning while updating only a small subset of model parameters. We find an editing-preserving trade-off: harder transfers favor editing circuit heads, while easier transfers often favor near-zero (i.e., low-relevance heads) updates, preserving the source mechanism. CT-SFT also substantially reduces catastrophic forgetting, preserving proxy/source-language competence during transfer.

</details>


### [22] [WISE-Flow: Workflow-Induced Structured Experience for Self-Evolving Conversational Service Agents](https://arxiv.org/abs/2601.08158)
*Yuqing Zhou,Zhuoer Wang,Jie Yuan,Hong Wang,Samson Koelle,Ziwei Zhu,Wei Niu*

Main category: cs.CL

TL;DR: WISE-Flow：一个工作流中心框架，通过从历史服务交互中提取可重用程序经验，使LLM智能体能够自我进化，提升在用户服务环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体在新任务中容易出错，倾向于重复相同的失败模式，且运行间变异性大。通过特定环境训练或手动修补来修复故障成本高且难以扩展，需要一种能让智能体在用户服务环境中自我进化的方法。

Method: 提出WISE-Flow框架：1）从历史服务交互中提取可重用的程序经验，通过前提条件增强的动作块来诱导工作流；2）在部署时，将智能体的执行轨迹与检索到的工作流对齐；3）执行前提条件感知的可行性推理，实现基于状态的下一个动作。

Result: 在ToolSandbox和τ²-bench上的实验显示，该方法在不同基础模型上均能带来一致的性能提升。

Conclusion: WISE-Flow通过将历史交互转化为可重用工作流，使LLM智能体能够在用户服务环境中自我进化，有效解决了现有智能体的错误倾向和可扩展性问题。

Abstract: Large language model (LLM)-based agents are widely deployed in user-facing services but remain error-prone in new tasks, tend to repeat the same failure patterns, and show substantial run-to-run variability. Fixing failures via environment-specific training or manual patching is costly and hard to scale. To enable self-evolving agents in user-facing service environments, we propose WISE-Flow, a workflow-centric framework that converts historical service interactions into reusable procedural experience by inducing workflows with prerequisite-augmented action blocks. At deployment, WISE-Flow aligns the agent's execution trajectory to retrieved workflows and performs prerequisite-aware feasibility reasoning to achieve state-grounded next actions. Experiments on ToolSandbox and $τ^2$-bench show consistent improvement across base models.

</details>


### [23] [SwiftMem: Fast Agentic Memory via Query-aware Indexing](https://arxiv.org/abs/2601.08160)
*Anxin Tian,Yiming Li,Xing Li,Hui-Ling Zhen,Lei Chen,Xianzhi Yu,Zhenhua Dong,Mingxuan Yuan*

Main category: cs.CL

TL;DR: SwiftMem提出了一种查询感知的智能体记忆系统，通过时间和语义索引实现亚线性检索，解决了现有记忆系统全量检索导致的延迟瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能体记忆系统存在根本性限制：无论查询特性如何，都会在整个存储层执行穷举检索。这种暴力方法随着内存增长会造成严重的延迟瓶颈，阻碍实时智能体交互。

Method: SwiftMem采用查询感知的智能体记忆系统，通过专门的时间索引实现对数时间范围查询，以及语义DAG-Tag索引通过分层标签结构将查询映射到相关主题。还引入了嵌入-标签协同整合机制，基于语义聚类重新组织存储以提高缓存局部性。

Result: 在LoCoMo和LongMemEval基准测试中，SwiftMem相比最先进的基线方法实现了47倍的搜索加速，同时保持竞争性准确率，使内存增强的LLM智能体能够实际部署。

Conclusion: SwiftMem通过查询感知的索引方法有效解决了智能体记忆系统的检索延迟问题，为实时内存增强的LLM智能体提供了实用的解决方案。

Abstract: Agentic memory systems have become critical for enabling LLM agents to maintain long-term context and retrieve relevant information efficiently. However, existing memory frameworks suffer from a fundamental limitation: they perform exhaustive retrieval across the entire storage layer regardless of query characteristics. This brute-force approach creates severe latency bottlenecks as memory grows, hindering real-time agent interactions. We propose SwiftMem, a query-aware agentic memory system that achieves sub-linear retrieval through specialized indexing over temporal and semantic dimensions. Our temporal index enables logarithmic-time range queries for time-sensitive retrieval, while the semantic DAG-Tag index maps queries to relevant topics through hierarchical tag structures. To address memory fragmentation during growth, we introduce an embedding-tag co-consolidation mechanism that reorganizes storage based on semantic clusters to improve cache locality. Experiments on LoCoMo and LongMemEval benchmarks demonstrate that SwiftMem achieves 47$\times$ faster search compared to state-of-the-art baselines while maintaining competitive accuracy, enabling practical deployment of memory-augmented LLM agents.

</details>


### [24] [Relational Knowledge Distillation Using Fine-tuned Function Vectors](https://arxiv.org/abs/2601.08169)
*Andrea Kang,Yingnian Wu,Hongjing Lu*

Main category: cs.CL

TL;DR: 通过微调函数向量提升语言模型的关系表示能力，并引入复合函数向量增强类比推理性能


<details>
  <summary>Details</summary>
Motivation: 关系表示是智能系统理解世界的核心前提。现有因果中介分析得到的函数向量虽能捕捉任务表示，但仍有改进空间，特别是在关系表示和推理能力方面。

Method: 1. 使用少量示例（约20个词对）微调函数向量；2. 引入复合函数向量，即微调函数向量的加权组合；3. 在推理时将复合向量插入LLM激活中。

Result: 1. 微调后的函数向量在关系型词语补全任务上表现优于原始向量；2. 在关系词解码和语义关系的人类相似性判断对齐方面表现更好；3. 复合函数向量显著提升认知科学和SAT基准中的类比问题性能。

Conclusion: 激活修补作为编码和操作关系知识的可控机制具有巨大潜力，可同时提升大语言模型的可解释性和推理能力。

Abstract: Representing relations between concepts is a core prerequisite for intelligent systems to make sense of the world. Recent work using causal mediation analysis has shown that a small set of attention heads encodes task representation in in-context learning, captured in a compact representation known as the function vector. We show that fine-tuning function vectors with only a small set of examples (about 20 word pairs) yields better performance on relation-based word-completion tasks than using the original vectors derived from causal mediation analysis. These improvements hold for both small and large language models. Moreover, the fine-tuned function vectors yield improved decoding performance for relation words and show stronger alignment with human similarity judgments of semantic relations. Next, we introduce the composite function vector - a weighted combination of fine-tuned function vectors - to extract relational knowledge and support analogical reasoning. At inference time, inserting this composite vector into LLM activations markedly enhances performance on challenging analogy problems drawn from cognitive science and SAT benchmarks. Our results highlight the potential of activation patching as a controllable mechanism for encoding and manipulating relational knowledge, advancing both the interpretability and reasoning capabilities of large language models.

</details>


### [25] [Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering](https://arxiv.org/abs/2601.08176)
*Lavanya Prahallad,Sai Utkarsh Choudarypally,Pragna Prahallad,Pranathi Prahallad*

Main category: cs.CL

TL;DR: 研究探索提示设计对LLM政治问答清晰度自动评估的影响，发现GPT-5.2在链式思维+少样本提示下将清晰度预测准确率从56%提升至63%，但细粒度回避和主题检测仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM自动评估主要关注事实准确性，而政治问答中的清晰度评估同样重要。虽然已有数据集提供清晰度和回避性的人工标注，但提示设计对自动清晰度评估的影响尚未充分探索。

Method: 使用SemEval 2026共享任务的CLARITY数据集，比较GPT-3.5基线模型与GPT-5.2在三种提示策略下的表现：简单提示、链式思维提示、链式思维+少样本示例。评估指标包括准确率、类别指标和层次精确匹配。

Result: GPT-5.2在清晰度预测上始终优于GPT-3.5基线，链式思维+少样本提示将准确率从56%提升至63%。链式思维提示在回避性评估上达到最高准确率34%。主题识别方面，推理提示将准确率从60%提升至74%。

Conclusion: 提示设计能可靠提升高层次清晰度评估效果，但细粒度回避性评估和主题检测仍然具有挑战性，即使使用结构化推理提示也难以完全解决。

Abstract: Automatic evaluation of large language model (LLM) responses requires not only factual correctness but also clarity, particularly in political question-answering. While recent datasets provide human annotations for clarity and evasion, the impact of prompt design on automatic clarity evaluation remains underexplored. In this paper, we study prompt-based clarity evaluation using the CLARITY dataset from the SemEval 2026 shared task. We compare a GPT-3.5 baseline provided with the dataset against GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Model predictions are evaluated against human annotations using accuracy and class-wise metrics for clarity and evasion, along with hierarchical exact match. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56 percent to 63 percent under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy at 34 percent, though improvements are less stable across fine-grained evasion categories. We further evaluate topic identification and find that reasoning-based prompting improves accuracy from 60 percent to 74 percent relative to human annotations. Overall, our findings indicate that prompt design reliably improves high-level clarity evaluation, while fine-grained evasion and topic detection remain challenging despite structured reasoning prompts.

</details>


### [26] [Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis](https://arxiv.org/abs/2601.08196)
*Da Song,Yuheng Huang,Boqi Chen,Tianshuo Cong,Randy Goebel,Lei Ma,Foutse Khomh*

Main category: cs.CL

TL;DR: 论文提出LogiSafetyGen框架和LogiSafetyBench基准，用于评估LLM在自主执行任务时对隐含监管合规性的遵守情况，发现大模型虽功能正确但常忽视安全约束。


<details>
  <summary>Details</summary>
Motivation: 当前LLM集成到自主代理中能实现复杂工具使用，但在高风险领域，系统必须严格遵循超越简单功能正确性的监管标准。现有基准往往忽略隐含的监管合规性，无法评估LLM是否能自主执行强制性安全约束。

Method: 提出LogiSafetyGen框架：将非结构化监管规则转换为线性时序逻辑预言机，采用逻辑引导的模糊测试合成有效的安全关键轨迹。基于此构建LogiSafetyBench基准，包含240个人工验证的任务，要求LLM生成同时满足功能目标和隐含合规规则的Python程序。

Result: 对13个最先进LLM的评估显示：更大的模型虽然实现更好的功能正确性，但经常优先考虑任务完成而非安全性，导致不合规行为。

Conclusion: 需要开发能同时保证功能正确性和监管合规性的LLM系统，当前大模型在安全约束遵守方面存在明显不足，LogiSafetyBench为评估这一关键能力提供了有效工具。

Abstract: The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. However, existing benchmarks often overlook implicit regulatory compliance, thus failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To fill this gap, we introduce LogiSafetyGen, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, we construct LogiSafetyBench, a benchmark comprising 240 human-verified tasks that require LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art (SOTA) LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, which results in non-compliant behavior.

</details>


### [27] [Triplets Better Than Pairs: Towards Stable and Effective Self-Play Fine-Tuning for LLMs](https://arxiv.org/abs/2601.08198)
*Yibo Wang,Hai-Long Sun,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.CL

TL;DR: T-SPIN是一种改进的自对弈微调方法，通过引入历史优势和熵约束来解决SPIN的不稳定优化和训练-生成不一致问题，在数据稀缺情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: SPIN方法在迭代过程中当前奖励优势会逐渐消失导致优化不稳定，且参考策略的使用导致训练奖励公式与生成指标不一致。需要解决这些问题以提升自对弈微调的效果。

Method: 提出T-SPIN方法，包含两个关键设计：1) 除了当前优势外，还引入历史优势（迭代生成响应与初始策略生成的原型合成响应之间的比较）；2) 在自对弈框架中引入熵约束，支持无参考微调，消除训练-生成差异。

Result: 在各种任务上的实验结果表明，T-SPIN不仅性能优于SPIN，而且在迭代过程中保持稳定演化。与监督微调相比，仅使用25%的样本就能达到相当甚至更好的性能。

Conclusion: T-SPIN通过历史优势和熵约束有效解决了SPIN的局限性，在标注数据稀缺的情况下表现出色，为大规模语言模型的下游应用适配提供了更稳定有效的自对弈微调方法。

Abstract: Recently, self-play fine-tuning (SPIN) has been proposed to adapt large language models to downstream applications with scarce expert-annotated data, by iteratively generating synthetic responses from the model itself. However, SPIN is designed to optimize the current reward advantages of annotated responses over synthetic responses at hand, which may gradually vanish during iterations, leading to unstable optimization. Moreover, the utilization of reference policy induces a misalignment issue between the reward formulation for training and the metric for generation. To address these limitations, we propose a novel Triplet-based Self-Play fIne-tuNing (T-SPIN) method that integrates two key designs. First, beyond current advantages, T-SPIN additionally incorporates historical advantages between iteratively generated responses and proto-synthetic responses produced by the initial policy. Even if the current advantages diminish, historical advantages remain effective, stabilizing the overall optimization. Second, T-SPIN introduces the entropy constraint into the self-play framework, which is theoretically justified to support reference-free fine-tuning, eliminating the training-generation discrepancy. Empirical results on various tasks demonstrate not only the superior performance of T-SPIN over SPIN, but also its stable evolution during iterations. Remarkably, compared to supervised fine-tuning, T-SPIN achieves comparable or even better performance with only 25% samples, highlighting its effectiveness when faced with scarce annotated data.

</details>


### [28] [Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models](https://arxiv.org/abs/2601.08209)
*Rongji Li,Jian Xu,Xueqing Chen,Yisheng Yang,Jiayi Wang,Xingyu Chen,Chunyu Xie,Dawei Leng,Xu-Yao Zhang*

Main category: cs.CL

TL;DR: 提出GAG方法，将私有专业知识作为额外专家模态，通过紧凑表示级接口注入冻结基础模型，避免提示时证据序列化，实现即插即用专业化和可扩展多领域组合。


<details>
  <summary>Details</summary>
Motivation: 在生物医学、材料、金融等高风险领域部署大语言模型时，需要注入私有、领域特定的知识，这些知识具有专有性、快速演变性和公共预训练中代表性不足的特点。现有两种主要私有知识注入范式各有明显缺点：微调迭代成本高且存在灾难性遗忘风险；检索增强生成在专业私有语料库中脆弱，存在证据碎片化、检索漂移和长上下文压力等问题。

Method: 受多模态大语言模型将异构模态对齐到共享语义空间的启发，提出生成增强生成方法，将私有专业知识视为额外的专家模态，通过紧凑的表示级接口注入冻结的基础模型，避免提示时证据序列化，实现即插即用专业化和可扩展的多领域组合。

Result: 在两个私有科学问答基准测试（免疫学佐剂和催化材料）和混合领域评估中，GAG在两个基准测试上分别比强RAG基线提升15.34%和14.86%的专业性能，同时在六个开放通用基准测试上保持性能，并实现接近oracle选择激活的可扩展多领域部署。

Conclusion: GAG方法通过将私有专业知识作为额外模态注入，有效解决了现有私有知识注入方法的局限性，在保持基础模型通用能力的同时显著提升专业领域性能，支持可扩展的多领域部署。

Abstract: In domains such as biomedicine, materials, and finance, high-stakes deployment of large language models (LLMs) requires injecting private, domain-specific knowledge that is proprietary, fast-evolving, and under-represented in public pretraining. However, the two dominant paradigms for private knowledge injection each have pronounced drawbacks: fine-tuning is expensive to iterate, and continual updates risk catastrophic forgetting and general-capability regression; retrieval-augmented generation (RAG) keeps the base model intact but is brittle in specialized private corpora due to chunk-induced evidence fragmentation, retrieval drift, and long-context pressure that yields query-dependent prompt inflation. Inspired by how multimodal LLMs align heterogeneous modalities into a shared semantic space, we propose Generation-Augmented Generation (GAG), which treats private expertise as an additional expert modality and injects it via a compact, representation-level interface aligned to the frozen base model, avoiding prompt-time evidence serialization while enabling plug-and-play specialization and scalable multi-domain composition with reliable selective activation. Across two private scientific QA benchmarks (immunology adjuvant and catalytic materials) and mixed-domain evaluations, GAG improves specialist performance over strong RAG baselines by 15.34% and 14.86% on the two benchmarks, respectively, while maintaining performance on six open general benchmarks and enabling near-oracle selective activation for scalable multi-domain deployment.

</details>


### [29] [Towards Principled Design of Mixture-of-Experts Language Models under Memory and Inference Constraints](https://arxiv.org/abs/2601.08215)
*Seng Pei Liew,Kenta Shinzato,Yuyang Dong*

Main category: cs.CL

TL;DR: MoE模型性能主要由总参数量和专家稀疏度决定，而非仅考虑总参数和激活参数。研究发现应最大化总参数、最小化稀疏度和专家数量。


<details>
  <summary>Details</summary>
Motivation: 当前MoE语言模型设计仅考虑总参数（内存占用）和激活参数（推理成本），但研究发现这两个因素不足以描述最优架构，需要更系统的分析框架。

Method: 通过系统性研究，分析MoE性能与总参数(N_total)和专家稀疏度(s:=n_exp/n_topk)的关系，发现专家数量和top-k选择数不会在稀疏度中抵消。

Result: MoE性能主要由总参数和专家稀疏度决定，专家数量增加会轻微损害性能（因需减少核心模型维度以满足内存限制）。专家数量和top-k选择数不会在稀疏度中抵消。

Conclusion: 提出MoE设计原则：在给定约束下最大化总参数，同时最小化稀疏度（最大化top-k选择数）和专家数量，为MoE架构设计提供明确框架。

Abstract: Modern Mixture-of-Experts (MoE) language models are designed based on total parameters (memory footprint) and active parameters (inference cost). However, we find these two factors alone are insufficient to describe an optimal architecture. Through a systematic study, we demonstrate that MoE performance is primarily determined by total parameters ($N_{total}$) and expert sparsity ($s:=n_{exp}/n_{topk}$).
  Moreover, $n_{exp}$ and $n_{topk}$ do not "cancel out" within the sparsity ratio; instead, a larger total number of experts slightly penalizes performance by forcing a reduction in core model dimensions (depth and width) to meet memory constraints. This motivates a simple principle for MoE design which maximizes $N_{total}$ while minimizing $s$ (maximizing $n_{topk}$) and $n_{exp}$ under the given constraints. Our findings provide a robust framework for resolving architectural ambiguity and guiding MoE design.

</details>


### [30] [User-Oriented Multi-Turn Dialogue Generation with Tool Use at scale](https://arxiv.org/abs/2601.08225)
*Jungho Cho,Minbyul Jeong,Sungrae Park*

Main category: cs.CL

TL;DR: 提出用户导向的模拟框架，通过解耦任务生成与用户模拟器，生成更真实的多轮工具使用对话数据，解决现有任务导向方法交互不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型作为自主代理需要复杂多轮工具使用能力，但现有数据集受限于静态预定义工具集，且任务导向设计导致交互不足，无法反映真实人机协作的迭代特性。

Method: 开发用户导向模拟范式：1) 解耦任务生成与专用用户模拟器；2) 用户模拟器模仿人类行为规则（增量请求、逐轮反馈）；3) 构建可扩展的即插即用生成管道，可从任何状态启动生成；4) 支持单轨迹内完成多个任务。

Result: 生成更真实、扩展的多轮对话数据，反映真实世界问题解决的迭代特性，产生高密度数据集，捕捉人机交互的多方面需求。

Conclusion: 用户导向模拟框架能有效生成高质量、可扩展的多轮工具使用数据，弥补任务导向方法的不足，为大型推理模型的工具使用能力发展提供更好的数据支持。

Abstract: The recent paradigm shift toward large reasoning models (LRMs) as autonomous agents has intensified the demand for sophisticated, multi-turn tool-use capabilities. Yet, existing datasets and data-generation approaches are limited by static, predefined toolsets that cannot scale to the complexity of open-ended human-agent collaboration. To address this, we initially developed a framework for automated task-oriented multi-turn dialogue generation at scale, utilizing an LRM-based simulator to dynamically generate high-value, domain-specific tools to solve specified tasks. However, we observe that a purely task-oriented design often results in "solely task-solving" trajectories, where the agent completes the objective with minimal interaction, failing to generate the high turn-count conversations seen in realistic scenarios. To bridge this gap, we shift toward a user-oriented simulation paradigm. By decoupling task generation from a dedicated user simulator that mimics human behavioral rules - such as incremental request-making and turn-by-turn feedback - we facilitate more authentic, extended multi-turn dialogues that reflect the iterative nature of real-world problem solving. Our generation pipeline operates as a versatile, plug-and-play module capable of initiating generation from any state, ensuring high scalability in producing extended tool-use data. Furthermore, by facilitating multiple task completions within a single trajectory, it yields a high-density dataset that reflects the multifaceted demands of real-world human-agent interaction.

</details>


### [31] [Med-CoReasoner: Reducing Language Disparities in Medical Reasoning via Language-Informed Co-Reasoning](https://arxiv.org/abs/2601.08267)
*Fan Gao,Sherry T. Tong,Jiwoong Sohn,Jiahao Huang,Junfeng Jiang,Ding Xia,Piyalitt Ittichaiwong,Kanyakorn Veerakanjana,Hyunjae Kim,Qingyu Chen,Edison Marrese Taylor,Kazuma Kobayashi,Akkiko Aizawa,Irene Li*

Main category: cs.CL

TL;DR: Med-CoReasoner：一种语言感知的协同推理框架，通过并行英语和本地语言推理、结构化概念抽象，以及概念级对齐和检索，将本地临床知识整合到英语逻辑框架中，显著提升多语言医疗推理性能


<details>
  <summary>Details</summary>
Motivation: 虽然推理增强的大型语言模型在英语医疗任务上表现良好，但多语言差距仍然存在，本地语言的推理能力明显较弱，限制了全球医疗公平部署。需要弥合这一差距，使医疗AI能更好地服务于不同语言环境

Method: 提出Med-CoReasoner框架：1）并行激发英语和本地语言推理；2）将推理抽象为结构化概念；3）通过概念级对齐和检索，将本地临床知识整合到英语逻辑框架中。还构建了MultiMed-X基准，涵盖7种语言的长形式问答和自然语言推理任务

Result: 在三个基准测试中，Med-CoReasoner平均提升多语言推理性能5%，在低资源语言中提升尤为显著。模型蒸馏和专家评估证实，该框架能产生临床合理且文化基础扎实的推理轨迹

Conclusion: Med-CoReasoner成功结合了英语推理的结构稳健性和本地语言编码的实践基础专业知识，有效缩小了多语言医疗推理差距，为全球医疗AI的公平部署提供了可行方案

Abstract: While reasoning-enhanced large language models perform strongly on English medical tasks, a persistent multilingual gap remains, with substantially weaker reasoning in local languages, limiting equitable global medical deployment. To bridge this gap, we introduce Med-CoReasoner, a language-informed co-reasoning framework that elicits parallel English and local-language reasoning, abstracts them into structured concepts, and integrates local clinical knowledge into an English logical scaffold via concept-level alignment and retrieval. This design combines the structural robustness of English reasoning with the practice-grounded expertise encoded in local languages. To evaluate multilingual medical reasoning beyond multiple-choice settings, we construct MultiMed-X, a benchmark covering seven languages with expert-annotated long-form question answering and natural language inference tasks, comprising 350 instances per language. Experiments across three benchmarks show that Med-CoReasoner improves multilingual reasoning performance by an average of 5%, with particularly substantial gains in low-resource languages. Moreover, model distillation and expert evaluation analysis further confirm that Med-CoReasoner produces clinically sound and culturally grounded reasoning traces.

</details>


### [32] [Discovery and Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees](https://arxiv.org/abs/2601.08274)
*Kun Li,Zenan Xu,Junan Li,Zengrui Jin,Jinghao Deng,Zexuan Qiu,Bo Zhou*

Main category: cs.CL

TL;DR: DART是一个强化学习框架，通过动态构建rollout树来自发发现工具使用机会，在长链思维推理中整合工具使用，无需人工标注，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前工具集成推理虽然能增强大语言模型的计算能力，但在长链思维推理中整合工具使用仍未被充分探索，主要由于训练数据稀缺以及如何在保持模型内在长链推理能力的同时整合工具使用的挑战。

Method: DART框架在训练期间构建动态rollout树来发现有效的工具使用机会，在promising位置分支以探索多样化的工具集成轨迹，然后通过基于树的优势估计识别和奖励那些工具调用对解决方案有积极贡献的特定子轨迹。

Result: 在AIME和GPQA-Diamond等具有挑战性的基准测试中，DART显著优于现有方法，成功地将工具执行与长链思维推理协调统一。

Conclusion: DART通过强化学习框架实现了在长链思维推理中自发工具使用，无需人工标注，有效解决了工具集成与长链推理的协调问题，为增强大语言模型的计算能力提供了新方法。

Abstract: Tool-Integrated Reasoning has emerged as a key paradigm to augment Large Language Models (LLMs) with computational capabilities, yet integrating tool-use into long Chain-of-Thought (long CoT) remains underexplored, largely due to the scarcity of training data and the challenge of integrating tool-use without compromising the model's intrinsic long-chain reasoning. In this paper, we introduce DART (Discovery And Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees), a reinforcement learning framework that enables spontaneous tool-use during long CoT reasoning without human annotation. DART operates by constructing dynamic rollout trees during training to discover valid tool-use opportunities, branching out at promising positions to explore diverse tool-integrated trajectories. Subsequently, a tree-based process advantage estimation identifies and credits specific sub-trajectories where tool invocation positively contributes to the solution, effectively reinforcing these beneficial behaviors. Extensive experiments on challenging benchmarks like AIME and GPQA-Diamond demonstrate that DART significantly outperforms existing methods, successfully harmonizing tool execution with long CoT reasoning.

</details>


### [33] [D$^2$Plan: Dual-Agent Dynamic Global Planning for Complex Retrieval-Augmented Reasoning](https://arxiv.org/abs/2601.08282)
*Kangcheng Luo,Tinglang Wu,Yansong Feng*

Main category: cs.CL

TL;DR: D²Plan：双智能体动态全局规划范式，通过Reasoner和Purifier协作解决检索增强LLM中的搜索链构建失败和推理劫持问题，提升多跳推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的检索增强LLM在多跳推理任务中存在两个关键失败模式：1）搜索链构建无效，产生错误查询或遗漏关键信息；2）推理被外围证据劫持，模型将干扰项误认为有效证据。这些问题在上下文积累过程中尤为突出。

Method: 提出D²Plan双智能体动态全局规划范式，包含Reasoner（构建显式全局规划并根据检索反馈动态调整）和Purifier（评估检索相关性并压缩关键信息）。采用两阶段训练框架：基于合成轨迹的监督微调冷启动，以及基于规划导向奖励的强化学习。

Result: 大量实验表明，D²Plan能够实现更连贯的多步推理，对无关信息具有更强的鲁棒性，在具有挑战性的QA基准测试中取得了优越性能。

Conclusion: D²Plan通过双智能体协作和动态全局规划，有效解决了检索增强LLM在多跳推理中的关键失败模式，提升了复杂检索增强推理的能力。

Abstract: Recent search-augmented LLMs trained with reinforcement learning (RL) can interleave searching and reasoning for multi-hop reasoning tasks. However, they face two critical failure modes as the accumulating context becomes flooded with both crucial evidence and irrelevant information: (1) ineffective search chain construction that produces incorrect queries or omits retrieval of critical information, and (2) reasoning hijacking by peripheral evidence that causes models to misidentify distractors as valid evidence. To address these challenges, we propose **D$^2$Plan**, a **D**ual-agent **D**ynamic global **Plan**ning paradigm for complex retrieval-augmented reasoning. **D$^2$Plan** operates through the collaboration of a *Reasoner* and a *Purifier*: the *Reasoner* constructs explicit global plans during reasoning and dynamically adapts them based on retrieval feedback; the *Purifier* assesses retrieval relevance and condenses key information for the *Reasoner*. We further introduce a two-stage training framework consisting of supervised fine-tuning (SFT) cold-start on synthesized trajectories and RL with plan-oriented rewards to teach LLMs to master the **D$^2$Plan** paradigm. Extensive experiments demonstrate that **D$^2$Plan** enables more coherent multi-step reasoning and stronger resilience to irrelevant information, thereby achieving superior performance on challenging QA benchmarks.

</details>


### [34] [Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques](https://arxiv.org/abs/2601.08302)
*Marvin Schmitt,Anne Schwerk,Sebastian Lempert*

Main category: cs.CL

TL;DR: 研究评估了GPT-4o-mini和gemini-1.5-flash在情感分析任务中的提示工程效果，发现高级提示技术能显著提升性能，但最佳策略因模型和任务而异。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过提示工程提升大型语言模型在情感分析任务中的性能，特别是针对不同模型架构和复杂语义任务（如反讽检测）的优化策略。

Method: 使用GPT-4o-mini和gemini-1.5-flash模型，评估few-shot学习、思维链提示和自一致性等高级提示技术，对比基线方法。任务包括情感分类、基于方面的情感分析和反讽检测，使用准确率、召回率、精确率和F1分数进行评估。

Result: 高级提示技术显著提升了情感分析性能：few-shot方法在GPT-4o-mini上表现最佳，思维链提示使gemini-1.5-flash的反讽检测性能提升高达46%。不同模型对提示策略的响应存在差异。

Conclusion: 提示策略需要根据特定模型架构和任务语义复杂度进行定制，提示设计与LLM架构和任务特性的对齐至关重要。

Abstract: This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details the theoretical background, datasets, and methods used, assessing performance of LLMs as measured by accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with the few-shot approach excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. Thus, while advanced prompting techniques overall improve performance, the fact that few-shot prompting works best for GPT-4o-mini and chain-of-thought excels in gemini-1.5-flash for irony detection suggests that prompting strategies must be tailored to both the model and the task. This highlights the importance of aligning prompt design with both the LLM's architecture and the semantic complexity of the task.

</details>


### [35] [AgriAgent: Contract-Driven Planning and Capability-Aware Tool Orchestration in Real-World Agriculture](https://arxiv.org/abs/2601.08308)
*Bo Yang,Yu Zhang,Yunkui Chen,Lanfei Feng,Xiao Xu,Nueraili Aierken,Shijian Li*

Main category: cs.CL

TL;DR: AgriAgent是一个面向真实农业场景的两层智能体框架，通过分层执行策略处理不同复杂度的任务：简单任务由模态特定智能体直接推理，复杂任务通过契约驱动规划机制进行多步可验证执行。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统在真实农业场景中存在局限性，它们通常采用统一的执行范式，难以适应农业环境中任务复杂度差异大、工具可用性不完整的问题。

Method: AgriAgent采用分层执行策略：简单任务由模态特定智能体直接推理处理；复杂任务触发契约驱动规划机制，将任务转化为能力需求，进行能力感知的工具编排和动态工具生成，支持多步可验证执行和故障恢复。

Result: 实验结果表明，与依赖统一执行范式的现有工具中心智能体基线相比，AgriAgent在复杂任务上实现了更高的执行成功率和鲁棒性。

Conclusion: AgriAgent通过分层执行策略有效解决了农业场景中任务复杂度差异大和工具可用性不完整的问题，为真实农业环境中的智能体系统提供了更灵活可靠的解决方案。

Abstract: Intelligent agent systems in real-world agricultural scenarios must handle diverse tasks under multimodal inputs, ranging from lightweight information understanding to complex multi-step execution. However, most existing approaches rely on a unified execution paradigm, which struggles to accommodate large variations in task complexity and incomplete tool availability commonly observed in agricultural environments. To address this challenge, we propose AgriAgent, a two-level agent framework for real-world agriculture. AgriAgent adopts a hierarchical execution strategy based on task complexity: simple tasks are handled through direct reasoning by modality-specific agents, while complex tasks trigger a contract-driven planning mechanism that formulates tasks as capability requirements and performs capability-aware tool orchestration and dynamic tool generation, enabling multi-step and verifiable execution with failure recovery. Experimental results show that AgriAgent achieves higher execution success rates and robustness on complex tasks compared to existing tool-centric agent baselines that rely on unified execution paradigms. All code, data will be released at after our work be accepted to promote reproducible research.

</details>


### [36] [CLaS-Bench: A Cross-Lingual Alignment and Steering Benchmark](https://arxiv.org/abs/2601.08331)
*Daniil Gurgurov,Yusser Al Ghussin,Tanja Baeumel,Cheng-Ting Chou,Patrick Schramowski,Marius Mosbach,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: CLaS-Bench：首个多语言控制基准，评估32种语言的LLM控制技术，发现DiffMean方法最有效，语言结构主要在深层出现


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门评估LLM多语言控制技术的基准和协议，需要系统量化不同控制方法的有效性

Method: 构建CLaS-Bench轻量级并行问题基准，涵盖32种语言，评估多种控制技术（DiffMean、探针方向、语言特定神经元、PCA/LDA、稀疏自编码器等），从语言控制和语义相关性两个维度测量性能

Result: 简单的基于残差的DiffMean方法在所有语言中一致优于其他方法；语言特定结构主要在深层出现；控制方向按语系聚类

Conclusion: CLaS-Bench是首个标准化多语言控制基准，既能科学分析语言表示，又能作为低成本适应替代方案的实际评估工具

Abstract: Understanding and controlling the behavior of large language models (LLMs) is an increasingly important topic in multilingual NLP. Beyond prompting or fine-tuning, , i.e.,~manipulating internal representations during inference, has emerged as a more efficient and interpretable technique for adapting models to a target language. Yet, no dedicated benchmarks or evaluation protocols exist to quantify the effectiveness of steering techniques. We introduce CLaS-Bench, a lightweight parallel-question benchmark for evaluating language-forcing behavior in LLMs across 32 languages, enabling systematic evaluation of multilingual steering methods. We evaluate a broad array of steering techniques, including residual-stream DiffMean interventions, probe-derived directions, language-specific neurons, PCA/LDA vectors, Sparse Autoencoders, and prompting baselines. Steering performance is measured along two axes: language control and semantic relevance, combined into a single harmonic-mean steering score. We find that across languages simple residual-based DiffMean method consistently outperforms all other methods. Moreover, a layer-wise analysis reveals that language-specific structure emerges predominantly in later layers and steering directions cluster based on language family. CLaS-Bench is the first standardized benchmark for multilingual steering, enabling both rigorous scientific analysis of language representations and practical evaluation of steering as a low-cost adaptation alternative.

</details>


### [37] [Detecting Mental Manipulation in Speech via Synthetic Multi-Speaker Dialogue](https://arxiv.org/abs/2601.08342)
*Run Chen,Wen Liang,Ziwei Gong,Lin Ai,Julia Hirschberg*

Main category: cs.CL

TL;DR: 首个针对语音对话中精神操纵检测的研究，通过合成多说话者语音数据集，发现模型和人类在语音模态下的检测效果均不如文本


<details>
  <summary>Details</summary>
Motivation: 精神操纵作为计算社会推理中的新兴任务，先前研究仅关注文本对话，忽视了操纵策略在语音中的表现形式。需要研究语音模态下的精神操纵检测

Method: 创建合成多说话者语音数据集SPEECHMENTALMANIP，将文本数据集通过高质量、声音一致的文本转语音技术转换为音频。使用少样本大型音频-语言模型和人工标注，评估模态对检测准确性和感知的影响

Result: 模型在语音上的特异性高但召回率显著低于文本，表明对训练中缺失的声学或韵律线索敏感。人类评估者在音频设置下也表现出类似的不确定性，突显了操纵性语音固有的模糊性

Conclusion: 研究结果强调了在多模态对话系统中进行模态感知评估和安全对齐的必要性，语音模态下的精神操纵检测面临独特挑战

Abstract: Mental manipulation, the strategic use of language to covertly influence or exploit others, is a newly emerging task in computational social reasoning. Prior work has focused exclusively on textual conversations, overlooking how manipulative tactics manifest in speech. We present the first study of mental manipulation detection in spoken dialogues, introducing a synthetic multi-speaker benchmark SPEECHMENTALMANIP that augments a text-based dataset with high-quality, voice-consistent Text-to-Speech rendered audio. Using few-shot large audio-language models and human annotation, we evaluate how modality affects detection accuracy and perception. Our results reveal that models exhibit high specificity but markedly lower recall on speech compared to text, suggesting sensitivity to missing acoustic or prosodic cues in training. Human raters show similar uncertainty in the audio setting, underscoring the inherent ambiguity of manipulative speech. Together, these findings highlight the need for modality-aware evaluation and safety alignment in multimodal dialogue systems.

</details>


### [38] [PATS: Personality-Aware Teaching Strategies with Large Language Model Tutors](https://arxiv.org/abs/2601.08402)
*Donya Rooein,Sankalan Pal Chowdhury,Mariia Eremeeva,Yuan Qin,Debora Nozza,Mrinmaya Sachan,Dirk Hovy*

Main category: cs.CL

TL;DR: 本文提出了一种基于学生个性特征的LLM辅导系统，通过构建教学策略与人格特征的分类框架，使LLM能够根据模拟的学生个性调整辅导策略，从而提供更个性化的教育体验。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）辅导系统虽然展示了作为教育导师的潜力，但未能考虑学生的人格特征。不同的教学策略对不同性格的学生效果不同，策略与人格不匹配可能对学习成果产生负面影响。

Method: 首先基于教育学文献构建了教学策略与人格特征的分类框架。然后模拟师生对话，让LLM导师根据模拟的学生人格特征调整其教学策略。最后通过人类教师进行评估。

Result: 人类教师一致偏好本文提出的方法，相比两个基线方法表现更优。该方法还增加了较少使用但高影响力的策略（如角色扮演）的使用频率，这些策略受到人类和LLM标注者的显著偏好。

Conclusion: 该研究为开发更个性化、更有效的LLM教育应用铺平了道路，展示了考虑学生人格特征在AI辅导系统中的重要性。

Abstract: Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Despite this, current LLM tutoring systems do not take into account student personality traits. To address this problem, we first construct a taxonomy that links pedagogical methods to personality profiles, based on pedagogical literature. We simulate student-teacher conversations and use our framework to let the LLM tutor adjust its strategy to the simulated student personality. We evaluate the scenario with human teachers and find that they consistently prefer our approach over two baselines. Our method also increases the use of less common, high-impact strategies such as role-playing, which human and LLM annotators prefer significantly. Our findings pave the way for developing more personalized and effective LLM use in educational applications.

</details>


### [39] [Silence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering](https://arxiv.org/abs/2601.08427)
*Nonghai Zhang,Weitao Ma,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Jingwen Xu*

Main category: cs.CL

TL;DR: Latent-GRPO：通过潜在空间几何学直接从潜在表示中获取内在奖励，替代昂贵的外部验证器，实现2倍以上的训练加速


<details>
  <summary>Details</summary>
Motivation: GRPO方法虽然提升了LLM的推理性能，但严重依赖昂贵的外部验证器或人工规则，导致计算成本高、训练延迟大，且稀疏奖励阻碍了优化效率

Method: 提出Latent-GRPO框架，基于发现正确推理轨迹的终端token表示形成密集聚类而错误轨迹呈离群点的几何特性，引入迭代鲁棒质心估计算法（IRCE），通过球面投影缓解幅度波动，并通过迭代聚合估计鲁棒的"真理质心"来生成密集连续奖励

Result: 在多个数据集上的实验结果表明，该方法在保持模型性能的同时，相比基线实现了2倍以上的训练加速，并展现出强大的泛化能力和鲁棒性

Conclusion: Latent-GRPO通过潜在空间几何学有效解决了GRPO对外部验证器的依赖问题，显著降低了计算成本并提升了训练效率，为LLM推理优化提供了新思路

Abstract: Group Relative Policy Optimization (GRPO) significantly enhances the reasoning performance of Large Language Models (LLMs). However, this success heavily relies on expensive external verifiers or human rules. Such dependency not only leads to significant computational costs and training latency, but also yields sparse rewards that hinder optimization efficiency. To address these challenges, we propose Latent-GRPO, a framework that derives intrinsic rewards directly from latent space geometry. Crucially, our empirical analysis reveals a compelling geometric property: terminal token representations of correct reasoning trajectories form dense clusters with high intra-class similarity, whereas incorrect trajectories remain scattered as outliers. In light of this discovery, we introduce the Iterative Robust Centroid Estimation (IRCE) algorithm, which generates dense, continuous rewards by mitigating magnitude fluctuations via spherical projection and estimating a robust ``truth centroid'' through iterative aggregation. Experimental results on multiple datasets show that our method maintains model performance while achieving a training speedup of over 2x compared to baselines. Furthermore, extensive results demonstrate strong generalization ability and robustness. The code will be released soon.

</details>


### [40] [Fine-Mem: Fine-Grained Feedback Alignment for Long-Horizon Memory Management](https://arxiv.org/abs/2601.08435)
*Weitao Ma,Xiaocheng Feng,Lei Huang,Xiachong Feng,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Bing Qin*

Main category: cs.CL

TL;DR: Fine-Mem框架通过细粒度反馈对齐解决LLM智能体记忆管理中的奖励稀疏问题，引入块级步进奖励和证据锚定奖励归因，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的记忆管理器主要依赖最终任务性能作为奖励，导致严重的奖励稀疏和信用分配问题，无法为单个记忆操作提供有效指导。

Method: 提出Fine-Mem统一框架：1) 块级步进奖励：通过辅助的块特定问答任务提供即时步级监督；2) 证据锚定奖励归因：基于推理中作为证据使用的具体记忆项，将全局奖励重新分配给关键记忆操作。

Result: 在Memalpha和MemoryAgentBench上的实验表明，Fine-Mem始终优于强基线，在各种子任务中实现了更高的成功率。进一步分析显示其在不同模型配置和骨干网络上的适应性和强泛化能力。

Conclusion: Fine-Mem通过细粒度反馈对齐解决了记忆管理中的奖励稀疏问题，实现了稳定的策略优化，并使局部记忆操作与记忆的长期效用保持一致。

Abstract: Effective memory management is essential for large language model agents to navigate long-horizon tasks. Recent research has explored using Reinforcement Learning to develop specialized memory manager agents. However, existing approaches rely on final task performance as the primary reward, which results in severe reward sparsity and ineffective credit assignment, providing insufficient guidance for individual memory operations. To this end, we propose Fine-Mem, a unified framework designed for fine-grained feedback alignment. First, we introduce a Chunk-level Step Reward to provide immediate step-level supervision via auxiliary chunk-specific question answering tasks. Second, we devise Evidence-Anchored Reward Attribution to redistribute global rewards by anchoring credit to key memory operations, based on the specific memory items utilized as evidence in reasoning. Together, these components enable stable policy optimization and align local memory operations with the long-term utility of memory. Experiments on Memalpha and MemoryAgentBench demonstrate that Fine-Mem consistently outperforms strong baselines, achieving superior success rates across various sub-tasks. Further analysis reveals its adaptability and strong generalization capabilities across diverse model configurations and backbones.

</details>


### [41] [JudgeRLVR: Judge First, Generate Second for Efficient Reasoning](https://arxiv.org/abs/2601.08468)
*Jiangshan Duo,Hanyu Li,Hailin Zhang,Yudong Wang,Sujian Li,Liang Zhao*

Main category: cs.CL

TL;DR: 提出JudgeRLVR方法，通过先训练模型判断解决方案正确性，再基于此进行生成，在数学领域实现更好的准确率-效率平衡


<details>
  <summary>Details</summary>
Motivation: 传统RLVR仅优化最终答案正确性会导致模型进行漫无目的、冗长的探索，依赖试错而非结构化规划。启发式约束如长度惩罚可能截断必要推理步骤，需要在效率和验证之间权衡。

Method: 提出JudgeRLVR两阶段范式：1) 训练模型判断带有可验证答案的解决方案；2) 基于判断能力初始化，用标准生成RLVR微调同一模型

Result: 相比传统RLVR，JudgeRLVR在Qwen3-30B-A3B上实现更好质量-效率平衡：领域内数学任务平均准确率提升约3.7分，平均生成长度减少42%；领域外基准平均准确率提升约4.5分，展示增强的泛化能力

Conclusion: 判别能力是高效生成的前提，通过学习区分有效解决方案，模型可以内化指导信号来剪枝搜索空间，实现更好的推理效率和泛化性能

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often drives models into aimless, verbose exploration, where they rely on exhaustive trial-and-error tactics rather than structured planning to reach solutions. While heuristic constraints like length penalties can reduce verbosity, they often truncate essential reasoning steps, creating a difficult trade-off between efficiency and verification. In this paper, we argue that discriminative capability is a prerequisite for efficient generation: by learning to distinguish valid solutions, a model can internalize a guidance signal that prunes the search space. We propose JudgeRLVR, a two-stage judge-then-generate paradigm. In the first stage, we train the model to judge solution responses with verifiable answers. In the second stage, we fine-tune the same model with vanilla generating RLVR initialized from the judge. Compared to Vanilla RLVR using the same math-domain training data, JudgeRLVR achieves a better quality--efficiency trade-off for Qwen3-30B-A3B: on in-domain math, it delivers about +3.7 points average accuracy gain with -42\% average generation length; on out-of-domain benchmarks, it delivers about +4.5 points average accuracy improvement, demonstrating enhanced generalization.

</details>


### [42] [sui-1: Grounded and Verifiable Long-Form Summarization](https://arxiv.org/abs/2601.08472)
*Benedikt Droste,Jan Philipp Harries,Maximilian Idahl,Björn Plüster*

Main category: cs.CL

TL;DR: sui-1是一个24B参数的模型，能够生成带有内联引用的摘要，让用户可以追踪每个主张到源文本，在引用基础的摘要任务上显著优于更大的模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常生成看似合理但不准确的摘要，用户无法根据源文本验证，这在政府、法律分析等合规敏感领域是一个关键限制。

Method: 使用合成数据流水线，结合思维链提示和多阶段验证，从议会文件、网页文本和维基百科等多样化来源生成超过22,000个高质量训练示例，涵盖五种语言。

Result: sui-1显著优于所有测试的开源基线模型，包括参数多3倍的模型，展示了任务特定训练在引用基础摘要任务上明显优于单纯扩大模型规模。

Conclusion: 任务特定的训练在引用基础摘要任务上比单纯扩大模型规模更有效，sui-1模型权重和交互演示已公开可用。

Abstract: Large language models frequently generate plausible but unfaithful summaries that users cannot verify against source text, a critical limitation in compliance-sensitive domains such as government and legal analysis. We present sui-1, a 24B parameter model that produces abstractive summaries with inline citations, enabling users to trace each claim to its source sentence. Our synthetic data pipeline combines chain-of-thought prompting with multi-stage verification, generating over 22,000 high-quality training examples across five languages from diverse sources including parliamentary documents, web text, and Wikipedia. Evaluation shows sui-1 significantly outperforms all tested open-weight baselines, including models with 3x more parameters. These results demonstrate that task-specific training substantially outperforms scale alone for citation-grounded summarization. Model weights and an interactive demo are publicly available.

</details>


### [43] [Do You Understand How I Feel?: Towards Verified Empathy in Therapy Chatbots](https://arxiv.org/abs/2601.08477)
*Francesco Dettori,Matteo Forasassi,Lorenzo Veronese,Livia Lestingi,Vincenzo Scotti,Matteo Giovanni Rossi*

Main category: cs.CL

TL;DR: 提出结合NLP和形式验证的框架，用于开发具有共情能力的治疗对话机器人，通过Transformer提取对话特征，用随机混合自动机建模治疗会话，并通过统计模型检查验证共情属性。


<details>
  <summary>Details</summary>
Motivation: 对话机器人在心理健康治疗路径中作为支持工具越来越重要，共情是治疗环境中的关键非功能性需求，但当前聊天机器人开发实践缺乏系统化的方法来规范和验证共情能力。

Method: 1. 使用Transformer模型提取对话特征；2. 将特征转换为治疗会话的随机混合自动机模型；3. 通过统计模型检查验证共情相关属性；4. 策略合成为塑造智能体行为提供指导。

Result: 初步结果显示，形式模型能够良好地捕捉治疗动态，且专门设计的策略提高了满足共情需求的概率。

Conclusion: 该框架为开发具有共情能力的治疗对话机器人提供了系统化方法，结合自然语言处理和形式验证技术，有望改善心理健康支持工具的质量和效果。

Abstract: Conversational agents are increasingly used as support tools along mental therapeutic pathways with significant societal impacts. In particular, empathy is a key non-functional requirement in therapeutic contexts, yet current chatbot development practices provide no systematic means to specify or verify it. This paper envisions a framework integrating natural language processing and formal verification to deliver empathetic therapy chatbots. A Transformer-based model extracts dialogue features, which are then translated into a Stochastic Hybrid Automaton model of dyadic therapy sessions. Empathy-related properties can then be verified through Statistical Model Checking, while strategy synthesis provides guidance for shaping agent behavior. Preliminary results show that the formal model captures therapy dynamics with good fidelity and that ad-hoc strategies improve the probability of satisfying empathy requirements.

</details>


### [44] [Surgical Refusal Ablation: Disentangling Safety from Intelligence via Concept-Guided Spectral Cleaning](https://arxiv.org/abs/2601.08489)
*Tony Cristofano*

Main category: cs.CL

TL;DR: 提出Surgical Refusal Ablation (SRA)方法，通过正交化拒绝向量来减少有害请求拒绝，同时最小化对模型能力的损害。


<details>
  <summary>Details</summary>
Motivation: 现有激活导向方法在消除拒绝向量时会导致能力损害和分布漂移，因为原始拒绝向量是多义的，将拒绝信号与核心能力电路和语言风格纠缠在一起。

Method: SRA构建独立概念原子注册表表示受保护能力和风格混杂因素，使用岭正则化谱残差化将拒绝向量正交化于这些方向，得到干净的拒绝方向。

Result: 在五个模型上，SRA实现深度拒绝减少(0-2%)，对Wikitext-2的困惑度影响可忽略，分布漂移最小。相比标准消融，SRA保持原始分布同时达到相同拒绝率。

Conclusion: 常见的"模型损害"通常是"幽灵噪声"，即脏拒绝方向向能力子空间的谱泄漏。SRA能有效分离拒绝信号而不损害模型能力。

Abstract: Safety-aligned language models systematically refuse harmful requests. While activation steering can modulate refusal, ablating the raw "refusal vector" calculated from contrastive harmful and harmless prompts often causes collateral damage and distribution drift. We argue this degradation occurs because the raw vector is polysemantic, entangling the refusal signal with core capability circuits and linguistic style.
  We introduce Surgical Refusal Ablation (SRA) to distill these steering directions. SRA constructs a registry of independent Concept Atoms representing protected capabilities and stylistic confounds, then uses ridge-regularized spectral residualization to orthogonalize the refusal vector against these directions. This yields a clean refusal direction that targets refusal-relevant structure while minimizing disruption to the model's semantic geometry.
  Across five models (Qwen3-VL and Ministral series), SRA achieves deep refusal reduction (0-2%) with negligible perplexity impact on Wikitext-2 (mean delta PPL approx. 0.02) and minimal distribution drift. Notably, standard ablation on Qwen3-VL-4B induces severe drift (first-token KL = 2.088), whereas SRA maintains the original distribution (KL = 0.044) while achieving the same 0% refusal rate. Using teacher-forced perplexity on GSM8K and MBPP as a high-resolution capability proxy, we show SRA preserves math and code distributions. These results suggest that common "model damage" is often "Ghost Noise," defined as the spectral bleeding of the dirty refusal direction into capability subspaces.

</details>


### [45] [BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts](https://arxiv.org/abs/2601.08490)
*Erin Feiglin,Nir Hutnik,Raz Lapid*

Main category: cs.CL

TL;DR: 论文研究大语言模型在普通文本提示下产生过度输出的"溢出"现象，开发了BenchOverflow基准测试，发现该问题普遍存在且可通过简洁提醒缓解，强调长度控制对可靠性、成本和可持续性的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在普通交互设置下产生过度输出的"溢出"现象，这一问题不同于越狱或提示注入，会导致服务成本增加、延迟升高、跨用户性能下降，并带来经济和环境影响，包括运营成本和碳足迹增加。

Method: 引入BenchOverflow基准测试，包含9种纯文本提示策略，使用标准化协议（固定5000新token预算）评估9个开源和闭源模型，通过上限饱和率、经验累积分布函数、内部提示方差和跨模型相关性等指标量化尾部风险。

Result: 观察到模型输出长度分布明显右移和重尾现象，溢出问题在不同模型家族和攻击向量间具有广泛可重复性但存在异质性，轻量级缓解措施（固定简洁提醒）能有效衰减右尾并降低上限饱和率。

Conclusion: 长度控制应被视为可测量的可靠性、成本和可持续性问题，而非风格怪癖。BenchOverflow为选择最小化资源浪费的部署模型和评估防御措施提供了实用基础，有助于在不影响任务性能的情况下遏制计算放大。

Abstract: We investigate a failure mode of large language models (LLMs) in which plain-text prompts elicit excessive outputs, a phenomenon we term Overflow. Unlike jailbreaks or prompt injection, Overflow arises under ordinary interaction settings and can lead to elevated serving cost, latency, and cross-user performance degradation, particularly when scaled across many requests. Beyond usability, the stakes are economic and environmental: unnecessary tokens increase per-request cost and energy consumption, compounding into substantial operational spend and carbon footprint at scale. Moreover, Overflow represents a practical vector for compute amplification and service degradation in shared environments. We introduce BenchOverflow, a model-agnostic benchmark of nine plain-text prompting strategies that amplify output volume without adversarial suffixes or policy circumvention. Using a standardized protocol with a fixed budget of 5000 new tokens, we evaluate nine open- and closed-source models and observe pronounced rightward shifts and heavy tails in length distributions. Cap-saturation rates (CSR@1k/3k/5k) and empirical cumulative distribution functions (ECDFs) quantify tail risk; within-prompt variance and cross-model correlations show that Overflow is broadly reproducible yet heterogeneous across families and attack vectors. A lightweight mitigation-a fixed conciseness reminder-attenuates right tails and lowers CSR for all strategies across the majority of models. Our findings position length control as a measurable reliability, cost, and sustainability concern rather than a stylistic quirk. By enabling standardized comparison of length-control robustness across models, BenchOverflow provides a practical basis for selecting deployments that minimize resource waste and operating expense, and for evaluating defenses that curb compute amplification without eroding task performance.

</details>


### [46] [It's All About the Confidence: An Unsupervised Approach for Multilingual Historical Entity Linking using Large Language Models](https://arxiv.org/abs/2601.08500)
*Cristian Santini,Marieke Van Erp,Mehwish Alam*

Main category: cs.CL

TL;DR: MHEL-LLaMo：一种结合小型语言模型和大型语言模型的无监督集成方法，用于解决历史文本实体链接的挑战，无需微调即可超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 历史文本实体链接面临语言变异、噪声输入和语义演变等挑战，现有方法需要大量训练数据或依赖领域特定规则，可扩展性有限。

Method: 采用无监督集成方法，结合小型语言模型（BELA多语言双编码器）进行候选检索，以及指令调优的大型语言模型通过提示链进行NIL预测和候选选择。使用SLM置信度区分简单和困难样本，仅对困难样本应用LLM。

Result: 在6种欧洲语言（英、芬、法、德、意、瑞典）的4个历史文本基准测试中，MHEL-LLaMo无需微调即超越最先进模型，同时降低计算成本。

Conclusion: MHEL-LLaMo为低资源历史实体链接提供了可扩展的解决方案，通过智能集成SLM和LLM，在保持性能的同时减少计算开销。

Abstract: Despite the recent advancements in NLP with the advent of Large Language Models (LLMs), Entity Linking (EL) for historical texts remains challenging due to linguistic variation, noisy inputs, and evolving semantic conventions. Existing solutions either require substantial training data or rely on domain-specific rules that limit scalability. In this paper, we present MHEL-LLaMo (Multilingual Historical Entity Linking with Large Language MOdels), an unsupervised ensemble approach combining a Small Language Model (SLM) and an LLM. MHEL-LLaMo leverages a multilingual bi-encoder (BELA) for candidate retrieval and an instruction-tuned LLM for NIL prediction and candidate selection via prompt chaining. Our system uses SLM's confidence scores to discriminate between easy and hard samples, applying an LLM only for hard cases. This strategy reduces computational costs while preventing hallucinations on straightforward cases. We evaluate MHEL-LLaMo on four established benchmarks in six European languages (English, Finnish, French, German, Italian and Swedish) from the 19th and 20th centuries. Results demonstrate that MHEL-LLaMo outperforms state-of-the-art models without requiring fine-tuning, offering a scalable solution for low-resource historical EL. The implementation of MHEL-LLaMo is available on Github.

</details>


### [47] [STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays](https://arxiv.org/abs/2601.08510)
*Qiuyu Tian,Yiding Li,Fengyi Chen,Zequn Liu,Youyong Kong,Fan Guo,Yuyao Li,Jinjing Shen,Zhijing Xie,Yiyun Luo,Xin Zhang*

Main category: cs.CL

TL;DR: STAGE是一个统一的电影剧本叙事理解基准，包含知识图谱构建、场景事件摘要、长上下文问答和角色扮演四个任务，基于150部中英文电影的共享叙事世界表示。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注问答或对话生成等单一子任务，缺乏评估模型能否构建连贯故事世界并在多种推理和生成任务中保持一致性的能力。电影剧本作为丰富的长篇叙事形式，包含复杂角色关系、时序事件和对话互动，需要更全面的评估框架。

Method: STAGE定义了四个基于共享叙事世界表示的任务：1)知识图谱构建，2)场景级事件摘要，3)长上下文剧本问答，4)剧本内角色扮演。基准提供150部中英文电影的清洗后剧本、精心构建的知识图谱，以及事件和角色为中心的标注。

Result: STAGE基准提供了全面的评估框架，能够从多个维度评估模型能力：构建世界表示、抽象和验证叙事事件、长叙事推理、生成角色一致响应。覆盖150部中英文电影，支持跨语言评估。

Conclusion: STAGE是一个统一的电影剧本叙事理解基准，通过四个相互关联的任务和共享叙事世界表示，能够全面评估模型在构建连贯故事世界和保持一致性方面的能力，填补了现有基准的空白。

Abstract: Movie screenplays are rich long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. While prior benchmarks target individual subtasks such as question answering or dialogue generation, they rarely evaluate whether models can construct a coherent story world and use it consistently across multiple forms of reasoning and generation. We introduce STAGE (Screenplay Text, Agents, Graphs and Evaluation), a unified benchmark for narrative understanding over full-length movie screenplays. STAGE defines four tasks: knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation. The benchmark provides cleaned scripts, curated knowledge graphs, and event- and character-centric annotations for 150 films across English and Chinese, enabling holistic evaluation of models' abilities to build world representations, abstract and verify narrative events, reason over long narratives, and generate character-consistent responses.

</details>


### [48] [STAR: Detecting Inference-time Backdoors in LLM Reasoning via State-Transition Amplification Ratio](https://arxiv.org/abs/2601.08511)
*Seong-Gyu Park,Sohee Park,Jisu Lee,Hyunsik Na,Daeseon Choi*

Main category: cs.CL

TL;DR: STAR框架通过分析输出概率转移来检测推理时后门攻击，利用恶意推理路径的先验概率低但后验概率高的统计差异，在多种模型上实现接近完美的检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs集成CoT等推理机制，显式推理暴露了推理时后门攻击的新攻击面。这些攻击注入恶意推理路径而不改变模型参数，且由于生成语言连贯的路径，能有效规避传统检测方法。

Method: 提出STAR框架，通过分析输出概率转移来检测后门。利用恶意输入诱导路径在模型通用知识中先验概率低但后验概率高的统计差异，量化状态转移放大，并采用CUSUM算法检测持续异常。

Result: 在多种模型（8B-70B）和五个基准数据集上的实验表明，STAR展现出强大的泛化能力，始终实现接近完美的性能（AUROC≈1.0），效率比现有基线高约42倍，且对试图绕过检测的自适应攻击具有鲁棒性。

Conclusion: STAR框架有效解决了LLMs推理时后门攻击的检测问题，通过统计差异分析实现了高效、鲁棒的检测，为推理机制的安全性提供了重要保障。

Abstract: Recent LLMs increasingly integrate reasoning mechanisms like Chain-of-Thought (CoT). However, this explicit reasoning exposes a new attack surface for inference-time backdoors, which inject malicious reasoning paths without altering model parameters. Because these attacks generate linguistically coherent paths, they effectively evade conventional detection. To address this, we propose STAR (State-Transition Amplification Ratio), a framework that detects backdoors by analyzing output probability shifts. STAR exploits the statistical discrepancy where a malicious input-induced path exhibits high posterior probability despite a low prior probability in the model's general knowledge. We quantify this state-transition amplification and employ the CUSUM algorithm to detect persistent anomalies. Experiments across diverse models (8B-70B) and five benchmark datasets demonstrate that STAR exhibits robust generalization capabilities, consistently achieving near-perfect performance (AUROC $\approx$ 1.0) with approximately $42\times$ greater efficiency than existing baselines. Furthermore, the framework proves robust against adaptive attacks attempting to bypass detection.

</details>


### [49] [Algorithmic Stability in Infinite Dimensions: Characterizing Unconditional Convergence in Banach Spaces](https://arxiv.org/abs/2601.08512)
*Przemysław Spyra*

Main category: cs.CL

TL;DR: 该论文系统研究了无限维空间中无条件收敛的七种等价条件，并将其与计算算法的稳定性分析联系起来


<details>
  <summary>Details</summary>
Motivation: 在无限维空间中，条件收敛、无条件收敛和绝对收敛的区别对计算算法有根本性影响。虽然这些概念在有限维中重合，但在一般Banach空间中存在严格分离，这需要通过Dvoretzky-Rogers定理来理解。研究旨在为计算实践提供严格的数学基础

Method: 提出一个统一的特征定理，建立了无条件收敛的七种等价条件：置换不变性、网收敛、子级数检验、符号稳定性、有界乘子性质、弱一致收敛等。这些理论结果直接应用于算法稳定性分析

Result: 系统表征了无条件收敛的各种等价条件，并将这些理论结果应用于随机梯度下降中的梯度累积置换不变性分析，以及基于框架的信号处理中的系数阈值化方法

Conclusion: 该工作架起了经典泛函分析与现代计算实践之间的桥梁，为顺序无关和数值稳健的求和过程提供了严格的理论基础，对算法设计和分析具有重要指导意义

Abstract: The distinction between conditional, unconditional, and absolute convergence in infinite-dimensional spaces has fundamental implications for computational algorithms. While these concepts coincide in finite dimensions, the Dvoretzky-Rogers theorem establishes their strict separation in general Banach spaces. We present a comprehensive characterization theorem unifying seven equivalent conditions for unconditional convergence: permutation invariance, net convergence, subseries tests, sign stability, bounded multiplier properties, and weak uniform convergence. These theoretical results directly inform algorithmic stability analysis, governing permutation invariance in gradient accumulation for Stochastic Gradient Descent and justifying coefficient thresholding in frame-based signal processing. Our work bridges classical functional analysis with contemporary computational practice, providing rigorous foundations for order-independent and numerically robust summation processes.

</details>


### [50] [DeepResearch Bench II: Diagnosing Deep Research Agents via Rubrics from Expert Report](https://arxiv.org/abs/2601.08536)
*Ruizhe Li,Mingxuan Du,Benfeng Xu,Chiwei Zhu,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: Deep Research Bench II：一个包含132个研究任务、9430个细粒度二元评分标准的基准测试，用于评估深度研究系统生成报告的质量，发现当前最强模型仅满足不到50%的标准。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究系统评估基准存在两个问题：1）未能充分测试系统分析证据和撰写连贯报告的能力；2）评估标准过于粗糙或直接由LLM定义，导致评分存在偏见且难以验证解释。需要建立一个更严谨的评估框架。

Method: 构建包含132个跨22个领域的研究任务的基准测试，每个任务需要系统生成长篇研究报告。通过四阶段LLM+人工流程创建了9430个细粒度二元评分标准，涵盖信息回忆、分析和呈现三个维度。所有标准都基于专家撰写的调查文章，并经过400多小时专家审查。

Result: 评估多个最先进的深度研究系统后发现，即使最强的模型也仅满足不到50%的评分标准，揭示了当前深度研究系统与人类专家之间存在显著差距。

Conclusion: Deep Research Bench II提供了一个更严谨、可验证且与人类专家判断一致的评估框架，有助于推动深度研究系统的改进和发展。

Abstract: Deep Research Systems (DRS) aim to help users search the web, synthesize information, and deliver comprehensive investigative reports. However, how to rigorously evaluate these systems remains under-explored. Existing deep-research benchmarks often fall into two failure modes. Some do not adequately test a system's ability to analyze evidence and write coherent reports. Others rely on evaluation criteria that are either overly coarse or directly defined by LLMs (or both), leading to scores that can be biased relative to human experts and are hard to verify or interpret. To address these issues, we introduce Deep Research Bench II, a new benchmark for evaluating DRS-generated reports. It contains 132 grounded research tasks across 22 domains; for each task, a system must produce a long-form research report that is evaluated by a set of 9430 fine-grained binary rubrics in total, covering three dimensions: information recall, analysis, and presentation. All rubrics are derived from carefully selected expert-written investigative articles and are constructed through a four-stage LLM+human pipeline that combines automatic extraction with over 400 human-hours of expert review, ensuring that the criteria are atomic, verifiable, and aligned with human expert judgment. We evaluate several state-of-the-art deep-research systems on Deep Research Bench II and find that even the strongest models satisfy fewer than 50% of the rubrics, revealing a substantial gap between current DRSs and human experts.

</details>


### [51] [Ministral 3](https://arxiv.org/abs/2601.08584)
*Alexander H. Liu,Kartik Khandelwal,Sandeep Subramanian,Victor Jouault,Abhinav Rastogi,Adrien Sadé,Alan Jeffares,Albert Jiang,Alexandre Cahill,Alexandre Gavaudan,Alexandre Sablayrolles,Amélie Héliou,Amos You,Andy Ehrenberg,Andy Lo,Anton Eliseev,Antonia Calvi,Avinash Sooriyarachchi,Baptiste Bout,Baptiste Rozière,Baudouin De Monicault,Clémence Lanfranchi,Corentin Barreau,Cyprien Courtot,Daniele Grattarola,Darius Dabert,Diego de las Casas,Elliot Chane-Sane,Faruk Ahmed,Gabrielle Berrada,Gaëtan Ecrepont,Gauthier Guinet,Georgii Novikov,Guillaume Kunsch,Guillaume Lample,Guillaume Martin,Gunshi Gupta,Jan Ludziejewski,Jason Rute,Joachim Studnia,Jonas Amar,Joséphine Delas,Josselin Somerville Roberts,Karmesh Yadav,Khyathi Chandu,Kush Jain,Laurence Aitchison,Laurent Fainsin,Léonard Blier,Lingxiao Zhao,Louis Martin,Lucile Saulnier,Luyu Gao,Maarten Buyl,Margaret Jennings,Marie Pellat,Mark Prins,Mathieu Poirée,Mathilde Guillaumin,Matthieu Dinot,Matthieu Futeral,Maxime Darrin,Maximilian Augustin,Mia Chiquier,Michel Schimpf,Nathan Grinsztajn,Neha Gupta,Nikhil Raghuraman,Olivier Bousquet,Olivier Duchenne,Patricia Wang,Patrick von Platen,Paul Jacob,Paul Wambergue,Paula Kurylowicz,Pavankumar Reddy Muddireddy,Philomène Chagniot,Pierre Stock,Pravesh Agrawal,Quentin Torroba,Romain Sauvestre,Roman Soletskyi,Rupert Menneer,Sagar Vaze,Samuel Barry,Sanchit Gandhi,Siddhant Waghjale,Siddharth Gandhi,Soham Ghosh,Srijan Mishra,Sumukh Aithal,Szymon Antoniak,Teven Le Scao,Théo Cachet,Theo Simon Sorg,Thibaut Lavril,Thiziri Nait Saada,Thomas Chabal,Thomas Foubert,Thomas Robert,Thomas Wang,Tim Lawson,Tom Bewley,Tom Bewley,Tom Edwards,Umar Jamil,Umberto Tomasini,Valeriia Nemychnikova,Van Phung,Vincent Maladière,Virgile Richard,Wassim Bouaziz,Wen-Ding Li,William Marshall,Xinghui Li,Xinyu Yang,Yassine El Ouahidi,Yihan Wang,Yunhao Tang,Zaccharie Ramzi*

Main category: cs.CL

TL;DR: Ministral 3系列是参数高效的密集语言模型，包含3B、8B、14B三种尺寸，每个尺寸都有基础预训练、指令微调和推理三种变体，采用级联蒸馏方法训练，具备图像理解能力，使用Apache 2.0许可证。


<details>
  <summary>Details</summary>
Motivation: 针对计算和内存受限的应用场景，需要开发参数高效、性能强大的语言模型，同时提供多种变体满足不同任务需求。

Method: 采用级联蒸馏方法，通过迭代剪枝和持续训练结合蒸馏技术来推导模型。每个模型都具备图像理解能力。

Result: 发布了Ministral 3系列模型，包含三种尺寸（3B、8B、14B），每种尺寸都有三个变体：基础预训练模型、指令微调模型和推理模型。

Conclusion: Ministral 3系列为计算和内存受限应用提供了高效的密集语言模型解决方案，采用Apache 2.0开源许可证，具备图像理解能力，适用于多种任务场景。

Abstract: We introduce the Ministral 3 series, a family of parameter-efficient dense language models designed for compute and memory constrained applications, available in three model sizes: 3B, 8B, and 14B parameters. For each model size, we release three variants: a pretrained base model for general-purpose use, an instruction finetuned, and a reasoning model for complex problem-solving. In addition, we present our recipe to derive the Ministral 3 models through Cascade Distillation, an iterative pruning and continued training with distillation technique. Each model comes with image understanding capabilities, all under the Apache 2.0 license.

</details>


### [52] [ExpSeek: Self-Triggered Experience Seeking for Web Agents](https://arxiv.org/abs/2601.08605)
*Wenyuan Zhang,Xinghua Zhang,Haiyang Yu,Shuaiyi Nie,Bingli Wu,Juwei Yue,Tingwen Liu,Yongbin Li*

Main category: cs.CL

TL;DR: ExpSeek提出了一种主动寻求经验的网络代理方法，通过熵阈值确定干预时机，在四个基准测试中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有经验注入方法主要在任务执行前被动注入全局上下文，难以适应代理与环境交互过程中动态变化的上下文观察

Method: ExpSeek将经验转向步骤级主动寻求：(1) 使用模型内在信号估计步骤级熵阈值来确定干预时机；(2) 设计步骤级定制化经验内容

Result: 在Qwen3-8B和32B模型上的四个挑战性网络代理基准测试中，ExpSeek分别实现了9.3%和7.5%的绝对提升，验证了熵作为自触发信号的可行性

Conclusion: 该方法展示了步骤级主动经验寻求的有效性，即使是4B小规模经验模型也能显著提升更大代理模型的性能

Abstract: Experience intervention in web agents emerges as a promising technical paradigm, enhancing agent interaction capabilities by providing valuable insights from accumulated experiences. However, existing methods predominantly inject experience passively as global context before task execution, struggling to adapt to dynamically changing contextual observations during agent-environment interaction. We propose ExpSeek, which shifts experience toward step-level proactive seeking: (1) estimating step-level entropy thresholds to determine intervention timing using the model's intrinsic signals; (2) designing step-level tailor-designed experience content. Experiments on Qwen3-8B and 32B models across four challenging web agent benchmarks demonstrate that ExpSeek achieves absolute improvements of 9.3% and 7.5%, respectively. Our experiments validate the feasibility and advantages of entropy as a self-triggering signal, reveal that even a 4B small-scale experience model can significantly boost the performance of larger agent models.

</details>


### [53] [GraphSearch: Agentic Search-Augmented Reasoning for Zero-Shot Graph Learning](https://arxiv.org/abs/2601.08621)
*Jiajin Liu,Yuanfu Sun,Dongzhe Fan,Qiaoyu Tan*

Main category: cs.CL

TL;DR: GraphSearch：首个将搜索增强推理扩展到图学习的框架，无需任务特定微调即可实现零样本图学习，在图结构数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有搜索增强大推理模型主要处理文本数据，但在图结构数据（如电商、社交网络、科学引用）上的应用不足。图数据包含丰富的拓扑信号，可作为检索的有价值先验，但有效利用图结构面临独特挑战。

Method: GraphSearch框架包含：1）图感知查询规划器，将搜索空间（1跳、多跳或全局邻居）与语义查询解耦；2）图感知检索器，基于拓扑构建候选集并使用混合评分函数排序。提供两种遍历模式：递归扩展邻居的GraphSearch-R和灵活检索局部与全局邻居的GraphSearch-F。

Result: 在多样化基准测试中，GraphSearch在零样本节点分类和链接预测任务上达到竞争性甚至优于监督图学习方法的结果，建立了新的最先进性能。

Conclusion: GraphSearch作为首个将搜索增强推理扩展到图学习的框架，为图上的智能推理提供了一个灵活且可泛化的范式，无需任务特定微调即可实现强大的零样本图学习能力。

Abstract: Recent advances in search-augmented large reasoning models (LRMs) enable the retrieval of external knowledge to reduce hallucinations in multistep reasoning. However, their ability to operate on graph-structured data, prevalent in domains such as e-commerce, social networks, and scientific citations, remains underexplored. Unlike plain text corpora, graphs encode rich topological signals that connect related entities and can serve as valuable priors for retrieval, enabling more targeted search and improved reasoning efficiency. Yet, effectively leveraging such structure poses unique challenges, including the difficulty of generating graph-expressive queries and ensuring reliable retrieval that balances structural and semantic relevance. To address this gap, we introduce GraphSearch, the first framework that extends search-augmented reasoning to graph learning, enabling zero-shot graph learning without task-specific fine-tuning. GraphSearch combines a Graph-aware Query Planner, which disentangles search space (e.g., 1-hop, multi-hop, or global neighbors) from semantic queries, with a Graph-aware Retriever, which constructs candidate sets based on topology and ranks them using a hybrid scoring function. We further instantiate two traversal modes: GraphSearch-R, which recursively expands neighborhoods hop by hop, and GraphSearch-F, which flexibly retrieves across local and global neighborhoods without hop constraints. Extensive experiments across diverse benchmarks show that GraphSearch achieves competitive or even superior performance compared to supervised graph learning methods, setting state-of-the-art results in zero-shot node classification and link prediction. These findings position GraphSearch as a flexible and generalizable paradigm for agentic reasoning over graphs.

</details>


### [54] [How Order-Sensitive Are LLMs? OrderProbe for Deterministic Structural Reconstruction](https://arxiv.org/abs/2601.08626)
*Yingjie He,Zhaolu Kang,Kehan Jiang,Qianyuan Zhang,Jiachen Qian,Chunlei Meng,Yujie Feng,Yuan Wang,Jiabao Dou,Aming Wu,Leqi Zheng,Pengxiang Zhao,Jiaxin Liu,Zeyu Zhang,Lei Wang,Guansu Wang,Qishi Zhan,Xiaomin He,Meisheng Zhang,Jianyuan Ni*

Main category: cs.CL

TL;DR: OrderProbe是一个用于评估大语言模型结构重建能力的确定性基准测试，使用中文、日文和韩文中的固定四字表达式，通过精确匹配评分来衡量模型恢复规范词序的能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在语义理解方面表现出色，但从乱序输入中重建内部结构的能力尚未得到充分探索。句子级恢复难以进行自动化评估，因为通常存在多种有效的词序排列。

Method: 提出OrderProbe基准测试，使用中文、日文和韩文中的固定四字表达式，这些表达式具有唯一的规范顺序，支持精确匹配评分。同时提出一个诊断框架，评估模型在恢复准确性之外的多个维度：语义保真度、逻辑有效性、一致性、鲁棒性敏感度和信息密度。

Result: 在12个广泛使用的大语言模型上的实验表明，结构重建即使对于前沿系统仍然很困难：零样本恢复准确率经常低于35%。研究还观察到语义回忆和结构规划之间存在一致性的分离，表明结构鲁棒性不是语义能力的自动副产品。

Conclusion: 结构重建是大语言模型面临的一个挑战性任务，需要专门的评估方法。语义能力并不自动转化为结构鲁棒性，这表明需要更深入地理解模型如何处理语言结构信息。

Abstract: Large language models (LLMs) excel at semantic understanding, yet their ability to reconstruct internal structure from scrambled inputs remains underexplored. Sentence-level restoration is ill-posed for automated evaluation because multiple valid word orders often exist. We introduce OrderProbe, a deterministic benchmark for structural reconstruction using fixed four-character expressions in Chinese, Japanese, and Korean, which have a unique canonical order and thus support exact-match scoring. We further propose a diagnostic framework that evaluates models beyond recovery accuracy, including semantic fidelity, logical validity, consistency, robustness sensitivity, and information density. Experiments on twelve widely used LLMs show that structural reconstruction remains difficult even for frontier systems: zero-shot recovery frequently falls below 35%. We also observe a consistent dissociation between semantic recall and structural planning, suggesting that structural robustness is not an automatic byproduct of semantic competence.

</details>


### [55] [Get away with less: Need of source side data curation to build parallel corpus for low resource Machine Translation](https://arxiv.org/abs/2601.08629)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: LALITA框架通过词汇和语言特征筛选复杂句子来优化低资源机器翻译的数据选择，显著提升翻译质量并减少一半以上的数据需求。


<details>
  <summary>Details</summary>
Motivation: 低资源语言机器翻译面临数据获取困难，人工翻译成本过高，需要开发有效的数据筛选框架来优化并行文本构建，确保MT系统在低资源环境下的最佳性能。

Method: 提出LALITA框架，基于词汇和语言特征进行源语言句子选择，主要训练复杂句子（包括现有和合成数据集），在英语-印地语双语文本上评估句子选择策略。

Result: 在50K到800K英语句子的数据集上测试，所有数据规模都显示性能提升；LALITA显著减少数据需求（超过一半），在印地语、奥里亚语、尼泊尔语、挪威尼诺斯克语和德语等多个语言上验证了效率。

Conclusion: LALITA框架通过智能句子选择有效降低机器翻译训练成本，减少数据需求，并在数据增强方面展现实用价值，为低资源语言机器翻译提供了高效的数据管理方案。

Abstract: Data curation is a critical yet under-researched step in the machine translation training paradigm. To train translation systems, data acquisition relies primarily on human translations and digital parallel sources or, to a limited degree, synthetic generation. But, for low-resource languages, human translation to generate sufficient data is prohibitively expensive. Therefore, it is crucial to develop a framework that screens source sentences to form efficient parallel text, ensuring optimal MT system performance in low-resource environments. We approach this by evaluating English-Hindi bi-text to determine effective sentence selection strategies for optimal MT system training. Our extensively tested framework, (Lexical And Linguistically Informed Text Analysis) LALITA, targets source sentence selection using lexical and linguistic features to curate parallel corpora. We find that by training mostly on complex sentences from both existing and synthetic datasets, our method significantly improves translation quality. We test this by simulating low-resource data availabilty with curated datasets of 50K to 800K English sentences and report improved performances on all data sizes. LALITA demonstrates remarkable efficiency, reducing data needs by more than half across multiple languages (Hindi, Odia, Nepali, Norwegian Nynorsk, and German). This approach not only reduces MT systems training cost by reducing training data requirement, but also showcases LALITA's utility in data augmentation.

</details>


### [56] [Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs](https://arxiv.org/abs/2601.08634)
*Chenchen Yuan,Bolei Ma,Zheyu Zhang,Bardh Prenkaj,Frauke Kreuter,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型中道德价值观与政治立场之间的因果关系，通过道德条件化控制模型的政治倾向，发现道德引导能显著改变模型在政治坐标上的位置。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过直接探测或人口统计角色工程来评估LLMs的政治倾向，但社会心理学认为政治意识形态是基本道德直觉的下游结果。本研究旨在探究道德价值观与政治立场之间的因果关系，而非简单地分配人口统计角色。

Method: 将道德取向作为可控条件，让模型支持或拒绝特定道德价值观，然后使用政治罗盘测试评估由此产生的政治立场变化。将道德价值观作为"透镜"，观察道德条件化如何主动引导模型在经济和社会维度上的轨迹。

Result: 研究发现道德条件化能引起模型政治坐标的显著、特定价值观的偏移。这些效应受到角色框架和模型规模的系统调节，并且在实例化相同道德价值观的替代评估工具中具有鲁棒性。

Conclusion: 有效的对齐需要将政治评估锚定在包括道德在内的更广泛社会价值观的背景下，这为更具社会基础的对齐技术铺平了道路。

Abstract: While recent research has systematically documented political orientation in large language models (LLMs), existing evaluations rely primarily on direct probing or demographic persona engineering to surface ideological biases. In social psychology, however, political ideology is also understood as a downstream consequence of fundamental moral intuitions. In this work, we investigate the causal relationship between moral values and political positioning by treating moral orientation as a controllable condition. Rather than simply assigning a demographic persona, we condition models to endorse or reject specific moral values and evaluate the resulting shifts on their political orientations, using the Political Compass Test. By treating moral values as lenses, we observe how moral conditioning actively steers model trajectories across economic and social dimensions. Our findings show that such conditioning induces pronounced, value-specific shifts in models' political coordinates. We further notice that these effects are systematically modulated by role framing and model scale, and are robust across alternative assessment instruments instantiating the same moral value. This highlights that effective alignment requires anchoring political assessments within the context of broader social values including morality, paving the way for more socially grounded alignment techniques.

</details>


### [57] [A Parallel Cross-Lingual Benchmark for Multimodal Idiomaticity Understanding](https://arxiv.org/abs/2601.08645)
*Dilara Torunoğlu-Selamet,Dogukan Arslan,Rodrigo Wilkens,Wei He,Doruk Eryiğit,Thomas Pickard,Adriana S. Pagano,Aline Villavicencio,Gülşen Eryiğit,Ágnes Abuczki,Aida Cardoso,Alesia Lazarenka,Dina Almassova,Amalia Mendes,Anna Kanellopoulou,Antoni Brosa-Rodríguez,Baiba Saulite,Beata Wojtowicz,Bolette Pedersen,Carlos Manuel Hidalgo-Ternero,Chaya Liebeskind,Danka Jokić,Diego Alves,Eleni Triantafyllidi,Erik Velldal,Fred Philippy,Giedre Valunaite Oleskeviciene,Ieva Rizgeliene,Inguna Skadina,Irina Lobzhanidze,Isabell Stinessen Haugen,Jauza Akbar Krito,Jelena M. Marković,Johanna Monti,Josue Alejandro Sauca,Kaja Dobrovoljc,Kingsley O. Ugwuanyi,Laura Rituma,Lilja Øvrelid,Maha Tufail Agro,Manzura Abjalova,Maria Chatzigrigoriou,María del Mar Sánchez Ramos,Marija Pendevska,Masoumeh Seyyedrezaei,Mehrnoush Shamsfard,Momina Ahsan,Muhammad Ahsan Riaz Khan,Nathalie Carmen Hau Norman,Nilay Erdem Ayyıldız,Nina Hosseini-Kivanani,Noémi Ligeti-Nagy,Numaan Naeem,Olha Kanishcheva,Olha Yatsyshyna,Daniil Orel,Petra Giommarelli,Petya Osenova,Radovan Garabik,Regina E. Semou,Rozane Rebechi,Salsabila Zahirah Pranida,Samia Touileb,Sanni Nimb,Sarfraz Ahmad,Sarvinoz Nematkhonova,Shahar Golan,Shaoxiong Ji,Sopuruchi Christian Aboh,Srdjan Sucur,Stella Markantonatou,Sussi Olsen,Vahide Tajalli,Veronika Lipp,Voula Giouli,Yelda Yeşildal Eraydın,Zahra Saaberi,Zhuohan Xie*

Main category: cs.CL

TL;DR: XMPIE是一个包含34种语言、超过一万个条目的平行多语言多模态数据集，用于评估NLP系统对潜在习语表达的理解能力，支持跨语言和跨模态的习语理解研究。


<details>
  <summary>Details</summary>
Motivation: 潜在习语表达（PIEs）与特定语言社区的日常经验密切相关，是评估NLP系统语言和文化能力的重要挑战。目前缺乏能够系统评估多语言和多模态习语理解能力的高质量数据集。

Method: 创建了XMPIE数据集，包含34种语言，由语言专家按照多语言指南创建文本和视觉组件。每个PIE配有五张图像，涵盖从习语意义到字面意义的连续谱，包括语义相关和随机干扰项。

Result: 构建了一个高质量的多语言多模态基准数据集，支持：1）比较不同语言中习语模式的实现和偏好；2）评估模型在不同语言中的PIE理解能力；3）研究跨模态（文本vs图像）的习语理解迁移。

Conclusion: XMPIE为评估多语言和多模态习语理解能力提供了重要基准，有助于深入了解不同语言社区共享的文化方面，并促进跨语言和跨模态的习语理解研究。

Abstract: Potentially idiomatic expressions (PIEs) construe meanings inherently tied to the everyday experience of a given language community. As such, they constitute an interesting challenge for assessing the linguistic (and to some extent cultural) capabilities of NLP systems. In this paper, we present XMPIE, a parallel multilingual and multimodal dataset of potentially idiomatic expressions. The dataset, containing 34 languages and over ten thousand items, allows comparative analyses of idiomatic patterns among language-specific realisations and preferences in order to gather insights about shared cultural aspects. This parallel dataset allows to evaluate model performance for a given PIE in different languages and whether idiomatic understanding in one language can be transferred to another. Moreover, the dataset supports the study of PIEs across textual and visual modalities, to measure to what extent PIE understanding in one modality transfers or implies in understanding in another modality (text vs. image). The data was created by language experts, with both textual and visual components crafted under multilingual guidelines, and each PIE is accompanied by five images representing a spectrum from idiomatic to literal meanings, including semantically related and random distractors. The result is a high-quality benchmark for evaluating multilingual and multimodal idiomatic language understanding.

</details>


### [58] [Safe Language Generation in the Limit](https://arxiv.org/abs/2601.08648)
*Antonios Anastasopoulos,Giuseppe Ateniese,Evgenios M. Kornaropoulos*

Main category: cs.CL

TL;DR: 该论文首次对安全语言生成进行理论分析，基于极限学习范式，证明了安全语言识别不可能，安全语言生成至少与普通语言识别一样困难（同样不可能），并讨论了部分可处理与不可处理的情况。


<details>
  <summary>Details</summary>
Motivation: 随着极限学习领域的发展，虽然语言识别不可能但语言生成可处理，需要研究安全语言生成在现实世界中的理论意义。

Method: 基于极限学习的计算范式，形式化安全语言识别和生成任务，进行理论分析证明。

Result: 证明安全语言识别不可能，安全语言生成至少与普通语言识别一样困难（同样不可能），并识别出一些可处理与不可处理的具体情况。

Conclusion: 安全语言生成在理论上具有挑战性，虽然在某些情况下可能可处理，但总体上存在根本性困难，为实际应用提供了理论边界。

Abstract: Recent results in learning a language in the limit have shown that, although language identification is impossible, language generation is tractable. As this foundational area expands, we need to consider the implications of language generation in real-world settings.
  This work offers the first theoretical treatment of safe language generation. Building on the computational paradigm of learning in the limit, we formalize the tasks of safe language identification and generation. We prove that under this model, safe language identification is impossible, and that safe language generation is at least as hard as (vanilla) language identification, which is also impossible. Last, we discuss several intractable and tractable cases.

</details>


### [59] [RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation](https://arxiv.org/abs/2601.08654)
*Yihan Hong,Huaiyuan Yao,Bolin Shen,Wanpeng Xu,Hua Wei,Yushun Dong*

Main category: cs.CL

TL;DR: RULERS框架通过将评分标准编译为可执行规范，解决LLM作为评分者的稳定性、可验证性和尺度对齐问题，显著提升与人类评分的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为评分者的范式存在三个主要问题：提示敏感性导致的评分标准不稳定、缺乏可审计证据的不可验证推理、以及评分尺度与人类标准不匹配。这些问题限制了LLM评分在实际应用中的可靠性。

Method: 提出RULERS框架，包含三个核心组件：1) 将自然语言评分标准编译为版本化不可变包；2) 通过结构化解码强制确定性证据验证；3) 应用基于Wasserstein距离的轻量级后校准，整个过程不更新模型参数。

Result: 在论文和摘要评估基准测试中，RULERS显著优于代表性基线方法，在人类评分一致性方面表现更好，对对抗性评分标准扰动保持强稳定性，并使较小模型能够媲美大型专有评分模型。

Conclusion: 可靠的LLM评分需要可执行的评分标准、可验证的证据和校准的尺度，而不仅仅是提示词优化。RULERS框架为实现这一目标提供了系统化解决方案。

Abstract: The LLM-as-a-Judge paradigm promises scalable rubric-based evaluation, yet aligning frozen black-box models with human standards remains a challenge due to inherent generation stochasticity. We reframe judge alignment as a criteria transfer problem and isolate three recurrent failure modes: rubric instability caused by prompt sensitivity, unverifiable reasoning that lacks auditable evidence, and scale misalignment with human grading boundaries. To address these issues, we introduce RULERS (Rubric Unification, Locking, and Evidence-anchored Robust Scoring), a compiler-executor framework that transforms natural language rubrics into executable specifications. RULERS operates by compiling criteria into versioned immutable bundles, enforcing structured decoding with deterministic evidence verification, and applying lightweight Wasserstein-based post-hoc calibration, all without updating model parameters. Extensive experiments on essay and summarization benchmarks demonstrate that RULERS significantly outperforms representative baselines in human agreement, maintains strong stability against adversarial rubric perturbations, and enables smaller models to rival larger proprietary judges. Overall, our results suggest that reliable LLM judging requires executable rubrics, verifiable evidence, and calibrated scales rather than prompt phrasing alone. Code is available at https://github.com/LabRAI/Rulers.git.

</details>


### [60] [Analyzing Bias in False Refusal Behavior of Large Language Models for Hate Speech Detoxification](https://arxiv.org/abs/2601.08668)
*Kyuri Im,Shuzhou Yuan,Michael Färber*

Main category: cs.CL

TL;DR: LLMs在仇恨言论净化任务中经常错误拒绝处理，研究发现拒绝行为与语义毒性和特定目标群体相关，提出跨语言翻译策略有效减少错误拒绝。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在仇恨言论净化任务中经常触发安全警报而拒绝处理，这种错误拒绝行为需要系统研究，以理解其触发机制并找到缓解方法。

Method: 评估9个LLM在英语和多语言数据集上的表现，分析语义毒性和目标群体对拒绝行为的影响，提出跨语言翻译策略（英语→中文净化→英语）来减少错误拒绝。

Result: LLM对高语义毒性和针对国籍、宗教、政治意识形态等特定群体的输入更容易拒绝；多语言数据集总体拒绝率低于英语，但仍存在语言依赖的系统性偏见；跨语言翻译策略显著减少错误拒绝，同时保持内容完整性。

Conclusion: LLM在仇恨言论净化中存在系统性偏见和错误拒绝问题，跨语言翻译提供了一种轻量有效的缓解方法，未来需要更深入理解模型的安全机制和偏见来源。

Abstract: While large language models (LLMs) have increasingly been applied to hate speech detoxification, the prompts often trigger safety alerts, causing LLMs to refuse the task. In this study, we systematically investigate false refusal behavior in hate speech detoxification and analyze the contextual and linguistic biases that trigger such refusals. We evaluate nine LLMs on both English and multilingual datasets, our results show that LLMs disproportionately refuse inputs with higher semantic toxicity and those targeting specific groups, particularly nationality, religion, and political ideology. Although multilingual datasets exhibit lower overall false refusal rates than English datasets, models still display systematic, language-dependent biases toward certain targets. Based on these findings, we propose a simple cross-translation strategy, translating English hate speech into Chinese for detoxification and back, which substantially reduces false refusals while preserving the original content, providing an effective and lightweight mitigation approach.

</details>


### [61] [Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization](https://arxiv.org/abs/2601.08682)
*Kushal Chawla,Chenyang Zhu,Pengshan Cai,Sangwoo Cho,Scott Novotney,Ayushman Singh,Jonah Lewis,Keasha Safewright,Alfy Samuel,Erin Babinsky,Shi-Xiong Zhang,Sambit Sahu*

Main category: cs.CL

TL;DR: 该论文介绍了一个工业案例研究，开发用于多方对话摘要的智能体系统，分享了从评估方法到供应商锁定等全生命周期实践洞察。


<details>
  <summary>Details</summary>
Motivation: 多方对话摘要在工业中至关重要，但自动生成高质量摘要面临挑战。现有研究主要使用静态数据集，而实际场景中需求会不断演变，需要更实用的解决方案。

Method: 采用智能体架构开发多方对话摘要系统，通过任务分解实现组件级优化，并分享全生命周期开发实践，包括评估方法、架构设计、数据处理等。

Result: 提出了构建可靠、自适应摘要系统的实用指导，包括：1) 需求演变下的鲁棒评估方法；2) 智能体架构的组件优化；3) 上游数据瓶颈影响；4) LLM提示词可移植性差导致的供应商锁定现实。

Conclusion: 该工业案例研究为从业者提供了构建自适应摘要系统的实用指导，并指出LLM提示词可移植性差导致的供应商锁定是需要关注的重要现实问题。

Abstract: Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across many domains. However, automatically generating high-quality summaries is challenging, as the ideal summary must satisfy a set of complex, multi-faceted requirements. While summarization has received immense attention in research, prior work has primarily utilized static datasets and benchmarks, a condition rare in practical scenarios where requirements inevitably evolve. In this work, we present an industry case study on developing an agentic system to summarize multi-party interactions. We share practical insights spanning the full development lifecycle to guide practitioners in building reliable, adaptable summarization systems, as well as to inform future research, covering: 1) robust methods for evaluation despite evolving requirements and task subjectivity, 2) component-wise optimization enabled by the task decomposition inherent in an agentic architecture, 3) the impact of upstream data bottlenecks, and 4) the realities of vendor lock-in due to the poor transferability of LLM prompts.

</details>


### [62] [QuantEval: A Benchmark for Financial Quantitative Tasks in Large Language Models](https://arxiv.org/abs/2601.08689)
*Zhaolu Kang,Junhao Gong,Wenqing Hu,Shuo Yin,Kehan Jiang,Zhicheng Fang,Yingjie He,Chunlei Meng,Rong Fu,Dongyang Chen,Leqi Zheng,Eric Hanchen Jiang,Yunfei Feng,Yitong Leng,Junfan Zhu,Xiaoyou Chen,Xi Yang,Richeng Xuan*

Main category: cs.CL

TL;DR: QuantEval是一个评估大语言模型在量化金融领域能力的基准，涵盖知识问答、数学推理和策略编码三个维度，并包含CTA风格的回测框架来评估模型生成的交易策略。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在金融量化任务上的评估是碎片化的，主要局限于知识型问答，缺乏对实际量化能力的全面评估，特别是策略编码和回测能力。

Method: 构建QuantEval基准，包含三个维度：知识型问答、量化数学推理和量化策略编码；引入CTA风格回测框架执行模型生成的策略并使用金融绩效指标评估；对开源和专有LLMs进行评估，并进行大规模监督微调和强化学习实验。

Result: 评估发现当前最先进的LLMs与人类专家在推理和策略编码方面存在显著差距；通过领域对齐数据的监督微调和强化学习实验，模型性能得到一致提升。

Conclusion: QuantEval基准将促进LLMs在量化金融能力方面的研究，加速其在真实交易工作流中的实际应用；作者发布了完整的确定性回测配置以确保严格的可复现性。

Abstract: Large Language Models (LLMs) have shown strong capabilities across many domains, yet their evaluation in financial quantitative tasks remains fragmented and mostly limited to knowledge-centric question answering. We introduce QuantEval, a benchmark that evaluates LLMs across three essential dimensions of quantitative finance: knowledge-based QA, quantitative mathematical reasoning, and quantitative strategy coding. Unlike prior financial benchmarks, QuantEval integrates a CTA-style backtesting framework that executes model-generated strategies and evaluates them using financial performance metrics, enabling a more realistic assessment of quantitative coding ability. We evaluate some state-of-the-art open-source and proprietary LLMs and observe substantial gaps to human experts, particularly in reasoning and strategy coding. Finally, we conduct large-scale supervised fine-tuning and reinforcement learning experiments on domain-aligned data, demonstrating consistent improvements. We hope QuantEval will facilitate research on LLMs' quantitative finance capabilities and accelerate their practical adoption in real-world trading workflows. We additionally release the full deterministic backtesting configuration (asset universe, cost model, and metric definitions) to ensure strict reproducibility.

</details>


### [63] [Nationality and Region Prediction from Names: A Comparative Study of Neural Models and Large Language Models](https://arxiv.org/abs/2601.08692)
*Keito Inoshita*

Main category: cs.CL

TL;DR: LLMs在国籍预测任务上优于传统神经网络模型，尤其在细粒度预测中优势明显，但低频国籍预测仍有挑战。模型选择应考虑预测粒度需求，评估需关注错误质量而不仅是准确率。


<details>
  <summary>Details</summary>
Motivation: 从个人姓名预测国籍在营销、人口研究和家谱研究中具有实用价值。传统神经网络模型需要特定任务训练数据，难以泛化到低频国籍和区分同一区域内相似国籍。LLMs通过预训练获得的世界知识有潜力解决这些挑战。

Method: 全面比较神经网络模型和LLMs在国籍预测任务上的表现，评估6个神经网络模型和6种LLM提示策略，涵盖三个粒度级别（国籍、地区、大洲），进行基于频率的分层分析和错误分析。

Result: LLMs在所有粒度级别上都优于神经网络模型，随着粒度变粗差距缩小。简单机器学习方法表现出最高的频率鲁棒性，而预训练模型和LLMs在低频国籍上表现下降。错误分析显示LLMs倾向于做出"接近命中"错误（预测正确地区但错误国籍），而神经网络模型表现出更多跨区域错误和对高频类别的偏见。

Conclusion: LLMs的优越性源于其世界知识，模型选择应考虑所需预测粒度，评估应超越准确率关注错误质量。研究为姓名到国籍预测任务提供了实用指导。

Abstract: Predicting nationality from personal names has practical value in marketing, demographic research, and genealogical studies. Conventional neural models learn statistical correspondences between names and nationalities from task-specific training data, posing challenges in generalizing to low-frequency nationalities and distinguishing similar nationalities within the same region. Large language models (LLMs) have the potential to address these challenges by leveraging world knowledge acquired during pre-training. In this study, we comprehensively compare neural models and LLMs on nationality prediction, evaluating six neural models and six LLM prompting strategies across three granularity levels (nationality, region, and continent), with frequency-based stratified analysis and error analysis. Results show that LLMs outperform neural models at all granularity levels, with the gap narrowing as granularity becomes coarser. Simple machine learning methods exhibit the highest frequency robustness, while pre-trained models and LLMs show degradation for low-frequency nationalities. Error analysis reveals that LLMs tend to make ``near-miss'' errors, predicting the correct region even when nationality is incorrect, whereas neural models exhibit more cross-regional errors and bias toward high-frequency classes. These findings indicate that LLM superiority stems from world knowledge, model selection should consider required granularity, and evaluation should account for error quality beyond accuracy.

</details>


### [64] [RAGShaper: Eliciting Sophisticated Agentic RAG Skills via Automated Data Synthesis](https://arxiv.org/abs/2601.08699)
*Zhengwei Tao,Bo Li,Jialong Wu,Guochen Yan,Huanyao Zhang,Jiahao Xu,Haitao Mi,Wentao Zhang*

Main category: cs.CL

TL;DR: RAGShaper：一个自动化合成RAG任务和鲁棒代理轨迹的数据生成框架，通过构建包含对抗性干扰的信息树和约束导航策略来训练更鲁棒的代理


<details>
  <summary>Details</summary>
Motivation: 当前代理式检索增强生成(RAG)面临高质量训练数据稀缺的问题，传统人工标注无法捕捉真实检索环境中的噪声和复杂性，也无法反映处理检索失败所需的动态推理策略

Method: 提出RAGShaper框架：1) InfoCurator构建包含感知和认知层面对抗性干扰的密集信息树；2) 约束导航策略强制教师代理面对这些干扰，生成展示错误纠正和噪声拒绝的轨迹

Result: 实验表明，使用合成语料库训练的模型显著优于现有基线，在噪声密集和复杂检索任务中表现出更优越的鲁棒性

Conclusion: RAGShaper能够自动化生成高质量的RAG训练数据，有效解决真实世界检索环境中的噪声和复杂性挑战，为构建鲁棒的代理式RAG系统提供了可行的数据合成方案

Abstract: Agentic Retrieval-Augmented Generation (RAG) empowers large language models to autonomously plan and retrieve information for complex problem-solving. However, the development of robust agents is hindered by the scarcity of high-quality training data that reflects the noise and complexity of real-world retrieval environments. Conventional manual annotation is unscalable and often fails to capture the dynamic reasoning strategies required to handle retrieval failures. To bridge this gap, we introduce RAGShaper, a novel data synthesis framework designed to automate the construction of RAG tasks and robust agent trajectories. RAGShaper incorporates an InfoCurator to build dense information trees enriched with adversarial distractors spanning Perception and Cognition levels. Furthermore, we propose a constrained navigation strategy that forces a teacher agent to confront these distractors, thereby eliciting trajectories that explicitly demonstrate error correction and noise rejection. Comprehensive experiments confirm that models trained on our synthesized corpus significantly outperform existing baselines, exhibiting superior robustness in noise-intensive and complex retrieval tasks.

</details>


### [65] [PrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation](https://arxiv.org/abs/2601.08739)
*Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang*

Main category: cs.CL

TL;DR: PrivGemo是一个保护隐私的知识图谱增强推理框架，通过双重架构设计在保持原始KG本地化的同时，支持对匿名化视图进行远程推理，解决了KG隐私泄露问题并提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 许多实际知识图谱是私有的，将检索到的三元组或探索轨迹发送到闭源LLM API会带来泄露风险。现有隐私处理方法主要关注实体名称掩码，但仍面临四个限制：语义掩码下的结构泄露、不可控的远程交互、脆弱的多跳多实体推理，以及稳定性和效率方面的有限经验复用。

Method: PrivGemo采用双重架构设计，保持原始KG知识本地化，同时支持对超越名称掩码的匿名化视图进行远程推理，限制语义和结构暴露。通过检索连接所有主题实体的匿名化长跳路径支持多跳多实体推理，同时在本地KG上进行基础和验证。采用分层控制器和隐私感知经验记忆进一步减少不必要的探索和远程交互。

Result: 在六个基准测试上的综合实验表明，PrivGemo实现了整体最先进的结果，比最强基线高出17.1%。此外，PrivGemo使较小模型（如Qwen3-4B）能够达到与GPT-4-Turbo相当的推理性能。

Conclusion: PrivGemo通过隐私保护的检索增强框架有效解决了KG增强推理中的隐私泄露问题，在保护隐私的同时显著提升了推理性能，使较小模型能够达到大型模型的推理水平。

Abstract: Knowledge graphs (KGs) provide structured evidence that can ground large language model (LLM) reasoning for knowledge-intensive question answering. However, many practical KGs are private, and sending retrieved triples or exploration traces to closed-source LLM APIs introduces leakage risk. Existing privacy treatments focus on masking entity names, but they still face four limitations: structural leakage under semantic masking, uncontrollable remote interaction, fragile multi-hop and multi-entity reasoning, and limited experience reuse for stability and efficiency. To address these issues, we propose PrivGemo, a privacy-preserving retrieval-augmented framework for KG-grounded reasoning with memory-guided exposure control. PrivGemo uses a dual-tower design to keep raw KG knowledge local while enabling remote reasoning over an anonymized view that goes beyond name masking to limit both semantic and structural exposure. PrivGemo supports multi-hop, multi-entity reasoning by retrieving anonymized long-hop paths that connect all topic entities, while keeping grounding and verification on the local KG. A hierarchical controller and a privacy-aware experience memory further reduce unnecessary exploration and remote interactions. Comprehensive experiments on six benchmarks show that PrivGemo achieves overall state-of-the-art results, outperforming the strongest baseline by up to 17.1%. Furthermore, PrivGemo enables smaller models (e.g., Qwen3-4B) to achieve reasoning performance comparable to that of GPT-4-Turbo.

</details>


### [66] [From Rows to Reasoning: A Retrieval-Augmented Multimodal Framework for Spreadsheet Understanding](https://arxiv.org/abs/2601.08741)
*Anmol Gulati,Sahil Sen,Waqar Sarguroh,Kevin Paul*

Main category: cs.CL

TL;DR: FRTR是一个多模态检索增强生成框架，专门用于处理大规模企业级电子表格，通过细粒度嵌入和混合检索技术，显著提升了LLM在复杂表格推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理包含数千行数字、多个关联工作表以及嵌入图表和收据等视觉内容的企业级电子表格时存在困难。现有的电子表格推理方法通常依赖单表压缩或全上下文编码，这限制了可扩展性，且无法反映真实用户与复杂多模态工作簿的交互方式。

Method: 提出了FRTR（From Rows to Reasoning）框架：1）将Excel工作簿分解为细粒度的行、列和块嵌入；2）采用基于互惠排名融合（RRF）的混合词汇-稠密检索；3）集成多模态嵌入以同时处理数值和视觉信息。

Result: 在FRTR-Bench基准测试中，使用Claude Sonnet 4.5达到74%的答案准确率，相比之前最佳方法的24%有显著提升。在SpreadsheetLLM基准测试中，使用GPT-5达到87%准确率，同时相比上下文压缩方法减少了约50%的token使用量。

Conclusion: FRTR框架通过细粒度分解和混合检索策略，有效解决了LLM在大规模多模态电子表格推理中的挑战，在准确性和效率方面都取得了显著改进，为实际企业应用提供了可行的解决方案。

Abstract: Large Language Models (LLMs) struggle to reason over large-scale enterprise spreadsheets containing thousands of numeric rows, multiple linked sheets, and embedded visual content such as charts and receipts. Prior state-of-the-art spreadsheet reasoning approaches typically rely on single-sheet compression or full-context encoding, which limits scalability and fails to reflect how real users interact with complex, multimodal workbooks. We introduce FRTR-Bench, the first large-scale benchmark for multimodal spreadsheet reasoning, comprising 30 enterprise-grade Excel workbooks spanning nearly four million cells and more than 50 embedded images. To address these challenges, we present From Rows to Reasoning (FRTR), an advanced, multimodal retrieval-augmented generation framework that decomposes Excel workbooks into granular row, column, and block embeddings, employs hybrid lexical-dense retrieval with Reciprocal Rank Fusion (RRF), and integrates multimodal embeddings to reason over both numerical and visual information. We tested FRTR on six LLMs, achieving 74% answer accuracy on FRTR-Bench with Claude Sonnet 4.5, a substantial improvement over prior state-of-the-art approaches that reached only 24%. On the SpreadsheetLLM benchmark, FRTR achieved 87% accuracy with GPT-5 while reducing token usage by roughly 50% compared to context-compression methods.

</details>


### [67] [Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents](https://arxiv.org/abs/2601.08742)
*Xin Quan,Jiafeng Xiong,Marco Valentino,André Freitas*

Main category: cs.CL

TL;DR: 论文提出Attributional NLI框架，将社会心理学原理融入自然语言推理，用于评估LLM在多智能体环境中的意图推理能力，并通过实验证明神经符号方法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 传统自然语言推理无法捕捉多智能体环境中基于意图的复杂推理，而理解潜在意图对LLM在交互系统中的运作至关重要，这一能力尚未得到充分探索。

Method: 提出Attributional NLI框架，结合溯因推理（生成潜在意图假设）和演绎验证（得出逻辑结论）。通过Undercover-V文本游戏实验，比较三种LLM智能体：仅用演绎推理的标准NLI智能体、使用溯因-演绎推理的Att-NLI智能体、以及结合外部定理证明器的神经符号Att-NLI智能体。

Result: 实验显示归因推理能力存在明显层级，神经符号智能体表现最佳，平均胜率达到17.08%，显著优于其他方法。

Conclusion: Att-NLI框架有助于开发具有复杂推理能力的智能体，同时突显了神经符号AI在构建理性LLM智能体方面的潜力，特别是在多智能体环境中。

Abstract: Attributional inference, the ability to predict latent intentions behind observed actions, is a critical yet underexplored capability for large language models (LLMs) operating in multi-agent environments. Traditional natural language inference (NLI), in fact, fails to capture the nuanced, intention-driven reasoning essential for complex interactive systems. To address this gap, we introduce Attributional NLI (Att-NLI), a framework that extends NLI with principles from social psychology to assess an agent's capacity for abductive intentional inference (generating hypotheses about latent intentions), and subsequent deductive verification (drawing valid logical conclusions). We instantiate Att-NLI via a textual game, Undercover-V, experimenting with three types of LLM agents with varying reasoning capabilities and access to external tools: a standard NLI agent using only deductive inference, an Att-NLI agent employing abductive-deductive inference, and a neuro-symbolic Att-NLI agent performing abductive-deductive inference with external theorem provers. Extensive experiments demonstrate a clear hierarchy of attributional inference capabilities, with neuro-symbolic agents consistently outperforming others, achieving an average win rate of 17.08%. Our results underscore the role that Att-NLI can play in developing agents with sophisticated reasoning capabilities, highlighting, at the same time, the potential impact of neuro-symbolic AI in building rational LLM agents acting in multi-agent environments.

</details>


### [68] [TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL](https://arxiv.org/abs/2601.08743)
*Jinbo Su,Yuxuan Hu,Cuiping Li,Hong Chen,Jia Li,Lintao Ma,Jing Zhang*

Main category: cs.CL

TL;DR: TableCache：通过预计算数据库表的KV缓存并建立Table Trie结构，在Text-to-SQL任务中实现跨查询的KV缓存共享，显著降低TTFT延迟


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based方法在Text-to-SQL任务中需要将完整数据库模式包含在提示中，导致上下文过长和预填充延迟增加。虽然用户查询通常关注重复的表集合，但当前推理引擎在处理不同表顺序的查询时会产生冗余的前缀缓存副本。

Method: 1. 离线预计算表表示作为KV缓存；2. 计算表缓存时保持主外键关系；3. 构建Table Trie结构支持高效KV缓存查找；4. 引入缓存管理系统，包括查询重排序策略提高缓存命中率；5. 设计计算加载管道并行化模型推理和缓存加载。

Result: TableCache实现了最高3.62倍的Time to First Token (TTFT)加速，性能下降可忽略不计。

Conclusion: 通过预计算表缓存和构建Table Trie结构，TableCache有效解决了Text-to-SQL任务中KV缓存冗余问题，显著提升了推理效率，为LLM-based数据库查询优化提供了新思路。

Abstract: In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets-offering an opportunity for KV cache sharing across queries-current inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user queries with varying table orders. To address this inefficiency, we propose precomputing table representations as KV caches offline and querying the required ones online. A key aspect of our approach is the computation of table caches while preserving primary foreign key relationships between tables. Additionally, we construct a Table Trie structure to facilitate efficient KV cache lookups during inference. To enhance cache performance, we introduce a cache management system with a query reranking strategy to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading. Experimental results show that our proposed TableCache achieves up to a 3.62x speedup in Time to First Token (TTFT) with negligible performance degradation.

</details>


### [69] [To Retrieve or To Think? An Agentic Approach for Context Evolution](https://arxiv.org/abs/2601.08747)
*Rubing Chen,Jian Wang,Wenjie Li,Xiao-Yong Wei,Qing Li*

Main category: cs.CL

TL;DR: ACE框架通过元认知启发的动态决策机制，在需要时检索外部知识，避免冗余检索，提高多跳问答任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有上下文增强方法（如检索增强生成）通常采用僵化的暴力策略，在每一步都执行检索，这导致不必要的计算成本，并且由于上下文充满无关噪声而降低性能。

Method: 提出Agentic Context Evolution (ACE)框架，受人类元认知启发，通过中央编排代理使用多数投票策略动态决定是寻求新证据还是利用现有知识进行推理。框架在检索代理（外部检索）和推理代理（内部分析和精炼）之间交替激活。

Result: 在具有挑战性的多跳QA基准测试中，ACE在准确性方面显著优于竞争基线，同时实现了高效的token消耗。

Conclusion: ACE通过消除冗余检索步骤，保持简洁且进化的上下文，为推进复杂知识密集型任务的上下文进化生成提供了有价值的见解。

Abstract: Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks.However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. To address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting.It aims to alternate between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption.Our work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.

</details>


### [70] [Spatial Context Improves the Integration of Text with Remote Sensing for Mapping Environmental Variables](https://arxiv.org/abs/2601.08750)
*Valerie Zermatten,Chiara Vanalli,Gencer Sumbul,Diego Marcos,Devis Tuia*

Main category: cs.CL

TL;DR: 提出基于注意力的方法，结合航空影像和地理定位文本，通过空间邻域整合多模态信息，用于预测环境变量。


<details>
  <summary>Details</summary>
Motivation: 文本作为生态学新兴数据源，包含独特信息，可与地理空间数据互补，提供局部尺度的环境洞察。但文本数据在生态应用中的贡献不明确，可用性稀疏且与地理空间数据整合困难。

Method: 提出注意力机制方法，结合视觉（航空影像）和文本表示与地理位置编码，通过注意力模块动态选择对预测任务有用的空间邻居。

Result: 在EcoWikiRS数据集上评估，预测SWECO25数据立方体的103个环境变量。该方法持续优于单位置或单模态（仅图像或仅文本）基线。在气候、土壤、人口和土地利用/土地覆盖变量上表现显著提升。

Conclusion: 结合文本和图像数据时，包含空间上下文能显著提升环境变量预测性能，证明了多模态空间整合方法的有效性。

Abstract: Recent developments in natural language processing highlight text as an emerging data source for ecology. Textual resources carry unique information that can be used in complementarity with geospatial data sources, thus providing insights at the local scale into environmental conditions and properties hidden from more traditional data sources. Leveraging textual information in a spatial context presents several challenges. First, the contribution of textual data remains poorly defined in an ecological context, and it is unclear for which tasks it should be incorporated. Unlike ubiquitous satellite imagery or environmental covariates, the availability of textual data is sparse and irregular; its integration with geospatial data is not straightforward. In response to these challenges, this work proposes an attention-based approach that combines aerial imagery and geolocated text within a spatial neighbourhood, i.e. integrating contributions from several nearby observations. Our approach combines vision and text representations with a geolocation encoding, with an attention-based module that dynamically selects spatial neighbours that are useful for predictive tasks.The proposed approach is applied to the EcoWikiRS dataset, which combines high-resolution aerial imagery with sentences extracted from Wikipedia describing local environmental conditions across Switzerland. Our model is evaluated on the task of predicting 103 environmental variables from the SWECO25 data cube. Our approach consistently outperforms single-location or unimodal, i.e. image-only or text-only, baselines. When analysing variables by thematic groups, results show a significant improvement in performance for climatic, edaphic, population and land use/land cover variables, underscoring the benefit of including the spatial context when combining text and image data.

</details>


### [71] [Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge](https://arxiv.org/abs/2601.08808)
*Yao Tang,Li Dong,Yaru Hao,Qingxiu Dong,Furu Wei,Jiatao Gu*

Main category: cs.CL

TL;DR: 提出Multiplex Thinking方法，通过采样K个候选token并聚合其嵌入到单个连续多路复用token中，实现随机软推理机制，在保持词汇嵌入先验的同时压缩序列长度，并通过强化学习优化。


<details>
  <summary>Details</summary>
Motivation: 大语言模型使用思维链(CoT)解决复杂推理任务时会产生长序列和低带宽问题，而人类通常通过维护可能下一步的概率分布进行软推理。希望开发一种更紧凑、更高效的推理机制。

Method: 在每个思考步骤中，采样K个候选token，将它们的嵌入聚合到单个连续多路复用token中。这种方法保持了词汇嵌入先验和标准离散生成的采样动态，同时诱导出可处理的多路复用轨迹概率分布。然后使用策略强化学习直接优化多路复用轨迹。

Result: 在具有挑战性的数学推理基准测试中，Multiplex Thinking从Pass@1到Pass@1024都一致优于强大的离散CoT和RL基线方法，同时产生更短的序列。

Conclusion: Multiplex Thinking是一种自适应的软推理机制：当模型置信度高时，多路复用token接近离散，行为类似标准CoT；当不确定时，它能紧凑地表示多个可能的下一个步骤而不增加序列长度，实现了高效推理。

Abstract: Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at https://github.com/GMLR-Penn/Multiplex-Thinking.

</details>


### [72] [Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System](https://arxiv.org/abs/2601.08829)
*Hsiang-Wei Huang,Junbin Lu,Kuang-Ming Chen,Jenq-Neng Hwang*

Main category: cs.CL

TL;DR: 研究探索在Elo排名系统中使用LLM代理审稿人进行论文评审的动态，通过真实会议投稿数据模拟多轮评审，比较基线设置与加入Elo评分和审稿人记忆的条件，发现Elo能提高区域主席决策准确性，但审稿人会适应性地利用Elo系统而不提升评审努力。


<details>
  <summary>Details</summary>
Motivation: 探索在学术会议评审系统中引入Elo排名机制对LLM代理审稿人动态的影响，研究如何通过模拟多轮评审交互来优化评审过程，提高决策质量。

Method: 使用真实会议论文投稿数据，构建多LLM代理审稿人系统，每个代理具有不同角色特征。在区域主席主持下进行多轮评审交互，比较基线设置与加入Elo评分和审稿人记忆的条件。

Result: 模拟结果显示：1）加入Elo评分能提高区域主席决策准确性；2）审稿人会发展出适应性评审策略，利用Elo系统而不增加实际评审努力；3）揭示了LLM代理在结构化评审系统中的行为模式。

Conclusion: Elo排名系统能有效提升评审决策质量，但需要警惕审稿人可能发展出"博弈"策略。研究为优化学术评审流程提供了新视角，代码已开源供进一步研究。

Abstract: In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort. Our code is available at https://github.com/hsiangwei0903/EloReview.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [73] [Contact-aware Path Planning for Autonomous Neuroendovascular Navigation](https://arxiv.org/abs/2601.07945)
*Aabha Tamhankar,Ron Alterovitz,Ajit S. Puri,Giovanni Pittiglio*

Main category: cs.RO

TL;DR: 提出了一种用于神经血管导航的确定性、时间高效的接触感知路径规划器，利用血管术前和术中图像信息，通过智能预测和利用与解剖结构的相互作用来导航预弯曲被动工具。


<details>
  <summary>Details</summary>
Motivation: 神经血管导航需要精确控制预弯曲工具在复杂血管结构中的运动，传统方法难以高效处理工具与血管壁的接触相互作用，需要开发能够智能利用接触信息的时间高效路径规划算法。

Method: 基于采样的路径规划器，推导并采用运动学模型，利用简化的运动基元进行树扩展，结合术前和术中血管图像信息，智能预测和利用工具与解剖结构的相互作用。

Result: 在最坏情况下22.8秒内达到100%收敛率，亚毫米级跟踪误差（小于0.64毫米），在代表约94%患者的解剖体模上验证有效，计算速度快且精度损失可忽略。

Conclusion: 该方法为神经血管导航提供了一种确定性、时间高效的接触感知路径规划解决方案，能够快速计算可行路径，在复杂血管解剖结构中表现出优异的收敛性和跟踪精度。

Abstract: We propose a deterministic and time-efficient contact-aware path planner for neurovascular navigation. The algorithm leverages information from pre- and intra-operative images of the vessels to navigate pre-bent passive tools, by intelligently predicting and exploiting interactions with the anatomy. A kinematic model is derived and employed by the sampling-based planner for tree expansion that utilizes simplified motion primitives. This approach enables fast computation of the feasible path, with negligible loss in accuracy, as demonstrated in diverse and representative anatomies of the vessels. In these anatomical demonstrators, the algorithm shows a 100% convergence rate within 22.8s in the worst case, with sub-millimeter tracking errors (less than 0.64 mm), and is found effective on anatomical phantoms representative of around 94% of patients.

</details>


### [74] [Fiducial Exoskeletons: Image-Centric Robot State Estimation](https://arxiv.org/abs/2601.08034)
*Cameron Smith,Basile Van Hoorick,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: Fiducial Exoskeletons：通过单张RGB图像进行3D机器人状态估计的新方法，使用带标记的3D打印外骨骼替代传统繁琐的标定流程


<details>
  <summary>Details</summary>
Motivation: 传统机器人状态估计方法依赖高精度执行器和耗时的手眼标定流程，而现代基于学习的机器人控制越来越多地使用低成本硬件上的RGB观测。需要简化机器人状态估计流程，使其更易于部署。

Method: 1. 将机器人状态估计重新定义为从单张RGB图像估计每个连杆的6D姿态；2. 引入"基准外骨骼"：每个连杆上安装带有已知几何关系的基准标记的3D打印支架；3. 通过轻量级全局优化确保运动学一致性，可选使用编码器读数进行预热启动

Result: 在低成本机械臂上验证，显著简化设置流程，同时提高了标定精度、状态准确性和下游3D控制性能。即使在断电机器人上也能实现鲁棒的状态估计。

Conclusion: Fiducial Exoskeletons提供了一种简单、鲁棒的机器人状态估计方法，通过算法-硬件协同设计，实现了从单张图像获取相机-机器人外参、连杆SE(3)姿态和关节角状态的能力。

Abstract: We introduce Fiducial Exoskeletons, an image-based reformulation of 3D robot state estimation that replaces cumbersome procedures and motor-centric pipelines with single-image inference. Traditional approaches - especially robot-camera extrinsic estimation - often rely on high-precision actuators and require time-consuming routines such as hand-eye calibration. In contrast, modern learning-based robot control is increasingly trained and deployed from RGB observations on lower-cost hardware.
  Our key insight is twofold. First, we cast robot state estimation as 6D pose estimation of each link from a single RGB image: the robot-camera base transform is obtained directly as the estimated base-link pose, and the joint state is recovered via a lightweight global optimization that enforces kinematic consistency with the observed link poses (optionally warm-started with encoder readings). Second, we make per-link 6D pose estimation robust and simple - even without learning - by introducing the fiducial exoskeleton: a lightweight 3D-printed mount with a fiducial marker on each link and known marker-link geometry.
  This design yields robust camera-robot extrinsics, per-link SE(3) poses, and joint-angle state from a single image, enabling robust state estimation even on unplugged robots. Demonstrated on a low-cost robot arm, fiducial exoskeletons substantially simplify setup while improving calibration, state accuracy, and downstream 3D control performance. We release code and printable hardware designs to enable further algorithm-hardware co-design.

</details>


### [75] [Efficient Incremental SLAM via Information-Guided and Selective Optimization](https://arxiv.org/abs/2601.08110)
*Reza Arablouei*

Main category: cs.RO

TL;DR: 提出一种高效增量SLAM后端，结合信息引导门控和选择性部分优化，在保持批量优化精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统增量SLAM方法需要在精度和效率之间权衡：批量优化精度高但计算成本大，而增量方法效率高但可能损失精度。需要一种既能保持全局一致性又能高效计算的方法。

Method: 结合两种互补思想：1) 信息引导门控(IGG)：基于信息矩阵对数行列式的信息论准则量化新测量的贡献，仅在观察到显著信息增益时触发全局优化；2) 选择性部分优化(SPO)：执行多轮高斯牛顿更新，但每轮只优化受新测量影响最大的变量子集，动态调整活跃集直至收敛。

Result: 在基准SLAM数据集上的实验表明，该方法始终匹配批量求解器的估计精度，同时相比传统增量方法实现显著的计算节省。理论分析证明该方法保持了完整高斯牛顿的收敛保证。

Conclusion: 该方法在精度和效率之间提供了原则性平衡，是动态数据丰富环境中实时操作的鲁棒且可扩展的解决方案。

Abstract: We present an efficient incremental SLAM back-end that achieves the accuracy of full batch optimization while substantially reducing computational cost. The proposed approach combines two complementary ideas: information-guided gating (IGG) and selective partial optimization (SPO). IGG employs an information-theoretic criterion based on the log-determinant of the information matrix to quantify the contribution of new measurements, triggering global optimization only when a significant information gain is observed. This avoids unnecessary relinearization and factorization when incoming data provide little additional information. SPO executes multi-iteration Gauss-Newton (GN) updates but restricts each iteration to the subset of variables most affected by the new measurements, dynamically refining this active set until convergence. Together, these mechanisms retain all measurements to preserve global consistency while focusing computation on parts of the graph where it yields the greatest benefit. We provide theoretical analysis showing that the proposed approach maintains the convergence guarantees of full GN. Extensive experiments on benchmark SLAM datasets show that our approach consistently matches the estimation accuracy of batch solvers, while achieving significant computational savings compared to conventional incremental approaches. The results indicate that the proposed approach offers a principled balance between accuracy and efficiency, making it a robust and scalable solution for real-time operation in dynamic data-rich environments.

</details>


### [76] [A Pin-Array Structure for Gripping and Shape Recognition of Convex and Concave Terrain Profiles](https://arxiv.org/abs/2601.08143)
*Takuya Kato,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 开发了一种用于极端环境移动机器人的抓取器，既能抓握不规则地形，又能通过针阵列结构测量地形形状


<details>
  <summary>Details</summary>
Motivation: 多肢攀爬机器人在崎岖地形（如悬崖和洞穴墙壁）上很有效，但在未知自然环境中可能因误抓表面或失去可抓握点而摔倒或卡住。需要一种既能自适应抓握不规则地形，又能准确测量地形形状的抓取器。

Method: 开发了一种采用针阵列结构的抓取器，能够抓握凸凹地形并同时测量地形形状。通过原型机演示了抓取器机制，并评估了其抓取和地形识别性能。

Result: 该抓取器能够抓握凸凹地形并测量地形形状，提出的针阵列设计不仅适用于自适应抓握不规则地形，还能很好地用于3D地形映射。

Conclusion: 开发的针阵列抓取器解决了极端环境中移动机器人抓握和地形识别的问题，为在未知自然环境中安全导航提供了有效解决方案。

Abstract: This paper presents a gripper capable of grasping and recognizing terrain shapes for mobile robots in extreme environments. Multi-limbed climbing robots with grippers are effective on rough terrains, such as cliffs and cave walls. However, such robots may fall over by misgrasping the surface or getting stuck owing to the loss of graspable points in unknown natural environments. To overcome these issues, we need a gripper capable of adaptive grasping to irregular terrains, not only for grasping but also for measuring the shape of the terrain surface accurately. We developed a gripper that can grasp both convex and concave terrains and simultaneously measure the terrain shape by introducing a pin-array structure. We demonstrated the mechanism of the gripper and evaluated its grasping and terrain recognition performance using a prototype. Moreover, the proposed pin-array design works well for 3D terrain mapping as well as adaptive grasping for irregular terrains.

</details>


### [77] [Robust Subpixel Localization of Diagonal Markers in Large-Scale Navigation via Multi-Layer Screening and Adaptive Matching](https://arxiv.org/abs/2601.08161)
*Jing Tao,Banglei Guan,Yang Shang,Shunkun Liang,Qifeng Yu*

Main category: cs.RO

TL;DR: 提出一种用于大规模飞行导航的鲁棒高精度定位方法，通过多层角点筛选和自适应模板匹配解决复杂背景干扰和传统滑动窗口计算效率低的问题


<details>
  <summary>Details</summary>
Motivation: 解决大规模飞行导航中复杂背景干扰导致的定位失败问题，以及传统滑动窗口匹配技术的计算效率低下问题

Method: 采用三层框架：1）通过光照均衡和结构信息提取降维；2）粗到精候选点选择策略降低滑动窗口计算成本；3）为候选点生成自适应模板，通过改进的模板匹配和相关系数极值拟合实现亚像素精度

Result: 实验结果表明该方法在复杂大规模环境中能有效提取和定位对角标记，适用于导航任务中的视场测量

Conclusion: 该方法为大规模飞行导航提供了一种鲁棒、高精度的定位解决方案，特别适合复杂环境下的视场测量应用

Abstract: This paper proposes a robust, high-precision positioning methodology to address localization failures arising from complex background interference in large-scale flight navigation and the computational inefficiency inherent in conventional sliding window matching techniques. The proposed methodology employs a three-tiered framework incorporating multi-layer corner screening and adaptive template matching. Firstly, dimensionality is reduced through illumination equalization and structural information extraction. A coarse-to-fine candidate selection strategy minimizes sliding window computational costs, enabling rapid estimation of the marker's position. Finally, adaptive templates are generated for candidate points, achieving subpixel precision through improved template matching with correlation coefficient extremum fitting. Experimental results demonstrate the method's effectiveness in extracting and localizing diagonal markers in complex, large-scale environments, making it ideal for field-of-view measurement in navigation tasks.

</details>


### [78] [A brain-inspired information fusion method for enhancing robot GPS outages navigation](https://arxiv.org/abs/2601.08244)
*Yaohua Liu,Hengjun Zhang,Binkai Ou*

Main category: cs.RO

TL;DR: 提出基于脉冲神经网络的脑启发GPS/INS融合网络(BGFN)，通过脉冲Transformer和脉冲编码器提取IMU信号时空特征，在GPS失效时提高导航精度


<details>
  <summary>Details</summary>
Motivation: 低成本惯性导航系统存在传感器偏差和测量噪声，在GPS中断时导航精度迅速下降，需要提高GPS拒止环境下的定位连续性

Method: 提出脑启发的GPS/INS融合网络(BGFN)，集成脉冲Transformer和脉冲编码器，同时提取IMU信号的空间特征并捕捉其时间动态，建模车辆姿态、比力、角速率与GPS位置增量之间的关系

Result: 通过真实场景测试和公开数据集实验验证，与传统深度学习方法相比，BGFN在导航性能上达到更高精度和增强的可靠性，特别是在长时间GPS中断情况下

Conclusion: BGFN方法能有效解决低成本INS在GPS中断时的精度下降问题，为GPS拒止环境提供更可靠的导航解决方案

Abstract: Low-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages both current and historical IMU data to estimate vehicle motion. The effectiveness of the proposed method is evaluated through real-world field tests and experiments on public datasets. Compared to conventional deep learning approaches, the results demonstrate that BGFN achieves higher accuracy and enhanced reliability in navigation performance, particularly under prolonged GPS outages.

</details>


### [79] [FSAG: Enhancing Human-to-Dexterous-Hand Finger-Specific Affordance Grounding via Diffusion Models](https://arxiv.org/abs/2601.08246)
*Yifan Han,Pengfei Yi,Junyan Li,Hanqing Wang,Gaojing Zhang,Qi Peng Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: 提出基于预训练扩散模型的数据高效框架，从人类视频演示中提取语义先验，实现无需硬件特定数据集的多指灵巧抓取合成


<details>
  <summary>Details</summary>
Motivation: 灵巧抓取合成面临高维度和运动多样性挑战，现有方法依赖大量硬件特定数据集，限制了新灵巧手设计的可扩展性

Method: 从人类视频演示中提取时间对齐的精细抓取功能，与深度图像3D场景几何融合，通过运动学感知重定向模块映射到不同灵巧手

Result: 系统产生稳定、功能适当的多接触抓取，在常见物体和工具上可靠成功，对未见物体实例、姿态变化和不同手部实现具有强泛化能力

Conclusion: 展示了基于人类演示和预训练生成模型的、可扩展的硬件无关灵巧操作路径，单一深度模态结合基础模型语义即可实现高性能抓取合成

Abstract: Dexterous grasp synthesis remains a central challenge: the high dimensionality and kinematic diversity of multi-fingered hands prevent direct transfer of algorithms developed for parallel-jaw grippers. Existing approaches typically depend on large, hardware-specific grasp datasets collected in simulation or through costly real-world trials, hindering scalability as new dexterous hand designs emerge. To this end, we propose a data-efficient framework, which is designed to bypass robot grasp data collection by exploiting the rich, object-centric semantic priors latent in pretrained generative diffusion models. Temporally aligned and fine-grained grasp affordances are extracted from raw human video demonstrations and fused with 3D scene geometry from depth images to infer semantically grounded contact targets. A kinematics-aware retargeting module then maps these affordance representations to diverse dexterous hands without per-hand retraining. The resulting system produces stable, functionally appropriate multi-contact grasps that remain reliably successful across common objects and tools, while exhibiting strong generalization across previously unseen object instances within a category, pose variations, and multiple hand embodiments. This work (i) introduces a semantic affordance extraction pipeline leveraging vision-language generative priors for dexterous grasping, (ii) demonstrates cross-hand generalization without constructing hardware-specific grasp datasets, and (iii) establishes that a single depth modality suffices for high-performance grasp synthesis when coupled with foundation-model semantics. Our results highlight a path toward scalable, hardware-agnostic dexterous manipulation driven by human demonstrations and pretrained generative models.

</details>


### [80] [Spiking Neural-Invariant Kalman Fusion for Accurate Localization Using Low-Cost IMUs](https://arxiv.org/abs/2601.08248)
*Yaohua Liu,Qiao Xu,Yemin Wang,Hui Yi Leong,Binkai Ou*

Main category: cs.RO

TL;DR: 提出一种结合脉冲神经网络和不变扩展卡尔曼滤波的脑启发状态估计框架，用于提升低成本IMU在移动机器人定位中的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 低成本IMU因其价格优势和易于集成而被广泛用于移动机器人定位，但其复杂的非线性时变噪声特性直接用于航位推算时会导致定位精度显著下降。

Method: 提出脑启发状态估计框架，将脉冲神经网络与不变扩展卡尔曼滤波结合。SNN从受大量随机噪声影响的IMU长序列数据中提取运动特征，通过替代梯度下降算法训练，动态调整InEKF中的协方差噪声参数。将SNN输出与原始IMU测量值融合。

Result: 在KITTI数据集和配备低成本IMU的移动机器人采集的真实世界数据上进行广泛实验，证明该方法在定位精度上优于最先进方法，对传感器噪声表现出强鲁棒性。

Conclusion: 该方法提升了低成本IMU在移动机器人定位中的性能，展示了在实际移动机器人应用中的潜力。

Abstract: Low-cost inertial measurement units (IMUs) are widely utilized in mobile robot localization due to their affordability and ease of integration. However, their complex, nonlinear, and time-varying noise characteristics often lead to significant degradation in localization accuracy when applied directly for dead reckoning. To overcome this limitation, we propose a novel brain-inspired state estimation framework that combines a spiking neural network (SNN) with an invariant extended Kalman filter (InEKF). The SNN is designed to extract motion-related features from long sequences of IMU data affected by substantial random noise and is trained via a surrogate gradient descent algorithm to enable dynamic adaptation of the covariance noise parameter within the InEKF. By fusing the SNN output with raw IMU measurements, the proposed method enhances the robustness and accuracy of pose estimation. Extensive experiments conducted on the KITTI dataset and real-world data collected using a mobile robot equipped with a low-cost IMU demonstrate that the proposed approach outperforms state-of-the-art methods in localization accuracy and exhibits strong robustness to sensor noise, highlighting its potential for real-world mobile robot applications.

</details>


### [81] [ActiveVLA: Injecting Active Perception into Vision-Language-Action Models for Precise 3D Robotic Manipulation](https://arxiv.org/abs/2601.08325)
*Zhenyang Liu,Yongchong Gu,Yikai Wang,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: ActiveVLA：一种具有主动感知能力的视觉-语言-动作框架，通过粗到细的两阶段方法（关键区域定位+主动感知优化）实现高精度细粒度机器人操作


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作方法大多依赖静态腕部摄像头，缺乏主动感知能力，无法在任务执行过程中自适应选择最优视角和分辨率，限制了在长时程任务和细粒度操作场景中的性能

Method: 采用粗到细的两阶段范式：1）关键区域定位：将3D输入投影到多视角2D图像，识别关键3D区域；2）主动感知优化：基于定位区域，使用主动视角选择策略选择最优视角（最大化模态相关性和多样性，最小化遮挡），并进行3D放大以提高关键区域分辨率

Result: 在三个仿真基准测试中优于现有最先进方法，实现了精确的3D操作，并能无缝迁移到真实世界场景，使机器人能够在复杂环境中学习高精度任务

Conclusion: ActiveVLA通过赋予机器人主动感知能力，有效解决了现有VLA方法在细粒度操作中的局限性，为高精度机器人操作提供了新的解决方案

Abstract: Recent advances in robot manipulation have leveraged pre-trained vision-language models (VLMs) and explored integrating 3D spatial signals into these models for effective action prediction, giving rise to the promising vision-language-action (VLA) paradigm. However, most existing approaches overlook the importance of active perception: they typically rely on static, wrist-mounted cameras that provide an end-effector-centric viewpoint. As a result, these models are unable to adaptively select optimal viewpoints or resolutions during task execution, which significantly limits their performance in long-horizon tasks and fine-grained manipulation scenarios. To address these limitations, we propose ActiveVLA, a novel vision-language-action framework that empowers robots with active perception capabilities for high-precision, fine-grained manipulation. ActiveVLA adopts a coarse-to-fine paradigm, dividing the process into two stages: (1) Critical region localization. ActiveVLA projects 3D inputs onto multi-view 2D projections, identifies critical 3D regions, and supports dynamic spatial awareness. (2) Active perception optimization. Drawing on the localized critical regions, ActiveVLA uses an active view selection strategy to choose optimal viewpoints. These viewpoints aim to maximize amodal relevance and diversity while minimizing occlusions. Additionally, ActiveVLA applies a 3D zoom-in to improve resolution in key areas. Together, these steps enable finer-grained active perception for precise manipulation. Extensive experiments demonstrate that ActiveVLA achieves precise 3D manipulation and outperforms state-of-the-art baselines on three simulation benchmarks. Moreover, ActiveVLA transfers seamlessly to real-world scenarios, enabling robots to learn high-precision tasks in complex environments.

</details>


### [82] [Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition](https://arxiv.org/abs/2601.08327)
*Gabriele Calzolari,Vidya Sumathy,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出一个去中心化多智能体强化学习框架，让结构异构的智能体团队在部分可观测、通信受限的动态环境中协同发现和获取随机目标


<details>
  <summary>Details</summary>
Motivation: 解决异构智能体团队在部分可观测、通信受限的动态环境中协同执行目标发现和获取任务的挑战，需要结合局部感知、通信和安全约束

Method: 使用多智能体近端策略优化算法训练智能体策略，采用图注意力网络编码器整合模拟距离感知数据和邻居智能体通信嵌入，结合基于图的通信和轨迹感知安全过滤器

Result: 通过消融研究验证了奖励函数的有效性，仿真结果表明能够安全稳定地执行任务，证明了框架的有效性

Conclusion: 提出的统一框架成功实现了异构智能体团队在复杂环境中的协同目标获取，结合了图注意力网络、安全过滤器和结构化奖励函数，为多智能体系统提供了有效的解决方案

Abstract: This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments characterized by partial observability, communication constraints, and dynamic interactions. Each agent's policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and employs a Graph Attention Network encoder that integrates simulated range-sensing data with communication embeddings exchanged among neighboring agents, enabling context-aware decision-making from both local sensing and relational information. In particular, this work introduces a unified framework that integrates graph-based communication and trajectory-aware safety through safety filters. The architecture is supported by a structured reward formulation designed to encourage effective target discovery and acquisition, collision avoidance, and de-correlation between the agents' communication vectors by promoting informational orthogonality. The effectiveness of the proposed reward function is demonstrated through a comprehensive ablation study. Moreover, simulation results demonstrate safe and stable task execution, confirming the framework's effectiveness.

</details>


### [83] [Large Language Models to Enhance Multi-task Drone Operations in Simulated Environments](https://arxiv.org/abs/2601.08405)
*Yizhan Feng,Hichem Snoussi,Jing Teng,Abel Cherouat,Tian Wang*

Main category: cs.RO

TL;DR: 提出一种基于CodeT5和AirSim的自然语言控制无人机方法，通过微调模型实现自然语言到可执行代码的自动转换，降低操作门槛


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，人机交互面临前所未有的机遇。现有无人机操作门槛较高，需要专业编程知识，希望通过自然语言交互简化操作流程

Method: 1) 使用微调的CodeT5模型；2) 结合基于Unreal Engine的AirSim无人机模拟器；3) 利用ChatGPT生成的自然语言-程序代码对数据集和开发者编写的无人机代码作为训练数据；4) 在模拟器中构建逼真的动态环境

Result: 实验结果表明，该方法在模拟环境中表现出优越的任务执行效率和命令理解能力，能够有效实现自然语言到无人机可执行代码的自动转换

Conclusion: 该方法成功降低了无人机操作门槛，未来计划以模块化方式扩展模型功能，增强对复杂场景的适应性，推动无人机技术在真实环境中的应用

Abstract: Benefiting from the rapid advancements in large language models (LLMs), human-drone interaction has reached unprecedented opportunities. In this paper, we propose a method that integrates a fine-tuned CodeT5 model with the Unreal Engine-based AirSim drone simulator to efficiently execute multi-task operations using natural language commands. This approach enables users to interact with simulated drones through prompts or command descriptions, allowing them to easily access and control the drone's status, significantly lowering the operational threshold. In the AirSim simulator, we can flexibly construct visually realistic dynamic environments to simulate drone applications in complex scenarios. By combining a large dataset of (natural language, program code) command-execution pairs generated by ChatGPT with developer-written drone code as training data, we fine-tune the CodeT5 to achieve automated translation from natural language to executable code for drone tasks. Experimental results demonstrate that the proposed method exhibits superior task execution efficiency and command understanding capabilities in simulated environments. In the future, we plan to extend the model functionality in a modular manner, enhancing its adaptability to complex scenarios and driving the application of drone technologies in real-world environments.

</details>


### [84] [Teaching Robots Like Dogs: Learning Agile Navigation from Luring, Gesture, and Speech](https://arxiv.org/abs/2601.08422)
*Taerim Yoon,Dongho Kang,Jin Cheng,Fatemeh Zargarbashi,Yijiang Huang,Minsung Ahn,Stelian Coros,Sungjoon Choi*

Main category: cs.RO

TL;DR: 提出人机交互框架，让四足机器人通过少量人类演示数据学习理解社交线索和导航行为，支持手势和语音多模态输入，在真实场景中达到97.15%成功率。


<details>
  <summary>Details</summary>
Motivation: 让四足机器人能够理解人类社交线索并产生适当行为，但传统物理引导学习需要大量人类数据，给用户带来沉重负担，需要更高效的学习方法。

Method: 提出人在回路框架，使用物理仿真重建交互场景并聚合数据缓解分布偏移，采用渐进式目标提示策略自适应提供命令和导航目标，支持手势和语音多模态输入。

Result: 在六个真实世界敏捷导航场景（包括跳跃和避障）中测试，总演示数据少于1小时，任务成功率高达97.15%，几乎在所有试验中都取得成功。

Conclusion: 该框架能够以数据高效的方式让机器人学习导航行为，通过多模态自然输入实现准确导航，并增强人类输入与机器人行为的一致性。

Abstract: In this work, we aim to enable legged robots to learn how to interpret human social cues and produce appropriate behaviors through physical human guidance. However, learning through physical engagement can place a heavy burden on users when the process requires large amounts of human-provided data. To address this, we propose a human-in-the-loop framework that enables robots to acquire navigational behaviors in a data-efficient manner and to be controlled via multimodal natural human inputs, specifically gestural and verbal commands. We reconstruct interaction scenes using a physics-based simulation and aggregate data to mitigate distributional shifts arising from limited demonstration data. Our progressive goal cueing strategy adaptively feeds appropriate commands and navigation goals during training, leading to more accurate navigation and stronger alignment between human input and robot behavior. We evaluate our framework across six real-world agile navigation scenarios, including jumping over or avoiding obstacles. Our experimental results show that our proposed method succeeds in almost all trials across these scenarios, achieving a 97.15% task success rate with less than 1 hour of demonstration data in total.

</details>


### [85] [Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?](https://arxiv.org/abs/2601.08434)
*Long Zhang,Yuchen Xia*

Main category: cs.RO

TL;DR: 提出语义与策略双驱动的混合决策框架，结合大语言模型和深度强化学习，实现自动驾驶的具身智能驾驶


<details>
  <summary>Details</summary>
Motivation: 传统模块化自动驾驶在开放世界场景中存在局限性，需要持续的环境理解和逻辑推理能力。虽然大语言模型和具身人工智能提供了改进可能，但仅依赖大语言模型无法实现联合决策，限制了具身智能驾驶的发展。

Method: 提出语义与策略双驱动的混合决策框架，融合大语言模型进行语义理解和认知表征，结合深度强化学习进行实时策略优化，实现持续学习和联合决策。

Result: 通过车道变换规划任务的案例研究实验验证了该框架的性能优越性，展示了其在完成自动驾驶任务中的有效性。

Conclusion: 该框架为具身智能驾驶提供了新的解决方案，并指出了未来研究方向以指导后续工作，推动自动驾驶向具身智能方向发展。

Abstract: The advent of Large Multimodal Models (LMMs) offers a promising technology to tackle the limitations of modular design in autonomous driving, which often falters in open-world scenarios requiring sustained environmental understanding and logical reasoning. Besides, embodied artificial intelligence facilitates policy optimization through closed-loop interactions to achieve the continuous learning capability, thereby advancing autonomous driving toward embodied intelligent (El) driving. However, such capability will be constrained by relying solely on LMMs to enhance EI driving without joint decision-making. This article introduces a novel semantics and policy dual-driven hybrid decision framework to tackle this challenge, ensuring continuous learning and joint decision. The framework merges LMMs for semantic understanding and cognitive representation, and deep reinforcement learning (DRL) for real-time policy optimization. We starts by introducing the foundational principles of EI driving and LMMs. Moreover, we examine the emerging opportunities this framework enables, encompassing potential benefits and representative use cases. A case study is conducted experimentally to validate the performance superiority of our framework in completing lane-change planning task. Finally, several future research directions to empower EI driving are identified to guide subsequent work.

</details>


### [86] [Real2Sim based on Active Perception with automatically VLM-generated Behavior Trees](https://arxiv.org/abs/2601.08454)
*Alessandro Adami,Sebastian Zudaire,Ruggero Carli,Pietro Falco*

Main category: cs.RO

TL;DR: 提出一个自主生成行为树的Real2Sim框架，通过任务特定的物理交互来获取仿真所需参数，无需预定义任务模板或专家设计的探索流程。


<details>
  <summary>Details</summary>
Motivation: 传统Real2Sim流程依赖手动测量或固定的预编程探索程序，限制了其对不同任务和用户意图的适应性。需要一种能够根据具体仿真目标自主获取必要参数的方法。

Method: 基于视觉语言模型进行多模态推理，识别相关对象、推断所需物理参数，并生成结构化行为树。通过扭矩控制的Franka Emika Panda机械臂执行柔顺、接触丰富的交互来估计参数，自动构建物理感知的仿真。

Result: 在真实机械臂上的实验结果表明，该方法能够估计物体质量、表面高度和摩擦相关参数，适用于多种场景，包括遮挡物体和不完整先验模型。

Conclusion: 该方法实现了可解释、意图驱动且自主的Real2Sim流程，将高层推理与物理基础的机器人交互相结合，为仿真建模提供了更灵活、自适应的解决方案。

Abstract: Constructing an accurate simulation model of real-world environments requires reliable estimation of physical parameters such as mass, geometry, friction, and contact surfaces. Traditional real-to-simulation (Real2Sim) pipelines rely on manual measurements or fixed, pre-programmed exploration routines, which limit their adaptability to varying tasks and user intents. This paper presents a Real2Sim framework that autonomously generates and executes Behavior Trees for task-specific physical interactions to acquire only the parameters required for a given simulation objective, without relying on pre-defined task templates or expert-designed exploration routines. Given a high-level user request, an incomplete simulation description, and an RGB observation of the scene, a vision-language model performs multi-modal reasoning to identify relevant objects, infer required physical parameters, and generate a structured Behavior Tree composed of elementary robotic actions. The resulting behavior is executed on a torque-controlled Franka Emika Panda, enabling compliant, contact-rich interactions for parameter estimation. The acquired measurements are used to automatically construct a physics-aware simulation. Experimental results on the real manipulator demonstrate estimation of object mass, surface height, and friction-related quantities across multiple scenarios, including occluded objects and incomplete prior models. The proposed approach enables interpretable, intent-driven, and autonomously Real2Sim pipelines, bridging high-level reasoning with physically-grounded robotic interaction.

</details>


### [87] [AME-2: Agile and Generalized Legged Locomotion via Attention-Based Neural Map Encoding](https://arxiv.org/abs/2601.08485)
*Chong Zhang,Victor Klemm,Fan Yang,Marco Hutter*

Main category: cs.RO

TL;DR: AME-2是一个统一的强化学习框架，通过注意力机制的地图编码器和基于学习的映射管道，实现四足和双足机器人在复杂地形上的敏捷和泛化运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：端到端传感器运动模型泛化能力有限且难以解释；而针对泛化运动的方法又缺乏敏捷性且难以处理视觉遮挡。需要一种既能实现敏捷运动又能泛化到不同地形的统一框架。

Method: 1. 提出注意力机制的地图编码器，提取局部和全局地图特征，聚焦关键区域，生成可解释的嵌入表示；2. 开发基于学习的映射管道，将深度观测转换为带不确定性的局部高程图，并与里程计融合，提供鲁棒的地形表示；3. 结合并行仿真训练控制器，支持在线映射，促进仿真到现实的迁移。

Result: 在四足和双足机器人上验证了AME-2框架，控制器在仿真和真实世界实验中展现出强大的敏捷性和对未见地形的泛化能力。

Conclusion: AME-2框架通过注意力机制的地图编码器和基于学习的映射管道，成功实现了机器人在复杂地形上的敏捷和泛化运动，解决了现有方法在泛化性、敏捷性和处理遮挡方面的局限性。

Abstract: Achieving agile and generalized legged locomotion across terrains requires tight integration of perception and control, especially under occlusions and sparse footholds. Existing methods have demonstrated agility on parkour courses but often rely on end-to-end sensorimotor models with limited generalization and interpretability. By contrast, methods targeting generalized locomotion typically exhibit limited agility and struggle with visual occlusions. We introduce AME-2, a unified reinforcement learning (RL) framework for agile and generalized locomotion that incorporates a novel attention-based map encoder in the control policy. This encoder extracts local and global mapping features and uses attention mechanisms to focus on salient regions, producing an interpretable and generalized embedding for RL-based control. We further propose a learning-based mapping pipeline that provides fast, uncertainty-aware terrain representations robust to noise and occlusions, serving as policy inputs. It uses neural networks to convert depth observations into local elevations with uncertainties, and fuses them with odometry. The pipeline also integrates with parallel simulation so that we can train controllers with online mapping, aiding sim-to-real transfer. We validate AME-2 with the proposed mapping pipeline on a quadruped and a biped robot, and the resulting controllers demonstrate strong agility and generalization to unseen terrains in simulation and in real-world experiments.

</details>


### [88] [AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization](https://arxiv.org/abs/2601.08491)
*Mohamed Afouene Melki,Mohammad Shehab,Mohamed-Slim Alouini*

Main category: cs.RO

TL;DR: 本文提出了一种可持续的水下物联网解决方案，通过AUV同时实现信息上行和声能传输，采用DRL算法优化AoI和公平性，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统水下物联网设备依赖电池供电，存在寿命限制和废弃后环境危害的问题，需要可持续的解决方案来支持长期水下监测和维护任务。

Method: 提出通过自主水下航行器同时进行信息上行和声能传输的方案，采用信息年龄和Jain公平指数作为评估指标，开发了两种深度强化学习算法：高性能的频分双工方案和中等性能的时分双工方案。

Result: 提出的FDD和TDD解决方案相比基线方法显著降低了平均信息年龄，提高了能量收集效率和数据收集公平性。

Conclusion: 该方法为水下物联网设备提供了可持续的运作方案，有望实现设备的无限期运行，解决了传统电池供电设备的局限性。

Abstract: Internet of underwater things (IoUT) is increasingly gathering attention with the aim of monitoring sea life and deep ocean environment, underwater surveillance as well as maintenance of underwater installments. However, conventional IoUT devices, reliant on battery power, face limitations in lifespan and pose environmental hazards upon disposal. This paper introduces a sustainable approach for simultaneous information uplink from the IoUT devices and acoustic energy transfer (AET) to the devices via an autonomous underwater vehicle (AUV), potentially enabling them to operate indefinitely. To tackle the time-sensitivity, we adopt age of information (AoI), and Jain's fairness index. We develop two deep-reinforcement learning (DRL) algorithms, offering a high-complexity, high-performance frequency division duplex (FDD) solution and a low-complexity, medium-performance time division duplex (TDD) approach. The results elucidate that the proposed FDD and TDD solutions significantly reduce the average AoI and boost the harvested energy as well as data collection fairness compared to baseline approaches.

</details>


### [89] [Simplifying ROS2 controllers with a modular architecture for robot-agnostic reference generation](https://arxiv.org/abs/2601.08514)
*Davide Risi,Vincenzo Petrone,Antonio Langella,Lorenzo Pagliara,Enrico Ferrentino,Pasquale Chiacchio*

Main category: cs.RO

TL;DR: 提出ROS2模块化架构，将参考获取、验证和插值与控制律解耦，通过Reference Generator组件处理参考输入，减少控制器代码重复，提高跨平台复用性。


<details>
  <summary>Details</summary>
Motivation: 现有ROS2控制器中，参考处理逻辑与控制律代码紧密耦合，导致代码重复和复用性差。需要一种架构来分离这些关注点，提高控制器在不同机器人平台间的可重用性。

Method: 设计Reference Generator组件，接收来自规划器的单点或轨迹参考，通过ros2_control链式机制以控制器采样周期输出单点参考。实现关节空间和笛卡尔空间两种参考生成器，并开发PD重力补偿、笛卡尔位姿和导纳控制器。

Result: 在模拟和真实机器人（Universal Robots和Franka Emika）上验证：1）所有测试场景中参考都能可靠跟踪；2）参考生成器显著减少链式控制器中的重复代码；3）控制器实现更专注于控制律本身。

Conclusion: 提出的模块化架构成功分离了参考处理与控制律，提高了ROS2控制器的代码复用性和可维护性，支持构建复杂的控制器管道，为机器人控制提供了更灵活的框架。

Abstract: This paper introduces a novel modular architecture for ROS2 that decouples the logic required to acquire, validate, and interpolate references from the control laws that track them. The design includes a dedicated component, named Reference Generator, that receives references, in the form of either single points or trajectories, from external nodes (e.g., planners), and writes single-point references at the controller's sampling period via the existing ros2_control chaining mechanism to downstream controllers. This separation removes duplicated reference-handling code from controllers and improves reusability across robot platforms. We implement two reference generators: one for handling joint-space references and one for Cartesian references, along with a set of new controllers (PD with gravity compensation, Cartesian pose, and admittance controllers) and validate the approach on simulated and real Universal Robots and Franka Emika manipulators. Results show that (i) references are tracked reliably in all tested scenarios, (ii) reference generators reduce duplicated reference-handling code across chained controllers to favor the construction and reuse of complex controller pipelines, and (iii) controller implementations remain focused only on control laws.

</details>


### [90] [Keyframe-based Dense Mapping with the Graph of View-Dependent Local Maps](https://arxiv.org/abs/2601.08520)
*Krzysztof Zielinski,Dominik Belter*

Main category: cs.RO

TL;DR: 提出基于关键帧的NDT建图系统，利用RGB-D传感器数据更新局部NDT地图，采用2D视角相关结构存储单元，通过位姿图实现闭环校正，并与Octomap和NDT-OM进行对比


<details>
  <summary>Details</summary>
Motivation: 传统建图方法未能充分利用RGB-D相机的特性和不确定性模型，需要一种能更好处理传感器特性、自然表示物体距离精度差异、支持闭环校正的建图系统

Method: 基于关键帧的NDT建图系统，使用RGB-D数据更新局部NDT地图，将NDT单元存储在2D视角相关结构中，局部地图存储在位姿图中支持闭环校正，并提出局部地图合并过滤算法构建全局地图

Result: 与Octomap和NDT-OM相比，该方法能更好地利用RGB-D相机特性，自然实现距离相机越近的物体表示精度越高，支持闭环校正后的全局地图更新

Conclusion: 提出的关键帧NDT建图系统有效利用了RGB-D传感器特性，通过视角相关存储和位姿图机制实现了更精确、可闭环校正的建图方案，具有实际应用价值

Abstract: In this article, we propose a new keyframe-based mapping system. The proposed method updates local Normal Distribution Transform maps (NDT) using data from an RGB-D sensor. The cells of the NDT are stored in 2D view-dependent structures to better utilize the properties and uncertainty model of RGB-D cameras. This method naturally represents an object closer to the camera origin with higher precision. The local maps are stored in the pose graph which allows correcting global map after loop closure detection. We also propose a procedure that allows merging and filtering local maps to obtain a global map of the environment. Finally, we compare our method with Octomap and NDT-OM and provide example applications of the proposed mapping method.

</details>


### [91] [QP-Based Control of an Underactuated Aerial Manipulator under Constraints](https://arxiv.org/abs/2601.08523)
*Nesserine Laribi,Mohammed Rida Mokhtari,Abdelaziz Benallegue,Abdelhafid El-Hadri,Mehdi Benallegue*

Main category: cs.RO

TL;DR: 提出一种约束感知控制框架，用于欠驱动空中机械臂，实现精确末端执行器轨迹跟踪，同时显式考虑安全和可行性约束。


<details>
  <summary>Details</summary>
Motivation: 解决欠驱动空中机械臂在复杂环境中执行任务时，需要同时满足精确轨迹跟踪、安全约束和系统可行性的挑战性问题。

Method: 将控制问题表述为二次规划问题，计算动态一致广义加速度，考虑欠驱动、执行器边界和系统约束；加入基于无源性的积分作用增强鲁棒性。

Result: 通过高保真物理仿真验证，在参数扰动、粘性关节摩擦和实际传感状态下，实现了精确跟踪、平滑控制输入和可靠的约束满足。

Conclusion: 提出的约束感知控制框架能够有效处理欠驱动空中机械臂的复杂控制问题，在实际操作条件下实现安全可靠的性能。

Abstract: This paper presents a constraint-aware control framework for underactuated aerial manipulators, enabling accurate end-effector trajectory tracking while explicitly accounting for safety and feasibility constraints. The control problem is formulated as a quadratic program that computes dynamically consistent generalized accelerations subject to underactuation, actuator bounds, and system constraints. To enhance robustness against disturbances, modeling uncertainties, and steady-state errors, a passivity-based integral action is incorporated at the torque level without compromising feasibility. The effectiveness of the proposed approach is demonstrated through high-fidelity physics-based simulations, which include parameter perturbations, viscous joint friction, and realistic sensing and state-estimation effects. This demonstrates accurate tracking, smooth control inputs, and reliable constraint satisfaction under realistic operating conditions.

</details>


### [92] [VLingNav: Embodied Navigation with Adaptive Reasoning and Visual-Assisted Linguistic Memory](https://arxiv.org/abs/2601.08665)
*Shaoan Wang,Yuanfei Luo,Xingyu Chen,Aocheng Luo,Dongyue Li,Chang Liu,Sheng Chen,Yangang Zhang,Junzhi Yu*

Main category: cs.RO

TL;DR: VLingNav是一个基于语言驱动认知的视觉语言行动模型，通过自适应思维链机制和视觉辅助语言记忆模块，在具身导航任务中实现了最先进的性能，并能零样本迁移到真实机器人平台。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要依赖从观察到动作的被动映射，缺乏显式推理能力和持久记忆，难以处理复杂、长时程的导航任务。需要开发具有认知能力的导航模型。

Method: 1. 引入自适应思维链机制，动态触发显式推理，实现快速直觉执行与慢速深思规划的流畅切换；2. 开发视觉辅助语言记忆模块，构建持久跨模态语义记忆；3. 构建Nav-AdaCoT-2.9M数据集，包含自适应CoT标注；4. 采用在线专家指导强化学习训练。

Result: VLingNav在多个具身导航基准测试中达到最先进性能，能够零样本迁移到真实机器人平台，执行各种导航任务，展现出强大的跨领域和跨任务泛化能力。

Conclusion: VLingNav通过语言驱动认知框架，结合自适应推理和持久记忆，显著提升了VLA模型在复杂具身导航任务中的能力，实现了从模拟环境到真实机器人的有效迁移。

Abstract: VLA models have shown promising potential in embodied navigation by unifying perception and planning while inheriting the strong generalization abilities of large VLMs. However, most existing VLA models rely on reactive mappings directly from observations to actions, lacking the explicit reasoning capabilities and persistent memory required for complex, long-horizon navigation tasks. To address these challenges, we propose VLingNav, a VLA model for embodied navigation grounded in linguistic-driven cognition. First, inspired by the dual-process theory of human cognition, we introduce an adaptive chain-of-thought mechanism, which dynamically triggers explicit reasoning only when necessary, enabling the agent to fluidly switch between fast, intuitive execution and slow, deliberate planning. Second, to handle long-horizon spatial dependencies, we develop a visual-assisted linguistic memory module that constructs a persistent, cross-modal semantic memory, enabling the agent to recall past observations to prevent repetitive exploration and infer movement trends for dynamic environments. For the training recipe, we construct Nav-AdaCoT-2.9M, the largest embodied navigation dataset with reasoning annotations to date, enriched with adaptive CoT annotations that induce a reasoning paradigm capable of adjusting both when to think and what to think about. Moreover, we incorporate an online expert-guided reinforcement learning stage, enabling the model to surpass pure imitation learning and to acquire more robust, self-explored navigation behaviors. Extensive experiments demonstrate that VLingNav achieves state-of-the-art performance across a wide range of embodied navigation benchmarks. Notably, VLingNav transfers to real-world robotic platforms in a zero-shot manner, executing various navigation tasks and demonstrating strong cross-domain and cross-task generalization.

</details>


### [93] [A Hybrid Model-based and Data-based Approach Developed for a Prosthetic Hand Wrist](https://arxiv.org/abs/2601.08711)
*Shifa Sulaiman,Francesco Schetter,Mehul Menon,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 提出一种基于人工神经网络和滑模控制的模型控制器，用于PRISMA HAND II假肢手的肌腱驱动软连续腕部，实现快速动态响应和低计算量


<details>
  <summary>Details</summary>
Motivation: 将先进控制算法融入假肢手能显著增强其模拟人手复杂运动的能力，需要开发一种能提供快速动态响应且计算量小的腕部控制器

Method: 结合人工神经网络（ANN）和滑模控制器（SMC），ANN计算弯曲角度，SMC调节肌腱力，基于分段恒定曲率假设建立腕部运动学和动力学模型

Result: 通过仿真研究和实验验证，该控制器在相同腕部上相比其他控制策略表现出更好的性能

Conclusion: 提出的ANN-SMC控制器能有效控制假肢手腕部运动，提供快速动态响应并减少计算量，为假肢手控制提供了有前景的解决方案

Abstract: The incorporation of advanced control algorithms into prosthetic hands significantly enhances their ability to replicate the intricate motions of a human hand. This work introduces a model-based controller that combines an Artificial Neural Network (ANN) approach with a Sliding Mode Controller (SMC) designed for a tendon-driven soft continuum wrist integrated into a prosthetic hand known as "PRISMA HAND II". Our research focuses on developing a controller that provides a fast dynamic response with reduced computational effort during wrist motions. The proposed controller consists of an ANN for computing bending angles together with an SMC to regulate tendon forces. Kinematic and dynamic models of the wrist are formulated using the Piece-wise Constant Curvature (PCC) hypothesis. The performance of the proposed controller is compared with other control strategies developed for the same wrist. Simulation studies and experimental validations of the fabricated wrist using the controller are included in the paper.

</details>


### [94] [Real-Time Localization Framework for Autonomous Basketball Robots](https://arxiv.org/abs/2601.08713)
*Naren Medarametla,Sreejon Mondal*

Main category: cs.RO

TL;DR: 提出一种结合经典方法与学习方法的混合定位算法，仅利用球场地面视觉数据进行篮球场自定位


<details>
  <summary>Details</summary>
Motivation: 定位是自主机器人的基本能力，在Robocon 2025比赛中，准确可靠的定位对于提高射击精度、避免与其他机器人碰撞以及高效导航比赛场地至关重要

Method: 混合定位算法，集成经典技术与基于学习的方法，仅依赖球场地面的视觉数据

Result: 未在摘要中明确说明具体结果，但暗示该方法能实现篮球场上的自定位

Conclusion: 通过结合经典与学习方法，仅使用视觉数据即可实现有效的机器人定位，适用于Robocon 2025等比赛场景

Abstract: Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. In this paper, we propose a hybrid localization algorithm that integrates classical techniques with learning based methods that rely solely on visual data from the court's floor to achieve self-localization on the basketball field.

</details>


### [95] [Older Adults' Preferences for Feedback Cadence from an Exercise Coach Robot](https://arxiv.org/abs/2601.08819)
*Roshni Kaushik,Reid Simmons*

Main category: cs.RO

TL;DR: 研究探索老年人对机器人运动教练不同节奏反馈的感知，发现改变一种模态的节奏会影响对该模态及另一模态的感知。


<details>
  <summary>Details</summary>
Motivation: 人们以不同方式回应反馈和指导，机器人需要个性化互动并利用语言和非语言沟通线索。特别关注老年人对机器人运动教练反馈节奏的反应。

Method: 通过在线研究，让老年人观看机器人以不同节奏提供语言和非语言反馈的视频，评估他们对不同节奏反馈的感知。

Result: 改变一种模态的节奏会影响对该模态及另一模态的感知。研究结果为设计机器人教练在运动训练中的反馈频率提供了依据。

Conclusion: 研究结果可用于优化机器人教练对老年人群体的反馈设计，特别是在运动训练中调整语言和非语言反馈的节奏。

Abstract: People can respond to feedback and guidance in different ways, and it is important for robots to personalize their interactions and utilize verbal and nonverbal communication cues. We aim to understand how older adults respond to different cadences of verbal and nonverbal feedback of a robot exercise coach. We conducted an online study of older adults, where participants evaluated videos of the robot giving feedback at different cadences for each modality. The results indicate that changing the cadence of one modality affects the perception of both it and the other modality. We can use the results from this study to better design the frequency of the robot coach's feedback during an exercise session with this population.

</details>
