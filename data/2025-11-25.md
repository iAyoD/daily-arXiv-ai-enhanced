<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 77]
- [cs.RO](#cs.RO) [Total: 65]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering](https://arxiv.org/abs/2511.17559)
*Gyubok Lee,Woosog Chay,Edward Choi*

Main category: cs.CL

TL;DR: SCARE是一个用于评估电子健康记录问答系统中后置安全层的基准测试，专注于问题可回答性分类和SQL查询验证/修正的联合任务。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中部署文本到SQL模型存在安全风险，错误的SQL查询可能危及患者护理。现有研究缺乏对后置验证机制的统一评估基准。

Method: 构建包含4,200个问题-SQL查询-期望输出的三元组数据集，基于MIMIC-III、MIMIC-IV和eICU数据库，涵盖7种不同文本到SQL模型生成的多样化查询。

Result: 实验揭示了问题分类和SQL错误修正之间的关键权衡，为未来研究指明了方向。

Conclusion: SCARE基准填补了电子健康记录问答系统安全部署的关键空白，为后置验证机制提供了标准化评估框架。

Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.

</details>


### [2] [$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving](https://arxiv.org/abs/2511.17560)
*Yuechi Zhou,Yi Su,Jianxin Zhang,Juntao Li,Qingrong Xia,Zhefeng Wang,Xinyu Duan,Baoxing Huai*

Main category: cs.CL

TL;DR: 提出A³算法，通过预计算和选择性融合文本块的KV缓存，在减少解码延迟的同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能处理长上下文，但解码延迟和内存开销仍然很大，现有KV缓存重用方法存在性能下降问题。

Method: 提出注意力感知的准确KV缓存融合算法(A³)，基于问题相关性预计算和选择性融合文本块的KV缓存。

Result: 在多个基准测试和LLM上，A³相比四个基线方法获得最佳任务性能，同时将首token时间减少2倍。

Conclusion: A³算法能有效解决长上下文处理中的延迟问题，实现准确KV缓存融合并显著提升效率。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmented Generation (RAG) systems. However, despite their ability to handle long sequences, the resulting decoding latency and memory overhead remain substantial, posing challenges for real-world deployment. Recent advances in KV Cache reuse have shown potential to mitigate these costs, but still suffer from notable performance degradation. To address this issue, we conduct an in-depth investigation of recomputation-based reuse methods and observe that the recomputed tokens often fail to align with the context segments most relevant to the question. This misalignment hinders proper updates to the critical contextual representations. Therefore, we propose the $\textbf{A}$ttention-$\textbf{A}$ware $\textbf{A}$ccurate KV Cache Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache of text chunks based on their relevance to the question, achieving accurate integration with minimal computational overhead. Extensive experiments on various benchmarks and LLMs demonstrate that $A^3$ achieves the best task performance compared to four baselines while reducing the time-to-first-token (TTFT) by 2$\times$.

</details>


### [3] [LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models](https://arxiv.org/abs/2511.17561)
*Huimin Ren,Yan Liang,Baiqiao Su,Chaobo Sun,Hengtong Lu,Kaike Zhang,Chen Wei*

Main category: cs.CL

TL;DR: LexInstructEval是一个新的基准测试和评估框架，用于评估大语言模型在细粒度词汇指令遵循方面的能力，通过基于规则的语法将复杂指令解构为<过程、关系、值>三元组，实现客观验证。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM遵循复杂细粒度词汇指令能力的方法存在局限性：人工评估主观且昂贵，自动LLM-as-a-judge系统存在偏见和不可靠性，现有程序化基准测试缺乏表达复杂组合约束的能力。

Method: 基于正式的基于规则语法，将复杂指令解构为<过程、关系、值>三元组，通过多阶段人工参与流程系统生成多样化数据集，并使用透明的程序化引擎进行客观验证。

Result: 开发了LexInstructEval基准测试框架，包含数据集和开源评估工具，支持对LLM可控性和可靠性的进一步研究。

Conclusion: LexInstructEval为解决LLM细粒度词汇指令遵循评估的挑战提供了系统化、客观的解决方案，促进了LLM可控性和可靠性研究的发展。

Abstract: The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods either rely on subjective and costly human evaluation or on automated LLM-as-a-judge systems, which suffer from inherent biases and unreliability. Existing programmatic benchmarks, while objective, often lack the expressiveness to test intricate, compositional constraints at a granular level. To address these limitations, we introduce LexInstructEval, a new benchmark and evaluation framework for fine-grained lexical instruction following. Our framework is built upon a formal, rule-based grammar that deconstructs complex instructions into a canonical <Procedure, Relation, Value> triplet. This grammar enables the systematic generation of a diverse dataset through a multi-stage, human-in-the-loop pipeline and facilitates objective verification via a transparent, programmatic engine. We release our dataset and open-source evaluation tools to facilitate further research into the controllability and reliability of LLMs.

</details>


### [4] [ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector](https://arxiv.org/abs/2511.17562)
*Wei Tian,YuhaoZhou*

Main category: cs.CL

TL;DR: 基于Qwen3-4B开发的中文拼写和语法纠错统一模型ChineseErrorCorrector3-4B，在多个权威基准测试中取得了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的中文拼写和语法纠错模型，以提升中文文本纠错的准确性和效率。

Method: 基于Qwen3-4B构建统一的中文拼写和语法纠错模型ChineseErrorCorrector3-4B。

Result: 在SIGHAN-2015、EC-LAW、MCSC和NaCGEC等权威基准测试中，该模型的F1和F0.5分数显著超过现有公开模型，在拼写和语法纠错任务中均排名第一。

Conclusion: ChineseErrorCorrector3-4B在中文拼写和语法纠错方面表现出色，是目前性能最优的公开模型。

Abstract: This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art results in both spelling correction (CSC) and grammatical correction (CGC). On several authoritative benchmark datasets -- including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5 scores significantly surpass existing publicly available models, ranking first in both spelling and grammatical error correction tasks.

</details>


### [5] [Generative Caching for Structurally Similar Prompts and Responses](https://arxiv.org/abs/2511.17565)
*Sarthak Chakraborty,Suman Nath,Xuchao Zhang,Chetan Bansal,Indranil Gupta*

Main category: cs.CL

TL;DR: 提出了一种生成式缓存方法，能够为结构相似的提示生成变体感知的响应，提高缓存命中率和执行效率


<details>
  <summary>Details</summary>
Motivation: 在重复性工作流和代理场景中，提示通常具有相似结构但存在微小变化，精确匹配会失败，而语义缓存可能忽略关键差异导致错误响应

Method: 识别相似提示结构中的可重用响应模式，为新请求合成定制化输出

Result: 在无提示重复的数据集上达到83%的缓存命中率，错误命中率极低；在代理工作流中，相比标准提示匹配提高约20%的缓存命中率，减少约34%的端到端执行延迟

Conclusion: 该方法有效解决了结构相似提示的缓存问题，显著提升了LLM在重复性任务中的性能表现

Abstract: Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar structure for recurring tasks. This opens up opportunities for caching. However, exact prompt matching fails on such structurally similar prompts, while semantic caching may produce incorrect responses by ignoring critical differences. To address this, we introduce \ourmethod{}, a generative cache that produces variation-aware responses for structurally similar prompts. \ourmethod{} identifies reusable response patterns across similar prompt structures and synthesizes customized outputs for new requests. We show that \ourmethod{} achieves 83\% cache hit rate, while having minimal incorrect hits on datasets without prompt repetition. In agentic workflows, it improves cache hit rate by $\sim$20\% and reduces end-to-end execution latency by $\sim$34\% compared to standard prompt matching.

</details>


### [6] [Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs](https://arxiv.org/abs/2511.17572)
*Patrick Gerard,Aiden Chang,Svitlana Volkova*

Main category: cs.CL

TL;DR: 本文提出了一个测试认识立场转移的框架，发现在删除事件知识后，对齐的大语言模型仍能保持社区特定的不确定性处理行为模式，表明对齐编码了超越表面模仿的结构化、可泛化行为。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在特定社区对齐后，是表现出可泛化的行为模式反映社区态度，还是仅仅回忆训练数据中的模式。

Method: 引入认识立场转移测试框架：通过目标性删除事件知识，并使用多个探针验证，然后评估模型在无知状态下是否仍能重现社区的有机响应模式。使用俄罗斯-乌克兰军事讨论和美国党派推特数据进行实验。

Result: 即使在激进的事实删除后，对齐的大语言模型仍保持稳定的、社区特定的不确定性处理行为模式。

Conclusion: 对齐编码了结构化、可泛化的行为，超越了表面模仿。该框架为检测在无知状态下持续存在的行为偏差提供了系统方法，有助于实现更安全透明的LLM部署。

Abstract: When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from training data? We introduce a framework to test epistemic stance transfer: targeted deletion of event knowledge, validated with multiple probes, followed by evaluation of whether models still reproduce the community's organic response patterns under ignorance. Using Russian--Ukrainian military discourse and U.S. partisan Twitter data, we find that even after aggressive fact removal, aligned LLMs maintain stable, community-specific behavioral patterns for handling uncertainty. These results provide evidence that alignment encodes structured, generalizable behaviors beyond surface mimicry. Our framework offers a systematic way to detect behavioral biases that persist under ignorance, advancing efforts toward safer and more transparent LLM deployments.

</details>


### [7] [Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models](https://arxiv.org/abs/2511.17575)
*Vladimir Berman*

Main category: cs.CL

TL;DR: 该论文提出了一个完全非语言学的文本模型，通过独立抽取有限字母表加空格符号来研究文本结构。该模型在没有任何形态、句法或语义假设的情况下，推导出几何分布的字长、词汇增长规律和Zipf型秩频分布。


<details>
  <summary>Details</summary>
Motivation: 为自然语言单词统计和大语言模型中的token统计提供一个结构上基于基础的零模型，澄清哪些现象需要超出随机文本结构的深层解释。

Method: 使用有限字母表加空格符号的独立抽取模型，定义单词为最大非空格符号块，通过组合数学和优惠券收集者论证推导结构结果。

Result: 推导出字长服从几何分布，词汇增长和关键字长有闭式表达式，得到Zipf型秩频律p(r) ∝ r^{-α}，指数由字母表大小和空格概率确定。

Conclusion: Zipf-like模式可以纯粹从组合数学和分割中产生，无需优化原则或语言组织，这为理解语言统计现象提供了结构基础的空模型。

Abstract: We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level framework, which assumes no morphology, syntax, or semantics, we derive several structural results. First, word lengths follow a geometric distribution governed solely by the probability of the space symbol. Second, the expected number of words of a given length, and the expected number of distinct words of that length, admit closed-form expressions based on a coupon-collector argument. This yields a critical word length k* at which word types transition from appearing many times on average to appearing at most once. Third, combining the exponential growth of the number of possible strings of length k with the exponential decay of the probability of each string, we obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an exponent determined explicitly by the alphabet size and the space probability.
  Our contribution is twofold. Mathematically, we give a unified derivation linking word lengths, vocabulary growth, critical length, and rank-frequency structure in a single explicit model. Conceptually, we argue that this provides a structurally grounded null model for both natural-language word statistics and token statistics in large language models. The results show that Zipf-like patterns can arise purely from combinatorics and segmentation, without optimization principles or linguistic organization, and help clarify which phenomena require deeper explanation beyond random-text structure.

</details>


### [8] [Computational frame analysis revisited: On LLMs for studying news coverage](https://arxiv.org/abs/2511.17746)
*Sharaj Kunjar,Alyssa Hasegawa Smith,Tyler R Mckenzie,Rushali Mohbe,Samuel V Scarpino,Brooke Foucault Welles*

Main category: cs.CL

TL;DR: 评估生成式LLM在媒体框架分析中的表现，发现其被人工编码员和较小语言模型超越，需要人工验证来确定合适的模型选择。


<details>
  <summary>Details</summary>
Motivation: 研究生成式LLM作为内容分析工具在媒体框架识别中的有效性，与传统计算方法及人工编码进行比较。

Method: 使用新颖的金标准数据集，系统评估GPT、Claude等生成式LLM与词袋模型、编码器转换器及人工编码在Mpox疫情新闻框架分析中的表现。

Result: 生成式LLM在某些应用中有潜力，但总体上被人工编码员超越，在某些情况下甚至被较小语言模型超越。需要人工验证来确定合适的模型选择。

Conclusion: 支持方法多元主义，提出计算框架分析路线图，建议研究人员利用这些方法的互补性进行协同使用。

Abstract: Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.

</details>


### [9] [PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese](https://arxiv.org/abs/2511.17808)
*Thales Sales Almeida,Rodrigo Nogueira,Hélio Pedrini*

Main category: cs.CL

TL;DR: PoETa v2是迄今为止对葡萄牙语LLMs最广泛的评估，包含40多个任务的综合基准，评估了20多个模型，揭示了计算投资和语言特定适应对葡萄牙语性能的影响。


<details>
  <summary>Details</summary>
Motivation: LLMs在不同语言和文化背景下的性能差异显著，需要系统评估多种语言。葡萄牙语作为重要语言，缺乏全面的评估基准。

Method: 引入PoETa v2基准，包含40多个葡萄牙语任务，评估20多个不同训练规模和计算资源的模型，并与英语等效任务进行对比分析。

Result: 研究揭示了计算投资和语言特定适应对葡萄牙语性能的影响，分析了与英语任务的性能差距。

Conclusion: PoETa v2为葡萄牙语语言建模和评估的未来研究奠定了基础，提供了公开可用的基准。

Abstract: Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.

</details>


### [10] [Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation](https://arxiv.org/abs/2511.17813)
*Scott Merrill,Shashank Srivastava*

Main category: cs.CL

TL;DR: 该论文提出了一个可复现的流程，将Zoom公开录音转换为带有说话人身份、人物画像和语用行为标签的转录文本，并发布了三个地方政府审议数据集。使用这些"行为感知"数据微调LLM可以显著提升模拟审议的真实性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型模拟多方审议时缺乏说话人身份数据的问题，自动语音识别产生的匿名说话人标签无法捕捉一致的人类行为模式。

Method: 开发了一个可复现的流程，将公开Zoom录音转换为带有说话人身份、人物画像和语用行为标签（如[propose_motion]）的转录文本，并基于这些"行为感知"数据微调LLM来建模特定参与者。

Result: 使用该方法微调的LLM在困惑度上降低了67%，在说话人忠实度和真实性方面的分类器性能指标几乎翻倍。图灵式人工评估显示模拟审议与真实审议难以区分。

Conclusion: 该方法为复杂现实公民模拟提供了实用且可扩展的解决方案，能够生成高度真实的审议模拟。

Abstract: Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this "action-aware" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.

</details>


### [11] [A superpersuasive autonomous policy debating system](https://arxiv.org/abs/2511.17854)
*Allen Roush,Devin Gonier,John Hines,Judah Goldfeder,Philippe Martin Wyder,Sanjay Basu,Ravid Shwartz Ziv*

Main category: cs.CL

TL;DR: DeepDebater是一个能够参与并赢得完整政策辩论的自主AI系统，采用分层多智能体架构，结合大规模辩论证据库，生成完整的辩论演讲、质询和反驳。


<details>
  <summary>Details</summary>
Motivation: 解决AI在复杂、基于证据且具有战略适应性的说服能力方面的重大挑战，超越之前简化的辩论系统如IBM Project Debater。

Method: 采用分层架构的多智能体工作流，LLM驱动的智能体团队协作执行特定辩论任务，使用迭代检索、合成和自校正技术，基于大规模政策辩论证据库OpenDebateEvidence。

Result: 在初步评估中，DeepDebater产生质量更高的论证组件，在模拟辩论中持续获胜，独立自主裁判和人类辩论教练都更偏好其构建的论点、证据和案例。

Conclusion: DeepDebater展示了AI在复杂政策辩论中的能力，支持全自主和混合人机操作模式，为AI说服系统的发展提供了重要进展。

Abstract: The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main

</details>


### [12] [Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction](https://arxiv.org/abs/2511.17908)
*Debashish Chakraborty,Eugene Yang,Daniel Khashabi,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 本文提出了一种基于保形预测的覆盖控制过滤框架，用于在RAG系统中去除无关内容，同时保证相关证据的召回率。该方法能减少2-3倍的上下文内容，同时保持下游事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理长文本或噪声上下文时，LLM的准确性会下降，且现有预生成过滤器缺乏对保留证据的统计控制。

Method: 使用保形预测框架，通过嵌入和LLM评分函数对检索内容进行覆盖控制过滤，在NeuCLIR和RAGTIME数据集上进行评估。

Result: 保形过滤始终达到目标覆盖度，减少2-3倍保留上下文，在严格过滤下ARGUE F1指标得到改善，在中等覆盖度下保持稳定。

Conclusion: 保形预测为RAG提供了可靠、覆盖控制的上下文缩减方法，是一种模型无关且原则性的上下文工程方法。

Abstract: Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.

</details>


### [13] [L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention](https://arxiv.org/abs/2511.17910)
*Yuliang Zhan,Xinyu Tang,Han Wan,Jian Li,Ji-Rong Wen,Hao Sun*

Main category: cs.CL

TL;DR: 本文提出L2V-CoT方法，通过频率域的低频潜在表示干预，无需训练即可将LLMs的思维链推理能力迁移到VLMs上。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多步推理任务上表现不佳，现有方法需要高训练成本或架构对齐，因此需要探索更高效的推理能力迁移方法。

Method: 使用线性人工断层扫描发现LLMs和VLMs在思维链推理上共享相似的低频潜在表示，提出L2V-CoT方法在频率域提取和重采样LLMs的低频CoT表示，通过维度匹配和潜在注入增强VLMs的推理能力。

Result: 实验表明该方法在无需训练的情况下持续优于基线方法，甚至超过有监督方法。

Conclusion: LLMs和VLMs在思维链推理上存在共享的低频潜在表示，通过频率域干预可以实现高效的推理能力迁移。

Abstract: Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.

</details>


### [14] [Towards Efficient LLM-aware Heterogeneous Graph Learning](https://arxiv.org/abs/2511.17923)
*Wenda Li,Tongya Zheng,Shunyu Liu,Yu Wang,Kaixuan Chen,Hanyang Yuan,Bingde Hu,Zujie Ren,Mingli Song,Gang Chen*

Main category: cs.CL

TL;DR: 提出了一个高效的LLM感知框架ELLA，用于解决异质图中复杂关系语义建模问题，通过LLM感知的关系分词器、跳级关系图变换器和任务感知的思维链提示，在性能和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 异质图中节点和关系类型的多样性导致复杂丰富的语义，现有方法受限于预定义的语义依赖和缺乏监督信号。LLM具有强大的文本推理能力，但计算复杂度限制了其在异质图中的应用。

Method: 1. LLM感知关系分词器：利用LLM编码多跳多类型关系；2. 跳级关系图变换器：将LLM感知关系推理复杂度从指数级降至线性级；3. 细粒度任务感知思维链提示：弥合预训练和微调任务间的语义鸿沟。

Result: 在四个异质图上的广泛实验表明，ELLA在性能和效率上优于最先进方法，可扩展到130亿参数LLM，相比现有基于LLM的方法实现高达4倍加速。

Conclusion: ELLA框架有效解决了异质图中复杂关系语义建模的挑战，通过创新的LLM集成方法在保持高性能的同时显著提升了计算效率。

Abstract: Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.

</details>


### [15] [SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization](https://arxiv.org/abs/2511.17938)
*Jianghao Wu,Yasmeen George,Jin Ye,Yicheng Wu,Daniel F. Schmidt,Jianfei Cai*

Main category: cs.CL

TL;DR: SPINE是一个基于token选择性的测试时强化学习框架，通过只更新高熵分支点token来避免传统测试时强化学习方法中的响应长度崩溃问题，在多个推理基准上稳定提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统测试时强化学习方法存在分布偏移、缺乏可验证监督以及多数投票奖励导致响应缩短和性能下降的问题，需要一种更稳定的测试时适应机制。

Method: SPINE框架：(1) 只更新分叉token（通过前向传递统计识别的高熵分支点）；(2) 在分叉token处应用熵带正则化器，在熵过低时维持探索，在熵过高时抑制噪声监督。

Result: 在10个基准测试中，SPINE相比传统测试时强化学习方法持续提升Pass@1性能，避免响应长度崩溃，并在LLM和MLLM骨干网络上产生更稳定的训练动态。

Conclusion: 将更新与思维链分支点对齐是一种简单且无需标签的机制，能够在推理模型中实现稳定有效的测试时适应。

Abstract: Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.

</details>


### [16] [Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models](https://arxiv.org/abs/2511.17946)
*Shuo Zhang,Fabrizio Gotti,Fengran Mo,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 本文探讨了预训练数据覆盖度作为大语言模型幻觉检测补充信号的有效性，发现在高不确定性数据集上，词汇覆盖特征与对数概率结合能带来适度提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要使用模型内部信号检测幻觉，但预训练数据暴露与幻觉之间的关系研究不足。本文旨在探索问题或生成答案的词汇训练数据覆盖度是否能提供额外的幻觉检测信号。

Method: 在RedPajama的1.3万亿token预训练语料上构建可扩展后缀数组，检索提示和模型生成的n-gram统计信息，并在三个QA基准上评估其幻觉检测效果。

Result: 基于出现频率的特征单独使用时预测能力较弱，但与对数概率结合时能带来适度增益，特别是在内在模型不确定性较高的数据集上。

Conclusion: 词汇覆盖特征为幻觉检测提供了补充信号，表明预训练数据覆盖度可以作为有用的检测指标。

Abstract: Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.

</details>


### [17] [MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok](https://arxiv.org/abs/2511.17955)
*Dat Thanh Nguyen,Nguyen Hung Lam,Anh Hoang-Thi Nguyen,Trong-Hop Do*

Main category: cs.CL

TL;DR: MTikGuard是一个针对TikTok的实时多模态有害内容检测系统，通过扩展数据集、多模态特征融合和可扩展流式架构，实现了89.37%的准确率和89.45%的F1分数。


<details>
  <summary>Details</summary>
Motivation: TikTok作为儿童和青少年中极具影响力的平台，存在大量有害内容，这些内容往往隐蔽或具有欺骗性，传统审核方法难以应对海量实时上传的挑战。

Method: 扩展TikHarm数据集至4,723个标注视频；构建集成视觉、音频和文本特征的多模态分类框架；基于Apache Kafka和Apache Spark构建可扩展的流式架构。

Result: 系统在有害内容检测上达到89.37%的准确率和89.45%的F1分数，展示了多模态融合和实时部署的有效性。

Conclusion: 结合数据集扩展、先进的多模态融合和稳健部署，能够为大规模社交媒体内容审核提供实用解决方案。

Abstract: With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.

</details>


### [18] [Blu-WERP (Web Extraction and Refinement Pipeline): A Scalable Pipeline for Preprocessing Large Language Model Datasets](https://arxiv.org/abs/2511.18054)
*Gowtham,Sai Rupesh,Sanjay Kumar,Saravanan,Venkata Chaithanya*

Main category: cs.CL

TL;DR: Blu-WERP是一个新颖的数据预处理管道，显著优于现有基线方法，在多个模型规模和评估基准上都能提升LLM训练数据质量和下游模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有预处理管道难以有效去除网络规模语料库中的噪声和非结构化内容，影响大语言模型的性能。

Method: Blu-WERP处理CC WARC转储文件，实现高级过滤和质量评估机制，优化Common Crawl WARC文件质量。

Result: 在150M到1B参数的多个模型规模上，Blu-WERP在9个标准基准测试中表现一致优于基线。在1B参数规模下，相比DCLM和Fineweb分别实现4.0%和9.5%的总体改进，并在世界知识与推理、语言理解、常识推理三个类别均有显著提升。

Conclusion: Blu-WERP代表了数据质量优化的实际进展，为研究人员和从业者提供了提高LLM训练效率和模型性能的有效解决方案。

Abstract: High-quality training data is fundamental to large language model (LLM) performance, yet existing preprocessing pipelines often struggle to effectively remove noise and unstructured content from web-scale corpora. This paper presents Blu-WERP, a novel data preprocessing pipeline designed to optimize the quality of Common Crawl WARC files for LLM training. We demonstrate that Blu-WERP significantly outperforms established baselines including DCLM across multiple model scales and evaluation benchmarks. Our pipeline processes CC WARC dumps, implementing advanced filtering and quality assessment mechanisms. We conducted comprehensive evaluations using models with 150M, 400M, 530M, 750M, and 1B parameters, testing against nine standard benchmarks categorized as World Knowledge & Reasoning, Language Understanding, and Commonsense Reasoning. Results show Blu-WERP consistently achieved superior performance across all model scales. At the 1B parameter scale, Relatively Blu-WERP demonstrates a 4.0% and 9.5% aggregate improvement over DCLM and Fineweb respectively, while achieving quality-per-token efficiency gain. Categorical analysis reveals 2.4% improvement in World Knowledge & Reasoning, 6.2% improvement in Language Understanding, and 4.2% improvement in Commonsense Reasoning. These results establish Blu-WERP as a state-of-the-art preprocessing pipeline that substantially improves LLM training data quality and downstream model performance with reduced computational cost. Our findings contribute to the growing body of research on data-centric AI, demonstrating that preprocessing pipeline design significantly impacts LLM capabilities. The Blu-WERP pipeline represents a practical advancement in data quality optimization, offering researchers and practitioners an effective solution for improving LLM training efficiency and model performance.

</details>


### [19] [GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set](https://arxiv.org/abs/2511.18146)
*Yomal De Mel,Nisansa de Silva*

Main category: cs.CL

TL;DR: 本研究创建了GeeSanBhava数据集，包含从YouTube提取的僧伽罗语歌曲评论，使用Russell的效价-唤醒模型手动标注，并开发了优化的多层感知器模型进行情感分类，ROC-AUC得分为0.887。


<details>
  <summary>Details</summary>
Motivation: 解决僧伽罗语自然语言处理中缺乏高质量情感标注数据集的问题，探索基于评论的音乐情感识别，并应对用户生成内容中的偏见挑战。

Method: 从YouTube提取僧伽罗语歌曲评论，由三名独立标注者使用Russell效价-唤醒模型手动标注；使用在僧伽罗语新闻评论数据集上预训练的机器学习和深度学习模型进行零样本测试；开发优化的三层MLP模型（256-128-64神经元配置）。

Result: 标注者间一致性高（Fleiss kappa = 84.96%）；不同歌曲呈现明显不同的情感特征；优化的MLP模型在情感分类任务中达到0.887的ROC-AUC得分。

Conclusion: 本研究为僧伽罗语NLP和音乐情感识别领域贡献了有价值的标注数据集，并为未来研究提供了重要见解。

Abstract: This study introduce GeeSanBhava, a high-quality data set of Sinhala song comments extracted from YouTube manually tagged using Russells Valence-Arousal model by three independent human annotators. The human annotators achieve a substantial inter-annotator agreement (Fleiss kappa = 84.96%). The analysis revealed distinct emotional profiles for different songs, highlighting the importance of comment based emotion mapping. The study also addressed the challenges of comparing comment-based and song-based emotions, mitigating biases inherent in user-generated content. A number of Machine learning and deep learning models were pre-trained on a related large data set of Sinhala News comments in order to report the zero-shot result of our Sinhala YouTube comment data set. An optimized Multi-Layer Perceptron model, after extensive hyperparameter tuning, achieved a ROC-AUC score of 0.887. The model is a three-layer MLP with a configuration of 256, 128, and 64 neurons. This research contributes a valuable annotated dataset and provides insights for future work in Sinhala Natural Language Processing and music emotion recognition.

</details>


### [20] [Vector Arithmetic in Concept and Token Subspaces](https://arxiv.org/abs/2511.18162)
*Sheridan Feucht,Byron Wallace,David Bau*

Main category: cs.CL

TL;DR: 论文展示了如何利用概念归纳头和词元归纳头来识别LLaMA-2-7b模型激活中的语义和表面级信息子空间，通过注意力权重变换显著提升平行四边形算术等任务的准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs需要同时表示语义和表面级信息来预测下一个词元，已有研究发现概念归纳头和词元归纳头能够分离这两种信息，但如何利用这些头来识别模型激活中的结构化子空间尚待探索。

Method: 使用概念归纳头的注意力权重变换隐藏状态，创建具有连贯语义结构的子空间；同时使用词元归纳头变换来揭示表面级词信息。

Result: 概念头变换后的隐藏状态在平行四边形算术任务中达到80%的最近邻准确率，远高于原始隐藏状态的47%；词元头变换能够成功进行词形变化操作。

Conclusion: 特定类型的注意力头可以识别模型激活中的语义和表面级信息子空间，这些子空间支持更准确的语义和词形操作，为理解LLMs的内部表示提供了新视角。

Abstract: In order to predict the next token, LLMs must represent semantic and surface-level information about the current word. Previous work identified two types of attention heads that disentangle this information: (i) Concept induction heads, which copy word meanings, and (ii) Token induction heads, which copy literal token representations (Feucht et al., 2025). We show that these heads can be used to identify subspaces of model activations that exhibit coherent semantic structure in Llama-2-7b. Specifically, when we transform hidden states using the attention weights of concept heads, we are able to more accurately perform parallelogram arithmetic (Mikolov et al., 2013) on the resulting hidden states, e.g., showing that "Athens" - "Greece" + "China" = "Beijing". This transformation allows for much higher nearest-neighbor accuracy (80%) than direct use of raw hidden states (47%). Analogously, we show that token heads allow for transformations that reveal surface-level word information in hidden states, allowing for operations like "coding" - "code" + "dance" = "dancing".

</details>


### [21] [Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models](https://arxiv.org/abs/2511.18177)
*Elias Lumer,Matt Melich,Olivia Zino,Elena Kim,Sara Dieter,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah,James A. Burke,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文首次系统比较了基于向量的智能RAG与基于层次节点系统的金融文档检索方法，发现向量RAG在检索准确率和答案质量上显著优于传统方法，交叉编码器重排和小到大块检索技术能进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作缺乏对金融文档中基于向量和非向量RAG架构的系统比较，以及高级RAG技术对检索准确性、答案质量、延迟和成本影响的实证研究。

Method: 评估基于向量的智能RAG（使用混合搜索和元数据过滤）与基于层次节点的系统（无需嵌入遍历文档结构），并测试两种增强技术：交叉编码器重排和小到大块检索。

Result: 基于向量的智能RAG在150个问题的基准测试中，相比层次节点系统获得68%的胜率；交叉编码器重排在最优参数下MRR@5提升59%；小到大块检索相比基线块划分获得65%胜率，仅增加0.2秒延迟。

Conclusion: 在金融问答系统中应用高级RAG技术能显著提升检索准确性和答案质量，但在生产环境中需要考虑成本与性能的权衡。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models to answer financial questions using external knowledge bases of U.S. SEC filings, earnings reports, and regulatory documents. However, existing work lacks systematic comparison of vector-based and non-vector RAG architectures for financial documents, and the empirical impact of advanced RAG techniques on retrieval accuracy, answer quality, latency, and cost remain unclear. We present the first systematic evaluation comparing vector-based agentic RAG using hybrid search and metadata filtering against hierarchical node-based systems that traverse document structure without embeddings. We evaluate two enhancement techniques applied to the vector-based architecture, i) cross-encoder reranking for retrieval precision, and ii) small-to-big chunk retrieval for context completeness. Across 1,200 SEC 10-K, 10-Q, and 8-K filings on a 150-question benchmark, we measure retrieval metrics (MRR, Recall@5), answer quality through LLM-as-a-judge pairwise comparisons, latency, and preprocessing costs. Vector-based agentic RAG achieves a 68% win rate over hierarchical node-based systems with comparable latency (5.2 compared to 5.98 seconds). Cross-encoder reranking achieves a 59% absolute improvement at optimal parameters (10, 5) for MRR@5. Small-to-big retrieval achieves a 65% win rate over baseline chunking with only 0.2 seconds additional latency. Our findings reveal that applying advanced RAG techniques to financial Q&A systems improves retrieval accuracy, answer quality, and has cost-performance tradeoffs to be considered in production.

</details>


### [22] [Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems](https://arxiv.org/abs/2511.18194)
*Faheem Nizar,Elias Lumer,Anmol Gulati,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah*

Main category: cs.CL

TL;DR: 提出了Agent-as-a-Graph检索方法，通过知识图谱表示代理和工具，在LiveMCPBenchmark上显著提升了检索性能


<details>
  <summary>Details</summary>
Motivation: 现有代理、MCP和检索方法通常只匹配单个代理描述，无法充分利用每个代理的细粒度工具能力，导致代理选择不理想

Method: 使用知识图谱检索增强生成方法，将工具及其父代理表示为知识图谱中的节点和边，通过向量搜索、加权互逆排名融合重排序和知识图谱遍历进行检索

Result: 在LiveMCPBenchmark上，Recall@5和nDCG@5分别比现有最优检索器提升14.9%和14.6%，wRRF优化提升2.4%

Conclusion: Agent-as-a-Graph方法通过知识图谱表示和检索策略有效提升了多代理系统中代理选择的准确性和效率

Abstract: Recent advances in Large Language Model Multi-Agent Systems enable scalable orchestration and retrieval of specialized, parallelized subagents, each equipped with hundreds or thousands of Model Context Protocol (MCP) servers and tools. However, existing agent, MCP, and retrieval methods typically match queries against a single agent description, obscuring fine-grained tool capabilities of each agent, resulting in suboptimal agent selection. We introduce Agent-as-a-Graph retrieval, a knowledge graph retrieval augmented generation approach that represents both tools and their parent agents as nodes and edges in a knowledge graph. During retrieval, i) relevant agents and tool nodes are first retrieved through vector search, ii) we apply a type-specific weighted reciprocal rank fusion (wRRF) for reranking tools and agents, and iii) parent agents are traversed in the knowledge graph for the final set of agents. We evaluate Agent-as-a-Graph on the LiveMCPBenchmark, achieving 14.9% and 14.6% improvements in Recall@5 and nDCG@5 over prior state-of-the-art retrievers, and 2.4% improvements in wRRF optimizations.

</details>


### [23] [From Archives to Decisions: Multi-Agent Pharmaceutical Co-Scientist for Traceable Drug Discovery and Reverse Translation](https://arxiv.org/abs/2511.18259)
*Xiaochen Zheng,Alvaro Serra,Ilya Schneider Chernov,Maddalena Marchesi,Eunice Musvasva,Tatyana Y. Doktorova*

Main category: cs.CL

TL;DR: DiscoVerse是一个多智能体协同科学家系统，用于支持药物研发，通过语义检索、跨文档链接和可审计的合成技术，在罗氏历史数据上实现逆向转化研究。


<details>
  <summary>Details</summary>
Motivation: 药物研发积累了海量异构数据，其中许多来自已终止的研究项目。重新利用这些档案对逆向转化研究具有重要价值，但在实践中往往不可行。

Method: 开发了DiscoVerse多智能体系统，实现语义检索、跨文档链接和可审计的合成，在罗氏0.87亿BPE令牌、跨越40多年的研究数据上进行验证。

Result: 在涵盖180个分子的7个基准查询中，DiscoVerse实现了接近完美的召回率(≥0.99)和中等精确度(0.71-0.91)，在终止理由和器官特异性毒性评估中显示出忠实、源链接的合成能力。

Conclusion: 这是首个在真实药物数据上系统评估的逆向转化智能体框架，展示了有前景的答案准确性和决策洞察力，为药物研发提供了有效支持。

Abstract: Pharmaceutical research and development has accumulated vast, heterogeneous archives of data. Much of this knowledge stems from discontinued programs, and reusing these archives is invaluable for reverse translation. However, in practice, such reuse is often infeasible. In this work, we introduce DiscoVerse, a multi-agent co-scientist designed to support pharmaceutical research and development. The system implements semantic retrieval, cross-document linking, and auditable synthesis on a large historical corpus from Roche. To validate our approach at real-world scale, we selected a subset of 180 molecules from the Roche research repositories, covering over 0.87 billion BPE tokens and more than four decades of research. Given that automated evaluation metrics are poorly aligned with scientific utility, we evaluate the performance of DiscoVerse using blinded expert evaluation of source-linked outputs. To our knowledge, this is the first agentic framework systematically assessed on real pharmaceutical data for reverse translation, enabled by authorized access to confidential, end-to-end drug-development archives. Our contributions include role-specialized agent designs aligned with scientist workflows; human-in-the-loop support for reverse translation; expert evaluation; and a large-scale demonstration showing promising answer accuracy and decision-making insights. In brief, across seven benchmark queries covering 180 molecules, DiscoVerse achieved near-perfect recall ($\geq 0.99$) with moderate precision ($0.71-0.91$), while qualitative assessments of discontinuation rationale and organ-specific toxicity showed faithful, source-linked synthesis across preclinical and clinical evidence.

</details>


### [24] ["AGI" team at SHROOM-CAP: Data-Centric Approach to Multilingual Hallucination Detection using XLM-RoBERTa](https://arxiv.org/abs/2511.18301)
*Harsh Rathva,Pruthwik Mishra,Shrikant Malviya*

Main category: cs.CL

TL;DR: 本文通过数据中心的策略，统一并平衡五个现有数据集创建了124,821个样本的训练语料库，在SHROOM-CAP 2025多语言科学文本幻觉检测任务中取得了竞争性表现，特别是在零样本语言古吉拉特语中获得第二名。


<details>
  <summary>Details</summary>
Motivation: 解决多语言科学文本中LLM生成幻觉检测的训练数据稀缺和不平衡问题，特别是在低资源语言和零样本设置下。

Method: 采用数据中心策略，统一平衡五个现有数据集创建大规模训练语料库，然后使用5.6亿参数的XLM-RoBERTa-Large模型进行微调。

Result: 在9种语言中表现优异，古吉拉特语（零样本语言）获得第二名（Factuality F1为0.5107），其余8种语言排名4-6位。

Conclusion: 系统化的数据管理策略能够显著超越仅依靠架构创新的方法，特别是在低资源语言的零样本设置中。

Abstract: The detection of hallucinations in multilingual scientific text generated by Large Language Models (LLMs) presents significant challenges for reliable AI systems. This paper describes our submission to the SHROOM-CAP 2025 shared task on scientific hallucination detection across 9 languages. Unlike most approaches that focus primarily on model architecture, we adopted a data-centric strategy that addressed the critical issue of training data scarcity and imbalance. We unify and balance five existing datasets to create a comprehensive training corpus of 124,821 samples (50% correct, 50% hallucinated), representing a 172x increase over the original SHROOM training data. Our approach fine-tuned XLM-RoBERTa-Large with 560 million parameters on this enhanced dataset, achieves competitive performance across all languages, including \textbf{2nd place in Gujarati} (zero-shot language) with Factuality F1 of 0.5107, and rankings between 4th-6th place across the remaining 8 languages. Our results demonstrate that systematic data curation can significantly outperform architectural innovations alone, particularly for low-resource languages in zero-shot settings.

</details>


### [25] [Table Comprehension in Building Codes using Vision Language Models and Domain-Specific Fine-Tuning](https://arxiv.org/abs/2511.18306)
*Mohammad Aqib,Mohd Hamza,Ying Hei Chui,Qipei Mei*

Main category: cs.CL

TL;DR: 本文比较了两种从建筑规范表格数据中提取信息的方法：直接输入法和间接输入法（通过LaTeX转换），发现直接输入法准确率更高。通过LoRA微调VLM模型，Qwen2.5-VL-3B-Instruct实现了超过100%的相对准确率提升。


<details>
  <summary>Details</summary>
Motivation: 建筑规范包含确保安全和合规性的关键信息，但表格数据提取困难，因为表格具有复杂布局、合并单元格、多行表头和嵌入式语义关系，传统NLP技术和VLM难以有效处理。

Method: 比较两种方法：1）直接输入法：将页面图像直接输入VLM回答问题；2）间接输入法：将表格图像转换为LaTeX代码，然后基于LaTeX输入回答问题。使用LoRA对VLM进行领域特定的表格数据微调。

Result: 直接输入法通常比间接输入法准确率更高。经过LoRA微调的模型性能显著提升，Qwen2.5-VL-3B-Instruct实现了超过100%的相对准确率增益。

Conclusion: 参数高效的微调方法能够使强大的VLM适应专业领域（如建筑规范解释和法规合规）中复杂结构化数据的理解，具有重要应用潜力。

Abstract: Building codes contain critical information for ensuring safety, regulatory compliance, and informed decision-making in construction and engineering. Automated question answering systems over such codes enable quick and accurate access to specific regulatory clauses, improving efficiency and reducing errors. Retrieval-Augmented Generation (RAG) systems are essential for this task as they combine the precision of information retrieval with the generative capabilities of language models. However, tabular data are challenging to extract as they often involve complex layouts, merged cells, multi-row headers, and embedded semantic relationships that are not easily captured by traditional natural language processing techniques and Vision Language Models (VLMs). This paper explores and compares two methods for extracting information from tabular data in building codes using several pre-trained VLMs. First, a direct input method is used, where the image of the page is input directly into the VLMs, which are then tasked with answering questions based on the image. Second, an indirect input method is introduced, which involves converting an image of a page containing tables into the LaTeX code and then answering inquires based on the LaTeX-based input. The experiments find that the direct input method generally resulted in higher accuracy than the indirect input method. To further improve the performance, we fine-tuned each VLM using Low Rank Adaptation (LoRA) on a domain-specific tabular dataset. The fine-tuned models exhibited substantial improvements, with Qwen2.5-VL-3B-Instruct achieving relative accuracy gains exceeding 100%. Our results highlight the potential of parameter-efficient fine-tuning methods to adapt powerful VLMs for understanding complex structured data in specialized fields, such as building code interpretation and regulatory compliance.

</details>


### [26] [Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search](https://arxiv.org/abs/2511.18313)
*Joseph Oladokun*

Main category: cs.CL

TL;DR: 提出了路径约束检索(PCR)方法，结合图结构约束和语义搜索，确保检索信息在知识图谱中保持逻辑关系，提高LLM代理推理的可靠性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理从知识库检索上下文时，由于缺乏与当前推理状态的结构一致性，导致推理链不连贯。

Method: PCR方法将搜索空间限制在从锚节点可达的节点，防止检索结构断开的信息。结合结构图约束和语义搜索。

Result: 在PathRAG-6基准测试中，PCR实现100%结构一致性（基线为24-32%），同时保持强相关性得分。在技术领域，PCR在排名10时获得100%相关性和完全结构一致性。PCR将检索上下文的平均图距离减少78%。

Conclusion: 路径约束检索是提高LLM代理推理系统可靠性和连贯性的有效方法。

Abstract: Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.

</details>


### [27] [Gradient Masters at BLP-2025 Task 1: Advancing Low-Resource NLP for Bengali using Ensemble-Based Adversarial Training for Hate Speech Detection](https://arxiv.org/abs/2511.18324)
*Syed Mohaiminul Hoque,Naimur Rahman,Md Sakhawat Hossain*

Main category: cs.CL

TL;DR: 本文介绍了一种基于集成微调策略的"Gradient Masters"方法，用于孟加拉语多任务仇恨言论识别任务，在YouTube评论的仇恨类型分类和目标群体分类两个子任务中取得了良好表现。


<details>
  <summary>Details</summary>
Motivation: 解决低资源孟加拉语仇恨言论检测场景中的泛化能力和数据集覆盖问题，提升仇恨言论分类的准确性。

Method: 采用基于孟加拉语语言模型的混合集成微调策略，通过广泛实验评估模型鲁棒性，并与其他语言模型变体进行比较。

Result: 在子任务1A中获得第6名（微F1分数73.23%），在子任务1B中获得第3名（微F1分数73.28%），超越了基线模型。

Conclusion: 提出的集成方法在孟加拉语仇恨言论检测中表现优异，同时提供了误分类模式的详细分析，为低资源语言场景的仇恨言论识别提供了有效解决方案。

Abstract: This paper introduces the approach of "Gradient Masters" for BLP-2025 Task 1: "Bangla Multitask Hate Speech Identification Shared Task". We present an ensemble-based fine-tuning strategy for addressing subtasks 1A (hate-type classification) and 1B (target group classification) in YouTube comments. We propose a hybrid approach on a Bangla Language Model, which outperformed the baseline models and secured the 6th position in subtask 1A with a micro F1 score of 73.23% and the third position in subtask 1B with 73.28%. We conducted extensive experiments that evaluated the robustness of the model throughout the development and evaluation phases, including comparisons with other Language Model variants, to measure generalization in low-resource Bangla hate speech scenarios and data set coverage. In addition, we provide a detailed analysis of our findings, exploring misclassification patterns in the detection of hate speech.

</details>


### [28] [OmniStruct: Universal Text-to-Structure Generation across Diverse Schemas](https://arxiv.org/abs/2511.18335)
*James Y. Huang,Wenxuan Zhou,Nan Xu,Fei Wang,Qin Liu,Sheng Zhang,Hoifung Poon,Muhao Chen*

Main category: cs.CL

TL;DR: OmniStruct是一个全面的文本到结构任务基准，用于评估LLMs在信息提取、表格生成和函数调用等结构化输出任务上的能力。通过合成任务生成收集高质量训练数据，研究表明可以在不使用监督数据的情况下，将更小模型微调为通用结构化生成模型，性能可与GPT-4o相媲美。


<details>
  <summary>Details</summary>
Motivation: 虽然现代LLMs在生成非结构化自然语言响应方面表现出色，但它们在文本到结构任务上的表现是否同样优秀仍不清楚。需要建立一个全面的基准来评估LLMs在各种结构化输出任务上的能力。

Method: 构建OmniStruct基准，识别适合结构化答案格式的现有数据集，并在统一的文本到结构问题设置下进行适配。通过合成任务生成收集高质量训练数据，在不使用OmniStruct任务监督数据的情况下微调更小模型。

Result: 实验证明，通过在合成数据上微调更小模型，可以将其转变为通用结构化生成模型，其性能能够与GPT-4o相媲美。

Conclusion: OmniStruct为评估LLMs在文本到结构任务上的能力提供了全面基准，并展示了通过合成数据微调小模型实现高效结构化生成的可行性。

Abstract: The ability of Large Language Models (LLMs) to generate structured outputs that follow arbitrary schemas is crucial to a wide range of downstream tasks that require diverse structured representations of results such as information extraction, table generation, and function calling. While modern LLMs excel in generating unstructured responses in natural language, whether this advancement translates to a strong performance on text-to-structure tasks remains unclear. To bridge this gap, we first introduce OmniStruct, a comprehensive benchmark for assessing LLMs' capabilities on diverse text-to-structure tasks such as information extraction, table generation, and function calling. We build OmniStruct by identifying existing datasets across a wide range of tasks that are suitable for a structured answer format, and adapting them under a unified text-to-structure problem setting. To facilitate the development of efficient text-to-structure models, we collect high-quality training data via synthetic task generation. Without using any supervised data for OmniStruct tasks, our experiments demonstrate the possibility of fine-tuning much smaller models on synthetic data into universal structured generation models that can rival the performance of GPT-4o.

</details>


### [29] [Tu crois que c'est vrai ? Diversite des regimes d'enonciation face aux fake news et mecanismes d'autoregulation conversationnelle](https://arxiv.org/abs/2511.18369)
*Manon Berriche*

Main category: cs.CL

TL;DR: 该论文研究了两个悖论：虚假新闻在社交媒体中占比很小但政治极化加剧。通过Twitter和Facebook的混合方法研究发现，虚假新闻分享集中在少数高度政治化的用户中，用户会根据社会位置采取不同批判距离，但这些互动很少产生真正辩论。


<details>
  <summary>Details</summary>
Motivation: 解释为什么在缺乏编辑控制的社交媒体上虚假新闻占比很小，以及为什么用户对虚假新闻不特别敏感但政治极化仍在加剧这两个悖论。

Method: 采用混合方法设计，结合数字痕迹定量分析、在线观察和访谈，在Twitter和Facebook上进行两项互补研究，考察不同互动情境下的用户实践。

Result: 1) 虚假新闻分享集中在少数高度政治化、批评制度的用户中；2) 用户根据社会位置采取不同批判距离形式；3) 这些互动很少产生真正辩论，更多是"聋子对话"。

Conclusion: 虚假新闻的影响不是通过广泛传播，而是通过少数高度活跃用户的议程设置能力，以及用户批判距离形式的社会分化来实现的，这解释了政治极化的加剧。

Abstract: This thesis addresses two paradoxes: (1) why empirical studies find that fake news represent only a small share of the information consulted and shared on social media despite the absence of editorial control or journalistic norms, and (2) how political polarization has intensified even though users do not appear especially receptive to fake news. To investigate these issues, two complementary studies were carried out on Twitter and Facebook, combining quantitative analyses of digital traces with online observation and interviews. This mixed-methods design avoids reducing users to single reactions to identified fake items and instead examines the variety of practices across different interactional situations, online and offline, while recording socio-demographic traits. The first study mapped users who shared at least one item labeled fake by fact-checkers in the French Twittersphere. The second used a corpus of items flagged by Facebook users to study reactions to statements whose epistemic status is uncertain. Three main findings emerge. First, sharing fake news is concentrated among a limited group of users who are not less educated or cognitively disadvantaged but are more politicized and critical of institutions; owing to their high activity and prolific sharing, they can help set the agenda for their political camp. Second, exposed users can deploy varying forms of critical distance depending on their social position and the interactional norms of the situations they inhabit: either discursive caution (prudence énonciative) or interventions ('points d'arrêt') that express disagreement or corrections. Third, these forms of critical distance seldom yield genuine deliberative debates or agonistic pluralism; rather, they often produce dialogues of the deaf among a small, particularly active minority.

</details>


### [30] [Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical Notes with Large Language Models](https://arxiv.org/abs/2511.18393)
*Heejoon Koo*

Main category: cs.CL

TL;DR: 本研究系统分析了文本退化对LLM在临床诊断预测中鲁棒性和公平性的影响，提出了临床标签缩减和分层思维链策略来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 临床文本常因人为错误或自动化流程故障而质量下降，这会影响AI辅助决策的可靠性和公平性，但目前对此类退化影响的研究不足，特别是关于噪声如何增加预测不确定性并不同影响人口亚群。

Method: 引入临床基础的标签缩减方案和分层思维链策略，模拟临床医生的推理过程，在多种文本退化场景下测试最先进的LLM。

Result: 该方法在退化输入下提高了模型的鲁棒性，减少了亚群不稳定性，推进了LLM在临床决策支持系统中的可靠使用。

Conclusion: 提出的临床标签缩减和分层CoT策略有效提升了LLM在临床文本退化情况下的鲁棒性和公平性，为CDSS中可靠使用LLM提供了解决方案。

Abstract: A decade of rapid advances in artificial intelligence (AI) has opened new opportunities for clinical decision support systems (CDSS), with large language models (LLMs) demonstrating strong reasoning abilities on timely medical tasks. However, clinical texts are often degraded by human errors or failures in automated pipelines, raising concerns about the reliability and fairness of AI-assisted decision-making. Yet the impact of such degradations remains under-investigated, particularly regarding how noise-induced shifts can heighten predictive uncertainty and unevenly affect demographic subgroups. We present a systematic study of state-of-the-art LLMs under diverse text corruption scenarios, focusing on robustness and equity in next-visit diagnosis prediction. To address the challenge posed by the large diagnostic label space, we introduce a clinically grounded label-reduction scheme and a hierarchical chain-of-thought (CoT) strategy that emulates clinicians' reasoning. Our approach improves robustness and reduces subgroup instability under degraded inputs, advancing the reliable use of LLMs in CDSS. We release code at https://github.com/heejkoo9/NECHOv3.

</details>


### [31] [Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and Causal Variables in Language Models](https://arxiv.org/abs/2511.18409)
*Dana Arad,Yonatan Belinkov,Hanjie Chen,Najoung Kim,Hosein Mohebbi,Aaron Mueller,Gabriele Sarti,Martin Tutek*

Main category: cs.CL

TL;DR: 该论文介绍了基于Mechanistic Interpretability Benchmark (MIB)的BlackboxNLP 2025共享任务，包含电路定位和因果变量定位两个赛道，展示了多种方法在可解释性研究中的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决机制可解释性(MI)研究中进展衡量困难的问题，通过标准化评估框架来比较不同MI技术的效果。

Method: 基于MIB基准构建共享任务，包含电路定位(识别因果影响组件和交互)和因果变量定位(将激活映射为可解释特征)两个赛道，采用集成、正则化、低维和非线性投影等方法。

Result: 在电路定位中，8种方法通过集成和正则化策略获得显著提升；在因果变量定位中，2种方法通过低维和非线性投影实现显著增益。

Conclusion: MIB排行榜保持开放，鼓励继续使用这一标准化评估框架来衡量MI研究的进展。

Abstract: Mechanistic interpretability (MI) seeks to uncover how language models (LMs) implement specific behaviors, yet measuring progress in MI remains challenging. The recently released Mechanistic Interpretability Benchmark (MIB; Mueller et al., 2025) provides a standardized framework for evaluating circuit and causal variable localization. Building on this foundation, the BlackboxNLP 2025 Shared Task extends MIB into a community-wide reproducible comparison of MI techniques. The shared task features two tracks: circuit localization, which assesses methods that identify causally influential components and interactions driving model behavior, and causal variable localization, which evaluates approaches that map activations into interpretable features. With three teams spanning eight different methods, participants achieved notable gains in circuit localization using ensemble and regularization strategies for circuit discovery. With one team spanning two methods, participants achieved significant gains in causal variable localization using low-dimensional and non-linear projections to featurize activation vectors. The MIB leaderboard remains open; we encourage continued work in this standard evaluation framework to measure progress in MI research going forward.

</details>


### [32] [SmolKalam: Ensemble Quality-Filtered Translation at Scale for High Quality Arabic Post-Training Data](https://arxiv.org/abs/2511.18411)
*Sultan Alrashed,Chadi Helwe,Francesco Orabona*

Main category: cs.CL

TL;DR: SmolKalam是一个阿拉伯语多轮对话数据集，通过多模型集成翻译管道从Smoltalk2翻译而来，包含质量过滤和翻译技术消融研究。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、多轮、包含推理和工具调用的阿拉伯语数据集，而单纯的翻译方法在预训练后阶段需要更高质量的数据。

Method: 使用多模型集成翻译管道，应用质量过滤，并通过消融研究检验传统仅解码器模型的有效翻译技术。

Result: 成功创建了高质量的阿拉伯语多轮对话数据集SmolKalam。

Conclusion: 通过严格的翻译流程和质量控制，可以创建高质量的阿拉伯语对话数据集，满足后训练阶段的需求。

Abstract: Although the community has tackled the acquisition of high-quality Arabic pretraining data, we still lack large-scale, multi-turn Arabic datasets that include reasoning and tool calling. Naive translation can work at the pretraining scale, but post-training demands much higher quality, which requires a stricter approach to dataset curation. In this work, we introduce SmolKalam, a translation of Smoltalk2 that uses a multi-model ensemble translation pipeline, applies quality filtering, and examines effective translation techniques for traditional decoder-only models through ablations.

</details>


### [33] [Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations](https://arxiv.org/abs/2511.18413)
*Yu Xia,Sungchul Kim,Tong Yu,Ryan A. Rossi,Julian McAuely*

Main category: cs.CL

TL;DR: 提出了多智能体协同过滤框架MACF，将传统协同过滤算法与基于LLM的多智能体协作进行类比，通过动态智能体招募和个性化协作指令来提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有智能体推荐系统大多关注通用单智能体或多智能体任务分解流程，缺乏推荐导向设计，未能充分利用用户-物品交互历史中的协同信号，导致推荐结果不理想。

Method: 为目标用户和查询实例化相似用户和相关物品作为具有独特配置文件的LLM智能体，每个智能体能够调用检索工具、推荐候选物品并与其他智能体交互，通过中央编排器智能体动态管理用户和物品智能体之间的协作。

Result: 在三个不同领域的数据集上的实验结果表明，MACF框架相比强大的智能体推荐基线具有优势。

Conclusion: MACF框架通过将传统协同过滤与LLM多智能体协作相结合，有效提升了智能体推荐系统的性能。

Abstract: Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.

</details>


### [34] [General Agentic Memory Via Deep Research](https://arxiv.org/abs/2511.18423)
*B. Y. Yan,Chaofan Li,Hongjin Qian,Shuqi Lu,Zheng Liu*

Main category: cs.CL

TL;DR: 提出了一种名为GAM的新型智能体记忆框架，采用即时编译原则，在运行时为客户端创建优化上下文，同时离线阶段仅保留简单但有用的记忆。


<details>
  <summary>Details</summary>
Motivation: 解决静态记忆系统在预先创建可用记忆时不可避免的信息丢失问题。

Method: 采用双组件设计：1) Memorizer使用轻量级记忆突出关键历史信息，同时在通用页面存储中维护完整历史信息；2) Researcher根据预构建的记忆从页面存储中检索和整合有用信息。

Result: 在多种基于记忆的任务完成场景中，相比现有记忆系统实现了显著改进。

Conclusion: GAM框架能够有效利用前沿大语言模型的智能体能力和测试时扩展性，同时通过强化学习促进端到端性能优化。

Abstract: Memory is critical for AI agents, yet the widely-adopted static memory, aiming to create readily available memory in advance, is inevitably subject to severe information loss. To address this limitation, we propose a novel framework called \textbf{general agentic memory (GAM)}. GAM follows the principle of "\textbf{just-in time (JIT) compilation}" where it focuses on creating optimized contexts for its client at runtime while keeping only simple but useful memory during the offline stage. To this end, GAM employs a duo-design with the following components. 1) \textbf{Memorizer}, which highlights key historical information using a lightweight memory, while maintaining complete historical information within a universal page-store. 2) \textbf{Researcher}, which retrieves and integrates useful information from the page-store for its online request guided by the pre-constructed memory. This design allows GAM to effectively leverage the agentic capabilities and test-time scalability of frontier large language models (LLMs), while also facilitating end-to-end performance optimization through reinforcement learning. In our experimental study, we demonstrate that GAM achieves substantial improvement on various memory-grounded task completion scenarios against existing memory systems.

</details>


### [35] [MindEval: Benchmarking Language Models on Multi-turn Mental Health Support](https://arxiv.org/abs/2511.18491)
*José Pombal,Maya D'Eon,Nuno M. Guerreiro,Pedro Henrique Martins,António Farinhas,Ricardo Rei*

Main category: cs.CL

TL;DR: 提出了MindEval框架，这是一个与临床心理学家合作开发的自动评估语言模型在心理健康治疗对话中表现的系统，通过患者模拟和自动评估来测试AI聊天机器人的治疗能力。


<details>
  <summary>Details</summary>
Motivation: 当前心理健康AI聊天机器人存在诸多局限（如谄媚、过度验证、强化不良信念），且缺乏能捕捉真实治疗对话复杂性的评估基准。现有基准主要通过选择题测试临床知识或孤立评估单次回复。

Method: 与博士级持证临床心理学家合作设计MindEval框架，通过患者模拟和基于LLM的自动评估，在真实的多轮心理健康对话中评估语言模型。验证了模拟患者的真实性，并展示了自动评估与人类专家判断的强相关性。

Result: 评估了12个最先进的LLM，所有模型平均得分低于4分（满分6分），在AI特有的沟通模式方面表现尤其薄弱。推理能力和模型规模不能保证更好表现，系统在较长交互或支持严重症状患者时表现恶化。

Conclusion: 当前AI系统在心理健康支持方面仍有显著不足，需要更全面的评估框架来推动改进。MindEval为自动评估治疗对话中的语言模型提供了可行方案，并发布了所有代码、提示和人工评估数据。

Abstract: Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.

</details>


### [36] [For Those Who May Find Themselves on the Red Team](https://arxiv.org/abs/2511.18499)
*Tyler Shoemaker*

Main category: cs.CL

TL;DR: 文学学者必须参与大型语言模型可解释性研究，尽管这会涉及意识形态斗争甚至妥协，但当前可解释性方法的工具性不应成为衡量LLM解释的唯一标准。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型可解释性研究过于注重工具性，文学学者需要参与其中以引入更丰富的解释标准。

Method: 提出将红队作为文学学者参与LLM可解释性研究的实践场所。

Result: 论证了文学学者参与LLM可解释性研究的必要性和可行性。

Conclusion: 文学学者应当积极介入LLM可解释性研究领域，通过红队等实践场所展开意识形态斗争，推动解释标准的多元化。

Abstract: This position paper argues that literary scholars must engage with large language model (LLM) interpretability research. While doing so will involve ideological struggle, if not out-right complicity, the necessity of this engagement is clear: the abiding instrumentality of current approaches to interpretability cannot be the only standard by which we measure interpretation with LLMs. One site at which this struggle could take place, I suggest, is the red team.

</details>


### [37] [Dealing with the Hard Facts of Low-Resource African NLP](https://arxiv.org/abs/2511.18557)
*Yacouba Diarra,Nouhoum Souleymane Coulibaly,Panga Azazia Kamaté,Madani Amadou Tall,Emmanuel Élisé Koné,Aymane Dembélé,Michael Leventhal*

Main category: cs.CL

TL;DR: 为低资源语言班巴拉语收集了612小时自发语音数据，创建了半自动标注的数据集，开发了多个单语超紧凑和小型模型，并进行了自动和人工评估。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言创建语音数据集、模型和评估框架具有挑战性，缺乏相关经验基础。

Method: 通过实地收集班巴拉语自发语音，进行半自动转录标注，创建单语超紧凑和小型模型，并进行自动和人工评估。

Result: 收集了612小时语音数据，创建了多个模型，提供了数据收集协议、标注和模型设计的实用建议，并证明了人工评估的重要性。

Conclusion: 除了主要数据集外，还公开了多个评估数据集、模型和代码，为低资源语言的语音处理提供了实用资源和方法。

Abstract: Creating speech datasets, models, and evaluation frameworks for low-resource languages remains challenging given the lack of a broad base of pertinent experience to draw from. This paper reports on the field collection of 612 hours of spontaneous speech in Bambara, a low-resource West African language; the semi-automated annotation of that dataset with transcriptions; the creation of several monolingual ultra-compact and small models using the dataset; and the automatic and human evaluation of their output. We offer practical suggestions for data collection protocols, annotation, and model design, as well as evidence for the importance of performing human evaluation. In addition to the main dataset, multiple evaluation datasets, models, and code are made publicly available.

</details>


### [38] [Toward Trustworthy Difficulty Assessments: Large Language Models as Judges in Programming and Synthetic Tasks](https://arxiv.org/abs/2511.18597)
*H. M. Shadman Tabib,Jaber Ahmed Deedar*

Main category: cs.CL

TL;DR: GPT-4o作为编程问题难度评估器的表现不如基于特征的LightGBM模型，准确率仅37.75% vs 86%，且存在对简单类别的强烈偏见。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在结构化任务（如预测编程问题难度）中的表现，特别是在竞争性编程和教育应用中的可信度。

Method: 系统比较GPT-4o（纯自然语言评估器）与基于数值和文本特征的LightGBM集成模型，在1825个LeetCode问题上进行测试，并使用SHAP进行可解释性分析。

Result: LightGBM达到86%准确率，GPT-4o仅37.75%；GPT-4o忽视数值约束（如输入大小限制和接受率），对简单类别有强烈偏见；在合成难题生成实验中，GPT-4o将自己生成的难题大多标记为中等难度。

Conclusion: 在竞争性编程、教育平台或强化学习管道中，基于LLM的评判器在解决具体失败模式之前尚不可信。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in natural language and code generation, and are increasingly deployed as automatic judges of model outputs and learning activities. Yet, their behavior on structured tasks such as predicting the difficulty of competitive programming problems remains under-explored. We conduct a systematic comparison of GPT-4o, used purely as a natural-language difficulty assessor, against an interpretable Light-GBM ensemble trained on explicit numeric and textual features. On a dataset of 1,825 LeetCode problems labeled Easy, Medium, or Hard, LightGBM attains 86% accuracy, whereas GPT-4o reaches only 37.75%. Detailed analyses, including confusion matrices and SHAP-based interpretability, show that numeric constraints -- such as input size limits and acceptance rates -- play a crucial role in separating Hard problems from easier ones. By contrast, GPT-4o often overlooks these cues and exhibits a strong bias toward simpler categories. We further probe GPT-4o through a synthetic Hard-problem generation protocol. Surprisingly, GPT-4o labels almost all of its own synthetic Hard problems as Medium, contradicting its tendency to downgrade real Hard problems to Easy. Our findings connect to recent work on LLMs-as-judges and automatic difficulty estimation in programming and education, and highlight concrete failure modes that must be addressed before LLM-based judges can be considered trustworthy in competitive programming, educational platforms, or reinforcement-learning pipelines.

</details>


### [39] [A Benchmark for Zero-Shot Belief Inference in Large Language Models](https://arxiv.org/abs/2511.18616)
*Joseph Malone,Rachith Aiyappa,Byunghwee Lee,Haewoon Kwak,Jisun An,Yong-Yeol Ahn*

Main category: cs.CL

TL;DR: 该研究构建了一个系统性基准，评估LLM在零样本设置下预测个体对各种话题立场的能力，发现提供更多背景信息能提高准确性，但性能在不同信念领域差异显著。


<details>
  <summary>Details</summary>
Motivation: 信念是人类推理、沟通和社交的核心，但现有计算方法局限于特定社会政治背景且依赖微调。需要了解LLM在不同信念领域的泛化能力。

Method: 使用在线辩论平台数据，构建可复现的基准测试，包含多种信息条件来分离人口统计背景和已知先验信念对预测成功的贡献。

Result: 提供更多个体背景信息能提高预测准确率，但不同信念领域的性能差异很大。中小型模型表现各异。

Conclusion: 研究揭示了当前LLM模拟人类推理的能力和局限性，为超越社会政治领域的信念系统建模提供了可扩展框架。

Abstract: Beliefs are central to how humans reason, communicate, and form social connections, yet most computational approaches to studying them remain confined to narrow sociopolitical contexts and rely on fine-tuning for optimal performance. Despite the growing use of large language models (LLMs) across disciplines, how well these systems generalize across diverse belief domains remains unclear. We introduce a systematic, reproducible benchmark that evaluates the ability of LLMs to predict individuals' stances on a wide range of topics in a zero-shot setting using data from an online debate platform. The benchmark includes multiple informational conditions that isolate the contribution of demographic context and known prior beliefs to predictive success. Across several small- to medium-sized models, we find that providing more background information about an individual improves predictive accuracy, but performance varies substantially across belief domains. These findings reveal both the capacity and limitations of current LLMs to emulate human reasoning, advancing the study of machine behavior and offering a scalable framework for modeling belief systems beyond the sociopolitical sphere.

</details>


### [40] [A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News](https://arxiv.org/abs/2511.18618)
*Mirza Raquib,Munazer Montasir Akash,Tawhid Ahmed,Saydul Akbar Murad,Farida Siddiqi Prity,Mohammad Amzad Hossain,Asif Pervez Polok,Nick Rahimi*

Main category: cs.CL

TL;DR: 该研究提出了一种结合BERT-CNN-BiLSTM混合迁移学习模型的孟加拉语新闻标题分类和情感分析方法，在BAN-ABSA数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 报纸是重要的信息来源，但有效导航大量新闻内容具有挑战性。新闻标题情感分析有助于快速理解新闻的情感基调，特别是在孟加拉语这种低资源语言中。

Method: 使用BERT-CNN-BiLSTM混合迁移学习模型，在9014条孟加拉语新闻标题数据集上应用两种实验策略：技术1（分割前进行欠采样和过采样）和技术2（分割后进行欠采样和过采样）。

Result: 技术1中过采样在标题和情感分类上分别达到78.57%和73.43%的最佳性能；技术2中直接在原始不平衡数据集上训练分别达到81.37%和64.46%。BERT-CNN-BiLSTM模型显著优于所有基线模型。

Conclusion: 该模型为孟加拉语文本分类提供了强大的基准，证明了同时利用标题和情感数据集的重要性，在低资源语言中取得了最先进的结果。

Abstract: In our daily lives, newspapers are an essential information source that impacts how the public talks about present-day issues. However, effectively navigating the vast amount of news content from different newspapers and online news portals can be challenging. Newspaper headlines with sentiment analysis tell us what the news is about (e.g., politics, sports) and how the news makes us feel (positive, negative, neutral). This helps us quickly understand the emotional tone of the news. This research presents a state-of-the-art approach to Bangla news headline classification combined with sentiment analysis applying Natural Language Processing (NLP) techniques, particularly the hybrid transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called BAN-ABSA of 9014 news headlines, which is the first time that has been experimented with simultaneously in the headline and sentiment categorization in Bengali newspapers. Over this imbalanced dataset, we applied two experimental strategies: technique-1, where undersampling and oversampling are applied before splitting, and technique-2, where undersampling and oversampling are applied after splitting on the In technique-1 oversampling provided the strongest performance, both headline and sentiment, that is 78.57\% and 73.43\% respectively, while technique-2 delivered the highest result when trained directly on the original imbalanced dataset, both headline and sentiment, that is 81.37\% and 64.46\% respectively. The proposed model BERT-CNN-BiLSTM significantly outperforms all baseline models in classification tasks, and achieves new state-of-the-art results for Bangla news headline classification and sentiment analysis. These results demonstrate the importance of leveraging both the headline and sentiment datasets, and provide a strong baseline for Bangla text classification in low-resource.

</details>


### [41] [Prompt Optimization as a State-Space Search Problem](https://arxiv.org/abs/2511.18619)
*Maanas Taneja*

Main category: cs.CL

TL;DR: 将提示优化建模为状态空间搜索问题，通过束搜索和随机游走算法在提示图中探索优化路径，在五个NLP任务上验证了该方法能有效提升开发集性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型对输入提示的微小变化极为敏感，现有方法如DSpy通过演示优化提示，本文提出将提示优化视为经典状态空间搜索问题的新思路。

Method: 将提示空间建模为图结构，节点代表提示状态，边对应提示变换操作（如缩短、添加示例、重新排序内容），使用束搜索和随机游走算法系统探索空间，在开发集上评估候选提示并剪枝不具前景的分支。

Result: 在五个NLP任务上，即使浅层搜索配置（束宽=2，深度=2）也能在开发集上超越种子提示。例如推理任务中开发集准确率从0.40提升至0.80，但测试集改进较为有限（0.20到0.50），表明存在对开发集启发式的过拟合。

Conclusion: 验证了将提示优化作为搜索问题的可行性，成功优化路径分析显示简洁化变换最常用，而冗长操作从未被选择。建议通过更多计算资源和改进评估指标，进行更深层探索以获得更鲁棒的提示。

Abstract: Language Models are extremely susceptible to performance collapse with even small changes to input prompt strings. Libraries such as DSpy (from Stanford NLP) avoid this problem through demonstration-based prompt optimisation. Inspired by this, I propose an alternative approach that treats prompt optimisation as a classical state-space search problem. I model the prompt space as a graph where nodes represent prompt states and edges correspond to deliberate transformations such as shortening, adding examples, or re- ordering content. Using beam search and random walk algorithms, I systematically explore this space, evaluating candidates on development sets and pruning unpromising branches. Across five NLP tasks (sentiment classification, question answering, summarisation, reason- ing, and natural language inference), I find that even shallow search configurations (beam width=2, depth=2) improve upon seed prompts on development sets. For instance, beam search achieves development accuracy gains from 0.40 to 0.80 on reasoning tasks, though test set improvements are more modest (0.20 to 0.50), indicating overfitting to the develop- ment heuristic. Analysis of successful optimisation paths reveals that transformations that make prompts concise appear most frequently, while verbosity operators are never selected. My results validate prompt optimization as a search problem and suggest that with greater computational resources and improved evaluation metrics, deeper exploration could yield more robust prompts that generalize beyond development sets. Code and implementation are available at [https://github.com/MaanasTaneja/PromptOptimiser].

</details>


### [42] [OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge Graph](https://arxiv.org/abs/2511.18622)
*Michael J. Bommarito*

Main category: cs.CL

TL;DR: OpenGloss是一个合成的英语百科全书词典和语义知识图谱，整合了词典定义、百科全书背景、词源历史和语义关系，包含53.7万个词义和150万个词条，成本低于1000美元且在一周内生成。


<details>
  <summary>Details</summary>
Motivation: 解决传统词典资源制作成本高、周期长的问题，通过结构化生成技术创建综合的词汇资源，填补教学应用中的空白，支持词汇学习和自然语言处理任务。

Method: 采用多智能体程序生成流水线，结合模式验证的LLM输出和自动化质量保证，在低成本下快速生成结构化词汇资源。

Result: 生成了包含53.7万个词义、150万个词条、910万个语义边、100万个使用示例、300万个搭配和6000万词百科全书内容的资源，规模与WordNet 3.1相当但定义数量多四倍。

Conclusion: 结构化生成技术能够在传统人工整理不可行的时间和成本规模上创建全面的词汇资源，随着基础模型的改进可实现快速迭代，该资源已在Hugging Face上公开供研究和教育使用。

Abstract: We present OpenGloss, a synthetic encyclopedic dictionary and semantic knowledge graph for English that integrates lexicographic definitions, encyclopedic context, etymological histories, and semantic relationships in a unified resource. OpenGloss contains 537K senses across 150K lexemes, on par with WordNet 3.1 and Open English WordNet, while providing more than four times as many sense definitions. These lexemes include 9.1M semantic edges, 1M usage examples, 3M collocations, and 60M words of encyclopedic content.
  Generated through a multi-agent procedural generation pipeline with schema-validated LLM outputs and automated quality assurance, the entire resource was produced in under one week for under $1,000. This demonstrates that structured generation can create comprehensive lexical resources at cost and time scales impractical for manual curation, enabling rapid iteration as foundation models improve. The resource addresses gaps in pedagogical applications by providing integrated content -- definitions, examples, collocations, encyclopedias, etymology -- that supports both vocabulary learning and natural language processing tasks.
  As a synthetically generated resource, OpenGloss reflects both the capabilities and limitations of current foundation models. The dataset is publicly available on Hugging Face under CC-BY 4.0, enabling researchers and educators to build upon and adapt this resource.

</details>


### [43] [No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases](https://arxiv.org/abs/2511.18635)
*Shireen Chand,Faith Baca,Emilio Ferrara*

Main category: cs.CL

TL;DR: 该研究探讨了针对特定偏见进行缓解时可能产生的跨类别后果，发现虽然目标偏见可能减少，但经常会在其他维度产生意外的负面后果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从训练数据中继承了社会偏见，可能导致有害或不公平的输出。现有偏见缓解技术通常只评估目标偏见维度，而忽略了跨类别的影响。

Method: 研究了四种偏见缓解技术应用于十个模型（来自七个模型家族），探索了种族、宗教、职业和性别相关的偏见，使用StereoSet基准评估偏见缓解对模型连贯性和刻板印象偏好的影响。

Result: 研究结果显示，针对性偏见缓解虽然有时能减少目标维度的偏见，但经常在其他维度产生意外且往往是负面的后果，如增加模型偏见和降低一般连贯性。

Conclusion: 这些发现强调了在检查和开发偏见缓解策略时，需要强大的多维度评估工具，以避免无意中在未针对性维度上转移或加剧偏见。

Abstract: Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of the bias being targeted. This work investigates the cross-category consequences of targeted bias mitigation. We study four bias mitigation techniques applied across ten models from seven model families, and we explore racial, religious, profession- and gender-related biases. We measure the impact of debiasing on model coherence and stereotypical preference using the StereoSet benchmark. Our results consistently show that while targeted mitigation can sometimes reduce bias in the intended dimension, it frequently leads to unintended and often negative consequences in others, such as increasing model bias and decreasing general coherence. These findings underscore the critical need for robust, multi-dimensional evaluation tools when examining and developing bias mitigation strategies to avoid inadvertently shifting or worsening bias along untargeted axes.

</details>


### [44] [Evaluating Large Language Models on the 2026 Korean CSAT Mathematics Exam: Measuring Mathematical Ability in a Zero-Data-Leakage Setting](https://arxiv.org/abs/2511.18649)
*Goun Pyeon,Inbum Heo,Jeesu Jung,Taewook Hwang,Hyuk Namgoong,Hyein Seo,Yerim Han,Eunbin Kim,Hyeonseok Kang,Sangkeun Jung*

Main category: cs.CL

TL;DR: 本研究使用2026年韩国高考数学试卷对24个大语言模型进行数学推理能力评估，GPT-5 Codex获得满分，并分析了不同输入方式和推理强度对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基准测试中数据泄露问题，确保在完全未被模型训练数据污染的环境中评估LLMs的数学推理能力。

Method: 在考试公开后2小时内数字化所有46道题目，评估24个最先进LLMs在不同输入模态（文本、图像、文本+图形）和提示语言（韩语、英语）下的表现。

Result: GPT-5 Codex获得唯一满分，几何是最薄弱领域（平均77.7%），文本输入优于图像输入，增加推理强度能提升性能但大幅降低效率。

Conclusion: 本研究实现了完全未暴露的评估环境，建立了基于真实考试的LLM评估框架，并提供了综合考虑性能、成本和时间因素的实用评估视角。

Abstract: This study systematically evaluated the mathematical reasoning capabilities of Large Language Models (LLMs) using the 2026 Korean College Scholastic Ability Test (CSAT) Mathematics section, ensuring a completely contamination-free evaluation environment. To address data leakage issues in existing benchmarks, we digitized all 46 questions (22 common and 24 elective) within two hours of the exam's public release, eliminating any possibility of inclusion in model training data. We conducted comprehensive evaluations of 24 state-of-the-art LLMs across varying input modalities (text, image, text+figure) and prompt languages (Korean, English).
  GPT-5 Codex achieved the only perfect score (100 points) with text input and Korean prompts, while Grok 4, GPT-5, and Deepseek R1 scored above 95 points. Notably, gpt-oss-20B achieved 95.7 points despite its relatively small size, demonstrating high cost-effectiveness. Problem-specific analysis revealed geometry as the weakest domain (77.7% average) with significant performance degradation on 4-point high-difficulty problems. Text input consistently outperformed image input, while prompt language effects varied by model scale.
  In reasoning enhancement experiments with GPT-5 series, increased reasoning intensity improved performance (from 82.6 to 100 points) but quadrupled token usage and drastically reduced efficiency, suggesting that models with minimal reasoning may be more practical. This research contributes: (1) implementation of a completely unexposed evaluation environment, (2) a real-exam-based LLM assessment framework, and (3) a practical evaluation perspective integrating performance, cost, and time considerations. Detailed results and model comparisons are available at the 2026 Korean CSAT LLM Evaluation Leaderboard (https://isoft.cnu.ac.kr/csat2026/).

</details>


### [45] [CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning](https://arxiv.org/abs/2511.18659)
*Jie He,Richard He Bai,Sinead Williamson,Jeff Z. Pan,Navdeep Jaitly,Yizhe Zhang*

Main category: cs.CL

TL;DR: CLaRa是一个统一的检索增强生成框架，通过嵌入压缩和联合优化在共享连续空间中解决长上下文和检索-生成分离优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成方法存在长上下文处理和检索-生成模块分离优化的问题，导致性能受限。

Method: 提出CLaRa框架，使用SCP数据合成方法生成语义丰富的压缩向量，通过可微分top-k估计器实现重排序器和生成器的端到端联合训练。

Result: 在多个问答基准测试中，CLaRa实现了最先进的压缩和重排序性能，通常超越基于文本的微调基线方法。

Conclusion: CLaRa通过统一连续空间中的联合优化，成功解决了检索增强生成中的关键挑战，证明了理论上的检索相关性与答案质量对齐的有效性。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but still suffers from long contexts and disjoint retrieval-generation optimization. In this work, we propose CLaRa (Continuous Latent Reasoning), a unified framework that performs embedding-based compression and joint optimization in a shared continuous space. To obtain semantically rich and retrievable compressed vectors, we introduce SCP, a key-preserving data synthesis framework using QA and paraphrase supervision. CLaRa then trains the reranker and generator end-to-end via a single language modeling loss, with gradients flowing through both modules using a differentiable top-k estimator. Theoretically, this unified optimization aligns retrieval relevance with answer quality. Experiments across multiple QA benchmarks show that CLaRa achieves state-of-the-art compression and reranking performance, often surpassing text-based fine-tuned baselines.

</details>


### [46] [Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models](https://arxiv.org/abs/2511.18696)
*Wangjiaxuan Xin*

Main category: cs.CL

TL;DR: ECN框架通过四阶段提示方法增强大语言模型的共情能力，在GPT-3.5-turbo和GPT-4上获得最高共情商数得分


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在对话AI中的共情和包容能力

Method: 使用四阶段提示方法：视角采纳、情感共鸣、反思理解、整合综合

Result: ECN在GPT-3.5-turbo和GPT-4上获得最高共情商数得分，同时保持竞争力的尊重度和困惑度指标

Conclusion: ECN在需要共情和包容性的对话AI应用中具有重要潜力

Abstract: This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional Resonance, Reflective Understanding, and Integrative Synthesis, to guide models toward generating emotionally resonant and contextually aware responses. Experimental results demonstrate that ECN achieves the highest Empathy Quotient (EQ) scores across GPT-3.5-turbo and GPT-4, while maintaining competitive Regard and Perplexity metrics. These findings emphasize ECN's potential for applications requiring empathy and inclusivity in conversational AI.

</details>


### [47] [RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context](https://arxiv.org/abs/2511.18743)
*Yu Lei,Shuzheng Si,Wei Wang,Yifei Wu,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: RhinoInsight是一个深度研究框架，通过可验证清单和证据审计两个控制机制，增强LLM代理在深度研究任务中的鲁棒性、可追溯性和质量，无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 现有系统采用线性管道（规划-搜索-写作-报告）存在错误累积和上下文腐化问题，缺乏对模型行为和上下文的显式控制。

Method: 1. 可验证清单模块：将用户需求转化为可追溯的子目标，通过批评者精炼并生成层次化大纲；2. 证据审计模块：结构化搜索内容，迭代更新大纲，修剪噪声上下文，通过批评者排名和绑定高质量证据。

Result: 实验表明RhinoInsight在深度研究任务上达到最先进性能，同时在深度搜索任务上保持竞争力。

Conclusion: RhinoInsight通过添加控制机制有效解决了现有系统的局限性，提升了深度研究任务的质量和可靠性。

Abstract: Large language models are evolving from single-turn responders into tool-using agents capable of sustained reasoning and decision-making for deep research. Prevailing systems adopt a linear pipeline of plan to search to write to a report, which suffers from error accumulation and context rot due to the lack of explicit control over both model behavior and context. We introduce RhinoInsight, a deep research framework that adds two control mechanisms to enhance robustness, traceability, and overall quality without parameter updates. First, a Verifiable Checklist module transforms user requirements into traceable and verifiable sub-goals, incorporates human or LLM critics for refinement, and compiles a hierarchical outline to anchor subsequent actions and prevent non-executable planning. Second, an Evidence Audit module structures search content, iteratively updates the outline, and prunes noisy context, while a critic ranks and binds high-quality evidence to drafted content to ensure verifiability and reduce hallucinations. Our experiments demonstrate that RhinoInsight achieves state-of-the-art performance on deep research tasks while remaining competitive on deep search tasks.

</details>


### [48] [Large Language Models Require Curated Context for Reliable Political Fact-Checking -- Even with Reasoning and Web Search](https://arxiv.org/abs/2511.18749)
*Matthew R. DeVerna,Kai-Cheng Yang,Harry Yaojun Yan,Filippo Menczer*

Main category: cs.CL

TL;DR: 评估15个主流LLM在6000多个事实核查任务上的表现，发现标准模型表现差，推理能力帮助有限，网络搜索仅提供中等提升，而使用高质量上下文检索的RAG系统显著改善性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM具备推理和网络搜索能力并被广泛用于事实核查，急需对其性能进行严格评估。

Method: 在PolitiFact的6000多个事实核查声明上测试15个LLM，比较标准模型、推理变体和网络搜索变体的表现。

Result: 标准模型表现差，推理能力帮助有限，网络搜索仅提供中等提升，而RAG系统将宏观F1平均提高了233%。

Conclusion: 为模型提供高质量上下文是自动化事实核查的有前景路径，而非依赖模型自身的推理或网络搜索能力。

Abstract: Large language models (LLMs) have raised hopes for automated end-to-end fact-checking, but prior studies report mixed results. As mainstream chatbots increasingly ship with reasoning capabilities and web search tools -- and millions of users already rely on them for verification -- rigorous evaluation is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek on more than 6,000 claims fact-checked by PolitiFact, comparing standard models with reasoning- and web-search variants. Standard models perform poorly, reasoning offers minimal benefits, and web search provides only moderate gains, despite fact-checks being available on the web. In contrast, a curated RAG system using PolitiFact summaries improved macro F1 by 233% on average across model variants. These findings suggest that giving models access to curated high-quality context is a promising path for automated fact-checking.

</details>


### [49] [Robust Multimodal Sentiment Analysis with Distribution-Based Feature Recovery and Fusion](https://arxiv.org/abs/2511.18751)
*Daiqing Wu,Dongbao Yang,Can Ma,Yu Zhou*

Main category: cs.CL

TL;DR: 提出了一种基于分布的特征恢复与融合方法(DRF)，用于处理图像-文本对中低质量和缺失模态的鲁棒多模态情感分析问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在同时利用图像和文本信息方面取得显著成果，但缺乏对可能存在的低质量和缺失模态的考虑。在现实应用中，这些问题频繁发生，迫切需要能够鲁棒预测情感的模型。

Method: 为每个模态维护特征队列以近似其特征分布，通过统一框架同时处理低质量和缺失模态。对于低质量模态，基于分布定量估计模态质量并减少其对融合的贡献；对于缺失模态，通过样本和分布监督建立模态间映射关系，从可用模态恢复缺失模态。

Result: 在三个公开图像-文本数据集上的综合实验表明，DRF相比SOTA方法在两种破坏策略下均取得普遍改进，验证了其在鲁棒多模态情感分析中的有效性。

Conclusion: DRF方法能够有效处理现实场景中的低质量和缺失模态问题，为鲁棒多模态情感分析提供了有效的解决方案。

Abstract: As posts on social media increase rapidly, analyzing the sentiments embedded in image-text pairs has become a popular research topic in recent years. Although existing works achieve impressive accomplishments in simultaneously harnessing image and text information, they lack the considerations of possible low-quality and missing modalities. In real-world applications, these issues might frequently occur, leading to urgent needs for models capable of predicting sentiment robustly. Therefore, we propose a Distribution-based feature Recovery and Fusion (DRF) method for robust multimodal sentiment analysis of image-text pairs. Specifically, we maintain a feature queue for each modality to approximate their feature distributions, through which we can simultaneously handle low-quality and missing modalities in a unified framework. For low-quality modalities, we reduce their contributions to the fusion by quantitatively estimating modality qualities based on the distributions. For missing modalities, we build inter-modal mapping relationships supervised by samples and distributions, thereby recovering the missing modalities from available ones. In experiments, two disruption strategies that corrupt and discard some modalities in samples are adopted to mimic the low-quality and missing modalities in various real-world scenarios. Through comprehensive experiments on three publicly available image-text datasets, we demonstrate the universal improvements of DRF compared to SOTA methods under both two strategies, validating its effectiveness in robust multimodal sentiment analysis.

</details>


### [50] [Context-Aware Whisper for Arabic ASR Under Linguistic Varieties](https://arxiv.org/abs/2511.18774)
*Bashar Talafha,Amin Abu Alhassan,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 提出上下文感知提示策略，无需重新训练即可适配Whisper用于阿拉伯语语音识别，在多种阿拉伯语条件下显著降低词错误率


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语等低资源语言的ASR挑战，特别是方言变异大和标注数据有限的问题

Method: 使用解码器提示（首遍转录或检索语句）和编码器前缀（目标说话人语音合成），包括提示重排序、说话人感知前缀合成和模态特定检索技术

Result: 在九种阿拉伯语条件下，现代标准阿拉伯语WER降低22.3%，方言语音降低9.2%，显著减少幻觉和说话人不匹配

Conclusion: 上下文感知提示策略能有效提升低资源阿拉伯语ASR性能，无需模型重训练

Abstract: Low-resource ASR remains a challenging problem, especially for languages like Arabic that exhibit wide dialectal variation and limited labeled data. We propose context-aware prompting strategies to adapt OpenAI's Whisper for Arabic speech recognition without retraining. Our methods include decoder prompting with first-pass transcriptions or retrieved utterances, and encoder prefixing using speech synthesized in the target speaker's voice. We introduce techniques such as prompt reordering, speaker-aware prefix synthesis, and modality-specific retrieval (lexical, semantic, acoustic) to improve transcription in real-world, zero-shot settings. Evaluated on nine Arabic linguistic conditions, our approach reduces WER by up to 22.3% on Modern Standard Arabic and 9.2% on dialectal speech, significantly mitigating hallucinations and speaker mismatch.

</details>


### [51] [HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations](https://arxiv.org/abs/2511.18808)
*Cao Linxiao,Wang Ruitao,Li Jindong,Zhou Zhipeng,Yang Menglin*

Main category: cs.CL

TL;DR: HyperbolicRAG是一个将双曲几何融入基于图的检索增强生成框架，通过双曲嵌入捕捉知识图谱中的层次结构关系，提升语义检索效果


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的RAG方法依赖欧几里得嵌入，虽然能捕捉语义相似性但缺乏对层次深度关系的几何表示，限制了在复杂知识图谱中表示抽象关系的能力

Method: 提出三个关键设计：1) 在共享庞加莱流形中的深度感知表示学习器；2) 跨抽象层次强制几何一致性的无监督对比正则化；3) 联合利用欧几里得和双曲空间检索信号的互排名融合机制

Result: 在多个QA基准测试上的广泛实验表明，HyperbolicRAG优于包括标准RAG和图增强基线在内的竞争基线

Conclusion: 双曲几何能够有效增强图基RAG的表示能力，通过同时捕捉细粒度语义和全局层次结构，显著提升检索性能

Abstract: Retrieval-augmented generation (RAG) enables large language models (LLMs) to access external knowledge, helping mitigate hallucinations and enhance domain-specific expertise. Graph-based RAG enhances structural reasoning by introducing explicit relational organization that enables information propagation across semantically connected text units. However, these methods typically rely on Euclidean embeddings that capture semantic similarity but lack a geometric notion of hierarchical depth, limiting their ability to represent abstraction relationships inherent in complex knowledge graphs. To capture both fine-grained semantics and global hierarchy, we propose HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware representation learner that embeds nodes within a shared Poincare manifold to align semantic similarity with hierarchical containment, (2) an unsupervised contrastive regularization that enforces geometric consistency across abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing cross-space agreement during inference. Extensive experiments across multiple QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines, including both standard RAG and graph-augmented baselines.

</details>


### [52] [Concept than Document: Context Compression via AMR-based Conceptual Entropy](https://arxiv.org/abs/2511.18832)
*Kaize Shi,Xueyao Sun,Xiaohui Tao,Lin Li,Qika Lin,Guandong Xu*

Main category: cs.CL

TL;DR: 提出基于抽象意义表示(AMR)图的无监督上下文压缩框架，通过节点级熵量化概念重要性，保留核心语义同时过滤冗余内容，在问答任务中实现更高准确率和更短上下文。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文时面临信息过载问题，特别是在检索增强生成中，大量支持文档常包含冗余内容，这会降低推理准确性并增加计算开销。

Method: 构建AMR图，计算节点概念熵来估计每个节点的概念重要性，筛选重要信息节点形成压缩的语义聚焦上下文。

Result: 在PopQA和EntityQuestions数据集上的实验表明，该方法优于基准方法，在显著减少上下文长度的同时获得更高准确率。

Conclusion: 这是首个将基于AMR的概念熵引入上下文压缩的工作，展示了稳定语言特征在上下文工程中的潜力。

Abstract: Large Language Models (LLMs) face information overload when handling long contexts, particularly in Retrieval-Augmented Generation (RAG) where extensive supporting documents often introduce redundant content. This issue not only weakens reasoning accuracy but also increases computational overhead. We propose an unsupervised context compression framework that exploits Abstract Meaning Representation (AMR) graphs to preserve semantically essential information while filtering out irrelevant text. By quantifying node-level entropy within AMR graphs, our method estimates the conceptual importance of each node, enabling the retention of core semantics. Specifically, we construct AMR graphs from raw contexts, compute the conceptual entropy of each node, and screen significant informative nodes to form a condensed and semantically focused context than raw documents. Experiments on the PopQA and EntityQuestions datasets show that our method outperforms vanilla and other baselines, achieving higher accuracy while substantially reducing context length. To the best of our knowledge, this is the first work introducing AMR-based conceptual entropy for context compression, demonstrating the potential of stable linguistic features in context engineering.

</details>


### [53] [A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis](https://arxiv.org/abs/2511.18843)
*Heger Arfaoui,Mohammed Iheb Hergli,Beya Benzina,Slimane BenMiled*

Main category: cs.CL

TL;DR: 提出了一个用于焦点小组讨论文本的计算分析框架，通过BERTopic主题建模解决超参数敏感性、模型稳定性和可解释性验证等挑战，在突尼斯HPV疫苗认知研究中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统焦点小组数据分析依赖人工编码，限制了可扩展性和可重复性。需要开发可重复的计算框架来处理定性文本数据。

Method: 使用BERTopic对10个焦点小组的1076条话语进行主题建模，系统评估27种超参数配置，通过30次bootstrap重采样评估稳定性，并由3名领域专家进行人工验证。

Result: 发现主题建模对超参数选择敏感，分层合并策略在稳定性-连贯性权衡中表现良好（连贯性0.558 vs 0.539），人工验证显示良好评分者间信度（ICC=0.79，加权Cohen's kappa=0.578）。

Conclusion: 该框架为定性研究提供了实用指南，所有代码、数据处理脚本和评估协议都已公开，支持研究的复现和扩展。

Abstract: Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a rigorous, reproducible computational framework for applying neural topic modeling to focus group transcripts, addressing fundamental methodological challenges: hyperparameter sensitivity, model stability, and validation of interpretability. Using BERTopic applied to ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076 utterances), we conducted systematic evaluation across 27 hyperparameter configurations, assessed stability through bootstrap resampling with 30 replicates per configuration, and validated interpretability through formal human evaluation by three domain experts. Our analysis demonstrates substantial sensitivity to hyperparameter choices and reveals that metric selection for stability assessment must align with analytical goals. A hierarchical merging strategy (extracting fine-grained topics for stability then consolidating for interpretability) effectively navigates the stability-coherence tradeoff, achieving coherence of 0.558 compared to 0.539 for direct extraction. Human validation confirmed topic quality with very good inter-rater reliability (ICC = 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical guidelines that researchers can adapt to their own qualitative research contexts. All code, data processing scripts, and evaluation protocols are publicly available to support reproduction and extension of this work.

</details>


### [54] [Large Language Models for the Summarization of Czech Documents: From History to the Present](https://arxiv.org/abs/2511.18848)
*Václav Tran,Jakub Šmíd,Ladislav Lenc,Jean-Pierre Salmon,Pavel Král*

Main category: cs.CL

TL;DR: 本文通过使用大型语言模型（Mistral和mT5）和翻译方法，解决了捷克语文本摘要的空白，特别是在历史文献领域，并创建了新的历史捷克语摘要数据集。


<details>
  <summary>Details</summary>
Motivation: 捷克语摘要，特别是历史文献摘要，由于语言复杂性和缺乏高质量标注数据集而研究不足，需要填补这一空白。

Method: 使用大型语言模型（Mistral和mT5）进行直接摘要，以及翻译方法：先将捷克语文本翻译成英语，用英语模型摘要，再翻译回捷克语。

Result: 在SumeCzech数据集上达到最先进结果，创建了新的历史捷克语摘要数据集Posel od Čerchova，并为该数据集提供了基准模型。

Conclusion: 这项工作为捷克语摘要研究奠定了基础，为捷克历史文献处理和低资源语言摘要提供了宝贵资源。

Abstract: Text summarization is the task of automatically condensing longer texts into shorter, coherent summaries while preserving the original meaning and key information. Although this task has been extensively studied in English and other high-resource languages, Czech summarization, particularly in the context of historical documents, remains underexplored. This is largely due to the inherent linguistic complexity of Czech and the lack of high-quality annotated datasets.
  In this work, we address this gap by leveraging the capabilities of Large Language Models (LLMs), specifically Mistral and mT5, which have demonstrated strong performance across a wide range of natural language processing tasks and multilingual settings. In addition, we also propose a translation-based approach that first translates Czech texts into English, summarizes them using an English-language model, and then translates the summaries back into Czech. Our study makes the following main contributions: We demonstrate that LLMs achieve new state-of-the-art results on the SumeCzech dataset, a benchmark for modern Czech text summarization, showing the effectiveness of multilingual LLMs even for morphologically rich, medium-resource languages like Czech. We introduce a new dataset, Posel od Čerchova, designed for the summarization of historical Czech texts. This dataset is derived from digitized 19th-century publications and annotated for abstractive summarization. We provide initial baselines using modern LLMs to facilitate further research in this underrepresented area.
  By combining cutting-edge models with both modern and historical Czech datasets, our work lays the foundation for further progress in Czech summarization and contributes valuable resources for future research in Czech historical document processing and low-resource summarization more broadly.

</details>


### [55] [Cognitive Alpha Mining via LLM-Driven Code-Based Evolution](https://arxiv.org/abs/2511.18850)
*Fengyuan Liu,Huang Yi,Sichun Luo,Yuqi Wang,Yazheng Yang,Xinye Li,Zefa Hu,Junlan Feng,Qi Liu*

Main category: cs.CL

TL;DR: 提出了CogAlpha框架，结合代码级alpha表示、LLM驱动推理和进化搜索，用于从高维金融数据中发现有效的预测信号（alpha因子）。


<details>
  <summary>Details</summary>
Motivation: 现有方法（深度学习、遗传编程、LLM因子生成）在庞大的alpha搜索空间中探索范围有限，神经网络模型产生不透明和脆弱的模式，符号方法产生冗余或经济意义不足的表达式，缺乏平衡逻辑一致性和创造性的人类式探索。

Method: 将LLM作为自适应认知代理，通过多阶段提示和金融反馈迭代优化、变异和重组alpha候选，结合代码级alpha表示与进化搜索。

Result: 在A股股票上的实验表明，CogAlpha能够持续发现具有更优预测准确性、鲁棒性和泛化能力的alpha因子。

Conclusion: 将进化优化与基于LLM的推理相结合，有望实现自动化和可解释的alpha发现。

Abstract: Discovering effective predictive signals, or ``alphas,'' from financial data with high dimensionality and extremely low signal-to-noise ratio remains a difficult open problem. Despite progress in deep learning, genetic programming, and, more recently, large language model (LLM)--based factor generation, existing approaches still explore only a narrow region of the vast alpha search space. Neural models tend to produce opaque and fragile patterns, while symbolic or formula-based methods often yield redundant or economically ungrounded expressions that generalize poorly. Although different in form, these paradigms share a key limitation: none can conduct broad, structured, and human-like exploration that balances logical consistency with creative leaps. To address this gap, we introduce the Cognitive Alpha Mining Framework (CogAlpha), which combines code-level alpha representation with LLM-driven reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents, our framework iteratively refines, mutates, and recombines alpha candidates through multi-stage prompts and financial feedback. This synergistic design enables deeper thinking, richer structural diversity, and economically interpretable alpha discovery, while greatly expanding the effective search space. Experiments on A-share equities demonstrate that CogAlpha consistently discovers alphas with superior predictive accuracy, robustness, and generalization over existing methods. Our results highlight the promise of aligning evolutionary optimization with LLM-based reasoning for automated and explainable alpha discovery. All source code will be released.

</details>


### [56] [FanarGuard: A Culturally-Aware Moderation Filter for Arabic Language Models](https://arxiv.org/abs/2511.18852)
*Masoomali Fatehkia,Enes Altinisik,Husrev Taha Sencar*

Main category: cs.CL

TL;DR: FanarGuard是一个双语内容审核过滤器，专门针对阿拉伯语和英语设计，同时评估安全性和文化对齐性。它通过大规模数据集训练，在文化对齐方面表现优于人类标注者间的一致性，在安全性基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核过滤器主要关注一般安全性而忽视文化背景，特别是在阿拉伯语等非英语语境中缺乏文化敏感性的评估。

Method: 构建包含46.8万条提示-响应对的数据集，由LLM评委在无害性和文化意识方面评分，训练两种过滤器变体。开发首个针对阿拉伯文化背景的基准测试，包含1000多个规范敏感提示和人工标注的LLM生成响应。

Result: FanarGuard在文化对齐方面与人类标注的一致性优于标注者间可靠性，在安全性基准测试中与最先进过滤器性能相当。

Conclusion: 研究强调了将文化意识整合到内容审核中的重要性，FanarGuard是实现更上下文敏感保障措施的实际步骤。

Abstract: Content moderation filters are a critical safeguard against alignment failures in language models. Yet most existing filters focus narrowly on general safety and overlook cultural context. In this work, we introduce FanarGuard, a bilingual moderation filter that evaluates both safety and cultural alignment in Arabic and English. We construct a dataset of over 468K prompt and response pairs, drawn from synthetic and public datasets, scored by a panel of LLM judges on harmlessness and cultural awareness, and use it to train two filter variants. To rigorously evaluate cultural alignment, we further develop the first benchmark targeting Arabic cultural contexts, comprising over 1k norm-sensitive prompts with LLM-generated responses annotated by human raters. Results show that FanarGuard achieves stronger agreement with human annotations than inter-annotator reliability, while matching the performance of state-of-the-art filters on safety benchmarks. These findings highlight the importance of integrating cultural awareness into moderation and establish FanarGuard as a practical step toward more context-sensitive safeguards.

</details>


### [57] [Generating Reading Comprehension Exercises with Large Language Models for Educational Applications](https://arxiv.org/abs/2511.18860)
*Xingyu Huang,Fei Jiang,Jianli Xiao*

Main category: cs.CL

TL;DR: 提出了一个名为RCEG的LLM框架，用于自动生成高质量、个性化的英语阅读理解练习，通过微调LLM生成候选内容，再使用判别器选择最佳候选，显著提升了生成内容的质量。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，在教育领域特别是自动文本生成方面展现出巨大潜力，能够创建智能和自适应的学习内容。

Method: RCEG框架首先使用微调的大语言模型生成内容候选，然后使用判别器选择最佳候选，最后通过质量提升机制大幅改善生成内容质量。

Result: 实验结果表明，RCEG显著提高了生成练习的相关性和认知适当性，在内容多样性、事实准确性、语言毒性和教学对齐等综合评估指标上表现优异。

Conclusion: RCEG框架能够有效生成高质量的英语阅读理解练习，在教育领域具有重要的应用价值。

Abstract: With the rapid development of large language models (LLMs), the applications of LLMs have grown substantially. In the education domain, LLMs demonstrate significant potential, particularly in automatic text generation, which enables the creation of intelligent and adaptive learning content. This paper proposes a new LLMs framework, which is named as Reading Comprehension Exercise Generation (RCEG). It can generate high-quality and personalized English reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned LLMs to generate content candidates. Then, it uses a discriminator to select the best candidate. Finally, the quality of the generated content has been improved greatly. To evaluate the performance of RCEG, a dedicated dataset for English reading comprehension is constructed to perform the experiments, and comprehensive evaluation metrics are used to analyze the experimental results. These metrics include content diversity, factual accuracy, linguistic toxicity, and pedagogical alignment. Experimental results show that RCEG significantly improves the relevance and cognitive appropriateness of the generated exercises.

</details>


### [58] [Think Before You Prune: Selective Self-Generated Calibration for Pruning Large Reasoning Models](https://arxiv.org/abs/2511.18864)
*Yang Xiang,Yixin Ji,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 首次对大型推理模型进行剪枝研究，发现使用自生成推理数据作为校准数据能显著提升剪枝效果，提出选择性自生成推理数据构建策略，相比通用剪枝方法提升推理能力10%-13%。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务上表现出色，但其长链推理过程带来显著推理开销。剪枝是减少计算成本的有前景方法，但现有研究主要关注大语言模型，大型推理模型的剪枝尚未探索。

Method: 提出选择性自生成推理数据构建策略，使用具有挑战性和中等长度的自生成推理数据作为剪枝校准数据，研究推理数据难度和长度对剪枝效果的影响。

Result: 在DeepSeek-R1-Distill模型系列上的实验结果表明，该策略相比通用剪枝方法将剪枝后大型推理模型的推理能力提升了10%-13%。

Conclusion: 自生成推理数据是大型推理模型剪枝的有效校准数据，挑战性和中等长度的推理数据是最佳选择，选择性自生成推理数据构建策略显著提升了剪枝效果。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning benchmarks. However, their long chain-of-thought reasoning processes incur significant inference overhead. Pruning has emerged as a promising approach to reducing computational costs. However, existing efforts have primarily focused on large language models (LLMs), while pruning LRMs remains unexplored. In this work, we conduct the first empirical study on pruning LRMs and show that directly applying existing pruning techniques fails to yield satisfactory results. Our findings indicate that using self-generated reasoning data for calibration can substantially improve pruning performance. We further investigate how the difficulty and length of reasoning data affect pruning outcomes. Our analysis reveals that challenging and moderately long self-generated reasoning data serve as ideal calibration data. Based on these insights, we propose a Selective Self-Generated Reasoning (SSGR) data construction strategy to provide effective calibration data for pruning LRMs. Experimental results on the DeepSeek-R1-Distill model series validate that our strategy improves the reasoning ability of pruned LRMs by 10%-13% compared to general pruning methods.

</details>


### [59] [CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation](https://arxiv.org/abs/2511.18889)
*Jingqian Zhao,Bingbing Wang,Geng Tu,Yice Zhang,Qianlong Wang,Bin Liang,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: CoreEval是一种抗数据污染评估策略，通过从GDELT数据库获取最新知识来更新数据，解决LLM评估中的测试数据泄露问题。


<details>
  <summary>Details</summary>
Motivation: 数据污染导致LLM评估不公平，现有方法无法完全消除模型预训练知识或保持原始数据集的语义复杂性。

Method: 从原始数据提取实体关系，使用GDELT数据库检索最新知识，重新语境化并整合知识，通过数据反射机制迭代验证标签。

Result: 在更新数据集上的广泛实验验证了CoreEval的鲁棒性，有效减轻了由数据污染引起的性能高估。

Conclusion: CoreEval提供了一种有效的抗数据污染评估方法，通过动态知识更新确保评估的公平性和准确性。

Abstract: Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \textbf{CoreEval}, a \textbf{Co}ntamination-\textbf{re}silient \textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.

</details>


### [60] [Reproducibility Study of Large Language Model Bayesian Optimization](https://arxiv.org/abs/2511.18891)
*Adam Rychert,Gasper Spagnolo,Evgenii Posashkov*

Main category: cs.CL

TL;DR: LLAMBO框架使用大语言模型作为贝叶斯优化的判别式代理和采集优化器，通过纯文本交互实现。复现研究证实了其主要主张：上下文预热启动改善了早期遗憾行为，减少了方差；判别式代理虽弱于传统方法但受益于跨任务语义先验；移除文本上下文会显著降低性能；候选采样器优于TPE和随机采样。


<details>
  <summary>Details</summary>
Motivation: 重新验证LLAMBO框架的有效性，使用开源的Llama 3.1 70B模型替代GPT-3.5，测试该架构对不同语言模型骨干的鲁棒性。

Method: 在原始评估协议下复现核心Bayesmark和HPOBench实验，将GPT-3.5替换为Llama 3.1 70B模型用于所有文本编码组件，并进行消融实验验证各组件重要性。

Result: 结果证实了LLAMBO的主要主张：上下文预热启动改善了早期遗憾行为和方差；判别式代理受益于跨任务语义先验；移除文本上下文会降低预测准确性和校准；候选采样器生成更高质量和多样化的提议；较小模型产生不稳定预测。

Conclusion: LLAMBO架构对更换语言模型骨干具有鲁棒性，使用Llama 3.1 70B时仍保持有效性，但需要足够容量的模型才能实现可靠的代理行为。

Abstract: In this reproducibility study, we revisit the LLAMBO framework of Daxberger et al. (2024), a prompting-based Bayesian optimization (BO) method that uses large language models as discriminative surrogates and acquisition optimizers via text-only interactions. We replicate the core Bayesmark and HPOBench experiments under the original evaluation protocol, but replace GPT-3.5 with the open-weight Llama 3.1 70B model used for all text encoding components.
  Our results broadly confirm the main claims of LLAMBO. Contextual warm starting via textual problem and hyperparameter descriptions substantially improves early regret behaviour and reduces variance across runs. LLAMBO's discriminative surrogate is weaker than GP or SMAC as a pure single task regressor, yet benefits from cross task semantic priors induced by the language model. Ablations that remove textual context markedly degrade predictive accuracy and calibration, while the LLAMBO candidate sampler consistently generates higher quality and more diverse proposals than TPE or random sampling. Experiments with smaller backbones (Gemma 27B, Llama 3.1 8B) yield unstable or invalid predictions, suggesting insufficient capacity for reliable surrogate behaviour.
  Overall, our study shows that the LLAMBO architecture is robust to changing the language model backbone and remains effective when instantiated with Llama 3.1 70B.

</details>


### [61] [Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs](https://arxiv.org/abs/2511.18931)
*Sahil Kale*

Main category: cs.CL

TL;DR: 评估大型语言模型在需要时有效使用网络搜索的能力，发现网络访问能显著提升准确性，但模型存在过度自信、检索时机不当和查询表述不佳等问题。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型集成了网络搜索功能，但尚不清楚它们是否能在真正需要时有效使用搜索。需要评估模型基于内部置信度调用搜索的能力，以及识别何时需要搜索并检索更新信息的能力。

Method: 构建包含静态和动态问题的基准数据集。静态部分包含783个时间锚定问题，测试模型基于低内部置信度调用搜索的能力；动态部分包含288个截止日期后查询，测试模型识别搜索需求并检索更新信息的能力。

Result: 网络访问显著提高了GPT-5-mini和Claude Haiku 4.5的静态准确性，但置信度校准变差。在动态查询中，模型频繁调用搜索但准确率仍低于70%，主要由于查询表述不佳。选择性调用有帮助，但搜索后模型变得过度自信和不一致。

Conclusion: 内置网络搜索能显著提升事实准确性且可选择性调用，但模型仍存在过度自信、在必需时跳过检索以及初始搜索查询表现不佳时表现下降的问题。网络搜索更适合作为低延迟验证层而非可靠分析工具，仍有明显改进空间。

Abstract: Modern large language models integrate web search to provide real-time answers, yet it remains unclear whether they are efficiently calibrated to use search when it is actually needed. We introduce a benchmark evaluating both the necessity and effectiveness of web access across commercial models with no access to internal states or parameters. The dataset includes a static split of 783 temporally anchored questions answerable from pre-cutoff knowledge, aimed at testing whether models invoke search based on low internal confidence, and a dynamic split of 288 post-cutoff queries designed to test whether models recognise when search is required and retrieve updated information. Web access substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5, though confidence calibration worsens. On dynamic queries, both models frequently invoke search yet remain below 70 percent accuracy due to weak query formulation. Costs per accuracy-improving call remain low, but returns diminish once initial retrieval fails. Selective invocation helps, but models become overconfident and inconsistent after search. Overall, built-in web search meaningfully improves factual accuracy and can be invoked selectively, yet models remain overconfident, skip retrieval when it is essential, and falter once initial search queries underperform. Taken together, internal web search works better as a good low-latency verification layer than a reliable analytical tool, with clear room for improvement.

</details>


### [62] [Skeletons Matter: Dynamic Data Augmentation for Text-to-Query](https://arxiv.org/abs/2511.18934)
*Yuchen Ji,Bo Xu,Jie Shi,Jiaqing Liang,Deqing Yang,Yu Mao,Hai Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: 本文提出了Text-to-Query任务范式，通过识别查询骨架作为共享优化目标，并开发动态数据增强框架来诊断模型弱点并合成针对性训练数据，在四个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只关注单一查询语言，导致方法在不同语言间的泛化能力有限。需要统一语义解析任务，提高跨查询语言的通用性。

Method: 定义Text-to-Query任务范式，识别查询骨架作为共享优化目标，提出动态数据增强框架来诊断模型特定弱点并合成针对性训练数据。

Result: 在四个Text-to-Query基准测试中，仅使用少量合成数据就实现了最先进的性能，证明了方法的效率和通用性。

Conclusion: 该方法为Text-to-Query任务的统一研究奠定了坚实基础，通过查询骨架和动态数据增强实现了跨查询语言的高效语义解析。

Abstract: The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.

</details>


### [63] [Knowledge-based Graphical Method for Safety Signal Detection in Clinical Trials](https://arxiv.org/abs/2511.18937)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: 提出了一种基于图形化知识的方法，通过为MedDRA添加隐藏医学知识层(Safeterm)来自动聚类不良事件术语，并计算其与试验疾病的关联度，从而提高临床试验中不良事件审查的清晰度、效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统MedDRA术语系统缺乏语义关系信息，导致不良事件审查效率低下且容易遗漏重要信号。需要一种能够自动识别相似不良事件并量化其与试验疾病关联的方法。

Method: 在MedDRA基础上添加Safeterm医学知识层，构建2D语义地图；使用收缩发生率比计算治疗特异性不成比例指标；通过精度加权聚合推导簇级EBGM值；提供语义地图和期望度-不成比例度图两种可视化输出。

Result: 应用于三个历史试验，自动化方法能够清晰恢复所有预期的安全信号，验证了方法的有效性。

Conclusion: 通过为MedDRA添加医学知识层，显著提高了临床试验中不良事件解释的清晰度、效率和准确性。

Abstract: We present a graphical, knowledge-based method for reviewing treatment-emergent adverse events (AEs) in clinical trials. The approach enhances MedDRA by adding a hidden medical knowledge layer (Safeterm) that captures semantic relationships between terms in a 2-D map. Using this layer, AE Preferred Terms can be regrouped automatically into similarity clusters, and their association to the trial disease may be quantified. The Safeterm map is available online and connected to aggregated AE incidence tables from ClinicalTrials.gov. For signal detection, we compute treatment-specific disproportionality metrics using shrinkage incidence ratios. Cluster-level EBGM values are then derived through precision-weighted aggregation. Two visual outputs support interpretation: a semantic map showing AE incidence and an expectedness-versus-disproportionality plot for rapid signal detection. Applied to three legacy trials, the automated method clearly recovers all expected safety signals. Overall, augmenting MedDRA with a medical knowledge layer improves clarity, efficiency, and accuracy in AE interpretation for clinical trials.

</details>


### [64] [Logic of Montage](https://arxiv.org/abs/2511.19063)
*Hayami Takahashi,Kensuke Takahashi*

Main category: cs.CL

TL;DR: 提出了一种基于矛盾结构效应的情感表达模型，作为自然语言的补充形式，通过蒙太奇操作产生结构效应。


<details>
  <summary>Details</summary>
Motivation: 为情感表达提供一种独立于自然语言的替代形式，作为情感状态的代理或窗口。

Method: 建立矛盾结构效应模型，通过蒙太奇操作重叠多个矛盾结构效应，引入强度概念作为模型要素。

Result: 构建了一个通用的理论框架——系统间词语导入，并通过教育升级的例子演示了结构效应的产生过程。

Conclusion: 矛盾结构效应模型能够有效表达情感状态，蒙太奇操作和强度概念的引入增强了情感表达的动态性和层次性。

Abstract: In expressing emotions, as an expression form separate from natural language, we propose an alternative form that complements natural language, acting as a proxy or window for emotional states. First, we set up an expression form "Effect of Contradictory Structure." "Effect of Contradictory Structure" is not static but dynamic. Effect in "Effect of Contradictory Structure" is unpleasant or pleasant, and the orientation to avoid that unpleasantness is considered pseudo-expression of will. Second, "Effect of Contradictory Structure" can be overlapped with each other. This overlapping operation is called "montage." A broader "Structure" that includes related "Effect of Contradictory Structure" and "Effect of Structure" are set up. Montage produces "Effect of Structure". In montage, it is necessary to set something like "strength," so we adopted Deleuze and Deleuze/Guattari's word "intensity" and set it as an element of our model. We set up a general theoretical framework - Word Import Between Systems (Models) and justified the import of "intensity" through Austin's use of the word "force." "Effect of Structure" process is demonstrated using the example of proceeding to the next level of education.

</details>


### [65] [GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning](https://arxiv.org/abs/2511.19078)
*Yutong Li,Yitian Zhou,Xudong Wang,GuoChen,Caiyan Qin*

Main category: cs.CL

TL;DR: GraphMind是一个基于动态图的框架，将图神经网络与LLMs结合，用于多步推理中的定理选择和中间结论生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏明确动态机制来表示和演化中间推理状态，限制了上下文感知的定理选择和迭代结论生成能力。

Method: 将推理过程建模为异构演化图，节点表示条件、定理和结论，边捕获逻辑依赖关系，使用GNN编码当前推理状态并通过语义匹配进行定理选择。

Result: 在多个QA数据集上的实验表明，GraphMind方法实现了持续的性能提升，在多步推理中显著优于现有基线方法。

Conclusion: GraphMind框架为多步推理提供了上下文感知、可解释和结构化的推理能力，验证了该方法的有效性和泛化性。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.

</details>


### [66] [A Multi-Agent LLM Framework for Multi-Domain Low-Resource In-Context NER via Knowledge Retrieval, Disambiguation and Reflective Analysis](https://arxiv.org/abs/2511.19083)
*Wenxuan Mu,Jinzhong Ning,Di Zhao,Yijia Zhang*

Main category: cs.CL

TL;DR: KDR-Agent是一个用于多领域低资源命名实体识别的多智能体框架，通过知识检索、消歧和反思分析解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于上下文学习的命名实体识别方法的三个关键局限：依赖动态检索标注数据、对未见领域泛化能力有限、无法整合外部知识或解决实体歧义。

Method: 提出KDR-Agent多智能体框架，使用自然语言类型定义和静态实体级对比演示，通过中央规划器协调专门智能体进行知识检索、消歧推理和结构化自评估。

Result: 在5个领域的10个数据集上实验表明，KDR-Agent在多个LLM骨干网络上显著优于现有的零样本和少样本上下文学习基线方法。

Conclusion: KDR-Agent通过整合知识检索、消歧和反思分析，有效提升了低资源场景下命名实体识别的性能，特别是在跨领域泛化方面表现优异。

Abstract: In-context learning (ICL) with large language models (LLMs) has emerged as a promising paradigm for named entity recognition (NER) in low-resource scenarios. However, existing ICL-based NER methods suffer from three key limitations: (1) reliance on dynamic retrieval of annotated examples, which is problematic when annotated data is scarce; (2) limited generalization to unseen domains due to the LLM's insufficient internal domain knowledge; and (3) failure to incorporate external knowledge or resolve entity ambiguities. To address these challenges, we propose KDR-Agent, a novel multi-agent framework for multi-domain low-resource in-context NER that integrates Knowledge retrieval, Disambiguation, and Reflective analysis. KDR-Agent leverages natural-language type definitions and a static set of entity-level contrastive demonstrations to reduce dependency on large annotated corpora. A central planner coordinates specialized agents to (i) retrieve factual knowledge from Wikipedia for domain-specific mentions, (ii) resolve ambiguous entities via contextualized reasoning, and (iii) reflect on and correct model predictions through structured self-assessment. Experiments across ten datasets from five domains demonstrate that KDR-Agent significantly outperforms existing zero-shot and few-shot ICL baselines across multiple LLM backbones. The code and data can be found at https://github.com/MWXGOD/KDR-Agent.

</details>


### [67] [DeCoRL: Decoupling Reasoning Chains via Parallel Sub-Step Generation and Cascaded Reinforcement for Interpretable and Scalable RLHF](https://arxiv.org/abs/2511.19097)
*Ziyuan Gao,Di Liang,Xianjie Wu,Philippe Morel,Minlong Peng*

Main category: cs.CL

TL;DR: DeCoRL是一个新颖的强化学习框架，通过将推理过程从顺序处理转变为协作式模块化编排，解决了现有方法在奖励信号不明确和时间复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在思维链推理中存在两个关键限制：1) 作为黑盒提供无差别的奖励信号，难以识别单个步骤的贡献和诊断错误；2) 顺序解码具有O(n)时间复杂度，使得复杂推理任务的实时部署不切实际。

Method: DeCoRL训练轻量级专用模型来并行生成推理子步骤，通过并行处理消除顺序瓶颈。框架设计模块化奖励函数来独立评分每个子步骤，并使用级联DRPO优化来协调这些奖励同时保持步骤间依赖关系。

Result: 在RM-Bench、RMB和RewardBench上的综合评估显示，DeCoRL实现了最先进的结果，优于包括大规模模型在内的现有方法。推理速度提高3.8倍，同时保持卓越的解决方案质量，通过显式奖励归因可解释性提高22.7%。

Conclusion: DeCoRL通过3.8倍推理加速、22.7%可解释性提升、72.4%能耗降低和68%吞吐量增加，使复杂推理系统的实时部署成为现实。

Abstract: Existing reinforcement learning methods for Chain-of-Thought reasoning suffer from two critical limitations. First, they operate as monolithic black boxes that provide undifferentiated reward signals, obscuring individual step contributions and hindering error diagnosis. Second, sequential decoding has O(n) time complexity. This makes real-time deployment impractical for complex reasoning tasks. We present DeCoRL (Decoupled Reasoning Chains via Coordinated Reinforcement Learning), a novel framework that transforms reasoning from sequential processing into collaborative modular orchestration. DeCoRL trains lightweight specialized models to generate reasoning sub-steps concurrently, eliminating sequential bottlenecks through parallel processing. To enable precise error attribution, the framework designs modular reward functions that score each sub-step independently. Cascaded DRPO optimization then coordinates these rewards while preserving inter-step dependencies. Comprehensive evaluation demonstrates state-of-the-art results across RM-Bench, RMB, and RewardBench, outperforming existing methods including large-scale models. DeCoRL delivers 3.8 times faster inference while maintaining superior solution quality and offers a 22.7\% improvement in interpretability through explicit reward attribution. These advancements, combined with a 72.4\% reduction in energy consumption and a 68\% increase in throughput, make real-time deployment of complex reasoning systems a reality.

</details>


### [68] [A symbolic Perl algorithm for the unification of Nahuatl word spellings](https://arxiv.org/abs/2511.19118)
*Juan-José Guzmán-Landa,Jesús Vázquez-Osorio,Juan-Manuel Torres-Moreno,Ligia Quintana Torres,Miguel Figueroa-Saavedra,Martha-Lorena Avendaño-Garrido,Graham Ranger,Patricia Velázquez-Morales,Gerardo Eugenio Sierra Martínez*

Main category: cs.CL

TL;DR: 提出了一种基于符号正则表达式的纳瓦特尔文本自动正字法统一模型，使用π-yalli语料库进行训练，并通过人工评估协议验证统一句子的语义质量。


<details>
  <summary>Details</summary>
Motivation: 解决纳瓦特尔文本在不同正字法系统下的统一问题，便于文本处理和分析。

Method: 基于先前分析纳瓦特尔句子的算法，使用符号正则表达式实现语言规则，构建自动统一算法。

Result: 在句子语义任务中测试，获得了评估者对人工统一句子大多数期望特征的积极反馈。

Conclusion: 该自动统一算法在纳瓦特尔文本正字法统一方面取得了令人鼓舞的结果。

Abstract: In this paper, we describe a symbolic model for the automatic orthographic unification of Nawatl text documents. Our model is based on algorithms that we have previously used to analyze sentences in Nawatl, and on the corpus called $π$-yalli, consisting of texts in several Nawatl orthographies. Our automatic unification algorithm implements linguistic rules in symbolic regular expressions. We also present a manual evaluation protocol that we have proposed and implemented to assess the quality of the unified sentences generated by our algorithm, by testing in a sentence semantic task. We have obtained encouraging results from the evaluators for most of the desired features of our artificially unified sentences

</details>


### [69] [On the Optimality of Discrete Object Naming: a Kinship Case Study](https://arxiv.org/abs/2511.19120)
*Phong Le,Mees Lindeman,Raquel G. Alhama*

Main category: cs.CL

TL;DR: 本文提出了一个信息论框架来分析自然语言命名系统，证明了当听者的解码器等同于说话者的贝叶斯解码器时，才能实现信息丰富性和复杂性的最优权衡。


<details>
  <summary>Details</summary>
Motivation: 解决先前研究的两个简化假设：(i) 最优听者假设和(ii) 跨语言通用交际需求假设，以更真实地建模命名系统。

Method: 引入离散对象命名系统的信息论框架，采用涌现通信中的指称游戏设置，聚焦亲属关系语义领域。

Result: 理论证明最优权衡是可实现的，且在学习通信系统中经验性地涌现出来。

Conclusion: 当听者解码器与说话者贝叶斯解码器等价时，命名系统能够在信息丰富性和复杂性之间达到最优平衡，这一理论结果在实际学习系统中得到了验证。

Abstract: The structure of naming systems in natural languages hinges on a trade-off between high informativeness and low complexity. Prior work capitalizes on information theory to formalize these notions; however, these studies generally rely on two simplifications: (i) optimal listeners, and (ii) universal communicative need across languages. Here, we address these limitations by introducing an information-theoretic framework for discrete object naming systems, and we use it to prove that an optimal trade-off is achievable if and only if the listener's decoder is equivalent to the Bayesian decoder of the speaker. Adopting a referential game setup from emergent communication, and focusing on the semantic domain of kinship, we show that our notion of optimality is not only theoretically achievable but also emerges empirically in learned communication systems.

</details>


### [70] [Emotion-Enhanced Multi-Task Learning with LLMs for Aspect Category Sentiment Analysis](https://arxiv.org/abs/2511.19122)
*Yaping Chai,Haoran Xie,Joe S. Qin*

Main category: cs.CL

TL;DR: 提出了一种情感增强的多任务ACSA框架，联合学习情感极性和基于Ekman六种基本情绪的分类特定情绪，通过VAD维度框架的情绪精炼机制确保生成情绪的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有ACSA方法主要关注情感极性，忽视了塑造情感表达的基础情绪维度，这限制了模型捕捉针对特定方面类别的细粒度情感信号的能力。

Method: 利用LLMs的生成能力，为每个方面类别生成情感描述；引入基于VAD维度框架的情绪精炼机制，将LLM预测的情绪投影到VAD空间，对不一致的情绪进行重新标注。

Result: 实验结果表明，该方法在所有基准数据集上都显著优于强基线模型。

Conclusion: 将情感维度整合到ACSA中是有效的，能够丰富情感表示并提高性能。

Abstract: Aspect category sentiment analysis (ACSA) has achieved remarkable progress with large language models (LLMs), yet existing approaches primarily emphasize sentiment polarity while overlooking the underlying emotional dimensions that shape sentiment expressions. This limitation hinders the model's ability to capture fine-grained affective signals toward specific aspect categories. To address this limitation, we introduce a novel emotion-enhanced multi-task ACSA framework that jointly learns sentiment polarity and category-specific emotions grounded in Ekman's six basic emotions. Leveraging the generative capabilities of LLMs, our approach enables the model to produce emotional descriptions for each aspect category, thereby enriching sentiment representations with affective expressions. Furthermore, to ensure the accuracy and consistency of the generated emotions, we introduce an emotion refinement mechanism based on the Valence-Arousal-Dominance (VAD) dimensional framework. Specifically, emotions predicted by the LLM are projected onto a VAD space, and those inconsistent with their corresponding VAD coordinates are re-annotated using a structured LLM-based refinement strategy. Experimental results demonstrate that our approach significantly outperforms strong baselines on all benchmark datasets. This underlines the effectiveness of integrating affective dimensions into ACSA.

</details>


### [71] [Eliciting Chain-of-Thought in Base LLMs via Gradient-Based Representation Optimization](https://arxiv.org/abs/2511.19131)
*Zijian Wang,Yanxiang Ma,Chang Xu*

Main category: cs.CL

TL;DR: 提出了一种基于概率条件生成的新方法，通过优化隐藏状态来激发基础大语言模型的思维链推理能力，在数学、常识和逻辑推理任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基础大语言模型在预训练时缺乏专门的推理训练，导致推理能力不足。现有隐藏状态操纵方法存在刚性约束问题，容易导致分布偏移和文本质量下降。

Method: 将挑战重新表述为带平衡似然和先验正则化的优化问题，在概率条件生成框架下引导隐藏状态朝向推理轨迹，同时保持语言连贯性。

Result: 在数学、常识和逻辑推理基准测试中，该方法一致优于现有的操纵方法。

Conclusion: 该方法为增强基础大语言模型的推理能力提供了一个理论上有原则且有效的解决方案。

Abstract: Chain-of-Thought (CoT) reasoning is a critical capability for large language models (LLMs), enabling them to tackle com- plex multi-step tasks. While base LLMs, pre-trained on general text corpora, often struggle with reasoning due to a lack of specialized training, recent studies reveal their latent reason- ing potential tied to hidden states. However, existing hidden state manipulation methods, such as linear activation steering, suffer from limitations due to their rigid and unconstrained nature, often leading to distribution shifts and degraded text quality. In this work, we propose a novel approach for elic- iting CoT reasoning from base LLMs through hidden state manipulation grounded in probabilistic conditional generation. By reformulating the challenge as an optimization problem with a balanced likelihood and prior regularization framework, our method guides hidden states toward reasoning-oriented trajectories while preserving linguistic coherence. Extensive evaluations across mathematical, commonsense, and logical reasoning benchmarks demonstrate that our approach con- sistently outperforms existing steering methods, offering a theoretically principled and effective solution for enhancing reasoning capabilities in base LLMs.

</details>


### [72] [Representational Stability of Truth in Large Language Models](https://arxiv.org/abs/2511.19166)
*Samantha Dies,Courtney Maynard,Germans Savcisens,Tina Eliassi-Rad*

Main category: cs.CL

TL;DR: 本文提出了表示稳定性概念，评估LLM在真实、虚假和中性陈述之间的内部概率表示的鲁棒性，发现表示稳定性更多源于认知熟悉度而非语言形式。


<details>
  <summary>Details</summary>
Motivation: 研究LLM如何在其内部概率表示中稳定地区分真实、虚假和中性内容，以及这种表示对真理操作定义扰动的鲁棒性。

Method: 通过在线性探针上训练LLM激活来分离真实与非真实陈述，并在受控标签变化下测量学习决策边界的变化，使用16个开源模型和3个事实领域进行比较。

Result: 陌生中性陈述（关于训练数据中不存在的实体的断言）导致最大的边界偏移，在脆弱领域（如词汇定义）产生高达40%的真实判断翻转；而熟悉虚构陈述保持更一致的聚类，变化较小（≤8.2%）。

Conclusion: 表示稳定性更多源于认知熟悉度而非语言形式，该方法为审计和训练LLM提供了诊断工具，以在语义不确定性下保持连贯的真理分配。

Abstract: Large language models (LLMs) are widely used for factual tasks such as "What treats asthma?" or "What is the capital of Latvia?". However, it remains unclear how stably LLMs encode distinctions between true, false, and neither-true-nor-false content in their internal probabilistic representations. We introduce representational stability as the robustness of an LLM's veracity representations to perturbations in the operational definition of truth. We assess representational stability by (i) training a linear probe on an LLM's activations to separate true from not-true statements and (ii) measuring how its learned decision boundary shifts under controlled label changes. Using activations from sixteen open-source models and three factual domains, we compare two types of neither statements. The first are fact-like assertions about entities we believe to be absent from any training data. We call these unfamiliar neither statements. The second are nonfactual claims drawn from well-known fictional contexts. We call these familiar neither statements. The unfamiliar statements induce the largest boundary shifts, producing up to $40\%$ flipped truth judgements in fragile domains (such as word definitions), while familiar fictional statements remain more coherently clustered and yield smaller changes ($\leq 8.2\%$). These results suggest that representational stability stems more from epistemic familiarity than from linguistic form. More broadly, our approach provides a diagnostic for auditing and training LLMs to preserve coherent truth assignments under semantic uncertainty, rather than optimizing for output accuracy alone.

</details>


### [73] [In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations](https://arxiv.org/abs/2511.19232)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: 该研究探索了transformer模型如何检测语义异常句子，发现模型在中间层才开始有效识别语义不合理性，这与人类语言处理中先语法后语义的模式相似。


<details>
  <summary>Details</summary>
Motivation: 探索transformer模型在何处以及如何检测句子语义异常，以理解模型的语言处理机制并与人类认知过程进行对比。

Method: 使用phi-2因果语言模型，分析不同层级的隐藏状态，采用线性探测器和维度分析两种方法来研究语义违规的编码方式。

Result: 线性探测器在模型底层难以区分合理与不合理结尾，但在中间层准确率急剧上升；语义违规编码先扩展表示子空间，后经过瓶颈层压缩，显示从探索到快速整合的转变。

Conclusion: transformer检测语义异常的模式与人类心理语言学发现一致，即语义异常检测发生在语法解析之后，支持模型与人类语言处理的相似性。

Abstract: How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.

</details>


### [74] [MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset](https://arxiv.org/abs/2511.19317)
*Md. Tanzim Ferdous,Naeem Ahsan Chowdhury,Prithwiraj Bhattacharjee*

Main category: cs.CL

TL;DR: 开发了一个包含54,000多篇孟加拉语文章和摘要的新数据集，涵盖多个领域和写作风格，为孟加拉语自然语言处理提供了基准资源。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注新闻文章，而现实世界中的孟加拉语文本具有多样性，需要能够适应不同写作风格的摘要系统来减轻信息过载。

Method: 从多个来源收集孟加拉语文章和摘要，包括博客和报纸，并使用LSTM、BanglaT5-small和MTS-small等深度学习模型进行训练和评估。

Result: 数据集展示了作为孟加拉语自然语言处理未来研究基准的潜力，为构建稳健的摘要系统提供了坚实基础。

Conclusion: 该数据集有助于扩展低资源语言的NLP资源，并为开发适应现实世界文本多样性的摘要系统提供了重要支持。

Abstract: This study developed a new Bangla abstractive summarization dataset to generate concise summaries of Bangla articles from diverse sources. Most existing studies in this field have concentrated on news articles, where journalists usually follow a fixed writing style. While such approaches are effective in limited contexts, they often fail to adapt to the varied nature of real-world Bangla texts. In today's digital era, a massive amount of Bangla content is continuously produced across blogs, newspapers, and social media. This creates a pressing need for summarization systems that can reduce information overload and help readers understand content more quickly. To address this challenge, we developed a dataset of over 54,000 Bangla articles and summaries collected from multiple sources, including blogs such as Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike single-domain resources, our dataset spans multiple domains and writing styles. It offers greater adaptability and practical relevance. To establish strong baselines, we trained and evaluated this dataset using several deep learning and transfer learning models, including LSTM, BanglaT5-small, and MTS-small. The results highlight its potential as a benchmark for future research in Bangla natural language processing. This dataset provides a solid foundation for building robust summarization systems and helps expand NLP resources for low-resource languages.

</details>


### [75] [Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces](https://arxiv.org/abs/2511.19333)
*Shaltiel Shmidman,Asher Fredman,Oleg Sudakov,Meriem Bendris*

Main category: cs.CL

TL;DR: 比较DeepSeek-R1和gpt-oss两种大型语言模型生成的推理轨迹对中等规模LLM数学问题解决能力的影响，评估准确性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 利用前沿大模型生成的推理轨迹作为高质量监督数据，训练中小型语言模型获得推理能力，避免昂贵的人工标注成本。

Method: 对中等规模LLM进行后训练，使用DeepSeek-R1和gpt-oss生成的两种推理轨迹数据，比较其在数学问题上的表现。

Result: 评估两种推理轨迹在准确性和推理效率方面的影响差异。

Conclusion: 比较不同大模型生成的推理轨迹对中小模型推理能力训练的效果，为高效推理能力迁移提供参考。

Abstract: Test-time scaling, which leverages additional computation during inference to improve model accuracy, has enabled a new class of Large Language Models (LLMs) that are able to reason through complex problems by understanding the goal, turning this goal into a plan, working through intermediate steps, and checking their own work before answering . Frontier large language models with reasoning capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same procedure when solving complex problems by generating intermediate reasoning traces before giving the final answer. Today, these models are being increasingly used to generate reasoning traces that serve as high-quality supervised data for post-training of small and medium-sized language models to teach reasoning capabilities without requiring expensive human curation. In this work, we compare the performance of medium-sized LLMs on Math problems after post-training on two kinds of reasoning traces. We compare the impact of reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy and inference efficiency.

</details>


### [76] [DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research](https://arxiv.org/abs/2511.19399)
*Rulin Shao,Akari Asai,Shannon Zejiang Shen,Hamish Ivison,Varsha Kishore,Jingming Zhuo,Xinran Zhao,Molly Park,Samuel G. Finlayson,David Sontag,Tyler Murray,Sewon Min,Pradeep Dasigi,Luca Soldaini,Faeze Brahman,Wen-tau Yih,Tongshuang Wu,Luke Zettlemoyer,Yoon Kim,Hannaneh Hajishirzi,Pang Wei Koh*

Main category: cs.CL

TL;DR: 提出了RLER（强化学习与演进式评分标准）方法，开发了Deep Research Tulu模型，在长格式深度研究任务上超越现有开源模型，性能媲美专有系统。


<details>
  <summary>Details</summary>
Motivation: 现有开源深度研究模型主要在可验证的短格式QA任务上训练，无法扩展到现实的长格式研究任务，需要新的训练方法。

Method: 使用RLER方法构建和维护与策略模型共同演进的评分标准，让评分标准能够整合模型新探索的信息并提供区分性的在线反馈。

Result: 开发的DR Tulu-8B模型在科学、医疗和通用领域的四个长格式深度研究基准测试中，显著优于现有开源模型，性能达到或超过专有系统。

Conclusion: RLER方法有效解决了长格式深度研究的训练挑战，DR Tulu模型展示了开源深度研究系统的可行性，并发布了相关数据、模型和代码。

Abstract: Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.

</details>


### [77] [Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration](https://arxiv.org/abs/2511.19417)
*James Y. Huang,Sheng Zhang,Qianchu Liu,Guanghui Qin,Tinghui Zhu,Tristan Naumann,Muhao Chen,Hoifung Poon*

Main category: cs.CL

TL;DR: BeMyEyes是一个模块化的多智能体框架，通过让高效的视觉语言模型作为感知器与强大的大语言模型作为推理器进行对话协作，扩展LLMs的多模态推理能力，无需训练大规模多模态模型。


<details>
  <summary>Details</summary>
Motivation: 扩展LLMs到多模态推理通常需要开发成本高昂的大规模视觉语言模型，而较小的VLMs虽然高效但缺乏前沿LLMs的广泛知识和推理能力。

Method: 提出模块化多智能体框架，通过对话协调感知器和推理器的协作，并引入数据合成和监督微调管道来训练感知器与推理器有效协作。

Result: 实验表明，该框架为LLMs解锁了多模态推理能力，使用轻量级开源解决方案（DeepSeek-R1 + Qwen2.5-VL-7B）在知识密集型多模态任务上超越了GPT-4o等大规模专有VLMs。

Conclusion: BeMyEyes展示了多智能体方法在构建未来多模态推理系统中的有效性、模块化和可扩展性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [78] [AUTOSAR AP and ROS 2 Collaboration Framework](https://arxiv.org/abs/2511.17540)
*Ryudai Iwakami,Bo Peng,Hiroyuki Hanyu,Tasuku Ishigooka,Takuya Azumi*

Main category: cs.RO

TL;DR: 提出一个连接AUTOSAR AP和ROS 2的协作框架，通过DDS协议桥接通信差异，实现两个平台的无缝交互。


<details>
  <summary>Details</summary>
Motivation: AUTOSAR AP受许可限制难以用于研究，而ROS 2主要在研究中使用，导致研发平台差异阻碍商业化进程。

Method: 使用DDS协议构建桥接转换器，解决AUTOSAR AP的SOME/IP与ROS 2之间的通信协议差异，并自动生成配置文件。

Result: 通过实证分析验证了桥接转换器的功能和性能，展示了其在转换时间和与ROS 2工具集成方面的效率。

Conclusion: 提出的协作框架有效连接了AUTOSAR AP和ROS 2，促进了研发平台间的无缝协作，加速了商业化进程。

Abstract: The field of autonomous vehicle research is advancing rapidly, necessitating platforms that meet real-time performance, safety, and security requirements for practical deployment. AUTOSAR Adaptive Platform (AUTOSAR AP) is widely adopted in development to meet these criteria; however, licensing constraints and tool implementation challenges limit its use in research. Conversely, Robot Operating System 2 (ROS 2) is predominantly used in research within the autonomous driving domain, leading to a disparity between research and development platforms that hinders swift commercialization. This paper proposes a collaboration framework that enables AUTOSAR AP and ROS 2 to communicate with each other using a Data Distribution Service for Real-Time Systems (DDS). In contrast, AUTOSAR AP uses Scalable service-Oriented Middleware over IP (SOME/IP) for communication. The proposed framework bridges these protocol differences, ensuring seamless interaction between the two platforms. We validate the functionality and performance of our bridge converter through empirical analysis, demonstrating its efficiency in conversion time and ease of integration with ROS 2 tools. Furthermore, the availability of the proposed collaboration framework is improved by automatically generating a configuration file for the proposed bridge converter.

</details>


### [79] [Implicit Neural Field-Based Process Planning for Multi-Axis Manufacturing: Direct Control over Collision Avoidance and Toolpath Geometry](https://arxiv.org/abs/2511.17578)
*Neelotpal Dutta,Tianyu Zhang,Tao Liu,Yongxue Chen,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 提出了一种基于隐式神经场的多轴制造工艺规划框架，将层生成和刀具路径设计集成在单个可微分管道中，实现直接碰撞避免和联合优化。


<details>
  <summary>Details</summary>
Motivation: 现有基于弯曲层的多轴制造工艺规划方法只能间接处理碰撞问题，并在后处理步骤中生成刀具路径，导致在优化过程中无法控制刀具路径几何形状。

Method: 使用正弦激活神经网络将层和刀具路径表示为隐式场，构建可微分管道，可直接评估任意空间点的场值和导数，实现显式碰撞避免和联合优化。

Result: 该方法在增材制造和减材制造示例中得到验证，展示了其通用性和有效性，能够控制奇点行为和拓扑转换。

Conclusion: 提出的隐式神经场框架克服了现有方法的局限性，为多轴制造提供了更直接和可控的工艺规划解决方案。

Abstract: Existing curved-layer-based process planning methods for multi-axis manufacturing address collisions only indirectly and generate toolpaths in a post-processing step, leaving toolpath geometry uncontrolled during optimization. We present an implicit neural field-based framework for multi-axis process planning that overcomes these limitations by embedding both layer generation and toolpath design within a single differentiable pipeline. Using sinusoidally activated neural networks to represent layers and toolpaths as implicit fields, our method enables direct evaluation of field values and derivatives at any spatial point, thereby allowing explicit collision avoidance and joint optimization of manufacturing layers and toolpaths. We further investigate how network hyperparameters and objective definitions influence singularity behavior and topology transitions, offering built-in mechanisms for regularization and stability control. The proposed approach is demonstrated on examples in both additive and subtractive manufacturing, validating its generality and effectiveness.

</details>


### [80] [Translating Cultural Choreography from Humanoid Forms to Robotic Arm](https://arxiv.org/abs/2511.17603)
*Chelsea-Xi Chen,Zhe Zhang,Aven-Le Zhou*

Main category: cs.RO

TL;DR: 本研究开发了ROPERA系统，通过符号姿态转移和关节空间兼容符号来保持文化语义保真度，并在六自由度机械臂上实现昆曲《牡丹亭》的舞蹈动作重现。


<details>
  <summary>Details</summary>
Motivation: 机器人手臂编舞通常只重现轨迹而缺乏文化语义，需要开发能够保持文化语义保真度且跨形态可移植的方法。

Method: 实现ROPERA三阶段流程：编码文化编码姿态、组合符号序列、解码为伺服命令。使用昆曲《牡丹亭》场景作为评估材料，包括基于语料库的姿态选择、符号记谱、直接关节角度执行以及带有光绘和服装色彩的可视化层。

Result: 结果显示可重现的执行效果，具有预期的时间安排，专家和观众报告了文化可读性。

Conclusion: 该研究指向非人类中心的文化保护和可移植的创作工作流程。未来工作将设计舞蹈启发的过渡轮廓，将符号扩展到具有触觉、音乐和空间线索的移动，并测试跨平台的可移植性。

Abstract: Robotic arm choreography often reproduces trajectories while missing cultural semantics. This study examines whether symbolic posture transfer with joint space compatible notation can preserve semantic fidelity on a six-degree-of-freedom arm and remain portable across morphologies. We implement ROPERA, a three-stage pipeline for encoding culturally codified postures, composing symbolic sequences, and decoding to servo commands. A scene from Kunqu opera, \textit{The Peony Pavilion}, serves as the material for evaluation. The procedure includes corpus-based posture selection, symbolic scoring, direct joint angle execution, and a visual layer with light painting and costume-informed colors. Results indicate reproducible execution with intended timing and cultural legibility reported by experts and audiences. The study points to non-anthropocentric cultural preservation and portable authoring workflows. Future work will design dance-informed transition profiles, extend the notation to locomotion with haptic, musical, and spatial cues, and test portability across platforms.

</details>


### [81] [Robot joint characterisation and control using a magneto-optical rotary encoder](https://arxiv.org/abs/2511.17608)
*Yunlong Guo,John Canning,Zenon Chaczko,Gang-Ding Peng*

Main category: cs.RO

TL;DR: 提出了一种用于机器人旋转关节表征的紧凑型磁光旋转编码器，通过磁场诱导光学衰减实现360°连续旋转跟踪，具有低成本和高可靠性。


<details>
  <summary>Details</summary>
Motivation: 为机器人旋转关节提供一种低成本、可靠的替代传统旋转编码器的解决方案，同时保持竞争性能。

Method: 采用双通配置，利用旋转非均匀磁体在光学环行器反射模式下产生磁场诱导的光学衰减效应。

Result: 编码器能够跟踪360°连续旋转，旋转扫描速率从135°/s到370°/s，角分辨率为0.3°。

Conclusion: 该系统为传统机器人旋转编码器提供了一个低成本且可靠的替代方案，同时保持了竞争性的性能表现。

Abstract: A robust and compact magneto-optical rotary encoder for the characterisation of robotic rotary joints is demonstrated. The system employs magnetic field-induced optical attenuation in a double-pass configuration using rotating nonuniform magnets around an optical circulator operating in reflection. The encoder tracks continuous 360° rotation with rotation sweep rates from ν = 135 °/s to ν = 370 °/s, and an angular resolution of Δθ = 0.3°. This offers a low-cost and reliable alternative to conventional robot rotation encoders while maintaining competitive performance.

</details>


### [82] [Vision-Guided Optic Flow Navigation for Small Lunar Missions](https://arxiv.org/abs/2511.17720)
*Sean Cowan,Pietro Fanti,Leon B. S. Williams,Chit Hong Yam,Kaneyasu Asakuma,Yuichiro Nada,Dario Izzo*

Main category: cs.RO

TL;DR: 提出一种基于光流和测距仪深度估计的运动场反演框架，用于月球着陆过程中的自主导航，能够在有限计算资源下实现实时、准确的姿态估计。


<details>
  <summary>Details</summary>
Motivation: 解决私人月球任务在质量、功耗和计算资源严格限制下实现鲁棒自主导航的挑战，特别是针对小型月球着陆器的需求。

Method: 扩展经典光流公式，结合针对月球/行星接近、下降和着陆几何形状定制的深度建模策略，使用激光测距仪参数化的平面和球形地形近似，通过最小二乘框架进行运动场反演。

Result: 在月球南极复杂地形上的测试显示，从接近到着陆阶段都能准确估计速度，复杂地形误差低于10%，典型地形误差约为1%，性能适合实时应用。

Conclusion: 该框架有望为小型月球任务提供鲁棒、轻量级的机载导航解决方案。

Abstract: Private lunar missions are faced with the challenge of robust autonomous navigation while operating under stringent constraints on mass, power, and computational resources. This work proposes a motion-field inversion framework that uses optical flow and rangefinder-based depth estimation as a lightweight CPU-based solution for egomotion estimation during lunar descent. We extend classical optical flow formulations by integrating them with depth modeling strategies tailored to the geometry for lunar/planetary approach, descent, and landing, specifically, planar and spherical terrain approximations parameterized by a laser rangefinder. Motion field inversion is performed through a least-squares framework, using sparse optical flow features extracted via the pyramidal Lucas-Kanade algorithm. We verify our approach using synthetically generated lunar images over the challenging terrain of the lunar south pole, using CPU budgets compatible with small lunar landers. The results demonstrate accurate velocity estimation from approach to landing, with sub-10% error for complex terrain and on the order of 1% for more typical terrain, as well as performances suitable for real-time applications. This framework shows promise for enabling robust, lightweight on-board navigation for small lunar missions.

</details>


### [83] [LEARN: Learning End-to-End Aerial Resource-Constrained Multi-Robot Navigation](https://arxiv.org/abs/2511.17765)
*Darren Chiu,Zhehui Huang,Ruohai Ge,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: LEARN是一个轻量级的两阶段安全引导强化学习框架，用于多无人机在复杂空间中的导航，结合低分辨率ToF传感器和紧凑的注意力RL策略，在资源受限的纳米无人机上实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 纳米无人机团队具有高敏捷性，但受限于机载传感、通信和计算能力，现有基于高分辨率视觉或计算密集型规划器的方法不适用于这些平台。

Method: 采用两阶段安全引导强化学习框架，结合低分辨率飞行时间传感器、简单运动规划器和紧凑的注意力机制RL策略。

Result: 在仿真中性能优于两种最先进规划器10%，资源消耗显著减少；在6架Crazyflie四旋翼上实现全机载飞行，在室内外环境中速度达2.0m/s，可穿越0.2m间隙。

Conclusion: LEARN框架证明了在资源受限的纳米无人机平台上实现高效多机导航的可行性，为小型无人机自主导航提供了实用解决方案。

Abstract: Nano-UAV teams offer great agility yet face severe navigation challenges due to constrained onboard sensing, communication, and computation. Existing approaches rely on high-resolution vision or compute-intensive planners, rendering them infeasible for these platforms. We introduce LEARN, a lightweight, two-stage safety-guided reinforcement learning (RL) framework for multi-UAV navigation in cluttered spaces. Our system combines low-resolution Time-of-Flight (ToF) sensors and a simple motion planner with a compact, attention-based RL policy. In simulation, LEARN outperforms two state-of-the-art planners by $10\%$ while using substantially fewer resources. We demonstrate LEARN's viability on six Crazyflie quadrotors, achieving fully onboard flight in diverse indoor and outdoor environments at speeds up to $2.0 m/s$ and traversing $0.2 m$ gaps.

</details>


### [84] [Learning Diffusion Policies for Robotic Manipulation of Timber Joinery under Fabrication Uncertainty](https://arxiv.org/abs/2511.17774)
*Salma Mozaffari,Daniel Ruan,William van den Bogert,Nima Fazeli,Sigrid Adriaenssens,Arash Adel*

Main category: cs.RO

TL;DR: 该论文研究了扩散策略学习在建筑尺度接触敏感机器人装配中的性能和鲁棒性，以木工榫卯接头为案例，在存在制造不确定性的情况下实现了75%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 建筑中的制造误差和材料缺陷等不确定性给接触密集的机器人操作带来了重大挑战，阻碍了精确和稳健的装配。

Method: 采用两阶段研究：首先评估策略性能和适用性，其次评估处理制造不确定性的鲁棒性，通过随机扰动榫眼位置来模拟不确定性。

Result: 最佳策略在高达10毫米的扰动下实现了75%的总平均成功率，其中无扰动情况下达到100%成功率。

Conclusion: 结果表明感觉运动扩散策略有潜力推广到建筑和制造业中各种复杂、接触密集的装配任务，推动不确定性下的机器人建筑发展，促进更安全、更高效的建筑实践。

Abstract: Construction uncertainties such as fabrication inaccuracies and material imperfections pose a significant challenge to contact-rich robotic manipulation by hindering precise and robust assembly. In this paper, we explore the performance and robustness of diffusion policy learning as a promising solution for contact-sensitive robotic assembly at construction scale, using timber mortise and tenon joints as a case study. A two-phase study is conducted: first, to evaluate policy performance and applicability; second, to assess robustness in handling fabrication uncertainties simulated as randomized perturbations to the mortise position. The best-performing policy achieved a total average success rate of 75% with perturbations up to 10 mm, including 100% success in unperturbed cases. The results demonstrate the potential of sensory-motor diffusion policies to generalize to a wide range of complex, contact-rich assembly tasks across construction and manufacturing, advancing robotic construction under uncertainty and contributing to safer, more efficient building practices.

</details>


### [85] [See, Plan, Cut: MPC-Based Autonomous Volumetric Robotic Laser Surgery with OCT Guidance](https://arxiv.org/abs/2511.17777)
*Ravi Prakash,Vincent Y. Wang,Arpit Mishra,Devi Yuliarti,Pei Zhong,Ryan P. McNabb,Patrick J. Codd,Leila J. Bridgeman*

Main category: cs.RO

TL;DR: RATS是一个智能光学机械平台，集成OCT引导和手术激光，用于自主软组织体积切除，通过多级校准和模型预测控制实现高精度手术。


<details>
  <summary>Details</summary>
Motivation: 现有机器人激光系统缺乏体积规划和术中反馈，需要开发能够进行自主体积软组织切除的智能手术平台。

Method: 集成RGB-D成像、OCT和光纤耦合手术激光，采用多级校准管道，使用超高斯激光-组织相互作用模型，并基于采样的模型预测控制框架直接在OCT体素数据上操作。

Result: OCT到激光校准精度达0.161±0.031mm，激光-组织相互作用模型平均RMSE为0.231±0.121mm，模型预测控制实现0.842mm RMSE，相比前馈执行提高IoU一致性64.8%。

Conclusion: RATS能够检测亚表面结构并修改规划目标以保护这些结构，展示了临床可行性。

Abstract: Robotic laser systems offer the potential for sub-millimeter, non-contact, high-precision tissue resection, yet existing platforms lack volumetric planning and intraoperative feedback. We present RATS (Robot-Assisted Tissue Surgery), an intelligent opto-mechanical, optical coherence tomography (OCT)-guided robotic platform designed for autonomous volumetric soft tissue resection in surgical applications. RATS integrates macro-scale RGB-D imaging, micro-scale OCT, and a fiber-coupled surgical laser, calibrated through a novel multistage alignment pipeline that achieves OCT-to-laser calibration accuracy of 0.161+-0.031mm on tissue phantoms and ex vivo porcine tissue. A super-Gaussian laser-tissue interaction (LTI) model characterizes ablation crater morphology with an average RMSE of 0.231+-0.121mm, outperforming Gaussian baselines. A sampling-based model predictive control (MPC) framework operates directly on OCT voxel data to generate constraint-aware resection trajectories with closed-loop feedback, achieving 0.842mm RMSE and improving intersection-over-union agreement by 64.8% compared to feedforward execution. With OCT, RATS detects subsurface structures and modifies the planner's objective to preserve them, demonstrating clinical feasibility.

</details>


### [86] [SAFE-SMART: Safety Analysis and Formal Evaluation using STL Metrics for Autonomous RoboTs](https://arxiv.org/abs/2511.17781)
*Kristy Sakano,Jianyu An,Dinesh Manocha,Huan Xu*

Main category: cs.RO

TL;DR: 提出了一种基于监管的后验安全评估方法，用于评估基于学习的黑盒自主移动机器人，通过Signal Temporal Logic规范将人类安全需求转化为可量化指标，并通过迭代改进显著提升了机器人的安全性能。


<details>
  <summary>Details</summary>
Motivation: 随着学习型自主移动机器人的广泛应用，需要一种系统性的方法来确保这些黑盒系统能够持续符合不断演进的人类安全规则，而传统的验证方法难以应对这种动态变化的安全需求。

Method: 采用监管驱动的工作流程：将人类安全需求转化为STL规范，对黑盒模型的轨迹进行外部验证，计算TRV和LRV两个量化安全指标，基于这些指标进行针对性重训练和迭代改进。

Result: 在两个应用场景中均观察到显著改进：虚拟驾驶场景中，遵守限速的轨迹增加177%，减少越野驾驶的轨迹增加1138%，按时到达目标的轨迹增加16%；自主导航场景中，避免急转弯的轨迹增加300%，按时到达目标的轨迹增加200%，减少靠近障碍物时间的轨迹增加49%。

Conclusion: 该方法能够有效提升学习型自主机器人的安全性能，并在真实世界的TurtleBot3机器人上验证了改进的障碍物导航能力，证明了该监管驱动安全评估框架的实用性和有效性。

Abstract: We present a novel, regulator-driven approach for post hoc safety evaluation of learning-based, black-box autonomous mobile robots, ensuring ongoing compliance with evolving, human-defined safety rules. In our iterative workflow, human safety requirements are translated by regulators into Signal Temporal Logic (STL) specifications. Rollout traces from the black-box model are externally verified for compliance, yielding quantitative safety metrics, Total Robustness Value (TRV) and Largest Robustness Value (LRV), which measure average and worst-case specification adherence. These metrics inform targeted retraining and iterative improvement by model designers. We apply our method across two different applications: a virtual driving scenario and an autonomous mobile robot navigating a complex environment, and observe statistically significant improvements across both scenarios. In the virtual driving scenario, we see a 177% increase in traces adhering to the simulation speed limit, a 1138% increase in traces minimizing off-road driving, and a 16% increase in traces successfully reaching the goal within the time limit. In the autonomous navigation scenario, there is a 300% increase in traces avoiding sharp turns, a 200% increase in traces reaching the goal within the time limit, and a 49% increase in traces minimizing time spent near obstacles. Finally, we validate our approach on a TurtleBot3 robot in the real world, and demonstrate improved obstacle navigation with safety buffers.

</details>


### [87] [SM$^2$ITH: Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control](https://arxiv.org/abs/2511.17798)
*Francesco D'Orazio,Sepehr Samavi,Xintong Du,Siqi Zhou,Giuseppe Oriolo,Angela P. Schoellig*

Main category: cs.RO

TL;DR: SM²ITH框架结合分层任务模型预测控制与交互式人体运动预测，通过双层优化实现移动机器人在动态人机环境中的安全操作。


<details>
  <summary>Details</summary>
Motivation: 现有优化方法主要应用于静态或结构化场景，需要扩展至动态人机环境，考虑人类对机器人动作的反应。

Method: 提出任务分层双层模型预测控制框架，结合分层任务MPC与交互式人体运动预测，通过双层优化同时考虑机器人和人类动力学。

Result: 在两个移动机械臂上验证，在递送任务、顺序拾放任务和对抗性人类行为交互中均表现出色，优于基于加权目标或开环人类模型的基线方法。

Conclusion: 交互式预测能够实现安全高效的协调，在动态人机环境中显著提升移动机械臂的操作性能。

Abstract: Mobile manipulators are designed to perform complex sequences of navigation and manipulation tasks in human-centered environments. While recent optimization-based methods such as Hierarchical Task Model Predictive Control (HTMPC) enable efficient multitask execution with strict task priorities, they have so far been applied mainly to static or structured scenarios. Extending these approaches to dynamic human-centered environments requires predictive models that capture how humans react to the actions of the robot. This work introduces Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control (SM$^2$ITH), a unified framework that combines HTMPC with interactive human motion prediction through bilevel optimization that jointly accounts for robot and human dynamics. The framework is validated on two different mobile manipulators, the Stretch 3 and the Ridgeback-UR10, across three experimental settings: (i) delivery tasks with different navigation and manipulation priorities, (ii) sequential pick-and-place tasks with different human motion prediction models, and (iii) interactions involving adversarial human behavior. Our results highlight how interactive prediction enables safe and efficient coordination, outperforming baselines that rely on weighted objectives or open-loop human models.

</details>


### [88] [MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots](https://arxiv.org/abs/2511.17889)
*Ting Huang,Dongjian Li,Rui Yang,Zeyu Zhang,Zida Yang,Hao Tang*

Main category: cs.RO

TL;DR: MobileVLA-R1是一个统一的视觉-语言-动作框架，通过构建大规模多粒度思维链数据集和两阶段训练范式，实现了四足机器人的显式推理和连续控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将高级语义推理与低级驱动连接起来，导致在真实世界中存在不稳定的接地和弱泛化问题。

Method: 构建MobileVLA-CoT大规模思维链数据集，采用监督CoT对齐与GRPO强化学习的两阶段训练范式。

Result: 在VLN和VLA任务上表现优于强基线约5%，在真实四足机器人上验证了复杂环境中的鲁棒性能。

Conclusion: MobileVLA-R1通过显式推理和连续控制的统一框架，有效解决了四足机器人的自然语言指令接地问题。

Abstract: Grounding natural-language instructions into continuous control for quadruped robots remains a fundamental challenge in vision language action. Existing methods struggle to bridge high-level semantic reasoning and low-level actuation, leading to unstable grounding and weak generalization in the real world. To address these issues, we present MobileVLA-R1, a unified vision-language-action framework that enables explicit reasoning and continuous control for quadruped robots. We construct MobileVLA-CoT, a large-scale dataset of multi-granularity chain-of-thought (CoT) for embodied trajectories, providing structured reasoning supervision for alignment. Built upon this foundation, we introduce a two-stage training paradigm that combines supervised CoT alignment with GRPO reinforcement learning to enhance reasoning consistency, control stability, and long-horizon execution. Extensive evaluations on VLN and VLA tasks demonstrate superior performance over strong baselines, with approximately a 5% improvement. Real-world deployment on a quadruped robot validates robust performance in complex environments. Code: https://github.com/AIGeeksGroup/MobileVLA-R1. Website: https://aigeeksgroup.github.io/MobileVLA-R1.

</details>


### [89] [L1 Sample Flow for Efficient Visuomotor Learning](https://arxiv.org/abs/2511.17898)
*Weixi Song,Zhetao Chen,Tao Xu,Xianchao Zeng,Xinyu Zhou,Lixin Yang,Donglin Wang,Cewu Lu,Yong-Lu Li*

Main category: cs.RO

TL;DR: 提出L1 Flow方法，将v预测流匹配转换为样本预测，通过两步采样实现多模态动作生成，在保持流匹配优势的同时大幅减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 结合去噪模型的多模态分布拟合能力和L1回归的高效性，避免模式坍塌同时提升训练和推理效率。

Method: 将v预测流匹配转换为样本预测，采用两步采样：单步积分生成次优动作序列，单步预测重构精确动作序列。

Result: 在MimicGen、RoboMimic、PushT等多个基准测试中表现出训练效率、推理速度和整体性能的优势。

Conclusion: L1 Flow成功结合了流匹配和L1回归的优点，仅需两次神经网络评估即可实现高效的多模态动作生成。

Abstract: Denoising-based models, such as diffusion and flow matching, have been a critical component of robotic manipulation for their strong distribution-fitting and scaling capacity. Concurrently, several works have demonstrated that simple learning objectives, such as L1 regression, can achieve performance comparable to denoising-based methods on certain tasks, while offering faster convergence and inference. In this paper, we focus on how to combine the advantages of these two paradigms: retaining the ability of denoising models to capture multi-modal distributions and avoid mode collapse while achieving the efficiency of the L1 regression objective. To achieve this vision, we reformulate the original v-prediction flow matching and transform it into sample-prediction with the L1 training objective. We empirically show that the multi-modality can be expressed via a single ODE step. Thus, we propose \textbf{L1 Flow}, a two-step sampling schedule that generates a suboptimal action sequence via a single integration step and then reconstructs the precise action sequence through a single prediction. The proposed method largely retains the advantages of flow matching while reducing the iterative neural function evaluations to merely two and mitigating the potential performance degradation associated with direct sample regression. We evaluate our method with varying baselines and benchmarks, including 8 tasks in MimicGen, 5 tasks in RoboMimic \& PushT Bench, and one task in the real-world scenario. The results show the advantages of the proposed method with regard to training efficiency, inference speed, and overall performance. \href{https://song-wx.github.io/l1flow.github.io/}{Project Website.}

</details>


### [90] [Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game](https://arxiv.org/abs/2511.17925)
*Jeonghwan Kim,Wontaek Kim,Yidan Lu,Jin Cheng,Fatemeh Zargarbashi,Zicheng Zeng,Zekun Qi,Zhiyang Dou,Nitish Sontakke,Donghoon Baek,Sehoon Ha,Tianyu Li*

Main category: cs.RO

TL;DR: Switch-JustDance是一个低成本、可复现的机器人全身控制基准测试流水线，利用任天堂Switch的Just Dance游戏来评估机器人性能，并通过游戏内置评分系统进行量化评估。


<details>
  <summary>Details</summary>
Motivation: 现有机器人全身控制评估方法依赖预收集的人类运动数据或仿真实验，缺乏标准化基准测试，难以实现真实环境下的可复现性和人机公平比较。

Method: 通过Just Dance游戏平台，构建包含流媒体传输、运动重建和运动重定向模块的流水线，将游戏编舞转换为机器人可执行动作，利用游戏内置评分系统评估控制器性能。

Result: 验证了Just Dance平台的可靠性、有效性、敏感性和潜在偏差，证明其能提供一致且可解释的性能度量，适合作为具身AI基准测试工具。

Conclusion: Switch-JustDance为机器人全身控制提供了实用的基准测试框架，成功评估了三种先进人形机器人控制器的相对优势和局限性。

Abstract: Recent advances in whole-body robot control have enabled humanoid and legged robots to perform increasingly agile and coordinated motions. However, standardized benchmarks for evaluating these capabilities in real-world settings, and in direct comparison to humans, remain scarce. Existing evaluations often rely on pre-collected human motion datasets or simulation-based experiments, which limit reproducibility, overlook hardware factors, and hinder fair human-robot comparisons. We present Switch-JustDance, a low-cost and reproducible benchmarking pipeline that leverages motion-sensing console games, Just Dance on the Nintendo Switch, to evaluate robot whole-body control. Using Just Dance on the Nintendo Switch as a representative platform, Switch-JustDance converts in-game choreography into robot-executable motions through streaming, motion reconstruction, and motion retargeting modules and enables users to evaluate controller performance through the game's built-in scoring system. We first validate the evaluation properties of Just Dance, analyzing its reliability, validity, sensitivity, and potential sources of bias. Our results show that the platform provides consistent and interpretable performance measures, making it a suitable tool for benchmarking embodied AI. Building on this foundation, we benchmark three state-of-the-art humanoid whole-body controllers on hardware and provide insights into their relative strengths and limitations.

</details>


### [91] [RoboArmGS: High-Quality Robotic Arm Splatting via Bézier Curve Refinement](https://arxiv.org/abs/2511.17961)
*Hao Wang,Xiaobao Wei,Ying Li,Qingpo Wuwu,Dongli Wu,Jiajun Cao,Ming Lu,Wenzhao Zheng,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboArmGS提出了一种混合表示方法，通过可学习的贝塞尔曲线细化URDF骨架运动，解决了机器人手臂真实运动与理想化URDF运动不匹配的问题，提升了3D高斯渲染质量。


<details>
  <summary>Details</summary>
Motivation: 当前方法将静态3D高斯简单地绑定到URDF链接上，迫使它们被动跟随URDF骨架运动。然而真实世界的手臂运动存在噪声，理想化的URDF骨架运动无法准确建模，导致3D高斯渲染出现严重伪影。

Method: 提出RoboArmGS混合表示，使用可学习的贝塞尔曲线运动细化器来校正每个关节的残差，解决真实世界运动与URDF骨架运动之间的不匹配问题，实现3D高斯在手臂各部件间的连贯绑定。

Result: 在RoboArm4D数据集上的评估显示，RoboArmGS在真实世界运动建模和渲染质量方面达到了最先进的性能。

Conclusion: RoboArmGS能够学习更准确的真实世界运动，同时实现3D高斯在手臂部件间的连贯绑定，为构建高质量数字资产提供了有效解决方案。

Abstract: Building high-quality digital assets of robotic arms is crucial yet challenging for the Real2Sim2Real pipeline. Current approaches naively bind static 3D Gaussians according to URDF links, forcing them to follow an URDF-rigged motion passively. However, real-world arm motion is noisy, and the idealized URDF-rigged motion cannot accurately model it, leading to severe rendering artifacts in 3D Gaussians. To address these challenges, we propose RoboArmGS, a novel hybrid representation that refines the URDF-rigged motion with learnable Bézier curves, enabling more accurate real-world motion modeling. To be more specific, we present a learnable Bézier Curve motion refiner that corrects per-joint residuals to address mismatches between real-world motion and URDF-rigged motion. RoboArmGS enables the learning of more accurate real-world motion while achieving a coherent binding of 3D Gaussians across arm parts. To support future research, we contribute a carefully collected dataset named RoboArm4D, which comprises several widely used robotic arms for evaluating the quality of building high-quality digital assets. We evaluate our approach on RoboArm4D, and RoboArmGS achieves state-of-the-art performance in real-world motion modeling and rendering quality. The code and dataset will be released.

</details>


### [92] [Unobservable Subspace Evolution and Alignment for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2511.17992)
*Chungeng Tian,Fenghua He,Ning Hao*

Main category: cs.RO

TL;DR: 本文提出了Unobservable Subspace Evolution (USE)分析框架和Unobservable Subspace Alignment (USA)解决方案，系统性地解决了视觉惯性导航系统中的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要将VINS不一致性归因于可观测性失配，但分析基于简化的理论框架，未能涵盖MSCKF校正和延迟初始化等非标准估计步骤，且缺乏对不一致性如何动态产生的全面理解。

Method: 提出了USE框架，通过显式跟踪不可观测子空间评估点的变化来系统描述其在完整估计流程中的演化；基于此提出了USA解决方案，包括基于变换和基于重评估的两种方法。

Result: 分析发现某些步骤引起的可观测性错位是可观测性失配的前因；提出的USA方法通过选择性干预引发错位的估计步骤来消除不一致性。

Conclusion: USE框架为理解VINS不一致性提供了新视角，USA方法提供了准确且计算轻量的解决方案，仿真和真实实验验证了其有效性。

Abstract: The inconsistency issue in the Visual-Inertial Navigation System (VINS) is a long-standing and fundamental challenge. While existing studies primarily attribute the inconsistency to observability mismatch, these analyses are often based on simplified theoretical formulations that consider only prediction and SLAM correction. Such formulations fail to cover the non-standard estimation steps, such as MSCKF correction and delayed initialization, which are critical for practical VINS estimators. Furthermore, the lack of a comprehensive understanding of how inconsistency dynamically emerges across estimation steps has hindered the development of precise and efficient solutions. As a result, current approaches often face a trade-off between estimator accuracy, consistency, and implementation complexity. To address these limitations, this paper proposes a novel analysis framework termed Unobservable Subspace Evolution (USE), which systematically characterizes how the unobservable subspace evolves throughout the entire estimation pipeline by explicitly tracking changes in its evaluation points. This perspective sheds new light on how individual estimation steps contribute to inconsistency. Our analysis reveals that observability misalignment induced by certain steps is the antecedent of observability mismatch. Guided by this insight, we propose a simple yet effective solution paradigm, Unobservable Subspace Alignment (USA), which eliminates inconsistency by selectively intervening only in those estimation steps that induce misalignment. We design two USA methods: transformation-based and re-evaluation-based, both offering accurate and computationally lightweight solutions. Extensive simulations and real-world experiments validate the effectiveness of the proposed methods.

</details>


### [93] [Continually Evolving Skill Knowledge in Vision Language Action Model](https://arxiv.org/abs/2511.18085)
*Yuxuan Wu,Guangming Wang,Zhiheng Yang,Maoqing Yao,Brian Sheil,Hesheng Wang*

Main category: cs.RO

TL;DR: Stellar VLA是一个知识驱动的持续学习框架，通过任务潜在表示和知识空间的联合学习实现自我监督的知识演化，在LIBERO基准测试和真实世界任务中相比基线方法平均提升超过50%的最终成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型虽然能支持多样化的操作任务，但严重依赖任务特定的微调，缺乏持续学习能力。现有的持续学习方法也难以扩展到VLA模型。

Method: 提出Stellar VLA框架，包含两个变体：T-Stellar建模任务中心知识空间，TS-Stellar捕获分层任务-技能结构。通过知识引导的专家路由实现任务专业化，无需额外网络参数。

Result: 在LIBERO基准测试和真实世界任务中，相比基线方法平均提升超过50%的最终成功率。TS-Stellar在复杂动作推理方面表现更佳。

Conclusion: Stellar VLA框架有效解决了VLA模型的持续学习问题，实现了有效的知识保留和发现，降低了训练开销和标注需求。

Abstract: Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models leverage massive pretraining data to support diverse manipulation tasks, but they still depend heavily on task-specific fine-tuning, revealing a lack of continual learning capability. Existing continual learning methods are also resource-intensive to scale to VLA models. We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, modeling task-centric knowledge space, and TS-Stellar, capturing hierarchical task-skill structure. Stellar VLA enables self-supervised knowledge evolution through joint learning of task latent representation and the knowledge space, reducing annotation needs. Knowledge-guided expert routing provide task specialization without extra network parameters, lowering training overhead.Experiments on the LIBERO benchmark and real-world tasks show over 50 percentage average improvement in final success rates relative to baselines. TS-Stellar further excels in complex action inference, and in-depth analyses verify effective knowledge retention and discovery. Our code will be released soon.

</details>


### [94] [Anti-Jamming based on Null-Steering Antennas and Intelligent UAV Swarm Behavior](https://arxiv.org/abs/2511.18086)
*Miguel Lourenço,António Grilo*

Main category: cs.RO

TL;DR: UAV集群通过遗传算法、监督学习和强化学习的统一优化框架，结合零陷天线技术，有效抵御干扰并保持通信稳定性和任务效率。


<details>
  <summary>Details</summary>
Motivation: 无人机集群依赖无线通信，容易受到干扰攻击，这会破坏协调和任务成功率，因此需要研究如何有效克服干扰。

Method: 提出结合遗传算法、监督学习和强化学习的统一优化框架，采用分时段任务模型进行动态路径规划、天线定向和集群编队，使用零陷天线技术将天线零陷指向干扰源。

Result: 遗传算法获得稳定无碰撞轨迹但计算成本高；监督学习能复制遗传算法配置但泛化能力不足；强化学习具有适应性和实时决策能力，通信稳定且计算需求低。

Conclusion: 配备零陷天线和智能优化算法的无人机集群能有效缓解干扰，保持通信稳定、编队凝聚和碰撞安全，为弹性集群通信系统研究提供了统一灵活的基础。

Abstract: Unmanned Aerial Vehicle (UAV) swarms represent a key advancement in autonomous systems, enabling coordinated missions through inter-UAV communication. However, their reliance on wireless links makes them vulnerable to jamming, which can disrupt coordination and mission success. This work investigates whether a UAV swarm can effectively overcome jamming while maintaining communication and mission efficiency.
  To address this, a unified optimization framework combining Genetic Algorithms (GA), Supervised Learning (SL), and Reinforcement Learning (RL) is proposed. The mission model, structured into epochs and timeslots, allows dynamic path planning, antenna orientation, and swarm formation while progressively enforcing collision rules. Null-steering antennas enhance resilience by directing antenna nulls toward interference sources.
  Results show that the GA achieved stable, collision-free trajectories but with high computational cost. SL models replicated GA-based configurations but struggled to generalize under dynamic or constrained settings. RL, trained via Proximal Policy Optimization (PPO), demonstrated adaptability and real-time decision-making with consistent communication and lower computational demand. Additionally, the Adaptive Movement Model generalized UAV motion to arbitrary directions through a rotation-based mechanism, validating the scalability of the proposed system.
  Overall, UAV swarms equipped with null-steering antennas and guided by intelligent optimization algorithms effectively mitigate jamming while maintaining communication stability, formation cohesion, and collision safety. The proposed framework establishes a unified, flexible, and reproducible basis for future research on resilient swarm communication systems.

</details>


### [95] [A Unified Multi-Dynamics Framework for Perception-Oriented Modeling in Tendon-Driven Continuum Robots](https://arxiv.org/abs/2511.18088)
*Ibrahim Alsarraj,Yuhao Wang,Abdalla Swikir,Cesare Stefanini,Dezhen Song,Zhanchi Wang,Ke Wu*

Main category: cs.RO

TL;DR: 提出了一个统一的多动力学建模框架，用于肌腱驱动连续体机器人系统，通过整合电机电气动力学、电机卷筒动力学和连续体机器人动力学，实现基于内在电机信号的外部交互感知。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动连续体机器人具有运动冗余和结构柔顺性，但感知通常依赖外部传感器，增加了硬件复杂性和限制了可扩展性。

Method: 开发统一的多动力学建模框架，整合电机电气动力学、电机卷筒动力学和连续体机器人动力学，通过电机电流和角位移等信号揭示外部交互的机电特征。

Result: 模型成功捕捉并验证了实际系统的关键物理行为，包括驱动迟滞和运动极限的自接触。在环境交互应用中，实现了被动接触检测、主动接触感知和物体尺寸估计。

Conclusion: 该框架为肌腱驱动连续体机器人提供了一种基于物理的方式来解释来自内在电机信号的交互特征，实现了无需外部传感器的感知能力。

Abstract: Tendon-driven continuum robots offer intrinsically safe and contact-rich interactions owing to their kinematic redundancy and structural compliance. However, their perception often depends on external sensors, which increase hardware complexity and limit scalability. This work introduces a unified multi-dynamics modeling framework for tendon-driven continuum robotic systems, exemplified by a spiral-inspired robot named Spirob. The framework integrates motor electrical dynamics, motor-winch dynamics, and continuum robot dynamics into a coherent system model. Within this framework, motor signals such as current and angular displacement are modeled to expose the electromechanical signatures of external interactions, enabling perception grounded in intrinsic dynamics. The model captures and validates key physical behaviors of the real system, including actuation hysteresis and self-contact at motion limits. Building on this foundation, the framework is applied to environmental interaction: first for passive contact detection, verified experimentally against simulation data; then for active contact sensing, where control and perception strategies from simulation are successfully applied to the real robot; and finally for object size estimation, where a policy learned in simulation is directly deployed on hardware. The results demonstrate that the proposed framework provides a physically grounded way to interpret interaction signatures from intrinsic motor signals in tendon-driven continuum robots.

</details>


### [96] [EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation](https://arxiv.org/abs/2511.18112)
*Min Lin,Xiwen Liang,Bingqian Lin,Liu Jingzhi,Zijian Jiao,Kehan Li,Yuhan Ma,Yuecheng Liu,Shen Zhao,Yuzheng Zhuang,Xiaodan Liang*

Main category: cs.RO

TL;DR: EchoVLA是一个具有记忆能力的视觉-语言-动作模型，专为长时程移动操作任务设计，通过场景记忆和情景记忆的协同工作来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型主要局限于短时程桌面操作，缺乏处理长时程移动操作所需的记忆和推理能力，其中智能体需要在变化的空间环境中协调导航和操作。

Method: EchoVLA引入了受人类大脑启发的声明性记忆系统，包括维护空间语义地图的场景记忆和存储任务级多模态上下文特征的情景记忆。通过粗粒度和细粒度注意力融合记忆表示来指导移动臂扩散策略。

Result: 在模拟和真实世界实验中，EchoVLA在长时程任务上表现优异，操作/导航任务达到0.52成功率，移动操作任务达到0.31成功率，分别比基线模型提升了0.08和0.11。

Conclusion: EchoVLA通过记忆增强机制有效解决了长时程移动操作的挑战，为具身智能体在复杂环境中的任务执行提供了新的解决方案。

Abstract: Recent progress in Vision-Language-Action (VLA) models has enabled embodied agents to interpret multimodal instructions and perform complex tasks. However, existing VLAs are mostly confined to short-horizon, table-top manipulation, lacking the memory and reasoning capability required for long-horizon mobile manipulation, where agents must coordinate navigation and manipulation under changing spatial contexts. In this work, we present EchoVLA, a memory-aware VLA model for long-horizon mobile manipulation. EchoVLA incorporates a synergistic declarative memory inspired by the human brain, consisting of a scene memory that maintains a collection of spatial-semantic maps and an episodic memory that stores task-level experiences with multimodal contextual features. During both training and inference, the two memories are individually stored, updated, and retrieved based on current observations, task history, and instructions, and their retrieved representations are fused via coarse- and fine-grained attention to guide mobile-arm diffusion policies. To support large-scale training and evaluation, we further introduce MoMani, an automated benchmark that generates expert-level long-horizon trajectories through multimodal large language model (MLLM)-guided planning and feedback-driven refinement, supplemented with real-robot demonstrations. Experiments in simulated and real-world settings show that EchoVLA improves long-horizon performance, reaching 0.52 SR on manipulation/navigation and 0.31 on mobile manipulation, exceeding $π_{0.5}$ by +0.08 and +0.11.

</details>


### [97] [Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting](https://arxiv.org/abs/2511.18140)
*Yilong Wang,Cheng Qian,Ruomeng Fan,Edward Johns*

Main category: cs.RO

TL;DR: ObAct是一个主动视觉模仿学习框架，通过动态分配观察者和执行者角色来优化视觉观察，提升机器人策略的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决静态相机设置中物体和夹爪遮挡问题，提升模仿学习策略在复杂环境中的性能。

Method: 使用双臂机器人系统，观察者臂构建3D高斯泼溅表示并虚拟探索最佳相机位姿，执行者臂基于优化后的观察执行策略。

Result: 相比静态相机设置，轨迹传递性能提升145%（无遮挡）和233%（有遮挡），行为克隆提升75%和143%。

Conclusion: ObAct框架通过主动视觉观察显著提升了模仿学习策略的性能和鲁棒性。

Abstract: We propose Observer Actor (ObAct), a novel framework for active vision imitation learning in which the observer moves to optimal visual observations for the actor. We study ObAct on a dual-arm robotic system equipped with wrist-mounted cameras. At test time, ObAct dynamically assigns observer and actor roles: the observer arm constructs a 3D Gaussian Splatting (3DGS) representation from three images, virtually explores this to find an optimal camera pose, then moves to this pose; the actor arm then executes a policy using the observer's observations. This formulation enhances the clarity and visibility of both the object and the gripper in the policy's observations. As a result, we enable the training of ambidextrous policies on observations that remain closer to the occlusion-free training distribution, leading to more robust policies. We study this formulation with two existing imitation learning methods -- trajectory transfer and behavior cloning -- and experiments show that ObAct significantly outperforms static-camera setups: trajectory transfer improves by 145% without occlusion and 233% with occlusion, while behavior cloning improves by 75% and 143%, respectively. Videos are available at https://obact.github.io.

</details>


### [98] [A Coordinated Dual-Arm Framework for Delicate Snap-Fit Assemblies](https://arxiv.org/abs/2511.18153)
*Shreyas Kumar,Barat S,Debojit Das,Yug Desai,Siddhi Jain,Rajesh Kumar,Harish J. Palanthandalam-Madapusi*

Main category: cs.RO

TL;DR: 提出SnapNet神经网络实时检测卡扣装配的啮合，结合基于动态系统的双臂协调框架，实现精密卡扣装配中的准确定位和柔顺插入，显著降低冲击力。


<details>
  <summary>Details</summary>
Motivation: 精密卡扣装配（如镜片插入眼镜框或电子组装）需要及时检测啮合并快速衰减力，以防止过冲导致的组件损坏或装配失败。

Method: 1. 引入轻量级神经网络SnapNet，从关节速度瞬变中实时检测卡扣啮合；2. 提出基于动态系统的双臂协调框架，集成SnapNet检测与事件触发的阻抗调制。

Result: 在异构双手平台上对不同几何形状进行实验，显示检测准确率高（召回率超过96%），与标准阻抗控制相比峰值冲击力降低达30%。

Conclusion: 该方法仅使用本体感受信号即可实现可靠的卡扣啮合检测，并通过事件触发的阻抗调制实现精密装配中的准确定位和柔顺插入。

Abstract: Delicate snap-fit assemblies, such as inserting a lens into an eye-wear frame or during electronics assembly, demand timely engagement detection and rapid force attenuation to prevent overshoot-induced component damage or assembly failure. We address these challenges with two key contributions. First, we introduce SnapNet, a lightweight neural network that detects snap-fit engagement from joint-velocity transients in real-time, showing that reliable detection can be achieved using proprioceptive signals without external sensors. Second, we present a dynamical-systems-based dual-arm coordination framework that integrates SnapNet driven detection with an event-triggered impedance modulation, enabling accurate alignment and compliant insertion during delicate snap-fit assemblies. Experiments across diverse geometries on a heterogeneous bimanual platform demonstrate high detection accuracy (over 96% recall) and up to a 30% reduction in peak impact forces compared to standard impedance control.

</details>


### [99] [Time-aware Motion Planning in Dynamic Environments with Conformal Prediction](https://arxiv.org/abs/2511.18170)
*Kaier Liang,Licheng Luo,Yixuan Wang,Mingyu Cai,Cristian Ioan Vasile*

Main category: cs.RO

TL;DR: 提出了两个基于共形预测的运动规划框架：全局规划器集成SIPP进行不确定性感知轨迹生成，局部规划器执行在线反应式规划，通过自适应共形预测增强动态环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的安全导航面临障碍物行为不确定性和缺乏形式化预测保证的挑战。

Method: 全局规划器提供无分布安全保证，局部规划器通过自适应共形预测缓解障碍物轨迹预测不准确性，并引入自适应分位数机制优化不确定性量化。

Result: 在动态和拥挤环境中进行了数值实验验证。

Conclusion: 所提框架能够适应性地收紧安全边界，在不确定性较高区域保持轨迹可行性，实现动态环境中的鲁棒运动规划。

Abstract: Safe navigation in dynamic environments remains challenging due to uncertain obstacle behaviors and the lack of formal prediction guarantees. We propose two motion planning frameworks that leverage conformal prediction (CP): a global planner that integrates Safe Interval Path Planning (SIPP) for uncertainty-aware trajectory generation, and a local planner that performs online reactive planning. The global planner offers distribution-free safety guarantees for long-horizon navigation, while the local planner mitigates inaccuracies in obstacle trajectory predictions through adaptive CP, enabling robust and responsive motion in dynamic environments. To further enhance trajectory feasibility, we introduce an adaptive quantile mechanism in the CP-based uncertainty quantification. Instead of using a fixed confidence level, the quantile is automatically tuned to the optimal value that preserves trajectory feasibility, allowing the planner to adaptively tighten safety margins in regions with higher uncertainty. We validate the proposed framework through numerical experiments conducted in dynamic and cluttered environments. The project page is available at https://time-aware-planning.github.io

</details>


### [100] [Off-Road Navigation via Implicit Neural Representation of Terrain Traversability](https://arxiv.org/abs/2511.18183)
*Yixuan Jia,Qingyuan Li,Jonathan P. How*

Main category: cs.RO

TL;DR: 提出TRAIL框架，利用隐式神经表示连续参数化地形属性，结合梯度优化方法同时调整路径几何和速度剖面以适应地形可通行性


<details>
  <summary>Details</summary>
Motivation: 传统基于采样的规划器只能优化短期控制动作，无法考虑完整路径几何，且缺乏根据地形颠簸度调整速度的能力

Method: 使用隐式神经表示连续参数化地形属性，结合梯度优化方法同时优化路径几何和速度剖面

Result: 开发了TRAIL框架，能够生成考虑地形可通行性的优化路径和速度剖面

Conclusion: TRAIL框架通过隐式表示和梯度优化，解决了传统方法在路径几何和速度调整方面的局限性

Abstract: Autonomous off-road navigation requires robots to estimate terrain traversability from onboard sensors and plan accordingly. Conventional approaches typically rely on sampling-based planners such as MPPI to generate short-term control actions that aim to minimize traversal time and risk measures derived from the traversability estimates. These planners can react quickly but optimize only over a short look-ahead window, limiting their ability to reason about the full path geometry, which is important for navigating in challenging off-road environments. Moreover, they lack the ability to adjust speed based on the terrain bumpiness, which is important for smooth navigation on challenging terrains. In this paper, we introduce TRAIL (Traversability with an Implicit Learned Representation), an off-road navigation framework that leverages an implicit neural representation to continuously parameterize terrain properties. This representation yields spatial gradients that enable integration with a novel gradient-based trajectory optimization method that adapts the path geometry and speed profile based on terrain traversability.

</details>


### [101] [SkillWrapper: Generative Predicate Invention for Skill Abstraction](https://arxiv.org/abs/2511.18203)
*Ziyi Yang,Benned Hedegaard,Ahmed Jaafar,Yichen Wei,Skye Thompson,Shreyas S. Raman,Haotian Fu,Stefanie Tellex,George Konidaris,David Paulius,Naman Shah*

Main category: cs.RO

TL;DR: 提出了SkillWrapper方法，利用基础模型主动收集机器人数据，学习可解释、可规划的黑盒技能抽象表示，实现真实世界中未见长时程任务的求解。


<details>
  <summary>Details</summary>
Motivation: 解决从个体技能执行泛化到长时程任务求解的核心挑战，需要学习与低层状态空间无关的高层符号抽象表示来进行推理和规划。

Method: 提出SkillWrapper方法，利用基础模型主动收集机器人数据，仅使用RGB图像观察学习人类可解释、可规划的黑盒技能抽象表示。

Result: 在仿真和真实机器人上的广泛实验表明，SkillWrapper学习的抽象表示能够使用黑盒技能解决真实世界中未见的长时程任务。

Conclusion: 提出了生成谓词发明的形式理论框架，确保学习到的符号操作符可用于可证明正确和完备的规划，SkillWrapper方法实现了这一目标。

Abstract: Generalizing from individual skill executions to solving long-horizon tasks remains a core challenge in building autonomous agents. A promising direction is learning high-level, symbolic abstractions of the low-level skills of the agents, enabling reasoning and planning independent of the low-level state space. Among possible high-level representations, object-centric skill abstraction with symbolic predicates has been proven to be efficient because of its compatibility with domain-independent planners. Recent advances in foundation models have made it possible to generate symbolic predicates that operate on raw sensory inputs, a process we call generative predicate invention, to facilitate downstream abstraction learning. However, it remains unclear which formal properties the learned representations must satisfy, and how they can be learned to guarantee these properties. In this paper, we address both questions by presenting a formal theory of generative predicate invention for skill abstraction, resulting in symbolic operators that can be used for provably sound and complete planning. Within this framework, we propose SkillWrapper, a method that leverages foundation models to actively collect robot data and learn human-interpretable, plannable representations of black-box skills, using only RGB image observations. Our extensive empirical evaluation in simulation and on real robots shows that SkillWrapper learns abstract representations that enable solving unseen, long-horizon tasks in the real world with black-box skills.

</details>


### [102] [AFT: Appearance-Based Feature Tracking for Markerless and Training-Free Shape Reconstruction of Soft Robots](https://arxiv.org/abs/2511.18215)
*Shangyuan Yuan,Preston Fairchild,Yu Mei,Xinyu Zhou,Xiaobo Tan*

Main category: cs.RO

TL;DR: 提出了一种基于视觉、无标记、无需训练的软机器人形状重建框架，利用机器人自然表面特征作为隐式视觉标记，实现实时形状跟踪和闭环控制。


<details>
  <summary>Details</summary>
Motivation: 现有视觉方法依赖复杂相机设置、特定背景或大规模训练数据，限制了实际应用。需要一种更实用、低成本的方法在真实场景中实现软机器人形状重建。

Method: 使用机器人自然表面特征作为隐式视觉标记，采用分层匹配策略，将局部分区对齐与全局运动学优化解耦，仅需初始3D重建和运动学对齐。

Result: 在连续软机器人上验证，实时操作时平均尖端误差为2.6%，在遮挡和相机视角变化下保持鲁棒性，在闭环控制任务中表现稳定。

Conclusion: 该方法具有在动态真实环境中可靠、低成本部署的潜力，为软机器人形状重建提供了实用的视觉解决方案。

Abstract: Accurate shape reconstruction is essential for precise control and reliable operation of soft robots. Compared to sensor-based approaches, vision-based methods offer advantages in cost, simplicity, and ease of deployment. However, existing vision-based methods often rely on complex camera setups, specific backgrounds, or large-scale training datasets, limiting their practicality in real-world scenarios. In this work, we propose a vision-based, markerless, and training-free framework for soft robot shape reconstruction that directly leverages the robot's natural surface appearance. These surface features act as implicit visual markers, enabling a hierarchical matching strategy that decouples local partition alignment from global kinematic optimization. Requiring only an initial 3D reconstruction and kinematic alignment, our method achieves real-time shape tracking across diverse environments while maintaining robustness to occlusions and variations in camera viewpoints. Experimental validation on a continuum soft robot demonstrates an average tip error of 2.6% during real-time operation, as well as stable performance in practical closed-loop control tasks. These results highlight the potential of the proposed approach for reliable, low-cost deployment in dynamic real-world settings.

</details>


### [103] [APULSE: A Scalable Hybrid Algorithm for the RCSPP on Large-Scale Dense Graphs](https://arxiv.org/abs/2511.18236)
*Nuno Soares,António Grilo*

Main category: cs.RO

TL;DR: APULSE是一种混合标签设置算法，用于高效解决资源受限最短路径问题(RCSPP)，在大规模密集图上表现出色，比现有方法快几个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有RCSPP求解器在复杂现实场景的大规模密集图上存在可扩展性限制，无法满足时间关键规划需求，特别是在无人地面车辆任务规划等领域。

Method: APULSE结合了A*启发式引导的最佳优先搜索、脉冲式剪枝机制和时间分桶策略，实现有效的状态空间缩减。

Result: 在大规模UGV规划场景的基准测试中，APULSE始终能找到接近最优解，速度比竞争方法快几个数量级，在大型问题实例上更具鲁棒性。

Conclusion: APULSE在复杂大规模环境中为RCSPP提供了有效解决方案，支持交互式决策支持和动态重规划能力。

Abstract: The resource-constrained shortest path problem (RCSPP) is a fundamental NP-hard optimization challenge with broad applications, from network routing to autonomous navigation. This problem involves finding a path that minimizes a primary cost subject to a budget on a secondary resource. While various RCSPP solvers exist, they often face critical scalability limitations when applied to the large, dense graphs characteristic of complex, real-world scenarios, making them impractical for time-critical planning. This challenge is particularly acute in domains like mission planning for unmanned ground vehicles (UGVs), which demand solutions on large-scale terrain graphs. This paper introduces APULSE, a hybrid label-setting algorithm designed to efficiently solve the RCSPP on such challenging graphs. APULSE integrates a best-first search guided by an A* heuristic with aggressive, Pulse-style pruning mechanisms and a time-bucketing strategy for effective state-space reduction. A computational study, using a large-scale UGV planning scenario, benchmarks APULSE against state-of-the-art algorithms. The results demonstrate that APULSE consistently finds near-optimal solutions while being orders of magnitude faster and more robust, particularly on large problem instances where competing methods fail. This superior scalability establishes APULSE as an effective solution for RCSPP in complex, large-scale environments, enabling capabilities such as interactive decision support and dynamic replanning.

</details>


### [104] [Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters](https://arxiv.org/abs/2511.18243)
*Eashan Vytla,Bhavanishankar Kalavakolanu,Andrew Perrault,Matthew McCrink*

Main category: cs.RO

TL;DR: 论文探索了基于物理信息的世界模型学习方法，将其应用于无人机控制，并与标准RNN世界模型进行比较，发现两种模型在训练数据上表现良好但无法泛化到新轨迹。


<details>
  <summary>Details</summary>
Motivation: 当前无人机控制算法在动态环境和恶劣条件下缺乏鲁棒性，基于模型的强化学习虽然样本效率高但难以应用于无人机系统，Dreamer方法在无人机上存在样本效率低和动力学模型泛化能力差的问题。

Method: 采用物理信息方法构建世界模型，将四旋翼视为自由体系统预测净力和力矩，通过6自由度龙格-库塔积分器预测未来状态展开，并与标准RNN世界模型进行对比。

Result: 两种模型在训练数据上都表现良好，但都无法泛化到新轨迹，导致状态展开快速发散，阻碍了策略收敛。

Conclusion: 物理信息方法虽然改进了世界模型学习，但与标准RNN模型一样面临泛化能力不足的问题，无法有效应用于无人机控制策略学习。

Abstract: Current control algorithms for aerial robots struggle with robustness in dynamic environments and adverse conditions. Model-based reinforcement learning (RL) has shown strong potential in handling these challenges while remaining sample-efficient. Additionally, Dreamer has demonstrated that online model-based RL can be achieved using a recurrent world model trained on replay buffer data. However, applying Dreamer to aerial systems has been quite challenging due to its sample inefficiency and poor generalization of dynamics models. Our work explores a physics-informed approach to world model learning and improves policy performance. The world model treats the quadcopter as a free-body system and predicts the net forces and moments acting on it, which are then passed through a 6-DOF Runge-Kutta integrator (RK4) to predict future state rollouts. In this paper, we compare this physics-informed method to a standard RNN-based world model. Although both models perform well on the training data, we observed that they fail to generalize to new trajectories, leading to rapid divergence in state rollouts, preventing policy convergence.

</details>


### [105] [Skypilot: Fine-Tuning LLM with Physical Grounding for AAV Coverage Search](https://arxiv.org/abs/2511.18270)
*Zhongkai Chen,Yihao Sun,Chao Yan,Han Zhou,Xiaojia Xiang,Jie Jiang*

Main category: cs.RO

TL;DR: 提出了Skypilot框架，通过结合蒙特卡洛树搜索(MCTS)将大语言模型(LLMs)物理接地，解决自主飞行器在覆盖任务中的幻觉和可重复性问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自主飞行器的覆盖操作和搜索任务中具有潜力，但缺乏物理接地导致空间推理和决策中出现幻觉和可重复性问题。

Method: 采用两阶段框架：第一阶段引入多样化动作空间（生成、重新生成、微调、评估）和物理感知奖励函数；第二阶段在23,000个MCTS生成样本上微调Qwen3-4B模型。

Result: 通过数值模拟和真实飞行实验验证了方法的效率和优越性，实现了推理加速同时保持解决方案质量。

Conclusion: Skypilot框架成功将语言模型物理接地，解决了自主飞行器决策中的幻觉问题，为复杂覆盖任务提供了可靠解决方案。

Abstract: Autonomous aerial vehicles (AAVs) have played a pivotal role in coverage operations and search missions. Recent advances in large language models (LLMs) offer promising opportunities to augment AAV intelligence. These advances help address complex challenges like area coverage optimization, dynamic path planning, and adaptive decision-making. However, the absence of physical grounding in LLMs leads to hallucination and reproducibility problems in spatial reasoning and decision-making. To tackle these issues, we present Skypilot, an LLM-enhanced two-stage framework that grounds language models in physical reality by integrating monte carlo tree search (MCTS). In the first stage, we introduce a diversified action space that encompasses generate, regenerate, fine-tune, and evaluate operations, coupled with physics-informed reward functions to ensure trajectory feasibility. In the second stage, we fine-tune Qwen3-4B on 23,000 MCTS-generated samples, achieving substantial inference acceleration while maintaining solution quality. Extensive numerical simulations and real-world flight experiments validate the efficiency and superiority of our proposed approach. Detailed information and experimental results are accessible at https://sky-pilot.top.

</details>


### [106] [AIA-UltraNeRF:Acoustic-Impedance-Aware Neural Radiance Field with Hash Encodings for Robotic Ultrasound Reconstruction and Localization](https://arxiv.org/abs/2511.18293)
*Shuai Zhang,Jingsong Mu,Cancan Zhao,Leiqi Tian,Zhijun Xing,Bo Ouyang,Xiang Li*

Main category: cs.RO

TL;DR: 提出了一种声阻抗感知的超声NeRF系统(AIA-UltraNeRF)，结合机器人超声系统，通过哈希编码空间坐标来建模3D超声图，实现快速重建和定位，推理速度比原始NeRF快9.9倍。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法忽略了声阻抗在超声成像中的关键作用，定位方法因初始位姿选择而面临局部极小值问题。需要将扫描和诊断过程解耦。

Method: 设计机器人超声系统，采用AIA-UltraNeRF对哈希编码的空间坐标建模连续函数存储声阻抗；提出双监督网络利用师生模型哈希编码渲染图像；开发球形远程运动中心机构实现操作者无关扫描。

Result: 在体模和人体实验中验证了声阻抗在隐式表征超声图像颜色方面的有效性，AIA-UltraNeRF实现了重建和定位，推理速度比原始NeRF快9.9倍。

Conclusion: 该方法成功将声阻抗整合到NeRF框架中，实现了高效的超声图像重建和定位，为机器人超声系统提供了可行的解决方案。

Abstract: Neural radiance field (NeRF) is a promising approach for reconstruction and new view synthesis. However, previous NeRF-based reconstruction methods overlook the critical role of acoustic impedance in ultrasound imaging. Localization methods face challenges related to local minima due to the selection of initial poses. In this study, we design a robotic ultrasound system (RUSS) with an acoustic-impedance-aware ultrasound NeRF (AIA-UltraNeRF) to decouple the scanning and diagnostic processes. Specifically, AIA-UltraNeRF models a continuous function of hash-encoded spatial coordinates for the 3D ultrasound map, allowing for the storage of acoustic impedance without dense sampling. This approach accelerates both reconstruction and inference speeds. We then propose a dual-supervised network that leverages teacher and student models to hash-encode the rendered ultrasound images from the reconstructed map. AIA-UltraNeRF retrieves the most similar hash values without the need to render images again, providing an offline initial image position for localization. Moreover, we develop a RUSS with a spherical remote center of motion mechanism to hold the probe, implementing operator-independent scanning modes that separate image acquisition from diagnostic workflows. Experimental results on a phantom and human subjects demonstrate the effectiveness of acoustic impedance in implicitly characterizing the color of ultrasound images. AIAUltraNeRF achieves both reconstruction and localization with inference speeds that are 9.9 faster than those of vanilla NeRF.

</details>


### [107] [MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing](https://arxiv.org/abs/2511.18299)
*Steven Oh,Tai Inui,Magdeline Kuan,Jia-Yeu Lin*

Main category: cs.RO

TL;DR: MicCheck是一种低成本、即插即用的声学传感方法，利用现成的蓝牙针式麦克风作为接触传感器，通过音频信号实现材料分类和机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 机器人操作任务需要丰富的接触信息，但现有模仿学习方法主要依赖视觉，难以捕捉刚度、粗糙度、滑动等精细交互线索。触觉信号可以弥补这一差距，但现有传感器通常昂贵、脆弱或集成复杂。

Method: 将现成的蓝牙针式麦克风重新用作低成本接触传感器，通过3D打印的夹持器插入件固定，通过标准USB接收器传输音频，无需定制电子设备或驱动程序。

Result: 在10类材料的分类任务中达到92.9%的准确率；在拾取和倾倒任务中，将成功率从0.40提高到0.80，并能够可靠执行拔插和基于声音的排序等接触密集型技能。

Conclusion: 与高分辨率触觉传感器相比，针式麦克风在空间细节上有所牺牲，但在成本和集成便利性方面具有优势，为低成本机器人设置中部署声学接触传感提供了实用途径。

Abstract: Robotic manipulation tasks are contact-rich, yet most imitation learning (IL) approaches rely primarily on vision, which struggles to capture stiffness, roughness, slip, and other fine interaction cues. Tactile signals can address this gap, but existing sensors often require expensive, delicate, or integration-heavy hardware. In this work, we introduce MicCheck, a plug-and-play acoustic sensing approach that repurposes an off-the-shelf Bluetooth pin microphone as a low-cost contact sensor. The microphone clips into a 3D-printed gripper insert and streams audio via a standard USB receiver, requiring no custom electronics or drivers. Despite its simplicity, the microphone provides signals informative enough for both perception and control. In material classification, it achieves 92.9% accuracy on a 10-class benchmark across four interaction types (tap, knock, slow press, drag). For manipulation, integrating pin microphone into an IL pipeline with open source hardware improves the success rate on picking and pouring task from 0.40 to 0.80 and enables reliable execution of contact-rich skills such as unplugging and sound-based sorting. Compared with high-resolution tactile sensors, pin microphones trade spatial detail for cost and ease of integration, offering a practical pathway for deploying acoustic contact sensing in low-cost robot setups.

</details>


### [108] [Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video](https://arxiv.org/abs/2511.18322)
*Henrik Krauss,Johann Licher,Naoya Takeishi,Annika Raatz,Takehisa Yairi*

Main category: cs.RO

TL;DR: 提出Attention Broadcast Decoder (ABCD)模块，结合注意力机制和2D振荡器网络，从高维观测数据中学习软体连续机器人的物理可解释动力学模型，显著提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 数据驱动方法学习软体连续机器人动力学缺乏物理可解释性，而基于模型的方法需要先验知识且计算昂贵，需要弥合这一差距。

Method: 引入ABCD模块作为自编码器潜在动力学学习的即插即用组件，生成像素级注意力图定位每个潜在维度的贡献；将注意力图与2D振荡器网络耦合，实现学习动力学的直接可视化。

Result: 在单段和双段软体连续机器人上验证，ABCD模型显著提升多步预测精度：双段机器人上Koopman算子误差减少5.7倍，振荡器网络误差减少3.5倍；学习到的振荡器网络自主发现振荡器链结构；支持训练数据之外的平滑潜在空间外推。

Conclusion: 这种完全数据驱动的方法产生了紧凑、物理可解释的模型，适用于控制应用。

Abstract: Data-driven learning of soft continuum robot (SCR) dynamics from high-dimensional observations offers flexibility but often lacks physical interpretability, while model-based approaches require prior knowledge and can be computationally expensive. We bridge this gap by introducing (1) the Attention Broadcast Decoder (ABCD), a plug-and-play module for autoencoder-based latent dynamics learning that generates pixel-accurate attention maps localizing each latent dimension's contribution while filtering static backgrounds. (2) By coupling these attention maps to 2D oscillator networks, we enable direct on-image visualization of learned dynamics (masses, stiffness, and forces) without prior knowledge. We validate our approach on single- and double-segment SCRs, demonstrating that ABCD-based models significantly improve multi-step prediction accuracy: 5.7x error reduction for Koopman operators and 3.5x for oscillator networks on the two-segment robot. The learned oscillator network autonomously discovers a chain structure of oscillators. Unlike standard methods, ABCD models enable smooth latent space extrapolation beyond training data. This fully data-driven approach yields compact, physically interpretable models suitable for control applications.

</details>


### [109] [Enhancing UAV Search under Occlusion using Next Best View Planning](https://arxiv.org/abs/2511.18353)
*Sigrid Helene Strand,Thomas Wiedemann,Bram Burczek,Dmitriy Shutin*

Main category: cs.RO

TL;DR: 提出了一种针对遮挡环境中无人机搜索救援任务的优化规划策略，通过几何启发式和可见性启发式两种新方法来解决最佳视角选择问题，可见性启发式在模拟和真实环境中都表现出更好的性能。


<details>
  <summary>Details</summary>
Motivation: 在密集森林等遮挡环境中进行搜救任务时，无人机需要优化相机位置和视角来获取清晰的地面视图，但现有方法在遮挡环境中的搜索效果有限。

Method: 提出了两种新颖的优化启发式方法：几何启发式和可见性启发式，用于选择最优相机视点，并开发了高效的算法来解决遮挡环境中的最佳视角问题。

Result: 在模拟和真实环境中的比较评估显示，可见性启发式识别了模拟森林中90%以上的隐藏物体，比几何启发式的检测率高10%，并且在真实环境中提供了更好的树冠下覆盖。

Conclusion: 可见性启发式在遮挡环境中具有更好的搜索性能，能够显著提高搜救任务的效果，特别是在密集森林等难以进入的地形中。

Abstract: Search and rescue missions are often critical following sudden natural disasters or in high-risk environmental situations. The most challenging search and rescue missions involve difficult-to-access terrains, such as dense forests with high occlusion. Deploying unmanned aerial vehicles for exploration can significantly enhance search effectiveness, facilitate access to challenging environments, and reduce search time. However, in dense forests, the effectiveness of unmanned aerial vehicles depends on their ability to capture clear views of the ground, necessitating a robust search strategy to optimize camera positioning and perspective. This work presents an optimized planning strategy and an efficient algorithm for the next best view problem in occluded environments. Two novel optimization heuristics, a geometry heuristic, and a visibility heuristic, are proposed to enhance search performance by selecting optimal camera viewpoints. Comparative evaluations in both simulated and real-world settings reveal that the visibility heuristic achieves greater performance, identifying over 90% of hidden objects in simulated forests and offering 10% better detection rates than the geometry heuristic. Additionally, real-world experiments demonstrate that the visibility heuristic provides better coverage under the canopy, highlighting its potential for improving search and rescue missions in occluded environments.

</details>


### [110] [Explicit Bounds on the Hausdorff Distance for Truncated mRPI Sets via Norm-Dependent Contraction Rates](https://arxiv.org/abs/2511.18374)
*Jiaxun Sun*

Main category: cs.RO

TL;DR: 本文首次建立了截断最小鲁棒正不变集与其无限时极限之间Hausdorff距离的显式闭式上界，提供了可计算的截断误差表达式。


<details>
  <summary>Details</summary>
Motivation: 现有mRPI近似方法通过几何或范数论证保证渐近收敛，但都没有提供量化给定时域截断误差的可计算表达式。

Method: 证明误差满足d_H(ℰ_N,ℰ_∞) ≤ r_W γ^(N+1)/(1-γ)，其中γ<1是诱导范数收缩因子，r_W仅依赖于扰动集。该边界完全解析，无需迭代集计算。

Result: 边界完全解析，直接表征截断Minkowski级数的衰减率，向量范数的选择可作为设计参数加速收敛。数值实验验证了边界的锐度、可扩展性和实际相关性。

Conclusion: 提出的边界显著改进了鲁棒不变集计算和基于管的MPC的时域选择，为截断误差提供了首个可计算的显式量化。

Abstract: This paper establishes the first explicit and closed-form upper bound on the Hausdorff distance between the truncated minimal robust positively invariant (mRPI) set and its infinite-horizon limit. While existing mRPI approximations guarantee asymptotic convergence through geometric or norm-based arguments, none provides a computable expression that quantifies the truncation error for a given horizon. We show that the error satisfies \( d_H(\mathcal{E}_N,\mathcal{E}_\infty) \le r_W\,γ^{N+1}/(1-γ), \) where $γ<1$ is the induced-norm contraction factor and $r_W$ depends only on the disturbance set. The bound is fully analytic, requires no iterative set computations, and directly characterizes the decay rate of the truncated Minkowski series. We further demonstrate that the choice of vector norm serves as a design parameter that accelerates convergence, enabling substantially tighter horizon selection for robust invariant-set computations and tube-based MPC. Numerical experiments validate the sharpness, scalability, and practical relevance of the proposed bound.

</details>


### [111] [Expanding the Workspace of Electromagnetic Navigation Systems Using Dynamic Feedback for Single- and Multi-agent Control](https://arxiv.org/abs/2511.18486)
*Jasan Zughaibi,Denis von Arx,Maurus Derungs,Florian Heemeyer,Luca A. Antonelli,Quentin Boehler,Michael Muehlebach,Bradley J. Nelson*

Main category: cs.RO

TL;DR: 通过系统级控制设计显著扩展电磁导航系统的工作空间，采用运动中心的扭矩/力目标、能量最优电流分配等五种方法，在OctoMag和Navion系统上验证了电流需求大幅降低和稳定性提升。


<details>
  <summary>Details</summary>
Motivation: 电磁导航系统的有效工作空间常受功率和热限制严重约束，需要寻找方法来扩展工作空间并降低电流需求。

Method: 采用五种系统方法：运动中心的扭矩/力目标、能量最优电流分配、实时位姿估计、动态反馈控制和高带宽eMNS组件，在OctoMag和Navion系统上进行实验验证。

Result: 在OctoMag系统上稳定3D倒立摆的电流从8-14A降至0.1-0.2A，在Navion系统上能在距离线圈50cm处保持稳定平衡，显著扩展了工作空间。

Conclusion: 反馈控制是实现可扩展、高效且临床相关的磁操作的实际路径，系统级设计能显著提升电磁导航系统的性能。

Abstract: Electromagnetic navigation systems (eMNS) enable a number of magnetically guided surgical procedures. A challenge in magnetically manipulating surgical tools is that the effective workspace of an eMNS is often severely constrained by power and thermal limits. We show that system-level control design significantly expands this workspace by reducing the currents needed to achieve a desired motion. We identified five key system approaches that enable this expansion: (i) motion-centric torque/force objectives, (ii) energy-optimal current allocation, (iii) real-time pose estimation, (iv) dynamic feedback, and (v) high-bandwidth eMNS components. As a result, we stabilize a 3D inverted pendulum on an eight-coil OctoMag eMNS with significantly lower currents (0.1-0.2 A vs. 8-14 A), by replacing a field-centric field-alignment strategy with a motion-centric torque/force-based approach. We generalize to multi-agent control by simultaneously stabilizing two inverted pendulums within a shared workspace, exploiting magnetic-field nonlinearity and coil redundancy for independent actuation. A structured analysis compares the electromagnetic workspaces of both paradigms and examines current-allocation strategies that map motion objectives to coil currents. Cross-platform evaluation of the clinically oriented Navion eMNS further demonstrates substantial workspace expansion by maintaining stable balancing at distances up to 50 cm from the coils. The results demonstrate that feedback is a practical path to scalable, efficient, and clinically relevant magnetic manipulation.

</details>


### [112] [SafeFall: Learning Protective Control for Humanoid Robots](https://arxiv.org/abs/2511.18509)
*Ziyu Meng,Tengyu Liu,Le Ma,Yingying Wu,Ran Song,Wei Zhang,Siyuan Huang*

Main category: cs.RO

TL;DR: SafeFall是一个保护人形机器人免受摔倒损坏的框架，通过预测不可避免的摔倒并执行保护动作来最小化硬件损伤


<details>
  <summary>Details</summary>
Motivation: 双足行走使人形机器人容易摔倒，导致昂贵的传感器、执行器和结构组件损坏，这是实际部署的关键障碍

Method: 结合轻量级GRU摔倒预测器和强化学习保护策略，在检测到不可避免摔倒时激活保护动作，使用损伤感知奖励函数训练

Result: 在Unitree G1人形机器人上验证，峰值接触力减少68.3%，峰值关节扭矩减少78.4%，99.3%的脆弱部件碰撞被消除

Conclusion: SafeFall为机器人提供了关键的安全网，使更激进的实验成为可能，加速了复杂现实环境中的部署

Abstract: Bipedal locomotion makes humanoid robots inherently prone to falls, causing catastrophic damage to the expensive sensors, actuators, and structural components of full-scale robots. To address this critical barrier to real-world deployment, we present \method, a framework that learns to predict imminent, unavoidable falls and execute protective maneuvers to minimize hardware damage. SafeFall is designed to operate seamlessly alongside existing nominal controller, ensuring no interference during normal operation. It combines two synergistic components: a lightweight, GRU-based fall predictor that continuously monitors the robot's state, and a reinforcement learning policy for damage mitigation. The protective policy remains dormant until the predictor identifies a fall as unavoidable, at which point it activates to take control and execute a damage-minimizing response. This policy is trained with a novel, damage-aware reward function that incorporates the robot's specific structural vulnerabilities, learning to shield critical components like the head and hands while absorbing energy with more robust parts of its body. Validated on a full-scale Unitree G1 humanoid, SafeFall demonstrated significant performance improvements over unprotected falls. It reduced peak contact forces by 68.3\%, peak joint torques by 78.4\%, and eliminated 99.3\% of collisions with vulnerable components. By enabling humanoids to fail safely, SafeFall provides a crucial safety net that allows for more aggressive experiments and accelerates the deployment of these robots in complex, real-world environments.

</details>


### [113] [Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation](https://arxiv.org/abs/2511.18525)
*Samarth Chopra,Jing Liang,Gershom Seneviratne,Yonghan Lee,Jaehoon Choi,Jianyu An,Stephen Cheng,Dinesh Manocha*

Main category: cs.RO

TL;DR: Splatblox是一个用于户外密集植被环境的实时自主导航系统，通过融合RGB图像和LiDAR点云构建可通行性感知的ESDF地图，在植被丰富场景中相比现有方法成功率提高50%以上。


<details>
  <summary>Details</summary>
Motivation: 解决户外环境中密集植被、不规则障碍物和复杂地形下的自主导航挑战，需要同时处理几何和语义信息来区分可穿越植被与刚性障碍物。

Method: 使用高斯泼溅技术融合分割的RGB图像和LiDAR点云，构建在线更新的可通行性感知欧几里得符号距离场(ESDF)，结合语义推理和360度几何覆盖。

Result: 在植被丰富场景的现场试验中，相比最先进方法成功率提高50%以上，冻结事件减少40%，路径缩短5%，目标到达时间加快13%，支持长达100米的远程任务。

Conclusion: Splatblox系统在复杂户外环境中实现了高效的自主导航，验证了其在不同平台（四足和轮式机器人）上的可转移性，为户外导航提供了有效解决方案。

Abstract: We present Splatblox, a real-time system for autonomous navigation in outdoor environments with dense vegetation, irregular obstacles, and complex terrain. Our method fuses segmented RGB images and LiDAR point clouds using Gaussian Splatting to construct a traversability-aware Euclidean Signed Distance Field (ESDF) that jointly encodes geometry and semantics. Updated online, this field enables semantic reasoning to distinguish traversable vegetation (e.g., tall grass) from rigid obstacles (e.g., trees), while LiDAR ensures 360-degree geometric coverage for extended planning horizons. We validate Splatblox on a quadruped robot and demonstrate transfer to a wheeled platform. In field trials across vegetation-rich scenarios, it outperforms state-of-the-art methods with over 50% higher success rate, 40% fewer freezing incidents, 5% shorter paths, and up to 13% faster time to goal, while supporting long-range missions up to 100 meters. Experiment videos and more details can be found on our project page: https://splatblox.github.io

</details>


### [114] [Object-centric Task Representation and Transfer using Diffused Orientation Fields](https://arxiv.org/abs/2511.18563)
*Cem Bilaloglu,Tobias Löw,Sylvain Calinon*

Main category: cs.RO

TL;DR: 提出使用扩散方向场(DOF)来解决曲面物体上技能迁移的挑战，通过局部参考帧表示将任务迁移问题简化为稀疏关键点对应问题。


<details>
  <summary>Details</summary>
Motivation: 曲面物体缺乏全局参考框架，导致任务相关方向随位置和几何形状变化，使得面向物体的任务难以在不同形状间迁移。

Method: 使用扩散方向场(DOF)作为局部参考帧的平滑表示，通过受偏微分方程控制的扩散过程从原始点云数据在线计算，并基于关键点进行条件化。

Result: 在几何、拓扑和定位扰动下评估DOF，成功实现了需要连续物理交互的任务（如检查、切割和剥皮）在不同物体间的迁移。

Conclusion: DOF方法有效解决了曲面物体上技能迁移的根本挑战，将复杂任务迁移简化为建立稀疏关键点对应关系。

Abstract: Curved objects pose a fundamental challenge for skill transfer in robotics: unlike planar surfaces, they do not admit a global reference frame. As a result, task-relevant directions such as "toward" or "along" the surface vary with position and geometry, making object-centric tasks difficult to transfer across shapes. To address this, we introduce an approach using Diffused Orientation Fields (DOF), a smooth representation of local reference frames, for transfer learning of tasks across curved objects. By expressing manipulation tasks in these smoothly varying local frames, we reduce the problem of transferring tasks across curved objects to establishing sparse keypoint correspondences. DOF is computed online from raw point cloud data using diffusion processes governed by partial differential equations, conditioned on keypoints. We evaluate DOF under geometric, topological, and localization perturbations, and demonstrate successful transfer of tasks requiring continuous physical interaction such as inspection, slicing, and peeling across varied objects. We provide our open-source codes at our website https://github.com/idiap/diffused_fields_robotics

</details>


### [115] [An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms](https://arxiv.org/abs/2511.18604)
*Hannah Lee,James D. Motes,Marco Morales,Nancy M. Amato*

Main category: cs.RO

TL;DR: 该研究通过基于约束分类指导约束搜索算法的选择，为多智能体路径规划(MAPF)和多机器人运动规划(MRMP)算法设计提供指导。研究将约束分为保守型和激进型，分析其搜索行为，特别关注CBS和CBSw/P算法。


<details>
  <summary>Details</summary>
Motivation: 为未来的MAPF和MRMP算法设计提供指导，帮助用户基于约束分类选择合适的算法，考虑拓扑特征与问题、解决方案和表示特征的结合。

Method: 使用混合网格-路线图表示方法，在不同分辨率下比较保守型(运动约束)和激进型(优先级约束)约束的搜索行为，重点关注CBS和CBSw/P算法。

Result: 研究发现激进型(优先级约束)在智能体数量或分辨率增加时能解决更多实例，而保守型(运动约束)在两者都成功时能提供更强的解决方案质量。

Conclusion: 研究提供了决策流程图帮助用户选择合适的约束，并强调在MRMP中考虑拓扑特征的重要性。所有原始数据和地图性能数据可在GitHub仓库中获取。

Abstract: This study informs the design of future multi-agent pathfinding (MAPF) and multi-robot motion planning (MRMP) algorithms by guiding choices based on constraint classification for constraint-based search algorithms. We categorize constraints as conservative or aggressive and provide insights into their search behavior, focusing specifically on vanilla Conflict-Based Search (CBS) and Conflict-Based Search with Priorities (CBSw/P). Under a hybrid grid-roadmap representation with varying resolution, we observe that aggressive (priority constraint) formulations tend to solve more instances as agent count or resolution increases, whereas conservative (motion constraint) formulations yield stronger solution quality when both succeed. Findings are synthesized in a decision flowchart, aiding users in selecting suitable constraints. Recommendations extend to Multi-Robot Motion Planning (MRMP), emphasizing the importance of considering topological features alongside problem, solution, and representation features. A comprehensive exploration of the study, including raw data and map performance, is available in our public GitHub Repository: https://GitHub.com/hannahjmlee/constraint-mapf-analysis

</details>


### [116] [How to Train Your Latent Control Barrier Function: Smooth Safety Filtering Under Hard-to-Model Constraints](https://arxiv.org/abs/2511.18606)
*Kensuke Nakamura,Arun L. Bishop,Steven Man,Aaron M. Johnson,Zachary Manchester,Andrea Bajcsy*

Main category: cs.RO

TL;DR: LatentCBF提出了一种基于控制障碍函数的平滑安全过滤方法，解决了现有潜在安全过滤器在名义策略和安全策略之间离散切换的问题，通过梯度惩罚和混合数据训练实现了更好的任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有潜在安全过滤器采用"最小限制"过滤，在名义策略和安全策略之间进行离散切换，这会损害现代视觉运动策略的任务性能。虽然可达性值函数理论上可以适配为控制障碍函数进行平滑过滤，但当前潜在空间学习方法产生的值函数存在不兼容问题。

Method: 提出LatentCBF方法：1）使用梯度惩罚获得平滑的边界函数，无需额外标注；2）采用混合数据训练程序，同时使用名义策略和安全策略分布的数据进行值函数训练。

Result: 在模拟基准测试和硬件实验中，LatentCBF实现了平滑的安全过滤，相比之前的切换方法将任务完成率提高了一倍。

Conclusion: LatentCBF成功解决了潜在安全过滤器中的值函数不兼容问题，通过平滑的边界函数和混合数据训练，实现了既安全又高效的控制性能。

Abstract: Latent safety filters extend Hamilton-Jacobi (HJ) reachability to operate on latent state representations and dynamics learned directly from high-dimensional observations, enabling safe visuomotor control under hard-to-model constraints. However, existing methods implement "least-restrictive" filtering that discretely switch between nominal and safety policies, potentially undermining the task performance that makes modern visuomotor policies valuable. While reachability value functions can, in principle, be adapted to be control barrier functions (CBFs) for smooth optimization-based filtering, we theoretically and empirically show that current latent-space learning methods produce fundamentally incompatible value functions. We identify two sources of incompatibility: First, in HJ reachability, failures are encoded via a "margin function" in latent space, whose sign indicates whether or not a latent is in the constraint set. However, representing the margin function as a classifier yields saturated value functions that exhibit discontinuous jumps. We prove that the value function's Lipschitz constant scales linearly with the margin function's Lipschitz constant, revealing that smooth CBFs require smooth margins. Second, reinforcement learning (RL) approximations trained solely on safety policy data yield inaccurate value estimates for nominal policy actions, precisely where CBF filtering needs them. We propose the LatentCBF, which addresses both challenges through gradient penalties that lead to smooth margin functions without additional labeling, and a value-training procedure that mixes data from both nominal and safety policy distributions. Experiments on simulated benchmarks and hardware with a vision-based manipulation policy demonstrate that LatentCBF enables smooth safety filtering while doubling the task-completion rate over prior switching methods.

</details>


### [117] [AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations](https://arxiv.org/abs/2511.18617)
*Litian Gong,Fatemeh Bahrani,Yutai Zhou,Amin Banayeeanzade,Jiachen Li,Erdem Biyik*

Main category: cs.RO

TL;DR: AutoFocus-IL是一种通过视觉语言模型自动生成时间显著性图来改进视觉模仿学习的方法，无需昂贵的人工监督即可让策略关注任务相关特征，在CARLA仿真和真实机器人任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于显著性正则化的方法需要昂贵的人工监督（如人类注视数据或手动标注），限制了其实际应用。

Method: 利用视觉语言模型自动识别和跟踪演示中的关键物体，生成时间显著性图来突出因果视觉信号并抑制干扰物，然后用这些图来正则化行为克隆策略。

Result: 在CARLA仿真和真实机器人操作任务中，AutoFocus-IL不仅优于标准行为克隆，还超越了需要人类监督的最先进基线方法。

Conclusion: AutoFocus-IL提供了一种无需昂贵人工监督的有效方法，能显著提高视觉模仿学习的数据效率和泛化能力。

Abstract: AutoFocus-IL is a simple yet effective method to improve data efficiency and generalization in visual imitation learning by guiding policies to attend to task-relevant features rather than distractors and spurious correlations. Although saliency regularization has emerged as a promising way to achieve this, existing approaches typically require costly supervision such as human gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages vision-language models (VLMs) to automatically identify and track key objects in demonstrations, generating temporal saliency maps that highlight causal visual signals while suppressing distractors. These maps are then used to regularize behavior cloning policies, yielding stronger alignment between visual attention and task-relevant cues. Experiments in both the CARLA simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not only outperforms standard behavior cloning but also surpasses state-of-the-art baselines that assume privileged access to human supervision, such as gaze data. Code, datasets, and trained policy videos are available at https://AutoFocus-IL.github.io/.

</details>


### [118] [Online Learning-Enhanced Lie Algebraic MPC for Robust Trajectory Tracking of Autonomous Surface Vehicles](https://arxiv.org/abs/2511.18683)
*Yinan Dong,Ziyu Xu,Tsimafei Lazouski,Sangli Teng,Maani Ghaffari*

Main category: cs.RO

TL;DR: 提出了一种结合李群上凸误差状态MPC和在线学习模块的高效控制器，用于在未知扰动下实现海洋车辆轨迹跟踪


<details>
  <summary>Details</summary>
Motivation: 自主水面车辆(ASV)容易受到风浪等环境扰动影响，在动态海洋条件下实现精确轨迹跟踪是一个持续挑战

Method: 将李群上的凸误差状态模型预测控制(MPC)与在线学习模块相结合，实时补偿未知扰动

Result: 在数值模拟、VRX仿真器和真实世界现场实验中的广泛评估表明，该方法在各种扰动场景下相比现有方法实现了更优越的跟踪精度

Conclusion: 该设计能够在保持计算效率的同时实现自适应和鲁棒控制

Abstract: Autonomous surface vehicles (ASVs) are easily influenced by environmental disturbances such as wind and waves, making accurate trajectory tracking a persistent challenge in dynamic marine conditions. In this paper, we propose an efficient controller for trajectory tracking of marine vehicles under unknown disturbances by combining a convex error-state MPC on the Lie group with an online learning module to compensate for these disturbances in real time. This design enables adaptive and robust control while maintaining computational efficiency. Extensive evaluations in numerical simulations, the Virtual RobotX (VRX) simulator, and real-world field experiments demonstrate that our method achieves superior tracking accuracy under various disturbance scenarios compared with existing approaches.

</details>


### [119] [Stable Multi-Drone GNSS Tracking System for Marine Robots](https://arxiv.org/abs/2511.18694)
*Shuo Wen,Edwin Meriaux,Mariana Sosa Guzmán,Zhizun Wang,Junming Shi,Gregory Dudek*

Main category: cs.RO

TL;DR: 提出了一种基于多无人机GNSS的海洋机器人跟踪系统，通过视觉检测、多目标跟踪和三角定位，为水面和近水面机器人提供实时稳定的GNSS估计。


<details>
  <summary>Details</summary>
Motivation: 解决水下GNSS信号不可靠的问题，传统方法存在误差累积、计算量大或依赖基础设施的局限性。

Method: 结合高效视觉检测、轻量级多目标跟踪、GNSS三角定位和置信度加权扩展卡尔曼滤波，并引入跨无人机跟踪ID对齐算法确保全局一致性。

Result: 在多样化复杂环境中验证了系统的可扩展性和鲁棒性。

Conclusion: 该系统能够为海洋机器人提供可靠的位置估计，解决了水下定位的挑战。

Abstract: Accurate localization is essential for marine robotics, yet Global Navigation Satellite System (GNSS) signals are unreliable or unavailable even at a very short distance below the water surface. Traditional alternatives, such as inertial navigation, Doppler Velocity Loggers (DVL), SLAM, and acoustic methods, suffer from error accumulation, high computational demands, or infrastructure dependence. In this work, we present a scalable multi-drone GNSS-based tracking system for surface and near-surface marine robots. Our approach combines efficient visual detection, lightweight multi-object tracking, GNSS-based triangulation, and a confidence-weighted Extended Kalman Filter (EKF) to provide stable GNSS estimation in real time. We further introduce a cross-drone tracking ID alignment algorithm that enforces global consistency across views, enabling robust multi-robot tracking with redundant aerial coverage. We validate our system in diversified complex settings to show the scalability and robustness of the proposed algorithm.

</details>


### [120] [CNN-Based Camera Pose Estimation and Localisation of Scan Images for Aircraft Visual Inspection](https://arxiv.org/abs/2511.18702)
*Xueyan Oh,Leonard Loh,Shaohui Foong,Zhong Bao Andy Koh,Kow Leong Ng,Poh Kang Tan,Pei Lin Pearlin Toh,U-Xuan Tan*

Main category: cs.RO

TL;DR: 提出一种无需基础设施的现场方法，用于估计PTZ相机姿态并定位扫描图像，通过仅使用合成图像微调的深度卷积神经网络来预测相机姿态，在真实飞机上实现了小于0.24米和2度的RMS姿态估计误差。


<details>
  <summary>Details</summary>
Motivation: 自动化飞机外部目视检查过程，减少对人工的依赖，同时克服在不受控的室外环境和有限周转时间内基础设施部署的挑战，以及航空公司对接触飞机表面和使用无人机的限制。

Method: 使用仅基于合成图像微调的深度卷积神经网络预测PTZ相机自身姿态，应用领域随机化生成训练数据集，并利用飞机几何改进损失函数，提出包括初始化、扫描路径规划和图像精确定位的工作流程。

Result: 在真实飞机场景中，所有场景的相机姿态估计均方根误差均小于0.24米和2度。

Conclusion: 该方法实现了基础设施自由、易于部署的飞机检查系统，能够在机场停机坪的有限时间内准确估计相机姿态并定位扫描图像。

Abstract: General Visual Inspection is a manual inspection process regularly used to detect and localise obvious damage on the exterior of commercial aircraft. There has been increasing demand to perform this process at the boarding gate to minimise the downtime of the aircraft and automating this process is desired to reduce the reliance on human labour. Automating this typically requires estimating a camera's pose with respect to the aircraft for initialisation but most existing localisation methods require infrastructure, which is very challenging in uncontrolled outdoor environments and within the limited turnover time (approximately 2 hours) on an airport tarmac. Additionally, many airlines and airports do not allow contact with the aircraft's surface or using UAVs for inspection between flights, and restrict access to commercial aircraft. Hence, this paper proposes an on-site method that is infrastructure-free and easy to deploy for estimating a pan-tilt-zoom camera's pose and localising scan images. This method initialises using the same pan-tilt-zoom camera used for the inspection task by utilising a Deep Convolutional Neural Network fine-tuned on only synthetic images to predict its own pose. We apply domain randomisation to generate the dataset for fine-tuning the network and modify its loss function by leveraging aircraft geometry to improve accuracy. We also propose a workflow for initialisation, scan path planning, and precise localisation of images captured from a pan-tilt-zoom camera. We evaluate and demonstrate our approach through experiments with real aircraft, achieving root-mean-square camera pose estimation errors of less than 0.24 m and 2 degrees for all real scenes.

</details>


### [121] [Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication](https://arxiv.org/abs/2511.18703)
*Ardalan Tajbakhsh,Augustinos Saravanos,James Zhu,Evangelos A. Theodorou,Lorenz T. Biegler,Aaron M. Johnson*

Main category: cs.RO

TL;DR: 提出了一种延迟感知ADMM（DA-ADMM）算法，通过基于实时延迟统计调整惩罚参数，在多机器人系统中有效处理通信延迟问题，显著提升了运动规划的鲁棒性和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在实际通信延迟下的协调问题，传统ADMM算法对惩罚参数调优敏感，且现有自适应方法未显式考虑延迟影响。

Method: 开发了延迟感知ADMM变体，根据实时延迟统计调整惩罚参数，使智能体能够降低陈旧信息的权重，在共识和双重更新中优先处理最新更新。

Result: 在2D和3D环境中对双积分器、Dubins-car和无人机动力学进行广泛仿真，DA-ADMM相比固定参数、残差平衡和固定约束基线方法，显著提高了鲁棒性、成功率和解决方案质量。

Conclusion: 性能下降不仅由延迟长度或频率决定，还取决于优化器对延迟信息的上下文推理能力。DA-ADMM在各种延迟条件下实现了一致的更好协调性能，为不完美通信下的弹性多机器人运动规划提供了原则性高效机制。

Abstract: This paper addresses the challenge of coordinating multi-robot systems under realistic communication delays using distributed optimization. We focus on consensus ADMM as a scalable framework for generating collision-free, dynamically feasible motion plans in both trajectory optimization and receding-horizon control settings. In practice, however, these algorithms are sensitive to penalty tuning or adaptation schemes (e.g. residual balancing and adaptive parameter heuristics) that do not explicitly consider delays. To address this, we introduce a Delay-Aware ADMM (DA-ADMM) variant that adapts penalty parameters based on real-time delay statistics, allowing agents to down-weight stale information and prioritize recent updates during consensus and dual updates. Through extensive simulations in 2D and 3D environments with double-integrator, Dubins-car, and drone dynamics, we show that DA-ADMM significantly improves robustness, success rate, and solution quality compared to fixed-parameter, residual-balancing, and fixed-constraint baselines. Our results highlight that performance degradation is not solely determined by delay length or frequency, but by the optimizer's ability to contextually reason over delayed information. The proposed DA-ADMM achieves consistently better coordination performance across a wide range of delay conditions, offering a principled and efficient mechanism for resilient multi-robot motion planning under imperfect communication.

</details>


### [122] [GVD-TG: Topological Graph based on Fast Hierarchical GVD Sampling for Robot Exploration](https://arxiv.org/abs/2511.18708)
*Yanbin Li,Canran Xiao,Shenghai Yuan,Peilai Yu,Ziruo Li,Zhiguo Zhang,Wenzheng Chi,Wei Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于广义Voronoi图(GVD)的拓扑地图更新方法，通过多粒度分层GVD生成、节点聚类与连通性约束、基于形态学膨胀的前沿提取等技术，实现实时、准确的环境拓扑地图构建，提高机器人探索效率。


<details>
  <summary>Details</summary>
Motivation: 实时更新准确且细节丰富的环境拓扑地图在机器人探索任务中仍然是一个挑战，需要解决GVD节点误导拓扑结构、路径回溯、不可达节点生成等问题。

Method: 1) 对新观测区域去噪；2) 多粒度分层GVD生成方法控制采样粒度；3) 带连通性约束的节点聚类和基于切换机制的连通方法；4) 基于形态学膨胀的前沿提取方法；5) 轻量级成本函数实时评估和切换下一个视点。

Result: 通过对比测试验证了系统在探索任务中的性能优于SOTA方法，提高了拓扑结构准确性、细节特征捕捉能力，减少了路径回溯概率，提升了探索效率。

Conclusion: 该方法能够有效构建实时更新的拓扑地图，提高机器人探索的灵活性和效率，特别是在出现路径回溯迹象时能快速调整策略。

Abstract: Topological maps are more suitable than metric maps for robotic exploration tasks. However, real-time updating of accurate and detail-rich environmental topological maps remains a challenge. This paper presents a topological map updating method based on the Generalized Voronoi Diagram (GVD). First, the newly observed areas are denoised to avoid low-efficiency GVD nodes misleading the topological structure. Subsequently, a multi-granularity hierarchical GVD generation method is designed to control the sampling granularity at both global and local levels. This not only ensures the accuracy of the topological structure but also enhances the ability to capture detail features, reduces the probability of path backtracking, and ensures no overlap between GVDs through the maintenance of a coverage map, thereby improving GVD utilization efficiency. Second, a node clustering method with connectivity constraints and a connectivity method based on a switching mechanism are designed to avoid the generation of unreachable nodes and erroneous nodes caused by obstacle attraction. A special cache structure is used to store all connectivity information, thereby improving exploration efficiency. Finally, to address the issue of frontiers misjudgment caused by obstacles within the scope of GVD units, a frontiers extraction method based on morphological dilation is designed to effectively ensure the reachability of frontiers. On this basis, a lightweight cost function is used to assess and switch to the next viewpoint in real time. This allows the robot to quickly adjust its strategy when signs of path backtracking appear, thereby escaping the predicament and increasing exploration flexibility. And the performance of system for exploration task is verified through comparative tests with SOTA methods.

</details>


### [123] [Autonomous Surface Selection For Manipulator-Based UV Disinfection In Hospitals Using Foundation Models](https://arxiv.org/abs/2511.18709)
*Xueyan Oh,Jonathan Her,Zhixiang Ong,Brandon Koh,Yun Hann Tan,U-Xuan Tan*

Main category: cs.RO

TL;DR: 提出了一种基于基础模型的紫外线消毒表面选择方法，无需模型训练，通过VLM辅助分割细化减少误分割错误，在真实环境中验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 传统紫外线消毒方法需要大量人工干预定义消毒区域，而基于深度学习的方法需要大量微调和数据集，且缺乏对部分表面消毒的场景理解能力。

Method: 利用基础模型简化机械臂紫外线消毒的表面选择，减少人工参与，无需模型训练；采用VLM辅助分割细化来检测和排除细小非目标物体。

Result: 目标和非目标表面正确分割成功率超过92%，真实机械臂和模拟紫外线实验证明了其实际应用潜力。

Conclusion: 该方法有效解决了紫外线消毒自动化中的表面选择问题，减少了人工干预和模型训练需求，具有实际部署的可行性。

Abstract: Ultraviolet (UV) germicidal radiation is an established non-contact method for surface disinfection in medical environments. Traditional approaches require substantial human intervention to define disinfection areas, complicating automation, while deep learning-based methods often need extensive fine-tuning and large datasets, which can be impractical for large-scale deployment. Additionally, these methods often do not address scene understanding for partial surface disinfection, which is crucial for avoiding unintended UV exposure. We propose a solution that leverages foundation models to simplify surface selection for manipulator-based UV disinfection, reducing human involvement and removing the need for model training. Additionally, we propose a VLM-assisted segmentation refinement to detect and exclude thin and small non-target objects, showing that this reduces mis-segmentation errors. Our approach achieves over 92\% success rate in correctly segmenting target and non-target surfaces, and real-world experiments with a manipulator and simulated UV light demonstrate its practical potential for real-world applications.

</details>


### [124] [Head Stabilization for Wheeled Bipedal Robots via Force-Estimation-Based Admittance Control](https://arxiv.org/abs/2511.18712)
*Tianyu Wang,Chunxiang Yan,Xuanhong Liao,Tao Zhang,Ping Wang,Cong Wen,Dingchuan Liu,Haowen Yu,Ximin Lyu*

Main category: cs.RO

TL;DR: 开发了一种基于模型的地面力估计方法和导纳控制算法，用于提高轮式双足机器人在不平坦地形上的头部稳定性。


<details>
  <summary>Details</summary>
Motivation: 轮式双足机器人作为灵活的现场探索平台，但在不平坦地形上头部不稳定会降低传感器精度或损坏有效载荷。现有研究主要关注平台稳定而忽略了世界坐标系中的头部主动稳定。

Method: 为6自由度轮式双足机器人开发了基于模型的地面力估计方法，并利用力估计实现导纳控制算法以增强地形适应性。

Result: 仿真实验验证了力估计器的实时性能和机器人在不平坦地形穿越时的鲁棒性。

Conclusion: 所提出的方法能有效解决轮式双足机器人在不平坦地形上的头部稳定问题，提高整体稳定性。

Abstract: Wheeled bipedal robots are emerging as flexible platforms for field exploration. However, head instability induced by uneven terrain can degrade the accuracy of onboard sensors or damage fragile payloads. Existing research primarily focuses on stabilizing the mobile platform but overlooks active stabilization of the head in the world frame, resulting in vertical oscillations that undermine overall stability. To address this challenge, we developed a model-based ground force estimation method for our 6-degree-of-freedom wheeled bipedal robot. Leveraging these force estimates, we implemented an admittance control algorithm to enhance terrain adaptability. Simulation experiments validated the real-time performance of the force estimator and the robot's robustness when traversing uneven terrain.

</details>


### [125] [AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation](https://arxiv.org/abs/2511.18718)
*Omar Garib,Jayaprakash D. Kambhampaty,Olivia J. Pinon Fischer,Dimitri N. Mavris*

Main category: cs.RO

TL;DR: AIRHILT是一个基于Godot引擎的轻量级模拟环境，用于评估航空冲突检测中的多模态飞行员和空管辅助系统，支持人机交互和标准化接口。


<details>
  <summary>Details</summary>
Motivation: 需要统一的平台来评估航空冲突检测中的多模态辅助系统，整合无线电通信、视觉场景理解和ADS-B监视数据。

Method: 基于开源Godot引擎构建，同步飞行员和空管无线电通信、摄像头流视觉理解和ADS-B数据，提供标准化JSON接口集成ASR、视觉检测、决策和TTS模型。

Result: 在代表性跑道重叠场景中，辅助系统平均首次警告时间为7.7秒，ASR和视觉延迟分别为5.9秒和0.4秒。

Conclusion: AIRHILT为航空多模态态势感知和冲突检测提供了可复现的研究环境，代码和场景已开源。

Abstract: We introduce AIRHILT (Aviation Integrated Reasoning, Human-in-the-Loop Testbed), a modular and lightweight simulation environment designed to evaluate multimodal pilot and air traffic control (ATC) assistance systems for aviation conflict detection. Built on the open-source Godot engine, AIRHILT synchronizes pilot and ATC radio communications, visual scene understanding from camera streams, and ADS-B surveillance data within a unified, scalable platform. The environment supports pilot- and controller-in-the-loop interactions, providing a comprehensive scenario suite covering both terminal area and en route operational conflicts, including communication errors and procedural mistakes. AIRHILT offers standardized JSON-based interfaces that enable researchers to easily integrate, swap, and evaluate automatic speech recognition (ASR), visual detection, decision-making, and text-to-speech (TTS) models. We demonstrate AIRHILT through a reference pipeline incorporating fine-tuned Whisper ASR, YOLO-based visual detection, ADS-B-based conflict logic, and GPT-OSS-20B structured reasoning, and present preliminary results from representative runway-overlap scenarios, where the assistant achieves an average time-to-first-warning of approximately 7.7 s, with average ASR and vision latencies of approximately 5.9 s and 0.4 s, respectively. The AIRHILT environment and scenario suite are openly available, supporting reproducible research on multimodal situational awareness and conflict detection in aviation; code and scenarios are available at https://github.com/ogarib3/airhilt.

</details>


### [126] [SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map](https://arxiv.org/abs/2511.18756)
*Xueyu Du,Lilian Zhang,Fuan Duan,Xincan Luo,Maosong Wang,Wenqi Wu,JunMao*

Main category: cs.RO

TL;DR: 提出了一种基于滤波器的立体视觉惯性导航系统SP-VINS，通过隐式环境地图实现高效闭环约束，结合混合残差滤波框架和在线外参标定，在保持高计算效率的同时实现长期高精度定位。


<details>
  <summary>Details</summary>
Motivation: 基于滤波器的VINS在精度和效率之间取得了良好平衡，但其有限的建图质量限制了长期高精度状态估计能力。

Method: 1) 提出基于关键帧和2D关键点的隐式环境地图实现高效闭环约束；2) 设计结合地标重投影和射线约束的混合残差滤波框架；3) 将相机-IMU外参融入视觉描述实现在线标定。

Result: 基准测试表明SP-VINS在保持高计算效率的同时实现了长期高精度定位性能，优于现有最先进方法。

Conclusion: 所提出的SP-VINS系统在滤波框架下实现了类似SLAM的建图能力，为移动机器人提供了高效且准确的长期定位解决方案。

Abstract: Filter-based visual inertial navigation system (VINS) has attracted mobile-robot researchers for the good balance between accuracy and efficiency, but its limited mapping quality hampers long-term high-accuracy state estimation. To this end, we first propose a novel filter-based stereo VINS, differing from traditional simultaneous localization and mapping (SLAM) systems based on 3D map, which performs efficient loop closure constraints with implicit environmental map composed of keyframes and 2D keypoints. Secondly, we proposed a hybrid residual filter framework that combines landmark reprojection and ray constraints to construct a unified Jacobian matrix for measurement updates. Finally, considering the degraded environment, we incorporated the camera-IMU extrinsic parameters into visual description to achieve online calibration. Benchmark experiments demonstrate that the proposed SP-VINS achieves high computational efficiency while maintaining long-term high-accuracy localization performance, and is superior to existing state-of-the-art (SOTA) methods.

</details>


### [127] [MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent](https://arxiv.org/abs/2511.18810)
*Yuxia Fu,Zhizhen Zhang,Yuqi Zhang,Zijian Wang,Zi Huang,Yadan Luo*

Main category: cs.RO

TL;DR: MergeVLA是一个可合并的视觉-语言-动作模型架构，通过稀疏激活的LoRA适配器和仅交叉注意力块设计，解决了多技能VLA模型合并时性能下降的问题，实现了跨任务、具身和环境的稳健泛化。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在单一任务上表现良好，但在多技能设置中直接合并专家模型会导致性能急剧下降。这引发了一个基本问题：什么阻止了VLA在一个模型中掌握多种技能？

Method: 提出MergeVLA架构：1) 使用任务掩码的稀疏激活LoRA适配器保持参数一致性；2) 用仅交叉注意力块替换自注意力，使专业化保持局部化和可组合；3) 测试时任务路由器根据初始观察自适应选择任务掩码和专家头。

Result: 在LIBERO、LIBERO-Plus、RoboTwin和真实SO101机械臂上的多任务实验中，MergeVLA实现了与单独微调专家相当甚至更好的性能，展示了跨任务、具身和环境的稳健泛化能力。

Conclusion: MergeVLA通过架构设计保留了可合并性，成功解决了VLA模型在多技能设置中的合并挑战，为构建通用多技能机器人模型提供了可行方案。

Abstract: Recent Vision-Language-Action (VLA) models reformulate vision-language models by tuning them with millions of robotic demonstrations. While they perform well when fine-tuned for a single embodiment or task family, extending them to multi-skill settings remains challenging: directly merging VLA experts trained on different tasks results in near-zero success rates. This raises a fundamental question: what prevents VLAs from mastering multiple skills within one model? With an empirical decomposition of learnable parameters during VLA fine-tuning, we identify two key sources of non-mergeability: (1) Finetuning drives LoRA adapters in the VLM backbone toward divergent, task-specific directions beyond the capacity of existing merging methods to unify. (2) Action experts develop inter-block dependencies through self-attention feedback, causing task information to spread across layers and preventing modular recombination. To address these challenges, we present MergeVLA, a merging-oriented VLA architecture that preserves mergeability by design. MergeVLA introduces sparsely activated LoRA adapters via task masks to retain consistent parameters and reduce irreconcilable conflicts in the VLM. Its action expert replaces self-attention with cross-attention-only blocks to keep specialization localized and composable. When the task is unknown, it uses a test-time task router to adaptively select the appropriate task mask and expert head from the initial observation, enabling unsupervised task inference. Across LIBERO, LIBERO-Plus, RoboTwin, and multi-task experiments on the real SO101 robotic arm, MergeVLA achieves performance comparable to or even exceeding individually finetuned experts, demonstrating robust generalization across tasks, embodiments, and environments.

</details>


### [128] [AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion](https://arxiv.org/abs/2511.18857)
*Changsheng Luo,Yushi Wang,Wenhan Cai,Mingguo Zhao*

Main category: cs.RO

TL;DR: AutoOdom是一种新型自回归本体感知里程计系统，通过两阶段训练范式解决足式机器人在GPS缺失和视觉退化环境中的定位问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决足式机器人在GPS缺失和视觉退化环境中的精确定位问题，克服传统视觉里程计失效以及现有方法在建模不确定性、累积漂移、仿真到现实迁移等方面的局限性。

Method: 采用两阶段训练范式：第一阶段使用大规模仿真数据学习足式运动的复杂非线性动力学和快速变化的接触状态；第二阶段使用有限真实世界数据引入自回归增强机制，通过模型从自身预测中学习来弥合仿真到现实的差距。

Result: 在Booster T1人形机器人上的实验验证显示，相比Legolas基线，AutoOdom在绝对轨迹误差上提升57.2%，在Umeyama对齐误差上提升59.2%，在相对位姿误差上提升36.2%。

Conclusion: AutoOdom通过创新的自回归训练方法有效解决了本体感知里程计的关键挑战，在动态环境中表现出卓越的鲁棒性和准确性，为足式机器人在挑战性环境中的导航提供了可靠解决方案。

Abstract: Accurate proprioceptive odometry is fundamental for legged robot navigation in GPS-denied and visually degraded environments where conventional visual odometry systems fail. Current approaches face critical limitations: analytical filtering methods suffer from modeling uncertainties and cumulative drift, hybrid learning-filtering approaches remain constrained by their analytical components, while pure learning-based methods struggle with simulation-to-reality transfer and demand extensive real-world data collection. This paper introduces AutoOdom, a novel autoregressive proprioceptive odometry system that overcomes these challenges through an innovative two-stage training paradigm. Stage 1 employs large-scale simulation data to learn complex nonlinear dynamics and rapidly changing contact states inherent in legged locomotion, while Stage 2 introduces an autoregressive enhancement mechanism using limited real-world data to effectively bridge the sim-to-real gap. The key innovation lies in our autoregressive training approach, where the model learns from its own predictions to develop resilience against sensor noise and improve robustness in highly dynamic environments. Comprehensive experimental validation on the Booster T1 humanoid robot demonstrates that AutoOdom significantly outperforms state-of-the-art methods across all evaluation metrics, achieving 57.2% improvement in absolute trajectory error, 59.2% improvement in Umeyama-aligned error, and 36.2% improvement in relative pose error compared to the Legolas baseline. Extensive ablation studies provide critical insights into sensor modality selection and temporal modeling, revealing counterintuitive findings about IMU acceleration data and validating our systematic design choices for robust proprioceptive odometry in challenging locomotion scenarios.

</details>


### [129] [Accelerating Reinforcement Learning via Error-Related Human Brain Signals](https://arxiv.org/abs/2511.18878)
*Suzie Kim,Hye-Bin Shin,Hyo-Jeong Jang*

Main category: cs.RO

TL;DR: 研究探索如何利用隐式神经反馈加速复杂机器人操作任务中的强化学习，通过EEG解码的错误相关电位进行奖励塑形，在7自由度机械臂障碍环境中验证了该方法能加速学习并提高成功率。


<details>
  <summary>Details</summary>
Motivation: 先前基于脑电图（EEG）的强化学习研究主要关注导航或低维运动任务，本研究旨在探索神经评估信号是否能在涉及障碍物和精确末端执行器控制的高维操作任务中改进策略学习。

Method: 将离线训练的EEG分类器解码的错误相关电位整合到奖励塑形中，系统评估人类反馈权重的影响，在7自由度机械臂的障碍丰富环境中进行实验。

Result: 神经反馈加速了强化学习，根据人类反馈权重的不同，任务成功率有时超过稀疏奖励基线。最佳反馈权重在所有受试者中一致加速了强化学习，留一受试者验证表明框架对EEG解码能力的个体差异具有鲁棒性。

Conclusion: 基于EEG的强化学习可以扩展到运动任务之外，为人类对齐的操作技能获取提供了可行途径。

Abstract: In this work, we investigate how implicit neural feed back can accelerate reinforcement learning in complex robotic manipulation settings. While prior electroencephalogram (EEG) guided reinforcement learning studies have primarily focused on navigation or low-dimensional locomotion tasks, we aim to understand whether such neural evaluative signals can improve policy learning in high-dimensional manipulation tasks involving obstacles and precise end-effector control. We integrate error related potentials decoded from offline-trained EEG classifiers into reward shaping and systematically evaluate the impact of human-feedback weighting. Experiments on a 7-DoF manipulator in an obstacle-rich reaching environment show that neural feedback accelerates reinforcement learning and, depending on the human-feedback weighting, can yield task success rates that at times exceed those of sparse-reward baselines. Moreover, when applying the best-performing feedback weighting across all sub jects, we observe consistent acceleration of reinforcement learning relative to the sparse-reward setting. Furthermore, leave-one subject-out evaluations confirm that the proposed framework remains robust despite the intrinsic inter-individual variability in EEG decodability. Our findings demonstrate that EEG-based reinforcement learning can scale beyond locomotion tasks and provide a viable pathway for human-aligned manipulation skill acquisition.

</details>


### [130] [An Efficient Closed-Form Solution to Full Visual-Inertial State Initialization](https://arxiv.org/abs/2511.18910)
*Samuel Cerezo,Seong Hun Lee,Javier Civera*

Main category: cs.RO

TL;DR: 提出了一种闭式初始化方法，无需非线性优化即可恢复完整的视觉-惯性状态，相比基于优化的方法具有更低的初始化误差、更短的初始化窗口和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖迭代求解器，需要非线性优化，计算成本高且初始化延迟长。需要一种解析、易实现且数值稳定的初始化方法来实现可靠启动。

Method: 基于小旋转和恒定速度近似，保持公式紧凑同时保留运动与惯性测量之间的基本耦合。提出可观测性驱动的两阶段初始化方案，平衡精度与初始化延迟。

Result: 在EuRoC数据集上的实验验证：相比基于优化的方法，初始化误差降低10-20%，初始化窗口缩短4倍，计算成本降低5倍。

Conclusion: 该方法提供了解析、易实现且数值稳定的解决方案，在精度和效率方面均优于现有优化方法，适用于视觉-惯性系统的可靠启动。

Abstract: In this letter, we present a closed-form initialization method that recovers the full visual-inertial state without nonlinear optimization. Unlike previous approaches that rely on iterative solvers, our formulation yields analytical, easy-to-implement, and numerically stable solutions for reliable start-up. Our method builds on small-rotation and constant-velocity approximations, which keep the formulation compact while preserving the essential coupling between motion and inertial measurements. We further propose an observability-driven, two-stage initialization scheme that balances accuracy with initialization latency. Extensive experiments on the EuRoC dataset validate our assumptions: our method achieves 10-20% lower initialization error than optimization-based approaches, while using 4x shorter initialization windows and reducing computational cost by 5x.

</details>


### [131] [Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation](https://arxiv.org/abs/2511.18950)
*Juntao Gao,Feiyang Ye,Jing Zhang,Wenjing Qian*

Main category: cs.RO

TL;DR: 提出了Compressor-VLA框架，通过语义任务压缩器和空间细化压缩器实现视觉语言动作模型的高效任务导向压缩，在保持性能的同时显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 视觉语言动作模型在具身AI中计算开销大，现有任务无关的token剪枝方法难以保留任务关键视觉信息，需要同时保持整体上下文和细粒度细节以实现精确动作。

Method: 提出混合指令条件token压缩框架，包含语义任务压缩器（提取整体任务相关上下文）和空间细化压缩器（保留细粒度空间细节），通过自然语言指令动态调节压缩过程。

Result: 在LIBERO基准测试中达到竞争性成功率，FLOPs减少59%，视觉token数量减少3倍以上，真实机器人部署验证了模拟到现实的迁移性和实用性。

Conclusion: Compressor-VLA框架通过指令引导动态调整感知焦点到任务相关对象，实现了高效的任务导向视觉信息压缩，为实时机器人部署提供了可行方案。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful paradigm in Embodied AI. However, the significant computational overhead of processing redundant visual tokens remains a critical bottleneck for real-time robotic deployment. While standard token pruning techniques can alleviate this, these task-agnostic methods struggle to preserve task-critical visual information. To address this challenge, simultaneously preserving both the holistic context and fine-grained details for precise action, we propose Compressor-VLA, a novel hybrid instruction-conditioned token compression framework designed for efficient, task-oriented compression of visual information in VLA models. The proposed Compressor-VLA framework consists of two token compression modules: a Semantic Task Compressor (STC) that distills holistic, task-relevant context, and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial details. This compression is dynamically modulated by the natural language instruction, allowing for the adaptive condensation of task-relevant visual information. Experimentally, extensive evaluations demonstrate that Compressor-VLA achieves a competitive success rate on the LIBERO benchmark while reducing FLOPs by 59% and the visual token count by over 3x compared to its baseline. The real-robot deployments on a dual-arm robot platform validate the model's sim-to-real transferability and practical applicability. Moreover, qualitative analyses reveal that our instruction guidance dynamically steers the model's perceptual focus toward task-relevant objects, thereby validating the effectiveness of our approach.

</details>


### [132] [End-to-end Autonomous Vehicle Following System using Monocular Fisheye Camera](https://arxiv.org/abs/2511.19011)
*Jiale Zhang,Yeqiang Qian,Tong Qin,Mingyang Jiang,Siyuan Chen,Ming Yang*

Main category: cs.RO

TL;DR: 提出了一种仅使用摄像头的车辆跟随框架，通过端到端方法提升驾驶性能，解决了现有编队系统对车道线和昂贵传感器的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 车辆保有量增加导致交通拥堵、事故和碳排放问题加剧，车辆编队是解决这些问题的有前景方案，但现有系统依赖车道线和昂贵传感器，限制了通用性。

Method: 使用端到端方法，结合语义掩码解决多帧数据融合中的因果混淆问题，并引入动态采样机制精确跟踪前车轨迹。

Result: 在真实世界车辆实验中进行了广泛的闭环验证，证明系统能在各种场景下跟随车辆，性能优于传统多阶段算法。

Conclusion: 该系统是成本效益高的自动驾驶车辆编队的有前景解决方案，仅需摄像头即可实现通用场景应用。

Abstract: The increase in vehicle ownership has led to increased traffic congestion, more accidents, and higher carbon emissions. Vehicle platooning is a promising solution to address these issues by improving road capacity and reducing fuel consumption. However, existing platooning systems face challenges such as reliance on lane markings and expensive high-precision sensors, which limits their general applicability. To address these issues, we propose a vehicle following framework that expands its capability from restricted scenarios to general scenario applications using only a camera. This is achieved through our newly proposed end-to-end method, which improves overall driving performance. The method incorporates a semantic mask to address causal confusion in multi-frame data fusion. Additionally, we introduce a dynamic sampling mechanism to precisely track the trajectories of preceding vehicles. Extensive closed-loop validation in real-world vehicle experiments demonstrates the system's ability to follow vehicles in various scenarios, outperforming traditional multi-stage algorithms. This makes it a promising solution for cost-effective autonomous vehicle platooning. A complete real-world vehicle experiment is available at https://youtu.be/zL1bcVb9kqQ.

</details>


### [133] [Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors](https://arxiv.org/abs/2511.19031)
*Haihang Wu,Yuchen Zhou*

Main category: cs.RO

TL;DR: 提出了首个多智能体单目稠密SLAM系统，通过3D重建先验和基于闭环的地图融合机制，在保持精度的同时提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的单目SLAM系统虽然能生成详细的3D几何，但计算成本高，且MASt3R-SLAM仅限于单智能体操作。需要扩展到多智能体场景以实现更高效的协作建图。

Method: 每个智能体使用3D重建先验进行局部SLAM，通过基于闭环的地图融合机制将个体地图融合成全局一致的地图。

Result: 在真实世界数据集上的评估表明，该方法在保持相似建图精度的同时，相比最先进方法提高了计算效率。

Conclusion: 成功实现了首个多智能体单目稠密SLAM系统，证明了3D重建先验和地图融合机制在多智能体协作建图中的有效性。

Abstract: Monocular Simultaneous Localization and Mapping (SLAM) aims to estimate a robot's pose while simultaneously reconstructing an unknown 3D scene using a single camera. While existing monocular SLAM systems generate detailed 3D geometry through dense scene representations, they are computationally expensive due to the need for iterative optimization. To address this challenge, MASt3R-SLAM utilizes learned 3D reconstruction priors, enabling more efficient and accurate estimation of both 3D structures and camera poses. However, MASt3R-SLAM is limited to single-agent operation. In this paper, we extend MASt3R-SLAM to introduce the first multi-agent monocular dense SLAM system. Each agent performs local SLAM using a 3D reconstruction prior, and their individual maps are fused into a globally consistent map through a loop-closure-based map fusion mechanism. Our approach improves computational efficiency compared to state-of-the-art methods, while maintaining similar mapping accuracy when evaluated on real-world datasets.

</details>


### [134] [Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework](https://arxiv.org/abs/2511.19094)
*David Bricher,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出基于深度学习的人机安全框架(HRSF)，通过动态调整机器人速度来提升协作效率，相比传统安全技术可减少15%的周期时间。


<details>
  <summary>Details</summary>
Motivation: 当前符合ISO/TS-15066标准的协作机器人实现由于保守的速度限制，限制了协作任务的效率。

Method: 开发深度学习框架，使用四种人体提取方法（人体识别、人体分割、人体姿态估计、人体部位分割）来动态适应机器人速度，同时遵守最大生物力学力和压力限制。

Result: 实验显示相比传统安全技术，周期时间最多可减少15%。

Conclusion: 该框架能够区分人体部位与其他物体，实现优化的机器人流程执行，提高协作效率。

Abstract: Over the last years collaborative robots have gained great success in manufacturing applications where human and robot work together in close proximity. However, current ISO/TS-15066-compliant implementations often limit the efficiency of collaborative tasks due to conservative speed restrictions. For this reason, this paper introduces a deep-learning-based human-robot-safety framework (HRSF) that aims at a dynamical adaptation of robot velocities depending on the separation distance between human and robot while respecting maximum biomechanical force and pressure limits. The applicability of the framework was investigated for four different deep learning approaches that can be used for human body extraction: human body recognition, human body segmentation, human pose estimation, and human body part segmentation. Unlike conventional industrial safety systems, the proposed HRSF differentiates individual human body parts from other objects, enabling optimized robot process execution. Experiments demonstrated a quantitative reduction in cycle time of up to 15% compared to conventional safety technology.

</details>


### [135] [Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts](https://arxiv.org/abs/2511.19135)
*Pascal Goldschmid,Aamir Ahmad*

Main category: cs.RO

TL;DR: 提出了一种多旋翼无人机在飞艇上自主对接的方法，通过时间卷积网络预测飞艇对风阵风的响应，并结合模型预测控制器实现避障对接。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机受限于电池续航时间，通过在飞艇上进行自主对接可以实现电池充电和数据传输，从而延长任务时间。但飞艇易受风阵风影响导致轨迹偏差，需要精确的避障对接策略。

Method: 使用时间卷积网络预测飞艇对风阵风的响应，快速检测风阵风并估计风效应消退点；结合模型预测控制器计算无碰撞对接轨迹，采用新型近距离避障方法。

Result: 仿真结果表明该方法在不同场景下显著优于基线恒定速度模型；在真实世界实验中验证了首个在飞艇上的自主多旋翼对接控制策略。

Conclusion: 该方法成功实现了多旋翼无人机在飞艇上的自主对接，解决了风阵风影响下的精确对接问题，为延长无人机任务时间提供了可行方案。

Abstract: Multi-rotor UAVs face limited flight time due to battery constraints. Autonomous docking on blimps with onboard battery recharging and data offloading offers a promising solution for extended UAV missions. However, the vulnerability of blimps to wind gusts causes trajectory deviations, requiring precise, obstacle-aware docking strategies. To this end, this work introduces two key novelties: (i) a temporal convolutional network that predicts blimp responses to wind gusts, enabling rapid gust detection and estimation of points where the wind gust effect has subsided; (ii) a model predictive controller (MPC) that leverages these predictions to compute collision-free trajectories for docking, enabled by a novel obstacle avoidance method for close-range manoeuvres near the blimp. Simulation results show our method outperforms a baseline constant-velocity model of the blimp significantly across different scenarios. We further validate the approach in real-world experiments, demonstrating the first autonomous multi-rotor docking control strategy on blimps shown outside simulation. Source code is available here https://github.com/robot-perception-group/multi_rotor_airship_docking.

</details>


### [136] [Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap](https://arxiv.org/abs/2511.19201)
*Ann-Sophia Müller,Moonkwang Jeong,Jiyuan Tian,Meng Zhang,Tian Qiu*

Main category: cs.RO

TL;DR: 提出了一种使用永磁体阵列实现稳定2D磁力陷阱的方法，用于控制医疗微型机器人，通过GPU加速优化算法计算磁体最优角度，实现了在20-120mm距离范围内的稳定控制。


<details>
  <summary>Details</summary>
Motivation: 解决在医疗应用中远距离对微型机器人施加高驱动力的挑战，同时克服永磁体难以实现稳定3D磁力陷阱的限制。

Method: 开发了基于均方误差和Adam优化器的GPU加速优化算法，计算永磁体阵列中磁体的最优角度，实现2D磁力陷阱。

Result: 成功实现了在20-120mm距离范围内的稳定磁力陷阱，能够控制微型机器人沿复杂轨迹运动，算法具有高可扩展性，可在3秒内优化100个磁体。

Conclusion: 该方法为医疗微型机器人的精确控制提供了有效解决方案，优化流程可适应不同磁力场需求。

Abstract: Untethered magnetic manipulation of biomedical millirobots has a high potential for minimally invasive surgical applications. However, it is still challenging to exert high actuation forces on the small robots over a large distance. Permanent magnets offer stronger magnetic torques and forces than electromagnetic coils, however, feedback control is more difficult. As proven by Earnshaw's theorem, it is not possible to achieve a stable magnetic trap in 3D by static permanent magnets. Here, we report a stable 2D magnetic force trap by an array of permanent magnets to control a millirobot. The trap is located in an open space with a tunable distance to the magnet array in the range of 20 - 120mm, which is relevant to human anatomical scales. The design is achieved by a novel GPU-accelerated optimization algorithm that uses mean squared error (MSE) and Adam optimizer to efficiently compute the optimal angles for any number of magnets in the array. The algorithm is verified using numerical simulation and physical experiments with an array of two magnets. A millirobot is successfully trapped and controlled to follow a complex trajectory. The algorithm demonstrates high scalability by optimizing the angles for 100 magnets in under three seconds. Moreover, the optimization workflow can be adapted to optimize a permanent magnet array to achieve the desired force vector fields.

</details>


### [137] [Reference-Free Sampling-Based Model Predictive Control](https://arxiv.org/abs/2511.19204)
*Fabian Schramm,Pierre Fabre,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.RO

TL;DR: 提出基于采样的模型预测控制框架，无需预设步态模式或接触序列，通过优化高层目标自动发现多样化运动模式，包括小跑、疾跑、跳跃等，实现实时CPU控制。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖手工设计的步态模式和预定义的接触序列，限制了机器人的运动多样性和适应性。本文旨在通过纯优化方法自动发现复杂运动行为。

Method: 基于模型预测路径积分(MPPI)，提出双空间样条参数化方法，在位置和速度控制点上操作，实现自适应接触策略，仅需有限采样轨迹即可高效控制。

Result: 在Go2四足机器人上验证了多种涌现步态和基本跳跃能力，仿真中展示了后空翻、动态倒立平衡等复杂行为，无需参考跟踪或离线预训练。

Conclusion: 该方法实现了无需预设模式的运动控制，在标准CPU上达到实时性能，展示了通过优化高层目标自动发现多样化运动模式的潜力。

Abstract: We present a sampling-based model predictive control (MPC) framework that enables emergent locomotion without relying on handcrafted gait patterns or predefined contact sequences. Our method discovers diverse motion patterns, ranging from trotting to galloping, robust standing policies, jumping, and handstand balancing, purely through the optimization of high-level objectives. Building on model predictive path integral (MPPI), we propose a dual-space spline parameterization that operates on position and velocity control points. Our approach enables contact-making and contact-breaking strategies that adapt automatically to task requirements, requiring only a limited number of sampled trajectories. This sample efficiency allows us to achieve real-time control on standard CPU hardware, eliminating the need for GPU acceleration typically required by other state-of-the-art MPPI methods. We validate our approach on the Go2 quadrupedal robot, demonstrating various emergent gaits and basic jumping capabilities. In simulation, we further showcase more complex behaviors, such as backflips, dynamic handstand balancing and locomotion on a Humanoid, all without requiring reference tracking or offline pre-training.

</details>


### [138] [Soft pneumatic grippers: Topology optimization, 3D-printing and experimental validation](https://arxiv.org/abs/2511.19211)
*Prabhat Kumar,Chandra Prakash,Josh Pinskier,David Howard,Matthijs Langelaar*

Main category: cs.RO

TL;DR: 提出了一种考虑设计依赖载荷的软体气动抓取器系统拓扑优化框架，通过2D软臂单元优化和3D组装，实现了对不同物体的抓取性能。


<details>
  <summary>Details</summary>
Motivation: 传统软体气动抓取器设计未充分考虑设计依赖的驱动载荷特性，需要开发系统化的拓扑优化方法来提升性能。

Method: 使用Darcy定律建模气动载荷，采用稳健公式将2D软臂单元设计表述为柔顺机构优化问题，通过MMA算法求解，最后将优化单元挤出为3D模块并组装成抓取器。

Result: 优化的2D单元在气动载荷下性能优于传统矩形设计，组装的软臂在不同压力下呈现良好变形特性，3D打印的抓取器能够有效抓取不同重量、尺寸、刚度和形状的物体。

Conclusion: 提出的拓扑优化框架成功实现了高性能软体气动抓取器的设计，验证了考虑设计依赖载荷的优化方法在软体机器人设计中的有效性。

Abstract: This paper presents a systematic topology optimization framework for designing a soft pneumatic gripper (SPG), explicitly considering the design-dependent nature of the actuating load. The load is modeled using Darcy's law with an added drainage term. A 2D soft arm unit is optimized by formulating it as a compliant mechanism design problem using the robust formulation. The problem is posed as a min-max optimization, where the output deformations of blueprint and eroded designs are considered. A volume constraint is imposed on the blueprint part, while a strain-energy constraint is enforced on the eroded part. The MMA is employed to solve the optimization problem and obtain the optimized soft unit. Finite element analysis with the Ogden material model confirms that the optimized 2D unit outperforms a conventional rectangular design under pneumatic loading. The optimized 2D unit is extruded to obtain a 3D module, and ten such units are assembled to create a soft arm. Deformation profiles of the optimized arm are analysed under different pressure loads. Four arms are 3D-printed and integrated with a supporting structure to realize the proposed SPG. The gripping performance of the SPG is demonstrated on objects with different weights, sizes, stiffness, and shapes.

</details>


### [139] [SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control](https://arxiv.org/abs/2511.19236)
*Yuxuan Wang,Haobin Jiang,Shiqing Yao,Ziluo Ding,Zongqing Lu*

Main category: cs.RO

TL;DR: SENTINEL是一个端到端的语言-动作模型，用于人形机器人全身控制，直接映射语言命令和本体感受输入到低级动作，无需中间表示。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制系统依赖遥操作或模块化生成流水线，前者完全由人类驱动，后者缺乏语言命令与物理行为之间的紧密对齐。

Method: 通过在仿真中使用预训练的全身控制器跟踪人类运动并配以文本标注构建大规模数据集。模型使用流匹配生成动作块，并通过残差动作头进行细化以适应现实世界部署。

Result: 该方法在人形机器人的仿真和现实世界部署中表现出强大的语义理解和稳定执行能力，并支持通过将输入转换为文本来实现多模态扩展。

Conclusion: SENTINEL提供了一个完全端到端的解决方案，实现了语言命令与物理行为之间的紧密对齐，为人形机器人控制提供了新的范式。

Abstract: Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.

</details>


### [140] [Rethinking Intermediate Representation for VLM-based Robot Manipulation](https://arxiv.org/abs/2511.19315)
*Weiliang Tang,Jialin Gao,Jia-Hui Pan,Gang Wang,Li Erran Li,Yunhui Liu,Mingyu Ding,Pheng-Ann Heng,Chi-Wing Fu*

Main category: cs.RO

TL;DR: 提出SEAM语义组装表示法，通过分解中间表示为词汇表和语法，实现VLM友好且通用的机器人操作表示，结合开放词汇分割和检索增强少样本学习，在真实实验中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决VLM在机器人操作中翻译人类指令时，在VLM可理解性和通用性之间的权衡问题。

Method: 设计SEAM表示法，将中间表示分解为语义丰富的操作词汇表和VLM友好的语法；提出开放词汇分割范式，采用检索增强的少样本学习策略来定位细粒度物体部件。

Result: 在动作通用性和VLM可理解性方面优于主流表示方法，在真实世界实验中达到SOTA性能，且推理时间最短。

Conclusion: SEAM表示法通过词汇-语法分解有效平衡了VLM可理解性和任务通用性，结合高效的物体部件定位方法，为机器人操作提供了强大的中间表示方案。

Abstract: Vision-Language Model (VLM) is an important component to enable robust robot manipulation. Yet, using it to translate human instructions into an action-resolvable intermediate representation often needs a tradeoff between VLM-comprehensibility and generalizability. Inspired by context-free grammar, we design the Semantic Assembly representation named SEAM, by decomposing the intermediate representation into vocabulary and grammar. Doing so leads us to a concise vocabulary of semantically-rich operations and a VLM-friendly grammar for handling diverse unseen tasks. In addition, we design a new open-vocabulary segmentation paradigm with a retrieval-augmented few-shot learning strategy to localize fine-grained object parts for manipulation, effectively with the shortest inference time over all state-of-the-art parallel works. Also, we formulate new metrics for action-generalizability and VLM-comprehensibility, demonstrating the compelling performance of SEAM over mainstream representations on both aspects. Extensive real-world experiments further manifest its SOTA performance under varying settings and tasks.

</details>


### [141] [Deployment Dynamics and Optimization of Novel Space Antenna Deployable Mechanism](https://arxiv.org/abs/2511.19377)
*Mamoon Aamir,Mariyam Sattar,Naveed Ur Rehman Junejo,Aqsa Zafar Abbasi*

Main category: cs.RO

TL;DR: 提出了一种新型三重剪刀可展开桁架机构(TSDTM)，用于空间天线任务，该机构在发射时可收起，在轨道上高效展开，实现最大孔径尺寸和最小发射体积。


<details>
  <summary>Details</summary>
Motivation: 随着空间任务对大孔径天线需求的增加，将这些结构装入小型运载火箭的困难促使了可展开天线系统的设计。

Method: 涵盖从几何建模、使用螺旋理论和牛顿方法的运动学分析、通过特征值和仿真方法的动力学分析，到SolidWorks验证的完整设计过程。基于支持向量机编写了优化程序用于LEO环境材料选择，使用机器学习方法进行几何设置。

Result: 提出的TSDTM具有增强的结构动力学性能，仿真与解析预测结果良好吻合。优化结构非常准确，机器学习预测与模拟固有频率之间的偏差仅为1.94%。

Conclusion: 展示了将基于AI的方法纳入空间结构设计的潜力。

Abstract: Given the increasing need for large aperture antennas in space missions, the difficulty of fitting such structures into small launch vehicles has prompted the design of deployable antenna systems. The thesis introduces a new Triple Scissors Deployable Truss Mechanism (TSDTM) for space antenna missions. The new mechanism is to be stowed during launch and efficiently deploy in orbit, offering maximum aperture size while taking up minimal launch volume. The thesis covers the entire design process from geometric modeling, kinematic analysis with screw theory and Newtonian approaches, dynamic analysis by eigenvalue and simulation methods, and verification with SolidWorks. In addition, optimization routines were coded based on Support Vector Machines for material choice in LEO environments and machine learning method for geometric setup. The TSDTM presented has enhanced structural dynamics with good comparison between simulation and analytical predictions. The structure optimized proved highly accurate, with a deviation of just 1.94% between machine learning-predicted and simulated natural frequencies, demonstrating the potential of incorporating AI-based methods in space structural design.

</details>


### [142] [Mixture of Horizons in Action Chunking](https://arxiv.org/abs/2511.19433)
*Dong Jing,Gang Wang,Jiaqi Liu,Weiliang Tang,Zelong Sun,Yunchao Yao,Zhenyu Wei,Yunhui Liu,Zhiwu Lu,Mingyu Ding*

Main category: cs.RO

TL;DR: 提出混合视野(MoH)策略来解决VLA模型中行动块长度选择的权衡问题，通过并行处理不同视野长度的行动段并融合输出，同时获得长期前瞻性和短期精度


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人操作中表现出色，但其性能对训练时使用的行动块长度（视野）敏感。研究发现存在固有权衡：较长视野提供更强的全局前瞻性但降低细粒度精度，较短视野则增强局部控制但难以处理长期任务

Method: MoH将行动块重新排列为几个具有不同视野的段，用共享的行动变换器并行处理，并通过轻量级线性门融合输出。支持动态推理和自适应视野选择

Result: 在LIBERO基准测试中，π0.5+MoH在仅30k训练迭代后达到99%的平均成功率，创下新纪录。动态推理实现2.5倍吞吐量提升，同时保持优越性能

Conclusion: MoH策略有效缓解了视野选择权衡，在仿真和真实世界任务中均带来一致且显著的性能提升，具有即插即用、训练推理开销小等优点

Abstract: Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\textbf{action chunk length}$ used during training, termed $\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $π_0$, $π_{0.5}$, and one-step regression policy $π_{\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $π_{0.5}$ with MoH reaches a new state-of-the-art with 99$\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons

</details>
