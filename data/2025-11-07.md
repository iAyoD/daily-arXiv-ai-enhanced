<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 比较三种数据驱动模型降阶方法（ERA、DMDc、LOpInf）在鳗鱼仿生软体机器人动态形状控制中的效果，发现LOpInf方法在所有实验中跟踪误差最小


<details>
  <summary>Details</summary>
Motivation: 软体机器人需要动态形状控制，但缺乏适合控制的通用建模工具，需要研究数据驱动的模型降阶技术来生成适合控制的线性模型

Method: 使用特征系统实现算法（ERA）、带控制的动态模态分解（DMDc）和拉格朗日算子推断（LOpInf）三种方法进行模型降阶，在模拟的鳗鱼仿生软体机器人上进行轨迹跟踪实验

Result: 在所有三个实验中（可行参考轨迹跟踪、生物运动学轨迹跟踪、物理模拟轨迹跟踪），基于LOpInf的控制策略产生的跟踪误差均低于其他模型

Conclusion: LOpInf方法在软体机器人动态形状控制中表现最佳，为软体机器人控制提供了有效的模型降阶解决方案

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [2] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的统一控制器，通过直接整合视觉感知和运动控制，使人形机器人能够在动态环境中获得反应式足球技能。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常依赖解耦模块，导致动态环境中响应延迟和行为不连贯，而现实世界的感知限制进一步加剧了这些问题。

Method: 扩展对抗运动先验到现实动态环境中的感知设置，结合编码器-解码器架构和虚拟感知系统，从有缺陷的观察中恢复特权状态，建立感知与动作的主动协调。

Result: 控制器表现出强大的反应能力，在各种场景（包括真实RoboCup比赛）中持续执行连贯且稳健的足球行为。

Conclusion: 该方法成功实现了视觉感知与运动控制的直接集成，为人形机器人在动态环境中的反应式技能学习提供了有效解决方案。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [3] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 提出一种上肢姿态优化方法，用于提升双臂人机协同搬运任务中的物理工效学和力可操作性，通过优化简化人体骨骼模型的关节角度来平衡安全性和操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只关注人类安全或操作效率，而本方法独特地将这两个方面整合，以在不同条件下（如不同抓握姿势和物体形状）加强协作。

Method: 通过最小化代价函数优化简化人体骨骼模型的关节角度，优先考虑安全性和操作能力；通过变换模块生成机器人末端执行器的参考位姿；提出双臂模型预测阻抗控制器（MPIC）来重新校准末端执行器位姿。

Result: 在人与人协作（HHC）和人机协作（HRC）中通过不同受试者和物体进行了验证，实验结果显示通过比较优化前后目标肌肉的激活情况，肌肉状况得到显著改善。

Conclusion: 所提出的方法能够有效提升双臂人机协同搬运任务中的物理工效学和力可操作性，显著改善肌肉状况。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [4] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 提出基于LLM的认知增强系统，通过自然交互解决无人机群在灾害救援中的人机协作瓶颈，显著提升任务效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决灾害搜救中无人机群协调的"意图到行动差距"问题，减轻人类操作员的认知负担，提高人机协作效率。

Method: 开发LLM-CRF系统，通过语音和图形标注捕获操作员意图，利用LLM进行意图理解、任务分解和任务规划，实现闭环反馈。

Result: 相比传统命令界面，任务完成时间减少64.2%，成功率提升7%，NASA-TLX认知负荷评分下降42.9%。

Conclusion: LLM能够创建更直观有效的人机协作系统，在高风险场景中具有重要应用潜力。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [5] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 评估新一代多核处理器在行星探测任务中部署GNC和LVS算法的性能提升，并提出ARBITER多核投票机制实现实时故障检测和恢复。


<details>
  <summary>Details</summary>
Motivation: 未来行星探测任务需要高性能、容错计算来实现自主的制导导航控制和着陆视觉系统操作，特别是在进入、下降和着陆阶段。

Method: 在HPSC、Snapdragon VOXL2和AMD Xilinx Versal等多核处理器上部署GNC和LVS算法，并开发ARBITER多核投票机制进行实时故障检测和纠正。

Result: LVS图像处理实现15倍加速，GFOLD轨迹优化实现250倍加速；ARBITER在静态优化和动态闭环控制中有效验证；故障注入研究识别梯度计算阶段对位级错误最敏感。

Conclusion: 为未来火星样本返回、土卫二轨道着陆器和谷神星样本返回等任务建立了可扩展且节能的架构，满足机载自主性、低延迟和容错能力的关键需求。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [6] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出基于脉冲神经网络的仿生控制框架，模拟人类中枢神经系统，实现机器臂在复杂环境中的敏捷控制


<details>
  <summary>Details</summary>
Motivation: 随着机器臂应用扩展到医疗、服务和日常生活，现有控制算法难以在动态轨迹、不可预测交互和多样物体的复杂环境中实现敏捷操作

Method: 采用五模块（大脑皮层、小脑、丘脑、脑干、脊髓）、三层次控制（一阶、二阶、三阶）和双信息通路（上行、下行）的仿生框架，各模块均使用SNN实现，包括基于LIF神经元的反馈控制、强化学习参数调整和回归学习动态特性

Result: 在仿真和真实机器臂平台上验证，在不同负载和轨迹下均优于工业级位置控制方法

Conclusion: 基于SNN的仿生控制框架能够显著提升机器臂在复杂环境中的操作敏捷性

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [7] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero是一个用于人形机器人的行为基础模型框架，通过共享潜在表示统一多种控制任务，支持零样本运动跟踪、目标到达和奖励优化，以及少样本优化适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么仅部署在模拟人形角色上，要么专门用于特定任务如跟踪。需要一种能够统一多种控制任务的通用策略。

Method: 基于无监督强化学习和前向-后向模型，学习嵌入运动、目标和奖励的共享潜在表示，结合关键奖励塑造、域随机化和历史依赖非对称学习来弥合仿真到现实的差距。

Result: 在真实世界的Unitree G1人形机器人上实现了多功能和鲁棒的全身体技能，通过定量消融研究验证了关键设计选择的有效性。

Conclusion: BFM-Zero为可扩展、可提示的全身体人形控制行为基础模型迈出了重要一步。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [8] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 提出了一种结合路径-不确定性协同优化深度强化学习和轻量级停滞检测机制的混合框架，显著提升主动SLAM的探索效率和路径质量


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法存在探索速度慢、路径次优等问题，需要解决探索与利用的平衡以及冗余探索的问题

Method: 采用路径-不确定性协同优化框架通过双目标奖励函数联合优化行进距离和地图不确定性，结合轻量级停滞检测机制通过激光雷达静态异常检测和地图更新停滞检测减少冗余探索

Result: 相比前沿方法和RRT方法，探索时间缩短65%，路径距离减少42%，在复杂环境中显著提升探索效率同时保持可靠的地图完整性

Conclusion: 该协同机制加速训练收敛，在物理机器人平台上验证了算法的实际适用性和从仿真到真实环境的成功迁移性

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [9] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一个仅使用RGB相机的机器人抓取系统，通过全局场景重建、主动感知策略和在线度量对齐，在杂乱环境中实现精确抓取，特别适用于透明物体和遮挡严重的情况。


<details>
  <summary>Details</summary>
Motivation: 传统基于RGB-D相机的抓取系统在透明物体、近距离感知和遮挡严重时表现不佳，需要一种仅使用RGB相机的可靠替代方案。

Method: 集成三个关键组件：全局感知场景重建（从单视图生成局部一致的几何信息）、渲染评分主动感知策略（动态选择最佳视角揭示遮挡区域）、在线度量对齐模块（校准抓取预测与机器人运动学）。

Result: 在多样化桌面物体上的实验表明，GraspView显著优于RGB-D和单视图RGB基线方法，特别是在严重遮挡、近距离感知和透明物体情况下。

Conclusion: GraspView是RGB-D管道的实用替代方案，能够在非结构化真实环境中实现可靠抓取。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [10] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: 该论文提出在基于域随机化的强化学习框架中集成上下文估计模块，通过让策略感知环境动态参数来改进模拟到现实的迁移性能。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在机器人领域中的模拟到现实迁移问题，传统域随机化方法虽然能提高泛化性但会降低性能，需要更有效的方法来应对环境动态差异。

Method: 在基于域随机化的强化学习框架中集成上下文估计模块，让策略能够感知环境动态参数，并系统比较了最先进的监督策略。

Result: 上下文感知策略在所有设置中都优于上下文无关的基线方法，但最佳监督策略取决于具体任务。

Conclusion: 通过让策略感知环境动态参数可以显著改进模拟到现实的迁移性能，为机器人强化学习提供了一种有效的解决方案。

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [11] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 设计了一种可重构机翼的尾坐式垂直起降无人机，采用同轴异构双旋翼配置和无斜盘机构，通过机翼收放和结构优化实现高效能、低振动的全包线稳定飞行。


<details>
  <summary>Details</summary>
Motivation: 传统尾坐式VTOL无人机在多旋翼模式下因暴露较大机身面积而容易受风干扰，需要解决抗风性和功率效率问题。

Method: 采用可收放机翼设计、同轴异构双旋翼配置、无斜盘机构并增加挥舞铰链优化结构，降低振动。

Result: 显著降低了总功耗，减少了结构重量和复杂性，实现了整个飞行包线的稳定飞行性能。

Conclusion: 所提出的可重构机翼尾坐式无人机设计有效解决了抗风性和功率效率问题，通过结构优化实现了稳定高效的全包线飞行。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [12] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav是一个基于学习的导航框架，通过轻量级上下文编码器和强化学习策略，在未知环境中实现高效自主导航，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在丰富上下文表示和导航效率之间取得平衡，而未知环境中的自主导航需要紧凑且表达能力强的空间理解来支持高级决策。

Method: 包含两个关键组件：(1) 通过多任务自监督学习训练的轻量级上下文编码器，捕捉多尺度、导航中心的空间表示；(2) 强化学习策略，将这些表示与基于图的推理无缝集成以进行高效动作选择。

Result: 实验证明上下文编码器具有高效和鲁棒的环境理解能力。实际部署验证了MacroNav的有效性，在成功率和路径长度加权成功率方面显著优于最先进的导航方法，同时保持低计算成本。

Conclusion: MacroNav框架在未知环境中实现了高效自主导航，平衡了表示能力和导航效率，为实际应用提供了有前景的解决方案。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [13] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: GraSP-VLA是一个神经符号框架，使用连续场景图表示从人类演示中生成符号表示，用于推理时生成新的规划域，并协调低级VLA策略以扩展连续执行动作的数量。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案存在局限性：端到端模仿学习的VLA模型缺乏高层符号规划能力，影响长期任务表现；符号方法的AML缺乏泛化性和可扩展性。需要结合两者优势的新方法。

Method: 提出神经符号方法GraSP-VLA，使用连续场景图表示生成人类演示的符号表示，在推理时生成新规划域，并作为低级VLA策略的协调器。

Result: GraSP-VLA在自动规划域生成任务中有效建模符号表示，真实世界实验显示连续场景图表示在协调长期任务中低级VLA策略方面具有潜力。

Conclusion: GraSP-VLA框架成功结合了神经和符号方法的优势，在长期任务中展示了协调VLA策略的能力，为自主机器人技能学习提供了新方向。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [14] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 本文研究了在自动驾驶场景中如何最佳表示智能体之间的交互关系，发现明确定义的交互（如路口谁先通过）比让网络从数据中学习隐式交互更能提升性能。


<details>
  <summary>Details</summary>
Motivation: 有效捕捉场景中所有智能体的联合分布对于预测场景真实演化和为自动驾驶决策提供更准确信息至关重要，但目前缺乏关于如何最佳表示智能体交互的共识。

Method: 在同一网络结构中研究不同交互描述方式对最终学习到的联合分布的影响，比较隐式学习与基于时空关系的显式建模。

Result: 研究发现，让网络基于数据建立隐式交互连接通常会对性能产生负面影响，而明确定义的交互（如路口通行顺序）往往能显著提升性能。

Conclusion: 在表示智能体交互时，基于人类决策过程的明确定义交互比数据驱动的隐式学习更有效，能为自动驾驶系统提供更准确的场景演化预测。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [15] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo是一个生成式机器人代理，通过生成模拟自主获取操作技能，结合生成范式与经典控制，实现零样本模拟到真实环境的迁移。


<details>
  <summary>Details</summary>
Motivation: 有效利用模拟来获取高级操作技能具有挑战性但意义重大，传统端到端策略学习方法在可解释性和执行效率方面存在不足。

Method: 采用"提出-生成-学习-执行"循环：提出技能并构建模拟环境，配置物体生成技能一致的目标状态(ForeGen)，用虚拟无限数据训练状态生成模型(ForeFormer)，最后用经典控制算法驱动真实机器人。

Result: 在多种刚体和关节物体操作任务中，ForeFormer比最先进的状态生成模型平均提升56.32%，在20多个真实机器人任务中实现零样本迁移，平均成功率79.28%。

Conclusion: ForeRobo展示了生成模拟与经典控制结合的有效性，提供更好的可解释性和执行效率，在多种操作模式中表现出强泛化能力。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [16] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: 提出TAS算法解决动作分块在模仿学习中反应性不足的问题，通过缓存多时间步预测动作块并用轻量选择器动态选择最优动作，平衡反应性、决策一致性和运动连贯性


<details>
  <summary>Details</summary>
Motivation: 动作分块方法虽然增强了建模能力，但降低了决策频率，限制了近期观测的利用，导致对传感器噪声和环境动态变化的适应能力不足。现有方法需要在反应性和决策一致性之间权衡，无法同时兼顾

Method: TAS算法缓存多个时间步预测的动作块，通过轻量级选择器网络动态选择最优动作。将TAS作为基础策略与残差强化学习结合，提升训练效率和性能

Result: 在多个任务和不同基础策略上的实验表明，TAS显著提高成功率，绝对增益高达73.3%。与残差RL结合后进一步提升了训练效率和性能上限

Conclusion: TAS算法有效解决了动作分块方法的反应性不足问题，在仿真和物理机器人实验中验证了方法的有效性，实现了反应性、决策一致性和运动连贯性的平衡优化

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [17] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一个轻量级的视觉-语言-动作模型，通过新颖的跨调制扩散变换器和优化的集成模块，在减少计算量和提高部署效率的同时，无需机器人数据预训练即可实现强大性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型参数庞大，依赖大规模机器人数据预训练，导致训练计算成本高、实时推理部署困难，且训练范式会降低视觉语言骨干的感知表示，导致过拟合和泛化能力差。

Method: 基于原生多模态视觉语言模型，引入跨调制扩散变换器和优化集成模块，采用两阶段训练范式逐步对齐动作与感知，保留VLM表示。

Result: 仅0.77B参数，在Meta-World和RoboTwin套件上分别超越之前最佳模型12.4%和6.9%，在LIBERO上达到94.8%的竞争性结果，真实世界评估达到78%成功率，具有高推理频率和低内存开销。

Conclusion: Evo-1为轻量高效VLA模型研究提供了有效解决方案，在保持性能的同时显著提升了部署效率。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [18] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一个基于语义表示的共享自动驾驶框架，利用视觉语言模型从多模态线索推断驾驶员意图，在语义层面进行人机控制仲裁，显著提升了在罕见和模糊场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统在罕见、模糊和分布外场景中表现脆弱，而人类驾驶员通过上下文推理能够成功应对。现有共享自治方法局限于低层轨迹层面，无法保持底层驾驶意图。

Method: 使用视觉语言模型从驾驶员动作和环境上下文等多模态线索推断驾驶员意图，在语义层面合成协调策略来调解人类和自主控制。

Result: 在模拟人类设置中实现完美召回率和高精度；人类受试者调查显示92%的案例中参与者同意仲裁结果；在Bench2Drive基准测试中显著降低碰撞率并提升整体性能。

Conclusion: 基于语义、语言表示的仲裁成为共享自治的设计原则，使系统能够运用常识推理并保持与人类意图的连续性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [19] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一个基于真实世界视频构建软体数字孪生的真实到仿真策略评估框架，使用3D高斯泼溅实现逼真渲染，用于评估机器人对可变形物体的操作策略。


<details>
  <summary>Details</summary>
Motivation: 真实世界中直接评估机器人操作策略成本高、耗时长且难以复现，特别是涉及可变形物体的任务。现有模拟器难以捕捉软体交互的视觉和物理复杂性。

Method: 从真实世界视频构建软体数字孪生，使用3D高斯泼溅技术对机器人、物体和环境进行逼真渲染，结合物理信息重建技术。

Result: 在毛绒玩具打包、绳索路由和T型块推动等代表性可变形操作任务上验证，模拟运行与现实执行性能高度相关，能揭示学习策略的关键行为模式。

Conclusion: 物理信息重建与高质量渲染相结合，能够实现可重复、可扩展且准确的机器人操作策略评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [20] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion是一个利用人类视频数据训练机器人策略的扩散框架，通过噪声注入解决人类与机器人动作执行差异问题，在五个操作任务中比最佳基线平均成功率提高16%。


<details>
  <summary>Details</summary>
Motivation: 人类视频数据获取容易且规模大，但人类与机器人在动作执行上存在根本差异，直接使用人类动作会导致机器人学习到物理上不可行的动作。

Method: 首先训练分类器区分人类和机器人动作，然后在策略训练中只使用添加足够噪声后分类器无法区分的人类动作，在低噪声级别使用机器人动作进行精细去噪，在高噪声级别使用人类动作提供粗略指导。

Result: 实验表明，在动作执行不匹配的情况下，简单的共同训练会降低策略性能，而X-Diffusion能持续改进性能，在五个操作任务中平均成功率比最佳基线高16%。

Conclusion: X-Diffusion提供了一个原则性框架，能够最大化利用人类数据而不学习动态不可行的动作，有效解决了人类-机器人动作执行差异问题。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [21] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: GentleHumanoid框架将阻抗控制集成到全身运动跟踪策略中，实现上半身柔顺性，通过统一的弹簧模型处理抵抗性和引导性接触，在保持任务成功率的同时显著降低接触力峰值。


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要在以人为中心的环境中安全自然地物理交互，但现有强化学习策略过于强调刚性跟踪而抑制外力，现有阻抗控制方法通常局限于基座或末端执行器控制，且主要关注抵抗极端力而非实现柔顺性。

Method: 提出GentleHumanoid框架，核心是统一的基于弹簧的公式化方法，建模抵抗性接触（按压表面时的恢复力）和引导性接触（从人类运动数据采样的推拉动作），确保肩、肘、腕关节的运动学一致性力，并通过任务可调力阈值保证安全性。

Result: 在仿真和Unitree G1人形机器人上评估，在需要不同柔顺性水平的任务中（温柔拥抱、坐站辅助、安全物体操作），相比基线方法，策略持续降低峰值接触力同时保持任务成功率，实现更平滑自然的交互。

Conclusion: 该研究向能够安全有效与人类协作并在真实环境中处理物体的人形机器人迈出了一步，展示了通过阻抗控制实现柔顺交互的可行性。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>
