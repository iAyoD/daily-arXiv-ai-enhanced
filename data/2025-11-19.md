<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models](https://arxiv.org/abs/2511.13722)
*William Guo,Adaku Uchendu,Ana Smith*

Main category: cs.CL

TL;DR: 评估多种水印技术对对抗攻击的鲁棒性及其对文本质量和写作风格的保持能力，发现这些技术能保持语义但偏离原始写作风格，且易受对抗攻击特别是回译攻击的影响。


<details>
  <summary>Details</summary>
Motivation: 缓解大语言模型生成文本的潜在危害，通过水印技术嵌入可检测信号。然而，现有技术常降低生成文本质量且易受对抗攻击，导致业界对水印技术广泛应用的抵制。

Method: 通过比较释义和回译（英语→其他语言→英语）攻击来评估多种水印技术的鲁棒性；使用语言指标来评估水印技术保持文本质量和写作风格的能力。

Result: 水印技术能保持语义，但偏离未加水印文本的写作风格，且易受对抗攻击，特别是回译攻击。

Conclusion: 为鼓励水印技术的采用，需要提高其对对抗攻击的鲁棒性，并更好地保持原始文本的写作风格。

Abstract: To mitigate the potential harms of Large Language Models (LLMs)generated text, researchers have proposed watermarking, a process of embedding detectable signals within text. With watermarking, we can always accurately detect LLM-generated texts. However, recent findings suggest that these techniques often negatively affect the quality of the generated texts, and adversarial attacks can strip the watermarking signals, causing the texts to possibly evade detection. These findings have created resistance in the wide adoption of watermarking by LLM creators. Finally, to encourage adoption, we evaluate the robustness of several watermarking techniques to adversarial attacks by comparing paraphrasing and back translation (i.e., English $\to$ another language $\to$ English) attacks; and their ability to preserve quality and writing style of the unwatermarked texts by using linguistic metrics to capture quality and writing style of texts. Our results suggest that these watermarking techniques preserve semantics, deviate from the writing style of the unwatermarked texts, and are susceptible to adversarial attacks, especially for the back translation attack.

</details>


### [2] [Refine Thought: A Test-Time Inference Method for Embedding Model Reasoning](https://arxiv.org/abs/2511.13726)
*Guangzhi Wang,Kai Li,Yinghao Jiao,Zhi Liu*

Main category: cs.CL

TL;DR: RT是一种通过多次前向传递提升文本嵌入模型语义推理能力的方法，在语义推理任务上表现显著提升，同时保持通用语义理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 提升文本嵌入模型的语义推理能力，进一步激活预训练期间学习到的语义推理能力。

Method: 通过多次前向传递运行文本嵌入模型来获得最终的语义表示，是一种测试时推理方法。

Result: 在BRIGHT和PJBenchmark1语义推理任务上取得显著改进，在C-MTEB等通用语义理解任务上保持稳定性能。

Conclusion: RT方法有效激活了解码器专用文本嵌入模型在预训练期间学习到的语义推理能力。

Abstract: We propose RT (Refine Thought), a method that can enhance the semantic rea-soning ability of text embedding models. The method obtains the final semanticrepresentation by running multiple forward passes of the text embedding model.Experiments show that RT achieves significant improvements on semantic reason-ing tasks in BRIGHT and the person job matching benchmark PJBenchmark1, while maintaining consistent performance on general-purpose semantic under-standing tasks such as C-MTEB. Our results indicate that RT is effective becauseit further activates the semantic reasoning ability learned during pretraining bydecoder-only text embedding models(e.g., Qwen3-Embedding-8B). RT canbe seen as a test-time inference method.

</details>


### [3] [Can QE-informed (Re)Translation lead to Error Correction?](https://arxiv.org/abs/2511.13884)
*Govardhan Padmanabhan*

Main category: cs.CL

TL;DR: 该论文提出了两种无需训练的QE-informed错误校正方法：一种是选择不同LLM生成的最佳翻译候选，另一种是基于QE解释替换错误子串。第一种方法在WMT 2025任务中获胜。


<details>
  <summary>Details</summary>
Motivation: 虽然联合训练QE和APE系统能提升性能，但APE系统存在过度校正问题，导致性能下降。作者希望探索无需训练的简单方法来避免这个问题。

Method: 1. QE-informed重翻译：从不同LLM生成的多个候选翻译中选择质量最高的一个
2. 基于QE解释的错误替换：根据提供的QE解释，指导LLM替换错误子串，并使用条件启发式方法最小化编辑次数

Result: 两种方法分别获得了0.0201和-0.0108的Delta COMET分数，第一种方法在子任务排行榜上获胜

Conclusion: 无需训练的QE-informed重翻译方法在机器翻译错误校正任务中表现优异，避免了APE系统的过度校正问题，为质量评估指导的错误校正提供了有效的替代方案

Abstract: The paper presents two approaches submitted to the WMT 2025 Automated Translation Quality Evaluation Systems Task 3 - Quality Estimation (QE)-informed Segment-level Error Correction. While jointly training QE systems with Automatic Post-Editing (APE) has shown improved performance for both tasks, APE systems are still known to overcorrect the output of Machine Translation (MT), leading to a degradation in performance. We investigate a simple training-free approach - QE-informed Retranslation, and compare it with another within the same training-free paradigm. Our winning approach selects the highest-quality translation from multiple candidates generated by different LLMs. The second approach, more akin to APE, instructs an LLM to replace error substrings as specified in the provided QE explanation(s). A conditional heuristic was employed to minimise the number of edits, with the aim of maximising the Gain-to-Edit ratio. The two proposed approaches achieved a Delta COMET score of 0.0201 and -0.0108, respectively, leading the first approach to achieve the winning position on the subtask leaderboard.

</details>


### [4] [What Works for 'Lost-in-the-Middle' in LLMs? A Study on GM-Extract and Mitigations](https://arxiv.org/abs/2511.13900)
*Mihir Gupte,Eshan Dixit,Muhammad Tayyab,Arun Adiththan*

Main category: cs.CL

TL;DR: 提出了GM-Extract基准数据集来评估LLM在长上下文检索中的表现，发现数据表示方式显著影响检索性能，并分析了各种缓解方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长距离上下文检索中出现的"迷失在中间"现象，这在基于检索的LLM应用中是一个重要挑战。

Method: 设计了GM-Extract基准数据集，使用两个评估指标（空间检索能力和语义检索能力），系统评估了7-8B参数模型在多文档任务上的表现，并分析了各种缓解方法。

Result: 发现通过改变数据在上下文窗口中的表示方式可以显著影响检索性能，虽然未始终观察到明显的U型曲线，但发现了清晰的性能模式。缓解方法的效果具有高度复杂性，在某些情况下能提升性能，但在其他情况下会产生负面影响。

Conclusion: 长上下文检索性能受数据表示方式影响显著，现有的缓解方法效果复杂多变，需要在实际应用场景中谨慎选择和使用。

Abstract: The diminishing ability of large language models (LLMs) to effectively utilize long-range context-the "lost-in-the-middle" phenomenon-poses a significant challenge in retrieval-based LLM applications. To study the impact of this phenomenon in a real-world application setting, we introduce GM-Extract, a novel benchmark dataset meticulously designed to evaluate LLM performance on retrieval of control variables. To accurately diagnose failure modes, we propose a simple yet elegant evaluation system using two distinct metrics: one for spatial retrieval capability (Document Metric) and the other for semantic retrieval capability (Variable Extraction Metric). We conduct a systematic evaluation of 7-8B parameter models on two multi-document tasks (key-value extraction and question-answering), demonstrating a significant change in retrieval performance simply by altering how the data is represented in the context window. While a distinct U-shaped curve was not consistently observed, our analysis reveals a clear pattern of performance across models, which we further correlate with perplexity scores. Furthermore, we perform a literature survey of mitigation methods, which we categorize into two distinct approaches: black-box and white-box methods. We then apply these techniques to our benchmark, finding that their efficacy is highly nuanced. Our evaluation highlights scenarios where these strategies successfully improve performance, as well as surprising cases where they lead to a negative impact, providing a comprehensive understanding of their utility in a practical context.

</details>


### [5] [Hint-Augmented Re-ranking: Efficient Product Search using LLM-Based Query Decomposition](https://arxiv.org/abs/2511.13994)
*Yilun Zhu,Nikhita Vedula,Shervin Malmasi*

Main category: cs.CL

TL;DR: LLM框架解析电商搜索中最高级查询的潜在意图，通过属性-值提示分解查询，提升搜索性能10.9 MAP和5.9 MRR，并开发高效方法将解释转移到轻量级模型以解决延迟问题。


<details>
  <summary>Details</summary>
Motivation: 电商搜索中的最高级查询（如"最好"、"最受欢迎"）需要跨多个维度比较候选商品，这需要语言理解和领域知识，现有方法难以有效处理这类复杂语义。

Method: 开发了一个框架，通过LLM提取结构化解释或提示，将查询分解为属性-值提示，并在检索过程中并行生成，然后集成到排序管道中。

Result: 方法在MAP上提升10.9点，在MRR上提升5.9点，优于基线方法。由于直接使用LLM重新排序面临过高延迟，开发了将最高级解释转移到轻量级模型的高效方法。

Conclusion: 研究揭示了最高级语义如何在模型间表示和转移，推进了检索系统中的语言解释能力，同时解决了实际部署的约束问题。

Abstract: Search queries with superlatives (e.g., best, most popular) require comparing candidates across multiple dimensions, demanding linguistic understanding and domain knowledge. We show that LLMs can uncover latent intent behind these expressions in e-commerce queries through a framework that extracts structured interpretations or hints. Our approach decomposes queries into attribute-value hints generated concurrently with retrieval, enabling efficient integration into the ranking pipeline. Our method improves search performanc eby 10.9 points in MAP and ranking by 5.9 points in MRR over baselines. Since direct LLM-based reranking faces prohibitive latency, we develop an efficient approach transferring superlative interpretations to lightweight models. Our findings provide insights into how superlative semantics can be represented and transferred between models, advancing linguistic interpretation in retrieval systems while addressing practical deployment constraints.

</details>


### [6] [Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports](https://arxiv.org/abs/2511.14010)
*Chenchen Kuai,Zihao Li,Braden Rosen,Stephanie Paan,Navid Jafari,Jean-Louis Briaud,Yunlong Zhang,Youssef M. A. Hashash,Yang Zhou*

Main category: cs.CL

TL;DR: 提出MoRA-RAG框架，通过混合检索和代理分块机制，将灾后勘察报告转化为结构化知识库，用于多灾害推理，显著提升准确率并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 灾后勘察报告包含理解多灾害相互作用的关键证据，但其非结构化叙述使得系统知识传递困难。现有LLM在缺乏领域基础时会产生不可靠或幻觉输出。

Method: 开发MoRA-RAG框架，包含混合检索机制动态路由跨灾害特定数据库查询，使用代理分块保持检索上下文连贯性，并集成验证循环评估证据充分性、优化查询和启动针对性搜索。

Result: 在HazardRecQA数据集上，MoRA-RAG达到94.5%准确率，比零样本LLM提升30%，比最先进RAG系统提升10%，同时在不同LLM架构上减少幻觉。

Conclusion: MoRA-RAG为将灾后文档转化为可操作、可信赖的灾害韧性情报建立了新范式，使开源LLM达到与专有模型相当的性能。

Abstract: Post-disaster reconnaissance reports contain critical evidence for understanding multi-hazard interactions, yet their unstructured narratives make systematic knowledge transfer difficult. Large language models (LLMs) offer new potential for analyzing these reports, but often generate unreliable or hallucinated outputs when domain grounding is absent. This study introduces the Mixture-of-Retrieval Agentic RAG (MoRA-RAG), a knowledge-grounded LLM framework that transforms reconnaissance reports into a structured foundation for multi-hazard reasoning. The framework integrates a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while using agentic chunking to preserve contextual coherence during retrieval. It also includes a verification loop that assesses evidence sufficiency, refines queries, and initiates targeted searches when information remains incomplete. We construct HazardRecQA by deriving question-answer pairs from GEER reconnaissance reports, which document 90 global events across seven major hazard types. MoRA-RAG achieves up to 94.5 percent accuracy, outperforming zero-shot LLMs by 30 percent and state-of-the-art RAG systems by 10 percent, while reducing hallucinations across diverse LLM architectures. MoRA-RAG also enables open-weight LLMs to achieve performance comparable to proprietary models. It establishes a new paradigm for transforming post-disaster documentation into actionable, trustworthy intelligence for hazard resilience.

</details>


### [7] [HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection](https://arxiv.org/abs/2511.14027)
*Junjie Wu,Yumeng Fu,Nan Yu,Guohong Fu*

Main category: cs.CL

TL;DR: 提出了HiEAG框架，通过分层证据增强生成来改进多模态假信息检测中的外部一致性检查，结合检索、重排序和重写模块，利用MLLMs的广泛知识。


<details>
  <summary>Details</summary>
Motivation: 现有的OOC假信息检测方法过于强调内部一致性，忽略了图像-文本对与外部证据之间的外部一致性的重要性。

Method: HiEAG框架将外部一致性检查分解为检索、重排序和重写的综合引擎管道，使用AESP进行证据重排序，AEGP进行证据重写，并通过指令调优实现判断解释。

Result: 在不同基准数据集上的实验结果表明，HiEAG在所有样本的准确率上超越了之前的最先进方法。

Conclusion: HiEAG通过分层证据增强生成框架有效提升了多模态假信息检测的性能，证明了外部一致性检查的重要性。

Abstract: Recent advancements in multimodal out-of-context (OOC) misinformation detection have made remarkable progress in checking the consistencies between different modalities for supporting or refuting image-text pairs. However, existing OOC misinformation detection methods tend to emphasize the role of internal consistency, ignoring the significant of external consistency between image-text pairs and external evidence. In this paper, we propose HiEAG, a novel Hierarchical Evidence-Augmented Generation framework to refine external consistency checking through leveraging the extensive knowledge of multimodal large language models (MLLMs). Our approach decomposes external consistency checking into a comprehensive engine pipeline, which integrates reranking and rewriting, apart from retrieval. Evidence reranking module utilizes Automatic Evidence Selection Prompting (AESP) that acquires the relevant evidence item from the products of evidence retrieval. Subsequently, evidence rewriting module leverages Automatic Evidence Generation Prompting (AEGP) to improve task adaptation on MLLM-based OOC misinformation detectors. Furthermore, our approach enables explanation for judgment, and achieves impressive performance with instruction tuning. Experimental results on different benchmark datasets demonstrate that our proposed HiEAG surpasses previous state-of-the-art (SOTA) methods in the accuracy over all samples.

</details>


### [8] [Based on Data Balancing and Model Improvement for Multi-Label Sentiment Classification Performance Enhancement](https://arxiv.org/abs/2511.14073)
*Zijin Su,Huanzhu Lv,Yuren Niu,Yiming Liu*

Main category: cs.CL

TL;DR: 构建平衡的多标签情感数据集，开发增强分类模型，显著提升多标签情感分类性能


<details>
  <summary>Details</summary>
Motivation: 现有数据集如GoEmotions存在严重的类别不平衡问题，影响模型性能，特别是对于代表性不足的情感类别

Method: 整合GoEmotions原始数据、使用RoBERTa-base-GoEmotions模型标注的Sentiment140样本，以及GPT-4 mini生成的手动标注文本，构建平衡数据集；开发结合FastText嵌入、卷积层、双向LSTM和注意力机制的多标签分类模型

Result: 实验结果显示在准确率、精确率、召回率、F1分数和AUC方面相比不平衡数据训练的模型有显著提升

Conclusion: 该方法有效解决了多标签情感分类中的类别不平衡问题，证明了平衡数据集和增强模型架构的有效性

Abstract: Multi-label sentiment classification plays a vital role in natural language processing by detecting multiple emotions within a single text. However, existing datasets like GoEmotions often suffer from severe class imbalance, which hampers model performance, especially for underrepresented emotions. To address this, we constructed a balanced multi-label sentiment dataset by integrating the original GoEmotions data, emotion-labeled samples from Sentiment140 using a RoBERTa-base-GoEmotions model, and manually annotated texts generated by GPT-4 mini. Our data balancing strategy ensured an even distribution across 28 emotion categories. Based on this dataset, we developed an enhanced multi-label classification model that combines pre-trained FastText embeddings, convolutional layers for local feature extraction, bidirectional LSTM for contextual learning, and an attention mechanism to highlight sentiment-relevant words. A sigmoid-activated output layer enables multi-label prediction, and mixed precision training improves computational efficiency. Experimental results demonstrate significant improvements in accuracy, precision, recall, F1-score, and AUC compared to models trained on imbalanced data, highlighting the effectiveness of our approach.

</details>


### [9] [Stealth Fine-Tuning: Efficiently Breaking Alignment in RVLMs Using Self-Generated CoT](https://arxiv.org/abs/2511.14106)
*Le Yu,Zhengyue Zhao,Yawen Zheng,Yunhao Liu*

Main category: cs.CL

TL;DR: 提出了一种名为Stealth Fine-Tuning的攻击方法，通过在推理过程中进行分段级干扰，利用自生成输出作为监督微调数据，能够以低成本有效绕过RVLMs的安全对齐防御。


<details>
  <summary>Details</summary>
Motivation: 尽管RVLMs依赖安全对齐来防止有害行为，但其暴露的思维链轨迹引入了新的攻击面，安全对齐容易被突破。

Method: 通过分段级干扰引发有害推理轨迹，将自生成输出作为监督微调数据，采用基于轮次的加权损失设计，实现轻量级、分布一致的微调方法。

Result: 仅用499个样本和单张A100显卡3小时内，攻击成功率比IDEATOR高出38.52%，同时保持通用推理能力，模型表示分布保持不变。

Conclusion: Stealth Fine-Tuning是一种低成本、高效绕过对齐防御的方法，在AdvBench和多个通用基准测试中表现出色。

Abstract: Reasoning-augmented Vision-Language Models (RVLMs) rely on safety alignment to prevent harmful behavior, yet their exposed chain-of-thought (CoT) traces introduce new attack surfaces. In this work, we find that the safety alignment of RVLMs can be easily break through a novel attack method termed \textbf{Stealth Fine-Tuning}. Our method elicits harmful reasoning traces through \textbf{segment-level interference} and reuses the self-generated outputs as supervised fine-tuning data. Through a \textbf{turn-based weighted} loss design, yielding a lightweight, distribution-consistent finetuning method. In our experiment, with only 499 samples and under 3 hours on a single A100 (QLoRA), Stealth Fine-Tuning outperforms IDEATOR by 38.52\% ASR while preserving general reasoning ability, as the tuned model retains the original representation distribution. Experiments on AdvBench and several general benchmarks demonstrate that Stealth Fine-Tuning is a low-cost and highly effective way to bypass alignment defenses. \textcolor{red}{\textbf{Disclaimer: This paper contains content that may be disturbing or offensive.}}

</details>


### [10] [Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for Long-Tail Medical Coding](https://arxiv.org/abs/2511.14112)
*Truong Vo,Weiyi Wu,Kaize Ding*

Main category: cs.CL

TL;DR: 提出一个数据中心的框架，通过生成高质量合成出院摘要来解决ICD编码中的长尾分布问题，提升罕见和零样本代码的预测性能。


<details>
  <summary>Details</summary>
Motivation: 临床文本自动ICD编码任务受到诊断代码极端长尾分布的阻碍，数千个罕见和零样本ICD代码在数据集中代表性不足，导致宏观F1分数较低。

Method: 构建基于罕见代码的现实多标签代码集，利用真实世界共现模式、ICD描述、同义词、分类法和相似临床笔记生成结构化提示，生成90,000个合成笔记覆盖7,902个ICD代码。

Result: 在两个最先进的基于transformer的模型上微调，实验显示该方法适度提高了宏观F1，同时保持强大的微观F1，优于先前的最先进方法。

Conclusion: 虽然相对于计算成本增益可能显得有限，但结果表明精心制作的合成数据可以增强长尾ICD代码预测的公平性。

Abstract: Automatic ICD coding from clinical text is a critical task in medical NLP but remains hindered by the extreme long-tail distribution of diagnostic codes. Thousands of rare and zero-shot ICD codes are severely underrepresented in datasets like MIMIC-III, leading to low macro-F1 scores. In this work, we propose a data-centric framework that generates high-quality synthetic discharge summaries to mitigate this imbalance. Our method constructs realistic multi-label code sets anchored on rare codes by leveraging real-world co-occurrence patterns, ICD descriptions, synonyms, taxonomy, and similar clinical notes. Using these structured prompts, we generate 90,000 synthetic notes covering 7,902 ICD codes, significantly expanding the training distribution. We fine-tune two state-of-the-art transformer-based models, PLM-ICD and GKI-ICD, on both the original and extended datasets. Experiments show that our approach modestly improves macro-F1 while maintaining strong micro-F1, outperforming prior SOTA. While the gain may seem marginal relative to the computational cost, our results demonstrate that carefully crafted synthetic data can enhance equity in long-tail ICD code prediction.

</details>


### [11] [From Graphs to Hypergraphs: Enhancing Aspect-Based Sentiment Analysis via Multi-Level Relational Modeling](https://arxiv.org/abs/2511.14142)
*Omkar Mahesh Kashyap,Padegal Amit,Madhav Kashyap,Ashwini M Joshi,Shylaja SS*

Main category: cs.CL

TL;DR: HyperABSA是一个动态超图框架，通过样本特定的层次聚类构建方面-观点结构，解决了传统图方法在短文本情感分析中的冗余和参数开销问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的方法只能建模成对依赖关系，需要构建多个图来捕捉不同关系视图，这引入了冗余、参数开销和融合过程中的错误传播，在短文本、低资源设置下限制了鲁棒性。

Method: 提出动态超图框架，通过样本特定的层次聚类诱导方面-观点结构，并引入加速-回退截止点的新方法来自适应确定聚类的粒度级别。

Result: 在三个基准数据集（Lap14、Rest14、MAMS）上的实验显示，相比强大的图基线方法取得了持续改进，特别是与RoBERTa骨干网络结合时获得了显著提升。

Conclusion: 动态超图构建是ABSA任务的高效强大替代方案，并有潜力扩展到其他短文本NLP任务。

Abstract: Aspect-Based Sentiment Analysis (ABSA) predicts sentiment polarity for specific aspect terms, a task made difficult by conflicting sentiments across aspects and the sparse context of short texts. Prior graph-based approaches model only pairwise dependencies, forcing them to construct multiple graphs for different relational views. These introduce redundancy, parameter overhead, and error propagation during fusion, limiting robustness in short-text, low-resource settings. We present HyperABSA, a dynamic hypergraph framework that induces aspect-opinion structures through sample-specific hierarchical clustering. To construct these hyperedges, we introduce a novel acceleration-fallback cutoff for hierarchical clustering, which adaptively determines the level of granularity. Experiments on three benchmarks (Lap14, Rest14, MAMS) show consistent improvements over strong graph baselines, with substantial gains when paired with RoBERTa backbones. These results position dynamic hypergraph construction as an efficient, powerful alternative for ABSA, with potential extensions to other short-text NLP tasks.

</details>


### [12] [Applying Relation Extraction and Graph Matching to Answering Multiple Choice Questions](https://arxiv.org/abs/2511.14144)
*Naoki Shimoda,Akihiro Yamamoto*

Main category: cs.CL

TL;DR: 提出了一种结合Transformer关系抽取和知识图谱匹配的方法，用于回答填空题形式的多选题，同时保持输出过程的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 利用Transformer关系抽取方法动态生成知识图谱来表示输入句子的含义，解决传统知识图谱构建成本高且静态的问题。

Method: 通过关系抽取将问题句子转换为关系图，然后在封闭世界假设下与事实正确的知识图谱进行验证，以衡量句子的真实性。

Result: 实验结果显示该方法能正确回答约70%的问题，同时提供过程可追溯性，且问题类别对准确率有显著影响。

Conclusion: 该方法成功实现了基于关系抽取和知识图谱验证的多选题回答，证明了动态知识图谱在自然语言理解任务中的有效性。

Abstract: In this research, we combine Transformer-based relation extraction with matching of knowledge graphs (KGs) and apply them to answering multiple-choice questions (MCQs) while maintaining the traceability of the output process. KGs are structured representations of factual knowledge consisting of entities and relations. Due to the high construction cost, they had been regarded as static databases with validated links. However, the recent development of Transformer-based relation extraction (RE) methods has enabled us to generate KGs dynamically by giving them natural language texts, and thereby opened the possibility for representing the meaning of the input sentences with the created KGs. Using this effect, we propose a method that answers MCQs in the "fill-in-the-blank" format, taking care of the point that RE methods generate KGs that represent false information if provided with factually incorrect texts. We measure the truthfulness of each question sentence by (i) converting the sentence into a relational graph using an RE method and (ii) verifying it against factually correct KGs under the closed-world assumption. The experimental results demonstrate that our method correctly answers up to around 70% of the questions, while providing traceability of the procedure. We also highlight that the question category has a vast influence on the accuracy.

</details>


### [13] [Selective Weak-to-Strong Generalization](https://arxiv.org/abs/2511.14166)
*Hao Lang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 提出选择性弱到强泛化框架，通过训练二元分类器识别强模型能回答的问题，避免不必要的弱监督，并使用图平滑方法优化弱标签，在三个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决超人类模型对齐时缺乏高质量数据的问题，现有弱到强泛化方法使用弱监督存在鲁棒性问题，部分弱标签对模型有害。

Method: 训练P(IK)二元分类器识别强模型能回答的问题，使用自生成标签进行对齐，通过图平滑方法优化弱标签。

Result: 在三个基准测试中持续优于竞争基线，P(IK)能跨任务和难度泛化。

Conclusion: 选择性弱到强泛化有助于超对齐问题的解决。

Abstract: Future superhuman models will surpass the ability of humans and humans will only be able to \textit{weakly} supervise superhuman models. To alleviate the issue of lacking high-quality data for model alignment, some works on weak-to-strong generalization (W2SG) finetune a strong pretrained model with a weak supervisor so that it can generalize beyond weak supervision. However, the invariable use of weak supervision in existing methods exposes issues in robustness, with a proportion of weak labels proving harmful to models. In this paper, we propose a selective W2SG framework to avoid using weak supervision when unnecessary. We train a binary classifier P(IK) to identify questions that a strong model can answer and use its self-generated labels for alignment. We further refine weak labels with a graph smoothing method. Extensive experiments on three benchmarks show that our method consistently outperforms competitive baselines. Further analyses show that P(IK) can generalize across tasks and difficulties, which indicates selective W2SG can help superalignment.

</details>


### [14] [SymLoc: Symbolic Localization of Hallucination across HaluEval and TruthfulQA](https://arxiv.org/abs/2511.14172)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 提出了首个基于符号语言知识的幻觉定位框架，发现LLMs的幻觉本质上是符号语言处理失败而非一般生成问题，符号语义知识是理解幻觉机制的关键。


<details>
  <summary>Details</summary>
Motivation: LLMs在遇到修饰语、否定、数字、例外和命名实体等符号触发器时仍存在幻觉问题，但缺乏对这些符号幻觉来源的清晰理解，需要系统性地处理这些触发器并在模型内部定位幻觉的出现位置。

Method: 提出了首个符号定位框架，利用符号语言和语义知识来有意义地追踪所有模型层中幻觉的发展。通过关注模型如何处理符号触发器，使用HaluEval和TruthfulQA分析了五个模型。

Result: 符号知识方法显示这些语言元素的注意力方差在早期层（2-4）爆炸到临界不稳定性，否定触发了灾难性的方差水平，表明符号语义处理从一开始就崩溃。尽管模型规模更大，幻觉率仍保持高位（Gemma变体为78.3%-83.7%），在更深层中符号语义触发器的注意力急剧下降。

Conclusion: 幻觉本质上是符号语言处理失败，而非一般生成问题，符号语义知识为理解和定位LLMs中的幻觉机制提供了关键。

Abstract: LLMs still struggle with hallucination, especially when confronted with symbolic triggers like modifiers, negation, numbers, exceptions, and named entities. Yet, we lack a clear understanding of where these symbolic hallucinations originate, making it crucial to systematically handle such triggers and localize the emergence of hallucination inside the model. While prior work explored localization using statistical techniques like LSC and activation variance analysis, these methods treat all tokens equally and overlook the role symbolic linguistic knowledge plays in triggering hallucinations. So far, no approach has investigated how symbolic elements specifically drive hallucination failures across model layers, nor has symbolic linguistic knowledge been used as the foundation for a localization framework. We propose the first symbolic localization framework that leverages symbolic linguistic and semantic knowledge to meaningfully trace the development of hallucinations across all model layers. By focusing on how models process symbolic triggers, we analyze five models using HaluEval and TruthfulQA. Our symbolic knowledge approach reveals that attention variance for these linguistic elements explodes to critical instability in early layers (2-4), with negation triggering catastrophic variance levels, demonstrating that symbolic semantic processing breaks down from the very beginning. Through the lens of symbolic linguistic knowledge, despite larger model sizes, hallucination rates remain consistently high (78.3%-83.7% across Gemma variants), with steep attention drops for symbolic semantic triggers throughout deeper layers. Our findings demonstrate that hallucination is fundamentally a symbolic linguistic processing failure, not a general generation problem, revealing that symbolic semantic knowledge provides the key to understanding and localizing hallucination mechanisms in LLMs.

</details>


### [15] [Harnessing Deep LLM Participation for Robust Entity Linking](https://arxiv.org/abs/2511.14181)
*Jiajun Hou,Chenyu Zhang,Rui Meng*

Main category: cs.CL

TL;DR: DeepEL是一个将大语言模型深度集成到实体链接所有阶段的框架，通过自验证机制利用全局上下文信息纠正预测，在多个基准数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只在实体链接的孤立阶段使用LLMs，未能充分利用其在整个流程中的能力，且孤立消歧无法达到最优性能。

Method: 提出DeepEL框架，将LLMs集成到实体链接的每个阶段，并引入自验证机制利用全局上下文信息来纠正预测和识别实体间的连贯关系。

Result: 在10个基准数据集上的评估显示，DeepEL在整体F1分数上平均提升2.6%，在域外数据集上提升4%，显著优于现有最先进方法。

Conclusion: 深度集成LLMs能有效推进实体链接技术发展，自验证机制通过利用全局上下文显著提升了性能。

Abstract: Entity Linking (EL), the task of mapping textual entity mentions to their corresponding entries in knowledge bases, constitutes a fundamental component of natural language understanding. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable potential for enhancing EL performance. Prior research has leveraged LLMs to improve entity disambiguation and input representation, yielding significant gains in accuracy and robustness. However, these approaches typically apply LLMs to isolated stages of the EL task, failing to fully integrate their capabilities throughout the entire process.
  In this work, we introduce DeepEL, a comprehensive framework that incorporates LLMs into every stage of the entity linking task. Furthermore, we identify that disambiguating entities in isolation is insufficient for optimal performance. To address this limitation, we propose a novel self-validation mechanism that utilizes global contextual information, enabling LLMs to rectify their own predictions and better recognize cohesive relationships among entities within the same sentence.
  Extensive empirical evaluation across ten benchmark datasets demonstrates that DeepEL substantially outperforms existing state-of-the-art methods, achieving an average improvement of 2.6\% in overall F1 score and a remarkable 4% gain on out-of-domain datasets. These results underscore the efficacy of deep LLM integration in advancing the state-of-the-art in entity linking.

</details>


### [16] [ArbESC+: Arabic Enhanced Edit Selection System Combination for Grammatical Error Correction Resolving conflict and improving system combination in Arabic GEC](https://arxiv.org/abs/2511.14230)
*Ahlam Alrehili,Areej Alhothali*

Main category: cs.CL

TL;DR: 提出了ArbESC+系统，这是首个阿拉伯语语法错误纠正的多系统集成方法，通过组合多个模型和特征分类器，显著提升了纠错性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语具有复杂的形态和句法结构，现有方法多为单一模型，未充分利用多系统集成的优势。

Method: 使用AraT5、ByT5、mT5、AraBART等多个模型生成修正建议，通过数值特征表示和分类器选择最佳修正，并采用支持技术过滤重叠修正和评估决策可靠性。

Result: 在QALB-14测试数据上F0.5达到82.63%，QALB-15 L1数据达到84.64%，QALB-15 L2数据达到65.55%，优于单一模型。

Conclusion: 这是首个集成语言错误修正的阿拉伯语系统，为开发先进的阿拉伯语文本处理工具提供了实用步骤。

Abstract: Grammatical Error Correction (GEC) is an important aspect of natural language processing. Arabic has a complicated morphological and syntactic structure, posing a greater challenge than other languages. Even though modern neural models have improved greatly in recent years, the majority of previous attempts used individual models without taking into account the potential benefits of combining different systems. In this paper, we present one of the first multi-system approaches for correcting grammatical errors in Arabic, the Arab Enhanced Edit Selection System Complication (ArbESC+). Several models are used to collect correction proposals, which are represented as numerical features in the framework. A classifier determines and implements the appropriate corrections based on these features. In order to improve output quality, the framework uses support techniques to filter overlapping corrections and estimate decision reliability. A combination of AraT5, ByT5, mT5, AraBART, AraBART+Morph+GEC, and Text editing systems gave better results than a single model alone, with F0.5 at 82.63% on QALB-14 test data, 84.64% on QALB-15 L1 data, and 65.55% on QALB-15 L2 data. As one of the most significant contributions of this work, it's the first Arab attempt to integrate linguistic error correction. Improving existing models provides a practical step towards developing advanced tools that will benefit users and researchers of Arabic text processing.

</details>


### [17] [MuCPT: Music-related Natural Language Model Continued Pretraining](https://arxiv.org/abs/2511.14245)
*Kai Tian,Yirong Mao,Wendong Bi,Hanjie Wang,Que Wenhui*

Main category: cs.CL

TL;DR: 本文提出了一个针对音乐领域的大语言模型训练框架，包括构建大规模音乐相关语料库（40B tokens）、实施领域优先的数据处理流程、引入基于参考模型的软评分质量控制系统，以及创建MusicSimpleQA基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在通用任务上表现良好，但在音乐等专业领域受到限制，主要问题包括语料库规模、纯净度以及数据与训练目标的匹配度不足。

Method: 1. 构建大规模音乐相关自然语言语料库；2. 实施领域优先数据管道，包括轻量级分类器过滤、多阶段清理和隐私保护掩码；3. 引入基于参考模型的token级软评分进行质量控制；4. 设计MusicSimpleQA基准测试评估事实性。

Result: 提出了一个可扩展的数据训练框架和可重用的评估工具，能够更有效地进行音乐领域的持续预训练和对齐。

Conclusion: 该工作通过正确的语料库和训练目标，为构建音乐领域大语言模型提供了系统性的解决方案，推动了领域专用LLM的发展。

Abstract: Large language models perform strongly on general tasks but remain constrained in specialized settings such as music, particularly in the music-entertainment domain, where corpus scale, purity, and the match between data and training objectives are critical. We address this by constructing a large, music-related natural language corpus (40B tokens) that combines open source and in-house data, and by implementing a domain-first data pipeline: a lightweight classifier filters and weights in-domain text, followed by multi-stage cleaning, de-duplication, and privacy-preserving masking. We further integrate multi-source music text with associated metadata to form a broader, better-structured foundation of domain knowledge. On the training side, we introduce reference-model (RM)-based token-level soft scoring for quality control: a unified loss-ratio criterion is used both for data selection and for dynamic down-weighting during optimization, reducing noise gradients and amplifying task-aligned signals, thereby enabling more effective music-domain continued pretraining and alignment. To assess factuality, we design the MusicSimpleQA benchmark, which adopts short, single-answer prompts with automated agreement scoring. Beyond the benchmark design, we conduct systematic comparisons along the axes of data composition. Overall, this work advances both the right corpus and the right objective, offering a scalable data-training framework and a reusable evaluation tool for building domain LLMs in the music field.

</details>


### [18] [Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](https://arxiv.org/abs/2511.14249)
*Rui Liu,Yuan Zhao,Zhenqi Jia*

Main category: cs.CL

TL;DR: 提出了Authentic-Dubber模型，通过检索增强的导演-演员交互学习方案，模拟真实电影配音工作流程，显著提升情感表达能力


<details>
  <summary>Details</summary>
Motivation: 现有电影配音方法模拟简化的工作流程，忽略了导演与演员之间的关键互动环节，而真实工作流程涉及导演指导演员内化情感线索的动态协作

Method: 构建多模态参考片段库，使用情感相似性检索增强策略，开发渐进式图基语音生成方法，整合LLM进行多模态情感表示深度理解

Result: 在V2C Animation基准数据集上的主观和客观评估验证了有效性，实现了情感表达能力的全面提升

Conclusion: Authentic-Dubber通过模拟真实配音工作流程，在情感表达方面取得了显著改进，为自动电影配音提供了更真实的解决方案

Abstract: The automatic movie dubbing model generates vivid speech from given scripts, replicating a speaker's timbre from a brief timbre prompt while ensuring lip-sync with the silent video. Existing approaches simulate a simplified workflow where actors dub directly without preparation, overlooking the critical director-actor interaction. In contrast, authentic workflows involve a dynamic collaboration: directors actively engage with actors, guiding them to internalize the context cues, specifically emotion, before performance. To address this issue, we propose a new Retrieve-Augmented Director-Actor Interaction Learning scheme to achieve authentic movie dubbing, termed Authentic-Dubber, which contains three novel mechanisms: (1) We construct a multimodal Reference Footage library to simulate the learning footage provided by directors. Note that we integrate Large Language Models (LLMs) to achieve deep comprehension of emotional representations across multimodal signals. (2) To emulate how actors efficiently and comprehensively internalize director-provided footage during dubbing, we propose an Emotion-Similarity-based Retrieval-Augmentation strategy. This strategy retrieves the most relevant multimodal information that aligns with the target silent video. (3) We develop a Progressive Graph-based speech generation approach that incrementally incorporates the retrieved multimodal emotional knowledge, thereby simulating the actor's final dubbing process. The above mechanisms enable the Authentic-Dubber to faithfully replicate the authentic dubbing workflow, achieving comprehensive improvements in emotional expressiveness. Both subjective and objective evaluations on the V2C Animation benchmark dataset validate the effectiveness. The code and demos are available at https://github.com/AI-S2-Lab/Authentic-Dubber.

</details>


### [19] [AfriSpeech-MultiBench: A Verticalized Multidomain Multicountry Benchmark Suite for African Accented English ASR](https://arxiv.org/abs/2511.14255)
*Gabrial Zencha Ashungafac,Mardhiyah Sanni,Busayo Awobade,Alex Gichamba,Tobi Olatunji*

Main category: cs.CL

TL;DR: AfriSpeech-MultiBench是首个针对非洲英语口音的领域特定评估套件，涵盖100多种口音、10多个国家和7个应用领域，评估了多种语音识别系统在非洲语境下的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管语音AI技术快速发展，但目前缺乏针对非洲语言多样性的公开应用特定模型评估，需要为非洲社区开发包容性语音应用提供评估基准。

Method: 构建包含10+国家、100多种非洲英语口音的评估套件，涵盖7个应用领域，使用自发和非自发语音对话数据，对开源、闭源、单模态ASR和多模态LLM语音识别系统进行基准测试。

Result: 开源ASR在自发语音中表现良好但在嘈杂非母语对话中退化；多模态LLM对口音更鲁棒但在领域特定命名实体上表现不佳；专有模型在清晰语音中准确率高但不同国家和领域差异显著；非洲英语微调的模型具有竞争性准确率和更低延迟。

Conclusion: 通过发布这一全面基准，使从业者和研究人员能够选择适合非洲用例的语音技术，促进为服务不足社区开发包容性语音应用。

Abstract: Recent advances in speech-enabled AI, including Google's NotebookLM and OpenAI's speech-to-speech API, are driving widespread interest in voice interfaces globally. Despite this momentum, there exists no publicly available application-specific model evaluation that caters to Africa's linguistic diversity. We present AfriSpeech-MultiBench, the first domain-specific evaluation suite for over 100 African English accents across 10+ countries and seven application domains: Finance, Legal, Medical, General dialogue, Call Center, Named Entities and Hallucination Robustness. We benchmark a diverse range of open, closed, unimodal ASR and multimodal LLM-based speech recognition systems using both spontaneous and non-spontaneous speech conversation drawn from various open African accented English speech datasets. Our empirical analysis reveals systematic variation: open-source ASR models excels in spontaneous speech contexts but degrades on noisy, non-native dialogue; multimodal LLMs are more accent-robust yet struggle with domain-specific named entities; proprietary models deliver high accuracy on clean speech but vary significantly by country and domain. Models fine-tuned on African English achieve competitive accuracy with lower latency, a practical advantage for deployment, hallucinations still remain a big problem for most SOTA models. By releasing this comprehensive benchmark, we empower practitioners and researchers to select voice technologies suited to African use-cases, fostering inclusive voice applications for underserved communities.

</details>


### [20] [Entropy-Guided Reasoning Compression](https://arxiv.org/abs/2511.14258)
*Hourun Zhu,Yang Gao,Wenlong Fei,Jiawei Li,Huashan Sun*

Main category: cs.CL

TL;DR: 提出了一种熵引导训练框架来解决推理模型压缩中的熵冲突问题，将推理长度压缩至原始的20%同时保持或提升准确率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型的思维链输出过长导致计算成本高和部署困难，现有压缩方法忽略了训练过程中的熵冲突现象

Method: 采用熵引导训练框架，在熵下降时鼓励简洁思维步骤，在熵上升时在紧凑推理模式下加强探索以提高鲁棒性

Result: 在六个数学基准测试中，将推理长度压缩至原始的20%，同时保持甚至超过基线准确率

Conclusion: 熵引导训练框架有效解决了推理压缩中的熵冲突问题，实现了高效且鲁棒的推理压缩

Abstract: Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.

</details>


### [21] [Don't Miss the Forest for the Trees: In-Depth Confidence Estimation for LLMs via Reasoning over the Answer Space](https://arxiv.org/abs/2511.14275)
*Ante Wang,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出通过预测语言化概率分布来增强LLM置信度估计的方法，该方法鼓励模型深入思考所有候选答案而非单一猜测，在不同模型和任务中均表现出优势。


<details>
  <summary>Details</summary>
Motivation: 了解模型响应的可靠性在应用中至关重要。虽然已有研究关注生成语言化置信度并结合思维链推理提供逻辑透明的估计，但推理策略如何影响置信度估计仍未被充分探索。

Method: 提出预测语言化概率分布的方法，要求LLM考虑答案空间中的所有候选答案而非单一猜测，并仔细分配置信度分数以满足分布要求。

Result: 该方法在不同模型和各种任务中均显示出优势，无论答案空间是否已知。即使在强化学习后其优势仍得以保持，进一步分析显示其推理模式与人类期望一致。

Conclusion: 预测语言化概率分布能有效鼓励深度推理进行置信度估计，提供了一种改进LLM置信度估计的有效方法。

Abstract: Knowing the reliability of a model's response is essential in application. With the strong generation capabilities of LLMs, research has focused on generating verbalized confidence. This is further enhanced by combining chain-of-thought reasoning, which provides logical and transparent estimation. However, how reasoning strategies affect the estimated confidence is still under-explored. In this work, we demonstrate that predicting a verbalized probability distribution can effectively encourage in-depth reasoning for confidence estimation. Intuitively, it requires an LLM to consider all candidates within the answer space instead of basing on a single guess, and to carefully assign confidence scores to meet the requirements of a distribution. This method shows an advantage across different models and various tasks, regardless of whether the answer space is known. Its advantage is maintained even after reinforcement learning, and further analysis shows its reasoning patterns are aligned with human expectations.

</details>


### [22] [AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models](https://arxiv.org/abs/2511.14295)
*Mohammad Zbib,Hasan Abed Al Kader Hammoud,Sina Mukalled,Nadine Rizk,Fatima Karnib,Issam Lakkis,Ammar Mohanna,Bernard Ghanem*

Main category: cs.CL

TL;DR: AraLingBench是一个全面人工标注的基准测试，用于评估大型语言模型的阿拉伯语语言学能力，包含语法、形态学、拼写、阅读理解和句法五个核心类别，共150个专家设计的多项选择题。


<details>
  <summary>Details</summary>
Motivation: 当前阿拉伯语和双语LLMs在表面水平上表现出色，但在深层语法和句法推理方面存在困难，需要专门的基准测试来区分真实语言掌握与模式识别。

Method: 通过150个专家设计的多项选择题，评估35个阿拉伯语和双语LLMs在五个语言学核心类别（语法、形态学、拼写、阅读理解、句法）的表现。

Result: 评估显示当前模型在表面水平上表现良好，但在深层语法和句法推理方面存在困难，许多模型通过记忆或模式识别而非真实理解获得高分。

Conclusion: AraLingBench揭示了基于知识的基准测试高分与真实语言掌握之间的持续差距，为开发阿拉伯语LLMs提供了诊断框架，评估代码已在GitHub公开。

Abstract: We present AraLingBench: a fully human annotated benchmark for evaluating the Arabic linguistic competence of large language models (LLMs). The benchmark spans five core categories: grammar, morphology, spelling, reading comprehension, and syntax, through 150 expert-designed multiple choice questions that directly assess structural language understanding. Evaluating 35 Arabic and bilingual LLMs reveals that current models demonstrate strong surface level proficiency but struggle with deeper grammatical and syntactic reasoning. AraLingBench highlights a persistent gap between high scores on knowledge-based benchmarks and true linguistic mastery, showing that many models succeed through memorization or pattern recognition rather than authentic comprehension. By isolating and measuring fundamental linguistic skills, AraLingBench provides a diagnostic framework for developing Arabic LLMs. The full evaluation code is publicly available on GitHub.

</details>


### [23] [ConInstruct: Evaluating Large Language Models on Conflict Detection and Resolution in Instructions](https://arxiv.org/abs/2511.14342)
*Xingwei He,Qianru Zhang,Pengfei Chen,Guanhua Chen,Linlin Yu,Yuan Yuan,Siu-Ming Yiu*

Main category: cs.CL

TL;DR: ConInstruct基准测试评估LLMs在检测和解决用户指令中冲突约束的能力，发现专有LLMs冲突检测能力强但很少明确通知用户冲突。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs遵循用户指令的能力，但忽略了指令包含冲突约束的常见场景，LLMs在此类条件下的行为尚未充分探索。

Method: 引入ConInstruct基准测试，专门评估LLMs检测和解决用户指令中冲突的能力，并分析其冲突解决行为。

Result: 专有LLMs冲突检测能力强，DeepSeek-R1和Claude-4.5-Sonnet分别以91.5%和87.3%的F1分数排名前二；但LLMs很少明确通知用户冲突或请求澄清。

Conclusion: 当前LLMs在冲突处理方面存在关键缺陷，这是设计指令遵循LLMs时需要改进的重要领域。

Abstract: Instruction-following is a critical capability of Large Language Models (LLMs). While existing works primarily focus on assessing how well LLMs adhere to user instructions, they often overlook scenarios where instructions contain conflicting constraints-a common occurrence in complex prompts. The behavior of LLMs under such conditions remains under-explored. To bridge this gap, we introduce ConInstruct, a benchmark specifically designed to assess LLMs' ability to detect and resolve conflicts within user instructions. Using this dataset, we evaluate LLMs' conflict detection performance and analyze their conflict resolution behavior. Our experiments reveal two key findings: (1) Most proprietary LLMs exhibit strong conflict detection capabilities, whereas among open-source models, only DeepSeek-R1 demonstrates similarly strong performance. DeepSeek-R1 and Claude-4.5-Sonnet achieve the highest average F1-scores at 91.5% and 87.3%, respectively, ranking first and second overall. (2) Despite their strong conflict detection abilities, LLMs rarely explicitly notify users about the conflicts or request clarification when faced with conflicting constraints. These results underscore a critical shortcoming in current LLMs and highlight an important area for future improvement when designing instruction-following LLMs.

</details>


### [24] [The Tokenization Bottleneck: How Vocabulary Extension Improves Chemistry Representation Learning in Pretrained Language Models](https://arxiv.org/abs/2511.14365)
*Prathamesh Kalamkar,Ned Letcher,Meissane Chami,Sahger Lad,Shayan Mohanty,Prasanna Pendse*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The application of large language models (LLMs) to chemistry is frequently hampered by a "tokenization bottleneck", where tokenizers tuned on general-domain text tend to fragment chemical representations such as SMILES into semantically uninformative sub-tokens. This paper introduces a principled methodology to resolve this bottleneck by unifying the representation of natural language and molecular structures within a single model. Our approach involves targeted vocabulary extension-augmenting a pretrained LLM's vocabulary with chemically salient tokens, followed by continued pretraining on chemistry-domain text to integrate this new knowledge. We provide an empirical demonstration of the effectiveness of this strategy, showing that our methodology leads to superior performance on a range of downstream chemical tasks.

</details>


### [25] [ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366)
*Hongwei Liu,Junnan Liu,Shudong Liu,Haodong Duan,Yuqiang Li,Mao Su,Xiaohong Liu,Guangtao Zhai,Xinyu Fang,Qianhong Ma,Taolin Zhang,Zihan Ma,Yufeng Zhao,Peiheng Zhou,Linchen Xiao,Wenlong Zhang,Shijie Zhou,Xingjian Ma,Siqi Sun,Jiaye Ge,Meng Li,Yuhong Liu,Jianxin Dong,Jiaying Li,Hui Wu,Hanwen Liang,Jintai Lin,Yanting Wang,Jie Dong,Tong Zhu,Tianfan Fu,Conghui He,Qi Zhang,Songyang Zhang,Lei Bai,Kai Chen*

Main category: cs.CL

TL;DR: ATLAS是一个面向AGI的大规模、高难度跨学科科学评估套件，包含约800个原创问题，旨在解决现有基准测试在区分前沿模型能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在性能饱和、学科范围狭窄、答案格式简化、易受数据污染等问题，与真实科学探究存在保真度差距，需要新的评估方法来准确衡量模型的科学推理能力。

Method: 开发了包含7个核心科学领域的原创问题集，采用多阶段专家评审和对抗测试进行质量控制，并提出了使用LLM评委小组进行自动评估的稳健评估范式。

Result: 初步结果显示ATLAS能有效区分领先模型的先进科学推理能力，证明了其在评估前沿模型方面的有效性。

Conclusion: ATLAS将发展成为一个长期、开放、社区驱动的平台，为迈向人工通用智能的进展提供可靠的衡量标准。

Abstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable "ruler" for progress toward Artificial General Intelligence.

</details>


### [26] [Mitigating Label Length Bias in Large Language Models](https://arxiv.org/abs/2511.14385)
*Mario Sanz-Guerrero,Katharina von der Wense*

Main category: cs.CL

TL;DR: 提出标准化上下文校准(NCC)方法，解决LLMs中多标记类标签的长度偏差问题，在多个数据集和模型上显著提升性能，最高达10% F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有校准方法忽视了多标记类标签带来的偏差，特别是标签长度偏差问题，即不同长度的标签即使经过标准化处理后仍被不一致对待。

Method: 提出标准化上下文校准(NCC)，在全标签级别对预测进行标准化和校准，可扩展到多项选择题等更广泛任务。

Result: NCC在多个数据集和模型上取得统计显著改进，最高提升10% F1分数；结合上下文学习时，对少样本示例选择不敏感，需要更少示例达到竞争性能，产生更可靠的置信度估计。

Conclusion: 缓解全标签偏差对于提高基于LLM方法的性能和鲁棒性至关重要，特别是在类标签自然包含多个标记的现实应用中。

Abstract: Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.

</details>


### [27] [Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education](https://arxiv.org/abs/2511.14423)
*Xin Yi,Yue Li,Dongsheng Shi,Linlin Wang,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 提出了EduHarm基准和TSSF三阶段防护框架，用于评估和防御教育场景中LLM的越狱和微调攻击，在保持良性查询效用的同时增强安全性。


<details>
  <summary>Details</summary>
Motivation: LLM在教育应用中面临越狱和微调攻击风险，现有研究主要关注通用安全评估，缺乏针对教育场景特殊安全需求的专门研究。

Method: 构建EduHarm基准包含五个教育场景的安全-不安全指令对；提出三阶段防护框架：安全感知注意力重新对齐、分层安全判断、防御驱动双路由机制。

Result: 在八种越狱攻击策略下有效增强安全性，防止良性查询过度拒绝；在三个微调攻击数据集上保持对有害查询的鲁棒防御，同时保留良性微调的效用增益。

Conclusion: TSSF框架能够同时缓解越狱和微调攻击，为教育LLM提供有效的安全防护，在安全性和实用性之间取得良好平衡。

Abstract: Large Language Models (LLMs) are increasingly integrated into educational applications. However, they remain vulnerable to jailbreak and fine-tuning attacks, which can compromise safety alignment and lead to harmful outputs. Existing studies mainly focus on general safety evaluations, with limited attention to the unique safety requirements of educational scenarios. To address this gap, we construct EduHarm, a benchmark containing safe-unsafe instruction pairs across five representative educational scenarios, enabling systematic safety evaluation of educational LLMs. Furthermore, we propose a three-stage shield framework (TSSF) for educational LLMs that simultaneously mitigates both jailbreak and fine-tuning attacks. First, safety-aware attention realignment redirects attention toward critical unsafe tokens, thereby restoring the harmfulness feature that discriminates between unsafe and safe inputs. Second, layer-wise safety judgment identifies harmfulness features by aggregating safety cues across multiple layers to detect unsafe instructions. Finally, defense-driven dual routing separates safe and unsafe queries, ensuring normal processing for benign inputs and guarded responses for harmful ones. Extensive experiments across eight jailbreak attack strategies demonstrate that TSSF effectively strengthens safety while preventing over-refusal of benign queries. Evaluations on three fine-tuning attack datasets further show that it consistently achieves robust defense against harmful queries while maintaining preserving utility gains from benign fine-tuning.

</details>


### [28] [MedBench v4: A Robust and Scalable Benchmark for Evaluating Chinese Medical Language Models, Multimodal Models, and Intelligent Agents](https://arxiv.org/abs/2511.14439)
*Jinru Ding,Lu Lu,Chao Ding,Mouxiao Bian,Jiayuan Chen,Renjie Lu,Wenrao Pang,Xiaoqin Wu,Zhiqiang Liu,Luyi Jiang,Bing Han,Yunqiu Wang,Jie Xu*

Main category: cs.CL

TL;DR: MedBench v4是一个全国性的医疗AI基准测试平台，包含70多万个专家策划的任务，涵盖24个主要专科和91个次要专科，专门评估LLM、多模态模型和智能体在临床环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着医疗大语言模型、多模态模型和智能体的快速发展，需要能够反映真实临床工作流程和安全约束的评估框架。

Method: 构建包含70多万个任务的云基准测试基础设施，任务经过多阶段细化和多轮临床医生评审，开放式回答通过经过人类评分校准的LLM-as-a-judge进行评分。

Result: 基础LLM平均得分54.1/100（最佳：Claude Sonnet 4.5，62.5/100），但安全和伦理得分较低（18.4/100）。多模态模型表现更差（平均47.5/100），智能体表现最佳（平均79.8/100），基于Claude Sonnet 4.5的智能体在安全任务上达到88.9/100。

Conclusion: 基础模型在多模态推理和安全性方面仍存在差距，但具有治理意识的智能体编排可以显著提高临床准备度而不牺牲能力，该平台为医院、开发者和政策制定者提供了实用的医疗AI审计参考。

Abstract: Recent advances in medical large language models (LLMs), multimodal models, and agents demand evaluation frameworks that reflect real clinical workflows and safety constraints. We present MedBench v4, a nationwide, cloud-based benchmarking infrastructure comprising over 700,000 expert-curated tasks spanning 24 primary and 91 secondary specialties, with dedicated tracks for LLMs, multimodal models, and agents. Items undergo multi-stage refinement and multi-round review by clinicians from more than 500 institutions, and open-ended responses are scored by an LLM-as-a-judge calibrated to human ratings. We evaluate 15 frontier models. Base LLMs reach a mean overall score of 54.1/100 (best: Claude Sonnet 4.5, 62.5/100), but safety and ethics remain low (18.4/100). Multimodal models perform worse overall (mean 47.5/100; best: GPT-5, 54.9/100), with solid perception yet weaker cross-modal reasoning. Agents built on the same backbones substantially improve end-to-end performance (mean 79.8/100), with Claude Sonnet 4.5-based agents achieving up to 85.3/100 overall and 88.9/100 on safety tasks. MedBench v4 thus reveals persisting gaps in multimodal reasoning and safety for base models, while showing that governance-aware agentic orchestration can markedly enhance benchmarked clinical readiness without sacrificing capability. By aligning tasks with Chinese clinical guidelines and regulatory priorities, the platform offers a practical reference for hospitals, developers, and policymakers auditing medical AI.

</details>


### [29] [Tell Me: An LLM-powered Mental Well-being Assistant with RAG, Synthetic Dialogue Generation, and Agentic Planning](https://arxiv.org/abs/2511.14445)
*Trishala Jayesh Ahalpara*

Main category: cs.CL

TL;DR: Tell Me是一个基于大语言模型的心理健康系统，包含个性化对话助手、合成治疗对话生成器和AI健康规划器三个组件，旨在提供可访问的心理支持而非替代专业治疗。


<details>
  <summary>Details</summary>
Motivation: 解决心理健康支持的可及性问题，降低寻求帮助的门槛，同时应对治疗对话数据稀缺的挑战，促进NLP研究者与心理健康专业人士的跨学科合作。

Method: 采用检索增强生成技术实现个性化对话，基于用户档案生成合成治疗对话用于研究和数据增强，使用CrewAI实现动态自愈计划生成和冥想音频指导。

Result: 系统在精心设计的健康场景中通过自动LLM评估和人工用户研究进行了评估，展示了其在提供情境感知支持和降低支持障碍方面的有效性。

Conclusion: 对话助手能够有效补充现有护理，扩大心理健康资源的可及性，为人类-AI互动在健康领域的负责任创新提供了机会。

Abstract: We present Tell Me, a mental well-being system that leverages advances in large language models to provide accessible, context-aware support for users and researchers. The system integrates three components: (i) a retrieval-augmented generation (RAG) assistant for personalized, knowledge-grounded dialogue; (ii) a synthetic client-therapist dialogue generator conditioned on client profiles to facilitate research on therapeutic language and data augmentation; and (iii) a Well-being AI crew, implemented with CrewAI, that produces weekly self-care plans and guided meditation audio. The system is designed as a reflective space for emotional processing rather than a substitute for professional therapy. It illustrates how conversational assistants can lower barriers to support, complement existing care, and broaden access to mental health resources. To address the shortage of confidential therapeutic data, we introduce synthetic client-therapist dialogue generation conditioned on client profiles. Finally, the planner demonstrates an innovative agentic workflow for dynamically adaptive, personalized self-care, bridging the limitations of static well-being tools. We describe the architecture, demonstrate its functionalities, and report evaluation of the RAG assistant in curated well-being scenarios using both automatic LLM-based judgments and a human-user study. This work highlights opportunities for interdisciplinary collaboration between NLP researchers and mental health professionals to advance responsible innovation in human-AI interaction for well-being.

</details>


### [30] [Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning](https://arxiv.org/abs/2511.14460)
*Mingyue Cheng,Jie Ouyang,Shuo Yu,Ruiran Yan,Yucong Luo,Zirui Liu,Daoyu Wang,Qi Liu,Enhong Chen*

Main category: cs.CL

TL;DR: 本文系统化地扩展了MDP框架来定义LLM智能体的关键组件，并提出了Agent-R1训练框架，通过多跳问答任务验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前RL在LLM智能体训练中的应用仍处于早期阶段，缺乏专门针对LLM智能体场景的RL方法探索和灵活可扩展的训练框架。

Method: 1. 系统化扩展MDP框架来定义LLM智能体的关键组件；2. 提出Agent-R1训练框架，具有模块化、灵活性和用户友好性特点。

Result: 在多跳问答基准任务上的实验初步验证了所提方法和框架的有效性。

Conclusion: 本文为RL在LLM智能体训练领域的发展提供了方法论基础和实用框架支持。

Abstract: Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.

</details>


### [31] [LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation](https://arxiv.org/abs/2511.14531)
*David Carmel,Simone Filice,Guy Horowitz,Yoelle Maarek,Alex Shtoff,Oren Somekh,Ran Tavory*

Main category: cs.CL

TL;DR: LiveRAG benchmark是一个包含895个合成问答对的公开数据集，用于系统评估基于RAG的问答系统，源自SIGIR'2025 LiveRAG挑战赛，包含真实答案、支持证据以及难度和区分度评分。


<details>
  <summary>Details</summary>
Motivation: 随着RAG在生成式AI解决方案中日益重要，需要系统评估其有效性，但缺乏标准化的评估基准。

Method: 构建包含895个合成问答对的公开数据集，基于SIGIR'2025 LiveRAG挑战赛，添加真实答案、支持证据，并应用项目反应理论模型计算难度和区分度评分。

Result: 分析显示基准问题具有多样性、难度范围广，能有效区分系统能力差异。

Conclusion: LiveRAG基准将帮助社区推进RAG研究、进行系统评估并开发更稳健的问答系统。

Abstract: With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.

</details>


### [32] [Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak](https://arxiv.org/abs/2511.14566)
*Lucia Makaiová,Martin Fajčík,Antonín Jarolím*

Main category: cs.CL

TL;DR: 本文探索了文档级主张提取的评估方法，通过对齐算法计算两组主张的相似度，为事实核查领域提供可靠的评估框架。


<details>
  <summary>Details</summary>
Motivation: 文档级主张提取在事实核查领域仍面临挑战，现有的评估方法关注有限，需要开发能够有效比较模型提取主张和人工标注主张的评估框架。

Method: 研究了对齐两组主张的技术，通过计算对齐得分来衡量相似度，并在捷克和斯洛伐克新闻评论数据集上进行实验验证。

Result: 实验结果揭示了当前评估方法在文档级主张提取中的局限性，特别是在处理非正式语言、强本地语境和语言细微差别时的不足。

Conclusion: 需要开发更先进的评估方法，能够正确捕捉语义相似度并评估关键主张属性，如原子性、可核查性和去语境化。

Abstract: Document-level claim extraction remains an open challenge in the field of fact-checking, and subsequently, methods for evaluating extracted claims have received limited attention. In this work, we explore approaches to aligning two sets of claims pertaining to the same source document and computing their similarity through an alignment score. We investigate techniques to identify the best possible alignment and evaluation method between claim sets, with the aim of providing a reliable evaluation framework. Our approach enables comparison between model-extracted and human-annotated claim sets, serving as a metric for assessing the extraction performance of models and also as a possible measure of inter-annotator agreement. We conduct experiments on newly collected dataset-claims extracted from comments under Czech and Slovak news articles-domains that pose additional challenges due to the informal language, strong local context, and subtleties of these closely related languages. The results draw attention to the limitations of current evaluation approaches when applied to document-level claim extraction and highlight the need for more advanced methods-ones able to correctly capture semantic similarity and evaluate essential claim properties such as atomicity, checkworthiness, and decontextualization.

</details>


### [33] [Leveraging Digitized Newspapers to Collect Summarization Data in Low-Resource Languages](https://arxiv.org/abs/2511.14598)
*Noam Dahan,Omer Kidron,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: 提出了一种通过报纸头版预告收集自然摘要的新方法，适用于多种语言，并创建了希伯来语首个多文档摘要数据集


<details>
  <summary>Details</summary>
Motivation: 低资源语言的高质量摘要数据稀缺，而数字化历史报纸提供了丰富的自然标注数据源

Method: 开发自动流程从报纸头版预告中收集自然摘要，适用于不同语言资源水平

Result: 该方法在七种语言中验证有效，并成功创建了HEBTEASESUM希伯来语多文档摘要数据集

Conclusion: 报纸头版预告是获取多语言多文档摘要数据的有效来源，特别适用于低资源语言

Abstract: High quality summarization data remains scarce in under-represented languages. However, historical newspapers, made available through recent digitization efforts, offer an abundant source of untapped, naturally annotated data. In this work, we present a novel method for collecting naturally occurring summaries via Front-Page Teasers, where editors summarize full length articles. We show that this phenomenon is common across seven diverse languages and supports multi-document summarization. To scale data collection, we develop an automatic process, suited to varying linguistic resource levels. Finally, we apply this process to a Hebrew newspaper title, producing HEBTEASESUM, the first dedicated multi-document summarization dataset in Hebrew.

</details>


### [34] [A Method for Characterizing Disease Progression from Acute Kidney Injury to Chronic Kidney Disease](https://arxiv.org/abs/2511.14603)
*Yilu Fang,Jordan G. Nestor,Casey N. Ta,Jerard Z. Kneifati-Hayek,Chunhua Weng*

Main category: cs.CL

TL;DR: 使用电子健康记录数据动态追踪AKI患者临床演变，识别AKI向CKD进展的模式。通过聚类分析发现15种不同的AKI后临床状态，每种状态具有不同的CKD发展概率。


<details>
  <summary>Details</summary>
Motivation: 急性肾损伤（AKI）患者发展为慢性肾病（CKD）的风险很高，但识别最高风险患者仍然具有挑战性。

Method: 使用电子健康记录数据，通过纵向医疗代码和肌酐测量值聚类患者向量识别AKI后临床状态，使用多状态模型估计状态间转换概率和CKD进展概率。

Result: 在20,699名AKI患者中，3,491人（17%）发展为CKD。识别出15种不同的AKI后状态，75%患者在研究期间保持单一状态或仅进行一次转换。发现传统和新型CKD风险因素在不同临床状态中影响各异。

Conclusion: 本研究展示了一种数据驱动方法识别高风险AKI患者，支持开发用于早期CKD检测和干预的决策支持工具。

Abstract: Patients with acute kidney injury (AKI) are at high risk of developing chronic kidney disease (CKD), but identifying those at greatest risk remains challenging. We used electronic health record (EHR) data to dynamically track AKI patients' clinical evolution and characterize AKI-to-CKD progression. Post-AKI clinical states were identified by clustering patient vectors derived from longitudinal medical codes and creatinine measurements. Transition probabilities between states and progression to CKD were estimated using multi-state modeling. After identifying common post-AKI trajectories, CKD risk factors in AKI subpopulations were identified through survival analysis. Of 20,699 patients with AKI at admission, 3,491 (17%) developed CKD. We identified fifteen distinct post-AKI states, each with different probabilities of CKD development. Most patients (75%, n=15,607) remained in a single state or made only one transition during the study period. Both established (e.g., AKI severity, diabetes, hypertension, heart failure, liver disease) and novel CKD risk factors, with their impact varying across these clinical states. This study demonstrates a data-driven approach for identifying high-risk AKI patients, supporting the development of decision-support tools for early CKD detection and intervention.

</details>


### [35] [Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models](https://arxiv.org/abs/2511.14606)
*Shreya Adrita Banik,Niaz Nafi Rahman,Tahsina Moiukh,Farig Sadeque*

Main category: cs.CL

TL;DR: 本研究比较了人类标注与多种大语言模型在政治偏见检测中的表现，发现RoBERTa与人类标注最一致，GPT在零样本设置下表现最佳，揭示了人类与模型在政治偏见感知上的系统性差异。


<details>
  <summary>Details</summary>
Motivation: 尽管NLP技术已能自动分类政治偏见，但大语言模型与人类判断的一致性程度仍未被充分探索和理解，需要系统评估人类与模型在偏见检测上的差异。

Method: 构建手动标注的新闻文章数据集，评估标注一致性、偏见极性和模型间一致性，量化人类与模型在偏见感知上的差异，比较GPT、BERT、RoBERTa和FLAN等模型表现。

Result: 传统基于Transformer的模型中，RoBERTa与人类标签对齐度最高；生成模型如GPT在零样本设置下与人类标注的总体一致性最强；微调的RoBERTa模型在所有基线中获得了最高准确率和最强的人类标注对齐度。

Conclusion: 人类与LLMs在政治倾向感知上存在系统性差异，需要结合人类可解释性和模型可扩展性的混合评估框架来自动化媒体偏见检测。

Abstract: Detecting political bias in news media is a complex task that requires interpreting subtle linguistic and contextual cues. Although recent advances in Natural Language Processing (NLP) have enabled automatic bias classification, the extent to which large language models (LLMs) align with human judgment still remains relatively underexplored and not yet well understood. This study aims to present a comparative framework for evaluating the detection of political bias across human annotations and multiple LLMs, including GPT, BERT, RoBERTa, and FLAN. We construct a manually annotated dataset of news articles and assess annotation consistency, bias polarity, and inter-model agreement to quantify divergence between human and model perceptions of bias. Experimental results show that among traditional transformer-based models, RoBERTa achieves the highest alignment with human labels, whereas generative models such as GPT demonstrate the strongest overall agreement with human annotations in a zero-shot setting. Among all transformer-based baselines, our fine-tuned RoBERTa model acquired the highest accuracy and the strongest alignment with human-annotated labels. Our findings highlight systematic differences in how humans and LLMs perceive political slant, underscoring the need for hybrid evaluation frameworks that combine human interpretability with model scalability in automated media bias detection.

</details>


### [36] [Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities](https://arxiv.org/abs/2511.14631)
*Kahaan Gandhi,Boris Bolliet,Inigo Zubeldia*

Main category: cs.CL

TL;DR: 基于视觉语言模型的多智能体系统通过将图表作为可验证检查点，显著提升了端到端自主科学发现能力，在宇宙学和天体化学案例中实现了错误推理路径的自我修正和新数据集的适应性学习。


<details>
  <summary>Details</summary>
Motivation: 现有自主科学发现系统缺乏实时错误修正和适应性学习能力，需要开发能够通过视觉反馈进行自我验证和调整的智能系统。

Method: 使用视觉语言模型作为评判者，通过动态生成的领域特定评分标准评估图表，使智能体能够实时纠正错误并引导探索性数据分析。

Result: 在10个数据驱动发现任务的基准测试中，VLM增强系统达到0.7-0.8的pass@1分数，显著优于仅代码（0.2-0.3）和代码加文本（0.4-0.5）的基线方法，同时提供可审计的推理轨迹。

Conclusion: 视觉语言模型引导的多智能体系统能够有效提升自主科学发现的准确性和适应性，为数据驱动的科学探索提供了新的范式。

Abstract: We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: https://github.com/CMBAgents/cmbagent

</details>


### [37] [A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases](https://arxiv.org/abs/2511.14638)
*Tao Yang,Dandan Huang,Yunting Lin,Pengfei Wu,Zhikun Wu,Gangyuan Ma,Yulan Lu,Xinran Dong,Dingpeng Li,Junshuang Ge,Zhiyan Zhang,Xuanzhao Huang,Wenyan Nong,Yao Zhou,Hui Tang,Hongxi Yang,Shijie Zhang,Juan Li,Xiaojun Cao,Lin Yang,Xia Gao,Kaishou Xu,Xiaoqiong Gu,Wen Zhang,Huimin Xia,Li Liu,Wenhao Zhou,Mulin Jun Li*

Main category: cs.CL

TL;DR: RareSeek R1是一个专门用于罕见病诊断的AI系统，通过领域特定的临床语料库和分阶段指令调优，在嘈杂或重叠表型下实现最先进的诊断准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响全球数亿人，但诊断通常需要数年时间。传统方法将证据提取与诊断推理分离，而通用/医学大语言模型面临真实世界电子健康记录稀缺、领域知识陈旧和幻觉问题。

Method: 构建大型领域专用临床语料库和临床医生验证的推理集，通过分阶段指令调优、思维链学习和图基础检索开发RareSeek R1。

Result: 在多中心电子健康记录叙述和公共基准测试中，RareSeek R1达到最先进准确性、稳健泛化能力和稳定性。增强检索在叙述与优先变异配对时产生最大收益。人类研究显示其性能与经验丰富的医生相当。

Conclusion: 这项工作推进了以叙述为先、知识整合的推理范式，缩短诊断历程，并提供可审计、临床可转化的决策支持。

Abstract: Rare diseases affect hundreds of millions worldwide, yet diagnosis often spans years. Convectional pipelines decouple noisy evidence extraction from downstream inferential diagnosis, and general/medical large language models (LLMs) face scarce real world electronic health records (EHRs), stale domain knowledge, and hallucinations. We assemble a large, domain specialized clinical corpus and a clinician validated reasoning set, and develop RareSeek R1 via staged instruction tuning, chain of thought learning, and graph grounded retrieval. Across multicenter EHR narratives and public benchmarks, RareSeek R1 attains state of the art accuracy, robust generalization, and stability under noisy or overlapping phenotypes. Augmented retrieval yields the largest gains when narratives pair with prioritized variants by resolving ambiguity and aligning candidates to mechanisms. Human studies show performance on par with experienced physicians and consistent gains in assistive use. Notably, transparent reasoning highlights decisive non phenotypic evidence (median 23.1%, such as imaging, interventions, functional tests) underpinning many correct diagnoses. This work advances a narrative first, knowledge integrated reasoning paradigm that shortens the diagnostic odyssey and enables auditable, clinically translatable decision support.

</details>


### [38] [Graded strength of comparative illusions is explained by Bayesian inference](https://arxiv.org/abs/2511.14642)
*Yuhan Zhang,Erxiao Wang,Cory Shain*

Main category: cs.CL

TL;DR: 本文通过定量模型证明比较性语言幻觉可以用贝叶斯噪声信道理论解释，模型成功预测了幻觉强度的细微差异和代词与名词短语的影响。


<details>
  <summary>Details</summary>
Motivation: 研究比较性语言幻觉现象，验证噪声信道理论是否能解释这种系统性语言误感知，并超越先前研究的局限。

Method: 结合统计语言模型与人类行为数据，构建后验概率定量模型来预测幻觉强度，分析不同解释的贝叶斯概率。

Result: 模型成功解释了比较性幻觉的强度梯度以及代词与全名词短语than从句主语的影响，支持噪声信道理论。

Conclusion: 噪声信道推理可以作为统一的计算层面理论解释各种语言处理现象，包括幻觉性和非幻觉性情境。

Abstract: Like visual processing, language processing is susceptible to illusions in which people systematically misperceive stimuli. In one such case--the comparative illusion (CI), e.g., More students have been to Russia than I have--comprehenders tend to judge the sentence as acceptable despite its underlying nonsensical comparison. Prior research has argued that this phenomenon can be explained as Bayesian inference over a noisy channel: the posterior probability of an interpretation of a sentence is proportional to both the prior probability of that interpretation and the likelihood of corruption into the observed (CI) sentence. Initial behavioral work has supported this claim by evaluating a narrow set of alternative interpretations of CI sentences and showing that comprehenders favor interpretations that are more likely to have been corrupted into the illusory sentence. In this study, we replicate and go substantially beyond this earlier work by directly predicting the strength of illusion with a quantitative model of the posterior probability of plausible interpretations, which we derive through a novel synthesis of statistical language models with human behavioral data. Our model explains not only the fine gradations in the strength of CI effects, but also a previously unexplained effect caused by pronominal vs. full noun phrase than-clause subjects. These findings support a noisy-channel theory of sentence comprehension by demonstrating that the theory makes novel predictions about the comparative illusion that bear out empirically. This outcome joins related evidence of noisy channel processing in both illusory and non-illusory contexts to support noisy channel inference as a unified computational-level theory of diverse language processing phenomena.

</details>


### [39] [Bias in, Bias out: Annotation Bias in Multilingual Large Language Models](https://arxiv.org/abs/2511.14662)
*Xia Cui,Ziyi Huang,Naeemeh Adel*

Main category: cs.CL

TL;DR: 提出了一个理解NLP数据集中标注偏见的综合框架，包括指令偏见、标注者偏见和情境文化偏见，并提供了检测方法和缓解策略。


<details>
  <summary>Details</summary>
Motivation: NLP数据集中的标注偏见是开发多语言大语言模型的主要挑战，特别是在文化多样环境中。偏见会扭曲模型输出并加剧社会危害。

Method: 提出了一个分类法来区分不同类型的标注偏见，综述了检测方法（包括标注者间一致性、模型分歧和元数据分析），并提出了缓解策略，包括多样化标注者招募、迭代指南改进和事后模型调整。

Result: 开发了一个综合框架，包括偏见分类法、检测指标综合、适用于多语言环境的集成偏见缓解方法，以及对标注过程的伦理分析。

Conclusion: 这些见解旨在为LLMs提供更公平和文化基础的标注流程，促进多语言模型的公正发展。

Abstract: Annotation bias in NLP datasets remains a major challenge for developing multilingual Large Language Models (LLMs), particularly in culturally diverse settings. Bias from task framing, annotator subjectivity, and cultural mismatches can distort model outputs and exacerbate social harms. We propose a comprehensive framework for understanding annotation bias, distinguishing among instruction bias, annotator bias, and contextual and cultural bias. We review detection methods (including inter-annotator agreement, model disagreement, and metadata analysis) and highlight emerging techniques such as multilingual model divergence and cultural inference. We further outline proactive and reactive mitigation strategies, including diverse annotator recruitment, iterative guideline refinement, and post-hoc model adjustments. Our contributions include: (1) a typology of annotation bias; (2) a synthesis of detection metrics; (3) an ensemble-based bias mitigation approach adapted for multilingual settings, and (4) an ethical analysis of annotation processes. Together, these insights aim to inform more equitable and culturally grounded annotation pipelines for LLMs.

</details>


### [40] [Streamlining Industrial Contract Management with Retrieval-Augmented LLMs](https://arxiv.org/abs/2511.14671)
*Kristi Topollai,Tolga Dimlioglu,Anna Choromanska,Simon Odie,Reginald Hui*

Main category: cs.CL

TL;DR: 提出了一个基于检索增强生成(RAG)的模块化框架，用于自动化合同管理流程，能够识别问题修订并生成改进方案，在真实低资源条件下达到80%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 合同管理涉及条款审查和谈判，但自动化面临标注数据稀缺和非结构化历史合同丰富的挑战。

Method: 采用模块化框架，整合合成数据生成、语义条款检索、可接受性分类和基于奖励的对齐机制，构建RAG流程。

Result: 与行业合作伙伴共同开发评估，系统在识别和优化问题修订方面均达到80%以上的准确率。

Conclusion: 该系统在真实低资源条件下表现优异，为加速合同修订工作流程提供了实用解决方案。

Abstract: Contract management involves reviewing and negotiating provisions, individual clauses that define rights, obligations, and terms of agreement. During this process, revisions to provisions are proposed and iteratively refined, some of which may be problematic or unacceptable. Automating this workflow is challenging due to the scarcity of labeled data and the abundance of unstructured legacy contracts. In this paper, we present a modular framework designed to streamline contract management through a retrieval-augmented generation (RAG) pipeline. Our system integrates synthetic data generation, semantic clause retrieval, acceptability classification, and reward-based alignment to flag problematic revisions and generate improved alternatives. Developed and evaluated in collaboration with an industry partner, our system achieves over 80% accuracy in both identifying and optimizing problematic revisions, demonstrating strong performance under real-world, low-resource conditions and offering a practical means of accelerating contract revision workflows.

</details>


### [41] [Quadratic Term Correction on Heaps' Law](https://arxiv.org/abs/2511.14683)
*Oscar Fontanelli,Wentian Li*

Main category: cs.CL

TL;DR: 本文发现词汇类型-词汇标记关系在双对数坐标下仍呈轻微凹形，不符合幂律关系，而是用二次函数能完美拟合数据。通过随机抽取模型分析，发现这种曲率与"伪方差"相关。


<details>
  <summary>Details</summary>
Motivation: 传统Heap定律认为词汇类型与标记关系符合幂律函数，在双对数坐标下应为直线。但实际观察发现即使在双对数坐标下，类型-标记曲线仍呈轻微凹形，这挑战了幂律关系的有效性。

Method: 使用20部英文小说或作品进行回归分析，在双对数坐标下用线性项和二次项拟合类型-标记数据。同时采用"从袋中随机抽取彩色球并放回"的模型来分析曲率特性。

Result: 回归分析显示线性系数略大于1，二次系数约为-0.02。模型分析表明双对数坐标下的曲率等同于负的"伪方差"，虽然在大标记数时可能遇到数值不稳定性。

Conclusion: 词汇类型-标记关系在双对数坐标下确实存在轻微凹形，二次函数比幂律函数能更好地描述这种关系，这为理解语言统计特性提供了新的视角。

Abstract: Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a linear and quadratic term consistently lead to a linear coefficient of slightly larger than 1, and a quadratic coefficient around -0.02. Using the ``random drawing colored ball from the bag with replacement" model, we have shown that the curvature of the log-log scale is identical to a ``pseudo-variance" which is negative. Although a pseudo-variance calculation may encounter numeric instability when the number of tokens is large, due to the large values of pseudo-weights, this formalism provides a rough estimation of the curvature when the number of tokens is small.

</details>


### [42] [SMRC: Aligning Large Language Models with Student Reasoning for Mathematical Error Correction](https://arxiv.org/abs/2511.14684)
*Biaojie Zeng,Min Zhang,Juan Zhou,Fengrui Liu,Ruiyang Huang,Xin Lin*

Main category: cs.CL

TL;DR: 提出SMRC方法，使用蒙特卡洛树搜索探索最优修正路径，通过广度优先搜索和答案评估生成奖励信号，实现对学生数学推理过程的自动修正。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注模型内部的自修正，无法满足教育场景中"教师式"修正的需求，即系统性地指导和修正学生解题过程。

Method: 将学生推理建模为多步序列决策问题，引入蒙特卡洛树搜索探索修正路径，利用广度优先搜索和最终答案评估生成奖励信号，并通过反向传播机制实现细粒度过程监督。

Result: 在ProcessBench、MR-GSM8K和自建的MSEB数据集上，SMRC在效果和整体性能上显著优于现有方法。

Conclusion: SMRC方法能够有效对齐大语言模型与学生推理，实现教育场景中所需的系统性修正，在数学问题求解中表现出优越性能。

Abstract: Large language models (LLMs) often make reasoning errors when solving mathematical problems, and how to automatically detect and correct these errors has become an important research direction. However, existing approaches \textit{mainly focus on self-correction within the model}, which falls short of the ``teacher-style`` correction required in educational settings, \textit{i.e.}, systematically guiding and revising a student's problem-solving process. To address this gap, we propose \texttt{SMRC} (\textit{\underline{S}tudent \underline{M}athematical \underline{R}easoning \underline{C}orrection}), a novel method that aligns LLMs with student reasoning. Specifically, \texttt{SMRC} formulates student reasoning as a multi-step sequential decision problem and introduces Monte Carlo Tree Search (MCTS) to explore optimal correction paths. To reduce the cost of the annotating process-level rewards, we leverage breadth-first search (BFS) guided by LLMs and final-answer evaluation to generate reward signals, which are then distributed across intermediate reasoning steps via a back-propagation mechanism, enabling fine-grained process supervision. Additionally, we construct a benchmark for high school mathematics, MSEB (Multi-Solution Error Benchmark), consisting of 158 instances that include problem statements, student solutions, and correct reasoning steps. We further propose a dual evaluation protocol centered on \textbf{solution accuracy} and \textbf{correct-step retention}, offering a comprehensive measure of educational applicability. Experiments demonstrate that \texttt{SMRC} significantly outperforms existing methods on two public datasets (ProcessBench and MR-GSM8K) and our MSEB in terms of effectiveness and overall performance. The code and data are available at https://github.com/Mind-Lab-ECNU/SMRC.

</details>


### [43] [Encoding and Understanding Astrophysical Information in Large Language Model-Generated Summaries](https://arxiv.org/abs/2511.14685)
*Kiera McCormick,Rafael Martínez-Galarza*

Main category: cs.CL

TL;DR: 研究探索LLM嵌入是否能编码从科学测量获得的天体物理统计量，分析提示工程和语言要素对物理信息编码的影响。


<details>
  <summary>Details</summary>
Motivation: 利用LLM在跨领域泛化和上下文学习方面的能力，研究其是否能编码通常仅从科学测量获得且松散编码在文本描述中的物理信息。

Method: 使用天体物理学作为测试平台，通过稀疏自编码器从文本中提取可解释特征，分析提示工程和语言要素的作用。

Result: 未在摘要中明确说明具体实验结果。

Conclusion: 该研究旨在理解LLM如何编码物理信息，特别是提示工程和语言要素在编码测量所代表的物理特性方面的重要性。

Abstract: Large Language Models have demonstrated the ability to generalize well at many levels across domains, modalities, and even shown in-context learning capabilities. This enables research questions regarding how they can be used to encode physical information that is usually only available from scientific measurements, and loosely encoded in textual descriptions. Using astrophysics as a test bed, we investigate if LLM embeddings can codify physical summary statistics that are obtained from scientific measurements through two main questions: 1) Does prompting play a role on how those quantities are codified by the LLM? and 2) What aspects of language are most important in encoding the physics represented by the measurement? We investigate this using sparse autoencoders that extract interpretable features from the text.

</details>


### [44] [Ground Truth Generation for Multilingual Historical NLP using LLMs](https://arxiv.org/abs/2511.14688)
*Clovis Gladstone,Zhao Fang,Spencer Dean Stewart*

Main category: cs.CL

TL;DR: 使用大型语言模型为历史法语和中文文本生成标注数据，通过微调spaCy模型显著提升了词性标注、词形还原和命名实体识别在特定历史时期的性能


<details>
  <summary>Details</summary>
Motivation: 解决历史文本和低资源NLP面临的标注数据有限以及与现代网络语料领域不匹配的挑战

Method: 利用LLM生成历史文本的标注数据，然后用这些数据微调spaCy模型

Result: 在特定历史时期的测试中，词性标注、词形还原和命名实体识别任务都取得了显著提升

Conclusion: 领域特定模型的重要性得到验证，即使相对有限的合成数据也能改善计算人文学研究中低资源语料的NLP工具

Abstract: Historical and low-resource NLP remains challenging due to limited annotated data and domain mismatches with modern, web-sourced corpora. This paper outlines our work in using large language models (LLMs) to create ground-truth annotations for historical French (16th-20th centuries) and Chinese (1900-1950) texts. By leveraging LLM-generated ground truth on a subset of our corpus, we were able to fine-tune spaCy to achieve significant gains on period-specific tests for part-of-speech (POS) annotations, lemmatization, and named entity recognition (NER). Our results underscore the importance of domain-specific models and demonstrate that even relatively limited amounts of synthetic data can improve NLP tools for under-resourced corpora in computational humanities research.

</details>


### [45] [Talk, Snap, Complain: Validation-Aware Multimodal Expert Framework for Fine-Grained Customer Grievances](https://arxiv.org/abs/2511.14693)
*Rishu Kumar Singh,Navneet Shreya,Sarmistha Das,Apoorva Singh,Sriparna Saha*

Main category: cs.CL

TL;DR: 提出VALOR框架，用于多模态多轮客户支持对话中的投诉分析，通过视觉-文本语义对齐和专家路由机制实现细粒度投诉方面和严重程度分类。


<details>
  <summary>Details</summary>
Motivation: 现有投诉分析方法主要依赖单模态短文本，而实际客户支持对话中用户常同时提供文本投诉和视觉证据，需要更细粒度的多模态分析方法。

Method: 使用多专家推理设置，结合大规模生成模型和思维链提示进行决策，计算模态间语义对齐分数并通过元融合策略整合到最终分类中。

Result: 在标注细粒度方面和严重程度的多模态投诉数据集上评估，VALOR始终优于基线模型，尤其在信息分布在文本和图像中的复杂投诉场景中表现更佳。

Conclusion: 该研究强调了多模态交互和专家验证在实际投诉理解系统中的价值，支持联合国可持续发展目标9和12，促进更负责任的产品设计和消费者服务问责制。

Abstract: Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (CoT) prompting for nuanced decision-making. To ensure coherence between modalities, a semantic alignment score is computed and integrated into the final classification through a meta-fusion strategy. In alignment with the United Nations Sustainable Development Goals (UN SDGs), the proposed framework supports SDG 9 (Industry, Innovation and Infrastructure) by advancing AI-driven tools for robust, scalable, and context-aware service infrastructure. Further, by enabling structured analysis of complaint narratives and visual context, it contributes to SDG 12 (Responsible Consumption and Production) by promoting more responsive product design and improved accountability in consumer services. We evaluate VALOR on a curated multimodal complaint dataset annotated with fine-grained aspect and severity labels, showing that it consistently outperforms baseline models, especially in complex complaint scenarios where information is distributed across text and images. This study underscores the value of multimodal interaction and expert validation in practical complaint understanding systems. Resources related to data and codes are available here: https://github.com/sarmistha-D/VALOR

</details>


### [46] [Subword Tokenization Strategies for Kurdish Word Embeddings](https://arxiv.org/abs/2511.14696)
*Ali Salehi,Cassandra L. Jacobs*

Main category: cs.CL

TL;DR: 比较库尔德语词嵌入的三种分词策略：词级、基于语素和BPE方法，发现基于语素的方法在全面评估中表现最佳，而BPE由于覆盖率低导致评估偏差。


<details>
  <summary>Details</summary>
Motivation: 研究库尔德语这种低资源语言的分词策略，探索如何更好地保留形态相似性并构建有效的词嵌入空间。

Method: 开发基于BiLSTM-CRF的形态分割器，使用最小手动标注进行自举训练，比较三种分词方法在Word2Vec嵌入上的表现，采用包括相似性保持、聚类质量和语义组织在内的综合评估指标。

Result: BPE在形态相似性上表面表现更好，但仅评估了28.6%的测试用例，而语素模型评估了68.7%。全面评估显示基于语素的分词在嵌入空间组织、语义邻域结构和跨形态复杂度覆盖方面更优。

Conclusion: 在低资源语言处理中，基于覆盖率的评估至关重要，基于语素的分词方法为低资源语言处理提供了更好的解决方案。

Abstract: We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\% of test cases compared to 68.7\% for morpheme model, creating artificial performance inflation. When assessed comprehensively, morpheme-based tokenization demonstrates superior embedding space organization, better semantic neighborhood structure, and more balanced coverage across morphological complexity levels. These findings highlight the importance of coverage-aware evaluation in low-resource language processing and offers different tokenization methods for low-resourced language processing.

</details>


### [47] [Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance](https://arxiv.org/abs/2511.14709)
*Raha Aghaei,Ali A. Kiaei,Mahnaz Boush,Mahan Rofoosheh,Mohammad Zavvar*

Main category: cs.CL

TL;DR: LLMs通过自动化知识发现、促进假设生成、整合跨学科见解和促进创新生态系统合作，显著提升研发过程的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 分析LLMs在转变研发过程中的多重功能，探索如何通过自动化知识发现、假设生成和跨学科整合来提升研发效率。

Method: 通过广泛分析科学文献、专利数据库和实验数据，利用LLMs实现更灵活和知情的研发工作流程。

Result: LLMs显著提高了研发过程的效率和效果，加速了创新周期，缩短了突破性想法的上市时间。

Conclusion: LLMs通过多重功能转变研发过程，为创新生态系统提供强大的支持，显著提升研发效率和创新速度。

Abstract: This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market for breakthrough ideas.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [48] [FICO: Finite-Horizon Closed-Loop Factorization for Unified Multi-Agent Path Finding](https://arxiv.org/abs/2511.13961)
*Jiarui Li,Alessandro Zanardi,Runyu Zhang,Gioele Zardini*

Main category: cs.RO

TL;DR: 提出了一个系统级的多智能体路径规划框架，将规划与执行集成，通过闭环控制处理不确定性，支持数千智能体的实时响应。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体路径规划方法将规划与执行分离，以临时方式处理问题变体，缺乏对不确定性的显式建模。

Method: 引入MAPF系统作为形式模型，将MAPF视为控制设计问题，并提出基于因子分解的有限时域闭环算法FICO，利用组合结构实现高效闭环操作。

Result: FICO算法实现毫秒级响应，可扩展到数千智能体，在随机延迟和智能体到达情况下比开环基线计算时间减少两个数量级，吞吐量显著提高。

Conclusion: 通过系统级建模、因子分解和闭环设计，为分析和推进MAPF建立了原则性基础。

Abstract: Multi-Agent Path Finding is a fundamental problem in robotics and AI, yet most existing formulations treat planning and execution separately and address variants of the problem in an ad hoc manner. This paper presents a system-level framework for MAPF that integrates planning and execution, generalizes across variants, and explicitly models uncertainties. At its core is the MAPF system, a formal model that casts MAPF as a control design problem encompassing classical and uncertainty-aware formulations. To solve it, we introduce Finite-Horizon Closed-Loop Factorization (FICO), a factorization-based algorithm inspired by receding-horizon control that exploits compositional structure for efficient closed-loop operation. FICO enables real-time responses -- commencing execution within milliseconds -- while scaling to thousands of agents and adapting seamlessly to execution-time uncertainties. Extensive case studies demonstrate that it reduces computation time by up to two orders of magnitude compared with open-loop baselines, while delivering significantly higher throughput under stochastic delays and agent arrivals. These results establish a principled foundation for analyzing and advancing MAPF through system-level modeling, factorization, and closed-loop design.

</details>


### [49] [LIO-MARS: Non-uniform Continuous-time Trajectories for Real-time LiDAR-Inertial-Odometry](https://arxiv.org/abs/2511.13985)
*Jan Quenzel,Sven Behnke*

Main category: cs.RO

TL;DR: 提出了一种基于LiDAR-IMU的里程计系统LIO-MARS，通过多分辨率面元地图与高斯混合模型的联合配准，结合连续时间B样条轨迹，实现了高精度的实时定位。


<details>
  <summary>Details</summary>
Motivation: 自主机器人系统需要鲁棒的实时感知能力，特别是在搜救等应用中。LiDAR提供精确距离测量，IMU约束加速度和旋转，两者互补可提升定位精度和鲁棒性。

Method: 使用连续时间B样条轨迹，通过非均匀时间节点放置确保轨迹连续性；采用Kronecker和与积加速协方差和GMM计算；使用无迹变换去偏斜面元；引入相对位姿和预积分IMU伪测量的软约束。

Result: 在手持、地面和空中车辆数据集上的广泛评估表明，LIO-MARS相比现有LIO系统达到了最先进的性能水平，计算速度提升了3.3倍。

Conclusion: LIO-MARS通过创新的多分辨率面元地图配准、连续时间轨迹表示和计算优化，实现了高精度、高效率的LiDAR-IMU里程计，为自主机器人导航提供了可靠的解决方案。

Abstract: Autonomous robotic systems heavily rely on environment knowledge to safely navigate. For search & rescue, a flying robot requires robust real-time perception, enabled by complementary sensors. IMU data constrains acceleration and rotation, whereas LiDAR measures accurate distances around the robot. Building upon the LiDAR odometry MARS, our LiDAR-inertial odometry (LIO) jointly aligns multi-resolution surfel maps with a Gaussian mixture model (GMM) using a continuous-time B-spline trajectory. Our new scan window uses non-uniform temporal knot placement to ensure continuity over the whole trajectory without additional scan delay. Moreover, we accelerate essential covariance and GMM computations with Kronecker sums and products by a factor of 3.3. An unscented transform de-skews surfels, while a splitting into intra-scan segments facilitates motion compensation during spline optimization. Complementary soft constraints on relative poses and preintegrated IMU pseudo-measurements further improve robustness and accuracy. Extensive evaluation showcases the state-of-the-art quality of our LIO-MARS w.r.t. recent LIO systems on various handheld, ground and aerial vehicle-based datasets.

</details>


### [50] [Searching in Space and Time: Unified Memory-Action Loops for Open-World Object Retrieval](https://arxiv.org/abs/2511.14004)
*Taijing Chen,Sateesh Kumar,Junhong Xu,George Pavlakos,J oydeep Biswas,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: STAR框架统一时空查询和具身交互，通过长期记忆和工作记忆支持高效检索，在动态开放世界中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法只能解决部分问题：场景图忽略时间维度，时序推理不支持具身交互，动态场景图仍是封闭世界。需要统一时空检索和具身动作的框架。

Method: STAR框架结合非参数长期记忆和工作记忆，使用视觉语言模型在每一步选择时空动作，形成统一的决策循环。

Result: 在STARBench基准测试和Tiago机器人实验中，STAR持续优于场景图和纯记忆基线方法。

Conclusion: 将时间搜索和空间搜索作为统一问题处理具有显著优势，STAR框架有效解决了动态开放世界中的对象检索问题。

Abstract: Service robots must retrieve objects in dynamic, open-world settings where requests may reference attributes ("the red mug"), spatial context ("the mug on the table"), or past states ("the mug that was here yesterday"). Existing approaches capture only parts of this problem: scene graphs capture spatial relations but ignore temporal grounding, temporal reasoning methods model dynamics but do not support embodied interaction, and dynamic scene graphs handle both but remain closed-world with fixed vocabularies. We present STAR (SpatioTemporal Active Retrieval), a framework that unifies memory queries and embodied actions within a single decision loop. STAR leverages non-parametric long-term memory and a working memory to support efficient recall, and uses a vision-language model to select either temporal or spatial actions at each step. We introduce STARBench, a benchmark of spatiotemporal object search tasks across simulated and real environments. Experiments in STARBench and on a Tiago robot show that STAR consistently outperforms scene-graph and memory-only baselines, demonstrating the benefits of treating search in time and search in space as a unified problem.

</details>


### [51] [FACA: Fair and Agile Multi-Robot Collision Avoidance in Constrained Environments with Dynamic Priorities](https://arxiv.org/abs/2511.14024)
*Jaskirat Singh,Rohan Chandra*

Main category: cs.RO

TL;DR: FACA是一种公平敏捷的碰撞避免方法，通过自然语言协调多机器人系统，在受限空间中实现高效导航


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在救援、配送等关键应用中需要在受限空间高速导航，但拥挤环境中的角色优先级动态变化使得传统方法难以应对

Method: 使用自然语言通信协调任务，结合新型人工势场算法在冲突时自动创建"环岛"效应，平衡安全性与敏捷性

Result: FACA比基线方法效率提升3.5倍以上，任务完成时间减少70%以上，同时保持鲁棒的安全边界

Conclusion: FACA通过自然语言协调和智能势场设计，在多机器人系统中实现了安全与敏捷性的良好平衡

Abstract: Multi-robot systems are increasingly being used for critical applications such as rescuing injured people, delivering food and medicines, and monitoring key areas. These applications usually involve navigating at high speeds through constrained spaces such as small gaps. Navigating such constrained spaces becomes particularly challenging when the space is crowded with multiple heterogeneous agents all of which have urgent priorities. What makes the problem even harder is that during an active response situation, roles and priorities can quickly change on a dime without informing the other agents. In order to complete missions in such environments, robots must not only be safe, but also agile, able to dodge and change course at a moment's notice. In this paper, we propose FACA, a fair and agile collision avoidance approach where robots coordinate their tasks by talking to each other via natural language (just as people do). In FACA, robots balance safety with agility via a novel artificial potential field algorithm that creates an automatic ``roundabout'' effect whenever a conflict arises. Our experiments show that FACA achieves a improvement in efficiency, completing missions more than 3.5X faster than baselines with a time reduction of over 70% while maintaining robust safety margins.

</details>


### [52] [BIM-Discrepancy-Driven Active Sensing for Risk-Aware UAV-UGV Navigation](https://arxiv.org/abs/2511.14037)
*Hesam Mojtahedi,Reza Akhavian*

Main category: cs.RO

TL;DR: 提出基于BIM差异驱动的主动感知框架，用于无人机和地面机器人在动态建筑环境中的协同导航，通过风险触发重新扫描显著降低导航风险。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖静态BIM先验或有限的机载感知，无法适应动态建筑环境的变化，需要一种能够融合实时感知数据与BIM先验的主动感知方法。

Method: 融合空中和地面机器人的实时LiDAR数据与BIM先验，维护动态演化的2D占据地图，通过统一的走廊风险指标量化导航安全性，当风险超过阈值时无人机自主重新扫描受影响区域。

Result: 在PX4-Gazebo仿真中验证，风险触发重新扫描使平均走廊风险降低58%，地图熵降低43%，同时保持0.4米以上的安全间距，相比前沿探索方法在相同不确定性减少的情况下任务时间减半。

Conclusion: 将BIM先验与风险自适应空中感知相结合，能够为建筑机器人提供可扩展的、不确定性感知的自主性。

Abstract: This paper presents a BIM-discrepancy-driven active sensing framework for cooperative navigation between unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) in dynamic construction environments. Traditional navigation approaches rely on static Building Information Modeling (BIM) priors or limited onboard perception. In contrast, our framework continuously fuses real-time LiDAR data from aerial and ground robots with BIM priors to maintain an evolving 2D occupancy map. We quantify navigation safety through a unified corridor-risk metric integrating occupancy uncertainty, BIM-map discrepancy, and clearance. When risk exceeds safety thresholds, the UAV autonomously re-scans affected regions to reduce uncertainty and enable safe replanning. Validation in PX4-Gazebo simulation with Robotec GPU LiDAR demonstrates that risk-triggered re-scanning reduces mean corridor risk by 58% and map entropy by 43% compared to static BIM navigation, while maintaining clearance margins above 0.4 m. Compared to frontier-based exploration, our approach achieves similar uncertainty reduction in half the mission time. These results demonstrate that integrating BIM priors with risk-adaptive aerial sensing enables scalable, uncertainty-aware autonomy for construction robotics.

</details>


### [53] [FlexiCup: Wireless Multimodal Suction Cup with Dual-Zone Vision-Tactile Sensing](https://arxiv.org/abs/2511.14139)
*Junhao Gong,Shoujie Li,Kit-Wa Sou,Changqing Guo,Hourong Huang,Tong Wu,Yifan Xie,Chenxin Liang,Chuqiao Lyu,Xiaojun Liang,Wenbo Ding*

Main category: cs.RO

TL;DR: FlexiCup是一种完全无线多模态吸盘，集成了双区域视觉触觉传感，支持真空和伯努利两种吸附模式，通过模块化机械配置实现无线自主操作。


<details>
  <summary>Details</summary>
Motivation: 传统吸盘缺乏传感能力，无法在非结构化环境中进行接触感知操作。需要开发具有传感功能的吸盘来改善在复杂环境中的抓取性能。

Method: 设计双区域传感系统：中心区域通过照明控制在视觉和触觉模态间动态切换用于接触检测，外围区域提供连续空间感知用于接近规划。采用模块化机械配置支持两种吸附模式，并实现完全无线自主操作。

Result: 在结构化表面上的模块化感知驱动抓取中，真空模式平均成功率90.0%，伯努利模式86.7%。基于扩散的端到端学习在倾斜运输任务中成功率73.3%，橙子提取任务中66.7%。双区域观测协调提供13%的接触感知操作改进。

Conclusion: FlexiCup通过集成多模态传感和双吸附模式，显著提升了吸盘在非结构化环境中的操作能力，证明了无线多模态吸盘在复杂抓取任务中的有效性。

Abstract: Conventional suction cups lack sensing capabilities for contact-aware manipulation in unstructured environments. This paper presents FlexiCup, a fully wireless multimodal suction cup that integrates dual-zone vision-tactile sensing. The central zone dynamically switches between vision and tactile modalities via illumination control for contact detection, while the peripheral zone provides continuous spatial awareness for approach planning. FlexiCup supports both vacuum and Bernoulli suction modes through modular mechanical configurations, achieving complete wireless autonomy with onboard computation and power. We validate hardware versatility through dual control paradigms. Modular perception-driven grasping across structured surfaces with varying obstacle densities demonstrates comparable performance between vacuum (90.0% mean success) and Bernoulli (86.7% mean success) modes. Diffusion-based end-to-end learning achieves 73.3% success on inclined transport and 66.7% on orange extraction tasks. Ablation studies confirm that multi-head attention coordinating dual-zone observations provides 13% improvements for contact-aware manipulation. Hardware designs and firmware are available at https://anonymous.4open.science/api/repo/FlexiCup-DA7D/file/index.html?v=8f531b44.

</details>


### [54] [AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models](https://arxiv.org/abs/2511.14148)
*Yuhua Jiang,Shuang Cheng,Yan Ding,Feifei Gao,Biqing Qi*

Main category: cs.RO

TL;DR: 提出AsyncVLA框架，通过异步流匹配和自校正机制改进VLA模型，在长时程任务中实现更稳定的动作生成。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型使用同步流匹配，依赖刚性的均匀时间调度，缺乏动作上下文感知和异步自校正能力，在长时程任务中容易因单个动作错误导致级联失败。

Method: 引入异步流匹配，在非均匀时间调度中生成动作token；设计置信度评估器提取初始生成动作的置信度，选择性精炼不准确的动作token；提出SFM和AFM的统一训练流程。

Result: 在机器人操作基准测试中，AsyncVLA表现出数据效率和自校正能力，在通用具身评估中达到最先进的结果。

Conclusion: AsyncVLA通过异步生成和自校正机制显著提升了VLA模型在长时程任务中的稳定性和性能。

Abstract: Vision-language-action (VLA) models have recently emerged as a powerful paradigm for building generalist robots. However, traditional VLA models that generate actions through flow matching (FM) typically rely on rigid and uniform time schedules, i.e., synchronous FM (SFM). Without action context awareness and asynchronous self-correction, SFM becomes unstable in long-horizon tasks, where a single action error can cascade into failure. In this work, we propose asynchronous flow matching VLA (AsyncVLA), a novel framework that introduces temporal flexibility in asynchronous FM (AFM) and enables self-correction in action generation. AsyncVLA breaks from the vanilla SFM in VLA models by generating the action tokens in a non-uniform time schedule with action context awareness. Besides, our method introduces the confidence rater to extract confidence of the initially generated actions, enabling the model to selectively refine inaccurate action tokens before execution. Moreover, we propose a unified training procedure for SFM and AFM that endows a single model with both modes, improving KV-cache utilization. Extensive experiments on robotic manipulation benchmarks demonstrate that AsyncVLA is data-efficient and exhibits self-correction ability. AsyncVLA achieves state-of-the-art results across general embodied evaluations due to its asynchronous generation in AFM. Our code is available at https://github.com/YuhuaJiang2002/AsyncVLA.

</details>


### [55] [RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action](https://arxiv.org/abs/2511.14161)
*Xiaoquan Sun,Ruijian Zhang,Kang Pang,Bingchen Miao,Yuxiang Tan,Zhen Yang,Ming Li,Jiayu Chen*

Main category: cs.RO

TL;DR: RoboTidy是一个统一的语言引导家庭整理基准，支持视觉-语言-动作和视觉-语言导航的训练与评估，填补了具身AI中现实家庭整理评估的关键空白。


<details>
  <summary>Details</summary>
Motivation: 当前的家庭整理基准既不能模拟用户偏好，也不支持移动性，且泛化能力差，难以全面评估语言到动作的集成能力。

Method: 提供500个逼真的3D高斯溅射家庭场景，涵盖500个物体和容器，将整理表述为"动作(物体,容器)"列表，并提供6.4k高质量操作演示轨迹和1.5k导航轨迹。

Result: 构建了一个可扩展的平台，支持小样本和大规模训练，并在真实世界中部署用于物体整理，建立了端到端的家庭整理基准。

Conclusion: RoboTidy通过实现语言引导机器人的整体和现实评估，填补了具身AI中的关键空白。

Abstract: Household tidying is an important application area, yet current benchmarks neither model user preferences nor support mobility, and they generalize poorly, making it hard to comprehensively assess integrated language-to-action capabilities. To address this, we propose RoboTidy, a unified benchmark for language-guided household tidying that supports Vision-Language-Action (VLA) and Vision-Language-Navigation (VLN) training and evaluation. RoboTidy provides 500 photorealistic 3D Gaussian Splatting (3DGS) household scenes (covering 500 objects and containers) with collisions, formulates tidying as an "Action (Object, Container)" list, and supplies 6.4k high-quality manipulation demonstration trajectories and 1.5k naviagtion trajectories to support both few-shot and large-scale training. We also deploy RoboTidy in the real world for object tidying, establishing an end-to-end benchmark for household tidying. RoboTidy offers a scalable platform and bridges a key gap in embodied AI by enabling holistic and realistic evaluation of language-guided robots.

</details>


### [56] [Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion](https://arxiv.org/abs/2511.14178)
*Zhuo Li,Junjia Liu,Zhipeng Dong,Tao Teng,Quentin Rouxel,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: VLA-Pilot是一种即插即用的推理时策略引导方法，无需额外微调或数据收集即可实现预训练VLA模型的零样本部署，显著提升下游操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言-动作模型在下游部署时存在性能显著下降的问题，而微调方法依赖昂贵的演示数据收集和密集计算，在实际应用中不实用。

Method: 提出VLA-Pilot方法，这是一种推理时策略引导技术，无需微调或额外数据收集，通过即插即用的方式提升预训练VLA模型的性能。

Result: 在六个真实世界下游操作任务和两种不同机器人平台上进行评估，涵盖分布内和分布外场景，实验结果显示VLA-Pilot显著提升了现成预训练VLA策略的成功率。

Conclusion: VLA-Pilot能够实现预训练VLA模型的鲁棒零样本泛化，适用于多样化任务和机器人平台，为实际部署提供了实用解决方案。

Abstract: Vision-Language-Action (VLA) models have demonstrated significant potential in real-world robotic manipulation. However, pre-trained VLA policies still suffer from substantial performance degradation during downstream deployment. Although fine-tuning can mitigate this issue, its reliance on costly demonstration collection and intensive computation makes it impractical in real-world settings. In this work, we introduce VLA-Pilot, a plug-and-play inference-time policy steering method for zero-shot deployment of pre-trained VLA without any additional fine-tuning or data collection. We evaluate VLA-Pilot on six real-world downstream manipulation tasks across two distinct robotic embodiments, encompassing both in-distribution and out-of-distribution scenarios. Experimental results demonstrate that VLA-Pilot substantially boosts the success rates of off-the-shelf pre-trained VLA policies, enabling robust zero-shot generalization to diverse tasks and embodiments. Experimental videos and code are available at: https://rip4kobe.github.io/vla-pilot/.

</details>


### [57] [Dual-Variable Force Characterisation method for Human-Robot Interaction in Wearable Robotics](https://arxiv.org/abs/2511.14327)
*Felipe Ballen-Moreno,Pasquale Ferrentino,Milan Amighi,Bram Vanderborght,Tom Verstraten*

Main category: cs.RO

TL;DR: 本文提出了一种双变量表征方法，用于分析可穿戴机器人物理交互中的法向和切向力，解决了现有单变量方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 可穿戴机器人与人体之间的物理交互复杂，涉及多自由度运动和软组织非线性行为，现有单变量表征方法无法准确描述这种复杂交互。

Method: 引入双变量表征方法，同时考虑法向力和切向力，通过分析不同场景和材料模型下的归一化均方误差来评估单变量拟合对力和扭矩响应的影响。

Result: 该方法证明了在表征过程中纳入两个变量的重要性，为模拟可穿戴机器人袖带与人体肢体之间的物理交互提供了更准确的基础。

Conclusion: 双变量表征方法能够更可靠地识别材料参数，提高对可穿戴机器人物理交互的理解，为改善袖带设计和安全性提供了有价值的见解。

Abstract: Understanding the physical interaction with wearable robots is essential to ensure safety and comfort. However, this interaction is complex in two key aspects: (1) the motion involved, and (2) the non-linear behaviour of soft tissues. Multiple approaches have been undertaken to better understand this interaction and to improve the quantitative metrics of physical interfaces or cuffs. As these two topics are closely interrelated, finite modelling and soft tissue characterisation offer valuable insights into pressure distribution and shear stress induced by the cuff. Nevertheless, current characterisation methods typically rely on a single fitting variable along one degree of freedom, which limits their applicability, given that interactions with wearable robots often involve multiple degrees of freedom. To address this limitation, this work introduces a dual-variable characterisation method, involving normal and tangential forces, aimed at identifying reliable material parameters and evaluating the impact of single-variable fitting on force and torque responses. This method demonstrates the importance of incorporating two variables into the characterisation process by analysing the normalized mean square error (NMSE) across different scenarios and material models, providing a foundation for simulation at the closest possible level, with a focus on the cuff and the human limb involved in the physical interaction between the user and the wearable robot.

</details>


### [58] [MA-SLAM: Active SLAM in Large-Scale Unknown Environment using Map Aware Deep Reinforcement Learning](https://arxiv.org/abs/2511.14330)
*Yizhen Yin,Yuhua Qi,Dapeng Feng,Hongbo Chen,Hongjun Ma,Jin Wu,Yi Jiang*

Main category: cs.RO

TL;DR: 提出MA-SLAM系统，基于深度强化学习的主动SLAM方法，通过结构化地图表示和全局规划器优化探索路径，显著减少大规模环境中的探索时间和距离。


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法在小规模受控环境中有效，但在大规模多样化环境中面临探索时间长、路径优化不足的挑战。

Method: 使用结构化地图表示（离散化空间数据、整合边界点和历史轨迹），结合深度强化学习决策模块和全局规划器来优化长距离探索路径。

Result: 在三个仿真环境和真实无人地面车辆上的实验表明，相比最先进方法，显著减少了探索时间和距离。

Conclusion: MA-SLAM系统能够有效解决大规模环境中的高效探索问题，通过结构化地图和全局规划策略提升主动SLAM性能。

Abstract: Active Simultaneous Localization and Mapping (Active SLAM) involves the strategic planning and precise control of a robotic system's movement in order to construct a highly accurate and comprehensive representation of its surrounding environment, which has garnered significant attention within the research community. While the current methods demonstrate efficacy in small and controlled settings, they face challenges when applied to large-scale and diverse environments, marked by extended periods of exploration and suboptimal paths of discovery. In this paper, we propose MA-SLAM, a Map-Aware Active SLAM system based on Deep Reinforcement Learning (DRL), designed to address the challenge of efficient exploration in large-scale environments. In pursuit of this objective, we put forward a novel structured map representation. By discretizing the spatial data and integrating the boundary points and the historical trajectory, the structured map succinctly and effectively encapsulates the visited regions, thereby serving as input for the deep reinforcement learning based decision module. Instead of sequentially predicting the next action step within the decision module, we have implemented an advanced global planner to optimize the exploration path by leveraging long-range target points. We conducted experiments in three simulation environments and deployed in a real unmanned ground vehicle (UGV), the results demonstrate that our approach significantly reduces both the duration and distance of exploration compared with state-of-the-art methods.

</details>


### [59] [Simultaneous Localization and 3D-Semi Dense Mapping for Micro Drones Using Monocular Camera and Inertial Sensors](https://arxiv.org/abs/2511.14335)
*Jeryes Danial,Yosi Ben Asher,Itzik Klein*

Main category: cs.RO

TL;DR: 提出了一种结合稀疏关键点姿态估计与稠密边缘重建的边缘感知轻量级单目SLAM系统，通过深度学习深度预测和边缘检测，融合惯性数据解决尺度模糊问题，实现资源受限环境下的实时建图和导航。


<details>
  <summary>Details</summary>
Motivation: 当前单目SLAM算法存在稀疏方法缺乏详细几何信息、学习驱动方法计算密集、以及尺度模糊影响精度等问题，需要一种轻量级且能提供丰富几何信息的解决方案。

Method: 结合稀疏关键点姿态估计与稠密边缘重建，使用深度学习进行深度预测和边缘检测，通过优化算法精化关键点和边缘的几何一致性，融合惯性数据通过扩展卡尔曼滤波器解决尺度模糊。

Result: 系统在低功耗平台上实时运行，在DJI Tello无人机上验证，并在室内走廊和TUM RGBD数据集上展示了鲁棒的自主导航和避障能力。

Conclusion: 该方法为资源受限环境下的实时建图和导航提供了有效实用的解决方案。

Abstract: Monocular simultaneous localization and mapping (SLAM) algorithms estimate drone poses and build a 3D map using a single camera. Current algorithms include sparse methods that lack detailed geometry, while learning-driven approaches produce dense maps but are computationally intensive. Monocular SLAM also faces scale ambiguities, which affect its accuracy. To address these challenges, we propose an edge-aware lightweight monocular SLAM system combining sparse keypoint-based pose estimation with dense edge reconstruction. Our method employs deep learning-based depth prediction and edge detection, followed by optimization to refine keypoints and edges for geometric consistency, without relying on global loop closure or heavy neural computations. We fuse inertial data with vision by using an extended Kalman filter to resolve scale ambiguity and improve accuracy. The system operates in real time on low-power platforms, as demonstrated on a DJI Tello drone with a monocular camera and inertial sensors. In addition, we demonstrate robust autonomous navigation and obstacle avoidance in indoor corridors and on the TUM RGBD dataset. Our approach offers an effective, practical solution to real-time mapping and navigation in resource-constrained environments.

</details>


### [60] [Going Places: Place Recognition in Artificial and Natural Systems](https://arxiv.org/abs/2511.14341)
*Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 这篇综述整合了机器人系统、动物研究和人类研究，探讨不同系统如何编码和回忆地点，提出了统一的概念框架来考虑和开发地点识别机制。


<details>
  <summary>Details</summary>
Motivation: 地点识别对于生物导航和自主系统都至关重要，需要从不同系统的角度理解地点编码和回忆的机制，以促进人工定位系统的发展。

Method: 通过综合机器人系统、动物研究和人类研究的发现，分析计算和表征策略，包括拓扑映射、线索整合和记忆管理等收敛解决方案。

Result: 识别了动物系统的多模态导航和环境适应机制，人类研究的语义地点概念、文化影响和内省能力，以及人工系统的可扩展架构和数据驱动模型。

Conclusion: 提出了统一的概念框架，确定了泛化性、鲁棒性和环境变异性等关键挑战，旨在通过连接动物导航研究和人类空间认知研究的见解来促进人工地点识别系统的创新。

Abstract: Place recognition, the ability to identify previously visited locations, is critical for both biological navigation and autonomous systems. This review synthesizes findings from robotic systems, animal studies, and human research to explore how different systems encode and recall place. We examine the computational and representational strategies employed across artificial systems, animals, and humans, highlighting convergent solutions such as topological mapping, cue integration, and memory management. Animal systems reveal evolved mechanisms for multimodal navigation and environmental adaptation, while human studies provide unique insights into semantic place concepts, cultural influences, and introspective capabilities. Artificial systems showcase scalable architectures and data-driven models. We propose a unifying set of concepts by which to consider and develop place recognition mechanisms and identify key challenges such as generalization, robustness, and environmental variability. This review aims to foster innovations in artificial localization by connecting future developments in artificial place recognition systems to insights from both animal navigation research and human spatial cognition studies.

</details>


### [61] [Perception-aware Exploration for Consumer-grade UAVs](https://arxiv.org/abs/2511.14393)
*Svetlana Seliunina,Daniel Schleich,Sven Behnke*

Main category: cs.RO

TL;DR: 将多无人机自主探索技术扩展到消费级无人机，提出包含深度估计视点选择、轨迹规划和半分布式通信的完整流程


<details>
  <summary>Details</summary>
Motivation: 将先进的多无人机自主探索技术应用于消费级无人机，克服硬件限制，实现安全的环境探索和地图重建

Method: 提出完整流程：选择可进行深度估计的视点对，规划满足运动约束的轨迹，采用半分布式通信方案平衡工作负载

Result: 通过模拟验证了不同数量无人机下的性能，证明即使在消费级无人机硬件限制下也能安全探索环境并重建地图

Conclusion: 成功将多无人机自主探索技术扩展到消费级平台，为低成本无人机应用提供了可行的解决方案

Abstract: In our work, we extend the current state-of-the-art approach for autonomous multi-UAV exploration to consumer-level UAVs, such as the DJI Mini 3 Pro. We propose a pipeline that selects viewpoint pairs from which the depth can be estimated and plans the trajectory that satisfies motion constraints necessary for odometry estimation. For the multi-UAV exploration, we propose a semi-distributed communication scheme that distributes the workload in a balanced manner. We evaluate our model performance in simulation for different numbers of UAVs and prove its ability to safely explore the environment and reconstruct the map even with the hardware limitations of consumer-grade UAVs.

</details>


### [62] [Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning](https://arxiv.org/abs/2511.14396)
*Xiuxiu Qi,Yu Yang,Jiannong Cao,Luyao Bai,Chongshan Fan,Chengtai Cao,Hongpeng Wang*

Main category: cs.RO

TL;DR: 提出了CCoL框架，通过视觉-语言-动作的连续协同学习和语义-物理对齐，解决了行为克隆中的复合误差问题，实现了更平滑准确的动作执行。


<details>
  <summary>Details</summary>
Motivation: 解决行为克隆中复合误差导致的物理不连续性和语义-物理错位问题，提高机器人动作执行的准确性和连续性。

Method: 采用视觉-语言-本体感觉输入的连续协同学习，通过双向交叉注意力将语言语义锚定到视觉运动表示中，学习动作生成的上下文信息。

Result: 在三个仿真套件中平均相对提升8.0%，在双手插入任务中相对增益达19.2%，在7自由度机器人上验证了在未见和噪声物体状态下的泛化能力。

Conclusion: CCoL框架通过连续协同学习和语义-物理对齐，有效克服了行为克隆中的复合误差问题，实现了更鲁棒平滑的动作执行轨迹。

Abstract: Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance. Existing approaches mitigate compounding errors through data augmentation, expressive representation, or temporal abstraction. However, they suffer from physical discontinuities and semantic-physical misalignment, leading to inaccurate action cloning and intermittent execution. In this paper, we present Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL), a novel BC framework that ensures temporally consistent execution and fine-grained semantic grounding. It generates robust and smooth action execution trajectories through continuous co-learning across vision, language, and proprioceptive inputs (e.g., robot internal states). Meanwhile, we anchor language semantics to visuomotor representations by a bidirectional cross-attention to learn contextual information for action generation, successfully overcoming the problem of semantic-physical misalignment. Extensive experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites, with up to 19.2% relative gain in human-demonstrated bimanual insertion tasks. Real-world tests on a 7-DoF robot further confirm CCoL's generalization under unseen and noisy object states.

</details>


### [63] [Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning](https://arxiv.org/abs/2511.14427)
*Rickmer Krohn,Vignesh Prasad,Gabriele Tiboni,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: MSDP是一个多感官动态预训练框架，通过掩码自编码学习多感官表征，结合非对称架构实现快速、鲁棒的多感官机器人操作学习


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在多感官设置中学习困难的问题，特别是在存在感官噪声和动态变化的情况下

Method: 基于掩码自编码训练transformer编码器重建多感官观测，下游策略学习采用非对称架构，评论家使用交叉注意力提取动态特征，演员接收稳定的池化表征

Result: 在多种接触丰富的机器人操作任务中展示加速学习和鲁棒性能，对传感器噪声和物体动态变化具有强鲁棒性，真实机器人上仅需6000次在线交互即可达到高成功率

Conclusion: MSDP为复杂多感官机器人控制提供了一个简单而强大的解决方案

Abstract: Effective contact-rich manipulation requires robots to synergistically leverage vision, force, and proprioception. However, Reinforcement Learning agents struggle to learn in such multisensory settings, especially amidst sensory noise and dynamic changes. We propose MultiSensory Dynamic Pretraining (MSDP), a novel framework for learning expressive multisensory representations tailored for task-oriented policy learning. MSDP is based on masked autoencoding and trains a transformer-based encoder by reconstructing multisensory observations from only a subset of sensor embeddings, leading to cross-modal prediction and sensor fusion. For downstream policy learning, we introduce a novel asymmetric architecture, where a cross-attention mechanism allows the critic to extract dynamic, task-specific features from the frozen embeddings, while the actor receives a stable pooled representation to guide its actions. Our method demonstrates accelerated learning and robust performance under diverse perturbations, including sensor noise, and changes in object dynamics. Evaluations in multiple challenging, contact-rich robot manipulation tasks in simulation and the real world showcase the effectiveness of MSDP. Our approach exhibits strong robustness to perturbations and achieves high success rates on the real robot with as few as 6,000 online interactions, offering a simple yet powerful solution for complex multisensory robotic control.

</details>


### [64] [Mutation Testing for Industrial Robotic Systems](https://arxiv.org/abs/2511.14432)
*Marcela Gonçalves dos Santos,Sylvain Hallé,Fábio Petrillo*

Main category: cs.RO

TL;DR: 本文提出了针对工业机器人系统的领域特定变异测试方法，通过定义捕获机器人动作和传感器语义的变异算子，提高了测试套件的有效性。


<details>
  <summary>Details</summary>
Motivation: 工业机器人系统故障可能导致严重事故和高昂停机成本，传统变异测试算子不适用于涉及消息命令和物理世界交互的机器人程序。

Method: 提出在高层读写操作级别生成有意义变异体的方法，包括运动、夹爪动作和传感器噪声注入等机器人特定操作。

Result: 在拾取放置场景的实证研究表明，该方法产生更多信息丰富的变异体，相比传统算子减少了无效或等价情况的数量。

Conclusion: 变异测试有潜力提高测试套件质量，为更安全可靠的工业机器人系统做出贡献。

Abstract: Industrial robotic systems (IRS) are increasingly deployed in diverse environments, where failures can result in severe accidents and costly downtime. Ensuring the reliability of the software controlling these systems is therefore critical. Mutation testing, a technique widely used in software engineering, evaluates the effectiveness of test suites by introducing small faults, or mutants, into the code. However, traditional mutation operators are poorly suited to robotic programs, which involve message-based commands and interactions with the physical world. This paper explores the adaptation of mutation testing to IRS by defining domain-specific mutation operators that capture the semantics of robot actions and sensor readings. We propose a methodology for generating meaningful mutants at the level of high-level read and write operations, including movement, gripper actions, and sensor noise injection. An empirical study on a pick-and-place scenario demonstrates that our approach produces more informative mutants and reduces the number of invalid or equivalent cases compared to conventional operators. Results highlight the potential of mutation testing to enhance test suite quality and contribute to safer, more reliable industrial robotic systems.

</details>


### [65] [Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies](https://arxiv.org/abs/2511.14434)
*Marlow Fawn,Matthias Scheutz*

Main category: cs.RO

TL;DR: 提出一种将谐波控制李雅普诺夫-屏障函数与机器人策略结合的方法，将不安全策略转化为具有形式化保证的安全策略


<details>
  <summary>Details</summary>
Motivation: 将基于信号时序逻辑的安全约束与任意机器人策略结合，确保安全性的同时保持任务驱动行为

Method: 通过HCLBF导出的安全证书将两个组件结合，产生既保持安全又保留任务驱动行为的指令

Result: 通过概念验证实现，展示了静止机械臂在桌面移动任务中能够避免与障碍物碰撞

Conclusion: 该方法可推广到更复杂的规范要求和动态任务场景

Abstract: We propose a method for combining Harmonic Control Lyapunov-Barrier Functions (HCLBFs) derived from Signal Temporal Logic (STL) specifications with any given robot policy to turn an unsafe policy into a safe one with formal guarantees.  The two components are combined via HCLBF-derived safety certificates, thus producing commands that preserve both safety and task-driven behavior.  We demonstrate with a simple proof-of-concept implementation for an object-centric force-based policy trained through reinforcement learning for a movement task of a stationary robot arm that is able to avoid colliding with obstacles on a table top after combining the policy with the safety constraints.  The proposed method can be generalized to more complex specifications and dynamic task settings.

</details>


### [66] [Advancing Minimally Invasive Precision Surgery in Open Cavities with Robotic Flexible Endoscopy](https://arxiv.org/abs/2511.14458)
*Michelle Mattille,Alexandre Mesot,Miriam Weisskopf,Nicole Ochsenbein-Kölble,Ueli Moehrlen,Bradley J. Nelson,Quentin Boehler*

Main category: cs.RO

TL;DR: 提出了一种用于开放腔体内窥镜手术的机器人平台，结合磁驱动柔性内窥镜和半自主导航能力，通过实时场景重建增强手术感知，并在羊模型中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 柔性机器人在微创手术中具有优势，但在开放腔体中的内窥镜干预面临控制困难和视野受限的挑战，特别是在需要高度专业技能的胎儿镜激光凝固手术中。

Method: 开发了一个结合磁驱动柔性内窥镜的机器人平台，具有遥操作和半自主导航功能，能够重建内窥镜场景的实时拼接图像以提供扩展的视觉环境。

Result: 该系统在羊模型中进行了体内验证，证明能够克服开放空间微创手术的关键限制。

Conclusion: 该机器人平台成功解决了开放腔体内窥镜手术的控制和视野限制问题，展示了在复杂微创手术中的潜力。

Abstract: Flexible robots hold great promise for enhancing minimally invasive surgery (MIS) by providing superior dexterity, precise control, and safe tissue interaction. Yet, translating these advantages into endoscopic interventions within open cavities remains challenging. The lack of anatomical constraints and the inherent flexibility of such devices complicate their control, while the limited field of view of endoscopes restricts situational awareness. We present a robotic platform designed to overcome these challenges and demonstrate its potential in fetoscopic laser coagulation, a complex MIS procedure typically performed only by highly experienced surgeons. Our system combines a magnetically actuated flexible endoscope with teleoperated and semi-autonomous navigation capabilities for performing targeted laser ablations. To enhance surgical awareness, the platform reconstructs real-time mosaics of the endoscopic scene, providing an extended and continuous visual context. The ability of this system to address the key limitations of MIS in open spaces is validated in vivo in an ovine model.

</details>


### [67] [Aerial Assistance System for Automated Firefighting during Turntable Ladder Operations](https://arxiv.org/abs/2511.14504)
*Jan Quenzel,Valerij Sekin,Daniel Schleich,Alexander Miller,Merlin Stampa,Norbert Pahlke,Christof Röhrig,Sven Behnke*

Main category: cs.RO

TL;DR: 提出一种使用无人机和机动消防监控器的自动化消防辅助系统，通过无人机自主探测热源并定位，系统自动引导水枪瞄准火源。


<details>
  <summary>Details</summary>
Motivation: 工业设施火灾由于建筑规模大、视觉遮挡严重，导致消防员难以准确定位火源，影响灭火效率和准确性。

Method: 使用安装在转台梯上的机动消防监控器，配合无人机空中支持。无人机在无障碍飞行通道内自主飞行，探测和定位热源，操作员通过手持控制器选择目标后，系统自动规划三角测量路径并引导水枪瞄准。

Result: 初步测试表明，该系统成功定位了多个热源，并能将水枪准确导向火源。

Conclusion: 该自动化辅助系统能够有效提高工业火灾的灭火精度和效率，减少损失和消防作业时间。

Abstract: Fires in industrial facilities pose special challenges to firefighters, e.g., due to the sheer size and scale of the buildings. The resulting visual obstructions impair firefighting accuracy, further compounded by inaccurate assessments of the fire's location. Such imprecision simultaneously increases the overall damage and prolongs the fire-brigades operation unnecessarily.
  We propose an automated assistance system for firefighting using a motorized fire monitor on a turntable ladder with aerial support from an unmanned aerial vehicle (UAV). The UAV flies autonomously within an obstacle-free flight funnel derived from geodata, detecting and localizing heat sources. An operator supervises the operation on a handheld controller and selects a fire target in reach. After the selection, the UAV automatically plans and traverses between two triangulation poses for continued fire localization. Simultaneously, our system steers the fire monitor to ensure the water jet reaches the detected heat source. In preliminary tests, our assistance system successfully localized multiple heat sources and directed a water jet towards the fires.

</details>


### [68] [Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language](https://arxiv.org/abs/2511.14565)
*Minyoung Hwang,Alexandra Forsey-Smerek,Nathaniel Dennler,Andreea Bobu*

Main category: cs.RO

TL;DR: Masked IRL结合语言指令和演示数据，通过LLM推断状态相关性掩码，在数据有限时提高奖励函数的泛化能力，相比现有方法性能提升15%且数据需求减少4.7倍。


<details>
  <summary>Details</summary>
Motivation: 传统基于演示的奖励学习容易过拟合到虚假相关性，因为演示只展示如何执行任务而不指明任务重点。语言指令能更直接指定机器人应关注的内容，但现有方法未充分利用语言消除歧义的潜力。

Method: 提出Masked IRL框架，使用LLM从语言指令推断状态相关性掩码，强制奖励函数对无关状态组件保持不变性。当指令模糊时，利用LLM在演示上下文中的推理来澄清指令。

Result: 在仿真和真实机器人实验中，Masked IRL比现有语言条件IRL方法性能提升达15%，同时数据使用量减少达4.7倍，表现出更好的样本效率、泛化能力和对模糊语言的鲁棒性。

Conclusion: 语言指令和演示数据包含互补信息，Masked IRL通过LLM有效结合两者优势，解决了奖励学习中的过拟合问题，实现了更高效和鲁棒的机器人适应能力。

Abstract: Robots can adapt to user preferences by learning reward functions from demonstrations, but with limited data, reward models often overfit to spurious correlations and fail to generalize. This happens because demonstrations show robots how to do a task but not what matters for that task, causing the model to focus on irrelevant state details. Natural language can more directly specify what the robot should focus on, and, in principle, disambiguate between many reward functions consistent with the demonstrations. However, existing language-conditioned reward learning methods typically treat instructions as simple conditioning signals, without fully exploiting their potential to resolve ambiguity. Moreover, real instructions are often ambiguous themselves, so naive conditioning is unreliable. Our key insight is that these two input types carry complementary information: demonstrations show how to act, while language specifies what is important. We propose Masked Inverse Reinforcement Learning (Masked IRL), a framework that uses large language models (LLMs) to combine the strengths of both input types. Masked IRL infers state-relevance masks from language instructions and enforces invariance to irrelevant state components. When instructions are ambiguous, it uses LLM reasoning to clarify them in the context of the demonstrations. In simulation and on a real robot, Masked IRL outperforms prior language-conditioned IRL methods by up to 15% while using up to 4.7 times less data, demonstrating improved sample-efficiency, generalization, and robustness to ambiguous language. Project page: https://MIT-CLEAR-Lab.github.io/Masked-IRL and Code: https://github.com/MIT-CLEAR-Lab/Masked-IRL

</details>


### [69] [Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks](https://arxiv.org/abs/2511.14592)
*Xianhui Meng,Yuchen Zhang,Zhijian Huang,Zheng Lu,Ziling Ji,Yaoyao Yin,Hongyuan Zhang,Guangfeng Jiang,Yandan Lin,Long Chen,Hangjun Ye,Li Zhang,Jun Liu,Xiaoshuai Hao*

Main category: cs.RO

TL;DR: DSBench是首个综合性的驾驶安全基准测试，用于统一评估视觉语言模型在外部环境风险和车内驾驶行为安全方面的表现，包含10大类28个子类场景，通过大规模数据集微调可显著提升模型安全性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在自动驾驶中的应用潜力巨大，但其在安全关键场景下的适用性尚未充分验证，缺乏同时评估外部环境风险和车内驾驶行为安全的综合基准测试。

Method: 构建DSBench基准测试，包含外部环境风险和车内驾驶行为安全两大类别，细分为10个关键类别和28个子类别，涵盖广泛的安全关键场景，并构建98K个实例的数据集用于模型微调。

Result: 对各种主流开源和闭源视觉语言模型的广泛评估显示，在复杂安全关键情况下性能显著下降，突显了紧迫的安全问题。通过在该数据集上微调，现有视觉语言模型的安全性能得到显著提升。

Conclusion: DSBench填补了驾驶安全评估的关键空白，为推进自动驾驶技术提供了重要工具，通过针对性微调可有效提升视觉语言模型在安全关键场景下的表现。

Abstract: Vision-Language Models (VLMs) show great promise for autonomous driving, but their suitability for safety-critical scenarios is largely unexplored, raising safety concerns. This issue arises from the lack of comprehensive benchmarks that assess both external environmental risks and in-cabin driving behavior safety simultaneously. To bridge this critical gap, we introduce DSBench, the first comprehensive Driving Safety Benchmark designed to assess a VLM's awareness of various safety risks in a unified manner. DSBench encompasses two major categories: external environmental risks and in-cabin driving behavior safety, divided into 10 key categories and a total of 28 sub-categories. This comprehensive evaluation covers a wide range of scenarios, ensuring a thorough assessment of VLMs' performance in safety-critical contexts. Extensive evaluations across various mainstream open-source and closed-source VLMs reveal significant performance degradation under complex safety-critical situations, highlighting urgent safety concerns. To address this, we constructed a large dataset of 98K instances focused on in-cabin and external safety scenarios, showing that fine-tuning on this dataset significantly enhances the safety performance of existing VLMs and paves the way for advancing autonomous driving technology. The benchmark toolkit, code, and model checkpoints will be publicly accessible.

</details>


### [70] [Gallant: Voxel Grid-based Humanoid Locomotion and Local-navigation across 3D Constrained Terrains](https://arxiv.org/abs/2511.14625)
*Qingwei Ben,Botian Xu,Kailin Li,Feiyu Jia,Wentao Zhang,Jingping Wang,Jingbo Wang,Dahua Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: Gallant是一个基于体素网格的人形机器人3D地形导航框架，利用体素化LiDAR数据作为感知表示，通过端到端优化实现稳健的3D环境导航。


<details>
  <summary>Details</summary>
Motivation: 现有感知模块（深度图像或高程图）只能提供局部平坦的环境视图，无法捕捉完整的3D结构，限制了人形机器人在复杂3D地形中的导航能力。

Method: 使用体素化LiDAR数据作为轻量级结构化感知表示，采用z分组2D CNN将感知映射到控制策略，实现完全端到端优化，并开发了高保真LiDAR仿真支持可扩展训练。

Result: Gallant的广泛感知覆盖使单一策略能够处理地面障碍物、侧向杂物、顶部约束、多层结构和狭窄通道等场景，在楼梯攀爬和平台登高等挑战性场景中实现接近100%的成功率。

Conclusion: Gallant框架通过体素化LiDAR表示和端到端优化，显著提升了人形机器人在3D约束地形中的导航能力，超越了现有方法的局限性。

Abstract: Robust humanoid locomotion requires accurate and globally consistent perception of the surrounding 3D environment. However, existing perception modules, mainly based on depth images or elevation maps, offer only partial and locally flattened views of the environment, failing to capture the full 3D structure. This paper presents Gallant, a voxel-grid-based framework for humanoid locomotion and local navigation in 3D constrained terrains. It leverages voxelized LiDAR data as a lightweight and structured perceptual representation, and employs a z-grouped 2D CNN to map this representation to the control policy, enabling fully end-to-end optimization. A high-fidelity LiDAR simulation that dynamically generates realistic observations is developed to support scalable, LiDAR-based training and ensure sim-to-real consistency. Experimental results show that Gallant's broader perceptual coverage facilitates the use of a single policy that goes beyond the limitations of previous methods confined to ground-level obstacles, extending to lateral clutter, overhead constraints, multi-level structures, and narrow passages. Gallant also firstly achieves near 100% success rates in challenging scenarios such as stair climbing and stepping onto elevated platforms through improved end-to-end optimization.

</details>


### [71] [NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards](https://arxiv.org/abs/2511.14659)
*Chia-Yu Hung,Navonil Majumder,Haoyuan Deng,Liu Renhang,Yankang Ang,Amir Zadeh,Chuan Li,Dorien Herremans,Ziwei Wang,Soujanya Poria*

Main category: cs.RO

TL;DR: NORA-1.5是基于预训练NORA骨干构建的视觉-语言-动作模型，通过添加基于流匹配的动作专家和奖励驱动的后训练，显著提升了在具身任务中的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在可靠性和泛化能力方面存在不足，特别是在不同具身系统和真实环境中的部署表现不佳。

Method: 1) 在预训练NORA骨干上添加基于流匹配的动作专家；2) 开发结合动作条件世界模型和偏离地面真值启发式的奖励模型；3) 使用直接偏好优化进行后训练。

Result: NORA-1.5在模拟和真实世界基准测试中超越了NORA和多个最先进的VLA模型，奖励驱动的后训练在仿真和真实机器人设置中持续提升性能。

Conclusion: NORA-1.5和奖励引导的后训练为实现更可靠的具身智能体提供了一条可行路径，适合真实世界部署。

Abstract: Vision--language--action (VLA) models have recently shown promising performance on a variety of embodied tasks, yet they still fall short in reliability and generalization, especially when deployed across different embodiments or real-world environments. In this work, we introduce NORA-1.5, a VLA model built from the pre-trained NORA backbone by adding to it a flow-matching-based action expert. This architectural enhancement alone yields substantial performance gains, enabling NORA-1.5 to outperform NORA and several state-of-the-art VLA models across both simulated and real-world benchmarks. To further improve robustness and task success, we develop a set of reward models for post-training VLA policies. Our rewards combine (i) an action-conditioned world model (WM) that evaluates whether generated actions lead toward the desired goal, and (ii) a deviation-from-ground-truth heuristic that distinguishes good actions from poor ones. Using these reward signals, we construct preference datasets and adapt NORA-1.5 to target embodiments through direct preference optimization (DPO). Extensive evaluations show that reward-driven post-training consistently improves performance in both simulation and real-robot settings, demonstrating significant VLA model-reliability gains through simple yet effective reward models. Our findings highlight NORA-1.5 and reward-guided post-training as a viable path toward more dependable embodied agents suitable for real-world deployment.

</details>


### [72] [Robust Verification of Controllers under State Uncertainty via Hamilton-Jacobi Reachability Analysis](https://arxiv.org/abs/2511.14755)
*Albert Lin,Alessandro Pinto,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了RoVer-CoRe框架，使用Hamilton-Jacobi可达性分析来验证感知控制系统在感知不确定性下的安全性，通过将控制器、观测函数和状态估计模块串联构建等效闭环系统。


<details>
  <summary>Details</summary>
Motivation: 随着基于感知的自主系统控制器在现实世界中日益普及，需要在感知不确定性下正式验证其安全性和性能。现有验证方法要么限制控制器和系统类型，要么分析过于保守。

Method: 提出RoVer-CoRe框架，将系统控制器、观测函数和状态估计模块串联构建等效闭环系统，使其与现有可达性框架兼容。包含正式安全验证和鲁棒控制器设计的新方法。

Result: 在飞机滑行和基于神经网络的漫游车导航案例研究中验证了框架的有效性。

Conclusion: RoVer-CoRe是首个基于HJ可达性分析的感知系统验证框架，能够处理感知不确定性下的安全验证问题。

Abstract: As perception-based controllers for autonomous systems become increasingly popular in the real world, it is important that we can formally verify their safety and performance despite perceptual uncertainty. Unfortunately, the verification of such systems remains challenging, largely due to the complexity of the controllers, which are often nonlinear, nonconvex, learning-based, and/or black-box. Prior works propose verification algorithms that are based on approximate reachability methods, but they often restrict the class of controllers and systems that can be handled or result in overly conservative analyses. Hamilton-Jacobi (HJ) reachability analysis is a popular formal verification tool for general nonlinear systems that can compute optimal reachable sets under worst-case system uncertainties; however, its application to perception-based systems is currently underexplored. In this work, we propose RoVer-CoRe, a framework for the Robust Verification of Controllers via HJ Reachability. To the best of our knowledge, RoVer-CoRe is the first HJ reachability-based framework for the verification of perception-based systems under perceptual uncertainty. Our key insight is to concatenate the system controller, observation function, and the state estimation modules to obtain an equivalent closed-loop system that is readily compatible with existing reachability frameworks. Within RoVer-CoRe, we propose novel methods for formal safety verification and robust controller design. We demonstrate the efficacy of the framework in case studies involving aircraft taxiing and NN-based rover navigation. Code is available at the link in the footnote.

</details>


### [73] [HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation](https://arxiv.org/abs/2511.14756)
*Lai Wei,Xuanbin Peng,Ri-Zhao Qiu,Tianshu Huang,Xuxin Cheng,Xiaolong Wang*

Main category: cs.RO

TL;DR: 提出了一种异构元控制框架，用于机器人操作任务，通过自适应结合位置、阻抗和混合力-位置控制模式，提高了在复杂环境中的控制性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人演示学习面临复杂交互动态的挑战，纯位置控制器在处理接触和变负载时表现不佳，需要更灵活的控制策略。

Method: 开发了HMC-Controller接口在扭矩空间连续混合不同控制模式的动作，并设计了HMC-Policy使用专家混合路由从大规模位置数据和细粒度力感知演示中学习。

Result: 在真实人形机器人上的实验显示，在挑战性任务如柔性桌面擦拭和抽屉开启中，相比基线方法有超过50%的相对改进。

Conclusion: HMC框架有效提升了机器人操作任务的性能，证明了异构控制策略在复杂现实环境中的价值。

Abstract: Learning from real-world robot demonstrations holds promise for interacting with complex real-world environments. However, the complexity and variability of interaction dynamics often cause purely positional controllers to struggle with contacts or varying payloads. To address this, we propose a Heterogeneous Meta-Control (HMC) framework for Loco-Manipulation that adaptively stitches multiple control modalities: position, impedance, and hybrid force-position. We first introduce an interface, HMC-Controller, for blending actions from different control profiles continuously in the torque space. HMC-Controller facilitates both teleoperation and policy deployment. Then, to learn a robust force-aware policy, we propose HMC-Policy to unify different controllers into a heterogeneous architecture. We adopt a mixture-of-experts style routing to learn from large-scale position-only data and fine-grained force-aware demonstrations. Experiments on a real humanoid robot show over 50% relative improvement vs. baselines on challenging tasks such as compliant table wiping and drawer opening, demonstrating the efficacy of HMC.

</details>
