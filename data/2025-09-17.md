<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 50]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [An integrated process for design and control of lunar robotics using AI and simulation](https://arxiv.org/abs/2509.12367)
*Daniel Lindmark,Jonas Andersson,Kenneth Bodin,Tora Bodin,Hugo Börjesson,Fredrik Nordfeldth,Martin Servin*

Main category: cs.RO

TL;DR: 提出了一个集成框架OpenPLX，用于并行开发月球建筑设备的物理设计和控制系统，通过高保真实时3D模拟连接CAD模型与自主系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决月球建筑设备开发中物理设计和控制系统分离的问题，实现两者的并行探索和集成开发。

Method: 开发了OpenPLX声明式语言，将CAD模型和自主系统连接到高保真实时3D模拟，包括多体动力学接触、机器-月壤相互作用力和非理想传感器模拟。

Result: 通过两个案例研究验证了框架能力，包括结合视觉语言模型导航和强化学习控制策略的自主月球漫游车。

Conclusion: OpenPLX框架成功实现了月球建筑设备物理设计与控制的并行开发，为未来月球建设任务提供了有效的技术支撑。

Abstract: We envision an integrated process for developing lunar construction
equipment, where physical design and control are explored in parallel. In this
paper, we describe a technical framework that supports this process. It relies
on OpenPLX, a readable/writable declarative language that links CAD-models and
autonomous systems to high-fidelity, real-time 3D simulations of contacting
multibody dynamics, machine regolith interaction forces, and non-ideal sensors.
To demonstrate its capabilities, we present two case studies, including an
autonomous lunar rover that combines a vision-language model for navigation
with a reinforcement learning-based control policy for locomotion.

</details>


### [2] [Geometric Red-Teaming for Robotic Manipulation](https://arxiv.org/abs/2509.12379)
*Divyam Goel,Yufei Wang,Tiancheng Wu,Guixiu Qiao,Pavel Piliptchak,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 提出了Geometric Red-Teaming (GRT)框架，通过对象几何变形来测试机器人操作策略的鲁棒性，自动生成导致策略失败的CrashShapes，并通过blue-teaming方法进行针对性策略优化。


<details>
  <summary>Details</summary>
Motivation: 传统机器人操作评估协议主要基于精心策划的测试集，无法充分揭示系统在几何变化下的脆弱性，需要一种结构化方法来系统性地测试策略的鲁棒性。

Method: 结合基于雅可比场的变形模型和无梯度优化策略，通过任务级策略执行和约束感知的形状探索，自动生成有效的几何变形来触发策略失败。

Result: 在插入、关节操作和抓取任务中，GRT能够发现导致策略性能崩溃的变形，将任务成功率从90%降低至22.5%。通过blue-teaming微调，可在特定形状上恢复性能至90%。

Conclusion: GRT提供了一个通用的对象中心鲁棒性评估框架，能够发现传统基准测试遗漏的脆弱性，并通过针对性训练有效提升策略在特定几何变形上的性能。

Abstract: Standard evaluation protocols in robotic manipulation typically assess policy
performance over curated, in-distribution test sets, offering limited insight
into how systems fail under plausible variation. We introduce Geometric
Red-Teaming (GRT), a red-teaming framework that probes robustness through
object-centric geometric perturbations, automatically generating CrashShapes --
structurally valid, user-constrained mesh deformations that trigger
catastrophic failures in pre-trained manipulation policies. The method
integrates a Jacobian field-based deformation model with a gradient-free,
simulator-in-the-loop optimization strategy. Across insertion, articulation,
and grasping tasks, GRT consistently discovers deformations that collapse
policy performance, revealing brittle failure modes missed by static
benchmarks. By combining task-level policy rollouts with constraint-aware shape
exploration, we aim to build a general purpose framework for structured,
object-centric robustness evaluation in robotic manipulation. We additionally
show that fine-tuning on individual CrashShapes, a process we refer to as
blue-teaming, improves task success by up to 60 percentage points on those
shapes, while preserving performance on the original object, demonstrating the
utility of red-teamed geometries for targeted policy refinement. Finally, we
validate both red-teaming and blue-teaming results with a real robotic arm,
observing that simulated CrashShapes reduce task success from 90% to as low as
22.5%, and that blue-teaming recovers performance to up to 90% on the
corresponding real-world geometry -- closely matching simulation outcomes.
Videos and code can be found on our project website:
https://georedteam.github.io/ .

</details>


### [3] [Distributed Event-Triggered Distance-Based Formation Control for Multi-Agent Systems](https://arxiv.org/abs/2509.12390)
*Evangelos Psomiadis,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 提出基于事件触发的分布式编队控制器，通过距离测量实现多智能体系统编队控制，仅在测量误差超过阈值时更新控制，显著减少控制开销


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在有限资源条件下的编队控制问题，减少不必要的控制更新以节省资源

Method: 设计分布式事件触发编队控制器，依赖智能体间距离测量，当测量误差超过预设阈值时才触发控制更新

Result: 通过仿真和真实实验验证，事件触发方法在保持编队性能的同时显著降低了控制开销

Conclusion: 事件触发策略相比周期性触发策略能有效减少控制努力，适用于资源受限的多智能体编队控制

Abstract: This paper addresses the problem of collaborative formation control for
multi-agent systems with limited resources. We consider a team of robots tasked
with achieving a desired formation from arbitrary initial configurations. To
reduce unnecessary control updates and conserve resources, we propose a
distributed event-triggered formation controller that relies on inter-agent
distance measurements. Control updates are triggered only when the measurement
error exceeds a predefined threshold, ensuring system stability. The proposed
controller is validated through extensive simulations and real-world
experiments involving different formations, communication topologies,
scalability tests, and variations in design parameters, while also being
compared against periodic triggering strategies. Results demonstrate that the
event-triggered approach significantly reduces control efforts while preserving
formation performance.

</details>


### [4] [MinJointTracker: Real-time inertial kinematic chain tracking with joint position estimation and minimal state size](https://arxiv.org/abs/2509.12398)
*Michael Lorenz,Bertram Taetz,Gabriele Bleser-Taetz,Didier Stricker*

Main category: cs.RO

TL;DR: 提出了一种实时无标定的惯性运动捕捉方法，能够同时估计IMU全局角运动和关节位置，无需预先校准IMU与肢段的相对位姿。


<details>
  <summary>Details</summary>
Motivation: 当前惯性运动捕捉方法需要离线校准IMU与肢段的相对位姿、肢段长度等参数，导致设置过程不便。本文旨在实现无需校准的实时运动跟踪。

Method: 采用递归贝叶斯估计算法，最小化状态空间，同时估计全局IMU角运动和关节在IMU坐标系中的位置。

Result: 在模拟的三连杆机械臂数据和人体行走数据上测试，算法能够提供无漂移的相对和绝对方向估计，且关节位置估计收敛快速稳健。

Conclusion: 该方法实现了无需校准的实时惯性运动捕捉，具有状态空间小、收敛快、估计无漂移等优点，适用于各种运动场景。

Abstract: Inertial motion capture is a promising approach for capturing motion outside
the laboratory. However, as one major drawback, most of the current methods
require different quantities to be calibrated or computed offline as part of
the setup process, such as segment lengths, relative orientations between
inertial measurement units (IMUs) and segment coordinate frames (IMU-to-segment
calibrations) or the joint positions in the IMU frames. This renders the setup
process inconvenient. This work contributes to real-time capable
calibration-free inertial tracking of a kinematic chain, i.e. simultaneous
recursive Bayesian estimation of global IMU angular kinematics and joint
positions in the IMU frames, with a minimal state size. Experimental results on
simulated IMU data from a three-link kinematic chain (manipulator study) as
well as re-simulated IMU data from healthy humans walking (lower body study)
show that the calibration-free and lightweight algorithm provides not only
drift-free relative but also drift-free absolute orientation estimates with a
global heading reference for only one IMU as well as robust and fast
convergence of joint position estimates in the different movement scenarios.

</details>


### [5] [Computing forward statics from tendon-length in flexible-joint hyper-redundant manipulators](https://arxiv.org/abs/2509.12444)
*Weiting Feng,Kyle L. Walker,Yunjie Yang,Francesco Giorgio-Serchi*

Main category: cs.RO

TL;DR: 提出了一种基于螺旋理论的肌腱驱动超冗余机械臂静态力学求解方法，能够同时使用肌腱长度或张力作为输入，实现开环控制，避免了张力测量和状态估计的难题。


<details>
  <summary>Details</summary>
Motivation: 传统肌腱驱动超冗余机械臂控制需要精确的张力测量或状态估计，但在大型机械臂受重力影响时，这些参数难以准确获取，限制了实际应用。

Method: 开发基于螺旋理论的肌腱驱动多段超冗余弹性关节机械臂建模方法，提出前向静态迭代求解算法，可等效使用肌腱长度或张力作为输入参数。

Result: 实验验证表明，该方法在使用传统张力输入时有效，且在使用纯肌腱长度输入时同样有效，证实了在静态条件下仅使用运动学输入进行开环控制的可行性。

Conclusion: 该方法解决了超冗余系统张力测量和状态估计的实践问题，为肌腱驱动机械臂的控制提供了更实用的解决方案。

Abstract: Hyper-redundant tendon-driven manipulators offer greater flexibility and
compliance over traditional manipulators. A common way of controlling such
manipulators relies on adjusting tendon lengths, which is an accessible control
parameter. This approach works well when the kinematic configuration is
representative of the real operational conditions. However, when dealing with
manipulators of larger size subject to gravity, it becomes necessary to solve a
static force problem, using tendon force as the input and employing a mapping
from the configuration space to retrieve tendon length. Alternatively,
measurements of the manipulator posture can be used to iteratively adjust
tendon lengths to achieve a desired posture. Hence, either tension measurement
or state estimation of the manipulator are required, both of which are not
always accurately available. Here, we propose a solution by reconciling cables
tension and length as the input for the solution of the system forward statics.
We develop a screw-based formulation for a tendon-driven, multi-segment,
hyper-redundant manipulator with elastic joints and introduce a forward statics
iterative solution method that equivalently makes use of either tendon length
or tension as the input. This strategy is experimentally validated using a
traditional tension input first, subsequently showing the efficacy of the
method when exclusively tendon lengths are used. The results confirm the
possibility to perform open-loop control in static conditions using a kinematic
input only, thus bypassing some of the practical problems with tension
measurement and state estimation of hyper-redundant systems.

</details>


### [6] [Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.12458)
*Àlmos Veres-Vitàlyos,Genis Castillo Gomez-Raya,Filip Lemic,Daniel Johannes Bugelnig,Bernhard Rinner,Sergi Abadal,Xavier Costa-Pérez*

Main category: cs.RO

TL;DR: 提出了一种轻量级无人机自主3D扫描系统，通过双重建管道实现实时反馈和动态轨迹调整，显著提升了小型无人机在受限环境中的高精度3D重建能力。


<details>
  <summary>Details</summary>
Motivation: 小型无人机在室内和难以到达区域具有巨大潜力，但由于有效载荷和自主性限制，难以执行高质量3D重建等复杂任务。需要克服这些限制，使微型无人机能够进行精细的3D扫描。

Method: 采用双重建管道架构：近实时管道使用SfM生成即时点云并分析模型质量，动态调整无人机轨迹以补拍覆盖不足区域；非实时管道结合SfM相机位姿和UWB定位数据，采用基于NeRF的神经3D重建方法实现高精度输出。使用Crazyflie 2.1无人机在单机和多机配置下验证。

Result: 实验证明动态轨迹调整相比静态飞行路径能持续提升重建质量。系统成功实现了在100克以下无人机上的完全自主高保真3D扫描。

Conclusion: 这项工作展示了一个可扩展的自主解决方案，释放了微型无人机在受限环境中进行精细3D重建的潜力，这一能力此前仅限于更大的平台。

Abstract: Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for
navigating indoor and hard-to-reach areas, yet their significant constraints in
payload and autonomy have largely prevented their use for complex tasks like
high-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we
introduce a novel system architecture that enables fully autonomous,
high-fidelity 3D scanning of static objects using UAVs weighing under 100
grams. Our core innovation lies in a dual-reconstruction pipeline that creates
a real-time feedback loop between data capture and flight control. A
near-real-time (near-RT) process uses Structure from Motion (SfM) to generate
an instantaneous pointcloud of the object. The system analyzes the model
quality on the fly and dynamically adapts the UAV's trajectory to intelligently
capture new images of poorly covered areas. This ensures comprehensive data
acquisition. For the final, detailed output, a non-real-time (non-RT) pipeline
employs a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR)
approach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB)
location data to achieve superior accuracy. We implemented and validated this
architecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both
single- and multi-UAV configurations, conclusively show that dynamic trajectory
adaptation consistently improves reconstruction quality over static flight
paths. This work demonstrates a scalable and autonomous solution that unlocks
the potential of miniaturized UAVs for fine-grained 3D reconstruction in
constrained environments, a capability previously limited to much larger
platforms.

</details>


### [7] [Bio-inspired tail oscillation enables robot fast crawling on deformable granular terrains](https://arxiv.org/abs/2509.12468)
*Shipeng Liu,Meghana Sagare,Shubham Patil,Feifei Qian*

Main category: cs.RO

TL;DR: 通过模仿弹涂鱼的尾部形态和运动控制，研究发现主动摆尾能显著提高机器人在颗粒介质上的移动性能，速度提升67%，阻力降低46%，并提出基于基质强度和尾部形态的设计原则。


<details>
  <summary>Details</summary>
Motivation: 受弹涂鱼在泥沙等可变形基质中通过调整尾部形态和运动来导航的启发，研究如何通过尾部设计和控制的协同优化来增强机器人在颗粒介质上的鳍驱动运动性能。

Method: 使用仿生弹涂鱼机器人进行实验比较，对比空闲尾部和主动摆动尾部的运动性能，通过剪切力测量分析基质流化效应，并研究不同尾部形态对摆动策略的影响。

Result: 尾部摆动使机器人速度提高67%，身体阻力降低46%；剪切力测量显示尾部摆动通过流化基质来降低阻力；较大水平表面积的尾部设计能更有效地利用摆动减阻效果。

Conclusion: 提出了基于基质强度和尾部形态的尾部动作选择设计原则，为改善机器人在可变形基质上的运动性能提供了新的尾部设计和控制见解，在农业机器人、搜救和环境探索等领域具有应用价值。

Abstract: Deformable substrates such as sand and mud present significant challenges for
terrestrial robots due to complex robot-terrain interactions. Inspired by
mudskippers, amphibious animals that naturally adjust their tail morphology and
movement jointly to navigate such environments, we investigate how tail design
and control can jointly enhance flipper-driven locomotion on granular media.
Using a bio-inspired robot modeled after the mudskipper, we experimentally
compared locomotion performance between idle and actively oscillating tail
configurations. Tail oscillation increased robot speed by 67% and reduced body
drag by 46%. Shear force measurements revealed that this improvement was
enabled by tail oscillation fluidizing the substrate, thereby reducing
resistance. Additionally, tail morphology strongly influenced the oscillation
strategy: designs with larger horizontal surface areas leveraged the
oscillation-reduced shear resistance more effectively by limiting insertion
depth. Based on these findings, we present a design principle to inform tail
action selection based on substrate strength and tail morphology. Our results
offer new insights into tail design and control for improving robot locomotion
on deformable substrates, with implications for agricultural robotics, search
and rescue, and environmental exploration.

</details>


### [8] [Learning to Generate Pointing Gestures in Situated Embodied Conversational Agents](https://arxiv.org/abs/2509.12507)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 结合模仿学习和强化学习的框架，用于生成具身代理的指向手势，在自然性和准确性方面优于现有监督学习方法


<details>
  <summary>Details</summary>
Motivation: 实现与人类在物理环境中的自然交流，特别是非语言沟通（如指向手势）对于灵活交互至关重要

Method: 结合模仿学习和强化学习，使用小规模运动捕捉数据集学习运动控制策略，生成物理有效且自然的指向手势

Result: 在客观指标和虚拟现实参考游戏中，系统在自然性和准确性方面均优于最先进的监督模型和检索基线

Conclusion: 模仿-强化学习方法在交流手势生成方面具有巨大潜力，有望应用于机器人系统

Abstract: One of the main goals of robotics and intelligent agent research is to enable
natural communication with humans in physically situated settings. While recent
work has focused on verbal modes such as language and speech, non-verbal
communication is crucial for flexible interaction. We present a framework for
generating pointing gestures in embodied agents by combining imitation and
reinforcement learning. Using a small motion capture dataset, our method learns
a motor control policy that produces physically valid, naturalistic gestures
with high referential accuracy. We evaluate the approach against supervised
learning and retrieval baselines in both objective metrics and a virtual
reality referential game with human users. Results show that our system
achieves higher naturalness and accuracy than state-of-the-art supervised
models, highlighting the promise of imitation-RL for communicative gesture
generation and its potential application to robots.

</details>


### [9] [Zero to Autonomy in Real-Time: Online Adaptation of Dynamics in Unstructured Environments](https://arxiv.org/abs/2509.12516)
*William Ward,Sarah Etter,Jesse Quattrociocchi,Christian Ellis,Adam J. Thorpe,Ufuk Topcu*

Main category: cs.RO

TL;DR: 提出一种在线自适应方法，结合函数编码器和递归最小二乘法，在几秒内实现零先验知识到安全控制的快速适应，适用于非结构化环境中的地形突变场景。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在非结构化环境中运行时，需要从零先验知识快速适应到安全控制。地形突变（如突然转向冰面）会导致动力学变化，破坏规划器的稳定性，因此需要实时模型自适应。

Method: 将函数编码器系数作为潜在状态，通过流式里程计数据进行更新，结合递归最小二乘法实现恒定时间系数估计，无需基于梯度的内循环更新。

Result: 在Van der Pol系统、Unity高保真越野导航模拟器和Clearpath Jackal机器人（包括当地溜冰场的挑战性地形）上验证，方法提高了模型精度和下游规划性能，相比静态和元学习基线减少了碰撞。

Conclusion: 该方法能够仅用几秒数据实现快速在线适应，在多种环境中有效改善模型准确性和规划性能，为自主机器人在动态变化环境中的安全操作提供了可行解决方案。

Abstract: Autonomous robots must go from zero prior knowledge to safe control within
seconds to operate in unstructured environments. Abrupt terrain changes, such
as a sudden transition to ice, create dynamics shifts that can destabilize
planners unless the model adapts in real-time. We present a method for online
adaptation that combines function encoders with recursive least squares,
treating the function encoder coefficients as latent states updated from
streaming odometry. This yields constant-time coefficient estimation without
gradient-based inner-loop updates, enabling adaptation from only a few seconds
of data. We evaluate our approach on a Van der Pol system to highlight
algorithmic behavior, in a Unity simulator for high-fidelity off-road
navigation, and on a Clearpath Jackal robot, including on a challenging terrain
at a local ice rink. Across these settings, our method improves model accuracy
and downstream planning, reducing collisions compared to static and
meta-learning baselines.

</details>


### [10] [Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning](https://arxiv.org/abs/2509.12531)
*Scott Jones,Liyou Zhou,Sebastian W. Pattinson*

Main category: cs.RO

TL;DR: 预训练视觉模型在基于模型的强化学习中能显著提升视觉策略学习对视觉域变化的鲁棒性，部分微调在极端分布偏移下表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有研究发现预训练视觉模型在基于模型的强化学习中效果不佳，但基于模型的强化学习比无模型方法更具样本效率，因此需要研究预训练视觉模型在MBRL中的有效性，特别是在视觉域偏移下的泛化能力

Method: 研究预训练视觉模型在基于模型的强化学习中的应用效果，特别关注视觉域偏移下的泛化性能，并比较不同程度的微调策略

Result: 在严重视觉域偏移场景下，预训练视觉模型表现远优于从头训练的基线模型；部分微调能在最极端分布偏移下保持最高的平均任务性能

Conclusion: 预训练视觉模型能有效提升视觉策略学习的鲁棒性，为在基于模型的机器人学习应用中更广泛采用提供了有力证据

Abstract: In visuomotor policy learning, the control policy for the robotic agent is
derived directly from visual inputs. The typical approach, where a policy and
vision encoder are trained jointly from scratch, generalizes poorly to novel
visual scene changes. Using pre-trained vision models (PVMs) to inform a policy
network improves robustness in model-free reinforcement learning (MFRL). Recent
developments in Model-based reinforcement learning (MBRL) suggest that MBRL is
more sample-efficient than MFRL. However, counterintuitively, existing work has
found PVMs to be ineffective in MBRL. Here, we investigate PVM's effectiveness
in MBRL, specifically on generalization under visual domain shifts. We show
that, in scenarios with severe shifts, PVMs perform much better than a baseline
model trained from scratch. We further investigate the effects of varying
levels of fine-tuning of PVMs. Our results show that partial fine-tuning can
maintain the highest average task performance under the most extreme
distribution shifts. Our results demonstrate that PVMs are highly successful in
promoting robustness in visual policy learning, providing compelling evidence
for their wider adoption in model-based robotic learning applications.

</details>


### [11] [Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling](https://arxiv.org/abs/2509.12562)
*Zhefei Gong,Shangke Lyu,Pengxiang Ding,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: KORR框架通过结合Koopman算子理论进行全局动力学建模，指导残差策略学习，在长时程精细机器人装配任务中显著提升了性能、鲁棒性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有残差策略学习方法主要关注局部修正，缺乏对状态演化的全局理解，限制了在未见场景中的鲁棒性和泛化能力

Method: 提出KORR框架，利用Koopman算子理论在学习潜空间中施加线性时不变结构，基于Koopman预测的潜状态条件化残差修正，实现全局信息指导的稳定动作精炼

Result: 在长时程精细机器人家具装配任务的各种扰动下，KORR相比强基线方法在性能、鲁棒性和泛化能力方面都取得了持续提升

Conclusion: 研究结果表明基于Koopman的建模有潜力将现代学习方法与经典控制理论相结合，为残差策略学习提供全局指导

Abstract: Imitation learning (IL) enables efficient skill acquisition from
demonstrations but often struggles with long-horizon tasks and high-precision
control due to compounding errors. Residual policy learning offers a promising,
model-agnostic solution by refining a base policy through closed-loop
corrections. However, existing approaches primarily focus on local corrections
to the base policy, lacking a global understanding of state evolution, which
limits robustness and generalization to unseen scenarios. To address this, we
propose incorporating global dynamics modeling to guide residual policy
updates. Specifically, we leverage Koopman operator theory to impose linear
time-invariant structure in a learned latent space, enabling reliable state
transitions and improved extrapolation for long-horizon prediction and unseen
environments. We introduce KORR (Koopman-guided Online Residual Refinement), a
simple yet effective framework that conditions residual corrections on
Koopman-predicted latent states, enabling globally informed and stable action
refinement. We evaluate KORR on long-horizon, fine-grained robotic furniture
assembly tasks under various perturbations. Results demonstrate consistent
gains in performance, robustness, and generalization over strong baselines. Our
findings further highlight the potential of Koopman-based modeling to bridge
modern learning methods with classical control theory.

</details>


### [12] [The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](https://arxiv.org/abs/2509.12594)
*Titong Jiang,Xuefeng Jiang,Yuan Ma,Xin Wen,Bailin Li,Kun Zhan,Peng Jia,Yahui Liu,Sheng Sun,Xianpeng Lang*

Main category: cs.RO

TL;DR: LightVLA是一个针对视觉-语言-动作模型的可微分token剪枝框架，通过自适应剪枝视觉token来减少计算开销，同时提高任务成功率，在LIBERO基准测试中实现了59.1%的FLOPs减少和2.9%的成功率提升。


<details>
  <summary>Details</summary>
Motivation: VLA模型在真实机器人任务中表现出色，但在资源受限平台上部署时，基于注意力机制的大规模视觉token计算成为瓶颈，需要一种高效的token剪枝方法来平衡性能和效率。

Method: 使用动态查询评估视觉token重要性，采用Gumbel softmax实现可微分token选择，通过微调学习保留信息量最大的token，无需启发式参数或额外可训练参数。

Result: 在LIBERO基准测试中，LightVLA相比现有方法在多个任务上表现更优，FLOPs减少59.1%，延迟降低38.2%，任务成功率提高2.9%。LightVLA*变体也取得了满意性能。

Conclusion: LightVLA是首个将自适应视觉token剪枝应用于VLA任务的工作，从性能驱动角度自发学习剪枝策略，为实现高效、强大且实用的实时机器人系统迈出了重要一步。

Abstract: We present LightVLA, a simple yet effective differentiable token pruning
framework for vision-language-action (VLA) models. While VLA models have shown
impressive capability in executing real-world robotic tasks, their deployment
on resource-constrained platforms is often bottlenecked by the heavy
attention-based computation over large sets of visual tokens. LightVLA
addresses this challenge through adaptive, performance-driven pruning of visual
tokens: It generates dynamic queries to evaluate visual token importance, and
adopts Gumbel softmax to enable differentiable token selection. Through
fine-tuning, LightVLA learns to preserve the most informative visual tokens
while pruning tokens which do not contribute to task execution, thereby
improving efficiency and performance simultaneously. Notably, LightVLA requires
no heuristic magic numbers and introduces no additional trainable parameters,
making it compatible with modern inference frameworks. Experimental results
demonstrate that LightVLA outperforms different VLA models and existing token
pruning methods across diverse tasks on the LIBERO benchmark, achieving higher
success rates with substantially reduced computational overhead. Specifically,
LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9%
improvement in task success rate. Meanwhile, we also investigate the learnable
query-based token pruning method LightVLA* with additional trainable
parameters, which also achieves satisfactory performance. Our work reveals that
as VLA pursues optimal performance, LightVLA spontaneously learns to prune
tokens from a performance-driven perspective. To the best of our knowledge,
LightVLA is the first work to apply adaptive visual token pruning to VLA tasks
with the collateral goals of efficiency and performance, marking a significant
step toward more efficient, powerful and practical real-time robotic systems.

</details>


### [13] [ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation](https://arxiv.org/abs/2509.12618)
*Zekai Zhang,Weiye Zhu,Hewei Pan,Xiangchen Wang,Rongtao Xu,Xing Sun,Feng Zheng*

Main category: cs.RO

TL;DR: ActiveVLN是一个视觉语言导航框架，通过多轮强化学习实现主动探索，相比传统的模仿学习和DAgger方法，在减少数据收集和训练成本的同时取得了更好的性能


<details>
  <summary>Details</summary>
Motivation: 现有的VLN方法主要依赖模仿学习和DAgger后训练，成本高昂；而之前的强化学习方法缺乏与环境动态交互，依赖专家轨迹进行奖励塑造，限制了代理发现多样化导航路径的能力

Method: 两阶段方法：第一阶段使用少量专家轨迹进行模仿学习初始化；第二阶段通过多轮强化学习，代理迭代预测和执行动作，自动收集多样化轨迹，使用GRPO目标优化多个rollout，并引入动态早停策略修剪失败轨迹

Result: ActiveVLN相比模仿学习基线取得了最大的性能提升，与最先进方法相比达到了竞争性性能，同时使用了更小的模型

Conclusion: ActiveVLN框架通过主动探索和多轮强化学习有效解决了VLN任务中的数据效率和探索多样性问题，为视觉语言导航提供了新的解决方案

Abstract: The Vision-and-Language Navigation (VLN) task requires an agent to follow
natural language instructions and navigate through complex environments.
Existing MLLM-based VLN methods primarily rely on imitation learning (IL) and
often use DAgger for post-training to mitigate covariate shift. While
effective, these approaches incur substantial data collection and training
costs. Reinforcement learning (RL) offers a promising alternative. However,
prior VLN RL methods lack dynamic interaction with the environment and depend
on expert trajectories for reward shaping, rather than engaging in open-ended
active exploration. This restricts the agent's ability to discover diverse and
plausible navigation routes. To address these limitations, we propose
ActiveVLN, a VLN framework that explicitly enables active exploration through
multi-turn RL. In the first stage, a small fraction of expert trajectories is
used for IL to bootstrap the agent. In the second stage, the agent iteratively
predicts and executes actions, automatically collects diverse trajectories, and
optimizes multiple rollouts via the GRPO objective. To further improve RL
efficiency, we introduce a dynamic early-stopping strategy to prune long-tail
or likely failed trajectories, along with additional engineering optimizations.
Experiments show that ActiveVLN achieves the largest performance gains over IL
baselines compared to both DAgger-based and prior RL-based post-training
methods, while reaching competitive performance with state-of-the-art
approaches despite using a smaller model. Code and data will be released soon.

</details>


### [14] [PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion](https://arxiv.org/abs/2509.12620)
*Yikai Chen,Zhi Zheng,Jin Wang,Bingye He,Xiangyu Xu,Jialu Zhang,Huan Yu,Guodong Lu*

Main category: cs.RO

TL;DR: PerchMobi³是一个四风扇负压空地墙机器人，通过推进-吸附功率复用机制实现了空中飞行、地面行驶和墙面爬行的无缝集成，无需专用吸附泵。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态机器人设计依赖额外吸附执行器导致复杂度增加、效率降低和可靠性下降的问题。

Method: 采用四个涵道风扇同时提供空中推力和负压吸附，结合四个主动驱动轮，实现功率复用机制；建立建模和控制框架支持跨域协调操作。

Result: 通过全面实验验证了地面行驶、载荷辅助墙面爬行、空中飞行和跨模式转换的可行性，展示了在各种运动场景中的鲁棒适应性。

Conclusion: PerchMobi³为多模态机器人移动性提供了新颖的设计范式，为未来自主和应用导向的部署铺平了道路。

Abstract: Achieving seamless integration of aerial flight, ground driving, and wall
climbing within a single robotic platform remains a major challenge, as
existing designs often rely on additional adhesion actuators that increase
complexity, reduce efficiency, and compromise reliability. To address these
limitations, we present PerchMobi^3, a quad-fan, negative-pressure,
air-ground-wall robot that implements a propulsion-adhesion power-reuse
mechanism. By repurposing four ducted fans to simultaneously provide aerial
thrust and negative-pressure adhesion, and integrating them with four actively
driven wheels, PerchMobi^3 eliminates dedicated pumps while maintaining a
lightweight and compact design. To the best of our knowledge, this is the first
quad-fan prototype to demonstrate functional power reuse for multi-modal
locomotion. A modeling and control framework enables coordinated operation
across ground, wall, and aerial domains with fan-assisted transitions. The
feasibility of the design is validated through a comprehensive set of
experiments covering ground driving, payload-assisted wall climbing, aerial
flight, and cross-mode transitions, demonstrating robust adaptability across
locomotion scenarios. These results highlight the potential of PerchMobi^3 as a
novel design paradigm for multi-modal robotic mobility, paving the way for
future extensions toward autonomous and application-oriented deployment.

</details>


### [15] [Safety filtering of robotic manipulation under environment uncertainty: a computational approach](https://arxiv.org/abs/2509.12674)
*Anna Johansson,Daniel Lindmark,Viktor Wiberg,Martin Servin*

Main category: cs.RO

TL;DR: 提出基于物理仿真的安全过滤方法，通过密集rollout和稀疏重评估来处理机器人操作中的不确定性，确保在未知物体质量和摩擦系数情况下的安全操作。


<details>
  <summary>Details</summary>
Motivation: 现有安全过滤器通常假设完全可观测性，限制了在真实世界任务中的适用性。机器人操作在动态和非结构化环境中需要利用已知和不确定信息的安全机制。

Method: 结合密集rollout和并行稀疏重评估，使用高保真仿真评估控制策略在不确定世界参数下的表现，通过广义安全因子量化稳定抓取和执行器限制，并通过探测动作进行针对性不确定性降低。

Result: 在模拟的双臂操作任务中证明该方法能有效识别和过滤不安全轨迹，展示了在物体质量和摩擦系数不确定情况下的安全操作能力。

Conclusion: 基于物理的稀疏安全评估是处理不确定性下安全机器人操作的可扩展策略，能够高效识别不安全轨迹并确保操作安全。

Abstract: Robotic manipulation in dynamic and unstructured environments requires safety
mechanisms that exploit what is known and what is uncertain about the world.
Existing safety filters often assume full observability, limiting their
applicability in real-world tasks. We propose a physics-based safety filtering
scheme that leverages high-fidelity simulation to assess control policies under
uncertainty in world parameters. The method combines dense rollout with nominal
parameters and parallelizable sparse re-evaluation at critical
state-transitions, quantified through generalized factors of safety for stable
grasping and actuator limits, and targeted uncertainty reduction through
probing actions. We demonstrate the approach in a simulated bimanual
manipulation task with uncertain object mass and friction, showing that unsafe
trajectories can be identified and filtered efficiently. Our results highlight
physics-based sparse safety evaluation as a scalable strategy for safe robotic
manipulation under uncertainty.

</details>


### [16] [UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints](https://arxiv.org/abs/2509.12702)
*Hongrui Zhao,Xunlan Zhou,Boris Ivanovic,Negar Mehr*

Main category: cs.RO

TL;DR: UDON是一个实时多智能体神经隐式建图框架，通过不确定性加权分布式优化，在极低通信成功率（低至1%）下仍能实现高质量建图。


<details>
  <summary>Details</summary>
Motivation: 多机器人神经隐式建图需要应对通信挑战（如丢包和带宽限制），现有方法在极低通信成功率下性能仍会下降。

Method: 提出不确定性加权分布式优化：不确定性加权优先处理地图中更可靠的部分，分布式优化隔离并惩罚通信智能体之间的建图分歧。

Result: 在标准基准数据集和真实机器人硬件上的实验表明，UDON显著优于现有基线方法，即使在极端通信退化条件下也能保持高保真重建和一致的场景表示。

Conclusion: UDON框架通过创新的不确定性加权和分布式优化机制，有效解决了多机器人神经隐式建图在恶劣通信条件下的性能退化问题。

Abstract: Multi-robot mapping with neural implicit representations enables the compact
reconstruction of complex environments. However, it demands robustness against
communication challenges like packet loss and limited bandwidth. While prior
works have introduced various mechanisms to mitigate communication disruptions,
performance degradation still occurs under extremely low communication success
rates. This paper presents UDON, a real-time multi-agent neural implicit
mapping framework that introduces a novel uncertainty-weighted distributed
optimization to achieve high-quality mapping under severe communication
deterioration. The uncertainty weighting prioritizes more reliable portions of
the map, while the distributed optimization isolates and penalizes mapping
disagreement between individual pairs of communicating agents. We conduct
extensive experiments on standard benchmark datasets and real-world robot
hardware. We demonstrate that UDON significantly outperforms existing
baselines, maintaining high-fidelity reconstructions and consistent scene
representations even under extreme communication degradation (as low as 1%
success rate).

</details>


### [17] [MoiréTac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moiré Pattern Amplification](https://arxiv.org/abs/2509.12714)
*Kit-Wa Sou,Junhao Gong,Shoujie Li,Chuqiao Lyu,Ziwu Song,Shilong Mu,Wenbo Ding*

Main category: cs.RO

TL;DR: MoiréTac是一种双模式触觉传感器，通过重叠微光栅产生密集的干涉图案，实现高分辨率触觉感知和视觉功能的同时集成。


<details>
  <summary>Details</summary>
Motivation: 传统视觉触觉传感器使用稀疏标记阵列，空间分辨率有限且缺乏清晰的分析力-图像关系，需要一种能够同时提供高分辨率触觉感知和视觉功能的新型传感器。

Method: 采用重叠微光栅结构产生莫尔条纹图案，放大微观变形。结合基于物理的特征（亮度、相位梯度、方向、周期）和深度空间特征，通过端到端学习实现可解释的回归。

Result: 在测试轴上实现R^2 > 0.98的力/扭矩测量；通过几何参数实现三倍增益调节的灵敏度调谐；尽管有莫尔条纹叠加仍能实现物体分类的视觉功能。

Conclusion: 该传感器成功集成到机械臂中实现瓶盖移除任务，验证了其在灵巧操作中协调力和扭矩控制的潜力。

Abstract: Visuotactile sensors typically employ sparse marker arrays that limit spatial
resolution and lack clear analytical force-to-image relationships. To solve
this problem, we present \textbf{Moir\'eTac}, a dual-mode sensor that generates
dense interference patterns via overlapping micro-gratings within a transparent
architecture. When two gratings overlap with misalignment, they create moir\'e
patterns that amplify microscopic deformations. The design preserves optical
clarity for vision tasks while producing continuous moir\'e fields for tactile
sensing, enabling simultaneous 6-axis force/torque measurement, contact
localization, and visual perception. We combine physics-based features
(brightness, phase gradient, orientation, and period) from moir\'e patterns
with deep spatial features. These are mapped to 6-axis force/torque
measurements, enabling interpretable regression through end-to-end learning.
Experimental results demonstrate three capabilities: force/torque measurement
with R^2 > 0.98 across tested axes; sensitivity tuning through geometric
parameters (threefold gain adjustment); and vision functionality for object
classification despite moir\'e overlay. Finally, we integrate the sensor into a
robotic arm for cap removal with coordinated force and torque control,
validating its potential for dexterous manipulation.

</details>


### [18] [NAMOUnc: Navigation Among Movable Obstacles with Decision Making on Uncertainty Interval](https://arxiv.org/abs/2509.12723)
*Kai Zhang,Eric Lucet,Julien Alexandre Dit Sandretto,Shoubin Chen,David Filait*

Main category: cs.RO

TL;DR: NAMOUnc框架通过将不确定性整合到决策过程中，解决了移动障碍物导航中的观测噪声、模型近似、动作失败和部分可观测性等问题，提高了成功率和时间效率。


<details>
  <summary>Details</summary>
Motivation: 现有的NAMO解决方案通常假设理想条件，导致在现实世界不确定性（如观测噪声、模型近似、动作失败和部分可观测性）下做出次优或风险决策。

Method: 首先估计不确定性，然后比较移除和绕过障碍物的相应时间成本区间，优化成功率和时间效率，确保更安全高效的导航。

Result: 通过大量仿真和真实世界实验验证，相比现有NAMO框架显示出显著改进。

Conclusion: NAMOUnc框架通过显式处理不确定性，为移动障碍物导航提供了更鲁棒和高效的解决方案。

Abstract: Navigation among movable obstacles (NAMO) is a critical task in robotics,
often challenged by real-world uncertainties such as observation noise, model
approximations, action failures, and partial observability. Existing solutions
frequently assume ideal conditions, leading to suboptimal or risky decisions.
This paper introduces NAMOUnc, a novel framework designed to address these
uncertainties by integrating them into the decision-making process. We first
estimate them and compare the corresponding time cost intervals for removing
and bypassing obstacles, optimizing both the success rate and time efficiency,
ensuring safer and more efficient navigation. We validate our method through
extensive simulations and real-world experiments, demonstrating significant
improvements over existing NAMO frameworks. More details can be found in our
website: https://kai-zhang-er.github.io/namo-uncertainty/

</details>


### [19] [Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors](https://arxiv.org/abs/2509.12739)
*Trung Kien La,Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 使用深度神经网络（多层LSTM和全连接层）预测机器人关节电机的热行为，采用无模型、可扩展的方法处理复杂性和不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需要大量参数推导、识别和验证的困难，这些参数模型往往难以获得且处理复杂不确定性挑战。

Method: 采用深度神经网络架构，包含多个隐藏LSTM层和全连接层，通过感知的关节扭矩数据来预测电机温度动态。

Result: 在七关节冗余机器人上获得了有前景的预测结果，成功捕捉了关节电机的温度动态。

Conclusion: 基于机器学习的方法为机器人关节电机热行为预测提供了一种有效的无模型解决方案，能够处理复杂系统的热动态特性。

Abstract: In this work, deep neural networks made up of multiple hidden Long Short-Term
Memory (LSTM) and Feedforward layers are trained to predict the thermal
behavior of the joint motors of robot manipulators. A model-free and scalable
approach is adopted. It accommodates complexity and uncertainty challenges
stemming from the derivation, identification, and validation of a large number
of parameters of an approximation model that is hardly available. To this end,
sensed joint torques are collected and processed to foresee the thermal
behavior of joint motors. Promising prediction results of the machine learning
based capture of the temperature dynamics of joint motors of a redundant robot
with seven joints are presented.

</details>


### [20] [Deep Generative and Discriminative Digital Twin endowed with Variational Autoencoder for Unsupervised Predictive Thermal Condition Monitoring of Physical Robots in Industry 6.0 and Society 6.0](https://arxiv.org/abs/2509.12740)
*Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 利用生成式AI的数字孪生技术管理机器人热异常状态，通过变分自编码器重建误差推导热难度评分，使机器人能预测、预期和共享运动轮廓的热可行性


<details>
  <summary>Details</summary>
Motivation: 工业4.0和5.0中机器人需要自主应对电机过热导致的热饱和和烧伤问题，传统关机策略影响生产效率，需要智能的热管理方案

Method: 采用基于变分自编码器的智能数字孪生技术，通过重建误差来识别热异常状态并生成无临界机器人状态

Result: 提出了热难度评分概念，使机器人能够预测和共享运动轮廓的热可行性

Conclusion: 该方法为工业6.0和社会6.0应用提供了热可行性管理的新途径，延长机器人寿命并确保人类安全

Abstract: Robots are unrelentingly used to achieve operational efficiency in Industry
4.0 along with symbiotic and sustainable assistance for the work-force in
Industry 5.0. As resilience, robustness, and well-being are required in
anti-fragile manufacturing and human-centric societal tasks, an autonomous
anticipation and adaption to thermal saturation and burns due to motors
overheating become instrumental for human safety and robot availability. Robots
are thereby expected to self-sustain their performance and deliver user
experience, in addition to communicating their capability to other agents in
advance to ensure fully automated thermally feasible tasks, and prolong their
lifetime without human intervention. However, the traditional robot shutdown,
when facing an imminent thermal saturation, inhibits productivity in factories
and comfort in the society, while cooling strategies are hard to implement
after the robot acquisition. In this work, smart digital twins endowed with
generative AI, i.e., variational autoencoders, are leveraged to manage
thermally anomalous and generate uncritical robot states. The notion of thermal
difficulty is derived from the reconstruction error of variational
autoencoders. A robot can use this score to predict, anticipate, and share the
thermal feasibility of desired motion profiles to meet requirements from
emerging applications in Industry 6.0 and Society 6.0.

</details>


### [21] [Force-Modulated Visual Policy for Robot-Assisted Dressing with Arm Motions](https://arxiv.org/abs/2509.12741)
*Alexis Yihong Hao,Yufei Wang,Navin Sriram Ravie,Bharath Hegde,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 开发了一个机器人辅助穿衣系统，能够处理视觉遮挡的部分观测，并在穿衣过程中适应手臂运动，通过仿真训练和少量真实数据微调策略，在12名参与者的264次试验中表现优于现有基线


<details>
  <summary>Details</summary>
Motivation: 机器人辅助穿衣可以显著改善行动不便人士的生活，但现有研究通常假设人体肢体在穿衣过程中保持静态，限制了实际应用，需要开发能够处理部分观测和适应肢体运动的系统

Method: 在仿真环境中训练具有部分观测的策略，然后在真实世界中使用少量数据和多模态反馈（视觉和力传感）进行微调，以提高策略对手臂运动的适应性和安全性

Result: 在仿真和真实世界人体研究中评估方法，策略成功为12名参与者穿上两种长袖日常服装，能够适应各种手臂运动，在任务完成度和用户反馈方面大大优于现有基线

Conclusion: 提出的方法能够有效处理机器人辅助穿衣中的视觉遮挡和肢体运动适应问题，通过仿真到真实的迁移学习实现了更好的性能和用户体验

Abstract: Robot-assisted dressing has the potential to significantly improve the lives
of individuals with mobility impairments. To ensure an effective and
comfortable dressing experience, the robot must be able to handle challenging
deformable garments, apply appropriate forces, and adapt to limb movements
throughout the dressing process. Prior work often makes simplifying assumptions
-- such as static human limbs during dressing -- which limits real-world
applicability. In this work, we develop a robot-assisted dressing system
capable of handling partial observations with visual occlusions, as well as
robustly adapting to arm motions during the dressing process. Given a policy
trained in simulation with partial observations, we propose a method to
fine-tune it in the real world using a small amount of data and multi-modal
feedback from vision and force sensing, to further improve the policy's
adaptability to arm motions and enhance safety. We evaluate our method in
simulation with simplified articulated human meshes and in a real world human
study with 12 participants across 264 dressing trials. Our policy successfully
dresses two long-sleeve everyday garments onto the participants while being
adaptive to various kinds of arm motions, and greatly outperforms prior
baselines in terms of task completion and user feedback. Video are available at
https://dressing-motion.github.io/.

</details>


### [22] [NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts](https://arxiv.org/abs/2509.12747)
*Botao He,Amir Hossein Shahidzadeh,Yu Chen,Jiayi Wu,Tianrui Guan,Guofei Chen,Howie Choset,Dinesh Manocha,Glen Chou,Cornelia Fermuller,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: NAVMOE是一个用于机器人导航的混合专家系统，通过动态组合专门化模型来处理不同地形类型，实现了高效可靠的通行性估计，计算成本降低81.2%且路径质量损失小于2%。


<details>
  <summary>Details</summary>
Motivation: 当前通行性估计的关键瓶颈在于如何在多样化环境中高效实现可靠稳健的预测，同时准确编码几何和语义信息。

Method: 提出NAVMOE分层模块化方法，结合多个专门化模型（基于经典模型或学习的方法），通过门控网络动态加权不同模型的贡献，采用训练免费的惰性门控机制和两阶段训练策略。

Result: 实验显示NAVMOE在不同领域实现了更好的效率和性能平衡，通过惰性门控将平均计算成本降低81.2%，路径质量损失小于2%，并提高了跨域泛化能力。

Conclusion: NAVMOE通过混合专家方法有效解决了通行性估计的效率和泛化问题，为机器人导航提供了实用的解决方案。

Abstract: This paper explores traversability estimation for robot navigation. A key
bottleneck in traversability estimation lies in efficiently achieving reliable
and robust predictions while accurately encoding both geometric and semantic
information across diverse environments. We introduce Navigation via Mixture of
Experts (NAVMOE), a hierarchical and modular approach for traversability
estimation and local navigation. NAVMOE combines multiple specialized models
for specific terrain types, each of which can be either a classical model-based
or a learning-based approach that predicts traversability for specific terrain
types. NAVMOE dynamically weights the contributions of different models based
on the input environment through a gating network. Overall, our approach offers
three advantages: First, NAVMOE enables traversability estimation to adaptively
leverage specialized approaches for different terrains, which enhances
generalization across diverse and unseen environments. Second, our approach
significantly improves efficiency with negligible cost of solution quality by
introducing a training-free lazy gating mechanism, which is designed to
minimize the number of activated experts during inference. Third, our approach
uses a two-stage training strategy that enables the training for the gating
networks within the hybrid MoE method that contains nondifferentiable modules.
Extensive experiments show that NAVMOE delivers a better efficiency and
performance balance than any individual expert or full ensemble across
different domains, improving cross- domain generalization and reducing average
computational cost by 81.2% via lazy gating, with less than a 2% loss in path
quality.

</details>


### [23] [Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model](https://arxiv.org/abs/2509.12754)
*Saki Hashimoto,Shoichi Hasegawa,Tomochika Ishikawa,Akira Taniguchi,Yoshinobu Hagiwara,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: ActOwL框架通过主动提问和LLM常识推理，让机器人高效学习物品所有权，提升社交任务执行能力


<details>
  <summary>Details</summary>
Motivation: 机器人在家庭和办公环境中需要理解物品所有权来正确执行指令，但仅靠视觉特征无法可靠推断所有权

Method: 使用概率生成模型主动生成最大化信息增益的所有权相关问题，结合LLM常识知识预分类共享/私有物品，只对私有物品提问

Result: 在模拟家庭环境和真实实验室环境中，ActOwL以更少的问题实现了显著更高的所有权聚类准确率

Conclusion: 主动推理与LLM引导的常识推理相结合，有效提升了机器人获取所有权知识的能力，为实际社交任务执行提供了先进解决方案

Abstract: Robots operating in domestic and office environments must understand object
ownership to correctly execute instructions such as ``Bring me my cup.''
However, ownership cannot be reliably inferred from visual features alone. To
address this gap, we propose Active Ownership Learning (ActOwL), a framework
that enables robots to actively generate and ask ownership-related questions to
users. ActOwL employs a probabilistic generative model to select questions that
maximize information gain, thereby acquiring ownership knowledge efficiently to
improve learning efficiency. Additionally, by leveraging commonsense knowledge
from Large Language Models (LLM), objects are pre-classified as either shared
or owned, and only owned objects are targeted for questioning. Through
experiments in a simulated home environment and a real-world laboratory
setting, ActOwL achieved significantly higher ownership clustering accuracy
with fewer questions than baseline methods. These findings demonstrate the
effectiveness of combining active inference with LLM-guided commonsense
reasoning, advancing the capability of robots to acquire ownership knowledge
for practical and socially appropriate task execution.

</details>


### [24] [Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing](https://arxiv.org/abs/2509.12776)
*Renjie Wang,Shangke Lyu,Xin Lang,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: 提出结合轨迹优化和强化学习的四足机器人安全着陆框架，实现崎岖地形自适应着陆


<details>
  <summary>Details</summary>
Motivation: 现有四足机器人跳跃研究主要关注站立和飞行阶段，假设平坦着陆地面，这在现实世界中不实用

Method: 结合轨迹优化(TO)和强化学习(RL)，RL智能体学习在崎岖地形环境中跟踪TO生成的参考运动，采用奖励松弛策略促进着陆恢复期的探索

Result: 大量实验验证了该方法在各种场景下的准确跟踪和安全着陆能力

Conclusion: 提出的框架能够实现四足机器人在崎岖地形上的自适应安全着陆

Abstract: Jumping constitutes an essential component of quadruped robots' locomotion
capabilities, which includes dynamic take-off and adaptive landing. Existing
quadrupedal jumping studies mainly focused on the stance and flight phase by
assuming a flat landing ground, which is impractical in many real world cases.
This work proposes a safe landing framework that achieves adaptive landing on
rough terrains by combining Trajectory Optimization (TO) and Reinforcement
Learning (RL) together. The RL agent learns to track the reference motion
generated by TO in the environments with rough terrains. To enable the learning
of compliant landing skills on challenging terrains, a reward relaxation
strategy is synthesized to encourage exploration during landing recovery
period. Extensive experiments validate the accurate tracking and safe landing
skills benefiting from our proposed method in various scenarios.

</details>


### [25] [Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks](https://arxiv.org/abs/2509.12813)
*Bowen Ye,Junyue Huang,Yang Liu,Xiaozhen Qiao,Xiang Yin*

Main category: cs.RO

TL;DR: S-MSP是一个可微分框架，通过多视角相机观测和STL规范直接生成可行轨迹，在工厂物流场景中优于单专家基线。


<details>
  <summary>Details</summary>
Motivation: 现有STL方法依赖预定义地图或移动性表示，在非结构化现实环境中效果不佳，需要直接从视觉观测生成满足时序逻辑约束的轨迹。

Method: 提出结构化混合专家模型(S-MSP)，集成STL约束到统一管道中，使用结合轨迹重建和STL鲁棒性的复合损失进行训练，采用时间锚定嵌入实现视界感知专业化。

Result: 在高保真工厂物流仿真中，S-MSP在STL满足度和轨迹可行性方面优于单专家基线，推理时的基于规则安全过滤器提高了物理可执行性。

Conclusion: S-MSP展示了直接从视觉输入处理STL规划任务的实用性，为机器人在非结构化环境中的时序逻辑约束任务提供了有效解决方案。

Abstract: We investigate the task and motion planning problem for Signal Temporal Logic
(STL) specifications in robotics. Existing STL methods rely on pre-defined maps
or mobility representations, which are ineffective in unstructured real-world
environments. We propose the \emph{Structured-MoE STL Planner}
(\textbf{S-MSP}), a differentiable framework that maps synchronized multi-view
camera observations and an STL specification directly to a feasible trajectory.
S-MSP integrates STL constraints within a unified pipeline, trained with a
composite loss that combines trajectory reconstruction and STL robustness. A
\emph{structure-aware} Mixture-of-Experts (MoE) model enables horizon-aware
specialization by projecting sub-tasks into temporally anchored embeddings. We
evaluate S-MSP using a high-fidelity simulation of factory-logistics scenarios
with temporally constrained tasks. Experiments show that S-MSP outperforms
single-expert baselines in STL satisfaction and trajectory feasibility. A
rule-based \emph{safety filter} at inference improves physical executability
without compromising logical correctness, showcasing the practicality of the
approach.

</details>


### [26] [Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models](https://arxiv.org/abs/2509.12838)
*Kento Murata,Shoichi Hasegawa,Tomochika Ishikawa,Yoshinobu Hagiwara,Akira Taniguchi,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: 提出基于大语言模型和空间概念的多机器人任务规划框架，能够处理模糊指令并分解为子任务分配给不同机器人


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统中如何根据各机器人的现场空间知识来分配任务的问题，特别是处理需要搜索多个对象或理解上下文依赖指令的复杂任务

Method: 设计新颖的少样本提示策略，利用大语言模型从模糊指令推断所需对象，并将任务分解为适合的子任务分配给多个机器人

Result: 在实验中实现了47/50的成功分配率，优于随机分配(28/50)和常识分配(26/50)，并通过实际移动机械臂验证了框架有效性

Conclusion: 该框架能够成功处理包含临时类别指令的任务分解、分配、顺序规划和执行，为多机器人协作提供了有效解决方案

Abstract: It is crucial to efficiently execute instructions such as "Find an apple and
a banana" or "Get ready for a field trip," which require searching for multiple
objects or understanding context-dependent commands. This study addresses the
challenging problem of determining which robot should be assigned to which part
of a task when each robot possesses different situational on-site
knowledge-specifically, spatial concepts learned from the area designated to it
by the user. We propose a task planning framework that leverages large language
models (LLMs) and spatial concepts to decompose natural language instructions
into subtasks and allocate them to multiple robots. We designed a novel
few-shot prompting strategy that enables LLMs to infer required objects from
ambiguous commands and decompose them into appropriate subtasks. In our
experiments, the proposed method achieved 47/50 successful assignments,
outperforming random (28/50) and commonsense-based assignment (26/50).
Furthermore, we conducted qualitative evaluations using two actual mobile
manipulators. The results demonstrated that our framework could handle
instructions, including those involving ad hoc categories such as "Get ready
for a field trip," by successfully performing task decomposition, assignment,
sequential planning, and execution.

</details>


### [27] [Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration](https://arxiv.org/abs/2509.12846)
*Junlin Song,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 提出了一种基于离散时间状态表示的新型高效视觉-惯性标定方法，解决了传统连续时间方法计算成本高的问题，同时克服了离散时间方法在时间标定方面的弱点


<details>
  <summary>Details</summary>
Motivation: 视觉-惯性融合在机器人导航和增强现实等应用中至关重要，但现有基于B样条的连续时间标定方法计算成本过高，需要更高效的标定方案来满足大规模设备标定需求

Method: 采用离散时间状态表示方法，设计了新颖的标定算法，特别解决了离散时间方法在时间标定方面的技术难题

Result: 实现了极高效的标定性能，相比连续时间方法显著降低了计算成本，同时保持了标定精度

Conclusion: 该方法为大规模视觉-惯性设备提供了高效的标定解决方案，具有重要的研究和工业应用价值，代码将开源以促进社区发展

Abstract: Visual-inertial fusion is crucial for a large amount of intelligent and
autonomous applications, such as robot navigation and augmented reality. To
bootstrap and achieve optimal state estimation, the spatial-temporal
displacements between IMU and cameras must be calibrated in advance. Most
existing calibration methods adopt continuous-time state representation, more
specifically the B-spline. Despite these methods achieve precise
spatial-temporal calibration, they suffer from high computational cost caused
by continuous-time state representation. To this end, we propose a novel and
extremely efficient calibration method that unleashes the power of
discrete-time state representation. Moreover, the weakness of discrete-time
state representation in temporal calibration is tackled in this paper. With the
increasing production of drones, cellphones and other visual-inertial
platforms, if one million devices need calibration around the world, saving one
minute for the calibration of each device means saving 2083 work days in total.
To benefit both the research and industry communities, our code will be
open-source.

</details>


### [28] [A Novel Skill Modeling Approach: Integrating Vergnaud's Scheme with Cognitive Architectures](https://arxiv.org/abs/2509.12851)
*Antoine Lénat,Olivier Cheminat,Damien Chablat,Camilo Charron*

Main category: cs.RO

TL;DR: 本文探讨人机交互中操作员技能建模的重要性，特别是在焊接等工业场景中，需要整合认知架构来弥补传统谓词逻辑方法的不足。


<details>
  <summary>Details</summary>
Motivation: 随着工业5.0的发展，需要更好地理解和建模人类操作员的技能，以便在人机协作中实现最佳性能。传统谓词逻辑方法无法充分处理认知系统约束，如时间限制、认知资源限制等。

Method: 提出将认知架构模型与Vergnaud基于皮亚杰图式概念的谓词逻辑方法相结合，以焊接作为案例研究，分析操作员的感知-决策-行动循环。

Result: 研究表明需要开发能够整合认知约束的技能表示方法，以促进生物系统与机械系统之间的技能转移。

Conclusion: 结合认知架构和谓词逻辑的方法为理解和建模人类操作员技能提供了有前景的途径，特别是在焊接等复杂工业任务中。

Abstract: Human-machine interaction is increasingly important in industry, and this
trend will only intensify with the rise of Industry 5.0. Human operators have
skills that need to be adapted when using machines to achieve the best results.
It is crucial to highlight the operator's skills and understand how they use
and adapt them [18]. A rigorous description of these skills is necessary to
compare performance with and without robot assistance. Predicate logic, used by
Vergnaud within Piaget's scheme concept, offers a promising approach. However,
this theory doesn't account for cognitive system constraints, such as the
timing of actions, the limitation of cognitive resources, the parallelization
of tasks, or the activation of automatic gestures contrary to optimal
knowledge. Integrating these constraints is essential for representing agent
skills understanding skill transfer between biological and mechanical
structures. Cognitive architectures models [2] address these needs by
describing cognitive structure and can be combined with the scheme for mutual
benefit. Welding provides a relevant case study, as it highlights the
challenges faced by operators, even highly skilled ones. Welding's complexity
stems from the need for constant skill adaptation to variable parameters like
part position and process. This adaptation is crucial, as weld quality, a key
factor, is only assessed afterward via destructive testing. Thus, the welder is
confronted with a complex perception-decision-action cycle, where the
evaluation of the impact of his actions is delayed and where errors are
definitive. This dynamic underscores the importance of understanding and
modeling the skills of operators.

</details>


### [29] [Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion](https://arxiv.org/abs/2509.12858)
*Yidan Lu,Rurui Yang,Qiran Kou,Mengting Chen,Tao Fan,Peter Cui,Yinzhao Dong,Peng Lu*

Main category: cs.RO

TL;DR: 提出了一种通过对比学习框架将特权环境信息编码到纯本体感知策略中的方法，使策略具备前瞻性能力，解决了反应式控制与感知驱动系统之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人运动控制中反应式本体感知控制的鲁棒性与复杂感知驱动系统的前瞻性之间的根本矛盾，避免部署时的感知成本。

Method: 使用对比学习框架，强制执行器的潜在状态编码来自仿真的特权环境信息，创建"蒸馏意识"，并采用自适应步态时钟使策略能够根据地形的推断理解主动调整节奏。

Result: 通过零样本仿真到真实世界迁移，在完整尺寸人形机器人上实现了高度鲁棒的运动控制，能够应对30厘米高台阶和26.5度斜坡等挑战性地形。

Conclusion: 该方法成功解决了刚性时钟步态与不稳定无时钟策略之间的经典权衡，为实际部署提供了既鲁棒又具有前瞻性的运动控制解决方案。

Abstract: Reinforcement learning has produced remarkable advances in humanoid
locomotion, yet a fundamental dilemma persists for real-world deployment:
policies must choose between the robustness of reactive proprioceptive control
or the proactivity of complex, fragile perception-driven systems. This paper
resolves this dilemma by introducing a paradigm that imbues a purely
proprioceptive policy with proactive capabilities, achieving the foresight of
perception without its deployment-time costs. Our core contribution is a
contrastive learning framework that compels the actor's latent state to encode
privileged environmental information from simulation. Crucially, this
``distilled awareness" empowers an adaptive gait clock, allowing the policy to
proactively adjust its rhythm based on an inferred understanding of the
terrain. This synergy resolves the classic trade-off between rigid, clocked
gaits and unstable clock-free policies. We validate our approach with zero-shot
sim-to-real transfer to a full-sized humanoid, demonstrating highly robust
locomotion over challenging terrains, including 30 cm high steps and 26.5{\deg}
slopes, proving the effectiveness of our method. Website:
https://lu-yidan.github.io/cra-loco.

</details>


### [30] [GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration](https://arxiv.org/abs/2509.12863)
*Haozhan Ni,Jingsong Liang,Chenyu He,Yuhong Cao,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: GRATE是一种基于深度强化学习的自主机器人探索方法，使用图Transformer增强对信息图的结构理解，结合卡尔曼滤波器确保运动可行性，在探索效率上比现有方法提升21%以上。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的自主探索方法在图结构数据处理能力有限，且忽视机器人运动约束，导致策略主要优化距离而忽略时间效率。

Method: 提出GRATE方法：1）使用图Transformer捕捉信息图的局部结构模式和全局上下文依赖；2）部署卡尔曼滤波器平滑路径点输出，确保运动学可行性。

Result: 实验显示在多种仿真基准测试中，相比最先进的传统和学习基线方法，探索效率提升达21.5%（距离）和21.3%（时间），并在真实场景中得到验证。

Conclusion: GRATE通过结合图Transformer和运动约束处理，显著提升了自主机器人探索的效率和可行性，为实际应用提供了有效解决方案。

Abstract: Autonomous robot exploration (ARE) is the process of a robot autonomously
navigating and mapping an unknown environment. Recent Reinforcement Learning
(RL)-based approaches typically formulate ARE as a sequential decision-making
problem defined on a collision-free informative graph. However, these methods
often demonstrate limited reasoning ability over graph-structured data.
Moreover, due to the insufficient consideration of robot motion, the resulting
RL policies are generally optimized to minimize travel distance, while
neglecting time efficiency. To overcome these limitations, we propose GRATE, a
Deep Reinforcement Learning (DRL)-based approach that leverages a Graph
Transformer to effectively capture both local structure patterns and global
contextual dependencies of the informative graph, thereby enhancing the model's
reasoning capability across the entire environment. In addition, we deploy a
Kalman filter to smooth the waypoint outputs, ensuring that the resulting path
is kinodynamically feasible for the robot to follow. Experimental results
demonstrate that our method exhibits better exploration efficiency (up to 21.5%
in distance and 21.3% in time to complete exploration) than state-of-the-art
conventional and learning-based baselines in various simulation benchmarks. We
also validate our planner in real-world scenarios.

</details>


### [31] [Towards Context-Aware Human-like Pointing Gestures with RL Motion Imitation](https://arxiv.org/abs/2509.12880)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 提出基于强化学习和动作模仿的机器人指向动作生成方法，通过运动捕捉数据集训练策略，实现高精度且自然的指向行为


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注指向动作的识别而非生成，需要开发能够产生人类化、上下文感知的指向动作的机器人系统

Method: 收集包含多种风格、手性和空间目标的运动捕捉数据集，使用强化学习和动作模仿训练策略，在保持自然动态的同时最大化指向精度

Result: 方法在仿真中实现了上下文感知的指向行为，在任务性能和自然动态之间取得了良好平衡

Conclusion: 该工作填补了指向动作生成的研究空白，为机器人自然交互提供了有效解决方案

Abstract: Pointing is a key mode of interaction with robots, yet most prior work has
focused on recognition rather than generation. We present a motion capture
dataset of human pointing gestures covering diverse styles, handedness, and
spatial targets. Using reinforcement learning with motion imitation, we train
policies that reproduce human-like pointing while maximizing precision. Results
show our approach enables context-aware pointing behaviors in simulation,
balancing task performance with natural dynamics.

</details>


### [32] [Responsibility and Engagement -- Evaluating Interactions in Social Robot Navigation](https://arxiv.org/abs/2509.12890)
*Malte Probst,Raphael Wenzel,Monica Dasi*

Main category: cs.RO

TL;DR: 本文扩展了社交机器人导航中的责任度量框架，提出了时间归一化建模冲突积累阶段，并引入了新的参与度度量来捕捉冲突加剧程度，通过模拟实验验证了这些度量在评估冲突合作解决中的有效性。


<details>
  <summary>Details</summary>
Motivation: 在社交机器人导航中，需要有意义的标准来评估人机交互轨迹，特别是在解决多智能体冲突时，量化各智能体对冲突解决的贡献程度至关重要。

Method: 基于现有责任度量框架进行扩展：1）通过时间归一化建模冲突积累阶段；2）提出参与度度量来量化智能体行为对冲突的加剧程度；3）在模拟场景中进行全面测试，包括二元、群体和人群交互。

Result: 在模拟实验中证明，所提出的责任和参与度度量能够有效捕捉交互中冲突合作解决的有意义信息，可用于评估行为质量和前瞻性。

Conclusion: 提出的度量框架为社交机器人导航中的冲突解决评估提供了有效工具，但需要进一步讨论其适用性、设计选择和局限性。

Abstract: In Social Robot Navigation (SRN), the availability of meaningful metrics is
crucial for evaluating trajectories from human-robot interactions. In the SRN
context, such interactions often relate to resolving conflicts between two or
more agents. Correspondingly, the shares to which agents contribute to the
resolution of such conflicts are important. This paper builds on recent work,
which proposed a Responsibility metric capturing such shares. We extend this
framework in two directions: First, we model the conflict buildup phase by
introducing a time normalization. Second, we propose the related Engagement
metric, which captures how the agents' actions intensify a conflict. In a
comprehensive series of simulated scenarios with dyadic, group and crowd
interactions, we show that the metrics carry meaningful information about the
cooperative resolution of conflicts in interactions. They can be used to assess
behavior quality and foresightedness. We extensively discuss applicability,
design choices and limitations of the proposed metrics.

</details>


### [33] [Spotting the Unfriendly Robot -- Towards better Metrics for Interactions](https://arxiv.org/abs/2509.12912)
*Raphael Wenzel,Malte Probst*

Main category: cs.RO

TL;DR: 提出了两个新的社交机器人导航评估指标：冲突强度指标和责任指标，用于量化算法在减少冲突中的贡献程度和确定责任归属，以解决现有指标无法评估合作行为的问题。


<details>
  <summary>Details</summary>
Motivation: 当前社交机器人导航(SRN)算法评估指标缺乏量化机器人与人类互动中合作行为的能力，特别是在简单正面接近场景中无法区分是双方合作还是一方被迫避让的情况。

Method: 提出两个新指标：冲突强度指标（评估算法减少冲突的程度）和责任指标（确定哪个智能体承担了解决冲突的责任）。

Result: 开发了能够评估人机交互质量的新指标体系，可以具体量化算法在冲突解决中的贡献和责任分配。

Conclusion: 这些新指标有助于建立全面标准化的SRN评估方法，最终提升机器人在人本环境中的安全性、效率和社交接受度。

Abstract: Establishing standardized metrics for Social Robot Navigation (SRN)
algorithms for assessing the quality and social compliance of robot behavior
around humans is essential for SRN research. Currently, commonly used
evaluation metrics lack the ability to quantify how cooperative an agent
behaves in interaction with humans. Concretely, in a simple frontal approach
scenario, no metric specifically captures if both agents cooperate or if one
agent stays on collision course and the other agent is forced to evade. To
address this limitation, we propose two new metrics, a conflict intensity
metric and the responsibility metric. Together, these metrics are capable of
evaluating the quality of human-robot interactions by showing how much a given
algorithm has contributed to reducing a conflict and which agent actually took
responsibility of the resolution. This work aims to contribute to the
development of a comprehensive and standardized evaluation methodology for SRN,
ultimately enhancing the safety, efficiency, and social acceptance of robots in
human-centric environments.

</details>


### [34] [Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint](https://arxiv.org/abs/2509.12928)
*Peiwen Yang,Mingquan Jiang,Xinyue Shen,Heping Zhang*

Main category: cs.RO

TL;DR: 基于直线约束的光学视觉传感器时空检定方法，解决摄像机延迟和手眼变化导致的测量同步问题


<details>
  <summary>Details</summary>
Motivation: 摄像机通信延迟和手眼外参在长期测量中变化，导致图像捕获与机器人运动时间不同步，影响焊接应用中工件几何数据的准确获取

Method: 利用直线约束的时空检定方法，通过机器人以S形轨迹扫描直线角焊缘，并使用Plucker坐标表示所有测量热点位置都约束在直线上，建立非线性优化模型并使用LMA算法优化时间偏移、手眼外参和直线参数

Result: 通过曲线焊缘扫描实验定量验证了方法的可行性和准确性，并开源了代码、数据集和模拟报告

Conclusion: 该方法能够有效解决光学视觉传感器的时空同步问题，提高工业机器人焊接应用中工件几何数据测量的准确性和稳定性

Abstract: Laser vision sensors (LVS) are critical perception modules for industrial
robots, facilitating real-time acquisition of workpiece geometric data in
welding applications. However, the camera communication delay will lead to a
temporal desynchronization between captured images and the robot motions.
Additionally, hand-eye extrinsic parameters may vary during prolonged
measurement. To address these issues, we introduce a measurement model of LVS
considering the effect of the camera's time-offset and propose a teaching-free
spatiotemporal calibration method utilizing line constraints. This method
involves a robot equipped with an LVS repeatedly scanning straight-line fillet
welds using S-shaped trajectories. Regardless of the robot's orientation
changes, all measured welding positions are constrained to a straight-line,
represented by Plucker coordinates. Moreover, a nonlinear optimization model
based on straight-line constraints is established. Subsequently, the
Levenberg-Marquardt algorithm (LMA) is employed to optimize parameters,
including time-offset, hand-eye extrinsic parameters, and straight-line
parameters. The feasibility and accuracy of the proposed approach are
quantitatively validated through experiments on curved weld scanning. We
open-sourced the code, dataset, and simulation report at
https://anonymous.4open.science/r/LVS_ST_CALIB-015F/README.md.

</details>


### [35] [Tendon-Based Proprioception in an Anthropomorphic Underactuated Robotic Hand with Series Elastic Actuators](https://arxiv.org/abs/2509.12969)
*Jae-Hyun Lee,Jonghoo Park,Kyu-Jin Cho*

Main category: cs.RO

TL;DR: 提出了一种基于肌腱本体感知的仿生欠驱动手，通过串联弹性执行器实现全面的手-物体交互状态感知，无需视觉或触觉反馈即可完成抓取重建、柔性物体处理和盲抓任务


<details>
  <summary>Details</summary>
Motivation: 仿生欠驱动手因其多功能性和结构简单性被广泛应用，但紧凑的传感集成和与欠驱动机制匹配的状态感知是实现实用抓取功能的关键挑战

Method: 开发了高精度可靠的紧凑型串联弹性执行器(SEA)，集成到无传感器手指中；通过肌腱本体感知与基于势能的建模相结合，估计接触时机、关节角度、物体相对刚度等关键抓取变量

Result: 手指级实验和手级演示验证了方法的有效性，能够实现抓取姿态重建、柔性物体安全处理和基于本体感知的盲抓识别

Conclusion: 肌腱本体感知作为一种紧凑且鲁棒的传感方式，可在不依赖视觉或触觉反馈的情况下实现实用操作

Abstract: Anthropomorphic underactuated hands are widely employed for their versatility
and structural simplicity. In such systems, compact sensing integration and
proper interpretation aligned with underactuation are crucial for realizing
practical grasp functionalities. This study proposes an anthropomorphic
underactuated hand that achieves comprehensive situational awareness of
hand-object interaction, utilizing tendon-based proprioception provided by
series elastic actuators (SEAs). We developed a compact SEA with high accuracy
and reliability that can be seamlessly integrated into sensorless fingers. By
coupling proprioceptive sensing with potential energy-based modeling, the
system estimates key grasp-related variables, including contact timing, joint
angles, relative object stiffness, and finger configuration changes indicating
external disturbances. These estimated variables enable grasp posture
reconstruction, safe handling of deformable objects, and blind grasping with
proprioceptive-only recognition of objects with varying geometry and stiffness.
Finger-level experiments and hand-level demonstrations confirmed the
effectiveness of the proposed approach. The results demonstrate that
tendon-based proprioception serves as a compact and robust sensing modality for
practical manipulation without reliance on vision or tactile feedback.

</details>


### [36] [Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins](https://arxiv.org/abs/2509.12982)
*Erblin Isaku,Hassan Sartaj,Shaukat Ali,Beatriz Sanguino,Tongtong Wang,Guoyuan Li,Houxiang Zhang,Thomas Peyrucain*

Main category: cs.RO

TL;DR: 提出基于数字孪生的ODiSAR方法，使用Transformer模型预测机器人状态，结合重构误差和蒙特卡洛dropout进行不确定性量化，有效检测未知异常行为


<details>
  <summary>Details</summary>
Motivation: 复杂不确定环境中的自适应机器人需要主动检测和处理异常行为，包括分布外(OOD)情况，数字孪生为此提供了有价值的解决方案

Method: 使用基于Transformer的数字孪生预测机器人状态，采用重构误差和蒙特卡洛dropout进行不确定性量化，结合重构误差和预测方差来检测OOD行为，并包含可解释性层

Result: 在两个工业机器人案例中（办公室导航和海上船舶导航），ODiSAR实现了高达98% AUROC、96% TNR@TPR95和95% F1分数的检测性能

Conclusion: ODiSAR方法能够有效预测机器人行为并主动检测OOD事件，同时提供可解释的见解来支持自适应决策

Abstract: Self-adaptive robots (SARs) in complex, uncertain environments must
proactively detect and address abnormal behaviors, including
out-of-distribution (OOD) cases. To this end, digital twins offer a valuable
solution for OOD detection. Thus, we present a digital twin-based approach for
OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to
forecast SAR states and employs reconstruction error and Monte Carlo dropout
for uncertainty quantification. By combining reconstruction error with
predictive variance, the digital twin effectively detects OOD behaviors, even
in previously unseen conditions. The digital twin also includes an
explainability layer that links potential OOD to specific SAR states, offering
insights for self-adaptation. We evaluated ODiSAR by creating digital twins of
two industrial robots: one navigating an office environment, and another
performing maritime ship navigation. In both cases, ODiSAR forecasts SAR
behaviors (i.e., robot trajectories and vessel motion) and proactively detects
OOD events. Our results showed that ODiSAR achieved high detection performance
-- up to 98\% AUROC, 96\% TNR@TPR95, and 95\% F1-score -- while providing
interpretable insights to support self-adaptation.

</details>


### [37] [DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception](https://arxiv.org/abs/2509.13024)
*Haohan Min,Zhoujian Li,Yu Yang,Jinyu Chen,Shenghai Yuan*

Main category: cs.RO

TL;DR: 提出了一种名为DVDP的端到端视觉对接方法，使用双目RGB-D相机直接输出机器人对接路径，解决了传统视觉对接方法对初始位置要求严格的问题。


<details>
  <summary>Details</summary>
Motivation: 自动对接是移动机器人领域的重要挑战，视觉对接方法相比其他方法具有更高精度和更低部署成本，但对机器人初始位置要求严格，需要克服现有方法的局限性。

Method: 开发了DVDP端到端视觉对接策略，仅需在移动机器人上安装双目RGB-D相机即可直接输出对接路径。通过Unity 3D平台和真实移动机器人设置，收集了大规模虚拟和真实环境结合的视觉自动对接数据集。

Result: 开发了量化端到端视觉对接方法性能的评估指标。大量实验表明，该方法在性能上优于领先的感知骨干网络。在SCOUT Mini上的实际部署证实了DVDP的有效性，能够生成平滑、可行的对接轨迹，满足物理约束并达到目标姿态。

Conclusion: DVDP方法为移动机器人视觉自动对接提供了一种高效、精确的端到端解决方案，在实际应用中表现出色。

Abstract: Automatic docking has long been a significant challenge in the field of
mobile robotics. Compared to other automatic docking methods, visual docking
methods offer higher precision and lower deployment costs, making them an
efficient and promising choice for this task. However, visual docking methods
impose strict requirements on the robot's initial position at the start of the
docking process. To overcome the limitations of current vision-based methods,
we propose an innovative end-to-end visual docking method named DVDP(direct
visual docking policy). This approach requires only a binocular RGB-D camera
installed on the mobile robot to directly output the robot's docking path,
achieving end-to-end automatic docking. Furthermore, we have collected a
large-scale dataset of mobile robot visual automatic docking dataset through a
combination of virtual and real environments using the Unity 3D platform and
actual mobile robot setups. We developed a series of evaluation metrics to
quantify the performance of the end-to-end visual docking method. Extensive
experiments, including benchmarks against leading perception backbones adapted
into our framework, demonstrate that our method achieves superior performance.
Finally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy,
with our model generating smooth, feasible docking trajectories that meet
physical constraints and reach the target pose.

</details>


### [38] [Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol](https://arxiv.org/abs/2509.13069)
*James C. Ward,Arthur Richards,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 提出了一种新的分散式多机器人巡逻方法，用于在高度动态环境中进行持续监控，能够在线适应路线可通行性的变化


<details>
  <summary>Details</summary>
Motivation: 在安全、环境监测和灾难恢复等领域，需要机器人团队进行持续监控。完全在线分散式监控具有鲁棒性、适应性和可扩展性的优势，能够实时适应变化的环境

Method: 开发了一种新的分散式多机器人巡逻方法，巡逻机器人团队需要持续最小化访问兴趣点的时间间隔，并在完全分散的在线方式下观察和适应路线可通行性的动态变化

Result: 该方法在高度动态场景中显著优于现实基线，并研究了在某些动态场景中明确考虑环境动态可能不必要或不切实际的情况

Conclusion: 提出的分散式监控方法能够有效处理高度动态环境，为多机器人巡逻提供了实用的解决方案，但在某些情况下可能需要权衡是否明确处理环境动态

Abstract: Persistent monitoring using robot teams is of interest in fields such as
security, environmental monitoring, and disaster recovery. Performing such
monitoring in a fully on-line decentralised fashion has significant potential
advantages for robustness, adaptability, and scalability of monitoring
solutions, including, in principle, the capacity to effectively adapt in
real-time to a changing environment. We examine this through the lens of
multi-robot patrol, in which teams of patrol robots must persistently minimise
time between visits to points of interest, within environments where
traversability of routes is highly dynamic. These dynamics must be observed by
patrol agents and accounted for in a fully decentralised on-line manner. In
this work, we present a new method of monitoring and adjusting for environment
dynamics in a decentralised multi-robot patrol team. We demonstrate that our
method significantly outperforms realistic baselines in highly dynamic
scenarios, and also investigate dynamic scenarios in which explicitly
accounting for environment dynamics may be unnecessary or impractical.

</details>


### [39] [Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five](https://arxiv.org/abs/2509.13074)
*Simon Fritsch,Liam Achenbach,Riccardo Bianco,Nicola Irmiger,Gawain Marti,Samuel Visca,Chenyu Yang,Davide Liconti,Barnabas Gavin Cangan,Robert Jomar Malate,Ronan J. Hinchet,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SABD手是一个16自由度的机器人手，通过将第四和第五手指的内收/外展关节合并为单个大范围运动关节，实现了更大的抓取范围、超越人类能力的操作姿态，并减少了执行器数量。


<details>
  <summary>Details</summary>
Motivation: 传统仿人机器人手设计限制了抓取范围和能力，需要开发一种能够扩大抓取范围、实现非人类操作姿态同时减少复杂度的新型机器人手设计。

Method: 将第四和第五手指的内收/外展关节合并为单个大范围运动关节，使用强化学习方法进行抓取策略研究，并通过遥操作实验验证性能。

Result: 合并关节使手指工作空间增加400%，可抓取侧向距离达200mm的物体，遥操作试验中对合适YCB物体的抓取成功率达到86%，包括具有挑战性的非仿人配置。

Conclusion: SABD手设计在不增加复杂度的情况下显著提升了抓取稳定性、灵活性和灵巧操作能力，适用于广泛的应用场景。

Abstract: This paper presents the SABD hand, a 16-degree-of-freedom (DoF) robotic hand
that departs from purely anthropomorphic designs to achieve an expanded grasp
envelope, enable manipulation poses beyond human capability, and reduce the
required number of actuators. This is achieved by combining the
adduction/abduction (Add/Abd) joint of digits four and five into a single joint
with a large range of motion. The combined joint increases the workspace of the
digits by 400\% and reduces the required DoFs while retaining dexterity.
Experimental results demonstrate that the combined Add/Abd joint enables the
hand to grasp objects with a side distance of up to 200 mm. Reinforcement
learning-based investigations show that the design enables grasping policies
that are effective not only for handling larger objects but also for achieving
enhanced grasp stability. In teleoperated trials, the hand successfully
performed 86\% of attempted grasps on suitable YCB objects, including
challenging non-anthropomorphic configurations. These findings validate the
design's ability to enhance grasp stability, flexibility, and dexterous
manipulation without added complexity, making it well-suited for a wide range
of applications.

</details>


### [40] [A Design Co-Pilot for Task-Tailored Manipulators](https://arxiv.org/abs/2509.13077)
*Jonathan Külz,Sehoon Ha,Matthias Althoff*

Main category: cs.RO

TL;DR: 提出了一种自动设计和优化针对特定环境的机器人形态的完全可微分框架，能够快速生成专业化设计并实现即时适应


<details>
  <summary>Details</summary>
Motivation: 传统机器人制造商采用"一刀切"策略导致性能不佳，定制化机器人开发周期长、成本高，需要克服人类工程瓶颈

Method: 学习各种机械臂的逆运动学，建立完全可微分框架实现梯度优化的机器人形态设计和逆运动学解决方案

Result: 方法能够找到可在杂乱环境中导航的机器人、在指定工作空间表现良好的机械臂，并可适应不同硬件约束，实验证明仿真设计的模块化机器人成功通过障碍赛道

Conclusion: 该生成式方法将基于优化的设计生成时间从数小时缩短到数秒，可作为设计协作者实现即时适应和有效的人机协作

Abstract: Although robotic manipulators are used in an ever-growing range of
applications, robot manufacturers typically follow a ``one-fits-all''
philosophy, employing identical manipulators in various settings. This often
leads to suboptimal performance, as general-purpose designs fail to exploit
particularities of tasks. The development of custom, task-tailored robots is
hindered by long, cost-intensive development cycles and the high cost of
customized hardware. Recently, various computational design methods have been
devised to overcome the bottleneck of human engineering. In addition, a surge
of modular robots allows quick and economical adaptation to changing industrial
settings. This work proposes an approach to automatically designing and
optimizing robot morphologies tailored to a specific environment. To this end,
we learn the inverse kinematics for a wide range of different manipulators. A
fully differentiable framework realizes gradient-based fine-tuning of designed
robots and inverse kinematics solutions. Our generative approach accelerates
the generation of specialized designs from hours with optimization-based
methods to seconds, serving as a design co-pilot that enables instant
adaptation and effective human-AI collaboration. Numerical experiments show
that our approach finds robots that can navigate cluttered environments,
manipulators that perform well across a specified workspace, and can be adapted
to different hardware constraints. Finally, we demonstrate the real-world
applicability of our method by setting up a modular robot designed in
simulation that successfully moves through an obstacle course.

</details>


### [41] [Empowering Multi-Robot Cooperation via Sequential World Models](https://arxiv.org/abs/2509.13095)
*Zijie Zhao,Honglei Guo,Shengqian Chen,Kaixuan Xu,Bo Jiang,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.RO

TL;DR: SeqWM是一个基于序列化世界模型的多机器人强化学习框架，通过独立agent-wise模型分解复杂联合动力学，实现线性通信复杂度的显式意图共享和高效协作。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人协作中模型强化学习面临的联合动力学复杂性问题，提高样本效率和规划能力。

Method: 采用序列化结构，每个agent使用独立的世界模型，通过顺序通信进行潜在状态推演和决策，前序agent预测轨迹供后序agent规划行动。

Result: 在Bi-DexHands和Multi-Quad仿真环境中超越现有模型自由和模型基础方法，在真实四足机器人上成功部署，展现出预测适应和角色分工等高级协作行为。

Conclusion: SeqWM框架有效解决了多机器人协作的动力学建模挑战，实现了高效的意图共享和协作性能，具有实际部署价值。

Abstract: Model-based reinforcement learning (MBRL) has shown significant potential in
robotics due to its high sample efficiency and planning capability. However,
extending MBRL to multi-robot cooperation remains challenging due to the
complexity of joint dynamics. To address this, we propose the Sequential World
Model (SeqWM), a novel framework that integrates the sequential paradigm into
model-based multi-agent reinforcement learning. SeqWM employs independent,
sequentially structured agent-wise world models to decompose complex joint
dynamics. Latent rollouts and decision-making are performed through sequential
communication, where each agent generates its future trajectory and plans its
actions based on the predictions of its predecessors. This design enables
explicit intention sharing, enhancing cooperative performance, and reduces
communication overhead to linear complexity. Results in challenging simulated
environments (Bi-DexHands and Multi-Quad) show that SeqWM outperforms existing
state-of-the-art model-free and model-based baselines in both overall
performance and sample efficiency, while exhibiting advanced cooperative
behaviors such as predictive adaptation and role division. Furthermore, SeqWM
has been success fully deployed on physical quadruped robots, demonstrating its
effectiveness in real-world multi-robot systems. Demos and code are available
at: https://github.com/zhaozijie2022/seqwm-marl

</details>


### [42] [Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation](https://arxiv.org/abs/2509.13109)
*Fabian Flürenbrock,Yanick Büchel,Johannes Köhler,Marianne Schmid Daners,Melanie N. Zeilinger*

Main category: cs.RO

TL;DR: 本文提出了一个基于学习的软体机器人控制框架，用于调节颅内压波形，通过模型预测控制和贝叶斯优化的双层框架实现安全精确的控制。


<details>
  <summary>Details</summary>
Motivation: 研究脑脊液动力学和神经系统疾病的病理过程需要精确调节颅内压波形，但现有方法难以处理系统的非线性特性和安全约束。

Method: 采用双层控制框架：第一层使用带扰动观测器的模型预测控制器进行电机位置轨迹的安全跟踪；第二层使用贝叶斯优化算法在线学习产生目标颅内压波形的电机位置参考轨迹。

Result: 实验验证显示，MPC控制器将电机位置跟踪的平均误差和最大误差分别降低了83%和73%；贝叶斯优化在不到20次迭代内就能学习到产生目标颅内压波形的轨迹。

Conclusion: 该学习型控制框架能够安全有效地实现颅内压波形的精确调制，为神经系统疾病研究提供了可靠的技术手段。

Abstract: This paper introduces a learning-based control framework for a soft robotic
actuator system designed to modulate intracranial pressure (ICP) waveforms,
which is essential for studying cerebrospinal fluid dynamics and pathological
processes underlying neurological disorders. A two-layer framework is proposed
to safely achieve a desired ICP waveform modulation. First, a model predictive
controller (MPC) with a disturbance observer is used for offset-free tracking
of the system's motor position reference trajectory under safety constraints.
Second, to address the unknown nonlinear dependence of ICP on the motor
position, we employ a Bayesian optimization (BO) algorithm used for online
learning of a motor position reference trajectory that yields the desired ICP
modulation. The framework is experimentally validated using a test bench with a
brain phantom that replicates realistic ICP dynamics in vitro. Compared to a
previously employed proportional-integral-derivative controller, the MPC
reduces mean and maximum motor position reference tracking errors by 83 % and
73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor
position reference trajectory that yields an ICP waveform with the desired mean
and amplitude.

</details>


### [43] [Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation](https://arxiv.org/abs/2509.13126)
*Miquel Oller,An Dang,Nima Fazeli*

Main category: cs.RO

TL;DR: 提出了一种计算高效的非完整流体弹性模型，用于准确建模触觉传感器中路径依赖的接触力分布和动态表面积变化，通过扩展状态空间显式包含分布式力，支持基于梯度的轨迹优化。


<details>
  <summary>Details</summary>
Motivation: 触觉传感器虽然具有出色的感知能力，但其固有的柔顺性（被动柔顺元件引入的复杂非线性动力学）尚未得到充分探索，需要解决路径依赖行为的建模挑战。

Method: 开发了可微分的非完整流体弹性模型，扩展物体状态空间以显式包含柔顺传感器产生的分布式力，能够准确建模路径依赖的接触力分布和动态表面积变化。

Result: 在模拟和真实世界实验中证明了方法的有效性，强调了建模传感器动力学路径依赖性的重要性。

Conclusion: 该模型不仅能够处理路径依赖行为，还支持基于梯度的轨迹优化，可与高分辨率触觉反馈无缝集成，为柔顺触觉传感器的动力学建模提供了有效解决方案。

Abstract: Tactile sensors have long been valued for their perceptual capabilities,
offering rich insights into the otherwise hidden interface between the robot
and grasped objects. Yet their inherent compliance -- a key driver of
force-rich interactions -- remains underexplored. The central challenge is to
capture the complex, nonlinear dynamics introduced by these passive-compliant
elements. Here, we present a computationally efficient non-holonomic
hydroelastic model that accurately models path-dependent contact force
distributions and dynamic surface area variations. Our insight is to extend the
object's state space, explicitly incorporating the distributed forces generated
by the compliant sensor. Our differentiable formulation not only accounts for
path-dependent behavior but also enables gradient-based trajectory
optimization, seamlessly integrating with high-resolution tactile feedback. We
demonstrate the effectiveness of our approach across a range of simulated and
real-world experiments and highlight the importance of modeling the path
dependence of sensor dynamics.

</details>


### [44] [An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios](https://arxiv.org/abs/2509.13132)
*Zhihao Zhang,Chengyang Peng,Minghao Zhu,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 提出不确定性加权决策变换器(UWDT)，通过多通道鸟瞰图占用网格和变换器序列建模，在复杂环岛场景中实现更安全高效的自动驾驶决策


<details>
  <summary>Details</summary>
Motivation: 密集动态环境中的自动驾驶需要能够利用空间结构和长时域时间依赖性的决策系统，同时保持对不确定性的鲁棒性。需要解决频繁低风险状态与罕见安全关键决策之间的不平衡问题

Method: UWDT框架整合多通道鸟瞰图占用网格与基于变换器的序列建模。使用冻结教师变换器估计每个token的预测熵，作为学生模型损失函数的权重，增强对不确定、高影响状态的学习

Result: 在环岛模拟器中不同交通密度下的实验显示，UWDT在奖励、碰撞率和行为稳定性方面始终优于其他基线方法

Conclusion: 不确定性感知的时空变换器能够在复杂交通环境中为自动驾驶提供更安全高效的决策

Abstract: Autonomous driving in dense, dynamic environments requires decision-making
systems that can exploit both spatial structure and long-horizon temporal
dependencies while remaining robust to uncertainty. This work presents a novel
framework that integrates multi-channel bird's-eye-view occupancy grids with
transformer-based sequence modeling for tactical driving in complex roundabout
scenarios. To address the imbalance between frequent low-risk states and rare
safety-critical decisions, we propose the Uncertainty-Weighted Decision
Transformer (UWDT). UWDT employs a frozen teacher transformer to estimate
per-token predictive entropy, which is then used as a weight in the student
model's loss function. This mechanism amplifies learning from uncertain,
high-impact states while maintaining stability across common low-risk
transitions. Experiments in a roundabout simulator, across varying traffic
densities, show that UWDT consistently outperforms other baselines in terms of
reward, collision rate, and behavioral stability. The results demonstrate that
uncertainty-aware, spatial-temporal transformers can deliver safer and more
efficient decision-making for autonomous driving in complex traffic
environments.

</details>


### [45] [TeraSim-World: Worldwide Safety-Critical Data Synthesis for End-to-End Autonomous Driving](https://arxiv.org/abs/2509.13164)
*Jiawei Wang,Haowei Sun,Xintao Yan,Shuo Feng,Jun Gao,Henry X. Liu*

Main category: cs.RO

TL;DR: TeraSim-World是一个自动化管道，用于合成逼真且地理多样化的安全关键数据，用于全球任意位置的端到端自动驾驶训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶数据主要来自模拟器（存在显著的模拟到现实差距）或道路测试（成本高且不安全），需要一种能够生成大规模、多样化安全关键数据的方法。

Method: 从任意位置检索真实世界地图和交通需求，模拟自然驾驶数据集中的智能体行为，编排多样化逆境创建极端情况，并利用街景实现逼真的地理接地传感器渲染。

Result: 通过桥接智能体和传感器模拟，TeraSim-World提供了一个可扩展的关键数据合成框架。

Conclusion: 该框架为端到端自动驾驶系统的训练和评估提供了安全、可扩展的数据生成解决方案。

Abstract: Safe and scalable deployment of end-to-end (E2E) autonomous driving requires
extensive and diverse data, particularly safety-critical events. Existing data
are mostly generated from simulators with a significant sim-to-real gap or
collected from on-road testing that is costly and unsafe. This paper presents
TeraSim-World, an automated pipeline that synthesizes realistic and
geographically diverse safety-critical data for E2E autonomous driving at
anywhere in the world. Starting from an arbitrary location, TeraSim-World
retrieves real-world maps and traffic demand from geospatial data sources.
Then, it simulates agent behaviors from naturalistic driving datasets, and
orchestrates diverse adversities to create corner cases. Informed by street
views of the same location, it achieves photorealistic, geographically grounded
sensor rendering via the frontier video generation model Cosmos-Drive. By
bridging agent and sensor simulations, TeraSim-World provides a scalable and
critical~data synthesis framework for training and evaluation of E2E autonomous
driving systems.

</details>


### [46] [ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation](https://arxiv.org/abs/2509.13177)
*Salvatore Esposito,Matías Mattamala,Daniel Rebain,Francis Xiatian Zhang,Kevin Dhaliwal,Mohsen Khadem,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: ROOM是一个用于生成逼真支气管镜训练数据的仿真框架，通过患者CT扫描渲染多模态传感器数据，解决医疗机器人开发中真实数据获取困难的问题。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人在支气管镜检查中具有优势，但开发受到缺乏真实训练和测试环境的限制，真实数据收集存在伦理约束和患者安全问题。

Method: 利用患者CT扫描，渲染包括RGB图像、深度图、表面法线、光流和点云在内的多模态传感器数据，具有逼真的噪声和光照效果。

Result: 在医学机器人两个典型任务（多视角姿态估计和单目深度估计）中验证了ROOM生成的数据，展示了现有方法在医疗场景中需要克服的挑战，并证明可用于微调现有深度估计模型。

Conclusion: ROOM能够在大规模患者解剖结构和程序场景中生成数据，这些在临床环境中难以获取，有望推动医疗机器人技术的发展。

Abstract: Continuum robots are advancing bronchoscopy procedures by accessing complex
lung airways and enabling targeted interventions. However, their development is
limited by the lack of realistic training and test environments: Real data is
difficult to collect due to ethical constraints and patient safety concerns,
and developing autonomy algorithms requires realistic imaging and physical
feedback. We present ROOM (Realistic Optical Observation in Medicine), a
comprehensive simulation framework designed for generating photorealistic
bronchoscopy training data. By leveraging patient CT scans, our pipeline
renders multi-modal sensor data including RGB images with realistic noise and
light specularities, metric depth maps, surface normals, optical flow and point
clouds at medically relevant scales. We validate the data generated by ROOM in
two canonical tasks for medical robotics -- multi-view pose estimation and
monocular depth estimation, demonstrating diverse challenges that
state-of-the-art methods must overcome to transfer to these medical settings.
Furthermore, we show that the data produced by ROOM can be used to fine-tune
existing depth estimation models to overcome these challenges, also enabling
other downstream applications such as navigation. We expect that ROOM will
enable large-scale data generation across diverse patient anatomies and
procedural scenarios that are challenging to capture in clinical settings. Code
and data: https://github.com/iamsalvatore/room.

</details>


### [47] [StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening](https://arxiv.org/abs/2509.13200)
*Moonyoung Lee,Dong Ki Kim,Jai Krishna Bandi,Max Smith,Aileen Liao,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: StageACT是一种阶段条件模仿学习框架，通过为低级策略添加任务阶段输入，有效解决了人形机器人开门任务中的部分可观测性问题，在真实办公环境中对未见过的门实现了55%的成功率，比最佳基线提高了一倍多。


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要在人类日常环境中操作，开门是其中关键技能。但开门任务具有长时程和部分可观测性的挑战，特别是门锁状态的不可观测性导致标准行为克隆容易出现模式崩溃问题。

Method: 提出了StageACT框架，在低级策略中引入任务阶段条件输入，通过阶段提示支持有意行为引导，增强了在部分可观测环境下的鲁棒性。

Result: 在真实办公环境中，StageACT对未见过的门实现了55%的成功率，比最佳基线提高了一倍多，同时缩短了完成任务的时间，并支持通过阶段提示实现恢复行为。

Conclusion: 阶段条件化是一种轻量级但强大的机制，能够有效解决长时程人形机器人运动操作任务中的部分可观测性问题，显著提高了任务执行的成功率和效率。

Abstract: Humanoid robots promise to operate in everyday human environments without
requiring modifications to the surroundings. Among the many skills needed,
opening doors is essential, as doors are the most common gateways in built
spaces and often limit where a robot can go. Door opening, however, poses
unique challenges as it is a long-horizon task under partial observability,
such as reasoning about the door's unobservable latch state that dictates
whether the robot should rotate the handle or push the door. This ambiguity
makes standard behavior cloning prone to mode collapse, yielding blended or
out-of-sequence actions. We introduce StageACT, a stage-conditioned imitation
learning framework that augments low-level policies with task-stage inputs.
This effective addition increases robustness to partial observability, leading
to higher success rates and shorter completion times. On a humanoid operating
in a real-world office environment, StageACT achieves a 55% success rate on
previously unseen doors, more than doubling the best baseline. Moreover, our
method supports intentional behavior guidance through stage prompting, enabling
recovery behaviors. These results highlight stage conditioning as a lightweight
yet powerful mechanism for long-horizon humanoid loco-manipulation.

</details>


### [48] [Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum](https://arxiv.org/abs/2509.13239)
*Tianxu An,Flavio De Vincenti,Yuntao Ma,Marco Hutter,Stelian Coros*

Main category: cs.RO

TL;DR: 提出分层强化学习框架，训练单臂腿式机器人端到端执行拾取放置任务，在单机和双机协作场景中均有效，通过动态奖励课程提高55%训练效率和18.6%执行效率


<details>
  <summary>Details</summary>
Motivation: 解决长时域强化学习任务中训练效率低的问题，特别是针对腿式机器人协作拾取放置这一复杂任务，现有方法难以有效处理完整任务流程

Method: 采用分层RL框架，引入新颖的动态奖励课程机制，通过逐步引导智能体完成以载荷为中心的子目标，使单一策略能高效学习长时域操作；在双机器人场景中通过自主注意力转移实现有效协调

Result: 在仿真实验中相比最先进方法提升55%训练效率和18.6%执行时间减少；在真实世界ANYmal D平台上验证了单机和双机场景的有效性；双机器人策略能根据不同任务阶段关注观察空间的不同组件

Conclusion: 这是首个处理两个腿式操纵器完整协作拾取放置任务的RL框架，证明了动态奖励课程和分层方法在复杂长时域机器人任务中的有效性

Abstract: We present a hierarchical RL pipeline for training one-armed legged robots to
perform pick-and-place (P&P) tasks end-to-end -- from approaching the payload
to releasing it at a target area -- in both single-robot and cooperative
dual-robot settings. We introduce a novel dynamic reward curriculum that
enables a single policy to efficiently learn long-horizon P&P operations by
progressively guiding the agents through payload-centered sub-objectives.
Compared to state-of-the-art approaches for long-horizon RL tasks, our method
improves training efficiency by 55% and reduces execution time by 18.6% in
simulation experiments. In the dual-robot case, we show that our policy enables
each robot to attend to different components of its observation space at
distinct task stages, promoting effective coordination via autonomous attention
shifts. We validate our method through real-world experiments using ANYmal D
platforms in both single- and dual-robot scenarios. To our knowledge, this is
the first RL pipeline that tackles the full scope of collaborative P&P with two
legged manipulators.

</details>


### [49] [Design and Control of a Perching Drone Inspired by the Prey-Capturing Mechanism of Venus Flytrap](https://arxiv.org/abs/2509.13249)
*Ye Li,Daming Liu,Yanhe Zhu,Junming Zhang,Yongsheng Luo,Ziqi Wang,Chenyu Liu,Jie Zhao*

Main category: cs.RO

TL;DR: 提出了一种受捕蝇草启发的主动柔性栖息无人机，可在100毫秒内完成栖息，采用级联高增益观测器控制方法实时估计和补偿外部扰动，提高了系统稳定性和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 无人机续航能力和能源效率是其设计和操作中的关键挑战。通过栖息机制可以让无人机暂时停止飞行以节省能量，从而延长任务时间。

Method: 开发了仿生栖息结构，采用主动柔性栖息机制；设计了级联扩展高增益观测器（EHGO）控制方法，能够实时估计和补偿外部扰动。

Result: 实验结果表明栖息结构具有良好的适应性，级联EHGO在抵抗风和栖息扰动方面表现出优越性能，栖息时间少于100毫秒。

Conclusion: 该仿生栖息无人机系统实现了快速、稳定的栖息能力，为解决无人机续航问题提供了有效的技术方案。

Abstract: The endurance and energy efficiency of drones remain critical challenges in
their design and operation. To extend mission duration, numerous studies
explored perching mechanisms that enable drones to conserve energy by
temporarily suspending flight. This paper presents a new perching drone that
utilizes an active flexible perching mechanism inspired by the rapid predation
mechanism of the Venus flytrap, achieving perching in less than 100 ms. The
proposed system is designed for high-speed adaptability to the perching
targets. The overall drone design is outlined, followed by the development and
validation of the biomimetic perching structure. To enhance the system
stability, a cascade extended high-gain observer (EHGO) based control method is
developed, which can estimate and compensate for the external disturbance in
real time. The experimental results demonstrate the adaptability of the
perching structure and the superiority of the cascaded EHGO in resisting wind
and perching disturbances.

</details>


### [50] [HARMONIC: A Content-Centric Cognitive Robotic Architecture](https://arxiv.org/abs/2509.13279)
*Sanjay Oruganti,Sergei Nirenburg,Marjorie McShane,Jesse English,Michael K. Roberts,Christian Arndt,Carlos Gonzalez,Mingyo Seo,Luis Sentis*

Main category: cs.RO

TL;DR: HARMONIC是一个认知机器人架构，专为人类-机器人团队设计，支持语义感知解释、类人决策和意向性语言通信，旨在解决数据稀缺、可解释性和安全性问题。


<details>
  <summary>Details</summary>
Motivation: 解决人类-机器人团队中的安全性、结果质量问题，以及数据稀缺、可解释性和安全性等挑战，促进透明度和信任。

Method: 开发HARMONIC认知机器人架构，支持语义感知解释、类人决策和意向性语言通信，并在高保真仿真环境和物理机器人平台上实现两个概念验证系统。

Result: 成功实现了两个基于HARMONIC的机器人系统，分别在仿真环境和物理平台上进行了验证。

Conclusion: HARMONIC架构有效解决了人类-机器人团队中的关键问题，为构建更安全、可解释和可信的机器人系统提供了可行方案。

Abstract: This paper introduces HARMONIC, a cognitive-robotic architecture designed for
robots in human-robotic teams. HARMONIC supports semantic perception
interpretation, human-like decision-making, and intentional language
communication. It addresses the issues of safety and quality of results; aims
to solve problems of data scarcity, explainability, and safety; and promotes
transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are
demonstrated, each implemented in both a high-fidelity simulation environment
and on physical robotic platforms.

</details>
