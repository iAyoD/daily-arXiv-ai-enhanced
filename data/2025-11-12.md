<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [CAVER: Curious Audiovisual Exploring Robot](https://arxiv.org/abs/2511.07619)
*Luca Macesanu,Boueny Folefack,Samik Singh,Ruchira Ray,Ben Abbatematteo,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: CAVER是一个机器人系统，通过新颖的末端执行器、视听表征和探索算法，高效构建物体的视听表征，提升材料分类和音频演示模仿能力。


<details>
  <summary>Details</summary>
Motivation: 多模态视听感知能为机器人操作开辟新途径，但需要学习物体视觉外观与交互声音之间的关联，这需要新的交互能力、表征和探索方法。

Method: 1) 3D打印末端执行器激发物体音频响应；2) 结合局部和全局外观信息与声音特征的视听表征；3) 好奇心驱动的探索算法，优先与高不确定性物体交互。

Result: CAVER在不同场景下比多个基线方法更高效地构建丰富表征，学习的视听表征显著改善了材料分类和纯音频人类演示的模仿。

Conclusion: CAVER系统通过创新的硬件设计和算法，成功实现了高效的视听表征学习，为机器人多模态感知提供了有效解决方案。

Abstract: Multimodal audiovisual perception can enable new avenues for robotic manipulation, from better material classification to the imitation of demonstrations for which only audio signals are available (e.g., playing a tune by ear). However, to unlock such multimodal potential, robots need to learn the correlations between an object's visual appearance and the sound it generates when they interact with it. Such an active sensorimotor experience requires new interaction capabilities, representations, and exploration methods to guide the robot in efficiently building increasingly rich audiovisual knowledge. In this work, we present CAVER, a novel robot that builds and utilizes rich audiovisual representations of objects. CAVER includes three novel contributions: 1) a novel 3D printed end-effector, attachable to parallel grippers, that excites objects' audio responses, 2) an audiovisual representation that combines local and global appearance information with sound features, and 3) an exploration algorithm that uses and builds the audiovisual representation in a curiosity-driven manner that prioritizes interacting with high uncertainty objects to obtain good coverage of surprising audio with fewer interactions. We demonstrate that CAVER builds rich representations in different scenarios more efficiently than several exploration baselines, and that the learned audiovisual representation leads to significant improvements in material classification and the imitation of audio-only human demonstrations. https://caver-bot.github.io/

</details>


### [2] [Time-Aware Policy Learning for Adaptive and Punctual Robot Control](https://arxiv.org/abs/2511.07654)
*Yinsen Jia,Boyuan Chen*

Main category: cs.RO

TL;DR: 提出时间感知策略学习框架，让机器人将时间作为首要变量进行感知和推理，通过剩余时间和时间比率两个时间信号，使单一策略能在快速动态和谨慎精确执行之间连续调节行为。


<details>
  <summary>Details</summary>
Motivation: 当前大多数机器人学习算法对时间缺乏感知能力，而时间意识是动物和人类智能行为的基础，指导动作如何排序、调整节奏并适应变化的目标和环境。

Method: 增强传统强化学习策略，引入剩余时间和时间比率两个互补的时间信号，联合优化准时性和稳定性，使机器人无需重新训练或奖励调整就能平衡效率、鲁棒性、韧性和准时性。

Result: 在多种操作领域（长视野拾放、颗粒介质倾倒、关节对象处理、多智能体对象递送）中，时间感知策略比标准强化学习基线效率提升高达48%，模拟到现实转移鲁棒性提高8倍，声学安静度提升90%，同时保持接近完美的成功率。

Conclusion: 通过将时间视为行为的可控维度而非约束，时间感知策略学习为高效、鲁棒、有韧性且与人类对齐的机器人自主性提供了统一基础。

Abstract: Temporal awareness underlies intelligent behavior in both animals and humans, guiding how actions are sequenced, paced, and adapted to changing goals and environments. Yet most robot learning algorithms remain blind to time. We introduce time-aware policy learning, a reinforcement learning framework that enables robots to explicitly perceive and reason with time as a first-class variable. The framework augments conventional reinforcement policies with two complementary temporal signals, the remaining time and a time ratio, which allow a single policy to modulate its behavior continuously from rapid and dynamic to cautious and precise execution. By jointly optimizing punctuality and stability, the robot learns to balance efficiency, robustness, resiliency, and punctuality without re-training or reward adjustment. Across diverse manipulation domains from long-horizon pick and place, to granular-media pouring, articulated-object handling, and multi-agent object delivery, the time-aware policy produces adaptive behaviors that outperform standard reinforcement learning baselines by up to 48% in efficiency, 8 times more robust in sim-to-real transfer, and 90% in acoustic quietness while maintaining near-perfect success rates. Explicit temporal reasoning further enables real-time human-in-the-loop control and multi-agent coordination, allowing robots to recover from disturbances, re-synchronize after delays, and align motion tempo with human intent. By treating time not as a constraint but as a controllable dimension of behavior, time-aware policy learning provides a unified foundation for efficient, robust, resilient, and human-aligned robot autonomy.

</details>


### [3] [Testing and Evaluation of Underwater Vehicle Using Hardware-In-The-Loop Simulation with HoloOcean](https://arxiv.org/abs/2511.07687)
*Braden Meyers,Joshua G. Mangelson*

Main category: cs.RO

TL;DR: 本文展示了使用HoloOcean 2.0模拟器进行水下机器人硬件在环和软件在环测试的方法，通过ROS 2接口连接模拟环境与真实机器人系统，并将模拟结果与实际现场试验进行对比。


<details>
  <summary>Details</summary>
Motivation: 在受控环境中测试海洋机器人系统具有挑战性，特别是当声学传感器和控制表面仅在水下正常工作时。室内水池测试面临空间限制，难以大规模测试控制、导航和感知算法。

Method: 使用HoloOcean 2.0模拟器，通过ROS 2桥接实现硬件在环和软件在环测试。模拟传感器数据发送给CougUV AUV，控制命令返回模拟器进行计算。

Result: 成功建立了HIL和SIL测试设置，能够模拟传感器数据和车辆动力学，并将模拟结果与实际现场试验结果进行比较。

Conclusion: 高保真水下模拟工具能够有效解决海洋机器人测试的空间限制问题，HoloOcean 2.0模拟器为AUV的开发和测试提供了可靠的环境。

Abstract: Testing marine robotics systems in controlled environments before field tests is challenging, especially when acoustic-based sensors and control surfaces only function properly underwater. Deploying robots in indoor tanks and pools often faces space constraints that complicate testing of control, navigation, and perception algorithms at scale. Recent developments of high-fidelity underwater simulation tools have the potential to address these problems. We demonstrate the utility of the recently released HoloOcean 2.0 simulator with improved dynamics for torpedo AUV vehicles and a new ROS 2 interface. We have successfully demonstrated a Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) setup for testing and evaluating a CougUV torpedo autonomous underwater vehicle (AUV) that was built and developed in our lab. With this HIL and SIL setup, simulations are run in HoloOcean using a ROS 2 bridge such that simulated sensor data is sent to the CougUV (mimicking sensor drivers) and control surface commands are sent back to the simulation, where vehicle dynamics and sensor data are calculated. We compare our simulated results to real-world field trial results.

</details>


### [4] [RoboTAG: End-to-end Robot Configuration Estimation via Topological Alignment Graph](https://arxiv.org/abs/2511.07717)
*Yifan Liu,Fangneng Zhan,Wanhua Li,Haowen Sun,Katerina Fragkiadaki,Hanspeter Pfister*

Main category: cs.RO

TL;DR: 提出RoboTAG方法，通过引入3D分支注入3D先验知识，实现2D和3D表征的协同进化，减少对标注数据的依赖，利用无标注的野外图像进行训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法基于2D视觉骨干网络，严重依赖标注数据训练，而真实场景中标注数据稀缺，导致仿真到现实的差距。这些方法将3D问题简化为2D领域，忽略了3D先验知识。

Method: RoboTAG包含3D分支和2D分支，节点表示相机和机器人系统状态，边捕获变量间依赖关系或对齐关系。在图的闭环上应用跨分支一致性监督，无需标注即可利用野外图像训练。

Result: 实验结果表明该方法在不同类型机器人上都有效，显示出缓解机器人领域数据瓶颈的潜力。

Conclusion: RoboTAG通过融合3D先验和2D-3D协同进化，成功减少了标注数据依赖，为解决机器人姿态估计中的数据稀缺问题提供了有效方案。

Abstract: Estimating robot pose from a monocular RGB image is a challenge in robotics and computer vision. Existing methods typically build networks on top of 2D visual backbones and depend heavily on labeled data for training, which is often scarce in real-world scenarios, causing a sim-to-real gap. Moreover, these approaches reduce the 3D-based problem to 2D domain, neglecting the 3D priors. To address these, we propose Robot Topological Alignment Graph (RoboTAG), which incorporates a 3D branch to inject 3D priors while enabling co-evolution of the 2D and 3D representations, alleviating the reliance on labels. Specifically, the RoboTAG consists of a 3D branch and a 2D branch, where nodes represent the states of the camera and robot system, and edges capture the dependencies between these variables or denote alignments between them. Closed loops are then defined in the graph, on which a consistency supervision across branches can be applied. This design allows us to utilize in-the-wild images as training data without annotations. Experimental results demonstrate that our method is effective across robot types, highlighting its potential to alleviate the data bottleneck in robotics.

</details>


### [5] [A QP Framework for Improving Data Collection: Quantifying Device-Controller Performance in Robot Teleoperation](https://arxiv.org/abs/2511.07720)
*Yuxuan Zhao,Yuanchen Tang,Jindi Zhang,Hongyu Yu*

Main category: cs.RO

TL;DR: 开发了一个兼容不同遥操作设备和机械臂控制器的遥操作流水线，采用基于动态零空间和阻抗跟踪的最优控制器，实现顺应性姿态跟踪和奇异性避免。


<details>
  <summary>Details</summary>
Motivation: 为实现类似大型语言模型的具身智能，需要高质量数据来训练包含多样化机器人技能的基础模型，而遥操作设备的数据收集质量对机器人学习至关重要。

Method: 构建了兼容不同遥操作设备和机械臂控制器的遥操作流水线，开发了基于动态零空间和阻抗跟踪的最优QP控制器，根据关节可操作性自适应调整权重分配。

Result: 定量实验分析比较了不同遥操作接口和运动控制器组合下的轨迹数据质量，包括跟踪误差、奇异性发生情况和关节轨迹平滑度。

Conclusion: 提出的遥操作流水线和最优控制器能够有效提高遥操作轨迹数据的质量，为机器人学习提供高质量的训练数据。

Abstract: Robot learning empowers the robot system with human brain-like intelligence to autonomously acquire and adapt skills through experience, enhancing flexibility and adaptability in various environments. Aimed at achieving a similar level of capability in large language models (LLMs) for embodied intelligence, data quality plays a crucial role in training a foundational model with diverse robot skills. In this study, we investigate the collection of data for manipulation tasks using teleoperation devices. Different devices yield varying effects when paired with corresponding controller strategies, including position-based inverse kinematics (IK) control, torque-based inverse dynamics (ID) control, and optimization-based compliance control. In this paper, we develop a teleoperation pipeline that is compatible with different teleoperation devices and manipulator controllers. Within the pipeline, we construct the optimal QP formulation with the dynamic nullspace and the impedance tracking as the novel optimal controller to achieve compliant pose tracking and singularity avoidance. Regarding the optimal controller, it adaptively adjusts the weights assignment depending on the robot joint manipulability that reflects the state of joint configuration for the pose tracking in the form of impedance control and singularity avoidance with nullspace tracking. Analysis of quantitative experimental results suggests the quality of the teleoperated trajectory data, including tracking error, occurrence of singularity, and the smoothness of the joints' trajectory, with different combinations of teleoperation interface and the motion controller.

</details>


### [6] [LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models](https://arxiv.org/abs/2511.07727)
*Xiaohan Zhang,Yan Ding,Yohei Hayamizu,Zainab Altaweel,Yifeng Zhu,Yuke Zhu,Peter Stone,Chris Paxton,Shiqi Zhang*

Main category: cs.RO

TL;DR: 提出一个结合任务规划和运动规划的TAMP框架，用于移动机器人的多物体操作任务，利用大语言模型的常识知识来指导物体摆放位置和方式


<details>
  <summary>Details</summary>
Motivation: 解决移动操作任务中物体摆放位置和方式的不确定性问题，特别是在目标描述不明确的情况下（如"布置餐桌"），需要结合常识知识来规划导航和操作动作

Method: 结合大语言模型的常识知识进行任务级规划，使用计算机视觉方法选择基座位置，构建一个自适应的TAMP框架来处理多物体移动的新颖场景

Result: 在真实世界和模拟环境中进行了定量实验，成功完成了84.4%的真实世界物体重排试验，但主观人类评估显示机器人性能仍低于经验丰富的人类服务员

Conclusion: 提出的TAMP框架能够有效处理移动操作任务中的物体重排问题，利用LLM的常识知识提高了任务完成率，但在性能上仍有提升空间

Abstract: Task planning and motion planning are two of the most important problems in robotics, where task planning methods help robots achieve high-level goals and motion planning methods maintain low-level feasibility. Task and motion planning (TAMP) methods interleave the two processes of task planning and motion planning to ensure goal achievement and motion feasibility. Within the TAMP context, we are concerned with the mobile manipulation (MoMa) of multiple objects, where it is necessary to interleave actions for navigation and manipulation.
  In particular, we aim to compute where and how each object should be placed given underspecified goals, such as ``set up dinner table with a fork, knife and plate.'' We leverage the rich common sense knowledge from large language models (LLMs), e.g., about how tableware is organized, to facilitate both task-level and motion-level planning. In addition, we use computer vision methods to learn a strategy for selecting base positions to facilitate MoMa behaviors, where the base position corresponds to the robot's ``footprint'' and orientation in its operating space. Altogether, this article provides a principled TAMP framework for MoMa tasks that accounts for common sense about object rearrangement and is adaptive to novel situations that include many objects that need to be moved. We performed quantitative experiments in both real-world settings and simulated environments. We evaluated the success rate and efficiency in completing long-horizon object rearrangement tasks. While the robot completed 84.4\% real-world object rearrangement trials, subjective human evaluations indicated that the robot's performance is still lower than experienced human waiters.

</details>


### [7] [ViPRA: Video Prediction for Robot Actions](https://arxiv.org/abs/2511.07732)
*Sandeep Routray,Hengkai Pan,Unnat Jain,Shikhar Bahl,Deepak Pathak*

Main category: cs.RO

TL;DR: ViPRA是一个从无动作标签视频中学习机器人控制的预训练-微调框架，通过预测未来视觉观察和运动中心潜在动作来学习连续控制，仅需少量演示即可实现跨具身智能体的泛化。


<details>
  <summary>Details</summary>
Motivation: 大多数视频（包括人类或遥操作机器人视频）缺乏动作标签，限制了它们在机器人学习中的应用。需要一种方法能够从这些无动作视频中学习连续机器人控制。

Method: 训练视频语言模型预测未来视觉观察和运动中心潜在动作，使用感知损失和光流一致性确保物理基础行为。下游控制使用分块流匹配解码器将潜在动作映射到机器人特定连续动作序列。

Result: 在SIMPLER基准上提升16%，在现实世界操作任务中提升13%，支持22Hz的高频连续控制，仅需100-200个遥操作演示。

Conclusion: ViPRA能够有效从无动作视频中学习连续机器人控制，避免昂贵的动作标注，支持跨具身智能体泛化，实现平滑高频控制。

Abstract: Can we turn a video prediction model into a robot policy? Videos, including those of humans or teleoperated robots, capture rich physical interactions. However, most of them lack labeled actions, which limits their use in robot learning. We present Video Prediction for Robot Actions (ViPRA), a simple pretraining-finetuning framework that learns continuous robot control from these actionless videos. Instead of directly predicting actions, we train a video-language model to predict both future visual observations and motion-centric latent actions, which serve as intermediate representations of scene dynamics. We train these latent actions using perceptual losses and optical flow consistency to ensure they reflect physically grounded behavior. For downstream control, we introduce a chunked flow matching decoder that maps latent actions to robot-specific continuous action sequences, using only 100 to 200 teleoperated demonstrations. This approach avoids expensive action annotation, supports generalization across embodiments, and enables smooth, high-frequency continuous control upto 22 Hz via chunked action decoding. Unlike prior latent action works that treat pretraining as autoregressive policy learning, explicitly models both what changes and how. Our method outperforms strong baselines, with a 16% gain on the SIMPLER benchmark and a 13% improvement across real world manipulation tasks. We will release models and code at https://vipra-project.github.io

</details>


### [8] [Navigating the Wild: Pareto-Optimal Visual Decision-Making in Image Space](https://arxiv.org/abs/2511.07750)
*Durgakant Pushp,Weizhe Chen,Zheng Chen,Chaomin Luo,Jason M. Gregory,Lantao Liu*

Main category: cs.RO

TL;DR: 提出Pareto最优视觉导航框架，结合数据驱动语义、Pareto最优决策和视觉伺服，实现轻量级实时导航


<details>
  <summary>Details</summary>
Motivation: 传统反应式方法在复杂环境中容易失败，基于地图的方法需要大量建图工作，基于学习的方法依赖大数据集且泛化能力有限

Method: 使用图像空间框架，结合数据驱动语义、Pareto最优决策和视觉伺服

Result: 实现了轻量级实时导航

Conclusion: 该框架能够有效解决复杂环境中的导航问题

Abstract: Navigating complex real-world environments requires semantic understanding and adaptive decision-making. Traditional reactive methods without maps often fail in cluttered settings, map-based approaches demand heavy mapping effort, and learning-based solutions rely on large datasets with limited generalization. To address these challenges, we present Pareto-Optimal Visual Navigation, a lightweight image-space framework that combines data-driven semantics, Pareto-optimal decision-making, and visual servoing for real-time navigation.

</details>


### [9] [High-Altitude Balloon Station-Keeping with First Order Model Predictive Control](https://arxiv.org/abs/2511.07761)
*Myles Pasetsky,Jiawei Lin,Bradley Guo,Sarah Dean*

Main category: cs.RO

TL;DR: 本文开发了基于梯度优化的模型预测控制方法(FOMPC)，用于高空气球站控任务，相比无模型强化学习方法提升了24%的站控性能，且无需离线训练。


<details>
  <summary>Details</summary>
Motivation: 重新评估模型控制在高空气球站控任务中的有效性，挑战传统认为由于系统复杂性和风场不确定性而只能依赖无模型方法的假设。

Method: 使用JAX实现可微分的风场和气球动力学模型，通过基于梯度的轨迹优化进行在线规划，开发了FOMPC方法。

Result: FOMPC在时间-半径内停留时间(TWR)指标上比最先进的RL策略提升了24%，但每个控制步骤需要更多在线计算。

Conclusion: 在线规划在多种配置下都有效，包括简化的风场和动力学模型，模型控制方法在高空气球站控中具有实际应用价值。

Abstract: High-altitude balloons (HABs) are common in scientific research due to their wide range of applications and low cost. Because of their nonlinear, underactuated dynamics and the partial observability of wind fields, prior work has largely relied on model-free reinforcement learning (RL) methods to design near-optimal control schemes for station-keeping. These methods often compare only against hand-crafted heuristics, dismissing model-based approaches as impractical given the system complexity and uncertain wind forecasts. We revisit this assumption about the efficacy of model-based control for station-keeping by developing First-Order Model Predictive Control (FOMPC). By implementing the wind and balloon dynamics as differentiable functions in JAX, we enable gradient-based trajectory optimization for online planning. FOMPC outperforms a state-of-the-art RL policy, achieving a 24% improvement in time-within-radius (TWR) without requiring offline training, though at the cost of greater online computation per control step. Through systematic ablations of modeling assumptions and control factors, we show that online planning is effective across many configurations, including under simplified wind and dynamics models.

</details>


### [10] [Benchmarking Resilience and Sensitivity of Polyurethane-Based Vision-Based Tactile Sensors](https://arxiv.org/abs/2511.07797)
*Benjamin Davis,Hannah Stuart*

Main category: cs.RO

TL;DR: 比较硅胶和聚氨酯橡胶在视觉触觉传感器中的性能，聚氨酯在耐用性方面表现更好但灵敏度可能较低


<details>
  <summary>Details</summary>
Motivation: 现有视觉触觉传感器使用硅胶凝胶，灵敏度高但容易因负载和表面磨损而劣化，需要寻找更耐用的替代材料

Method: 提出标准评估基准协议，包括耐久性测试（法向加载、剪切加载、磨损）和灵敏度测试（力和空间灵敏度），并进行瓶盖松紧演示

Result: 聚氨酯橡胶在物理凝胶韧性方面表现更好，可能以灵敏度为代价，在瓶盖操作等应用中具有优势

Conclusion: 聚氨酯橡胶作为视觉触觉传感器材料在耐用性方面优于硅胶，适合高负载应用，但需要在灵敏度和韧性之间权衡

Abstract: Vision-based tactile sensors (VBTSs) are a promising technology for robots, providing them with dense signals that can be translated into an understanding of normal and shear load, contact region, texture classification, and more. However, existing VBTS tactile surfaces make use of silicone gels, which provide high sensitivity but easily deteriorate from loading and surface wear. We propose that polyurethane rubber, used for high-load applications like shoe soles, rubber wheels, and industrial gaskets, may provide improved physical gel resilience, potentially at the cost of sensitivity. To compare the resilience and sensitivity of silicone and polyurethane VBTS gels, we propose a series of standard evaluation benchmarking protocols. Our resilience tests assess sensor durability across normal loading, shear loading, and abrasion. For sensitivity, we introduce model-free assessments of force and spatial sensitivity to directly measure the physical capabilities of each gel without effects introduced from data and model quality. Finally, we include a bottle cap loosening and tightening demonstration as an example where polyurethane gels provide an advantage over their silicone counterparts.

</details>


### [11] [Virtual Traffic Lights for Multi-Robot Navigation: Decentralized Planning with Centralized Conflict Resolution](https://arxiv.org/abs/2511.07811)
*Sagar Gupta,Thanh Vinh Nguyen,Thieu Long Phan,Vidul Attri,Archit Gupta,Niroshinie Fernando,Kevin Lee,Seng W. Loke,Ronny Kutadinata,Benjamin Champion,Akansel Cosgun*

Main category: cs.RO

TL;DR: 提出了一种结合分散式路径规划和集中式冲突解决的混合多机器人协调框架，通过虚拟交通灯机制避免死锁


<details>
  <summary>Details</summary>
Motivation: 传统集中式规划方法需要完全控制机器人路径，而分散式方法容易产生冲突和死锁，需要一种平衡两者优势的协调方法

Method: 机器人自主规划路径并共享给集中节点，集中系统检测潜在冲突并发出停止指令，仅允许一个冲突机器人通过，类似虚拟交通灯机制

Result: 在仿真实验中提高了机器人到达目标的成功率并减少了死锁，在真实实验中成功验证了四足机器人和轮式Duckiebots的协调效果

Conclusion: 该混合协调框架有效结合了分散规划和集中冲突解决的优势，在不完全控制机器人路径的情况下实现了高效的冲突避免

Abstract: We present a hybrid multi-robot coordination framework that combines decentralized path planning with centralized conflict resolution. In our approach, each robot autonomously plans its path and shares this information with a centralized node. The centralized system detects potential conflicts and allows only one of the conflicting robots to proceed at a time, instructing others to stop outside the conflicting area to avoid deadlocks. Unlike traditional centralized planning methods, our system does not dictate robot paths but instead provides stop commands, functioning as a virtual traffic light. In simulation experiments with multiple robots, our approach increased the success rate of robots reaching their goals while reducing deadlocks. Furthermore, we successfully validated the system in real-world experiments with two quadruped robots and separately with wheeled Duckiebots.

</details>


### [12] [SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control](https://arxiv.org/abs/2511.07820)
*Zhengyi Luo,Ye Yuan,Tingwu Wang,Chenran Li,Sirui Chen,Fernando Castañeda,Zi-Ang Cao,Jiefeng Li,David Minor,Qingwei Ben,Xingye Da,Runyu Ding,Cyrus Hogg,Lina Song,Edy Lim,Eugene Jeong,Tairan He,Haoru Xue,Wenli Xiao,Zi Wang,Simon Yuen,Jan Kautz,Yan Chang,Umar Iqbal,Linxi "Jim" Fan,Yuke Zhu*

Main category: cs.RO

TL;DR: 通过扩大模型容量、数据和计算规模，构建了一个能够产生自然且鲁棒全身运动的人形机器人通用控制器，将运动跟踪作为可扩展的任务，并展示了在实际应用中的实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在数千个GPU上训练了数十亿参数，但人形控制领域尚未显示出类似的扩展收益。当前的人形神经控制器规模较小，目标行为有限，训练资源有限。

Method: 将运动跟踪作为人形控制的自然且可扩展任务，利用多样化的运动捕捉数据进行密集监督，无需手动奖励工程。在三个维度上进行扩展：网络规模（1.2M到42M参数）、数据集规模（超过1亿帧，700小时高质量运动数据）和计算资源（9k GPU小时）。

Result: 创建了一个通用的运动跟踪基础模型，性能随着计算和数据多样性的增加而稳步提升，学习到的表示能够泛化到未见过的运动。通过实时通用运动规划器和统一标记空间支持多种运动输入接口。

Conclusion: 规模化运动跟踪展现出良好的特性，为人形控制建立了实用的基础，证明了在人形控制领域进行规模扩展的价值和可行性。

Abstract: Despite the rise of billion-parameter foundation models trained across thousands of GPUs, similar scaling gains have not been shown for humanoid control. Current neural controllers for humanoids remain modest in size, target a limited behavior set, and are trained on a handful of GPUs over several days. We show that scaling up model capacity, data, and compute yields a generalist humanoid controller capable of creating natural and robust whole-body movements. Specifically, we posit motion tracking as a natural and scalable task for humanoid control, leverageing dense supervision from diverse motion-capture data to acquire human motion priors without manual reward engineering. We build a foundation model for motion tracking by scaling along three axes: network size (from 1.2M to 42M parameters), dataset volume (over 100M frames, 700 hours of high-quality motion data), and compute (9k GPU hours). Beyond demonstrating the benefits of scale, we show the practical utility of our model through two mechanisms: (1) a real-time universal kinematic planner that bridges motion tracking to downstream task execution, enabling natural and interactive control, and (2) a unified token space that supports various motion input interfaces, such as VR teleoperation devices, human videos, and vision-language-action (VLA) models, all using the same policy. Scaling motion tracking exhibits favorable properties: performance improves steadily with increased compute and data diversity, and learned representations generalize to unseen motions, establishing motion tracking at scale as a practical foundation for humanoid control.

</details>


### [13] [Occlusion-Aware Ground Target Search by a UAV in an Urban Environment](https://arxiv.org/abs/2511.07822)
*Collin Hague,Artur Wolek*

Main category: cs.RO

TL;DR: 提出了一种基于概率可见性体积的无人机搜索策略，用于在城市道路网络中搜索移动的兴趣点，通过迭代加深A*算法规划路径，在复杂环境中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在城市环境中搜索移动兴趣点的问题，由于城市环境可能遮挡传感器视线，需要开发有效的搜索策略来克服这些限制。

Method: 使用概率可见性体积表示传感约束，结合迭代加深A*算法进行路径规划，通过最大池化创建可变时间步规划器，平衡长期和短期规划。

Result: 通过蒙特卡洛模拟与现有方法比较，在复杂环境中，当无人机传感器误报概率较高时，所提方法优于基线方法。

Conclusion: 提出的基于概率可见性体积的路径规划方法在城市搜索任务中表现良好，特别是在传感器性能受限的复杂环境中具有优势。

Abstract: This paper considers the problem of searching for a point of interest (POI) moving along an urban road network with an uncrewed aerial vehicle (UAV). The UAV is modeled as a variable-speed Dubins vehicle with a line-of-sight sensor in an urban environment that may occlude the sensor's view of the POI. A search strategy is proposed that exploits a probabilistic visibility volume (VV) to plan its future motion with iterative deepening $A^\ast$. The probabilistic VV is a time-varying three-dimensional representation of the sensing constraints for a particular distribution of the POI's state. To find the path most likely to view the POI, the planner uses a heuristic to optimistically estimate the probability of viewing the POI over a time horizon. The probabilistic VV is max-pooled to create a variable-timestep planner that reduces the search space and balances long-term and short-term planning. The proposed path planning method is compared to prior work with a Monte-Carlo simulation and is shown to outperform the baseline methods in cluttered environments when the UAV's sensor has a higher false alarm probability.

</details>


### [14] [A Comprehensive Experimental Characterization of Mechanical Layer Jamming Systems](https://arxiv.org/abs/2511.07882)
*Jessica Gumowski,Krishna Manaswi Digumarti,David Howard*

Main category: cs.RO

TL;DR: 本文研究了机械层卡阻现象，通过双层多材料结构实现刚度调节，重点分析了齿状突起几何参数对弯曲和扭转刚度的影响，实现了5倍弯曲刚度和3.2倍扭转刚度的峰值变化。


<details>
  <summary>Details</summary>
Motivation: 受自然界生物（如头足类和厚皮动物）利用刚度调节实现灵巧控制的启发，探索层卡阻机制在软体机器人中的应用，为机械层卡阻系统的原理化设计提供指导。

Method: 采用双层多材料结构，设计齿状突起，通过弯曲和扭转载荷测试，分析齿几何参数对卡阻结构性能的影响，并测量分离两层卡阻结构所需的力。

Result: 实现了峰值刚度变化：弯曲刚度增加5倍，扭转刚度增加3.2倍；测量了分离卡阻层所需的力，这是以往研究中常被忽略的参数。

Conclusion: 该研究为机械层卡阻系统的原理化设计提供了指导，帮助研究人员根据具体应用领域选择合适的结构设计参数。

Abstract: Organisms in nature, such as Cephalopods and Pachyderms, exploit stiffness modulation to achieve amazing dexterity in the control of their appendages. In this paper, we explore the phenomenon of layer jamming, which is a popular stiffness modulation mechanism that provides an equivalent capability for soft robots. More specifically, we focus on mechanical layer jamming, which we realise through two-layer multi material structure with tooth-like protrusions. We identify key design parameters for mechanical layer jamming systems, including the ability to modulate stiffness, and perform a variety of comprehensive tests placing the specimens under bending and torsional loads to understand the influence of our selected design parameters (mainly tooth geometry) on the performance of the jammed structures. We note the ability of these structures to produce a peak change in stiffness of 5 times in bending and 3.2 times in torsion. We also measure the force required to separate the two jammed layers, an often ignored parameter in the study of jamming-induced stiffness change. This study aims to shed light on the principled design of mechanical layer jammed systems and guide researchers in the selection of appropriate designs for their specific application domains.

</details>


### [15] [EquiMus: Energy-Equivalent Dynamic Modeling and Simulation of Musculoskeletal Robots Driven by Linear Elastic Actuators](https://arxiv.org/abs/2511.07887)
*Yinglei Zhu,Xuguang Dong,Qiyao Wang,Qi Shao,Fugui Xie,Xinjun Liu,Huichan Zhao*

Main category: cs.RO

TL;DR: 提出了EquiMus框架，用于肌肉骨骼刚柔混合机器人的动态建模和仿真，解决了传统方法难以处理连续分布质量、运动学闭环和多样化运动模式的挑战。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有复杂本构行为和实际工作条件，动态建模和控制面临挑战。生物启发的肌肉骨骼机器人结合了刚性骨架和软体致动器，兼具高负载能力和固有灵活性，但精确有效的建模和仿真仍是重大难题。

Method: 提出EquiMus能量等效动态建模框架和基于MuJoCo的仿真方法，针对具有线性弹性致动器的肌肉骨骼刚柔混合机器人。

Result: 通过仿真实例和仿生机器人腿的真实实验验证了所提方法的等效性和有效性。

Conclusion: EquiMus框架在控制器设计和基于学习的控制策略等下游任务中展示了其应用价值。

Abstract: Dynamic modeling and control are critical for unleashing soft robots' potential, yet remain challenging due to their complex constitutive behaviors and real-world operating conditions. Bio-inspired musculoskeletal robots, which integrate rigid skeletons with soft actuators, combine high load-bearing capacity with inherent flexibility. Although actuation dynamics have been studied through experimental methods and surrogate models, accurate and effective modeling and simulation remain a significant challenge, especially for large-scale hybrid rigid--soft robots with continuously distributed mass, kinematic loops, and diverse motion modes. To address these challenges, we propose EquiMus, an energy-equivalent dynamic modeling framework and MuJoCo-based simulation for musculoskeletal rigid--soft hybrid robots with linear elastic actuators. The equivalence and effectiveness of the proposed approach are validated and examined through both simulations and real-world experiments on a bionic robotic leg. EquiMus further demonstrates its utility for downstream tasks, including controller design and learning-based control strategies.

</details>


### [16] [Dual-MPC Footstep Planning for Robust Quadruped Locomotion](https://arxiv.org/abs/2511.07921)
*Byeong-Il Ham,Hyun-Bin Kim,Jeonguk Kang,Keun Ha Choi,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出基于模型预测控制的脚步规划策略，通过优化脚步位置来稳健调节身体方向，对抗不期望的身体旋转。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的运动方法通常采用启发式方法或基于线性倒立摆模型的规划，这些方法在脚步规划中考虑线性速度但排除角速度，导致角动量只能通过地面反作用力处理。

Method: 基于MPC的脚步规划考虑角速度，将角动量控制问题重新构建为协调地面反作用力和脚步位置的双输入方法，而不是单独优化地面反作用力。脚步规划器和地面反作用力MPC形成相互反馈循环，各自使用对方的解来迭代更新脚步和地面反作用力。

Result: 使用最优解减少了身体振荡，实现了更长的站立和摆动阶段。在四足机器人上的验证表明，在各种地形上实现了稳健运动，振荡减少，站立和摆动阶段延长。

Conclusion: 该方法通过协调脚步位置和地面反作用力的双输入控制，显著改善了角动量控制性能，实现了更稳定和高效的四足机器人运动。

Abstract: In this paper, we propose a footstep planning strategy based on model predictive control (MPC) that enables robust regulation of body orientation against undesired body rotations by optimizing footstep placement. Model-based locomotion approaches typically adopt heuristic methods or planning based on the linear inverted pendulum model. These methods account for linear velocity in footstep planning, while excluding angular velocity, which leads to angular momentum being handled exclusively via ground reaction force (GRF). Footstep planning based on MPC that takes angular velocity into account recasts the angular momentum control problem as a dual-input approach that coordinates GRFs and footstep placement, instead of optimizing GRFs alone, thereby improving tracking performance. A mutual-feedback loop couples the footstep planner and the GRF MPC, with each using the other's solution to iteratively update footsteps and GRFs. The use of optimal solutions reduces body oscillation and enables extended stance and swing phases. The method is validated on a quadruped robot, demonstrating robust locomotion with reduced oscillations, longer stance and swing phases across various terrains.

</details>


### [17] [Local Path Planning with Dynamic Obstacle Avoidance in Unstructured Environments](https://arxiv.org/abs/2511.07927)
*Okan Arif Guvenkaya,Selim Ahmet Iz,Mustafa Unel*

Main category: cs.RO

TL;DR: 提出了一种结合切线路径规划和外推方法的局部路径规划算法，用于无人地面车辆在动态障碍物环境中的避障导航


<details>
  <summary>Details</summary>
Motivation: 无人地面车辆在密集动态障碍物环境中需要有效的局部路径规划来避免碰撞，现有方法在复杂动态环境中的表现有待提升

Method: 结合切线路径规划和外推方法，基于已知的全局路径和航点，在动态障碍物遵循多项式轨迹的情况下进行局部避障决策

Result: 仿真结果显示该算法能够逐步生成无碰撞路径，使机器人能够在初始位置和目标位置之间安全导航

Conclusion: 所提出的局部路径规划策略在动态障碍物环境中表现出良好的有效性，能够确保无人地面车辆的安全导航

Abstract: Obstacle avoidance and path planning are essential for guiding unmanned ground vehicles (UGVs) through environments that are densely populated with dynamic obstacles. This paper develops a novel approach that combines tangentbased path planning and extrapolation methods to create a new decision-making algorithm for local path planning. In the assumed scenario, a UGV has a prior knowledge of its initial and target points within the dynamic environment. A global path has already been computed, and the robot is provided with waypoints along this path. As the UGV travels between these waypoints, the algorithm aims to avoid collisions with dynamic obstacles. These obstacles follow polynomial trajectories, with their initial positions randomized in the local map and velocities randomized between O and the allowable physical velocity limit of the robot, along with some random accelerations. The developed algorithm is tested in several scenarios where many dynamic obstacles move randomly in the environment. Simulation results show the effectiveness of the proposed local path planning strategy by gradually generating a collision free path which allows the robot to navigate safely between initial and the target locations.

</details>


### [18] [USV Obstacles Detection and Tracking in Marine Environments](https://arxiv.org/abs/2511.07950)
*Yara AlaaEldin,Enrico Simetti,Francesca Odone*

Main category: cs.RO

TL;DR: 该论文评估并改进了USV在海洋环境中的障碍物检测与跟踪系统，通过传感器融合和纯LiDAR两种方法进行实验分析，最终提出了一种结合两者优势的混合方法。


<details>
  <summary>Details</summary>
Motivation: 为无人水面艇(USV)在海洋环境中开发鲁棒有效的障碍物检测与跟踪系统具有挑战性，需要在现有研究基础上进一步评估和改进系统性能。

Method: 首先评估现有系统在最新海洋数据集上的性能，然后在ROS平台上集成系统模块，使用MIT海洋数据集中的同步LiDAR和相机数据进行实时测试，比较传感器融合与纯LiDAR两种方法。

Result: 通过实验分析获得了两种方法的结果，传感器融合方法结合了相机和LiDAR的优势，纯LiDAR方法则基于点云数据进行检测跟踪。

Conclusion: 提出了一种混合方法，结合了传感器融合和纯LiDAR两种方法的优势，为USV构建了更全面的周围环境障碍物地图。

Abstract: Developing a robust and effective obstacle detection and tracking system for Unmanned Surface Vehicle (USV) at marine environments is a challenging task. Research efforts have been made in this area during the past years by GRAAL lab at the university of Genova that resulted in a methodology for detecting and tracking obstacles on the image plane and, then, locating them in the 3D LiDAR point cloud. In this work, we continue on the developed system by, firstly, evaluating its performance on recently published marine datasets. Then, we integrate the different blocks of the system on ROS platform where we could test it in real-time on synchronized LiDAR and camera data collected in various marine conditions available in the MIT marine datasets. We present a thorough experimental analysis of the results obtained using two approaches; one that uses sensor fusion between the camera and LiDAR to detect and track the obstacles and the other uses only the LiDAR point cloud for the detection and tracking. In the end, we propose a hybrid approach that merges the advantages of both approaches to build an informative obstacles map of the surrounding environment to the USV.

</details>


### [19] [Effective Game-Theoretic Motion Planning via Nested Search](https://arxiv.org/abs/2511.08001)
*Avishav Engle,Andrey Zhitnikov,Oren Salzman,Omer Ben-Porat,Kiril Solovey*

Main category: cs.RO

TL;DR: 提出Game-Theoretic Nested Search (GTNS)方法，用于在一般动力系统中计算纳什均衡，解决了现有方法在动态系统简化和可扩展性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有基于博弈论的方法在真实世界部署中存在局限性：优化方法需要简化机器人动力学且容易陷入局部最优，基于收益矩阵的方法因枚举所有可能轨迹而可扩展性差。

Method: GTNS通过嵌套搜索高效搜索所有智能体的动作空间，同时通过在内层搜索低维空间来丢弃违反纳什均衡约束的轨迹，支持用户指定全局目标来选择均衡解。

Result: 在自动驾驶和赛车场景中验证，在普通硬件上仅需数秒即可获得解决方案。

Conclusion: GTNS是一种新颖、可扩展且可证明正确的方法，能够捕捉丰富的现实交互场景，为真实世界部署提供有效的博弈论推理。

Abstract: To facilitate effective, safe deployment in the real world, individual robots must reason about interactions with other agents, which often occur without explicit communication. Recent work has identified game theory, particularly the concept of Nash Equilibrium (NE), as a key enabler for behavior-aware decision-making. Yet, existing work falls short of fully unleashing the power of game-theoretic reasoning. Specifically, popular optimization-based methods require simplified robot dynamics and tend to get trapped in local minima due to convexification. Other works that rely on payoff matrices suffer from poor scalability due to the explicit enumeration of all possible trajectories. To bridge this gap, we introduce Game-Theoretic Nested Search (GTNS), a novel, scalable, and provably correct approach for computing NEs in general dynamical systems. GTNS efficiently searches the action space of all agents involved, while discarding trajectories that violate the NE constraint (no unilateral deviation) through an inner search over a lower-dimensional space. Our algorithm enables explicit selection among equilibria by utilizing a user-specified global objective, thereby capturing a rich set of realistic interactions. We demonstrate the approach on a variety of autonomous driving and racing scenarios where we achieve solutions in mere seconds on commodity hardware.

</details>


### [20] [A Two-Layer Electrostatic Film Actuator with High Actuation Stress and Integrated Brake](https://arxiv.org/abs/2511.08005)
*Huacen Wang,Hongqiang Wang*

Main category: cs.RO

TL;DR: 提出了一种双层静电薄膜执行器，通过交替分布在上下层的电极设计，在相同制造约束下实现更小的有效电极间距，使驱动力提升90.5%，并集成了制动功能。


<details>
  <summary>Details</summary>
Motivation: 传统电机驱动的机器人系统存在质量大、控制算法复杂、需要额外制动机制等问题，限制了其在轻量化紧凑机器人平台的应用。静电薄膜执行器虽然具有轻薄、柔性、轻量和高开环定位精度等优势，但在空气中的驱动力仍需提升。

Method: 设计双层静电薄膜执行器，在顶层和底层交替分布电极，实现更小的有效电极间距。同时集成了静电吸附制动机制，可在制动模式下保持负载。

Result: 执行器驱动力达到约241 N/m²，相比之前的三相执行器提升了90.5%。通过多个演示验证了其在驱动和制动模式下的优越性能，包括与传统单层执行器的拔河测试、负载操作、单自由度机械臂和双模式夹爪。

Conclusion: 该双层静电薄膜执行器在提升驱动性能的同时集成了制动功能，为轻量化紧凑机器人平台提供了有效的解决方案，展示了在驱动和制动模式下的优异能力。

Abstract: Robotic systems driven by conventional motors often suffer from challenges such as large mass, complex control algorithms, and the need for additional braking mechanisms, which limit their applications in lightweight and compact robotic platforms. Electrostatic film actuators offer several advantages, including thinness, flexibility, lightweight construction, and high open-loop positioning accuracy. However, the actuation stress exhibited by conventional actuators in air still needs improvement, particularly for the widely used three-phase electrode design. To enhance the output performance of actuators, this paper presents a two-layer electrostatic film actuator with an integrated brake. By alternately distributing electrodes on both the top and bottom layers, a smaller effective electrode pitch is achieved under the same fabrication constraints, resulting in an actuation stress of approximately 241~N/m$^2$, representing a 90.5\% improvement over previous three-phase actuators operating in air. Furthermore, its integrated electrostatic adhesion mechanism enables load retention under braking mode. Several demonstrations, including a tug-of-war between a conventional single-layer actuator and the proposed two-layer actuator, a payload operation, a one-degree-of-freedom robotic arm, and a dual-mode gripper, were conducted to validate the actuator's advantageous capabilities in both actuation and braking modes.

</details>


### [21] [AVOID-JACK: Avoidance of Jackknifing for Swarms of Long Heavy Articulated Vehicles](https://arxiv.org/abs/2511.08016)
*Adrian Schönnagel,Michael Dubé,Christoph Steup,Felix Keppler,Sanaz Mostaghim*

Main category: cs.RO

TL;DR: 提出基于去中心化群体智能的方法，避免重型铰接车辆的折叠和相互碰撞，适用于具有复杂运动学的长型机器人。


<details>
  <summary>Details</summary>
Motivation: 现有文献未解决长型铰接车辆在物流自动化、远程采矿、机场行李运输和农业作业等实际应用中的折叠和碰撞问题。

Method: 采用纯反应式的去中心化群体智能策略，专门针对长型铰接车辆自动化设计，优先避免折叠并建立相互碰撞避免基础。

Result: 单辆HAV实验中99.8%成功避免折叠，86.7%和83.4%分别到达第一和第二目标；两辆HAV交互时分别为98.9%、79.4%和65.1%，99.7%未发生相互碰撞。

Conclusion: 该方法有效解决了长型铰接车辆的折叠和碰撞问题，为实际应用提供了可行解决方案。

Abstract: This paper presents a novel approach to avoiding jackknifing and mutual collisions in Heavy Articulated Vehicles (HAVs) by leveraging decentralized swarm intelligence. In contrast to typical swarm robotics research, our robots are elongated and exhibit complex kinematics, introducing unique challenges. Despite its relevance to real-world applications such as logistics automation, remote mining, airport baggage transport, and agricultural operations, this problem has not been addressed in the existing literature.
  To tackle this new class of swarm robotics problems, we propose a purely reaction-based, decentralized swarm intelligence strategy tailored to automate elongated, articulated vehicles. The method presented in this paper prioritizes jackknifing avoidance and establishes a foundation for mutual collision avoidance. We validate our approach through extensive simulation experiments and provide a comprehensive analysis of its performance. For the experiments with a single HAV, we observe that for 99.8% jackknifing was successfully avoided and that 86.7% and 83.4% reach their first and second goals, respectively. With two HAVs interacting, we observe 98.9%, 79.4%, and 65.1%, respectively, while 99.7% of the HAVs do not experience mutual collisions.

</details>


### [22] [Model Predictive Control via Probabilistic Inference: A Tutorial](https://arxiv.org/abs/2511.08019)
*Kohei Honda*

Main category: cs.RO

TL;DR: 本文是关于基于概率推理的模型预测控制(MPC)的教程，特别是MPPI控制方法，它将最优控制重新解释为概率推理问题，使用采样技术而非梯度优化来处理非线性系统。


<details>
  <summary>Details</summary>
Motivation: 传统数值优化方法在处理机器人中常见的非线性或不可微分系统时往往变得难以处理，因此需要能够处理任意成本函数和动态的替代方法。

Method: 通过将最优控制重新表述为概率推理问题，使用采样技术估计最优控制分布，特别是推导了MPPI算法作为实践示例。

Result: 提供了基于概率推理的MPC的统一理论框架和代表性方法概述，能够处理传统方法难以处理的复杂系统。

Conclusion: 本文为研究人员和实践者提供了理解和实现这些方法的系统指南，适用于机器人及其他领域。

Abstract: Model Predictive Control (MPC) is a fundamental framework for optimizing robot behavior over a finite future horizon. While conventional numerical optimization methods can efficiently handle simple dynamics and cost structures, they often become intractable for the nonlinear or non-differentiable systems commonly encountered in robotics. This article provides a tutorial on probabilistic inference-based MPC, presenting a unified theoretical foundation and a comprehensive overview of representative methods. Probabilistic inference-based MPC approaches, such as Model Predictive Path Integral (MPPI) control, have gained significant attention by reinterpreting optimal control as a problem of probabilistic inference. Rather than relying on gradient-based numerical optimization, these methods estimate optimal control distributions through sampling-based techniques, accommodating arbitrary cost functions and dynamics. We first derive the optimal control distribution from the standard optimal control problem, elucidating its probabilistic interpretation and key characteristics. The widely used MPPI algorithm is then derived as a practical example, followed by discussions on prior and variational distribution design, tuning principles, and theoretical aspects. This article aims to serve as a systematic guide for researchers and practitioners seeking to understand, implement, and extend these methods in robotics and beyond.

</details>


### [23] [PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision](https://arxiv.org/abs/2511.08098)
*Sabrina Patania,Luca Annese,Anita Pellegrini,Silvia Serino,Anna Lambiase,Luca Pallonetto,Silvia Rossi,Simone Colombani,Tom Foulsham,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.RO

TL;DR: 本研究评估了使用ReAct框架显式整合多视角是否能增强LLM理解其他智能体需求的能力，通过扩展Director任务并引入主动视觉探索，发现显式视角线索结合主动探索策略能显著提高模型的解释准确性和协作效果。


<details>
  <summary>Details</summary>
Motivation: 当前训练范式往往忽视交互情境，导致模型在推理个体视角主观性或处理多观察者环境时面临挑战，需要增强多智能体交互中的视角获取能力。

Method: 扩展经典Director任务，引入主动视觉探索，包含七个视角获取复杂度递增的场景，在不同状态表示和提示策略下测试智能体基于视觉访问和交互解决指称歧义的能力。

Result: 显式视角线索与主动探索策略相结合能显著提高模型的解释准确性和协作有效性。

Conclusion: 将主动感知与视角获取机制整合具有推进LLM在机器人和多智能体系统中应用的潜力，为未来自适应和情境感知AI系统研究奠定基础。

Abstract: Recent advances in Large Language Models (LLMs) and multimodal foundation models have significantly broadened their application in robotics and collaborative systems. However, effective multi-agent interaction necessitates robust perspective-taking capabilities, enabling models to interpret both physical and epistemic viewpoints. Current training paradigms often neglect these interactive contexts, resulting in challenges when models must reason about the subjectivity of individual perspectives or navigate environments with multiple observers. This study evaluates whether explicitly incorporating diverse points of view using the ReAct framework, an approach that integrates reasoning and acting, can enhance an LLM's ability to understand and ground the demands of other agents. We extend the classic Director task by introducing active visual exploration across a suite of seven scenarios of increasing perspective-taking complexity. These scenarios are designed to challenge the agent's capacity to resolve referential ambiguity based on visual access and interaction, under varying state representations and prompting strategies, including ReAct-style reasoning. Our results demonstrate that explicit perspective cues, combined with active exploration strategies, significantly improve the model's interpretative accuracy and collaborative effectiveness. These findings highlight the potential of integrating active perception with perspective-taking mechanisms in advancing LLMs' application in robotics and multi-agent systems, setting a foundation for future research into adaptive and context-aware AI systems.

</details>


### [24] [Prioritizing Perception-Guided Self-Supervision: A New Paradigm for Causal Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.08214)
*Yi Huang,Zhan Qu,Lihui Jiang,Bingbing Liu,Hongbo Zhang*

Main category: cs.RO

TL;DR: 提出感知引导自监督(PGS)训练范式，利用感知输出作为主要监督信号，通过正负自监督对齐决策模块与感知结果，缓解专家轨迹噪声导致的因果混淆问题，在闭环Bench2Drive基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统在开环评估中表现良好，但在闭环场景中因因果混淆问题性能显著下降。这种混淆源于模仿学习过度依赖包含不可归因噪声的专家轨迹，干扰了环境上下文与驾驶动作间因果关系的建模。

Method: PGS框架利用感知输出(如车道中心线和周围智能体预测运动)作为主要监督信号，通过正负自监督对齐决策模块的输入输出与感知结果，专门设计用于缓解专家轨迹固有噪声引起的因果混淆。

Result: 在挑战性闭环Bench2Drive基准上，该方法获得78.08的驾驶分数和48.64%的平均成功率，显著优于现有最先进方法，包括使用更复杂网络架构和推理流程的方法。

Conclusion: PGS框架在解决因果混淆和增强自动驾驶真实世界泛化能力方面展现出有效性和鲁棒性，为未来研究指明了有前景的方向。

Abstract: End-to-end autonomous driving systems, predominantly trained through imitation learning, have demonstrated considerable effectiveness in leveraging large-scale expert driving data. Despite their success in open-loop evaluations, these systems often exhibit significant performance degradation in closed-loop scenarios due to causal confusion. This confusion is fundamentally exacerbated by the overreliance of the imitation learning paradigm on expert trajectories, which often contain unattributable noise and interfere with the modeling of causal relationships between environmental contexts and appropriate driving actions.
  To address this fundamental limitation, we propose Perception-Guided Self-Supervision (PGS) - a simple yet effective training paradigm that leverages perception outputs as the primary supervisory signals, explicitly modeling causal relationships in decision-making. The proposed framework aligns both the inputs and outputs of the decision-making module with perception results, such as lane centerlines and the predicted motions of surrounding agents, by introducing positive and negative self-supervision for the ego trajectory. This alignment is specifically designed to mitigate causal confusion arising from the inherent noise in expert trajectories.
  Equipped with perception-driven supervision, our method, built on a standard end-to-end architecture, achieves a Driving Score of 78.08 and a mean success rate of 48.64% on the challenging closed-loop Bench2Drive benchmark, significantly outperforming existing state-of-the-art methods, including those employing more complex network architectures and inference pipelines. These results underscore the effectiveness and robustness of the proposed PGS framework and point to a promising direction for addressing causal confusion and enhancing real-world generalization in autonomous driving.

</details>


### [25] [Real-Time Performance Analysis of Multi-Fidelity Residual Physics-Informed Neural Process-Based State Estimation for Robotic Systems](https://arxiv.org/abs/2511.08231)
*Devin Hunter,Chinwendu Enyioha*

Main category: cs.RO

TL;DR: 提出了一种基于多保真度残差物理信息神经过程(MFR-PINP)的实时状态估计方法，用于机器人系统状态估计，通过结合简单低保真度模型和复杂高保真度真实动态之间的残差学习，解决模型失配问题，并采用分裂保形预测框架提供不确定性保证。


<details>
  <summary>Details</summary>
Motivation: 随着数据驱动模型在状态估计领域的广泛应用，需要为模型预测提供可靠的误差边界，特别是在安全关键应用中。本文旨在解决选择准确运动学模型时的模型失配问题。

Method: 使用多保真度残差物理信息神经过程(MFR-PINP)，学习低保真度预测与高保真度真实动态之间的残差，并结合分裂保形预测框架建模训练和推理过程中的不确定性。

Result: 实验结果表明，与卡尔曼滤波器的先进变体(无迹卡尔曼滤波器和深度卡尔曼滤波器)相比，MFR-PINP模型在估计场景中表现出有希望的结果。

Conclusion: MFR-PINP模型可作为实时估计任务中的可行选择，特别是在需要处理模型不确定性和提供可靠误差边界的应用中。

Abstract: Various neural network architectures are used in many of the state-of-the-art approaches for real-time nonlinear state estimation. With the ever-increasing incorporation of these data-driven models into the estimation domain, model predictions with reliable margins of error are a requirement -- especially for safety-critical applications. This paper discusses the application of a novel real-time, data-driven estimation approach based on the multi-fidelity residual physics-informed neural process (MFR-PINP) toward the real-time state estimation of a robotic system. Specifically, we address the model-mismatch issue of selecting an accurate kinematic model by tasking the MFR-PINP to also learn the residuals between simple, low-fidelity predictions and complex, high-fidelity ground-truth dynamics. To account for model uncertainty present in a physical implementation, robust uncertainty guarantees from the split conformal (SC) prediction framework are modeled in the training and inference paradigms. We provide implementation details of our MFR-PINP-based estimator for a hybrid online learning setting to validate our model's usage in real-time applications. Experimental results of our approach's performance in comparison to the state-of-the-art variants of the Kalman filter (i.e. unscented Kalman filter and deep Kalman filter) in estimation scenarios showed promising results for the MFR-PINP model as a viable option in real-time estimation tasks.

</details>


### [26] [X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention](https://arxiv.org/abs/2511.08277)
*Dehan Shen,Changhao Chen*

Main category: cs.RO

TL;DR: X-IONet是一个跨平台惯性里程计框架，使用单一IMU实现四足机器人和行人的精确导航，通过专家选择模块和双阶段注意力架构显著降低了轨迹误差。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的惯性里程计方法在行人导航中表现良好，但在四足机器人上性能严重下降，因为四足机器人的运动模式与人完全不同且高度动态。

Method: X-IONet包含基于规则的专家选择模块来分类运动平台，将IMU序列路由到平台特定的专家网络。位移预测网络采用双阶段注意力架构，联合建模长程时间依赖性和轴间相关性，输出位移和不确定性，通过扩展卡尔曼滤波器进行状态估计。

Result: 在公开行人数据集和自收集四足机器人数据集上的实验表明，X-IONet在行人数据上绝对轨迹误差降低14.3%，相对轨迹误差降低11.4%；在四足机器人数据上分别降低52.8%和41.3%。

Conclusion: X-IONet在人类和腿式机器人平台上都能实现准确鲁棒的惯性导航，证明了其跨平台有效性。

Abstract: Learning-based inertial odometry has achieved remarkable progress in pedestrian navigation. However, extending these methods to quadruped robots remains challenging due to their distinct and highly dynamic motion patterns. Models that perform well on pedestrian data often experience severe degradation when deployed on legged platforms. To tackle this challenge, we introduce X-IONet, a cross-platform inertial odometry framework that operates solely using a single Inertial Measurement Unit (IMU). X-IONet incorporates a rule-based expert selection module to classify motion platforms and route IMU sequences to platform-specific expert networks. The displacement prediction network features a dual-stage attention architecture that jointly models long-range temporal dependencies and inter-axis correlations, enabling accurate motion representation. It outputs both displacement and associated uncertainty, which are further fused through an Extended Kalman Filter (EKF) for robust state estimation. Extensive experiments on public pedestrian datasets and a self-collected quadruped robot dataset demonstrate that X-IONet achieves state-of-the-art performance, reducing Absolute Trajectory Error (ATE) by 14.3% and Relative Trajectory Error (RTE) by 11.4% on pedestrian data, and by 52.8% and 41.3% on quadruped robot data. These results highlight the effectiveness of X-IONet in advancing accurate and robust inertial navigation across both human and legged robot platforms.

</details>


### [27] [Learning Omnidirectional Locomotion for a Salamander-Like Quadruped Robot](https://arxiv.org/abs/2511.08299)
*Zhiang Liu,Yang Liu,Yongchun Fang,Xian Guo*

Main category: cs.RO

TL;DR: 提出了一种学习框架，使蝾螈四足机器人无需参考运动即可获得多样化的全向步态，通过相位变量控制和形态对称性增强实现灵活运动。


<details>
  <summary>Details</summary>
Motivation: 现有控制器无法充分利用机器人的形态特征，依赖预定义的步态模式或关节轨迹，限制了在真实场景中的灵活性和多样性。

Method: 使用可前后演化的相位变量控制身体各部分，通过相位覆盖奖励促进腿部相位空间探索，并利用形态对称性进行数据增强。

Result: 机器人成功获得了22种全向步态，表现出动态和对称运动，验证了学习框架的有效性。

Conclusion: 该学习框架能够使机器人自主学习多样化的全向步态，无需参考运动，提高了运动灵活性和适应性。

Abstract: Salamander-like quadruped robots are designed inspired by the skeletal structure of their biological counterparts. However, existing controllers cannot fully exploit these morphological features and largely rely on predefined gait patterns or joint trajectories, which prevents the generation of diverse and flexible locomotion and limits their applicability in real-world scenarios. In this paper, we propose a learning framework that enables the robot to acquire a diverse repertoire of omnidirectional gaits without reference motions. Each body part is controlled by a phase variable capable of forward and backward evolution, with a phase coverage reward to promote the exploration of the leg phase space. Additionally, morphological symmetry of the robot is incorporated via data augmentation, improving sample efficiency and enforcing both motion-level and task-level symmetry in learned behaviors. Extensive experiments show that the robot successfully acquires 22 omnidirectional gaits exhibiting both dynamic and symmetric movements, demonstrating the effectiveness of the proposed learning framework.

</details>


### [28] [A CODECO Case Study and Initial Validation for Edge Orchestration of Autonomous Mobile Robots](https://arxiv.org/abs/2511.08354)
*H. Zhu,T. Samizadeh,R. C. Sofia*

Main category: cs.RO

TL;DR: CODECO与标准Kubernetes在移动机器人环境中的对比研究，显示CODECO在CPU消耗和通信稳定性方面表现更好，但内存开销和pod生命周期延迟略有增加


<details>
  <summary>Details</summary>
Motivation: Kubernetes在移动机器人环境中存在网络不稳定、资源异构和计算能力有限的问题，需要更适合的编排方案

Method: 在智能制造AMR案例研究中，使用受控KinD环境对比CODECO编排与标准Kubernetes，测量pod部署删除时间、CPU内存使用量和pod间数据速率

Result: CODECO提供更低的CPU消耗和更稳定的通信模式，但存在10-15%的内存开销，且由于安全覆盖层初始化导致pod生命周期延迟略有增加

Conclusion: CODECO在资源受限的移动机器人环境中比标准Kubernetes更具优势，特别是在CPU效率和通信稳定性方面

Abstract: Autonomous Mobile Robots (AMRs) increasingly adopt containerized micro-services across the Edge-Cloud continuum. While Kubernetes is the de-facto orchestrator for such systems, its assumptions of stable networks, homogeneous resources, and ample compute capacity do not fully hold in mobile, resource-constrained robotic environments.
  This paper describes a case study on smart-manufacturing AMRs and performs an initial comparison between CODECO orchestration and standard Kubernetes using a controlled KinD environment. Metrics include pod deployment and deletion times, CPU and memory usage, and inter-pod data rates. The observed results indicate that CODECO offers reduced CPU consumption and more stable communication patterns, at the cost of modest memory overhead (10-15%) and slightly increased pod lifecycle latency due to secure overlay initialization.

</details>


### [29] [Human Motion Intent Inferencing in Teleoperation Through a SINDy Paradigm](https://arxiv.org/abs/2511.08377)
*Michael Bowman,Xiaoli Zhang*

Main category: cs.RO

TL;DR: Psychic框架通过跳跃-漂移-扩散随机微分方程建模操作者的微小指示性运动，结合Kramers-Moyal系数和统计异常检测来识别目标转换，实现操作者意图的早期检测和未定义目标的发现。


<details>
  <summary>Details</summary>
Motivation: 当前意图推断方法往往忽略可能指示意图突然变化的细微运动，需要解决如何检测操作者轨迹中的突然跳跃、如何利用这些跳跃推断目标状态，以及如何结合不连续和连续动态来推断操作者运动。

Method: 使用跳跃-漂移-扩散随机微分方程建模不连续和连续动态，通过Kramers-Moyal系数检测跳跃，结合统计异常检测算法提名目标转换，并应用SINDy模型推断操作者运动行为。

Result: 在600个操作者轨迹的回顾性研究中，Psychic能够生成概率可达集，并在离线和在线学习中有效工作，能够早期检测现有目标并发现未定义目标。

Conclusion: Psychic框架成功解决了操作者意图推断中的跳跃检测问题，能够有效处理非结构化场景中的操作者运动行为推断。

Abstract: Intent inferencing in teleoperation has been instrumental in aligning operator goals and coordinating actions with robotic partners. However, current intent inference methods often ignore subtle motion that can be strong indicators for a sudden change in intent. Specifically, we aim to tackle 1) if we can detect sudden jumps in operator trajectories, 2) how we appropriately use these sudden jump motions to infer an operator's goal state, and 3) how to incorporate these discontinuous and continuous dynamics to infer operator motion. Our framework, called Psychic, models these small indicative motions through a jump-drift-diffusion stochastic differential equation to cover discontinuous and continuous dynamics. Kramers-Moyal (KM) coefficients allow us to detect jumps with a trajectory which we pair with a statistical outlier detection algorithm to nominate goal transitions. Through identifying jumps, we can perform early detection of existing goals and discover undefined goals in unstructured scenarios. Our framework then applies a Sparse Identification of Nonlinear Dynamics (SINDy) model using KM coefficients with the goal transitions as a control input to infer an operator's motion behavior in unstructured scenarios. We demonstrate Psychic can produce probabilistic reachability sets and compare our strategy to a negative log-likelihood model fit. We perform a retrospective study on 600 operator trajectories in a hands-free teleoperation task to evaluate the efficacy of our opensource package, Psychic, in both offline and online learning.

</details>


### [30] [Intuitive control of supernumerary robotic limbs through a tactile-encoded neural interface](https://arxiv.org/abs/2511.08454)
*Tianyu Jia,Xingchen Yang,Ciaran McGeady,Yifeng Li,Jinzhi Lin,Kit San Ho,Feiyu Pan,Linhong Ji,Chong Li,Dario Farina*

Main category: cs.RO

TL;DR: 提出了一种基于触觉编码的脑机接口，通过触觉诱发的P300范式实现超限运动意图的解码，能够在自然运动的同时控制额外的机器人手臂。


<details>
  <summary>Details</summary>
Motivation: 解决脑机接口在扩展人类运动能力时，如何在不干扰自然运动的情况下整合多自由度增强命令的关键挑战。

Method: 采用触觉编码的脑机接口，通过新颖的触觉诱发P300范式，利用感觉传入神经进行超限运动意图的解码。在多日实验中评估单任务和双任务条件下的性能。

Result: 实现了四个超限自由度的实时可靠解码，经过三天训练后性能显著提升。在双任务条件下性能与单任务无显著差异，自然运动不受影响。成功应用于双手机器人臂的功能辅助任务。

Conclusion: 建立了一种通过刺激感觉传入神经的运动增强神经接口新范式，能够扩展运动自由度而不损害自然运动。

Abstract: Brain-computer interfaces (BCIs) promise to extend human movement capabilities by enabling direct neural control of supernumerary effectors, yet integrating augmented commands with multiple degrees of freedom without disrupting natural movement remains a key challenge. Here, we propose a tactile-encoded BCI that leverages sensory afferents through a novel tactile-evoked P300 paradigm, allowing intuitive and reliable decoding of supernumerary motor intentions even when superimposed with voluntary actions. The interface was evaluated in a multi-day experiment comprising of a single motor recognition task to validate baseline BCI performance and a dual task paradigm to assess the potential influence between the BCI and natural human movement. The brain interface achieved real-time and reliable decoding of four supernumerary degrees of freedom, with significant performance improvements after only three days of training. Importantly, after training, performance did not differ significantly between the single- and dual-BCI task conditions, and natural movement remained unimpaired during concurrent supernumerary control. Lastly, the interface was deployed in a movement augmentation task, demonstrating its ability to command two supernumerary robotic arms for functional assistance during bimanual tasks. These results establish a new neural interface paradigm for movement augmentation through stimulation of sensory afferents, expanding motor degrees of freedom without impairing natural movement.

</details>


### [31] [A Supervised Autonomous Resection and Retraction Framework for Transurethral Enucleation of the Prostatic Median Lobe](https://arxiv.org/abs/2511.08490)
*Mariana Smith,Tanner Watts,Susheela Sharma Stern,Brendan Burkhart,Hao Li,Alejandro O. Chara,Nithesh Kumar,James Ferguson,Ayberk Acar,Jesse F. d'Almeida,Lauren Branscombe,Lauren Shepard,Ahmed Ghazi,Ipek Oguz,Jie Ying Wu,Robert J. Webster,Axel Krieger,Alan Kuntz*

Main category: cs.RO

TL;DR: 本文提出了一种结合模型规划和学习网络的方法，用于双臂经尿道同心管机器人的半自主组织切除手术，在前列腺模型上实现了97.1%的中叶切除率。


<details>
  <summary>Details</summary>
Motivation: 同心管机器人能够在毫米尺度提供灵巧运动，实现通过自然腔道的微创手术。本文旨在开发一种半自主的组织切除系统，为经尿道机器人手术建立图像引导自主性的基础。

Method: 采用协调的基于模型的切除规划器和基于学习的回缩网络(PushCVAE)。切除规划器直接在分割的CT体积上操作，自动生成三阶段中叶切除工作流程的工具轨迹；回缩网络根据手术阶段生成回缩动作。

Result: 在前列腺模型上执行Level-3(监督)自主性手术，实现了97.1%的目标中叶体积切除。

Conclusion: 该研究为经尿道机器人手术中的图像引导自主性奠定了基础，是迈向完全自动化微创前列腺剜除术的第一步。

Abstract: Concentric tube robots (CTRs) offer dexterous motion at millimeter scales, enabling minimally invasive procedures through natural orifices. This work presents a coordinated model-based resection planner and learning-based retraction network that work together to enable semi-autonomous tissue resection using a dual-arm transurethral concentric tube robot (the Virtuoso). The resection planner operates directly on segmented CT volumes of prostate phantoms, automatically generating tool trajectories for a three-phase median lobe resection workflow: left/median trough resection, right/median trough resection, and median blunt dissection. The retraction network, PushCVAE, trained on surgeon demonstrations, generates retractions according to the procedural phase. The procedure is executed under Level-3 (supervised) autonomy on a prostate phantom composed of hydrogel materials that replicate the mechanical and cutting properties of tissue. As a feasibility study, we demonstrate that our combined autonomous system achieves a 97.1% resection of the targeted volume of the median lobe. Our study establishes a foundation for image-guided autonomy in transurethral robotic surgery and represents a first step toward fully automated minimally-invasive prostate enucleation.

</details>


### [32] [Safe and Optimal Learning from Preferences via Weighted Temporal Logic with Applications in Robotics and Formula 1](https://arxiv.org/abs/2511.08502)
*Ruya Karagulle,Cristian-Ioan Vasile,Necmiye Ozay*

Main category: cs.RO

TL;DR: 提出了一种基于加权信号时序逻辑的安全保证学习方法，用于从偏好、排名或演示中学习，通过结构剪枝和对数变换将问题转化为混合整数线性规划


<details>
  <summary>Details</summary>
Motivation: 自主系统越来越依赖人类反馈来调整行为，但现有方法在安全关键领域无法保证安全性

Method: 使用加权信号时序逻辑，通过结构剪枝和对数变换将多线性约束问题转化为混合整数线性规划

Result: 在机器人导航和真实世界F1数据上的实验表明，该方法能有效捕捉细微偏好并建模复杂任务目标

Conclusion: 该方法提供了安全保证、最优性和效率，适用于从偏好、排名或演示中学习的安全关键应用

Abstract: Autonomous systems increasingly rely on human feedback to align their behavior, expressed as pairwise comparisons, rankings, or demonstrations. While existing methods can adapt behaviors, they often fail to guarantee safety in safety-critical domains. We propose a safety-guaranteed, optimal, and efficient approach to solve the learning problem from preferences, rankings, or demonstrations using Weighted Signal Temporal Logic (WSTL). WSTL learning problems, when implemented naively, lead to multi-linear constraints in the weights to be learned. By introducing structural pruning and log-transform procedures, we reduce the problem size and recast the problem as a Mixed-Integer Linear Program while preserving safety guarantees. Experiments on robotic navigation and real-world Formula 1 data demonstrate that the method effectively captures nuanced preferences and models complex task objectives.

</details>


### [33] [SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment](https://arxiv.org/abs/2511.08583)
*Rong Xue,Jiageng Mao,Mingtong Zhang,Yue Wang*

Main category: cs.RO

TL;DR: SeFA提出了一种选择性流对齐策略，通过利用专家演示选择性校正生成的动作，确保动作与观察保持一致，同时保持多模态性，解决了现有整流流方法中动作偏离观察导致累积误差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有整流流方法在迭代蒸馏后，生成的动作可能偏离当前视觉观察对应的真实动作，导致累积误差和不稳定的任务执行。

Method: 采用选择性流对齐策略，利用专家演示选择性校正生成的动作，恢复与观察的一致性，同时保持多模态性，并引入一致性校正机制。

Result: 在模拟和真实世界操作任务上的广泛实验表明，SeFA策略超越了最先进的基于扩散和流的方法，实现了更高的准确性和鲁棒性，同时将推理延迟降低了98%以上。

Conclusion: SeFA通过统一整流流效率与观察一致的动作生成，为实时视觉运动策略学习提供了可扩展且可靠的解决方案。

Abstract: Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the ground-truth actions corresponding to the current visual observation, leading to accumulated error as the reflow process repeats and unstable task execution. We present Selective Flow Alignment (SeFA), an efficient and accurate visuomotor policy learning framework. SeFA resolves this challenge by a selective flow alignment strategy, which leverages expert demonstrations to selectively correct generated actions and restore consistency with observations, while preserving multimodality. This design introduces a consistency correction mechanism that ensures generated actions remain observation-aligned without sacrificing the efficiency of one-step flow inference. Extensive experiments across both simulated and real-world manipulation tasks show that SeFA Policy surpasses state-of-the-art diffusion-based and flow-based policies, achieving superior accuracy and robustness while reducing inference latency by over 98%. By unifying rectified flow efficiency with observation-consistent action generation, SeFA provides a scalable and dependable solution for real-time visuomotor policy learning. Code is available on https://github.com/RongXueZoe/SeFA.

</details>
