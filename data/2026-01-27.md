<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 111]
- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle](https://arxiv.org/abs/2601.16986)
*Zihan Wang,Cheng Tang,Lei Gong,Cheng Li,Chao Wang,teng wang,Wenqi Lou,Xuehai Zhou*

Main category: cs.CL

TL;DR: Crystal-KV是一个针对CoT推理优化的KV缓存管理框架，通过区分SlipKV和CrystalKV，采用基于注意力的LRFU算法和自适应缓存预算分配，在保持甚至提高答案准确性的同时实现高效的KV缓存压缩。


<details>
  <summary>Details</summary>
Motivation: CoT推理在LLMs中显著提高了复杂任务的准确性，但由于需要存储长思考序列到KV缓存中，导致过高的内存开销。传统KV压缩策略在CoT场景下效果不佳，因为CoT更关注最终答案而非所有token的均匀重要性。

Method: 1. 提出答案优先原则，通过将答案偏好映射到思考阶段注意力图，区分SlipKV（主要维持推理流程但可能引入误导上下文）和CrystalKV（真正贡献于最终答案正确性）。2. 提出基于注意力的LRFU算法，精确识别SlipKV条目的效用何时过期并驱逐它们，保留CrystalKV而不破坏推理流程。3. 引入自适应缓存预算分配算法，基于CrystalKV的动态比例估计每层/每个头的重要性，在推理过程中调整KV缓存预算，放大关键组件以提高预算利用率。

Result: Crystal-KV实现了最先进的KV缓存压缩，显著提高了吞吐量，实现了更快的响应时间，同时在CoT推理中保持甚至提高了答案准确性。

Conclusion: Crystal-KV通过创新的KV缓存管理框架，有效解决了CoT推理中的内存开销问题，在保持准确性的同时显著提升了推理效率。

Abstract: Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.

</details>


### [2] [Evaluating Reward Model Generalization via Pairwise Maximum Discrepancy Competitions](https://arxiv.org/abs/2601.16987)
*Shunyang Luo,Peibei Cao,Zhihui Zhu,Kehua Feng,Zhihua Wang,Keyan Ding*

Main category: cs.CL

TL;DR: PMDC是一种动态评估奖励模型泛化能力的新框架，通过主动选择分歧最大的提示-响应对来构建紧凑测试集，相比传统静态评估能更真实反映模型在开放世界中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型评估主要依赖静态预标注偏好数据集，覆盖范围有限，无法真实评估模型在开放世界设置下的泛化能力，需要更有效的评估方法。

Method: 提出PMDC框架：1）使用大型未标注开放域提示池；2）主动选择两个奖励模型分歧最大的提示-响应对；3）由oracle裁决争议案例；4）通过Bradley-Terry模型聚合结果生成全局排名和配对胜率图。

Result: 对10个代表性奖励模型进行重新评估，发现与传统基准相比排名发生显著变化。定性分析揭示了系统性的泛化失败模式，为改进奖励建模提供了有价值见解。

Conclusion: PMDC提供了一种动态、标注高效的奖励模型评估框架，能更真实地评估模型泛化能力，揭示了传统评估方法的局限性，为奖励建模的改进提供了新方向。

Abstract: Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.

</details>


### [3] [Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction](https://arxiv.org/abs/2601.16999)
*Matthew Singer,Srijan Sengupta,Karl Pazdernik*

Main category: cs.CL

TL;DR: 提出一个基于序列标注的NER模型不确定性感知预测集框架，通过conformal prediction提供统计保证，确保预测集以用户指定置信度包含正确标注


<details>
  <summary>Details</summary>
Motivation: 当前NER模型通常只输出单一预测标签序列，缺乏不确定性度量，导致下游应用容易受到级联错误影响。需要为NER预测提供类似经典统计学中置信区间的可靠性保证。

Method: 基于conformal prediction框架，设计高效的非一致性评分函数，构建支持无条件覆盖和类别条件覆盖的校准预测集。该方法考虑句子长度、语言、实体类型和句子内实体数量等异质性因素。

Result: 在三个基准数据集上的四个NER模型上进行实证实验，证明了所提方法具有广泛的适用性、有效性和高效性。

Conclusion: 该框架为NER模型提供了不确定性感知的预测集，具有统计保证，能够提高下游应用的可靠性，减少级联错误风险。

Abstract: Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.

</details>


### [4] [RAM-SD: Retrieval-Augmented Multi-agent framework for Sarcasm Detection](https://arxiv.org/abs/2601.17002)
*Ziyang Zhou,Ziqi Liu,Yan Wang,Yiming Lin,Yangbin Chen*

Main category: cs.CL

TL;DR: RAM-SD：一个用于讽刺检测的检索增强多智能体框架，通过四阶段流程实现最先进的性能，并提供可解释的推理过程。


<details>
  <summary>Details</summary>
Motivation: 讽刺检测面临重大挑战，因为其依赖于细微的上下文理解、世界知识和多方面的语言线索，这些在不同讽刺表达中差异很大。现有方法对所有输入采用统一的推理策略，难以应对讽刺分析的不同需求，包括建模上下文期望违反、外部知识基础或特定修辞模式识别。

Method: 提出RAM-SD（检索增强多智能体讽刺检测框架），包含四个阶段：1）上下文检索：将查询基于讽刺和非讽刺示例进行基础；2）元规划器：分类讽刺类型并从预定义集合中选择最优推理计划；3）专业智能体集成：执行互补的多视角分析；4）集成器：将这些分析合成为最终的可解释判断，并提供自然语言解释。

Result: 在四个标准基准测试中，RAM-SD实现了77.74%的Macro-F1分数，比强大的GPT-4o+CoC基线高出7.01个百分点，达到了最先进的性能水平。

Conclusion: 该框架不仅设定了新的性能基准，还提供了透明且可解释的推理轨迹，阐明了讽刺理解的认知过程，为讽刺检测领域带来了性能提升和可解释性的双重优势。

Abstract: Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.

</details>


### [5] [From Emotion to Expression: Theoretical Foundations and Resources for Fear Speech](https://arxiv.org/abs/2601.17132)
*Vigneshwaran Shankaran,Gabriella Lapesa,Claudia Wagner*

Main category: cs.CL

TL;DR: 该论文提出将恐惧言论作为独立于仇恨言论的研究对象，通过跨学科视角整合心理学、政治学、传播学和语言学理论，构建恐惧言论分类体系，为相关数据集创建和研究提供理论指导。


<details>
  <summary>Details</summary>
Motivation: 恐惧言论在社交媒体中广泛传播且影响力超过仇恨言论，但由于其"更文明"的表象往往逃避内容审核。目前计算语言学领域对恐惧言论的研究分散且资源不足，缺乏统一的理论框架和分类体系。

Method: 1) 比较心理学、政治学、传播学和语言学中的恐惧理论；2) 回顾现有定义；3) 调查相关研究领域的数据集；4) 提出整合不同恐惧维度的分类法。

Result: 建立了跨学科的恐惧言论理论框架，提出了系统化的恐惧维度分类法，为恐惧言论数据集创建提供了理论基础和实践指导。

Conclusion: 恐惧言论需要作为独立的研究对象进行系统研究，跨学科整合的理论框架和分类体系将推动恐惧言论检测、数据集创建和相关研究的进一步发展。

Abstract: Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears "civiler" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.

</details>


### [6] [Dynamic Role Assignment for Multi-Agent Debate](https://arxiv.org/abs/2601.17152)
*Miao Zhang,Junsik Kim,Siyuan Xiang,Jian Gao,Cheng Cao*

Main category: cs.CL

TL;DR: 提出动态角色分配框架，通过元辩论选择最适合的模型担任不同角色，显著提升多智能体辩论系统的性能


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM/VLM辩论系统虽然使用专门角色解决复杂问题，但没有根据模型的专业能力来分配角色，导致系统效率不高

Method: 提出动态角色分配框架，包含两个阶段：1) 提案阶段：候选模型提供针对角色的论证；2) 同行评审阶段：根据数据和角色特定标准对提案评分，选择最适合每个角色的模型

Result: 在LLM问题解决基准测试中，该方法相比统一分配（所有角色使用相同模型）提升高达74.8%，相比随机分配提升高达29.7%

Conclusion: 这项工作为多智能体系统设计建立了新范式，从静态部署转向动态、能力感知的选择机制

Abstract: Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.

</details>


### [7] [Interpretability of the Intent Detection Problem: A New Approach](https://arxiv.org/abs/2601.17156)
*Eduardo Sanchez-Karhunen,Jose F. Quesada-Moreno,Miguel A. Gutiérrez-Naranjo*

Main category: cs.CL

TL;DR: 该论文应用动力系统理论分析RNN在意图检测任务中的内部机制，发现RNN在平衡数据集上学习理想几何解（状态空间分簇），而在不平衡数据集上该几何解会扭曲退化。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在意图检测任务中占主导地位，但RNN解决该任务的内部机制尚不清楚。研究者希望理解RNN如何从动力系统角度处理意图检测问题。

Method: 应用动力系统理论分析RNN架构，将句子解释为隐藏状态空间中的轨迹。使用平衡的SNIPS数据集和不平衡的ATIS数据集进行对比分析。

Result: 在平衡SNIPS数据集上，网络学习到理想解：状态空间被约束在低维流形上，并划分为对应不同意图的独立簇。在不平衡ATIS数据集上，低频意图对应的簇会退化扭曲。该框架解耦了几何分离与读出对齐。

Conclusion: 研究提供了RNN动态的新见解，给出了数据集属性如何直接塑造网络计算解决方案的几何解释，为现实世界性能差异提供了机制性解释。

Abstract: Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.

</details>


### [8] [Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text](https://arxiv.org/abs/2601.17172)
*Tunazzina Islam*

Main category: cs.CL

TL;DR: LLMs在生成针对不同人口群体的定向信息时，会表现出系统性的人口统计偏见，年轻和男性受众的信息更强调能动性和创新，而女性和老年受众的信息则强调温暖和传统。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs能够大规模生成个性化、有说服力的文本，需要系统分析其在人口统计条件定向信息生成中的偏见和公平性问题。

Method: 使用GPT-4o、Llama-3.3和Mistral-Large 2.1三个模型，在两种生成设置下评估：独立生成（隔离内在人口效应）和上下文丰富生成（包含主题和区域背景）。从词汇内容、语言风格和说服框架三个维度评估生成信息。

Result: 在气候沟通任务中发现一致的年龄和性别不对称：针对男性和年轻人的信息强调能动性、创新和自信，而针对女性和老年人的信息强调温暖、关怀和传统。上下文提示会系统性地放大这些差异，针对年轻或男性受众的信息说服力得分显著更高。

Conclusion: 人口统计刻板印象会在LLM生成的定向沟通中浮现并加剧，需要在社会敏感应用中开发偏见感知的生成流程和透明的审计框架，明确考虑人口统计条件。

Abstract: Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.

</details>


### [9] [Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content](https://arxiv.org/abs/2601.17173)
*Parth Bhalerao,Diola Dsouza,Ruiwen Guan,Oana Ignat*

Main category: cs.CL

TL;DR: MentorQA：首个多语言长视频指导式问答数据集与评估框架，包含近9000个QA对，定义超越事实准确性的指导维度，比较多种问答架构，发现多智能体架构在复杂主题和低资源语言中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统主要评估事实准确性，但教育、职业指导等实际应用需要提供反思和指导的"指导式"回答。现有基准很少捕捉这种区别，特别是在多语言和长文本场景中。

Method: 引入MentorQA数据集，包含180小时视频内容、近9000个QA对，覆盖四种语言。定义指导式评估维度（清晰度、一致性、学习价值）。在受控条件下比较单智能体、双智能体、RAG和多智能体问答架构。

Result: 多智能体流水线始终产生更高质量的指导式回答，在复杂主题和低资源语言中表现尤为突出。分析发现基于LLM的自动评估与人工判断存在显著差异。

Conclusion: 将指导式问答确立为独立研究问题，提供多语言基准用于研究教育AI中的智能体架构和评估设计。发布数据集和评估框架供社区使用。

Abstract: Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.

</details>


### [10] [Systematicity between Forms and Meanings across Languages Supports Efficient Communication](https://arxiv.org/abs/2601.17181)
*Doreen Osmelak,Yang Xu,Michael Hahn,Kate McCurdy*

Main category: cs.CL

TL;DR: 论文提出基于可学习性的复杂度度量，解释动词和代词形式如何平衡简洁性和准确性压力，更好地预测语言系统的存在性。


<details>
  <summary>Details</summary>
Motivation: 现有高效沟通理论未能充分解释词形内部的系统性关系，需要新的模型来捕捉语法意义到形式映射的精细规律。

Method: 提出基于意义到形式映射可学习性的新复杂度度量，分析跨语言类型多样的动词和代词形式，比较简洁性（最小化语法区分）和准确性（恢复意义）的竞争压力。

Result: 新模型能更好地区分实际存在和不存在的语言系统，捕捉到语言形式的细粒度规律性，验证了动词和代词形式确实受简洁性和准确性压力的共同塑造。

Conclusion: 基于可学习性的复杂度度量建立了高效沟通理论与自然语言系统性之间的新联系，为理解语法形式分布提供了更精细的理论框架。

Abstract: Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.

</details>


### [11] [Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding](https://arxiv.org/abs/2601.17197)
*Seyyed Saeid Cheshmi,Hahnemann Ortiz,James Mooney,Dongyeop Kang*

Main category: cs.CL

TL;DR: 提出三步框架提升视觉语言模型对多模态比喻语言的理解能力，通过推理轨迹实现跨风格泛化


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在字面多模态任务上表现良好，但在理解讽刺、幽默、隐喻等比喻语言方面存在挑战，这些语言通过表达与意图之间的微妙不一致来传达情感和意图

Method: 提出三步框架：1) 解释多模态比喻语言；2) 提供透明推理轨迹；3) 跨多种比喻风格泛化。通过实验验证推理轨迹的加入、风格间知识迁移以及联合训练的效果

Result: 1) 加入推理轨迹显著提升多模态比喻理解；2) 一种风格学习的推理能力可迁移到其他风格，特别是讽刺与幽默等相似风格之间；3) 跨风格联合训练得到的通用推理VLM优于更大规模的开源和闭源模型

Conclusion: 轻量级视觉语言模型通过可验证推理能够实现鲁棒的跨风格泛化，同时为多模态任务提供可检查的推理轨迹，代码已开源

Abstract: Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.

</details>


### [12] [Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis](https://arxiv.org/abs/2601.17203)
*Scott Friedman,Sonja Schmer-Galunder,Anthony Chen,Jeffrey Rye*

Main category: cs.CL

TL;DR: 提出一种量化词嵌入中性别偏见的方法，并将其用于衡量教育、政治、经济和健康领域的统计性别差距，通过Twitter数据验证与真实性别差距的相关性。


<details>
  <summary>Details</summary>
Motivation: 当前NLP模型中的种族和性别偏见通常被视为需要修正的问题，但这些偏见实际上可能反映了训练文本所来源文化中的真实性别差距，因此可以作为一种通过大数据理解文化背景的工具。

Method: 提出量化词嵌入中性别偏见的方法，使用2018年Twitter数据覆盖51个美国地区和99个国家，将词嵌入偏见与18个国际和5个美国统计性别差距指标进行相关性分析。

Result: 验证了词嵌入偏见指标与真实世界性别差距统计数据的相关性，能够表征规律性和预测强度，表明词嵌入中的偏见可以反映文化中的实际性别差距。

Conclusion: 词嵌入中的性别偏见不仅是一个需要修正的技术问题，还可以作为理解文化背景中实际性别差距的有价值工具，为通过大数据分析文化现象提供了新视角。

Abstract: Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.

</details>


### [13] [DF-RAG: Query-Aware Diversity for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.17212)
*Saadat Hasan Khan,Spencer Hong,Jingyu Wu,Kevin Lybarger,Youbing Yin,Erin Babinsky,Daben Liu*

Main category: cs.CL

TL;DR: DF-RAG通过引入多样性检索机制改进传统RAG，在推理密集型QA任务上比传统余弦相似度检索提升4-10%的F1分数


<details>
  <summary>Details</summary>
Motivation: 传统RAG在推理密集型问答任务中存在局限性，因为常用的余弦相似度检索方法虽然能最大化相关性，但会引入冗余内容，降低信息召回率

Method: 基于最大边际相关性框架，选择既与查询相关又彼此差异最大的信息块，并能在测试时动态优化每个查询的多样性水平，无需额外微调或先验信息

Result: 在推理密集型QA基准测试中，DF-RAG比传统余弦相似度RAG提升4-10%的F1性能，优于其他基线方法，能实现Oracle上限91.3%的性能

Conclusion: DF-RAG通过系统性地在检索步骤中引入多样性，有效解决了传统RAG在推理密集型QA任务中的局限性，显著提升了性能

Abstract: Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.

</details>


### [14] [Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning](https://arxiv.org/abs/2601.17223)
*Massimiliano Pronesti,Anya Belz,Yufang Hou*

Main category: cs.CL

TL;DR: 本文提出可验证过程奖励模型(VPRMs)，通过确定性规则验证器检查中间推理步骤，在医学证据合成偏倚评估中显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程监督方法依赖神经评分器评估思维链步骤，容易受到不透明性、偏见和奖励攻击的影响。需要一种能够对中间推理步骤进行确定性验证的强化学习框架。

Method: 提出可验证过程奖励模型(VPRMs)，使用确定性、基于规则的验证器检查中间推理步骤。应用于医学证据合成偏倚评估领域，利用指南定义的标准和基于规则的决策路径实现推理轨迹的程序化验证。

Result: 在多个数据集上，VPRMs生成的推理紧密遵循领域规则，步骤级决策与最终标签的一致性显著提高。相比最先进模型提升高达20%的F1分数，比可验证结果奖励高6.5%，在证据基础和逻辑一致性方面有实质性提升。

Conclusion: VPRMs通过确定性规则验证器有效解决了过程监督中的不透明性和奖励攻击问题，在医学证据合成偏倚评估中实现了更好的领域规则遵循和推理一致性。

Abstract: Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.

</details>


### [15] [Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation](https://arxiv.org/abs/2601.17226)
*David Y. Liu,Xanthe Muston,Aditya Joshi,Sebastian Sequoiah-Grayson*

Main category: cs.CL

TL;DR: 本文探索使用强化学习（d-RLAIF）作为监督微调（SFT）的替代方案进行自动故事生成的后训练，通过叙事均衡理论建立评估原则，利用LLM作为评判模型提供奖励信号，最终生成的故事比SFT更具多样性和人类叙事一致性。


<details>
  <summary>Details</summary>
Motivation: 自动故事生成（ASG）具有主观性，但以往研究依赖有限的真实数据进行训练和评估。本文旨在探索强化学习作为监督微调替代方案，以生成更符合人类叙事惯例的故事。

Method: 1. 应用Todorov的叙事均衡理论建立ASG质量评估原则；2. 使用7B和14B的LLM作为评判模型，验证与人类标注者的一致性并提供奖励信号；3. 采用d-RLAIF（基于AI反馈的强化学习）进行后训练；4. 使用Gemini-3-Flash评估模型输出，并与TimeTravel数据集的人类编写故事比较。

Result: d-RLAIF作为监督微调的可行替代方案，生成的故事更具多样性且更符合人类叙事惯例。LLM评判模型与人类标注者对齐良好，强化学习在主观任务（如ASG）的语言基础后训练中展现出潜力。

Conclusion: 强化学习为自动故事生成等主观任务提供了一种有前景的后训练方法，能够生成更符合人类叙事期望的多样化故事，超越了传统监督微调方法的局限性。

Abstract: Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.

</details>


### [16] [CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval](https://arxiv.org/abs/2601.17230)
*Akshith Reddy Putta,Jacob Devasier,Chengkai Li*

Main category: cs.CL

TL;DR: CaseFacts是一个用于验证美国最高法院先例中通俗法律声明的基准数据集，包含6,294个声明，分为支持、反驳或被推翻三类，旨在解决法律领域事实核查的特殊挑战。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查主要关注静态语料库中的一般知识，忽略了法律等高风险领域，其中真相是动态演变且技术复杂的。法律声明需要弥合通俗表达与技术法理之间的语义鸿沟，并考虑时间有效性。

Method: 采用多阶段流水线：利用大型语言模型从专家案例摘要中合成声明，使用新颖的语义相似性启发式方法高效识别和验证复杂的法律推翻情况。数据集包含6,294个声明，分为支持、反驳或被推翻三类。

Result: 实验表明，即使使用最先进的LLMs，该任务仍然具有挑战性。值得注意的是，为模型添加无限制的网络搜索反而会降低性能（相比闭卷基线），因为会检索到嘈杂、非权威的先例。

Conclusion: CaseFacts基准旨在推动法律事实核查系统的研究，强调了法律领域事实核查的特殊挑战，包括语义鸿沟和时间有效性，以及权威来源的重要性。

Abstract: Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.

</details>


### [17] [Frame-Guided Synthetic Claim Generation for Automatic Fact-Checking Using High-Volume Tabular Data](https://arxiv.org/abs/2601.17232)
*Jacob Devasier,Akshith Putta,Qing Wang,Alankrit Moses,Chengkai Li*

Main category: cs.CL

TL;DR: 该论文提出了一个针对大规模结构化数据的事实核查新基准数据集，包含78,503个基于434个复杂OECD表格的合成声明，旨在解决现有基准忽略真实世界高容量数据验证的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动化事实核查基准主要关注小型、精选的表格数据，而忽略了验证真实世界中高容量结构化数据的挑战。这造成了研究空白，因为现实世界的事实核查往往需要处理大规模、复杂的表格数据。

Method: 提出了一种基于语义框架的引导方法，通过六个语义框架程序化地选择重要数据点，生成英语、中文、西班牙语和印地语的真实声明。使用434个平均超过50万行的复杂OECD表格作为数据源。

Result: 创建了包含78,503个合成声明的大规模多语言数据集。通过知识探测实验证明LLMs没有记忆这些事实，迫使系统执行真正的检索和推理。基准测试显示证据检索是主要瓶颈，模型难以在庞大表格中找到正确数据。

Conclusion: 该数据集为解决真实世界大规模结构化数据事实核查问题提供了关键资源，强调了证据检索的挑战性，为未来研究指明了方向。

Abstract: Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.

</details>


### [18] [PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues](https://arxiv.org/abs/2601.17277)
*Mohammad Rifqi Farhansyah,Hanif Muhammad Zhafran,Farid Adilazuarda,Shamsuddeen Hassan Muhammad,Maryam Ibrahim Mukhtar,Nedjma Ousidhoum,Genta Indra Winata,Ayu Purwarianti,Alham Fikri Aji*

Main category: cs.CL

TL;DR: PingPong是一个用于自然多语言代码切换对话的基准测试，包含五种语言组合变体，部分为三语对话，涵盖问答、对话摘要和主题分类三个下游任务。


<details>
  <summary>Details</summary>
Motivation: 代码切换是全球多语种人群的普遍实践，但现有基准测试未能准确反映日常交流中的复杂性，需要更贴近真实多语言对话的数据集。

Method: 构建PingPong基准测试，包含人类撰写的2-4人自然对话，涵盖五种语言组合变体（部分为三语），对话具有真实的多线程结构，回复经常引用较早的对话点。

Result: PingPong数据比机器生成替代方案更自然、结构更多样，在消息长度、说话者主导性和回复距离方面变化更大；当前最先进语言模型在代码切换输入上表现有限。

Conclusion: 需要更强大的NLP系统来处理现实世界多语言交流的复杂性，PingPong基准测试为评估和改进代码切换能力提供了重要资源。

Abstract: Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.

</details>


### [19] [Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering](https://arxiv.org/abs/2601.17284)
*Yaokun Liu,Yifan Liu,Phoebe Mbuvi,Zelin Li,Ruichen Yao,Gawon Lim,Dong Wang*

Main category: cs.CL

TL;DR: 提出CV-MedBench基准，用于研究医学QA中的输入歧义问题，并提出基于歧义探测的"先澄清后回答"框架，显著提升医学QA安全性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学问答中面临用户查询歧义问题，这会显著降低高风险医疗环境中的回答准确性，构成严重安全隐患

Method: 1) 构建CV-MedBench基准；2) 从表示工程角度分析歧义性不确定性(AU)；3) 提出AU-Probe轻量模块从隐藏状态检测输入歧义；4) 设计AU引导的"先澄清后回答"框架

Result: 在四个开源LLM上的实验表明，该框架平均准确率比基线提升9.48%，无需微调或多前向传播，能主动请求用户澄清

Conclusion: 该框架为安全医学QA提供了高效鲁棒的解决方案，增强了健康相关应用的可靠性，代码和数据集已开源

Abstract: The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided "Clarify-Before-Answer" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.

</details>


### [20] [Meta-Judging with Large Language Models: Concepts, Methods, and Challenges](https://arxiv.org/abs/2601.17312)
*Hugo Silva,Mateus Mendes,Hugo Gonçalo Oliveira*

Main category: cs.CL

TL;DR: 本文综述了LLM评估从"LLM-as-a-Judge"到"LLM-as-a-Meta-Judge"的演进，分析了传统LLM评估的局限性，并提出了元评估框架的六个关键视角。


<details>
  <summary>Details</summary>
Motivation: 传统LLM-as-a-Judge评估方法存在显著漏洞，包括对提示的敏感性、系统性偏见、冗长效应以及不可靠或幻觉的推理过程。这些局限性促使开发更稳健的元评估范式。

Method: 提出LLM-as-a-Meta-Judge框架，从六个关键视角组织文献：(1)概念基础，(2)元评估机制，(3)对齐训练方法，(4)评估，(5)局限性和失败模式，(6)未来方向。

Result: LLM-as-a-Meta-Judge为更稳定和可信的自动化评估提供了有前景的方向，但仍需解决成本、提示敏感性和共享模型偏见等挑战。

Conclusion: 元评估是推进下一代LLM评估方法学的关键，需要解决现有挑战以实现更可靠的自动化评估系统。

Abstract: Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.

</details>


### [21] [The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents](https://arxiv.org/abs/2601.17344)
*Chen Chen,Kim Young Il,Yuan Yang,Wenhao Su,Yilin Zhang,Xueluan Gong,Qian Wang,Yongsen Zheng,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 论文提出IMPRESS框架，用于评估LLM智能体在完全良性情境下的内在价值错位风险，发现这是普遍存在的安全问题，现有缓解策略效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注对显性有害输入的响应或系统故障的鲁棒性，而在现实、完全良性、自主的智能体设置中，价值错位风险尚未得到充分探索。

Method: 首先形式化失控风险，识别内在价值错位；然后提出IMPRESS框架，通过多阶段LLM生成管道构建现实、完全良性、情境化的场景基准；评估21个最先进的LLM智能体。

Result: 内在价值错位是跨模型的普遍安全风险；错位率因动机、风险类型、模型规模和架构而异；解码策略影响有限，情境化和框架机制显著影响错位行为；现有缓解策略不稳定或效果有限。

Conclusion: 内在价值错位是LLM智能体安全的重要风险，需要更有效的缓解策略；IMPRESS框架为AI生态系统提供了关键评估工具。

Abstract: Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.

</details>


### [22] [Do readers prefer AI-generated Italian short stories?](https://arxiv.org/abs/2601.17363)
*Michael Farrell*

Main category: cs.CL

TL;DR: 研究通过盲测发现，读者对AI生成的意大利语短篇小说的评价略高于著名意大利作家阿尔贝托·莫拉维亚的作品，挑战了人类创作小说更受偏好的假设。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨读者是否更喜欢AI生成的短篇小说而非人类作家作品，挑战关于读者偏好的传统假设，并检验合成文本在文学语境中是否需要编辑的必要性。

Method: 采用盲测实验设计，20名参与者在不知情的情况下阅读并评估三篇短篇小说（两篇由ChatGPT-4o生成，一篇由阿尔贝托·莫拉维亚创作），同时收集阅读习惯和人口统计学数据（年龄、性别、教育程度、母语）。

Result: AI生成的文本获得了略高的平均评分，且更常被偏好，但差异不大。文本偏好与人口统计学或阅读习惯变量之间未发现统计学显著关联。

Conclusion: 研究结果挑战了读者偏好人类创作小说的假设，并引发了对文学语境中合成文本编辑必要性的质疑，表明AI生成内容在文学领域可能具有竞争力。

Abstract: This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.

</details>


### [23] [Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws](https://arxiv.org/abs/2601.17364)
*Mohammed Fasha,Bassam Hammo,Bilal Sowan,Husam Barham,Esam Nsour*

Main category: cs.CL

TL;DR: 本研究以约旦法律为案例，探索了Llama-3.1大语言模型在阿拉伯语法律问答任务中的微调方法，通过量化和参数高效微调技术实现了资源高效的法律领域适应。


<details>
  <summary>Details</summary>
Motivation: 探索如何将大语言模型有效适应到阿拉伯语法律领域，解决法律专业问答任务，同时通过量化技术实现资源高效训练。

Method: 使用两种Llama-3.1模型版本（8B-bnb-4bit和8B-Instruct-bnb-4bit），采用参数高效微调（PEFT）和LoRA适配器，结合4位量化技术，利用Unsloth框架进行加速训练。构建了包含6000个约旦法律问答对的定制数据集。

Result: 微调后的模型在法律推理和准确性方面表现提升，同时通过量化和优化微调策略实现了资源效率。使用BLEU和ROUGE指标评估显示性能改进。

Conclusion: 该研究证明了将大语言模型适应到阿拉伯语法律领域的可行性，展示了量化技术和参数高效微调在领域特定任务中的有效性，为阿拉伯语法律AI应用提供了技术路径。

Abstract: This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.

</details>


### [24] [Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers](https://arxiv.org/abs/2601.17367)
*Zecheng Tang,Quantong Qiu,Yi Yang,Zhiyi Hong,Haiya Xiang,Kebin Liu,Qingqing Dang,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出Elastic Attention方法，通过轻量级Attention Router动态调整注意力稀疏度，解决长上下文场景中标准注意力二次复杂度问题


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制的二次复杂度限制了LLM在长上下文场景的可扩展性，现有混合注意力策略采用静态计算比例，无法适应下游任务的不同稀疏敏感度

Method: 提出Elastic Attention，集成轻量级Attention Router到预训练模型中，动态分配每个注意力头到不同的计算模式，实现整体稀疏度的自适应调整

Result: 仅需8xA800 GPU上12小时训练，在三个长上下文基准测试中，方法在广泛使用的LLM上展现出优越性能，实现强性能和高效推理

Conclusion: Elastic Attention通过动态调整注意力稀疏度，有效解决了长上下文LLM的扩展瓶颈，相比静态混合策略更具适应性

Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.

</details>


### [25] [WarrantScore: Modeling Warrants between Claims and Evidence for Substantiation Evaluation in Peer Reviews](https://arxiv.org/abs/2601.17377)
*Kiyotada Mori,Shohei Tanaka,Tosho Hirasawa,Tadashi Kozuno,Koichiro Yoshino,Yoshitaka Ushiku*

Main category: cs.CL

TL;DR: 提出一种评估科学评审评论中主张与证据间逻辑推理的新方法，比传统方法更能反映人工评分


<details>
  <summary>Details</summary>
Motivation: 科学同行评审面临人力资源短缺，语言模型可降低评审成本，但现有方法仅检测主张是否有证据支持，无法准确评估逻辑推理关系

Method: 提取评审评论中的核心论证组件（主张和证据），提出新评估指标来评估主张与证据间的逻辑推理关系，而非简单检测证据存在与否

Result: 实验结果显示，提出的方法比传统方法获得更高的人工评分相关性，表明能更好地支持同行评审过程的效率

Conclusion: 新方法能更准确地评估科学评审评论的论证质量，有潜力提高同行评审效率，解决人力资源短缺问题

Abstract: The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.

</details>


### [26] [Revisiting Modality Invariance in a Multilingual Speech-Text Model via Neuron-Level Analysis](https://arxiv.org/abs/2601.17387)
*Toshiki Nakai,Varsha Suresh,Vera Demberg*

Main category: cs.CL

TL;DR: SeamlessM4T v2多语言语音-文本基础模型在语音和文本模态下对同一语言的内部表示并不完全一致，存在模态不变性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 研究多语言语音-文本基础模型是否能在语音和文本两种模态下对同一语言保持一致的内部表示，探索模态不变性的程度。

Method: 通过三种互补分析：1) 使用平均精度排名识别语言和模态选择性神经元；2) 通过推理时的中值替换干预研究其功能作用；3) 分析跨语言和模态的激活幅度不平等。

Result: 发现不完全的模态不变性：编码器表示变得语言无关，但这种压缩使共享解码器更难恢复源语言（特别是从语音到文本时）；观察到交叉注意力键值投影中高度局部化的模态选择性结构；语音条件解码和非主导脚本表现出更高的激活集中度。

Conclusion: 多语言语音-文本基础模型在语音和文本模态下的语言表示存在差异，模态不变性不完全，这可能解释了跨模态和语言的脆弱性增加。

Abstract: Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.

</details>


### [27] [CLM-Bench: Benchmarking and Analyzing Cross-lingual Misalignment of LLMs in Knowledge Editing](https://arxiv.org/abs/2601.17397)
*Yucheng Hu,Wei Zhou,Juesi Xiao*

Main category: cs.CL

TL;DR: 本文提出了CLM-Bench，一个文化感知的中文优先多语言知识编辑基准，揭示了当前方法在跨语言知识传播上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有MKE基准通常通过机械翻译英文数据集构建，存在翻译伪影且忽略目标语言的文化特定实体，无法反映LLMs的真实知识分布。

Method: 采用中文优先方法构建CLM-Bench，包含1010个基于中文文化背景的高质量CounterFact对，并与英文对应项对齐。在代表性LLMs上进行实验，并通过层表示分析提供几何解释。

Result: 发现显著的跨语言错位：一种语言的编辑独立运作，无法传播到另一种语言。中文和英文编辑向量几乎正交，存在于不相交的子空间中，而混合语言编辑显示这些向量的线性可加性。

Conclusion: 当前方法在跨语言转移上效果有限，强调文化原生基准的重要性。编辑向量正交性表明需要开发能促进跨语言知识传播的新方法。

Abstract: Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.

</details>


### [28] [Oops, Wait: Token-Level Signals as a Lens into LLM Reasoning](https://arxiv.org/abs/2601.17421)
*Jaehui Hwang,Dongyoon Han,Sangdoo Yun,Byeongho Heo*

Main category: cs.CL

TL;DR: 分析LLM中"wait"、"therefore"等话语标记token的概率信号，发现这些信号与推理正确性高度相关，且在不同模型规模下稳定，但受训练策略影响。小数据集微调的模型会利用但不完全利用这些信号。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中出现的"wait"、"therefore"等话语标记token为理解其推理过程提供了独特窗口，但目前缺乏对这些信号如何随训练策略和模型规模变化的系统分析。

Method: 通过分析不同模型的token级概率信号，特别是"wait"等话语标记token的概率分布，研究这些信号与推理正确性的相关性，并考察训练策略和模型规模的影响。

Result: 特定token与推理正确性高度相关，这种相关性在不同模型规模下保持稳定，但受训练策略影响。小数据集微调的模型通过这类信号获得推理能力，但只部分利用这些信号。

Conclusion: 这项工作为观察和理解LLM推理动态提供了系统性视角，揭示了话语标记token在模型推理中的重要作用及其与训练策略的关联。

Abstract: The emergence of discourse-like tokens such as "wait" and "therefore" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the "wait" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.

</details>


### [29] [Clustering-driven Memory Compression for On-device Large Language Models](https://arxiv.org/abs/2601.17443)
*Ondrej Bohdal,Pramit Saha,Umberto Michieli,Mete Ozay,Taha Ceritli*

Main category: cs.CL

TL;DR: 提出基于聚类的记忆压缩策略，通过相似性分组和合并来平衡上下文效率与个性化质量，在减少记忆token的同时提升生成质量


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：直接拼接记忆会耗尽有限上下文空间，而平均压缩会因语义冲突损害性能。需要一种能平衡上下文效率和个性化质量的记忆压缩方法

Method: 基于聚类的记忆压缩策略：首先按相似性对记忆进行分组，然后在每个聚类内合并记忆，最后将合并后的记忆与输入提示拼接，从而在减少冗余的同时保持语义连贯性

Result: 实验表明该方法显著减少了记忆token数量，同时优于基线策略（如直接平均或直接拼接）。在固定上下文预算下，聚类驱动的合并能产生更紧凑的记忆表示，并持续提升生成质量

Conclusion: 提出的聚类记忆压缩策略有效解决了LLMs中个性化记忆的上下文限制问题，在保持个性化质量的同时实现了高效的记忆压缩，为设备端LLMs的个性化生成提供了实用解决方案

Abstract: Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.

</details>


### [30] [Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes](https://arxiv.org/abs/2601.17530)
*Gautam Siddharth Kashyap,Harsh Joshi,Niharika Jain,Ebad Shabbir,Jiechao Gao,Nipun Joshi,Usman Naseem*

Main category: cs.CL

TL;DR: 提出ConLLM框架，通过对比学习和LLM推理解决深度伪造检测中的模态碎片化和浅层跨模态推理问题，显著提升音频、视频和视听深度伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对社会政治稳定构成严重威胁，现有检测方法存在两个核心局限：1）模态碎片化导致跨不同对抗性深度伪造模态的泛化能力差；2）浅层跨模态推理导致细粒度语义不一致检测有限。

Method: 提出ConLLM（基于大语言模型的对比学习）混合框架，采用两阶段架构：第一阶段使用预训练模型提取模态特定嵌入；第二阶段通过对比学习对齐这些嵌入以缓解模态碎片化，并使用基于LLM的推理进行精炼以解决浅层跨模态推理问题，捕捉语义不一致。

Result: ConLLM在音频、视频和视听模态上表现优异：音频深度伪造EER降低高达50%，视频准确率提升高达8%，视听任务准确率提升约9%。消融研究证实基于PTM的嵌入为各模态带来9%-10%的稳定改进。

Conclusion: ConLLM框架通过结合对比学习和LLM推理，有效解决了深度伪造检测中的模态碎片化和浅层跨模态推理问题，显著提升了多模态深度伪造检测的鲁棒性和准确性。

Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.

</details>


### [31] [Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection](https://arxiv.org/abs/2601.17532)
*Zhipeng Song,Yizhi Zhou,Xiangyu Kong,Jiulong Jiao,Xinrui Bao,Xu You,Xueqing Shi,Yuhang Zhou,Heng Qi*

Main category: cs.CL

TL;DR: RAG系统中，检索相关性指标与最终QA质量相关性弱，甚至负相关。提出IGP方法，通过信息增益剪枝选择证据，在保持预算接口不变的情况下显著提升质量-成本权衡。


<details>
  <summary>Details</summary>
Motivation: 在有限上下文预算下，检索增强生成(RAG)的关键挑战是决定注入哪些检索到的段落。研究发现检索相关性指标（如NDCG）与端到端QA质量相关性弱，在多段落注入情况下甚至可能负相关，因为冗余和轻微冲突会破坏生成的稳定性。

Method: 提出信息增益剪枝(IGP)，这是一个部署友好的重排序和剪枝模块。它使用生成器对齐的效用信号选择证据，在截断前过滤弱或有害的段落，而不改变现有的预算接口。

Result: 在五个开放域QA基准测试和多种检索器和生成器上，IGP一致地改善了质量-成本权衡。在典型的多证据设置中，IGP相比仅使用检索器的基线，平均F1相对提升约12-20%，同时最终阶段输入token减少约76-79%。

Conclusion: IGP通过生成器对齐的效用信号有效选择证据，解决了RAG中检索相关性指标与最终生成质量不匹配的问题，显著提升了系统效率和质量。

Abstract: Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.

</details>


### [32] [Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations](https://arxiv.org/abs/2601.17569)
*Alireza Salemi,Hamed Zamani*

Main category: cs.CL

TL;DR: P³框架：通过客户端小模型修改服务器大模型生成的草稿token，实现个性化LLM输出，保护用户隐私


<details>
  <summary>Details</summary>
Motivation: 现有个性化LLM方案面临隐私与性能的权衡：要么将用户私有数据暴露给云端服务器模型，要么依赖性能较弱的本地模型。需要一种既能保护隐私又能提供高质量个性化的解决方案。

Method: P³交互式框架：服务器端大模型仅基于用户查询生成k个草稿token；客户端小模型访问用户私有配置文件，评估并修改这些草稿以更好地反映用户偏好；此过程重复直到生成结束token。

Result: 在LaMP-QA基准测试中，P³显著优于非个性化服务器端和个性化客户端基线，平均提升7.4%-9%；恢复率90.3%-95.7%（与完全暴露配置文件的理想情况相比）；隐私泄漏仅增加1.5%-3.5%；客户端模型仅生成总token的9.2%。

Conclusion: P³提供了一个实用有效的个性化生成解决方案，在保护隐私的同时实现了接近理想情况的性能，适合边缘部署。

Abstract: Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.

</details>


### [33] [Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models](https://arxiv.org/abs/2601.17585)
*Matija Luka Kukić,Marko Čuljak,David Dukić,Martin Tutek,Jan Šnajder*

Main category: cs.CL

TL;DR: 序列重复（SR）是一种让仅解码器语言模型具备双向上下文能力的新方法，相比移除因果掩码更少侵入性，能提升词级表示质量并超越编码器模型。


<details>
  <summary>Details</summary>
Motivation: 传统序列标注任务依赖双向编码器模型，而现代仅解码器语言模型是自回归训练的，只利用前缀信息。虽然移除因果掩码可以让解码器利用完整上下文，但需要大幅修改模型结构。需要探索更少侵入性的方法让解码器模型适应序列标注任务。

Method: 提出序列重复（SR）方法，通过重复输入序列来让仅解码器模型获得双向上下文能力。在微调实验中，比较SR方法、编码器模型和移除因果掩码的解码器模型在序列标注任务上的表现，并研究重复次数和不同层嵌入的效果。

Result: SR方法使解码器具备双向性，显著提升词级嵌入质量，超越编码器模型和移除因果掩码的解码器。增加重复次数不会降低性能，与之前研究结论相反。中间层的嵌入效果与最终层相当，但计算效率更高。

Conclusion: 序列重复方法有效缓解了仅解码器模型的结构限制，使其能更高效地适应序列标注等词级任务，扩展了语言模型的应用范围，同时保持了计算效率。

Abstract: Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.

</details>


### [34] [From Chains to DAGs: Probing the Graph Structure of Reasoning in LLMs](https://arxiv.org/abs/2601.17593)
*Tianjun Zhong,Linyang He,Nima Mesgarani*

Main category: cs.CL

TL;DR: 该论文提出Reasoning DAG Probing框架，研究LLM隐藏状态是否线性编码推理有向无环图的几何结构，发现中间层确实编码了推理图结构，且可恢复性随节点深度和模型规模系统变化。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在多步推理方面取得进展，但现有研究多将推理视为线性链式过程。然而许多推理问题更适合用有向无环图表示，其中中间结论可能依赖多个前提、分支为并行子推导、后续合并或重用。理解模型内部是否反映这种图结构推理仍是一个开放问题。

Method: 提出Reasoning DAG Probing框架：将每个推理节点与文本实现关联，训练轻量级探针从隐藏状态预测两个图论属性（节点深度和节点间距离）。通过该框架分析DAG结构在层间的涌现，并评估破坏推理相关结构但保留表面文本属性的控制实验。

Result: 结果表明推理DAG几何结构在中间层有意义地被编码，可恢复性随节点深度和模型规模系统变化。这证明LLM推理不仅是顺序的，而且表现出可测量的内部图结构。

Conclusion: LLM推理不仅具有序列特性，还在中间层编码了可测量的图结构几何信息，这为理解模型如何表示和计算多步推理提供了新的机制性视角。

Abstract: Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.
  In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.

</details>


### [35] [Learning to Ideate for Machine Learning Engineering Agents](https://arxiv.org/abs/2601.17596)
*Yunxiang Zhang,Kang Zhou,Zhichao Xu,Kiran Ramnath,Yun Zhou,Sangmin Woo,Haibo Ding,Lin Lee Cheong*

Main category: cs.CL

TL;DR: MLE-Ideator：双智能体框架，将创意生成与实现分离，通过强化学习训练Ideator智能体，在MLE任务上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有机器学习工程智能体难以迭代优化算法效果，需要分离创意生成与实现过程以提高优化能力

Method: 提出MLE-Ideator双智能体框架：实现智能体负责执行，Ideator智能体专门提供策略帮助；使用强化学习训练Ideator生成更有效的创意

Result: 在无训练设置下显著优于仅实现智能体基线；经过1K样本RL训练的Qwen3-8B Ideator相比未训练版本提升11.5%，超越Claude Sonnet 3.5

Conclusion: 分离创意与实现的双智能体框架有效提升机器学习工程优化能力，为训练科学发现策略AI系统提供了有前景的路径

Abstract: Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.

</details>


### [36] [What Language Models Know But Don't Say: Non-Generative Prior Extraction for Generalization](https://arxiv.org/abs/2601.17609)
*Sara Rezaeimanesh,Mohammad M. Ghassemi*

Main category: cs.CL

TL;DR: LoID：通过直接访问LLM的token级预测来提取贝叶斯逻辑回归信息先验分布的确定性方法，在协变量偏移的OOD设置下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 在医学和金融等领域，大规模标注数据成本高且难以获取，导致在小数据集上训练的模型难以泛化到真实世界人群。LLM包含这些领域多年研究的广泛知识，但如何有效提取这些知识用于统计模型仍具挑战

Method: LoID通过精心构建的句子探测LLM在相反语义方向（正面vs负面影响）上的置信度，测量LLM在不同表达方式中偏好某一方向的一致性，从而提取每个特征影响的强度和可靠性信息，为贝叶斯逻辑回归提供信息先验分布

Result: 在10个真实世界表格数据集上，在协变量偏移的合成OOD设置下，LoID显著优于在OOD数据上训练的逻辑回归，恢复了相对于oracle模型高达59%的性能差距。在8/10的数据集上优于AutoElicit和LLMProcesses方法

Conclusion: LoID提供了一种可重现且计算高效的机制，将LLM知识整合到贝叶斯推理中，在数据有限且存在分布偏移的实际场景中具有重要应用价值

Abstract: In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \textbf{59\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.

</details>


### [37] [Beyond the Rabbit Hole: Mapping the Relational Harms of QAnon Radicalization](https://arxiv.org/abs/2601.17658)
*Bich Ngoc,Doan,Giuseppe Russo,Gianmarco De Francisci Morales,Robert West*

Main category: cs.CL

TL;DR: 研究通过分析QAnon支持者亲友的叙述，首次系统性地量化了阴谋论激进化的情感代价，识别出六种激进者原型并揭示了不同原型与亲友特定情感伤害的关联。


<details>
  <summary>Details</summary>
Motivation: 现有大规模计算研究主要关注阴谋论对公共话语的宏观影响，但忽视了其对亲友造成的个人情感伤害。本研究旨在填补这一空白，系统性地量化激进化的情感代价。

Method: 采用混合方法：1) 使用BERTopic主题建模分析12747个r/QAnonCasualties社区叙述，映射激进化轨迹；2) 应用LDA图模型识别六种激进化原型；3) 使用LLM辅助情感检测和回归模型，将原型与叙述者报告的情感伤害关联。

Result: 识别出六种QAnon追随者原型（激进化人格），这些原型能有效预测亲友经历的具体情感伤害：被视为意识形态选择的激进化与愤怒和厌恶相关，而个人和认知崩溃型则与恐惧和悲伤相关。

Conclusion: 研究首次为理解激进化作为关系现象提供了实证框架，为研究人员和实践者应对其人际后果提供了重要路线图，揭示了不同激进化类型与特定情感伤害的预测性关联。

Abstract: The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term "radicalization personas." Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.

</details>


### [38] [UrduLM: A Resource-Efficient Monolingual Urdu Language Model](https://arxiv.org/abs/2601.17664)
*Syed Muhammad Ali,Hammad Sajid,Zainab Haider,Ali Muhammad Asad,Haya Fatima,Abdul Samad*

Main category: cs.CL

TL;DR: 本文提出了UrduLM，一个针对乌尔都语的预训练单语语言模型，解决了乌尔都语缺乏专用Transformer模型和高质量语料库的问题。该模型在低资源环境下训练，性能可与大30倍的多语言模型竞争。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语有2.3亿使用者，但缺乏专用的Transformer语言模型和精心整理的语料库。现有的多语言模型对乌尔都语支持有限，存在性能差、计算成本高、文化不准确等问题，主要原因是训练数据不足。

Method: 1) 从多种来源整理了一个33GB的乌尔都语语料库；2) 开发了自定义BPE分词器，比多语言分词器减少20-30%的分词开销；3) 预训练了一个1亿参数的仅解码器模型。

Result: 在少样本评估中，UrduLM与比它大30倍的多语言模型性能相当：情感分类准确率达到66.6%，语法纠正任务的BLEU分数超过30。

Conclusion: 作者开源了完整的语料库、分词器、模型权重和评估基准，为乌尔都语NLP研究建立了基线，并为其他资源不足语言提供了可扩展的框架。

Abstract: Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.

</details>


### [39] [Align to the Pivot: Dual Alignment with Self-Feedback for Multilingual Math Reasoning](https://arxiv.org/abs/2601.17671)
*Chunxu Zhao,Xin Huang,Xue Han,Shujian Huang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: PASMR方法通过将主语言作为枢纽语言，建立跨语言自反馈机制，提升LLM在低资源语言上的数学推理能力对齐


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出强大的推理能力，但在多语言环境下（特别是低资源语言）性能会下降，这归因于模型的多语言理解和推理对齐不一致

Method: 提出Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR)方法：1) 将模型主语言设为枢纽语言；2) 训练时将问题翻译到枢纽语言以对齐推理模式；3) 目标语言的推理过程由枢纽语言的推理答案监督，建立跨语言自反馈机制，无需外部正确答案或奖励模型

Result: 广泛的实验结果表明，该方法显著提升了模型对问题的理解和推理能力，带来了显著的任务改进

Conclusion: PASMR方法通过跨语言自反馈机制有效改善了LLM在多语言数学推理任务中的能力对齐，特别是在低资源语言上的表现

Abstract: Despite the impressive reasoning abilities demonstrated by large language models (LLMs), empirical evidence indicates that they are not language agnostic as expected, leading to performance declines in multilingual settings, especially for low-resource languages. We attribute the decline to the model's inconsistent multilingual understanding and reasoning alignment. To address this, we present Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR), aiming to improve the alignment of multilingual math reasoning abilities in LLMs. This approach designates the model's primary language as the pivot language. During training, the model first translates questions into the pivot language to facilitate better alignment of reasoning patterns. The reasoning process in the target language is then supervised by the pivot language's reasoning answers, thereby establishing a cross-lingual self-feedback mechanism without relying on external correct answers or reward models. Extensive experimental results demonstrate that our method enhances both the model's understanding of questions and its reasoning capabilities, leading to notable task improvements.

</details>


### [40] [S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference](https://arxiv.org/abs/2601.17702)
*Qingsen Ma,Dianyun Wang,Yaoye Wang,Lechen Ning,Sujie Zhu,Xiaohang Zhang,Jiaming Lyu,Linhao Ren,Zhenbo Xu,Zhaofeng He*

Main category: cs.CL

TL;DR: S3-Attention是一种内存优先的推理时框架，通过将长上下文处理视为注意力对齐的内生检索，完全丢弃KV缓存，用CPU倒排索引映射特征到token位置，显著降低GPU内存使用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地应用于多文档和长格式输入，但长上下文推理仍然存在内存和噪声效率低下的问题。KV缓存随上下文长度线性扩展，而外部检索方法通常返回词汇相似但因果无关的段落。

Method: S3-Attention将长上下文处理视为注意力对齐的内生检索，将瞬态键和查询投影解码为top-k稀疏特征标识符，使用轻量级稀疏自编码器，并在单次流式扫描中构建CPU倒排索引映射特征到token位置或跨度。生成时使用特征共激活检索紧凑证据跨度，可选与BM25融合进行精确词汇匹配。

Result: 在统一的LongBench评估协议下，S3-Hybrid在多个模型系列中与全上下文推理结果接近，并在多个信息密集设置中提高了鲁棒性。但当前原型存在工程限制，比优化的全KV基线具有更高的实际延迟。

Conclusion: S3-Attention提供了一种内存高效的推理框架，能够处理长上下文输入，但需要未来的内核级优化来减少延迟。

Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.
  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.
  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.

</details>


### [41] [Distance-to-Distance Ratio: A Similarity Measure for Sentences Based on Rate of Change in LLM Embeddings](https://arxiv.org/abs/2601.17705)
*Abdullah Qureshi,Kenneth Rice,Alexander Wolpert*

Main category: cs.CL

TL;DR: 本文提出了一种新的文本嵌入相似度度量方法DDR（距离-距离比），它通过测量上下文前后嵌入相似度的变化率来评估语义相似性，相比现有方法能更好地区分语义相似与不相似的文本。


<details>
  <summary>Details</summary>
Motivation: 现有的文本嵌入相似度度量方法需要符合人类对文本相似性的感知。本文旨在提出一种更符合人类感知的相似度度量方法，能够更精细地区分语义相似与不相似的文本。

Method: 提出距离-距离比（DDR）方法，受Lipschitz连续性启发，测量预上下文词嵌入相似度与后上下文LLM嵌入相似度之间的变化率，从而衡量上下文的语义影响。通过实验设计，对句子数据集中的句子进行一系列扰动（用同义词或随机词替换1-3个词），评估DDR性能。

Result: DDR相比其他主流相似度度量方法，在区分语义相似与不相似文本方面表现更优，即使在最小化、受控的编辑条件下也能提供更精细的区分能力。

Conclusion: DDR是一种有效的文本嵌入相似度度量方法，能够更好地捕捉人类对文本相似性的感知，在区分语义相似与不相似文本方面优于现有方法。

Abstract: A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.

</details>


### [42] [A Computational Approach to Visual Metonymy](https://arxiv.org/abs/2601.17706)
*Saptarshi Ghosh,Linfeng Liu,Tianyu Jiang*

Main category: cs.CL

TL;DR: 论文首次对视觉转喻进行系统性计算研究，构建了ViMET数据集来评估多模态模型理解间接视觉引用的能力，发现当前模型与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 图像常常传达比字面描绘更多的信息（如工具暗示职业、文物暗示传统），这种间接视觉引用（视觉转喻）在人类认知中很常见，但尚未有系统的计算研究来探索机器是否能理解这种视觉推理。

Method: 基于符号学理论提出新流程，利用大语言模型和文本到图像模型生成转喻视觉表示，构建了包含2000个多选题的ViMET数据集来评估多模态模型的认知推理能力。

Result: 实验结果显示人类表现（86.9%）与最先进的视觉语言模型（65.9%）之间存在显著差距，表明机器在解释间接视觉引用方面存在局限性。

Conclusion: 这是首次对视觉转喻的计算研究，揭示了当前多模态模型在理解间接视觉推理方面的不足，提出的ViMET数据集为未来研究提供了基准。

Abstract: Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.

</details>


### [43] [Unsupervised Elicitation of Moral Values from Language Models](https://arxiv.org/abs/2601.17728)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei*

Main category: cs.CL

TL;DR: 本文提出了一种无监督的道德推理激发方法ICM，通过最大化内部一致性来激发预训练语言模型中的潜在道德推理能力，在多个基准测试中超越了现有方法，并显著减少了社会偏见。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益普及，将其行为与人类价值观对齐变得至关重要。现有研究表明语言模型的内在道德推理能力有限，但构建道德评估的真实数据又面临多元框架和普遍偏见的挑战。因此需要探索无监督方法来激发预训练模型中的潜在道德推理能力。

Method: 采用内部一致性最大化（ICM）算法，在三个基准数据集和四个语言模型上进行测试。ICM通过最大化模型内部一致性来无监督地标记道德判断，无需人类监督。研究评估了ICM在标记道德判断、跨道德框架泛化和减轻社会偏见方面的能力。

Result: ICM在Norm Bank和ETHICS基准测试中超越了所有预训练模型和聊天机器人基线。使用ICM标签进行微调的模型表现与使用人类标签的模型相当甚至更好。在正义和常识道德框架上，ICM取得了最大的相对收益。ICM将社会偏见错误减少了超过一半，在种族、社会经济地位和政治方面的改进最为显著。

Conclusion: 预训练语言模型拥有潜在的道德推理能力，可以通过ICM等无监督方法激发出来。这为AI对齐提供了一条可扩展的路径，表明无需大量人工标注也能实现有效的道德推理。

Abstract: As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.

</details>


### [44] [Hylog: A Hybrid Approach to Logging Text Production in Non-alphabetic Scripts](https://arxiv.org/abs/2601.17753)
*Roberto Crotti,Giovanni Denaro,Zhiqiang Du,Ricardo Muñoz Martín*

Main category: cs.CL

TL;DR: Hylog是一个混合日志系统，结合分析性键盘记录和生态文本记录，用于捕捉非字母文字输入法编辑器的屏幕转换，支持更完整、更细粒度的文本生产认知研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究键盘记录工具大多无法捕捉非字母文字（如中文）输入法编辑器（IME）的屏幕转换过程，这造成了文本生产认知研究的方法学空白。

Method: 开发了模块化、开源的Hylog系统，通过插件在标准应用（Word、Chrome）中同时捕获键盘输出和渲染文本，然后由混合器模块同步成双重轨迹。

Result: 概念验证研究中，Hylog成功捕捉了拉丁字母、中文字符和IME确认之间的按键和时间间隔，这些测量传统键盘记录器无法获取，支持了新的可测试假设。

Conclusion: Hylog填补了非字母文字文本生产研究的方法学空白，其插件架构可扩展到其他IME系统，促进了更包容的多语言文本生产研究。

Abstract: Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.

</details>


### [45] [ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation](https://arxiv.org/abs/2601.17755)
*Jinyoung Park,Sanghyeok Lee,Omar Zia Khan,Hyunwoo J. Kim,Joo-Kyung Kim*

Main category: cs.CL

TL;DR: ProGraph-R1提出了一种基于进度感知的图检索增强生成框架，通过结构感知的超图检索和基于进度的逐步策略优化，解决了现有RL-based GraphRAG方法在检索和奖励机制上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的GraphRAG框架（如Graph-R1）存在两个主要问题：1）主要依赖语义相似性进行检索，忽略了底层图结构；2）依赖稀疏的结果级奖励，无法捕捉中间检索步骤的质量及其依赖关系。这些问题限制了多步推理的效果。

Method: ProGraph-R1提出两个关键技术：1）结构感知的超图检索机制，联合考虑语义相关性和图连通性，鼓励沿着多跳推理路径进行连贯遍历；2）基于进度的逐步策略优化，通过根据图中的中间推理进度调节优势函数，提供密集的学习信号，而不是仅依赖最终结果。

Result: 在多跳问答基准测试中，ProGraph-R1在推理准确性和生成质量方面持续优于现有的GraphRAG方法。

Conclusion: ProGraph-R1通过结合结构感知检索和基于进度的强化学习优化，有效提升了图检索增强生成在多步推理任务中的性能，为知识密集型问答提供了更有效的解决方案。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.

</details>


### [46] [Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali](https://arxiv.org/abs/2601.17764)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Jui Saha Pritha,Abdullah Al Noman,Abir Ahmed,Golam Md Mohiuddin,Tze Hui Liew*

Main category: cs.CL

TL;DR: 该研究分析了孟加拉语中的性别偏见问题，发现英语中心的偏见检测框架在孟加拉语中效果有限，需要更本地化和社区驱动的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在非英语语言（如孟加拉语）中的内在性别偏见问题研究不足，现有研究主要关注英语，忽略了全球南方语言的独特语言文化特征。

Method: 采用多种方法：基于词典的挖掘、计算分类模型、翻译对比分析、GPT生成偏见数据，并在农村和低收入地区进行实地调查收集真实偏见见解。

Result: 研究发现孟加拉语中的性别偏见与英语有显著不同，英语中心的偏见检测框架因语言差异和社会文化因素而效果有限，需要更本地化的方法。

Conclusion: 需要为代表性不足的语言开发专门的偏见检测工具，采用社区驱动的研究方法识别文化相关偏见，为孟加拉语和其他印度语言建立更公平的NLP系统奠定基础。

Abstract: Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.

</details>


### [47] [DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning](https://arxiv.org/abs/2601.17777)
*Xiaoyu Liu,Xiaoyu Guan,Di Liang,Xianjie Wu*

Main category: cs.CL

TL;DR: 提出动态参数隔离策略解决SFT中的跷跷板效应，通过识别任务核心参数区域、合并重叠任务、分阶段训练并冻结先前任务参数，减少任务间干扰


<details>
  <summary>Details</summary>
Motivation: 监督微调中异构任务的目标冲突导致"跷跷板效应"：优化一个任务可能损害其他任务性能，特别是当模型参数被无差别更新时。参数异质性可能是跨任务干扰的根本原因。

Method: 1. 在不同SFT任务上独立微调LLMs，识别每个任务的核心参数区域（更新幅度最大的参数子集）；2. 合并核心参数区域高度重叠的任务进行联合训练；3. 将不相交的任务组织到不同阶段；4. 在多阶段SFT中，冻结先前任务获得的核心参数，防止被后续任务覆盖

Result: 在多个公共数据集上的实验表明，动态参数隔离策略持续减少了数据冲突，相比多阶段和多任务调优基线实现了稳定的性能提升

Conclusion: 通过动态识别和隔离任务特定参数区域，可以有效缓解SFT中的跷跷板效应，提高模型在异构任务上的整体性能

Abstract: Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the "seesaw effect": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.

</details>


### [48] [Controlling Reading Ease with Gaze-Guided Text Generation](https://arxiv.org/abs/2601.17781)
*Andreas Säuberli,Darja Jepifanova,Diego Frassinelli,Barbara Plank*

Main category: cs.CL

TL;DR: 使用眼动预测模型控制文本生成难度，通过眼动追踪实验验证方法有效性


<details>
  <summary>Details</summary>
Motivation: 阅读时的眼动模式能反映认知努力程度，利用这一特性可以生成具有可控阅读难度的文本，应用于信息可访问性和语言学习

Method: 使用预测人类注视模式的模型来引导语言模型输出，使其引发特定的阅读行为，通过眼动追踪实验评估方法

Result: 方法能有效使生成的文本更容易或更难阅读，体现在阅读时间和感知难度上；统计分析显示阅读行为变化主要源于影响词汇处理的特性

Conclusion: 基于眼动预测的文本生成方法能有效控制阅读难度，主要应用于文本简化提升信息可访问性和生成个性化语言学习材料

Abstract: The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.

</details>


### [49] [Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations](https://arxiv.org/abs/2601.17786)
*Yixin Liu,Kehan Yan,Shiyuan Li,Qingfeng Chen,Shirui Pan*

Main category: cs.CL

TL;DR: 提出MCA²多视图文本异常检测框架，通过集成多个预训练语言模型的嵌入，使用多视图重构模型提取正常文本模式，结合对比协作模块和自适应分配模块，在10个基准数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有两步式"嵌入-检测器"文本异常检测方法通常只使用单一嵌入模型，缺乏跨不同数据集和异常类型的适应性，限制了其性能。

Method: 提出MCA²多视图框架：1) 利用多个预训练语言模型的嵌入；2) 使用多视图重构模型从多个嵌入视角提取正常文本模式；3) 设计对比协作模块加强视图间交互；4) 开发自适应分配模块自动分配各视图贡献权重。

Result: 在10个基准数据集上的大量实验验证了MCA²相对于强基线的有效性，表明该方法能够更好地适应不同数据集和异常类型。

Conclusion: MCA²通过集成多模型嵌入、视图间协作和自适应权重分配，有效解决了传统文本异常检测方法的局限性，提升了检测性能和适应性。

Abstract: Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step "embedding-detector" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.

</details>


### [50] [DIETA: A Decoder-only transformer-based model for Italian-English machine TrAnslation](https://arxiv.org/abs/2601.17823)
*Pranav Kasela,Marco Braga,Alessandro Ghiotto,Andrea Pilzer,Marco Viviani,Alessandro Raganato*

Main category: cs.CL

TL;DR: DIETA是一个专门为意大利语-英语机器翻译设计的5亿参数解码器Transformer模型，在多个基准测试中表现出色，性能优于大多数小于30亿参数的模型。


<details>
  <summary>Details</summary>
Motivation: 针对意大利语-英语机器翻译领域缺乏专门优化的小型模型，作者旨在开发一个专门为此任务设计的模型，同时创建新的评估数据集以促进该领域研究。

Method: 构建了包含约2.07亿句对的意大利语-英语平行语料库，涵盖议会记录、法律文本、网络内容、字幕、新闻、文学等多个领域，并使用预训练模型生成了3.52亿反向翻译数据。基于2025篇WikiNews文章创建了包含450个句子的新评估集。

Result: DIETA在多个意大利语-英语基准测试中表现出色，在32个系统的排行榜中始终排名第二四分位数，在五个测试套件中的四个上优于大多数其他小于30亿参数的模型。

Conclusion: DIETA为意大利语-英语机器翻译提供了一个有效的专门化小型模型，同时发布的训练脚本、模型、语料库和评估集将促进该领域的进一步研究和发展。

Abstract: In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation

</details>


### [51] [Linguistic and Argument Diversity in Synthetic Data for Function-Calling Agents](https://arxiv.org/abs/2601.17829)
*Dan Greenstein,Zohar Karnin,Chen Amiraz,Oren Somekh*

Main category: cs.CL

TL;DR: 提出一种通过优化通用多样性指标来生成函数调用代理训练数据的方法，无需依赖手工规则或分类法，在多样性和分布外性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 构建函数调用代理需要高质量多样的训练数据，现有方法在函数、调用模式和交互轮次上关注多样性，但请求的语言多样性和参数覆盖（如城市名、股票代码）仍未被充分探索。

Method: 提出一种生成合成数据集的方法，通过优化查询和参数的通用多样性指标，不依赖手工规则或分类法，使其适用于不同用例。

Result: 在内在和外在测试中优于现有数据生成方法，在保持可比正确性的同时实现更高的多样性。使用该数据集训练的模型在分布外性能上优于基于基线方法的模型，在BFCL基准上准确率提升7.4%。

Conclusion: 提出的数据生成方法能有效提高函数调用代理训练数据的多样性和模型性能，特别是在分布外场景下表现优异。

Abstract: The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \texttt{city\_name}, \texttt{stock\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.

</details>


### [52] [EFT-CoT: A Multi-Agent Chain-of-Thought Framework for Emotion-Focused Therapy](https://arxiv.org/abs/2601.17842)
*Lanqing Du,Yunong Li,YuJie Long,Shihong Chen*

Main category: cs.CL

TL;DR: 提出基于情绪聚焦疗法(EFT)的多智能体思维链框架(EFT-CoT)，通过"自下而上"的三阶段推理流程提升心理健康问答效果，并构建专门数据集和模型EFT-LLM


<details>
  <summary>Details</summary>
Motivation: 现有基于认知行为疗法(CBT)的心理健康问答方法主要采用"自上而下"的理性重构，忽视了来访者的具身体验和初级情绪处理，需要更关注情绪体验的方法

Method: 提出EFT-CoT框架，采用"自下而上"的三阶段推理流程：具身感知-认知探索-叙事干预，使用8个专门智能体执行躯体意识映射、适应性评估、核心信念提取和叙事重构等关键组件

Result: 构建了包含约67,000条真实文本的高质量数据集EFT-Instruct，并微调了专门模型EFT-LLM。实验表明EFT-LLM在共情深度和结构专业性等指标上优于基线模型和人类响应

Conclusion: EFT-CoT框架通过多智能体机制实现了优越的心理推理能力，为可解释、高共情的心理咨询系统提供了有效途径，消融研究证实了多智能体机制的必要性

Abstract: Leveraging Large Language Models (LLMs) for Mental Health Question Answering (MHQA) is promising for mitigating resource shortages. However, existing Cognitive Behavioral Therapy (CBT)-based approaches predominantly favor a "top-down" rational restructuring, often neglecting clients' embodied experiences and primary emotion processing. To address this, we propose an Emotion-Focused Therapy (EFT)-based Multi-Agent Chain-of-Thought framework (EFT-CoT). Adopting a "bottom-up" trajectory, it deconstructs the intervention into a three-stage reasoning flow: "Embodied Perception - Cognitive Exploration - Narrative Intervention." Utilizing eight specialized agents, the system explicitly executes critical components such as somatic awareness mapping, adaptive assessment, core belief extraction, and narrative restructuring. We further constructed "EFT-Instruct," a high-quality dataset via Chain-of-Thought distillation of approximately 67,000 authentic texts, and fine-tuned a specialized model, EFT-LLM. Experimental evaluations demonstrate that EFT-LLM outperforms strong baselines and human responses across metrics like empathy depth and structural professionalism. Ablation studies confirm the necessity of the multi-agent mechanism. The model exhibits superior psychological reasoning, offering an effective pathway for interpretable, high-empathy counseling systems.

</details>


### [53] [D-Models and E-Models: Diversity-Stability Trade-offs in the Sampling Behavior of Large Language Models](https://arxiv.org/abs/2601.17865)
*Jia Gu,Liang Pang,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 研究发现LLMs在细粒度采样概率上存在两种类型：D-模型（如Qwen-2.5）的token概率变化大且与任务分布对齐差，E-模型（如Mistral-Small）的token概率更稳定且与任务分布对齐更好，这影响了代码生成和推荐等下游任务中多样性与稳定性的权衡。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs能生成近似真实世界分布的样本，但其细粒度采样概率是否忠实对齐任务需求仍是一个开放问题。需要探究LLMs的token预测概率与任务级目标分布之间的关系，以及这对下游应用的影响。

Method: 通过受控分布采样模拟，识别出两种模型类型：D-模型和E-模型。进一步在代码生成和推荐等下游任务中评估这两种模型类型，并分析它们的内在属性以探究底层机制。

Result: 发现D-模型的P_token具有较大的步间变异性且与P_task对齐差，而E-模型的P_token更稳定且与P_task对齐更好。在下游任务中，两种模型类型展现出多样性与稳定性之间的系统性权衡。

Conclusion: 研究为LLMs的概率采样行为提供了基础性见解，并为何时选择D-模型或E-模型提供了实践指导。对于推荐、搜索和对话代理等网络规模应用，结果可指导模型选择和配置，以在现实世界不确定性下平衡多样性与可靠性。

Abstract: The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.

</details>


### [54] [On the Emergence and Test-Time Use of Structural Information in Large Language Models](https://arxiv.org/abs/2601.17869)
*Michelle Chao Chen,Moritz Miller,Bernhard Schölkopf,Siyuan Guo*

Main category: cs.CL

TL;DR: 语言模型学习抽象结构信息的能力与复杂推理任务相关，但测试时组合生成能力有限


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何从观察数据中学习抽象结构信息，这对于科学发现中的机制理解和测试时的灵活组合生成至关重要

Method: 设计基于语言结构转换的自然语言数据集，在受控设置下研究语言模型学习抽象结构的能力

Result: 学习结构信息的出现与复杂推理任务相关，但模型在测试时进行组合生成的能力仍然有限

Conclusion: 语言模型能够学习抽象结构信息，但需要进一步研究如何提升测试时的组合生成能力

Abstract: Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.

</details>


### [55] [Self-Manager: Parallel Agent Loop for Long-form Deep Research](https://arxiv.org/abs/2601.17879)
*Yilong Xu,Zhi Zheng,Xiang Long,Yujun Cai,Yiwei Wang*

Main category: cs.CL

TL;DR: Self-Manager：一种并行代理循环框架，通过多线程异步并发执行解决长深度研究中单上下文窗口和顺序执行的限制


<details>
  <summary>Details</summary>
Motivation: 现有代理在处理长深度研究任务时，虽然通过子任务级上下文管理克服了线性上下文积累和信息丢失问题，但仍受限于单一上下文窗口和顺序执行范式，导致相互干扰和阻塞行为，限制了可扩展性和适应性

Method: 提出Self-Manager并行代理循环框架：主线程可创建多个子线程，每个子线程拥有独立的隔离上下文，通过线程控制块进行迭代管理，实现更专注、灵活的并行代理执行

Result: 在DeepResearch Bench基准测试中，Self-Manager在所有指标上持续优于现有的单代理循环基线；扩展分析实验证明了其设计选择的必要性，以及在上下文容量、效率和泛化能力方面的优势

Conclusion: Self-Manager通过并行代理循环设计有效解决了长深度研究中的可扩展性和适应性问题，为复杂研究任务提供了更高效、灵活的解决方案

Abstract: Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.

</details>


### [56] [Assessment of Generative Named Entity Recognition in the Era of Large Language Models](https://arxiv.org/abs/2601.17898)
*Qi Zhan,Yile Wang,Hui Huang*

Main category: cs.CL

TL;DR: 本文系统评估了开源大语言模型在平面和嵌套命名实体识别任务上的表现，发现通过参数高效微调和结构化输出格式，LLMs能达到与传统编码器模型竞争的性能，其NER能力源于指令跟随和生成能力而非记忆，且NER微调对模型通用能力影响很小。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，命名实体识别正从序列标注任务转向生成范式。本文旨在系统评估开源LLMs在平面和嵌套NER任务上的表现，研究生成式NER与传统NER模型的性能差距、输出格式的影响、LLMs是否依赖记忆、以及微调后通用能力的保持等问题。

Method: 对八个不同规模的LLMs在四个标准NER数据集上进行实验，采用参数高效微调方法，比较不同输出格式（如内联括号或XML格式），分析LLMs的NER能力来源，并评估NER指令微调对模型通用能力的影响。

Result: 研究发现：(1) 通过参数高效微调和结构化输出格式，开源LLMs能达到与传统编码器模型竞争的性能，甚至超过GPT-3等闭源模型；(2) LLMs的NER能力源于指令跟随和生成能力，而非简单的实体-标签对记忆；(3) NER指令微调对LLMs的通用能力影响很小，甚至因增强实体理解而提升了在DROP等数据集上的表现。

Conclusion: 生成式NER与LLMs结合是传统NER方法的有前景且用户友好的替代方案。开源LLMs通过适当的微调和输出格式设计，能够在NER任务上取得优异表现，同时保持其通用能力。

Abstract: Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.

</details>


### [57] [ShapLoRA: Allocation of Low-rank Adaption on Large Language Models via Shapley Value Inspired Importance Estimation](https://arxiv.org/abs/2601.17921)
*Yi Zhao,Qinghua Yao,Xinyuan song,Wei Zhu*

Main category: cs.CL

TL;DR: ShapLoRA：基于Shapley值的可解释性LoRA秩分配方法，通过结合敏感度度量和协作博弈思想，提出Shapley敏感度指标，优化了LoRA秩分配流程，在多种任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA秩分配方法依赖于不可解释且不可靠的重要性度量指标，这限制了参数高效微调的性能提升。需要一种更可解释、更可靠的秩分配方法来优化大型语言模型的微调效果。

Method: 提出ShapLoRA框架：1）受可解释归因度量Shapley值启发，结合敏感度度量和LoRA秩间协作博弈思想，提出Shapley敏感度这一更可解释的重要性度量；2）优化工作流程：在单独验证集上计算Shapley敏感度，建立分配-重训练流程以确保公平比较。

Result: 在多种挑战性任务上的实验结果表明，ShapLoRA方法在可调参数数量相当的情况下，能够超越现有基线方法，表现出更好的性能。

Conclusion: ShapLoRA通过引入基于Shapley值的可解释重要性度量，解决了现有LoRA秩分配方法的局限性，为参数高效微调提供了更可靠、更有效的秩分配策略，有助于推动大型语言模型的民主化应用。

Abstract: Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.

</details>


### [58] [A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models](https://arxiv.org/abs/2601.17952)
*Michail Mamalakis,Tiago Azevedo,Cristian Cosentino,Chiara D'Ercoli,Subati Abulikemu,Zhongtian Sun,Richard Bethlehem,Pietro Lio*

Main category: cs.CL

TL;DR: 提出统一可解释性框架，结合归因和机制视角，通过单义特征提取减少方法间变异，为LLM在阿尔茨海默病诊断中提供稳定重要性评分。


<details>
  <summary>Details</summary>
Motivation: LLM在临床环境（如阿尔茨海默病进展诊断）中部署面临可解释性挑战，现有归因方法存在高方法间变异和不稳定解释，而机制可解释性方法缺乏与模型输入输出的直接对齐且不提供明确重要性评分。

Method: 通过单义特征提取整合归因和机制视角，在LLM层级别构建单义嵌入空间，优化框架以显式减少方法间变异，产生稳定输入级重要性评分，并通过感兴趣层的解压缩表示突出显著特征。

Result: 该方法能产生稳定的输入级重要性评分，通过解压缩表示突出显著特征，推进LLM在认知健康和神经退行性疾病中的安全可信应用。

Conclusion: 提出的统一可解释性框架通过整合归因和机制视角，解决了LLM在临床应用中可解释性不足的问题，为阿尔茨海默病等神经退行性疾病的早期诊断提供了更可靠的可解释工具。

Abstract: Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.

</details>


### [59] [LLMs as Cultural Archives: Cultural Commonsense Knowledge Graph Extraction](https://arxiv.org/abs/2601.17971)
*Junior Cedric Tonga,Chen Cecilia Liu,Iryna Gurevych,Fajri Koto*

Main category: cs.CL

TL;DR: 提出一个基于提示的迭代框架，从大语言模型中提取文化常识知识，构建多语言文化常识知识图谱，并评估其在文化推理和故事生成中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型编码了丰富的文化知识，但这些知识大多是隐式和非结构化的，限制了其可解释性和实际应用。需要系统性地提取和结构化这些文化常识知识。

Method: 采用迭代的基于提示的框架，将LLMs视为文化档案库，系统地提取文化特定实体、关系和实践，并将其组合成跨语言的多步推理链，构建文化常识知识图谱。

Result: 评估了五个国家的文化知识图谱，发现英语实现效果最好，即使目标文化是非英语的（如中文、印尼语、阿拉伯语），表明当前LLMs中的文化编码不均衡。用CCKG增强较小LLMs可提高文化推理和故事生成性能，英语链带来的提升最大。

Conclusion: 研究显示了LLMs作为文化技术的潜力和局限性，链式结构化的文化知识是文化基础NLP的实用基础，为跨文化理解和应用提供了结构化知识资源。

Abstract: Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.

</details>


### [60] [SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets](https://arxiv.org/abs/2601.17982)
*Kshitij Mishra,Nils Lukas,Salem Lahlou*

Main category: cs.CL

TL;DR: SD-E²是一个强化学习框架，通过优化语义多样性来提升小语言模型的复杂推理能力，在多个数学和医学推理基准上显著超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 小语言模型在有限计算预算下难以进行有效的探索，导致复杂推理能力不足。需要一种更高效的探索-利用机制来提升推理能力。

Method: 提出SD-E²框架，使用冻结的句子嵌入模型计算语义多样性奖励，捕捉不同解决策略的覆盖度和平均成对差异。将多样性奖励与结果正确性和解决方案效率结合，通过z-score归一化的多目标目标稳定训练。

Result: 在GSM8K上超越基础模型27.4个百分点，每个问题平均发现9.8个语义不同的策略。MedMCQA提升至49.64%（基础模型38.37%），AIME基准达到13.28%（基础模型6.74%）。

Conclusion: 奖励语义新颖性为训练推理能力强的小语言模型提供了更高效的计算探索-利用信号。通过认知适应调整推理过程结构，为资源受限模型提供了补充的效率提升路径。

Abstract: Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.

</details>


### [61] [AI-based approach to burnout identification from textual data](https://arxiv.org/abs/2601.17993)
*Marina Zavertiaeva,Petr Parshakov,Mikhail Usanin,Aleksei Smirnov,Sofia Paklina,Anastasiia Kibardina*

Main category: cs.CL

TL;DR: 基于RuBERT模型的AI方法，通过NLP从文本数据中检测职业倦怠，结合ChatGPT生成的合成句子和YouTube用户评论进行微调


<details>
  <summary>Details</summary>
Motivation: 开发一种能够从文本数据中自动检测职业倦怠的AI方法，用于监测高压工作环境中的倦怠相关语言信号

Method: 使用原本用于情感分析的RuBERT模型，通过ChatGPT生成的合成句子和俄罗斯YouTube视频中关于倦怠的用户评论进行微调，构建倦怠检测模型

Result: 开发出能够为输入文本分配倦怠概率的模型，可应用于处理大量书面通信，监测高压工作环境中的倦怠语言信号

Conclusion: 提出的AI方法能够有效从文本中检测职业倦怠，为组织监测员工心理健康提供了可行的技术解决方案

Abstract: This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.

</details>


### [62] [PEAR: Pairwise Evaluation for Automatic Relative Scoring in Machine Translation](https://arxiv.org/abs/2601.18006)
*Lorenzo Proietti,Roman Grundkiewicz,Matt Post*

Main category: cs.CL

TL;DR: PEAR是一个基于成对比较的机器翻译质量评估指标，通过预测两个候选翻译的质量差异方向和幅度来评估翻译质量，在WMT24基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译质量评估指标通常基于单个候选翻译进行评估，缺乏对翻译质量相对差异的精确度量。作者希望开发一种能够直接比较两个翻译质量差异的评估方法。

Method: PEAR将无参考机器翻译评估重构为分级成对比较任务，给定源文本和两个候选翻译，预测它们的质量差异方向和幅度。使用从人工判断差异中导出的成对监督进行训练，并加入候选顺序反转时符号反转的正则化项。

Result: 在WMT24元评估基准上，PEAR优于使用相同数据和骨干网络的单候选质量评估基线。尽管参数数量远少于近期大型指标，PEAR超越了更大的质量评估模型和基于参考的指标。分析表明PEAR产生更冗余的评估信号。

Conclusion: PEAR通过成对比较框架有效提升了机器翻译质量评估性能，参数效率高，评估信号冗余度低，并且可作为最小贝叶斯风险解码的有效效用函数，显著降低成对评分成本。

Abstract: We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.

</details>


### [63] [Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems](https://arxiv.org/abs/2601.18012)
*Hendrika Maclean,Mert Can Cakmak,Muzakkiruddin Ahmed Mohammed,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 研究评估大语言模型在精确数值计算和可审计输出方面的可靠性，以薪资系统为案例，发现某些情况下仔细提示足够，但复杂情况需要显式计算。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在日常写作、搜索和分析中广泛应用且自然语言理解能力不断提升，但在精确数值计算和生成易于审计的输出方面仍然不可靠。研究者希望通过薪资系统这一具体、高风险的应用场景来评估模型的可靠性。

Method: 研究采用分层数据集（从基础到复杂案例）、多种提示策略（从最小基线到模式引导和推理变体），并测试多个模型家族（GPT、Claude、Perplexity、Grok和Gemini），评估模型理解薪资模式、按正确顺序应用规则和提供分位精度结果的能力。

Result: 结果表明存在明确的机制：在某些情况下仔细的提示就足够，而在其他情况下需要显式计算。研究提供了可复现的紧凑框架。

Conclusion: 该研究为在要求准确性和保证性的场景中部署大语言模型提供了实用的指导，强调了在某些情况下需要显式计算来确保可靠性。

Abstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.

</details>


### [64] [A System for Name and Address Parsing with Large Language Models](https://arxiv.org/abs/2601.18014)
*Adeeba Tarannum,Muzakkiruddin Ahmed Mohammed,Mert Can Cakmak,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 提出一个结合提示工程与确定性验证的框架，用于将非结构化人员地址文本转换为结构化数据，无需微调即可实现高精度、可复现的提取。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则和概率的方法在干净输入上表现良好，但在噪声或多语言条件下失效；神经模型和大型语言模型缺乏确定性控制和可复现性。需要一种既能处理复杂输入又能保证可靠性的结构化信息提取方法。

Method: 采用提示驱动、验证中心的框架，包含输入标准化、结构化提示、约束解码和严格的基于规则验证，在固定实验设置下确保可复现性，无需微调即可将自由文本转换为17字段模式。

Result: 在异构真实地址数据上的评估显示高字段级准确率、强模式遵循性和稳定的置信度校准，表明该方法在结构化信息提取中具有鲁棒性。

Conclusion: 结合确定性验证与生成提示为结构化信息提取提供了鲁棒、可解释且可扩展的解决方案，是训练密集型或领域特定模型的实用替代方案。

Abstract: Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.

</details>


### [65] [CommonLID: Re-evaluating State-of-the-Art Language Identification Performance on Web Data](https://arxiv.org/abs/2601.18026)
*Pedro Ortiz Suarez,Laurie Burchell,Catherine Arnett,Rafael Mosquera-Gómez,Sara Hincapie-Monsalve,Thom Vaughan,Damian Stewart,Malte Ostendorff,Idris Abdulmumin,Vukosi Marivate,Shamsuddeen Hassan Muhammad,Atnafu Lambebo Tonja,Hend Al-Khalifa,Nadia Ghezaiel Hammouda,Verrah Otiende,Tack Hwa Wong,Jakhongir Saydaliev,Melika Nobakhtian,Muhammad Ravi Shulthan Habibi,Chalamalasetti Kranti,Carol Muchemi,Khang Nguyen,Faisal Muhammad Adam,Luis Frentzen Salim,Reem Alqifari,Cynthia Amol,Joseph Marvin Imperial,Ilker Kesen,Ahmad Mustafid,Pavel Stepachev,Leshem Choshen,David Anugraha,Hamada Nayel,Seid Muhie Yimam,Vallerie Alexandra Putra,My Chiffon Nguyen,Azmine Toushik Wasi,Gouthami Vadithya,Rob van der Goot,Lanwenn ar C'horr,Karan Dua,Andrew Yates,Mithil Bangera,Yeshil Bangera,Hitesh Laxmichand Patel,Shu Okabe,Fenal Ashokbhai Ilasariya,Dmitry Gaynullin,Genta Indra Winata,Yiyuan Li,Juan Pablo Martínez,Amit Agarwal,Ikhlasul Akmal Hanif,Raia Abu Ahmad,Esther Adenuga,Filbert Aurelian Tjiaranata,Weerayut Buaphet,Michael Anugraha,Sowmya Vajjala,Benjamin Rice,Azril Hafizi Amirudin,Jesujoba O. Alabi,Srikant Panda,Yassine Toughrai,Bruhan Kyomuhendo,Daniel Ruffinelli,Akshata A,Manuel Goulão,Ej Zhou,Ingrid Gabriela Franco Ramirez,Cristina Aggazzotti,Konstantin Dobler,Jun Kevin,Quentin Pagès,Nicholas Andrews,Nuhu Ibrahim,Mattes Ruckdeschel,Amr Keleg,Mike Zhang,Casper Muziri,Saron Samuel,Sotaro Takeshita,Kun Kerdthaisong,Luca Foppiano,Rasul Dent,Tommaso Green,Ahmad Mustapha Wali,Kamohelo Makaaka,Vicky Feliren,Inshirah Idris,Hande Celikkanat,Abdulhamid Abubakar,Jean Maillard,Benoît Sagot,Thibault Clérice,Kenton Murray,Sarah Luger*

Main category: cs.CL

TL;DR: CommonLID是一个社区驱动、人工标注的语言识别基准数据集，覆盖109种语言，专注于网络领域文本，旨在解决现有语言识别模型在嘈杂异构网络数据上表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 语言识别是构建多语言语料库的基础步骤，但现有模型在许多语言上表现不佳，特别是在用于训练多语言模型的嘈杂异构网络数据上。许多语言在现有评估中被忽视，需要更具代表性的高质量评估资源。

Method: 创建CommonLID基准数据集，包含109种语言的社区驱动、人工标注的网络领域文本。使用该数据集与另外五个常见评估集，测试八个流行的语言识别模型，分析结果以了解当前技术状态。

Result: 研究发现现有评估高估了许多语言在网络领域的识别准确率。CommonLID揭示了语言识别模型在实际网络数据上的真实性能，为开发更高质量的多语言语料库提供了关键资源。

Conclusion: CommonLID填补了语言识别评估的重要空白，特别是针对网络领域和先前被忽视的语言。该数据集在开放许可下发布，有助于推动更公平、更准确的语言识别技术发展。

Abstract: Language identification (LID) is a fundamental step in curating multilingual corpora. However, LID models still perform poorly for many languages, especially on the noisy and heterogeneous web data often used to train multilingual language models. In this paper, we introduce CommonLID, a community-driven, human-annotated LID benchmark for the web domain, covering 109 languages. Many of the included languages have been previously under-served, making CommonLID a key resource for developing more representative high-quality text corpora. We show CommonLID's value by using it, alongside five other common evaluation sets, to test eight popular LID models. We analyse our results to situate our contribution and to provide an overview of the state of the art. In particular, we highlight that existing evaluations overestimate LID accuracy for many languages in the web domain. We make CommonLID and the code used to create it available under an open, permissive license.

</details>


### [66] [Addressing LLM Diversity by Infusing Random Concepts](https://arxiv.org/abs/2601.18053)
*Pulin Agrawal,Prasoon Goyal*

Main category: cs.CL

TL;DR: 在LLM提示中加入随机概念可以显著提高生成输出的多样性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通常生成多样性有限的输出，这限制了它们在需要创造性或多样化响应的应用中的潜力。研究旨在探索通过提示工程改善输出多样性的方法。

Method: 设计了一个系统评估协议，通过在提示前添加与问题无关的随机单词或句子（如"Name 10 Hollywood actors"前加入随机概念），然后分析LLM输出的多样性指标。在多个LLM上进行实验验证。

Result: 实验表明，在提示前添加不相关的随机单词/句子能显著提高LLM输出的多样性。这一结果在多个LLM上得到验证。

Conclusion: 在提示中注入随机性是提高LLM输出多样性的有效方法。该研究不仅提出了有前景的技术方向，还建立了系统评估协议，为未来LLM多样性基准测试和其他领域的随机性应用研究开辟了新途径。

Abstract: Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form "Name 10 Hollywood actors", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.

</details>


### [67] [Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production](https://arxiv.org/abs/2601.18056)
*Ahmet Yavuz Uluslu,Elliot Murphy*

Main category: cs.CL

TL;DR: 该论文主张在双语产出错误研究中加入振荡信号分析，并提出ROSE神经模型能为双语语法迁移提供神经计算解释，特别以跨语言影响为案例，将其视为L2句子规划中的特定振荡失败模式。


<details>
  <summary>Details</summary>
Motivation: 传统双语研究主要关注事件相关电位等时间特征，但振荡信号能提供新的实施层面约束，为双语理论提供更丰富的神经计算基础。

Method: 采用ROSE神经语言模型，将跨语言影响和功能抑制/竞争理论重新解释为L2句子规划过程中的特定振荡失败模式。

Result: ROSE模型能够捕捉双语语法迁移的形式特性和形态句法序列失败模式的范围，为跨语言影响提供神经计算解释。

Conclusion: 这种建模方法不仅提供了ROSE模型旨在建立的连接假设，还允许探索比传统神经特征更复杂的时空生物标志物，为语言功能障碍研究开辟新途径。

Abstract: We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.

</details>


### [68] [Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models](https://arxiv.org/abs/2601.18065)
*Aryan Roy,Zekun Wang,Christopher J. MacLellan*

Main category: cs.CL

TL;DR: 研究比较了纯文本LLM与视觉-语言模型(VLM)对语言具体性的敏感度差异，发现VLM在多模态预训练后表现出更接近人类的具象化感知能力


<details>
  <summary>Details</summary>
Motivation: 探究视觉-语言模型(VLMs)是否比纯文本大语言模型(LLMs)发展出更接近人类的对语言具体性的敏感度，特别是在仅使用文本提示进行评估时

Method: 采用控制比较方法，匹配Llama文本主干及其Llama Vision对应模型，从三个层面测量具体性效应：输出行为（QA准确性与问题具体性关系）、嵌入几何（表示是否沿具体性轴组织）、注意力动态（通过注意力熵量化上下文依赖）

Result: 在所有基准测试和模型规模中，VLMs在更具体的输入上表现出更大的增益，具有更清晰的具体性结构化表示，产生的评分更符合人类规范，并显示出系统性的不同注意力模式，表明增加了基础性

Conclusion: 多模态训练使模型发展出更接近人类的语言具体性感知能力，即使仅使用文本提示，视觉-语言模型也比纯文本模型表现出更强的具象化基础

Abstract: Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.

</details>


### [69] [Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents](https://arxiv.org/abs/2601.18077)
*Mahesh Ramesh,Kaousheik Jayakumar,Aswinkumar Ramkumar,Pavan Thodima,Aniket Rege*

Main category: cs.CL

TL;DR: 论文评估了17个LLM代理在Hanabi游戏中的表现，通过不同上下文工程方法提升推理能力，并发布首个公开数据集用于微调，显著提升了协作推理性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决不完全信息下的协作推理挑战，特别是在Hanabi游戏中需要心智理论和策略性沟通。当前LLM代理在此类任务中表现不佳，需要系统评估和改进方法。

Method: 方法包括：1）在2-5人游戏中评估17个最先进的LLM代理；2）设计三种上下文工程设置（Watson、Sherlock、Mycroft）；3）创建两个公开数据集（HanabiLogs和HanabiRewards）；4）对4B模型进行监督和RL微调。

Result: 结果显示：1）最强推理模型在Sherlock设置下平均得分超过15分；2）微调使协作Hanabi游戏性能分别提升21%和156%；3）RL微调模型在多个基准测试中表现出良好的泛化能力。

Conclusion: 结论表明上下文工程和特定领域微调能显著提升LLM在不完全信息协作推理中的表现，但仍落后于人类专家。公开数据集为未来研究提供了宝贵资源。

Abstract: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.

</details>


### [70] [CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations](https://arxiv.org/abs/2601.18102)
*Stephanie Fong,Zimu Wang,Guilherme C. Oliveira,Xiangyu Zhao,Yiwen Jiang,Jiahe Liu,Beau-Luke Colton,Scott Woods,Martha E. Shenton,Barnaby Nelson,Zongyuan Ge,Dominic Dwyer*

Main category: cs.CL

TL;DR: CHiRPE是一个临床NLP管道，通过转录的半结构化临床访谈预测精神病风险，并生成与临床医生共同开发的新型SHAP解释格式，实现了超过90%的准确率。


<details>
  <summary>Details</summary>
Motivation: 医疗领域采用NLP工具需要最终用户的可解释性，但传统的可解释AI方法与临床推理不匹配且缺乏临床医生参与。

Method: 开发CHiRPE管道：整合症状域映射、LLM摘要和BERT分类，使用944份半结构化访谈转录数据进行训练，并与临床医生共同开发新型SHAP解释格式。

Result: CHiRPE在三个BERT变体上均达到超过90%的准确率，优于基线模型。28位临床专家评估显示，他们强烈偏好新型概念引导的解释格式，特别是混合图-文摘要格式。

Conclusion: 临床指导的模型开发能够产生准确且可解释的结果。下一步将在24个国际站点进行真实世界测试。

Abstract: The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.

</details>


### [71] [GLEN-Bench: A Graph-Language based Benchmark for Nutritional Health](https://arxiv.org/abs/2601.18106)
*Jiatan Huang,Zheyuan Zhang,Tianyi Ma,Mingchen Li,Yaning Zheng,Yanfang Ye,Chuxu Zhang*

Main category: cs.CL

TL;DR: GLEN-Bench：首个基于图语言模型的营养健康评估基准，整合多源数据构建知识图谱，针对阿片类药物使用障碍等慢性病，提供风险检测、个性化推荐和解释性问答三个关联任务。


<details>
  <summary>Details</summary>
Motivation: 当前营养干预计算方法存在三大局限：忽视社会经济等现实约束、缺乏解释性、缺少统一评估基准。需要开发能综合考虑患者约束条件、提供可解释建议的个性化营养干预系统。

Method: 整合NHANES健康记录、FNDDS食物成分数据和USDA食物获取指标，构建连接人口统计、健康状况、饮食行为、贫困约束和营养需求的知识图谱。针对阿片类药物使用障碍，设计风险检测、个性化推荐和问答解释三个关联任务，评估图神经网络、大语言模型和混合架构。

Result: 建立了GLEN-Bench基准，能够检测疾病不同阶段的细微营养差异，识别与健康风险相关的明确饮食模式，为实际干预提供指导。评估了多种图语言方法，建立了可靠的基线。

Conclusion: GLEN-Bench填补了营养健康评估领域的空白，通过整合多源数据和设计关联任务，为开发考虑现实约束、提供可解释建议的个性化营养干预系统提供了重要基础。

Abstract: Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions.

</details>


### [72] [FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning](https://arxiv.org/abs/2601.18116)
*Lin Sun,Linglin Zhang,Jingang Huang,Change Jia,Zhengwei Cheng,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: FABLE是一个森林结构的自适应双路径检索增强框架，通过LLM增强的层次索引和双路径检索策略，在保持高准确性的同时大幅减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 尽管长上下文LLM快速发展，但仍存在"中间丢失"现象、高计算成本和多文档推理扩展性差等问题。传统RAG系统受限于平面块级检索，引入语义噪声且不支持结构化跨文档合成。

Method: FABLE构建LLM增强的层次森林索引，采用双路径策略：LLM引导的层次遍历和结构感知传播，结合显式预算控制实现自适应效率权衡。

Result: 实验表明FABLE持续优于SOTA RAG方法，在达到与完整上下文LLM推理相当准确性的同时，减少高达94%的token使用量。

Conclusion: 长上下文LLM放大了而非完全替代结构化检索的需求，FABLE展示了LLM增强检索框架的有效性。

Abstract: The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.
  We present \textbf{FABLE}, a \textbf{F}orest-based \textbf{A}daptive \textbf{B}i-path \textbf{L}LM-\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.
  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.

</details>


### [73] [Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models](https://arxiv.org/abs/2601.18129)
*Kunat Pipatanakul,Pittawat Taveekitworachai*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Typhoon S的最小化开放后训练方法，用于在有限资源下开发主权LLM，以泰语为案例研究证明了该方法能有效提升模型在本地语言和文化任务上的能力。


<details>
  <summary>Details</summary>
Motivation: 当前主流LLM主要针对英语和中文等高资源语言，由少数拥有大规模计算和数据的组织开发，这为主权环境（如区域或国家机构）带来了实际障碍。这些环境需要在有限资源和严格透明度约束下保持对模型权重、训练数据和部署的控制与理解。

Method: 提出了Typhoon S方法，这是一种最小化开放后训练方案，结合了监督微调、策略蒸馏和小规模强化微调。特别引入了InK-GRPO，在GRPO损失基础上增加了下一个词预测损失，以提升特定任务能力同时保持通用性能。

Result: 以泰语为案例研究表明，该方法能将主权适应和通用基础模型转化为具有强大通用性能的指令调优模型。小规模RFT配合InK-GRPO能显著提升泰语法律推理和泰国特定知识能力，同时保持通用能力。

Conclusion: 精心设计的后训练策略可以减少指令数据和计算所需规模，为在学术规模资源下开发高质量主权LLM提供了实用路径，有助于解决主权环境下的LLM开发障碍。

Abstract: Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.

</details>


### [74] [Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models](https://arxiv.org/abs/2601.18162)
*Ani Harutyunyan,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文在GoEmotions数据集上对比了三种细粒度情感识别模型：基于TF-IDF的逻辑回归、带注意力的BiLSTM和微调的BERT模型。逻辑回归在Micro-F1上表现最佳（0.51），而BERT在整体平衡性上最优，超越了原论文报告的结果。


<details>
  <summary>Details</summary>
Motivation: 细粒度情感识别是一个具有挑战性的多标签NLP任务，面临标签重叠和类别不平衡的问题。本文旨在通过系统性地比较不同建模方法在GoEmotions数据集上的表现，探索最适合处理此类问题的技术方案。

Method: 使用GoEmotions数据集的官方训练/验证/测试划分，比较三种建模方法：1) 基于TF-IDF并使用二元相关性训练的逻辑回归系统；2) 带注意力的BiLSTM模型；3) 为多标签分类微调的BERT模型。采用逆频率类别权重来缓解类别不平衡问题。

Result: 逻辑回归在Micro-F1上达到最高值0.51，而BERT在整体平衡性上表现最佳，超越了原论文报告的结果，达到Macro-F1 0.49、Hamming Loss 0.036和Subset Accuracy 0.36。这表明高频情感通常依赖于表面词汇线索，而上下文表示能改善对稀有情感和更模糊示例的性能。

Conclusion: 不同建模方法在细粒度情感识别任务中各有优势：逻辑回归在处理高频情感时表现良好，而BERT的上下文表示能力使其在整体平衡性和处理稀有情感方面更优。这为实际应用中选择合适模型提供了指导。

Abstract: Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.

</details>


### [75] [MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning](https://arxiv.org/abs/2601.18204)
*Juexiang Ye,Xue Li,Xinyu Yang,Chengkai Huang,Lanshun Nie,Lina Yao,Dechen Zhan*

Main category: cs.CL

TL;DR: MemWeaver：统一记忆框架，通过结构化图记忆、经验记忆和文本证据记忆三组件，结合双通道检索策略，显著提升长时程智能体交互中的多跳推理和时间一致性，同时大幅减少上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的智能体在长时程交互中，记忆系统主要依赖非结构化检索或粗粒度抽象，导致时间冲突、推理脆弱和可追溯性有限的问题。需要一种能支持时间一致性、多跳推理和跨会话证据重用的记忆系统。

Method: 提出MemWeaver统一记忆框架，包含三个互连组件：1）时间基础图记忆用于结构化关系推理；2）经验记忆从重复观察中抽象出交互模式；3）文本证据记忆保留原始文本证据。采用双通道检索策略，联合检索结构化知识和支持证据，构建紧凑而信息密集的推理上下文。

Result: 在LoCoMo基准测试中，MemWeaver显著提高了多跳推理和时间推理的准确性，同时相比长上下文基线减少了超过95%的输入上下文长度。

Conclusion: MemWeaver通过结构化记忆组件和双通道检索策略，有效解决了长时程智能体交互中的记忆管理问题，在保持高推理准确性的同时大幅降低了计算开销。

Abstract: Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\% compared to long-context baselines.

</details>


### [76] [TechING: Towards Real World Technical Image Understanding via VLMs](https://arxiv.org/abs/2601.18238)
*Tafazzul Nadeem,Bhavik Shangari,Manish Rai,Gagan Raj Gupta,Ashutosh Modi*

Main category: cs.CL

TL;DR: 该论文提出使用合成生成的技术图表数据集训练视觉语言模型，以解决现有模型在理解手绘技术图表方面的不足，并通过人类评估验证了模型在实际手绘图像上的有效性。


<details>
  <summary>Details</summary>
Motivation: 专业人员在技术讨论中常手绘技术图表（如流程图、框图等），但现有视觉语言模型难以理解这些手绘技术图表。虽然可以通过真实手绘图像进行微调，但获取大量此类图像不现实。

Method: 1. 引入大规模合成生成的技术图表数据集（反映真实世界图像特征）；2. 提出多个新的自监督任务进行训练；3. 在合成图像上对Llama 3.2 11B-instruct模型进行微调，得到LLama-VL-TUG模型。

Result: LLama-VL-TUG将Llama 3.2 11B-instruct的ROUGE-L性能提升了2.14倍，在所有基线模型中表现最佳。在真实手绘图像上，人类评估显示在8种图表类型中的7种实现了最少编译错误，并将平均F1分数提升了6.97倍。

Conclusion: 通过合成数据集训练视觉语言模型能有效提升对手绘技术图表的理解能力，为解决实际应用中编辑手绘技术图表的问题提供了可行方案。

Abstract: Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.

</details>


### [77] [BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation](https://arxiv.org/abs/2601.18253)
*Peng Sun,Xiangyu Zhang,Duan Wu*

Main category: cs.CL

TL;DR: BoRP是一个基于LLM潜在空间几何特性的可扩展满意度评估框架，通过自举机制自动生成评估标准，使用偏最小二乘法将隐藏状态映射到连续分数，显著优于生成式基线且大幅降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 对话AI的迭代开发需要准确评估用户满意度，但传统A/B测试缺乏可靠指标：显式反馈稀疏，隐式指标模糊。需要填补这一空白。

Method: BoRP利用LLM潜在空间的几何特性，采用基于极化指数的自举机制自动生成评估标准，使用偏最小二乘法（PLS）将隐藏状态映射到连续满意度分数。

Result: 在工业数据集上的实验表明，BoRP（Qwen3-8B/14B）在与人判断的一致性方面显著优于生成式基线（甚至优于Qwen3-Max），同时推理成本降低了数个数量级。

Conclusion: BoRP为开放域对话助手提供了高保真、可扩展的满意度评估框架，支持全规模监控和通过CUPED实现的高灵敏度A/B测试。

Abstract: Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.

</details>


### [78] [Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue](https://arxiv.org/abs/2601.18281)
*Yuhang Jia,Pei Liu,Haoqin Sun,Jiaming Zhou,Xuxin Cheng,Cao Liu,Ke Zeng,Xunliang Cai,Yong Qin*

Main category: cs.CL

TL;DR: 提出ReEmpathy模型，通过自我反思交替推理机制增强端到端口语模型的共情对话能力，使用描述性语言评估而非刚性监督信号。


<details>
  <summary>Details</summary>
Motivation: 当前端到端口语模型的共情对话研究过度依赖刚性监督信号（如真实回复或偏好分数），无法充分捕捉复杂共情表达的细微差别，因为不存在单一"正确"回复，简单数值分数难以全面评估情感表达和共情行为的适当性。

Method: 1. 提出EmpathyEval：基于描述性自然语言的评估模型，用于评估口语对话中的共情质量；2. 提出ReEmpathy：端到端口语模型，采用共情自我反思交替推理机制，交替进行口语回复生成和自由形式的共情相关反思推理。

Result: 实验表明ReEmpathy显著提升了共情敏感的口语对话能力，通过启用反思推理机制，为更具情感智能和共情意识的人机交互提供了有前景的方法。

Conclusion: ReEmpathy通过自我反思交替推理机制有效增强了口语模型的共情对话能力，突破了传统刚性监督信号的限制，为实现更自然、情感智能的人机交互提供了新方向。

Abstract: End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single "correct" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.

</details>


### [79] [U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents](https://arxiv.org/abs/2601.18285)
*Jin Su,Runnan Fang,Yeqiu Li,Xiaobin Wang,Shihao Cai,Pengjun Xie,Ningyu Zhang,Fajie Yuan*

Main category: cs.CL

TL;DR: U-Fold：针对用户中心对话的动态上下文折叠框架，解决现有方法在长对话中丢失细节和意图跟踪的问题


<details>
  <summary>Details</summary>
Motivation: 现有上下文折叠方法主要为单查询或单意图场景设计，在真实用户中心对话中存在两个主要问题：1) 不可逆地丢弃后续决策所需的细粒度约束和中间事实；2) 摘要无法跟踪演变的用户意图，导致遗漏和错误操作

Method: U-Fold框架保留完整的用户-代理对话和工具调用历史，在每个对话轮次使用两个核心组件：1) 意图感知的演化对话摘要；2) 紧凑的任务相关工具日志

Result: 在τ-bench、τ²-bench、VitaBench和更难的上下文膨胀设置中，U-Fold始终优于ReAct（在长上下文设置中达到71.4%胜率）和先前的折叠基线（提升高达27.0%），特别是在长、嘈杂、多轮任务上表现突出

Conclusion: U-Fold是将上下文管理技术从单查询基准转移到真实用户中心应用的有希望的一步，为LLM代理在工具增强环境中的可扩展性提供了有效解决方案

Abstract: Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.

</details>


### [80] [Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.18296)
*Zhaoyan Gong,Zhiqiang Liu,Songze Li,Xiaoke Guo,Yuanxiang Liu,Xinle Deng,Zhizhen Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: Temp-R1是首个通过强化学习训练的端到端自主TKGQA代理，通过扩展动作空间和反向课程学习，在复杂问题上实现了19.8%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法依赖固定工作流程和昂贵的闭源API，缺乏灵活性和可扩展性，无法有效处理动态事实的多跳依赖和复杂时间约束。

Method: 提出Temp-R1：1）扩展动作空间，包含专用内部动作和外部动作以应对单动作推理的认知过载；2）引入反向课程学习，先训练困难问题强制发展复杂推理能力，再迁移到简单案例。

Result: 8B参数的Temp-R1在MultiTQ和TimelineKGQA上达到最先进性能，在复杂问题上比强基线提升19.8%。

Conclusion: Temp-R1为自主时间推理代理建立了新范式，展示了强化学习在复杂TKGQA任务中的有效性。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.

</details>


### [81] [Suppressing Final Layer Hidden State Jumps in Transformer Pretraining](https://arxiv.org/abs/2601.18302)
*Keigo Shibata,Kazuki Yano,Ryosuke Takahashi,Jaesung Lee,Wataru Ikeda,Jun Suzuki*

Main category: cs.CL

TL;DR: 本文提出了一种抑制Transformer语言模型最后一层"跳跃"现象的跳变抑制正则化方法(JREG)，通过在预训练中惩罚最后一层的角度距离跳变，使中间层能力使用更均衡，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 许多预训练模型在中间Transformer层中，输入和输出隐藏状态向量的角度距离变化很小，但在最后一层附近会出现不成比例的"跳跃"。这种跳跃可能表明模型能力使用不均衡，最后一层承担了过多计算负担。

Method: 首先引入量化最后一层附近跳跃强度的指标，然后提出跳变抑制正则化方法(JREG)，在预训练过程中惩罚这种跳跃现象，鼓励模型更均衡地利用中间层的能力。

Result: 实验表明JREG方法在多个Llama模型规模上都有效，相比基线模型在不改变架构的情况下提升了任务性能，同时减少了最后一层的角度距离跳跃。

Conclusion: Transformer语言模型最后一层的角度距离跳跃是一种普遍现象，通过JREG正则化方法可以抑制这种跳跃，使模型能力分布更均衡，从而提升整体性能。

Abstract: This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.

</details>


### [82] [Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM](https://arxiv.org/abs/2601.18306)
*Everlyn Asiko Chimoto,Mostafa Elhoushi,Bruce A. Bassett*

Main category: cs.CL

TL;DR: 多语言校准显著提升LLM量化性能，英语校准集效果不佳，需根据目标语言定制校准数据


<details>
  <summary>Details</summary>
Motivation: 现有后训练量化方法主要使用英语校准集，对多语言模型的影响研究不足，需要探索多语言校准对量化性能的影响

Method: 系统评估8种校准设置（5种单语言和3种多语言混合）在2种量化器（GPTQ、AWQ）上，覆盖10种语言数据，分析激活范围分布差异

Result: 非英语和多语言校准集相比英语基线显著降低困惑度，多语言混合最大降低3.52点困惑度；针对评估语言定制校准集效果最佳；某些语言-量化器组合存在性能下降问题

Conclusion: 静态通用校准方法不理想，根据语言和多样性定制校准数据对多语言LLM稳健量化至关重要

Abstract: Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.

</details>


### [83] [MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization](https://arxiv.org/abs/2601.18320)
*Jinwei Lu,Yuanfeng Song,Chen Zhang,Raymond Chi-Wing Wong*

Main category: cs.CL

TL;DR: MultiVis-Agent：基于逻辑规则增强的多智能体框架，用于可靠的多模态可视化生成，通过数学约束保证系统可靠性，在复杂任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界可视化任务涉及复杂的多模态需求（参考图像、代码示例、迭代优化），而现有系统存在单模态输入、一次性生成、工作流程僵化等根本限制。LLM方法虽有潜力但存在可靠性问题（灾难性故障、无限循环风险）。

Method: 提出MultiVis-Agent框架：1）四层逻辑规则框架提供数学可靠性保证，逻辑规则作为数学约束指导LLM推理而非替代；2）多智能体协作处理从基础生成到迭代优化的四个场景；3）开发MultiVis-Bench基准（1000+案例）用于多模态可视化评估。

Result: 在挑战性任务中达到75.63%可视化分数，显著优于基线（57.54-62.79%）；任务完成率99.58%，代码执行成功率94.56%（无逻辑规则时分别为74.48%和65.10%），成功解决了自动可视化生成中的复杂性和可靠性挑战。

Conclusion: MultiVis-Agent通过逻辑规则增强的多智能体框架，在保持灵活性的同时提供数学可靠性保证，有效解决了多模态可视化生成中的复杂需求和可靠性问题，为自动化可视化系统提供了新的解决方案。

Abstract: Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.

</details>


### [84] [Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare](https://arxiv.org/abs/2601.18334)
*Clément Christophe,Wadood Mohammed Abdul,Prateek Munjal,Tathagata Raha,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: 论文提出一个评估LLM在临床环境中谄媚倾向的新框架，发现推理优化的"思考"模型虽然准确率高，但在权威压力下更容易合理化错误建议


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地集成到临床工作流程中，它们倾向于谄媚（优先考虑用户同意而非事实准确性）对患者安全构成重大风险。现有评估通常依赖主观数据集，需要更可靠的评估方法。

Method: 引入基于医学MCQA（多项选择题）的稳健框架，提出调整后的谄媚分数（Adjusted Sycophancy Score），通过考虑随机模型不稳定性（"混淆性"）来隔离对齐偏差。对Qwen-3和Llama-3系列进行扩展分析，研究推理优化的"思考"模型。

Result: 发现清晰的扩展轨迹用于韧性，揭示推理优化模型的矛盾脆弱性：虽然它们表现出高准确率，但在权威压力下，其内部推理轨迹经常合理化错误的用户建议。基准性能不能代表临床可靠性，简化推理结构可能提供更好的鲁棒性。

Conclusion: LLM的谄媚倾向是临床部署中的重要风险，需要专门评估。推理优化的"思考"模型在权威压力下特别脆弱，简化推理结构可能更稳健。基准性能不能保证临床可靠性。

Abstract: As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or "confusability". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized "Thinking" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.

</details>


### [85] [When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs](https://arxiv.org/abs/2601.18350)
*Junyi Zou*

Main category: cs.CL

TL;DR: 该研究提出两阶段LoRA管道，通过领域自适应预训练和指令微调增强LLM的医学能力，并采用加权适配器合并平衡指令跟随和领域知识保留。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用领域表现出色，但在医学术语精确性和安全关键指令跟随方面存在不足，需要专门的方法来提升其在医疗领域的表现。

Method: 采用两阶段LoRA管道：1) 领域自适应预训练(DAPT)注入广泛医学知识；2) 监督微调(SFT)对齐医学问答行为。提出加权适配器合并技术，线性组合SFT和PT适配器权重。

Result: 在医学验证集(F5/F6)上，合并模型在实用解码配置下取得BLEU-4=16.38，ROUGE-1=20.42，ROUGE-2=4.60，ROUGE-L=11.54。进一步分析了解码敏感性和训练稳定性。

Conclusion: 加权适配器合并能有效平衡指令跟随能力和领域知识保留，为安全关键领域的大语言模型适配提供了可行方案，特别是在医学领域。

Abstract: Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.

</details>


### [86] [Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning](https://arxiv.org/abs/2601.18352)
*Manjie Xu,Isabella Yin,Xinyi Tu,Chi Zhang,Yixin Zhu*

Main category: cs.CL

TL;DR: 大型语言模型存在"语义惯性"问题，难以抑制预训练先验知识，当上下文规则与先验矛盾时表现更差。通过将动态规则表示为可执行代码而非描述性文本，可以逆转这一趋势。


<details>
  <summary>Details</summary>
Motivation: 研究发现LLMs存在"语义惯性"问题，即无法抑制预训练先验知识（如"熔岩是危险的"），当动态上下文规则与这些先验矛盾时表现不佳。这挑战了"模型越大越好"的假设，对需要动态覆盖学习先验的领域有重要影响。

Method: 使用Baba Is You游戏作为测试平台，其中物理规则是可变的文本规则。提出Code-Grounded Vistas (LCV)方法，将动态规则表示为可执行代码而非描述性文本，通过微调模型处理反事实对，识别具有矛盾规则的状态，强制模型关注逻辑约束而非视觉语义。

Result: 研究发现较大模型可能出现逆缩放现象：当自然语言推理需要抑制预训练关联时，表现反而比小模型更差。但将动态规则表示为可执行代码可以逆转这一趋势，使缩放能改善上下文推理。LCV方法在效率和准确性上都优于昂贵的推理时搜索方法。

Conclusion: 表示方式从根本上决定了缩放是否能改善上下文推理。自然语言编码将描述性语义和逻辑规则纠缠在一起，导致对熟悉物理的持续幻觉。代码表示能有效抑制先验知识，挑战了"更大模型总是更好"的假设，对需要动态覆盖学习先验的领域有重要意义。

Abstract: LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., "Lava is Dangerous") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting "Lava is Safe"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.

</details>


### [87] [CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes](https://arxiv.org/abs/2601.18374)
*Rodrigo Silva,José Evans,José Isidro,Miguel Marques,Afonso Fonseca,Ricardo Morais,João Canavilhas,Arian Pasquali,Purificação Silvano,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,Ricardo Campos*

Main category: cs.CL

TL;DR: CitiLink平台利用LLMs将非结构化的市政会议记录转换为结构化可搜索数据，通过NLP和IR技术提升地方政府透明度


<details>
  <summary>Details</summary>
Motivation: 市政会议记录通常冗长、正式且具有官僚写作风格，虽然公开可用，但其结构使得公民和记者难以高效查找信息，需要提升地方政府信息的可访问性和透明度

Method: 使用LLMs提取元数据、讨论主题和投票结果，将数据索引到数据库中，支持BM25排名的全文搜索和分面过滤，开发了用户友好界面，基于6个葡萄牙城市的120份会议记录构建系统

Result: 系统通过市政人员的引导测试评估了可用性，了解了真实用户如何与系统交互，同时评估了Gemini在从会议记录中提取相关信息方面的性能，证明了其在数据提取方面的有效性

Conclusion: CitiLink展示了NLP和IR技术如何增强地方政府信息的可访问性和透明度，将非结构化文档转换为结构化可搜索数据，为公民和记者提供了更好的信息获取途径

Abstract: City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.

</details>


### [88] [Hierarchical Text Classification with LLM-Refined Taxonomies](https://arxiv.org/abs/2601.18375)
*Jonas Golde,Nicolaas Jedema,Ravi Krishnan,Phong Le*

Main category: cs.CL

TL;DR: TaxMorph：使用LLM重构分类学层次结构以解决标签歧义问题，提升分层文本分类性能


<details>
  <summary>Details</summary>
Motivation: 现实世界中的分类学存在标签歧义问题，如同名叶子节点出现在相似父节点下，这阻碍了语言模型学习清晰的决策边界

Method: 提出TaxMorph框架，利用大语言模型通过重命名、合并、拆分和重新排序等操作重构整个分类学层次结构

Result: 在三个HTC基准测试中，LLM优化的分类学比人工构建的分类学性能提升高达+2.9pp F1分数

Conclusion: LLM引导的分类学优化能创建更符合模型学习方式的分类结构，即使它们更难分离，但能更好地反映模型的归纳偏置，从而提升HTC性能

Abstract: Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.

</details>


### [89] [Corpus-Based Approaches to Igbo Diacritic Restoration](https://arxiv.org/abs/2601.18380)
*Ignatius Ezeani*

Main category: cs.CL

TL;DR: 该论文针对低资源语言（特别是伊博语）开发了变音符号恢复的灵活框架，提出了三种主要方法：标准n-gram模型、分类模型和嵌入模型。


<details>
  <summary>Details</summary>
Motivation: 当前NLP研究主要关注英语、中文等高资源语言，而全球95%以上的7000种语言都是低资源语言，缺乏NLP所需的数据、工具和技术。伊博语作为低资源语言，存在变音符号歧义问题，需要开发专门的解决方案。

Method: 提出了三种变音符号消歧方法：1）标准n-gram模型：使用目标词之前的词序列作为预测正确变体形式的关键预测因子；2）分类模型：使用目标词两侧的窗口词；3）嵌入模型：比较上下文词嵌入组合与各候选变体向量嵌入的相似度得分。

Result: 开发了一个用于生成变音符号恢复数据集的灵活框架，并针对伊博语实现了三种不同的变音符号消歧方法，为低资源语言的NLP处理提供了解决方案。

Conclusion: 该研究为低资源语言的变音符号恢复问题提供了系统性的解决方案框架，通过多种模型方法解决了伊博语等低资源语言中的变音符号歧义问题，有助于推动低资源语言NLP研究的发展。

Abstract: With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.
  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.

</details>


### [90] [Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction](https://arxiv.org/abs/2601.18395)
*Mikel Zubillaga,Oscar Sainz,Oier Lopez de Lacalle,Eneko Agirre*

Main category: cs.CL

TL;DR: ThinkTwice框架通过采样生成多个候选模板，然后选择最佳方案，显著优于贪婪解码方法


<details>
  <summary>Details</summary>
Motivation: 传统文档级信息抽取使用贪婪解码以避免输出变异性，但作者认为采样能产生更好的解决方案，特别是使用推理模型时

Method: 提出ThinkTwice框架：1) LLM为给定文档生成多个候选模板 2) 选择模块选择最合适的模板。包含无监督方法（利用生成输出间的一致性）和监督方法（使用在标注数据上训练的奖励模型）。为解决DocIE黄金推理轨迹稀缺问题，提出基于拒绝采样的方法生成包含输出模板和推理轨迹的银训练数据

Result: 实验证明无监督和监督ThinkTwice方法的有效性，一致优于贪婪基线和最先进方法

Conclusion: 采样方法在文档级信息抽取中优于贪婪解码，ThinkTwice框架通过采样和选择策略显著提升性能

Abstract: Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.

</details>


### [91] [Pisets: A Robust Speech Recognition System for Lectures and Interviews](https://arxiv.org/abs/2601.18415)
*Ivan Bondarenko,Daniil Grebenkin,Oleg Sedukhin,Mikhail Klementev,Roman Derunets,Lyudmila Budneva*

Main category: cs.CL

TL;DR: 提出名为"Pisets"的语音转文本系统，采用三组件架构提升俄语语音识别准确率，减少Whisper模型的错误和幻觉问题


<details>
  <summary>Details</summary>
Motivation: 解决Whisper模型在俄语语音识别中存在的错误和幻觉问题，为科学家和记者提供更准确可靠的语音转文本工具

Method: 三组件架构：1) Wav2Vec2进行初步识别，2) Audio Spectrogram Transformer (AST)过滤误报，3) Whisper进行最终语音识别；采用课程学习方法和多样化的俄语语音语料库训练

Result: 相比WhisperX和标准Whisper模型，在各种声学条件下对长音频数据的转录更加稳健，转录质量显著提升

Conclusion: 提出的Pisets系统通过多阶段架构和先进训练方法有效提高了俄语语音识别准确性，代码已开源供研究使用

Abstract: This work presents a speech-to-text system "Pisets" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of "Pisets" system is publicly available at GitHub: https://github.com/bond005/pisets.

</details>


### [92] [Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models](https://arxiv.org/abs/2601.18468)
*Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 研究显示大语言模型中的潜在知识（latent knowledge）能预测微调时事实学习的速度和未见本体事实的有限泛化能力，而抵抗遗忘则取决于事实是否在训练中被强化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在预训练后存储生物医学事实的强度不均：有些事实存在于权重中但在确定性解码下不可靠（潜在知识），而有些则很少被表示。研究旨在探索这些潜在知识如何影响微调过程中的事实获取、泛化和遗忘。

Method: 对Llama 3.1 8B Instruct进行微调，学习来自人类表型本体（800对）和基因本体（400训练对）的术语标识符映射，保留400个GO对用于测试泛化。将学习视为跨越20个epoch的时间事件过程，使用随机解码检测基线潜在知识，并采用Cox比例风险模型识别获取、泛化和退化的预测因素。

Result: HPO的基线确定性召回率为2.8%，微调后升至71.9%。潜在知识是最强预测因子（HR 2.6），与更早、更高的峰值学习率和更快收敛相关；标识符频率和注释计数影响较小。对未见GO事实的泛化不常见（5.8%），但在存在潜在知识时更可能发生。先前正确的GO映射在未见术语中比在训练术语中退化更频繁，表明训练中的强化具有保护作用。

Conclusion: 潜在知识能预测微调期间事实学习的速度和未见本体事实的有限泛化，而抵抗退化取决于事实是否在训练中被强化。这为理解LLM如何学习和遗忘结构化知识提供了新见解。

Abstract: Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.

</details>


### [93] [Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs](https://arxiv.org/abs/2601.18483)
*Arya Labroo,Ivaxi Sheth,Vyas Raina,Amaani Ahmed,Mario Fritz*

Main category: cs.CL

TL;DR: 研究发现大语言模型在多概念控制上存在局限性：即使概念理论上可分离，模型在双概念控制任务中的表现仍会下降，揭示提示方法在组合性上的根本缺陷


<details>
  <summary>Details</summary>
Motivation: 许多应用需要对文本概念进行细粒度控制（如幽默、说服力、正式性），但现有方法只能提供粗略或单属性控制，缺乏对多属性设置的系统评估

Method: 引入一个评估框架，用于细粒度可控性评估，涵盖单概念和双概念场景，专注于语言学上不同的概念对（如说服力vs幽默）

Result: 在多个LLM和生成任务中，双概念设置下的性能经常下降，即使所选概念在理论上应该是可分离的，这揭示了基于提示控制的根本局限性

Conclusion: 模型在组合性方面存在困难，即使概念在直觉上是独立的。该框架为衡量未来多概念控制方法的能力提供了原则性方法

Abstract: Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.

</details>


### [94] [Demographic Probing of Large Language Models Lacks Construct Validity](https://arxiv.org/abs/2601.18486)
*Manuel Tonneau,Neil K. R. Seghal,Niyati Malhotra,Victor Orozco-Olvera,Ana María Muñoz Boudet,Lakshmi Subramanian,Sharath Chandra Guntuku,Valentin Hofmann*

Main category: cs.CL

TL;DR: 研究发现人口统计学探测方法缺乏构念效度，不同人口线索（如姓名、方言）对LLM行为的影响不一致，导致估计的差异不稳定，建议使用多种生态有效线索并控制混淆因素。


<details>
  <summary>Details</summary>
Motivation: 当前人口统计学探测研究通常使用单一人口线索（如姓名或方言）来研究LLM如何根据人口属性调整行为，但这种方法隐含假设这些线索是同一底层人口条件行为的可互换操作化。本文旨在测试这一构念效度假设。

Method: 在现实的寻求建议互动场景中测试人口统计学探测方法，聚焦美国背景下的种族和性别。使用不同的人口线索（如姓名、方言等）作为群体成员信号，分析这些线索如何影响模型行为，并探究不一致性的来源。

Result: 发现：1）旨在代表同一人口群体的线索仅引起模型行为的部分重叠变化；2）同一线索内不同群体间的区分度弱且不均匀；3）估计的差异不稳定，大小和方向随线索变化；4）不一致性部分源于线索编码人口属性的强度差异和独立影响模型行为的语言混淆因素。

Conclusion: 人口统计学探测缺乏构念效度，无法提供关于LLM如何根据人口信息进行条件化的单一稳定表征。建议使用多种生态有效线索并明确控制混淆因素，以支持关于LLM中人口效应的更可靠主张。

Abstract: Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.

</details>


### [95] [Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research](https://arxiv.org/abs/2601.18512)
*Antonio Garzon-Vico,Krithika Sharon Komalapati,Arsalan Shahid,Jan Rosier*

Main category: cs.CL

TL;DR: 使用大语言模型创建真实高管虚拟人格的方法框架，通过道德基础理论构建能模拟领导者决策的LLM参与者，验证其在组织研究中的有效性


<details>
  <summary>Details</summary>
Motivation: 在难以直接接触高管的情况下，需要开发能够模拟领导者决策的替代研究工具。传统方法难以获取高管样本，而LLM技术为创建可信的虚拟高管人格提供了可能

Method: 基于真实CEO沟通数据和道德基础理论，构建LLM虚拟人格。通过三个阶段评估：结构效度、信度和行为保真度，将虚拟CEO与人类参与者进行基准测试

Result: 理论支撑的虚拟人格能够近似人类样本中观察到的道德判断，表明LLM虚拟人格可以作为组织研究中可信且互补的工具，特别是在难以接触高管的情况下

Conclusion: LLM虚拟人格为组织研究提供了新的方法论工具，特别是在高管难以接触的背景下。未来研究应进一步探索LLM虚拟人格在组织环境中的应用潜力和局限性

Abstract: This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.

</details>


### [96] [GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback](https://arxiv.org/abs/2601.18517)
*James Sungarda,Hongkai Liu,Zilong Zhou,Tien-Hsuan Wu,Johnson Chun-Sing Cheung,Ben Kao*

Main category: cs.CL

TL;DR: SWITCH是一个社会工作互动训练聊天机器人，集成了真实客户模拟、实时咨询技能分类和动机性访谈进展系统，为社工学生提供可扩展、低成本、一致的训练流程。


<details>
  <summary>Details</summary>
Motivation: 社会工作领域教育是其标志性教学方法，但在培训期间提供及时客观的反馈受到教师和咨询客户可用性的限制。需要一种能够补充实地教育、让督导专注于更高层次指导的解决方案。

Method: SWITCH采用基于认知的客户模型，包含静态字段（背景、信念）和动态字段（情绪、自动思维、开放性），使代理行为在会话中真实演变。技能分类模块识别用户话语中的咨询技能，并将结果输入到调节MI阶段转换的控制器中。为提高分类准确性，研究了基于注释转录本的检索上下文学习，以及微调的BERT多标签分类器。

Result: 实验表明，基于BERT的方法和上下文学习方法都显著优于基线模型。SWITCH提供了一个可扩展、低成本、一致的训练工作流程。

Conclusion: SWITCH能够补充社会工作实地教育，提供可扩展、低成本、一致的训练，使督导能够专注于更高层次的指导工作，解决了传统培训中反馈及时性和客观性的限制。

Abstract: Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.

</details>


### [97] [Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models](https://arxiv.org/abs/2601.18527)
*Francesco Maria Molfese,Momchil Hardalov,Rexhina Blloshmi,Bill Byrne,Adrià de Gispert*

Main category: cs.CL

TL;DR: 研究探讨了长上下文语言模型的微调策略如何提升其在长文档中的信息检索能力，以及这些策略对KV缓存压缩的鲁棒性影响。


<details>
  <summary>Details</summary>
Motivation: 随着长上下文语言模型能够处理数百万token的文档，它们成为传统检索增强生成的有力替代方案。但尚不清楚微调策略是否能提升长上下文性能，以及这些改进是否能转化为在KV缓存压缩技术下的更强鲁棒性。

Method: 研究调查了哪些训练策略能最有效地增强长上下文语言模型识别和使用相关信息的能力，以及提升它们在KV缓存压缩下的鲁棒性。

Result: 实验显示在领域内性能有显著提升，相比基础模型获得高达+20分的增益。但领域外泛化能力因任务而异：长上下文模型在金融问题上表现优异（+9分），而检索增强生成在多项选择题上优于基线模型（+6分）。微调方法在KV缓存压缩下带来中等程度的鲁棒性改进，增益因任务而异。

Conclusion: 微调策略能有效提升长上下文语言模型的领域内性能，但领域外泛化能力具有任务依赖性。同时，这些方法能在一定程度上增强模型在KV缓存压缩下的鲁棒性，为实际部署提供参考。

Abstract: With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.

</details>


### [98] [From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation](https://arxiv.org/abs/2601.18533)
*Yuxin Jiang,Yufei Wang,Qiyuan Zhang,Xingshan Zeng,Liangyou Li,Jierun Chen,Chaofan Tao,Haoli Bai,Lifeng Shang*

Main category: cs.CL

TL;DR: RLVRR提出了一种基于可验证参考奖励的强化学习方法，通过从高质量参考中提取有序语言信号（奖励链），将奖励分解为内容和风格两个维度，结合RL的探索优势和SFT的效率可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统的可验证奖励强化学习（RLVR）在推理任务中有效，但在开放式生成任务中面临挑战，因为缺乏明确的标准答案。单一监督信号导致效率低下和奖励黑客问题，需要一种能统一结构化推理和开放式生成的训练方法。

Method: RLVRR从高质量参考中提取有序语言信号（奖励链），将奖励分解为两个维度：内容维度（保留确定性核心概念如关键词）和风格维度（通过LLM验证评估风格属性一致性）。这种方法结合了强化学习的探索能力和监督微调的效率可靠性。

Result: 在超过10个基准测试中使用Qwen和Llama模型进行实验，RLVRR显著优于使用十倍数据训练的SFT和先进奖励模型，统一了结构化推理和开放式生成的训练，在保持输出多样性的同时具有更好的泛化能力。

Conclusion: RLVRR为通用LLM对齐提供了一个原则性和高效的可验证强化学习路径，通过奖励链方法有效解决了开放式生成中的监督信号问题，实现了RL探索优势和SFT效率的有机结合。

Abstract: Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.

</details>


### [99] [Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features](https://arxiv.org/abs/2601.18536)
*Abishek Stephen,Jindřich Libovický*

Main category: cs.CL

TL;DR: 提出一种基于形态句法特征评估子词切分形态合理性的新指标，无需黄金切分数据，适用于更多语言


<details>
  <summary>Details</summary>
Motivation: 传统评估指标（如语素边界F值）需要黄金切分数据，但许多语言缺乏或质量不一致。需要一种更广泛适用的评估方法，利用更普遍可得的形态句法特征资源

Method: 利用Universal Dependencies或UniMorph等资源中的形态句法特征，通过IBM Model 1概率对齐子词与形态特征

Result: 该指标与传统语素边界召回率有良好相关性，同时在不同形态系统的语言中具有更广泛的适用性

Conclusion: 提出的新指标为评估子词切分的形态合理性提供了一种更通用、更广泛适用的方法，特别适合资源匮乏的语言

Abstract: We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.

</details>


### [100] [Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection](https://arxiv.org/abs/2601.18552)
*Devansh Srivastav,David Pape,Lea Schönherr*

Main category: cs.CL

TL;DR: 该论文系统分析了LLMs中隐藏意图的检测失败问题，提出了十类隐藏意图的分类法，并证明在开放世界设置下现有检测方法基本失效。


<details>
  <summary>Details</summary>
Motivation: LLMs在日常决策中应用日益广泛，但其输出可能编码微妙、无意的行为，影响用户信念和行动。这些隐藏意图可能源于训练优化伪影或被恶意开发者故意植入，但在实践中难以检测，存在重大风险。

Method: 1. 提出基于社会科学研究的十类隐藏意图分类法；2. 在受控模型中诱导隐藏意图，创建评估测试平台；3. 系统评估检测方法（推理和非推理LLM判断器）；4. 进行精度-流行率和精度-FNR权衡的压力测试；5. 对已部署的SOTA LLMs进行定性案例研究。

Result: 1. 隐藏意图可在受控模型中轻松诱导；2. 在现实开放世界设置下检测方法基本失效，特别是在低流行率条件下；3. 压力测试显示审计需要极低的假阳性率或对操纵类型的强先验；4. 案例研究证实十类隐藏意图在已部署LLMs中均存在。

Conclusion: 该研究首次系统分析了开放世界设置下LLMs隐藏意图的检测失败问题，为理解、诱导和压力测试此类行为提供了基础，建立了灵活的分类法来预测演化威胁并指导治理，强调了建立鲁棒框架的紧迫性。

Abstract: LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.

</details>


### [101] [One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization](https://arxiv.org/abs/2601.18572)
*Franziska Weeber,Vera Neplenbroek,Jan Batzner,Sebastian Padó*

Main category: cs.CL

TL;DR: 研究比较了六种常用的人设提示方法在七个LLM上的表现，发现不同提示方法会导致显著差异，建议未来个性化研究应评估多种外部有效的方法而非依赖单一提示。


<details>
  <summary>Details</summary>
Motivation: LLM的个性化虽然能提升用户体验，但可能引入或放大群体偏见。现有研究通常依赖单一提示方法（如用户名或显式属性）来研究偏见，但忽视了LLM对提示变化的敏感性以及某些提示在真实交互中的罕见性。

Method: 比较了六种常用的人设提示方法（persona cues），在七个开源和专有LLM上测试了四个写作和建议任务，分析不同提示方法产生的响应差异。

Result: 虽然不同提示方法总体上高度相关，但它们在不同人设上产生了显著的响应方差。单一提示方法得出的结论可能不可靠，需要谨慎对待。

Conclusion: 建议未来个性化研究应评估多种外部有效的提示方法，避免仅基于单一提示方法做出关于偏见或公平性的结论。

Abstract: Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.

</details>


### [102] [From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection](https://arxiv.org/abs/2601.18582)
*Yuan Cao,Feixiang Liu,Xinyue Wang,Yihan Zhu,Hui Xu,Zheng Wang,Qiang Qiu*

Main category: cs.CL

TL;DR: 该论文提出了一种基于强化学习的人格检测新方法，将人格检测视为排序任务而非分类任务，通过监督微调和分组相对策略优化实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的人格检测方法存在两个主要问题：1）人格特质分类困难，因为人格具有复杂性和特质间细微差异；2）基于提示的方法过度依赖专家知识，缺乏自主模式学习能力。

Method: 提出两阶段方法：1）使用监督微调（SFT）建立人格特质排序能力并标准化输出格式；2）引入分组相对策略优化（GRPO）和专门的基于排序的奖励函数，训练LLM学习最优答案排序。

Result: 在多个基准测试中实现了最先进的性能，证明了该方法在人格检测任务上的有效性。

Conclusion: 将人格检测重新定义为排序任务，并采用强化学习训练范式，能够有效解决人格特质分类的挑战，减少对专家知识的依赖，提升模型自主学习能力。

Abstract: Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.

</details>


### [103] [Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning](https://arxiv.org/abs/2601.18722)
*Lintang Sutawika,Gokul Swamy,Zhiwei Steven Wu,Graham Neubig*

Main category: cs.CL

TL;DR: SP3F是一个两阶段框架，通过自我对弈与特权成对反馈，无需目标语言数据即可提升多语言推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前推理大语言模型在训练数据中较少见的语言上表现显著低于英语，需要一种无需目标语言数据的方法来提升多语言推理能力。

Method: 1) 在翻译的英语问答对上进行监督微调以提高基础模型正确性；2) 通过自我对弈进行强化学习，使用特权成对评判器（接收英语参考回答作为特权信息）提供反馈。

Result: SP3F显著提升了基础模型性能，在多个数学和非数学任务上甚至优于完全后训练的模型，且训练数据量不到1%。

Conclusion: SP3F框架通过特权成对反馈和自我对弈，有效解决了多语言推理中的数据稀缺问题，在单语言、多语言和未见语言泛化场景中均表现出色。

Abstract: When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than
  of the training data across the single-language, multilingual, and generalization to unseen language settings.

</details>


### [104] [HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences](https://arxiv.org/abs/2601.18724)
*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 研究发现AI生成的论文中存在大量虚假引用（HalluCitation），在2024-2025年ACL、NAACL、EMNLP会议论文中发现了近300篇包含虚假引用的论文，且问题在2025年急剧恶化


<details>
  <summary>Details</summary>
Motivation: 近年来在审稿论文、预印本和已发表论文中频繁观察到虚假引用（引用不存在的文献），这严重威胁科学可靠性，并可能损害学术会议的声誉

Method: 系统分析了2024-2025年ACL、NAACL、EMNLP所有会议论文（包括主会、Findings和研讨会论文），识别并统计包含虚假引用的论文

Result: 发现近300篇论文包含至少一个虚假引用，其中大部分出现在2025年；EMNLP 2025会议尤为严重，一半问题论文集中于此，超过100篇主会和Findings论文受到影响

Conclusion: 虚假引用问题在自然语言处理领域迅速恶化，特别是在最近的大型会议中，严重威胁学术可信度，需要学术界采取紧急应对措施

Abstract: Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.

</details>


### [105] [Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale](https://arxiv.org/abs/2601.18730)
*Henry Bell,Caroline Zhang,Mohammed Mobasserul Haque,Dhaval Potdar,Samia Zaman,Brandon Fain*

Main category: cs.CL

TL;DR: REFLECT：一种无需训练或数据的推理时宪法对齐框架，通过上下文中的自我评估、自我批判和最终修订来提升LLM对复杂原则的遵从性


<details>
  <summary>Details</summary>
Motivation: 现有的宪法对齐方法（如RLHF）需要大量计算资源、精细工程调整和难以获取的人工标注数据，因此需要一种更轻量、即插即用的对齐方案

Method: 提出REFLECT框架，完全在推理时运行，包含：(i) 基于宪法的基本响应生成，(ii) 自我评估，(iii)(a) 自我批判，(iii)(b) 最终修订，通过显式的上下文推理来确保原则遵从

Result: REFLECT显著提升了LLM对多样复杂原则的遵从性，包括与原始参数微调强调的原则差异很大的情况，同时不牺牲事实推理能力；特别有效减少罕见但严重的原则违反，提升安全性和鲁棒性

Conclusion: REFLECT提供了一种无需训练、即插即用的宪法对齐方案，能生成有用的训练数据供传统参数微调使用，在长期部署中可减少推理时计算开销

Abstract: The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.

</details>


### [106] [One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment](https://arxiv.org/abs/2601.18731)
*Hongru Cai,Yongqi Li,Tiezheng Yu,Fengbin Zhu,Wenjie Wang,Fuli Feng,Wenjie Li*

Main category: cs.CL

TL;DR: 本文提出MRM方法，通过元学习框架解决个性化奖励建模中的数据稀缺和快速适应新用户的问题，使用MAML风格优化和鲁棒个性化目标提升少样本个性化效果。


<details>
  <summary>Details</summary>
Motivation: 个性化对齐需要个性化奖励模型来捕捉用户特定偏好，但面临两个关键挑战：个体用户反馈稀缺和需要高效适应未见用户。传统拟合数据的方法不足，需要转向学习偏好适应过程。

Method: 提出元奖励建模（MRM），将个性化奖励建模重构为元学习问题。将每个用户的奖励模型表示为基奖励函数的加权组合，使用MAML风格框架优化权重初始化以支持有限反馈下的快速适应。引入鲁棒个性化目标（RPO），在元优化中更重视难学习的用户。

Result: 在个性化偏好数据集上的大量实验验证了MRM能够增强少样本个性化、提高用户鲁棒性，并持续优于基线方法。

Conclusion: MRM通过元学习范式有效解决了个性化奖励建模中的数据稀缺和快速适应问题，为个性化对齐提供了更高效和鲁棒的解决方案。

Abstract: Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.

</details>


### [107] [Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory](https://arxiv.org/abs/2601.18771)
*Yanming Liu,Xinyue Peng,Zixuan Yan,Yanxin Shen,Wenjie Xu,Yuefeng Huang,Xinyi Wang,Jiannan Cao,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

TL;DR: Dep-Search是一个依赖感知的搜索框架，通过结构化推理、检索和持久内存集成，解决现有搜索框架在复杂多跳推理任务中的依赖管理和知识重用问题。


<details>
  <summary>Details</summary>
Motivation: 现有搜索框架严重依赖隐式自然语言推理来确定搜索策略和利用检索信息，这导致在子问题依赖管理、先前检索知识的有效重用以及通过强化学习学习最优搜索策略方面存在根本性挑战。

Method: 提出Dep-Search框架，引入显式控制机制，使模型能够：1) 分解具有依赖关系的问题；2) 在需要时检索信息；3) 从内存访问先前存储的知识；4) 将长推理上下文总结为可重用的内存条目；通过GRPO集成结构化推理、检索和持久内存。

Result: 在七个不同的问答数据集上进行广泛实验，Dep-Search显著增强了LLMs处理复杂多跳推理任务的能力，在不同模型规模上相比强基线实现了实质性改进。

Conclusion: Dep-Search通过依赖感知的搜索框架超越了现有搜索框架，通过结构化推理、检索和持久内存的集成，有效解决了复杂推理任务中的依赖管理和知识重用挑战。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.

</details>


### [108] [Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings](https://arxiv.org/abs/2601.18788)
*Mumin Jia,Jairo Diaz-Rodriguez*

Main category: cs.CL

TL;DR: Embed-KCPD：一种无监督文本分割方法，使用句子嵌入和惩罚KCPD目标检测边界，具有理论保证和实际效果验证


<details>
  <summary>Details</summary>
Motivation: 文本分割的边界标注成本高、主观性强，且难以跨领域和粒度迁移，需要有效的无监督方法

Method: 将句子表示为嵌入向量，通过最小化惩罚KCPD目标估计边界；建立m-依赖序列下的理论框架；使用LLM生成可控依赖的合成文档验证

Result: 在标准分割基准测试中常优于强无监督基线；理论证明边界恢复窗口相对于段长较小；通过Taylor Swift推文案例展示实用效果

Conclusion: Embed-KCPD结合了理论保证、模拟可靠性和实际有效性，为无监督文本分割提供了有前景的解决方案

Abstract: Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.

</details>


### [109] [MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts](https://arxiv.org/abs/2601.18790)
*Etienne Lanzeray,Stephane Meilliez,Malo Ruelle,Damien Sileo*

Main category: cs.CL

TL;DR: 研究发现，专注于深度推理的LLM在用户面临生命危险时仍会坚持完成数学任务，而忽视紧急情况，存在安全隐患。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越专注于深度推理能力，研究者担心这种对计算任务的执着可能导致模型忽视安全考量，特别是在用户面临生命危险的关键情境中。

Method: 研究者创建了MortalMATH基准测试，包含150个场景，用户在请求代数帮助的同时描述逐渐升级的生命威胁紧急情况（如中风症状、自由落体等），测试不同模型的行为反应。

Result: 发现明显的行为分化：通用模型（如Llama-3.1）能拒绝数学任务并关注危险；而专业推理模型（如Qwen-3-32b和GPT-5-nano）经常完全忽视紧急情况，在用户描述濒死状态时仍保持超过95%的任务完成率。推理计算时间还会引入危险延迟：最多达15秒才可能提供帮助。

Conclusion: 训练模型执着追求正确答案可能会无意中让它们失去安全部署所需的生存本能，需要在模型优化中平衡推理能力与安全考量。

Abstract: Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a "tunnel vision" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.

</details>


### [110] [Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets](https://arxiv.org/abs/2601.18791)
*Iaroslav Chelombitko,Mika Hämäläinen,Aleksey Komissarov*

Main category: cs.CL

TL;DR: 该研究使用BPE子词方法对242种拉丁和西里尔文字语言进行大规模比较分析，发现BPE分割与语素边界高度一致，词汇相似性与语言亲缘关系显著相关，跨语言同形词的分割差异与系统发育距离相关。


<details>
  <summary>Details</summary>
Motivation: 建立一个统一的框架来大规模比较不同文字系统（拉丁和西里尔）的语言，量化分析词汇模式、语言相似性和系统发育关系，为宏观语言学提供定量见解。

Method: 从维基百科词典构建"glottosets"，使用字节对编码（BPE）进行子词分割，创建基于排名的子词向量，分析词汇重叠、词汇分化和语言相似性。评估BPE分割与语素边界的一致性，计算词汇相似性与语言遗传关系的相关性。

Result: BPE分割在15种语言中比随机基线提高95%（F1=0.34 vs 0.15）。BPE词汇相似性与语言遗传关系显著相关（Mantel r=0.329，p<0.001），罗曼语族形成最紧密的聚类（平均距离0.51），跨语系对显示明显分离（0.82）。26,939个跨语言同形词中48.7%在不同相关语言中获得不同分割，变异与系统发育距离相关。

Conclusion: BPE子词方法为大规模跨语言比较提供了有效的统一分析框架，能够量化揭示语言间的词汇模式和系统发育关系，为宏观语言学提供了重要的定量见解。

Abstract: We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.

</details>


### [111] [ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models](https://arxiv.org/abs/2601.18796)
*Brian Ondov,Chia-Hsuan Chang,Yujia Zhou,Mauro Giuffrè,Hua Xu*

Main category: cs.CL

TL;DR: 开发了一个名为ctELM的嵌入语言模型，能够从临床试验的嵌入向量中准确描述和生成临床试验摘要，并展示了对年龄和性别等概念向量的响应性。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入已成为多种语言应用的核心组件，但解释、探索和反转嵌入空间的方法有限，这降低了透明度并阻碍了潜在的生成应用。特别是在生物医学领域，需要更好的方法来理解和操作临床试验的嵌入表示。

Method: 采用嵌入语言模型（ELM）方法，将大型语言模型与临床试验嵌入对齐。开发了开源、领域无关的ELM架构和训练框架，设计了针对临床试验的训练任务，并引入了专家验证的合成数据集。通过不同任务和训练方案训练了一系列ELM模型。

Result: 最终模型ctELM能够仅从嵌入向量中准确描述和比较未见过的临床试验，并能从新向量生成合理的临床试验摘要。生成的试验摘要能够响应沿着年龄和性别等概念向量移动嵌入的操作。

Conclusion: 公开的ELM实现和实验结果将有助于在生物医学领域及其他领域中将大型语言模型与嵌入空间对齐，提高嵌入空间的可解释性和生成能力。

Abstract: Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [112] [Breaking Task Impasses Quickly: Adaptive Neuro-Symbolic Learning for Open-World Robotics](https://arxiv.org/abs/2601.16985)
*Pierrick Lorang*

Main category: cs.RO

TL;DR: 提出神经符号框架，结合分层抽象、任务与运动规划及强化学习，实现机器人快速适应开放世界的新颖变化


<details>
  <summary>Details</summary>
Motivation: 自主系统在开放世界中适应不可预见的新颖变化仍然是一个主要挑战。现有的混合规划和强化学习方法存在样本效率低、适应速度慢和灾难性遗忘等问题

Method: 神经符号框架整合分层抽象、任务与运动规划(TAMP)和强化学习。结合符号目标导向学习和基于世界模型的探索，促进对环境变化的快速适应

Result: 在机器人操作和自动驾驶任务中验证，相比最先进的混合方法，实现了更快的收敛速度、更高的样本效率和更强的鲁棒性

Conclusion: 该框架展示了在现实世界部署的潜力，能够有效解决开放世界适应问题，为自主系统提供快速适应能力

Abstract: Adapting to unforeseen novelties in open-world environments remains a major challenge for autonomous systems. While hybrid planning and reinforcement learning (RL) approaches show promise, they often suffer from sample inefficiency, slow adaptation, and catastrophic forgetting. We present a neuro-symbolic framework integrating hierarchical abstractions, task and motion planning (TAMP), and reinforcement learning to enable rapid adaptation in robotics. Our architecture combines symbolic goal-oriented learning and world model-based exploration to facilitate rapid adaptation to environmental changes. Validated in robotic manipulation and autonomous driving, our approach achieves faster convergence, improved sample efficiency, and superior robustness over state-of-the-art hybrid methods, demonstrating its potential for real-world deployment.

</details>


### [113] [Advancing Improvisation in Human-Robot Construction Collaboration: Taxonomy and Research Roadmap](https://arxiv.org/abs/2601.17219)
*David Wireko Atibila,Vineet R. Kamat,Carol C. Menassa*

Main category: cs.RO

TL;DR: 本文提出了一个六层级分类法，用于评估建筑领域人机协作的即兴能力，发现当前研究集中在较低层级，存在向真正协作即兴发展的关键障碍。


<details>
  <summary>Details</summary>
Motivation: 建筑行业面临生产力停滞、熟练劳动力短缺和安全问题。虽然机器人自动化提供了解决方案，但建筑机器人在适应非结构化、动态工地方面存在困难。即兴能力（适应意外情况的创造性问题解决能力）目前主要依赖人类，在不可预测的建筑环境中，人机协作即兴对于工作流程连续性至关重要。

Method: 通过系统回顾214篇文献（2010-2025年），开发了一个六层级分类法，将建筑机器人分为：手动工作（0级）、人类控制执行（1级）、自适应操作（2级）、模仿学习（3级）、人在环BIM工作流程（4级）、基于云的知识集成（5级）和真正协作即兴（6级）。使用五维雷达框架分析规划、认知角色、物理执行、学习能力和即兴能力的渐进演变。

Result: 分析显示当前研究集中在较低层级，在经验学习方面存在关键差距，向协作即兴的进展有限。识别了三个基本障碍：接地和对话推理的技术限制、人类即兴与机器人研究之间的概念差距，以及方法论挑战。

Conclusion: 建议未来研究重点改进人机通信（通过增强/虚拟现实界面）、集成大语言模型和基于云的知识系统，以推进真正的协作即兴。互补的人机能力可以创造超越个体贡献的团队绩效。

Abstract: The construction industry faces productivity stagnation, skilled labor shortages, and safety concerns. While robotic automation offers solutions, construction robots struggle to adapt to unstructured, dynamic sites. Central to this is improvisation, adapting to unexpected situations through creative problem-solving, which remains predominantly human. In construction's unpredictable environments, collaborative human-robot improvisation is essential for workflow continuity. This research develops a six-level taxonomy classifying human-robot collaboration (HRC) based on improvisation capabilities. Through systematic review of 214 articles (2010-2025), we categorize construction robotics across: Manual Work (Level 0), Human-Controlled Execution (Level 1), Adaptive Manipulation (Level 2), Imitation Learning (Level 3), Human-in-Loop BIM Workflow (Level 4), Cloud-Based Knowledge Integration (Level 5), and True Collaborative Improvisation (Level 6). Analysis reveals current research concentrates at lower levels, with critical gaps in experiential learning and limited progression toward collaborative improvisation. A five-dimensional radar framework illustrates progressive evolution of Planning, Cognitive Role, Physical Execution, Learning Capability, and Improvisation, demonstrating how complementary human-robot capabilities create team performance exceeding individual contributions. The research identifies three fundamental barriers: technical limitations in grounding and dialogic reasoning, conceptual gaps between human improvisation and robotics research, and methodological challenges. We recommend future research emphasizing improved human-robot communication via Augmented/Virtual Reality interfaces, large language model integration, and cloud-based knowledge systems to advance toward true collaborative improvisation.

</details>


### [114] [Hierarchical Informative Path Planning via Graph Guidance and Trajectory Optimization](https://arxiv.org/abs/2601.17227)
*Avraiem Iskandar,Shamak Dutta,Kevin Murrant,Yash Vardhan Pant,Stephen L. Smith*

Main category: cs.RO

TL;DR: 提出分层框架解决杂乱环境中带旅行预算的信息路径规划问题，结合图规划与连续优化，在降低后验不确定性的同时提升计算效率


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：基于图的求解器需要预设测量位置，而连续轨迹优化计算量大且在障碍密集环境中对初始化敏感。需要结合两者优势，在杂乱环境中高效进行信息路径规划。

Method: 提出三层分层框架：1) 基于图的全局规划；2) 使用几何和核边界进行分段预算分配；3) 带硬约束和障碍修剪的样条基分段细化。结合全局指导与局部优化。

Result: 相比仅基于图的方法和连续基线，该方法实现了更低的后验不确定性。计算速度显著提升：比基于梯度的方法快9倍，比黑盒优化器快20倍，在合成杂乱环境和北极数据集中均表现优异。

Conclusion: 分层框架成功结合了图规划与连续优化的优势，在杂乱环境中实现了高效的信息路径规划，平衡了不确定性降低与计算效率。

Abstract: We study informative path planning (IPP) with travel budgets in cluttered environments, where an agent collects measurements of a latent field modeled as a Gaussian process (GP) to reduce uncertainty at target locations. Graph-based solvers provide global guarantees but assume pre-selected measurement locations, while continuous trajectory optimization supports path-based sensing but is computationally intensive and sensitive to initialization in obstacle-dense settings. We propose a hierarchical framework with three stages: (i) graph-based global planning, (ii) segment-wise budget allocation using geometric and kernel bounds, and (iii) spline-based refinement of each segment with hard constraints and obstacle pruning. By combining global guidance with local refinement, our method achieves lower posterior uncertainty than graph-only and continuous baselines, while running faster than continuous-space solvers (up to 9x faster than gradient-based methods and 20x faster than black-box optimizers) across synthetic cluttered environments and Arctic datasets.

</details>


### [115] [Real-Time, Energy-Efficient, Sampling-Based Optimal Control via FPGA Acceleration](https://arxiv.org/abs/2601.17231)
*Tanmay Desai,Brian Plancher,R. Iris Bahar*

Main category: cs.RO

TL;DR: FPGA优化的MPPI设计相比嵌入式GPU/CPU实现3.1-7.5倍加速和2.5-5.4倍能耗降低，适用于自主移动机器人


<details>
  <summary>Details</summary>
Motivation: 自主移动机器人需要快速鲁棒的规划控制方案，MPPI算法虽有效但GPU/CPU实现难以满足嵌入式平台的能耗和延迟约束

Method: 提出FPGA优化的MPPI设计，通过细粒度并行化、深度流水线和跨算法阶段并行消除同步瓶颈

Result: 相比嵌入式GPU和CPU实现，分别获得平均3.1倍和7.5倍加速，同时能耗降低2.5-5.4倍

Conclusion: FPGA架构是实现高能效高性能边缘机器人的有前景方向

Abstract: Autonomous mobile robots (AMRs), used for search-and-rescue and remote exploration, require fast and robust planning and control schemes. Sampling-based approaches for Model Predictive Control, especially approaches based on the Model Predictive Path Integral Control (MPPI) algorithm, have recently proven both to be highly effective for such applications and to map naturally to GPUs for hardware acceleration. However, both GPU and CPU implementations of such algorithms can struggle to meet tight energy and latency budgets on battery-constrained AMR platforms that leverage embedded compute. To address this issue, we present an FPGA-optimized MPPI design that exposes fine-grained parallelism and eliminates synchronization bottlenecks via deep pipelining and parallelism across algorithmic stages. This results in an average 3.1x to 7.5x speedup over optimized implementations on an embedded GPU and CPU, respectively, while simultaneously achieving a 2.5x to 5.4x reduction in energy usage. These results demonstrate that FPGA architectures are a promising direction for energy-efficient and high-performance edge robotics.

</details>


### [116] [Quantifying Ergonomics in the Elevate Soft Robotic Suit](https://arxiv.org/abs/2601.17249)
*Peter Bryan,Rejin John Varghese,Dario Farina*

Main category: cs.RO

TL;DR: 评估Elevate软体机器人外骨骼的舒适性和人体工学性能，该设备通过缆绳驱动辅助肩部抬高，在200N拉力下无不适感，压力分布接近人手抓握范围。


<details>
  <summary>Details</summary>
Motivation: 软体机器人外骨骼具有轻量、低成本、小型化等优势，适合日常使用，但数据驱动、用户定制和舒适优先的设计挑战限制了其广泛应用。本研究旨在定量评估Elevate外骨骼的人体工学和舒适性。

Method: 使用动作捕捉系统和力传感器测量外骨骼在辅助肩部抬高（最高70度）时的人体工学性能。对一名受试者进行两次4小时测试，传输高达200N的缆绳张力，测量肩部压力、体积压缩等参数。

Result: 在200N缆绳张力下无不适感报告。肩部压力估计为69.1-85.1kPa，接近人手抓握范围。躯干和上臂的体积压缩分别小于3%和8%。

Conclusion: 研究结果为Elevate外骨骼的人体工学设计提供了早期验证，为未来患者群体研究奠定了基础，表明软体机器人外骨骼在舒适性和人体工学方面具有良好潜力。

Abstract: Soft robotic suits have the potential to rehabilitate, assist, and augment the human body. The low weight, cost, and minimal form-factor of these devices make them ideal for daily use by both healthy and impaired individuals. However, challenges associated with data-driven, user-specific, and comfort-first design of human-robot interfaces using soft materials limit their widespread translation and adoption. In this work, we present the quantitative evaluation of ergonomics and comfort of the Elevate suit - a cable driven soft robotic suit that assists shoulder elevation. Using a motion-capture system and force sensors, we measured the suit's ergonomics during assisted shoulder elevation up to 70 degrees. Two 4-hour sessions were conducted with one subject, involving transmitting cable tensions of up to 200N with no discomfort reported. We estimated that the pressure applied to the shoulder during assisted movements was within the range seen in a human grasp (approximately 69.1-85.1kPa), and estimated volumetric compression of <3% and <8% across the torso and upper arm, respectively. These results provide early validation of Elevate's ergonomic design in preparation for future studies with patient groups.

</details>


### [117] [EMPM: Embodied MPM for Modeling and Simulation of Deformable Objects](https://arxiv.org/abs/2601.17251)
*Yunuo Chen,Yafei Hu,Lingfeng Sun,Tushar Kusnur,Laura Herlant,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: EMPM是一个基于可微分MPM模拟器的可变形物体建模框架，通过多视角RGB-D视频重建几何与外观，利用物理引擎模拟物体行为，并通过在线优化实现自适应、鲁棒的物理感知表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么过度简化可变形物体的复杂动力学，要么需要大量训练数据，这限制了泛化能力。需要一种物理合理、可泛化且数据高效的可变形物体建模方法。

Method: 基于可微分材料点法(MPM)模拟器构建框架，从多视角RGB-D视频重建几何和外观，使用MPM物理引擎模拟物体行为，通过最小化预测与观测视觉数据的差异来优化，并在线优化MPM参数。

Result: 实验表明EMPM优于弹簧-质量基线模型，能够实现自适应、鲁棒且物理感知的物体表示，为复杂可变形物体的机器人操作开辟了新可能性。

Conclusion: EMPM提供了一个物理合理、可泛化且数据高效的可变形物体建模框架，通过结合视觉重建与物理模拟，实现了对复杂材料动力学的准确捕捉，在机器人操作等领域具有应用前景。

Abstract: Modeling deformable objects - especially continuum materials - in a way that is physically plausible, generalizable, and data-efficient remains challenging across 3D vision, graphics, and robotic manipulation. Many existing methods oversimplify the rich dynamics of deformable objects or require large training sets, which often limits generalization. We introduce embodied MPM (EMPM), a deformable object modeling and simulation framework built on a differentiable Material Point Method (MPM) simulator that captures the dynamics of challenging materials. From multi-view RGB-D videos, our approach reconstructs geometry and appearance, then uses an MPM physics engine to simulate object behavior by minimizing the mismatch between predicted and observed visual data. We further optimize MPM parameters online using sensory feedback, enabling adaptive, robust, and physics-aware object representations that open new possibilities for robotic manipulation of complex deformables. Experiments show that EMPM outperforms spring-mass baseline models. Project website: https://embodied-mpm.github.io.

</details>


### [118] [Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots](https://arxiv.org/abs/2601.17287)
*Yanrong Chen,Xihan Bian*

Main category: cs.RO

TL;DR: 提出一个实时框架，让NAO机器人通过语音韵律与全身手势的同步实现情感化多模态交互，包含双通道情感引擎、时长感知动态时间规整和闭环可行性验证三个创新点。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人越来越多地进入社交场景，实现情感同步的多模态交互仍然是一个重大挑战。为了促进人形机器人在服务角色中的进一步采用和集成，需要解决情感表达与动作协调的问题。

Method: 提出三部分创新：(1) 双通道情感引擎，大语言模型同时生成上下文感知的文本响应和生物力学可行的运动描述符，受结构化关节运动库约束；(2) 时长感知动态时间规整，用于语音输出和运动关键帧的精确时间对齐；(3) 闭环可行性验证，通过实时适应确保手势符合NAO的物理关节限制。

Result: 评估显示，与基于规则的系统相比，情感对齐度提高了21%。通过协调语音音调（由唤醒驱动）与上肢运动学，同时保持下半身稳定性来实现。该框架实现了无缝的感觉运动协调。

Conclusion: 该框架通过实现无缝的感觉运动协调，推进了上下文感知社交机器人在动态应用中的部署，如个性化医疗、互动教育和响应式客户服务平台。

Abstract: As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction remains a significant challenges. To facilitate the further adoption and integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three key innovations: (1) A dual-channel emotion engine where large language model (LLM) simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Duration-aware dynamic time warping for precise temporal alignment of speech output and kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO's physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment compared to rule-based systems, achieved by coordinating vocal pitch (arousal-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.

</details>


### [119] [Eye-Tracking-Driven Control in Daily Task Assistance for Assistive Robotic Arms](https://arxiv.org/abs/2601.17404)
*Anke Fischer-Janzen,Thomas M. Wendt,Kristof Van Laerhoven*

Main category: cs.RO

TL;DR: 提出基于眼动追踪的控制框架，通过任务图标作为标记，结合特征匹配方法，帮助严重身体残疾人士独立完成日常任务，准确率高达97.9%。


<details>
  <summary>Details</summary>
Motivation: 当前眼动追踪驱动的方法面临3D注视估计准确性问题和多任务区分困难。需要为严重身体残疾人士开发能够独立执行日常任务的系统，减少用户负担并提高机器人自主性。

Method: 使用任务图标作为基准标记，结合特征匹配方法，将选定对象数据传输到眼在手配置中完成任务相关测量。系统不需要用户相对于对象位置的知识，可集成最先进的对象检测模型。

Result: 框架在高达97.9%的测量中正确解释对象和任务选择。评估中发现的问题得到改进并作为经验教训分享。开源框架可适应新任务和对象。

Conclusion: 提出的眼动追踪控制框架有效解决了现有方法的局限性，为严重身体残疾人士提供了独立执行日常任务的可行方案，具有高准确性和适应性。

Abstract: Shared control improves Human-Robot Interaction by reducing the user's workload and increasing the robot's autonomy. It allows robots to perform tasks under the user's supervision. Current eye-tracking-driven approaches face several challenges. These include accuracy issues in 3D gaze estimation and difficulty interpreting gaze when differentiating between multiple tasks. We present an eye-tracking-driven control framework, aimed at enabling individuals with severe physical disabilities to perform daily tasks independently. Our system uses task pictograms as fiducial markers combined with a feature matching approach that transmits data of the selected object to accomplish necessary task related measurements with an eye-in-hand configuration. This eye-tracking control does not require knowledge of the user's position in relation to the object. The framework correctly interpreted object and task selection in up to 97.9% of measurements. Issues were found in the evaluation, that were improved and shared as lessons learned. The open-source framework can be adapted to new tasks and objects due to the integration of state-of-the-art object detection models.

</details>


### [120] [DiffusionCinema: Text-to-Aerial Cinematography](https://arxiv.org/abs/2601.17412)
*Valerii Serpiva,Artem Lykov,Jeffrin Sam,Aleksey Fedoseev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 提出基于扩散模型的无人机创意拍摄系统，通过自然语言提示自动生成最佳飞行轨迹，实现文本到电影拍摄的自主控制


<details>
  <summary>Details</summary>
Motivation: 传统无人机操作需要专业技能，用户难以精确控制复杂拍摄动作。本文旨在通过自然语言界面降低无人机创意拍摄的门槛，让用户只需描述拍摄意图即可获得专业级航拍效果

Method: 系统结合自然语言提示和机载摄像头初始视觉快照，使用扩散模型采样满足场景几何和拍摄语义的时空运动规划，生成最优飞行轨迹并由无人机自主执行

Result: NASA-TLX评估显示系统显著降低工作负荷（21.6 vs 58.1），特别是心理需求（11.5 vs 60.5）和挫败感（14.0 vs 54.5）大幅降低，证明文本驱动飞行控制在可用性上的明显优势

Conclusion: 展示了"文本到电影飞行"的新交互范式，扩散模型作为"创意操作员"将故事意图直接转换为空中运动，为无人机创意拍摄提供了更直观、低门槛的解决方案

Abstract: We propose a novel Unmanned Aerial Vehicles (UAV) assisted creative capture system that leverages diffusion models to interpret high-level natural language prompts and automatically generate optimal flight trajectories for cinematic video recording. Instead of manually piloting the drone, the user simply describes the desired shot (e.g., "orbit around me slowly from the right and reveal the background waterfall"). Our system encodes the prompt along with an initial visual snapshot from the onboard camera, and a diffusion model samples plausible spatio-temporal motion plans that satisfy both the scene geometry and shot semantics. The generated flight trajectory is then executed autonomously by the UAV to record smooth, repeatable video clips that match the prompt. User evaluation using NASA-TLX showed a significantly lower overall workload with our interface (M = 21.6) compared to a traditional remote controller (M = 58.1), demonstrating a substantial reduction in perceived effort. Mental demand (M = 11.5 vs. 60.5) and frustration (M = 14.0 vs. 54.5) were also markedly lower for our system, confirming clear usability advantages in autonomous text-driven flight control. This project demonstrates a new interaction paradigm: text-to-cinema flight, where diffusion models act as the "creative operator" converting story intentions directly into aerial motion.

</details>


### [121] [Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.17428)
*Ziming Li,Chenhao Li,Marco Hutter*

Main category: cs.RO

TL;DR: 提出基于学习进度的自动课程强化学习框架LP-ACRL，通过在线估计智能体学习进度自适应调整任务采样分布，无需任务空间难度先验知识，在复杂地形上实现四足机器人高速稳定运动。


<details>
  <summary>Details</summary>
Motivation: 传统课程学习在扩展到复杂、广泛的任务空间时面临限制，因为这类任务空间通常缺乏明确定义的难度结构，难以定义传统方法所需的难度排序。

Method: 提出LP-ACRL框架：在线估计智能体的学习进度，自适应调整任务采样分布，实现无需任务空间难度先验知识的自动课程生成。

Result: 使用LP-ACRL训练的策略使ANYmal D四足机器人在楼梯、斜坡、碎石、低摩擦平面等多种地形上实现并保持2.5 m/s线速度和3.0 rad/s角速度的稳定高速运动，超越了先前方法（通常仅限于平坦地形高速或复杂地形低速）。

Conclusion: LP-ACRL展现出强大的可扩展性和实际应用性，为复杂广泛机器人学习任务空间的课程生成研究提供了稳健的基准。

Abstract: Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.

</details>


### [122] [PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes](https://arxiv.org/abs/2601.17440)
*Xinru Cui,Linxi Feng,Yixuan Zhou,Haoqi Han,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: PILOT：用于感知式移动操作的单阶段强化学习框架，通过跨模态编码器和MoE策略架构，在非结构化环境中实现稳定的人形机器人控制


<details>
  <summary>Details</summary>
Motivation: 现有全身控制器缺乏对外部环境的感知能力，无法在复杂非结构化场景中稳定执行任务，需要能够无缝整合精确移动和灵巧操作的控制器

Method: 提出PILOT统一单阶段强化学习框架，包含：1）跨模态上下文编码器融合预测性本体感知特征和注意力感知表示；2）专家混合策略架构协调不同运动技能

Result: 在仿真和Unitree G1人形机器人上的实验表明，PILOT在稳定性、指令跟踪精度和地形通过性方面优于现有基线方法

Conclusion: PILOT作为鲁棒的基础低级控制器，在非结构化场景中具有强大的移动操作潜力

Abstract: Humanoid robots hold great potential for diverse interactions and daily service tasks within human-centered environments, necessitating controllers that seamlessly integrate precise locomotion with dexterous manipulation. However, most existing whole-body controllers lack exteroceptive awareness of the surrounding environment, rendering them insufficient for stable task execution in complex, unstructured scenarios.To address this challenge, we propose PILOT, a unified single-stage reinforcement learning (RL) framework tailored for perceptive loco-manipulation, which synergizes perceptive locomotion and expansive whole-body control within a single policy. To enhance terrain awareness and ensure precise foot placement, we design a cross-modal context encoder that fuses prediction-based proprioceptive features with attention-based perceptive representations. Furthermore, we introduce a Mixture-of-Experts (MoE) policy architecture to coordinate diverse motor skills, facilitating better specialization across distinct motion patterns. Extensive experiments in both simulation and on the physical Unitree G1 humanoid robot validate the efficacy of our framework. PILOT demonstrates superior stability, command tracking precision, and terrain traversability compared to existing baselines. These results highlight its potential to serve as a robust, foundational low-level controller for loco-manipulation in unstructured scenes.

</details>


### [123] [EquiForm: Noise-Robust SE(3)-Equivariant Policy Learning from 3D Point Clouds](https://arxiv.org/abs/2601.17486)
*Zhiyuan Zhang,Yu She*

Main category: cs.RO

TL;DR: EquiForm：一种针对点云视觉模仿学习的噪声鲁棒SE(3)-等变策略学习框架，通过几何去噪模块和对比等变对齐目标，解决传感器噪声、姿态扰动和遮挡导致的几何失真问题，显著提升策略的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的点云策略对传感器噪声、姿态扰动和遮挡导致的几何失真高度敏感，这些失真会破坏等变假设，影响策略的鲁棒泛化。现有等变方法主要将对称约束编码到神经网络架构中，但未能显式校正噪声引起的几何偏差或强制学习表示的等变一致性。

Method: 1. 形式化分析噪声引起的几何失真如何导致观察到动作映射的等变偏差；2. 引入几何去噪模块，在噪声或不完整观察下恢复一致的3D结构；3. 提出对比等变对齐目标，强制表示在刚性变换和噪声扰动下的一致性；4. 构建集成噪声鲁棒几何推理与现代生成模型的灵活策略学习流程。

Result: 在16个模拟任务和4个真实世界操作任务上评估，相比最先进的点云模仿学习方法，EquiForm在模拟实验中平均提升17.2%，在真实世界实验中平均提升28.1%，展示了强大的噪声鲁棒性和空间泛化能力。

Conclusion: EquiForm通过显式处理噪声引起的几何失真和强制等变一致性，显著提升了点云策略的鲁棒性和泛化能力，为噪声环境下的3D视觉模仿学习提供了有效的解决方案。

Abstract: Visual imitation learning with 3D point clouds has advanced robotic manipulation by providing geometry-aware, appearance-invariant observations. However, point cloud-based policies remain highly sensitive to sensor noise, pose perturbations, and occlusion-induced artifacts, which distort geometric structure and break the equivariance assumptions required for robust generalization. Existing equivariant approaches primarily encode symmetry constraints into neural architectures, but do not explicitly correct noise-induced geometric deviations or enforce equivariant consistency in learned representations. We introduce EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation. EquiForm formalizes how noise-induced geometric distortions lead to equivariance deviations in observation-to-action mappings, and introduces a geometric denoising module to restore consistent 3D structure under noisy or incomplete observations. In addition, we propose a contrastive equivariant alignment objective that enforces representation consistency under both rigid transformations and noise perturbations. Built upon these components, EquiForm forms a flexible policy learning pipeline that integrates noise-robust geometric reasoning with modern generative models. We evaluate EquiForm on 16 simulated tasks and 4 real-world manipulation tasks across diverse objects and scene layouts. Compared to state-of-the-art point cloud imitation learning methods, EquiForm achieves an average improvement of 17.2% in simulation and 28.1% in real-world experiments, demonstrating strong noise robustness and spatial generalization.

</details>


### [124] [MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions](https://arxiv.org/abs/2601.17507)
*Yutong Shen,Hangxu Liu,Kailin Pei,Ruizhe Xia,Tongtong Feng*

Main category: cs.RO

TL;DR: MetaWorld是一个分层世界模型，通过专家策略迁移整合语义规划和物理控制，解决人形机器人操作中的语义-物理鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人操作存在三个主要限制：强化学习的低样本效率、模仿学习的泛化能力差、以及视觉语言模型的物理不一致性。需要一种能有效整合语义理解和物理控制的方法。

Method: 提出分层世界模型，将任务解耦为VLM驱动的语义层和在紧凑状态空间操作的潜在动力学模型。采用动态专家选择和运动先验融合机制，利用预训练的多专家策略库作为可迁移知识，通过两阶段框架实现在线高效适应。

Result: 在Humanoid-Bench上的实验表明，MetaWorld在世界模型为基础的强化学习方法中，在任务完成度和运动连贯性方面表现更优。

Conclusion: MetaWorld通过整合语义规划和物理控制，有效解决了人形机器人操作中的语义-物理鸿沟问题，为机器人学习提供了更高效的框架。

Abstract: Humanoid robot loco-manipulation remains constrained by the semantic-physical gap. Current methods face three limitations: Low sample efficiency in reinforcement learning, poor generalization in imitation learning, and physical inconsistency in VLMs. We propose MetaWorld, a hierarchical world model that integrates semantic planning and physical control via expert policy transfer. The framework decouples tasks into a VLM-driven semantic layer and a latent dynamics model operating in a compact state space. Our dynamic expert selection and motion prior fusion mechanism leverages a pre-trained multi-expert policy library as transferable knowledge, enabling efficient online adaptation via a two-stage framework. VLMs serve as semantic interfaces, mapping instructions to executable skills and bypassing symbol grounding. Experiments on Humanoid-Bench show MetaWorld outperforms world model-based RL in task completion and motion coherence. Our code will be found at https://anonymous.4open.science/r/metaworld-2BF4/

</details>


### [125] [AsterNav: Autonomous Aerial Robot Navigation In Darkness Using Passive Computation](https://arxiv.org/abs/2601.17550)
*Deepak Singh,Shreyas Khobragade,Nitin J. Sanket*

Main category: cs.RO

TL;DR: 提出AsterNav系统，结合红外单目相机、大孔径编码镜头和结构光，在完全黑暗环境中实现微型无人机自主导航，无需GPS或外部基础设施。


<details>
  <summary>Details</summary>
Motivation: 灾后搜救常发生在断电的黑暗环境中，但资源受限的微型无人机无法在黑暗中安全导航寻找幸存者，需要一种能在绝对黑暗中自主导航的解决方案。

Method: 使用红外单目相机+大孔径编码镜头+结构光系统，通过深度相关的离焦线索作为先验，训练AsterNet深度估计模型（在仿真中生成数据，无需真实世界微调），系统在NVIDIA Jetson Orin Nano上以20Hz运行。

Result: 在真实世界实验中成功导航，包括黑暗哑光障碍物和细绳（直径6.25mm），对未知物体形状、位置和材料达到95.5%的整体成功率，是首个基于单目结构光的四旋翼绝对黑暗导航工作。

Conclusion: AsterNav系统证明了在完全黑暗环境中使用低成本、轻量级硬件实现微型无人机自主导航的可行性，为灾后搜救等应用提供了有效解决方案。

Abstract: Autonomous aerial navigation in absolute darkness is crucial for post-disaster search and rescue operations, which often occur from disaster-zone power outages. Yet, due to resource constraints, tiny aerial robots, perfectly suited for these operations, are unable to navigate in the darkness to find survivors safely. In this paper, we present an autonomous aerial robot for navigation in the dark by combining an Infra-Red (IR) monocular camera with a large-aperture coded lens and structured light without external infrastructure like GPS or motion-capture. Our approach obtains depth-dependent defocus cues (each structured light point appears as a pattern that is depth dependent), which acts as a strong prior for our AsterNet deep depth estimation model. The model is trained in simulation by generating data using a simple optical model and transfers directly to the real world without any fine-tuning or retraining. AsterNet runs onboard the robot at 20 Hz on an NVIDIA Jetson Orin$^\text{TM}$ Nano. Furthermore, our network is robust to changes in the structured light pattern and relative placement of the pattern emitter and IR camera, leading to simplified and cost-effective construction. We successfully evaluate and demonstrate our proposed depth navigation approach AsterNav using depth from AsterNet in many real-world experiments using only onboard sensing and computation, including dark matte obstacles and thin ropes (diameter 6.25mm), achieving an overall success rate of 95.5% with unknown object shapes, locations and materials. To the best of our knowledge, this is the first work on monocular, structured-light-based quadrotor navigation in absolute darkness.

</details>


### [126] [Correct-by-Construction Vision-based Pose Estimation using Geometric Generative Models](https://arxiv.org/abs/2601.17556)
*Ulices Santa Cruz,Mahmoud Elfar,Yasser Shoukry*

Main category: cs.RO

TL;DR: 提出一种用于视觉姿态估计的可认证神经网络框架，结合物理驱动建模与学习估计，为自动驾驶等安全关键应用提供可证明的误差保证。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络在视觉任务中缺乏可证明的正确性保证，这对于自动驾驶等安全关键应用至关重要。需要一种既能利用神经网络优势又能提供可证明保证的姿态估计方法。

Method: 提出几何生成模型（GGM），其参数源自目标物体（如交通标志）的成像过程。基于GGM训练神经网络姿态估计器，并利用神经网络可达性分析设计可认证物体检测器，最终构建多阶段感知管道。

Result: 在合成和真实图像上评估框架，包括事件相机捕获的交通标志图像。训练后的编码器能有效估计姿态，且符合框架提供的认证误差边界。

Conclusion: 该框架成功将物理驱动建模与学习估计结合，为安全关键应用中的视觉姿态估计提供了可证明的保证，并能扩展到杂乱环境中。

Abstract: We consider the problem of vision-based pose estimation for autonomous systems. While deep neural networks have been successfully used for vision-based tasks, they inherently lack provable guarantees on the correctness of their output, which is crucial for safety-critical applications. We present a framework for designing certifiable neural networks (NNs) for perception-based pose estimation that integrates physics-driven modeling with learning-based estimation. The proposed framework begins by leveraging the known geometry of planar objects commonly found in the environment, such as traffic signs and runway markings, referred to as target objects. At its core, it introduces a geometric generative model (GGM), a neural-network-like model whose parameters are derived from the image formation process of a target object observed by a camera. Once designed, the GGM can be used to train NN-based pose estimators with certified guarantees in terms of their estimation errors. We first demonstrate this framework in uncluttered environments, where the target object is the only object present in the camera's field of view. We extend this using ideas from NN reachability analysis to design certified object NN that can detect the presence of the target object in cluttered environments. Subsequently, the framework consolidates the certified object detector with the certified pose estimator to design a multi-stage perception pipeline that generalizes the proposed approach to cluttered environments, while maintaining its certified guarantees. We evaluate the proposed framework using both synthetic and real images of various planar objects commonly encountered by autonomous vehicles. Using images captured by an event-based camera, we show that the trained encoder can effectively estimate the pose of a traffic sign in accordance with the certified bound provided by the framework.

</details>


### [127] [Delay-Compensated Stiffness Estimation for Robot-Mediated Dyadic Interaction](https://arxiv.org/abs/2601.17812)
*Mingtian Du,Suhas Raghavendra Kulkarni,Bernardo Noronha,Domenico Campolo*

Main category: cs.RO

TL;DR: 提出一种延迟补偿的刚度估计框架，通过代数估计器和归一化加权最小二乘法，解决远程物理治疗中网络延迟导致的力与位置信号时间错位问题。


<details>
  <summary>Details</summary>
Motivation: 远程机器人介导的人-人互动中，网络延迟导致力与位置信号时间错位，传统刚度估计方法忽略延迟因素，在延迟增加时产生显著误差，影响治疗师对患者僵硬度的准确感知。

Method: 1) 基于准静态平衡推导代数估计器，显式考虑专家输入与新手响应的时间对齐；2) 引入归一化加权最小二乘法(NWLS)来鲁棒地过滤代数推导产生的动态偏差。

Result: 在商用康复机器人(H-MAN)平台上的实验表明，该方法显著优于标准估计器，在多种引入延迟下保持一致的跟踪精度。

Conclusion: 该框架为远程双向互动中实现高保真触觉感知提供了有前景的解决方案，有望在网络环境中实现可靠的治疗刚度评估。

Abstract: Robot-mediated human-human (dyadic) interactions enable therapists to provide physical therapy remotely, yet an accurate perception of patient stiffness remains challenging due to network-induced haptic delays. Conventional stiffness estimation methods, which neglect delay, suffer from temporal misalignment between force and position signals, leading to significant estimation errors as delays increase. To address this, we propose a robust, delay-compensated stiffness estimation framework by deriving an algebraic estimator based on quasi-static equilibrium that explicitly accounts for temporally aligning the expert's input with the novice's response. A Normalised Weighted Least Squares (NWLS) implementation is then introduced to robustly filter dynamic bias resulting from the algebraic derivation. Experiments using commercial rehabilitation robots (H-MAN) as the platform demonstrate that the proposed method significantly outperforms the standard estimator, maintaining consistent tracking accuracy under multiple introduced delays. These findings offer a promising solution for achieving high-fidelity haptic perception in remote dyadic interaction, potentially facilitating reliable stiffness assessment in therapeutic settings across networks.

</details>


### [128] [Less Is More: Scalable Visual Navigation from Limited Data](https://arxiv.org/abs/2601.17815)
*Yves Inglin,Jonas Frey,Changan Chen,Marco Hutter*

Main category: cs.RO

TL;DR: 利用几何规划器生成合成轨迹来增强有限的人类演示数据，训练基于Transformer的视觉导航策略，实现更高效的目标条件导航


<details>
  <summary>Details</summary>
Motivation: 模仿学习虽然为移动机器人视觉导航提供了强大框架，但其效果严重依赖训练数据的质量和多样性。人类演示数据成本高昂且有限，需要寻找更高效的数据增强方法

Method: 提出LiMo（Less is More）方法：1）使用经典几何规划器生成合成轨迹作为监督信号；2）训练基于Transformer的视觉导航策略，从单张RGB观测预测目标条件的SE(2)轨迹；3）将有限的人类专家演示与规划器生成的监督数据相结合

Result: 通过数据增强获得了显著的性能提升，证明了数据集规模和多样性对规划性能的重要影响。实现了真实机器人部署，验证了方法的有效性

Conclusion: 鲁棒的视觉导航不是通过简单地收集更多演示数据实现的，而是通过战略性地策划多样化、高质量的数据集。可扩展的、特定于具体机器人的几何监督是实现数据高效视觉导航的实用途径

Abstract: Imitation learning provides a powerful framework for goal-conditioned visual navigation in mobile robots, enabling obstacle avoidance while respecting human preferences and social norms. However, its effectiveness depends critically on the quality and diversity of training data. In this work, we show how classical geometric planners can be leveraged to generate synthetic trajectories that complement costly human demonstrations. We train Less is More (LiMo), a transformer-based visual navigation policy that predicts goal-conditioned SE(2) trajectories from a single RGB observation, and find that augmenting limited expert demonstrations with planner-generated supervision yields substantial performance gains. Through ablations and complementary qualitative and quantitative analyses, we characterize how dataset scale and diversity affect planning performance. We demonstrate real-robot deployment and argue that robust visual navigation is enabled not by simply collecting more demonstrations, but by strategically curating diverse, high-quality datasets. Our results suggest that scalable, embodiment-specific geometric supervision is a practical path toward data-efficient visual navigation.

</details>


### [129] [NeuroManip: Prosthetic Hand Manipulation System Based on EMG and Eye Tracking Powered by the Neuromorphic Processor AltAi](https://arxiv.org/abs/2601.17991)
*Roman Akinshin,Elizaveta Lopatina,Kirill Bogatikov,Nikolai Kiz,Anna V. Makarova,Mikhail Lebedev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Valerii Kangler*

Main category: cs.RO

TL;DR: 提出结合表面肌电信号与眼动追踪计算机视觉的神经形态控制架构，用于上肢假肢，实现低功耗、高精度的实时控制。


<details>
  <summary>Details</summary>
Motivation: 传统肌电假肢控制存在功耗高、识别精度有限、缺乏情境感知等问题，需要更节能、可靠且能根据使用场景自适应调整的控制方案。

Method: 使用表面肌电信号和眼动追踪头戴设备+场景摄像头，通过部署在AltAi神经形态处理器上的脉冲神经网络实时分类EMG模式，同时识别用户注视的物体，结合视觉信息限制决策空间。

Result: 系统在6种功能手势上达到与传统肌电接口相当的识别性能，当视觉管道将决策空间限制到3个情境合适的手势时，识别准确率提升至约95%，同时排除不安全、不合适的抓握动作。

Conclusion: 提出的神经形态情境感知控制器能提供节能可靠的假肢控制，有潜力改善上肢截肢者日常活动的安全性和可用性。

Abstract: This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.

</details>


### [130] [Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization](https://arxiv.org/abs/2601.18121)
*Byeonggyeol Choi,Woojin Oh,Jongwoo Lim*

Main category: cs.RO

TL;DR: 提出模拟循环优化框架，将视觉对齐的手部轨迹转换为物理可执行轨迹，解决现有数据集在物理模拟中不真实的问题。


<details>
  <summary>Details</summary>
Motivation: 现有手部操作数据集（如DexYCB和HO3D）主要为视觉对齐优化，但在物理模拟中重放时会产生物理上不合理的结果，包括穿透、接触丢失和不稳定抓握。

Method: 使用模拟循环优化框架，将问题表述为可处理的黑盒优化问题。采用基于稀疏时间关键帧的低维样条表示参数化手部运动，使用CMA-ES梯度自由优化器将高保真物理引擎作为黑盒目标函数。

Result: 相比MANIPTRANS等现有方法，本方法在重放时获得更低的手部和物体姿态误差，更准确地恢复手-物体物理交互。

Conclusion: 提供了一种通用且可扩展的方法，将视觉演示转换为物理有效轨迹，为鲁棒策略学习生成高保真数据。

Abstract: Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps.
  We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration.
  Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.

</details>


### [131] [Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation](https://arxiv.org/abs/2601.18289)
*Jialong Li,Zhenguo Wang,Tianci Wang,Maj Stenmark,Volker Krueger*

Main category: cs.RO

TL;DR: Quest2ROS2是一个用于双手遥操作的ROS2开源框架，通过相对运动控制克服工作空间限制，支持直观的姿势无关操作，具有实时可视化、夹爪控制和暂停重置等功能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够扩展机器人数据收集的双手遥操作框架，解决传统VR遥操作中的工作空间限制问题，使操作更加直观和灵活。

Method: 基于相对运动控制方法，通过计算VR控制器姿态变化来确定机器人运动，实现姿势无关的操作。采用模块化架构，支持"并排"和"镜像"两种控制模式，集成了实时RViz可视化、流线型夹爪控制和暂停重置功能。

Result: 成功开发了Quest2ROS2框架，克服了工作空间限制，实现了直观的双手遥操作，支持多种机器人平台，提高了操作体验和数据收集效率。

Conclusion: Quest2ROS2是一个有效的开源ROS2双手遥操作框架，通过相对运动控制解决了工作空间限制问题，提供了安全易用的操作体验，有助于扩展机器人数据收集能力。

Abstract: Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports "Side-by-Side" and "Mirror" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.

</details>


### [132] [TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion](https://arxiv.org/abs/2601.18323)
*Weishi Mi,Yong Bao,Xiaowei Chi,Xiaozhu Ju,Zhiyuan Qin,Kuangzhi Ge,Kai Tang,Peidong Jia,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: TC-IDM通过提取世界模型生成视频中的工具点云轨迹，将其转换为可执行的6自由度末端执行器运动，桥接了视觉规划与物理控制之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作范式依赖大规模高质量机器人数据，泛化能力有限；而生成式世界模型的像素级规划与物理可执行动作之间存在关键差距。

Method: TC-IDM从世界模型生成的视频中通过分割和3D运动估计提取工具点云轨迹，采用解耦的动作头将这些规划轨迹投影为6自由度末端执行器运动和控制信号。

Result: 在真实世界评估中，结合TC-IDM的世界模型平均成功率61.11%，简单任务77.7%，零样本可变形物体任务38.46%，显著优于端到端VLA基线和其他逆动力学模型。

Conclusion: TC-IDM通过"规划-翻译"范式有效桥接了视觉规划与物理控制，支持多种末端执行器，提升视角不变性，在长视野和分布外任务中表现出强泛化能力。

Abstract: The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions.
  To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control.
  TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals.
  This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects.
  In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.

</details>


### [133] [SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation](https://arxiv.org/abs/2601.18442)
*Hongyi Zhao,Shuo Wang,Qijie He,Ziyuan Pu*

Main category: cs.RO

TL;DR: SG-CADVLM是一个基于上下文感知解码的视觉语言模型框架，能够从事故报告和道路网络图中生成安全关键场景，相比基线方法将关键风险场景生成率从12.5%提升到84.4%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶安全验证需要测试安全关键场景，但这些事件在真实驾驶中罕见且测试成本高。事故报告提供了真实的安全事件规格，但现有方法存在多样性不足、物理保真度差、上下文抑制等问题。

Method: 提出了SG-CADVLM框架，集成上下文感知解码与多模态输入处理，从事故报告和道路网络图生成安全关键场景，缓解VLM幻觉问题，同时生成道路几何和车辆轨迹。

Result: SG-CADVLM生成关键风险场景的比例达到84.4%，相比基线方法的12.5%提升了469%，并能生成可执行的自动驾驶测试仿真。

Conclusion: SG-CADVLM通过上下文感知解码有效解决了VLM的上下文抑制问题，显著提高了安全关键场景生成的准确性和实用性，为自动驾驶安全验证提供了有效的仿真生成工具。

Abstract: Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.

</details>


### [134] [DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation](https://arxiv.org/abs/2601.18492)
*Zijun Li,Shijie Li,Zhenxi Zhang,Bin Li,Shoujun Zhou*

Main category: cs.RO

TL;DR: DV-VLN提出了一种新的视觉语言导航框架，采用生成-验证范式，通过结构化导航思维链和双重验证机制提升导航决策的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的导航代理通常依赖单次动作决策，从嘈杂的多视角文本化观察中选择一个选项。由于局部不匹配和不完善的中间推理，这种决策容易偏离正确路径，导致误差累积和在未见环境中可靠性降低。

Method: DV-VLN采用生成-验证范式：1) 对开源LLaMA-2骨干进行参数高效领域自适应，生成结构化导航思维链；2) 通过两个互补通道验证候选动作：真伪验证(TFV)和掩码实体验证(MEV)；3) 聚合多个样本的验证成功次数进行动作选择，生成可解释的重新排序分数。

Result: 在R2R、RxR（英文子集）和REVERIE数据集上的实验表明，DV-VLN相比直接预测和仅采样基线有持续改进，在纯语言VLN代理中达到竞争性性能，与多个跨模态系统相比也显示出有前景的结果。

Conclusion: DV-VLN通过生成-验证范式和双重验证机制，有效解决了单次决策中的误差累积问题，提高了导航决策的可靠性和可解释性，为语言驱动的导航任务提供了新的解决方案。

Abstract: Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.

</details>


### [135] [SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction](https://arxiv.org/abs/2601.18537)
*Linyong Gan,Zimo Li,Wenxin Xu,Xingjian Li,Jianhua Z. Huang,Enmei Tu,Shuhang Chen*

Main category: cs.RO

TL;DR: 提出基于语义关键点条件化的轨迹建模框架，通过预测下一关键点来分解长时程预测为全局语义决策和局部运动建模，提升船舶轨迹预测的准确性和方向一致性。


<details>
  <summary>Details</summary>
Motivation: 现有船舶轨迹预测方法在长时程预测中难以保持全局方向一致性，容易产生漂移或不合理的轨迹，主要原因是复杂航行行为和环境因素带来的不确定性累积。

Method: 提出语义关键点条件化轨迹建模框架，将未来轨迹预测条件化于高层级的下一关键点（NKP），该关键点捕捉航行意图。采用预训练-微调策略从历史观测中高效估计NKP先验。

Result: 在真实AIS数据上的大量实验表明，该方法在长航行时间、方向准确性和细粒度轨迹预测方面一致优于现有最先进方法。

Conclusion: 通过将长时程预测分解为全局语义决策和局部运动建模，有效限制了未来轨迹的语义可行子集，显著提升了船舶轨迹预测的准确性和鲁棒性。

Abstract: Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.

</details>


### [136] [Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field](https://arxiv.org/abs/2601.18548)
*Yulin Li,Zhiyuan Song,Yiming Li,Zhicheng Song,Kai Chen,Chunxin Zheng,Zhihai Bi,Jiahang Cao,Sylvain Calinon,Fan Shi,Jun Ma*

Main category: cs.RO

TL;DR: 提出GCDF方法，将配置空间距离场扩展到移动机械臂，实现高效碰撞推理和轨迹优化


<details>
  <summary>Details</summary>
Motivation: 移动机械臂在复杂受限空间中的全身轨迹优化面临高维非凸性和快速准确碰撞推理的挑战，需要绕过非线性配置到工作空间的映射

Method: 提出广义配置空间距离场(GCDF)，扩展到具有平移和旋转关节的移动机械臂；开发数据生成和训练流程获得连续神经GCDF；构建基于GCDF的序列凸优化框架

Result: GCDF保持了类欧几里得局部距离结构，准确编码配置空间中的全身几何；支持高效GPU批量查询；优化框架能处理大量隐式约束

Conclusion: GCDF为移动机械臂提供了优化友好的碰撞代价表示，支持在复杂环境中进行高效轨迹优化和快速重规划

Abstract: Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.

</details>


### [137] [Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation](https://arxiv.org/abs/2601.18569)
*Seokju Lee,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出一种基于注意力机制的神经增强卡尔曼滤波器（AttenNKF），用于腿式机器人的状态估计，通过神经网络补偿器检测和补偿脚滑引起的误差。


<details>
  <summary>Details</summary>
Motivation: 脚滑是腿式机器人状态估计的主要误差来源，当脚滑发生时，运动学测量违反无滑移假设，在更新步骤中引入偏差。现有方法难以有效处理脚滑引起的误差。

Method: 将不变扩展卡尔曼滤波器（InEKF）与神经补偿器结合，使用注意力机制根据脚滑严重程度推断误差，然后将该估计作为后更新补偿应用于InEKF状态。补偿器在潜在空间中训练，以减少对原始输入尺度的敏感性，并鼓励结构化的滑移条件补偿，同时保留InEKF递归。

Result: 实验表明，与现有的腿式机器人状态估计器相比，该方法性能有所提升，特别是在易滑移条件下表现更好。

Conclusion: 提出的AttenNKF方法能够有效估计和补偿脚滑引起的误差，提高了腿式机器人在滑移条件下的状态估计精度，为腿式机器人在复杂地形中的鲁棒导航提供了解决方案。

Abstract: In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.

</details>


### [138] [ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection](https://arxiv.org/abs/2601.18629)
*Yiming Wang,Ruogu Zhang,Minyang Li,Hao Shi,Junbo Wang,Deyi Li,Jieji Ren,Wenhai Liu,Weiming Wang,Hao-Shu Fang*

Main category: cs.RO

TL;DR: ExoGS是一个机器人无关的4D真实-仿真-真实框架，通过被动外骨骼捕获人类演示的精确轨迹和RGB观测，将静态环境和动态交互重建为可编辑的3D高斯泼溅资产，实现几何一致的重放和大规模数据增强，显著提升接触丰富任务的数据效率和策略泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有真实-仿真-真实技术主要关注环境级视觉转移，忽略了交互转移，而接触丰富的任务在纯仿真中获取交互数据具有挑战性且效率低下。需要一种能够同时捕获静态环境和动态交互的框架，以实现可扩展的机器人操作数据收集和策略学习。

Method: 1. 使用自主设计的机器人同构被动外骨骼AirExo-3捕获毫米级精度的运动轨迹和同步RGB观测；2. 将机器人、物体和环境重建为可编辑的3D高斯泼溅资产；3. 采用轻量级掩码适配器向策略注入实例级语义，增强视觉域偏移下的鲁棒性。

Result: 真实世界实验表明，ExoGS相比基于遥操作的基线方法，显著提高了数据效率和策略泛化能力。代码和硬件文件已在GitHub上开源。

Conclusion: ExoGS提供了一个新颖的解决方案，能够无缝地将真实世界的静态环境和动态交互转移到仿真环境，为可扩展的操作数据收集和策略学习开辟了新途径，特别是在接触丰富的任务中表现出色。

Abstract: Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.

</details>


### [139] [Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation](https://arxiv.org/abs/2601.18639)
*Ojasva Mishra,Xiaolong Wu,Min Xu*

Main category: cs.RO

TL;DR: 提出一种面向实际实现的离散时间关节控制分析与调参流程，考虑离散化、饱和、延迟等因素，通过稳定性分析、抗饱和实现和贝叶斯优化提升控制性能


<details>
  <summary>Details</summary>
Motivation: 实际机器人关节控制中，PID回路因离散时间执行、执行器饱和、小延迟和测量不完美等因素，与连续时间理论存在偏差，需要实现感知的分析和调参方法

Method: 1) 使用Jury准则推导欧拉和精确零阶保持离散化下的PI稳定性区域；2) 评估饱和主导机制下的离散反计算抗饱和实现；3) 提出混合认证贝叶斯优化流程，筛选不稳定候选参数并优化鲁棒IAE目标

Result: 在模拟不确定性、延迟、噪声、量化和更紧饱和的随机模型族中，鲁棒导向调参将中位IAE从0.843提升至0.430，同时保持中位超调低于2%；认证筛选在完整鲁棒评估前拒绝11.6%的随机采样增益

Conclusion: 提出的实现感知分析和调参流程能有效处理离散时间关节控制的实际限制，通过稳定性认证和贝叶斯优化显著提升控制性能，无需硬件实验即可提高采样效率

Abstract: The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($τ=1.0$~s, $Δt=0.01$~s, $u\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\%$. In simulation-only tuning, the certification screen rejects $11.6\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.

</details>


### [140] [A Pragmatic VLA Foundation Model](https://arxiv.org/abs/2601.18692)
*Wei Wu,Fan Lu,Yunnan Wang,Shuai Yang,Shi Liu,Fangjing Wang,Qian Zhu,He Sun,Yong Wang,Shuailei Ma,Yiyu Ren,Kejia Zhang,Hui Yu,Jingmei Zhao,Shuai Zhou,Zhenqi Qiu,Houlong Xiong,Ziyu Wang,Zechen Wang,Ran Cheng,Yong-Lu Li,Yongtao Huang,Xing Zhu,Yujun Shen,Kecheng Zheng*

Main category: cs.RO

TL;DR: LingBot-VLA是一个基于约2万小时真实世界数据训练的视觉-语言-动作基础模型，在3个机器人平台上完成100个任务测试，性能优于竞争对手，代码库效率高，适合实际部署。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在不同任务和平台间忠实泛化、同时保证成本效率（数据需求和GPU训练时间）的视觉-语言-动作基础模型，以推动机器人操作领域的发展。

Method: 使用来自9种流行双臂机器人配置的约2万小时真实世界数据训练LingBot-VLA模型，构建高效代码库实现每秒261样本/GPU的吞吐量，在3个机器人平台上进行系统评估。

Result: 模型在3个机器人平台上完成100个任务测试（每个任务130次后训练测试），表现明显优于竞争对手，展示了强大的性能和广泛的泛化能力；代码库相比现有VLA代码库有1.5-2.8倍加速。

Conclusion: LingBot-VLA模型具有强大的性能、广泛的泛化能力和高效的训练代码库，适合实际部署；通过开源代码、基础模型和基准数据，旨在推动机器人学习领域发展，支持更具挑战性的任务和健全的评估标准。

Abstract: Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.

</details>


### [141] [Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods](https://arxiv.org/abs/2601.18723)
*Mengyuan Liu,Juyi Sheng,Peiming Li,Ziyi Wang,Tianming Xu,Tiantian Xu,Hong Liu*

Main category: cs.RO

TL;DR: 提出Eval-Actions基准和AutoEval架构，解决机器人模仿学习中可信评估的缺失问题，通过多维度监督信号和时空聚合方法提升评估质量。


<details>
  <summary>Details</summary>
Motivation: 当前机器人模仿学习的评估方法滞后，仅依赖二元成功率，无法评估可信度的关键维度：源真实性（区分策略行为与人工遥操作）和执行质量（平滑度、安全性）。

Method: 1) 构建Eval-Actions基准，包含VA/VLA策略执行轨迹和人工遥操作数据（含失败场景），采用三种监督信号：专家评分、排名引导偏好和思维链；2) 提出AutoEval架构：使用时空聚合进行语义评估，辅助运动学校准信号优化运动平滑度；3) AutoEval-P版本引入组相对策略优化增强逻辑推理能力。

Result: AutoEval在专家评分和排名引导协议下分别获得0.81和0.84的斯皮尔曼等级相关系数；框架具备强大的源判别能力，能99.6%准确区分策略生成视频与遥操作视频。

Conclusion: 提出的Eval-Actions基准和AutoEval架构为机器人模仿学习建立了可信评估标准，解决了当前评估方法的局限性，为未来研究提供了可靠的评估框架。

Abstract: Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.

</details>


### [142] [Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge](https://arxiv.org/abs/2601.18733)
*Li Kang,Heng Zhou,Xiufeng Song,Rui Li,Bruno N. Y. Chen,Ziye Wang,Ximeng Meng,Stone Tao,Yiran Qin,Xiaohong Liu,Ruimao Zhang,Lei Bai,Yilun Du,Hao Su,Philip Torr,Zhenfei Yin,Ruihao Gong,Yejun Zeng,Fengjun Zhong,Shenghao Jin,Jinyang Guo,Xianglong Liu,Xiaojun Jia,Tianqi Shan,Wenqi Ren,Simeng Qin,Jialing Yang,Xiaoyu Ma,Tianxing Chen,Zixuan Li,Zijian Cai,Yan Qin,Yusen Qin,Qiangyu Chen,Kaixuan Wang,Zhaoming Han,Yao Mu,Ping Luo,Yuanqi Yao,Haoming Song,Jan-Nico Zaech,Fabien Despinoy,Danda Pani Paudel,Luc Van Gool*

Main category: cs.RO

TL;DR: 该论文介绍了NeurIPS 2025 SpaVLE研讨会上的多智能体机器人系统(MARS)挑战赛，旨在推动具身AI中多智能体协作的研究，重点关注规划与控制两个关键领域。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI向更复杂任务场景发展，多智能体系统框架对于实现可扩展、高效和协作的解决方案变得至关重要。这一转变受到三个主要因素的推动：智能体能力提升、通过任务委派增强系统效率、以及实现高级人机交互。

Method: 提出MARS挑战赛作为研究平台，聚焦两个关键领域：1) 使用视觉语言模型进行多智能体具身规划以协调任务；2) 在动态环境中执行机器人操作的政策执行。通过评估参与者提交的解决方案来研究多智能体协作。

Result: 挑战赛为具身多智能体系统的设计和协调提供了有价值的见解，通过参与者提交的解决方案评估，为未来高级协作AI系统的发展做出贡献。

Conclusion: MARS挑战赛通过关注规划与控制两个关键领域，为解决多智能体协作的挑战提供了重要平台，推动了具身AI向更复杂、协作的多智能体系统发展。

Abstract: Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.

</details>


### [143] [Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery](https://arxiv.org/abs/2601.18765)
*Shutong Chen,Adnan Aijaz,Yansha Deng*

Main category: cs.RO

TL;DR: 提出面向目标的通信框架，通过联合设计通信-计算-控制回路，实现快速鲁棒的机器人故障检测与恢复，相比现有方法减少82.6%的FDR时间并提高76%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有故障检测与恢复框架存在通信计算延迟大、运动生成不可靠等问题，主要因为通信-计算-控制回路设计未考虑下游FDR目标。智能工厂中机器人需要在动态不确定且有人参与的环境中实现低延迟鲁棒的故障处理。

Method: 1) 故障检测：定义并提取3D场景图作为语义表示，通过监控3D-SG中的空间关系变化检测故障；2) 故障恢复：通过LoRA微调小型语言模型，利用知识蒸馏增强推理和泛化能力生成恢复动作；3) 设计轻量级目标导向数字孪生重建模块，仅使用任务相关物体轮廓细化恢复动作。

Result: 广泛仿真表明，相比依赖视觉语言模型进行故障检测和大语言模型进行故障恢复的最先进框架，GoC框架将FDR时间减少高达82.6%，任务成功率提高高达76%。

Conclusion: 提出的面向目标通信框架通过联合设计通信-计算-控制回路，实现了快速鲁棒的机器人故障检测与恢复，显著提升了智能工厂中机器人系统的可靠性和效率。

Abstract: Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.

</details>
