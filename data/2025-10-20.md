<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration](https://arxiv.org/abs/2510.15114)
*Marios-Nektarios Stamatopoulos,Elias Small,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出了一种使用异构无人机进行全自主空中砌体建造的框架，通过实验验证了其有效性。该框架包含专门的砖块搬运无人机和粘合剂应用无人机，采用反应式任务规划和分层状态机确保鲁棒操作。


<details>
  <summary>Details</summary>
Motivation: 开发全自主的空中砌体建造系统，利用异构无人机协同工作，实现砖块精确放置和粘合剂自动应用，为未来自主空中机器人建造奠定基础。

Method: 开发了两种专用无人机：砖块搬运无人机（配备球关节驱动机制）和粘合剂应用无人机（配备伺服控制阀和挤出喷嘴）。采用反应式任务规划、分层状态机、动态任务分配和最小急动轨迹生成技术。砖块搬运无人机使用机载视觉系统实时估计砖块位姿。

Result: 实验结果表明该框架有效，成功实现了全自主空中砌体建造，其中一架无人机精确放置砖块，另一架自动在砖块间应用粘合剂材料。

Conclusion: 这是首个使用异构无人机进行全自主空中砌体建造的实验演示，证明了所提出框架的有效性，并展示了其在自主空中机器人建造领域的应用潜力。

Abstract: This article presents a fully autonomous aerial masonry construction
framework using heterogeneous unmanned aerial vehicles (UAVs), supported by
experimental validation. Two specialized UAVs were developed for the task: (i)
a brick-carrier UAV equipped with a ball-joint actuation mechanism for precise
brick manipulation, and (ii) an adhesion UAV integrating a servo-controlled
valve and extruder nozzle for accurate adhesion application. The proposed
framework employs a reactive mission planning unit that combines a dependency
graph of the construction layout with a conflict graph to manage simultaneous
task execution, while hierarchical state machines ensure robust operation and
safe transitions during task execution. Dynamic task allocation allows
real-time adaptation to environmental feedback, while minimum-jerk trajectory
generation ensures smooth and precise UAV motion during brick pickup and
placement. Additionally, the brick-carrier UAV employs an onboard vision system
that estimates brick poses in real time using ArUco markers and a least-squares
optimization filter, enabling accurate alignment during construction. To the
best of the authors' knowledge, this work represents the first experimental
demonstration of fully autonomous aerial masonry construction using
heterogeneous UAVs, where one UAV precisely places the bricks while another
autonomously applies adhesion material between them. The experimental results
supported by the video showcase the effectiveness of the proposed framework and
demonstrate its potential to serve as a foundation for future developments in
autonomous aerial robotic construction.

</details>


### [2] [RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation](https://arxiv.org/abs/2510.15189)
*Xiangyu Chen,Chuhao Zhou,Yuxi Liu,Jianfei Yang*

Main category: cs.RO

TL;DR: 提出了角色模型强化学习(RM-RL)框架，通过自动生成近似最优动作标签来替代人工演示，统一了在线和离线训练，在精密机器人操作任务中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 精密机器人操作任务中，现有方法依赖高质量人工演示数据，但获取困难且耗时；离线强化学习存在分布偏移和低数据效率问题。

Method: 采用角色模型策略自动为在线训练数据生成标签，将策略学习重新表述为监督训练，结合混合训练方案重复利用在线数据。

Result: 相比现有RL方法收敛更快更稳定，在真实世界操作中翻译精度提升53%，旋转精度提升20%，成功完成细胞板精确放置等挑战性任务。

Conclusion: RM-RL框架有效解决了精密操作任务中的数据获取和训练效率问题，在无需人工演示的情况下实现了卓越的性能表现。

Abstract: Precise robot manipulation is critical for fine-grained applications such as
chemical and biological experiments, where even small errors (e.g., reagent
spillage) can invalidate an entire task. Existing approaches often rely on
pre-collected expert demonstrations and train policies via imitation learning
(IL) or offline reinforcement learning (RL). However, obtaining high-quality
demonstrations for precision tasks is difficult and time-consuming, while
offline RL commonly suffers from distribution shifts and low data efficiency.
We introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies
online and offline training in real-world environments. The key idea is a
role-model strategy that automatically generates labels for online training
data using approximately optimal actions, eliminating the need for human
demonstrations. RM-RL reformulates policy learning as supervised training,
reducing instability from distribution mismatch and improving efficiency. A
hybrid training scheme further leverages online role-model data for offline
reuse, enhancing data efficiency through repeated sampling. Extensive
experiments show that RM-RL converges faster and more stably than existing RL
methods, yielding significant gains in real-world manipulation: 53% improvement
in translation accuracy and 20% in rotation accuracy. Finally, we demonstrate
the successful execution of a challenging task, precisely placing a cell plate
onto a shelf, highlighting the framework's effectiveness where prior methods
fail.

</details>


### [3] [Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit](https://arxiv.org/abs/2510.15199)
*Borna Monazzah Moghaddam,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了Lagrange-Poincare-Kepler方程(LPKE)，用于在非惯性轨道参考系中建模航天器-机械臂系统的动力学，结合了航天器姿态、轨道运动和机械臂运动学的耦合效应。


<details>
  <summary>Details</summary>
Motivation: 扩展Lagrange-Poincare方程，以更好地建模在轨道环境中运行的航天器-机械臂系统的动力学，特别是考虑非惯性轨道参考系的影响。

Method: 结合Euler-Poincare方程（航天器基座）、开普勒轨道动力学（参考系）和简化Euler-Lagrange方程（机械臂形状空间），使用指数关节参数化，基于主丛上的Lagrange-d'Alembert原理推导结构矩阵。

Result: 推导出了新的封闭形式结构矩阵，明确捕捉轨道扰动效应及其与机械臂系统的动态耦合，能够系统包含外部施加的对称破缺力。

Conclusion: LPKE框架在建模轨道环境中的航天器-机械臂系统动力学方面具有数值优势，可直接集成到硬件在环仿真和基于模型的控制架构中。

Abstract: This article presents an extension of the Lagrange-Poincare Equations (LPE)
to model the dynamics of spacecraft-manipulator systems operating within a
non-inertial orbital reference frame. Building upon prior formulations of LPE
for vehicle-manipulator systems, the proposed framework, termed the
Lagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between
spacecraft attitude dynamics, orbital motion, and manipulator kinematics. The
formalism combines the Euler-Poincare equations for the base spacecraft,
Keplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange
equations for the manipulator's shape space, using an exponential joint
parametrization. Leveraging the Lagrange-d'Alembert principle on principal
bundles, we derive novel closed-form structural matrices that explicitly
capture the effects of orbital disturbances and their dynamic coupling with the
manipulator system. The LPKE framework also systematically includes externally
applied, symmetry-breaking wrenches, allowing for immediate integration into
hardware-in-the-loop simulations and model-based control architectures for
autonomous robotic operations in the orbital environment. To illustrate the
effectiveness of the proposed model and its numerical superiority, we present a
simulation study analyzing orbital effects on a 7-degree-of-freedom manipulator
mounted on a spacecraft.

</details>


### [4] [LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](https://arxiv.org/abs/2510.15220)
*Kevin Christiansen Marsim,Minho Oh,Byeongho Yu,Seungjae Lee,I Made Aswin Nahrendra,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的LiDAR-视觉-惯性-运动学里程计系统，通过多传感器融合（相机、LiDAR、IMU、关节编码器）来提升腿式机器人在复杂动态环境中的自主导航能力。


<details>
  <summary>Details</summary>
Motivation: 现有的传感器融合SLAM方法在挑战性环境中仍存在估计漂移问题，主要原因是采用了不合适的融合策略。

Method: 采用融合位姿估计方法，基于测量可用性运行优化型视觉-惯性-运动学里程计(VIKO)和滤波型LiDAR-惯性-运动学里程计(LIKO)，分别使用足部预积分技术和鲁棒的LiDAR-视觉深度一致性，以及足部运动学和点对面残差。

Result: 与其它传感器融合SLAM算法相比，该方法在公开和长期数据集上表现出鲁棒性能。

Conclusion: 所提出的多传感器融合系统能够有效提升腿式机器人在复杂环境中的定位和建图精度与鲁棒性。

Abstract: Autonomous navigation for legged robots in complex and dynamic environments
relies on robust simultaneous localization and mapping (SLAM) systems to
accurately map surroundings and localize the robot, ensuring safe and efficient
operation. While prior sensor fusion-based SLAM approaches have integrated
various sensor modalities to improve their robustness, these algorithms are
still susceptible to estimation drift in challenging environments due to their
reliance on unsuitable fusion strategies. Therefore, we propose a robust
LiDAR-visual-inertial-kinematic odometry system that integrates information
from multiple sensors, such as a camera, LiDAR, inertial measurement unit
(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our
system employs a fusion-based pose estimation approach that runs
optimization-based visual-inertial-kinematic odometry (VIKO) and filter-based
LiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In
VIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth
consistency using superpixel clusters in a sliding window optimization. In
LIKO, we incorporate foot kinematics and employ a point-toplane residual in an
error-state iterative Kalman filter (ESIKF). Compared with other sensor
fusion-based SLAM algorithms, our approach shows robust performance across
public and longterm datasets.

</details>


### [5] [PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation](https://arxiv.org/abs/2510.15226)
*Mrunal Sarvaiya,Guanrui Li,Giuseppe Loianno*

Main category: cs.RO

TL;DR: PolyFly是一种用于空中运输机器人的全局规划器，通过将机器人组件和环境建模为独立多面体，消除几何保守近似，实现更激进的飞行轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有方法对车辆和障碍物进行几何保守近似，导致飞行轨迹保守且飞行时间增加。需要消除这些限制，使机器人能在受限环境中进行更激进的飞行。

Method: 将机器人（四旋翼、电缆和负载）和环境物理组件建模为独立多面体，构建方向感知多面体以提高模型精度，通过对偶理论将多面体约束转换为平滑可微约束来求解最优控制问题。

Result: 在八个迷宫式环境中与现有最优方法比较，PolyFly在每个场景中都产生更快的轨迹。在真实四旋翼带悬挂负载的实验中验证了方法的实用可靠性和准确性。

Conclusion: PolyFly通过非保守的多面体建模方法，显著提高了空中运输机器人在受限环境中的飞行性能，实现了更快更激进的轨迹规划。

Abstract: Aerial transportation robots using suspended cables have emerged as versatile
platforms for disaster response and rescue operations. To maximize the
capabilities of these systems, robots need to aggressively fly through tightly
constrained environments, such as dense forests and structurally unsafe
buildings, while minimizing flight time and avoiding obstacles. Existing
methods geometrically over-approximate the vehicle and obstacles, leading to
conservative maneuvers and increased flight times. We eliminate these
restrictions by proposing PolyFly, an optimal global planner which considers a
non-conservative representation for aerial transportation by modeling each
physical component of the environment, and the robot (quadrotor, cable and
payload), as independent polytopes. We further increase the model accuracy by
incorporating the attitude of the physical components by constructing
orientation-aware polytopes. The resulting optimal control problem is
efficiently solved by converting the polytope constraints into smooth
differentiable constraints via duality theory. We compare our method against
the existing state-of-the-art approach in eight maze-like environments and show
that PolyFly produces faster trajectories in each scenario. We also
experimentally validate our proposed approach on a real quadrotor with a
suspended payload, demonstrating the practical reliability and accuracy of our
method.

</details>


### [6] [A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs](https://arxiv.org/abs/2510.15229)
*Sina Kazemdehbashi,Yanchao Liu,Boris S. Mordukhovich*

Main category: cs.RO

TL;DR: 提出了一种考虑风力和无人机异质性的数学框架，用于优化移动无人机站的位置，可将操作时间浪费减少84%。


<details>
  <summary>Details</summary>
Motivation: 自然灾害中通信基础设施常被破坏，无人机可用于数据收集和临时通信，但风力等恶劣天气条件限制了其实际部署。

Method: 将Sylvester问题推广为Sylvester-Fermat-Torricelli问题，建立统一框架考虑风力影响、无人机异质性和往返运动。

Result: 实验结果表明该框架可将操作时间浪费减少高达84%。

Conclusion: 所提出的框架通过考虑风力和无人机异质性等现实因素，提高了无人机灾害响应的实用性。

Abstract: Natural and human-made disasters can cause severe devastation and claim
thousands of lives worldwide. Therefore, developing efficient methods for
disaster response and management is a critical task for relief teams. One of
the most essential components of effective response is the rapid collection of
information about affected areas, damages, and victims. More data translates
into better coordination, faster rescue operations, and ultimately, more lives
saved. However, in some disasters, such as earthquakes, the communication
infrastructure is often partially or completely destroyed, making it extremely
difficult for victims to send distress signals and for rescue teams to locate
and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as
valuable tools in such scenarios. In particular, a fleet of UAVs can be
dispatched from a mobile station to the affected area to facilitate data
collection and establish temporary communication networks. Nevertheless,
real-world deployment of UAVs faces several challenges, with adverse weather
conditions--especially wind--being among the most significant. To address this,
we develop a novel mathematical framework to determine the optimal location of
a mobile UAV station while explicitly accounting for the heterogeneity of the
UAVs and the effect of wind. In particular, we generalize the Sylvester problem
to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures
complex factors such as wind influence, UAV heterogeneity, and back-and-forth
motion within a unified framework. The proposed framework enhances the
practicality of UAV-based disaster response planning by accounting for
real-world factors such as wind and UAV heterogeneity. Experimental results
demonstrate that it can reduce wasted operational time by up to 84%, making
post-disaster missions significantly more efficient and effective.

</details>


### [7] [Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping](https://arxiv.org/abs/2510.15319)
*Jeewon Kim,Minho Oh,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种可通行性感知的房间分割方法，通过考虑机器人与环境的交互，提高场景图的语义一致性和位姿图优化的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分割空间特征时，由于视角变化和传感器视野限制，难以一致识别房间。实时方法容易将大房间过度分割成无用的小空间，而基于体素的方法在复杂情况下（如非完全封闭的3D空间）又容易分割不足，导致位姿图优化中出现错误约束。

Method: 开发了可通行性感知的房间分割方法，考虑机器人与环境的交互，保持可通行性信息的一致性可行性。

Result: 通过在重复遍历相同路径的数据集上展示相同房间的重新检测频率提高，以及优化时间消耗的减少，证明了性能改进。

Conclusion: 该方法通过整合可通行性信息，显著提升了场景图的语义一致性和位姿图优化的计算效率。

Abstract: Scene graphs enhance 3D mapping capabilities in robotics by understanding the
relationships between different spatial elements, such as rooms and objects.
Recent research extends scene graphs to hierarchical layers, adding and
leveraging constraints across these levels. This approach is tightly integrated
with pose-graph optimization, improving both localization and mapping accuracy
simultaneously. However, when segmenting spatial characteristics, consistently
recognizing rooms becomes challenging due to variations in viewpoints and
limited field of view (FOV) of sensors. For example, existing real-time
approaches often over-segment large rooms into smaller, non-functional spaces
that are not useful for localization and mapping due to the time-dependent
method. Conversely, their voxel-based room segmentation method often
under-segment in complex cases like not fully enclosed 3D space that are
non-traversable for ground robots or humans, leading to false constraints in
pose-graph optimization. We propose a traversability-aware room segmentation
method that considers the interaction between robots and surroundings, with
consistent feasibility of traversability information. This enhances both the
semantic coherence and computational efficiency of pose-graph optimization.
Improved performance is demonstrated through the re-detection frequency of the
same rooms in a dataset involving repeated traversals of the same space along
the same path, as well as the optimization time consumption.

</details>


### [8] [ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning](https://arxiv.org/abs/2510.15331)
*Gahee Kim,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出主动仿真推理(ASBI)框架，通过机器人主动收集真实世界数据来优化黑盒仿真器参数，解决了传统仿真推理中观测数据信息不足的问题。


<details>
  <summary>Details</summary>
Motivation: 黑盒仿真器在机器人领域广泛应用，但由于无法获取似然函数，参数优化困难。传统仿真推理需要离线观测数据，但难以准备包含足够参数估计信息的观测数据。

Method: 使用主动数据收集策略，通过最大化信息增益来优化机器人动作。利用神经后验估计(NPE)解决黑盒仿真器中似然函数不可访问的问题。

Result: 三个仿真实验验证了方法的准确性，后验分布集中在真实参数周围。真实机器人实验成功估计了立方颗粒的仿真参数。

Conclusion: ASBI框架能够有效解决黑盒仿真器参数估计问题，通过主动数据收集实现了准确的参数调优。

Abstract: Black-box simulators are widely used in robotics, but optimizing their
parameters remains challenging due to inaccessible likelihoods.
Simulation-Based Inference (SBI) tackles this issue using simulation-driven
approaches, estimating the posterior from offline real observations and forward
simulations. However, in black-box scenarios, preparing observations that
contain sufficient information for parameter estimation is difficult due to the
unknown relationship between parameters and observations. In this work, we
present Active Simulation-Based Inference (ASBI), a parameter estimation
framework that uses robots to actively collect real-world online data to
achieve accurate black-box simulator tuning. Our framework optimizes robot
actions to collect informative observations by maximizing information gain,
which is defined as the expected reduction in Shannon entropy between the
posterior and the prior. While calculating information gain requires the
likelihood, which is inaccessible in black-box simulators, our method solves
this problem by leveraging Neural Posterior Estimation (NPE), which leverages a
neural network to learn the posterior estimator. Three simulation experiments
quantitatively verify that our method achieves accurate parameter estimation,
with posteriors sharply concentrated around the true parameters. Moreover, we
show a practical application using a real robot to estimate the simulation
parameters of cubic particles corresponding to two real objects, beads and
gravel, with a bucket pouring action.

</details>


### [9] [Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles](https://arxiv.org/abs/2510.15336)
*Liviu-Mihai Stan,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Masashi Konyo,Kazunori Ohno*

Main category: cs.RO

TL;DR: 提出了一种基于LiDAR和里程计的自适应路径规划框架，能够在ROS2 Nav2堆栈中识别和推开可移动障碍物，提高机器人在非结构化环境中的导航成功率。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应和非结构化室内环境中，机器人不仅需要避开障碍物，还需要识别哪些障碍物可以被推开，以提高导航效率。

Method: 开发了可移动障碍物层，将静态地图中不存在的LiDAR返回标记为可移动障碍物并分配较低遍历成本；配合慢速姿态进度检查器监控速度比，在机器人减速时提高局部成本，促使全局规划器重新规划路径。

Result: 在Gazebo模拟环境中对Scout Mini机器人的评估显示，相比无层基线，该方法具有更高的目标到达率和更少的死锁，遍历时间大致相当。

Conclusion: 交互感知成本地图是一种轻量级的ROS2原生扩展，适用于在非结构化环境中导航可移动障碍物，特别适合资源受限的搜救机器人。

Abstract: Reliable navigation in disaster-response and other unstructured indoor
settings requires robots not only to avoid obstacles but also to recognise when
those obstacles can be pushed aside. We present an adaptive, LiDAR and
odometry-based path-planning framework that embeds this capability into the
ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing
from a prior static map as tentatively movable and assigns a reduced traversal
cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to
actual velocity; when the robot slows appreciably, the local cost is raised
from light to heavy, and on a stall to lethal, prompting the global planner to
back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated
objects and cluttered corridors, show higher goal-reach rates and fewer
deadlocks than a no-layer baseline, with traversal times broadly comparable.
Because the method relies only on planar scans and CPU-level computation, it
suits resource-constrained search and rescue robots and integrates into
heterogeneous platforms with minimal engineering. Overall, the results indicate
that interaction-aware cost maps are a lightweight, ROS2-native extension for
navigating among potentially movable obstacles in unstructured settings. The
full implementation will be released as open source
athttps://costmap-namo.github.io.

</details>


### [10] [Nauplius Optimisation for Autonomous Hydrodynamics](https://arxiv.org/abs/2510.15350)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: NOAH是一种受藤壶幼体行为启发的仿生群优化算法，专为水下自主车辆在强水流、有限带宽和持续感知需求环境中的可靠运行而设计。


<details>
  <summary>Details</summary>
Motivation: 传统群优化方法在强水流、有限声学带宽和持续感知需求的水下环境中不可靠，需要新的算法来解决这些关键限制。

Method: 结合水流感知漂移、持续感知节点中的不可逆沉降和基于群体的通信，模仿藤壶幼体的行为模式。

Result: 验证研究表明，在永久锚定场景中达到86%的成功率，为水动力约束和不可逆沉降行为提供了统一公式。

Conclusion: NOAH为可扩展和节能的水下群机器人建立了全面基础，解决了现有群算法在水下探索任务中的关键限制。

Abstract: Autonomous Underwater vehicles must operate in strong currents, limited
acoustic bandwidth, and persistent sensing requirements where conventional
swarm optimisation methods are unreliable. This paper presents NOAH, a novel
nature-inspired swarm optimisation algorithm that combines current-aware drift,
irreversible settlement in persistent sensing nodes, and colony-based
communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH
addresses the critical limitations of existing swarm algorithms by providing
hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based
communication capabilities essential for underwater exploration missions. The
algorithm establishes a comprehensive foundation for scalable and
energy-efficient underwater swarm robotics with validated performance analysis.
Validation studies demonstrate an 86% success rate for permanent anchoring
scenarios, providing a unified formulation for hydrodynamic constraints and
irreversible settlement behaviours with an empirical study under flow.

</details>


### [11] [GaussGym: An open-source real-to-sim framework for learning locomotion from pixels](https://arxiv.org/abs/2510.15352)
*Alejandro Escontrela,Justin Kerr,Arthur Allshire,Jonas Frey,Rocky Duan,Carmelo Sferrazza,Pieter Abbeel*

Main category: cs.RO

TL;DR: 提出了一种将3D高斯泼溅作为渲染器集成到向量化物理模拟器中的新方法，实现了在消费级GPU上超过10万步/秒的高速模拟，同时保持高视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 为了桥接高吞吐量模拟和高保真感知，推进可扩展和可泛化的机器人学习，需要一种既能快速运行又具有逼真视觉效果的机器人模拟方法。

Method: 将3D高斯泼溅作为即插即用的渲染器集成到IsaacGym等向量化物理模拟器中，支持从iPhone扫描、大规模场景数据集和生成式视频模型中快速创建逼真训练环境。

Result: 实现了超过10万步/秒的模拟速度，展示了在模拟到真实机器人设置中的适用性，丰富的视觉语义改善了导航和决策能力，如避免不良区域。

Conclusion: 该方法成功桥接了高吞吐量模拟和高保真感知，为可扩展和可泛化的机器人学习提供了有效工具，所有代码和数据将开源供社区使用。

Abstract: We present a novel approach for photorealistic robot simulation that
integrates 3D Gaussian Splatting as a drop-in renderer within vectorized
physics simulators such as IsaacGym. This enables unprecedented speed --
exceeding 100,000 steps per second on consumer GPUs -- while maintaining high
visual fidelity, which we showcase across diverse tasks. We additionally
demonstrate its applicability in a sim-to-real robotics setting. Beyond
depth-based sensing, our results highlight how rich visual semantics improve
navigation and decision-making, such as avoiding undesirable regions. We
further showcase the ease of incorporating thousands of environments from
iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs
from generative video models like Veo, enabling rapid creation of realistic
training worlds. This work bridges high-throughput simulation and high-fidelity
perception, advancing scalable and generalizable robot learning. All code and
data will be open-sourced for the community to build upon. Videos, code, and
data available at https://escontrela.me/gauss_gym/.

</details>


### [12] [Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting](https://arxiv.org/abs/2510.15376)
*Zhaodong Yang,Ai-Ping Hu,Harish Ravichandar*

Main category: cs.RO

TL;DR: 提出了一种基于力反馈的自动化鸡肩去骨系统，通过强化学习训练反应式切割策略，实现6自由度刀具控制，在仿真和真实环境中成功完成鸡肩去骨任务。


<details>
  <summary>Details</summary>
Motivation: 自动化鸡肩去骨需要精确的6自由度切割，但由于关节部分遮挡、可变形且多材料特性，接触骨骼会带来严重的健康和安全风险。

Method: 开发了开源多材料切割仿真器，设计可重复使用的物理测试平台，训练残差强化学习策略，使用离散化力观测和领域随机化，实现零样本仿真到真实环境的迁移。

Result: 学习策略可靠地导航关节间隙，减少不必要的骨骼/软骨接触，相比现有开环切割基线，成功率提高4倍，骨骼避免效果显著改善。

Conclusion: 力反馈对于安全有效的多材料切割至关重要，该方法首次展示了学习策略在真实鸡肩去骨任务中的应用。

Abstract: Automating chicken shoulder deboning requires precise 6-DoF cutting through a
partially occluded, deformable, multi-material joint, since contact with the
bones presents serious health and safety risks. Our work makes both
systems-level and algorithmic contributions to train and deploy a reactive
force-feedback cutting policy that dynamically adapts a nominal trajectory and
enables full 6-DoF knife control to traverse the narrow joint gap while
avoiding contact with the bones. First, we introduce an open-source
custom-built simulator for multi-material cutting that models coupling,
fracture, and cutting forces, and supports reinforcement learning, enabling
efficient training and rapid prototyping. Second, we design a reusable physical
testbed to emulate the chicken shoulder: two rigid "bone" spheres with
controllable pose embedded in a softer block, enabling rigorous and repeatable
evaluation while preserving essential multi-material characteristics of the
target problem. Third, we train and deploy a residual RL policy, with
discretized force observations and domain randomization, enabling robust
zero-shot sim-to-real transfer and the first demonstration of a learned policy
that debones a real chicken shoulder. Our experiments in our simulator, on our
physical testbed, and on real chicken shoulders show that our learned policy
reliably navigates the joint gap and reduces undesired bone/cartilage contact,
resulting in up to a 4x improvement over existing open-loop cutting baselines
in terms of success rate and bone avoidance. Our results also illustrate the
necessity of force feedback for safe and effective multi-material cutting. The
project website is at https://sites.google.com/view/chickendeboning-2026.

</details>


### [13] [VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving](https://arxiv.org/abs/2510.15446)
*Ziang Guo,Zufeng Zhang*

Main category: cs.RO

TL;DR: VDRive是一个用于自动驾驶的端到端框架，通过状态-动作映射建模来解决动态环境和极端情况的挑战，结合视觉语言动作模型和扩散策略实现可解释的鲁棒决策。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的动态环境和极端情况对车辆状态理解和决策的鲁棒性提出了重大挑战，需要能够处理不确定性和复杂场景的解决方案。

Method: 使用视觉语言动作模型进行状态理解，通过条件向量量化变分自编码器将观测表示为离散代码，结合扩散策略生成动作，并采用强化学习微调来预测轨迹和动作。

Result: 在Bench2Drive闭环基准测试和nuScenes开环规划中实现了最先进的性能。

Conclusion: VDRive通过结合上下文和几何建模，以及强化学习框架，为自动驾驶提供了可解释且鲁棒的端到端解决方案。

Abstract: In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's state understanding and decision
making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving
that explicitly models state-action mapping to address these challenges,
enabling interpretable and robust decision making. By leveraging the
advancement of the state understanding of the Vision Language Action Model
(VLA) with generative diffusion policy-based action head, our VDRive guides the
driving contextually and geometrically. Contextually, VLA predicts future
observations through token generation pre-training, where the observations are
represented as discrete codes by a Conditional Vector Quantized Variational
Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning
fine-tuning of the VLA to predict future trajectories and actions based on
current driving conditions. VLA supplies the current state tokens and predicted
state tokens for the action policy head to generate hierarchical actions and
trajectories. During policy training, a learned critic evaluates the actions
generated by the policy and provides gradient-based feedback, forming an
actor-critic framework that enables a reinforcement-based policy learning
pipeline. Experiments show that our VDRive achieves state-of-the-art
performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop
planning.

</details>


### [14] [Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving](https://arxiv.org/abs/2510.15505)
*Aron Distelzweig,Faris Janjoš,Oliver Scheel,Sirish Reddy Varra,Raghu Rajan,Joschka Boedecker*

Main category: cs.RO

TL;DR: 研究发现当前集成预测与规划方法无法充分利用预测信息，提出以高质量提案生成为核心的方法，在交互场景中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 探讨集成预测与规划方法中预测的实际作用，验证其是否真正提升规划性能

Method: 基于PDM增强提案生成，强调生成多样但真实的高质量提案，主要使用预测进行碰撞检查

Result: 提案中心方法在分布外和高度交互场景中显著优于现有方法，达到新的最先进水平

Conclusion: 当前IPP方法未能充分利用预测信息，高质量提案生成比预测集成更重要

Abstract: Traditionally, prediction and planning in autonomous driving (AD) have been
treated as separate, sequential modules. Recently, there has been a growing
shift towards tighter integration of these components, known as Integrated
Prediction and Planning (IPP), with the aim of enabling more informed and
adaptive decision-making. However, it remains unclear to what extent this
integration actually improves planning performance. In this work, we
investigate the role of prediction in IPP approaches, drawing on the widely
adopted Val14 benchmark, which encompasses more common driving scenarios with
relatively low interaction complexity, and the interPlan benchmark, which
includes highly interactive and out-of-distribution driving situations. Our
analysis reveals that even access to perfect future predictions does not lead
to better planning outcomes, indicating that current IPP methods often fail to
fully exploit future behavior information. Instead, we focus on high-quality
proposal generation, while using predictions primarily for collision checks. We
find that many imitation learning-based planners struggle to generate realistic
and plausible proposals, performing worse than PDM - a simple lane-following
approach. Motivated by this observation, we build on PDM with an enhanced
proposal generation method, shifting the emphasis towards producing diverse but
realistic and high-quality proposals. This proposal-centric approach
significantly outperforms existing methods, especially in out-of-distribution
and highly interactive settings, where it sets new state-of-the-art results.

</details>


### [15] [VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation](https://arxiv.org/abs/2510.15530)
*Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 提出了一种仅使用视觉输入的单视图扩散策略学习方法VO-DP，利用预训练视觉基础模型融合语义和几何特征，在仿真和真实世界任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法大多依赖点云作为观测输入，缺乏对仅视觉解决方案的深入探索，而仅视觉方法具有显著潜力。

Method: 利用VGGT的中间特征，结合DINOv2的语义特征和交替注意力块的几何特征，通过交叉注意力融合特征，并用CNN进行空间压缩作为策略头输入。

Result: 在仿真任务中平均成功率64.6%，与DP3的64.0%相当，远高于DP的34.8%；在真实世界任务中达到87.9%，显著优于DP3的67.5%和DP的11.2%。

Conclusion: VO-DP方法在仅视觉输入条件下实现了与点云方法相当甚至更优的性能，并展示了良好的鲁棒性，同时开源了支持多机多GPU训练的工具库。

Abstract: In the context of imitation learning, visuomotor-based diffusion policy
learning is one of the main directions in robotic manipulation. Most of these
approaches rely on point clouds as observation inputs and construct scene
representations through point clouds feature learning, which enables them to
achieve remarkable accuracy. However, the existing literature lacks an in-depth
exploration of vision-only solutions that have significant potential. In this
paper, we propose a Vision-Only and single-view Diffusion Policy learning
method (VO-DP) that leverages pretrained visual foundation models to achieve
effective fusion of semantic and geometric features. We utilize intermediate
features from VGGT incorporating semantic features from DINOv2 and geometric
features from Alternating Attention blocks. Features are fused via
cross-attention and spatially compressed with a CNN to form the input to the
policy head. Extensive experiments demonstrate that VO-DP not only outperforms
the vision-only baseline DP significantly but also exhibits distinct
performance trends against the point cloud-based method DP3: in simulation
tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%
and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,
outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further
robustness evaluations confirm that VO-DP remains highly stable under varying
conditions including color, size, background, and lighting. Lastly, we
open-source a training library for robotic manipulation. Built on Accelerate,
this library supports multi-machine and multi-GPU parallel training, as well as
mixed precision training. It is compatible with visuomotor policies such as DP,
DP3 and VO-DP, and also supports the RoboTwin simulator.

</details>


### [16] [Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons](https://arxiv.org/abs/2510.15533)
*Shilei Li,Dawei Shi,Makoto Iwasaki,Yan Ning,Hongpeng Zhou,Ling Shi*

Main category: cs.RO

TL;DR: 该论文提出了两种新型扰动观测器方法，用于提高机械系统的跟踪精度，在外骨骼实验中显著减少了髋关节和膝关节的跟踪误差。


<details>
  <summary>Details</summary>
Motivation: 机械系统的标称性能常因未知扰动而下降，虽然二自由度控制结构能将标称性能与扰动抑制解耦，但当扰动动态未知时，无法实现完美的扰动抑制。

Method: 提出了两种新型扰动估计方法：基于交互多模型扩展卡尔曼滤波的扰动观测器和基于多核相关熵扩展卡尔曼滤波的扰动观测器。

Result: 在外骨骼实验中，与基于扩展卡尔曼滤波的扰动观测器相比，所提两种方法在时变交互力场景下分别将髋关节误差提高了36.3%和16.2%，膝关节误差提高了46.3%和24.4%。

Conclusion: 所提出的方法在扰动估计方面表现出优越性，显著提高了外骨骼系统的跟踪精度。

Abstract: The nominal performance of mechanical systems is often degraded by unknown
disturbances. A two-degree-of-freedom control structure can decouple nominal
performance from disturbance rejection. However, perfect disturbance rejection
is unattainable when the disturbance dynamic is unknown. In this work, we
reveal an inherent trade-off in disturbance estimation subject to tracking
speed and tracking uncertainty. Then, we propose two novel methods to enhance
disturbance estimation: an interacting multiple model extended Kalman
filter-based disturbance observer and a multi-kernel correntropy extended
Kalman filter-based disturbance observer. Experiments on an exoskeleton verify
that the proposed two methods improve the tracking accuracy $36.3\%$ and
$16.2\%$ in hip joint error, and $46.3\%$ and $24.4\%$ in knee joint error,
respectively, compared to the extended Kalman filter-based disturbance
observer, in a time-varying interaction force scenario, demonstrating the
superiority of the proposed method.

</details>


### [17] [Adaptive Legged Locomotion via Online Learning for Model Predictive Control](https://arxiv.org/abs/2510.15626)
*Hongyu Zhou,Xiaoyu Zhang,Vasileios Tzoumas*

Main category: cs.RO

TL;DR: 提出了一种通过在线学习和模型预测控制实现自适应腿式运动的算法，包含MPC和残差动力学在线学习两个交互模块，能够处理建模误差和外部干扰。


<details>
  <summary>Details</summary>
Motivation: 让四足机器人在存在未知不确定性的真实环境中自主执行复杂任务，如未知负载和不平坦地形。

Method: 使用随机傅里叶特征在再生核希尔伯特空间中近似残差动力学，基于当前学习模型进行MPC控制，并通过最小二乘法在线自监督更新模型。

Result: 算法具有次线性动态遗憾性能，在Gazebo和MuJoCo仿真中验证了有效性，能够处理高达12倍重力的外力、20度斜坡、0.25米高度变化地形、8kg负载和时变地面摩擦系数。

Conclusion: 该算法能够有效处理未知建模误差和外部干扰，实现四足机器人的自适应运动控制。

Abstract: We provide an algorithm for adaptive legged locomotion via online learning
and model predictive control. The algorithm is composed of two interacting
modules: model predictive control (MPC) and online learning of residual
dynamics. The residual dynamics can represent modeling errors and external
disturbances. We are motivated by the future of autonomy where quadrupeds will
autonomously perform complex tasks despite real-world unknown uncertainty, such
as unknown payload and uneven terrains. The algorithm uses random Fourier
features to approximate the residual dynamics in reproducing kernel Hilbert
spaces. Then, it employs MPC based on the current learned model of the residual
dynamics. The model is updated online in a self-supervised manner using least
squares based on the data collected while controlling the quadruped. The
algorithm enjoys sublinear \textit{dynamic regret}, defined as the
suboptimality against an optimal clairvoyant controller that knows how the
residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,
where the quadruped aims to track reference trajectories. The Gazebo
simulations include constant unknown external forces up to $12\boldsymbol{g}$,
where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain
with $20\degree$ inclination, and rough terrain with $0.25m$ height variation.
The MuJoCo simulations include time-varying unknown disturbances with payload
up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

</details>


### [18] [Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS](https://arxiv.org/abs/2510.15638)
*Jared K. Lepora,Haoran Li,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 使用乐高MINDSTORMS构建的仿人机器人手，采用肌腱驱动和高度欠驱动设计，具有自适应抓握能力，适合教育用途。


<details>
  <summary>Details</summary>
Motivation: 为教育环境设计一个仅使用标准乐高零件和家用设备的机器人手，让儿童能够接触和学习现代机器人技术的前沿概念。

Method: 采用肌腱驱动设计，每个手指使用双电机驱动拮抗肌腱对，通过离合器齿轮实现软协同运动的差动机制。

Result: 实现了具有精细反应控制的仿人手型，能够自适应抓握各种物体，使用简单的驱动和控制机制。

Conclusion: 该设计成功展示了使用乐高零件构建先进机器人手的可行性，具有教育和启发儿童学习现代机器人技术的潜力。

Abstract: This paper introduces an anthropomorphic robot hand built entirely using LEGO
MINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated
robot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for
an educational context, the design is constrained to use only standard LEGO
pieces with tests using common equipment available at home. The hand features
dual motors driving an agonist/antagonist opposing pair of tendons on each
finger, which are shown to result in reactive fine control. The finger motions
are synchonized through soft synergies, implemented with a differential
mechanism using clutch gears. Altogether, this design results in an
anthropomorphic hand that can adaptively grasp a broad range of objects using a
simple actuation and control mechanism. Since the hand can be constructed from
LEGO pieces and uses state-of-the-art design concepts for robotic hands, it has
the potential to educate and inspire children to learn about the frontiers of
modern robotics.

</details>


### [19] [Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation](https://arxiv.org/abs/2510.15639)
*Manuel J. Fernandez,Alejandro Suarez,Anibal Ollero,Matteo Fumagalli*

Main category: cs.RO

TL;DR: 提出可变刚度连杆(VSL)用于长距离空中操作，通过调节机械耦合刚度在柔性绳索和刚性杆之间切换，平衡抗干扰能力和操作精度。


<details>
  <summary>Details</summary>
Motivation: 传统长距离空中操作系统使用刚性或缆绳连接，限制了操作精度或会将扰动传递给飞行器，需要一种可调节刚度的连接机制。

Method: 在配备LiCAS双臂机械手的四旋翼无人机上集成可变刚度连杆，通过实验评估其在外部干扰和包裹运输任务中的表现。

Result: 可变刚度显著改变了无人机与负载之间的动态交互：柔性配置衰减外部冲击和气动扰动，刚性配置提高操作阶段的位置精度。

Conclusion: VSL提高了系统的多功能性和安全性，在柔顺性和精度之间提供了可控权衡。未来将研究自主刚度调节、多绳配置和协作空中操作。

Abstract: This paper presents the integration of a Variable Stiffness Link (VSL) for
long-reach aerial manipulation, enabling adaptable mechanical coupling between
an aerial multirotor platform and a dual-arm manipulator. Conventional
long-reach manipulation systems rely on rigid or cable connections, which limit
precision or transmit disturbances to the aerial vehicle. The proposed VSL
introduces an adjustable stiffness mechanism that allows the link to behave
either as a flexible rope or as a rigid rod, depending on task requirements.
  The system is mounted on a quadrotor equipped with the LiCAS dual-arm
manipulator and evaluated through teleoperated experiments, involving external
disturbances and parcel transportation tasks. Results demonstrate that varying
the link stiffness significantly modifies the dynamic interaction between the
UAV and the payload. The flexible configuration attenuates external impacts and
aerodynamic perturbations, while the rigid configuration improves positional
accuracy during manipulation phases.
  These results confirm that VSL enhances versatility and safety, providing a
controllable trade-off between compliance and precision. Future work will focus
on autonomous stiffness regulation, multi-rope configurations, cooperative
aerial manipulation and user studies to further assess its impact on
teleoperated and semi-autonomous aerial tasks.

</details>


### [20] [Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing](https://arxiv.org/abs/2510.15668)
*Yameng Zhang,Dianye Huang,Max Q. -H. Meng,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 提出了一种利用轻量级摄像头和视觉伺服的低成本3D超声成像方法，通过图像修复和仿真循环技术解决遮挡和姿态估计问题，在多种模型上验证了其准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统3D超声成像依赖昂贵的跟踪系统，而基于神经网络的方法受图像噪声和误差累积影响，需要一种成本效益高且精确的解决方案。

Method: 使用轻量级摄像头捕捉视觉反馈，引入图像修复方法处理遮挡，采用仿真循环方法进行姿态估计，并通过视觉伺服控制器优化图像对齐。

Result: 在血管模型、圆锥模型和人体手臂上的验证显示，与参考重建的Hausdorff距离分别为0.359 mm、1.171 mm和0.858 mm。

Conclusion: 该方法展示了可靠的徒手3D超声重建潜力，具有高精度和鲁棒性。

Abstract: Freehand 3D ultrasound (US) imaging using conventional 2D probes offers
flexibility and accessibility for diverse clinical applications but faces
challenges in accurate probe pose estimation. Traditional methods depend on
costly tracking systems, while neural network-based methods struggle with image
noise and error accumulation, compromising reconstruction precision. We propose
a cost-effective and versatile solution that leverages lightweight cameras and
visual servoing in simulated environments for precise 3D US imaging. These
cameras capture visual feedback from a textured planar workspace. To counter
occlusions and lighting issues, we introduce an image restoration method that
reconstructs occluded regions by matching surrounding texture patterns. For
pose estimation, we develop a simulation-in-the-loop approach, which replicates
the system setup in simulation and iteratively minimizes pose errors between
simulated and real-world observations. A visual servoing controller refines the
alignment of camera views, improving translational estimation by optimizing
image alignment. Validations on a soft vascular phantom, a 3D-printed conical
model, and a human arm demonstrate the robustness and accuracy of our approach,
with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171
mm, and 0.858 mm, respectively. These results confirm the method's potential
for reliable freehand 3D US reconstruction.

</details>


### [21] [HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward](https://arxiv.org/abs/2510.15679)
*Yuhong Cao,Yizhuo Wang,Jingsong Liang,Shuhao Liao,Yifeng Zhang,Peizhuo Li,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: HEADER是一种基于注意力机制的强化学习方法，使用分层图结构在大规模环境中进行高效自主探索，相比现有方法在探索效率上提升高达20%。


<details>
  <summary>Details</summary>
Motivation: 推动基于学习的方法在自主机器人探索中的边界，解决大规模环境下的探索效率问题。

Method: 采用注意力机制和分层图结构，设计新颖的基于社区的全局图构建更新算法，结合参数自由的特权奖励机制。

Result: 在模拟大规模探索场景中，HEADER比大多数现有学习方法和非学习方法具有更好的可扩展性，探索效率提升高达20%。在真实300m*230m校园环境中成功部署验证。

Conclusion: HEADER通过分层图表示、注意力机制和特权奖励的有效结合，实现了大规模环境中的高效自主探索。

Abstract: This work pushes the boundaries of learning-based methods in autonomous robot
exploration in terms of environmental scale and exploration efficiency. We
present HEADER, an attention-based reinforcement learning approach with
hierarchical graphs for efficient exploration in large-scale environments.
HEADER follows existing conventional methods to construct hierarchical
representations for the robot belief/map, but further designs a novel
community-based algorithm to construct and update a global graph, which remains
fully incremental, shape-adaptive, and operates with linear complexity.
Building upon attention-based networks, our planner finely reasons about the
nearby belief within the local range while coarsely leveraging distant
information at the global scale, enabling next-best-viewpoint decisions that
consider multi-scale spatial dependencies. Beyond novel map representation, we
introduce a parameter-free privileged reward that significantly improves model
performance and produces near-optimal exploration behaviors, by avoiding
training objective bias caused by handcrafted reward shaping. In simulated
challenging, large-scale exploration scenarios, HEADER demonstrates better
scalability than most existing learning and non-learning methods, while
achieving a significant improvement in exploration efficiency (up to 20%) over
state-of-the-art baselines. We also deploy HEADER on hardware and validate it
in complex, large-scale real-life scenarios, including a 300m*230m campus
environment.

</details>


### [22] [Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems](https://arxiv.org/abs/2510.15686)
*Taehyeon Kim,Vishnunandan L. N. Venkatesh,Byung-Cheol Min*

Main category: cs.RO

TL;DR: 提出了DDACE框架，一种用于多机器人系统的少样本学习方法，通过解耦时空要素实现任务协调和轨迹执行


<details>
  <summary>Details</summary>
Motivation: 传统从演示中学习的方法需要大量数据，而多机器人系统在现实应用中面临数据稀缺问题，需要更高效的学习方法

Method: 使用时间图网络学习任务无关的时间序列，结合高斯过程进行空间轨迹建模，实现时空要素的模块化解耦

Result: 在多种任务环境中验证了框架有效性，包括多序列执行、多动作动态、复杂轨迹生成和异构配置，成功实现少样本条件下的任务执行

Conclusion: 模块化架构能显著提升多机器人系统在实际应用中的实用性和可扩展性

Abstract: In this paper, we propose a novel few-shot learning framework for multi-robot
systems that integrate both spatial and temporal elements: Few-Shot
Demonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our
approach leverages temporal graph networks for learning task-agnostic temporal
sequencing and Gaussian Processes for spatial trajectory modeling, ensuring
modularity and generalization across various tasks. By decoupling temporal and
spatial aspects, DDACE requires only a small number of demonstrations,
significantly reducing data requirements compared to traditional learning from
demonstration approaches. To validate our proposed framework, we conducted
extensive experiments in task environments designed to assess various aspects
of multi-robot coordination-such as multi-sequence execution, multi-action
dynamics, complex trajectory generation, and heterogeneous configurations. The
experimental results demonstrate that our approach successfully achieves task
execution under few-shot learning conditions and generalizes effectively across
dynamic and diverse settings. This work underscores the potential of modular
architectures in enhancing the practicality and scalability of multi-robot
systems in real-world applications. Additional materials are available at
https://sites.google.com/view/ddace.

</details>


### [23] [DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation](https://arxiv.org/abs/2510.15786)
*Xinyue Xu,Jieqiang Sun,Jing,Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Yiwen Lu*

Main category: cs.RO

TL;DR: DexCanvas是一个大规模混合现实-合成人类操作数据集，包含7000小时灵巧手-物体交互，基于70小时真实人类演示，涵盖21种基本操作类型。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏结合大规模真实演示、系统性技能覆盖和物理验证接触标注的操作数据集，限制了机器人操作学习、接触丰富控制和技能迁移的研究。

Method: 使用真实到虚拟的流程，通过强化学习训练策略控制驱动MANO手在物理模拟中重现人类演示，同时发现产生观察物体运动的潜在接触力。

Result: 创建了首个结合大规模真实演示、基于既定分类法的系统性技能覆盖和物理验证接触标注的操作数据集，包含同步多视角RGB-D、高精度动作捕捉和逐帧接触点。

Conclusion: DexCanvas数据集能够促进机器人操作学习、接触丰富控制和不同手形态间技能迁移的研究。

Abstract: We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
dataset containing 7,000 hours of dexterous hand-object interactions seeded
from 70 hours of real human demonstrations, organized across 21 fundamental
manipulation types based on the Cutkosky taxonomy. Each entry combines
synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
and per-frame contact points with physically consistent force profiles. Our
real-to-sim pipeline uses reinforcement learning to train policies that control
an actuated MANO hand in physics simulation, reproducing human demonstrations
while discovering the underlying contact forces that generate the observed
object motion. DexCanvas is the first manipulation dataset to combine
large-scale real demonstrations, systematic skill coverage based on established
taxonomies, and physics-validated contact annotations. The dataset can
facilitate research in robotic manipulation learning, contact-rich control, and
skill transfer across different hand morphologies.

</details>


### [24] [Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion](https://arxiv.org/abs/2510.15803)
*Zahra Arjmandi,Gunho Sohn*

Main category: cs.RO

TL;DR: 提出了一种新颖的LiDAR SLAM融合技术，通过推断注意力融合模块结合AI与几何里程计，提高定位和3D建图精度。


<details>
  <summary>Details</summary>
Motivation: 改进LiDAR传感器在复杂场景中的定位和3D建图能力，增强自主导航系统的适应性。

Method: 使用INAF模块，基于KITTI数据集的LiDAR数据，根据环境反馈动态调整注意力权重。

Result: 提高了系统的适应性和测量精度，在定位和3D建图方面取得了更精确的结果。

Conclusion: 该融合技术展示了在复杂场景中增强自主导航系统的潜力。

Abstract: This paper presents a novel fusion technique for LiDAR Simultaneous
Localization and Mapping (SLAM), aimed at improving localization and 3D mapping
using LiDAR sensor. Our approach centers on the Inferred Attention Fusion
(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI
dataset's LiDAR data, INAF dynamically adjusts attention weights based on
environmental feedback, enhancing the system's adaptability and measurement
accuracy. This method advances the precision of both localization and 3D
mapping, demonstrating the potential of our fusion technique to enhance
autonomous navigation systems in complex scenarios.

</details>
