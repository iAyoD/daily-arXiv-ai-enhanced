<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration](https://arxiv.org/abs/2601.15296)
*Longxuan Wei,Yubo Zhang,Zijiao Zhang,Zhihu Wang,Shiwan Zhao,Tianyu Huang,Huiting Zhao,Chenfei Liu,Shenao Zhang,Junchi Yan*

Main category: cs.CL

TL;DR: Entropy-Tree是一种基于树的解码方法，利用熵作为分支决策信号，仅在模型表现出真正不确定性的位置扩展搜索树，在推理任务中实现了更好的准确性和校准。


<details>
  <summary>Details</summary>
Motivation: 现有解码策略要么盲目探索（随机采样），要么冗余探索（独立多重采样），无法有效利用模型的不确定性信息来指导推理过程。

Method: 提出Entropy-Tree方法，将熵作为分支决策信号，构建树形搜索结构，只在模型表现出真正不确定性的位置扩展搜索树，统一了高效结构化探索和可靠不确定性估计。

Result: 在多个模型和数据集上，Entropy-Tree在推理任务中表现出更好的pass@k性能，其预测熵相比传统指标具有更好的AUROC，实现了更好的准确性和校准。

Conclusion: Entropy-Tree通过利用熵信号指导树形搜索，统一了高效探索和不确定性估计，为语言模型推理提供了更有效的解码策略。

Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.

</details>


### [2] [AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports](https://arxiv.org/abs/2601.15297)
*Edward Ajayi*

Main category: cs.CL

TL;DR: AfriEconQA是一个专门针对非洲经济分析的基准数据集，包含8,937个高质量问答实例，基于236份世界银行报告，用于评估信息检索和RAG系统在专业经济分析任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在非洲经济分析方面存在知识缺口，因为相关数据很少出现在预训练语料中。需要专门的基准来评估信息检索系统在复杂经济查询、高精度数值推理和时间消歧方面的能力。

Method: 从236份世界银行报告中构建专业语料库，通过合成问题生成和严格过滤创建8,937个高质量QA实例。采用11个实验矩阵，对比零样本基线（GPT-5 Mini）与使用GPT-4o和Qwen 32B的RAG配置，测试五种不同的嵌入和排序策略。

Result: 零样本模型无法回答超过90%的查询，即使最先进的RAG管道也难以实现高精度。这证实了模型在非洲经济分析方面存在严重的参数知识缺口，AfriEconQA是一个具有挑战性的基准。

Conclusion: AfriEconQA是首个专注于非洲经济分析的基准数据集，为下一代领域特定的信息检索和RAG系统提供了稳健且具有挑战性的测试平台，数据集和代码将在发表后公开。

Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.

</details>


### [3] [Embedding Retrofitting: Data Engineering for better RAG](https://arxiv.org/abs/2601.15298)
*Anantha Sharma*

Main category: cs.CL

TL;DR: 本文提出一个数据工程框架，通过解决真实语料中标注伪影导致的数据质量下降问题，改善基于知识图谱的词嵌入调整效果。


<details>
  <summary>Details</summary>
Motivation: 词嵌入调整依赖知识图谱质量，而知识图谱质量又受文本预处理影响。真实语料中的标注伪影（如标签）会导致数据质量下降，影响嵌入调整效果。

Method: 提出数据工程框架，分析标注伪影（特别是标签）如何膨胀知识图谱密度并创建虚假边，然后通过预处理方法清理数据，使用EWMA（指数加权移动平均）调整技术。

Result: 在噪声图谱上，所有调整技术都导致显著性能下降（-3.5%到-5.2%）。预处理后，EWMA调整实现+6.2%改进，在定量综合问题上平均提升+33.8%。预处理质量差异（10%+波动）比算法差异（3%）更大。

Conclusion: 预处理质量是决定嵌入调整成功的主要因素，而非算法选择。数据工程框架能有效解决真实语料中的标注伪影问题，显著提升嵌入调整效果。

Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.
  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\%$ to $-5.2\%$, $p<0.05$). After preprocessing, \acrshort{ewma} retrofitting achieves $+6.2\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\%$ average). The gap between clean and noisy preprocessing (10\%+ swing) exceeds the gap between algorithms (3\%), establishing preprocessing quality as the primary determinant of retrofitting success.

</details>


### [4] [MALTopic: Multi-Agent LLM Topic Modeling Framework](https://arxiv.org/abs/2601.15299)
*Yash Sharma*

Main category: cs.CL

TL;DR: MALTopic：基于多智能体LLM的主题建模框架，通过整合结构化数据和分解任务提升调查数据分析效果


<details>
  <summary>Details</summary>
Motivation: 传统主题建模方法仅考虑自由文本响应，无法原生整合结构化或分类调查数据，且生成的主题抽象需要大量人工解释

Method: 提出多智能体LLM主题建模框架（MALTopic），将主题建模分解为三个专门任务：增强智能体利用结构化数据丰富文本响应，主题建模智能体提取潜在主题，去重智能体精炼结果

Result: 在调查数据集上的比较分析显示，MALTopic相比LDA和BERTopic显著提高了主题连贯性、多样性和可解释性

Conclusion: 通过整合结构化数据和采用多智能体方法，MALTopic生成具有增强上下文相关性的人类可读主题，为分析复杂调查数据提供了更有效的解决方案

Abstract: Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.

</details>


### [5] [Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis](https://arxiv.org/abs/2601.15300)
*Weiwei Wang,Jiyong Min,Weijie Zou*

Main category: cs.CL

TL;DR: 大语言模型在处理接近特定临界阈值的长上下文时会出现灾难性性能下降，即使信息仍然相关。本文首次系统性地描述了开源Qwen模型中的智能退化现象，提出了浅层长上下文适应的概念，并确定了Qwen2.5-7B模型在40-50%最大上下文长度处的临界阈值。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文应用中表现出灾难性的性能退化，即使信息仍然相关，当上下文长度接近某些临界阈值时，任务性能会急剧下降超过30%。这种智能退化严重限制了长上下文应用，需要系统性的分析和理解。

Method: 1) 自然长度分布分析：使用每个样本的自然token长度，不进行截断或填充，提供更强的因果证据；2) 临界阈值确定：在混合数据集（1000个样本覆盖5%-95%上下文长度）上进行实验，使用五折交叉验证方法；3) 统一框架：整合浅层适应概念，解释退化模式。

Result: 确定了Qwen2.5-7B模型的临界阈值在40-50%最大上下文长度处，F1分数从0.55-0.56下降到0.3（45.5%退化）。模型在临界阈值前保持强性能，之后灾难性崩溃，表现出浅层长上下文适应的模式。

Conclusion: 本文首次系统性地描述了开源Qwen模型中的智能退化现象，提出了浅层长上下文适应的统一框架来解释退化模式，为缓解策略提供了基础，并为在长上下文场景中部署LLMs提供了实用指导。

Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.

</details>


### [6] [Can We Trust LLM Detectors?](https://arxiv.org/abs/2601.15301)
*Jivnesh Sandhan,Harshit Jaiswal,Fei Cheng,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文系统评估了两种主流AI文本检测范式（无训练和监督式），发现它们在分布偏移、未见生成器和简单风格扰动下都很脆弱，提出了基于监督对比学习的框架来学习判别性风格嵌入。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的快速采用，对可靠AI文本检测的需求增加，但现有检测器在受控基准测试之外往往失效，需要更鲁棒的检测方法。

Method: 系统评估两种主流范式（无训练和监督式），并提出监督对比学习（SCL）框架来学习判别性风格嵌入，以解决现有方法的局限性。

Result: 监督检测器在域内表现优异但在域外急剧退化，无训练方法对代理选择高度敏感，整体暴露了构建领域无关检测器的根本挑战。

Conclusion: 现有AI文本检测方法在分布偏移、未见生成器和风格扰动下都很脆弱，监督对比学习框架提供了改进方向，但构建领域无关检测器仍面临根本性挑战。

Abstract: The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are brittle under distribution shift, unseen generators, and simple stylistic perturbations. To address these limitations, we propose a supervised contrastive learning (SCL) framework that learns discriminative style embeddings. Experiments show that while supervised detectors excel in-domain, they degrade sharply out-of-domain, and training-free methods remain highly sensitive to proxy choice. Overall, our results expose fundamental challenges in building domain-agnostic detectors. Our code is available at: https://github.com/HARSHITJAIS14/DetectAI

</details>


### [7] [ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation](https://arxiv.org/abs/2601.15330)
*Zhebo Wang,Xiaohu Mu,Zijie Zhou,Mohan Li,Wenpeng Xing,Dezhang Kong,Meng Han*

Main category: cs.CL

TL;DR: 提出ICPO训练框架，解决LLM在多轮对话中因早期错误假设导致的"对话迷失"问题，通过奖励模型在模糊指令下表达不确定性或寻求澄清，提升对话鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM在多轮对话中存在"对话迷失"现象，当用户提供模糊初始指令时，模型难以从早期错误假设中恢复。标准的后训练技术（如RLVR）通过奖励自信的直接回答加剧了这一问题，导致模型过度自信且不愿寻求澄清。

Method: 提出Illocution-Calibrated Policy Optimization (ICPO)训练框架：1) 在训练语料中增加未充分指定的提示；2) 根据用户的言外之意（illocutionary intent）调整奖励信号，奖励模型在面对模糊性时表达不确定性或寻求澄清的行为。

Result: ICPO显著提升了模型在模糊指令下的表现，在多轮对话中平均改进75%，同时保持了在单轮基准测试上的稳健性能。该方法培养了适当的"谦逊"行为。

Conclusion: ICPO为构建更鲁棒、协作的对话AI提供了实用路径，使模型能更好地处理人类交互中的细微差别，特别是在面对模糊指令时能够适当表达不确定性或寻求澄清。

Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.

</details>


### [8] [RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models](https://arxiv.org/abs/2601.15331)
*Rishit Chugh*

Main category: cs.CL

TL;DR: 提出一种资源高效的对抗提示方法，通过匹配新提示到预训练对抗提示数据库，无需重新训练，显著降低计算成本，实现可扩展的LLM红队测试。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到对抗提示攻击产生有害输出，现有自动化越狱方法（如GCG、PEZ、GBDA）计算成本高昂，限制了资源受限组织的实际应用。

Method: 将1000个提示分类为7个有害类别，评估GCG、PEZ、GBDA在Llama 3 8B模型上的效果，通过检索语义相似的预训练成功对抗提示来攻击新提示，无需重新训练。

Result: 发现提示类型与算法效果存在相关性，提出的方法在显著降低计算成本的同时，实现了有竞争力的攻击成功率。

Conclusion: 为对齐LLM的可扩展红队测试和安全评估提供了实用框架，包括无法访问模型内部的环境，通过预训练对抗提示库实现资源高效的攻击。

Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they remain vulnerable to automated jailbreaking methods such as GCG, PEZ, and GBDA, which generate adversarial suffixes via training and gradient-based search. Although effective, these methods particularly GCG are computationally expensive, limiting their practicality for organisations with constrained resources. This paper introduces a resource-efficient adversarial prompting approach that eliminates the need for retraining by matching new prompts to a database of pre-trained adversarial prompts. A dataset of 1,000 prompts was classified into seven harm-related categories, and GCG, PEZ, and GBDA were evaluated on a Llama 3 8B model to identify the most effective attack method per category. Results reveal a correlation between prompt type and algorithm effectiveness. By retrieving semantically similar successful adversarial prompts, the proposed method achieves competitive attack success rates with significantly reduced computational cost. This work provides a practical framework for scalable red-teaming and security evaluation of aligned LLMs, including in settings where model internals are inaccessible.

</details>


### [9] [No Reliable Evidence of Self-Reported Sentience in Small Large Language Models](https://arxiv.org/abs/2601.15334)
*Caspar Kaiser,Sean Enderby*

Main category: cs.CL

TL;DR: 语言模型否认自己具有意识，分类器检测显示这些否认是真实的，且更大模型更自信地否认意识


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否相信自己具有意识，通过实证方法测试模型对自身意识的信念，而非直接探讨意识本身的存在性

Method: 使用Qwen、Llama、GPT-OSS三个模型家族（0.6B-70B参数），询问约50个关于意识和主观体验的问题，采用三种可解释性文献中的分类方法，通过内部激活训练分类器来验证模型回答的真实性

Result: 1. 模型一致否认自己具有意识，将意识归因于人类而非自身；2. 检测潜在信念的分类器未提供证据表明这些否认是不真实的；3. 在Qwen家族中，更大模型更自信地否认意识

Conclusion: 研究结果表明语言模型不相信自己具有意识，这与近期认为模型潜藏自我意识信念的研究形成对比，为模型自我认知的实证研究提供了新视角

Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying their responses using classifiers trained on internal activations. We draw upon three model families (Qwen, Llama, GPT-OSS) ranging from 0.6 billion to 70 billion parameters, approximately 50 questions about consciousness and subjective experience, and three classification methods from the interpretability literature. First, we find that models consistently deny being sentient: they attribute consciousness to humans but not to themselves. Second, classifiers trained to detect underlying beliefs - rather than mere outputs - provide no clear evidence that these denials are untruthful. Third, within the Qwen family, larger models deny sentience more confidently than smaller ones. These findings contrast with recent work suggesting that models harbour latent beliefs in their own consciousness.

</details>


### [10] [From Quotes to Concepts: Axial Coding of Political Debates with Ensemble LMs](https://arxiv.org/abs/2601.15338)
*Angelina Parfenova,David Graus,Juergen Pfeffer*

Main category: cs.CL

TL;DR: 本文提出使用大语言模型实现轴向编码的方法，将辩论转录文本转化为层次化表示，比较了聚类嵌入和直接LLM分组两种策略。


<details>
  <summary>Details</summary>
Motivation: 轴向编码是常用的定性分析方法，但传统方法耗时耗力。本文旨在利用大语言模型自动化这一过程，将原始辩论转录转化为简洁的层次化表示，提高分析效率。

Method: 扩展基于集成的开放编码方法，增加轴向编码步骤。比较两种策略：1) 使用密度基和划分算法对代码-话语对嵌入进行聚类，然后LLM标注；2) 直接使用LLM将代码和话语分组到类别中。应用于荷兰议会辩论数据。

Result: 密度基聚类实现高覆盖率和强聚类对齐，而直接LLM分组获得更高的细粒度对齐但覆盖率降低20%。聚类最大化覆盖率和结构分离，LLM分组产生更简洁、可解释和语义对齐的类别。

Conclusion: 两种方法各有优劣：聚类适合最大化覆盖和结构分离，LLM分组适合产生简洁可解释的类别。公开释放完整数据集支持未来研究。

Abstract: Axial coding is a commonly used qualitative analysis method that enhances document understanding by organizing sentence-level open codes into broader categories. In this paper, we operationalize axial coding with large language models (LLMs). Extending an ensemble-based open coding approach with an LLM moderator, we add an axial coding step that groups open codes into higher-order categories, transforming raw debate transcripts into concise, hierarchical representations. We compare two strategies: (i) clustering embeddings of code-utterance pairs using density-based and partitioning algorithms followed by LLM labeling, and (ii) direct LLM-based grouping of codes and utterances into categories. We apply our method to Dutch parliamentary debates, converting lengthy transcripts into compact, hierarchically structured codes and categories. We evaluate our method using extrinsic metrics aligned with human-assigned topic labels (ROUGE-L, cosine, BERTScore), and intrinsic metrics describing code groups (coverage, brevity, coherence, novelty, JSD divergence). Our results reveal a trade-off: density-based clustering achieves high coverage and strong cluster alignment, while direct LLM grouping results in higher fine-grained alignment, but lower coverage 20%. Overall, clustering maximizes coverage and structural separation, whereas LLM grouping produces more concise, interpretable, and semantically aligned categories. To support future research, we publicly release the full dataset of utterances and codes, enabling reproducibility and comparative studies.

</details>


### [11] [Memorization Dynamics in Knowledge Distillation for Language Models](https://arxiv.org/abs/2601.15394)
*Jaydeep Borkar,Karan Chadha,Niloofar Mireshghallah,Yuchen Zhang,Irina-Elena Veliche,Archi Mitra,David A. Smith,Zheng Xu,Diego Garcia-Olano*

Main category: cs.CL

TL;DR: 知识蒸馏相比标准微调显著减少训练数据记忆（降低50%以上），某些样本更容易被记忆（占95%以上），学生模型记忆可预测，硬蒸馏比软蒸馏继承更多教师特定样本（2.7倍）。


<details>
  <summary>Details</summary>
Motivation: 研究知识蒸馏（KD）中训练数据记忆的动态，因为虽然KD被广泛采用来提升效率并作为隐私保护机制，但其在知识蒸馏设置中的记忆机制尚未被充分理解。

Method: 使用三个LLM家族（Pythia、OLMo-2、Qwen-3）和三个数据集（FineWeb、Wikitext、Nemotron-CC-v2）研究KD流程中的记忆现象，分析软蒸馏和硬蒸馏的差异。

Result: 1. 蒸馏模型比标准微调显著减少训练数据记忆（>50%）；2. 某些样本天生更容易记忆，占蒸馏中记忆的大部分（~95%）；3. 学生记忆可通过zlib熵、KL散度和困惑度特征预测；4. 硬蒸馏继承教师特定样本比软蒸馏多2.7倍。

Conclusion: 知识蒸馏既能提供更好的泛化能力，又能降低记忆风险，相比标准微调具有双重优势，但硬蒸馏比软蒸馏带来更高的隐私风险。

Abstract: Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.

</details>


### [12] [Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind](https://arxiv.org/abs/2601.15395)
*Tamunotonye Harry,Ivoline Ngong,Chima Nweke,Yuanyuan Feng,Joseph Near*

Main category: cs.CL

TL;DR: Chameleon数据集揭示用户交互中状态（74%）比特质（26%）更重要，但LLMs只关注特质而忽略状态，奖励模型对状态反应不一致。


<details>
  <summary>Details</summary>
Motivation: 现有的人设数据集（如PersonaChat、PANDORA等）只捕捉用户的静态特质，而忽略了交互情境（状态）的影响。需要研究用户状态在对话中的重要性。

Method: 引入Chameleon数据集，包含1,667名Reddit用户的5,001个情境化心理档案，每个用户在多个情境下测量。基于潜在状态-特质理论进行方差分解分析。

Result: 1. 方差分解显示74%是个人内部变化（状态），只有26%是个人间差异（特质）。2. LLMs是"状态盲"的，只关注特质，无论状态如何都产生相似回应。3. 奖励模型对用户状态有反应但不一致，不同模型对相同用户的评价方向相反。

Conclusion: 用户状态在对话中比特质更重要，但当前LLMs无法捕捉状态变化。Chameleon数据集支持情感计算、个性化对话和RLHF对齐研究，强调需要开发能感知状态的模型。

Abstract: User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.

</details>


### [13] [Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs](https://arxiv.org/abs/2601.15429)
*Sydney Anuyah,Mehedi Mahmud Kaushik,Hao Dai,Rakesh Shiradkar,Arjan Durresi,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 评估领域知识图谱如何提升医疗RAG性能，发现图谱与查询范围对齐是关键，精确匹配的图谱检索效果最好，而盲目合并图谱会引入干扰降低准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成流畅回答方面表现出色，但在特定领域的可信推理方面存在不足。研究旨在评估领域知识图谱是否能提升检索增强生成在医疗领域的性能。

Method: 从PubMed构建三个知识图谱：G1（2型糖尿病）、G2（阿尔茨海默病）、G3（AD+T2DM）。设计两个测试探针：探针1针对合并的AD T2DM知识，探针2针对G1和G2的交集。测试7个指令调优的LLM，比较不同检索源（无RAG、G1、G2、G1+G2、G3、G1+G2+G3）和三种解码温度下的表现。

Result: 图谱与查询范围对齐是关键：精确、范围匹配的检索（特别是G2）带来最一致的性能提升，而不加区分的图谱合并通常会引入干扰降低准确性。大模型在探针1上经常匹配或超过KG-RAG的无RAG基线，表明其强大的参数先验知识，而中小模型从范围匹配良好的检索中获益更多。温度起次要作用，较高值很少有帮助。

Conclusion: 精确优先、范围匹配的KG-RAG优于广度优先的图谱合并。提出了图谱选择、模型规模调整和检索/重排序的实用指南。

Abstract: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\mathbb{G}_1$ and $\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_1$ + $\mathbb{G}_2$, $\mathbb{G}_3$, $\mathbb{G}_1$+$\mathbb{G}_2$ + $\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison

</details>


### [14] [Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering](https://arxiv.org/abs/2601.15457)
*Anuj Maharjan,Umesh Yadav*

Main category: cs.CL

TL;DR: 该研究评估了RAG架构在公共卫生政策领域减少LLM幻觉的效果，发现高级RAG配置比基础RAG和普通LLM在准确性上有显著提升。


<details>
  <summary>Details</summary>
Motivation: LLM在公共卫生政策领域有应用潜力，但其生成幻觉（看似合理但事实错误的断言）在高风险环境中构成重大障碍，需要解决信息完整性问题。

Method: 使用Mistral-7B-Instruct-v0.2模型和all-MiniLM-L6-v2嵌入模型，比较普通LLM、基础RAG和高级RAG（使用交叉编码器重排序）三种架构。实验采用两种文档分块策略：递归字符分割和基于令牌的语义分割，在CDC政策文件语料库上进行测试。

Result: 基础RAG的忠实度得分（0.621）显著高于普通LLM基线（0.347），而高级RAG配置达到最高的忠实度平均值（0.797）。两阶段检索机制对领域特定政策问答的精确性至关重要。

Conclusion: RAG架构能有效减少LLM在公共卫生政策领域的幻觉，高级RAG配置表现最佳，但文档分割的结构限制仍然是多步推理任务的主要瓶颈。

Abstract: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.

</details>


### [15] [Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts](https://arxiv.org/abs/2601.15479)
*Sydney Anuyah,Sneha Shajee-Mohan,Ankit-Singh Chauhan,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 评估13个开源大语言模型在文本中成对因果发现任务上的表现，发现现有模型在因果检测和因果提取方面存在显著缺陷，最佳模型准确率不足50%。


<details>
  <summary>Details</summary>
Motivation: 为了安全地将大语言模型部署到生物医学等高风险领域，需要确保它们能够进行因果推理。本研究旨在评估LLMs在文本中识别和提取因果关系的基本能力。

Method: 使用12个多样化数据集构建基准测试，评估两种核心技能：因果检测（识别文本是否包含因果链接）和因果提取（提取确切的因果短语）。测试了多种提示方法，包括零样本、思维链和少样本上下文学习。

Result: 当前模型存在重大缺陷：最佳因果检测模型DeepSeek-R1-Distill-Llama-70B平均得分仅49.57%，最佳因果提取模型Qwen2.5-Coder-32B-Instruct仅47.12%。模型在简单、显式、单句关系上表现最好，但在隐式关系、跨多句链接和包含多个因果对的文本上表现急剧下降。

Conclusion: 现有大语言模型在文本因果发现任务上能力严重不足，特别是在复杂现实场景中。研究提供了统一的评估框架和公开数据集，以促进该领域的进一步研究。

Abstract: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).
  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($κ\ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}

</details>


### [16] [Multi-Persona Thinking for Bias Mitigation in Large Language Models](https://arxiv.org/abs/2601.15488)
*Yuxing Chen,Guoqing Luo,Zijun Wu,Lili Mou*

Main category: cs.CL

TL;DR: 提出MPT框架，通过多角色辩证推理减少LLM偏见，在保持推理能力的同时显著降低偏见


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在显著的社会偏见，可能延续有害刻板印象和不公平结果，需要有效方法来缓解这些偏见

Method: 提出多角色思维（MPT）框架，在推理时引导模型采用对比的社会身份（如男性和女性）以及中性视角，通过迭代辩证推理过程暴露和纠正偏见

Result: 在两个广泛使用的偏见基准测试中，MPT在开源和闭源模型上都显著优于现有提示策略，在保持核心推理能力的同时实现了最低的偏见水平

Conclusion: MPT框架成功将角色分配的潜在弱点转化为偏见缓解的优势，通过辩证推理有效减少LLM的社会偏见

Abstract: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.

</details>


### [17] [ViT Registers and Fractal ViT](https://arxiv.org/abs/2601.15506)
*Jason Chuan-Chih Chou,Abhinav Kumar,Shivank Garg*

Main category: cs.CL

TL;DR: 研究者提出了一种名为fractal ViT的视觉Transformer变体，通过引入"摘要token"和注意力掩码来打破token间的排列不变性，但实验表明其性能并未超越带寄存器的ViT。


<details>
  <summary>Details</summary>
Motivation: 受到两个最新发现的启发：1) 无位置编码的Transformer在语言模型中表现出不错的性能；2) 寄存器（与输入无关的额外token）可能提升大型视觉Transformer的性能。研究者希望探索如何通过打破token间的排列不变性来改进ViT。

Method: 提出fractal ViT变体，通过引入"摘要token"（类似寄存器）并在常规token和摘要token之间应用注意力掩码来打破排列不变性。该方法可以单独使用，也可以与各种位置编码结合使用。

Result: 这些模型在性能上并未超越带寄存器的标准ViT，表明这些发现可能是特定于规模、领域或应用的。

Conclusion: 虽然fractal ViT的设计理念有理论基础，但实际效果有限，提示Transformer架构的改进可能需要考虑具体的应用场景和规模因素。

Abstract: Drawing inspiration from recent findings including surprisingly decent performance of transformers without positional encoding (NoPE) in the domain of language models and how registers (additional throwaway tokens not tied to input) may improve the performance of large vision transformers (ViTs), we invent and test a variant of ViT called fractal ViT that breaks permutation invariance among the tokens by applying an attention mask between the regular tokens and ``summary tokens'' similar to registers, in isolation or in combination with various positional encodings. These models do not improve upon ViT with registers, highlighting the fact that these findings may be scale, domain, or application-specific.

</details>


### [18] [Computational Representations of Character Significance in Novels](https://arxiv.org/abs/2601.15508)
*Haaris Mian,Melanie Subbiah,Sharon Marcus,Nora Shaalan,Kathleen McKeown*

Main category: cs.CL

TL;DR: 提出基于六成分结构模型的小说角色分析方法，超越传统场景存在模型，结合叙述者-角色区分和角色间讨论，应用于19世纪英国现实主义小说，探索角色中心性和性别动态。


<details>
  <summary>Details</summary>
Motivation: 传统小说角色建模主要基于角色在场景中的存在（行动、命名提及、对话），过度强调出现场景最多的主角。需要更全面的角色分析方法，纳入叙述者-角色区分和角色间讨论等被忽视的维度。

Method: 采用新的文学理论提出的六成分结构模型，比较通用大语言模型和任务特定Transformer模型在19世纪英国现实主义小说上的应用，生成成分级和图表示的角色讨论表征。

Result: 方法能够生成组件级和图表示的角色讨论表征，使大规模探索文学问题成为可能，特别是Woloch的"一个与多个"角色中心性理论和角色讨论的性别动态。

Conclusion: 提出的六成分结构模型为角色分析提供了更全面的计算视角，能够探索传统方法无法处理的文学理论问题，特别是角色中心性和性别动态等深层文学结构。

Abstract: Characters in novels have typically been modeled based on their presence in scenes in narrative, considering aspects like their actions, named mentions, and dialogue. This conception of character places significant emphasis on the main character who is present in the most scenes. In this work, we instead adopt a framing developed from a new literary theory proposing a six-component structural model of character. This model enables a comprehensive approach to character that accounts for the narrator-character distinction and includes a component neglected by prior methods, discussion by other characters. We compare general-purpose LLMs with task-specific transformers for operationalizing this model of character on major 19th-century British realist novels. Our methods yield both component-level and graph representations of character discussion. We then demonstrate that these representations allow us to approach literary questions at scale from a new computational lens. Specifically, we explore Woloch's classic "the one vs the many" theory of character centrality and the gendered dynamics of character discussion.

</details>


### [19] [AdversaRiskQA: An Adversarial Factuality Benchmark for High-Risk Domains](https://arxiv.org/abs/2601.15511)
*Adam Szelestey,Sofie van Engelen,Tianhao Huang,Justin Snelders,Qintao Zeng,Songgaojun Deng*

Main category: cs.CL

TL;DR: AdversaRiskQA：首个针对健康、金融和法律领域的对抗性事实性基准测试，评估LLMs在对抗性错误信息下的防御能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的幻觉问题严重影响高风险领域，现有研究缺乏高质量的领域特定资源来评估模型在对抗性条件下的鲁棒性，且没有研究考察注入错误信息对长文本事实性的影响

Method: 提出AdversaRiskQA基准测试，包含两个难度级别，覆盖健康、金融和法律三个领域；开发两种自动化方法评估对抗攻击成功率和长文本事实性；评估六个开源和闭源LLM

Result: Qwen3 (80B)在排除无意义响应后获得最高平均准确率，GPT-5保持稳定高准确率；性能随模型规模非线性增长，不同领域表现差异大；长文本评估显示注入错误信息与模型事实输出无显著相关性

Conclusion: AdversaRiskQA为识别LLM弱点、开发更可靠的高风险应用模型提供了有价值的基准测试工具

Abstract: Hallucination in large language models (LLMs) remains an acute concern, contributing to the spread of misinformation and diminished public trust, particularly in high-risk domains. Among hallucination types, factuality is crucial, as it concerns a model's alignment with established world knowledge. Adversarial factuality, defined as the deliberate insertion of misinformation into prompts with varying levels of expressed confidence, tests a model's ability to detect and resist confidently framed falsehoods. Existing work lacks high-quality, domain-specific resources for assessing model robustness under such adversarial conditions, and no prior research has examined the impact of injected misinformation on long-form text factuality.
  To address this gap, we introduce AdversaRiskQA, the first verified and reliable benchmark systematically evaluating adversarial factuality across Health, Finance, and Law. The benchmark includes two difficulty levels to test LLMs' defensive capabilities across varying knowledge depths. We propose two automated methods for evaluating the adversarial attack success and long-form factuality. We evaluate six open- and closed-source LLMs from the Qwen, GPT-OSS, and GPT families, measuring misinformation detection rates. Long-form factuality is assessed on Qwen3 (30B) under both baseline and adversarial conditions. Results show that after excluding meaningless responses, Qwen3 (80B) achieves the highest average accuracy, while GPT-5 maintains consistently high accuracy. Performance scales non-linearly with model size, varies by domains, and gaps between difficulty levels narrow as models grow. Long-form evaluation reveals no significant correlation between injected misinformation and the model's factual output. AdversaRiskQA provides a valuable benchmark for pinpointing LLM weaknesses and developing more reliable models for high-stakes applications.

</details>


### [20] [Common to Whom? Regional Cultural Commonsense and LLM Bias in India](https://arxiv.org/abs/2601.15550)
*Sangmitra Madhusudan,Trush Shashank More,Steph Buongiorno,Renata Dividino,Jad Kabbara,Ali Emami*

Main category: cs.CL

TL;DR: Indica是首个评估LLMs对印度次国家级文化常识理解的基准，发现印度文化常识主要是区域性的而非全国性的，LLMs在区域特定问题上准确率仅13.4%-20.9%，且存在地理偏见。


<details>
  <summary>Details</summary>
Motivation: 现有文化常识基准将国家视为单一整体，假设文化实践在国家边界内是统一的。但文化常识在国家内部是否一致？是否存在次国家级的变化？本研究旨在探索这个问题，以印度为案例进行研究。

Method: 创建Indica基准，聚焦印度（28个邦、8个联邦属地、22种官方语言）。从印度五个地区（北、南、东、西、中）收集人工标注的答案，涵盖515个问题、8个日常生活领域，得到1,630个区域特定的问答对。评估8个最先进的LLMs。

Result: 只有39.4%的问题在五个地区获得一致答案，表明印度文化常识主要是区域性的。LLMs在区域特定问题上准确率仅13.4%-20.9%，存在地理偏见：过度选择中部和北部作为"默认"（比预期多选30-40%），而东部和西部代表性不足。

Conclusion: 文化常识在印度主要是区域性的而非全国性的，LLMs在理解区域文化差异方面表现不佳且存在系统性偏见。该方法论为评估任何文化异质性国家的文化常识提供了可推广的框架。

Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.

</details>


### [21] [From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare](https://arxiv.org/abs/2601.15558)
*Man Luo,Bahareh Harandizadeh,Amara Tariq,Halim Abbas,Umar Ghaffar,Christopher J Warren,Segun O. Kolade,Haidar M. Abdul-Muhsin*

Main category: cs.CL

TL;DR: LLMs作为同理心编辑器，能提升医生书面回复的同理心表达，同时保持医学事实准确性，比完全由LLM生成的回复更安全有效。


<details>
  <summary>Details</summary>
Motivation: 临床同理心对患者护理至关重要，但医生需要在认知和情感限制下平衡情感温暖与事实准确性。研究探索如何利用LLMs作为同理心编辑器，提升医疗沟通质量。

Method: 引入两个新颖的量化指标：同理心排名分数和医学事实核查分数，系统评估回复的情感和事实质量。比较LLM编辑的回复与完全LLM生成的回复。

Result: 实验结果显示，LLM编辑的回复显著提高了感知同理心，同时保持了事实准确性，优于完全由LLM生成的输出。

Conclusion: 将LLMs作为编辑助手而非自主生成器，为同理心和可信赖的AI辅助医疗沟通提供了更安全有效的途径。

Abstract: Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.

</details>


### [22] [YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models](https://arxiv.org/abs/2601.15588)
*Junyu Lin,Meizhen Liu,Xiufeng Huang,Jinfeng Li,Haiwen Hong,Xiaohan Yuan,Yuefeng Chen,Longtao Huang,Hui Xue,Ranjie Duan,Zhikai Chen,Yuchuan Fu,Defeng Li,Lingyao Gao,Yitong Yang*

Main category: cs.CL

TL;DR: YuFeng-XGuard是一个基于推理的安全护栏模型系列，通过结构化风险评估、分层推理和动态策略机制，为LLM提供细粒度、可解释、可适配的安全防护。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全解决方案存在局限性：粗粒度过滤、不透明、策略不灵活或推理成本过高。需要细粒度、可解释、可适配的风险评估机制。

Method: 1) 结构化风险预测：生成明确风险类别和可配置置信度，附带自然语言解释；2) 分层推理范式：基于首个解码token进行初始风险决策，按需提供解释性推理；3) 动态策略机制：将风险感知与策略执行解耦，无需重新训练即可调整安全策略。

Result: 在多个公共安全基准测试中，YuFeng-XGuard实现了最先进的性能，同时在效率与效果之间保持良好平衡。提供了完整容量和轻量级两个版本。

Conclusion: YuFeng-XGuard通过推理中心化的设计，为LLM交互提供了可操作、可解释、可适配的安全护栏，解决了现有方案的局限性，并作为开源模型系列支持广泛部署场景。

Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.

</details>


### [23] [Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow](https://arxiv.org/abs/2601.15593)
*Yangyang Zhong,Yanmei Gu,Zhengqing Zang,Xiaomeng Li,Yuqi Ding,Xibei Jia,Yuting Shen,Zhenzhong Lan,Liwang Zhu,Weiping Liu,Junlin Zhou,Haisheng Liu,Zhong Xin Yu,Pengxin Luo,Donglian Qi,Yunfeng Yan,Junbo Zhao*

Main category: cs.CL

TL;DR: MDLMs在并行生成和任意顺序解码方面仍有局限，主要因并行概率建模削弱了token间依赖关系，落后于同等规模的自回归模型。但MDLMs表现出自适应解码行为，在需要"后向信息"的任务中具有优势，建议采用"生成-编辑"范式来平衡依赖保持和解码效率。


<details>
  <summary>Details</summary>
Motivation: 研究Masked Diffusion Language Models（MDLMs）是否真正实现了并行token生成和任意顺序解码的承诺，并深入理解其行为特征和局限性。

Method: 使用平均最终化并行度（AFP）和Kendall's tau两个指标，从并行强度和生成顺序两个维度分析MDLM行为。评估了8个主流MDLM模型（最大100B参数）在58个涵盖知识、推理和编程的基准测试上的表现。

Result: MDLMs在性能上仍落后于同等规模的自回归模型，主要原因是并行概率建模削弱了token间依赖关系。MDLMs表现出自适应解码行为：其并行性和生成顺序随任务领域、推理阶段和输出正确性显著变化。在需要"后向信息"的任务（如数独）中，MDLMs倾向于先填充较简单的空格，显示出其优势。

Conclusion: 提出了"生成-编辑"范式的理论动机和设计思路，这种范式既能缓解依赖损失，又能保持并行解码的效率，为改进MDLMs提供了方向。

Abstract: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require "backward information" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.

</details>


### [24] [ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms](https://arxiv.org/abs/2601.15605)
*Baktash Ansari,Shiza Ali,Elias Martin,Maryna Sivachenko,Afra Mashhadi*

Main category: cs.CL

TL;DR: 本文提出ToxiTwitch混合模型，结合LLM生成的文本和表情嵌入与传统机器学习分类器，用于Twitch直播平台的毒性检测，通过纳入表情分析将准确率提升至80%。


<details>
  <summary>Details</summary>
Motivation: Twitch等直播平台面临毒性行为监管的复杂挑战。传统人工标注和关键词过滤方法在快速、高流量、上下文丰富的聊天环境中难以有效扩展，且人工审核员自身也面临骚扰。LLM的发展为理解涉及表情的细微多模态通信提供了新的毒性检测机会。

Method: 提出ToxiTwitch混合模型，结合DeepSeek-R1-Distill和Llama-3-8B-Instruct等LLM生成的文本和表情嵌入，与随机森林和SVM等传统机器学习分类器。通过纳入表情分析改进毒性行为检测。

Result: 在特定频道训练下，混合方法达到80%的准确率，相比BERT提升13%，F1分数为76%。分析显示纳入表情能改进毒性行为检测。

Conclusion: 这是一项探索性研究，旨在揭示Twitch平台上表情感知毒性检测的挑战和限制。结果表明结合表情分析的混合方法能有效提升检测性能，为直播平台毒性监管提供了新思路。

Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.

</details>


### [25] [Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation](https://arxiv.org/abs/2601.15645)
*Zhiyao Ren,Yibing Zhan,Siyuan Liang,Guozheng Ma,Baosheng Yu,Dacheng Tao*

Main category: cs.CL

TL;DR: 提出了首个用于评估现实医疗咨询中多轮交互置信度的基准，并开发了MedConf框架，通过症状档案构建和信息对齐来生成可解释的置信度估计，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要在单轮静态设置中评估置信度，忽视了真实医疗咨询中随着证据积累置信度与正确性的动态耦合关系，这限制了可靠决策支持。

Method: 提出首个多轮交互医疗咨询置信度评估基准，统一三类医疗数据进行开放式诊断生成，引入信息充分性梯度。开发MedConf框架：通过检索增强生成构建症状档案，将患者信息与支持、缺失和矛盾关系对齐，通过加权集成生成可解释置信度估计。

Result: 在两种LLM和三个医疗数据集上，MedConf在AUROC和Pearson相关系数指标上持续优于最先进方法，在信息不足和多病共存条件下保持稳定性能。

Conclusion: 信息充分性是可信医疗置信度建模的关键决定因素，为构建更可靠、可解释的大型医疗模型提供了新途径。

Abstract: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.

</details>


### [26] [What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking](https://arxiv.org/abs/2601.15674)
*Raymond Xiong,Furong Jia,Lionel Wong,Monica Agrawal*

Main category: cs.CL

TL;DR: 研究创建了一个基于患者真实问题的医疗问答数据集，发现许多问题包含错误假设和危险意图，而当前LLMs难以识别这些问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM医疗问答基准主要基于医学考试题目，与患者实际提出的问题在风格和内容上差异很大，需要创建更贴近真实患者问题的评估数据集

Method: 通过Google的"People Also Ask"功能，查询美国前200种处方药，收集患者常问的医疗问题，构建数据集并分析问题中的错误假设和危险意图

Result: 收集的数据集中有相当一部分问题包含错误假设和危险意图；这些"被污染"问题的出现不是随机的，而是与历史问题中的错误程度密切相关；当前在其他基准上表现良好的LLMs难以识别日常问题中的错误假设

Conclusion: 需要开发能够更好识别患者日常问题中错误假设和危险意图的LLMs，现有医疗问答基准需要包含更多真实患者问题以提高模型的实用性

Abstract: Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.

</details>


### [27] [Persona Switch: Mixing Distinct Perspectives in Decoding Time](https://arxiv.org/abs/2601.15708)
*Junseok Kim,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: Persona Switch：一种新颖的解码方法，通过动态比较零样本提示和角色扮演提示的输出置信度，在每一步选择更好的输出，从而结合两种提示策略的优势。


<details>
  <summary>Details</summary>
Motivation: 角色扮演提示通过注入角色来引导语言模型行为，提升零样本推理能力，但这种提升在不同任务或实例中不一致。这表明零样本提示和角色扮演提示可能具有互补优势，而非一方普遍优于另一方。

Method: 提出Persona Switch方法：逐步解码过程中，通过比较零样本提示和角色扮演提示的输出置信度（以logit gap衡量），在每一步选择更好的输出。动态结合两种提示策略的优势。

Result: 在广泛使用的LLMs上的实验表明，Persona Switch始终优于竞争基线，实现了高达5.13%的准确率提升。同时证明输出置信度是选择更可靠输出的有效指标。

Conclusion: Persona Switch通过动态结合零样本提示和角色扮演提示的优势，提供了一种有效的解码方法，能够一致地提升语言模型的性能，同时验证了输出置信度作为选择机制的有效性。

Abstract: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.

</details>


### [28] [Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind](https://arxiv.org/abs/2601.15715)
*Zhitao He,Zongwei Lyu,Yi R Fung*

Main category: cs.CL

TL;DR: 提出了首个基于心智理论（ToM）的学术反驳框架RebuttalAgent，通过TSR管道建模审稿人心理状态、制定说服策略并生成策略驱动的回复，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 学术反驳是一个在严重信息不对称下进行战略沟通的复杂过程，而非简单的技术辩论。现有方法主要模仿表面语言特征，缺乏有效说服所需的心智理论视角，因此难以应对这一挑战。

Method: 1. 提出RebuttalAgent框架，采用ToM-Strategy-Response（TSR）管道；2. 构建大规模数据集RebuttalBench，使用新颖的批判-精炼方法合成；3. 两阶段训练：监督微调培养ToM分析和战略规划能力，强化学习利用自奖励机制进行可扩展的自我改进；4. 开发Rebuttal-RM专门评估器，基于10万+多源反驳数据进行训练。

Result: RebuttalAgent在自动指标上平均比基础模型提升18.3%，同时在自动和人工评估中均优于先进的专有模型。Rebuttal-RM评估器在评分一致性上超越了GPT-4.1，与人类偏好更匹配。

Conclusion: 将心智理论融入学术反驳框架能显著提升反驳质量，通过建模审稿人心理状态和制定针对性说服策略，实现了更有效的学术沟通。该方法为复杂信息不对称场景下的战略沟通提供了新思路。

Abstract: Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.

</details>


### [29] [Hallucination Mitigating for Medical Report Generation](https://arxiv.org/abs/2601.15745)
*Ruoqing Zhao,Runze Xia,Piji Li*

Main category: cs.CL

TL;DR: KERM框架通过知识检索、净化模块和细粒度奖励机制，减少医学报告生成中的幻觉问题，提升报告质量。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学报告生成中容易产生看似合理但不准确的"幻觉"陈述，这在医学领域尤其危险，需要解决这一问题。

Method: 1) 使用MedCLIP从知识库中检索相关病灶事实句子；2) 引入净化模块确保检索知识与患者临床上下文相关；3) 采用细粒度奖励机制指导模型生成临床相关描述。

Result: 在IU-Xray和MIMIC-CXR数据集上的实验验证了该方法在减少幻觉和提升报告质量方面的有效性。

Conclusion: KERM框架通过知识增强和细粒度奖励机制，有效缓解了医学报告生成中的幻觉问题，为临床实践提供了更可靠的自动化工具。

Abstract: In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \textbf{K}nowledge-\textbf{E}nhanced with Fine-Grained \textbf{R}einforced Rewards \textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.

</details>


### [30] [Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs](https://arxiv.org/abs/2601.15755)
*Tristan Williams,Franziska Weeber,Sebastian Padó,Alan Akbik*

Main category: cs.CL

TL;DR: 该论文提出一个评估语言模型代表性的新框架，不仅关注边际响应分布，还强调多元相关模式的重要性，发现现有对齐技术在捕捉人类价值观的深层结构方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语言模型在单个调查项目上的边际响应分布对齐，但忽视了真实人群中存在的深层潜在结构和相关模式，而这些结构正是文化价值观理论的基础。需要更全面的评估方法来衡量模型对人类价值观的代表性。

Method: 提出一个评估框架，同时考虑边际分布和多元相关模式。比较两种模型引导技术：人物角色提示和人口统计微调，使用世界价值观调查的人类响应数据作为黄金标准进行评估。

Result: 人口统计微调模型在边际响应分布上比人物角色提示表现更好，但两种技术都无法完全捕捉黄金标准的相关模式。仅关注边际分布的评估会掩盖结构性问题，导致对模型能力过于乐观的结论。

Conclusion: 代表性是价值观对齐的一个独特方面，需要同时评估边际分布和相关模式。当前的对齐技术在捕捉人类价值观的深层结构方面仍有不足，需要开发更全面的评估方法。

Abstract: Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.

</details>


### [31] [HumanLLM: Towards Personalized Understanding and Simulation of Human Nature](https://arxiv.org/abs/2601.15793)
*Yuxuan Lei,Tianfu Wang,Jianxun Lian,Zhengyu Hu,Defu Lian,Xing Xie*

Main category: cs.CL

TL;DR: HumanLLM：基于大规模真实用户数据构建的个性化人类行为理解与模拟基础模型，通过认知基因组数据集训练，显著提升对人类行为、思维和体验的预测能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学、编程等客观任务上表现优异，但在模拟人类行为方面存在局限，缺乏对人类认知和行为的细致理解。这种限制源于标准预训练使用无上下文的海量网络数据，无法捕捉个体随时间变化的连续情境化决策、思维和行为。

Method: 1. 构建认知基因组数据集：从Reddit、Twitter、Blogger、Amazon等平台收集真实用户数据，通过多阶段数据过滤、合成和质量控制流程，自动提取超过550万条用户日志，提炼丰富的用户画像、行为和思维模式。
2. 设计多样化学习任务并进行监督微调：使模型能够预测广泛的个性化人类行为、思维和体验。

Result: HumanLLM在预测用户行为和内心思维方面表现优异，更准确地模仿用户写作风格和偏好，生成更真实的用户画像。在领域外社会智能基准测试中也显示出显著的泛化能力提升。

Conclusion: HumanLLM通过构建认知基因组数据集和专门训练，成功提升了语言模型对人类个性化行为的理解和模拟能力，为社会科学研究和以客户为中心的商业洞察提供了有力工具。

Abstract: Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.

</details>


### [32] [SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics](https://arxiv.org/abs/2601.15809)
*Silvia Casola,Ryan Soh-Eun Shim,Felicia Körner,Yuchen Mao,Barbara Plank*

Main category: cs.CL

TL;DR: 通过将多语言神经指标激活转向英语枢纽，可提升与人类判断的相关性


<details>
  <summary>Details</summary>
Motivation: 多语言自然语言生成任务缺乏准确稳健的评估指标，且多语言模型常以英语为内部枢纽语言，这种不匹配可能影响多语言神经指标的性能

Method: 采用测试时干预方法，将编码器和解码器基指标的激活转向英语枢纽，实验验证其有效性

Result: 测试时干预方法对所有类型指标都有效，显著提升了多种语言下指标与人类判断的相关性

Conclusion: 通过将多语言神经指标激活转向英语枢纽，可以有效改善其评估性能，为多语言自然语言生成任务提供更好的评估工具

Abstract: An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.

</details>


### [33] [ExDR: Explanation-driven Dynamic Retrieval Enhancement for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15820)
*Guoxuan Ding,Yuqing Li,Ziyan Zhou,Zheng Lin,Daren Zha,Jiangnan Li*

Main category: cs.CL

TL;DR: ExDR框架通过解释驱动的动态检索增强生成，提升多模态假新闻检测性能，解决冗余检索、相似度粗糙和无关证据等问题。


<details>
  <summary>Details</summary>
Motivation: 多模态假新闻快速传播对社会构成严重威胁，其动态演化和依赖时效性事实的特点使现有检测方法面临挑战。动态检索增强生成虽能通过关键词检索和外部知识整合提供解决方案，但在应用于欺骗性内容时仍存在冗余检索、相似度粗糙和无关证据等问题。

Method: 提出ExDR框架，在检索触发和证据检索模块中系统利用模型生成的解释：1）从三个互补维度评估触发置信度；2）通过融合欺骗性实体构建实体感知索引；3）基于欺骗特定特征检索对比证据来挑战初始主张并增强最终预测。

Result: 在AMG和MR2两个基准数据集上的实验表明，ExDR在检索触发准确性、检索质量和整体检测性能方面均优于先前方法，展现了其有效性和泛化能力。

Conclusion: ExDR框架通过解释驱动的动态检索增强生成，有效解决了多模态假新闻检测中的关键挑战，为动态检索在欺骗性内容分析中的应用提供了新思路。

Abstract: The rapid spread of multimodal fake news poses a serious societal threat, as its evolving nature and reliance on timely factual details challenge existing detection methods. Dynamic Retrieval-Augmented Generation provides a promising solution by triggering keyword-based retrieval and incorporating external knowledge, thus enabling both efficient and accurate evidence selection. However, it still faces challenges in addressing issues such as redundant retrieval, coarse similarity, and irrelevant evidence when applied to deceptive content. In this paper, we propose ExDR, an Explanation-driven Dynamic Retrieval-Augmented Generation framework for Multimodal Fake News Detection. Our framework systematically leverages model-generated explanations in both the retrieval triggering and evidence retrieval modules. It assesses triggering confidence from three complementary dimensions, constructs entity-aware indices by fusing deceptive entities, and retrieves contrastive evidence based on deception-specific features to challenge the initial claim and enhance the final prediction. Experiments on two benchmark datasets, AMG and MR2, demonstrate that ExDR consistently outperforms previous methods in retrieval triggering accuracy, retrieval quality, and overall detection performance, highlighting its effectiveness and generalization capability.

</details>


### [34] [Can professional translators identify machine-generated text?](https://arxiv.org/abs/2601.15828)
*Michael Farrell*

Main category: cs.CL

TL;DR: 专业翻译人员未经专门训练也能在一定程度上识别AI生成的意大利语短篇小说，但准确率有限且存在误判


<details>
  <summary>Details</summary>
Motivation: 研究专业翻译人员在没有专门培训的情况下，能否可靠识别AI生成的意大利语短篇小说，探讨AI文本在专业编辑环境中的可检测性

Method: 69名翻译人员参与现场实验，评估三篇匿名短篇小说（两篇由ChatGPT-4o生成，一篇由人类作者撰写），对每篇故事评估AI作者的可能性并提供判断依据

Result: 平均结果不明确，但16.2%的参与者能成功区分AI文本与人类文本；几乎同等数量的人反向误判。低爆发性和叙事矛盾是最可靠的AI文本指标，而语法准确性和情感基调常导致误判

Conclusion: 专业翻译人员具备一定的AI文本识别能力，但判断常基于主观印象而非客观标记，这引发了对专业环境中合成文本编辑角色和范围的思考

Abstract: This study investigates whether professional translators can reliably identify short stories generated in Italian by artificial intelligence (AI) without prior specialized training. Sixty-nine translators took part in an in-person experiment, where they assessed three anonymized short stories - two written by ChatGPT-4o and one by a human author. For each story, participants rated the likelihood of AI authorship and provided justifications for their choices. While average results were inconclusive, a statistically significant subset (16.2%) successfully distinguished the synthetic texts from the human text, suggesting that their judgements were informed by analytical skill rather than chance. However, a nearly equal number misclassified the texts in the opposite direction, often relying on subjective impressions rather than objective markers, possibly reflecting a reader preference for AI-generated texts. Low burstiness and narrative contradiction emerged as the most reliable indicators of synthetic authorship, with unexpected calques, semantic loans and syntactic transfer from English also reported. In contrast, features such as grammatical accuracy and emotional tone frequently led to misclassification. These findings raise questions about the role and scope of synthetic-text editing in professional contexts.

</details>


### [35] [Determinants of Training Corpus Size for Clinical Text Classification](https://arxiv.org/abs/2601.15846)
*Jaya Chaturvedi,Saniya Deshpande,Chenkai Ma,Robert Cobb,Angus Roberts,Robert Stewart,Daniel Stahl,Diana Shamsutdinova*

Main category: cs.CL

TL;DR: 研究分析了临床文本分类中训练数据量与性能的关系，发现600个文档即可达到使用10,000个文档时95%的性能，并揭示了词汇特性（强预测词和噪声词）对学习曲线的影响。


<details>
  <summary>Details</summary>
Motivation: 临床文本分类通常需要200-500个标注文档，但这一数量缺乏理论依据，且未考虑文本词汇特性对样本量需求的影响。研究旨在量化训练数据量与性能的关系，并分析词汇特性如何影响学习效率。

Method: 使用MIMIC-III数据集中的医院出院记录，以ICD-9诊断为标签。采用预训练的BERT嵌入和随机森林分类器，对10个随机选择的诊断进行分类。训练集规模从100到10,000个文档变化，并通过Lasso逻辑回归分析词汇特性，识别强预测词和噪声词。

Result: 不同分类任务的学习曲线差异显著。600个文档足以达到使用10,000个文档时95%的性能。词汇分析显示：强预测词越多、噪声词越少，学习曲线越陡峭。每增加100个噪声词，准确率下降约0.02；每增加100个强预测词，最大准确率提高约0.04。

Conclusion: 临床文本分类的样本量需求与词汇特性密切相关。600个文档可能是合理的基准样本量，但实际需求应根据具体任务的词汇特性进行调整。词汇分析可为样本量规划提供指导，优化标注资源分配。

Abstract: Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
  Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
  Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.

</details>


### [36] [Artificial Rigidities vs. Biological Noise: A Comparative Analysis of Multisensory Integration in AV-HuBERT and Human Observers](https://arxiv.org/abs/2601.15869)
*Francisco Portillo López*

Main category: cs.CL

TL;DR: AV-HuBERT在McGurk效应测试中与人类听觉主导率高度相似（32.0% vs 31.8%），但在语音融合上表现出更强的确定性偏好（68.0% vs 47.7%），缺乏人类感知的随机性和多样性。


<details>
  <summary>Details</summary>
Motivation: 评估AV-HuBERT模型的感知生物保真度，特别是测试其在不一致视听刺激（McGurk效应）下的反应是否与人类观察者相似，以了解当前自监督架构是否能模拟人类多感官语音感知的神经机制。

Method: 通过McGurk效应实验，比较AV-HuBERT模型与44名人类观察者对不一致视听刺激的反应。测量听觉主导率、语音融合率等指标，分析AI与人类在感知模式上的异同。

Result: 1. AI与人类听觉主导率惊人相似（32.0% vs 31.8%），表明模型能捕捉生物听觉抵抗阈值；2. AV-HuBERT在语音融合上表现出更强的确定性偏好（68.0% vs 47.7%）；3. 人类表现出感知随机性和多样错误模式，而模型保持严格分类性。

Conclusion: 当前自监督架构能模拟多感官结果，但缺乏人类语音感知固有的神经变异性。模型在定量同构上表现良好，但在感知随机性和多样性方面与生物系统存在差异。

Abstract: This study evaluates AV-HuBERT's perceptual bio-fidelity by benchmarking its response to incongruent audiovisual stimuli (McGurk effect) against human observers (N=44). Results reveal a striking quantitative isomorphism: AI and humans exhibited nearly identical auditory dominance rates (32.0% vs. 31.8%), suggesting the model captures biological thresholds for auditory resistance. However, AV-HuBERT showed a deterministic bias toward phonetic fusion (68.0%), significantly exceeding human rates (47.7%). While humans displayed perceptual stochasticity and diverse error profiles, the model remained strictly categorical. Findings suggest that current self-supervised architectures mimic multisensory outcomes but lack the neural variability inherent to human speech perception.

</details>


### [37] [Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model](https://arxiv.org/abs/2601.15892)
*Chenghao Fan,Wen Heng,Bo Li,Sichen Liu,Yuxuan Song,Jing Su,Xiaoye Qu,Kai Shen,Wei Wei*

Main category: cs.CL

TL;DR: Stable-DiffCoder是一个基于块扩散的代码模型，在相同数据和架构下超越了自回归模型，通过扩散训练提升了代码建模质量，并在代码编辑、推理和低资源语言方面表现出优势。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（DLLMs）相比自回归模型具有非顺序生成和更好的数据复用优势，但现有代码DLLMs在相同预算下仍落后于自回归基线。本文旨在探索扩散模型在代码建模中的潜力，提升其性能。

Method: 提出Stable-DiffCoder，基于Seed-Coder架构，采用块扩散持续预训练（CPT）阶段，结合定制化的预热策略和块级裁剪噪声调度，实现高效知识学习和稳定训练。

Result: 在相同数据和架构下，Stable-DiffCoder在广泛的代码基准测试中整体超越了其自回归对应模型。仅通过CPT和监督微调阶段，就超越了多种约8B参数的自回归和扩散模型。

Conclusion: 扩散训练可以提升代码建模质量，超越单纯的自回归训练。扩散模型的任意顺序建模能力改进了结构化代码的编辑和推理，并通过数据增强有益于低资源编程语言。

Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.

</details>


### [38] [Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech](https://arxiv.org/abs/2601.15909)
*Soufiane Jhilal,Stéphanie Martin,Anne-Lise Giraud*

Main category: cs.CL

TL;DR: 该论文提出了一种基于图像的方法，将MEG信号转换为时频表示，利用预训练视觉模型解码想象语音，取得了比传统方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 想象语音的非侵入式解码面临信号弱、分布广和标记数据有限的挑战，需要更有效的方法来提取神经信号中的语义信息。

Method: 通过可学习的传感器空间卷积将MEG信号投影为三种空间尺度混合的时频表示，形成类似图像的输入，然后使用ImageNet预训练的视觉模型进行处理。

Result: 预训练视觉模型在21名参与者的想象语音任务中表现优异：想象vs静默达到90.4%平衡准确率，想象vs默读81.0%，元音解码60.6%。跨被试评估显示模型能捕捉共享神经表征。

Conclusion: 预训练视觉模型应用于基于图像的MEG表示能有效捕捉想象语音的神经结构，为非侵入式脑机接口提供了有前景的方法。

Abstract: Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.

</details>


### [39] [Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain](https://arxiv.org/abs/2601.16018)
*Özgür Uğur,Mahmut Göksu,Mahmut Çimen,Musa Yılmaz,Esra Şavirdi,Alp Talha Demir,Rumeysa Güllüce,İclal Çetin,Ömer Can Sağbaş*

Main category: cs.CL

TL;DR: Mecellem框架通过领域适应策略开发土耳其法律领域专用语言模型，包括从头预训练的编码器模型和持续预训练的Decoder模型，在土耳其法律检索和文本理解任务上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 为土耳其法律领域开发专用语言模型，解决现有SOTA模型需要多阶段、计算密集型训练流程的问题，提供更高效、成本更低的替代方案。

Method: 1. 编码器模型：基于ModernBERT从头预训练，使用1127亿土耳其语为主的语料，采用检查点选择策略评估下游检索性能；2. Decoder模型：基于Qwen3-1.7B和Qwen3-4B进行持续预训练，采用四阶段课程学习逐步适应法律领域。

Result: 编码器模型在土耳其检索排行榜上排名前3，小模型(1.55亿参数)性能媲美大模型(3.07-5.67亿参数)，生产效率达92.36%；Decoder模型在土耳其法律文本上困惑度降低36.2%。

Conclusion: Mecellem框架通过单阶段预训练加高效后训练的方法，为土耳其法律领域提供了计算效率高、性能优异的专用语言模型，是现有多阶段训练方法的有效替代方案。

Abstract: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.

</details>


### [40] [Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction](https://arxiv.org/abs/2601.16034)
*Tony Cristofano*

Main category: cs.CL

TL;DR: 提出Trajectory Replay via Concept-Basis Reconstruction框架，通过概念指纹对齐和重构拒绝方向，实现跨模型架构的安全对齐干预迁移，证明拒绝行为源于跨模型的通用低维语义电路。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将LLM的拒绝行为视为模型特定的，但本文假设拒绝行为源于跨模型共享的通用低维语义电路。为了验证这一假设，需要开发能够跨不同架构和训练机制迁移拒绝干预的方法。

Method: 提出Trajectory Replay via Concept-Basis Reconstruction框架：1) 通过概念指纹对齐不同模型的层；2) 使用共享的"概念原子"配方重构拒绝方向；3) 将供体模型的消融轨迹映射到目标模型的语义空间；4) 引入weight-SVD稳定性保护，将干预投影到低方差权重子空间以避免能力损害。

Result: 在8个模型对（包括GPT-OSS-20B和GLM-4）上的评估表明，迁移的干预配方能持续减弱拒绝行为，同时保持模型性能，为安全对齐的语义通用性提供了有力证据。

Conclusion: 拒绝行为确实源于跨模型共享的通用低维语义电路，而非模型特定特性。提出的框架能够有效迁移安全对齐干预，为理解和操作LLM的安全机制提供了新途径。

Abstract: Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.

</details>


### [41] [Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating](https://arxiv.org/abs/2601.16097)
*Makbule Gulcin Ozsoy*

Main category: cs.CL

TL;DR: 该论文提出了一种可扩展的多语言Text2Cypher方法，通过训练语言特定的LoRA适配器，并使用学习型融合MLP动态组合，实现了接近联合多语言微调的性能，同时支持新语言的增量扩展。


<details>
  <summary>Details</summary>
Motivation: 当前Text2SQL/SPARQL/Cypher等自然语言数据库接口主要关注英语，多语言支持有限。需要一种可扩展的方法来支持新语言，避免重新进行完整的微调、手动超参数调整，同时保持接近联合多语言微调的性能。

Method: 为英语、西班牙语和土耳其语训练语言特定的LoRA适配器，通过两种方式组合：1) 统一线性合并；2) 具有动态门控的学习型融合MLP。这种方法允许通过仅添加一个LoRA适配器和轻量级MLP重新训练来增量扩展新语言。

Result: 实验结果显示，融合MLP方法恢复了约75%的联合多语言微调带来的准确率提升，同时只需要较小的数据子集。在所有三种语言上都优于线性合并方法。

Conclusion: 学习型适配器融合为昂贵的联合微调提供了实用的替代方案，在多语言Text2Cypher任务中平衡了性能、数据效率和可扩展性，支持新语言的增量扩展。

Abstract: Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.

</details>


### [42] [synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier](https://arxiv.org/abs/2601.16113)
*Haq Nawaz Malik,Kh Mohmad Shafi,Tanveer Ahmad Reshi*

Main category: cs.CL

TL;DR: SynthOCR-Gen是一个为低资源语言设计的开源合成OCR数据集生成工具，通过将数字Unicode文本转换为训练数据集，解决了OCR开发中的数据集瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 低资源语言如克什米尔语（约700万使用者）缺乏OCR支持，因为创建大规模标注训练数据集成本高、耗时长且易出错。现有主流OCR系统（Tesseract、TrOCR、PaddleOCR）都不支持这些语言。

Method: 开发了SynthOCR-Gen工具，包含完整流程：文本分割（字符、单词、n-gram、句子、行级）、Unicode规范化与脚本纯度强制、多字体渲染（可配置分布）、25+种数据增强技术（模拟真实文档退化如旋转、模糊、噪声、扫描伪影）。

Result: 生成了包含60万个单词分割样本的克什米尔语OCR数据集，并公开发布在HuggingFace上，为低资源语言进入视觉-语言AI模型时代提供了实用途径。

Conclusion: SynthOCR-Gen为全球研究者和从业者提供了一个开源工具，能够有效解决低资源语言OCR开发的数据集瓶颈问题，推动这些语言进入AI时代。

Abstract: Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.

</details>


### [43] [Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging](https://arxiv.org/abs/2601.16127)
*Alphaeus Dmonte,Vidhi Gupta,Daniel J Perry,Mark Arehart*

Main category: cs.CL

TL;DR: 本文首次从效率角度分析多语言模型合并策略，证明通过合并单语言模型而非完全重新训练，可显著降低计算成本和维护负担，同时保持模型质量。


<details>
  <summary>Details</summary>
Motivation: 传统多语言大语言模型微调需要为所有支持语言重新训练整个模型，计算效率低下且维护成本高。现有研究虽展示了多任务模型合并的质量优势，但缺乏对其计算和维护效率的系统分析。

Method: 采用多语言模型合并策略：首先训练单语言模型，然后合并这些模型，而非直接训练完整多语言模型。通过三个独立任务评估该方法的效率，包括更新单个语言时的重新合并策略。

Result: 合并方法将初始训练时间减少高达50%，更新单个语言并重新合并可将训练成本降低60%以上。在公开和工业数据集上均验证了该方法在保持质量的同时显著提升效率。

Conclusion: 多语言模型合并策略在工业应用和学术场景中都表现出显著的计算和维护效率优势，为解决多语言模型更新和维护瓶颈提供了有效方案。

Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.

</details>


### [44] [Automatic Classification of Arabic Literature into Historical Eras](https://arxiv.org/abs/2601.16138)
*Zainab Alhathloul,Irfan Ahmad*

Main category: cs.CL

TL;DR: 使用神经网络和深度学习技术自动分类阿拉伯语文本到不同历史时期，从二元分类到15类分类，在多个数据集上评估性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语随时间演变，古典与现代时期有明显差异，但现有研究很少探索阿拉伯文本（尤其是非诗歌领域）的自动时期分类，本文旨在填补这一空白。

Method: 采用神经网络和深度学习技术，使用两个公开可用的语料库（OpenITI和APCD）构建数据集，涵盖从前伊斯兰到现代时期的文本，研究从二元到15类的分类设置，考虑预定义历史时期和自定义分期。

Result: 二元时期分类任务在OpenITI和APCD数据集上分别获得0.83和0.79的F1分数；15时期分类任务在OpenITI上获得0.20的F1分数；12时期分类任务在APCD上获得0.18的F1分数。

Conclusion: 神经网络和深度学习技术可用于阿拉伯语文本的自动时期分类，二元分类效果较好，但随着类别数量增加性能下降，表明更精细的历史时期分类具有挑战性。

Abstract: The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.

</details>


### [45] [LLM-in-Sandbox Elicits General Agentic Intelligence](https://arxiv.org/abs/2601.16206)
*Daixuan Cheng,Shaohan Huang,Yuxian Gu,Huatong Song,Guoxin Chen,Li Dong,Wayne Xin Zhao,Ji-Rong Wen,Furu Wei*

Main category: cs.CL

TL;DR: LLM-in-Sandbox让大语言模型在代码沙箱中探索，激发其在非代码领域的通用智能，通过训练和无训练两种方式实现跨领域泛化。


<details>
  <summary>Details</summary>
Motivation: 激发大语言模型在非代码领域的通用智能，让模型能够利用代码沙箱环境来执行各种非编程任务，如访问外部资源、处理长上下文等。

Method: 1. 训练无方法：直接让强LLM在代码沙箱中探索；2. 强化学习方法：使用非智能数据训练模型进行沙箱探索（LLM-in-Sandbox-RL）。

Result: LLM-in-Sandbox在数学、物理、化学、生物医学、长上下文理解和指令遵循等任务上表现出强大的泛化能力，并开源为Python包。

Conclusion: LLM-in-Sandbox为LLM提供了在代码沙箱中探索的能力，有效激发了非代码领域的通用智能，具有实际部署价值。

Abstract: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [46] [Designing Persuasive Social Robots for Health Behavior Change: A Systematic Review of Behavior Change Strategies and Evaluation Methods](https://arxiv.org/abs/2601.15309)
*Jiaxin Xu,Chao Zhang,Raymond H. Cuijpers,Wijnand A. IJsselsteijn*

Main category: cs.RO

TL;DR: 系统综述分析了39项研究，总结了社交机器人在健康行为改变干预中使用的四大行为改变策略类别，并评估了当前的研究评估方法。


<details>
  <summary>Details</summary>
Motivation: 社交机器人越来越多地被应用于健康行为改变干预，但指导其设计和评估的可操作知识仍然有限。需要系统性地了解现有研究中使用哪些行为改变策略以及如何评估效果。

Method: 通过系统数据库检索和手动检索识别相关文献，对39项研究进行分析，总结行为改变策略类别和评估方法特征。

Result: 识别出四大行为改变策略类别：指导策略、咨询策略、社会影响策略和说服增强策略。同时分析了当前评估实践的关键特征，包括研究设计、设置、持续时间和结果测量。

Conclusion: 这些策略突出了社交机器人作为行为改变干预的独特优势，提供了有价值的设计启发。基于评估实践分析，提出了未来人机交互研究的几个方向。

Abstract: Social robots are increasingly applied as health behavior change interventions, yet actionable knowledge to guide their design and evaluation remains limited. This systematic review synthesizes (1) the behavior change strategies used in existing HRI studies employing social robots to promote health behavior change, and (2) the evaluation methods applied to assess behavior change outcomes. Relevant literature was identified through systematic database searches and hand searches. Analysis of 39 studies revealed four overarching categories of behavior change strategies: coaching strategies, counseling strategies, social influence strategies, and persuasion-enhancing strategies. These strategies highlight the unique affordances of social robots as behavior change interventions and offer valuable design heuristics. The review also identified key characteristics of current evaluation practices, including study designs, settings, durations, and outcome measures, on the basis of which we propose several directions for future HRI research.

</details>


### [47] [Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray](https://arxiv.org/abs/2601.15349)
*Jiaqing Chang,Song Gao,Chaowei Dong,zhaobang Li,Yang Liu*

Main category: cs.RO

TL;DR: 该研究设计了一种受牛鼻魟启发的磁响应微软机器人，采用NdFeB和PDMS材料制造，通过三维亥姆霍兹线圈产生的振荡谐波磁场驱动，实现了多种游泳模式，最高速度达5.25 mm/s。


<details>
  <summary>Details</summary>
Motivation: 在狭窄、非结构化的水下环境（如环境监测和微创医疗）中，微软机器人因其灵活运动能力和小尺寸具有独特优势。但受限于小型化，这些机器人难以内部供电，通常需要无线供电方式。本研究旨在开发一种磁驱动的仿生微软机器人。

Method: 基于牛鼻魟的游泳原理，设计制造了由NdFeB和PDMS按一定比例制成的磁响应微软机器人。使用三维亥姆霍兹线圈产生振荡谐波磁场进行游泳实验，探索磁场参数对机器人游泳性能的影响，并通过逐步调整方法减少响应误差。

Result: 实验结果显示：在B=5 mT、f=11 Hz时游泳速度最快，达到5.25 mm/s（约0.5体长/秒）。通过调整线圈电流方向和频率，机器人可实现直线游泳、转弯游泳和定向游泳等多种模式。逐步调整方法能有效减少响应误差对轨迹的影响。

Conclusion: 本研究展示了一种磁驱动微软机器人的方法，为无线驱动机器人在水下狭窄空间的应用奠定了基础，证明了仿生设计和磁驱动在微软机器人领域的可行性。

Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.

</details>


### [48] [Learning a Unified Latent Space for Cross-Embodiment Robot Control](https://arxiv.org/abs/2601.15419)
*Yashuai Yan,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出一个可扩展的跨具身人形机器人控制框架，通过学习共享潜在表示来统一人类和多样化人形平台（单臂、双臂、腿式人形机器人）的运动。


<details>
  <summary>Details</summary>
Motivation: 解决不同形态人形机器人之间的运动控制统一问题，实现跨具身的通用控制，避免为每个机器人单独训练策略，提高机器人控制的扩展性和适应性。

Method: 采用两阶段方法：1）通过对比学习构建解耦的潜在空间，捕捉不同身体部位的局部运动模式，使用结合关节旋转和末端执行器定位的定制相似性度量；2）在潜在空间中训练目标条件控制策略，使用条件变分自编码器预测潜在空间位移，仅需人类数据训练。

Result: 训练的策略可直接部署到多个机器人上无需适配，支持通过轻量级机器人特定嵌入层高效添加新机器人，学习到的潜在策略可直接应用于新机器人，实现稳健、可扩展、具身无关的机器人控制。

Conclusion: 该方法实现了跨多样化人形平台的统一控制框架，通过共享潜在表示和两阶段学习过程，显著提高了机器人控制的扩展性、适应性和部署效率。

Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.

</details>


### [49] [Neural Collision Detection for Multi-arm Laparoscopy Surgical Robots Through Learning-from-Simulation](https://arxiv.org/abs/2601.15459)
*Sarvin Ghiasi,Majid Roshanfar,Jake Barralet,Liane S. Feldman,Amir Hooshiar*

Main category: cs.RO

TL;DR: 提出整合分析建模、实时仿真和机器学习的框架，提升腹腔镜手术中机械臂的安全性和操作效率，解决碰撞检测和最小距离估计的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术中机械臂的安全操作面临碰撞检测和最小距离估计的挑战，需要开发既能确保安全又能提高操作效率的解决方案。

Method: 1) 开发分析模型基于关节配置估计机械臂间最小距离；2) 创建3D仿真环境模拟两个7自由度Kinova机械臂，生成碰撞检测和距离估计数据集；3) 训练深度神经网络，输入为机械臂关节执行器和相对位置。

Result: 深度神经网络模型达到平均绝对误差282.2毫米，R平方值0.85，预测距离与实际距离高度一致，验证了网络准确性和空间关系泛化能力。

Conclusion: 结合分析精度和机器学习算法能有效提升机器人系统的精度和可靠性，为腹腔镜手术中机械臂的安全高效操作提供了可行方案。

Abstract: This study presents an integrated framework for enhancing the safety and operational efficiency of robotic arms in laparoscopic surgery by addressing key challenges in collision detection and minimum distance estimation. By combining analytical modeling, real-time simulation, and machine learning, the framework offers a robust solution for ensuring safe robotic operations. An analytical model was developed to estimate the minimum distances between robotic arms based on their joint configurations, offering precise theoretical calculations that serve as both a validation tool and a benchmark. To complement this, a 3D simulation environment was created to model two 7-DOF Kinova robotic arms, generating a diverse dataset of configurations for collision detection and distance estimation. Using these insights, a deep neural network model was trained with joint actuators of robot arms and relative positions as inputs, achieving a mean absolute error of 282.2 mm and an R-squared value of 0.85. The close alignment between predicted and actual distances highlights the network's accuracy and its ability to generalize spatial relationships. This work demonstrates the effectiveness of combining analytical precision with machine learning algorithms to enhance the precision and reliability of robotic systems.

</details>


### [50] [A Universal Large Language Model -- Drone Command and Control Interface](https://arxiv.org/abs/2601.15486)
*Javier N. Ramos-Silva,Peter J. Burke*

Main category: cs.RO

TL;DR: 提出基于模型上下文协议（MCP）的通用无人机控制接口，将大型语言模型与无人机控制无缝集成，实现自然语言到无人机指令的转换。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的无人机控制面临挑战：虽然LLMs具备大规模通用知识（包括地理拓扑和实时天气数据），但将LLM知识连接到无人机指挥控制系统需要大量繁琐的人工工作。需要一种通用、易用的接口来解决这个问题。

Method: 采用模型上下文协议（MCP）标准，开发基于云的Linux机器托管MCP服务器，支持Mavlink协议（Ardupilot和PX4框架使用的通用无人机控制语言）。通过MCP服务器实现LLM与无人机控制的接口，并集成Google Maps MCP服务器提供实时导航信息。

Result: 成功演示了真实无人机的飞行控制，并在模拟无人机中展示了广泛的飞行规划和控制能力，集成了Google Maps提供的最新实时导航信息。实现了自然语言到无人机控制的转换。

Conclusion: 提出了一种通用的LLM与无人机指挥控制集成方法，利用MCP标准创建了LLM无关、无人机无关的通用接口，将现代AI产业与无人机技术相结合，实现了易用的自然语言到无人机控制转换。

Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.

</details>


### [51] [CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation](https://arxiv.org/abs/2601.15541)
*Heng Zhang,Wei-Hsing Huang,Qiyi Tong,Gokhan Solak,Puze Liu,Sheng Liu,Jan Peters,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出CompliantVLA-adaptor，通过VLM感知任务上下文来调整可变阻抗控制参数，结合实时力反馈，提升接触密集型机器人操作的安全性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA系统通常只输出位置控制，缺乏力感知适应能力，在涉及接触、顺应性或不确定性的物理任务中容易导致不安全或失败的操作。

Method: 使用视觉语言模型从图像和自然语言中解释任务上下文，调整可变阻抗控制器的刚度和阻尼参数，并通过实时力/力矩反馈调节这些参数以确保交互力保持在安全阈值内。

Result: 在模拟和真实硬件上的复杂接触密集型任务中，该方法优于VLA基线，成功率从9.86%提升到17.29%，减少了力违规情况。

Conclusion: CompliantVLA-adaptor为使用VLA进行安全接触密集型操作提供了有前景的路径，通过结合上下文感知的可变阻抗控制和实时力反馈提高了任务成功率和安全性。

Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.

</details>


### [52] [A Mobile Magnetic Manipulation Platform for Gastrointestinal Navigation with Deep Reinforcement Learning Control](https://arxiv.org/abs/2601.15545)
*Zhifan Yan,Chang Liu,Yiyang Jiang,Wenxuan Zheng,Xinhao Chen,Axel Krieger*

Main category: cs.RO

TL;DR: 提出一种基于深度强化学习的移动磁控平台，用于胃肠道靶向药物递送，无需复杂物理模型校准，15分钟内即可部署，实现大工作空间内的精确磁控


<details>
  <summary>Details</summary>
Motivation: 现有磁控系统存在局限性：固定式系统工作空间有限，移动式系统（如机械臂上的线圈）需要复杂、耗时的物理模型校准，形成"模型校准瓶颈"。需要一种快速部署、无需复杂模型的控制框架

Method: 开发紧凑型低成本移动磁控平台：四个电磁铁阵列安装在UR5协作机器人上，采用基于Soft Actor-Critic的深度强化学习控制策略，通过仿真到现实的训练流程，15分钟内完成策略部署

Result: 控制7毫米磁性胶囊沿2D轨迹运动：方形路径RMSE为1.18毫米，圆形路径RMSE为1.50毫米；在临床相关的30厘米×20厘米工作空间内成功跟踪；验证了在2D胃肠道模型中的有效性

Conclusion: 该工作展示了一种快速部署、无需模型的控制框架，能够在大工作空间内实现精确磁控，为胃肠道靶向药物递送提供了有前景的解决方案

Abstract: Targeted drug delivery in the gastrointestinal (GI) tract using magnetic robots offers a promising alternative to systemic treatments. However, controlling these robots is a major challenge. Stationary magnetic systems have a limited workspace, while mobile systems (e.g., coils on a robotic arm) suffer from a "model-calibration bottleneck", requiring complex, pre-calibrated physical models that are time-consuming to create and computationally expensive. This paper presents a compact, low-cost mobile magnetic manipulation platform that overcomes this limitation using Deep Reinforcement Learning (DRL). Our system features a compact four-electromagnet array mounted on a UR5 collaborative robot. A Soft Actor-Critic (SAC)-based control strategy is trained through a sim-to-real pipeline, enabling effective policy deployment within 15 minutes and significantly reducing setup time. We validated the platform by controlling a 7-mm magnetic capsule along 2D trajectories. Our DRL-based controller achieved a root-mean-square error (RMSE) of 1.18~mm for a square path and 1.50~mm for a circular path. We also demonstrated successful tracking over a clinically relevant, 30 cm * 20 cm workspace. This work demonstrates a rapidly deployable, model-free control framework capable of precise magnetic manipulation in a large workspace,validated using a 2D GI phantom.

</details>


### [53] [Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor](https://arxiv.org/abs/2601.15607)
*Lenworth Thomas,Tjaden Bridges,Sarah Bergbreiter*

Main category: cs.RO

TL;DR: 该论文提出了一种在小型四旋翼无人机上结合气流源追踪与化学羽流追踪的方法，使用定制的气流传感器实现流向和流速感知，改进"Cast and Surge"算法来定位气流源。


<details>
  <summary>Details</summary>
Motivation: 随着环境灾害日益频繁和严重，使用羽流追踪技术寻找污染物或有害颗粒源变得愈发重要。小型四旋翼无人机上的羽流追踪可以让这些系统在人类周围操作并在更受限的空间飞行，但由于适合小型四旋翼的气体传感器灵敏度差、响应时间长，这一任务具有挑战性。

Method: 开发了一种能够在小于100克的小型四旋翼上同时感知气流大小和方向的定制气流传感器。使用该传感器实现改进版的"Cast and Surge"算法，利用流向感知来寻找并导航至气流源。

Result: 一系列表征实验验证了系统在飞行中能够检测气流并重新定向四旋翼朝向气流方向。多次随机起始位置和方向的试验表明，该源追踪算法能够可靠地找到气流源。

Conclusion: 这项工作为未来平台奠定了基础，使气流传感器能够与其他传感器协同工作，实现更丰富的羽流追踪数据收集和源追踪能力。

Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors < 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.

</details>


### [54] [AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning](https://arxiv.org/abs/2601.15614)
*Zichen Yan,Yuchen Hou,Shenao Wang,Yichao Gao,Rui Huang,Lin Zhao*

Main category: cs.RO

TL;DR: AION是一个用于空中物体目标导航的端到端双策略强化学习框架，将探索和目标到达行为解耦为两个专门策略，在AI2-THOR和IsaacSim中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有物体目标导航研究主要集中在2D移动的零样本设置，而具有3D移动能力的空中平台导航研究不足。空中机器人虽然具有优越的机动性和搜索效率，但也带来了空间感知、动态控制和安全保障的新挑战。

Method: 提出AION框架，这是一个端到端的双策略强化学习框架，将探索和目标到达行为解耦为两个专门策略。该方法不依赖外部定位或全局地图，基于视觉进行空中物体目标导航。

Result: 在AI2-THOR基准测试中评估，并在IsaacSim中使用高保真无人机模型评估实时性能。实验结果显示，AION在探索、导航效率和安全性等综合评估指标上表现出色。

Conclusion: AION框架成功解决了空中物体目标导航的挑战，通过双策略设计实现了高效的探索和安全的目标到达，为空中机器人的自主导航提供了有效解决方案。

Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.

</details>


### [55] [D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot](https://arxiv.org/abs/2601.15707)
*Qifan Hu,Branko Celler,Weidong Mu,Steven W. Su*

Main category: cs.RO

TL;DR: 提出两阶段校准框架用于3自由度踝关节康复机器人，使用Kronecker积将校准转化为线性参数识别问题，通过PPO算法选择4个最优校准姿态，显著提升校准效率


<details>
  <summary>Details</summary>
Motivation: 多自由度康复机器人的精确对齐对患者训练的安全性和有效性至关重要，传统校准方法效率低且需要大量姿态数据

Method: 1) 基于Kronecker积的开环校准方法将输入输出对齐转化为线性参数识别问题；2) 使用D最优性准则作为实验设计目标；3) 训练PPO智能体从50个候选姿态中选择4个信息量最大的姿态

Result: PPO选择的姿态组合比随机选择的信息矩阵行列式均值高两个数量级以上，方差更小；仅用4个最优姿态获得的参数估计比50个非结构化姿态的预测一致性更强

Conclusion: 该框架在保持参数估计鲁棒性的同时显著提高了校准效率，为多自由度康复机器人的高精度对齐提供了实用指导

Abstract: Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.

</details>


### [56] [DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving](https://arxiv.org/abs/2601.15729)
*Rui Yang,Lei Zheng,Ruoyu Yao,Jun Ma*

Main category: cs.RO

TL;DR: DualShield：结合扩散模型与Hamilton-Jacobi可达性分析的自动驾驶规划控制框架，通过双重安全机制确保不确定交互下的安全性


<details>
  <summary>Details</summary>
Motivation: 扩散模型在自动驾驶多模态运动规划中表现出色，但存在两个主要问题：1) 难以强制执行车辆动力学约束；2) 严重依赖对其他智能体的准确预测，在不确定交互下容易产生安全问题。需要一种既能保持扩散模型丰富探索能力又能提供安全保证的方法。

Method: 提出DualShield框架，利用Hamilton-Jacobi可达性值函数实现双重保护：1) 主动引导：值函数指导扩散去噪过程朝向安全且动力学可行的区域；2) 反应式安全防护：使用控制屏障值函数修改执行动作确保安全。这种双重机制保留了扩散模型的探索能力，同时提供理论安全保证。

Result: 在具有挑战性的无保护U形转弯场景模拟中，DualShield相比不同规划范式的领先方法，在不确定条件下显著提高了安全性和任务效率。

Conclusion: DualShield成功解决了扩散模型在自动驾驶规划中的安全性和动力学可行性问题，通过Hamilton-Jacobi可达性分析的双重应用，实现了在不确定甚至对抗性交互下的安全保证，同时保持了扩散模型的丰富探索能力。

Abstract: Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.

</details>


### [57] [Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV](https://arxiv.org/abs/2601.15775)
*Amir Habel,Ivan Snegirev,Elizaveta Semenyakina,Miguel Altamirano Cabrera,Jeffrin Sam,Fawad Mehboob,Roohan Ahmed Khan,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: Glove2UAV：一款可穿戴IMU手套接口，通过手势控制无人机，并配备振动触觉警告系统，用于超速提醒


<details>
  <summary>Details</summary>
Motivation: 设计一种轻量级、易于部署的可穿戴接口，实现无人机直观手势控制，并通过触觉反馈增强动态飞行中的安全性和可预测性

Method: 使用IMU手套实时流式传输惯性测量数据，结合中值异常抑制和Madgwick方向估计算法处理手掌和手指方向，将运动估计映射到基本控制指令，并设置振动触觉反馈机制

Result: 在仿真和真实飞行中验证了实时可行性，实现了快速手势指令执行、手势动态与平台运动的稳定耦合、核心指令集的正确操作以及及时振动警告提示

Conclusion: Glove2UAV提供了一种直观、安全的手势控制无人机方案，通过实时处理和触觉反馈增强了飞行交互的可预测性和安全性

Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.

</details>


### [58] [A Beacon Based Solution for Autonomous UUVs GNSS-Denied Stealthy Navigation](https://arxiv.org/abs/2601.15802)
*Alexandre Albore,Humbert Fiorino,Damien Pellier*

Main category: cs.RO

TL;DR: 论文提出了一种在GNSS拒止环境下使用信标网络引导UUV舰队从大陆架到海岸目标的自适应导航系统


<details>
  <summary>Details</summary>
Motivation: 在沿海区域进行军事和民用隐蔽行动时，UUV需要在不依赖支持船只或GNSS的情况下进行导航。当无法获得水面访问且需要在保护区或危险区域进行隐蔽导航时，GNSS拒止导航对于保持隐蔽性至关重要，因为浮出水面可能暴露UUV位置。

Method: 通过空中或水面无人机部署信标星座建立合成地标网络，这些信标（水下或漂浮）发射声学信号用于UUV定位和导航。采用分层规划器为执行原始动作的无人机生成自适应路径，同时持续监控并在需要时重新规划以保持轨迹精度。

Result: 系统能够为UUV舰队提供精确的定位和导航，使舰队能够沿着从大陆架到海岸目标的优化路径进行隐蔽航行，同时保持轨迹准确性。

Conclusion: 提出的信标网络和分层规划系统为GNSS拒止环境下的UUV舰队提供了有效的隐蔽导航解决方案，适用于军事和民用沿海隐蔽行动。

Abstract: Autonomous Unmanned Underwater Vehicles (UUVs) enable military and civilian covert operations in coastal areas without relying on support vessels or Global Navigation Satellite Systems (GNSS). Such operations are critical when surface access is not possible and stealthy navigation is required in restricted environments such as protected zones or dangerous areas under access ban. GNSS denied navigation is then essential to maintaining concealment as surfacing could expose UUVs to detection. To ensure a precise fleet positioning a constellation of beacons deployed by aerial or surface drones establish a synthetic landmark network that will guide the fleet of UUVs along an optimized path from the continental shelf to the goal on the shore. These beacons either submerged or floating emit acoustic signals for UUV localisation and navigation. A hierarchical planner generates an adaptive route for the drones executing primitive actions while continuously monitoring and replanning as needed to maintain trajectory accuracy.

</details>


### [59] [TeNet: Text-to-Network for Compact Policy Synthesis](https://arxiv.org/abs/2601.15912)
*Ariyan Bighashdel,Kevin Sebastian Luck*

Main category: cs.RO

TL;DR: TeNet是一个从自然语言描述直接生成紧凑、任务特定机器人策略的框架，使用文本条件化的超网络，只需在策略实例化时使用一次语言，执行时轻量高效。


<details>
  <summary>Details</summary>
Motivation: 当前机器人遵循自然语言指令的方法存在两个极端：要么使用手工设计接口进行高级规划，要么依赖难以实时部署的大型端到端模型。需要一种既能利用大型语言模型的通用知识，又能在执行时保持轻量高效的方法。

Method: TeNet使用预训练大语言模型生成文本嵌入，然后通过超网络基于这些嵌入生成完全可执行的策略。策略只在实例化时使用语言，执行时仅处理低维状态输入。可选地在训练中通过将文本嵌入与演示动作对齐来增强泛化能力。

Result: 在MuJoCo和Meta-World基准测试中，TeNet生成的策略比基于序列的基线方法小几个数量级，同时在多任务和元学习设置中表现强劲，支持高频控制。

Conclusion: 文本条件化的超网络为资源受限的机器人控制任务提供了一种实用的构建紧凑、语言驱动控制器的方法，能够满足实时需求。

Abstract: Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.

</details>


### [60] [Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems](https://arxiv.org/abs/2601.15946)
*Zijie Chen,Xiaowei Liu,Yong Xu,Shenghai Yuan,Jianping Li,Lihua Xie*

Main category: cs.RO

TL;DR: 提出LM-Calibr标定方法和EVA-LIO定位方法，解决旋转驱动LiDAR的标定通用性和特征缺失区域定位鲁棒性问题


<details>
  <summary>Details</summary>
Motivation: 现有方法需要根据不同安装配置参数化外参，限制了通用性；旋转驱动LiDAR不可避免会扫描特征缺失区域，在扫描覆盖度和定位鲁棒性之间难以平衡

Method: 基于Denavit-Hartenberg约定的无目标LiDAR-电机标定方法(LM-Calibr)支持多种安装配置；环境自适应LiDAR-惯性里程计(EVA-LIO)根据空间尺度自适应选择下采样率和地图分辨率

Result: LM-Calibr在不同场景、安装角度和初始值下都表现出高精度和收敛性；EVA-LIO使执行器能以最大速度运行，增强扫描完整性，同时在LiDAR短暂扫描特征缺失区域时确保鲁棒定位

Conclusion: 提出的方法解决了旋转驱动LiDAR系统的标定通用性和定位鲁棒性问题，代码和硬件设计已开源

Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}

</details>


### [61] [PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour](https://arxiv.org/abs/2601.15995)
*Liang Wang,Kanzhong Yao,Yang Liu,Weikai Qin,Jun Wu,Zhe Sun,Qiuguo Zhu*

Main category: cs.RO

TL;DR: PUMA：一种端到端学习框架，将视觉感知和落脚点先验集成到单阶段训练中，用于四足机器人跑酷任务


<details>
  <summary>Details</summary>
Motivation: 人类运动员能够有效感知环境特征选择合适落脚点进行障碍穿越，但赋予腿式机器人类似感知推理能力仍具挑战。现有方法依赖分层控制器遵循预计算落脚点，限制了机器人的实时适应性和强化学习的探索潜力。

Method: 提出PUMA端到端学习框架，将视觉感知和落脚点先验集成到单阶段训练过程。利用地形特征估计以自我为中心的极坐标落脚点先验（相对距离和方向），指导机器人进行主动姿态适应。

Result: 在模拟和真实环境的各种离散复杂地形上进行广泛实验，证明PUMA在挑战性场景中具有卓越的敏捷性和鲁棒性。

Conclusion: PUMA框架通过集成视觉感知和落脚点先验，实现了四足机器人在跑酷任务中的端到端学习，克服了现有分层方法的局限性，展现出优异的实时适应能力。

Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.

</details>


### [62] [Collision-Free Humanoid Traversal in Cluttered Indoor Scenes](https://arxiv.org/abs/2601.16035)
*Han Xue,Sikai Liang,Zhikai Zhang,Zicheng Zeng,Yun Liu,Yunrui Lian,Jilong Wang,Qingtao Liu,Xuesong Shi,Li Yi*

Main category: cs.RO

TL;DR: 提出HumanoidPF表示方法，将人形机器人与障碍物关系编码为无碰撞运动方向，结合混合场景生成方法，实现人形机器人在杂乱室内场景中的通用穿越技能学习与真实世界迁移。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在杂乱室内场景（如跨越障碍、蹲行通过、挤过窄道）中的无碰撞穿越问题。现有方法缺乏有效表示人形机器人与障碍物关系的表示，难以直接学习相应的穿越技能。

Method: 提出Humanoid Potential Field (HumanoidPF)，将人形机器人与障碍物关系编码为无碰撞运动方向，显著促进基于强化学习的穿越技能学习。同时提出混合场景生成方法，结合真实3D室内场景裁剪和程序化合成的障碍物。

Result: HumanoidPF表现出惊人的可忽略的仿真到真实差距。成功将策略迁移到真实世界，开发了只需单次点击即可控制人形机器人穿越杂乱室内场景的遥操作系统。在仿真和真实世界中进行广泛实验验证了方法的有效性。

Conclusion: HumanoidPF作为感知表示能有效促进人形机器人穿越技能学习，具有很小的仿真到真实差距。结合混合场景生成方法，实现了在多样化杂乱室内场景中的通用穿越能力，并成功迁移到真实世界。

Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.

</details>


### [63] [DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning](https://arxiv.org/abs/2601.16046)
*Junha Lee,Eunha Park,Minsu Cho*

Main category: cs.RO

TL;DR: DextER提出了一种基于接触推理的灵巧抓取生成方法，通过预测手部链接与物体表面的接触点作为中间表示，将任务语义与物理约束连接起来，显著提升了抓取成功率和意图对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有语言驱动的灵巧抓取生成方法直接将观察映射到抓取参数，缺乏对物理交互的中间推理。需要一种能够理解任务语义、3D几何和复杂手-物交互的方法，通过物理约束的中间表示来桥接语义与抓取生成。

Method: DextER采用基于接触的具身推理方法，首先自回归生成具身接触令牌，指定哪些手部链接接触物体表面的哪些位置，然后生成编码手部配置的抓取令牌。这种方法通过接触预测作为中间表示，将任务语义与物理约束连接起来。

Result: 在DexGYS数据集上，DextER达到67.14%的成功率，比现有最佳方法提升3.83个百分点，意图对齐度提升96.4%。同时展示了通过部分接触规范实现可引导生成，为抓取合成提供细粒度控制。

Conclusion: 基于接触的具身推理为灵巧抓取生成提供了有效的中间表示，显著提升了抓取性能和意图对齐度。该方法通过物理交互的显式建模，实现了语义任务需求与物理约束的更好结合。

Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.

</details>


### [64] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis](https://arxiv.org/abs/2601.16062)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文分析了SE2(3)李群导航模型的自主性，发现传统方法在考虑地球旋转和惯性器件偏差时难以保持自主性，提出了新的建模方法以接近完全自主。


<details>
  <summary>Details</summary>
Motivation: SE2(3)李群框架在导航建模中的核心优势是误差传播的自主性。当前研究表明，在低精度应用（如不考虑地球旋转和惯性器件偏差的MEMS导航）中，这种自主性能够保持。但在高精度导航状态估计中，考虑地球旋转和惯性器件偏差时，维持自主性变得极其困难。

Method: 1. 对基于SE2(3)群的高精度导航模型在惯性系、地球系和世界系下进行自主性理论分析；2. 发现传统SE2(3)群导航建模方法的局限性在于非惯性系中速度引入的科里奥利力项；3. 提出一种SE2(3)群导航模型的构造方法，使导航模型更接近完全自主。

Result: 通过理论分析发现，传统SE2(3)群导航建模方法存在局限性，特别是在非惯性系中速度引入的科里奥利力项破坏了自主性。提出的新构造方法能够使导航模型更接近完全自主。

Conclusion: 本文揭示了传统SE2(3)群导航模型在高精度应用中的自主性限制，并提出了一种改进的建模方法，为高精度导航状态估计提供了更接近完全自主的理论框架。

Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.

</details>


### [65] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application](https://arxiv.org/abs/2601.16078)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文通过SINS/ODO实验和蒙特卡洛仿真验证了改进的SE2(3)群导航模型的性能，作为前期理论工作的实验补充。


<details>
  <summary>Details</summary>
Motivation: SE2(3)李群框架在导航建模中的核心优势在于误差传播的自主性。前期论文已从理论上分析了惯性、地球和世界坐标系下导航模型的自主性特性，并提出了改进非惯性导航模型实现完全自主性的构造方法。本文作为前期工作的补充，需要通过实际实验验证改进模型的性能。

Method: 1. 采用改进的SE2(3)群高精度导航模型；2. 进行真实世界的SINS/ODO（捷联惯性导航系统/里程计）实验；3. 进行蒙特卡洛仿真分析。

Result: 通过实验和仿真验证了改进的SE2(3)群导航模型的性能表现，具体性能指标需参考论文详细数据。

Conclusion: 本文通过实验验证了改进的SE2(3)群导航模型的有效性，为前期理论分析提供了实验支持，证明了该模型在实际导航应用中的可行性和性能优势。

Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.

</details>


### [66] [Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision](https://arxiv.org/abs/2601.16109)
*Yashuai Yan,Tobias Egle,Christian Ott,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出结合模型控制与残差强化学习的框架，通过模型基策略和特权监督训练，实现双足机器人对现实不确定性的鲁棒自适应行走


<details>
  <summary>Details</summary>
Motivation: 解决双足机器人在现实世界中面临的不确定性挑战，包括不精确的动力学建模和传感器噪声，实现从仿真到现实的可靠迁移

Method: 1) 使用基于DCM轨迹规划和全身控制的模型控制器作为基础策略；2) 通过域随机化的强化学习训练残差策略；3) 引入具有地面真实动力学特权的模型基oracle策略，通过监督损失指导残差策略学习

Result: 该方法在多种随机化条件下表现出改进的鲁棒性和泛化能力，为双足机器人的仿真到现实迁移提供了可扩展的解决方案

Conclusion: 结合模型控制与残差强化学习，通过特权监督训练，能够有效补偿未建模效应，实现双足机器人在现实不确定环境中的鲁棒自适应行走

Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.

</details>


### [67] [IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance](https://arxiv.org/abs/2601.16207)
*Jongwoo Park,Kanchana Ranasinghe,Jinhyeok Jang,Cristina Mata,Yoo Sung Jang,Michael S Ryoo*

Main category: cs.RO

TL;DR: IVRA：一种无需训练、轻量级的方法，通过利用视觉编码器内置的亲和力提示来增强VLA模型的空间理解能力，提升机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将图像块展平为1D序列，削弱了精确操作所需的2D空间线索。需要一种无需重新训练的方法来增强模型的空间理解能力。

Method: IVRA在推理时选择性注入视觉编码器内置的亲和力信号到语言模型层中，重新对齐视觉-标记交互，保持几何结构，所有模型参数固定。

Result: 在2D VIMA基准上，IVRA比基线LLaRA平均成功率提升+4.2%；在3D LIBERO基准上，对OpenVLA和FLOWER基线均有稳定提升，包括在基线准确率接近饱和时（96.3%到97.1%）。

Conclusion: IVRA是一种通用、轻量级、无需训练的方法，能有效增强VLA模型的空间理解能力，在模拟和真实机器人任务中均表现出性能提升。

Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA

</details>


### [68] [Point Bridge: 3D Representations for Cross Domain Policy Learning](https://arxiv.org/abs/2601.16212)
*Siddhant Haldar,Lars Johannsmeier,Lerrel Pinto,Abhishek Gupta,Dieter Fox,Yashraj Narang,Ajay Mandlekar*

Main category: cs.RO

TL;DR: Point Bridge框架通过点云表示实现零样本仿真到现实的策略迁移，无需视觉或物体级对齐，在合成数据训练下实现真实世界操作


<details>
  <summary>Details</summary>
Motivation: 机器人基础模型受限于大规模真实世界操作数据稀缺，仿真和合成数据存在视觉域差距问题，需要一种能有效利用合成数据进行零样本仿真到现实迁移的方法

Method: 使用统一的、领域无关的点云表示，结合视觉语言模型自动提取点云表示、基于Transformer的策略学习，以及高效的推理时管道，仅用合成数据训练真实世界操作智能体

Result: 在零样本仿真到现实迁移中实现高达44%的性能提升，配合少量真实演示数据后提升达66%，在单任务和多任务设置中均优于先前基于视觉的仿真-现实协同训练方法

Conclusion: Point Bridge框架通过点云表示有效解决了仿真到现实的视觉域差距问题，为利用合成数据训练真实世界机器人操作智能体提供了有效途径

Abstract: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/

</details>
