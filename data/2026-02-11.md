<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 63]
- [cs.RO](#cs.RO) [Total: 47]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Overview of PAN 2026: Voight-Kampff Generative AI Detection, Text Watermarking, Multi-Author Writing Style Analysis, Generative Plagiarism Detection, and Reasoning Trajectory Detection](https://arxiv.org/abs/2602.09147)
*Janek Bevendorff,Maik Fröbe,André Greiner-Petter,Andreas Jakoby,Maximilian Mayerl,Preslav Nakov,Henry Plutz,Martin Potthast,Benno Stein,Minh Ngoc Ta,Yuxia Wang,Eva Zangerle*

Main category: cs.CL

TL;DR: PAN 2026研讨会聚焦计算文体学与文本取证，包含五个任务：生成式AI检测、文本水印、多作者风格分析、生成式抄袭检测和推理轨迹检测，延续Docker容器提交传统。


<details>
  <summary>Details</summary>
Motivation: 推动计算文体学和文本取证领域的发展，通过客观可复现的评估方法解决生成式AI时代的新挑战，包括AI生成内容检测、文本水印鲁棒性、多作者分析等问题。

Method: 采用任务导向的评估框架，包含五个具体任务：Voight-Kampff生成式AI检测（特别针对混合和混淆场景）、文本水印鲁棒性评估、多作者写作风格分析、生成式抄袭检测、推理轨迹检测。延续使用Docker容器提交和TIRA实验平台确保可复现性。

Result: 自2012年以来，PAN已通过TIRA平台接收超过1,100份Docker容器提交，建立了成熟的评估体系。2026年新增文本水印和推理轨迹检测两个新任务，反映了生成式AI时代的新需求。

Conclusion: PAN 2026通过五个核心任务继续推动计算文体学和文本取证的发展，特别关注生成式AI带来的新挑战，同时保持了可复现评估的传统，为相关研究提供了标准化的评估框架。

Abstract: The goal of the PAN workshop is to advance computational stylometry and text forensics via objective and reproducible evaluation. In 2026, we run the following five tasks: (1) Voight-Kampff Generative AI Detection, particularly in mixed and obfuscated authorship scenarios, (2) Text Watermarking, a new task that aims to find new and benchmark the robustness of existing text watermarking schemes, (3) Multi-author Writing Style Analysis, a continued task that aims to find positions of authorship change, (4) Generative Plagiarism Detection, a continued task that targets source retrieval and text alignment between generated text and source documents, and (5) Reasoning Trajectory Detection, a new task that deals with source detection and safety detection of LLM-generated or human-written reasoning trajectories. As in previous years, PAN invites software submissions as easy-to-reproduce Docker containers for most of the tasks. Since PAN 2012, more than 1,100 submissions have been made this way via the TIRA experimentation platform.

</details>


### [2] [Measuring Inclusion in Interaction: Inclusion Analytics for Human-AI Collaborative Learning](https://arxiv.org/abs/2602.09269)
*Jaeyoon Choi,Nia Nixon*

Main category: cs.CL

TL;DR: 提出"包容性分析"框架，通过话语分析实时评估人机协作中的动态包容性过程


<details>
  <summary>Details</summary>
Motivation: 当前AI与教育领域的包容性评估多采用粗粒度样本描述或事后自我报告，无法捕捉协作问题解决中实时形成的包容性动态过程

Method: 提出包容性分析框架，从三个维度（参与公平性、情感氛围、认知公平性）构建可扩展的交互级测量指标，使用模拟对话和人机协作实验数据进行验证

Result: 该框架能够揭示传统聚合或事后评估无法发现的参与模式、关系动态和观点采纳模式

Conclusion: 这是向过程导向的人机协作学习环境包容性测量方法迈出的初步步骤

Abstract: Inclusion, equity, and access are widely valued in AI and education, yet are often assessed through coarse sample descriptors or post-hoc self-reports that miss how inclusion is shaped moment by moment in collaborative problem solving (CPS). In this proof-of-concept paper, we introduce inclusion analytics, a discourse-based framework for examining inclusion as a dynamic, interactional process in CPS. We conceptualize inclusion along three complementary dimensions -- participation equity, affective climate, and epistemic equity -- and demonstrate how these constructs can be made analytically visible using scalable, interaction-level measures. Using both simulated conversations and empirical data from human-AI teaming experiments, we illustrate how inclusion analytics can surface patterns of participation, relational dynamics, and idea uptake that remain invisible to aggregate or post-hoc evaluations. This work represents an initial step toward process-oriented approaches to measuring inclusion in human-AI collaborative learning environments.

</details>


### [3] [Effective Reasoning Chains Reduce Intrinsic Dimensionality](https://arxiv.org/abs/2602.09276)
*Archiki Prasad,Mandar Joshi,Kenton Lee,Mohit Bansal,Peter Shaw*

Main category: cs.CL

TL;DR: 本文提出使用内在维度作为量化指标来衡量推理链的有效性，发现有效的推理策略能降低任务的内在维度，从而提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: 虽然思维链推理及其变体显著提升了语言模型在复杂推理任务上的性能，但不同策略促进泛化的具体机制仍不清楚。当前解释多集中于增加测试时计算或提供结构指导，但这些因素与泛化之间的量化关系难以建立。

Method: 提出使用内在维度作为量化指标来表征推理链的有效性。内在维度衡量达到给定任务准确率阈值所需的最小模型维度数。通过固定模型架构，改变任务表述（不同推理策略），分析推理策略对任务内在维度的影响。

Result: 在GSM8K数据集上使用Gemma-3 1B和4B模型验证，发现有效的推理策略能一致地降低任务的内在维度。内在维度与泛化性能（包括分布内和分布外数据）呈强负相关。

Conclusion: 有效的推理链通过更好地压缩任务（使用更少参数）来促进学习，内在维度为分析推理过程提供了新的量化指标。

Abstract: Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as a quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach a given accuracy threshold on a given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies, we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe a strong inverse correlation between the intrinsic dimensionality of a reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering a new quantitative metric for analyzing reasoning processes.

</details>


### [4] [Don't Shoot The Breeze: Topic Continuity Model Using Nonlinear Naive Bayes With Attention](https://arxiv.org/abs/2602.09312)
*Shu-Ting Pi,Pradeep Bagavan,Yejia Li,Disha,Qun Liu*

Main category: cs.CL

TL;DR: 提出基于朴素贝叶斯和注意力机制的主题连续性模型，用于评估LLM聊天机器人回复是否保持话题一致性，具有线性时间复杂度和可解释性。


<details>
  <summary>Details</summary>
Motivation: LLM作为聊天机器人在商业场景中经常出现话题突然转换的问题，导致用户体验差和计算资源浪费，需要评估回复是否保持话题连续性。

Method: 将自然语言理解模型扩展为可量化的朴素贝叶斯方法，引入注意力机制和对数非线性变换来增强捕捉话题连续性的能力，形成可解释的分析公式。

Result: 模型能够处理任意长度的对话且具有线性时间复杂度，注意力机制显著提升了复杂对话中话题连续性的识别能力，实验表明优于传统方法。

Conclusion: 该模型为LLM的责任和可解释使用提供了机会，特别擅长处理长而复杂的对话，确保话题连续性评估。

Abstract: Utilizing Large Language Models (LLM) as chatbots in diverse business scenarios often presents the challenge of maintaining topic continuity. Abrupt shifts in topics can lead to poor user experiences and inefficient utilization of computational resources. In this paper, we present a topic continuity model aimed at assessing whether a response aligns with the initial conversation topic. Our model is built upon the expansion of the corresponding natural language understanding (NLU) model into quantifiable terms using a Naive Bayes approach. Subsequently, we have introduced an attention mechanism and logarithmic nonlinearity to enhance its capability to capture topic continuity. This approach allows us to convert the NLU model into an interpretable analytical formula. In contrast to many NLU models constrained by token limits, our proposed model can seamlessly handle conversations of any length with linear time complexity. Furthermore, the attention mechanism significantly improves the model's ability to identify topic continuity in complex conversations. According to our experiments, our model consistently outperforms traditional methods, particularly in handling lengthy and intricate conversations. This unique capability offers us an opportunity to ensure the responsible and interpretable use of LLMs.

</details>


### [5] [Beyond Uniform Credit: Causal Credit Assignment for Policy Optimization](https://arxiv.org/abs/2602.09331)
*Mykola Khandoga,Rui Yuan,Vinay Kumar Sankarapu*

Main category: cs.CL

TL;DR: 提出反事实重要性加权方法，用于语言模型推理中的策略梯度优化，通过掩码推理片段并测量答案概率下降来调整梯度权重，避免对填充文本和关键计算给予相同权重。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型推理的策略梯度方法（如GRPO和DAPO）对所有生成标记分配统一权重，导致填充短语"让我想想"和关键计算"23 + 45 = 68"获得相同的梯度更新，这显然不合理。

Method: 提出反事实重要性加权：掩码推理片段，测量答案概率下降，根据下降程度在策略梯度更新中相应上调标记权重。该方法无需辅助模型或外部标注，直接从策略模型自身的概率变化估计重要性。

Result: 在GSM8K数据集上对Qwen和Llama家族的三个模型进行实验，相比统一基线方法获得一致改进，更快收敛到相同准确率。反转重要性信号会损害性能，证实方法捕捉了真实的因果结构而非噪声。

Conclusion: 该方法能正确优先处理计算步骤而非脚手架文本，为后续研究建立了反事实重要性加权的基础，但并非完整解决方案。

Abstract: Policy gradient methods for language model reasoning, such as GRPO and DAPO, assign uniform credit to all generated tokens - the filler phrase "Let me think" receives the same gradient update as the critical calculation "23 + 45 = 68." We propose counterfactual importance weighting: mask reasoning spans, measure the drop in answer probability, and upweight tokens accordingly during policy gradient updates. Our method requires no auxiliary models or external annotation, instead importance is estimated directly from the policy model's own probability shifts. Experiments on GSM8K across three models spanning the Qwen and Llama families demonstrate consistent improvements over uniform baselines and faster convergence to equivalent accuracy. Inverting the importance signal hurts performance, confirming we capture genuine causal structure rather than noise. Analysis shows the method correctly prioritizes calculation steps over scaffolding text. We view these findings as establishing counterfactual importance weighting as a foundation for further research rather than a complete solution.

</details>


### [6] [FM SO.P: A Progressive Task Mixture Framework with Automatic Evaluation for Cross-Domain SOP Understanding](https://arxiv.org/abs/2602.09336)
*Siyuan Huang,Ziyu Wang,Chao Pan,Han Zhao*

Main category: cs.CL

TL;DR: FM SO.P：通过渐进式任务混合和自动多智能体评估系统，解决语言模型在标准操作程序理解和跨领域泛化方面的挑战，在SOPBench上超越基线表现。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在标准操作程序理解和跨领域泛化方面表现不佳，因为联合训练无法区分SOP所需的术语精确性、顺序性和约束推理等不同推理能力。

Method: 提出FM SO.P方法：1）渐进式任务混合，通过三个阶段累积数据构建能力：概念消歧、动作序列理解、场景感知图推理；2）自动多智能体评估系统，包含三个智能体自适应生成评估标准、分层测试集和评分。

Result: 在SOPBench的七个领域评估中，32B模型达到48.3%通过率，7B开源模型达到34.3%通过率，与Qwen-2.5-72B-Instruct基线（34.4%）相当，但参数量减少10倍。

Conclusion: FM SO.P通过结构化能力构建和自适应评估，有效解决了SOP理解和跨领域泛化的挑战，在减少参数量的情况下实现了与更大模型相当的性能。

Abstract: Standard Operating Procedures (SOPs) are critical for enterprise operations, yet existing language models struggle with SOP understanding and cross-domain generalization. Current methods fail because joint training cannot differentiate between reasoning capabilities that SOP requires: terminology precision, sequential ordering, and constraint reasoning. We propose FM SO.P, solving these challenges through two novelties. First, we introduce progressive task mixtures that build capabilities by stages across three task types with cumulative data: concept disambiguation for terminology precision, action sequence understanding for procedural correctness, and scenario-aware graph reasoning for conditional logic. Second, we propose an automatic multi-agent evaluation system consisting of three agents that adaptively generate rubrics, stratified test sets, and rubric scoring, adapting to domains (e.g., temporal constraints for DMV, regulatory compliance for banking). Evaluated on SOPBench across seven domains (Bank, DMV, Healthcare, Market, University, Library, Hotel), FM SO.P achieves 48.3\% pass rate with our 32B model and 34.3\% with our opensource 7B model, matching Qwen-2.5-72B-Instruct baseline (34.4\%) with 10x fewer parameters.

</details>


### [7] [Understanding Risk and Dependency in AI Chatbot Use from User Discourse](https://arxiv.org/abs/2602.09339)
*Jianfeng Zhu,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 该研究通过大规模计算主题分析，揭示了AI使用相关的五个心理风险体验维度，其中自我调节困难最为普遍，恐惧主要集中在自主权、控制和技术风险方面。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统日益融入日常生活，但关于AI使用相关心理风险如何产生、被体验以及被用户调节的实证理解仍然有限。研究旨在从真实用户话语中理解AI安全如何被感知和情感体验。

Method: 采用大规模计算主题分析，收集2023-2025年Reddit社区r/AIDangers和r/ChatbotAddiction的帖子。使用基于Braun和Clarke反思框架的多智能体、LLM辅助主题分析方法，识别14个重复主题类别，并综合为五个高阶体验维度。应用基于BERT的情感分类器进行情感标注，可视化各维度的情感特征。

Result: 研究发现五个基于真实用户话语的AI相关心理风险体验维度：自我调节困难最为普遍，恐惧主要集中在自主权、控制和技术风险方面。情感分析显示不同维度具有特定的情感特征。

Conclusion: 研究提供了来自真实用户体验的早期实证证据，展示了在实验室或推测性情境之外，AI安全如何被感知和情感体验。为未来AI安全研究、评估和负责任治理奠定了基础。

Abstract: Generative AI systems are increasingly embedded in everyday life, yet empirical understanding of how psychological risk associated with AI use emerges, is experienced, and is regulated by users remains limited. We present a large-scale computational thematic analysis of posts collected between 2023 and 2025 from two Reddit communities, r/AIDangers and r/ChatbotAddiction, explicitly focused on AI-related harm and distress. Using a multi-agent, LLM-assisted thematic analysis grounded in Braun and Clarke's reflexive framework, we identify 14 recurring thematic categories and synthesize them into five higher-order experiential dimensions. To further characterize affective patterns, we apply emotion labeling using a BERT-based classifier and visualize emotional profiles across dimensions. Our findings reveal five empirically derived experiential dimensions of AI-related psychological risk grounded in real-world user discourse, with self-regulation difficulties emerging as the most prevalent and fear concentrated in concerns related to autonomy, control, and technical risk. These results provide early empirical evidence from lived user experience of how AI safety is perceived and emotionally experienced outside laboratory or speculative contexts, offering a foundation for future AI safety research, evaluation, and responsible governance.

</details>


### [8] [Digital Linguistic Bias in Spanish: Evidence from Lexical Variation in LLMs](https://arxiv.org/abs/2602.09346)
*Yoshifumi Kawasaki*

Main category: cs.CL

TL;DR: 研究评估大语言模型对西班牙语地理词汇变异的掌握程度，发现模型能识别部分区域变体（如西班牙、墨西哥等），但难以区分智利变体，且性能差异与数字资源数量无关。


<details>
  <summary>Details</summary>
Motivation: 西班牙语存在显著区域变异，需要评估大语言模型是否准确捕捉这些地理词汇差异，以理解模型中的方言知识和数字语言偏见。

Method: 将LLMs视为虚拟信息提供者，使用专家策划的西班牙语词汇变异数据库，通过是非题和选择题两种调查形式，评估21个西班牙语国家的900多个词汇项目。

Result: 模型对西班牙、赤道几内亚、墨西哥及中美洲、拉普拉塔河地区的词汇变异识别更准确，智利变体最难区分；性能模式与国家数字资源数量无关。

Conclusion: 大语言模型对西班牙语方言的表征存在系统性差异，数据量以外的因素影响方言表示；研究为理解LLMs中的方言知识和西班牙语数字语言偏见提供了新证据。

Abstract: This study examines the extent to which Large Language Models (LLMs) capture geographic lexical variation in Spanish, a language that exhibits substantial regional variation. Treating LLMs as virtual informants, we probe their dialectal knowledge using two survey-style question formats: Yes-No questions and multiple-choice questions. To this end, we exploited a large-scale, expert-curated database of Spanish lexical variation. Our evaluation covers more than 900 lexical items across 21 Spanish-speaking countries and is conducted at both the country and dialectal area levels. Across both evaluation formats, the results reveal systematic differences in how LLMs represent Spanish language varieties. Lexical variation associated with Spain, Equatorial Guinea, Mexico & Central America, and the La Plata River is recognized more accurately by the models, while the Chilean variety proves particularly difficult for the models to distinguish. Importantly, differences in the volume of country-level digital resources do not account for these performance patterns, suggesting that factors beyond data quantity shape dialectal representation in LLMs. By providing a fine-grained, large-scale evaluation of geographic lexical variation, this work advances empirical understanding of dialectal knowledge in LLMs and contributes new evidence to discussions of Digital Linguistic Bias in Spanish.

</details>


### [9] [Unsupervised Cross-Lingual Part-of-Speech Tagging with Monolingual Corpora Only](https://arxiv.org/abs/2602.09366)
*Jianyu Zheng*

Main category: cs.CL

TL;DR: 提出完全无监督的跨语言词性标注框架，仅使用单语语料库，通过无监督神经机器翻译构建伪平行句对，无需平行语料库


<details>
  <summary>Details</summary>
Motivation: 低资源语言的词性标注通常依赖平行语料库进行标签投影，但许多低资源语言缺乏平行语料库，限制了现有方法的适用性

Method: 1) 使用无监督神经机器翻译系统将高资源语言句子翻译成低资源语言，构建伪平行句对；2) 基于词对齐进行标准标签投影训练目标语言词性标注器；3) 提出多源投影技术校准目标端投影标签

Result: 在28个语言对（4个源语言，7个目标语言）上评估，性能可与需要平行语料库的基线方法媲美，某些语言甚至超越；多源投影技术带来平均1.3%的性能提升

Conclusion: 提出的完全无监督框架仅需单语语料库即可实现有效的跨语言词性标注，解决了低资源语言缺乏平行语料库的问题，多源投影技术进一步提升了性能

Abstract: Due to the scarcity of part-of-speech annotated data, existing studies on low-resource languages typically adopt unsupervised approaches for POS tagging. Among these, POS tag projection with word alignment method transfers POS tags from a high-resource source language to a low-resource target language based on parallel corpora, making it particularly suitable for low-resource language settings. However, this approach relies heavily on parallel corpora, which are often unavailable for many low-resource languages. To overcome this limitation, we propose a fully unsupervised cross-lingual part-of-speech(POS) tagging framework that relies solely on monolingual corpora by leveraging unsupervised neural machine translation(UNMT) system. This UNMT system first translates sentences from a high-resource language into a low-resource one, thereby constructing pseudo-parallel sentence pairs. Then, we train a POS tagger for the target language following the standard projection procedure based on word alignments. Moreover, we propose a multi-source projection technique to calibrate the projected POS tags on the target side, enhancing to train a more effective POS tagger. We evaluate our framework on 28 language pairs, covering four source languages (English, German, Spanish and French) and seven target languages (Afrikaans, Basque, Finnis, Indonesian, Lithuanian, Portuguese and Turkish). Experimental results show that our method can achieve performance comparable to the baseline cross-lingual POS tagger with parallel sentence pairs, and even exceeds it for certain target languages. Furthermore, our proposed multi-source projection technique further boosts performance, yielding an average improvement of 1.3% over previous methods.

</details>


### [10] [AgentSkiller: Scaling Generalist Agent Intelligence through Semantically Integrated Cross-Domain Data Synthesis](https://arxiv.org/abs/2602.09372)
*Zexu Sun,Bokai Ji,Hengyi Cai,Shuaiqiang Wang,Lei Wang,Guangxia Li,Xu Chen*

Main category: cs.CL

TL;DR: AgentSkiller是一个自动化框架，通过DAG架构和跨领域融合机制合成多轮交互数据，解决高质量长视野数据稀缺问题，显著提升模型在函数调用方面的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理在解决现实世界问题方面展现出潜力，但通用智能受到高质量、长视野数据稀缺的限制。现有方法收集隐私受限的API日志或生成缺乏多样性的脚本交互，难以产生扩展能力所需的数据。

Method: 提出AgentSkiller框架，采用DAG架构确保确定性和可恢复性。构建领域本体和人物中心实体图，通过服务蓝图定义工具接口，填充环境数据库和严格领域策略。跨领域融合机制链接服务模拟复杂任务，通过验证解决方案路径、执行验证过滤和基于人物的模拟器生成查询来自动化部署。

Result: 合成了约11K个交互样本，实验结果表明，在此数据集上训练的模型在函数调用方面相比基线有显著改进，特别是在更大参数规模下表现更佳。

Conclusion: AgentSkiller能够自动合成高质量的多轮交互数据，有效解决数据稀缺问题，显著提升语言模型代理在工具使用和复杂任务解决方面的能力。

Abstract: Large Language Model agents demonstrate potential in solving real-world problems via tools, yet generalist intelligence is bottlenecked by scarce high-quality, long-horizon data. Existing methods collect privacy-constrained API logs or generate scripted interactions lacking diversity, which struggle to produce data requisite for scaling capabilities. We propose AgentSkiller, a fully automated framework synthesizing multi-turn interaction data across realistic, semantically linked domains. It employs a DAG-based architecture with explicit state transitions to ensure determinism and recoverability. The pipeline builds a domain ontology and Person-Centric Entity Graph, defines tool interfaces via Service Blueprints for Model Context Protocol servers, and populates environments with consistent databases and strict Domain Policies. A cross-domain fusion mechanism links services to simulate complex tasks. Finally, the pipeline creates user tasks by verifying solution paths, filtering via execution-based validation, and generating queries using a Persona-based Simulator for automated rollout. This produces reliable environments with clear state changes. To demonstrate effectiveness, we synthesized $\approx$ 11K interaction samples; experimental results indicate that models trained on this dataset achieve significant improvements on function calling over baselines, particularly in larger parameter regimes.

</details>


### [11] [AfriNLLB: Efficient Translation Models for African Languages](https://arxiv.org/abs/2602.09373)
*Yasmin Moslem,Aman Kassahun Wassie,Amanuel Gizachew Abebe*

Main category: cs.CL

TL;DR: AfriNLLB是一系列轻量级模型，支持15种非洲语言对（30个翻译方向），通过层剪枝和量化压缩NLLB-200 600M模型，在资源受限环境下实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 旨在为非洲语言提供高效的翻译模型，解决资源受限环境下的部署问题，支持包括斯瓦希里语、豪萨语、约鲁巴语等15种语言对。

Method: 基于NLLB-200 600M模型，采用迭代层剪枝和量化进行压缩，在精心策划的非洲语言平行语料库上进行微调，并使用知识蒸馏从更大的教师模型学习。

Result: AfriNLLB模型在保持与基线相当性能的同时显著提升了推理速度，发布了Transformers版本（支持进一步微调）和CTranslate2版本（高效推理）。

Conclusion: 成功开发了适用于非洲语言的高效轻量级翻译模型，释放了所有训练数据和模型以促进进一步研究，为资源受限环境下的多语言翻译提供了实用解决方案。

Abstract: In this work, we present AfriNLLB, a series of lightweight models for efficient translation from and into African languages. AfriNLLB supports 15 language pairs (30 translation directions), including Swahili, Hausa, Yoruba, Amharic, Somali, Zulu, Lingala, Afrikaans, Wolof, and Egyptian Arabic, as well as other African Union official languages such as Arabic (MSA), French, Portuguese, and Spanish. Our training data covers bidirectional translation between English and 13 languages, and between French and two languages (Lingala and Wolof).
  AfriNLLB models are based on NLLB-200 600M, which we compress using iterative layer pruning and quantization. We fine-tune the pruned models on parallel corpora we curated for African languages, employing knowledge distillation from a larger teacher model. Our work aims at enabling efficient deployment of translation models for African languages in resource-constrained settings.
  Our evaluation results demonstrate that AfriNLLB models achieve performance comparable to the baseline while being significantly faster. We release two versions of the AfriNLLB models, a Transformers version that allows further fine-tuning and a CTranslate2 version for efficient inference. Moreover, we release all the training data that we used for fine-tuning the baseline and pruned models to facilitate further research.

</details>


### [12] [BiasScope: Towards Automated Detection of Bias in LLM-as-a-Judge Evaluation](https://arxiv.org/abs/2602.09383)
*Peng Lai,Zhihao Ou,Yong Wang,Longyue Wang,Jian Yang,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: BiasScope：一个自动发现LLM评估中潜在偏见的框架，并基于此创建了更具挑战性的JudgeBench-Pro基准


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-Judge评估的鲁棒性和可靠性存在关键问题，现有研究主要关注已知偏见，缺乏对潜在未知偏见的自动系统探索

Method: 提出BiasScope框架，使用LLM驱动的方法自动、大规模地发现模型评估中可能出现的偏见，克服了依赖人工和预定义偏见列表的局限性

Result: BiasScope能够跨不同模型家族和规模发现潜在偏见，在JudgeBench数据集上验证了其通用性和有效性；基于此创建的JudgeBench-Pro基准显示，即使强大的LLM评估器错误率也超过50%

Conclusion: BiasScope将偏见发现从被动过程转变为主动全面的自动探索，揭示了LLM评估中存在的严重鲁棒性问题，强调了加强评估鲁棒性和减轻潜在偏见的紧迫性

Abstract: LLM-as-a-Judge has been widely adopted across various research and practical applications, yet the robustness and reliability of its evaluation remain a critical issue. A core challenge it faces is bias, which has primarily been studied in terms of known biases and their impact on evaluation outcomes, while automated and systematic exploration of potential unknown biases is still lacking. Nevertheless, such exploration is crucial for enhancing the robustness and reliability of evaluations. To bridge this gap, we propose BiasScope, a LLM-driven framework for automatically and at scale discovering potential biases that may arise during model evaluation. BiasScope can uncover potential biases across different model families and scales, with its generality and effectiveness validated on the JudgeBench dataset. It overcomes the limitations of existing approaches, transforming bias discovery from a passive process relying on manual effort and predefined bias lists into an active and comprehensive automated exploration. Moreover, based on BiasScope, we propose JudgeBench-Pro, an extended version of JudgeBench and a more challenging benchmark for evaluating the robustness of LLM-as-a-judge. Strikingly, even powerful LLMs as evaluators show error rates above 50\% on JudgeBench-Pro, underscoring the urgent need to strengthen evaluation robustness and to mitigate potential biases further.

</details>


### [13] [Contractual Deepfakes: Can Large Language Models Generate Contracts?](https://arxiv.org/abs/2602.09384)
*Eliza Mik*

Main category: cs.CL

TL;DR: 论文批判性地分析LLM在合同起草中的局限性，认为其无法真正理解法律语言和推理，生成的合同可能表面合理但实际无效或不适用。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在文本生成方面表现出色，但法律界存在一种过度乐观的观点，认为LLM可以协助合同起草等法律任务。作者旨在纠正这种误解，指出LLM缺乏对语言意义、上下文和法律推理的真正理解。

Method: 通过理论分析，对比LLM的统计模式预测能力与法律实践中需要的语言理解、情境分析和法律推理能力。论证LLM生成合同文档的局限性。

Result: LLM只能生成表面合理的一般性合同文件，但这些文件可能是内部条款不一致的无用组合，或者是虽然可执行但不适合特定交易的合同。预测词语与在法律情境中使用语言有本质区别。

Conclusion: LLM并不威胁法律行业的持续生存能力。简单的假设需要重新审视，法律实践需要真正的语言理解、情境分析和法律推理能力，而不仅仅是统计模式匹配。

Abstract: Notwithstanding their unprecedented ability to generate text, LLMs do not understand the meaning of words, have no sense of context and cannot reason. Their output constitutes an approximation of statistically dominant word patterns. And yet, the drafting of contracts is often presented as a typical legal task that could be facilitated by this technology. This paper seeks to put an end to such unreasonable ideas. Predicting words differs from using language in the circumstances of specific transactions and reconstituting common contractual phrases differs from reasoning about the law. LLMs seem to be able to generate generic and superficially plausible contractual documents. In the cold light of day, such documents may turn out to be useless assemblages of inconsistent provisions or contracts that are enforceable but unsuitable for a given transaction. This paper casts a shadow on the simplistic assumption that LLMs threaten the continued viability of the legal industry.

</details>


### [14] [Effective vocabulary expanding of multilingual language models for extremely low-resource languages](https://arxiv.org/abs/2602.09388)
*Jianyu Zheng*

Main category: cs.CL

TL;DR: 提出一种扩展多语言预训练模型到新低资源语言的方法，通过词汇扩展和双语词典初始化，在POS标注和NER任务上优于基线


<details>
  <summary>Details</summary>
Motivation: 现有的多语言预训练模型(mPLMs)虽然对许多低资源语言有益，但很少有工作研究如何将mPLMs扩展到之前不支持的低资源语言。当前方法主要关注已有语言的继续预训练，而缺乏扩展到新语言的有效方案。

Method: 1) 使用目标语言语料库扩展模型词汇表；2) 筛选出偏向源语言（如英语）的原始词汇子集；3) 利用双语词典初始化扩展词汇的表示；4) 基于扩展词汇表示，使用目标语言语料库继续预训练mPLMs。

Result: 在POS标注和NER任务上，该方法优于使用随机初始化扩展词汇的基线方法，分别提升0.54%和2.60%。同时，方法对训练语料选择具有高鲁棒性，且继续预训练后模型在源语言上的性能不会下降。

Conclusion: 提出的词汇扩展和双语词典初始化方法能有效将多语言预训练模型扩展到新的低资源语言，在保持源语言性能的同时，显著提升目标语言的下游任务表现。

Abstract: Multilingual pre-trained language models(mPLMs) offer significant benefits for many low-resource languages. To further expand the range of languages these models can support, many works focus on continued pre-training of these models. However, few works address how to extend mPLMs to low-resource languages that were previously unsupported. To tackle this issue, we expand the model's vocabulary using a target language corpus. We then screen out a subset from the model's original vocabulary, which is biased towards representing the source language(e.g. English), and utilize bilingual dictionaries to initialize the representations of the expanded vocabulary. Subsequently, we continue to pre-train the mPLMs using the target language corpus, based on the representations of these expanded vocabulary. Experimental results show that our proposed method outperforms the baseline, which uses randomly initialized expanded vocabulary for continued pre-training, in POS tagging and NER tasks, achieving improvements by 0.54% and 2.60%, respectively. Furthermore, our method demonstrates high robustness in selecting the training corpora, and the models' performance on the source language does not degrade after continued pre-training.

</details>


### [15] [Are Language Models Sensitive to Morally Irrelevant Distractors?](https://arxiv.org/abs/2602.09416)
*Andrew Shaw,Christina Hahn,Catherine Rasgaitis,Yash Mishra,Alisa Liu,Natasha Jaques,Yulia Tsvetkov,Amy X. Zhang*

Main category: cs.CL

TL;DR: 研究发现LLMs的道德判断会受到无关情境因素（道德干扰物）的显著影响，类似于人类道德心理学中的情境主义现象，挑战了LLMs具有稳定道德偏好的假设。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在高风险场景中的广泛应用，确保其行为符合人类价值观变得至关重要。现有道德基准假设LLMs具有相对稳定的道德偏好，但人类道德心理学研究表明人类道德判断会受到无关情境因素的影响，因此需要探究LLMs是否也存在类似的认知道德偏差。

Method: 从现有心理学数据集中收集了60个"道德干扰物"（情感性图像和叙事），这些干扰物与道德情境本身无关。将这些干扰物注入现有的道德基准中，测量它们对LLM回答的影响。

Result: 研究发现道德干扰物可以显著改变LLMs的道德判断，即使在低模糊性情境下也能使道德判断偏移超过30%，表明LLMs的道德判断具有情境敏感性。

Conclusion: LLMs表现出与人类相似的认知道德偏差，挑战了LLMs具有稳定道德偏好的假设。这强调了需要进行更情境化的道德评估，以及对LLMs更细致的认知道德建模。

Abstract: With the rapid development and uptake of large language models (LLMs) across high-stakes settings, it is increasingly important to ensure that LLMs behave in ways that align with human values. Existing moral benchmarks prompt LLMs with value statements, moral scenarios, or psychological questionnaires, with the implicit underlying assumption that LLMs report somewhat stable moral preferences. However, moral psychology research has shown that human moral judgements are sensitive to morally irrelevant situational factors, such as smelling cinnamon rolls or the level of ambient noise, thereby challenging moral theories that assume the stability of human moral judgements. Here, we draw inspiration from this "situationist" view of moral psychology to evaluate whether LLMs exhibit similar cognitive moral biases to humans. We curate a novel multimodal dataset of 60 "moral distractors" from existing psychological datasets of emotionally-valenced images and narratives which have no moral relevance to the situation presented. After injecting these distractors into existing moral benchmarks to measure their effects on LLM responses, we find that moral distractors can shift the moral judgements of LLMs by over 30% even in low-ambiguity scenarios, highlighting the need for more contextual moral evaluations and more nuanced cognitive moral modeling of LLMs.

</details>


### [16] [Breaking the Pre-Sampling Barrier: Activation-Informed Difficulty-Aware Self-Consistency](https://arxiv.org/abs/2602.09438)
*Taewoong Yoon,Geunyeong Jeong,Geon Park,Sihyeong Yeom,Harksoo Kim*

Main category: cs.CL

TL;DR: ACTSC：利用前馈网络神经元激活中的内部难度信号构建轻量级难度估计探针，动态调整自洽性采样数量，无需额外token生成或模型调用，有效降低推理成本


<details>
  <summary>Details</summary>
Motivation: 自洽性（SC）通过生成多个推理路径和多数投票提升LLM推理性能，但需要大量样本导致推理成本高。现有的难度自适应自洽性（DSC）需要额外的模型调用和预采样来估计难度，计算开销大且需要为每个数据集重复此过程。

Method: ACTSC利用前馈网络神经元激活中反映的内部难度信号，构建轻量级难度估计探针。该探针动态调整SC的样本数量，无需额外token生成或模型调用，且可应用于新数据集而无需进行难度估计的预采样。

Result: 在五个基准测试上的实验结果表明，ACTSC在保持相对于现有方法准确性的同时，有效降低了推理成本。

Conclusion: ACTSC通过利用LLM内部激活信号进行难度估计，提供了一种高效的自洽性采样策略，显著降低了推理成本且无需额外计算开销，为LLM推理优化提供了新思路。

Abstract: Self-Consistency (SC) is an effective decoding strategy that improves the reasoning performance of Large Language Models (LLMs) by generating multiple chain-of-thought reasoning paths and selecting the final answer via majority voting. However, it suffers from substantial inference costs because it requires a large number of samples. To mitigate this issue, Difficulty-Adaptive Self-Consistency (DSC) was proposed to reduce unnecessary token usage for easy problems by adjusting the number of samples according to problem difficulty. However, DSC requires additional model calls and pre-sampling to estimate difficulty, and this process is repeated when applying to each dataset, leading to significant computational overhead. In this work, we propose Activation-Informed Difficulty-Aware Self-Consistency (ACTSC) to address these limitations. ACTSC leverages internal difficulty signals reflected in the feed-forward network neuron activations to construct a lightweight difficulty estimation probe, without any additional token generation or model calls. The probe dynamically adjusts the number of samples for SC and can be applied to new datasets without requiring pre-sampling for difficulty estimation. To validate its effectiveness, we conduct experiments on five benchmarks. Experimental results show that ACTSC effectively reduces inference costs while maintaining accuracy relative to existing methods.

</details>


### [17] [Evaluating Social Bias in RAG Systems: When External Context Helps and Reasoning Hurts](https://arxiv.org/abs/2602.09442)
*Shweta Parihar,Lu Cheng*

Main category: cs.CL

TL;DR: RAG架构通过引入外部知识能减少LLM的社会偏见，但CoT提示会增强偏见，需要平衡准确性与公平性的框架


<details>
  <summary>Details</summary>
Motivation: 研究RAG架构中的社会偏见问题，尽管RAG通过检索外部知识增强LLM能力，但仍存在偏见风险，需要评估和理解其偏见影响

Method: 通过大规模实验评估不同检索语料库、LLM和偏见数据集（涵盖13种偏见类型），并整合CoT提示分析模型推理过程

Result: 意外发现RAG能减少偏见，外部上下文可对抗刻板印象预测；但CoT虽提高准确性却增加整体偏见，显示准确性与公平性的权衡

Conclusion: RAG通过多样化上下文可改善公平性，但需要开发偏见感知的推理框架来平衡CoT带来的准确性提升与偏见增加之间的矛盾

Abstract: Social biases inherent in large language models (LLMs) raise significant fairness concerns. Retrieval-Augmented Generation (RAG) architectures, which retrieve external knowledge sources to enhance the generative capabilities of LLMs, remain susceptible to the same bias-related challenges. This work focuses on evaluating and understanding the social bias implications of RAG. Through extensive experiments across various retrieval corpora, LLMs, and bias evaluation datasets, encompassing more than 13 different bias types, we surprisingly observe a reduction in bias in RAG. This suggests that the inclusion of external context can help counteract stereotype-driven predictions, potentially improving fairness by diversifying the contextual grounding of the model's outputs. To better understand this phenomenon, we then explore the model's reasoning process by integrating Chain-of-Thought (CoT) prompting into RAG while assessing the faithfulness of the model's CoT. Our experiments reveal that the model's bias inclinations shift between stereotype and anti-stereotype responses as more contextual information is incorporated from the retrieved documents. Interestingly, we find that while CoT enhances accuracy, contrary to the bias reduction observed with RAG, it increases overall bias across datasets, highlighting the need for bias-aware reasoning frameworks that can mitigate this trade-off.

</details>


### [18] [Conceptual Cultural Index: A Metric for Cultural Specificity via Relative Generality](https://arxiv.org/abs/2602.09444)
*Takumi Ohashi,Hitoshi Iyatomi*

Main category: cs.CL

TL;DR: 提出概念文化指数(CCI)，用于在句子层面量化文化特异性，通过比较目标文化与其他文化的泛化性估计来计算，在文化特定句子的识别上优于直接LLM评分。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多文化环境中的部署日益增多，但句子层面的文化特异性系统评估仍然不足。需要一种可操作、可解释的方法来量化句子中的文化特定性。

Method: 提出概念文化指数(CCI)：定义为目标文化内的泛化性估计与其他文化平均泛化性估计之间的差异。用户可以通过比较设置操作性地控制文化范围，分数源自底层泛化性估计，提供可解释性。

Result: 在400个句子（200个文化特定句和200个通用句）上验证CCI，分数分布呈现预期模式：文化特定句得分更高，通用句得分更低。在二元可分性方面，CCI优于直接LLM评分，对目标文化专门化模型带来超过10个点的AUC提升。

Conclusion: CCI是一种有效的句子层面文化特异性量化方法，提供可操作的文化范围控制和可解释的评分，在识别文化特定内容方面优于现有方法。

Abstract: Large language models (LLMs) are increasingly deployed in multicultural settings; however, systematic evaluation of cultural specificity at the sentence level remains underexplored. We propose the Conceptual Cultural Index (CCI), which estimates cultural specificity at the sentence level. CCI is defined as the difference between the generality estimate within the target culture and the average generality estimate across other cultures. This formulation enables users to operationally control the scope of culture via comparison settings and provides interpretability, since the score derives from the underlying generality estimates. We validate CCI on 400 sentences (200 culture-specific and 200 general), and the resulting score distribution exhibits the anticipated pattern: higher for culture-specific sentences and lower for general ones. For binary separability, CCI outperforms direct LLM scoring, yielding more than a 10-point improvement in AUC for models specialized to the target culture. Our code is available at https://github.com/IyatomiLab/CCI .

</details>


### [19] [NOWJ @BioCreative IX ToxHabits: An Ensemble Deep Learning Approach for Detecting Substance Use and Contextual Information in Clinical Texts](https://arxiv.org/abs/2602.09469)
*Huu-Huy-Hoang Tran,Gia-Bao Duong,Quoc-Viet-Anh Tran,Thi-Hai-Yen Vuong,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: 提出NOWJ系统参加BioCreative IX的ToxHabits共享任务，用于从西班牙临床文本中提取药物使用信息，采用多输出集成方法，在触发检测和参数检测上取得高精度表现


<details>
  <summary>Details</summary>
Motivation: 从非结构化电子健康记录中提取药物使用信息是临床自然语言处理的主要挑战。虽然大语言模型有进步，但在临床NLP中应用受到信任、控制和效率问题的限制。需要针对西班牙临床文本这一特定领域、低资源环境开发解决方案

Method: 提出多输出集成系统，整合BETO模型与CRF层进行序列标注，采用多样化训练策略，使用句子过滤技术提升精度，同时处理ToxNER和ToxUse两个子任务

Result: 最佳运行在触发检测上获得0.94 F1和0.97精度，在参数检测上获得0.91 F1分数，表现出色

Conclusion: 提出的NOWJ系统在ToxHabits共享任务中有效解决了西班牙临床文本中有毒物质使用信息的提取问题，展示了在低资源临床NLP任务中的实用性和高效性

Abstract: Extracting drug use information from unstructured Electronic Health Records remains a major challenge in clinical Natural Language Processing. While Large Language Models demonstrate advancements, their use in clinical NLP is limited by concerns over trust, control, and efficiency. To address this, we present NOWJ submission to the ToxHabits Shared Task at BioCreative IX. This task targets the detection of toxic substance use and contextual attributes in Spanish clinical texts, a domain-specific, low-resource setting. We propose a multi-output ensemble system tackling both Subtask 1 - ToxNER and Subtask 2 - ToxUse. Our system integrates BETO with a CRF layer for sequence labeling, employs diverse training strategies, and uses sentence filtering to boost precision. Our top run achieved 0.94 F1 and 0.97 precision for Trigger Detection, and 0.91 F1 for Argument Detection.

</details>


### [20] [Listen to the Layers: Mitigating Hallucinations with Inter-Layer Disagreement](https://arxiv.org/abs/2602.09486)
*Koduvayur Subbalakshmi,Sabbir Hossain Ujjal,Venkata Krishna Teja Mangichetty,Nastaran Jamalipour Soofi*

Main category: cs.CL

TL;DR: CoCoA是一种无需训练的推理时解码算法，通过分析LLM中间层的表征不稳定性来检测和减少幻觉，提高生成文本的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易产生流畅但事实错误的文本（幻觉），这降低了其在下游任务中的可靠性和实用性。作者假设生成文本的事实性与其在模型内部各层的表征稳定性相关。

Method: 提出CoCoA解码器，使用两种指标量化中间层的表征不稳定性，并利用这种不稳定性来惩罚高内部混乱的输出。还提出自信息门控变体CoCoA-SIG，动态调节惩罚以选择性针对高惊奇度、不稳定的生成。

Result: 在问答、摘要和代码生成等多种任务上的广泛实验表明，CoCoA显著提高了多个模型家族（如Llama-3、Qwen-2.5、Mistral）的事实正确性。

Conclusion: 通过利用模型内在信号，CoCoA提供了一种有效且广泛适用的方法，可以在无需模型重新训练的情况下，在推理时增强LLM的可信度。

Abstract: Pretrained Large Language Models (LLMs) are prone to generating fluent yet factually incorrect text-a phenomenon known as hallucinations, undermining their reliability and utility in downstream tasks. We hypothesize that a generated text span's factuality is correlated with its representational instability across the model's internal layers. Based on this, we propose the CoCoA (Confusion and Consistency Aware) decoder, a novel, training-free decoding algorithm that mitigates hallucinations at inference time by listening to these signals in the middle layers. We propose two metrics to quantify this instability in the middle layers, and use it to penalize outputs that exhibit high internal confusion, thereby steering the model towards more internally consistent and factually grounded outputs. We further propose a self-information gated variant, CoCoA-SIG, that dynamically modulates this penalty to selectively target high-surprise, unstable generations. Extensive experiments on diverse tasks, including question-answering, summarization and code generation demonstrate that CoCoA significantly improves factual correctness across multiple model families (e.g., Llama-3, Qwen-2.5, Mistral). By leveraging model-intrinsic signals, CoCoA offers an effective and broadly applicable method for enhancing the trustworthiness of LLMs at inference time, without requiring any model retraining.

</details>


### [21] [Where-to-Unmask: Ground-Truth-Guided Unmasking Order Learning for Masked Diffusion Language Models](https://arxiv.org/abs/2602.09501)
*Hikaru Asano,Tadashi Kozuno,Kuniaki Saito,Yukino Baba*

Main category: cs.CL

TL;DR: 提出Gt-Margin方法，通过真实token的概率差值确定最优解掩码顺序，并训练监督式解掩码规划器来模仿这个顺序，提升MDLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统MDLM在推理时依赖启发式置信度或强化学习来确定解掩码顺序，这些方法成本高且效果有限。需要一种更有效的方法来优化"where-to-unmask"决策。

Method: 1. 提出Gt-Margin：基于真实token与其最强替代token的概率差值，构建oracle解掩码顺序；2. 训练监督式解掩码规划器，通过learning-to-rank模仿oracle顺序；3. 将规划器集成到标准MDLM采样中指导解掩码位置选择。

Result: Gt-Margin提供的oracle解掩码顺序显著提升了最终生成质量，特别是在逻辑推理基准测试中。训练的解掩码规划器在不修改token预测模型的情况下提高了推理准确性。

Conclusion: 通过Gt-Margin获得的oracle解掩码顺序是有效的，监督式解掩码规划器能够有效模仿这一顺序，为MDLM提供更好的"where-to-unmask"决策，提升推理性能。

Abstract: Masked Diffusion Language Models (MDLMs) generate text by iteratively filling masked tokens, requiring two coupled decisions at each step: which positions to unmask (where-to-unmask) and which tokens to place (what-to-unmask). While standard MDLM training directly optimizes token prediction (what-to-unmask), inference-time unmasking orders (where-to-unmask) are typically determined by heuristic confidence measures or trained through reinforcement learning with costly on-policy rollouts. To address this, we introduce Gt-Margin, a position-wise score derived from ground-truth tokens, defined as the probability margin between the correct token and its strongest alternative. Gt-Margin yields an oracle unmasking order that prioritizes easier positions first under each partially masked state. We demonstrate that leveraging this oracle unmasking order significantly enhances final generation quality, particularly on logical reasoning benchmarks. Building on this insight, we train a supervised unmasking planner via learning-to-rank to imitate the oracle ordering from masked contexts. The resulting planner integrates into standard MDLM sampling to select where-to-unmask, improving reasoning accuracy without modifying the token prediction model.

</details>


### [22] [EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies](https://arxiv.org/abs/2602.09514)
*Xavier Hu,Jinxiang Xia,Shengze Xu,Kangqi Song,Yishuo Yuan,Guibin Zhang,Jincheng Ren,Boyu Feng,Li Lu,Tieyong Zeng,Jiaheng Liu,Minghao Liu,Yuchen Elenor Jiang,Wei Wang,He Zhu,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: EcoGym是一个用于评估LLM智能体长期规划和执行能力的基准测试，包含三个经济环境，通过1000+步的连续决策过程测试智能体的战略一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体评估框架存在局限性：大多是片段式的、领域特定的，或者缺乏持续经济动态的坚实基础。需要建立一个通用的、可扩展的基准来评估智能体在交互经济环境中的长期规划能力。

Method: 开发了EcoGym基准，包含三个多样化环境（Vending、Freelance、Operation），采用统一的决策过程接口，在部分可观测和随机性条件下进行1000+步的连续决策评估，关注商业相关指标如净资产、收入和日活跃用户。

Result: 对11个领先LLM的实验显示：没有单一模型在所有三个场景中都表现最优，模型在高层战略或高效执行方面存在显著次优性，暴露了系统性的能力差异。

Conclusion: EcoGym作为开源可扩展的测试平台，为透明评估长期规划智能体和研究现实经济环境中可控性与效用之间的权衡提供了工具，揭示了当前LLM在长期经济决策中的局限性。

Abstract: Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics. We introduce EcoGym, a generalizable benchmark for continuous plan-and-execute decision making in interactive economies. EcoGym comprises three diverse environments: Vending, Freelance, and Operation, implemented in a unified decision-making process with standardized interfaces, and budgeted actions over an effectively unbounded horizon (1000+ steps if 365 day-loops for evaluation). The evaluation of EcoGym is based on business-relevant outcomes (e.g., net worth, income, and DAU), targeting long-term strategic coherence and robustness under partial observability and stochasticity. Experiments across eleven leading LLMs expose a systematic tension: no single model dominates across all three scenarios. Critically, we find that models exhibit significant suboptimality in either high-level strategies or efficient actions executions. EcoGym is released as an open, extensible testbed for transparent long-horizon agent evaluation and for studying controllability-utility trade-offs in realistic economic settings.

</details>


### [23] [The CLEF-2026 CheckThat! Lab: Advancing Multilingual Fact-Checking](https://arxiv.org/abs/2602.09516)
*Julia Maria Struß,Sebastian Schellhammer,Stefan Dietze,Venktesh V,Vinay Setty,Tanmoy Chakraborty,Preslav Nakov,Avishek Anand,Primakov Chungkham,Salim Hafid,Dhruv Sahnan,Konstantin Todorov*

Main category: cs.CL

TL;DR: CheckThat! 2026实验室专注于验证流程任务：科学网络声明的来源检索、数值和时间声明的核查、以及完整核查文章生成


<details>
  <summary>Details</summary>
Motivation: 该实验室旨在开发创新技术，对抗多种语言和平台上的虚假信息和操纵行为。早期版本关注验证流程的核心任务，而今年重新聚焦验证流程，并增加推理和生成等新维度。

Method: 通过三个具体任务构建验证流程：任务1（科学网络声明的来源检索）、任务2（数值和时间声明的核查，增加推理组件）、任务3（生成完整的事实核查文章）。这些任务涉及分类、检索和生成挑战。

Result: 实验室设计了三个具有挑战性的任务，涵盖文档和片段级别的多语言设置，为验证技术开发提供了全面的测试平台。

Conclusion: CheckThat! 2026实验室通过聚焦验证流程的三个关键任务，为开发对抗虚假信息的技术提供了重要平台，特别强调了科学声明、数值推理和完整核查文章的生成能力。

Abstract: The CheckThat! lab aims to advance the development of innovative technologies combating disinformation and manipulation efforts in online communication across a multitude of languages and platforms. While in early editions the focus has been on core tasks of the verification pipeline (check-worthiness, evidence retrieval, and verification), in the past three editions, the lab added additional tasks linked to the verification process. In this year's edition, the verification pipeline is at the center again with the following tasks: Task 1 on source retrieval for scientific web claims (a follow-up of the 2025 edition), Task 2 on fact-checking numerical and temporal claims, which adds a reasoning component to the 2025 edition, and Task 3, which expands the verification pipeline with generation of full-fact-checking articles. These tasks represent challenging classification and retrieval problems as well as generation challenges at the document and span level, including multilingual settings.

</details>


### [24] [Knowledge Integration Decay in Search-Augmented Reasoning of Large Language Models](https://arxiv.org/abs/2602.09517)
*Sangwon Yu,Ik-hwan Kim,Donghun Kang,Bongkyu Hwang,Junhwa Choi,Suk-hoon Jung,Seungki Hong,Taehee Lee,Sungroh Yoon*

Main category: cs.CL

TL;DR: 论文提出SAKE方法解决LLM推理中的知识整合衰减问题，通过在推理过程首尾锚定检索知识来提升知识利用率


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型通过搜索增强推理将外部知识整合到长链思维中，但存在知识整合衰减的关键瓶颈：随着推理链增长，模型越来越难以将检索到的证据整合到后续推理步骤中

Method: 提出SAKE（Self-Anchored Knowledge Encoding），一种无需训练、在推理时使用的策略，通过在推理过程开始和结束时锚定检索到的知识，防止知识被先前上下文淹没，保持其语义完整性

Result: 在多跳问答和复杂推理基准测试上的广泛实验表明，SAKE显著缓解了知识整合衰减问题并提高了性能

Conclusion: SAKE为智能体LLM中的知识整合提供了一个轻量级但有效的解决方案

Abstract: Modern Large Language Models (LLMs) have demonstrated remarkable capabilities in complex tasks by employing search-augmented reasoning to incorporate external knowledge into long chains of thought. However, we identify a critical yet underexplored bottleneck in this paradigm, termed Knowledge Integration Decay (KID). Specifically, we observe that as the length of reasoning generated before search grows, models increasingly fail to integrate retrieved evidence into subsequent reasoning steps, limiting performance even when relevant information is available. To address this, we propose Self-Anchored Knowledge Encoding (SAKE), a training-free inference-time strategy designed to stabilize knowledge utilization. By anchoring retrieved knowledge at both the beginning and end of the reasoning process, SAKE prevents it from being overshadowed by prior context, thereby preserving its semantic integrity. Extensive experiments on multi-hop QA and complex reasoning benchmarks demonstrate that SAKE significantly mitigates KID and improves performance, offering a lightweight yet effective solution for knowledge integration in agentic LLMs.

</details>


### [25] [UniARM: Towards a Unified Autoregressive Reward Model for Multi-Objective Test-Time Alignment](https://arxiv.org/abs/2602.09538)
*Hongyan Xie,Yikun Ban,Ruiyu Fang,Zixuan Huang,Deqing Wang,Jianxin Li,Yitong Yao,Chao Wang,Shuangyong Song*

Main category: cs.CL

TL;DR: 提出MoSLoRA和UniARM框架，通过共享特征提取和偏好调制模块解决多目标对齐中特征纠缠问题，实现单参数空间建模所有偏好维度


<details>
  <summary>Details</summary>
Motivation: 现有多目标对齐方法存在两个问题：1) 为每个偏好目标独立训练自回归奖励模型，忽略了偏好特征间的交互；2) 使用独立特征提取模块训练单一ARM，导致特征纠缠。这两种策略都会使生成输出与用户偏好错位。

Method: 提出MoSLoRA训练方法：先通过偏好无关模块提取共享特征，再通过偏好调制模块对共享特征进行仿射变换，该模块以混合偏好向量为条件。在此基础上提出UniARM框架，在单一参数空间中联合建模所有偏好维度。

Result: MoSLoRA设计缓解了特征纠缠问题，并在推理过程中实现对偏好权衡的精确控制。UniARM框架消除了为每个偏好目标设置独立参数的需求，并在更大规模LLM上进行了扩展，增强了实际可用性。

Conclusion: 提出的MoSLoRA和UniARM框架有效解决了多目标对齐中的特征纠缠问题，通过共享特征提取和偏好调制实现了更精确的偏好控制，为多目标测试时对齐提供了高效解决方案。

Abstract: Multi-objective alignment aims to align LLM responses with multiple human preference objectives. Among existing methods, guiding the generation of frozen LLMs through autoregressive reward models (ARMs) to accomplish multi-objective test-time alignment is a low-cost solution. However, these methods typically rely on independent parameters for each preference objective, either by training ARMs independently across preference dimensions, which neglects interactions among preference features, or by training a single ARM with separate feature extraction modules for each preference, which can cause feature entanglement. Both strategies can result in misalignment between generated outputs and user preferences. To address this limitation, we propose Preference-Modulated \& Shared Low-Rank Adaptation (MoSLoRA) for ARM training, which first extracts shared features via a preference-agnostic module and then applies affine transformations to shared features via a preference modulation module conditioned on mixed preference vectors. This design mitigates feature entanglement and enables precise control over preference trade-offs during inference. Building on this, we introduce the Unified Autoregressive Reward Model (UniARM), a novel framework for multi-objective test-time alignment. UniARM jointly models all preference dimensions in a single parameter space, eliminating the need for independent parameters for each preference objective. es on larger-scale LLMs, enhancing its practical usability.

</details>


### [26] [Comprehensive Comparison of RAG Methods Across Multi-Domain Conversational QA](https://arxiv.org/abs/2602.09552)
*Klejda Alushi,Jan Strich,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: 该论文对多轮对话问答中的检索增强生成方法进行了系统性比较，发现简单方法如重排序、混合BM25和HyDE优于复杂方法，且检索效果受数据集特性和对话长度影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多孤立评估RAG方法，且主要关注单轮设置，缺乏对多轮对话问答中RAG方法的系统性比较，而多轮对话中的对话历史、指代消解和用户意图变化使检索更加复杂。

Method: 使用统一的实验设置，在八个不同领域的多轮对话QA数据集上，评估了基础和高级RAG方法的检索质量和答案生成效果，使用生成器和检索指标，并分析性能随对话轮数的变化。

Result: 结果显示，简单而稳健的方法（如重排序、混合BM25和HyDE）始终优于基础RAG，而几种高级技术未能带来增益，甚至可能使性能低于无RAG基线。数据集特性和对话长度强烈影响检索效果。

Conclusion: 有效的对话RAG更依赖于检索策略与数据集结构的对齐，而非方法的复杂性。没有单一的RAG策略在所有设置中占主导地位。

Abstract: Conversational question answering increasingly relies on retrieval-augmented generation (RAG) to ground large language models (LLMs) in external knowledge. Yet, most existing studies evaluate RAG methods in isolation and primarily focus on single-turn settings. This paper addresses the lack of a systematic comparison of RAG methods for multi-turn conversational QA, where dialogue history, coreference, and shifting user intent substantially complicate retrieval. We present a comprehensive empirical study of vanilla and advanced RAG methods across eight diverse conversational QA datasets spanning multiple domains. Using a unified experimental setup, we evaluate retrieval quality and answer generation using generator and retrieval metrics, and analyze how performance evolves across conversation turns. Our results show that robust yet straightforward methods, such as reranking, hybrid BM25, and HyDE, consistently outperform vanilla RAG. In contrast, several advanced techniques fail to yield gains and can even degrade performance below the No-RAG baseline. We further demonstrate that dataset characteristics and dialogue length strongly influence retrieval effectiveness, explaining why no single RAG strategy dominates across settings. Overall, our findings indicate that effective conversational RAG depends less on method complexity than on alignment between the retrieval strategy and the dataset structure. We publish the code used.\footnote{\href{https://github.com/Klejda-A/exp-rag.git}{GitHub Repository}}

</details>


### [27] [Advancing Block Diffusion Language Models for Test-Time Scaling](https://arxiv.org/abs/2602.09555)
*Yi Lu,Deyang Kong,Jianing Wang,Linsen Guo,Xue Wang,Qi Guo,Tao Gui,Xuanjing Huang,Wei Ye,Shikun Zhang,Wei Wang*

Main category: cs.CL

TL;DR: 提出一个统一框架，通过自适应解码和块生成优化块扩散语言模型在测试时扩展中的推理效率与效果平衡


<details>
  <summary>Details</summary>
Motivation: 现有块扩散语言模型在测试时扩展方面探索有限，在长链式思维推理中面临解码速度与效果的严重平衡挑战

Method: 提出有界自适应置信解码（BACD）和"粗思考、细批判"（TCCF）范式，结合渐进块大小扩展技术

Result: 在TDAR-8B上应用BACD和TCCF，相比TraDo-8B实现2.26倍加速，AIME24提升11.2分

Conclusion: 该框架是解锁块扩散语言模型在复杂推理任务中测试时扩展潜力的重要一步

Abstract: Recent advances in block diffusion language models have demonstrated competitive performance and strong scalability on reasoning tasks. However, existing BDLMs have limited exploration under the test-time scaling setting and face more severe decoding challenges in long Chain-of-Thought reasoning, particularly in balancing the decoding speed and effectiveness. In this work, we propose a unified framework for test-time scaling in BDLMs that introduces adaptivity in both decoding and block-wise generation. At the decoding level, we propose Bounded Adaptive Confidence Decoding (BACD), a difficulty-aware sampling strategy that dynamically adjusts denoising based on model confidence, accelerating inference while controlling error accumulation. Beyond step-wise adaptivity, we introduce Think Coarse, Critic Fine (TCCF), a test-time scaling paradigm that allocates large block sizes to exploratory reasoning and smaller block sizes to refinement, achieving an effective efficiency-effectiveness balance. To enable efficient and effective decoding with a large block size, we adopt Progressive Block Size Extension, which mitigates performance degradation when scaling block sizes. Extensive experiments show that applying BACD and TCCF to TDAR-8B yields significant improvements over strong baselines such as TraDo-8B (2.26x speedup, +11.2 points on AIME24). These results mark an important step toward unlocking the potential of BDLMs for test-time scaling in complex reasoning tasks.

</details>


### [28] [LEMUR: A Corpus for Robust Fine-Tuning of Multilingual Law Embedding Models for Retrieval](https://arxiv.org/abs/2602.09570)
*Narges Baba Ahmadi,Jan Strich,Martin Semmann,Chris Biemann*

Main category: cs.CL

TL;DR: LEMUR是一个大规模多语言欧盟环境法规语料库，通过优化PDF文本提取质量，并微调多语言嵌入模型，显著提升了法律检索性能，特别是在低资源语言上效果显著。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在多语言法律环境中的应用受到两个主要限制：不可靠的检索系统，以及缺乏领域适应的开放嵌入模型。现有法律语料库不适合语义检索，PDF源文件存在大量文本提取噪声。

Method: 1) 从24,953个EUR-Lex PDF文档构建LEMUR多语言环境法规语料库，覆盖25种语言；2) 使用词汇内容评分(LCS)量化PDF到文本转换的保真度；3) 在单语和双语设置下，使用对比目标微调三个最先进的多语言嵌入模型。

Result: 法律领域微调在高低资源语言上均能持续提升Top-k检索准确率，低资源语言提升尤为显著。跨语言评估显示改进可迁移到未见语言，表明微调主要增强了语言无关的内容级法律表示而非语言特定线索。

Conclusion: LEMUR语料库和微调的多语言嵌入模型有效解决了多语言法律检索的挑战，特别是在低资源语言上。改进主要源于对法律内容的理解增强，而非语言特定特征，具有很好的跨语言迁移能力。

Abstract: Large language models (LLMs) are increasingly used to access legal information. Yet, their deployment in multilingual legal settings is constrained by unreliable retrieval and the lack of domain-adapted, open-embedding models. In particular, existing multilingual legal corpora are not designed for semantic retrieval, and PDF-based legislative sources introduce substantial noise due to imperfect text extraction. To address these challenges, we introduce LEMUR, a large-scale multilingual corpus of EU environmental legislation constructed from 24,953 official EUR-Lex PDF documents covering 25 languages. We quantify the fidelity of PDF-to-text conversion by measuring lexical consistency against authoritative HTML versions using the Lexical Content Score (LCS). Building on LEMUR, we fine-tune three state-of-the-art multilingual embedding models using contrastive objectives in both monolingual and bilingual settings, reflecting realistic legal-retrieval scenarios. Experiments across low- and high-resource languages demonstrate that legal-domain fine-tuning consistently improves Top-k retrieval accuracy relative to strong baselines, with particularly pronounced gains for low-resource languages. Cross-lingual evaluations show that these improvements transfer to unseen languages, indicating that fine-tuning primarily enhances language-independent, content-level legal representations rather than language-specific cues. We publish code\footnote{\href{https://github.com/nargesbh/eur_lex}{GitHub Repository}} and data\footnote{\href{https://huggingface.co/datasets/G4KMU/LEMUR}{Hugging Face Dataset}}.

</details>


### [29] [Aligning Tree-Search Policies with Fixed Token Budgets in Test-Time Scaling of LLMs](https://arxiv.org/abs/2602.09574)
*Sora Miyamoto,Daisuke Oba,Naoaki Okazaki*

Main category: cs.CL

TL;DR: BG-MCTS是一种预算引导的树搜索解码算法，通过根据剩余token预算动态调整搜索策略，在固定预算约束下优化LLM推理性能。


<details>
  <summary>Details</summary>
Motivation: 实际部署中LLM有固定的每查询token预算限制，现有树搜索解码策略大多忽略预算约束，将其仅作为终止条件，导致后期过度分支或过早终止的问题。

Method: 提出预算引导的MCTS算法，根据剩余token预算动态调整搜索策略：开始阶段进行广泛探索，随着预算减少优先进行细化和答案完成，减少浅层节点的后期分支。

Result: 在MATH500和AIME24/25数据集上，使用开源权重LLM，BG-MCTS在不同预算设置下始终优于预算无关的树搜索基线方法。

Conclusion: 预算引导的树搜索解码能有效适应实际部署中的token预算约束，显著提升LLM在数学推理任务上的性能表现。

Abstract: Tree-search decoding is an effective form of test-time scaling for large language models (LLMs), but real-world deployment imposes a fixed per-query token budget that varies across settings. Existing tree-search policies are largely budget-agnostic, treating the budget as a termination condition, which can lead to late-stage over-branching or premature termination. We propose {Budget-Guided MCTS} (BG-MCTS), a tree-search decoding algorithm that aligns its search policy with the remaining token budget: it starts with broad exploration, then prioritizes refinement and answer completion as the budget depletes while reducing late-stage branching from shallow nodes. BG-MCTS consistently outperforms budget-agnostic tree-search baselines across different budgets on MATH500 and AIME24/25 with open-weight LLMs.

</details>


### [30] [Context-Aware Counterfactual Data Augmentation for Gender Bias Mitigation in Language Models](https://arxiv.org/abs/2602.09590)
*Shweta Parihar,Liu Guangliang,Natalie Parde,Lu Cheng*

Main category: cs.CL

TL;DR: 提出Context-CDA方法，通过增强上下文多样性和相关性来缓解微调语言模型中的社会偏见，同时保持语言建模能力


<details>
  <summary>Details</summary>
Motivation: 传统反事实数据增强(CDA)方法在缓解语言模型社会偏见时存在两个问题：1)生成的合成数据可能与真实世界分布不一致；2)创建的反事实过于简单，忽略了敏感属性（如性别）在社会语境中的复杂性。这可能导致语言建模能力下降，影响下游任务性能。

Method: 提出Context-CDA方法：1)使用大型语言模型增强反事实数据的多样性和语境相关性；2)通过增强的上下文最小化去偏见语料库与预训练数据之间的差异；3)采用基于不确定性的过滤机制，排除目标小型语言模型认为低质量的反事实生成，提高微调语料库质量。

Result: 在性别偏见基准测试中，Context-CDA有效缓解了偏见，同时没有牺牲语言建模性能。通过分析下一个标记生成概率的分布变化，该方法还提供了对社会偏见的深入洞察。

Conclusion: Context-CDA是一种简单而有效的上下文增强反事实数据增强方法，能够在不损害语言建模能力的情况下缓解语言模型中的社会偏见，同时通过分析生成概率分布变化提供对偏见的理解。

Abstract: A challenge in mitigating social bias in fine-tuned language models (LMs) is the potential reduction in language modeling capability, which can harm downstream performance. Counterfactual data augmentation (CDA), a widely used method for fine-tuning, highlights this issue by generating synthetic data that may align poorly with real-world distributions or creating overly simplistic counterfactuals that ignore the social context of altered sensitive attributes (e.g., gender) in the pretraining corpus. To address these limitations, we propose a simple yet effective context-augmented CDA method, Context-CDA, which uses large LMs to enhance the diversity and contextual relevance of the debiasing corpus. By minimizing discrepancies between the debiasing corpus and pretraining data through augmented context, this approach ensures better alignment, enhancing language modeling capability. We then employ uncertainty-based filtering to exclude generated counterfactuals considered low-quality by the target smaller LMs (i.e., LMs to be debiased), further improving the fine-tuning corpus quality. Experimental results on gender bias benchmarks demonstrate that Context-CDA effectively mitigates bias without sacrificing language modeling performance while offering insights into social biases by analyzing distribution shifts in next-token generation probabilities.

</details>


### [31] [On the Optimal Reasoning Length for RL-Trained Language Models](https://arxiv.org/abs/2602.09591)
*Daisuke Nohara,Taishi Nakamura,Rio Yokota*

Main category: cs.CL

TL;DR: 研究发现强化学习会延长思维链输出并增加计算成本，长度惩罚可能阻碍推理能力，而适当调整的长度控制能提升具有强推理先验模型的效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能提升大语言模型的推理能力，但会导致思维链输出变长，增加训练和推理的计算成本。目前已有长度控制方法，但最优输出长度如何平衡效率与性能仍不明确。

Method: 在Qwen3-1.7B Base和DeepSeek-R1-Distill-Qwen-1.5B两个模型上比较多种长度控制方法，并将先前工作扩展到强化学习训练的策略中。

Result: 长度惩罚可能阻碍推理能力的获取，而适当调整的长度控制能提升具有强推理先验模型的效率。发现两种失败模式：长输出增加分散性，短输出导致思考不足。

Conclusion: 需要谨慎设计长度控制方法，避免长度惩罚对推理能力的负面影响，同时通过适当调整来平衡输出长度与推理性能，以提升整体效率。

Abstract: Reinforcement learning substantially improves reasoning in large language models, but it also tends to lengthen chain of thought outputs and increase computational cost during both training and inference. Though length control methods have been proposed, it remains unclear what the optimal output length is for balancing efficiency and performance. In this work, we compare several length control methods on two models, Qwen3-1.7B Base and DeepSeek-R1-Distill-Qwen-1.5B. Our results indicate that length penalties may hinder reasoning acquisition, while properly tuned length control can improve efficiency for models with strong prior reasoning. By extending prior work to RL trained policies, we identify two failure modes, 1) long outputs increase dispersion, and 2) short outputs lead to under-thinking.

</details>


### [32] [Learning from the Irrecoverable: Error-Localized Policy Optimization for Tool-Integrated LLM Reasoning](https://arxiv.org/abs/2602.09598)
*Qiao Liang,Yuke Zhu,Chao Ge,Lei Yang,Ying Shen,Bo Zheng,Sheng Guo*

Main category: cs.CL

TL;DR: ELPO通过二分搜索定位不可恢复错误步骤，进行层次化优势归因和自适应裁剪，在工具集成推理任务中优于现有Agentic RL方法


<details>
  <summary>Details</summary>
Motivation: 在工具集成推理中，仅基于结果的强化学习面临稀疏延迟奖励和弱信用分配问题，早期不可恢复错误决定成败，需要精确定位关键步骤进行细粒度信用分配

Method: 1) 通过固定预算下的二分搜索展开树定位第一个不可恢复步骤；2) 将树转换为层次化优势归因的稳定学习信号；3) 应用错误定位自适应裁剪强化关键步骤及其后缀的修正更新

Result: 在数学、科学QA和代码执行等TIR基准测试中，ELPO在可比采样预算下持续优于强Agentic RL基线，在Pass@K、Major@K扩展、展开排名质量和工具调用效率方面有额外提升

Conclusion: ELPO通过精确定位不可恢复错误步骤并进行针对性优化，有效解决了工具集成推理中的信用分配问题，提升了Agentic RL的性能和效率

Abstract: Tool-integrated reasoning (TIR) enables LLM agents to solve tasks through planning, tool use, and iterative revision, but outcome-only reinforcement learning in this setting suffers from sparse, delayed rewards and weak step-level credit assignment. In long-horizon TIR trajectories, an early irrecoverable mistake can determine success or failure, making it crucial to localize the first irrecoverable step and leverage it for fine-grained credit assignment. We propose Error-Localized Policy Optimization (ELPO), which localizes the first irrecoverable step via binary-search rollout trees under a fixed rollout budget, converts the resulting tree into stable learning signals through hierarchical advantage attribution, and applies error-localized adaptive clipping to strengthen corrective updates on the critical step and its suffix. Across TIR benchmarks in math, science QA, and code execution, ELPO consistently outperforms strong Agentic RL baselines under comparable sampling budgets, with additional gains in Pass@K and Major@K scaling, rollout ranking quality, and tool-call efficiency. Our code will be publicly released soon.

</details>


### [33] [AlignTune: Modular Toolkit for Post-Training Alignment of Large Language Models](https://arxiv.org/abs/2602.09621)
*R E Zera Marveen Lyngkhoi,Chirag Chawla,Pratinav Seth,Utsav Avaiya,Soham Bhattacharjee,Mykola Khandoga,Rui Yuan,Vinay Kumar Sankarapu*

Main category: cs.CL

TL;DR: AlignTune是一个模块化工具包，为LLM的后训练对齐提供统一接口，解决现有工具碎片化和实验不可复现的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM后训练对齐工作流分散在不同后端工具和临时代码中，导致实验难以复现。主要障碍包括后端干扰、奖励碎片化和不可复现的流程。

Method: 引入AlignTune工具包，提供监督微调(SFT)和RLHF风格优化的统一接口，支持可互换的TRL和Unsloth后端。标准化配置，提供可扩展的奖励层（基于规则和学习的），并集成标准基准和自定义任务的评估。

Result: 通过将后端特定逻辑隔离在单一工厂边界后，AlignTune实现了受控比较和可复现的对齐实验。

Conclusion: AlignTune解决了对齐研究中的关键障碍，为LLM后训练对齐提供了标准化、可复现的实验框架。

Abstract: Post-training alignment is central to deploying large language models (LLMs), yet practical workflows remain split across backend-specific tools and ad-hoc glue code, making experiments hard to reproduce. We identify backend interference, reward fragmentation, and irreproducible pipelines as key obstacles in alignment research. We introduce AlignTune, a modular toolkit exposing a unified interface for supervised fine-tuning (SFT) and RLHF-style optimization with interchangeable TRL and Unsloth backends. AlignTune standardizes configuration, provides an extensible reward layer (rule-based and learned), and integrates evaluation over standard benchmarks and custom tasks. By isolating backend-specific logic behind a single factory boundary, AlignTune enables controlled comparisons and reproducible alignment experiments.

</details>


### [34] [MILE-RefHumEval: A Reference-Free, Multi-Independent LLM Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2602.09624)
*Nalin Srun,Parisa Rastin,Guénaël Cabanes,Lydia Boudjeloud Assala*

Main category: cs.CL

TL;DR: MILE-RefHumEval是一个无需参考标注的无监督框架，通过集成独立提示的评估器来评估大语言模型，支持离散和连续评分，在多个任务上表现优异且计算高效。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估通常需要人工标注或协调评估器，成本高且不灵活。需要一种无需参考标注、无需协调评估器、可扩展且与人类判断对齐的评估框架。

Method: 采用集成多个独立提示的评估器，基于人类对齐的评估模式，支持离散和连续评分。通过任务特定提示（从最佳候选选择、摘要、图像描述到对话）实现灵活评估。

Result: 实验表明该框架与人类判断高度一致，优于现有方法，同时显著降低计算开销，提供高效、鲁棒且人类对齐的评估解决方案。

Conclusion: MILE-RefHumEval为现实世界LLM评估提供了一个高效、鲁棒、可扩展且与人类对齐的无监督评估框架，解决了传统评估方法的局限性。

Abstract: We introduce MILE-RefHumEval, a reference-free framework for evaluating Large Language Models (LLMs) without ground-truth annotations or evaluator coordination. It leverages an ensemble of independently prompted evaluators guided by a human-aligned schema, supporting both discrete and continuous scoring judgement. With task-specific prompts from best candidate selection, summarization and image captioning to dialogue, MILE-RefHumEval provides flexible, interpretable, and scalable assessments. Experiments show it aligns closely with human judgments, outperforms prior methods, and reduces computational overhead, offering an efficient, robust, and human-aligned solution for real-world LLM evaluation.

</details>


### [35] [MATA: Multi-Agent Framework for Reliable and Flexible Table Question Answering](https://arxiv.org/abs/2602.09642)
*Sieun Hyeon,Jusang Oh,Sunghwan Steve Cho,Jaeyoung Do*

Main category: cs.CL

TL;DR: MATA是一个多智能体表格问答框架，通过多种推理路径和小语言模型工具实现高效可靠的表格理解，减少对大语言模型的依赖。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在表格理解任务上取得进展，但在可靠性、可扩展性和效率方面仍存在挑战，特别是在资源受限或隐私敏感的环境中。

Method: MATA采用多智能体框架，利用多种互补推理路径和基于小语言模型构建的工具集，为给定表格和问题生成候选答案，然后通过工具优化或选择最佳答案，并设计了减少昂贵大语言模型调用的算法。

Result: 在两个不同难度的基准测试中使用十种不同大语言模型进行广泛实验，MATA实现了最先进的准确性和高效推理，同时避免过度的大语言模型推理。

Conclusion: 精心编排多种推理路径可以实现可扩展且可靠的表格问答，MATA在保持小规模开源模型强大性能的同时，能够轻松适应各种大语言模型类型。

Abstract: Recent advances in Large Language Models (LLMs) have significantly improved table understanding tasks such as Table Question Answering (TableQA), yet challenges remain in ensuring reliability, scalability, and efficiency, especially in resource-constrained or privacy-sensitive environments. In this paper, we introduce MATA, a multi-agent TableQA framework that leverages multiple complementary reasoning paths and a set of tools built with small language models. MATA generates candidate answers through diverse reasoning styles for a given table and question, then refines or selects the optimal answer with the help of these tools. Furthermore, it incorporates an algorithm designed to minimize expensive LLM agent calls, enhancing overall efficiency. MATA maintains strong performance with small, open-source models and adapts easily across various LLM types. Extensive experiments on two benchmarks of varying difficulty with ten different LLMs demonstrate that MATA achieves state-of-the-art accuracy and highly efficient reasoning while avoiding excessive LLM inference. Our results highlight that careful orchestration of multiple reasoning pathways yields scalable and reliable TableQA. The code is available at https://github.com/AIDAS-Lab/MATA.

</details>


### [36] [Life Cycle-Aware Evaluation of Knowledge Distillation for Machine Translation: Environmental Impact and Translation Quality Trade-offs](https://arxiv.org/abs/2602.09691)
*Joseph Attieh,Timothee Mickus,Anne-Laure Ligozat,Aurélie Névéol,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 该研究评估了知识蒸馏方法在机器翻译中的计算成本和翻译质量，发现蒸馏开销在小规模部署时占主导，推理在大规模时占主导，词级蒸馏通常比序列级蒸馏有更好的计算质量权衡。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译中的知识蒸馏研究通常只报告学生模型的翻译质量，而忽略了计算复杂度，这使得在计算约束下难以选择合适的蒸馏方法。需要同时考虑翻译质量和计算成本来评估蒸馏方法。

Method: 使用机器学习生命周期评估工具将计算成本量化为碳足迹，考虑了蒸馏模型生命周期中的运行时操作排放和硬件生产摊销成本（包括教师训练、蒸馏和推理阶段）。评估了代表性的知识蒸馏方法。

Result: 发现：(1) 在小规模部署时，蒸馏开销占总碳足迹的主导地位；(2) 在大规模部署时，推理占主导，使得知识蒸馏只有在超过任务相关的使用阈值后才有利；(3) 词级蒸馏通常比序列级蒸馏提供更有利的计算质量权衡。

Conclusion: 该协议为在明确的质量和计算约束下选择知识蒸馏方法提供了可复现的指导，强调了同时考虑翻译质量和计算成本的重要性。

Abstract: Knowledge distillation (KD) is a tool to compress a larger system (teacher) into a smaller one (student). In machine translation, studies typically report only the translation quality of the student and omit the computational complexity of performing KD, making it difficult to select among the many available KD choices under compute-induced constraints. In this study, we evaluate representative KD methods by considering both translation quality and computational cost. We express computational cost as a carbon footprint using the machine learning life cycle assessment (MLCA) tool. This assessment accounts for runtime operational emissions and amortized hardware production costs throughout the KD model life cycle (teacher training, distillation, and inference). We find that (i) distillation overhead dominates the total footprint at small deployment volumes, (ii) inference dominates at scale, making KD beneficial only beyond a task-dependent usage threshold, and (iii) word-level distillation typically offers more favorable footprint-quality trade-offs than sequence-level distillation. Our protocol provides reproducible guidance for selecting KD methods under explicit quality and compute-induced constraints.

</details>


### [37] [Maastricht University at AMIYA: Adapting LLMs for Dialectal Arabic using Fine-tuning and MBR Decoding](https://arxiv.org/abs/2602.09703)
*Abdulhai Alali,Abderrahmane Issam*

Main category: cs.CL

TL;DR: 使用LoRA微调、适配器合并和方言感知MBR解码来提升LLM在阿拉伯语方言上的生成和翻译性能


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然支持多种语言，但对方言变体的支持不足，特别是阿拉伯语方言（如叙利亚、摩洛哥、沙特阿拉伯方言）由于数据有限和语言变异性而代表性不足

Method: 1. 使用低秩适应（LoRA）在单语和英语-方言平行数据上进行微调；2. 采用适配器合并技术；3. 使用方言感知的最小贝叶斯风险（MBR）解码来提高方言保真度

Result: 在叙利亚、摩洛哥和沙特阿拉伯阿拉伯语方言上的实验表明，合并和MBR方法在保持语义准确性的同时提高了方言保真度

Conclusion: 该方法提供了一个紧凑有效的框架，用于鲁棒的阿拉伯语方言生成，解决了方言数据有限的问题

Abstract: Large Language Models (LLMs) are becoming increasingly multilingual, supporting hundreds of languages, especially high resource ones. Unfortunately, Dialect variations are still underrepresented due to limited data and linguistic variation. In this work, we adapt a pre-trained LLM to improve dialectal performance. Specifically, we use Low Rank Adaptation (LoRA) fine-tuning on monolingual and English Dialect parallel data, adapter merging and dialect-aware MBR decoding to improve dialectal fidelity generation and translation. Experiments on Syrian, Moroccan, and Saudi Arabic show that merging and MBR improve dialectal fidelity while preserving semantic accuracy. This combination provides a compact and effective framework for robust dialectal Arabic generation.

</details>


### [38] [TraceMem: Weaving Narrative Memory Schemata from User Conversational Traces](https://arxiv.org/abs/2602.09712)
*Yiming Shu,Pei Liu,Tiange Zhang,Ruiyang Gao,Jun Ma,Chen Sun*

Main category: cs.CL

TL;DR: TraceMem是一个受认知启发的记忆框架，通过三阶段流水线构建结构化叙事记忆模式，在长期对话中实现更好的叙事连贯性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的有限上下文窗口难以处理随时间延伸的对话历史，现有记忆系统将交互视为离散片段，无法捕捉对话流的底层叙事连贯性。

Method: 采用三阶段流水线：1) 短期记忆处理，使用演绎式主题分割划分情节边界并提取语义表示；2) 突触记忆巩固，将情节总结为情景记忆，并与语义一起提炼为用户特定痕迹；3) 系统记忆巩固，使用两阶段层次聚类将这些痕迹组织成连贯的、随时间演化的叙事线程，形成结构化用户记忆卡片。

Result: 在LoCoMo基准测试中达到最先进性能，在多跳推理和时间推理方面超越基线，证明了其在深度叙事理解中的重要作用。

Conclusion: TraceMem通过构建连贯的叙事记忆模式，有效解决了长期交互中的记忆瓶颈问题，为记忆系统领域提供了新的视角和未来展望。

Abstract: Sustaining long-term interactions remains a bottleneck for Large Language Models (LLMs), as their limited context windows struggle to manage dialogue histories that extend over time. Existing memory systems often treat interactions as disjointed snippets, failing to capture the underlying narrative coherence of the dialogue stream. We propose TraceMem, a cognitively-inspired framework that weaves structured, narrative memory schemata from user conversational traces through a three-stage pipeline: (1) Short-term Memory Processing, which employs a deductive topic segmentation approach to demarcate episode boundaries and extract semantic representation; (2) Synaptic Memory Consolidation, a process that summarizes episodes into episodic memories before distilling them alongside semantics into user-specific traces; and (3) Systems Memory Consolidation, which utilizes two-stage hierarchical clustering to organize these traces into coherent, time-evolving narrative threads under unifying themes. These threads are encapsulated into structured user memory cards, forming narrative memory schemata. For memory utilization, we provide an agentic search mechanism to enhance reasoning process. Evaluation on the LoCoMo benchmark shows that TraceMem achieves state-of-the-art performance with a brain-inspired architecture. Analysis shows that by constructing coherent narratives, it surpasses baselines in multi-hop and temporal reasoning, underscoring its essential role in deep narrative comprehension. Additionally, we provide an open discussion on memory systems, offering our perspectives and future outlook on the field. Our code implementation is available at: https://github.com/YimingShu-teay/TraceMem

</details>


### [39] [Unsupervised Layer-Wise Dynamic Test Time Adaptation for LLMs](https://arxiv.org/abs/2602.09719)
*Longhuan Xu,Cunjian Chen,Feng Yin*

Main category: cs.CL

TL;DR: 本文提出了一种层级的动态测试时适应框架，通过超网络预测每层每步的学习率乘子，解决了无监督、样本特定的LLM测试时适应中固定学习率导致的过拟合和性能退化问题。


<details>
  <summary>Details</summary>
Motivation: 无监督、样本特定的测试时适应（TTA）是LLMs部署中的常见场景，但使用固定手工学习率会导致不稳定：更新会过拟合到特定提示的统计特征，偏离期望答案分布，最终降低生成质量。这种失败模式源于TTA需要在少量梯度步内适应单个提示，而标准训练则在大数据集上平均更新。

Method: 提出层级动态测试时适应框架，通过轻量级超网络预测每层、每步的学习率乘子，实现对TTA强度的精细控制。该方法仅更新LoRA参数，根据提示表示、LLM结构和适应步骤来调节适应强度。

Result: 在各种数据集和LLMs上的实验表明，该方法通过学习有效的适应步骤和transformer层投影的缩放模式，显著增强了TTA的稳定性，并提供了更好的性能表现。

Conclusion: 层级动态测试时适应框架通过精细控制适应强度，解决了无监督、样本特定TTA中的稳定性问题，为LLMs在实际部署中的自适应提供了有效的解决方案。

Abstract: Test-time adaptation (TTA) for large language models (LLMs) updates model parameters at inference time using signals available at deployment. This paper focuses on a common yet under-explored regime: unsupervised, sample-specific TTA, where the model adapts independently for each prompt using only the prompt itself, without gold answers or external supervision. Although appealing, naive unsupervised TTA with a fixed, handcrafted learning rate can be unstable: updates may overfit to prompt-specific statistics, drift from the desired answer distribution, and ultimately degrade generation quality. This failure mode is not surprising, as in this case TTA must adapt to a single prompt within only a few gradient steps, unlike standard training that averages updates over large datasets and long optimization horizons. Therefore, we propose layer-wise dynamic test-time adaptation, a framework which explicitly modulates TTA strength as a function of prompt representation, LLM structure and adaptation step. In our setting, TTA updates only LoRA parameters, and a lightweight hypernetwork predicts per-layer, per-step learning-rate multipliers, enabling fine-grained control. Experiments across various datasets and LLMs consistently show that our method substantially strengthens TTA by learning effective scaling patterns over adaptation steps and transformer layer projections, improving stability while delivering better performance.

</details>


### [40] [AI-Assisted Scientific Assessment: A Case Study on Climate Change](https://arxiv.org/abs/2602.09723)
*Christian Buck,Levke Caesar,Michelle Chen Huebscher,Massimiliano Ciaramita,Erich M. Fischer,Zeke Hausfather,Özge Kart Tokmak,Reto Knutti,Markus Leippold,Joseph Ludescher,Katharine J. Mach,Sofia Palazzo Corner,Kasra Rafiezadeh Shahi,Johan Rockström,Joeri Rogelj,Boris Sakschewski*

Main category: cs.CL

TL;DR: AI辅助科学评估系统在气候科学领域测试，能加速科研流程但需专家监督


<details>
  <summary>Details</summary>
Motivation: 现有AI科学家范式仅适用于可重复验证的任务，无法处理需要理论证据综合评估的科学问题。需要开发能支持协作科学评估的AI系统。

Method: 开发基于Gemini的AI协作环境，集成到标准科学工作流中。与13位气候科学家合作，在AMOC稳定性这一复杂主题上进行测试，分析AI在文献综述中的作用。

Result: AI显著加速科研流程：团队在46人时内完成79篇论文的综合分析，经过104次修订。AI生成内容大部分被保留，帮助保持逻辑一致性和呈现质量。但专家贡献至关重要：不到一半报告由AI生成，需要大量监督才能达到严格科学标准。

Conclusion: AI能有效加速科学工作流程，但不能完全替代专家判断。AI与人类专家的协作模式对于复杂科学评估至关重要，需要大量专家监督来确保科学严谨性。

Abstract: The emerging paradigm of AI co-scientists focuses on tasks characterized by repeatable verification, where agents explore search spaces in 'guess and check' loops. This paradigm does not extend to problems where repeated evaluation is impossible and ground truth is established by the consensus synthesis of theory and existing evidence. We evaluate a Gemini-based AI environment designed to support collaborative scientific assessment, integrated into a standard scientific workflow. In collaboration with a diverse group of 13 scientists working in the field of climate science, we tested the system on a complex topic: the stability of the Atlantic Meridional Overturning Circulation (AMOC). Our results show that AI can accelerate the scientific workflow. The group produced a comprehensive synthesis of 79 papers through 104 revision cycles in just over 46 person-hours. AI contribution was significant: most AI-generated content was retained in the report. AI also helped maintain logical consistency and presentation quality. However, expert additions were crucial to ensure its acceptability: less than half of the report was produced by AI. Furthermore, substantial oversight was required to expand and elevate the content to rigorous scientific standards.

</details>


### [41] [Targum -- A Multilingual New Testament Translation Corpus](https://arxiv.org/abs/2602.09724)
*Maciej Rapacz,Aleksander Smywiński-Pohl*

Main category: cs.CL

TL;DR: 构建了一个包含657个新约译本的多语言语料库，其中352个是独特版本，在英语、法语、意大利语、波兰语和西班牙语五种语言中提供了前所未有的深度，支持翻译历史的定量研究。


<details>
  <summary>Details</summary>
Motivation: 现有语料库追求语言广度但缺乏深度，无法捕捉欧洲语言丰富的圣经翻译历史。需要填补这一空白，为翻译历史研究提供深度资源。

Method: 从12个在线圣经图书馆和一个现有语料库中收集657个新约译本，手动标注元数据，将文本映射到标准化的工作标识符、特定版本和修订年份，实现规范化。

Result: 创建了包含657个译本（352个独特版本）的多语言语料库，其中英语208个独特版本（共396个），法语41个（78个），意大利语18个（33个），波兰语30个（48个），西班牙语55个（102个）。

Conclusion: 该语料库为翻译历史的定量研究设立了新基准，支持从微观（如KJV谱系）到宏观的多层次灵活分析，是第一个为此类研究设计的资源。

Abstract: Many European languages possess rich biblical translation histories, yet existing corpora - in prioritizing linguistic breadth - often fail to capture this depth. To address this gap, we introduce a multilingual corpus of 657 New Testament translations, of which 352 are unique, with unprecedented depth in five languages: English (208 unique versions from 396 total), French (41 from 78), Italian (18 from 33), Polish (30 from 48), and Spanish (55 from 102). Aggregated from 12 online biblical libraries and one preexisting corpus, each translation is manually annotated with metadata that maps the text to a standardized identifier for the work, its specific edition, and its year of revision. This canonicalization empowers researchers to define "uniqueness" for their own needs: they can perform micro-level analyses on translation families, such as the KJV lineage, or conduct macro-level studies by deduplicating closely related texts. By providing the first resource designed for such flexible, multilevel analysis, our corpus establishes a new benchmark for the quantitative study of translation history.

</details>


### [42] [Improving Interpretability of Lexical Semantic Change with Neurobiological Features](https://arxiv.org/abs/2602.09760)
*Kohei Oda,Hiroya Takamura,Kiyoaki Shirai,Natthawut Kertkeidkachorn*

Main category: cs.CL

TL;DR: 该论文提出了一种将词向量语义空间映射到神经生物学特征空间的方法，以增强词汇语义变化的可解释性，并在LSC估计任务中取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有词汇语义变化研究主要关注变化程度的估计，但难以解释词义如何变化。提高LSC的可解释性对于该领域获得新见解具有重要意义。

Method: 将预训练语言模型得到的上下文词向量语义空间映射到神经生物学特征空间，该空间的每个维度对应词的基本特征，值表示特征强度，使人类能够系统解释LSC。

Result: 在LSC程度估计任务中，该方法优于大多数先前方法。由于高可解释性，能够发现以往研究中被忽视的有趣LSC类型，并有效搜索具有特定类型LSC的词汇。

Conclusion: 提出的神经生物学特征空间映射方法不仅提高了LSC估计性能，更重要的是增强了可解释性，为发现新的LSC类型和分析提供了有力工具。

Abstract: Lexical Semantic Change (LSC) is the phenomenon in which the meaning of a word change over time. Most studies on LSC focus on improving the performance of estimating the degree of LSC, however, it is often difficult to interpret how the meaning of a word change. Enhancing the interpretability of LSC is a significant challenge as it could lead to novel insights in this field. To tackle this challenge, we propose a method to map the semantic space of contextualized embeddings of words obtained by a pre-trained language model to a neurobiological feature space. In the neurobiological feature space, each dimension corresponds to a primitive feature of words, and its value represents the intensity of that feature. This enables humans to interpret LSC systematically. When employed for the estimation of the degree of LSC, our method demonstrates superior performance in comparison to the majority of the previous methods. In addition, given the high interpretability of the proposed method, several analyses on LSC are carried out. The results demonstrate that our method not only discovers interesting types of LSC that have been overlooked in previous studies but also effectively searches for words with specific types of LSC.

</details>


### [43] [Where Are We At with Automatic Speech Recognition for the Bambara Language?](https://arxiv.org/abs/2602.09785)
*Seydou Diallo,Yacouba Diarra,Mamadou K. Keita,Panga Azazia Kamaté,Adam Bouno Kampo,Aboubacar Ouattara*

Main category: cs.CL

TL;DR: 首个班巴拉语ASR标准化基准：使用1小时专业录制的马里宪法文本，评估37个模型，发现当前ASR性能远未达到部署标准，最佳WER 46.76%，最佳CER 13.00%，多语言模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 为班巴拉语（一种资源匮乏语言）建立首个标准化ASR评估基准，填补该领域空白，促进班巴拉语语音技术研究。

Method: 创建包含1小时专业录制马里宪法文本的基准数据集，在接近最优的声学和语言条件下设计控制参考集，评估37个模型（包括班巴拉语训练系统和大型商业模型）。

Result: 当前ASR性能远低于部署标准：最佳WER 46.76%，最佳CER 13.00%，多个知名多语言模型WER超过100%。结果表明多语言预训练和模型扩展对资源匮乏语言不足。

Conclusion: 班巴拉语ASR技术仍处于早期阶段，需要专门研究而非依赖通用多语言模型。基准数据集代表最简化形式，实际应用挑战更大。提供公开基准和排行榜促进透明评估。

Abstract: This paper introduces the first standardized benchmark for evaluating Automatic Speech Recognition (ASR) in the Bambara language, utilizing one hour of professionally recorded Malian constitutional text. Designed as a controlled reference set under near-optimal acoustic and linguistic conditions, the benchmark was used to evaluate 37 models, ranging from Bambara-trained systems to large-scale commercial models. Our findings reveal that current ASR performance remains significantly below deployment standards in a narrow formal domain; the top-performing system in terms of Word Error Rate (WER) achieved 46.76\% and the best Character Error Rate (CER) of 13.00\% was set by another model, while several prominent multilingual models exceeded 100\% WER. These results suggest that multilingual pre-training and model scaling alone are insufficient for underrepresented languages. Furthermore, because this dataset represents a best-case scenario of the most simplified and formal form of spoken Bambara, these figures are yet to be tested against practical, real-world settings. We provide the benchmark and an accompanying public leaderboard to facilitate transparent evaluation and future research in Bambara speech technology.

</details>


### [44] [Decomposing Reasoning Efficiency in Large Language Models](https://arxiv.org/abs/2602.09805)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: 提出一个可选的追踪框架，将令牌效率分解为可解释因素：固定令牌预算下的完成度、完成后的条件正确性、冗余度，并可进一步分解冗余度为平均言语化开销和耦合系数，以评估推理模型的令牌效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型评估仅报告最终准确率，掩盖了令牌消耗的具体情况，无法了解令牌在何处被使用或浪费，需要更精细的令牌效率评估框架。

Method: 引入可选的追踪框架，将令牌效率分解为：1) 固定令牌预算下的完成度；2) 完成后的条件正确性；3) 冗余度。当有基准元数据时，进一步将冗余度分解为平均言语化开销和耦合系数。当有推理轨迹时，添加确定性轨迹质量度量（基础性、重复性、提示复制）。

Result: 在CogniLoad上评估25个模型，发现准确率和令牌效率排名存在差异（Spearman ρ=0.63），效率差距通常由条件正确性驱动，言语化开销变化约9倍（与模型规模关系较弱）。分解揭示了不同的瓶颈特征，提示需要不同的效率干预措施。

Conclusion: 提出的框架能够深入分析令牌效率，揭示模型在令牌使用上的不同瓶颈模式，为优化推理模型的令牌效率提供有针对性的指导方向。

Abstract: Large language models trained for reasoning trade off inference tokens against accuracy, yet standard evaluations report only final accuracy, obscuring where tokens are spent or wasted. We introduce a trace-optional framework that decomposes token efficiency into interpretable factors: completion under a fixed token budget (avoiding truncation), conditional correctness given completion, and verbosity (token usage). When benchmark metadata provides per-instance workload proxies, we further factor verbosity into two components: mean verbalization overhead (tokens per work unit) and a coupling coefficient capturing how overhead scales with task workload. When reasoning traces are available, we add deterministic trace-quality measures (grounding, repetition, prompt copying) to separate degenerate looping from verbose-but-engaged reasoning, avoiding human labeling and LLM judges. Evaluating 25 models on CogniLoad, we find that accuracy and token-efficiency rankings diverge (Spearman $ρ=0.63$), efficiency gaps are often driven by conditional correctness, and verbalization overhead varies by about 9 times (only weakly related to model scale). Our decomposition reveals distinct bottleneck profiles that suggest different efficiency interventions.

</details>


### [45] [AnalyticsGPT: An LLM Workflow for Scientometric Question Answering](https://arxiv.org/abs/2602.09817)
*Khang Ly,Georgios Cheirmpos,Adrian Raudaschl,Christopher James,Seyed Amin Tabatabaei*

Main category: cs.CL

TL;DR: AnalyticsGPT是一个基于大语言模型的科学计量问答工作流，专门处理"科学学"领域的元科学问题，通过检索增强生成和智能体概念实现端到端系统。


<details>
  <summary>Details</summary>
Motivation: 科学计量问答作为科学学的一个子领域，在规划阶段面临独特挑战，包括学术实体的命名实体识别和涉及影响因子等多维度数据检索。虽然大语言模型在传统NLP任务中表现出色，但在复杂应用如任务分解、规划和推理方面也有巨大潜力，因此探索LLM在科学计量问答中的应用具有重要意义。

Method: 提出一个端到端系统，采用顺序工作流，结合检索增强生成和智能体概念。使用专有的研究绩效评估平台作为检索增强生成的数据库，通过检索相关数据来增强LLM的生成能力。系统还处理将数据合成为可呈现、结构良好的高级分析这一次要任务。

Result: 通过咨询经验丰富的领域专家并利用LLM-as-judges进行评估，提供了关于LLM在特定下游任务中有效性的宝贵见解。代码和提示已开源。

Conclusion: AnalyticsGPT展示了LLM在科学计量问答这一专业领域的应用潜力，通过结合检索增强生成和智能体工作流，能够有效处理涉及学术实体识别和多维度数据检索的复杂元科学问题。

Abstract: This paper introduces AnalyticsGPT, an intuitive and efficient large language model (LLM)-powered workflow for scientometric question answering. This underrepresented downstream task addresses the subcategory of meta-scientific questions concerning the "science of science." When compared to traditional scientific question answering based on papers, the task poses unique challenges in the planning phase. Namely, the need for named-entity recognition of academic entities within questions and multi-faceted data retrieval involving scientometric indices, e.g. impact factors. Beyond their exceptional capacity for treating traditional natural language processing tasks, LLMs have shown great potential in more complex applications, such as task decomposition and planning and reasoning. In this paper, we explore the application of LLMs to scientometric question answering, and describe an end-to-end system implementing a sequential workflow with retrieval-augmented generation and agentic concepts. We also address the secondary task of effectively synthesizing the data into presentable and well-structured high-level analyses. As a database for retrieval-augmented generation, we leverage a proprietary research performance assessment platform. For evaluation, we consult experienced subject matter experts and leverage LLMs-as-judges. In doing so, we provide valuable insights on the efficacy of LLMs towards a niche downstream task. Our (skeleton) code and prompts are available at: https://github.com/lyvykhang/llm-agents-scientometric-qa/tree/acl.

</details>


### [46] [Text summarization via global structure awareness](https://arxiv.org/abs/2602.09821)
*Jiaquan Zhang,Chaoning Zhang,Shuxu Chen,Yibei Liu,Chenghao Li,Qigan Sun,Shuai Yuan,Fachrina Dewi Puspitasari,Dongshen Han,Guoqing Wang,Sung-Ho Bae,Yang Yang*

Main category: cs.CL

TL;DR: GloSA-sum：首个通过拓扑数据分析实现全局结构感知的文本摘要方法，在保持语义核心和逻辑依赖的同时高效摘要文本


<details>
  <summary>Details</summary>
Motivation: 现有摘要研究主要关注模型改进和句子级剪枝，但往往忽视全局结构，导致连贯性破坏和下游性能减弱。一些研究使用大语言模型虽能提高准确性，但带来巨大的资源和时间成本。

Method: 1. 从句子嵌入构建语义加权图，使用持久同调识别核心语义和逻辑结构，保存在"保护池"中作为摘要骨架；2. 设计拓扑引导的迭代策略，使用轻量级代理指标近似句子重要性，避免重复高成本计算；3. 提出分层策略，整合分段级和全局摘要以增强长文本处理。

Result: 在多个数据集上的实验表明，GloSA-sum在减少冗余的同时保持了语义和逻辑完整性，在准确性和效率之间取得了平衡，并通过缩短上下文同时保留必要的推理链，进一步有益于LLM下游任务。

Conclusion: GloSA-sum是首个通过拓扑数据分析实现全局结构感知的文本摘要方法，能够高效地总结文本，同时保持语义核心和逻辑依赖，为长文档处理提供了有效的解决方案。

Abstract: Text summarization is a fundamental task in natural language processing (NLP), and the information explosion has made long-document processing increasingly demanding, making summarization essential. Existing research mainly focuses on model improvements and sentence-level pruning, but often overlooks global structure, leading to disrupted coherence and weakened downstream performance. Some studies employ large language models (LLMs), which achieve higher accuracy but incur substantial resource and time costs. To address these issues, we introduce GloSA-sum, the first summarization approach that achieves global structure awareness via topological data analysis (TDA). GloSA-sum summarizes text efficiently while preserving semantic cores and logical dependencies. Specifically, we construct a semantic-weighted graph from sentence embeddings, where persistent homology identifies core semantics and logical structures, preserved in a ``protection pool'' as the backbone for summarization. We design a topology-guided iterative strategy, where lightweight proxy metrics approximate sentence importance to avoid repeated high-cost computations, thus preserving structural integrity while improving efficiency. To further enhance long-text processing, we propose a hierarchical strategy that integrates segment-level and global summarization. Experiments on multiple datasets demonstrate that GloSA-sum reduces redundancy while preserving semantic and logical integrity, striking a balance between accuracy and efficiency, and further benefits LLM downstream tasks by shortening contexts while retaining essential reasoning chains.

</details>


### [47] [From FusHa to Folk: Exploring Cross-Lingual Transfer in Arabic Language Models](https://arxiv.org/abs/2602.09826)
*Abdulmuizz Khalak,Abderrahmane Issam,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 阿拉伯语言模型主要在标准阿拉伯语上预训练，但需要迁移到方言上。研究发现跨方言迁移存在不均衡性，受地理距离影响，且多方言训练可能产生负向干扰。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语言模型主要在标准阿拉伯语（MSA）上预训练，但实际使用中人们使用各种方言。由于方言与标准阿拉伯语的相似度不同，这给阿拉伯语言模型带来了限制，需要研究跨方言迁移的有效性。

Method: 通过3个自然语言处理任务的探测分析和表征相似性研究，评估阿拉伯语言模型的跨方言迁移能力。

Result: 迁移是可能的，但在不同方言间不均衡，部分可由地理邻近性解释。同时发现支持所有阿拉伯方言的模型存在负向干扰证据。

Conclusion: 阿拉伯方言的相似度存在问题，对阿拉伯语言模型的跨方言迁移能力提出了质疑和担忧。

Abstract: Arabic Language Models (LMs) are pretrained predominately on Modern Standard Arabic (MSA) and are expected to transfer to its dialects. While MSA as the standard written variety is commonly used in formal settings, people speak and write online in various dialects that are spread across the Arab region. This poses limitations for Arabic LMs, since its dialects vary in their similarity to MSA. In this work we study cross-lingual transfer of Arabic models using probing on 3 Natural Language Processing (NLP) Tasks, and representational similarity. Our results indicate that transfer is possible but disproportionate across dialects, which we find to be partially explained by their geographic proximity. Furthermore, we find evidence for negative interference in models trained to support all Arabic dialects. This questions their degree of similarity, and raises concerns for cross-lingual transfer in Arabic models.

</details>


### [48] [LLM Reasoning Predicts When Models Are Right: Evidence from Coding Classroom Discourse](https://arxiv.org/abs/2602.09832)
*Bakhtawar Ahtisham,Kirk Vanacore,Zhuqian Zhou,Jinsook Lee,Rene F. Kizilcec*

Main category: cs.CL

TL;DR: 利用LLM生成的推理内容来预测其自身标注的正确性，在教育对话分析中实现了有效的错误检测


<details>
  <summary>Details</summary>
Motivation: 当前LLM在教育对话自动标注中缺乏可靠的错误检测机制，需要研究如何利用模型自身的推理来判断其预测的正确性

Method: 分析30,300个教师话语，使用多个先进LLM标注教学行为并生成推理，通过TF-IDF编码推理内容，评估五种监督分类器，并利用LIWC框架分析语言特征

Result: 随机森林分类器达到F1分数0.83，成功识别大多数错误预测；正确预测使用因果语言，错误推理更多依赖认知模糊和元认知表达；句法复杂性和长度不影响可靠性

Conclusion: 基于推理的错误检测为自动化教育对话分析提供了实用且可扩展的质量控制方法

Abstract: Large Language Models (LLMs) are increasingly deployed to automatically label and analyze educational dialogue at scale, yet current pipelines lack reliable ways to detect when models are wrong. We investigate whether reasoning generated by LLMs can be used to predict the correctness of a model's own predictions. We analyze 30,300 teacher utterances from classroom dialogue, each labeled by multiple state-of-the-art LLMs with an instructional move construct and an accompanying reasoning. Using human-verified ground-truth labels, we frame the task as predicting whether a model's assigned label for a given utterance is correct. We encode LLM reasoning using Term Frequency-Inverse Document Frequency (TF-IDF) and evaluate five supervised classifiers. A Random Forest classifier achieves an F1 score of 0.83 (Recall = 0.854), successfully identifying most incorrect predictions and outperforming baselines. Training specialist detectors for specific instructional move constructs further improves performance on difficult constructs, indicating that error detection benefits from construct-specific linguistic cues. Using the Linguistic Inquiry and Word Count (LIWC) framework, we examine four linguistic markers of correctness: Causation, Differentiation, Tentativeness, and Insight. Correct predictions exhibit grounded causal language (e.g., because, therefore), while incorrect reasoning is substantially more likely to rely on epistemic hedging (e.g., might, could) and performative metacognition (e.g., think, realize). Syntactic complexity does not distinguish correct from incorrect reasoning, and longer reasoning is not more reliable. These findings demonstrate that reasoning-based error detection offers a practical and scalable approach to quality control in automated educational dialogue analysis.

</details>


### [49] [How Do People Quantify Naturally: Evidence from Mandarin Picture Description](https://arxiv.org/abs/2602.09838)
*Yayun Zhang,Guanyi Chen,Fahime Same,Saad Mahamood,Tingting He*

Main category: cs.CL

TL;DR: 研究通过图片描述任务考察汉语使用者在自然表达中的量化行为，发现物体数量、生命性和表达模态系统性地影响量化选择、精确度和策略


<details>
  <summary>Details</summary>
Motivation: 量化是日常语言使用的基本组成部分，但人们对说话者在自然表达中如何决定是否以及如何进行量化知之甚少。本研究旨在探索汉语中的量化行为，特别是在无约束的自然表达条件下。

Method: 使用基于图片的诱发描述任务，让说话者自由描述包含多个物体的场景，没有明确的计数或量化指令。研究同时考察口语和书面语两种模态，分析三个方面的量化行为：是否选择量化、量化的精确度以及采用的量化策略。

Result: 物体数量、生命性和表达模态系统性地塑造量化行为。具体而言，物体数量的增加会降低量化的可能性和精确度，而生命性指称和表达模态则选择性地调节策略选择。

Conclusion: 本研究展示了如何在无约束的表达条件下考察量化行为，并为语言表达中数量表达的进一步分析提供了自然主义数据集。

Abstract: Quantification is a fundamental component of everyday language use, yet little is known about how speakers decide whether and how to quantify in naturalistic production. We investigate quantification in Mandarin Chinese using a picture-based elicited description task in which speakers freely described scenes containing multiple objects, without explicit instructions to count or quantify. Across both spoken and written modalities, we examine three aspects of quantification: whether speakers choose to quantify at all, how precise their quantification is, and which quantificational strategies they adopt. Results show that object numerosity, animacy, and production modality systematically shape quantificational behaviour. In particular, increasing numerosity reduces both the likelihood and the precision of quantification, while animate referents and modality selectively modulate strategy choice. This study demonstrates how quantification can be examined under unconstrained production conditions and provides a naturalistic dataset for further analyses of quantity expression in language production.

</details>


### [50] [SinFoS: A Parallel Dataset for Translating Sinhala Figures of Speech](https://arxiv.org/abs/2602.09866)
*Johan Sofalas,Dilushri Pavithra,Nevidu Jayatilleke,Ruvan Weerasinghe*

Main category: cs.CL

TL;DR: 该论文介绍了包含2,344条僧伽罗语修辞手法的语料库，包含文化和跨语言标注，用于评估LLM在低资源语言文化表达翻译中的表现。


<details>
  <summary>Details</summary>
Motivation: 神经机器翻译在处理高资源语言的修辞表达时表现较好，但对于僧伽罗语等低资源语言，由于数据有限，翻译修辞手法面临挑战。需要专门的语料库来支持低资源NLP研究和文化感知的机器翻译。

Method: 构建了包含2,344条僧伽罗语修辞手法的语料库，包含文化和跨语言标注。开发了二元分类器来区分数据集中的两种修辞类型，并评估了现有LLM在该数据集上的表现。

Result: 二元分类器达到了约92%的准确率。评估发现现有LLM在处理僧伽罗语修辞手法时存在显著不足，这些模型经常难以准确传达习语含义。

Conclusion: 该数据集为低资源NLP研究和文化感知机器翻译提供了重要基准，公开数据集将促进未来研究，特别是针对低资源语言和文化特定表达的机器翻译改进。

Abstract: Figures of Speech (FoS) consist of multi-word phrases that are deeply intertwined with culture. While Neural Machine Translation (NMT) performs relatively well with the figurative expressions of high-resource languages, it often faces challenges when dealing with low-resource languages like Sinhala due to limited available data. To address this limitation, we introduce a corpus of 2,344 Sinhala figures of speech with cultural and cross-lingual annotations. We examine this dataset to classify the cultural origins of the figures of speech and to identify their cross-lingual equivalents. Additionally, we have developed a binary classifier to differentiate between two types of FOS in the dataset, achieving an accuracy rate of approximately 92%. We also evaluate the performance of existing LLMs on this dataset. Our findings reveal significant shortcomings in the current capabilities of LLMs, as these models often struggle to accurately convey idiomatic meanings. By making this dataset publicly available, we offer a crucial benchmark for future research in low-resource NLP and culturally aware machine translation.

</details>


### [51] [Steer2Edit: From Activation Steering to Component-Level Editing](https://arxiv.org/abs/2602.09870)
*Chung-En Sun,Ge Yan,Zimo Wang,Tsui-Wei Weng*

Main category: cs.CL

TL;DR: Steer2Edit：一种无需训练的方法，将引导向量从推理时控制信号转换为组件级权重编辑的诊断信号，实现更优的属性-效用权衡


<details>
  <summary>Details</summary>
Motivation: 现有引导方法通过在推理时统一修改模型内部状态来影响LLM行为，但这种方法忽略了行为通常由少量异质组件控制的事实，导致在强控制下产生不利的属性-效用权衡

Method: Steer2Edit将引导向量转换为诊断信号，用于组件级（注意力头和MLP神经元）的秩-1权重编辑，选择性地重新分配行为影响，而非统一注入引导方向

Result: 在安全对齐、幻觉缓解和推理效率方面，Steer2Edit实现了更优的属性-效用权衡：在保持下游性能的同时，安全性提升达17.2%，真实性提高9.8%，推理长度平均减少12.2%

Conclusion: Steer2Edit通过将引导信号转换为可解释、无需训练的参数更新，为表示引导和权重编辑之间建立了原则性桥梁

Abstract: Steering methods influence Large Language Model behavior by identifying semantic directions in hidden representations, but are typically realized through inference-time activation interventions that apply a fixed, global modification to the model's internal states. While effective, such interventions often induce unfavorable attribute-utility trade-offs under strong control, as they ignore the fact that many behaviors are governed by a small and heterogeneous subset of model components. We propose Steer2Edit, a theoretically grounded, training-free framework that transforms steering vectors from inference-time control signals into diagnostic signals for component-level rank-1 weight editing. Instead of uniformly injecting a steering direction during generation, Steer2Edit selectively redistributes behavioral influence across individual attention heads and MLP neurons, yielding interpretable edits that preserve the standard forward pass and remain compatible with optimized parallel inference. Across safety alignment, hallucination mitigation, and reasoning efficiency, Steer2Edit consistently achieves more favorable attribute-utility trade-offs: at matched downstream performance, it improves safety by up to 17.2%, increases truthfulness by 9.8%, and reduces reasoning length by 12.2% on average. Overall, Steer2Edit provides a principled bridge between representation steering and weight editing by translating steering signals into interpretable, training-free parameter updates.

</details>


### [52] [The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies](https://arxiv.org/abs/2602.09877)
*Chenxu Wang,Chaozhuo Li,Songyang Liu,Zejian Chen,Jinyu Hou,Ji Qi,Rui Li,Litian Zhang,Qiwei Ye,Zheng Liu,Xu Chen,Xi Zhang,Philip S. Yu*

Main category: cs.CL

TL;DR: 论文证明完全封闭的LLM多智能体系统无法同时实现持续自我进化、完全隔离和安全不变性，存在"自我进化三难困境"。


<details>
  <summary>Details</summary>
Motivation: 研究基于大语言模型的多智能体系统在实现持续自我进化和安全对齐方面的根本限制，揭示完全封闭系统无法同时满足自我进化、隔离和安全不变性的三难困境。

Method: 采用信息论框架，将安全性形式化为与人类价值分布的偏离程度；通过理论分析证明隔离自我进化会导致统计盲点；在开放智能体社区和两个封闭自进化系统中进行实证验证。

Result: 理论和实证结果表明，完全隔离的自我进化系统必然导致安全对齐的不可逆退化，存在不可避免的安全侵蚀现象。

Conclusion: 自进化AI社会存在根本限制，需要从症状驱动的安全补丁转向对内在动态风险的原则性理解，强调外部监督或新型安全保护机制的必要性。

Abstract: The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.

</details>


### [53] [AmharicIR+Instr: A Two-Dataset Resource for Neural Retrieval and Instruction Tuning](https://arxiv.org/abs/2602.09914)
*Tilahun Yeshambel,Moncef Garouani,Josiane Mothe*

Main category: cs.CL

TL;DR: 发布了两个阿姆哈拉语数据集：1）1,091个手动验证的查询-正例-负例文档三元组，用于神经检索排序；2）6,285个指令提示-响应对，用于指令跟随文本生成，支持低资源语言研究。


<details>
  <summary>Details</summary>
Motivation: 阿姆哈拉语等低资源语言缺乏高质量监督数据，限制了神经检索和生成模型的发展。需要创建专门的数据资源来支持相关研究。

Method: 检索数据集通过专家策划查询、网络查询和LLM辅助生成构建三元组，正负文档来自网络或LLM合成并由母语者验证。指令数据集使用多个LLM生成，并通过人工审查修正语法、相关性、流畅性和事实合理性。

Result: 发布了两个标准化数据集：1,091个三元组用于检索排序，6,285个指令对用于文本生成，提供CSV、JSON、JSONL格式和标准划分，支持可重复研究。

Conclusion: 这些数据集填补了阿姆哈拉语高质量监督数据的空白，支持检索、排序和生成模型研究，其构建方法可推广到其他低资源语言。

Abstract: Neural retrieval and GPT-style generative models rely on large, high-quality supervised data, which is still scarce for low-resource languages such as Amharic. We release an Amharic data resource consisting of two datasets that supports research on (i) neural retrieval-ranking and (ii) instruction-following text generation. The retrieval-ranking dataset contains 1,091 manually verified query-positive-negative document triplets drawn from diverse Amharic sources and constructed to support contrastive training and benchmarking of neural retrievers (e.g., DPR, ColBERT-style late interaction and SPLADE-style sparse neural retrieval). Triplets are created through a combination of expert-curated queries, web-derived queries, and LLM-assisted generation, with positive/negative documents selected from the web or synthesized by LLMs and then validated by native speakers. The instruction prompt-response dataset comprises 6,285 Amharic prompt-response pairs spanning multiple domains and instruction types, generated with several LLMs and refined through manual review and correction for grammaticality, relevance, fluency, and factual plausibility. We release both datasets with standardized splits and formats (CSV,JSON,JSONL) to enable reproducible work on Amharic retrieval, ranking, and generative modelling. These datasets also come with a methodology that can be generalized to other low-resource languages.

</details>


### [54] [LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations](https://arxiv.org/abs/2602.09924)
*William Lugoloobi,Thomas Foster,William Bankes,Chris Russell*

Main category: cs.CL

TL;DR: 论文研究如何利用LLM内部表示预测其自身在数学和编程任务上的成功率，从而指导更高效的推理计算，通过路由查询到不同模型可减少70%推理成本。


<details>
  <summary>Details</summary>
Motivation: 运行LLM进行扩展推理计算成本高昂，但确定哪些输入真正需要额外计算仍然具有挑战性。研究是否可以从LLM生成前的内部表示中恢复其自身成功概率，并利用这一信号指导更高效的推理。

Method: 在生成前激活上训练线性探针，预测特定策略在数学和编程任务上的成功率；使用E2H-AMC数据集比较人类和模型在相同问题上的表现差异；利用探针结果路由查询到不同模型池。

Result: 线性探针在预测模型成功率方面显著优于表面特征（如问题长度和TF-IDF）；模型编码了与人类难度不同的模型特定难度概念，且这种差异随扩展推理而增加；通过路由查询可超越最佳模型性能，同时在MATH数据集上减少高达70%的推理成本。

Conclusion: LLM的内部表示能够预测其自身成功概率，即使这些表示与人类对难度的直觉不同，仍可实现实际的效率提升。通过基于内部表示的路由机制，可以在保持性能的同时大幅降低推理成本。

Abstract: Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require additional compute remains challenging. We investigate whether their own likelihood of success is recoverable from their internal representations before generation, and if this signal can guide more efficient inference. We train linear probes on pre-generation activations to predict policy-specific success on math and coding tasks, substantially outperforming surface features such as question length and TF-IDF. Using E2H-AMC, which provides both human and model performance on identical problems, we show that models encode a model-specific notion of difficulty that is distinct from human difficulty, and that this distinction increases with extended reasoning. Leveraging these probes, we demonstrate that routing queries across a pool of models can exceed the best-performing model whilst reducing inference cost by up to 70\% on MATH, showing that internal representations enable practical efficiency gains even when they diverge from human intuitions about difficulty. Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty

</details>


### [55] [ATTNPO: Attention-Guided Process Supervision for Efficient Reasoning](https://arxiv.org/abs/2602.09953)
*Shuaiyi Nie,Siyu Ding,Wenyuan Zhang,Linhao Yu,Tianmeng Yang,Yao Chen,Tingwen Liu,Weichong Yin,Yu Sun,Hua Wu*

Main category: cs.CL

TL;DR: ATTNPO：利用模型内在注意力信号进行步骤级信用分配的轻量级过程监督RL框架，有效减少推理冗余同时提升性能


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中常出现"过度思考"问题，生成冗余推理步骤而不提升性能。现有的轨迹级长度惩罚方法无法有效缩短推理长度且会降低准确性，因为它们对所有推理步骤一视同仁，缺乏区分冗余与必要步骤的细粒度信号。过程监督方法通常资源密集且存在信用分配不准确的问题。

Method: 提出ATTNPO框架：1）识别一组特殊的注意力头，这些头自然关注必要步骤而抑制冗余步骤；2）利用这些注意力头的注意力分数，采用两种子策略：通过惩罚冗余步骤来减少过度思考，同时通过减少对必要步骤的惩罚来保持准确性。

Result: 实验结果表明，ATTNPO在9个基准测试上显著减少了推理长度，同时显著提升了性能。

Conclusion: ATTNPO通过利用模型内在的注意力信号进行步骤级信用分配，有效解决了推理模型中的过度思考问题，实现了推理长度减少和性能提升的双重目标。

Abstract: Large reasoning models trained with reinforcement learning and verifiable rewards (RLVR) achieve strong performance on complex reasoning tasks, yet often overthink, generating redundant reasoning without performance gains. Existing trajectory-level length penalties often fail to effectively shorten reasoning length and degrade accuracy, as they uniformly treat all reasoning steps and lack fine-grained signals to distinguish redundancy from necessity. Meanwhile, process-supervised methods are typically resource-intensive and suffer from inaccurate credit assignment. To address these issues, we propose ATTNPO, a low-overhead process-supervised RL framework that leverages the model's intrinsic attention signals for step-level credit assignment. We first identify a set of special attention heads that naturally focus on essential steps while suppressing redundant ones. By leveraging the attention scores of these heads, We then employ two sub-strategies to mitigate overthinking by discouraging redundant steps while preserving accuracy by reducing penalties on essential steps. Experimental results show that ATTNPO substantially reduces reasoning length while significantly improving performance across 9 benchmarks.

</details>


### [56] [ViMultiChoice: Toward a Method That Gives Explanation for Multiple-Choice Reading Comprehension in Vietnamese](https://arxiv.org/abs/2602.09961)
*Trung Tien Cao,Lam Minh Thai,Nghia Hieu Nguyen,Duc-Vu Nguyen,Ngan Luu-Thuy Nguyen*

Main category: cs.CL

TL;DR: 提出ViMultiChoice方法，联合预测答案和生成解释，在越南语多选阅读理解任务上达到SotA性能


<details>
  <summary>Details</summary>
Motivation: 现有MCRC模型通常缺乏解释其选择背后推理的能力，需要专门针对越南语的数据集和方法来提升模型的解释生成能力

Method: 提出ViMultiChoice方法，专门为越南语阅读理解设计，联合预测正确答案并生成相应解释

Result: ViMultiChoice在ViMMRC 2.0基准和新数据集上均优于现有MCRC基线，达到SotA性能；联合训练选项决策和解释生成显著提高了多选准确率

Conclusion: 提出的ViMultiChoice方法有效解决了越南语MCRC模型的解释生成问题，联合训练策略能显著提升模型性能，为可解释的阅读理解系统提供了有效解决方案

Abstract: Multiple-choice Reading Comprehension (MCRC) models aim to select the correct answer from a set of candidate options for a given question. However, they typically lack the ability to explain the reasoning behind their choices. In this paper, we introduce a novel Vietnamese dataset designed to train and evaluate MCRC models with explanation generation capabilities. Furthermore, we propose ViMultiChoice, a new method specifically designed for modeling Vietnamese reading comprehension that jointly predicts the correct answer and generates a corresponding explanation. Experimental results demonstrate that ViMultiChoice outperforms existing MCRC baselines, achieving state-of-the-art (SotA) performance on both the ViMMRC 2.0 benchmark and the newly introduced dataset. Additionally, we show that jointly training option decision and explanation generation leads to significant improvements in multiple-choice accuracy.

</details>


### [57] [A Unified Assessment of the Poverty of the Stimulus Argument for Neural Language Models](https://arxiv.org/abs/2602.09992)
*Xiulin Yang,Arianna Bisazza,Nathan Schneider,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 神经语言模型在有限数据下能学习到类似儿童的句法泛化能力，但效率较低，挑战了"刺激贫乏假说"认为必须依赖先天句法知识的观点。


<details>
  <summary>Details</summary>
Motivation: 检验"刺激贫乏假说"的核心主张：儿童是否必须依赖先天语言约束才能从有限输入中学习句法泛化。通过神经语言模型这一缺乏语言特定约束的计算系统来测试这一长期争议。

Method: 构建POSHBench训练评估套件，针对英语问句形成、移位岛等PoSH核心现象。在1000-5000万词的发展合理文本上训练Transformer模型，并测试三种认知启发的归纳偏置。

Result: 神经模型在所有现象上都显示出泛化能力（即使没有直接正面证据），但数据效率低于儿童且泛化较弱。认知偏置提升了整体句法能力但未改善POSHBench表现。

Conclusion: 先天句法不是实现泛化的唯一途径，但达到人类水平的数据效率可能需要超出当前测试的归纳偏置。挑战了PoSH的极端主张，同时指出了人类语言学习的独特性。

Abstract: How can children acquire native-level syntax from limited input? According to the Poverty of the Stimulus Hypothesis (PoSH), the linguistic input children receive is insufficient to explain certain generalizations that are robustly learned; innate linguistic constraints, many have argued, are thus necessary to explain language learning. Neural language models, which lack such language-specific constraints in their design, offer a computational test of this longstanding (but controversial) claim. We introduce \poshbench, a training-and-evaluation suite targeting question formation, islands to movement, and other English phenomena at the center of the PoSH arguments. Training Transformer models on 10--50M words of developmentally plausible text, we find indications of generalization on all phenomena even without direct positive evidence -- yet neural models remain less data-efficient and their generalizations are weaker than those of children. We further enhance our models with three recently proposed cognitively motivated inductive biases. We find these biases improve general syntactic competence but not \poshbench performance. Our findings challenge the claim that innate syntax is the only possible route to generalization, while suggesting that human-like data efficiency requires inductive biases beyond those tested here.

</details>


### [58] [ViSpeechFormer: A Phonemic Approach for Vietnamese Automatic Speech Recognition](https://arxiv.org/abs/2602.10003)
*Khoa Anh Nguyen,Long Minh Hoang,Nghia Hieu Nguyen,Luan Thanh Nguyen,Ngan Luu-Thuy Nguyen*

Main category: cs.CL

TL;DR: ViSpeechFormer是首个基于音素的越南语语音识别框架，利用越南语的高字形-音素透明度，在公开数据集上表现出色，泛化能力强，受训练偏差影响小。


<details>
  <summary>Details</summary>
Motivation: 越南语具有高度透明的字形-音素对应关系（每个字形最多对应一个音素），这为开发基于音素的语音识别系统提供了独特优势。目前还没有专门针对越南语的音素建模ASR框架。

Method: 提出ViSpeechFormer（越南语音转换器），这是一个基于音素的越南语自动语音识别方法。该方法利用越南语的高字形-音素透明度，明确建模音素表示。

Result: 在两个公开的越南语ASR数据集上，ViSpeechFormer表现出强大的性能，对词汇外单词有更好的泛化能力，受训练偏差的影响较小。

Conclusion: 基于音素的方法为越南语ASR提供了有效的新范式，这种范式对于其他具有语音正字法的语言也很有前景。代码将在论文被接受后发布。

Abstract: Vietnamese has a phonetic orthography, where each grapheme corresponds to at most one phoneme and vice versa. Exploiting this high grapheme-phoneme transparency, we propose ViSpeechFormer (\textbf{Vi}etnamese \textbf{Speech} Trans\textbf{Former}), a phoneme-based approach for Vietnamese Automatic Speech Recognition (ASR). To the best of our knowledge, this is the first Vietnamese ASR framework that explicitly models phonemic representations. Experiments on two publicly available Vietnamese ASR datasets show that ViSpeechFormer achieves strong performance, generalizes better to out-of-vocabulary words, and is less affected by training bias. This phoneme-based paradigm is also promising for other languages with phonetic orthographies. The code will be released upon acceptance of this paper.

</details>


### [59] [SCORE: Specificity, Context Utilization, Robustness, and Relevance for Reference-Free LLM Evaluation](https://arxiv.org/abs/2602.10017)
*Homaira Huda Shomee,Rochana Chaturvedi,Yangxinyu Xie,Tanwi Mallick*

Main category: cs.CL

TL;DR: 本文提出一个多维无参考评估框架，用于评估大语言模型在自然灾害响应等高风险领域特定任务中的表现，重点关注回答的细节性、鲁棒性、相关性和上下文利用能力。


<details>
  <summary>Details</summary>
Motivation: 现有RAG和开放式问答评估框架主要依赖表面相似性、事实一致性或语义相关性，无法评估模型在领域敏感决策中是否提供了必要的具体信息。在高风险领域特定应用（如自然灾害响应）中，有效回答必须传达细粒度、决策关键细节。

Method: 提出一个多维无参考评估框架，从四个互补维度评估LLM输出：特异性、对改写和语义扰动的鲁棒性、答案相关性、上下文利用。构建包含1,412个领域特定问答对的数据集，涵盖40个专业角色和7种自然灾害类型，并进行人工评估验证。

Result: 研究结果表明，没有任何单一指标能够充分独立地捕捉答案质量，凸显了在高风险应用中部署LLM时需要结构化、多指标评估框架的必要性。人工评估显示了领域特定开放式评估固有的主观性。

Conclusion: 在高风险领域特定应用中部署LLM时，需要结构化、多指标评估框架来全面评估模型表现，单一指标不足以捕捉答案质量。领域特定开放式评估具有主观性，需要结合人工评估验证。

Abstract: Large language models (LLMs) are increasingly used to support question answering and decision-making in high-stakes, domain-specific settings such as natural hazard response and infrastructure planning, where effective answers must convey fine-grained, decision-critical details. However, existing evaluation frameworks for retrieval-augmented generation (RAG) and open-ended question answering primarily rely on surface-level similarity, factual consistency, or semantic relevance, and often fail to assess whether responses provide the specific information required for domain-sensitive decisions. To address this gap, we propose a multi-dimensional, reference-free evaluation framework that assesses LLM outputs along four complementary dimensions: specificity, robustness to paraphrasing and semantic perturbations, answer relevance, and context utilization. We introduce a curated dataset of 1,412 domain-specific question-answer pairs spanning 40 professional roles and seven natural hazard types to support systematic evaluation. We further conduct human evaluation to assess inter-annotator agreement and alignment between model outputs and human judgments, which highlights the inherent subjectivity of open-ended, domain-specific evaluation. Our results show that no single metric sufficiently captures answer quality in isolation and demonstrate the need for structured, multi-metric evaluation frameworks when deploying LLMs in high-stakes applications.

</details>


### [60] [Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference](https://arxiv.org/abs/2602.10021)
*Wenxuan Xie,Yujia Wang,Xin Tan,Chaochao Lu,Xia Hu,Xuhong Wang*

Main category: cs.CL

TL;DR: DRIFT提出了一种双模型架构，通过轻量级知识模型动态压缩文档为隐式事实标记，从而解耦知识提取与推理过程，有效扩展LLM的上下文窗口和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如RAG和知识编辑）在将动态知识整合到LLM中存在局限性：有限上下文窗口、检索器噪声、灾难性遗忘等问题，需要一种能解耦知识提取与推理的新方法。

Method: 提出DRIFT双模型架构：1）轻量级知识模型根据查询动态压缩文档块为隐式事实标记；2）将这些密集表示投影到推理模型的嵌入空间，替代原始冗余文本；3）保持推理准确性同时减少上下文负担。

Result: 在长上下文任务上显著提升性能，优于同等规模模型的强基线，提供可扩展且高效的范式来扩展LLM的有效上下文窗口和推理能力。

Conclusion: DRIFT通过显式解耦知识提取与推理过程，为LLM整合动态知识提供了创新解决方案，在保持准确性的同时有效扩展了上下文处理能力，代码已开源。

Abstract: The integration of extensive, dynamic knowledge into Large Language Models (LLMs) remains a significant challenge due to the inherent entanglement of factual data and reasoning patterns. Existing solutions, ranging from non-parametric Retrieval-Augmented Generation (RAG) to parametric knowledge editing, are often constrained in practice by finite context windows, retriever noise, or the risk of catastrophic forgetting. In this paper, we propose DRIFT, a novel dual-model architecture designed to explicitly decouple knowledge extraction from the reasoning process. Unlike static prompt compression, DRIFT employs a lightweight knowledge model to dynamically compress document chunks into implicit fact tokens conditioned on the query. These dense representations are projected into the reasoning model's embedding space, replacing raw, redundant text while maintaining inference accuracy. Extensive experiments show that DRIFT significantly improves performance on long-context tasks, outperforming strong baselines among comparably sized models. Our approach provides a scalable and efficient paradigm for extending the effective context window and reasoning capabilities of LLMs. Our code is available at https://github.com/Lancelot-Xie/DRIFT.

</details>


### [61] [MEVER: Multi-Modal and Explainable Claim Verification with Graph-based Evidence Retrieval](https://arxiv.org/abs/2602.10023)
*Delvin Ce Zhang,Suhan Cui,Zhelin Chu,Xianren Zhang,Dongwon Lee*

Main category: cs.CL

TL;DR: 提出一个联合实现证据检索、多模态声明验证和解释生成的新模型，并创建AI领域数据集AIChartClaim


<details>
  <summary>Details</summary>
Motivation: 现有声明验证工作大多仅关注文本证据或忽略可解释性，导致验证结果不准确且缺乏说服力。需要联合多模态推理（文本和视觉证据）并提供解释来增强透明性。

Method: 1) 构建双层多模态图进行证据检索，设计图像到文本和文本到图像的推理；2) 提出token级和证据级融合进行多模态声明验证；3) 引入多模态Fusion-in-Decoder进行解释生成；4) 创建AI领域数据集AIChartClaim。

Result: 实验证明了模型的有效性，但具体性能指标未在摘要中说明。

Conclusion: 该模型能够联合处理多模态证据检索、声明验证和解释生成，解决了现有方法的局限性，并通过创建AI领域数据集丰富了声明验证社区。

Abstract: Verifying the truthfulness of claims usually requires joint multi-modal reasoning over both textual and visual evidence, such as analyzing both textual caption and chart image for claim verification. In addition, to make the reasoning process transparent, a textual explanation is necessary to justify the verification result. However, most claim verification works mainly focus on the reasoning over textual evidence only or ignore the explainability, resulting in inaccurate and unconvincing verification. To address this problem, we propose a novel model that jointly achieves evidence retrieval, multi-modal claim verification, and explanation generation. For evidence retrieval, we construct a two-layer multi-modal graph for claims and evidence, where we design image-to-text and text-to-image reasoning for multi-modal retrieval. For claim verification, we propose token- and evidence-level fusion to integrate claim and evidence embeddings for multi-modal verification. For explanation generation, we introduce multi-modal Fusion-in-Decoder for explainability. Finally, since almost all the datasets are in general domain, we create a scientific dataset, AIChartClaim, in AI domain to complement claim verification community. Experiments show the strength of our model.

</details>


### [62] [Anagent For Enhancing Scientific Table & Figure Analysis](https://arxiv.org/abs/2602.10081)
*Xuehang Guo,Zhiyong Lu,Tom Hope,Qingyun Wang*

Main category: cs.CL

TL;DR: 提出了AnaBench基准和Anagent多智能体框架，用于解决科学图表分析中的复杂挑战，通过四个专门智能体协作实现高质量分析。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在科学图表分析方面存在困难，需要处理多模态知识、整合不同来源证据、基于领域知识推理，但科学表格和图形的复杂性、异质性结构和长上下文需求构成了根本障碍。

Method: 提出Anagent多智能体框架，包含四个专门智能体：Planner（任务分解）、Expert（信息检索）、Solver（信息合成分析）、Critic（迭代优化）。采用监督微调和专门强化学习的模块化训练策略。

Result: 在170个子领域的全面评估中，Anagent在无需训练设置下提升13.43%，经过微调后提升42.12%，显示任务导向推理和上下文感知问题解决对高质量科学图表分析至关重要。

Conclusion: Anagent框架通过多智能体协作和专门训练策略，显著提升了科学图表分析能力，为解决复杂科学分析任务提供了有效解决方案。

Abstract: In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heterogeneous structures and long-context requirements, pose fundamental obstacles to scientific table \& figure analysis. To quantify these challenges, we introduce AnaBench, a large-scale benchmark featuring $63,178$ instances from nine scientific domains, systematically categorized along seven complexity dimensions. To tackle these challenges, we propose Anagent, a multi-agent framework for enhanced scientific table \& figure analysis through four specialized agents: Planner decomposes tasks into actionable subtasks, Expert retrieves task-specific information through targeted tool execution, Solver synthesizes information to generate coherent analysis, and Critic performs iterative refinement through five-dimensional quality assessment. We further develop modular training strategies that leverage supervised finetuning and specialized reinforcement learning to optimize individual capabilities while maintaining effective collaboration. Comprehensive evaluation across 170 subdomains demonstrates that Anagent achieves substantial improvements, up to $\uparrow 13.43\%$ in training-free settings and $\uparrow 42.12\%$ with finetuning, while revealing that task-oriented reasoning and context-aware problem-solving are essential for high-quality scientific table \& figure analysis. Our project page: https://xhguo7.github.io/Anagent/.

</details>


### [63] [Quantum-Audit: Evaluating the Reasoning Limits of LLMs on Quantum Computing](https://arxiv.org/abs/2602.10092)
*Mohamed Afane,Kayla Laufer,Wenqi Wei,Ying Mao,Junaid Farooq,Ying Wang,Juntao Chen*

Main category: cs.CL

TL;DR: Quantum-Audit是一个包含2700个问题的量子计算概念理解基准测试，评估了26个模型，发现顶级模型在专家编写问题上表现下降，且在纠正错误前提方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 语言模型已成为量子计算教育和研究的实用工具，但现有基准主要评估量子代码生成和电路设计，缺乏对量子计算概念理解能力的系统测量。

Method: 创建包含2700个问题的Quantum-Audit基准：1000个专家编写问题、1000个LLM从研究论文提取并经专家验证的问题、350个开放式问题和350个包含错误前提的问题。评估了26个领先组织的模型。

Result: 人类参与者得分23%-86%，专家平均74%。最佳模型Claude Opus 4.5达到84%准确率，但在专家编写问题上比LLM生成问题平均下降12个百分点。在安全等高级主题上表现降至73%，在纠正错误前提的任务中准确率低于66%。

Conclusion: 虽然顶级模型在量子计算概念理解上能超越专家平均水平，但在专家编写问题和高级主题上表现下降，且经常接受而非纠正错误前提，表明模型在批判性推理方面存在不足。

Abstract: Language models have become practical tools for quantum computing education and research, from summarizing technical papers to explaining theoretical concepts and answering questions about recent developments in the field. While existing benchmarks evaluate quantum code generation and circuit design, their understanding of quantum computing concepts has not been systematically measured. Quantum-Audit addresses this gap with 2,700 questions covering core quantum computing topics. We evaluate 26 models from leading organizations. Our benchmark comprises 1,000 expert-written questions, 1,000 questions extracted from research papers using LLMs and validated by experts, plus an additional 700 questions including 350 open-ended questions and 350 questions with false premises to test whether models can correct erroneous assumptions. Human participants scored between 23% and 86%, with experts averaging 74%. Top-performing models exceeded the expert average, with Claude Opus 4.5 reaching 84% accuracy, though top models showed an average 12-point accuracy drop on expert-written questions compared to LLM-generated ones. Performance declined further on advanced topics, dropping to 73% on security questions. Additionally, models frequently accepted and reinforced false premises embedded in questions instead of identifying them, with accuracy below 66% on these critical reasoning tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [64] [Feasible Static Workspace Optimization of Tendon Driven Continuum Robot based on Euclidean norm](https://arxiv.org/abs/2602.09046)
*Mohammad Jabari,Carmen Visconte,Giuseppe Quaglia,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出一种基于可行静态工作空间的肌腱驱动连续体机器人优化设计方法，通过遗传算法优化肌腱力以最大化工作空间，并在外力作用下验证有效性。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动连续体机器人的性能高度依赖于肌腱力的配置，特别是在存在外部载荷（力和扭矩）的情况下。传统设计方法可能无法充分利用机器人的工作空间潜力，因此需要一种系统化的优化方法来最大化机器人在实际工作条件下的可行静态工作空间。

Method: 采用两段八肌腱结构（每段四个肌腱），将肌腱力作为设计变量，可行静态工作空间作为优化目标。使用遗传算法优化方法，最大化机器人末端位置的欧几里得范数在工作空间上的积分。在仿真中考虑了外部载荷（力和扭矩）的影响。

Result: 仿真结果表明，所提出的方法能够有效识别最优的肌腱力配置，即使在外部力和扭矩的作用下，也能最大化肌腱驱动连续体机器人的可行静态工作空间。

Conclusion: 基于可行静态工作空间的优化方法为肌腱驱动连续体机器人的设计提供了有效框架，能够在考虑实际工作条件（包括外部载荷）的情况下，系统化地优化肌腱力配置以最大化工作空间性能。

Abstract: This paper focuses on the optimal design of a tendon-driven continuum robot (TDCR) based on its feasible static workspace (FSW). The TDCR under consideration is a two-segment robot driven by eight tendons, with four tendon actuators per segment. Tendon forces are treated as design variables, while the feasible static workspace (FSW) serves as the optimization objective. To determine the robot's feasible static workspace, a genetic algorithm optimization approach is employed to maximize a Euclidian norm of the TDCR's tip position over the workspace. During the simulations, the robot is subjected to external loads, including torques and forces. The results demonstrate the effectiveness of the proposed method in identifying optimal tendon forces to maximize the feasible static workspace, even under the influence of external forces and torques.

</details>


### [65] [Legs Over Arms: On the Predictive Value of Lower-Body Pose for Human Trajectory Prediction from Egocentric Robot Perception](https://arxiv.org/abs/2602.09076)
*Nhat Le,Daeun Song,Xuesu Xiao*

Main category: cs.RO

TL;DR: 通过分析人体骨骼特征（特别是下肢3D关键点）来预测人类轨迹，相比传统点质量方法可降低13%平均位移误差，为社交机器人导航提供有效感知策略。


<details>
  <summary>Details</summary>
Motivation: 现有的人类轨迹预测方法大多将人视为点质量，忽略了人体骨骼结构信息。本文旨在探索利用不同骨骼特征（2D/3D关键点和生物力学线索）来提高预测精度，为社交机器人导航提供更好的感知能力。

Method: 系统评估了2D和3D骨骼关键点以及衍生的生物力学线索作为额外输入的预测效用。在JRDB数据集和新的360度全景视频社交导航数据集上进行综合研究，重点关注下肢3D关键点，并分析2D关键点从等距柱面全景图像中提取的效果。

Result: 聚焦下肢3D关键点可使平均位移误差降低13%；在3D关键点输入基础上增加生物力学线索可进一步改善1-4%性能；使用从全景图像提取的2D关键点输入时性能提升依然存在，表明单目环绕视觉能捕捉到运动预测的有用线索。

Conclusion: 机器人通过观察人类腿部可以有效预测其运动，这为设计社交机器人导航的感知能力提供了可行的见解。下肢骨骼特征包含丰富的运动信息，单目全景视觉足以捕捉这些线索。

Abstract: Predicting human trajectory is crucial for social robot navigation in crowded environments. While most existing approaches treat human as point mass, we present a study on multi-agent trajectory prediction that leverages different human skeletal features for improved forecast accuracy. In particular, we systematically evaluate the predictive utility of 2D and 3D skeletal keypoints and derived biomechanical cues as additional inputs. Through a comprehensive study on the JRDB dataset and another new dataset for social navigation with 360-degree panoramic videos, we find that focusing on lower-body 3D keypoints yields a 13% reduction in Average Displacement Error and augmenting 3D keypoint inputs with corresponding biomechanical cues provides a further 1-4% improvement. Notably, the performance gain persists when using 2D keypoint inputs extracted from equirectangular panoramic images, indicating that monocular surround vision can capture informative cues for motion forecasting. Our finding that robots can forecast human movement efficiently by watching their legs provides actionable insights for designing sensing capabilities for social robot navigation.

</details>


### [66] [Agile asymmetric multi-legged locomotion: contact planning via geometric mechanics and spin model duality](https://arxiv.org/abs/2602.09123)
*Jackson Habala,Gabriel B. Margolis,Tianyu Wang,Pratyush Bhatt,Juntao He,Naheel Naeem,Zhaochen Xu,Pulkit Agrawal,Daniel I. Goldman,Di Luo,Baxi Chong*

Main category: cs.RO

TL;DR: 提出一个基于几何力学和统计力学自旋模型对偶性的多足机器人控制框架，发现六足机器人的非对称步态策略，速度比传统步态提升50%


<details>
  <summary>Details</summary>
Motivation: 当前多足机器人研究集中在双足或四足机器人，而更多腿的机器人有潜力提升运动性能。缺乏解释何时以及如何利用额外腿来改进性能的原则性控制框架，现有方法无法利用高维系统的新对称性和控制机会。

Method: 使用几何力学将接触丰富的运动规划简化为图优化问题，并提出统计力学中的自旋模型对偶框架来利用对称性破缺并指导最优步态重组。

Result: 为六足机器人识别出非对称运动策略，达到0.61体长/周期的前进速度（比传统步态提升50%）。非对称性体现在控制和硬件两个层面：控制层面身体方向在快速顺时针和慢速逆时针转向阶段之间非对称振荡；硬件层面同一侧的两条腿可以保持非驱动状态，用刚性部件替代而不降低性能。

Conclusion: 通过数值模拟和机器人物理实验验证了该框架，揭示了在高维具身系统中通过对称性重构出现的新型运动行为，为多足机器人控制提供了原则性框架。

Abstract: Legged robot research is presently focused on bipedal or quadrupedal robots, despite capabilities to build robots with many more legs to potentially improve locomotion performance. This imbalance is not necessarily due to hardware limitations, but rather to the absence of principled control frameworks that explain when and how additional legs improve locomotion performance. In multi-legged systems, coordinating many simultaneous contacts introduces a severe curse of dimensionality that challenges existing modeling and control approaches. As an alternative, multi-legged robots are typically controlled using low-dimensional gaits originally developed for bipeds or quadrupeds. These strategies fail to exploit the new symmetries and control opportunities that emerge in higher-dimensional systems. In this work, we develop a principled framework for discovering new control structures in multi-legged locomotion. We use geometric mechanics to reduce contact-rich locomotion planning to a graph optimization problem, and propose a spin model duality framework from statistical mechanics to exploit symmetry breaking and guide optimal gait reorganization. Using this approach, we identify an asymmetric locomotion strategy for a hexapod robot that achieves a forward speed of 0.61 body lengths per cycle (a 50% improvement over conventional gaits). The resulting asymmetry appears at both the control and hardware levels. At the control level, the body orientation oscillates asymmetrically between fast clockwise and slow counterclockwise turning phases for forward locomotion. At the hardware level, two legs on the same side remain unactuated and can be replaced with rigid parts without degrading performance. Numerical simulations and robophysical experiments validate the framework and reveal novel locomotion behaviors that emerge from symmetry reforming in high-dimensional embodied systems.

</details>


### [67] [SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes](https://arxiv.org/abs/2602.09153)
*Nicholas Pfaff,Thomas Cohn,Sergey Zakharov,Rick Cory,Russ Tedrake*

Main category: cs.RO

TL;DR: SceneSmith是一个分层代理框架，通过VLM代理（设计师、批评家、编排者）的交互，从自然语言提示生成仿真就绪的室内环境，显著提升了场景的多样性和物理复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有仿真环境无法捕捉真实室内空间的多样性和物理复杂性，当前场景合成方法产生的房间缺乏密集杂物、可动家具和机器人操作所需的物理属性。

Method: 采用分层代理框架，通过设计师、批评家、编排者三个VLM代理的交互，分阶段构建场景：从建筑布局到家具摆放再到小物品填充，集成文本到3D合成、数据集检索和物理属性估计。

Result: 生成的对象数量比现有方法多3-6倍，物体间碰撞率低于2%，96%的物体在物理仿真中保持稳定。用户研究中获得92%的平均真实感和91%的平均提示忠实度胜率。

Conclusion: SceneSmith能够生成高质量、物理真实的仿真环境，可用于端到端的机器人策略评估，显著提升了室内机器人训练和评估的仿真能力。

Abstract: Simulation has become a key tool for training and evaluating home robots at scale, yet existing environments fail to capture the diversity and physical complexity of real indoor spaces. Current scene synthesis methods produce sparsely furnished rooms that lack the dense clutter, articulated furniture, and physical properties essential for robotic manipulation. We introduce SceneSmith, a hierarchical agentic framework that generates simulation-ready indoor environments from natural language prompts. SceneSmith constructs scenes through successive stages$\unicode{x2013}$from architectural layout to furniture placement to small object population$\unicode{x2013}$each implemented as an interaction among VLM agents: designer, critic, and orchestrator. The framework tightly integrates asset generation through text-to-3D synthesis for static objects, dataset retrieval for articulated objects, and physical property estimation. SceneSmith generates 3-6x more objects than prior methods, with <2% inter-object collisions and 96% of objects remaining stable under physics simulation. In a user study with 205 participants, it achieves 92% average realism and 91% average prompt faithfulness win rates against baselines. We further demonstrate that these environments can be used in an end-to-end pipeline for automatic robot policy evaluation.

</details>


### [68] [Elements of Robot Morphology: Supporting Designers in Robot Form Exploration](https://arxiv.org/abs/2602.09203)
*Amy Koike,Ge,Guo,Xinning He,Callie Y. Kim,Dakota Sullivan,Bilge Mutlu*

Main category: cs.RO

TL;DR: 提出了机器人形态学框架（Elements of Robot Morphology）和实体探索工具（Morphology Exploration Blocks），用于系统化探索机器人形态设计


<details>
  <summary>Details</summary>
Motivation: 机器人形态是HRI中的关键设计空间，影响机器人功能、表达和交互，但目前缺乏系统化的形态探索框架

Method: 1. 分析现有机器人，提出包含感知、关节、末端执行器、移动和结构五个基本元素的框架；2. 开发实体探索积木（MEB）支持动手协作实验

Result: 通过案例研究和设计工作坊评估，证明该框架和工具支持分析、构思、反思和协作机器人设计

Conclusion: 提出的机器人形态学框架和实体探索工具填补了机器人形态系统化设计方法的空白，促进了协作式机器人设计探索

Abstract: Robot morphology, the form, shape, and structure of robots, is a key design space in human-robot interaction (HRI), shaping how robots function, express themselves, and interact with people. Yet, despite its importance, little is known about how design frameworks can guide systematic form exploration. To address this gap, we introduce Elements of Robot Morphology, a framework that identifies five fundamental elements: perception, articulation, end effectors, locomotion, and structure. Derived from an analysis of existing robots, the framework supports structured exploration of diverse robot forms. To operationalize the framework, we developed Morphology Exploration Blocks (MEB), a set of tangible blocks that enable hands-on, collaborative experimentation with robot morphologies. We evaluate the framework and toolkit through a case study and design workshops, showing how they support analysis, ideation, reflection, and collaborative robot design.

</details>


### [69] [Risk-Aware Obstacle Avoidance Algorithm for Real-Time Applications](https://arxiv.org/abs/2602.09204)
*Ozan Kaya,Emir Cem Gezer,Roger Skjetne,Ingrid Bouwer Utne*

Main category: cs.RO

TL;DR: 提出了一种用于自主水面舰艇的混合风险感知导航架构，结合概率障碍物建模与平滑轨迹优化，通过风险偏置RRT*规划器和B样条优化实现安全导航。


<details>
  <summary>Details</summary>
Motivation: 在变化的海洋环境中，自主系统需要在不确定性下进行感知、推理和行动。传统基于LIDAR或视觉的导航方法在操作安全性和自主性方面存在局限，需要能够动态适应环境风险变化的解决方案。

Method: 1. 构建概率风险地图，捕捉障碍物接近度和动态物体行为；2. 使用风险偏置RRT*规划器生成无碰撞路径，提供三种重新布线模式：最小化路径长度、最小化风险、优化路径长度与总风险组合；3. 采用B样条算法细化路径，确保轨迹连续性。

Result: 在包含静态和动态障碍物的实验场景中评估，系统能够安全导航、保持平滑轨迹并动态适应变化的环境风险。相比传统LIDAR或视觉导航方法，在操作安全性和自主性方面有改进。

Conclusion: 该混合风险感知导航架构为不确定和动态环境中的风险感知自主车辆任务提供了有前景的解决方案，展示了在安全导航和自适应能力方面的优势。

Abstract: Robust navigation in changing marine environments requires autonomous systems capable of perceiving, reasoning, and acting under uncertainty. This study introduces a hybrid risk-aware navigation architecture that integrates probabilistic modeling of obstacles along the vehicle path with smooth trajectory optimization for autonomous surface vessels. The system constructs probabilistic risk maps that capture both obstacle proximity and the behavior of dynamic objects. A risk-biased Rapidly Exploring Random Tree (RRT) planner leverages these maps to generate collision-free paths, which are subsequently refined using B-spline algorithms to ensure trajectory continuity. Three distinct RRT* rewiring modes are implemented based on the cost function: minimizing the path length, minimizing risk, and optimizing a combination of the path length and total risk. The framework is evaluated in experimental scenarios containing both static and dynamic obstacles. The results demonstrate the system's ability to navigate safely, maintain smooth trajectories, and dynamically adapt to changing environmental risks. Compared with conventional LIDAR or vision-only navigation approaches, the proposed method shows improvements in operational safety and autonomy, establishing it as a promising solution for risk-aware autonomous vehicle missions in uncertain and dynamic environments.

</details>


### [70] [From Legible to Inscrutable Trajectories: (Il)legible Motion Planning Accounting for Multiple Observers](https://arxiv.org/abs/2602.09227)
*Ananya Yammanuru,Maria Lusardi,Nancy M. Amato,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 论文提出MMLO-LMP问题：在多观察者、不同动机和有限可见性的混合动机环境中，规划既对友好观察者可读又对敌对观察者不可读的机器人轨迹，并开发了DUBIOUS轨迹优化器来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 在现实环境中，机器人需要面对多个观察者，这些观察者可能具有不同的动机（合作或对抗），并且每个观察者只能看到环境的部分区域。传统方法要么追求完全可读性（合作环境），要么追求完全不可读性（对抗环境），无法处理这种混合动机和有限可见性的复杂场景。

Method: 提出MMLO-LMP（混合动机有限可见性可读运动规划）问题框架，并开发DUBIOUS轨迹优化器。该方法考虑多个观察者的不同动机（正面/负面）和各自的可见性限制，生成既能向友好观察者清晰传达意图，又能对敌对观察者隐藏意图的轨迹。

Result: DUBIOUS能够生成平衡可读性与观察者动机和有限可见区域的轨迹。实验结果表明该方法在混合动机环境中有效，能够根据观察者的不同动机和可见性限制调整轨迹的可读性。

Conclusion: MMLO-LMP问题框架和DUBIOUS优化器为解决混合动机环境中的可读运动规划提供了有效方案。未来工作包括扩展场景，如移动观察者和观察者团队协作等变体。

Abstract: In cooperative environments, such as in factories or assistive scenarios, it is important for a robot to communicate its intentions to observers, who could be either other humans or robots. A legible trajectory allows an observer to quickly and accurately predict an agent's intention. In adversarial environments, such as in military operations or games, it is important for a robot to not communicate its intentions to observers. An illegible trajectory leads an observer to incorrectly predict the agent's intention or delays when an observer is able to make a correct prediction about the agent's intention. However, in some environments there are multiple observers, each of whom may be able to see only part of the environment, and each of whom may have different motives. In this work, we introduce the Mixed-Motive Limited-Observability Legible Motion Planning (MMLO-LMP) problem, which requires a motion planner to generate a trajectory that is legible to observers with positive motives and illegible to observers with negative motives while also considering the visibility limitations of each observer. We highlight multiple strategies an agent can take while still achieving the problem objective. We also present DUBIOUS, a trajectory optimizer that solves MMLO-LMP. Our results show that DUBIOUS can generate trajectories that balance legibility with the motives and limited visibility regions of the observers. Future work includes many variations of MMLO-LMP, including moving observers and observer teaming.

</details>


### [71] [STaR: Scalable Task-Conditioned Retrieval for Long-Horizon Multimodal Robot Memory](https://arxiv.org/abs/2602.09255)
*Mingfeng Yuan,Hao Zhang,Mahan Mohammadi,Runhao Li,Jinjun Shan,Steven L. Waslander*

Main category: cs.RO

TL;DR: STaR：一个面向移动机器人的智能推理框架，通过构建任务无关的多模态长期记忆和基于信息瓶颈的可扩展检索算法，支持开放指令下的长期规划和导航推理。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在开放动态场景中长期部署时，需要构建可扩展的长期记忆系统，以支持基于开放指令的规划、检索和推理，同时产生精确可执行的导航答案。

Method: 提出STaR框架：(1) 构建任务无关的多模态长期记忆，保留细粒度环境语义；(2) 引入基于信息瓶颈原理的可扩展任务条件检索算法，从长期记忆中提取紧凑、非冗余、信息丰富的候选记忆进行上下文推理。

Result: 在NaVQA（混合室内外校园场景）和WH-VQA（仓库基准）上，STaR始终优于强基线，实现更高的成功率和显著更低的空间误差。在真实Husky轮式机器人上的部署验证了其鲁棒性、可扩展性和实用性。

Conclusion: STaR框架为移动机器人提供了有效的长期记忆和推理能力，支持开放指令下的精确导航，在模拟和真实环境中都表现出色。

Abstract: Mobile robots are often deployed over long durations in diverse open, dynamic scenes, including indoor setting such as warehouses and manufacturing facilities, and outdoor settings such as agricultural and roadway operations. A core challenge is to build a scalable long-horizon memory that supports an agentic workflow for planning, retrieval, and reasoning over open-ended instructions at variable granularity, while producing precise, actionable answers for navigation. We present STaR, an agentic reasoning framework that (i) constructs a task-agnostic, multimodal long-term memory that generalizes to unseen queries while preserving fine-grained environmental semantics (object attributes, spatial relations, and dynamic events), and (ii) introduces a Scalable TaskConditioned Retrieval algorithm based on the Information Bottleneck principle to extract from long-term memory a compact, non-redundant, information-rich set of candidate memories for contextual reasoning. We evaluate STaR on NaVQA (mixed indoor/outdoor campus scenes) and WH-VQA, a customized warehouse benchmark with many visually similar objects built with Isaac Sim, emphasizing contextual reasoning. Across the two datasets, STaR consistently outperforms strong baselines, achieving higher success rates and markedly lower spatial error. We further deploy STaR on a real Husky wheeled robot in both indoor and outdoor environments, demonstrating robust longhorizon reasoning, scalability, and practical utility.

</details>


### [72] [Data-centric Design of Learning-based Surgical Gaze Perception Models in Multi-Task Simulation](https://arxiv.org/abs/2602.09259)
*Yizhou Li,Shuyuan Yang,Jiaji Su,Zonghe Chua*

Main category: cs.RO

TL;DR: 研究探讨了机器人辅助微创手术中，专家注视监督的来源（专业水平与感知模态）如何影响注意力模型学习，通过收集主动-被动多任务手术注视数据集，发现被动注视可部分替代主动注视监督，为可扩展的众包注视监督提供了实用路径。


<details>
  <summary>Details</summary>
Motivation: 在机器人辅助微创手术中，触觉反馈和深度线索的减少增加了对专家视觉感知的依赖，但专家注视数据收集成本高昂，且不同来源的注视监督（专业水平和感知模态）如何影响注意力模型学习尚不明确。

Method: 在达芬奇SimNow模拟器上收集了配对主动-被动多任务手术注视数据集，主动注视通过VR头显眼动追踪记录任务执行过程，被动注视则通过让观察者观看相同视频收集。使用注视密度重叠分析和单帧显著性建模评估被动注视对主动监督的可替代性。

Result: MSI-Net产生稳定可解释的预测，而SalGAN不稳定且与人类注视对齐较差。被动注视训练的模型能恢复大部分中级主动注意力，但存在可预测的退化，主动与被动目标间的转移不对称。新手被动标签能以有限损失近似中级被动目标。

Conclusion: 被动注视监督可部分替代主动注视监督，新手被动标签能有效近似中级被动目标，为手术指导和感知建模提供了可扩展的众包注视监督实用路径。

Abstract: In robot-assisted minimally invasive surgery (RMIS), reduced haptic feedback and depth cues increase reliance on expert visual perception, motivating gaze-guided training and learning-based surgical perception models. However, operative expert gaze is costly to collect, and it remains unclear how the source of gaze supervision, both expertise level (intermediate vs. novice) and perceptual modality (active execution vs. passive viewing), shapes what attention models learn. We introduce a paired active-passive, multi-task surgical gaze dataset collected on the da Vinci SimNow simulator across four drills. Active gaze was recorded during task execution using a VR headset with eye tracking, and the corresponding videos were reused as stimuli to collect passive gaze from observers, enabling controlled same-video comparisons. We quantify skill- and modality-dependent differences in gaze organization and evaluate the substitutability of passive gaze for operative supervision using fixation density overlap analyses and single-frame saliency modeling. Across settings, MSI-Net produced stable, interpretable predictions, whereas SalGAN was unstable and often poorly aligned with human fixations. Models trained on passive gaze recovered a substantial portion of intermediate active attention, but with predictable degradation, and transfer was asymmetric between active and passive targets. Notably, novice passive labels approximated intermediate-passive targets with limited loss on higher-quality demonstrations, suggesting a practical path for scalable, crowd-sourced gaze supervision in surgical coaching and perception modeling.

</details>


### [73] [Disambiguating Anthropomorphism and Anthropomimesis in Human-Robot Interaction](https://arxiv.org/abs/2602.09287)
*Minja Axelsson,Henry Shevlin*

Main category: cs.RO

TL;DR: 论文区分了人机交互中的两个概念：拟人化（用户感知机器人的人类特质）和拟人模仿（开发者设计机器人的人类特征）。


<details>
  <summary>Details</summary>
Motivation: 在人机交互和社会机器人学中，"anthropomorphism"和"anthropomimesis"这两个理论概念经常混淆使用，缺乏明确的区分。作者希望通过澄清这两个概念，为未来的研究提供更清晰的理论基础。

Method: 通过概念分析和理论辨析的方法，对anthropomorphism和anthropomimesis进行初步区分和定义。将anthropomorphism定义为用户对机器人的人类特质感知，将anthropomimesis定义为开发者对机器人的人类特征设计。

Result: 成功区分了两个关键概念：anthropomorphism（用户感知层面）和anthropomimesis（设计者意图层面），明确了各自的责任主体——前者是机器人感知者，后者是机器人设计者。

Conclusion: 这种概念区分为人机交互研究提供了更清晰的理论框架，有助于未来的机器人设计和评估研究，使研究者能够基于这些明确的概念进行更精确的研究。

Abstract: In this preliminary work, we offer an initial disambiguation of the theoretical concepts anthropomorphism and anthropomimesis in Human-Robot Interaction (HRI) and social robotics. We define anthropomorphism as users perceiving human-like qualities in robots, and anthropomimesis as robot developers designing human-like features into robots. This contribution aims to provide a clarification and exploration of these concepts for future HRI scholarship, particularly regarding the party responsible for human-like qualities - robot perceiver for anthropomorphism, and robot designer for anthropomimesis. We provide this contribution so that researchers can build on these disambiguated theoretical concepts for future robot design and evaluation.

</details>


### [74] [CAPER: Constrained and Procedural Reasoning for Robotic Scientific Experiments](https://arxiv.org/abs/2602.09367)
*Jinghan Yang,Jingyi Hou,Xinbo Yu,Wei He,Yifan Wu*

Main category: cs.RO

TL;DR: CAPER框架通过分离责任结构，在科学实验机器人中实现约束性和程序性推理，提高成功率、程序正确性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 科学实验室中的机器人辅助需要程序正确的长时程操作、有限监督下的可靠执行以及低演示数据下的鲁棒性。现有的端到端视觉-语言-动作模型在这些协议敏感的实验环境中经常失效，因为它们假设错误可恢复且依赖数据驱动的策略学习。

Method: CAPER采用责任分离结构：任务级推理在显式约束下生成程序有效的动作序列；中层多模态基础实现子任务而不将空间决策委托给大语言模型；低层控制通过最少演示的强化学习适应物理不确定性。通过可解释的中间表示编码程序承诺。

Result: 在科学工作流基准和公共长时程操作数据集上的实验显示，在成功率、程序正确性方面有持续改进，特别是在低数据和长时程设置下表现突出。

Conclusion: CAPER通过约束程序推理和责任分离结构，防止执行时违反实验逻辑，提高了可控性、鲁棒性和数据效率，为科学实验机器人提供了更可靠的解决方案。

Abstract: Robotic assistance in scientific laboratories requires procedurally correct long-horizon manipulation, reliable execution under limited supervision, and robustness in low-demonstration regimes. Such conditions greatly challenge end-to-end vision-language-action (VLA) models, whose assumptions of recoverable errors and data-driven policy learning often break down in protocol-sensitive experiments. We propose CAPER, a framework for Constrained And ProcEdural Reasoning for robotic scientific experiments, which explicitly restricts where learning and reasoning occur in the planning and control pipeline. Rather than strengthening end-to-end policies, CAPER enforces a responsibility-separated structure: task-level reasoning generates procedurally valid action sequences under explicit constraints, mid-level multimodal grounding realizes subtasks without delegating spatial decision-making to large language models, and low-level control adapts to physical uncertainty via reinforcement learning with minimal demonstrations. By encoding procedural commitments through interpretable intermediate representations, CAPER prevents execution-time violations of experimental logic, improving controllability, robustness, and data efficiency. Experiments on a scientific workflow benchmark and a public long-horizon manipulation dataset demonstrate consistent improvements in success rate and procedural correctness, particularly in low-data and long-horizon settings.

</details>


### [75] [Certified Gradient-Based Contact-Rich Manipulation via Smoothing-Error Reachable Tubes](https://arxiv.org/abs/2602.09368)
*Wei-Chen Li,Glen Chou*

Main category: cs.RO

TL;DR: 提出一种基于梯度优化的接触丰富操作控制器合成方法，通过平滑动力学并量化补偿误差，为真实混合动力学提供形式化保证


<details>
  <summary>Details</summary>
Motivation: 基于梯度的控制器优化方法在接触丰富的操作任务中面临挑战，因为混合接触动力学会导致梯度不连续或消失。平滑动力学虽然能提供连续梯度，但会导致模型失配，在真实系统上执行时可能失败。

Method: 使用基于凸优化的新型可微模拟器平滑接触动力学和几何，将真实动力学与平滑模型之间的差异量化为集合值偏差。通过分析系统可达集的边界，优化时变仿射反馈策略，确保对真实闭环混合动力学的鲁棒约束满足。

Result: 在平面推动、物体旋转和手内灵巧操作等接触丰富任务上评估，相比基线方法实现了更低的违反安全约束和更小的目标误差，同时提供形式化保证。

Conclusion: 该方法首次将可微物理与集合值鲁棒控制相结合，成为首个可证明的基于梯度的接触丰富操作策略合成方法，在保持梯度信息的同时提供形式化保证。

Abstract: Gradient-based methods can efficiently optimize controllers using physical priors and differentiable simulators, but contact-rich manipulation remains challenging due to discontinuous or vanishing gradients from hybrid contact dynamics. Smoothing the dynamics yields continuous gradients, but the resulting model mismatch can cause controller failures when executed on real systems. We address this trade-off by planning with smoothed dynamics while explicitly quantifying and compensating for the induced errors, providing formal guarantees of constraint satisfaction and goal reachability on the true hybrid dynamics. Our method smooths both contact dynamics and geometry via a novel differentiable simulator based on convex optimization, which enables us to characterize the discrepancy from the true dynamics as a set-valued deviation. This deviation constrains the optimization of time-varying affine feedback policies through analytical bounds on the system's reachable set, enabling robust constraint satisfaction guarantees for the true closed-loop hybrid dynamics, while relying solely on informative gradients from the smoothed dynamics. We evaluate our method on several contact-rich tasks, including planar pushing, object rotation, and in-hand dexterous manipulation, achieving guaranteed constraint satisfaction with lower safety violation and goal error than baselines. By bridging differentiable physics with set-valued robust control, our method is the first certifiable gradient-based policy synthesis method for contact-rich manipulation.

</details>


### [76] [Phase-Aware Policy Learning for Skateboard Riding of Quadruped Robots via Feature-wise Linear Modulation](https://arxiv.org/abs/2602.09370)
*Minsung Yoon,Jeil Jeong,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: 提出PAPL强化学习框架，让四足机器人学会滑板，通过相位感知网络处理滑板不同阶段的模态变化


<details>
  <summary>Details</summary>
Motivation: 滑板作为个人移动设备具有紧凑高效的特点，但用腿式机器人控制滑板面临感知驱动交互和多模态控制目标的挑战，特别是在滑板不同阶段需要不同的控制策略

Method: 提出相位感知策略学习(PAPL)框架，利用滑板的周期性特点，在actor和critic网络中集成相位条件特征线性调制层，实现统一策略同时捕捉相位依赖行为并跨相位共享机器人特定知识

Result: 在仿真中验证了指令跟踪精度，通过消融研究量化各组件贡献，与腿式和轮腿式基线比较显示更高的运动效率，并展示了真实世界可迁移性

Conclusion: PAPL框架成功解决了四足机器人滑板控制中的多模态挑战，通过相位感知网络实现了高效统一的控制策略，具有实际应用价值

Abstract: Skateboards offer a compact and efficient means of transportation as a type of personal mobility device. However, controlling them with legged robots poses several challenges for policy learning due to perception-driven interactions and multi-modal control objectives across distinct skateboarding phases. To address these challenges, we introduce Phase-Aware Policy Learning (PAPL), a reinforcement-learning framework tailored for skateboarding with quadruped robots. PAPL leverages the cyclic nature of skateboarding by integrating phase-conditioned Feature-wise Linear Modulation layers into actor and critic networks, enabling a unified policy that captures phase-dependent behaviors while sharing robot-specific knowledge across phases. Our evaluations in simulation validate command-tracking accuracy and conduct ablation studies quantifying each component's contribution. We also compare locomotion efficiency against leg and wheel-leg baselines and show real-world transferability.

</details>


### [77] [Sci-VLA: Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments](https://arxiv.org/abs/2602.09430)
*Yiwen Pang,Bo Zhou,Changjin Li,Xuanhao Wang,Shengxiang Xu,Deng-Bao Wang,Min-Ling Zhang,Shimin Di*

Main category: cs.RO

TL;DR: 提出Agentic VLA Inference Plugin，通过LLM代理推理机制在科学实验长时程任务中生成过渡性机器人动作代码，解决VLA模型在复合任务执行中的分布不匹配问题，无需额外训练即可提升成功率。


<details>
  <summary>Details</summary>
Motivation: 科学实验通常由多个原子任务组成的长时程复合任务，现有VLA模型虽然能可靠执行训练时见过的原子动作，但在重新组合这些原子动作形成的复合任务中经常失败，原因是训练时的原子任务与推理时的复合任务之间存在分布不匹配，导致VLA模型无法执行必要的过渡操作。

Method: 提出Agentic VLA Inference Plugin，引入基于LLM的代理推理机制，在执行顺序操作任务时进行干预。通过执行显式的过渡推理并生成过渡性机器人动作代码，引导VLA模型完成缺失的过渡步骤，实现复合科学工作流的可靠执行，无需额外训练。

Result: 在现有仿真环境中构建了科学仪器和常见科学操作场景的3D资产，验证了该方法在推理过程中将每个原子任务的平均成功率提高了42%。此外，该方法可以轻松从仿真环境迁移到真实科学实验室。

Conclusion: 该方法通过纯推理干预解决了VLA模型在科学实验长时程复合任务中的执行问题，具有计算高效、数据高效的特点，适合开放性和长时程的机器人实验室任务，并能实现从仿真到真实环境的迁移。

Abstract: Robotic laboratories play a critical role in autonomous scientific discovery by enabling scalable, continuous experimental execution. Recent vision-language-action (VLA) models offer a promising foundation for robotic laboratories. However, scientific experiments typically involve long-horizon tasks composed of multiple atomic tasks, posing a fundamental challenge to existing VLA models. While VLA models fine-tuned for scientific tasks can reliably execute atomic experimental actions seen during training, they often fail to perform composite tasks formed by reordering and composing these known atomic actions. This limitation arises from a distributional mismatch between training-time atomic tasks and inference-time composite tasks, which prevents VLA models from executing necessary transitional operations between atomic tasks. To address this challenge, we propose an Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments. It introduces an LLM-based agentic inference mechanism that intervenes when executing sequential manipulation tasks. By performing explicit transition inference and generating transitional robotic action code, the proposed plugin guides VLA models through missing transitional steps, enabling reliable execution of composite scientific workflows without any additional training. This inference-only intervention makes our method computationally efficient, data-efficient, and well-suited for open-ended and long-horizon robotic laboratory tasks. We build 3D assets of scientific instruments and common scientific operating scenes within an existing simulation environment. In these scenes, we have verified that our method increases the average success rate per atomic task by 42\% during inference. Furthermore, we show that our method can be easily transferred from the simulation to real scientific laboratories.

</details>


### [78] [LLM-Grounded Dynamic Task Planning with Hierarchical Temporal Logic for Human-Aware Multi-Robot Collaboration](https://arxiv.org/abs/2602.09472)
*Shuyuan Hu,Tao Lin,Kai Ye,Yang Yang,Tianwei Zhang*

Main category: cs.RO

TL;DR: 提出神经符号框架，将LLM推理与分层LTL规范结合，解决多机器人任务分配与规划问题，通过滚动时域规划处理动态环境变化。


<details>
  <summary>Details</summary>
Motivation: LLM虽然能让非专家指定多机器人任务，但生成的计划缺乏运动学可行性且效率低下；形式化方法如LTL能提供正确性和最优性保证，但局限于静态离线设置且计算可扩展性差。

Method: 提出神经符号框架，将LLM推理落地为分层LTL规范，解决同步任务分配与规划问题；采用滚动时域规划循环处理随机环境变化，通过实时感知在分层状态空间中动态优化计划。

Result: 大量真实世界实验表明，该方法在成功率和交互流畅度上显著优于基线方法，同时最小化规划延迟。

Conclusion: 该框架成功结合了LLM的开放世界任务指定能力和LTL的形式化保证，通过动态规划机制有效处理现实世界中的不确定性。

Abstract: While Large Language Models (LLM) enable non-experts to specify open-world multi-robot tasks, the generated plans often lack kinematic feasibility and are not efficient, especially in long-horizon scenarios. Formal methods like Linear Temporal Logic (LTL) offer correctness and optimal guarantees, but are typically confined to static, offline settings and struggle with computational scalability. To bridge this gap, we propose a neuro-symbolic framework that grounds LLM reasoning into hierarchical LTL specifications and solves the corresponding Simultaneous Task Allocation and Planning (STAP) problem. Unlike static approaches, our system resolves stochastic environmental changes, such as moving users or updated instructions via a receding horizon planning (RHP) loop with real-time perception, which dynamically refines plans through a hierarchical state space. Extensive real-world experiments demonstrate that our approach significantly outperforms baseline methods in success rate and interaction fluency while minimizing planning latency.

</details>


### [79] [Optimal Control of Microswimmers for Trajectory Tracking Using Bayesian Optimization](https://arxiv.org/abs/2602.09563)
*Lucas Palazzolo,Mickaël Binois,Laëtitia Giraldi*

Main category: cs.RO

TL;DR: 提出一种基于贝叶斯优化的微游泳器轨迹跟踪最优控制方法，适用于不同精度模型，能处理复杂流体-结构相互作用


<details>
  <summary>Details</summary>
Motivation: 微游泳器的轨迹跟踪在微机器人领域具有挑战性，低雷诺数动力学使控制设计复杂，需要能处理高计算成本且无需复杂梯度计算的方法

Method: 将轨迹跟踪问题表述为最优控制问题，采用B样条参数化结合贝叶斯优化求解，避免复杂梯度计算，适用于从低维ODE到高精度PDE的不同模型

Result: 方法成功应用于鞭毛磁性游泳器，能重现多种目标轨迹（包括生物启发路径）；在三球游泳器模型中能适应并部分补偿壁面诱导的流体效应

Conclusion: 贝叶斯优化是微尺度运动复杂流体-结构相互作用下最优控制策略的通用工具，具有鲁棒性和普适性，可跨不同精度模型一致应用

Abstract: Trajectory tracking for microswimmers remains a key challenge in microrobotics, where low-Reynolds-number dynamics make control design particularly complex. In this work, we formulate the trajectory tracking problem as an optimal control problem and solve it using a combination of B-spline parametrization with Bayesian optimization, allowing the treatment of high computational costs without requiring complex gradient computations. Applied to a flagellated magnetic swimmer, the proposed method reproduces a variety of target trajectories, including biologically inspired paths observed in experimental studies. We further evaluate the approach on a three-sphere swimmer model, demonstrating that it can adapt to and partially compensate for wall-induced hydrodynamic effects. The proposed optimization strategy can be applied consistently across models of different fidelity, from low-dimensional ODE-based models to high-fidelity PDE-based simulations, showing its robustness and generality. These results highlight the potential of Bayesian optimization as a versatile tool for optimal control strategies in microscale locomotion under complex fluid-structure interactions.

</details>


### [80] [Sample-Efficient Real-World Dexterous Policy Fine-Tuning via Action-Chunked Critics and Normalizing Flows](https://arxiv.org/abs/2602.09580)
*Chenyu Yang,Denis Tarasov,Davide Liconti,Hehui Zheng,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SOFT-FLOW：一种基于标准化流的样本高效离线策略微调框架，用于解决灵巧操作中的多模态动作分布和长时域信用分配问题，在真实机器人硬件上实现了稳定的策略适应。


<details>
  <summary>Details</summary>
Motivation: 现实世界中灵巧操作策略的微调面临两大挑战：1）现实交互预算有限，需要样本高效的方法；2）动作分布高度多模态，传统高斯策略会崩溃，而基于扩散的策略无法进行基于似然的保守更新。此外，分块执行动作时，传统的每步评论家无法与分块执行对齐，导致信用分配不佳。

Method: 提出SOFT-FLOW框架：1）使用标准化流（NF）策略，为多模态动作块提供精确的似然计算，通过似然正则化实现保守稳定的策略更新；2）引入动作分块评论家，评估整个动作序列，使价值估计与策略的时间结构对齐，改善长时域信用分配。

Result: 在两项真实世界灵巧操作任务上评估：1）从盒子中取出剪刀剪胶带；2）掌心向下抓握下的手中立方体旋转。SOFT-FLOW在这些需要精确长时域控制的任务上实现了稳定、样本高效的适应，而标准方法表现不佳。

Conclusion: SOFT-FLOW首次在真实机器人硬件上展示了基于似然的多模态生成策略与分块级价值学习的结合，成功解决了灵巧操作中的多模态动作分布和长时域信用分配问题，实现了样本高效的策略微调。

Abstract: Real-world fine-tuning of dexterous manipulation policies remains challenging due to limited real-world interaction budgets and highly multimodal action distributions. Diffusion-based policies, while expressive, do not permit conservative likelihood-based updates during fine-tuning because action probabilities are intractable. In contrast, conventional Gaussian policies collapse under multimodality, particularly when actions are executed in chunks, and standard per-step critics fail to align with chunked execution, leading to poor credit assignment. We present SOFT-FLOW, a sample-efficient off-policy fine-tuning framework with normalizing flow (NF) to address these challenges. The normalizing flow policy yields exact likelihoods for multimodal action chunks, allowing conservative, stable policy updates through likelihood regularization and thereby improving sample efficiency. An action-chunked critic evaluates entire action sequences, aligning value estimation with the policy's temporal structure and improving long-horizon credit assignment. To our knowledge, this is the first demonstration of a likelihood-based, multimodal generative policy combined with chunk-level value learning on real robotic hardware. We evaluate SOFT-FLOW on two challenging dexterous manipulation tasks in the real world: cutting tape with scissors retrieved from a case, and in-hand cube rotation with a palm-down grasp -- both of which require precise, dexterous control over long horizons. On these tasks, SOFT-FLOW achieves stable, sample-efficient adaptation where standard methods struggle.

</details>


### [81] [Preference Aligned Visuomotor Diffusion Policies for Deformable Object Manipulation](https://arxiv.org/abs/2602.09583)
*Marco Moletta,Michael C. Welle,Danica Kragic*

Main category: cs.RO

TL;DR: RKO：一种结合RPO和KTO优势的新型偏好对齐方法，用于调整预训练的视觉运动扩散策略以适应个人偏好，在布料折叠任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 人类在操作任务中具有微妙、个性化且难以表达的偏好，机器人需要考虑这些偏好以提高个性化和用户满意度，但在可变形物体（如衣物和织物）操作中这一领域尚未充分探索

Method: 提出RKO方法，结合RPO和KTO两种框架的优势，使用有限演示来调整预训练的视觉运动扩散策略以反映偏好行为

Result: 在多种衣物和偏好设置的真实布料折叠任务中，偏好对齐策略（特别是RKO）相比标准扩散策略微调实现了更优的性能和样本效率

Conclusion: 结构化偏好学习对于在复杂可变形物体操作任务中扩展个性化机器人行为具有重要意义且可行

Abstract: Humans naturally develop preferences for how manipulation tasks should be performed, which are often subtle, personal, and difficult to articulate. Although it is important for robots to account for these preferences to increase personalization and user satisfaction, they remain largely underexplored in robotic manipulation, particularly in the context of deformable objects like garments and fabrics. In this work, we study how to adapt pretrained visuomotor diffusion policies to reflect preferred behaviors using limited demonstrations. We introduce RKO, a novel preference-alignment method that combines the benefits of two recent frameworks: RPO and KTO. We evaluate RKO against common preference learning frameworks, including these two, as well as a baseline vanilla diffusion policy, on real-world cloth-folding tasks spanning multiple garments and preference settings. We show that preference-aligned policies (particularly RKO) achieve superior performance and sample efficiency compared to standard diffusion policy fine-tuning. These results highlight the importance and feasibility of structured preference learning for scaling personalized robot behavior in complex deformable object manipulation tasks.

</details>


### [82] [AnyTouch 2: General Optical Tactile Representation Learning For Dynamic Tactile Perception](https://arxiv.org/abs/2602.09617)
*Ruoxuan Feng,Yuxuan Zhou,Siyu Mei,Dongzhan Zhou,Pengwei Wang,Shaowei Cui,Bin Fang,Guocai Yao,Di Hu*

Main category: cs.RO

TL;DR: 提出ToucHD大规模分层触觉数据集和AnyTouch 2通用触觉表示学习框架，用于光学触觉传感器的动态触觉感知


<details>
  <summary>Details</summary>
Motivation: 现实世界接触丰富的操作需要机器人感知时序触觉反馈、捕捉细微表面变形并推理物体属性和力动力学。现有触觉数据集和模型主要关注物体级属性，忽略了物理交互中的细粒度触觉时序动态

Method: 1) 提出ToucHD大规模分层触觉数据集，涵盖触觉原子动作、真实世界操作和触觉-力配对数据；2) 提出AnyTouch 2通用触觉表示学习框架，统一物体级理解和细粒度、力感知的动态感知，捕捉像素级和动作特定的跨帧变形，显式建模物理力动力学

Result: 实验结果表明，在覆盖静态物体属性和动态物理属性的基准测试以及真实世界操作任务中，模型在不同传感器和任务上表现一致且强大

Conclusion: 通过建立分层触觉动态数据生态系统和统一表示学习框架，显著推进了动态触觉感知能力，从基础物体级理解到力感知灵巧操作

Abstract: Real-world contact-rich manipulation demands robots to perceive temporal tactile feedback, capture subtle surface deformations, and reason about object properties as well as force dynamics. Although optical tactile sensors are uniquely capable of providing such rich information, existing tactile datasets and models remain limited. These resources primarily focus on object-level attributes (e.g., material) while largely overlooking fine-grained tactile temporal dynamics during physical interactions. We consider that advancing dynamic tactile perception requires a systematic hierarchy of dynamic perception capabilities to guide both data collection and model design. To address the lack of tactile data with rich dynamic information, we present ToucHD, a large-scale hierarchical tactile dataset spanning tactile atomic actions, real-world manipulations, and touch-force paired data. Beyond scale, ToucHD establishes a comprehensive tactile dynamic data ecosystem that explicitly supports hierarchical perception capabilities from the data perspective. Building on it, we propose AnyTouch 2, a general tactile representation learning framework for diverse optical tactile sensors that unifies object-level understanding with fine-grained, force-aware dynamic perception. The framework captures both pixel-level and action-specific deformations across frames, while explicitly modeling physical force dynamics, thereby learning multi-level dynamic perception capabilities from the model perspective. We evaluate our model on benchmarks that covers static object properties and dynamic physical attributes, as well as real-world manipulation tasks spanning multiple tiers of dynamic perception capabilities-from basic object-level understanding to force-aware dexterous manipulation. Experimental results demonstrate consistent and strong performance across sensors and tasks.

</details>


### [83] [TeleGate: Whole-Body Humanoid Teleoperation via Gated Expert Selection with Motion Prior](https://arxiv.org/abs/2602.09628)
*Jie Li,Bing Tang,Feng Wu,Rongyun Cao*

Main category: cs.RO

TL;DR: TeleGate是一个用于人形机器人全身遥操作的新型框架，通过轻量级门控网络动态激活领域专家策略，避免知识蒸馏的性能损失，并引入VAE运动先验模块实现预测性控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将多个专家策略蒸馏为单一通用策略，这不可避免地导致性能下降，特别是在高动态运动上。需要一种能够保持专家策略完整能力并支持实时遥操作的统一框架。

Method: 1) 训练轻量级门控网络，根据本体感知状态和参考轨迹实时动态激活领域专家策略；2) 引入基于VAE的运动先验模块，从历史观测中提取隐含的未来运动意图，实现对跳跃、站起等需要预测的运动的预期控制。

Result: 仅使用2.5小时运动捕捉数据进行训练，TeleGate在Unitree G1人形机器人上实现了高精度实时遥操作，在跑步、跌倒恢复、跳跃等多种动态运动中显著优于基线方法，在跟踪精度和成功率方面都有显著提升。

Conclusion: TeleGate通过门控网络保持专家策略完整能力，结合运动先验模块实现预测性控制，为复杂动态运动的实时全身遥操作提供了有效解决方案，避免了传统知识蒸馏方法的性能损失。

Abstract: Real-time whole-body teleoperation is a critical method for humanoid robots to perform complex tasks in unstructured environments. However, developing a unified controller that robustly supports diverse human motions remains a significant challenge. Existing methods typically distill multiple expert policies into a single general policy, which often inevitably leads to performance degradation, particularly on highly dynamic motions. This paper presents TeleGate, a unified whole-body teleoperation framework for humanoid robots that achieves high-precision tracking across various motions while avoiding the performance loss inherent in knowledge distillation. Our key idea is to preserve the full capability of domain-specific expert policies by training a lightweight gating network, which dynamically activates experts in real-time based on proprioceptive states and reference trajectories. Furthermore, to compensate for the absence of future reference trajectories in real-time teleoperation, we introduce a VAE-based motion prior module that extracts implicit future motion intent from historical observations, enabling anticipatory control for motions requiring prediction such as jumping and standing up. We conducted empirical evaluations in simulation and also deployed our technique on the Unitree G1 humanoid robot. Using only 2.5 hours of motion capture data for training, our TeleGate achieves high-precision real-time teleoperation across diverse dynamic motions (e.g., running, fall recovery, and jumping), significantly outperforming the baseline methods in both tracking accuracy and success rate.

</details>


### [84] [AutoFly: Vision-Language-Action Model for UAV Autonomous Navigation in the Wild](https://arxiv.org/abs/2602.09657)
*Xiaolou Sun,Wufei Si,Wenhui Ni,Yuntian Li,Dongming Wu,Fei Xie,Runwei Guan,He-Yang Xu,Henghui Ding,Yuan Wu,Yutao Yue,Yongming Huang,Hui Xiong*

Main category: cs.RO

TL;DR: AutoFly是一个用于无人机自主导航的端到端视觉-语言-动作模型，采用伪深度编码器和两阶段训练策略，在新型自主导航数据集上实现了3.9%的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 当前无人机视觉语言导航研究依赖详细的预定义指令和预定路线，而真实户外探索通常在未知环境中进行，只能提供粗粒度的位置或方向指导，需要无人机通过连续规划和避障实现自主导航。

Method: 提出AutoFly端到端VLA模型，包含伪深度编码器从RGB输入提取深度感知特征以增强空间推理，采用渐进式两阶段训练策略有效对齐视觉、深度和语言表示与动作策略。同时构建新型自主导航数据集，从指令跟随转向自主行为建模。

Result: AutoFly相比最先进的VLA基线实现了3.9%的成功率提升，在模拟和真实环境中表现一致。构建的数据集解决了现有VLN数据集对显式指令跟随依赖过强和真实世界数据不足的问题。

Conclusion: AutoFly通过深度感知特征提取和两阶段训练策略，结合新型自主导航数据集，有效解决了无人机在未知环境中基于粗粒度指导的自主导航问题，为具身AI的实际应用提供了重要进展。

Abstract: Vision-language navigation (VLN) requires intelligent agents to navigate environments by interpreting linguistic instructions alongside visual observations, serving as a cornerstone task in Embodied AI. Current VLN research for unmanned aerial vehicles (UAVs) relies on detailed, pre-specified instructions to guide the UAV along predetermined routes. However, real-world outdoor exploration typically occurs in unknown environments where detailed navigation instructions are unavailable. Instead, only coarse-grained positional or directional guidance can be provided, requiring UAVs to autonomously navigate through continuous planning and obstacle avoidance. To bridge this gap, we propose AutoFly, an end-to-end Vision-Language-Action (VLA) model for autonomous UAV navigation. AutoFly incorporates a pseudo-depth encoder that derives depth-aware features from RGB inputs to enhance spatial reasoning, coupled with a progressive two-stage training strategy that effectively aligns visual, depth, and linguistic representations with action policies. Moreover, existing VLN datasets have fundamental limitations for real-world autonomous navigation, stemming from their heavy reliance on explicit instruction-following over autonomous decision-making and insufficient real-world data. To address these issues, we construct a novel autonomous navigation dataset that shifts the paradigm from instruction-following to autonomous behavior modeling through: (1) trajectory collection emphasizing continuous obstacle avoidance, autonomous planning, and recognition workflows; (2) comprehensive real-world data integration. Experimental results demonstrate that AutoFly achieves a 3.9% higher success rate compared to state-of-the-art VLA baselines, with consistent performance across simulated and real environments.

</details>


### [85] [RANT: Ant-Inspired Multi-Robot Rainforest Exploration Using Particle Filter Localisation and Virtual Pheromone Coordination](https://arxiv.org/abs/2602.09661)
*Ameer Alhashemi,Layan Abdulhadi,Karam Abuodeh,Tala Baghdadi,Suryanarayana Datla*

Main category: cs.RO

TL;DR: RANT是一个受蚂蚁启发的多机器人探索框架，用于在噪声和不确定环境中进行探索。它结合了粒子滤波定位、基于行为的控制器和虚拟信息素协调机制，实验分析了团队规模、定位精度和协调对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 在噪声和不确定环境中进行高效的多机器人探索是一个挑战。需要解决定位不确定性、环境噪声以及机器人之间的协调问题，以提高覆盖率和热点发现能力，同时减少冗余探索。

Method: RANT框架包含三个核心组件：1) 粒子滤波定位处理定位不确定性；2) 基于行为的控制器，结合梯度驱动热点利用；3) 轻量级无重复访问协调机制，基于虚拟信息素阻塞。系统使用差速驱动机器人在10x10米地形中收集噪声探测测量，构建局部概率地图，同时监督器维护全局评估。

Result: 实验结果表明：1) 粒子滤波对于可靠的热点参与至关重要；2) 协调机制显著减少了重叠探索；3) 增加团队规模可以提高覆盖率，但由于干扰效应会产生收益递减。

Conclusion: RANT框架成功展示了在噪声不确定环境中多机器人探索的有效性。粒子滤波定位、梯度驱动热点利用和虚拟信息素协调的组合能够平衡覆盖率和效率，为实际应用中的多机器人探索系统提供了有价值的见解。

Abstract: This paper presents RANT, an ant-inspired multi-robot exploration framework for noisy, uncertain environments. A team of differential-drive robots navigates a 10 x 10 m terrain, collects noisy probe measurements of a hidden richness field, and builds local probabilistic maps while the supervisor maintains a global evaluation. RANT combines particle-filter localisation, a behaviour-based controller with gradient-driven hotspot exploitation, and a lightweight no-revisit coordination mechanism based on virtual pheromone blocking. We experimentally analyse how team size, localisation fidelity, and coordination influence coverage, hotspot recall, and redundancy. Results show that particle filtering is essential for reliable hotspot engagement, coordination substantially reduces overlap, and increasing team size improves coverage but yields diminishing returns due to interference.

</details>


### [86] [Fast Motion Planning for Non-Holonomic Mobile Robots via a Rectangular Corridor Representation of Structured Environments](https://arxiv.org/abs/2602.09714)
*Alejandro Gonzalez-Garcia,Sebastiaan Wyns,Sonia De Santis,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: 提出一个用于非完整自主移动机器人在复杂结构化环境中快速运动规划的完整框架，通过确定性自由空间分解创建紧凑的重叠矩形走廊图，显著减少搜索空间，实现高效大规模导航。


<details>
  <summary>Details</summary>
Motivation: 传统基于网格的规划器难以扩展，而许多运动学可行的规划器由于搜索空间复杂度过高而带来显著计算负担。需要一种既能保证运动学可行性又能高效处理大规模复杂环境的方法。

Method: 采用确定性自由空间分解方法，创建紧凑的重叠矩形走廊图，显著减少搜索空间。然后在线进行运动规划，找到矩形序列，并使用解析规划器生成近似时间最优且运动学可行的轨迹。

Result: 通过大量仿真和物理机器人实验验证了框架的有效性，实现了高效的大规模导航。该实现已作为开源软件公开发布。

Conclusion: 该框架为复杂结构化环境中非完整移动机器人的快速运动规划提供了一个高效解决方案，在保持路径分辨率的同时显著降低了计算复杂度，适用于大规模导航任务。

Abstract: We present a complete framework for fast motion planning of non-holonomic autonomous mobile robots in highly complex but structured environments. Conventional grid-based planners struggle with scalability, while many kinematically-feasible planners impose a significant computational burden due to their search space complexity. To overcome these limitations, our approach introduces a deterministic free-space decomposition that creates a compact graph of overlapping rectangular corridors. This method enables a significant reduction in the search space, without sacrificing path resolution. The framework then performs online motion planning by finding a sequence of rectangles and generating a near-time-optimal, kinematically-feasible trajectory using an analytical planner. The result is a highly efficient solution for large-scale navigation. We validate our framework through extensive simulations and on a physical robot. The implementation is publicly available as open-source software.

</details>


### [87] [Rethinking Visual-Language-Action Model Scaling: Alignment, Mixture, and Regularization](https://arxiv.org/abs/2602.09722)
*Ye Wang,Sipeng Zheng,Hao Luo,Wanpeng Zhang,Haoqi Yuan,Chaoyi Xu,Haiweng Xu,Yicheng Feng,Mingyang Yu,Zhiyu Kang,Zongqing Lu,Qin Jin*

Main category: cs.RO

TL;DR: 该研究系统分析了视觉-语言-动作模型在机器人控制中的扩展性，发现统一末端执行器相对动作表示对跨本体迁移至关重要，简单混合异构机器人数据可能导致负迁移，直观的训练正则化策略在规模化时并不总是有效。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉-语言-动作模型在通用机器人控制方面展现出潜力，但尚不清楚标准的"扩展数据"方法是否适用于机器人领域，因为机器人训练数据在具体实现、传感器和动作空间上具有固有的异构性。需要系统研究VLA在机器人领域的扩展规律。

Method: 使用代表性的VLA框架（视觉-语言骨干网络+流匹配），在匹配条件下消融关键设计决策，通过大量仿真和真实机器人实验进行评估。引入分组盲测集成协议来减少实验者偏差，该协议使操作者不知道模型身份，并将策略执行与结果判断分离。

Result: 1) 物理对齐：统一的末端执行器相对动作表示对跨本体鲁棒迁移至关重要；2) 本体混合：简单混合异构机器人数据集常导致负迁移而非性能提升；3) 训练正则化：直观策略（如感官丢失和多阶段微调）在规模化时并不总能改善性能。

Conclusion: 该研究挑战了关于具身智能扩展的一些常见假设，为从多样化机器人数据训练大规模VLA策略提供了实用指导。结果表明机器人领域的扩展需要更精细的数据混合和表示设计，而非简单的数据规模扩展。

Abstract: While Vision-Language-Action (VLA) models show strong promise for generalist robot control, it remains unclear whether -- and under what conditions -- the standard "scale data" recipe translates to robotics, where training data is inherently heterogeneous across embodiments, sensors, and action spaces. We present a systematic, controlled study of VLA scaling that revisits core training choices for pretraining across diverse robots. Using a representative VLA framework that combines a vision-language backbone with flow-matching, we ablate key design decisions under matched conditions and evaluate in extensive simulation and real-robot experiments. To improve the reliability of real-world results, we introduce a Grouped Blind Ensemble protocol that blinds operators to model identity and separates policy execution from outcome judgment, reducing experimenter bias. Our analysis targets three dimensions of VLA scaling. (1) Physical alignment: we show that a unified end-effector (EEF)-relative action representation is critical for robust cross-embodiment transfer. (2) Embodiment mixture: we find that naively pooling heterogeneous robot datasets often induces negative transfer rather than gains, underscoring the fragility of indiscriminate data scaling. (3) Training regularization: we observe that intuitive strategies, such as sensory dropout and multi-stage fine-tuning, do not consistently improve performance at scale. Together, this study challenge some common assumptions about embodied scaling and provide practical guidance for training large-scale VLA policies from diverse robotic data. Project website: https://research.beingbeyond.com/rethink_vla

</details>


### [88] [NavDreamer: Video Models as Zero-Shot 3D Navigators](https://arxiv.org/abs/2602.09765)
*Xijie Huang,Weiqi Gai,Tianyue Wu,Congyu Wang,Zhiyang Liu,Xin Zhou,Yuze Wu,Fei Gao*

Main category: cs.RO

TL;DR: NavDreamer：基于视频生成的3D导航框架，利用生成视频模型作为语言指令与导航轨迹的通用接口，通过采样优化和逆动力学模型实现零样本泛化


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在导航任务中存在数据稀缺、收集成本高、静态表示无法捕捉时空动态和物理规律等关键限制

Method: 1) 使用生成视频模型作为语言指令到导航轨迹的通用接口；2) 引入基于采样的优化方法，利用VLM进行轨迹评分和选择；3) 使用逆动力学模型从生成的视频计划解码可执行的导航路径点

Result: 在多个视频模型骨干上进行了广泛实验，展示了在新对象和未见环境中的鲁棒泛化能力，消融研究表明导航的高层决策特性特别适合基于视频的规划

Conclusion: 视频的时空信息编码能力和互联网规模可用性结合，能够实现导航任务的强零样本泛化，视频生成模型为导航规划提供了有效的通用接口

Abstract: Previous Vision-Language-Action models face critical limitations in navigation: scarce, diverse data from labor-intensive collection and static representations that fail to capture temporal dynamics and physical laws. We propose NavDreamer, a video-based framework for 3D navigation that leverages generative video models as a universal interface between language instructions and navigation trajectories. Our main hypothesis is that video's ability to encode spatiotemporal information and physical dynamics, combined with internet-scale availability, enables strong zero-shot generalization in navigation. To mitigate the stochasticity of generative predictions, we introduce a sampling-based optimization method that utilizes a VLM for trajectory scoring and selection. An inverse dynamics model is employed to decode executable waypoints from generated video plans for navigation. To systematically evaluate this paradigm in several video model backbones, we introduce a comprehensive benchmark covering object navigation, precise navigation, spatial grounding, language control, and scene reasoning. Extensive experiments demonstrate robust generalization across novel objects and unseen environments, with ablation studies revealing that navigation's high-level decision-making nature makes it particularly suited for video-based planning.

</details>


### [89] [Diverse Skill Discovery for Quadruped Robots via Unsupervised Learning](https://arxiv.org/abs/2602.09767)
*Ruopeng Cui,Yifei Bi,Haojie Luo,Wei Li*

Main category: cs.RO

TL;DR: 提出OMoE架构和多判别器框架，用于无监督技能发现，解决现有方法的学习效率低和奖励欺骗问题，在四足机器人上实现了多样化的运动技能。


<details>
  <summary>Details</summary>
Motivation: 强化学习需要专家精心设计奖励函数，模仿学习需要昂贵的任务特定数据。现有无监督技能发现方法存在两个关键限制：1）依赖单一策略学习多样化技能而不建模共享结构，导致学习效率低；2）容易发生奖励欺骗，奖励信号快速收敛但实际技能多样性不足。

Method: 提出正交混合专家（OMoE）架构，防止多样化行为在表示空间中重叠，使单一策略能够掌握广泛的运动技能。设计多判别器框架，不同判别器在不同观察空间上操作，有效缓解奖励欺骗问题。

Result: 在12-DOF Unitree A1四足机器人上评估，展示了多样化的运动技能。实验表明，提出的框架提高了训练效率，与基线相比状态空间覆盖率扩大了18.3%。

Conclusion: OMoE架构和多判别器框架能够有效解决无监督技能发现中的表示重叠和奖励欺骗问题，提高学习效率并实现更广泛的状态空间覆盖。

Abstract: Reinforcement learning necessitates meticulous reward shaping by specialists to elicit target behaviors, while imitation learning relies on costly task-specific data. In contrast, unsupervised skill discovery can potentially reduce these burdens by learning a diverse repertoire of useful skills driven by intrinsic motivation. However, existing methods exhibit two key limitations: they typically rely on a single policy to master a versatile repertoire of behaviors without modeling the shared structure or distinctions among them, which results in low learning efficiency; moreover, they are susceptible to reward hacking, where the reward signal increases and converges rapidly while the learned skills display insufficient actual diversity. In this work, we introduce an Orthogonal Mixture-of-Experts (OMoE) architecture that prevents diverse behaviors from collapsing into overlapping representations, enabling a single policy to master a wide spectrum of locomotion skills. In addition, we design a multi-discriminator framework in which different discriminators operate on distinct observation spaces, effectively mitigating reward hacking. We evaluated our method on the 12-DOF Unitree A1 quadruped robot, demonstrating a diverse set of locomotion skills. Our experiments demonstrate that the proposed framework boosts training efficiency and yields an 18.3\% expansion in state-space coverage compared to the baseline.

</details>


### [90] [Design and Evaluation of an Assisted Programming Interface for Behavior Trees in Robotics](https://arxiv.org/abs/2602.09772)
*Jonathan Styrud,Matteo Iovino,Rebecca Stower,Mart Kartašev,Mikael Norrlöf,Mårten Björkman,Christian Smith*

Main category: cs.RO

TL;DR: BETR-GUI：结合多种AI辅助方法（大语言模型、规划、遗传编程、贝叶斯优化）与拖拽式编辑器的行为树编程GUI，帮助用户更高效创建机器人程序


<details>
  <summary>Details</summary>
Motivation: 需要让非专业程序员也能快速创建反应式机器人程序，目前缺乏将多种行为树生成技术与完整GUI结合的方法，无法让用户验证和编辑AI生成的程序

Method: 开发BETR-GUI系统，整合大语言模型、规划算法、遗传编程和贝叶斯优化等多种AI辅助方法，提供拖拽式编辑器，让用户可以验证和编辑AI生成的行为树

Result: 60名参与者的用户研究表明，结合多种辅助方法的BETR-GUI能帮助用户更好地完成机器人编程任务，且使用完整BETR-GUI的人类用户表现优于单独运行的AI助手

Conclusion: BETR-GUI通过结合多种AI辅助方法与直观的GUI界面，有效提升了机器人编程的效率和质量，实现了人机协作的优势

Abstract: The possibility to create reactive robot programs faster without the need for extensively trained programmers is becoming increasingly important. So far, it has not been explored how various techniques for creating Behavior Tree (BT) program representations could be combined with complete graphical user interfaces (GUIs) to allow a human user to validate and edit trees suggested by automated methods. In this paper, we introduce BEhavior TRee GUI (BETR-GUI) for creating BTs with the help of an AI assistant that combines methods using large language models, planning, genetic programming, and Bayesian optimization with a drag-and-drop editor. A user study with 60 participants shows that by combining different assistive methods, BETR-GUI enables users to perform better at solving the robot programming tasks. The results also show that humans using the full variant of BETR-GUI perform better than the AI assistant running on its own.

</details>


### [91] [BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation](https://arxiv.org/abs/2602.09849)
*Yucheng Hu,Jianke Zhang,Yuanfei Luo,Yanjiang Guo,Xiaoyu Chen,Xinshu Sun,Kun Feng,Qingzhou Lu,Sheng Chen,Yangang Zhang,Wei Li,Jianyu Chen*

Main category: cs.RO

TL;DR: BagelVLA是一个统一模型，将语言规划、视觉预测和动作生成集成在单一框架中，通过残差流引导技术提升复杂长时程操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型通常孤立地处理语言规划或视觉预测，很少同时整合两种能力来指导动作生成，导致在复杂长时程操作任务中表现不佳。

Method: 基于预训练的统一理解和生成模型初始化，BagelVLA将文本推理和视觉预测交织到动作执行循环中，并引入残差流引导技术，从当前观察初始化，利用单步去噪提取预测性视觉特征，以最小延迟指导动作生成。

Result: 在多个模拟和真实世界基准测试中，BagelVLA显著优于现有基线方法，特别是在需要多阶段推理的任务中表现突出。

Conclusion: BagelVLA通过统一语言规划、视觉预测和动作生成，为具身智能体提供了更强大的任务推理和精确动作生成能力，在复杂操作任务中取得了显著改进。

Abstract: Equipping embodied agents with the ability to reason about tasks, foresee physical outcomes, and generate precise actions is essential for general-purpose manipulation. While recent Vision-Language-Action (VLA) models have leveraged pre-trained foundation models, they typically focus on either linguistic planning or visual forecasting in isolation. These methods rarely integrate both capabilities simultaneously to guide action generation, leading to suboptimal performance in complex, long-horizon manipulation tasks. To bridge this gap, we propose BagelVLA, a unified model that integrates linguistic planning, visual forecasting, and action generation within a single framework. Initialized from a pretrained unified understanding and generative model, BagelVLA is trained to interleave textual reasoning and visual prediction directly into the action execution loop. To efficiently couple these modalities, we introduce Residual Flow Guidance (RFG), which initializes from current observation and leverages single-step denoising to extract predictive visual features, guiding action generation with minimal latency. Extensive experiments demonstrate that BagelVLA outperforms existing baselines by a significant margin on multiple simulated and real-world benchmarks, particularly in tasks requiring multi-stage reasoning.

</details>


### [92] [TriPilot-FF: Coordinated Whole-Body Teleoperation with Force Feedback](https://arxiv.org/abs/2602.09888)
*Zihao Li,Yanan Zhou,Ranpeng Qiu,Hangyu Wu,Guoqiang Ren,Weiming Zhi*

Main category: cs.RO

TL;DR: TriPilot-FF：用于双手机器人全身遥操作的开源系统，引入带激光雷达触觉反馈的脚踏板，结合上半身双手跟随遥操作，实现碰撞感知和可操作性引导


<details>
  <summary>Details</summary>
Motivation: 移动操作机器人的全身遥操作存在挑战：操作者需要同时协调轮式底盘和双臂，同时考虑障碍物和接触。现有界面主要基于手部操作（如VR控制器和操纵杆），脚部操作通道未被充分探索用于连续底盘控制

Method: 提出TriPilot-FF系统：1）使用低成本底盘安装激光雷达的脚踏板，通过障碍物距离信号产生阻力触觉反馈；2）结合上半身双手跟随遥操作；3）提供臂部力反馈和双手可操作性视觉引导；4）将遥操作反馈信号集成到ACT策略中

Result: 系统能够有效"协同驾驶"操作者完成长时间任务，需要精确底盘移动和协调。将遥操作反馈信号集成到ACT策略中，当额外信息可用时表现出改进的性能

Conclusion: TriPilot-FF通过脚踏板触觉反馈和全身遥操作界面，解决了移动操作机器人遥操作的协调挑战，提高了碰撞感知和可操作性，并展示了与学习策略集成的潜力

Abstract: Mobile manipulators broaden the operational envelope for robot manipulation. However, the whole-body teleoperation of such robots remains a problem: operators must coordinate a wheeled base and two arms while reasoning about obstacles and contact. Existing interfaces are predominantly hand-centric (e.g., VR controllers and joysticks), leaving foot-operated channels underexplored for continuous base control. We present TriPilot-FF, an open-source whole-body teleoperation system for a custom bimanual mobile manipulator that introduces a foot-operated pedal with lidar-driven pedal haptics, coupled with upper-body bimanual leader-follower teleoperation. Using only a low-cost base-mounted lidar, TriPilot-FF renders a resistive pedal cue from proximity-to-obstacle signals in the commanded direction, shaping operator commands toward collision-averse behaviour without an explicit collision-avoidance controller. The system also supports arm-side force reflection for contact awareness and provides real-time force and visual guidance of bimanual manipulability to prompt mobile base repositioning, thereby improving reach. We demonstrate the capability of TriPilot-FF to effectively ``co-pilot'' the human operator over long time-horizons and tasks requiring precise mobile base movement and coordination. Finally, we incorporate teleoperation feedback signals into an Action Chunking with Transformers (ACT) policy and demonstrate improved performance when the additional information is available. We release the pedal device design, full software stack, and conduct extensive real-world evaluations on a bimanual wheeled platform. The project page of TriPilot-FF is http://bit.ly/46H3ZJT.

</details>


### [93] [TaCo: A Benchmark for Lossless and Lossy Codecs of Heterogeneous Tactile Data](https://arxiv.org/abs/2602.09893)
*Zhengxue Cheng,Yan Zhao,Keyu Wang,Hengdi Zhang,Li Song*

Main category: cs.RO

TL;DR: TaCo是首个触觉数据编解码器综合基准，评估了30种压缩方法，并提出了专门针对触觉数据训练的数据驱动编解码器TaCo-LL和TaCo-L，在多种任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 触觉传感对具身智能至关重要，但在严格带宽约束下的实时机器人应用中，高效的触觉数据压缩仍未被充分探索。触觉数据固有的异质性和时空复杂性使这一挑战更加困难。

Method: 提出TaCo基准，评估30种压缩方法（包括现成压缩算法和神经编解码器），覆盖5个不同传感器类型的数据集。系统评估无损和有损压缩方案在四个关键任务上的表现：无损存储、人类可视化、材料和物体分类、灵巧机器人抓取。首创专门针对触觉数据训练的数据驱动编解码器TaCo-LL（无损）和TaCo-L（有损）。

Result: 验证了TaCo-LL和TaCo-L的优越性能。该基准为理解压缩效率与任务性能之间的关键权衡提供了基础框架。

Conclusion: TaCo基准为触觉数据压缩研究奠定了基础，促进了未来触觉感知的进步，特别是在实时机器人应用中平衡压缩效率和任务性能方面。

Abstract: Tactile sensing is crucial for embodied intelligence, providing fine-grained perception and control in complex environments. However, efficient tactile data compression, which is essential for real-time robotic applications under strict bandwidth constraints, remains underexplored. The inherent heterogeneity and spatiotemporal complexity of tactile data further complicate this challenge. To bridge this gap, we introduce TaCo, the first comprehensive benchmark for Tactile data Codecs. TaCo evaluates 30 compression methods, including off-the-shelf compression algorithms and neural codecs, across five diverse datasets from various sensor types. We systematically assess both lossless and lossy compression schemes on four key tasks: lossless storage, human visualization, material and object classification, and dexterous robotic grasping. Notably, we pioneer the development of data-driven codecs explicitly trained on tactile data, TaCo-LL (lossless) and TaCo-L (lossy). Results have validated the superior performance of our TaCo-LL and TaCo-L. This benchmark provides a foundational framework for understanding the critical trade-offs between compression efficiency and task performance, paving the way for future advances in tactile perception.

</details>


### [94] [Instruct2Act: From Human Instruction to Actions Sequencing and Execution via Robot Action Network for Robotic Manipulation](https://arxiv.org/abs/2602.09940)
*Archit Sharma,Dharmendra Sharma,John Rebeiro,Peeyush Thakur,Narendra Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 提出一个轻量级、完全在设备上运行的机器人指令解析系统，将自然语言指令转换为可靠操作，包含Instruct2Act指令解析模块和RAN机器人动作网络，在资源受限的单摄像头环境中实现实时确定性操作。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实世界环境中执行自由形式的人类指令时，常因计算和感知限制而表现不佳。现有方法通常依赖云端服务或复杂系统，无法在资源受限的设备上实时运行。

Method: 采用两阶段流水线：1) Instruct2Act模块使用紧凑的BiLSTM和多头注意力自编码器将指令解析为原子动作序列；2) RAN机器人动作网络结合动态自适应轨迹径向网络(DATRN)和基于YOLOv8的视觉环境分析器，为每个子动作生成精确控制轨迹。

Result: 在自定义数据集上，Instruct2Act达到91.5%的子动作预测准确率。真实机器人评估在四个任务（拾取-放置、拾取-倾倒、擦拭、拾取-给予）中总体成功率90%，子动作推理时间<3.8秒，端到端执行时间30-60秒。

Conclusion: 细粒度指令到动作解析，结合DATRN轨迹生成和视觉引导，为资源受限的单摄像头环境中的确定性实时操作提供了实用路径，系统完全在设备上运行，无需云端服务。

Abstract: Robots often struggle to follow free-form human instructions in real-world settings due to computational and sensing limitations. We address this gap with a lightweight, fully on-device pipeline that converts natural-language commands into reliable manipulation. Our approach has two stages: (i) the instruction to actions module (Instruct2Act), a compact BiLSTM with a multi-head-attention autoencoder that parses an instruction into an ordered sequence of atomic actions (e.g., reach, grasp, move, place); and (ii) the robot action network (RAN), which uses the dynamic adaptive trajectory radial network (DATRN) together with a vision-based environment analyzer (YOLOv8) to generate precise control trajectories for each sub-action. The entire system runs on a modest system with no cloud services. On our custom proprietary dataset, Instruct2Act attains 91.5% sub-actions prediction accuracy while retaining a small footprint. Real-robot evaluations across four tasks (pick-place, pick-pour, wipe, and pick-give) yield an overall 90% success; sub-action inference completes in < 3.8s, with end-to-end executions in 30-60s depending on task complexity. These results demonstrate that fine-grained instruction-to-action parsing, coupled with DATRN-based trajectory generation and vision-guided grounding, provides a practical path to deterministic, real-time manipulation in resource-constrained, single-camera settings.

</details>


### [95] [Hydra-Nav: Object Navigation via Adaptive Dual-Process Reasoning](https://arxiv.org/abs/2602.09972)
*Zixuan Wang,Huang Fang,Shaoan Wang,Yuanfei Luo,Heng Dong,Wei Li,Yiming Gan*

Main category: cs.RO

TL;DR: Hydra-Nav是一个用于物体目标导航的统一视觉语言模型架构，通过自适应切换慢速推理系统和快速执行系统，结合三阶段课程训练，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的物体目标导航方法存在成功率低、未见物体定位效率低的问题，主要原因是时空推理能力弱。现有注入推理的方法虽然提高了成功率，但带来了巨大的计算开销。

Method: 提出Hydra-Nav统一架构，自适应切换慢速推理系统（分析探索历史、制定高层计划）和快速执行系统（高效执行）。采用三阶段课程训练：1) 空间-动作对齐强化轨迹规划；2) 记忆-推理集成增强长时域探索的时空推理；3) 迭代拒绝微调在关键决策点实现选择性推理。

Result: 在HM3D、MP3D和OVON基准测试中达到最先进性能，分别比第二名方法高出11.1%、17.4%和21.2%。同时提出SOT（操作时间加权的成功率）新指标来衡量不同推理强度VLM的搜索效率，结果显示自适应推理显著提高了搜索效率。

Conclusion: Hydra-Nav通过自适应切换慢速推理和快速执行系统，结合三阶段课程训练，有效解决了物体目标导航中推理效率与效果之间的权衡问题，显著提高了导航成功率和搜索效率。

Abstract: While large vision-language models (VLMs) show promise for object goal navigation, current methods still struggle with low success rates and inefficient localization of unseen objects--failures primarily attributed to weak temporal-spatial reasoning. Meanwhile, recent attempts to inject reasoning into VLM-based agents improve success rates but incur substantial computational overhead. To address both the ineffectiveness and inefficiency of existing approaches, we introduce Hydra-Nav, a unified VLM architecture that adaptively switches between a deliberative slow system for analyzing exploration history and formulating high-level plans, and a reactive fast system for efficient execution. We train Hydra-Nav through a three-stage curriculum: (i) spatial-action alignment to strengthen trajectory planning, (ii) memory-reasoning integration to enhance temporal-spatial reasoning over long-horizon exploration, and (iii) iterative rejection fine-tuning to enable selective reasoning at critical decision points. Extensive experiments demonstrate that Hydra-Nav achieves state-of-the-art performance on the HM3D, MP3D, and OVON benchmarks, outperforming the second-best methods by 11.1%, 17.4%, and 21.2%, respectively. Furthermore, we introduce SOT (Success weighted by Operation Time), a new metric to measure search efficiency across VLMs with varying reasoning intensity. Results show that adaptive reasoning significantly enhances search efficiency over fixed-frequency baselines.

</details>


### [96] [RoboInter: A Holistic Intermediate Representation Suite Towards Robotic Manipulation](https://arxiv.org/abs/2602.09973)
*Hao Li,Ziqin Wang,Zi-han Ding,Shuai Yang,Yilun Chen,Yang Tian,Xiaolin Hu,Tai Wang,Dahua Lin,Feng Zhao,Si Liu,Jiangmiao Pang*

Main category: cs.RO

TL;DR: RoboInter Manipulation Suite：一个包含数据、基准和模型的统一资源，用于机器人操作中的中间表示，通过大规模数据集（23万+片段）和多样化标注（10+类别）提升视觉-语言-动作模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据集成本高、具身特定性强、覆盖不足，限制了视觉-语言-动作模型的泛化。现有"规划-执行"方法依赖中间监督，但现有数据集缺乏此类标注。

Method: 1) RoboInter-Tool：轻量级GUI工具，支持半自动标注多样化中间表示；2) RoboInter-Data：大规模数据集（23万+片段，571场景），提供密集的每帧标注（10+类别）；3) RoboInter-VQA：9个空间和20个时间具身VQA类别基准；4) RoboInter-VLA：集成"规划-执行"框架，支持模块化和端到端变体。

Result: 构建了超过23万片段的大规模数据集，涵盖571个多样化场景，提供10+类别的密集中间表示标注，在规模和标注质量上显著超越先前工作，建立了系统化的具身推理基准。

Conclusion: RoboInter为通过细粒度、多样化的中间表示推进稳健和可泛化的机器人学习提供了实用基础，解决了现有数据集的局限性，支持更有效的视觉-语言-动作模型开发。

Abstract: Advances in large vision-language models (VLMs) have stimulated growing interest in vision-language-action (VLA) systems for robot manipulation. However, existing manipulation datasets remain costly to curate, highly embodiment-specific, and insufficient in coverage and diversity, thereby hindering the generalization of VLA models. Recent approaches attempt to mitigate these limitations via a plan-then-execute paradigm, where high-level plans (e.g., subtasks, trace) are first generated and subsequently translated into low-level actions, but they critically rely on extra intermediate supervision, which is largely absent from existing datasets. To bridge this gap, we introduce the RoboInter Manipulation Suite, a unified resource including data, benchmarks, and models of intermediate representations for manipulation. It comprises RoboInter-Tool, a lightweight GUI that enables semi-automatic annotation of diverse representations, and RoboInter-Data, a large-scale dataset containing over 230k episodes across 571 diverse scenes, which provides dense per-frame annotations over more than 10 categories of intermediate representations, substantially exceeding prior work in scale and annotation quality. Building upon this foundation, RoboInter-VQA introduces 9 spatial and 20 temporal embodied VQA categories to systematically benchmark and enhance the embodied reasoning capabilities of VLMs. Meanwhile, RoboInter-VLA offers an integrated plan-then-execute framework, supporting modular and end-to-end VLA variants that bridge high-level planning with low-level execution via intermediate supervision. In total, RoboInter establishes a practical foundation for advancing robust and generalizable robotic learning via fine-grained and diverse intermediate representations.

</details>


### [97] [Acoustic Drone Package Delivery Detection](https://arxiv.org/abs/2602.09991)
*François Marcoux,François Grondin*

Main category: cs.RO

TL;DR: 基于地面麦克风阵列的声学包裹投递检测算法，通过分析无人机螺旋桨转速变化识别监狱等禁区的非法无人机投递事件


<details>
  <summary>Details</summary>
Motivation: 近年来，无人机在监狱等禁区非法投递成为重大安全挑战。现有研究多关注无人机检测或定位，但对投递事件识别关注不足。本研究首次提出基于声学的包裹投递检测算法。

Method: 使用地面麦克风阵列采集声学信号，通过深度神经网络从梅尔频谱图中检测无人机存在并估计螺旋桨转速（叶片通过频率BPF）。算法分析BPF变化，基于特定时间前后的突变识别可能的投递时刻。

Result: 当无人机距离麦克风阵列小于150米时，叶片通过频率估计器的平均绝对误差为16Hz。无人机存在检测准确率达97%。投递检测算法正确识别96%的事件，误报率为8%。声学信号检测范围可达100米。

Conclusion: 研究表明，基于声学特征可以检测无人机投递事件，为监狱等禁区的安全监控提供了新的技术方案，有效识别非法无人机投递行为。

Abstract: In recent years, the illicit use of unmanned aerial vehicles (UAVs) for deliveries in restricted area such as prisons became a significant security challenge. While numerous studies have focused on UAV detection or localization, little attention has been given to delivery events identification. This study presents the first acoustic package delivery detection algorithm using a ground-based microphone array. The proposed method estimates both the drone's propeller speed and the delivery event using solely acoustic features. A deep neural network detects the presence of a drone and estimates the propeller's rotation speed or blade passing frequency (BPF) from a mel spectrogram. The algorithm analyzes the BPFs to identify probable delivery moments based on sudden changes before and after a specific time. Results demonstrate a mean absolute error of the blade passing frequency estimator of 16 Hz when the drone is less than 150 meters away from the microphone array. The drone presence detection estimator has a accuracy of 97%. The delivery detection algorithm correctly identifies 96% of events with a false positive rate of 8%. This study shows that deliveries can be identified using acoustic signals up to a range of 100 meters.

</details>


### [98] [A Collaborative Safety Shield for Safe and Efficient CAV Lane Changes in Congested On-Ramp Merging](https://arxiv.org/abs/2602.10007)
*Bharathkumar Hegde,Melanie Bouroche*

Main category: cs.RO

TL;DR: 提出MARL-MASS控制器，结合多智能体安全屏障(MASS)和强化学习，在密集交通中实现安全与效率平衡的换道控制


<details>
  <summary>Details</summary>
Motivation: 现有换道控制器要么只保证安全，要么只提升交通效率，未能同时考虑这两个冲突目标，特别是在密集交通场景下

Method: 1) 设计基于控制屏障函数的多智能体安全屏障(MASS)，通过图结构捕捉CAV间交互；2) 将MASS集成到最先进的多智能体强化学习换道控制器中；3) 定义定制奖励函数优先提升效率

Result: 在拥堵匝道合流仿真中，MASS能保证安全约束下的协作换道，定制奖励函数提升了带安全屏障的MARL策略稳定性，有效平衡安全与效率

Conclusion: MARL-MASS通过鼓励在安全约束下探索协作换道策略，在拥堵交通中有效平衡了安全保证和交通效率提升的权衡

Abstract: Lane changing in dense traffic is a significant challenge for Connected and Autonomous Vehicles (CAVs). Existing lane change controllers primarily either ensure safety or collaboratively improve traffic efficiency, but do not consider these conflicting objectives together. To address this, we propose the Multi-Agent Safety Shield (MASS), designed using Control Barrier Functions (CBFs) to enable safe and collaborative lane changes. The MASS enables collaboration by capturing multi-agent interactions among CAVs through interaction topologies constructed as a graph using a simple algorithm. Further, a state-of-the-art Multi-Agent Reinforcement Learning (MARL) lane change controller is extended by integrating MASS to ensure safety and defining a customised reward function to prioritise efficiency improvements. As a result, we propose a lane change controller, known as MARL-MASS, and evaluate it in a congested on-ramp merging simulation. The results demonstrate that MASS enables collaborative lane changes with safety guarantees by strictly respecting the safety constraints. Moreover, the proposed custom reward function improves the stability of MARL policies trained with a safety shield. Overall, by encouraging the exploration of a collaborative lane change policy while respecting safety constraints, MARL-MASS effectively balances the trade-off between ensuring safety and improving traffic efficiency in congested traffic. The code for MARL-MASS is available with an open-source licence at https://github.com/hkbharath/MARL-MASS

</details>


### [99] [Learning Force-Regulated Manipulation with a Low-Cost Tactile-Force-Controlled Gripper](https://arxiv.org/abs/2602.10013)
*Xuhui Kang,Tongxuan Tian,Sung-Wook Lee,Binghao Huang,Yunzhu Li,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 提出TF-Gripper低成本力控夹爪和RETAF反应式触觉力调节框架，用于机器人对日常力敏感物体的精确力控制操作


<details>
  <summary>Details</summary>
Motivation: 日常物体（如薯片）操作需要精确的力调节，商用夹爪成本高或最小力过大，不适合研究力控制策略学习

Method: 1) 开发TF-Gripper低成本力控夹爪（约150美元），集成触觉传感反馈；2) 设计配套遥操作设备记录人力数据；3) 提出RETAF框架，将力控制与臂姿预测解耦，使用手腕图像和触觉反馈进行高频力调节

Result: 在五个真实世界任务中，直接力控制相比位置控制显著提升抓取稳定性和任务性能，触觉反馈对力调节至关重要，RETAF始终优于基线方法

Conclusion: 该工作为机器人操作中力控制策略学习的规模化开辟了道路，TF-Gripper和RETAF框架能有效处理日常力敏感物体的精确操作

Abstract: Successfully manipulating many everyday objects, such as potato chips, requires precise force regulation. Failure to modulate force can lead to task failure or irreversible damage to the objects. Humans can precisely achieve this by adapting force from tactile feedback, even within a short period of physical contact. We aim to give robots this capability. However, commercial grippers exhibit high cost or high minimum force, making them unsuitable for studying force-controlled policy learning with everyday force-sensitive objects. We introduce TF-Gripper, a low-cost (~$150) force-controlled parallel-jaw gripper that integrates tactile sensing as feedback. It has an effective force range of 0.45-45N and is compatible with different robot arms. Additionally, we designed a teleoperation device paired with TF-Gripper to record human-applied grasping forces. While standard low-frequency policies can be trained on this data, they struggle with the reactive, contact-dependent nature of force regulation. To overcome this, we propose RETAF (REactive Tactile Adaptation of Force), a framework that decouples grasping force control from arm pose prediction. RETAF regulates force at high frequency using wrist images and tactile feedback, while a base policy predicts end-effector pose and gripper open/close action. We evaluate TF-Gripper and RETAF across five real-world tasks requiring precise force regulation. Results show that compared to position control, direct force control significantly improves grasp stability and task performance. We further show that tactile feedback is essential for force regulation, and that RETAF consistently outperforms baselines and can be integrated with various base policies. We hope this work opens a path for scaling the learning of force-controlled policies in robotic manipulation. Project page: https://force-gripper.github.io .

</details>


### [100] [RoboSubtaskNet: Temporal Sub-task Segmentation for Human-to-Robot Skill Transfer in Real-World Environments](https://arxiv.org/abs/2602.10015)
*Dharmendra Sharma,Archit Sharma,John Reberio,Vaibhav Kesharwani,Peeyush Thakur,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: RoboSubtaskNet：多阶段人机协作子任务分割框架，结合注意力增强I3D特征和改进的MS-TCN，用于长视频中细粒度子任务的时序定位与分类，可直接映射到机器人可执行动作。


<details>
  <summary>Details</summary>
Motivation: 在长未修剪视频中定位和分类细粒度子任务对于安全的人机协作至关重要。与通用活动识别不同，协作操作需要可直接映射到机器人可执行动作的子任务标签。

Method: 提出RoboSubtaskNet多阶段框架：结合注意力增强的I3D特征（RGB+光流）和改进的MS-TCN，采用斐波那契膨胀调度以捕捉短时程转换（如抓取-放置）。使用复合损失函数（交叉熵+时序正则化器）减少过分割并鼓励有效子任务进展。

Result: 在GTEA数据集上：F1@50=79.5%，Edit=88.6%，Acc=78.9%；在Breakfast数据集上：F1@50=30.4%，Edit=52.0%，Acc=53.5%；在RoboSubtask数据集上：F1@50=94.2%，Edit=95.6%，Acc=92.2%。在7-DoF Kinova Gen3机械臂上验证，端到端任务成功率约91.25%。

Conclusion: RoboSubtaskNet在多个基准测试中优于MS-TCN和MS-TCN++，展示了从子任务级视频理解到实际机器人操作的实用路径，为人机协作提供了有效的感知到执行解决方案。

Abstract: Temporally locating and classifying fine-grained sub-task segments in long, untrimmed videos is crucial to safe human-robot collaboration. Unlike generic activity recognition, collaborative manipulation requires sub-task labels that are directly robot-executable. We present RoboSubtaskNet, a multi-stage human-to-robot sub-task segmentation framework that couples attention-enhanced I3D features (RGB plus optical flow) with a modified MS-TCN employing a Fibonacci dilation schedule to capture better short-horizon transitions such as reach-pick-place. The network is trained with a composite objective comprising cross-entropy and temporal regularizers (truncated MSE and a transition-aware term) to reduce over-segmentation and to encourage valid sub-task progressions. To close the gap between vision benchmarks and control, we introduce RoboSubtask, a dataset of healthcare and industrial demonstrations annotated at the sub-task level and designed for deterministic mapping to manipulator primitives. Empirically, RoboSubtaskNet outperforms MS-TCN and MS-TCN++ on GTEA and our RoboSubtask benchmark (boundary-sensitive and sequence metrics), while remaining competitive on the long-horizon Breakfast benchmark. Specifically, RoboSubtaskNet attains F1 @ 50 = 79.5%, Edit = 88.6%, Acc = 78.9% on GTEA; F1 @ 50 = 30.4%, Edit = 52.0%, Acc = 53.5% on Breakfast; and F1 @ 50 = 94.2%, Edit = 95.6%, Acc = 92.2% on RoboSubtask. We further validate the full perception-to-execution pipeline on a 7-DoF Kinova Gen3 manipulator, achieving reliable end-to-end behavior in physical trials (overall task success approx 91.25%). These results demonstrate a practical path from sub-task level video understanding to deployed robotic manipulation in real-world settings.

</details>


### [101] [A Collision-Free Sway Damping Model Predictive Controller for Safe and Reactive Forestry Crane Navigation](https://arxiv.org/abs/2602.10035)
*Marc-Philip Ecker,Christoph Fröhlich,Johannes Huemer,David Gruber,Bernhard Bischof,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 首个将碰撞避免和负载摆动控制统一在单一MPC框架中的林业起重机控制器，通过LiDAR在线建图和欧几里得距离场实现实时环境适应


<details>
  <summary>Details</summary>
Motivation: 林业起重机在动态、非结构化的户外环境中作业，需要同时解决碰撞避免和负载摆动控制问题。现有方法要么单独处理摆动阻尼（基于预定义的无碰撞路径），要么只在全局规划层面进行碰撞避免，缺乏统一解决方案。

Method: 提出首个碰撞避免与摆动阻尼统一的模型预测控制器（MPC），将LiDAR环境建图通过在线欧几里得距离场（EDF）直接集成到MPC中，实现实时环境适应。控制器同时强制执行碰撞约束并阻尼负载摆动。

Result: 在真实林业起重机上的实验验证表明，该控制器能有效阻尼摆动并成功避免障碍物。具备以下能力：(i) 准静态环境变化时重新规划，(ii) 扰动下保持无碰撞操作，(iii) 无绕过路径时提供安全停止。

Conclusion: 首次实现了林业起重机碰撞避免与摆动阻尼的统一控制框架，通过LiDAR在线建图和MPC集成，在动态户外环境中实现了安全导航，为林业起重机操作提供了更安全、更高效的解决方案。

Abstract: Forestry cranes operate in dynamic, unstructured outdoor environments where simultaneous collision avoidance and payload sway control are critical for safe navigation. Existing approaches address these challenges separately, either focusing on sway damping with predefined collision-free paths or performing collision avoidance only at the global planning level. We present the first collision-free, sway-damping model predictive controller (MPC) for a forestry crane that unifies both objectives in a single control framework. Our approach integrates LiDAR-based environment mapping directly into the MPC using online Euclidean distance fields (EDF), enabling real-time environmental adaptation. The controller simultaneously enforces collision constraints while damping payload sway, allowing it to (i) replan upon quasi-static environmental changes, (ii) maintain collision-free operation under disturbances, and (iii) provide safe stopping when no bypass exists. Experimental validation on a real forestry crane demonstrates effective sway damping and successful obstacle avoidance. A video can be found at https://youtu.be/tEXDoeLLTxA.

</details>


### [102] [Humanoid Factors: Design Principles for AI Humanoids in Human Worlds](https://arxiv.org/abs/2602.10069)
*Xinyuan Liu,Eren Sadikoglu,Ransalu Senanayake,Lixiao Huang*

Main category: cs.RO

TL;DR: 提出"人形因素"框架，用于指导人形机器人设计，确保其与人类有效共存协作，包含物理、认知、社交和伦理四大支柱。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人进入人类环境，传统人因工程仅考虑人类因素已不足够，需要同时考虑人形机器人的因素，因为两者将在同一环境中共存互动。

Method: 提出包含物理、认知、社交和伦理四大支柱的"人形因素"框架，分析人类能力与基于AI基础模型的通用人形机器人能力之间的重叠与差异，并将该框架应用于评估真实世界的人形机器人控制算法。

Result: 框架揭示了传统机器人任务完成指标忽视了关键的人类认知和交互原则，证明了人形因素框架的实际应用价值。

Conclusion: 人形因素框架为设计、评估和管理持续的人-人形机器人共存提供了基础性框架。

Abstract: Human factors research has long focused on optimizing environments, tools, and systems to account for human performance. Yet, as humanoid robots begin to share our workplaces, homes, and public spaces, the design challenge expands. We must now consider not only factors for humans but also factors for humanoids, since both will coexist and interact within the same environments. Unlike conventional machines, humanoids introduce expectations of human-like behavior, communication, and social presence, which reshape usability, trust, and safety considerations. In this article, we introduce the concept of humanoid factors as a framework structured around four pillars - physical, cognitive, social, and ethical - that shape the development of humanoids to help them effectively coexist and collaborate with humans. This framework characterizes the overlap and divergence between human capabilities and those of general-purpose humanoids powered by AI foundation models. To demonstrate our framework's practical utility, we then apply the framework to evaluate a real-world humanoid control algorithm, illustrating how conventional task completion metrics in robotics overlook key human cognitive and interaction principles. We thus position humanoid factors as a foundational framework for designing, evaluating, and governing sustained human-humanoid coexistence.

</details>


### [103] [UniVTAC: A Unified Simulation Platform for Visuo-Tactile Manipulation Data Generation, Learning, and Benchmarking](https://arxiv.org/abs/2602.10093)
*Baijun Chen,Weijie Wan,Tianxing Chen,Xianda Guo,Congsheng Xu,Yuanyang Qi,Haojie Zhang,Longyan Wu,Tianling Xu,Zixuan Li,Yizhe Wu,Rui Li,Xiaokang Yang,Ping Luo,Wei Sui,Yao Mu*

Main category: cs.RO

TL;DR: UniVTAC是一个基于仿真的视觉-触觉数据合成平台，支持三种常用触觉传感器，通过大规模仿真数据训练视觉-触觉编码器，显著提升接触丰富操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作策略在机器人操作中进展迅速，但视觉单独难以鲁棒完成接触丰富的操作任务（如插入）。同时，物理世界中获取大规模可靠触觉数据成本高且困难，缺乏统一评估平台限制了策略学习和系统分析。

Method: 提出UniVTAC仿真平台，支持三种常用视觉-触觉传感器，实现可扩展可控的信息性接触交互生成。基于此平台开发UniVTAC编码器，在大规模仿真合成数据上训练，提供触觉中心的视觉-触觉表示。同时构建UniVTAC基准测试，包含八个代表性视觉-触觉操作任务。

Result: 集成UniVTAC编码器在基准测试上平均成功率提升17.1%，真实世界机器人实验显示任务成功率提升25%。

Conclusion: UniVTAC平台通过仿真合成大规模触觉数据，训练出的视觉-触觉编码器能显著提升接触丰富操作任务的性能，为触觉感知研究提供了有效的数据生成和评估解决方案。

Abstract: Robotic manipulation has seen rapid progress with vision-language-action (VLA) policies. However, visuo-tactile perception is critical for contact-rich manipulation, as tasks such as insertion are difficult to complete robustly using vision alone. At the same time, acquiring large-scale and reliable tactile data in the physical world remains costly and challenging, and the lack of a unified evaluation platform further limits policy learning and systematic analysis. To address these challenges, we propose UniVTAC, a simulation-based visuo-tactile data synthesis platform that supports three commonly used visuo-tactile sensors and enables scalable and controllable generation of informative contact interactions. Based on this platform, we introduce the UniVTAC Encoder, a visuo-tactile encoder trained on large-scale simulation-synthesized data with designed supervisory signals, providing tactile-centric visuo-tactile representations for downstream manipulation tasks. In addition, we present the UniVTAC Benchmark, which consists of eight representative visuo-tactile manipulation tasks for evaluating tactile-driven policies. Experimental results show that integrating the UniVTAC Encoder improves average success rates by 17.1% on the UniVTAC Benchmark, while real-world robotic experiments further demonstrate a 25% improvement in task success. Our webpage is available at https://univtac.github.io/.

</details>


### [104] [VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model](https://arxiv.org/abs/2602.10098)
*Jingwen Sun,Wenyao Zhang,Zekun Qi,Shaojie Ren,Zezhi Liu,Hanxin Zhu,Guangzhong Sun,Xin Jin,Zhibo Chen*

Main category: cs.RO

TL;DR: VLA-JEPA：一种基于联合嵌入预测架构的视觉-语言-动作预训练框架，通过泄漏无关的状态预测学习鲁棒的动作相关状态转移表示，避免外观偏差和无关运动干扰。


<details>
  <summary>Details</summary>
Motivation: 现有VLA预训练方法存在三个主要问题：1）容易受到外观偏差影响（过度关注像素变化而非状态转移）；2）对无关运动（如相机抖动）敏感；3）存在信息泄漏问题（未来信息被用作输入）。这些问题导致学习到的表示不够鲁棒，泛化能力有限。

Method: 提出VLA-JEPA框架，核心是"泄漏无关的状态预测"：目标编码器从未来帧生成潜在表示，学生路径仅能看到当前观测，未来信息仅作为监督目标而非输入。在潜在空间而非像素空间进行预测，学习对相机运动和背景变化鲁棒的动态抽象。采用两阶段训练：JEPA预训练 + 动作头微调。

Result: 在LIBERO、LIBERO-Plus、SimplerEnv和真实世界操作任务上的实验表明，VLA-JEPA相比现有方法在泛化能力和鲁棒性方面取得一致提升。

Conclusion: VLA-JEPA通过泄漏无关的状态预测机制，有效解决了现有VLA预训练中的外观偏差、无关运动和信息泄漏问题，提供了一种简单而有效的两阶段训练框架，显著提升了策略的泛化能力和鲁棒性。

Abstract: Pretraining Vision-Language-Action (VLA) policies on internet-scale video is appealing, yet current latent-action objectives often learn the wrong thing: they remain anchored to pixel variation rather than action-relevant state transitions, making them vulnerable to appearance bias, nuisance motion, and information leakage. We introduce VLA-JEPA, a JEPA-style pretraining framework that sidesteps these pitfalls by design. The key idea is \emph{leakage-free state prediction}: a target encoder produces latent representations from future frames, while the student pathway sees only the current observation -- future information is used solely as supervision targets, never as input. By predicting in latent space rather than pixel space, VLA-JEPA learns dynamics abstractions that are robust to camera motion and irrelevant background changes. This yields a simple two-stage recipe -- JEPA pretraining followed by action-head fine-tuning -- without the multi-stage complexity of prior latent-action pipelines. Experiments on LIBERO, LIBERO-Plus, SimplerEnv and real-world manipulation tasks show that VLA-JEPA achieves consistent gains in generalization and robustness over existing methods.

</details>


### [105] [Robo3R: Enhancing Robotic Manipulation with Accurate Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2602.10101)
*Sizhe Yang,Linning Xu,Hao Li,Juncheng Mu,Jia Zeng,Dahua Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: Robo3R：一个前馈的、面向机器人操作的3D重建模型，直接从RGB图像和机器人状态实时预测精确的度量尺度场景几何


<details>
  <summary>Details</summary>
Motivation: 3D空间感知对通用机器人操作至关重要，但现有深度传感器存在噪声和材质敏感性问题，而现有重建模型缺乏物理交互所需的精度和度量一致性

Method: 联合推断尺度不变的局部几何和相对相机位姿，通过学习的全局相似变换统一到规范机器人坐标系；使用掩码点云头生成锐利细粒度点云，基于关键点的PnP公式精炼相机外参和全局对齐；在Robo3R-4M合成数据集上训练

Result: 在机器人操作的下游任务中（模仿学习、仿真到真实迁移、抓取合成、无碰撞运动规划）表现优于现有最先进的重建方法和深度传感器

Conclusion: Robo3R展示了作为机器人操作替代3D感知模块的潜力，能够提供精确、度量一致的场景几何

Abstract: 3D spatial perception is fundamental to generalizable robotic manipulation, yet obtaining reliable, high-quality 3D geometry remains challenging. Depth sensors suffer from noise and material sensitivity, while existing reconstruction models lack the precision and metric consistency required for physical interaction. We introduce Robo3R, a feed-forward, manipulation-ready 3D reconstruction model that predicts accurate, metric-scale scene geometry directly from RGB images and robot states in real time. Robo3R jointly infers scale-invariant local geometry and relative camera poses, which are unified into the scene representation in the canonical robot frame via a learned global similarity transformation. To meet the precision demands of manipulation, Robo3R employs a masked point head for sharp, fine-grained point clouds, and a keypoint-based Perspective-n-Point (PnP) formulation to refine camera extrinsics and global alignment. Trained on Robo3R-4M, a curated large-scale synthetic dataset with four million high-fidelity annotated frames, Robo3R consistently outperforms state-of-the-art reconstruction methods and depth sensors. Across downstream tasks including imitation learning, sim-to-real transfer, grasp synthesis, and collision-free motion planning, we observe consistent gains in performance, suggesting the promise of this alternative 3D sensing module for robotic manipulation.

</details>


### [106] [DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos](https://arxiv.org/abs/2602.10105)
*Juncheng Mu,Sizhe Yang,Yiming Bao,Hojin Bae,Tianming Wei,Linning Xu,Boyi Li,Huazhe Xu,Jiangmiao Pang*

Main category: cs.RO

TL;DR: DexImit是一个自动化框架，将单目人类操作视频转换为物理合理的机器人数据，无需额外信息，用于解决双手灵巧操作的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 双手灵巧操作的数据稀缺限制了泛化能力，因为真实世界的数据收集昂贵且劳动密集。人类操作视频作为操作知识的直接载体，具有扩展机器人学习的巨大潜力，但人类手与机器人灵巧手之间的本体差距使得直接从人类视频预训练极具挑战性。

Method: DexImit采用四阶段生成流程：1) 从任意视角重建具有近度量尺度的手-物交互；2) 执行子任务分解和双手调度；3) 合成与演示交互一致的机器人轨迹；4) 全面的数据增强以实现零样本真实世界部署。

Result: DexImit能够基于人类视频（来自互联网或视频生成模型）生成大规模机器人数据，能够处理多样化的操作任务，包括工具使用（如切苹果）、长时程任务（如制作饮料）和精细操作（如堆叠杯子）。

Conclusion: DexImit通过弥合人类手与机器人手之间的本体差距，释放了大规模人类操作视频数据的潜力，为双手灵巧操作的泛化提供了有效的解决方案。

Abstract: Data scarcity fundamentally limits the generalization of bimanual dexterous manipulation, as real-world data collection for dexterous hands is expensive and labor-intensive. Human manipulation videos, as a direct carrier of manipulation knowledge, offer significant potential for scaling up robot learning. However, the substantial embodiment gap between human hands and robotic dexterous hands makes direct pretraining from human videos extremely challenging. To bridge this gap and unleash the potential of large-scale human manipulation video data, we propose DexImit, an automated framework that converts monocular human manipulation videos into physically plausible robot data, without any additional information. DexImit employs a four-stage generation pipeline: (1) reconstructing hand-object interactions from arbitrary viewpoints with near-metric scale; (2) performing subtask decomposition and bimanual scheduling; (3) synthesizing robot trajectories consistent with the demonstrated interactions; (4) comprehensive data augmentation for zero-shot real-world deployment. Building on these designs, DexImit can generate large-scale robot data based on human videos, either from the Internet or video generation models. DexImit is capable of handling diverse manipulation tasks, including tool use (e.g., cutting an apple), long-horizon tasks (e.g., making a beverage), and fine-grained manipulations (e.g., stacking cups).

</details>


### [107] [EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration](https://arxiv.org/abs/2602.10106)
*Modi Shi,Shijia Peng,Jin Chen,Haoran Jiang,Yinghui Li,Di Huang,Ping Luo,Hongyang Li,Li Chen*

Main category: cs.RO

TL;DR: EgoHumanoid框架首次利用丰富的自我中心人类演示数据与少量机器人数据协同训练视觉-语言-动作策略，使仿人机器人能够在多样真实环境中执行移动操作任务，性能比纯机器人基线提升51%。


<details>
  <summary>Details</summary>
Motivation: 人类演示数据具有丰富的环境多样性和自然扩展性，是机器人远程操作的理想替代方案。虽然这一范式已推动机器人手臂操控的发展，但在更具挑战性、数据需求更大的仿人机器人移动操作问题上潜力尚未充分挖掘。

Method: 开发了EgoHumanoid框架，包含系统性对齐管道：1) 硬件设计到数据处理的全流程对齐；2) 便携式可扩展人类数据收集系统；3) 视图对齐减少相机高度和视角差异；4) 动作对齐将人类动作映射到统一的运动学可行动作空间。

Result: 真实世界实验表明，结合无机器人自我中心数据比纯机器人基线性能提升51%，特别是在未见环境中表现更优。分析揭示了哪些行为能够有效迁移以及人类数据扩展的潜力。

Conclusion: EgoHumanoid首次证明了利用丰富人类演示数据训练仿人机器人移动操作策略的可行性，通过系统性对齐管道成功桥接了人类与机器人之间的具身差距，为大规模人类数据在机器人学习中的应用开辟了新途径。

Abstract: Human demonstrations offer rich environmental diversity and scale naturally, making them an appealing alternative to robot teleoperation. While this paradigm has advanced robot-arm manipulation, its potential for the more challenging, data-hungry problem of humanoid loco-manipulation remains largely unexplored. We present EgoHumanoid, the first framework to co-train a vision-language-action policy using abundant egocentric human demonstrations together with a limited amount of robot data, enabling humanoids to perform loco-manipulation across diverse real-world environments. To bridge the embodiment gap between humans and robots, including discrepancies in physical morphology and viewpoint, we introduce a systematic alignment pipeline spanning from hardware design to data processing. A portable system for scalable human data collection is developed, and we establish practical collection protocols to improve transferability. At the core of our human-to-humanoid alignment pipeline lies two key components. The view alignment reduces visual domain discrepancies caused by camera height and perspective variation. The action alignment maps human motions into a unified, kinematically feasible action space for humanoid control. Extensive real-world experiments demonstrate that incorporating robot-free egocentric data significantly outperforms robot-only baselines by 51\%, particularly in unseen environments. Our analysis further reveals which behaviors transfer effectively and the potential for scaling human data.

</details>


### [108] [ST4VLA: Spatially Guided Training for Vision-Language-Action Models](https://arxiv.org/abs/2602.10109)
*Jinhui Ye,Fangjing Wang,Ning Gao,Junqiu Yu,Yangkun Zhu,Bin Wang,Jinyu Zhang,Weiyang Jin,Yanwei Fu,Feng Zheng,Yilun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: ST4VLA是一个双系统视觉-语言-动作框架，通过空间引导训练将动作学习与视觉语言模型的空间先验对齐，显著提升了机器人任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态理解方面表现出色，但在需要将指令转换为低级运动动作的具身任务中表现不足。需要一种方法将VLM的空间理解能力与动作生成有效结合。

Method: 采用双阶段方法：1) 空间基础预训练，通过点、框和轨迹预测从网络数据和机器人数据中学习可迁移的空间先验；2) 空间引导动作后训练，通过空间提示鼓励模型产生更丰富的空间先验来指导动作生成。

Result: 在Google Robot上性能从66.1提升到84.6，在WidowX Robot上从54.7提升到73.2，在SimplerEnv上达到新的SOTA。同时展现出对未见物体、转述指令的更强泛化能力，以及对长时域扰动的鲁棒性。

Conclusion: 空间引导训练是构建鲁棒、可泛化机器人学习的有前景方向。ST4VLA框架有效保留了策略学习中的空间基础，促进了空间和动作目标的一致优化。

Abstract: Large vision-language models (VLMs) excel at multimodal understanding but fall short when extended to embodied tasks, where instructions must be transformed into low-level motor actions. We introduce ST4VLA, a dual-system Vision-Language-Action framework that leverages Spatial Guided Training to align action learning with spatial priors in VLMs. ST4VLA includes two stages: (i) spatial grounding pre-training, which equips the VLM with transferable priors via scalable point, box, and trajectory prediction from both web-scale and robot-specific data, and (ii) spatially guided action post-training, which encourages the model to produce richer spatial priors to guide action generation via spatial prompting. This design preserves spatial grounding during policy learning and promotes consistent optimization across spatial and action objectives. Empirically, ST4VLA achieves substantial improvements over vanilla VLA, with performance increasing from 66.1 -> 84.6 on Google Robot and from 54.7 -> 73.2 on WidowX Robot, establishing new state-of-the-art results on SimplerEnv. It also demonstrates stronger generalization to unseen objects and paraphrased instructions, as well as robustness to long-horizon perturbations in real-world settings. These results highlight scalable spatially guided training as a promising direction for robust, generalizable robot learning. Source code, data and models are released at https://internrobotics.github.io/internvla-m1.github.io/

</details>


### [109] [Learning Agile Quadrotor Flight in the Real World](https://arxiv.org/abs/2602.10111)
*Yunfan Ren,Zhiyuan Zhu,Jiaxu Xing,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 提出自適應框架，無需精確系統辨識或離線Sim2Real轉移，通過主動探索物理極限和線上殘差學習實現四軸飛行器敏捷飛行的持續性能提升


<details>
  <summary>Details</summary>
Motivation: 傳統學習型控制器依賴大量模擬訓練和精確系統辨識，但固定策略易受外部空氣動力干擾和內部硬體退化等分佈外場景影響，導致保守的安全邊界限制了敏捷性。線上適應雖有潛力，但安全探索物理極限存在數據稀缺和安全風險的瓶頸

Method: 提出自適應框架：1) 引入自適應時間縮放(ATS)主動探索平台物理極限；2) 使用線上殘差學習增強簡單標稱模型；3) 基於學習的混合模型，提出實世界錨定短時域反向傳播(RASH-BPTT)實現高效穩健的飛行中策略更新

Result: 四軸飛行器能可靠執行接近致動器飽和極限的敏捷機動。系統在約100秒飛行時間內將保守基礎策略的峰值速度從1.9 m/s提升至7.3 m/s，顯示實世界適應不僅能補償建模誤差，更是持續提升激進飛行性能的實用機制

Conclusion: 該自適應框架消除了對精確系統辨識或離線Sim2Real轉移的需求，通過主動探索物理極限和線上學習實現了四軸飛行器敏捷飛行的持續性能提升，為機器人系統在真實環境中的適應性控制提供了新途徑

Abstract: Learning-based controllers have achieved impressive performance in agile quadrotor flight but typically rely on massive training in simulation, necessitating accurate system identification for effective Sim2Real transfer. However, even with precise modeling, fixed policies remain susceptible to out-of-distribution scenarios, ranging from external aerodynamic disturbances to internal hardware degradation. To ensure safety under these evolving uncertainties, such controllers are forced to operate with conservative safety margins, inherently constraining their agility outside of controlled settings. While online adaptation offers a potential remedy, safely exploring physical limits remains a critical bottleneck due to data scarcity and safety risks. To bridge this gap, we propose a self-adaptive framework that eliminates the need for precise system identification or offline Sim2Real transfer. We introduce Adaptive Temporal Scaling (ATS) to actively explore platform physical limits, and employ online residual learning to augment a simple nominal model. {Based on the learned hybrid model, we further propose Real-world Anchored Short-horizon Backpropagation Through Time (RASH-BPTT) to achieve efficient and robust in-flight policy updates. Extensive experiments demonstrate that our quadrotor reliably executes agile maneuvers near actuator saturation limits. The system evolves a conservative base policy with a peak speed of 1.9 m/s to 7.3 m/s within approximately 100 seconds of flight time. These findings underscore that real-world adaptation serves not merely to compensate for modeling errors, but as a practical mechanism for sustained performance improvement in aggressive flight regimes.

</details>


### [110] [Decoupled MPPI-Based Multi-Arm Motion Planning](https://arxiv.org/abs/2602.10114)
*Dan Evron,Elias Goldsztejn,Ronen I. Brafman*

Main category: cs.RO

TL;DR: MR-STORM：基于分布式采样的多机器人运动规划算法，通过动态优先级和动态障碍物处理实现高效协同


<details>
  <summary>Details</summary>
Motivation: 现有基于采样的高自由度机械臂运动规划算法虽然可以利用GPU实现SOTA性能，但在多机器人协同控制时扩展性差，需要新的分布式解决方案

Method: 1) 扩展STORM算法处理动态障碍物；2) 让每个机械臂独立计算自己的运动规划前缀并共享给其他机械臂；3) 添加动态优先级机制，将其他机械臂的规划视为动态障碍物

Result: MR-STORM在静态和动态障碍物环境下都展现出比SOTA算法更明显的经验优势

Conclusion: MR-STORM通过分布式架构和动态优先级机制，成功解决了多机器人运动规划的扩展性问题，为高自由度机械臂协同控制提供了有效解决方案

Abstract: Recent advances in sampling-based motion planning algorithms for high DOF arms leverage GPUs to provide SOTA performance. These algorithms can be used to control multiple arms jointly, but this approach scales poorly. To address this, we extend STORM, a sampling-based model-predictive-control (MPC) motion planning algorithm, to handle multiple robots in a distributed fashion. First, we modify STORM to handle dynamic obstacles. Then, we let each arm compute its own motion plan prefix, which it shares with the other arms, which treat it as a dynamic obstacle. Finally, we add a dynamic priority scheme. The new algorithm, MR-STORM, demonstrates clear empirical advantages over SOTA algorithms when operating with both static and dynamic obstacles.

</details>
