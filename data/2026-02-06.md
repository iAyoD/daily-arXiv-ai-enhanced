<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 59]
- [cs.RO](#cs.RO) [Total: 27]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations](https://arxiv.org/abs/2602.04982)
*Deepak Gupta,Davis Bartels,Dina Demner-Fuhsman*

Main category: cs.CL

TL;DR: BioACE是一个用于评估生物医学问答和引用的自动化框架，通过完整性、正确性、精确度和召回率等多个维度来评估LLM生成的答案质量。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在生物医学问答中的广泛应用，需要自动化评估生成答案的质量和引用支持。由于生物医学领域的专业性要求专家验证，当前评估面临挑战。

Method: 提出BioACE框架，采用自动化方法评估完整性、正确性、精确度和召回率，并与人类评估进行相关性分析。同时考虑自然语言推理、预训练语言模型和LLM等多种现有方法来评估引用质量。

Result: 通过大量实验和分析，确定了生物医学答案和引用评估的最佳方法，并将其集成到BioACE评估包中。

Conclusion: BioACE提供了一个有效的自动化框架来评估生物医学问答和引用质量，解决了该领域专业评估的挑战，并提供了最佳实践方法。

Abstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluation of text generated by LLMs remains a challenge for question answering, retrieval-augmented generation (RAG), summarization, and many other natural language processing tasks in the biomedical domain, due to the requirements of expert assessment to verify consistency with the scientific literature and complex medical terminology. In this work, we propose BioACE, an automated framework for evaluating biomedical answers and citations against the facts stated in the answers. The proposed BioACE framework considers multiple aspects, including completeness, correctness, precision, and recall, in relation to the ground-truth nuggets for answer evaluation. We developed automated approaches to evaluate each of the aforementioned aspects and performed extensive experiments to assess and analyze their correlation with human evaluations. In addition, we considered multiple existing approaches, such as natural language inference (NLI) and pre-trained language models and LLMs, to evaluate the quality of evidence provided to support the generated answers in the form of citations into biomedical literature. With the detailed experiments and analysis, we provide the best approaches for biomedical answer and citation evaluation as a part of BioACE (https://github.com/deepaknlp/BioACE) evaluation package.

</details>


### [2] [CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System](https://arxiv.org/abs/2602.05004)
*Zexin Lin,Jiachen Yu,Haoyang Zhang,Yuzhao Li,Zhonghang Li,Yujiu Yang,Junjie Wang,Xiaoqiang Ji*

Main category: cs.CL

TL;DR: CoWork-X：实时协作任务的主动协同进化框架，通过结构化技能库和预算约束的补丁式技能整合，在保持低延迟的同时实现持续性能提升


<details>
  <summary>Details</summary>
Motivation: 当前语言条件智能体在高度协作任务中面临两个矛盾约束：需要亚秒级实时协调，同时要在严格的在线token预算下进行持续多回合适应。现有方法要么依赖频繁的回合内推理导致延迟和时序抖动，要么通过非结构化文本进行回合后改进，难以编译成可靠的低成本执行。

Method: 提出CoWork-X主动协同进化框架，将同伴协作建模为跨回合的闭环优化问题。框架包含：1) Skill-Agent：通过HTN（分层任务网络）从结构化、可解释、可组合的技能库中检索技能执行；2) 回合后Co-Optimizer：在明确预算约束和漂移正则化下进行补丁式技能整合。

Result: 在具有挑战性的Overcooked-AI类实时协作基准测试中，CoWork-X实现了稳定、累积的性能提升，同时持续降低在线延迟和token使用量。

Conclusion: CoWork-X通过将快速-慢速记忆分离思想应用于同伴协作，解决了实时协调与持续适应之间的平衡问题，为语言条件智能体在严格约束环境中的高效协作提供了有效解决方案。

Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is difficult to compile into reliable low-cost execution. We propose CoWork-X, an active co-evolution framework that casts peer collaboration as a closed-loop optimization problem across episodes, inspired by fast--slow memory separation. CoWork-X instantiates a Skill-Agent that executes via HTN (hierarchical task network)-based skill retrieval from a structured, interpretable, and compositional skill library, and a post-episode Co-Optimizer that performs patch-style skill consolidation with explicit budget constraints and drift regularization. Experiments in challenging Overcooked-AI-like realtime collaboration benchmarks demonstrate that CoWork-X achieves stable, cumulative performance gains while steadily reducing online latency and token usage.

</details>


### [3] [Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation](https://arxiv.org/abs/2602.05035)
*Sean Trott,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 多语言语言模型在词汇消歧任务上表现不如单语模型，研究发现这种"多语言惩罚"源于三种能力限制：表征限制、注意力限制和词汇限制。


<details>
  <summary>Details</summary>
Motivation: 多语言语言模型有时表现不如单语模型，可能是由于模型容量限制。本研究旨在量化这种"多语言惩罚"，特别是在需要精确语义表征和上下文机制的词汇消歧任务上，并探索具体的能力约束机制。

Method: 使用英语和西班牙语中歧义词的人类相关性判断数据集，比较同一模型家族的单语和多语言模型。探索三种潜在能力约束：表征限制（嵌入各向同性降低）、注意力限制（对消歧线索的关注减少）和词汇限制（多token分割增加）。

Result: 多语言模型在所有比较中表现一致降低。研究发现多语言模型存在所有三种限制的证据，这些因素在统计上解释了原本归因于模型多语言状态的方差。这些限制与消歧性能降低相关。

Conclusion: 多语言语言模型确实受到多种能力约束，这些约束与消歧性能降低相关。研究结果揭示了多语言模型在词汇消歧任务上表现不佳的具体机制。

Abstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty'' for lexical disambiguation--a task requiring precise semantic representations and contextualization mechanisms--using controlled datasets of human relatedness judgments for ambiguous words in both English and Spanish. Comparing monolingual and multilingual LMs from the same families, we find consistently reduced performance in multilingual LMs. We then explore three potential capacity constraints: representational (reduced embedding isotropy), attentional (reduced attention to disambiguating cues), and vocabulary-related (increased multi-token segmentation). Multilingual LMs show some evidence of all three limitations; moreover, these factors statistically account for the variance formerly attributed to a model's multilingual status. These findings suggest both that multilingual LMs do suffer from multiple capacity constraints, and that these constraints correlate with reduced disambiguation performance.

</details>


### [4] [Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories](https://arxiv.org/abs/2602.05085)
*Sidi Lu,Zhenwen Liang,Dongyang Ma,Yan Wang,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: Locas是一种局部支持的参数化记忆机制，可与Transformer的FFN块设计共享，支持灵活卸载或合并到模型参数中，实现高效持续学习。


<details>
  <summary>Details</summary>
Motivation: 桥接测试时训练与新型参数化记忆，使记忆能够灵活地从模型参数中卸载或合并，支持高效的持续学习。

Method: 提出Locas（局部支持的参数化记忆），有两种变体：1）传统两层MLP设计，理论保证更清晰；2）与SOTA LLMs共享GLU-FFN结构，可轻松附加到现有模型。关键是通过重用模型参数、激活和/或梯度进行原则性初始化。

Result: 在PG-19整书语言建模和LoCoMo长上下文对话问答任务上验证。Locas-GLU仅需0.02%额外参数即可存储过去上下文信息，同时保持较小上下文窗口。MMLU评估显示Locas能够将过去上下文永久化为参数知识，同时最小化对模型现有内部知识的灾难性遗忘。

Conclusion: Locas展示了将过去上下文永久化为参数知识的潜力，同时最小化灾难性遗忘，为参数高效和计算高效的持续学习提供了有前景的解决方案。

Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.

</details>


### [5] [Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models](https://arxiv.org/abs/2602.05106)
*Michael Browder,Kevin Duh,J. David Harris,Vince Lyzinski,Paul McNamee,Youngser Park,Carey E. Priebe,Peter Viechnicki*

Main category: cs.CL

TL;DR: 本文提出数据核视角空间（DKPS）作为分析Transformer模型输出质量的理论框架，为合成数据生成提供统计保证，解决LLM黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 标记训练数据的稀缺是构建高性能语言技术和生成式AI模型的主要瓶颈。虽然Transformer模型（特别是LLM）被用于生成合成数据来缓解数据稀缺问题，但由于模型是黑盒，合成数据的属性难以预测。实践中工程师通常只能调整温度参数并希望结果能改善下游模型，缺乏理论指导。

Method: 提出数据核视角空间（DKPS）作为数学分析基础，通过数学推导建立DKPS框架，为Transformer模型输出质量提供具体的统计保证。该方法能够阐明下游任务（如神经机器翻译模型或使用对比偏好优化的LLM）的性能表现。

Result: DKPS提供了Transformer模型输出质量的性能保证，能够指导合成数据生成过程，使工程师能够基于理论保证而非试错来优化模型性能。该框架为下游任务性能分析提供了理论基础。

Conclusion: DKPS为解决LLM黑盒问题和合成数据质量不确定性提供了数学分析框架，为语言技术工程提供了理论指导。文中也讨论了当前工作的局限性和未来研究方向。

Abstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via synthetic data generation. However, because the models are black boxes, the properties of the synthetic data are difficult to predict. In practice it is common for language technology engineers to 'fiddle' with the LLM temperature setting and hope that what comes out the other end improves the downstream model. Faced with this uncertainty, here we propose Data Kernel Perspective Space (DKPS) to provide the foundation for mathematical analysis yielding concrete statistical guarantees for the quality of the outputs of transformer models. We first show the mathematical derivation of DKPS and how it provides performance guarantees. Next we show how DKPS performance guarantees can elucidate performance of a downstream task, such as neural machine translation models or LLMs trained using Contrastive Preference Optimization (CPO). Limitations of the current work and future research are also discussed.

</details>


### [6] [Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text](https://arxiv.org/abs/2602.05107)
*Ahmed Ruby,Christian Hardmeier,Sara Stymne*

Main category: cs.CL

TL;DR: 提出一种多语言多模态隐式篇章关系分类方法，通过Qwen2-Audio整合文本和音频信息，在英语、法语和西班牙语上验证了多模态融合和跨语言迁移的有效性。


<details>
  <summary>Details</summary>
Motivation: 隐式篇章关系分类具有挑战性，需要从上下文中推断含义。上下文线索可能分布在多种模态中，并且在不同语言间存在差异，仅靠文本无法完全捕捉这些信息。

Method: 1) 提出自动方法构建英语、法语和西班牙语的多语言多模态隐式篇章关系数据集；2) 提出多模态方法，通过Qwen2-Audio整合文本和声学信息，实现跨语言的文本和音频联合建模。

Result: 1) 基于文本的模型优于基于音频的模型；2) 整合两种模态可以提升性能；3) 跨语言迁移能为低资源语言带来显著改进。

Conclusion: 多模态融合和跨语言迁移是提升隐式篇章关系分类性能的有效策略，特别是在处理多语言和低资源语言场景时。

Abstract: Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To address this, we introduce an automatic method for distantly related and unrelated language pairs to construct a multilingual and multimodal dataset for implicit discourse relations in English, French, and Spanish. For classification, we propose a multimodal approach that integrates textual and acoustic information through Qwen2-Audio, allowing joint modeling of text and audio for implicit discourse relation classification across languages. We find that while text-based models outperform audio-based models, integrating both modalities can enhance performance, and cross-lingual transfer can provide substantial improvements for low-resource languages.

</details>


### [7] [GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek](https://arxiv.org/abs/2602.05150)
*Yang Zhang,Mersin Konomi,Christos Xypolopoulos,Konstantinos Divriotis,Konstantinos Skianis,Giannis Nikolentzos,Giorgos Stamou,Guokan Shang,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 希腊MMLU是一个基于希腊本土内容的多任务语言理解基准测试，包含21,805个多项选择题，涵盖45个学科领域，用于评估LLM在希腊语上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽然在希腊语语料上训练，但缺乏基于真实本土内容的可靠评估基准。现有数据集多为英语机器翻译，无法捕捉希腊语言和文化特性。

Method: 创建希腊MMLU基准：收集或编写21,805个希腊语多项选择题，来自学术、专业和政府考试，涵盖45个学科，按新定义的主题分类法组织，并标注教育难度级别。

Result: 评估80多个开源和闭源LLM显示：前沿模型与开源模型之间存在显著性能差距；希腊适应模型与通用多语言模型之间也有明显差异。公开16,857个样本，保留4,948个用于私有排行榜。

Conclusion: 希腊MMLU填补了希腊语评估基准的空白，为改进LLM在希腊语上的能力提供了系统分析框架，揭示了模型规模、适应性和提示策略等因素对性能的影响。

Abstract: Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machine-translated from English, failing to capture Greek linguistic and cultural characteristics. We introduce GreekMMLU, a native-sourced benchmark for massive multitask language understanding in Greek, comprising 21,805 multiple-choice questions across 45 subject areas, organized under a newly defined subject taxonomy and annotated with educational difficulty levels spanning primary to professional examinations. All questions are sourced or authored in Greek from academic, professional, and governmental exams. We publicly release 16,857 samples and reserve 4,948 samples for a private leaderboard to enable robust and contamination-resistant evaluation. Evaluations of over 80 open- and closed-source LLMs reveal substantial performance gaps between frontier and open-weight models, as well as between Greek-adapted models and general multilingual ones. Finally, we provide a systematic analysis of factors influencing performance-including model scale, adaptation, and prompting-and derive insights for improving LLM capabilities in Greek.

</details>


### [8] [Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems](https://arxiv.org/abs/2602.05176)
*Ziyuan Yang,Wenxuan Ding,Shangbin Feng,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: 该论文研究了多语言模型协作系统中的安全风险，量化了恶意模型对系统性能的影响，并提出了使用外部监督器来缓解这些影响的策略。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地用于协作（如路由系统、多智能体辩论、模型融合等），在去中心化范式下存在关键的安全风险：如果多LLM系统中的某些模型被攻陷或恶意，会带来什么影响？

Method: 首先设计了四类恶意语言模型，将它们插入四种流行的模型协作系统中，在10个数据集上评估受影响的系统。然后提出了缓解策略，使用外部监督器来监督模型协作，通过禁用/屏蔽恶意组件来减少其影响。

Result: 恶意模型对多LLM系统有严重影响，特别是在推理和安全领域，性能平均下降7.12%和7.94%。提出的缓解策略平均能恢复95.31%的初始性能，但使模型协作系统完全抵抗恶意模型仍是一个开放的研究问题。

Conclusion: 多语言模型协作系统面临严重的恶意模型威胁，需要开发有效的防御机制。虽然外部监督策略能显著缓解影响，但实现完全抵抗恶意模型的系统仍需进一步研究。

Abstract: Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what if some of the models in multi-LLM systems are compromised or malicious? We first quantify the impact of malicious models by engineering four categories of malicious LMs, plug them into four types of popular model collaboration systems, and evaluate the compromised system across 10 datasets. We find that malicious models have a severe impact on the multi-LLM systems, especially for reasoning and safety domains where performance is lowered by 7.12% and 7.94% on average. We then propose mitigation strategies to alleviate the impact of malicious components, by employing external supervisors that oversee model collaboration to disable/mask them out to reduce their influence. On average, these strategies recover 95.31% of the initial performance, while making model collaboration systems fully resistant to malicious models remains an open research question.

</details>


### [9] [The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems](https://arxiv.org/abs/2602.05182)
*Shangbin Feng,Kishan Panaganti,Yulia Tsvetkov,Wenhao Yu*

Main category: cs.CL

TL;DR: 通过将多模型协作模式蒸馏到单个模型中，实现协作优势与单模型效率的平衡，并提出单-多进化循环让模型在协作与蒸馏中持续进化


<details>
  <summary>Details</summary>
Motivation: 多语言模型协作系统结合了不同模型的优势，但需要加载多个模型导致成本高昂。需要一种方法在保持协作优势的同时提高效率。

Method: 提出协作模式蒸馏：将多模型协作系统的输出作为训练数据，蒸馏到单个模型中；提出单-多进化循环：多个模型协作 → 各自从协作输出中蒸馏 → 蒸馏改进后的模型再次协作，形成集体进化生态系统。

Result: 在7种协作策略和15个任务上的实验表明：1) 单个模型平均提升8.0%，吸收了协作优势同时成本降至单模型；2) 协作系统从蒸馏后更强、更协同的模型中获益，相比初始系统平均提升14.9%。

Conclusion: 该方法优于现有进化AI方法，兼容多种模型/协作/蒸馏设置，能解决初始模型/系统难以处理的问题，实现了模型在协作环境中持续自我进化的生态系统。

Abstract: Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collaborative patterns into a single model, where the model is trained on the outputs of the model collaboration system. At inference time, only the distilled model is employed: it imitates the collaboration while only incurring the cost of a single model. Furthermore, we propose the single-multi evolution loop: multiple LMs collaborate, each distills from the collaborative outputs, and these post-distillation improved LMs collaborate again, forming a collective evolution ecosystem where models evolve and self-improve by interacting with an environment of other models. Extensive experiments with 7 collaboration strategies and 15 tasks (QA, reasoning, factuality, etc.) demonstrate that: 1) individual models improve by 8.0% on average, absorbing the strengths of collaboration while reducing the cost to a single model; 2) the collaboration also benefits from the stronger and more synergistic LMs after distillation, improving over initial systems without evolution by 14.9% on average. Analysis reveals that the single-multi evolution loop outperforms various existing evolutionary AI methods, is compatible with diverse model/collaboration/distillation settings, and helps solve problems where the initial model/system struggles to.

</details>


### [10] [Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky](https://arxiv.org/abs/2602.05189)
*Hsuan-Yu Chou,Wajiha Naveed,Shuyan Zhou,Xiaowei Yang*

Main category: cs.CL

TL;DR: 开源大语言模型在有害内容检测任务上表现与专有模型相当，可用于隐私保护的本地化内容审核


<details>
  <summary>Details</summary>
Motivation: 随着互联网访问扩大，有害内容暴露增加，需要有效的审核机制。虽然专有LLM在社交媒体审核任务中表现出色，但开源LLM的即用能力尚不明确，需要评估其实际性能。

Method: 评估了7个最先进的LLM（4个专有模型和3个开源模型），使用Bluesky的真实帖子、Bluesky审核服务的决策以及两位作者的标注进行测试。分析了模型的敏感性和特异性，并评估了人类审核员与LLM之间的一致性。

Result: 开源LLM的敏感性（81%-97%）和特异性（91%-100%）与专有模型（72%-98%和93%-99%）有相当程度的重叠。在粗鲁内容检测中特异性高于敏感性，但在不宽容和威胁检测中相反。发现了人类审核员与LLM之间的评分者间一致性。

Conclusion: 开源LLM可以在消费级硬件上支持隐私保护的审核，为设计平衡社区价值观与个人用户偏好的审核系统提供了新方向。

Abstract: As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful content detection. While proprietary LLMs have been shown to zero-shot outperform traditional machine learning models, the out-of-the-box capability of open-weight LLMs remains an open question.
  Motivated by recent developments of reasoning LLMs, we evaluate seven state-of-the-art models: four proprietary and three open-weight. Testing with real-world posts on Bluesky, moderation decisions by Bluesky Moderation Service, and annotations by two authors, we find a considerable degree of overlap between the sensitivity (81%--97%) and specificity (91%--100%) of the open-weight LLMs and those (72%--98%, and 93%--99%) of the proprietary ones. Additionally, our analysis reveals that specificity exceeds sensitivity for rudeness detection, but the opposite holds for intolerance and threats. Lastly, we identify inter-rater agreement across human moderators and the LLMs, highlighting considerations for deploying LLMs in both platform-scale and personalized moderation contexts. These findings show open-weight LLMs can support privacy-preserving moderation on consumer-grade hardware and suggest new directions for designing moderation systems that balance community values with individual user preferences.

</details>


### [11] [Aligning Large Language Model Behavior with Human Citation Preferences](https://arxiv.org/abs/2602.05205)
*Kenichiro Ando,Tatsuya Harada*

Main category: cs.CL

TL;DR: 研究探讨LLM引用行为与人类偏好的对齐程度，发现模型过度引用明确需要引用的文本，但低估数字和人名句子的引用需求，可通过DPO校准改善对齐


<details>
  <summary>Details</summary>
Motivation: 当前LLM服务普遍添加引用来增强可信度，但模型如何识别引用价值以及如何控制这一过程尚未充分研究。需要了解LLM当前的引用倾向及其与人类偏好的对齐程度

Method: 构建数据集表征人类引用偏好与LLM行为的关系，将网络文本分为8种引用动机类型，对所有类型组合进行成对引用偏好评估以捕捉细粒度对比

Result: 人类最常为医学文本寻求引用，更强模型显示相似倾向；当前模型比人类多27%可能为明确需要引用的文本添加引用，但系统性低估数字句子(-22.6%)和含人名句子(-20.1%)的引用需求；DPO实验显示模型行为可校准以更好匹配人类偏好

Conclusion: LLM引用行为与人类偏好存在系统性偏差，模型过度强调明确引用标记而低估数字和人名内容的引用需求，但可通过偏好优化校准。研究为更细粒度的LLM引用偏好调查奠定基础

Abstract: Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process should be controlled remains underexplored. In this study, we focus on what kinds of content LLMs currently tend to cite and how well that behavior aligns with human preferences. We construct a dataset to characterize the relationship between human citation preferences and LLM behavior. Web-derived texts are categorized into eight citation-motivation types, and pairwise citation preferences are exhaustively evaluated across all type combinations to capture fine-grained contrasts. Our results show that humans most frequently seek citations for medical text, and stronger models display a similar tendency. We also find that current models are as much as $27\%$ more likely than humans to add citations to text that is explicitly marked as needing citations on sources such as Wikipedia, and this overemphasis reduces alignment accuracy. Conversely, models systematically underselect numeric sentences (by $-22.6\%$ relative to humans) and sentences containing personal names (by $-20.1\%$), categories for which humans typically demand citations. Furthermore, experiments with Direct Preference Optimization demonstrate that model behavior can be calibrated to better match human citation preferences. We expect this study to provide a foundation for more fine-grained investigations into LLM citation preferences.

</details>


### [12] [Quantifying the Knowledge Proximity Between Academic and Industry Research: An Entity and Semantic Perspective](https://arxiv.org/abs/2602.05211)
*Hongye Zhao,Yi Zhao,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 该研究通过细粒度知识实体和语义空间量化了学术界与产业界的共同演化轨迹，发现两者知识邻近性上升，特别是在技术变革后，且学术界在技术范式转变期间的知识主导地位减弱。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖合作论文或专利数量等宏观指标，缺乏对文献中知识单元的分析，导致对学术界与产业界之间细粒度知识邻近性的把握不足，可能影响合作框架和资源配置效率。

Method: 1) 实体测量：通过预训练模型提取细粒度知识实体，使用余弦相似度测量序列重叠，通过复杂网络分析拓扑特征；2) 语义层面：采用无监督对比学习量化语义空间收敛，测量跨机构文本相似性；3) 使用引用分布模式分析双向知识流与相似性之间的相关性。

Result: 分析显示学术界与产业界之间的知识邻近性上升，特别是在技术变革后，这为共同演化中的双向适应提供了文本证据。此外，在技术范式转变期间，学术界知识主导地位减弱。

Conclusion: 该研究通过细粒度实体和语义空间分析，量化了学术界与产业界的共同演化轨迹，揭示了知识邻近性增强的趋势，特别是在技术变革时期，为理解两者互动关系提供了新的分析框架。

Abstract: The academia and industry are characterized by a reciprocal shaping and dynamic feedback mechanism. Despite distinct institutional logics, they have adapted closely in collaborative publishing and talent mobility, demonstrating tension between institutional divergence and intensive collaboration. Existing studies on their knowledge proximity mainly rely on macro indicators such as the number of collaborative papers or patents, lacking an analysis of knowledge units in the literature. This has led to an insufficient grasp of fine-grained knowledge proximity between industry and academia, potentially undermining collaboration frameworks and resource allocation efficiency. To remedy the limitation, this study quantifies the trajectory of academia-industry co-evolution through fine-grained entities and semantic space. In the entity measurement part, we extract fine-grained knowledge entities via pre-trained models, measure sequence overlaps using cosine similarity, and analyze topological features through complex network analysis. At the semantic level, we employ unsupervised contrastive learning to quantify convergence in semantic spaces by measuring cross-institutional textual similarities. Finally, we use citation distribution patterns to examine correlations between bidirectional knowledge flows and similarity. Analysis reveals that knowledge proximity between academia and industry rises, particularly following technological change. This provides textual evidence of bidirectional adaptation in co-evolution. Additionally, academia's knowledge dominance weakens during technological paradigm shifts. The dataset and code for this paper can be accessed at https://github.com/tinierZhao/Academic-Industrial-associations.

</details>


### [13] [Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions](https://arxiv.org/abs/2602.05220)
*Jinchuan Tian,Haoran Wang,Bo-Hao Su,Chien-yu Huang,Qingzheng Wang,Jiatong Shi,William Chen,Xun Gong,Siddhant Arora,Chin-Jou Li,Masao Someki,Takashi Maekaku,Yusuke Shinohara,Jin Sakuma,Chao-Han Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: Bagpiper是一个80亿参数的音频基础模型，通过丰富的自然语言描述将原始音频映射到高级认知概念空间，实现了音频理解与生成的统一，在多项基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有音频基础模型通常采用僵化的任务特定监督，只能处理音频的孤立因素而非整体。人类智能则能整体处理音频，无缝连接物理信号与抽象认知概念以执行复杂任务。因此需要开发能模拟人类认知过程的音频模型。

Method: 1. 使用丰富的自然语言描述（包含转录、音频事件等关键认知概念）来解释物理音频；2. 在6000亿token的大规模语料上进行预训练，建立原始音频与高级概念空间之间的双向映射；3. 微调时采用"描述-处理"工作流程，模拟中间认知推理步骤来解决多样化任务。

Result: 1. 在音频理解方面，在MMAU和AIRBench基准上超越Qwen-2.5-Omni；2. 在生成质量方面，超越CosyVoice3和TangoFlux，能够合成语音、音乐和音效的任意组合；3. 实现了通用音频的统一理解与生成。

Conclusion: Bagpiper是首批实现通用音频统一理解与生成的工作之一，通过模拟人类认知过程，建立了音频物理信号与抽象概念之间的桥梁，为音频AI的发展提供了新方向。

Abstract: Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.

</details>


### [14] [FedMosaic: Federated Retrieval-Augmented Generation via Parametric Adapters](https://arxiv.org/abs/2602.05235)
*Zhilin Liang,Yuxiang Wang,Zimu Zhou,Hainan Zhang,Boyi Liu,Yongxin Tong*

Main category: cs.CL

TL;DR: FedMosaic：首个基于参数化适配器的联邦RAG框架，通过聚类文档到多文档适配器并选择性聚合，在保护隐私的同时提升准确性并大幅降低存储和通信开销。


<details>
  <summary>Details</summary>
Motivation: 传统RAG假设集中式知识库，但在隐私敏感领域知识被隔离存储，无法共享原始文档。这促使了联邦RAG的需求，其中中央LLM服务器与分布式知识库协作而不共享原始文档。

Method: 采用参数化RAG方法，将文档编码为轻量级适配器。提出FedMosaic框架：1）将语义相关文档聚类到多文档适配器中，使用文档特定掩码减少开销；2）选择性聚合适配器，只合并相关对齐且无冲突的适配器。

Result: 在四个类别中平均准确率比最先进方法高10.9%，存储成本降低78.8%-86.3%，通信成本降低91.4%，且从不共享原始文档。

Conclusion: FedMosaic是首个基于参数化适配器的联邦RAG框架，有效解决了联邦RAG中的存储通信开销和破坏性聚合问题，在保护隐私的同时实现了高性能。

Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by grounding generation in external knowledge to improve factuality and reduce hallucinations. Yet most deployments assume a centralized corpus, which is infeasible in privacy aware domains where knowledge remains siloed. This motivates federated RAG (FedRAG), where a central LLM server collaborates with distributed silos without sharing raw documents. In context RAG violates this requirement by transmitting verbatim documents, whereas parametric RAG encodes documents into lightweight adapters that merge with a frozen LLM at inference, avoiding raw-text exchange. We adopt the parametric approach but face two unique challenges induced by FedRAG: high storage and communication from per-document adapters, and destructive aggregation caused by indiscriminately merging multiple adapters. We present FedMosaic, the first federated RAG framework built on parametric adapters. FedMosaic clusters semantically related documents into multi-document adapters with document-specific masks to reduce overhead while preserving specificity, and performs selective adapter aggregation to combine only relevance-aligned, nonconflicting adapters. Experiments show that FedMosaic achieves an average 10.9% higher accuracy than state-of-the-art methods in four categories, while lowering storage costs by 78.8% to 86.3% and communication costs by 91.4%, and never sharing raw documents.

</details>


### [15] [Copyright Detective: A Forensic System to Evidence LLMs Flickering Copyright Leakage Risks](https://arxiv.org/abs/2602.05252)
*Guangwei Zhang,Jianing Zhu,Cheng Qian,Neil Gong,Rada Mihalcea,Zhaozhuo Xu,Jingrui He,Jiaqi Ma,Yun Huang,Chaowei Xiao,Bo Li,Ahmed Abbasi,Dongwon Lee,Heng Ji,Denghui Zhang*

Main category: cs.CL

TL;DR: 首个交互式法证系统，用于检测、分析和可视化LLM输出中的潜在版权风险，将侵权检测视为证据发现过程而非静态分类任务


<details>
  <summary>Details</summary>
Motivation: 由于版权法的复杂性，需要更系统的方法来评估LLM输出的版权风险，现有方法多为静态分类，无法全面处理复杂的侵权判定问题

Method: 整合多种检测范式：内容召回测试、改写级相似性分析、说服性越狱探测和反学习验证，在统一可扩展框架中通过交互式提示、响应收集和迭代工作流程进行系统审计

Result: 开发了首个交互式法证系统，能够系统审计逐字记忆和改写级泄露，支持对黑盒访问的LLM进行负责任的部署和透明评估

Conclusion: Copyright Detective为LLM版权风险评估提供了创新的交互式法证方法，将侵权检测重新定义为证据发现过程，支持更全面的风险分析和透明评估

Abstract: We present Copyright Detective, the first interactive forensic system for detecting, analyzing, and visualizing potential copyright risks in LLM outputs. The system treats copyright infringement versus compliance as an evidence discovery process rather than a static classification task due to the complex nature of copyright law. It integrates multiple detection paradigms, including content recall testing, paraphrase-level similarity analysis, persuasive jailbreak probing, and unlearning verification, within a unified and extensible framework. Through interactive prompting, response collection, and iterative workflows, our system enables systematic auditing of verbatim memorization and paraphrase-level leakage, supporting responsible deployment and transparent evaluation of LLM copyright risks even with black-box access.

</details>


### [16] [CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs](https://arxiv.org/abs/2602.05258)
*Haoran Li,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CL

TL;DR: CoPE通过软截断RoPE的低频分量，统一了OOD缓解和语义建模两个目标，在长度泛化任务上达到SOTA性能，支持256k上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有RoPE适应长上下文的方法主要分为两类：OOD缓解（调整频率以适应未见位置）和语义建模（注意力分数应优先语义相似token）。本文旨在统一这两个看似不同的目标。

Method: 提出CoPE（软截断RoPE低频分量），通过软截断策略消除OOD异常值、精炼语义信号，并防止硬截断引起的频谱泄漏。

Result: 实验表明，简单应用CoPE软截断策略能在长度泛化任务上带来显著性能提升，可扩展到256k上下文长度，验证了理论分析并建立了新的SOTA。

Conclusion: CoPE通过软截断RoPE低频分量的简约干预，统一了OOD缓解和语义建模目标，为长度泛化提供了新的最先进方法。

Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.

</details>


### [17] [Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR](https://arxiv.org/abs/2602.05261)
*Fanfan Liu,Youyang Yin,Peng Shi,Siqi Yang,Zhixiong Zeng,Haibo Qiu*

Main category: cs.CL

TL;DR: 本文分析了RLVR算法中响应长度变化的原因，提出了解决长度偏差的LUSPO算法，在数学推理和多模态推理任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: RLVR训练中响应长度的增加通常被认为是推理能力提升的关键因素，但不同RLVR算法在训练过程中响应长度的变化模式差异显著，需要从理论上解释这些变化并提供改进方案。

Method: 深入分析主流RLVR算法的组件，理论分析影响响应长度的因素，提出Length-Unbiased Sequence Policy Optimization (LUSPO)算法，修正GSPO中的长度偏差，使其损失函数对响应长度无偏。

Result: 在数学推理基准测试和多模态推理场景中的大量实验表明，LUSPO始终取得优越性能，相比GRPO和GSPO等现有方法，LUSPO代表了新颖的SOTA优化策略。

Conclusion: LUSPO通过解决RLVR算法中的长度偏差问题，有效防止了响应长度崩溃，在复杂推理任务上实现了更好的性能，为RLVR优化提供了新的理论框架和实践方法。

Abstract: Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.

</details>


### [18] [Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science](https://arxiv.org/abs/2602.05289)
*Jingru Fan,Dewen Liu,Yufan Dang,Huatao Li,Yuheng Wang,Wei Liu,Feiyu Duan,Xuanwen Ding,Shu Yao,Lin Wu,Ruijie Shi,Wai-Shing Leung,Yuan Cheng,Zhongyu Wei,Cheng Yang,Chen Qian,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 该论文提出一个集成框架，将多智能体系统研究从经验试错转向设计科学，建立协作增益指标Γ来区分真实协作收益与资源积累，构建系统化的MAS因子库，实现从盲目实验到严谨科学的转变。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的多智能体系统在复杂开放领域表现出色，但当前研究仍依赖经验试错，缺乏统一的科学框架进行系统优化。主要瓶颈在于归因模糊性：缺乏结构化因子分类导致研究者只能进行无指导调整；缺乏统一指标无法区分真实协作增益与单纯资源积累。

Method: 1) 建立协作增益指标Γ作为科学标准，分离内在增益与预算增加；2) 提出因子归因范式，系统识别驱动协作的因素；3) 构建系统化的MAS因子库，将设计空间结构化分为控制级预设和信息级动态。

Result: 论文提出了一个集成框架，能够将多智能体系统研究从盲目实验转向严谨科学，为集体AI科学奠定基础。通过Γ指标和因子库，实现了对协作效果的系统化分析和优化。

Conclusion: 该框架促进了从经验试错到设计科学的转变，为实现真正的集体AI科学铺平了道路，为多智能体系统的系统化研究和优化提供了理论基础和方法论支持。

Abstract: Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical trial-and-error. It lacks a unified and principled scientific framework necessary for systematic optimization and improvement. This bottleneck stems from the ambiguity of attribution: first, the absence of a structured taxonomy of factors leaves researchers restricted to unguided adjustments; second, the lack of a unified metric fails to distinguish genuine collaboration gain from mere resource accumulation. In this paper, we advocate for a transition to design science through an integrated framework. We advocate to establish the collaboration gain metric ($Γ$) as the scientific standard to isolate intrinsic gains from increased budgets. Leveraging $Γ$, we propose a factor attribution paradigm to systematically identify collaboration-driving factors. To support this, we construct a systematic MAS factor library, structuring the design space into control-level presets and information-level dynamics. Ultimately, this framework facilitates the transition from blind experimentation to rigorous science, paving the way towards a true science of Collective AI.

</details>


### [19] [MentorCollab: Selective Large-to-Small Inference-Time Guidance for Efficient Reasoning](https://arxiv.org/abs/2602.05307)
*Haojin Wang,Yike Wang,Shangbin Feng,Hannaneh Hajishirzi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: MentorCollab：一种推理时协作方法，让大型推理模型稀疏地指导小型模型，通过轻量验证器选择性地让小型模型跟随导师的短前瞻片段，在降低推理成本的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型推理成本高且常产生冗余推理，小型语言模型效率高但在多步推理任务上表现不佳。现有协作方法往往导致模仿而非真正的错误纠正。

Method: 提出MentorCollab方法：在随机采样的token位置探测两个模型的分歧，使用轻量验证器决定小型模型是跟随导师的短前瞻片段还是继续自主生成。选择性稀疏指导而非接管生成。

Result: 在15个SLM-LRM对和3个领域（数学推理、常识推理、通用知识）中，12个设置性能提升，平均增益3.0%，最高达8.0%，平均仅18.4%的token由昂贵导师模型生成。

Conclusion: 选择性推理时指导能够恢复大型模型的推理能力而无需大量推理开销，短片段和选择性探测足以实现有效协作。

Abstract: Large reasoning models (LRMs) achieve strong performance by producing long chains of thought, but their inference costs are high and often generate redundant reasoning. Small language models (SLMs) are far more efficient, yet struggle on multi-step reasoning tasks. A natural idea is to let a large model guide a small one at inference time as a mentor, yet existing collaboration methods often promote imitation, resulting in verbose reasoning without consistent error correction. We propose MentorCollab, an inference-time collaboration method in which an LRM selectively and sparsely guides an SLM, rather than taking over generation. At randomly sampled token positions, we probe for divergences between the two models and use a lightweight verifier to decide whether the SLM should follow a short lookahead segment from its mentor or continue on its own. Across 15 SLM--LRM pairs and 3 domains (math reasoning, general knowledge, and commonsense reasoning), our method improves performance in 12 settings, with average gains of 3.0% and up to 8.0%, while adopting only having 18.4% tokens generated by the expensive mentor model on average. We find that short segments and selective probing are sufficient for effective collaboration. Our results show that selective inference-time guidance restores large-model reasoning ability without substantial inference overhead.

</details>


### [20] [How Do Language Models Acquire Character-Level Information?](https://arxiv.org/abs/2602.05347)
*Soma Sato,Ryohei Sasano*

Main category: cs.CL

TL;DR: 语言模型在未明确训练的情况下仍能隐式编码字符级信息，本文通过控制实验分析其机制，发现分词规则和拼写约束是主要影响因素，而子串语义关联和句法信息则是独立于分词的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型被报道能够隐式编码字符级信息，但其背后的机制尚未得到充分探索。研究者希望揭示语言模型如何获得字符级知识的机制。

Method: 通过比较在受控设置下训练的语言模型（如指定预训练数据集或分词器）与标准设置下训练的模型，分析模型如何获得字符级知识。将影响因素分为与分词相关和独立于分词的两类。

Result: 分析发现，合并规则和拼写约束是源于分词的主要因素，而子串的语义关联和句法信息则是独立于分词的关键因素。

Conclusion: 语言模型获取字符级知识受多种因素影响，既有分词相关的机制（如合并规则和拼写约束），也有独立于分词的机制（如语义关联和句法信息），这为理解语言模型的内部表征提供了新视角。

Abstract: Language models (LMs) have been reported to implicitly encode character-level information, despite not being explicitly provided during training. However, the mechanisms underlying this phenomenon remain largely unexplored. To reveal the mechanisms, we analyze how models acquire character-level knowledge by comparing LMs trained under controlled settings, such as specifying the pre-training dataset or tokenizer, with those trained under standard settings. We categorize the contributing factors into those independent of tokenization. Our analysis reveals that merge rules and orthographic constraints constitute primary factors arising from tokenization, whereas semantic associations of substrings and syntactic information function as key factors independent of tokenization.

</details>


### [21] [PACE: Defying the Scaling Hypothesis of Exploration in Iterative Alignment for Mathematical Reasoning](https://arxiv.org/abs/2602.05370)
*Jun Rao,Zixiong Yu,Xuebo Liu,Guhan Chen,Jing Li,Jiansheng Wei,Xiaojun Meng,Min Zhang*

Main category: cs.CL

TL;DR: PACE方法通过生成式纠正策略替代暴力采样，在数学推理任务中仅需少量样本就能超越DPO-R1（N=16）的性能，同时计算成本降低约80%


<details>
  <summary>Details</summary>
Motivation: 挑战DPO-R1中Best-of-N采样的扩展假设，发现数学推理中过度探索会导致收益递减甚至策略崩溃，需要更高效的偏好对齐方法

Method: 提出PACE（Proximal Alignment via Corrective Exploration），使用生成式纠正策略从失败探索中合成高质量偏好对，仅需少量样本（2<N<3）

Result: PACE在性能上超越DPO-R1（N=16），计算成本仅为其1/5，对奖励攻击和标签噪声具有更强的鲁棒性

Conclusion: 在数学推理任务中，质量优于数量，PACE通过智能纠正策略实现了更高效、更鲁棒的偏好对齐

Abstract: Iterative Direct Preference Optimization has emerged as the state-of-the-art paradigm for aligning Large Language Models on reasoning tasks. Standard implementations (DPO-R1) rely on Best-of-N sampling (e.g., $N \ge 8$) to mine golden trajectories from the distribution tail. In this paper, we challenge this scaling hypothesis and reveal a counter-intuitive phenomenon: in mathematical reasoning, aggressive exploration yields diminishing returns and even catastrophic policy collapse. We theoretically demonstrate that scaling $N$ amplifies verifier noise and induces detrimental distribution shifts. To resolve this, we introduce \textbf{PACE} (Proximal Alignment via Corrective Exploration), which replaces brute-force mining with a generation-based corrective strategy. Operating with a minimal budget ($2<N<3$), PACE synthesizes high-fidelity preference pairs from failed explorations. Empirical evaluations show that PACE outperforms DPO-R1 $(N=16)$ while using only about $1/5$ of the compute, demonstrating superior robustness against reward hacking and label noise.

</details>


### [22] [Cross-Lingual Empirical Evaluation of Large Language Models for Arabic Medical Tasks](https://arxiv.org/abs/2602.05374)
*Chaimae Abouzahir,Congbo Ma,Nizar Habash,Farah E. Shamout*

Main category: cs.CL

TL;DR: LLMs在阿拉伯语和英语医学问答中存在显著性能差距，且随任务复杂度增加而加剧，主要源于阿拉伯语医学文本的结构碎片化和模型置信度与正确性的低相关性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在医学应用中多为英语中心，限制了其在语言多样性社区中的鲁棒性和可靠性。虽然已有研究指出低资源语言在医学任务中的性能差异，但其根本原因尚不清楚。

Method: 对阿拉伯语和英语医学问答进行跨语言实证分析，包括性能差距评估、阿拉伯语医学文本的分词结构分析，以及模型报告置信度和解释与正确性的相关性分析。

Result: 发现持续存在的语言驱动性能差距，且随任务复杂度增加而加剧；阿拉伯语医学文本存在结构碎片化；模型报告的置信度和解释与正确性相关性有限。

Conclusion: 强调在医学任务LLMs中需要语言感知的设计和评估策略，以解决语言多样性带来的性能差距问题。

Abstract: In recent years, Large Language Models (LLMs) have become widely used in medical applications, such as clinical decision support, medical education, and medical question answering. Yet, these models are often English-centric, limiting their robustness and reliability for linguistically diverse communities. Recent work has highlighted discrepancies in performance in low-resource languages for various medical tasks, but the underlying causes remain poorly understood. In this study, we conduct a cross-lingual empirical analysis of LLM performance on Arabic and English medical question and answering. Our findings reveal a persistent language-driven performance gap that intensifies with increasing task complexity. Tokenization analysis exposes structural fragmentation in Arabic medical text, while reliability analysis suggests that model-reported confidence and explanations exhibit limited correlation with correctness. Together, these findings underscore the need for language-aware design and evaluation strategies in LLMs for medical tasks.

</details>


### [23] [IESR:Efficient MCTS-Based Modular Reasoning for Text-to-SQL with Large Language Models](https://arxiv.org/abs/2602.05385)
*Tao Liu,Jiafan Lu,Bohan Yu,Pengcheng Wu,Liu Haixin,Guoyu Xu,Li Xiangheng,Lixiao Li,Jiaming Hou,Zhao Shijun,Xinglin Lyu,Kunli Zhang,Yuxiang Jia,Hongyin Zan*

Main category: cs.CL

TL;DR: IESR框架通过信息增强结构化推理，使用轻量级LLM实现高效Text-to-SQL，在复杂推理基准上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL方法在复杂推理、领域知识、假设查询方面表现不佳，且企业部署成本高，需要轻量级解决方案

Method: 提出IESR框架：1) 利用LLM进行关键信息理解和模式链接，分离数学计算和SQL生成；2) 基于蒙特卡洛树搜索的多路径推理机制；3) 轨迹一致性验证模块确保准确性

Result: 在LogicCat基准上达到24.28 EX，Archer数据集上达到37.28 EX，仅使用轻量级模型无需微调即实现SOTA性能

Conclusion: IESR证明了轻量级模型在复杂Text-to-SQL任务中的有效性，同时揭示了当前编码器模型在物理知识、数学计算和常识推理方面的偏差和不足

Abstract: Text-to-SQL is a key natural language processing task that maps natural language questions to SQL queries, enabling intuitive interaction with web-based databases. Although current methods perform well on benchmarks like BIRD and Spider, they struggle with complex reasoning, domain knowledge, and hypothetical queries, and remain costly in enterprise deployment. To address these issues, we propose a framework named IESR(Information Enhanced Structured Reasoning) for lightweight large language models: (i) leverages LLMs for key information understanding and schema linking, and decoupling mathematical computation and SQL generation, (ii) integrates a multi-path reasoning mechanism based on Monte Carlo Tree Search (MCTS) with majority voting, and (iii) introduces a trajectory consistency verification module with a discriminator model to ensure accuracy and consistency. Experimental results demonstrate that IESR achieves state-of-the-art performance on the complex reasoning benchmark LogicCat (24.28 EX) and the Archer dataset (37.28 EX) using only compact lightweight models without fine-tuning. Furthermore, our analysis reveals that current coder models exhibit notable biases and deficiencies in physical knowledge, mathematical computation, and common-sense reasoning, highlighting important directions for future research. We released code at https://github.com/Ffunkytao/IESR-SLM.

</details>


### [24] [Beyond Length: Context-Aware Expansion and Independence as Developmentally Sensitive Evaluation in Child Utterances](https://arxiv.org/abs/2602.05392)
*Jiyun Chun,Eric Fosler-Lussier,Michael White,Andrew Perrault*

Main category: cs.CL

TL;DR: 提出基于LLM的儿童话语质量评估框架，从扩展性和独立性两个维度评估儿童在对话中的话语质量，替代传统基于长度的指标。


<details>
  <summary>Details</summary>
Motivation: 现有儿童话语评估指标（如平均话语长度、词汇多样性、可读性指数）过于依赖长度，忽略了对话语境，无法捕捉推理深度、话题维持和话语规划等质量维度。

Method: 采用LLM作为评判框架：首先分类成人前话语类型，然后从两个维度评分儿童回应：扩展性（语境阐述和推理深度）和独立性（儿童推动话语发展的贡献）。

Result: 方法具有发展有效性（显示年龄相关模式），预测价值优于常见基线，能检测与话语关系相关的语义差异，且与人类判断一致。

Conclusion: 将儿童话语评估从单纯测量长度转向评估儿童话语如何在语境中有意义地贡献和推动对话，支持大规模评估。

Abstract: Evaluating the quality of children's utterances in adult-child dialogue remains challenging due to insufficient context-sensitive metrics. Common proxies such as Mean Length of Utterance (MLU), lexical diversity (vocd-D), and readability indices (Flesch-Kincaid Grade Level, Gunning Fog Index) are dominated by length and ignore conversational context, missing aspects of response quality such as reasoning depth, topic maintenance, and discourse planning. We introduce an LLM-as-a-judge framework that first classifies the Previous Adult Utterance Type and then scores the child's response along two axes: Expansion (contextual elaboration and inferential depth) and Independence (the child's contribution to advancing the discourse). These axes reflect fundamental dimensions in child language development, where Expansion captures elaboration, clause combining, and causal and contrastive connectives. Independence captures initiative, topic control, decreasing reliance on adult scaffolding through growing self-regulation, and audience design. We establish developmental validity by showing age-related patterns and demonstrate predictive value by improving age estimation over common baselines. We further confirm semantic sensitivity by detecting differences tied to discourse relations. Our metrics align with human judgments, enabling large-scale evaluation. This shifts child utterance assessment from simply measuring length to evaluating how meaningfully the child's speech contributes to and advances the conversation within its context.

</details>


### [25] [Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better](https://arxiv.org/abs/2602.05393)
*Ji Zhao,Yufei Gu,Shitong Shao,Xun Zhou,Liang Xiang,Zeke Xie*

Main category: cs.CL

TL;DR: 提出Late-to-Early Training (LET)范式，利用小型预训练模型指导大型模型训练，通过后期知识早期学习和后期层指导早期层，实现训练加速和性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模扩大，预训练计算成本急剧增加。虽然已有大量预训练模型，但如何利用现有小型预训练模型加速大型模型训练这一实际问题尚未充分探索。

Method: 提出LET范式，核心思想是利用预训练模型后期层的表示来指导目标模型早期层的训练。包含两个关键机制：后期到早期步骤学习和后期到早期层学习。

Result: 在1.4B和7B参数模型上的实验表明，LET显著加速训练收敛，提升语言建模能力和下游任务性能。训练1.4B模型时，达到1.6倍加速，下游任务准确率提升近5%，即使使用参数少10倍的预训练模型。

Conclusion: LET范式能够有效利用现有小型预训练模型加速大型LLM训练，实现更快训练和更好性能，为解决LLM预训练计算成本问题提供了新思路。

Abstract: As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: \textit{Can we leverage existing small pretrained models to accelerate the training of larger models?} In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6$\times$ speedup with nearly 5\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10$\times$ fewer parameters than the target model.

</details>


### [26] [OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration](https://arxiv.org/abs/2602.05400)
*Shaobo Wang,Xuan Ouyang,Tianyi Xu,Yuzheng Hu,Jialin Liu,Guo Chen,Tianyu Zhang,Junhao Zheng,Kexin Yang,Xingzhang Ren,Dayiheng Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: OPUS是一个动态数据选择框架，通过优化器诱导的更新空间定义效用，在预训练中显著提升数据效率，用更少token达到更好效果。


<details>
  <summary>Details</summary>
Motivation: 随着高质量公共文本接近枯竭（数据墙现象），预训练正从更多token转向更好token。现有方法要么依赖忽略训练动态的启发式静态过滤器，要么使用基于原始梯度的动态但优化器无关的标准。

Method: OPUS在优化器诱导的更新空间定义效用，通过将候选数据的有效更新投影到来自稳定、同分布代理的目标方向来评分。采用Ghost技术和CountSketch确保可扩展性，使用Boltzmann采样保证数据多样性，仅增加4.7%计算开销。

Result: 在GPT-2 Large/XL的FineWeb和FineWeb-Edu预训练中，OPUS仅用30B token就超越了工业级基线和完整的200B token训练。与工业级静态过滤器结合时，即使使用低质量数据也能进一步提升效率。在Qwen3-8B-Base的SciencePedia持续预训练中，仅用0.5B token就超越了完整3B token训练。

Conclusion: OPUS是一个高效、可扩展的动态数据选择框架，在多种语料库、质量层级、优化器和模型规模上都取得了显著效果，为解决数据墙问题提供了有效方案，特别在专业领域的数据效率提升方面表现突出。

Abstract: As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.

</details>


### [27] [Grammatical Error Correction Evaluation by Optimally Transporting Edit Representation](https://arxiv.org/abs/2602.05419)
*Takumi Goto,Yusuke Sakai,Taro Watanabe*

Main category: cs.CL

TL;DR: 提出UOT-ERRANT，一种基于编辑向量和最优运输的GEC自动评估指标，通过将假设句的编辑向量运输到参考句来改进评估性能，特别是在多编辑的流畅性领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于嵌入的相似性度量（如BERTScore）在GEC评估中效果不佳，因为许多词在源句、假设句和参考句中保持不变。需要专门针对GEC编辑设计的评估方法。

Method: 提出编辑向量表示编辑操作，使用不平衡最优运输将假设句的编辑向量运输到参考句，计算相似度。基于ERRANT编辑提取框架，实现软编辑对齐。

Result: 在SEEDA元评估实验中，UOT-ERRANT提升了评估性能，特别是在+Fluency领域（多编辑场景）表现突出。方法具有高可解释性，运输计划可解释为软编辑对齐。

Conclusion: UOT-ERRANT是一种有效的GEC自动评估指标，既能用于系统排名，又能分析GEC系统。通过编辑向量和最优运输解决了传统嵌入相似度度量的局限性。

Abstract: Automatic evaluation in grammatical error correction (GEC) is crucial for selecting the best-performing systems. Currently, reference-based metrics are a popular choice, which basically measure the similarity between hypothesis and reference sentences. However, similarity measures based on embeddings, such as BERTScore, are often ineffective, since many words in the source sentences remain unchanged in both the hypothesis and the reference. This study focuses on edits specifically designed for GEC, i.e., ERRANT, and computes similarity measured over the edits from the source sentence. To this end, we propose edit vector, a representation for an edit, and introduce a new metric, UOT-ERRANT, which transports these edit vectors from hypothesis to reference using unbalanced optimal transport. Experiments with SEEDA meta-evaluation show that UOT-ERRANT improves evaluation performance, particularly in the +Fluency domain where many edits occur. Moreover, our method is highly interpretable because the transport plan can be interpreted as a soft edit alignment, making UOT-ERRANT a useful metric for both system ranking and analyzing GEC systems. Our code is available from https://github.com/gotutiyan/uot-errant.

</details>


### [28] [Once Correct, Still Wrong: Counterfactual Hallucination in Multilingual Vision-Language Models](https://arxiv.org/abs/2602.05437)
*Basel Mousi,Fahim Dalvi,Shammur Chowdhury,Firoj Alam,Nadir Durrani*

Main category: cs.CL

TL;DR: 提出了M2CQA基准测试，用于评估视觉语言模型在跨文化语境下的幻觉问题，特别是针对中东和北非地区，并提出了CounterFactual Hallucination Rate指标来衡量模型在正确回答真实陈述后接受反事实陈述的倾向。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉基准测试很少测试视觉语言模型在文化上合理但视觉上错误的解释这一失败模式，特别是在非西方语境和非英语语言中。需要评估模型在跨文化场景下的幻觉问题。

Method: 构建了M2CQA基准测试，包含来自17个中东和北非国家的图像，配以英语、阿拉伯语及其方言的真实陈述和反事实陈述。提出了CounterFactual Hallucination Rate指标，衡量模型在正确回答真实陈述后接受反事实陈述的概率。评估了最先进的视觉语言模型在多种提示策略下的表现。

Result: 在阿拉伯语中，特别是方言中，CFHR显著上升，即使真实陈述的准确率仍然很高。推理优先的提示策略会持续增加反事实幻觉，而先回答后解释的策略则能提高鲁棒性。

Conclusion: 视觉语言模型在跨文化语境下存在严重的幻觉问题，特别是在非英语语言中。需要开发更鲁棒的评估方法和模型改进策略来应对这一挑战。

Abstract: Vision-language models (VLMs) can achieve high accuracy while still accepting culturally plausible but visually incorrect interpretations. Existing hallucination benchmarks rarely test this failure mode, particularly outside Western contexts and English. We introduce M2CQA, a culturally grounded multimodal benchmark built from images spanning 17 MENA countries, paired with contrastive true and counterfactual statements in English, Arabic, and its dialects. To isolate hallucination beyond raw accuracy, we propose the CounterFactual Hallucination Rate (CFHR), which measures counterfactual acceptance conditioned on correctly answering the true statement. Evaluating state-of-the-art VLMs under multiple prompting strategies, we find that CFHR rises sharply in Arabic, especially in dialects, even when true-statement accuracy remains high. Moreover, reasoning-first prompting consistently increases counterfactual hallucination, while answering before justifying improves robustness. We will make the experimental resources and dataset publicly available for the community.

</details>


### [29] [Causal Front-Door Adjustment for Robust Jailbreak Attacks on LLMs](https://arxiv.org/abs/2602.05444)
*Yao Zhou,Zeen Song,Wenwen Qiang,Fengge Wu,Shuyi Zhou,Changwen Zheng,Hui Xiong*

Main category: cs.CL

TL;DR: 提出CFA²攻击框架，利用因果前门准则剥离安全机制，实现高效越狱


<details>
  <summary>Details</summary>
Motivation: 大语言模型的安全对齐机制通常作为潜在内部状态运行，掩盖了模型的固有能力。从因果视角看，安全机制如同未观测的混杂因子，阻碍了模型真实能力的展现。

Method: 将安全机制建模为未观测混杂因子，利用Pearl前门准则切断混杂关联。使用稀疏自编码器物理剥离防御相关特征，分离核心任务意图。将计算昂贵的边缘化简化为确定性干预，降低推理复杂度。

Result: CFA²实现了最先进的攻击成功率，同时为越狱过程提供了机制性解释。

Conclusion: 通过因果前门调整攻击框架，能够有效剥离LLM的安全对齐机制，揭示模型的真实能力，为越狱攻击提供了新的因果视角和高效方法。

Abstract: Safety alignment mechanisms in Large Language Models (LLMs) often operate as latent internal states, obscuring the model's inherent capabilities. Building on this observation, we model the safety mechanism as an unobserved confounder from a causal perspective. Then, we propose the \textbf{C}ausal \textbf{F}ront-Door \textbf{A}djustment \textbf{A}ttack ({\textbf{CFA}}$^2$) to jailbreak LLM, which is a framework that leverages Pearl's Front-Door Criterion to sever the confounding associations for robust jailbreaking. Specifically, we employ Sparse Autoencoders (SAEs) to physically strip defense-related features, isolating the core task intent. We further reduce computationally expensive marginalization to a deterministic intervention with low inference complexity. Experiments demonstrate that {CFA}$^2$ achieves state-of-the-art attack success rates while offering a mechanistic interpretation of the jailbreaking process.

</details>


### [30] [Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale](https://arxiv.org/abs/2602.05447)
*Damon McMillan*

Main category: cs.CL

TL;DR: 针对LLM代理在结构化数据上的上下文工程研究，通过SQL生成任务评估了11个模型、4种格式和不同规模模式，发现模型能力是主要影响因素，架构选择需根据模型能力定制而非通用最佳实践。


<details>
  <summary>Details</summary>
Motivation: LLM代理越来越多地通过编程接口操作外部系统，但实践者缺乏关于如何构建这些代理所消费上下文的实证指导。使用SQL生成作为编程代理操作的代理任务，研究结构化数据的上下文工程。

Method: 使用SQL生成为代理任务，进行了9,649个实验，涵盖11个模型、4种格式（YAML、Markdown、JSON、TOON）和从10到10,000个表的模式。比较了文件式上下文检索与直接上下文传递的效果。

Result: 1) 架构选择依赖模型：文件式检索提升前沿模型准确率(+2.7%)但对开源模型有害(-7.7%)；2) 格式对总体准确率无显著影响；3) 模型能力是主导因素，前沿与开源模型有21%准确率差距；4) 文件原生代理可扩展到10,000个表；5) 文件大小不能预测运行时效率。

Conclusion: 为部署LLM代理到结构化系统提供了基于证据的指导，表明架构决策应根据模型能力定制，而非假设存在通用最佳实践。模型能力是主要影响因素，格式选择相对次要。

Abstract: Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables.
  Our findings challenge common assumptions. First, architecture choice is model-dependent: file-based context retrieval improves accuracy for frontier-tier models (Claude, GPT, Gemini; +2.7%, p=0.029) but shows mixed results for open source models (aggregate -7.7%, p<0.001), with deficits varying substantially by model. Second, format does not significantly affect aggregate accuracy (chi-squared=2.45, p=0.484), though individual models, particularly open source, exhibit format-specific sensitivities. Third, model capability is the dominant factor, with a 21 percentage point accuracy gap between frontier and open source tiers that dwarfs any format or architecture effect. Fourth, file-native agents scale to 10,000 tables through domain-partitioned schemas while maintaining high navigation accuracy. Fifth, file size does not predict runtime efficiency: compact formats can consume significantly more tokens at scale due to format-unfamiliar search patterns.
  These findings provide practitioners with evidence-based guidance for deploying LLM agents on structured systems, demonstrating that architectural decisions should be tailored to model capability rather than assuming universal best practices.

</details>


### [31] [Reasoning under Ambiguity: Uncertainty-Aware Multilingual Emotion Classification under Partial Supervision](https://arxiv.org/abs/2602.05471)
*Md. Mithun Hossaina,Mashary N. Alrasheedy,Nirban Bhowmick,Shamim Forhad,Md. Shakil Hossain,Sudipto Chaki,Md Shafiqul Islam*

Main category: cs.CL

TL;DR: 提出Reasoning under Ambiguity框架，通过不确定性感知的多语言多标签情感分类方法，解决情感歧义和不完整监督问题，在英语、西班牙语和阿拉伯语基准上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前基于知识的多语言情感识别系统面临情感歧义和不完整监督的挑战。文本情感识别本质上是模糊的，因为多种情感状态常同时出现，且情感标注经常缺失或不一致。现有方法假设标签完全可观察，使用确定性学习目标，在部分监督下会导致学习偏差和不可靠预测。

Method: 提出Reasoning under Ambiguity框架：1) 使用共享多语言编码器配合语言特定优化；2) 基于熵的歧义加权机制，降低高歧义训练实例的权重而非将缺失标签视为负证据；3) 结合掩码感知目标和正-未标记正则化，实现部分监督下的鲁棒学习。

Result: 在英语、西班牙语和阿拉伯语情感分类基准测试中，相比强基线方法在多个评估指标上取得一致改进，同时提高了训练稳定性、对标注稀疏性的鲁棒性，并增强了可解释性。

Conclusion: 通过显式对齐学习与标注不确定性，提出的不确定性感知框架能有效处理多语言多标签情感分类中的情感歧义和不完整监督问题，为知识系统提供更可靠的情感识别能力。

Abstract: Contemporary knowledge-based systems increasingly rely on multilingual emotion identification to support intelligent decision-making, yet they face major challenges due to emotional ambiguity and incomplete supervision. Emotion recognition from text is inherently uncertain because multiple emotional states often co-occur and emotion annotations are frequently missing or heterogeneous. Most existing multi-label emotion classification methods assume fully observed labels and rely on deterministic learning objectives, which can lead to biased learning and unreliable predictions under partial supervision. This paper introduces Reasoning under Ambiguity, an uncertainty-aware framework for multilingual multi-label emotion classification that explicitly aligns learning with annotation uncertainty. The proposed approach uses a shared multilingual encoder with language-specific optimization and an entropy-based ambiguity weighting mechanism that down-weights highly ambiguous training instances rather than treating missing labels as negative evidence. A mask-aware objective with positive-unlabeled regularization is further incorporated to enable robust learning under partial supervision. Experiments on English, Spanish, and Arabic emotion classification benchmarks demonstrate consistent improvements over strong baselines across multiple evaluation metrics, along with improved training stability, robustness to annotation sparsity, and enhanced interpretability.

</details>


### [32] [LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation](https://arxiv.org/abs/2602.05493)
*Bingru Li*

Main category: cs.CL

TL;DR: LinguistAgent是一个集成平台，采用反思性多模型架构和双代理工作流程，通过提示工程、检索增强生成和微调三种范式，自动化语言学标注任务（以隐喻识别为例）。


<details>
  <summary>Details</summary>
Motivation: 人文社科领域的数据标注（尤其是复杂语义任务如隐喻识别）存在显著瓶颈，虽然大语言模型有潜力，但其理论能力与实际研究应用之间存在差距。

Method: 开发LinguistAgent平台，采用反思性多模型架构，包含标注者和评审者双代理工作流程，模拟专业同行评审过程，支持提示工程、检索增强生成和微调三种实验范式。

Result: 以隐喻识别任务为例，平台提供实时token级评估（精确率、召回率、F1分数），与人类黄金标准对比，展示了系统的有效性。

Conclusion: LinguistAgent为研究者提供了一个用户友好的自动化语言学标注平台，填补了大语言模型理论能力与实际应用之间的差距，代码已开源。

Abstract: Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the theoretical capability of LLMs and their practical utility for researchers. This paper introduces LinguistAgent, an integrated, user-friendly platform that leverages a reflective multi-model architecture to automate linguistic annotation. The system implements a dual-agent workflow, comprising an Annotator and a Reviewer, to simulate a professional peer-review process. LinguistAgent supports comparative experiments across three paradigms: Prompt Engineering (Zero/Few-shot), Retrieval-Augmented Generation, and Fine-tuning. We demonstrate LinguistAgent's efficacy using the task of metaphor identification as an example, providing real-time token-level evaluation (Precision, Recall, and $F_1$ score) against human gold standards. The application and codes are released on https://github.com/Bingru-Li/LinguistAgent.

</details>


### [33] [Transport and Merge: Cross-Architecture Merging for Large Language Models](https://arxiv.org/abs/2602.05495)
*Chenhang Cui,Binyun Yang,Fei Shen,Yuxin Chen,Jingnan Zheng,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 提出基于最优传输的跨架构模型合并框架，解决大模型向异构小模型的知识迁移问题


<details>
  <summary>Details</summary>
Motivation: 现实部署常使用小模型或低资源数据训练，需要从大模型向异构小模型进行知识迁移，但现有方法大多要求架构兼容

Method: 基于最优传输对齐激活值，推断异构模型间的神经元对应关系，利用传输计划指导权重空间融合，仅需少量输入数据

Result: 在低资源语言和专门领域实验中，相比目标模型取得一致改进

Conclusion: 提出的跨架构合并框架能有效实现从高资源大模型向低资源异构小模型的知识迁移

Abstract: Large language models (LLMs) achieve strong capabilities by scaling model capacity and training data, yet many real-world deployments rely on smaller models trained or adapted from low-resource data. This gap motivates the need for mechanisms to transfer knowledge from large, high-resource models to smaller, low-resource targets. While model merging provides an effective transfer mechanism, most existing approaches assume architecture-compatible models and therefore cannot directly transfer knowledge from large high-resource LLMs to heterogeneous low-resource targets. In this work, we propose a cross-architecture merging framework based on optimal transport (OT) that aligns activations to infer cross-neuron correspondences between heterogeneous models. The resulting transport plans are then used to guide direct weight-space fusion, enabling effective high-resource to low-resource transfer using only a small set of inputs. Extensive experiments across low-resource languages and specialized domains demonstrate consistent improvements over target models.

</details>


### [34] [A Human-in-the-Loop, LLM-Centered Architecture for Knowledge-Graph Question Answering](https://arxiv.org/abs/2602.05512)
*Larissa Pusch,Alexandre Courtiol,Tim Conrad*

Main category: cs.CL

TL;DR: 提出一个交互式框架，让LLM生成和解释Cypher图查询，用户通过自然语言迭代优化，提升对知识图谱的可访问性，同时保持事实准确性和语义严谨性。


<details>
  <summary>Details</summary>
Motivation: LLM在知识密集型领域存在幻觉、信息过时和可解释性有限的问题；基于文本的检索增强生成在多跳推理上表现不佳；知识图谱支持精确、可解释的查询，但需要掌握查询语言。

Method: 引入交互式框架，LLM生成和解释Cypher图查询，用户通过自然语言迭代优化查询；在真实世界知识图谱上应用该框架。

Result: 核心定量评估是在合成电影知识图谱上的90个查询基准测试，衡量查询解释质量和故障检测；补充了两个小型真实场景查询生成实验（Hyena KG和MaRDI KG）。

Conclusion: 该框架提高了对复杂数据集的可访问性，同时保持事实准确性和语义严谨性，并提供了模型性能在不同领域变化的洞察。

Abstract: Large Language Models (LLMs) excel at language understanding but remain limited in knowledge-intensive domains due to hallucinations, outdated information, and limited explainability. Text-based retrieval-augmented generation (RAG) helps ground model outputs in external sources but struggles with multi-hop reasoning. Knowledge Graphs (KGs), in contrast, support precise, explainable querying, yet require a knowledge of query languages. This work introduces an interactive framework in which LLMs generate and explain Cypher graph queries and users iteratively refine them through natural language. Applied to real-world KGs, the framework improves accessibility to complex datasets while preserving factual accuracy and semantic rigor and provides insight into how model performance varies across domains. Our core quantitative evaluation is a 90-query benchmark on a synthetic movie KG that measures query explanation quality and fault detection across multiple LLMs, complemented by two smaller real-life query-generation experiments on a Hyena KG and the MaRDI (Mathematical Research Data Initiative) KG.

</details>


### [35] [Multi-Task GRPO: Reliable LLM Reasoning Across Tasks](https://arxiv.org/abs/2602.05547)
*Shyam Sundhar Ramesh,Xiaotong Ji,Matthieu Zimmer,Sangwoong Yoon,Zhiyong Wang,Haitham Bou Ammar,Aurelien Lucchi,Ilija Bogunovic*

Main category: cs.CL

TL;DR: MT-GRPO：一种多任务GRPO算法，通过动态任务权重调整和比例保持采样器，解决多任务强化学习中的不平衡问题，显著提升最差任务性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署需要模型在多样化任务上都有可靠表现，但传统的多任务GRPO方法往往导致不平衡的结果——某些任务主导优化而其他任务停滞不前。此外，不同任务中提示产生零优势（从而零梯度）的频率差异很大，进一步扭曲了优化信号的有效贡献。

Method: 提出MT-GRPO算法：1) 动态调整任务权重，明确优化最差任务性能并促进跨任务平衡进展；2) 引入比例保持采样器，确保任务级策略梯度反映调整后的权重。

Result: 在3任务和9任务设置中，MT-GRPO在最差任务准确率上始终优于基线方法。相比标准GRPO和DAPO，在最差任务性能上分别获得16-28%和6%的绝对提升，同时保持竞争力的平均准确率。在3任务设置中，达到50%最差任务准确率所需的训练步数减少50%。

Conclusion: MT-GRPO通过动态任务权重调整和比例保持采样，有效解决了多任务强化学习中的不平衡问题，显著提升了跨任务的最差性能，同时提高了训练效率，为实现可靠的多任务性能提供了有效解决方案。

Abstract: RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.

</details>


### [36] [CASTLE: A Comprehensive Benchmark for Evaluating Student-Tailored Personalized Safety in Large Language Models](https://arxiv.org/abs/2602.05633)
*Rui Jia,Ruiyi Lan,Fengrui Liu,Zhongxiang Dai,Bo Jiang,Jing Shao,Jingyuan Chen,Guandong Xu,Fei Wu,Min Zhang*

Main category: cs.CL

TL;DR: CASTLE是一个基于教育理论构建的个性化安全评估基准，覆盖15种教育安全风险和14种学生属性，包含92,908个双语场景，用于评估LLM在个性化学习中的安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在个性化教育中存在同质化响应问题，忽视了学生认知和心理的异质性，可能对弱势群体造成安全风险。现有安全评估主要依赖事实准确性、偏见或毒性等上下文无关指标，无法捕捉同一响应对不同学生属性可能造成的不同危害。

Method: 提出"学生定制个性化安全"概念，构建CASTLE基准，包含15种教育安全风险和14种学生属性，共92,908个双语场景。设计三个评估指标：风险敏感性（检测风险能力）、情感共情（识别学生状态能力）和学生对齐（响应与学生属性匹配度）。

Result: 在18个最先进的LLM上进行实验，所有模型在5分制下的平均安全评分低于2.3分，表明现有模型在个性化安全保障方面存在显著不足。

Conclusion: CASTLE基准揭示了LLM在个性化教育安全方面的严重缺陷，强调了开发能够适应学生异质性的个性化安全机制的重要性，为未来教育AI的安全评估提供了新框架。

Abstract: Large language models (LLMs) have advanced the development of personalized learning in education. However, their inherent generation mechanisms often produce homogeneous responses to identical prompts. This one-size-fits-all mechanism overlooks the substantial heterogeneity in students cognitive and psychological, thereby posing potential safety risks to vulnerable groups. Existing safety evaluations primarily rely on context-independent metrics such as factual accuracy, bias, or toxicity, which fail to capture the divergent harms that the same response might cause across different student attributes. To address this gap, we propose the concept of Student-Tailored Personalized Safety and construct CASTLE based on educational theories. This benchmark covers 15 educational safety risks and 14 student attributes, comprising 92,908 bilingual scenarios. We further design three evaluation metrics: Risk Sensitivity, measuring the model ability to detect risks; Emotional Empathy, evaluating the model capacity to recognize student states; and Student Alignment, assessing the match between model responses and student attributes. Experiments on 18 SOTA LLMs demonstrate that CASTLE poses a significant challenge: all models scored below an average safety rating of 2.3 out of 5, indicating substantial deficiencies in personalized safety assurance.

</details>


### [37] [Modelling the Morphology of Verbal Paradigms: A Case Study in the Tokenization of Turkish and Hebrew](https://arxiv.org/abs/2602.05648)
*Giuseppe Samo,Paola Merlo*

Main category: cs.CL

TL;DR: 研究Transformer模型如何表示土耳其语和现代希伯来语的复杂动词范式，重点关注分词策略如何影响这种能力。土耳其语因其透明的形态标记，单语和多语模型都能成功；而希伯来语中，单语和多语模型表现不同，需要特定分词策略才能处理其非连接性形态。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解Transformer模型如何表示具有复杂形态变化的语言（特别是土耳其语和现代希伯来语），以及分词策略如何影响模型捕捉这些语言形态特征的能力。这有助于理解模型如何处理不同语言类型的形态结构。

Method: 使用Blackbird Language Matrices任务在自然数据上进行实验。对比不同分词策略：原子分词、小子词单元分词、字符级分词和语素感知分词。比较单语模型和多语模型在土耳其语和现代希伯来语上的表现差异。

Result: 对于土耳其语（具有透明形态标记），无论使用原子分词还是小子词单元分词，单语和多语模型都能成功。对于希伯来语，单语和多语模型表现不同：使用字符级分词的多语模型无法捕捉语言的非连接性形态，但使用语素感知分词的希伯来语单语模型表现良好。所有模型在更合成化的数据集上性能都有提升。

Conclusion: 分词策略对Transformer模型表示复杂形态范式的能力有重要影响。对于具有透明形态的语言（如土耳其语），多种分词策略都有效；但对于具有非连接性形态的语言（如希伯来语），需要特定的语素感知分词策略才能有效捕捉其形态特征。模型性能在合成数据上普遍更好。

Abstract: We investigate how transformer models represent complex verb paradigms in Turkish and Modern Hebrew, concentrating on how tokenization strategies shape this ability. Using the Blackbird Language Matrices task on natural data, we show that for Turkish -- with its transparent morphological markers -- both monolingual and multilingual models succeed, either when tokenization is atomic or when it breaks words into small subword units. For Hebrew, instead, monolingual and multilingual models diverge. A multilingual model using character-level tokenization fails to capture the language non-concatenative morphology, but a monolingual model with morpheme-aware segmentation performs well. Performance improves on more synthetic datasets, in all models.

</details>


### [38] [MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations](https://arxiv.org/abs/2602.05692)
*Congbo Ma,Yichun Zhang,Yousef Al-Jazzazi,Ahamed Foisal,Laasya Sharma,Yousra Sadqi,Khaled Saleh,Jihad Mallat,Farah E. Shamout*

Main category: cs.CL

TL;DR: MedErrBench是首个多语言临床文本错误检测、定位和纠正基准，涵盖英语、阿拉伯语和中文，包含10种常见错误类型，旨在评估LLMs在医疗领域的性能并促进更安全的AI医疗应用。


<details>
  <summary>Details</summary>
Motivation: 现有临床文本中的错误可能导致严重后果（如误诊或错误治疗建议），而随着LLMs在医疗应用中的广泛使用，需要全面的多语言评估基准，但目前此类数据集稀缺，特别是在不同语言和语境下。

Method: 在临床专家指导下开发MedErrBench基准，扩展了10种常见错误类型的分类体系，涵盖英语、阿拉伯语和中文的自然临床案例，由领域专家进行标注和审核。评估了通用、语言特定和医疗领域语言模型在三个任务（错误检测、定位和纠正）上的性能。

Result: 评估结果显示存在显著的性能差距，特别是在非英语环境中，突显了需要基于临床知识且具备语言感知能力的系统。基准数据集和评估协议已公开可用。

Conclusion: MedErrBench的发布旨在推动多语言临床NLP发展，促进全球更安全、更公平的基于AI的医疗保健。数据集已在补充材料中提供，匿名版本可通过GitHub获取。

Abstract: Inaccuracies in existing or generated clinical text may lead to serious adverse consequences, especially if it is a misdiagnosis or incorrect treatment suggestion. With Large Language Models (LLMs) increasingly being used across diverse healthcare applications, comprehensive evaluation through dedicated benchmarks is crucial. However, such datasets remain scarce, especially across diverse languages and contexts. In this paper, we introduce MedErrBench, the first multilingual benchmark for error detection, localization, and correction, developed under the guidance of experienced clinicians. Based on an expanded taxonomy of ten common error types, MedErrBench covers English, Arabic and Chinese, with natural clinical cases annotated and reviewed by domain experts. We assessed the performance of a range of general-purpose, language-specific, and medical-domain language models across all three tasks. Our results reveal notable performance gaps, particularly in non-English settings, highlighting the need for clinically grounded, language-aware systems. By making MedErrBench and our evaluation protocols publicly-available, we aim to advance multilingual clinical NLP to promote safer and more equitable AI-based healthcare globally. The dataset is available in the supplementary material. An anonymized version of the dataset is available at: https://github.com/congboma/MedErrBench.

</details>


### [39] [Consensus-Aligned Neuron Efficient Fine-Tuning Large Language Models for Multi-Domain Machine Translation](https://arxiv.org/abs/2602.05694)
*Shuting Jiang,Ran Song,Yuxin Huang,Yan Xiang,Yantuan Xian,Shengxiang Gao,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出一种基于共识对齐神经元的微调框架，用于多领域机器翻译，通过最大化神经元行为与领域特征间的互信息来选择关键神经元，有效缓解参数干扰和领域过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在机器翻译方面表现出色，但领域适应仍然是一个挑战。现有的多领域机器翻译方法如上下文学习和参数高效微调存在领域偏移、参数干扰和泛化能力有限的问题。

Method: 提出神经元高效微调框架，通过最大化神经元行为与领域特征之间的互信息来识别和更新共识对齐神经元，这些神经元能够捕捉可泛化的翻译模式和领域特定细微差别，然后基于这些神经元指导大语言模型的微调。

Result: 在三个大语言模型上对十个德语-英语和汉语-英语翻译领域进行综合实验，结果表明该方法在已见和未见领域上都持续优于强大的参数高效微调基线，达到了最先进的性能。

Conclusion: 该方法通过识别和微调共识对齐神经元，有效缓解了参数干扰和领域特定过拟合问题，为多领域机器翻译提供了一种有效的解决方案。

Abstract: Multi-domain machine translation (MDMT) aims to build a unified model capable of translating content across diverse domains. Despite the impressive machine translation capabilities demonstrated by large language models (LLMs), domain adaptation still remains a challenge for LLMs. Existing MDMT methods such as in-context learning and parameter-efficient fine-tuning often suffer from domain shift, parameter interference and limited generalization. In this work, we propose a neuron-efficient fine-tuning framework for MDMT that identifies and updates consensus-aligned neurons within LLMs. These neurons are selected by maximizing the mutual information between neuron behavior and domain features, enabling LLMs to capture both generalizable translation patterns and domain-specific nuances. Our method then fine-tunes LLMs guided by these neurons, effectively mitigating parameter interference and domain-specific overfitting. Comprehensive experiments on three LLMs across ten German-English and Chinese-English translation domains evidence that our method consistently outperforms strong PEFT baselines on both seen and unseen domains, achieving state-of-the-art performance.

</details>


### [40] [OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale](https://arxiv.org/abs/2602.05711)
*Jingze Shi,Zhangyang Peng,Yizhang Zhu,Yifan Wu,Guang Liu,Yuyu Luo*

Main category: cs.CL

TL;DR: OmniMoE提出了一种系统算法协同设计的框架，将专家粒度推到极致（向量级原子专家），通过笛卡尔积路由器和专家中心调度解决了细粒度MoE的路由复杂性和内存访问问题，在保持高准确率的同时大幅提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE架构在专家专业化粒度和硬件执行效率之间存在固有权衡。粗粒度专家效率高但专业化有限，细粒度专家专业化强但路由复杂、内存访问效率低。需要一种既能实现极致专家粒度又能保持高效执行的方法。

Method: 1. 引入向量级原子专家，实现单层MoE内的可扩展路由和执行，同时保留共享的密集MLP分支进行通用处理。2. 笛卡尔积路由器将大规模索引空间分解，将路由复杂度从O(N)降低到O(√N)。3. 专家中心调度反转执行顺序，将分散的内存绑定查找转换为高效的密集矩阵运算。

Result: 在7个基准测试中，OmniMoE（17亿激活参数）实现了50.9%的零样本准确率，优于粗粒度（如DeepSeekMoE）和细粒度（如PEER）基线。关键的是，与PEER相比，OmniMoE将推理延迟从73ms降低到6.7ms（加速10.9倍），证明大规模细粒度MoE可以既快速又准确。

Conclusion: OmniMoE通过系统算法协同设计，成功解决了细粒度MoE的路由复杂性和内存访问瓶颈，实现了极致专家粒度与高效硬件执行的平衡，为大规模MoE模型的实际部署提供了可行的解决方案。

Abstract: Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.

</details>


### [41] [CompactRAG: Reducing LLM Calls and Token Overhead in Multi-Hop Question Answering](https://arxiv.org/abs/2602.05728)
*Hao Yang,Zhiyu Yang,Xupeng Zhang,Wei Wei,Yunjie Zhang,Lin Yang*

Main category: cs.CL

TL;DR: CompactRAG：一种高效的多跳检索增强生成框架，通过离线知识库重构和在线推理解耦，显著减少LLM调用次数和token消耗


<details>
  <summary>Details</summary>
Motivation: 现有多跳RAG系统效率低下，需要在每个推理步骤交替进行检索和推理，导致重复的LLM调用、高token消耗以及跨跳实体接地不稳定

Method: 1. 离线阶段：LLM一次性读取语料库，将其转换为原子QA知识库，以最小化的细粒度问答对表示知识；2. 在线阶段：将复杂查询分解并重写以保持实体一致性，通过密集检索和RoBERTa答案提取解决，整个推理过程LLM仅调用两次

Result: 在HotpotQA、2WikiMultiHopQA和MuSiQue上的实验表明，CompactRAG在保持竞争力的准确率的同时，相比迭代式RAG基线显著减少了token消耗

Conclusion: CompactRAG提供了一种成本效益高且实用的多跳推理方法，通过解耦离线知识库重构和在线推理，实现了高效的大规模知识语料库推理

Abstract: Retrieval-augmented generation (RAG) has become a key paradigm for knowledge-intensive question answering. However, existing multi-hop RAG systems remain inefficient, as they alternate between retrieval and reasoning at each step, resulting in repeated LLM calls, high token consumption, and unstable entity grounding across hops. We propose CompactRAG, a simple yet effective framework that decouples offline corpus restructuring from online reasoning.
  In the offline stage, an LLM reads the corpus once and converts it into an atomic QA knowledge base, which represents knowledge as minimal, fine-grained question-answer pairs. In the online stage, complex queries are decomposed and carefully rewritten to preserve entity consistency, and are resolved through dense retrieval followed by RoBERTa-based answer extraction. Notably, during inference, the LLM is invoked only twice in total - once for sub-question decomposition and once for final answer synthesis - regardless of the number of reasoning hops.
  Experiments on HotpotQA, 2WikiMultiHopQA, and MuSiQue demonstrate that CompactRAG achieves competitive accuracy while substantially reducing token consumption compared to iterative RAG baselines, highlighting a cost-efficient and practical approach to multi-hop reasoning over large knowledge corpora. The implementation is available at GitHub.

</details>


### [42] [LongR: Unleashing Long-Context Reasoning via Reinforcement Learning with Dense Utility Rewards](https://arxiv.org/abs/2602.05758)
*Bowen Ping,Zijun Chen,Yiyao Yu,Tingfeng Hui,Junchi Yan,Baobao Chang*

Main category: cs.CL

TL;DR: LongR是一个强化学习框架，通过"思考-阅读"机制和上下文密度奖励来提升LLM在长上下文推理任务中的表现，在多个基准测试上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖稀疏的、仅基于结果的奖励信号，这在长上下文推理场景中效果有限，因为粗粒度的奖励信号不足以有效指导复杂的推理过程。长上下文任务（如长对话理解和结构化数据分析）不仅需要处理大量标记，还需要进行严格的演绎推理。

Method: 提出LongR统一框架，包含两个核心组件：1）动态的"思考-阅读"机制，交替进行推理和文档查阅；2）基于相对信息增益的上下文密度奖励，用于量化相关文档的效用。

Result: 在LongBench v2上获得9%的性能提升，在RULER和InfiniteBench上也取得一致的改进。LongR在不同RL算法（如DAPO、GSPO）上都能持续提升性能。分析显示推理链长度对效率有影响，模型对干扰信息具有鲁棒性。

Conclusion: LongR通过结合动态推理-阅读机制和细粒度的上下文密度奖励，有效解决了长上下文推理中奖励信号稀疏的问题，显著提升了LLM在复杂长上下文任务中的表现。

Abstract: Reinforcement Learning has emerged as a key driver for LLM reasoning. This capability is equally pivotal in long-context scenarios--such as long-dialogue understanding and structured data analysis, where the challenge extends beyond consuming tokens to performing rigorous deduction. While existing efforts focus on data synthesis or architectural changes, recent work points out that relying solely on sparse, outcome-only rewards yields limited gains, as such coarse signals are often insufficient to effectively guide the complex long-context reasoning. To address this, we propose LongR, a unified framework that enhances long-context performance by integrating a dynamic "Think-and-Read" mechanism, which interleaves reasoning with document consultation, with a contextual density reward based on relative information gain to quantify the utility of the relevant documents. Empirically, LongR achieves a 9% gain on LongBench v2 and consistent improvements on RULER and InfiniteBench, demonstrating robust efficiency in navigating extensive contexts. Furthermore, LongR consistently enhances performance across diverse RL algorithms (e.g., DAPO, GSPO). Finally, we conduct in-depth analyses to investigate the impact of reasoning chain length on efficiency and the model's robustness against distractors.

</details>


### [43] [Different Time, Different Language: Revisiting the Bias Against Non-Native Speakers in GPT Detectors](https://arxiv.org/abs/2602.05769)
*Adnan Al Ali,Jindřich Helcl,Jindřich Libovický*

Main category: cs.CL

TL;DR: 本文重新评估了LLM文本检测器对非母语者的偏见问题，发现在捷克语环境中，非母语者的文本困惑度并不低于母语者，且现代检测器没有系统性偏见，也不依赖困惑度进行检测。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等LLM助手的普及，学术界对其滥用的担忧日益增加。先前研究表明，自动检测方法经常错误地将非母语者的文章标记为生成文本，因为非母语者的文本困惑度较低（这是检测器的关键特征）。本文旨在重新评估这一说法，特别是在捷克语环境中。

Method: 1. 比较捷克语非母语者和母语者文本的困惑度；2. 测试来自三个不同家族的检测器；3. 分析检测器是否依赖困惑度特征进行判断。

Result: 1. 捷克语非母语者的文本困惑度并不低于母语者；2. 检测器没有显示出对非母语者的系统性偏见；3. 当代检测器在不需要依赖困惑度的情况下也能有效运作。

Conclusion: 在捷克语环境中，先前关于LLM文本检测器对非母语者存在偏见的说法不再成立。现代检测器已经发展出更复杂的检测机制，不再单纯依赖文本困惑度，从而避免了系统性偏见问题。

Abstract: LLM-based assistants have been widely popularised after the release of ChatGPT. Concerns have been raised about their misuse in academia, given the difficulty of distinguishing between human-written and generated text. To combat this, automated techniques have been developed and shown to be effective, to some extent. However, prior work suggests that these methods often falsely flag essays from non-native speakers as generated, due to their low perplexity extracted from an LLM, which is supposedly a key feature of the detectors. We revisit these statements two years later, specifically in the Czech language setting. We show that the perplexity of texts from non-native speakers of Czech is not lower than that of native speakers. We further examine detectors from three separate families and find no systematic bias against non-native speakers. Finally, we demonstrate that contemporary detectors operate effectively without relying on perplexity.

</details>


### [44] [Reinforcement World Model Learning for LLM-based Agents](https://arxiv.org/abs/2602.05842)
*Xiao Yu,Baolin Peng,Ruize Xu,Yelong Shen,Pengcheng He,Suman Nath,Nikhil Singh,Jiangfeng Gao,Zhou Yu*

Main category: cs.CL

TL;DR: RWML是一种自监督方法，通过模拟到现实的差距奖励为基于LLM的智能体学习动作条件的世界模型，提升其在环境动态中的适应能力。


<details>
  <summary>Details</summary>
Motivation: LLM在语言任务中表现出色，但在智能体设置中难以预测动作后果和适应环境动态，需要增强其世界建模能力。

Method: 提出RWML方法，使用模拟到现实的差距奖励在文本状态上学习动作条件的世界模型。通过将模型生成的模拟下一状态与环境观察到的实际下一状态在预训练嵌入空间中对齐，确保内部世界模拟与实际环境动态的一致性。

Result: 在ALFWorld和τ² Bench上评估，相比基础模型有显著提升。与任务成功奖励结合时，在ALFWorld和τ² Bench上分别比直接任务成功奖励RL高出6.9和5.7分，性能与专家数据训练相当。

Conclusion: RWML为基于LLM的智能体提供了一种有效的自监督世界模型学习方法，比下一状态令牌预测更稳健，比LLM-as-a-judge更不易受奖励黑客攻击，显著提升了智能体在环境中的适应能力。

Abstract: Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and $τ^2$ Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and $τ^2$ Bench respectively, while matching the performance of expert-data training.

</details>


### [45] [OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions](https://arxiv.org/abs/2602.05843)
*Fangzhi Xu,Hang Yan,Qiushi Sun,Jinyang Wu,Zixian Huang,Muye Huang,Jingyang Gong,Zichen Ding,Kanzhi Cheng,Yian Wang,Xinyu Che,Zeyi Sun,Jian Zhang,Zhangyue Yin,Haoran Luo,Xuanjing Huang,Ben Kao,Jun Liu,Qika Lin*

Main category: cs.CL

TL;DR: 提出OdysseyArena评估框架，专注于长视野、主动、归纳式交互，测试智能体从经验中发现潜在转移规律的能力，发现前沿LLMs在归纳场景中存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要采用演绎范式，智能体基于明确规则和静态目标执行任务，忽略了智能体从经验中自主发现潜在转移规律的归纳需求，这是实现智能体预见性和战略一致性的关键。

Method: 引入OdysseyArena框架，形式化并实例化四个原语，将抽象转移动态转化为具体交互环境。建立OdysseyArena-Lite用于标准化基准测试（120个任务），并推出OdysseyArena-Challenge以压力测试智能体在极端交互视野下的稳定性。

Result: 对15+个领先LLM的广泛实验表明，即使是前沿模型在归纳场景中也存在明显缺陷，揭示了在复杂环境中实现自主发现的关键瓶颈。

Conclusion: OdysseyArena填补了现有评估的空白，强调长视野、主动、归纳式交互的重要性，为评估智能体在复杂环境中的自主发现能力提供了新框架，并揭示了当前LLMs在这一关键能力上的不足。

Abstract: The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena

</details>


### [46] [RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference](https://arxiv.org/abs/2602.05853)
*Siran Liu,Guoxia Wang,Sa Wang,Jinle Zeng,HaoYang Xie,Siyu Lou,JiaBin Yang,DianHai Yu,Haifeng Wang,Chao Yang*

Main category: cs.CL

TL;DR: RRAttention是一种新颖的动态稀疏注意力方法，通过头轮询采样策略将注意力复杂度从O(L²)降低到O(L²/S²)，在保持查询独立性的同时实现高效全局模式发现，仅计算一半注意力块即可恢复99%以上性能，在128K上下文长度下实现2.4倍加速。


<details>
  <summary>Details</summary>
Motivation: 注意力机制的二次复杂度是处理长上下文大语言模型的关键瓶颈。现有动态稀疏注意力方法存在预处理需求、缺乏全局评估、违反查询独立性或计算开销高等基本权衡问题。

Method: 提出RRAttention方法，采用头轮询采样策略，在每个步幅内跨注意力头旋转查询采样位置，保持查询独立性同时实现步幅级聚合的高效全局模式发现。将复杂度从O(L²)降低到O(L²/S²)，并采用自适应Top-τ选择实现最优稀疏性。

Result: 在自然语言理解（HELMET）和多模态视频理解（Video-MME）上的广泛实验表明，RRAttention仅计算一半注意力块即可恢复超过99%的完整注意力性能，在128K上下文长度下实现2.4倍加速，优于现有动态稀疏注意力方法。

Conclusion: RRAttention通过头轮询采样策略同时实现了所有期望特性，解决了动态稀疏注意力方法面临的基本权衡问题，为处理长上下文的高效注意力机制提供了有效解决方案。

Abstract: The quadratic complexity of attention mechanisms poses a critical bottleneck for large language models processing long contexts. While dynamic sparse attention methods offer input-adaptive efficiency, they face fundamental trade-offs: requiring preprocessing, lacking global evaluation, violating query independence, or incurring high computational overhead. We present RRAttention, a novel dynamic sparse attention method that simultaneously achieves all desirable properties through a head \underline{r}ound-\underline{r}obin (RR) sampling strategy. By rotating query sampling positions across attention heads within each stride, RRAttention maintains query independence while enabling efficient global pattern discovery with stride-level aggregation. Our method reduces complexity from $O(L^2)$ to $O(L^2/S^2)$ and employs adaptive Top-$τ$ selection for optimal sparsity. Extensive experiments on natural language understanding (HELMET) and multimodal video comprehension (Video-MME) demonstrate that RRAttention recovers over 99\% of full attention performance while computing only half of the attention blocks, achieving 2.4$\times$ speedup at 128K context length and outperforming existing dynamic sparse attention methods.

</details>


### [47] [xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection](https://arxiv.org/abs/2602.05874)
*Adrián Girón,Pablo Miralles,Javier Huertas-Tato,Sergio D'Antonio,David Camacho*

Main category: cs.CL

TL;DR: xList-Hate：将仇恨言论检测重构为基于检查清单的诊断推理任务，通过LLM回答概念级问题生成诊断表示，再用可解释决策树聚合，提升跨数据集鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统仇恨言论检测被简化为二元分类问题，但仇恨言论是复合概念，受法律框架、平台政策和标注指南等多因素影响。监督模型容易过拟合特定数据集定义，在领域迁移和标注噪声下鲁棒性有限。

Method: 提出xList-Hate诊断框架：1) 将仇恨言论检测分解为基于广泛共享规范标准的检查清单，包含明确的概念级问题；2) 用大语言模型独立回答每个问题，生成二进制诊断表示；3) 用轻量级、完全可解释的决策树聚合诊断信号，产生透明可审计的预测。

Result: 在多个仇恨言论基准测试和模型家族中评估，相比零样本LLM分类和领域内监督微调：1) 监督方法通常最大化领域内性能，而xList-Hate持续提升跨数据集鲁棒性和领域迁移下的相对性能；2) 定性分析表明框架对某些形式的标注不一致和上下文模糊性更不敏感；3) 通过明确决策路径和因素级分析实现细粒度可解释性。

Conclusion: 将仇恨言论检测重构为诊断推理任务而非单一分类问题，为内容审核提供了鲁棒、可解释且可扩展的替代方案。xList-Hate框架通过分解概念和透明决策，解决了传统方法的过拟合和鲁棒性问题。

Abstract: Hate speech detection is commonly framed as a direct binary classification problem despite being a composite concept defined through multiple interacting factors that vary across legal frameworks, platform policies, and annotation guidelines. As a result, supervised models often overfit dataset-specific definitions and exhibit limited robustness under domain shift and annotation noise.
  We introduce xList-Hate, a diagnostic framework that decomposes hate speech detection into a checklist of explicit, concept-level questions grounded in widely shared normative criteria. Each question is independently answered by a large language model (LLM), producing a binary diagnostic representation that captures hateful content features without directly predicting the final label. These diagnostic signals are then aggregated by a lightweight, fully interpretable decision tree, yielding transparent and auditable predictions.
  We evaluate it across multiple hate speech benchmarks and model families, comparing it against zero-shot LLM classification and in-domain supervised fine-tuning. While supervised methods typically maximize in-domain performance, we consistently improves cross-dataset robustness and relative performance under domain shift. In addition, qualitative analysis of disagreement cases provides evidence that the framework can be less sensitive to certain forms of annotation inconsistency and contextual ambiguity. Crucially, the approach enables fine-grained interpretability through explicit decision paths and factor-level analysis.
  Our results suggest that reframing hate speech detection as a diagnostic reasoning task, rather than a monolithic classification problem, provides a robust, explainable, and extensible alternative for content moderation.

</details>


### [48] [EuroLLM-22B: Technical Report](https://arxiv.org/abs/2602.05879)
*Miguel Moura Ramos,Duarte M. Alves,Hippolyte Gisserot-Boukhlef,João Alves,Pedro Henrique Martins,Patrick Fernandes,José Pombal,Nuno M. Guerreiro,Ricardo Rei,Nicolas Boizard,Amin Farajian,Mateusz Klimaszewski,José G. C. de Souza,Barry Haddow,François Yvon,Pierre Colombo,Alexandra Birch,André F. T. Martins*

Main category: cs.CL

TL;DR: EuroLLM-22B是一个从头训练的大型语言模型，支持欧盟所有24种官方语言和11种额外语言，旨在解决欧洲语言在现有开源大模型中代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有开源大型语言模型中欧洲语言代表性不足且服务不充分，需要专门支持欧洲公民需求的多语言模型。

Method: 开发了EuroLLM-22B模型，包括分词器设计、架构规范、数据过滤和训练流程，覆盖35种语言，并发布了基础模型、指令调优模型、多语言预训练数据和评估代码库。

Result: EuroLLM-22B在广泛的多语言基准测试中表现出色，在推理、指令遵循和翻译任务上达到与同规模模型竞争的性能水平。

Conclusion: EuroLLM-22B成功填补了欧洲语言在大模型中的空白，为未来研究提供了全面的资源支持，包括模型、数据和代码的开放发布。

Abstract: This report presents EuroLLM-22B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-22B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. Across a broad set of multilingual benchmarks, EuroLLM-22B demonstrates strong performance in reasoning, instruction following, and translation, achieving results competitive with models of comparable size. To support future research, we release our base and instruction-tuned models, our multilingual web pretraining data and updated EuroBlocks instruction datasets, as well as our pre-training and evaluation codebases.

</details>


### [49] [Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models](https://arxiv.org/abs/2602.05897)
*Shuo Nie,Hexuan Deng,Chao Wang,Ruiyu Fang,Xuebo Liu,Shuangyong Song,Yu Li,Min Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: FaithRL：针对小型推理模型的忠实性感知步级强化学习方法，通过过程奖励模型和截断重采样策略减少推理步骤中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 小型推理模型在资源受限环境中很重要，但容易在中间推理步骤产生忠实性幻觉。现有基于在线强化学习的方法依赖结果奖励或粗粒度评估，当最终答案正确时可能无意中强化不忠实的推理。

Method: 提出FaithRL方法：1）通过过程奖励模型提供显式的步级忠实性监督；2）采用隐式截断重采样策略，从忠实前缀生成对比信号

Result: 在多个小型推理模型和开放书问答基准测试中，FaithRL能持续减少CoT和最终答案中的幻觉，实现更忠实可靠的推理

Conclusion: FaithRL通过步级监督和对比信号生成，有效解决了小型推理模型中的忠实性幻觉问题，为资源受限环境提供了更可靠的推理方法

Abstract: As large language models become smaller and more efficient, small reasoning models (SRMs) are crucial for enabling chain-of-thought (CoT) reasoning in resource-constrained settings. However, they are prone to faithfulness hallucinations, especially in intermediate reasoning steps. Existing mitigation methods based on online reinforcement learning rely on outcome-based rewards or coarse-grained CoT evaluation, which can inadvertently reinforce unfaithful reasoning when the final answer is correct. To address these limitations, we propose Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL), introducing step-level supervision via explicit faithfulness rewards from a process reward model, together with an implicit truncated resampling strategy that generates contrastive signals from faithful prefixes. Experiments across multiple SRMs and Open-Book QA benchmarks demonstrate that FaithRL consistently reduces hallucinations in both the CoT and final answers, leading to more faithful and reliable reasoning. Code is available at https://github.com/Easy195/FaithRL.

</details>


### [50] [Codified Finite-state Machines for Role-playing](https://arxiv.org/abs/2602.05905)
*Letian Peng,Yupeng Hou,Kun Zhou,Jingbo Shang*

Main category: cs.CL

TL;DR: 提出CFSM/CPFSM框架，通过LLM自动将角色描述编码为有限状态机，提升角色扮演的一致性


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法主要捕捉表面行为，难以跟踪驱动互动的潜在状态。传统手工制作的有限状态机难以适应角色扮演的开放语义空间

Method: 引入Codified Finite-State Machines (CFSMs)，使用LLM自动将文本角色配置文件编码为FSM，提取关键状态和转换。进一步扩展为Codified Probabilistic Finite-State Machines (CPFSMs)，将转换建模为状态的概率分布

Result: 在合成评估和真实世界角色扮演场景中，CFSM和CPFSM优于一般应用的基线方法，在结构化任务和开放随机状态探索中都验证了有效性

Conclusion: CFSM/CPFSM框架能够自动从角色描述中提取可解释的结构，强制保持角色一致性，有效解决了开放语义空间中角色状态建模的挑战

Abstract: Modeling latent character states is crucial for consistent and engaging role-playing (RP) with large language models (LLMs). Yet, existing prompting-based approaches mainly capture surface actions, often failing to track the latent states that drive interaction. We revisit finite-state machines (FSMs), long used in game design to model state transitions. While effective in small, well-specified state spaces, traditional hand-crafted, rule-based FSMs struggle to adapt to the open-ended semantic space of RP. To address this, we introduce Codified Finite-State Machines (CFSMs), a framework that automatically codifies textual character profiles into FSMs using LLM-based coding. CFSMs extract key states and transitions directly from the profile, producing interpretable structures that enforce character consistency. To further capture uncertainty and variability, we extend CFSMs into Codified Probabilistic Finite-State Machines (CPFSMs), where transitions are modeled as probability distributions over states. Through both synthetic evaluations and real-world RP scenarios in established artifacts, we demonstrate that CFSM and CPFSM outperform generally applied baselines, verifying effectiveness not only in structured tasks but also in open-ended stochastic state exploration.

</details>


### [51] [KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs](https://arxiv.org/abs/2602.05929)
*Jian Chen,Zhuoran Wang,Jiayu Qin,Ming Li,Meng Wang,Changyou Chen,Yin Chen,Qizhen Weng,Yirui Liu*

Main category: cs.CL

TL;DR: KV-CoRE：一种基于SVD的方法，用于量化KV缓存的数据相关低秩可压缩性，为LLM的KV缓存压缩提供原则性评估框架和大规模基准


<details>
  <summary>Details</summary>
Motivation: 随着上下文长度增长，KV缓存的读写会快速饱和GPU内存带宽。现有KV缓存压缩方法大多忽略了KV缓存的数据依赖性及其在不同层间的变化，需要一种量化评估方法来理解KV缓存的可压缩性模式。

Method: 提出KV-CoRE方法，基于SVD计算Frobenius范数下的最优低秩近似。该方法无需梯度、支持增量计算，能够高效进行数据集级别和层级的评估。使用归一化有效秩作为可压缩性度量指标。

Result: 分析了多个模型和数据集（涵盖5个英文领域和16种语言），揭示了可压缩性与模型架构、训练数据和语言覆盖的系统性关联。归一化有效秩与压缩下的性能下降有强相关性。

Conclusion: 建立了KV缓存可压缩性的原则性评估框架和首个大规模基准，为动态、数据感知的压缩和数据中心的模型开发提供了洞见。

Abstract: Large language models rely on kv-caches to avoid redundant computation during autoregressive decoding, but as context length grows, reading and writing the cache can quickly saturate GPU memory bandwidth. Recent work has explored KV-cache compression, yet most approaches neglect the data-dependent nature of kv-caches and their variation across layers. We introduce KV-CoRE KV-cache Compressibility by Rank Evaluation), an SVD-based method for quantifying the data-dependent low-rank compressibility of kv-caches. KV-CoRE computes the optimal low-rank approximation under the Frobenius norm and, being gradient-free and incremental, enables efficient dataset-level, layer-wise evaluation. Using this method, we analyze multiple models and datasets spanning five English domains and sixteen languages, uncovering systematic patterns that link compressibility to model architecture, training data, and language coverage. As part of this analysis, we employ the Normalized Effective Rank as a metric of compressibility and show that it correlates strongly with performance degradation under compression. Our study establishes a principled evaluation framework and the first large-scale benchmark of kv-cache compressibility in LLMs, offering insights for dynamic, data-aware compression and data-centric model development.

</details>


### [52] [Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions](https://arxiv.org/abs/2602.05932)
*Léo Labat,Etienne Ollion,François Yvon*

Main category: cs.CL

TL;DR: 研究多语言大语言模型在价值导向多选题上的跨语言一致性，发现虽然大型指令调优模型整体一致性较高，但某些问题仍会引发语言特异性行为。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注多语言LLM在事实回忆方面的表现，但较少探讨语言对价值导向多选题回答的影响。本研究旨在探究多语言LLM在不同语言下回答价值问题时是否保持一致（像理论上的多语者），还是表现出语言依赖的行为差异（像多个单语模型通过单一模型表达不同价值观）。

Method: 1. 创建新的语料库MEVS（多语言欧洲价值观调查），包含8种欧洲语言的人类翻译调查问题，避免了机器翻译或临时提示的问题。2. 对30多个不同规模、制造商和调优状态的多语言LLM进行测试。3. 在全面控制的提示变体下（包括答案顺序、符号类型和尾部字符）进行实验。

Result: 1. 更大、经过指令调优的模型整体一致性更高。2. 模型回答的稳健性在不同问题间差异很大：某些多选题在所有模型内和模型间达成完全一致，而另一些问题则导致LLM回答分裂。3. 所有一致的、经过指令微调的模型在某些问题上都表现出语言特异性行为。

Conclusion: 多语言LLM在价值导向多选题上并非完全一致的多语者，而是在某些问题上表现出语言依赖的行为差异。这提示需要进一步研究偏好微调的选择性效应，以及语言如何影响LLM的价值表达。

Abstract: Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.

</details>


### [53] [Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training](https://arxiv.org/abs/2602.05940)
*Junxiao Liu,Zhijun Wang,Yixiao Li,Zhejian Lai,Liqian Huang,Xin Huang,Xue Han,Junlan Feng,Shujian Huang*

Main category: cs.CL

TL;DR: TRIT框架通过整合翻译训练到多语言推理中，解决长推理模型在多语言场景下表现不佳的问题，无需外部反馈或额外数据即可提升问题理解和回答生成能力。


<details>
  <summary>Details</summary>
Motivation: 长推理模型在多语言环境中表现不佳：它们倾向于用英语推理非英语问题，而强制用问题语言推理时准确率大幅下降。这种困境源于多语言问题理解和多语言推理能力的双重不足。

Method: 提出TRIT（Translation-Reasoning Integrated Training）框架，这是一个自我改进的框架，将翻译训练整合到多语言推理训练中。该方法无需外部反馈或额外多语言数据，联合增强多语言问题理解和回答生成能力。

Result: 在MMATH数据集上，该方法平均优于多个基线7个百分点，提高了答案正确性和语言一致性。进一步分析显示，整合翻译训练将跨语言问题对齐提高了10个百分点以上，并提升了数学问题和通用领域文本的翻译质量，在FLORES-200上COMET分数提升高达8.4分。

Conclusion: TRIT框架通过整合翻译训练到多语言推理中，有效解决了长推理模型在多语言环境中的问题理解和推理能力不足，显著提升了多语言推理性能。

Abstract: Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning. To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning. Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH, our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200.

</details>


### [54] [Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space](https://arxiv.org/abs/2602.05971)
*Felipe D. Toro-Hernández,Jesuino Vieira Filho,Rodrigo M. Cabral-Carvalho*

Main category: cs.CL

TL;DR: 该研究提出一个框架，将概念生成视为在嵌入空间中的导航，通过累积嵌入构建语义轨迹并提取几何和动态指标，用于区分临床组和概念类型，在神经退行性疾病、言语流畅性等任务中验证。


<details>
  <summary>Details</summary>
Motivation: 研究人类如何在语义空间中导航以检索和操纵意义，为语义表征搜索提供计算基础，减少传统语言预处理方法的人工干预需求。

Method: 使用不同Transformer文本嵌入模型构建参与者特定的语义轨迹（基于累积嵌入），提取几何和动态指标（到下一个的距离、到质心的距离、熵、速度、加速度），在四种跨语言数据集上评估。

Result: 该方法能有效区分临床组和概念类型，累积嵌入在长轨迹中表现最佳，不同嵌入模型结果相似，表明不同学习表征之间存在共性。

Conclusion: 将语义导航框架化为嵌入空间中的结构化轨迹，连接认知建模与学习表征，为量化语义表征动态建立管道，在临床研究、跨语言分析和人工认知评估中有应用价值。

Abstract: Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Comparison with a non-cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, favoring the non-cumulative alternative. Critically, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.

</details>


### [55] [DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs](https://arxiv.org/abs/2602.05992)
*Lizhuo Luo,Shenggui Li,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: 提出Dynamic Sliding Block (DSB)方法，通过动态调整块大小来改进扩散大语言模型的块调度策略，提升生成质量和推理效率


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型使用固定的预定义块调度策略，无法根据语义难度动态调整，导致质量损失和效率低下：可能过早确定不确定位置，同时延迟边界附近的简单位置

Method: 提出DSB方法，使用动态大小的滑动块来克服固定块的刚性；进一步提出DSB Cache，为DSB定制的无需训练的KV缓存机制

Result: 在多个模型和基准测试上的实验表明，DSB与DSB Cache结合能够持续提升扩散大语言模型的生成质量和推理效率

Conclusion: 动态适应语义难度的块调度对于扩散大语言模型的可靠高效推理至关重要，DSB方法为此提供了有效的解决方案

Abstract: Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucial for avoiding order misalignment in global bidirectional decoding and improving output quality. However, the widely-used fixed, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, we propose Dynamic Sliding Block (DSB), a training-free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, we introduce DSB Cache, a training-free KV-cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, together with DSB Cache, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo-luo/DSB.

</details>


### [56] [A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies](https://arxiv.org/abs/2602.06015)
*Panagiotis Kaliosis,Adithya V Ganesan,Oscar N. E. Kjell,Whitney Ringwald,Scott Feltman,Melissa A. Carr,Dimitris Samaras,Camilo Ruggero,Benjamin J. Luft,Roman Kotov,Andrew H. Schwartz*

Main category: cs.CL

TL;DR: LLMs在零样本心理健康评估中的准确性受多种因素影响，包括上下文知识、建模策略等，最佳表现需要结合监督模型与LLM集成。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地用于零样本心理健康评估，但我们对其准确性影响因素了解有限，需要系统研究不同因素对评估性能的影响。

Method: 使用1,437名个体的临床数据集，评估11个SOTA LLMs，系统变化(i)上下文知识（子量表定义、分布摘要、访谈问题）和(ii)建模策略（零样本vs少样本、推理量、模型大小、结构化子量表vs直接标量预测、输出重缩放和9种集成方法）。

Result: (a)提供详细构造定义和叙述上下文时LLMs最准确；(b)增加推理努力提高估计准确性；(c)开源模型在70B参数后性能饱和，闭源模型随新代改进；(d)监督模型与零样本LLMs集成获得最佳性能。

Conclusion: 上下文知识和建模策略的选择对部署LLMs准确评估心理健康至关重要，需要仔细考虑这些因素以获得可靠结果。

Abstract: Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, distribution summary, and interview questions, and (ii) modeling strategies including zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open-weight models (Llama, Deepseek), plateau beyond 70B parameters while closed-weight (o3-mini, gpt-5) models improve with newer generations; and (d) best performance is achieved when ensembling a supervised model with the zero-shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.

</details>


### [57] [Multi-Token Prediction via Self-Distillation](https://arxiv.org/abs/2602.06019)
*John Kirchenbauer,Abhimanyu Hans,Brian Bartoldson,Micah Goldblum,Ashwinee Panda,Tom Goldstein*

Main category: cs.CL

TL;DR: 提出一种简单在线蒸馏方法，将预训练自回归语言模型转换为快速的多令牌预测模型，无需额外推理管道或辅助模型，在GSM8K上实现3倍以上解码加速且准确率下降小于5%


<details>
  <summary>Details</summary>
Motivation: 现有加速技术如推测解码需要训练辅助模型并构建复杂推理管道，部署复杂。本文寻求更简单的方法来加速语言模型推理

Method: 使用简单在线蒸馏目标，将预训练自回归语言模型从慢速单令牌预测转换为快速独立多令牌预测模型，保持与原始检查点完全相同的实现

Result: 在GSM8K上，该方法产生的模型平均解码速度提升3倍以上，准确率下降小于5%（相对于单令牌解码性能）

Conclusion: 该方法提供了一种简单有效的语言模型加速方案，无需额外推理管道或辅助模型，部署简单，在保持准确性的同时显著提升推理速度

Abstract: Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online distillation objective. The final model retains the exact same implementation as the pretrained initial checkpoint and is deployable without the addition of any auxiliary verifier or other specialized inference code. On GSM8K, our method produces models that can decode more than $3\times$ faster on average at $<5\%$ drop in accuracy relative to single token decoding performance.

</details>


### [58] [Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory](https://arxiv.org/abs/2602.06025)
*Haozhen Zhang,Haodong Yue,Tao Feng,Quanyu Long,Jianzhu Bao,Bowen Jin,Weizhi Zhang,Xiao Li,Jiaxuan You,Chengwei Qin,Wenya Wang*

Main category: cs.CL

TL;DR: BudgetMem：一个运行时代理内存框架，通过预算层级路由实现显式的查询感知性能-成本控制，在多个基准测试中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理内存系统主要依赖离线、查询无关的内存构建，效率低下且可能丢弃查询关键信息。运行时内存利用虽为自然替代方案，但现有方法开销大且缺乏对性能-成本权衡的显式控制。

Method: 将内存处理结构化为多个内存模块，每个模块提供三个预算层级（低/中/高）。轻量级路由器执行跨模块的预算层级路由，通过强化学习训练的紧凑神经策略来平衡任务性能和内存构建成本。研究了三种实现预算层级的互补策略：实现（方法复杂度）、推理（推理行为）和容量（模块模型大小）。

Result: 在LoCoMo、LongMemEval和HotpotQA基准测试中，BudgetMem在优先性能（高预算设置）时超越强基线，在更紧预算下提供更好的准确率-成本前沿。分析揭示了不同层级策略的优势和劣势，明确了在不同预算机制下每种策略何时提供最有利的权衡。

Conclusion: BudgetMem为运行时代理内存提供了有效的显式性能-成本控制框架，通过预算层级路由和多种实现策略，在不同预算约束下都能实现优越的权衡，为LLM代理内存系统的设计提供了新思路。

Abstract: Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \textsc{Low}/\textsc{Mid}/\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.

</details>


### [59] [DFlash: Block Diffusion for Flash Speculative Decoding](https://arxiv.org/abs/2602.06036)
*Jian Chen,Yesheng Liang,Zhijian Liu*

Main category: cs.CL

TL;DR: DFlash是一个使用轻量级块扩散模型进行并行草稿生成的推测解码框架，相比传统自回归草稿方法实现了6倍无损加速和2.5倍于现有最佳方法的速度提升。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型虽然性能强大，但需要顺序解码，导致推理延迟高且GPU利用率低。现有推测解码方法仍依赖自回归草稿，限制了实际加速效果。扩散模型虽能并行生成，但性能通常不如自回归模型。

Method: DFlash采用轻量级块扩散模型进行并行草稿生成，通过单次前向传播生成草稿token，并将草稿模型基于目标模型提取的上下文特征进行条件化，实现高质量输出和高接受率。

Result: 实验表明DFlash在多种模型和任务上实现了超过6倍的无损加速，比当前最先进的推测解码方法EAGLE-3快2.5倍。

Conclusion: DFlash通过结合扩散模型的并行生成能力和推测解码框架，有效解决了自回归模型推理延迟问题，为LLM高效推理提供了新方向。

Abstract: Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation, but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates. Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [60] [Signal or 'Noise': Human Reactions to Robot Errors in the Wild](https://arxiv.org/abs/2602.05010)
*Maia Stiber,Sameer Khan,Russell Taylor,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 研究通过咖啡机器人的实地部署，探索人们在真实世界中如何对机器人错误做出社会信号反应，发现这些信号丰富但"嘈杂"。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器人经常出错，但人们对机器人错误的社会反应在实验室外了解甚少。先前研究表明社会信号在受限交互中对错误管理可靠有用，但在真实世界（特别是非社交机器人、重复交互、群体交互和连续错误传播情况下）是否仍然有效尚不清楚。

Method: 构建咖啡机器人并进行公共实地部署（N=49），观察参与者在真实场景中对机器人错误和其他刺激的社会信号反应，特别关注群体交互中的表现。

Result: 参与者对错误和其他刺激一致表达多样化的社会信号，尤其在群体交互中更为明显。研究发现真实世界中的社会信号丰富（参与者主动提供交互信息），但"嘈杂"。

Conclusion: 讨论了在真实世界人机交互中使用社会信号的教训、益处和挑战，为未来研究提供了实践指导。

Abstract: In the real world, robots frequently make errors, yet little is known about people's social responses to errors outside of lab settings. Prior work has shown that social signals are reliable and useful for error management in constrained interactions, but it is unclear if this holds in the real world - especially with a non-social robot in repeated and group interactions with successive or propagated errors. To explore this, we built a coffee robot and conducted a public field deployment ($N = 49$). We found that participants consistently expressed varied social signals in response to errors and other stimuli, particularly during group interactions. Our findings suggest that social signals in the wild are rich (with participants volunteering information about the interaction), but "noisy." We discuss lessons, benefits, and challenges for using social signals in real-world HRI.

</details>


### [61] [Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping](https://arxiv.org/abs/2602.05029)
*Octavio Arriaga,Proneet Sharma,Jichen Guo,Marc Otto,Siddhant Kadwe,Rebecca Adam*

Main category: cs.RO

TL;DR: 提出一种可微分神经图形模型，结合神经基础模型与物理可微分渲染，实现零样本场景重建与机器人抓取，无需额外3D数据或测试样本。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量训练数据和测试样本构建黑盒场景表示，缺乏数据效率和可解释性。需要开发能在新环境中进行零样本场景重建和交互的方法。

Method: 结合神经基础模型与物理可微分渲染，通过约束优化问题估计物理一致的场景参数（网格、光照、材质、6D位姿），仅需单张RGBD图像和边界框。

Result: 在标准无模型少样本基准测试中优于现有位姿估计算法，并通过零样本抓取任务验证了场景重建的准确性。

Conclusion: 该方法为更数据高效、可解释、可泛化的机器人自主性提供了途径，无需依赖大量数据集或测试采样。

Abstract: Operating effectively in novel real-world environments requires robotic systems to estimate and interact with previously unseen objects. Current state-of-the-art models address this challenge by using large amounts of training data and test-time samples to build black-box scene representations. In this work, we introduce a differentiable neuro-graphics model that combines neural foundation models with physics-based differentiable rendering to perform zero-shot scene reconstruction and robot grasping without relying on any additional 3D data or test-time samples. Our model solves a series of constrained optimization problems to estimate physically consistent scene parameters, such as meshes, lighting conditions, material properties, and 6D poses of previously unseen objects from a single RGBD image and bounding boxes. We evaluated our approach on standard model-free few-shot benchmarks and demonstrated that it outperforms existing algorithms for model-free few-shot pose estimation. Furthermore, we validated the accuracy of our scene reconstructions by applying our algorithm to a zero-shot grasping task. By enabling zero-shot, physically-consistent scene reconstruction and grasping without reliance on extensive datasets or test-time sampling, our approach offers a pathway towards more data efficient, interpretable and generalizable robot autonomy in novel environments.

</details>


### [62] [Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking](https://arxiv.org/abs/2602.05079)
*Vinal Asodia,Iman Sharifi,Saber Fallah*

Main category: cs.RO

TL;DR: 本文提出了一种用于自动驾驶的神经符号特征表示和软一阶逻辑奖励函数，通过整合语义、空间和形状信息以及动态实体的空间增强特征，结合符号推理模块平衡人类价值观，提高了策略鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于摄像头的深度强化学习方法存在两个问题：很少将高层场景上下文整合到特征表示中，以及依赖僵化的固定奖励函数。这限制了自动驾驶系统的上下文感知能力和价值对齐决策。

Method: 提出神经符号特征表示管道，包含语义、空间和形状信息，以及动态实体（特别是安全关键道路使用者）的空间增强特征。同时提出软一阶逻辑（SFOL）奖励函数，通过符号推理模块从分割图中提取语义和空间谓词，应用语言规则获得奖励权重。

Result: 在CARLA仿真环境中的定量实验表明，与基线表示和奖励公式相比，所提出的神经符号表示和SFOL奖励函数在不同交通密度和遮挡水平下提高了策略鲁棒性和安全相关性能指标。

Conclusion: 将整体表示和软推理整合到强化学习中，可以支持自动驾驶中更具上下文感知和价值对齐的决策制定，证明了神经符号方法在提高自动驾驶系统安全性和鲁棒性方面的有效性。

Abstract: The problem with existing camera-based Deep Reinforcement Learning approaches is twofold: they rarely integrate high-level scene context into the feature representation, and they rely on rigid, fixed reward functions. To address these challenges, this paper proposes a novel pipeline that produces a neuro-symbolic feature representation that encompasses semantic, spatial, and shape information, as well as spatially boosted features of dynamic entities in the scene, with an emphasis on safety-critical road users. It also proposes a Soft First-Order Logic (SFOL) reward function that balances human values via a symbolic reasoning module. Here, semantic and spatial predicates are extracted from segmentation maps and applied to linguistic rules to obtain reward weights. Quantitative experiments in the CARLA simulation environment show that the proposed neuro-symbolic representation and SFOL reward function improved policy robustness and safety-related performance metrics compared to baseline representations and reward formulations across varying traffic densities and occlusion levels. The findings demonstrate that integrating holistic representations and soft reasoning into Reinforcement Learning can support more context-aware and value-aligned decision-making for autonomous driving.

</details>


### [63] [A Framework for Combining Optimization-Based and Analytic Inverse Kinematics](https://arxiv.org/abs/2602.05092)
*Thomas Cohn,Lihan Tang,Alexandre Amice,Russ Tedrake*

Main category: cs.RO

TL;DR: 提出一种新的优化逆运动学方法，通过解析解作为变量变换，使优化器更容易求解，在各种挑战性IK问题上获得更高成功率


<details>
  <summary>Details</summary>
Motivation: 传统解析方法和优化方法各有优缺点，但难以统一。优化方法面临关节角度与末端执行器姿态之间的复杂非线性关系，加上避碰等非凸约束时失败率较高

Method: 提出新的优化IK公式，使用解析IK解作为变量变换，从根本上降低优化器求解难度。在三种流行的求解器上进行测试，代表三种不同的约束非线性优化范式

Result: 广泛的实验比较表明，新公式在避碰、抓取选择和仿人机器人稳定性等各种挑战性IK问题上，比旧公式和基线方法获得更高的成功率

Conclusion: 通过将解析IK解作为变量变换的新优化IK公式，有效结合了解析方法和优化方法的优势，显著提高了求解成功率

Abstract: Analytic and optimization methods for solving inverse kinematics (IK) problems have been deeply studied throughout the history of robotics. The two strategies have complementary strengths and weaknesses, but developing a unified approach to take advantage of both methods has proved challenging. A key challenge faced by optimization approaches is the complicated nonlinear relationship between the joint angles and the end-effector pose. When this must be handled concurrently with additional nonconvex constraints like collision avoidance, optimization IK algorithms may suffer high failure rates. We present a new formulation for optimization IK that uses an analytic IK solution as a change of variables, and is fundamentally easier for optimizers to solve. We test our methodology on three popular solvers, representing three different paradigms for constrained nonlinear optimization. Extensive experimental comparisons demonstrate that our new formulation achieves higher success rates than the old formulation and baseline methods across various challenging IK problems, including collision avoidance, grasp selection, and humanoid stability.

</details>


### [64] [PLATO Hand: Shaping Contact Behavior with Fingernails for Precise Manipulation](https://arxiv.org/abs/2602.05156)
*Dong Ho Kang,Aaron Kim,Mingyo Seo,Kazuto Yokoyama,Tetsuya Narita,Luis Sentis*

Main category: cs.RO

TL;DR: PLATO Hand是一种灵巧机器人手，采用混合指尖设计（刚性指甲嵌入柔性指腹），通过结构化接触几何实现多种交互模式，提升夹持稳定性、力感知能力和边缘敏感操作性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器人手在精确操作中面临接触行为控制困难的问题，特别是在处理不同几何形状物体时，需要更智能的接触机制来实现稳定夹持和精细操作。

Method: 设计混合指尖（刚性指甲嵌入柔性指腹），开发基于应变能的弯曲-压入模型指导设计，通过引导接触保持局部压入同时抑制全局弯曲，结合力-运动透明机制。

Result: 实验显示PLATO Hand在夹持稳定性、力可观测性方面有显著提升，成功执行纸张分离、卡片拾取、橙子剥皮等边缘敏感操作任务。

Conclusion: 将结构化接触几何与力-运动透明机制相结合，为精确操作提供了一种有原则的物理实现方法，证明了混合指尖设计在灵巧操作中的有效性。

Abstract: We present the PLATO Hand, a dexterous robotic hand with a hybrid fingertip that embeds a rigid fingernail within a compliant pulp. This design shapes contact behavior to enable diverse interaction modes across a range of object geometries. We develop a strain-energy-based bending-indentation model to guide the fingertip design and to explain how guided contact preserves local indentation while suppressing global bending. Experimental results show that the proposed robotic hand design demonstrates improved pinching stability, enhanced force observability, and successful execution of edge-sensitive manipulation tasks, including paper singulation, card picking, and orange peeling. Together, these results show that coupling structured contact geometry with a force-motion transparent mechanism provides a principled, physically embodied approach to precise manipulation.

</details>


### [65] [Informative Path Planning with Guaranteed Estimation Uncertainty](https://arxiv.org/abs/2602.05198)
*Kalvik Jakkala,Saurav Agarwal,Jason O'Kane,Srinivas Akella*

Main category: cs.RO

TL;DR: 该论文提出了一种结合几何覆盖和信息路径规划的方法，在保证高斯过程后验方差低于指定阈值的前提下，规划最短路径进行环境监测。


<details>
  <summary>Details</summary>
Motivation: 环境监测机器人需要在距离和能量限制下重建空间场。传统boustrophedon方法有几何覆盖保证但会过度采样可预测区域，而信息路径规划方法虽能减少过度采样但缺乏重建质量保证。需要一种既能利用空间相关性又能提供重建质量保证的方法。

Method: 采用三阶段方法：1) 从先验信息学习高斯过程模型；2) 将学习到的核函数转换为二进制覆盖图，指示哪些位置的方差可降至目标值以下；3) 规划接近最短的路径，其组合覆盖满足全局不确定性约束。引入非平稳核处理异质现象，并适应有障碍物的非凸环境。

Result: 在真实地形数据上的实验表明，该方法比基线方法使用更少的传感位置和更短的旅行距离就能达到不确定性目标。自主水面和水下机器人的现场实验证明了实际可行性。

Conclusion: 该方法成功桥接了传统几何覆盖和信息路径规划，在保证估计不确定性的前提下实现了高效的环境监测路径规划，具有理论保证和实际应用价值。

Abstract: Environmental monitoring robots often need to reconstruct spatial fields (e.g., salinity, temperature, bathymetry) under tight distance and energy constraints. Classical boustrophedon lawnmower surveys provide geometric coverage guarantees but can waste effort by oversampling predictable regions. In contrast, informative path planning (IPP) methods leverage spatial correlations to reduce oversampling, yet typically offer no guarantees on reconstruction quality. This paper bridges these approaches by addressing informative path planning with guaranteed estimation uncertainty: computing the shortest path whose measurements ensure that the Gaussian-process (GP) posterior variance -- an intrinsic uncertainty measure that lower-bounds the mean-squared prediction error under the GP model -- falls below a user-specified threshold over the monitoring region.
  We propose a three-stage approach: (i) learn a GP model from available prior information; (ii) transform the learned GP kernel into binary coverage maps for each candidate sensing location, indicating which locations' uncertainty can be reduced below a specified target; and (iii) plan a near-shortest route whose combined coverage satisfies the global uncertainty constraint. To address heterogeneous phenomena, we incorporate a nonstationary kernel that captures spatially varying correlation structure, and we accommodate non-convex environments with obstacles. Algorithmically, we present methods with provable approximation guarantees for sensing-location selection and for the joint selection-and-routing problem under a travel budget. Experiments on real-world topographic data show that our planners meet the uncertainty target using fewer sensing locations and shorter travel distances than a recent baseline, and field experiments with bathymetry-mapping autonomous surface and underwater vehicles demonstrate real-world feasibility.

</details>


### [66] [MobileManiBench: Simplifying Model Verification for Mobile Manipulation](https://arxiv.org/abs/2602.05233)
*Wenbo Wang,Fangyun Wei,QiXiu Li,Xi Chen,Yaobo Liang,Chang Xu,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: 提出了MobileManiBench基准测试，用于移动机器人操作，通过仿真优先框架和强化学习自动生成多样化轨迹，包含30万条轨迹，支持VLA模型评估。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型依赖静态桌面场景的遥操作数据集，限制了移动机器人操作的发展，需要可扩展的仿真基准来验证VLA架构。

Method: 基于NVIDIA Isaac Sim构建仿真优先框架，使用强化学习自动生成多样化操作轨迹，包含丰富的标注（语言指令、多视角RGB-D分割图像、同步状态和动作）。

Result: 创建了MobileManiBench基准，包含2个移动平台、2个同步相机、630个物体、5种技能、100多个任务、100个真实场景，生成30万条轨迹，支持机器人本体、感知模态和政策架构的受控研究。

Conclusion: 该框架加速了数据效率和泛化能力的研究，通过基准测试代表性VLA模型，为复杂仿真环境中的感知、推理和控制提供了深入见解。

Abstract: Vision-language-action models have advanced robotic manipulation but remain constrained by reliance on the large, teleoperation-collected datasets dominated by the static, tabletop scenes. We propose a simulation-first framework to verify VLA architectures before real-world deployment and introduce MobileManiBench, a large-scale benchmark for mobile-based robotic manipulation. Built on NVIDIA Isaac Sim and powered by reinforcement learning, our pipeline autonomously generates diverse manipulation trajectories with rich annotations (language instructions, multi-view RGB-depth-segmentation images, synchronized object/robot states and actions). MobileManiBench features 2 mobile platforms (parallel-gripper and dexterous-hand robots), 2 synchronized cameras (head and right wrist), 630 objects in 20 categories, 5 skills (open, close, pull, push, pick) with over 100 tasks performed in 100 realistic scenes, yielding 300K trajectories. This design enables controlled, scalable studies of robot embodiments, sensing modalities, and policy architectures, accelerating research on data efficiency and generalization. We benchmark representative VLA models and report insights into perception, reasoning, and control in complex simulated environments.

</details>


### [67] [Low-Cost Underwater In-Pipe Centering and Inspection Using a Minimal-Sensing Robot](https://arxiv.org/abs/2602.05265)
*Kalvik Jakkala,Jason O'Kane*

Main category: cs.RO

TL;DR: 使用IMU、压力传感器和两个声纳（单波束和旋转360度）实现水下机器人在管道内自主居中导航的轻量级方案


<details>
  <summary>Details</summary>
Motivation: 水下管道检测面临几何受限、浑浊环境和定位信息稀缺的挑战，需要一种不依赖复杂传感器阵列的轻量级解决方案

Method: 提出基于单波束声纳强度数据的距离估计方法，利用几何模型计算管道中心，采用自适应置信度加权PD控制器保持居中

Result: 在46厘米直径的淹没管道中使用BlueROV2成功实现稳定居中和完整管道穿越，即使在环境流和结构变形条件下也能工作

Conclusion: 轻量级、计算高效的传感处理架构可实现可靠的水下管道内导航检测，提升了受限环境中自主水下检测的实用性

Abstract: Autonomous underwater inspection of submerged pipelines is challenging due to confined geometries, turbidity, and the scarcity of reliable localization cues. This paper presents a minimal-sensing strategy that enables a free-swimming underwater robot to center itself and traverse a flooded pipe of known radius using only an IMU, a pressure sensor, and two sonars: a downward-facing single-beam sonar and a rotating 360 degree sonar. We introduce a computationally efficient method for extracting range estimates from single-beam sonar intensity data, enabling reliable wall detection in noisy and reverberant conditions. A closed-form geometric model leverages the two sonar ranges to estimate the pipe center, and an adaptive, confidence-weighted proportional-derivative (PD) controller maintains alignment during traversal. The system requires no Doppler velocity log, external tracking, or complex multi-sensor arrays. Experiments in a submerged 46 cm-diameter pipe using a Blue Robotics BlueROV2 heavy remotely operated vehicle demonstrate stable centering and successful full-pipe traversal despite ambient flow and structural deformations. These results show that reliable in-pipe navigation and inspection can be achieved with a lightweight, computationally efficient sensing and processing architecture, advancing the practicality of autonomous underwater inspection in confined environments.

</details>


### [68] [Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions](https://arxiv.org/abs/2602.05273)
*Hengxuan Xu,Fengbo Lan,Zhixin Zhao,Shengjie Wang,Mengqiao Liu,Jieqian Sun,Yu Cheng,Tao Zhang*

Main category: cs.RO

TL;DR: AIDE是一个双流框架，通过交互式探索和视觉语言推理，让机器人在模糊指令下实时识别任务相关物体并执行任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的方法在模糊指令下（如"我渴了"）难以实时识别任务相关物体（杯子或饮料），主要因为推理效率低且缺乏环境交互，阻碍实时任务规划与执行。

Method: 提出AIDE双流框架：多阶段推理作为决策流，加速决策作为执行流，集成交互式探索与视觉语言推理，实现零样本可供性分析和模糊指令解释。

Result: 在仿真和真实环境实验中，AIDE任务规划成功率超过80%，闭环连续执行准确率超过95%（10Hz频率），在多样开放世界场景中优于现有VLM方法。

Conclusion: AIDE通过交互式探索与视觉语言推理的有效结合，显著提升了机器人在模糊指令下识别任务相关物体和执行任务的能力，为开放世界机器人应用提供了实用解决方案。

Abstract: Enabling robots to explore and act in unfamiliar environments under ambiguous human instructions by interactively identifying task-relevant objects (e.g., identifying cups or beverages for "I'm thirsty") remains challenging for existing vision-language model (VLM)-based methods. This challenge stems from inefficient reasoning and the lack of environmental interaction, which hinder real-time task planning and execution. To address this, We propose Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions (AIDE), a dual-stream framework that integrates interactive exploration with vision-language reasoning, where Multi-Stage Inference (MSI) serves as the decision-making stream and Accelerated Decision-Making (ADM) as the execution stream, enabling zero-shot affordance analysis and interpretation of ambiguous instructions. Extensive experiments in simulation and real-world environments show that AIDE achieves the task planning success rate of over 80\% and more than 95\% accuracy in closed-loop continuous execution at 10 Hz, outperforming existing VLM-based methods in diverse open-world scenarios.

</details>


### [69] [Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework](https://arxiv.org/abs/2602.05310)
*Jipeng Kong,Xinzhe Liu,Yuhang Lin,Jinrui Han,Sören Schwertfeger,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: PAiD是一个渐进式架构，将人形机器人足球技能学习分解为三个阶段：通过人体运动跟踪获取运动技能、轻量级感知-动作集成实现位置泛化、物理感知的仿真到现实迁移，在Unitree G1上实现了高保真的人形踢球能力。


<details>
  <summary>Details</summary>
Motivation: 足球对人形机器人提出了重大挑战，需要紧密集成的感知-动作能力。现有方法存在模块化管道中的模块间不稳定问题，或端到端框架中的训练目标冲突问题。

Method: 提出感知-动作集成决策（PAiD）架构，将足球技能获取分解为三个阶段：1）通过人体运动跟踪获取运动技能；2）轻量级感知-动作集成实现位置泛化；3）物理感知的仿真到现实迁移。

Result: 在Unitree G1上实现了高保真的人形踢球，在静态或滚动球、不同位置和干扰等多样化条件下表现稳健，在室内外场景中保持一致的执行能力。

Conclusion: 这种分而治之的策略推进了稳健的人形足球能力，并为复杂具身技能获取提供了一个可扩展的框架。

Abstract: Soccer presents a significant challenge for humanoid robots, demanding tightly integrated perception-action capabilities for tasks like perception-guided kicking and whole-body balance control. Existing approaches suffer from inter-module instability in modular pipelines or conflicting training objectives in end-to-end frameworks. We propose Perception-Action integrated Decision-making (PAiD), a progressive architecture that decomposes soccer skill acquisition into three stages: motion-skill acquisition via human motion tracking, lightweight perception-action integration for positional generalization, and physics-aware sim-to-real transfer. This staged decomposition establishes stable foundational skills, avoids reward conflicts during perception integration, and minimizes sim-to-real gaps. Experiments on the Unitree G1 demonstrate high-fidelity human-like kicking with robust performance under diverse conditions-including static or rolling balls, various positions, and disturbances-while maintaining consistent execution across indoor and outdoor scenarios. Our divide-and-conquer strategy advances robust humanoid soccer capabilities and offers a scalable framework for complex embodied skill acquisition. The project page is available at https://soccer-humanoid.github.io/.

</details>


### [70] [RoboPaint: From Human Demonstration to Any Robot and Any View](https://arxiv.org/abs/2602.05325)
*Jiacheng Fan,Zhiyue Zhao,Yiqian Zhang,Chao Chen,Peide Wang,Hengdi Zhang,Zhengxue Cheng*

Main category: cs.RO

TL;DR: 提出Real-Sim-Real数据流水线，通过人类演示生成机器人可执行数据，无需直接遥操作，解决VLA模型在灵巧操作中数据获取瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 获取大规模、高保真的机器人演示数据是扩展视觉-语言-动作模型在灵巧操作中的关键瓶颈。传统遥操作成本高、难以扩展。

Method: 1) 建立标准化数据采集室捕获多模态人类演示；2) 提出触觉感知重定向方法，通过几何和力引导优化将人手状态映射到机器人灵巧手状态；3) 在逼真仿真环境中渲染重定向轨迹生成训练数据

Result: 1) 重定向的灵巧手轨迹在10个多样化物体操作任务中达到84%成功率；2) 仅使用生成数据训练的VLA策略在三个代表性任务中达到80%平均成功率

Conclusion: 机器人训练数据可以通过人类演示"绘制"生成，提供了一种可扩展、经济高效的遥操作替代方案，在复杂灵巧操作中性能损失最小

Abstract: Acquiring large-scale, high-fidelity robot demonstration data remains a critical bottleneck for scaling Vision-Language-Action (VLA) models in dexterous manipulation. We propose a Real-Sim-Real data collection and data editing pipeline that transforms human demonstrations into robot-executable, environment-specific training data without direct robot teleoperation. Standardized data collection rooms are built to capture multimodal human demonstrations (synchronized 3 RGB-D videos, 11 RGB videos, 29-DoF glove joint angles, and 14-channel tactile signals). Based on these human demonstrations, we introduce a tactile-aware retargeting method that maps human hand states to robot dex-hand states via geometry and force-guided optimization. Then the retargeted robot trajectories are rendered in a photorealistic Isaac Sim environment to build robot training data. Real world experiments have demonstrated: (1) The retargeted dex-hand trajectories achieve an 84\% success rate across 10 diverse object manipulation tasks. (2) VLA policies (Pi0.5) trained exclusively on our generated data achieve 80\% average success rate on three representative tasks, i.e., pick-and-place, pushing and pouring. To conclude, robot training data can be efficiently "painted" from human demonstrations using our real-sim-real data pipeline. We offer a scalable, cost-effective alternative to teleoperation with minimal performance loss for complex dexterous manipulation.

</details>


### [71] [Benchmarking Affordance Generalization with BusyBox](https://arxiv.org/abs/2602.05441)
*Dean Fortier,Timothy Adamson,Tess Hellebrekers,Teresa LaScala,Kofi Ennin,Michael Murray,Andrey Kolobov,Galen Mullins*

Main category: cs.RO

TL;DR: BusyBox是一个用于评估VLA模型物理操作泛化能力的基准测试平台，包含6个可互换模块，挑战现有VLA模型的泛化性能


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在视觉和语言泛化方面已有进展，但缺乏对物理操作泛化（affordance generalization）的系统评估方法，即操纵具有熟悉物理特征的新物体的能力

Method: 设计BusyBox物理基准平台，包含6个可互换和旋转的模块（开关、滑块、电线、按钮、显示屏、旋钮），创建多种视觉外观不同但操作方式相同的变体，用于系统评估VLA模型的泛化能力

Result: BusyBox变体间的泛化对现有强大VLA模型（如π₀.₅和GR00T-N1.6）极具挑战性，证明了物理操作泛化评估的必要性

Conclusion: BusyBox为研究社区提供了易于构建的物理基准平台，促进VLA模型物理操作泛化能力的研究和评估，发布了完整的CAD文件、材料清单和演示数据集

Abstract: Vision-Language-Action (VLA) models have been attracting the attention of researchers and practitioners thanks to their promise of generalization. Although single-task policies still offer competitive performance, VLAs are increasingly able to handle commands and environments unseen in their training set. While generalization in vision and language space is undoubtedly important for robust versatile behaviors, a key meta-skill VLAs need to possess is affordance generalization -- the ability to manipulate new objects with familiar physical features.
  In this work, we present BusyBox, a physical benchmark for systematic semi-automatic evaluation of VLAs' affordance generalization. BusyBox consists of 6 modules with switches, sliders, wires, buttons, a display, and a dial. The modules can be swapped and rotated to create a multitude of BusyBox variations with different visual appearances but the same set of affordances. We empirically demonstrate that generalization across BusyBox variants is highly challenging even for strong open-weights VLAs such as $π_{0.5}$ and GR00T-N1.6. To encourage the research community to evaluate their own VLAs on BusyBox and to propose new affordance generalization experiments, we have designed BusyBox to be easy to build in most robotics labs. We release the full set of CAD files for 3D-printing its parts as well as a bill of materials for (optionally) assembling its electronics. We also publish a dataset of language-annotated demonstrations that we collected using the common bimanual Mobile Aloha robot on the canonical BusyBox configuration. All of the released materials are available at https://microsoft.github.io/BusyBox.

</details>


### [72] [Ontology-Driven Robotic Specification Synthesis](https://arxiv.org/abs/2602.05456)
*Maksym Figat,Ryan M. Mackey,Michel D. Ingham*

Main category: cs.RO

TL;DR: RSTM2方法通过本体驱动、分层建模，使用随机时间Petri网与资源，支持蒙特卡洛仿真，实现机器人系统从高层目标到形式化可执行规范的转换。


<details>
  <summary>Details</summary>
Motivation: 解决安全关键和任务关键机器人系统工程中高层目标与形式化可执行规范之间的鸿沟，支持复杂多机器人系统的架构权衡、资源分配和不确定性下的性能分析。

Method: 提出RSTM2（机器人系统任务到模型转换方法），采用本体驱动、分层方法，使用带资源的随机时间Petri网，支持任务、系统和子系统级别的蒙特卡洛仿真。

Result: 通过假设案例研究展示RSTM2支持架构权衡、资源分配和不确定性性能分析，本体概念支持可解释AI助手，实现全自主规范合成，特别适用于NASA CADRE等复杂多机器人任务。

Conclusion: RSTM2方法为复杂多机器人系统提供有效工程框架，支持分散、资源感知和自适应自主系统的开发，对未来自主系统设计具有重要意义。

Abstract: This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchical approach using stochastic timed Petri nets with resources, enabling Monte Carlo simulations at mission, system, and subsystem levels. A hypothetical case study demonstrates how the RSTM2 method supports architectural trades, resource allocation, and performance analysis under uncertainty. Ontological concepts further enable explainable AI-based assistants, facilitating fully autonomous specification synthesis. The methodology offers particular benefits to complex multi-robot systems, such as the NASA CADRE mission, representing decentralized, resource-aware, and adaptive autonomous systems of the future.

</details>


### [73] [TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation](https://arxiv.org/abs/2602.05468)
*Pranav Ponnivalavan,Satoshi Funabashi,Alexander Schmitz,Tetsuya Ogata,Shigeki Sugano*

Main category: cs.RO

TL;DR: 提出TaSA框架，通过两阶段深度预测学习，让机器人像人类一样区分自接触和外部接触的触觉信号，实现灵巧操作


<details>
  <summary>Details</summary>
Motivation: 机器人灵巧操作需要同时接触物体和多个手指，但难以区分自接触和外部接触的触觉信号。现有方法大多忽略自接触，限制了在真实场景中的泛化能力。人类通过感觉衰减机制区分可预测的自接触信号，使新颖物体刺激凸显为相关信号

Method: 提出TaSA两阶段深度预测学习框架：第一阶段学习自接触动力学，建模机器人自身动作如何产生触觉反馈；第二阶段将学习到的模型融入运动学习阶段，强调操作过程中的物体接触信号

Result: 在需要精细触觉辨别的插入任务上评估：将铅笔芯插入自动铅笔、将硬币插入投币口、将回形针固定在纸上。所有任务中，使用TaSA训练的策略都比基线方法获得显著更高的成功率

Conclusion: 基于感觉衰减的结构化触觉感知对于机器人灵巧操作至关重要。TaSA框架通过模拟人类的自接触感知机制，使机器人能够区分自接触和外部接触信号，实现更可靠的灵巧操作

Abstract: Humans can achieve diverse in-hand manipulations, such as object pinching and tool use, which often involve simultaneous contact between the object and multiple fingers. This is still an open issue for robotic hands because such dexterous manipulation requires distinguishing between tactile sensations generated by their self-contact and those arising from external contact. Otherwise, object/robot breakage happens due to contacts/collisions. Indeed, most approaches ignore self-contact altogether, by constraining motion to avoid/ignore self-tactile information during contact. While this reduces complexity, it also limits generalization to real-world scenarios where self-contact is inevitable. Humans overcome this challenge through self-touch perception, using predictive mechanisms that anticipate the tactile consequences of their own motion, through a principle called sensory attenuation, where the nervous system differentiates predictable self-touch signals, allowing novel object stimuli to stand out as relevant. Deriving from this, we introduce TaSA, a two-phased deep predictive learning framework. In the first phase, TaSA explicitly learns self-touch dynamics, modeling how a robot's own actions generate tactile feedback. In the second phase, this learned model is incorporated into the motion learning phase, to emphasize object contact signals during manipulation. We evaluate TaSA on a set of insertion tasks, which demand fine tactile discrimination: inserting a pencil lead into a mechanical pencil, inserting coins into a slot, and fixing a paper clip onto a sheet of paper, with various orientations, positions, and sizes. Across all tasks, policies trained with TaSA achieve significantly higher success rates than baseline methods, demonstrating that structured tactile perception with self-touch based on sensory attenuation is critical for dexterous robotic manipulation.

</details>


### [74] [DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter](https://arxiv.org/abs/2602.05513)
*Xukun Li,Yu Sun,Lei Zhang,Bosheng Huang,Yibo Peng,Yuan Meng,Haojun Jiang,Shaoxuan Xie,Guacai Yao,Alois Knoll,Zhenshan Bing,Xinlong Wang,Zhenguo Sun*

Main category: cs.RO

TL;DR: DECO是一个基于DiT的策略框架，通过解耦多模态条件来实现灵巧操作，并附带包含50小时数据的DECO-50数据集。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个能够有效处理多模态输入（视觉、触觉、本体感觉）的灵巧操作策略，同时利用预训练模型进行高效微调。

Method: 使用DiT-based策略，通过联合自注意力处理图像和动作token，自适应层归一化注入本体感觉，交叉注意力注入触觉信号，LoRA适配器进行高效微调。

Result: 提出了DECO框架和DECO-50数据集，包含4个场景、28个子任务、50小时数据、500万帧和8000条成功轨迹。

Conclusion: DECO框架通过解耦多模态条件实现了有效的灵巧操作，DECO-50数据集为双手机器人操作研究提供了宝贵资源。

Abstract: Overview of the Proposed DECO Framework.} DECO is a DiT-based policy that decouples multimodal conditioning. Image and action tokens interact via joint self attention, while proprioceptive states and optional conditions are injected through adaptive layer normalization. Tactile signals are injected via cross attention, while a lightweight LoRA-based adapter is used to efficiently fine-tune the pretrained policy. DECO is also accompanied by DECO-50, a bimanual dexterous manipulation dataset with tactile sensing, consisting of 4 scenarios and 28 sub-tasks, covering more than 50 hours of data, approximately 5 million frames, and 8,000 successful trajectories.

</details>


### [75] [Virtual-Tube-Based Cooperative Transport Control for Multi-UAV Systems in Constrained Environments](https://arxiv.org/abs/2602.05516)
*Runxiao Liu,Pengda Mao,Xiangli Le,Shuang Gu,Yapeng Chen,Quan Quan*

Main category: cs.RO

TL;DR: 提出基于虚拟管理论和耗散系统理论的多无人机协同运输控制框架，用于受限环境下的电缆悬挂负载运输


<details>
  <summary>Details</summary>
Motivation: 解决多无人机在受限环境中协同运输电缆悬挂负载的挑战，需要高效协调、动态适应障碍物布局，同时保证系统稳定性和鲁棒性

Method: 结合虚拟管理论和耗散系统理论，设计低计算开销的控制框架，实现张力分配和协调运输，动态调整无人机配置以适应障碍物布局

Result: 通过大量仿真验证了方法的有效性，展示了大规模多无人机系统的可扩展性，并在室外场景中进行了实验验证，证明了实际可行性和鲁棒性

Conclusion: 提出的控制框架能够高效实现多无人机在受限环境中的协同负载运输，具有低计算开销、高稳定性和鲁棒性，适用于实际应用场景

Abstract: This paper proposes a novel control framework for cooperative transportation of cable-suspended loads by multiple unmanned aerial vehicles (UAVs) operating in constrained environments. Leveraging virtual tube theory and principles from dissipative systems theory, the framework facilitates efficient multi-UAV collaboration for navigating obstacle-rich areas. The proposed framework offers several key advantages. (1) It achieves tension distribution and coordinated transportation within the UAV-cable-load system with low computational overhead, dynamically adapting UAV configurations based on obstacle layouts to facilitate efficient navigation. (2) By integrating dissipative systems theory, the framework ensures high stability and robustness, essential for complex multi-UAV operations. The effectiveness of the proposed approach is validated through extensive simulations, demonstrating its scalability for large-scale multi-UAV systems. Furthermore, the method is experimentally validated in outdoor scenarios, showcasing its practical feasibility and robustness under real-world conditions.

</details>


### [76] [VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator](https://arxiv.org/abs/2602.05552)
*Bessie Dominguez-Dager,Sergio Suescun-Ferrandiz,Felix Escalona,Francisco Gomez-Donoso,Miguel Cazorla*

Main category: cs.RO

TL;DR: VLN-Pilot是一个利用大型视觉语言模型作为无人机室内导航"飞行员"的框架，通过自然语言指令和视觉感知实现自主导航，无需GPS或复杂工程。


<details>
  <summary>Details</summary>
Motivation: 传统室内无人机导航依赖基于规则或几何路径规划的方法，需要大量任务特定工程。本文旨在利用VLLM的多模态推理能力，实现更自然、语义理解驱动的自主导航，减少操作员负担并提高安全性。

Method: VLN-Pilot框架让大型视觉语言模型充当无人机飞行员，通过解释自由形式的自然语言指令，结合视觉观察进行接地，规划并执行无人机轨迹。框架整合了语言驱动的语义理解和视觉感知，支持空间关系推理、避障和动态事件响应。

Result: 在自定义的逼真室内仿真基准测试中，VLLM驱动的智能体在复杂指令跟随任务上取得了高成功率，包括具有多个语义目标的长期导航。结果表明语言引导的自主代理有望替代远程无人机飞行员。

Conclusion: VLN-Pilot展示了VLLM在室内无人机导航中的潜力，能够显著减少操作员工作量，提高安全性和任务灵活性，为检查、搜救、设施监控等应用提供了可扩展、人性化的无人机控制方案。

Abstract: This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.

</details>


### [77] [TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards](https://arxiv.org/abs/2602.05596)
*Hokyun Lee,Woo-Jeong Baek,Junhyeok Cha,Jaeheung Park*

Main category: cs.RO

TL;DR: TOLEBI是一个用于双足机器人步态的故障容忍学习框架，通过模拟关节锁定、电源故障和外部干扰来学习容错步态策略，并包含在线关节状态模块进行实时故障分类。


<details>
  <summary>Details</summary>
Motivation: 随着学习算法在机器人应用中的广泛使用，双足步态的强化学习成为人形机器人研究的热点。然而，现有研究很少关注处理步态过程中可能发生的硬件故障，而现实环境中的干扰或突发硬件故障可能导致严重后果。

Method: 提出TOLEBI框架：1)在模拟中注入关节锁定、电源故障和外部干扰来学习容错步态策略；2)通过仿真到现实的迁移将学习到的策略转移到真实机器人；3)集成在线关节状态模块，根据实际观测实时分类关节状态。

Result: 在人形机器人TOCABI上进行的真实世界和模拟验证实验证明了该方法的适用性。据作者所知，这是首个基于学习的双足步态容错框架。

Conclusion: 该论文提出了首个基于学习的双足步态故障容忍框架TOLEBI，通过模拟故障训练和在线状态监测相结合的方法，为这一领域高效学习方法的发展做出了贡献。

Abstract: With the growing employment of learning algorithms in robotic applications, research on reinforcement learning for bipedal locomotion has become a central topic for humanoid robotics. While recently published contributions achieve high success rates in locomotion tasks, scarce attention has been devoted to the development of methods that enable to handle hardware faults that may occur during the locomotion process. However, in real-world settings, environmental disturbances or sudden occurrences of hardware faults might yield severe consequences. To address these issues, this paper presents TOLEBI (A faulT-tOlerant Learning framEwork for Bipedal locomotIon) that handles faults on the robot during operation. Specifically, joint locking, power loss and external disturbances are injected in simulation to learn fault-tolerant locomotion strategies. In addition to transferring the learned policy to the real robot via sim-to-real transfer, an online joint status module incorporated. This module enables to classify joint conditions by referring to the actual observations at runtime under real-world conditions. The validation experiments conducted both in real-world and simulation with the humanoid robot TOCABI highlight the applicability of the proposed approach. To our knowledge, this manuscript provides the first learning-based fault-tolerant framework for bipedal locomotion, thereby fostering the development of efficient learning methods in this field.

</details>


### [78] [HiCrowd: Hierarchical Crowd Flow Alignment for Dense Human Environments](https://arxiv.org/abs/2602.05608)
*Yufei Zhu,Shih-Min Yang,Martin Magnusson,Allan Wang*

Main category: cs.RO

TL;DR: HiCrowd：分层框架结合强化学习和模型预测控制，利用行人运动作为引导，解决机器人在密集人群中的冻结问题，提高导航效率和安全


<details>
  <summary>Details</summary>
Motivation: 解决机器人在密集人群中的"冻结机器人问题"——机器人难以找到安全运动路径而被困在人群中。现有方法将行人仅视为动态障碍物，限制了导航效率

Method: 提出HiCrowd分层框架：高层RL策略生成跟随点，使机器人与合适行人群体对齐；低层MPC安全跟踪引导，进行短期规划。结合长期人群感知决策与安全短期执行

Result: 在真实世界数据集和合成人群数据集上评估，相比反应式和基于学习的方法，在导航效率、安全性方面表现更优，减少了冻结行为

Conclusion: 将人类运动作为引导而非仅视为动态障碍物，为机器人在人群中的安全高效导航提供了有力原则。分层方法有效结合了长期决策与短期安全执行

Abstract: Navigating through dense human crowds remains a significant challenge for mobile robots. A key issue is the freezing robot problem, where the robot struggles to find safe motions and becomes stuck within the crowd. To address this, we propose HiCrowd, a hierarchical framework that integrates reinforcement learning (RL) with model predictive control (MPC). HiCrowd leverages surrounding pedestrian motion as guidance, enabling the robot to align with compatible crowd flows. A high-level RL policy generates a follow point to align the robot with a suitable pedestrian group, while a low-level MPC safely tracks this guidance with short horizon planning. The method combines long-term crowd aware decision making with safe short-term execution. We evaluate HiCrowd against reactive and learning-based baselines in offline setting (replaying recorded human trajectories) and online setting (human trajectories are updated to react to the robot in simulation). Experiments on a real-world dataset and a synthetic crowd dataset show that our method outperforms in navigation efficiency and safety, while reducing freezing behaviors. Our results suggest that leveraging human motion as guidance, rather than treating humans solely as dynamic obstacles, provides a powerful principle for safe and efficient robot navigation in crowds.

</details>


### [79] [From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking](https://arxiv.org/abs/2602.05683)
*Chuwei Wang,Eduardo Sebastián,Amanda Prorok,Anastasia Bizyaeva*

Main category: cs.RO

TL;DR: 提出一种神经形态控制框架，用于视觉引导导航和跟踪，通过动态神经元群体将视觉目标激励直接转换为自我中心运动命令，利用动态分岔机制解决目标对称性导致的决策困难。


<details>
  <summary>Details</summary>
Motivation: 机器人导航长期面临反应式传感器控制与基于模型规划之间的权衡问题。当多个目标选项对称存在时，反应式系统难以做出决策，而传统规划器计算成本高昂。需要一种既能实时响应又具有决策能力的方法。

Method: 提出神经形态控制框架：1) 将机载摄像头像素编码为动态神经元群体的输入；2) 将视觉目标激励直接转换为自我中心运动命令；3) 引入动态分岔机制，延迟决策直到环境几何诱导的临界点出现；4) 受动物认知和意见动态机制模型启发，设计具有可解释参数的系统。

Result: 在仿真环境和实验四旋翼平台上验证了该方法的有效性。控制器实现了实时自主性，计算负担小，参数少且可解释，能够无缝集成到特定应用的图像处理流程中。

Conclusion: 该神经形态控制框架成功桥接了反应式控制与模型规划之间的鸿沟，通过动态分岔机制解决了对称目标下的决策问题，为视觉引导导航提供了计算高效、实时响应的解决方案。

Abstract: Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.

</details>


### [80] [Task-Oriented Robot-Human Handovers on Legged Manipulators](https://arxiv.org/abs/2602.05760)
*Andreea Tulbure,Carmen Scheidemann,Elias Steiner,Marco Hutter*

Main category: cs.RO

TL;DR: AFT-Handover是一个零样本、可泛化的任务导向递物框架，通过LLM驱动的可供性推理和纹理化可供性转移，实现机器人对新颖物体-任务对的智能递物。


<details>
  <summary>Details</summary>
Motivation: 现有任务导向递物方法通常基于物体或任务特定的可供性，泛化能力有限，难以处理新颖场景。需要开发能够零样本泛化到新物体-任务对的递物框架。

Method: 结合LLM驱动的可供性推理和高效的基于纹理的可供性转移。给定新物体-任务对时，从数据库中检索代理示例，通过LLM推理建立部件级对应关系，纹理化可供性进行基于特征的点云转移。

Result: 在多样化的任务-物体对上评估显示，相比基线方法提高了递物成功率并增强了泛化能力。用户研究中显著优于当前最先进方法，有效减少了人类在使用工具前的重新抓握。

Conclusion: AFT-Handover框架实现了零样本、可泛化的任务导向递物，在腿式机械臂上展示了实际应用潜力，为现实世界机器人-人类递物提供了有效解决方案。

Abstract: Task-oriented handovers (TOH) are fundamental to effective human-robot collaboration, requiring robots to present objects in a way that supports the human's intended post-handover use. Existing approaches are typically based on object- or task-specific affordances, but their ability to generalize to novel scenarios is limited. To address this gap, we present AFT-Handover, a framework that integrates large language model (LLM)-driven affordance reasoning with efficient texture-based affordance transfer to achieve zero-shot, generalizable TOH. Given a novel object-task pair, the method retrieves a proxy exemplar from a database, establishes part-level correspondences via LLM reasoning, and texturizes affordances for feature-based point cloud transfer. We evaluate AFT-Handover across diverse task-object pairs, showing improved handover success rates and stronger generalization compared to baselines. In a comparative user study, our framework is significantly preferred over the current state-of-the-art, effectively reducing human regrasping before tool use. Finally, we demonstrate TOH on legged manipulators, highlighting the potential of our framework for real-world robot-human handovers.

</details>


### [81] [Scalable and General Whole-Body Control for Cross-Humanoid Locomotion](https://arxiv.org/abs/2602.05791)
*Yufei Xue,YunFeng Lin,Wentao Dong,Yang Tang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Minghuan Liu,Weinan Zhang*

Main category: cs.RO

TL;DR: XHugWBC：一个跨具身人形机器人控制框架，通过单次训练实现多种不同设计人形机器人的通用控制


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的人形机器人全身控制器通常需要针对特定机器人进行训练，缺乏通用性。本文研究跨具身人形控制问题，旨在开发一个能泛化到多种不同设计人形机器人的单一策略。

Method: 提出XHugWBC框架，包含三个关键技术：(1) 物理一致的形态随机化，(2) 跨不同人形机器人的语义对齐观察和动作空间，(3) 建模形态和动力学特性的有效策略架构。该框架在训练中内化广泛的形态和动力学特征分布。

Result: 在12个模拟人形机器人和7个真实机器人上的实验表明，该通用控制器具有强大的泛化能力和鲁棒性，能够实现零样本迁移到未见过的机器人。

Conclusion: XHugWBC框架通过一次训练即可实现跨多种人形机器人的通用控制，学习到的运动先验支持零样本迁移，为人形机器人控制提供了通用解决方案。

Abstract: Learning-based whole-body controllers have become a key driver for humanoid robots, yet most existing approaches require robot-specific training. In this paper, we study the problem of cross-embodiment humanoid control and show that a single policy can robustly generalize across a wide range of humanoid robot designs with one-time training. We introduce XHugWBC, a novel cross-embodiment training framework that enables generalist humanoid control through: (1) physics-consistent morphological randomization, (2) semantically aligned observation and action spaces across diverse humanoid robots, and (3) effective policy architectures modeling morphological and dynamical properties. XHugWBC is not tied to any specific robot. Instead, it internalizes a broad distribution of morphological and dynamical characteristics during training. By learning motion priors from diverse randomized embodiments, the policy acquires a strong structural bias that supports zero-shot transfer to previously unseen robots. Experiments on twelve simulated humanoids and seven real-world robots demonstrate the strong generalization and robustness of the resulting universal controller.

</details>


### [82] [A Hybrid Autoencoder for Robust Heightmap Generation from Fused Lidar and Depth Data for Humanoid Robot Locomotion](https://arxiv.org/abs/2602.05855)
*Dennis Bank,Joost Cordes,Thomas Seel,Simon F. G. Ehlers*

Main category: cs.RO

TL;DR: 提出基于学习的多模态感知框架，使用机器人中心高度图表示，结合CNN和GRU实现时空一致的地形重建，在深度相机、LiDAR和IMU融合下提升精度7.2-9.9%


<details>
  <summary>Details</summary>
Motivation: 传统人形机器人地形感知系统依赖手动设计的单传感器管道，在非结构化人类环境中可靠性不足，需要更鲁棒的多模态学习框架

Method: 采用机器人中心高度图作为中间表示，设计混合编码器-解码器结构：CNN提取空间特征，GRU核心处理时序一致性，融合Intel RealSense深度相机、LIVOX MID-360 LiDAR（通过球面投影处理）和IMU多模态数据

Result: 多模态融合相比仅用深度相机提升7.2%重建精度，相比仅用LiDAR提升9.9%；集成3.2秒时序上下文有效减少建图漂移

Conclusion: 学习型多模态框架显著提升人形机器人在非结构化环境中的地形感知可靠性，时空融合策略有效改善重建精度和稳定性

Abstract: Reliable terrain perception is a critical prerequisite for the deployment of humanoid robots in unstructured, human-centric environments. While traditional systems often rely on manually engineered, single-sensor pipelines, this paper presents a learning-based framework that uses an intermediate, robot-centric heightmap representation. A hybrid Encoder-Decoder Structure (EDS) is introduced, utilizing a Convolutional Neural Network (CNN) for spatial feature extraction fused with a Gated Recurrent Unit (GRU) core for temporal consistency. The architecture integrates multimodal data from an Intel RealSense depth camera, a LIVOX MID-360 LiDAR processed via efficient spherical projection, and an onboard IMU. Quantitative results demonstrate that multimodal fusion improves reconstruction accuracy by 7.2% over depth-only and 9.9% over LiDAR-only configurations. Furthermore, the integration of a 3.2 s temporal context reduces mapping drift.

</details>


### [83] [Residual Reinforcement Learning for Waste-Container Lifting Using Large-Scale Cranes with Underactuated Tools](https://arxiv.org/abs/2602.05895)
*Qi Li,Karsten Berns*

Main category: cs.RO

TL;DR: 提出一种残差强化学习方法，结合名义控制器和学习的残差策略，用于液压装载起重机执行垃圾容器提升任务，提高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 城市环境中垃圾容器回收任务的容器提升阶段面临严格几何公差要求，需要精确轨迹跟踪和摆动抑制，而传统控制器难以处理未建模动态和参数变化。

Method: 采用残差强化学习框架：名义控制器使用导纳控制进行轨迹跟踪和摆锤感知摆动阻尼，配合阻尼最小二乘逆运动学；PPO训练的残差策略补偿未建模动态；采用随机化初始化和域随机化增强泛化能力。

Result: 仿真结果显示，相比单独使用名义控制器，该方法提高了跟踪精度、减少了振荡、获得了更高的提升成功率。

Conclusion: 残差强化学习方法有效提升了液压起重机在严格几何公差任务中的性能，无需从头端到端学习，具有更好的精度和鲁棒性。

Abstract: This paper studies the container lifting phase of a waste-container recycling task in urban environments, performed by a hydraulic loader crane equipped with an underactuated discharge unit, and proposes a residual reinforcement learning (RRL) approach that combines a nominal Cartesian controller with a learned residual policy. All experiments are conducted in simulation, where the task is characterized by tight geometric tolerances between the discharge-unit hooks and the container rings relative to the overall crane scale, making precise trajectory tracking and swing suppression essential. The nominal controller uses admittance control for trajectory tracking and pendulum-aware swing damping, followed by damped least-squares inverse kinematics with a nullspace posture term to generate joint velocity commands. A PPO-trained residual policy in Isaac Lab compensates for unmodeled dynamics and parameter variations, improving precision and robustness without requiring end-to-end learning from scratch. We further employ randomized episode initialization and domain randomization over payload properties, actuator gains, and passive joint parameters to enhance generalization. Simulation results demonstrate improved tracking accuracy, reduced oscillations, and higher lifting success rates compared to the nominal controller alone.

</details>


### [84] [From Bench to Flight: Translating Drone Impact Tests into Operational Safety Limits](https://arxiv.org/abs/2602.05922)
*Aziz Mohamed Mili,Louis Catar,Paul Gérard,Ilyass Tabiai,David St-Onge*

Main category: cs.RO

TL;DR: 开发了一个端到端工具链，将实验室冲击测试转化为可部署的无人机安全控制器，用于室内微飞行器近人操作的安全管理


<details>
  <summary>Details</summary>
Motivation: 室内微飞行器越来越多地用于需要接近人员的任务，但缺乏基于实测冲击风险调整运动限制的实用方法

Method: 1) 设计紧凑可复制的冲击测试装置和协议；2) 建立数据驱动模型，将碰撞前速度映射到冲量和接触持续时间；3) 发布脚本和ROS2节点在线执行速度限制并记录合规性

Result: 在多个商用现成四旋翼无人机和代表性室内资产上验证了工作流程，证明推导出的控制器在满足安全利益相关者指定的力约束的同时保持了任务吞吐量

Conclusion: 提供了一个从实测冲击到运行时限制的实用桥梁，包括可共享的数据集、代码和可重复流程，团队可采用此方法认证室内微飞行器近人操作的安全性

Abstract: Indoor micro-aerial vehicles (MAVs) are increasingly used for tasks that require close proximity to people, yet practitioners lack practical methods to tune motion limits based on measured impact risk. We present an end-to-end, open toolchain that converts benchtop impact tests into deployable safety governors for drones. First, we describe a compact and replicable impact rig and protocol for capturing force-time profiles across drone classes and contact surfaces. Second, we provide data-driven models that map pre-impact speed to impulse and contact duration, enabling direct computation of speed bounds for a target force limit. Third, we release scripts and a ROS2 node that enforce these bounds online and log compliance, with support for facility-specific policies. We validate the workflow on multiple commercial off-the-shelf quadrotors and representative indoor assets, demonstrating that the derived governors preserve task throughput while meeting force constraints specified by safety stakeholders. Our contribution is a practical bridge from measured impacts to runtime limits, with shareable datasets, code, and a repeatable process that teams can adopt to certify indoor MAV operations near humans.

</details>


### [85] [Visuo-Tactile World Models](https://arxiv.org/abs/2602.06001)
*Carolina Higuera,Sergio Arnaud,Byron Boots,Mustafa Mukadam,Francois Robert Hogan,Franziska Meier*

Main category: cs.RO

TL;DR: 提出多任务视觉-触觉世界模型VT-WM，通过触觉推理捕捉接触物理特性，在接触丰富的操作任务中提升物理保真度和规划性能


<details>
  <summary>Details</summary>
Motivation: 纯视觉模型在遮挡或接触状态模糊时容易出现物体消失、瞬移或违反物理规律等失败模式，需要结合触觉传感来更好地理解机器人-物体交互

Method: 开发多任务视觉-触觉世界模型，通过触觉传感补充视觉信息，在多个接触丰富的操作任务上进行训练，学习接触动力学

Result: 在自回归推演中，物体持久性保持提升33%，运动规律符合度提升29%；零样本真实机器人实验成功率最高提升35%；能够有效适应新任务

Conclusion: VT-WM通过结合视觉和触觉传感显著提升了接触丰富任务中的物理保真度和规划性能，展示了接触动力学学习的下游适应能力

Abstract: We introduce multi-task Visuo-Tactile World Models (VT-WM), which capture the physics of contact through touch reasoning. By complementing vision with tactile sensing, VT-WM better understands robot-object interactions in contact-rich tasks, avoiding common failure modes of vision-only models under occlusion or ambiguous contact states, such as objects disappearing, teleporting, or moving in ways that violate basic physics. Trained across a set of contact-rich manipulation tasks, VT-WM improves physical fidelity in imagination, achieving 33% better performance at maintaining object permanence and 29% better compliance with the laws of motion in autoregressive rollouts. Moreover, experiments show that grounding in contact dynamics also translates to planning. In zero-shot real-robot experiments, VT-WM achieves up to 35% higher success rates, with the largest gains in multi-step, contact-rich tasks. Finally, VT-WM demonstrates significant downstream versatility, effectively adapting its learned contact dynamics to a novel task and achieving reliable planning success with only a limited set of demonstrations.

</details>


### [86] [CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction](https://arxiv.org/abs/2602.06038)
*Xiaopan Zhang,Zejin Wang,Zhixu Li,Jianpeng Yao,Jiachen Li*

Main category: cs.RO

TL;DR: 论文提出CommCP框架，用于解决多智能体多任务具身问答问题，通过LLM和保形预测来提升机器人间的通信效率和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现实世界中需要多个异构机器人协同完成人类自然语言指令，但现有研究缺乏对多智能体信息收集过程的系统处理，特别是在具身问答场景中如何有效通信以避免冗余。

Method: 提出CommCP框架：基于LLM的去中心化通信框架，采用保形预测校准生成的消息，减少接收者分心并提升通信可靠性。同时创建了MM-EQA基准测试。

Result: 实验结果表明，CommCP在任务成功率和探索效率上显著优于基线方法。

Conclusion: 该研究为解决多智能体协同信息收集问题提供了有效框架，通过可靠的通信机制提升了异构机器人团队在复杂环境中的任务执行能力。

Abstract: To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this component of the problem, we formalize the information-gathering process in a fully cooperative setting as an underexplored multi-agent multi-task Embodied Question Answering (MM-EQA) problem, which is a novel extension of canonical Embodied Question Answering (EQA), where effective communication is crucial for coordinating efforts without redundancy. To address this problem, we propose CommCP, a novel LLM-based decentralized communication framework designed for MM-EQA. Our framework employs conformal prediction to calibrate the generated messages, thereby minimizing receiver distractions and enhancing communication reliability. To evaluate our framework, we introduce an MM-EQA benchmark featuring diverse, photo-realistic household scenarios with embodied questions. Experimental results demonstrate that CommCP significantly enhances the task success rate and exploration efficiency over baselines. The experiment videos, code, and dataset are available on our project website: https://comm-cp.github.io.

</details>
