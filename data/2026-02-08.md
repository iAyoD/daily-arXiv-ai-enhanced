<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 59]
- [cs.RO](#cs.RO) [Total: 27]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations](https://arxiv.org/abs/2602.04982)
*Deepak Gupta,Davis Bartels,Dina Demner-Fuhsman*

Main category: cs.CL

TL;DR: BioACE是一个用于自动评估生物医学问答生成质量和引用支持的框架，通过完整性、正确性、精确度和召回率等多个维度来评估答案，并与人类评估进行相关性分析。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在生物医学问答中的广泛应用，评估生成答案的质量和引用支持变得至关重要。由于需要专家验证科学文献一致性和复杂医学术语，生物医学领域的文本生成评估仍然是一个挑战。

Method: 提出BioACE框架，从完整性、正确性、精确度和召回率等多个方面评估答案质量，基于真实信息片段进行评价。开发自动化方法评估每个方面，并与人类评估进行相关性分析。同时考虑自然语言推理、预训练语言模型和LLMs等多种现有方法来评估引用质量。

Result: 通过详细的实验和分析，提供了生物医学答案和引用评估的最佳方法，并作为BioACE评估包的一部分发布在GitHub上。

Conclusion: BioACE为生物医学问答生成和引用评估提供了一个有效的自动化框架，解决了该领域评估的挑战，并为研究人员提供了实用的评估工具。

Abstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluation of text generated by LLMs remains a challenge for question answering, retrieval-augmented generation (RAG), summarization, and many other natural language processing tasks in the biomedical domain, due to the requirements of expert assessment to verify consistency with the scientific literature and complex medical terminology. In this work, we propose BioACE, an automated framework for evaluating biomedical answers and citations against the facts stated in the answers. The proposed BioACE framework considers multiple aspects, including completeness, correctness, precision, and recall, in relation to the ground-truth nuggets for answer evaluation. We developed automated approaches to evaluate each of the aforementioned aspects and performed extensive experiments to assess and analyze their correlation with human evaluations. In addition, we considered multiple existing approaches, such as natural language inference (NLI) and pre-trained language models and LLMs, to evaluate the quality of evidence provided to support the generated answers in the form of citations into biomedical literature. With the detailed experiments and analysis, we provide the best approaches for biomedical answer and citation evaluation as a part of BioACE (https://github.com/deepaknlp/BioACE) evaluation package.

</details>


### [2] [CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System](https://arxiv.org/abs/2602.05004)
*Zexin Lin,Jiachen Yu,Haoyang Zhang,Yuzhao Li,Zhonghang Li,Yujiu Yang,Junjie Wang,Xiaoqiang Ji*

Main category: cs.CL

TL;DR: CoWork-X：一个主动协同进化框架，通过结构化技能库和预算约束的技能整合，解决实时协作任务中的延迟和令牌预算问题


<details>
  <summary>Details</summary>
Motivation: 当前语言条件智能体在高度协作任务中面临两个矛盾约束：需要亚秒级实时协调，同时要在严格的在线令牌预算下进行持续多回合适应。现有方法要么依赖频繁的回合内推理导致延迟和时序抖动，要么通过非结构化文本进行回合后改进，难以编译为可靠的低成本执行。

Method: 提出CoWork-X主动协同进化框架，将同伴协作建模为跨回合的闭环优化问题。框架包含：1）技能智能体，通过基于HTN的技能检索从结构化、可解释、可组合的技能库执行；2）回合后协同优化器，在明确预算约束和漂移正则化下执行补丁式技能整合。

Result: 在具有挑战性的Overcooked-AI类实时协作基准测试中，CoWork-X实现了稳定、累积的性能提升，同时持续降低在线延迟和令牌使用量。

Conclusion: CoWork-X通过结构化技能库和预算约束的技能整合，有效解决了实时协作任务中的延迟和令牌预算矛盾，实现了性能的持续改进和资源消耗的降低。

Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is difficult to compile into reliable low-cost execution. We propose CoWork-X, an active co-evolution framework that casts peer collaboration as a closed-loop optimization problem across episodes, inspired by fast--slow memory separation. CoWork-X instantiates a Skill-Agent that executes via HTN (hierarchical task network)-based skill retrieval from a structured, interpretable, and compositional skill library, and a post-episode Co-Optimizer that performs patch-style skill consolidation with explicit budget constraints and drift regularization. Experiments in challenging Overcooked-AI-like realtime collaboration benchmarks demonstrate that CoWork-X achieves stable, cumulative performance gains while steadily reducing online latency and token usage.

</details>


### [3] [Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation](https://arxiv.org/abs/2602.05035)
*Sean Trott,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 多语言语言模型在词汇消歧任务上表现不如单语模型，研究发现这主要源于三种能力限制：表征能力降低、注意力机制减弱和词汇分割问题。


<details>
  <summary>Details</summary>
Motivation: 多语言语言模型有时表现不如单语模型，可能是由于模型容量限制。研究旨在量化这种"多语言惩罚"现象，特别是在需要精确语义表示和上下文机制的词汇消歧任务上。

Method: 使用英语和西班牙语中歧义词的人类相关性判断数据集，比较同一模型家族的单语和多语言模型。探索三种潜在能力限制：表征能力（嵌入各向同性降低）、注意力机制（对消歧线索的关注减少）和词汇相关（多标记分割增加）。

Result: 多语言模型在所有比较中都表现一致下降。研究发现多语言模型确实存在所有三种能力限制，这些因素在统计上解释了原本归因于模型多语言状态的性能差异。

Conclusion: 多语言语言模型确实受到多种能力限制，这些限制与消歧性能下降相关。研究结果为理解多语言模型的局限性提供了实证基础。

Abstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty'' for lexical disambiguation--a task requiring precise semantic representations and contextualization mechanisms--using controlled datasets of human relatedness judgments for ambiguous words in both English and Spanish. Comparing monolingual and multilingual LMs from the same families, we find consistently reduced performance in multilingual LMs. We then explore three potential capacity constraints: representational (reduced embedding isotropy), attentional (reduced attention to disambiguating cues), and vocabulary-related (increased multi-token segmentation). Multilingual LMs show some evidence of all three limitations; moreover, these factors statistically account for the variance formerly attributed to a model's multilingual status. These findings suggest both that multilingual LMs do suffer from multiple capacity constraints, and that these constraints correlate with reduced disambiguation performance.

</details>


### [4] [Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories](https://arxiv.org/abs/2602.05085)
*Sidi Lu,Zhenwen Liang,Dongyang Ma,Yan Wang,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: Locas是一种局部支持的参数化记忆机制，可灵活卸载或合并到模型参数中，支持高效持续学习，仅需少量额外参数即可存储历史上下文信息。


<details>
  <summary>Details</summary>
Motivation: 将测试时训练与新型参数化记忆相结合，这种记忆可以灵活地从模型参数中卸载或合并，旨在实现高效的持续学习，同时减少灾难性遗忘。

Method: 提出Locas（局部支持参数化记忆），采用与Transformer中FFN块相似的设计，有两种变体：传统两层MLP设计（理论保证更清晰）和与SOTA LLMs相同的GLU-FFN结构。关键是通过重用模型参数、激活和/或梯度来正确初始化这种低秩侧向FFN式记忆。

Result: 在PG-19整书语言建模和LoCoMo长上下文对话问答任务上验证。Locas-GLU仅需0.02%额外参数即可存储历史上下文信息，同时保持较小的上下文窗口。MMLU评估显示Locas能够将过去上下文永久化为参数知识，同时最小化模型现有内部知识的灾难性遗忘。

Conclusion: Locas展示了将过去上下文永久化为参数知识的有前景能力，同时最小化灾难性遗忘，为参数高效和计算高效的持续学习提供了有效解决方案。

Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.

</details>


### [5] [Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models](https://arxiv.org/abs/2602.05106)
*Michael Browder,Kevin Duh,J. David Harris,Vince Lyzinski,Paul McNamee,Youngser Park,Carey E. Priebe,Peter Viechnicki*

Main category: cs.CL

TL;DR: 该论文提出数据核视角空间(DKPS)方法，为Transformer模型的输出质量提供数学分析和统计保证，解决合成数据生成中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 标记训练数据的稀缺是构建高性能语言技术和生成式AI模型的主要瓶颈。虽然Transformer模型（特别是LLMs）被用于生成合成数据来缓解这一问题，但由于模型是黑盒，合成数据的属性难以预测，工程师通常只能通过调整温度参数来尝试改进下游模型性能，缺乏理论保证。

Method: 提出数据核视角空间(DKPS)方法，首先展示DKPS的数学推导过程，说明其如何为Transformer模型输出提供性能保证。然后将DKPS的性能保证应用于下游任务分析，如神经机器翻译模型或使用对比偏好优化(CPO)训练的LLMs。

Result: 论文展示了DKPS如何为Transformer模型的输出质量提供具体的统计保证，并阐明这些保证如何影响下游任务（如机器翻译和CPO训练的LLMs）的性能。但当前工作存在局限性，需要未来研究进一步探索。

Conclusion: DKPS为Transformer模型的合成数据生成提供了数学分析基础，能够提供具体的统计质量保证，减少工程师在调整模型参数时的盲目性。虽然当前工作有局限性，但为未来研究奠定了基础。

Abstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via synthetic data generation. However, because the models are black boxes, the properties of the synthetic data are difficult to predict. In practice it is common for language technology engineers to 'fiddle' with the LLM temperature setting and hope that what comes out the other end improves the downstream model. Faced with this uncertainty, here we propose Data Kernel Perspective Space (DKPS) to provide the foundation for mathematical analysis yielding concrete statistical guarantees for the quality of the outputs of transformer models. We first show the mathematical derivation of DKPS and how it provides performance guarantees. Next we show how DKPS performance guarantees can elucidate performance of a downstream task, such as neural machine translation models or LLMs trained using Contrastive Preference Optimization (CPO). Limitations of the current work and future research are also discussed.

</details>


### [6] [Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text](https://arxiv.org/abs/2602.05107)
*Ahmed Ruby,Christian Hardmeier,Sara Stymne*

Main category: cs.CL

TL;DR: 提出一种跨语言多模态方法，通过Qwen2-Audio整合文本和音频信息进行隐式篇章关系分类，在英语、法语和西班牙语上验证了多模态融合和跨语言迁移的有效性。


<details>
  <summary>Details</summary>
Motivation: 隐式篇章关系分类具有挑战性，因为需要从上下文中推断含义。上下文线索可能分布在多模态中，且在不同语言间存在差异，仅靠文本无法完全捕捉这些信息。

Method: 1) 提出自动方法构建英语、法语和西班牙语的多语言多模态数据集；2) 提出多模态方法，通过Qwen2-Audio整合文本和声学信息，实现跨语言隐式篇章关系分类的联合建模。

Result: 1) 基于文本的模型优于基于音频的模型；2) 整合两种模态可以提升性能；3) 跨语言迁移能为低资源语言带来显著改进。

Conclusion: 多模态融合和跨语言迁移是提升隐式篇章关系分类性能的有效策略，特别是在资源有限的语言中。

Abstract: Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To address this, we introduce an automatic method for distantly related and unrelated language pairs to construct a multilingual and multimodal dataset for implicit discourse relations in English, French, and Spanish. For classification, we propose a multimodal approach that integrates textual and acoustic information through Qwen2-Audio, allowing joint modeling of text and audio for implicit discourse relation classification across languages. We find that while text-based models outperform audio-based models, integrating both modalities can enhance performance, and cross-lingual transfer can provide substantial improvements for low-resource languages.

</details>


### [7] [GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek](https://arxiv.org/abs/2602.05150)
*Yang Zhang,Mersin Konomi,Christos Xypolopoulos,Konstantinos Divriotis,Konstantinos Skianis,Giannis Nikolentzos,Giorgos Stamou,Guokan Shang,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 希腊MMLU：首个基于希腊本土内容的希腊语大规模多任务语言理解基准，包含21,805道选择题，覆盖45个学科领域，用于评估LLMs在希腊语上的真实能力。


<details>
  <summary>Details</summary>
Motivation: 目前希腊语评估基准有限，现有数据集多为英语机器翻译，无法捕捉希腊语言文化特性。需要基于真实本土内容的可靠评估工具来衡量LLMs在希腊语上的实际能力。

Method: 创建希腊MMLU基准：收集或编写21,805道希腊语选择题，涵盖45个学科领域，采用新定义的主题分类法，标注教育难度等级（从小学到专业考试）。所有问题均来自希腊学术、专业和政府考试。公开发布16,857个样本，保留4,948个样本用于私有排行榜。

Result: 评估80多个开源和闭源LLMs发现：前沿模型与开源模型之间存在显著性能差距；希腊语适应模型与通用多语言模型之间也存在明显差异。提供了影响性能因素的系统分析（模型规模、适应策略、提示方法等）。

Conclusion: 希腊MMLU为希腊语LLM评估提供了可靠基准，揭示了当前模型在希腊语能力上的局限性，并为提升LLMs在希腊语上的性能提供了实用见解。

Abstract: Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machine-translated from English, failing to capture Greek linguistic and cultural characteristics. We introduce GreekMMLU, a native-sourced benchmark for massive multitask language understanding in Greek, comprising 21,805 multiple-choice questions across 45 subject areas, organized under a newly defined subject taxonomy and annotated with educational difficulty levels spanning primary to professional examinations. All questions are sourced or authored in Greek from academic, professional, and governmental exams. We publicly release 16,857 samples and reserve 4,948 samples for a private leaderboard to enable robust and contamination-resistant evaluation. Evaluations of over 80 open- and closed-source LLMs reveal substantial performance gaps between frontier and open-weight models, as well as between Greek-adapted models and general multilingual ones. Finally, we provide a systematic analysis of factors influencing performance-including model scale, adaptation, and prompting-and derive insights for improving LLM capabilities in Greek.

</details>


### [8] [Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems](https://arxiv.org/abs/2602.05176)
*Ziyuan Yang,Wenxuan Ding,Shangbin Feng,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: 该论文研究多语言模型协作系统中的安全风险，量化恶意模型对系统性能的影响，并提出使用外部监督器来缓解这些风险。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在多方协作中越来越普遍，存在关键的安全风险：如果多LLM系统中的某些模型被破坏或恶意，会对整个系统造成什么影响？

Method: 1. 构建四类恶意语言模型；2. 将恶意模型插入四种流行的模型协作系统；3. 在10个数据集上评估受损系统；4. 提出使用外部监督器来监控模型协作，禁用/屏蔽恶意模型以减少其影响。

Result: 恶意模型对多LLM系统有严重影响，特别是在推理和安全领域，性能平均下降7.12%和7.94%。提出的缓解策略平均能恢复95.31%的初始性能。

Conclusion: 恶意模型对多LLM协作系统构成严重威胁，虽然提出的缓解策略能显著恢复性能，但使模型协作系统完全抵抗恶意模型仍然是一个开放的研究问题。

Abstract: Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what if some of the models in multi-LLM systems are compromised or malicious? We first quantify the impact of malicious models by engineering four categories of malicious LMs, plug them into four types of popular model collaboration systems, and evaluate the compromised system across 10 datasets. We find that malicious models have a severe impact on the multi-LLM systems, especially for reasoning and safety domains where performance is lowered by 7.12% and 7.94% on average. We then propose mitigation strategies to alleviate the impact of malicious components, by employing external supervisors that oversee model collaboration to disable/mask them out to reduce their influence. On average, these strategies recover 95.31% of the initial performance, while making model collaboration systems fully resistant to malicious models remains an open research question.

</details>


### [9] [The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems](https://arxiv.org/abs/2602.05182)
*Shangbin Feng,Kishan Panaganti,Yulia Tsvetkov,Wenhao Yu*

Main category: cs.CL

TL;DR: 通过将多模型协作模式蒸馏到单个模型中，实现协作优势与单模型效率的平衡，并提出单-多进化循环实现模型集体进化


<details>
  <summary>Details</summary>
Motivation: 多语言模型协作系统结合了不同模型的优势，但需要加载多个模型导致成本高昂。需要在保持协作优势的同时提高效率。

Method: 1) 协作蒸馏：将多模型协作系统的输出作为训练数据，蒸馏到单个模型中；2) 单-多进化循环：多个模型协作→各自从协作输出中蒸馏→蒸馏改进后的模型再次协作，形成集体进化生态系统

Result: 1) 单个模型平均提升8.0%，吸收了协作优势同时成本降至单模型；2) 协作系统从蒸馏后更强、更协同的模型中获益，相比初始系统平均提升14.9%；3) 在7种协作策略和15个任务上验证有效性

Conclusion: 提出的协作蒸馏和单-多进化循环方法有效平衡了协作优势与效率，实现了模型的集体进化，优于现有进化AI方法，兼容多种设置，能解决初始模型/系统难以处理的问题

Abstract: Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collaborative patterns into a single model, where the model is trained on the outputs of the model collaboration system. At inference time, only the distilled model is employed: it imitates the collaboration while only incurring the cost of a single model. Furthermore, we propose the single-multi evolution loop: multiple LMs collaborate, each distills from the collaborative outputs, and these post-distillation improved LMs collaborate again, forming a collective evolution ecosystem where models evolve and self-improve by interacting with an environment of other models. Extensive experiments with 7 collaboration strategies and 15 tasks (QA, reasoning, factuality, etc.) demonstrate that: 1) individual models improve by 8.0% on average, absorbing the strengths of collaboration while reducing the cost to a single model; 2) the collaboration also benefits from the stronger and more synergistic LMs after distillation, improving over initial systems without evolution by 14.9% on average. Analysis reveals that the single-multi evolution loop outperforms various existing evolutionary AI methods, is compatible with diverse model/collaboration/distillation settings, and helps solve problems where the initial model/system struggles to.

</details>


### [10] [Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky](https://arxiv.org/abs/2602.05189)
*Hsuan-Yu Chou,Wajiha Naveed,Shuyan Zhou,Xiaowei Yang*

Main category: cs.CL

TL;DR: 开源大语言模型在有害内容检测方面与专有模型表现相当，可用于保护隐私的本地化内容审核


<details>
  <summary>Details</summary>
Motivation: 随着互联网访问扩大，有害内容暴露增加，需要有效的内容审核。虽然专有LLMs在社交媒体审核任务中表现出色，但开源LLMs的即用能力仍不明确，需要评估其在真实场景中的表现。

Method: 评估了7个最先进的LLMs（4个专有模型和3个开源模型），使用Bluesky的真实帖子、Bluesky审核服务的决策以及两位作者的标注进行测试。分析了模型在敏感性、特异性方面的表现，并考察了人类审核员与LLMs之间的一致性。

Result: 开源LLMs的敏感性（81%-97%）和特异性（91%-100%）与专有模型（72%-98%和93%-99%）有相当程度的重叠。在粗鲁内容检测中特异性超过敏感性，但在不宽容和威胁检测中则相反。发现了人类审核员与LLMs之间的评分一致性。

Conclusion: 开源LLMs能够在消费级硬件上支持保护隐私的内容审核，为设计平衡社区价值观与个人用户偏好的审核系统提供了新方向。

Abstract: As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful content detection. While proprietary LLMs have been shown to zero-shot outperform traditional machine learning models, the out-of-the-box capability of open-weight LLMs remains an open question.
  Motivated by recent developments of reasoning LLMs, we evaluate seven state-of-the-art models: four proprietary and three open-weight. Testing with real-world posts on Bluesky, moderation decisions by Bluesky Moderation Service, and annotations by two authors, we find a considerable degree of overlap between the sensitivity (81%--97%) and specificity (91%--100%) of the open-weight LLMs and those (72%--98%, and 93%--99%) of the proprietary ones. Additionally, our analysis reveals that specificity exceeds sensitivity for rudeness detection, but the opposite holds for intolerance and threats. Lastly, we identify inter-rater agreement across human moderators and the LLMs, highlighting considerations for deploying LLMs in both platform-scale and personalized moderation contexts. These findings show open-weight LLMs can support privacy-preserving moderation on consumer-grade hardware and suggest new directions for designing moderation systems that balance community values with individual user preferences.

</details>


### [11] [Aligning Large Language Model Behavior with Human Citation Preferences](https://arxiv.org/abs/2602.05205)
*Kenichiro Ando,Tatsuya Harada*

Main category: cs.CL

TL;DR: 研究探索LLM的引用行为与人类偏好的对齐程度，发现模型在需要引用的文本上过度引用27%，而在数字和人名等人类需要引用的内容上引用不足22-20%，通过DPO可以校准模型行为。


<details>
  <summary>Details</summary>
Motivation: 当前LLM服务普遍添加引用来增强可信度，但LLM如何识别值得引用的内容以及如何控制这一过程尚未充分探索。研究关注LLM当前的引用倾向与人类偏好的对齐程度。

Method: 构建数据集分析人类引用偏好与LLM行为的关系。将网络文本分为8种引用动机类型，对所有类型组合进行成对引用偏好评估。使用Direct Preference Optimization校准模型行为。

Result: 人类最常为医学文本寻求引用，更强模型显示类似倾向。当前模型比人类多27%可能在明确需要引用的文本上添加引用，但在数字句子（-22.6%）和含人名句子（-20.1%）上引用不足。DPO实验表明模型行为可校准以更好匹配人类偏好。

Conclusion: LLM的引用行为与人类偏好存在系统性偏差，模型在需要引用的内容上过度引用，而在人类通常要求引用的内容上引用不足。通过DPO等技术可以校准模型行为，为更细粒度研究LLM引用偏好奠定基础。

Abstract: Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process should be controlled remains underexplored. In this study, we focus on what kinds of content LLMs currently tend to cite and how well that behavior aligns with human preferences. We construct a dataset to characterize the relationship between human citation preferences and LLM behavior. Web-derived texts are categorized into eight citation-motivation types, and pairwise citation preferences are exhaustively evaluated across all type combinations to capture fine-grained contrasts. Our results show that humans most frequently seek citations for medical text, and stronger models display a similar tendency. We also find that current models are as much as $27\%$ more likely than humans to add citations to text that is explicitly marked as needing citations on sources such as Wikipedia, and this overemphasis reduces alignment accuracy. Conversely, models systematically underselect numeric sentences (by $-22.6\%$ relative to humans) and sentences containing personal names (by $-20.1\%$), categories for which humans typically demand citations. Furthermore, experiments with Direct Preference Optimization demonstrate that model behavior can be calibrated to better match human citation preferences. We expect this study to provide a foundation for more fine-grained investigations into LLM citation preferences.

</details>


### [12] [Quantifying the Knowledge Proximity Between Academic and Industry Research: An Entity and Semantic Perspective](https://arxiv.org/abs/2602.05211)
*Hongye Zhao,Yi Zhao,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 该研究通过细粒度知识实体和语义空间量化了学术界与工业界的协同演化轨迹，发现两者知识邻近性在技术变革后上升，且学术界在技术范式转变期间的知识主导地位减弱。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖合作论文或专利数量等宏观指标，缺乏对文献中知识单元的分析，导致对学术界与工业界之间细粒度知识邻近性的把握不足，可能影响合作框架和资源配置效率。

Method: 1. 实体测量：使用预训练模型提取细粒度知识实体，通过余弦相似度测量序列重叠，通过复杂网络分析拓扑特征；2. 语义层面：使用无监督对比学习量化语义空间收敛，测量跨机构文本相似性；3. 使用引用分布模式分析双向知识流与相似性的相关性。

Result: 分析显示学术界与工业界之间的知识邻近性上升，特别是在技术变革之后，这为协同演化中的双向适应提供了文本证据。此外，在技术范式转变期间，学术界知识主导地位减弱。

Conclusion: 该研究通过细粒度方法揭示了学术界与工业界协同演化的动态特征，为理解两者关系提供了新的分析框架，数据与代码已开源。

Abstract: The academia and industry are characterized by a reciprocal shaping and dynamic feedback mechanism. Despite distinct institutional logics, they have adapted closely in collaborative publishing and talent mobility, demonstrating tension between institutional divergence and intensive collaboration. Existing studies on their knowledge proximity mainly rely on macro indicators such as the number of collaborative papers or patents, lacking an analysis of knowledge units in the literature. This has led to an insufficient grasp of fine-grained knowledge proximity between industry and academia, potentially undermining collaboration frameworks and resource allocation efficiency. To remedy the limitation, this study quantifies the trajectory of academia-industry co-evolution through fine-grained entities and semantic space. In the entity measurement part, we extract fine-grained knowledge entities via pre-trained models, measure sequence overlaps using cosine similarity, and analyze topological features through complex network analysis. At the semantic level, we employ unsupervised contrastive learning to quantify convergence in semantic spaces by measuring cross-institutional textual similarities. Finally, we use citation distribution patterns to examine correlations between bidirectional knowledge flows and similarity. Analysis reveals that knowledge proximity between academia and industry rises, particularly following technological change. This provides textual evidence of bidirectional adaptation in co-evolution. Additionally, academia's knowledge dominance weakens during technological paradigm shifts. The dataset and code for this paper can be accessed at https://github.com/tinierZhao/Academic-Industrial-associations.

</details>


### [13] [Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions](https://arxiv.org/abs/2602.05220)
*Jinchuan Tian,Haoran Wang,Bo-Hao Su,Chien-yu Huang,Qingzheng Wang,Jiatong Shi,William Chen,Xun Gong,Siddhant Arora,Chin-Jou Li,Masao Someki,Takashi Maekaku,Yusuke Shinohara,Jin Sakuma,Chao-Han Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: Bagpiper是一个80亿参数的音频基础模型，通过丰富的自然语言描述将原始音频映射到高级认知概念空间，实现统一的理解和生成能力，在音频理解和生成任务上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前音频基础模型通常依赖刚性、任务特定的监督，处理孤立的音频因素而非整体。相比之下，人类智能以整体方式处理音频，无缝连接物理信号与抽象认知概念以执行复杂任务。基于这一理念，需要开发能够统一理解和生成通用音频的模型。

Method: 1. 引入Bagpiper，一个80亿参数的音频基础模型；2. 通过丰富的自然语言描述（包含转录、音频事件等关键认知概念）解释物理音频；3. 在6000亿token的大规模语料库上进行预训练，建立原始音频与高级概念空间之间的稳健双向映射；4. 微调时采用"描述-处理"工作流程，模拟中间认知推理步骤来解决多样化任务，无需任务特定先验。

Result: 1. 在音频理解方面，Bagpiper在MMAU和AIRBench上优于Qwen-2.5-Omni；2. 在生成质量方面，超越CosyVoice3和TangoFlux，能够合成语音、音乐和音效的任意组合；3. 据作者所知，这是首批实现通用音频统一理解和生成的工作之一。

Conclusion: Bagpiper通过将原始音频映射到丰富的自然语言描述空间，实现了对通用音频的统一理解和生成能力，展示了音频处理的新范式。模型、数据和代码已公开。

Abstract: Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.

</details>


### [14] [FedMosaic: Federated Retrieval-Augmented Generation via Parametric Adapters](https://arxiv.org/abs/2602.05235)
*Zhilin Liang,Yuxiang Wang,Zimu Zhou,Hainan Zhang,Boyi Liu,Yongxin Tong*

Main category: cs.CL

TL;DR: FedMosaic：首个基于参数化适配器的联邦RAG框架，通过语义聚类和多文档适配器降低存储通信开销，选择性聚合避免冲突，实现隐私保护下的高效知识检索


<details>
  <summary>Details</summary>
Motivation: 传统RAG假设集中式知识库，但在隐私敏感领域知识分散在孤岛中无法共享。联邦RAG需要在保护原始文档隐私的前提下，让中央LLM服务器与分布式知识孤岛协作

Method: 采用参数化RAG方法，将文档编码为轻量适配器。提出FedMosaic框架：1）将语义相关文档聚类为多文档适配器，使用文档特定掩码保持特异性；2）选择性聚合适配器，只合并相关性对齐且无冲突的适配器

Result: 在四个类别中平均准确率比SOTA方法高10.9%，存储成本降低78.8%-86.3%，通信成本降低91.4%，且从不共享原始文档

Conclusion: FedMosaic成功解决了联邦RAG中的存储通信开销和破坏性聚合问题，实现了隐私保护下的高效知识检索增强，为分布式知识孤岛场景提供了可行解决方案

Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by grounding generation in external knowledge to improve factuality and reduce hallucinations. Yet most deployments assume a centralized corpus, which is infeasible in privacy aware domains where knowledge remains siloed. This motivates federated RAG (FedRAG), where a central LLM server collaborates with distributed silos without sharing raw documents. In context RAG violates this requirement by transmitting verbatim documents, whereas parametric RAG encodes documents into lightweight adapters that merge with a frozen LLM at inference, avoiding raw-text exchange. We adopt the parametric approach but face two unique challenges induced by FedRAG: high storage and communication from per-document adapters, and destructive aggregation caused by indiscriminately merging multiple adapters. We present FedMosaic, the first federated RAG framework built on parametric adapters. FedMosaic clusters semantically related documents into multi-document adapters with document-specific masks to reduce overhead while preserving specificity, and performs selective adapter aggregation to combine only relevance-aligned, nonconflicting adapters. Experiments show that FedMosaic achieves an average 10.9% higher accuracy than state-of-the-art methods in four categories, while lowering storage costs by 78.8% to 86.3% and communication costs by 91.4%, and never sharing raw documents.

</details>


### [15] [Copyright Detective: A Forensic System to Evidence LLMs Flickering Copyright Leakage Risks](https://arxiv.org/abs/2602.05252)
*Guangwei Zhang,Jianing Zhu,Cheng Qian,Neil Gong,Rada Mihalcea,Zhaozhuo Xu,Jingrui He,Jiaqi Ma,Yun Huang,Chaowei Xiao,Bo Li,Ahmed Abbasi,Dongwon Lee,Heng Ji,Denghui Zhang*

Main category: cs.CL

TL;DR: 首个交互式取证系统，用于检测、分析和可视化LLM输出中的潜在版权风险，将侵权检测视为证据发现过程而非静态分类任务


<details>
  <summary>Details</summary>
Motivation: 由于版权法的复杂性，需要开发一个系统来系统性地审计LLM输出中的版权风险，支持负责任部署和透明评估

Method: 集成多种检测范式：内容召回测试、改写级相似性分析、说服性越狱探测和反学习验证，在统一可扩展框架中通过交互式提示、响应收集和迭代工作流实现

Result: 开发了首个交互式取证系统，能够系统性地审计逐字记忆和改写级泄露，即使在黑盒访问条件下也能支持LLM版权风险的透明评估

Conclusion: Copyright Detective为LLM版权风险检测提供了创新的证据发现方法，支持负责任部署和透明评估，填补了该领域的技术空白

Abstract: We present Copyright Detective, the first interactive forensic system for detecting, analyzing, and visualizing potential copyright risks in LLM outputs. The system treats copyright infringement versus compliance as an evidence discovery process rather than a static classification task due to the complex nature of copyright law. It integrates multiple detection paradigms, including content recall testing, paraphrase-level similarity analysis, persuasive jailbreak probing, and unlearning verification, within a unified and extensible framework. Through interactive prompting, response collection, and iterative workflows, our system enables systematic auditing of verbatim memorization and paraphrase-level leakage, supporting responsible deployment and transparent evaluation of LLM copyright risks even with black-box access.

</details>


### [16] [CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs](https://arxiv.org/abs/2602.05258)
*Haoran Li,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CL

TL;DR: CoPE通过软截断RoPE的低频分量，统一了OOD缓解和语义建模两种目标，在长上下文扩展中取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 当前RoPE适应长上下文的方法主要分为两类：OOD缓解（调整频率以适应未见位置）和语义建模（注意力分数应优先语义相似token）。这两种看似不同的目标需要统一的理论框架。

Method: 提出CoPE方法：对RoPE的低频分量进行软截断。这种方法不仅消除OOD异常值、优化语义信号，还能防止硬截断引起的频谱泄漏。

Result: 实验表明，将软截断策略应用于RoPE能带来显著的性能提升，可扩展到256k上下文长度，验证了理论分析并建立了新的SOTA长度泛化方法。

Conclusion: CoPE通过简单的软截断干预，统一了OOD缓解和语义建模两种目标，为长上下文扩展提供了有效且理论完备的解决方案。

Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.

</details>


### [17] [Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR](https://arxiv.org/abs/2602.05261)
*Fanfan Liu,Youyang Yin,Peng Shi,Siqi Yang,Zhixiong Zeng,Haibo Qiu*

Main category: cs.CL

TL;DR: 本文分析了RLVR算法中响应长度变化的原因，提出了消除长度偏差的LUSPO算法，在数学推理和多模态推理任务中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: RLVR训练中响应长度增长通常被视为推理能力提升的关键因素，但不同RLVR算法的响应长度变化模式差异显著，需要理论解释这些差异的根本原因。

Method: 深入分析主流RLVR算法组件，理论分析影响响应长度的因素，提出长度无偏序列策略优化(LUSPO)算法，修正GSPO中的长度偏差，使其损失函数对响应长度无偏。

Result: 在数学推理基准和多模态推理场景中，LUSPO始终取得优越性能，解决了响应长度崩溃问题，相比GRPO和GSPO等现有方法达到了新的SOTA水平。

Conclusion: LUSPO是一种新颖的、最先进的优化策略，通过理论分析和实验验证，成功解决了RLVR算法中的长度偏差问题，提升了复杂任务的推理能力。

Abstract: Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.

</details>


### [18] [Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science](https://arxiv.org/abs/2602.05289)
*Jingru Fan,Dewen Liu,Yufan Dang,Huatao Li,Yuheng Wang,Wei Liu,Feiyu Duan,Xuanwen Ding,Shu Yao,Lin Wu,Ruijie Shi,Wai-Shing Leung,Yuan Cheng,Zhongyu Wei,Cheng Yang,Chen Qian,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 论文提出一个集成框架，将多智能体系统研究从经验试错转向设计科学，引入协作增益指标Γ来区分内在增益与资源积累，并建立系统化的因素库和归因范式。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型显著提升了多智能体系统的能力，但该领域仍严重依赖经验试错，缺乏统一的科学框架进行系统优化和改进。主要瓶颈在于归因模糊性：缺乏结构化因素分类法导致研究人员只能进行无指导的调整；缺乏统一指标无法区分真正的协作增益与单纯的资源积累。

Method: 提出集成框架，建立协作增益指标Γ作为科学标准来隔离内在增益与预算增加的影响。利用Γ提出因素归因范式，系统识别驱动协作的因素。构建系统化的MAS因素库，将设计空间结构化为控制级预设和信息级动态。

Result: 框架为多智能体系统研究提供了从盲目实验到严谨科学的转变路径，建立了协作增益的量化标准和系统化的因素分析体系。

Conclusion: 该框架促进了多智能体系统研究向设计科学的转型，为实现真正的集体人工智能科学铺平了道路，使该领域能够从经验试错转向系统化、可复现的科学探索。

Abstract: Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical trial-and-error. It lacks a unified and principled scientific framework necessary for systematic optimization and improvement. This bottleneck stems from the ambiguity of attribution: first, the absence of a structured taxonomy of factors leaves researchers restricted to unguided adjustments; second, the lack of a unified metric fails to distinguish genuine collaboration gain from mere resource accumulation. In this paper, we advocate for a transition to design science through an integrated framework. We advocate to establish the collaboration gain metric ($Γ$) as the scientific standard to isolate intrinsic gains from increased budgets. Leveraging $Γ$, we propose a factor attribution paradigm to systematically identify collaboration-driving factors. To support this, we construct a systematic MAS factor library, structuring the design space into control-level presets and information-level dynamics. Ultimately, this framework facilitates the transition from blind experimentation to rigorous science, paving the way towards a true science of Collective AI.

</details>


### [19] [MentorCollab: Selective Large-to-Small Inference-Time Guidance for Efficient Reasoning](https://arxiv.org/abs/2602.05307)
*Haojin Wang,Yike Wang,Shangbin Feng,Hannaneh Hajishirzi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: MentorCollab：一种推理时协作方法，让大型推理模型选择性、稀疏地指导小型语言模型，通过轻量验证器在关键分歧点决定是否采用导师的短前瞻片段，显著提升性能同时大幅降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型性能强但推理成本高且常生成冗余推理，小型语言模型效率高但在多步推理任务上表现不佳。现有协作方法往往导致模仿和冗长推理，缺乏一致的错误纠正。

Method: 提出MentorCollab方法：在随机采样的token位置探测两个模型的分歧，使用轻量验证器决定小型模型是应该跟随导师的短前瞻片段还是继续自主生成。实现选择性、稀疏的指导而非接管生成。

Result: 在15个SLM-LRM组合和3个领域（数学推理、通用知识、常识推理）中，12个设置性能提升，平均增益3.0%，最高达8.0%，同时平均只有18.4%的token由昂贵的大型模型生成。

Conclusion: 短片段和选择性探测足以实现有效协作，选择性推理时指导能够恢复大型模型的推理能力而无需大量推理开销，为高效推理协作提供了新思路。

Abstract: Large reasoning models (LRMs) achieve strong performance by producing long chains of thought, but their inference costs are high and often generate redundant reasoning. Small language models (SLMs) are far more efficient, yet struggle on multi-step reasoning tasks. A natural idea is to let a large model guide a small one at inference time as a mentor, yet existing collaboration methods often promote imitation, resulting in verbose reasoning without consistent error correction. We propose MentorCollab, an inference-time collaboration method in which an LRM selectively and sparsely guides an SLM, rather than taking over generation. At randomly sampled token positions, we probe for divergences between the two models and use a lightweight verifier to decide whether the SLM should follow a short lookahead segment from its mentor or continue on its own. Across 15 SLM--LRM pairs and 3 domains (math reasoning, general knowledge, and commonsense reasoning), our method improves performance in 12 settings, with average gains of 3.0% and up to 8.0%, while adopting only having 18.4% tokens generated by the expensive mentor model on average. We find that short segments and selective probing are sufficient for effective collaboration. Our results show that selective inference-time guidance restores large-model reasoning ability without substantial inference overhead.

</details>


### [20] [How Do Language Models Acquire Character-Level Information?](https://arxiv.org/abs/2602.05347)
*Soma Sato,Ryohei Sasano*

Main category: cs.CL

TL;DR: 研究发现语言模型通过合并规则、正字法约束、语义关联和句法信息四种机制隐式编码字符级知识，其中前两者源于分词过程，后两者独立于分词


<details>
  <summary>Details</summary>
Motivation: 语言模型被报道能够隐式编码字符级信息，尽管训练时并未明确提供。然而这种现象背后的机制尚未得到充分探索，需要揭示模型如何获取字符级知识

Method: 通过比较在受控设置下训练的语言模型（如指定预训练数据集或分词器）与标准设置下训练的模型，分析模型如何获取字符级知识，并将贡献因素分为与分词相关和独立于分词两类

Result: 分析发现合并规则和正字法约束是源于分词过程的主要因素，而子串的语义关联和句法信息则是独立于分词的关键因素

Conclusion: 语言模型通过多种机制隐式编码字符级信息，这些机制既包括分词过程相关的因素，也包括独立于分词的语言知识，为理解模型内部表示提供了新视角

Abstract: Language models (LMs) have been reported to implicitly encode character-level information, despite not being explicitly provided during training. However, the mechanisms underlying this phenomenon remain largely unexplored. To reveal the mechanisms, we analyze how models acquire character-level knowledge by comparing LMs trained under controlled settings, such as specifying the pre-training dataset or tokenizer, with those trained under standard settings. We categorize the contributing factors into those independent of tokenization. Our analysis reveals that merge rules and orthographic constraints constitute primary factors arising from tokenization, whereas semantic associations of substrings and syntactic information function as key factors independent of tokenization.

</details>


### [21] [PACE: Defying the Scaling Hypothesis of Exploration in Iterative Alignment for Mathematical Reasoning](https://arxiv.org/abs/2602.05370)
*Jun Rao,Zixiong Yu,Xuebo Liu,Guhan Chen,Jing Li,Jiansheng Wei,Xiaojun Meng,Min Zhang*

Main category: cs.CL

TL;DR: PACE方法通过生成式纠正策略替代暴力采样，在极小计算预算下超越标准DPO-R1，解决数学推理中探索过度导致的性能下降问题


<details>
  <summary>Details</summary>
Motivation: 挑战迭代直接偏好优化中的扩展假设，发现在数学推理任务中，过度探索（如Best-of-N采样中N过大）反而会导致性能下降甚至策略崩溃，需要更高效的探索策略

Method: 提出PACE（Proximal Alignment via Corrective Exploration），用生成式纠正策略替代暴力采样，在极小计算预算（2<N<3）下从失败的探索中合成高质量偏好对

Result: PACE在性能上超越DPO-R1（N=16），同时仅使用约1/5的计算资源，展现出对奖励攻击和标签噪声更强的鲁棒性

Conclusion: 在数学推理任务中，探索质量比数量更重要，PACE通过高效的纠正策略实现了更好的对齐效果和计算效率

Abstract: Iterative Direct Preference Optimization has emerged as the state-of-the-art paradigm for aligning Large Language Models on reasoning tasks. Standard implementations (DPO-R1) rely on Best-of-N sampling (e.g., $N \ge 8$) to mine golden trajectories from the distribution tail. In this paper, we challenge this scaling hypothesis and reveal a counter-intuitive phenomenon: in mathematical reasoning, aggressive exploration yields diminishing returns and even catastrophic policy collapse. We theoretically demonstrate that scaling $N$ amplifies verifier noise and induces detrimental distribution shifts. To resolve this, we introduce \textbf{PACE} (Proximal Alignment via Corrective Exploration), which replaces brute-force mining with a generation-based corrective strategy. Operating with a minimal budget ($2<N<3$), PACE synthesizes high-fidelity preference pairs from failed explorations. Empirical evaluations show that PACE outperforms DPO-R1 $(N=16)$ while using only about $1/5$ of the compute, demonstrating superior robustness against reward hacking and label noise.

</details>


### [22] [Cross-Lingual Empirical Evaluation of Large Language Models for Arabic Medical Tasks](https://arxiv.org/abs/2602.05374)
*Chaimae Abouzahir,Congbo Ma,Nizar Habash,Farah E. Shamout*

Main category: cs.CL

TL;DR: LLMs在医学应用中存在语言性能差距，阿拉伯语与英语相比性能显著下降，且任务越复杂差距越大，需要语言感知的设计策略。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在医学应用中多为英语中心，对多语言社区的可信度和鲁棒性有限。虽然已有研究指出低资源语言性能差异，但根本原因尚不清楚，需要深入分析语言驱动的性能差距。

Method: 对阿拉伯语和英语医学问答进行跨语言实证分析，包括性能评估、分词结构分析和可靠性分析（模型置信度与解释相关性）。

Result: 发现持续的语言驱动性能差距，且任务复杂度增加时差距加剧；阿拉伯语医学文本存在结构碎片化；模型报告的置信度和解释与正确性相关性有限。

Conclusion: 医学任务LLMs需要语言感知的设计和评估策略，以解决语言性能差距问题，提高对多语言社区的可靠性和鲁棒性。

Abstract: In recent years, Large Language Models (LLMs) have become widely used in medical applications, such as clinical decision support, medical education, and medical question answering. Yet, these models are often English-centric, limiting their robustness and reliability for linguistically diverse communities. Recent work has highlighted discrepancies in performance in low-resource languages for various medical tasks, but the underlying causes remain poorly understood. In this study, we conduct a cross-lingual empirical analysis of LLM performance on Arabic and English medical question and answering. Our findings reveal a persistent language-driven performance gap that intensifies with increasing task complexity. Tokenization analysis exposes structural fragmentation in Arabic medical text, while reliability analysis suggests that model-reported confidence and explanations exhibit limited correlation with correctness. Together, these findings underscore the need for language-aware design and evaluation strategies in LLMs for medical tasks.

</details>


### [23] [IESR:Efficient MCTS-Based Modular Reasoning for Text-to-SQL with Large Language Models](https://arxiv.org/abs/2602.05385)
*Tao Liu,Jiafan Lu,Bohan Yu,Pengcheng Wu,Liu Haixin,Guoyu Xu,Li Xiangheng,Lixiao Li,Jiaming Hou,Zhao Shijun,Xinglin Lyu,Kunli Zhang,Yuxiang Jia,Hongyin Zan*

Main category: cs.CL

TL;DR: IESR框架通过信息增强结构化推理，为轻量级大语言模型解决复杂Text-to-SQL任务，在LogicCat和Archer数据集上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL方法在复杂推理、领域知识、假设查询方面表现不佳，且企业部署成本高，需要更高效的解决方案

Method: 提出IESR框架：1) 利用LLM进行关键信息理解和模式链接，分离数学计算和SQL生成；2) 基于蒙特卡洛树搜索的多路径推理机制；3) 轨迹一致性验证模块确保准确性

Result: 在LogicCat基准上达到24.28 EX，Archer数据集上达到37.28 EX，仅使用轻量级模型无需微调即实现SOTA性能

Conclusion: IESR框架有效解决了复杂Text-to-SQL任务，同时发现当前编码器模型在物理知识、数学计算和常识推理方面存在明显偏差，为未来研究指明方向

Abstract: Text-to-SQL is a key natural language processing task that maps natural language questions to SQL queries, enabling intuitive interaction with web-based databases. Although current methods perform well on benchmarks like BIRD and Spider, they struggle with complex reasoning, domain knowledge, and hypothetical queries, and remain costly in enterprise deployment. To address these issues, we propose a framework named IESR(Information Enhanced Structured Reasoning) for lightweight large language models: (i) leverages LLMs for key information understanding and schema linking, and decoupling mathematical computation and SQL generation, (ii) integrates a multi-path reasoning mechanism based on Monte Carlo Tree Search (MCTS) with majority voting, and (iii) introduces a trajectory consistency verification module with a discriminator model to ensure accuracy and consistency. Experimental results demonstrate that IESR achieves state-of-the-art performance on the complex reasoning benchmark LogicCat (24.28 EX) and the Archer dataset (37.28 EX) using only compact lightweight models without fine-tuning. Furthermore, our analysis reveals that current coder models exhibit notable biases and deficiencies in physical knowledge, mathematical computation, and common-sense reasoning, highlighting important directions for future research. We released code at https://github.com/Ffunkytao/IESR-SLM.

</details>


### [24] [Beyond Length: Context-Aware Expansion and Independence as Developmentally Sensitive Evaluation in Child Utterances](https://arxiv.org/abs/2602.05392)
*Jiyun Chun,Eric Fosler-Lussier,Michael White,Andrew Perrault*

Main category: cs.CL

TL;DR: 提出LLM评估框架，从扩展性和独立性两个维度评估儿童话语质量，替代传统长度主导的指标


<details>
  <summary>Details</summary>
Motivation: 现有儿童话语质量评估指标（如MLU、词汇多样性、可读性指数）过于依赖长度且忽略对话上下文，无法捕捉推理深度、话题维持和话语规划等质量维度

Method: 引入LLM作为评估者的框架：首先分类成人前话语类型，然后从扩展性（上下文阐述和推理深度）和独立性（推动话语发展的贡献）两个轴对儿童回答进行评分

Result: 框架显示出与年龄相关的发展模式，在年龄估计上优于常见基线，能检测与话语关系相关的差异，且与人类判断一致

Conclusion: 该框架将儿童话语评估从简单测量长度转向评估儿童言语如何在上下文中有意义地贡献和推动对话，支持大规模评估

Abstract: Evaluating the quality of children's utterances in adult-child dialogue remains challenging due to insufficient context-sensitive metrics. Common proxies such as Mean Length of Utterance (MLU), lexical diversity (vocd-D), and readability indices (Flesch-Kincaid Grade Level, Gunning Fog Index) are dominated by length and ignore conversational context, missing aspects of response quality such as reasoning depth, topic maintenance, and discourse planning. We introduce an LLM-as-a-judge framework that first classifies the Previous Adult Utterance Type and then scores the child's response along two axes: Expansion (contextual elaboration and inferential depth) and Independence (the child's contribution to advancing the discourse). These axes reflect fundamental dimensions in child language development, where Expansion captures elaboration, clause combining, and causal and contrastive connectives. Independence captures initiative, topic control, decreasing reliance on adult scaffolding through growing self-regulation, and audience design. We establish developmental validity by showing age-related patterns and demonstrate predictive value by improving age estimation over common baselines. We further confirm semantic sensitivity by detecting differences tied to discourse relations. Our metrics align with human judgments, enabling large-scale evaluation. This shifts child utterance assessment from simply measuring length to evaluating how meaningfully the child's speech contributes to and advances the conversation within its context.

</details>


### [25] [Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better](https://arxiv.org/abs/2602.05393)
*Ji Zhao,Yufei Gu,Shitong Shao,Xun Zhou,Liang Xiang,Zeke Xie*

Main category: cs.CL

TL;DR: 提出Late-to-Early Training (LET)范式，利用小型预训练模型指导大型模型训练，实现1.6倍加速和5%下游任务精度提升


<details>
  <summary>Details</summary>
Motivation: 大语言模型预训练计算成本高昂，阻碍快速发展。现有大量预训练模型计算代价巨大，但如何利用小型预训练模型加速大型模型训练这一实际问题尚未充分探索

Method: 提出Late-to-Early Training (LET)范式，让LLM在早期训练阶段和早期层中显式学习后期知识。核心思想是使用预训练模型（后期训练阶段）的深层表示来指导目标模型浅层的早期训练。包含两个关键机制：后期到早期步骤学习和后期到早期层学习

Result: 在1.4B和7B参数模型上验证了LET的高效性和有效性。在Pile数据集上训练1.4B LLM时，相比标准训练实现了1.6倍加速，下游任务精度提升近5%，即使使用的预训练模型参数只有目标模型的1/10

Conclusion: LET范式能够显著加速训练收敛，同时鲁棒地提升语言建模能力和下游任务性能，实现更快训练和更优性能

Abstract: As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: \textit{Can we leverage existing small pretrained models to accelerate the training of larger models?} In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6$\times$ speedup with nearly 5\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10$\times$ fewer parameters than the target model.

</details>


### [26] [OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration](https://arxiv.org/abs/2602.05400)
*Shaobo Wang,Xuan Ouyang,Tianyi Xu,Yuzheng Hu,Jialin Liu,Guo Chen,Tianyu Zhang,Junhao Zheng,Kexin Yang,Xingzhang Ren,Dayiheng Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: OPUS是一个动态数据选择框架，通过优化器诱导的更新空间定义效用，显著提升预训练数据效率，在多种设置下超越工业级基线甚至完整训练。


<details>
  <summary>Details</summary>
Motivation: 随着高质量公共文本接近枯竭（数据墙现象），预训练正从更多token转向更好token。现有方法要么依赖忽略训练动态的启发式静态过滤器，要么使用基于原始梯度的动态但优化器无关的标准。

Method: OPUS在优化器诱导的更新空间中定义效用，通过将候选数据的有效更新投影到来自稳定、同分布代理的目标方向来评分。采用Ghost技术和CountSketch确保计算效率，使用Boltzmann采样保证数据多样性，仅增加4.7%计算开销。

Result: 在GPT-2 Large/XL的FineWeb和FineWeb-Edu 30B token预训练中，OPUS超越工业级基线甚至200B token完整训练。结合工业级静态过滤器后进一步改善预训练效率。在Qwen3-8B-Base的SciencePedia持续预训练中，仅用0.5B token就达到3B token完整训练的性能。

Conclusion: OPUS通过优化器感知的动态数据选择框架，在数据墙时代显著提升预训练效率，在通用和专用领域都表现出卓越的数据效率，为高质量数据稀缺下的模型训练提供了有效解决方案。

Abstract: As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.

</details>


### [27] [Grammatical Error Correction Evaluation by Optimally Transporting Edit Representation](https://arxiv.org/abs/2602.05419)
*Takumi Goto,Yusuke Sakai,Taro Watanabe*

Main category: cs.CL

TL;DR: 提出UOT-ERRANT指标，通过不平衡最优传输计算编辑向量相似度来改进语法错误纠正的自动评估


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌入的相似度度量（如BERTScore）在语法错误纠正评估中效果不佳，因为许多单词在源句、假设句和参考句中保持不变

Method: 提出编辑向量表示编辑操作，使用不平衡最优传输将假设句的编辑向量传输到参考句，计算相似度

Result: 在SEEDA元评估中表现优异，特别是在+Fluency领域，且具有高度可解释性

Conclusion: UOT-ERRANT是一个有效的语法错误纠正评估指标，既能用于系统排名，又能分析系统性能

Abstract: Automatic evaluation in grammatical error correction (GEC) is crucial for selecting the best-performing systems. Currently, reference-based metrics are a popular choice, which basically measure the similarity between hypothesis and reference sentences. However, similarity measures based on embeddings, such as BERTScore, are often ineffective, since many words in the source sentences remain unchanged in both the hypothesis and the reference. This study focuses on edits specifically designed for GEC, i.e., ERRANT, and computes similarity measured over the edits from the source sentence. To this end, we propose edit vector, a representation for an edit, and introduce a new metric, UOT-ERRANT, which transports these edit vectors from hypothesis to reference using unbalanced optimal transport. Experiments with SEEDA meta-evaluation show that UOT-ERRANT improves evaluation performance, particularly in the +Fluency domain where many edits occur. Moreover, our method is highly interpretable because the transport plan can be interpreted as a soft edit alignment, making UOT-ERRANT a useful metric for both system ranking and analyzing GEC systems. Our code is available from https://github.com/gotutiyan/uot-errant.

</details>


### [28] [Once Correct, Still Wrong: Counterfactual Hallucination in Multilingual Vision-Language Models](https://arxiv.org/abs/2602.05437)
*Basel Mousi,Fahim Dalvi,Shammur Chowdhury,Firoj Alam,Nadir Durrani*

Main category: cs.CL

TL;DR: M2CQA是一个针对中东和北非地区文化背景的多模态幻觉基准，通过对比真实与反事实陈述来评估VLMs的文化幻觉问题，提出CFHR指标衡量反事实接受率。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉基准很少测试VLMs在非西方语境和非英语环境中的文化幻觉问题，即模型可能接受文化上合理但视觉上错误的解释。

Method: 构建M2CQA基准，包含17个中东和北非国家的图像，配以英语、阿拉伯语及其方言的真实与反事实对比陈述。提出CFHR指标来衡量在正确回答真实陈述条件下的反事实接受率。

Result: 评估发现：1) 在阿拉伯语（特别是方言）中CFHR显著上升，即使真实陈述准确率保持高位；2) 推理优先的提示策略会增加反事实幻觉，而先回答后解释的策略能提高鲁棒性。

Conclusion: 需要开发更稳健的VLMs来处理文化多样性和多语言环境中的幻觉问题，M2CQA基准和CFHR指标为这一方向提供了重要工具。

Abstract: Vision-language models (VLMs) can achieve high accuracy while still accepting culturally plausible but visually incorrect interpretations. Existing hallucination benchmarks rarely test this failure mode, particularly outside Western contexts and English. We introduce M2CQA, a culturally grounded multimodal benchmark built from images spanning 17 MENA countries, paired with contrastive true and counterfactual statements in English, Arabic, and its dialects. To isolate hallucination beyond raw accuracy, we propose the CounterFactual Hallucination Rate (CFHR), which measures counterfactual acceptance conditioned on correctly answering the true statement. Evaluating state-of-the-art VLMs under multiple prompting strategies, we find that CFHR rises sharply in Arabic, especially in dialects, even when true-statement accuracy remains high. Moreover, reasoning-first prompting consistently increases counterfactual hallucination, while answering before justifying improves robustness. We will make the experimental resources and dataset publicly available for the community.

</details>


### [29] [Causal Front-Door Adjustment for Robust Jailbreak Attacks on LLMs](https://arxiv.org/abs/2602.05444)
*Yao Zhou,Zeen Song,Wenwen Qiang,Fengge Wu,Shuyi Zhou,Changwen Zheng,Hui Xiong*

Main category: cs.CL

TL;DR: 提出CFA²攻击框架，利用因果前门准则解除安全机制对LLM的混淆影响，实现高效越狱


<details>
  <summary>Details</summary>
Motivation: LLM中的安全对齐机制作为潜在内部状态，掩盖了模型的固有能力。从因果视角看，安全机制是未观测的混淆变量，阻碍了模型正常功能发挥。

Method: 将安全机制建模为未观测的混淆变量，采用Pearl前门准则切断混淆关联。使用稀疏自编码器物理剥离防御相关特征，分离核心任务意图。将计算昂贵的边缘化简化为确定性干预，降低推理复杂度。

Result: CFA²实现了最先进的攻击成功率，同时为越狱过程提供了机制性解释。

Conclusion: 通过因果前门调整框架，可以有效解除LLM安全对齐机制的混淆影响，实现高效越狱，并提供了对越狱过程的机制性理解。

Abstract: Safety alignment mechanisms in Large Language Models (LLMs) often operate as latent internal states, obscuring the model's inherent capabilities. Building on this observation, we model the safety mechanism as an unobserved confounder from a causal perspective. Then, we propose the \textbf{C}ausal \textbf{F}ront-Door \textbf{A}djustment \textbf{A}ttack ({\textbf{CFA}}$^2$) to jailbreak LLM, which is a framework that leverages Pearl's Front-Door Criterion to sever the confounding associations for robust jailbreaking. Specifically, we employ Sparse Autoencoders (SAEs) to physically strip defense-related features, isolating the core task intent. We further reduce computationally expensive marginalization to a deterministic intervention with low inference complexity. Experiments demonstrate that {CFA}$^2$ achieves state-of-the-art attack success rates while offering a mechanistic interpretation of the jailbreaking process.

</details>


### [30] [Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale](https://arxiv.org/abs/2602.05447)
*Damon McMillan*

Main category: cs.CL

TL;DR: 针对LLM代理在结构化数据上的上下文工程进行大规模实证研究，发现模型能力是主要影响因素，架构选择需根据模型类型定制，格式影响不大但开源模型有敏感性，文件原生代理可扩展到万表规模。


<details>
  <summary>Details</summary>
Motivation: LLM代理越来越多地通过编程接口操作外部系统，但实践中缺乏关于如何构建这些代理所消费上下文的实证指导。使用SQL生成为程序化代理操作的代理，研究结构化数据的上下文工程。

Method: 使用SQL生成作为程序化代理操作的代理，进行系统化研究：9,649个实验，涵盖11个模型、4种格式（YAML、Markdown、JSON、TOON），模式规模从10到10,000个表。

Result: 1) 架构选择模型依赖：文件式上下文检索提升前沿模型准确率(+2.7%)，但对开源模型效果不一(总体-7.7%)；2) 格式不影响总体准确率，但开源模型有格式敏感性；3) 模型能力是主导因素，前沿与开源模型有21个百分点差距；4) 文件原生代理可通过域分区模式扩展到10,000表；5) 文件大小不预测运行时效率，紧凑格式可能消耗更多token。

Conclusion: 为部署LLM代理到结构化系统提供基于证据的指导：架构决策应根据模型能力定制，而非假设通用最佳实践。模型能力是主要影响因素，格式影响有限但开源模型有敏感性，文件原生代理可扩展到大规模模式。

Abstract: Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables.
  Our findings challenge common assumptions. First, architecture choice is model-dependent: file-based context retrieval improves accuracy for frontier-tier models (Claude, GPT, Gemini; +2.7%, p=0.029) but shows mixed results for open source models (aggregate -7.7%, p<0.001), with deficits varying substantially by model. Second, format does not significantly affect aggregate accuracy (chi-squared=2.45, p=0.484), though individual models, particularly open source, exhibit format-specific sensitivities. Third, model capability is the dominant factor, with a 21 percentage point accuracy gap between frontier and open source tiers that dwarfs any format or architecture effect. Fourth, file-native agents scale to 10,000 tables through domain-partitioned schemas while maintaining high navigation accuracy. Fifth, file size does not predict runtime efficiency: compact formats can consume significantly more tokens at scale due to format-unfamiliar search patterns.
  These findings provide practitioners with evidence-based guidance for deploying LLM agents on structured systems, demonstrating that architectural decisions should be tailored to model capability rather than assuming universal best practices.

</details>


### [31] [Reasoning under Ambiguity: Uncertainty-Aware Multilingual Emotion Classification under Partial Supervision](https://arxiv.org/abs/2602.05471)
*Md. Mithun Hossaina,Mashary N. Alrasheedy,Nirban Bhowmick,Shamim Forhad,Md. Shakil Hossain,Sudipto Chaki,Md Shafiqul Islam*

Main category: cs.CL

TL;DR: 提出RA框架，通过不确定性感知的多语言多标签情感分类方法，解决情感模糊性和不完全监督问题，在英西阿语基准上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前基于知识的多语言情感识别系统面临情感模糊性和不完全监督的挑战。文本情感识别本质上是模糊的，因为多种情感状态常共存且标注常缺失或不一致。现有方法假设完全观察标签并使用确定性学习目标，在部分监督下会导致偏见学习和不可靠预测。

Method: 提出RA框架：1）共享多语言编码器+语言特定优化；2）基于熵的模糊性加权机制，降低高模糊训练实例权重而非将缺失标签视为负证据；3）包含正未标记正则化的掩码感知目标，实现部分监督下的鲁棒学习。

Result: 在英语、西班牙语和阿拉伯语情感分类基准测试中，相比强基线在多个评估指标上取得一致改进，同时提升了训练稳定性、对标注稀疏性的鲁棒性和可解释性。

Conclusion: RA框架通过显式对齐学习和标注不确定性，有效解决了多语言多标签情感分类中的模糊性和不完全监督问题，为实际应用提供了更可靠的情感识别解决方案。

Abstract: Contemporary knowledge-based systems increasingly rely on multilingual emotion identification to support intelligent decision-making, yet they face major challenges due to emotional ambiguity and incomplete supervision. Emotion recognition from text is inherently uncertain because multiple emotional states often co-occur and emotion annotations are frequently missing or heterogeneous. Most existing multi-label emotion classification methods assume fully observed labels and rely on deterministic learning objectives, which can lead to biased learning and unreliable predictions under partial supervision. This paper introduces Reasoning under Ambiguity, an uncertainty-aware framework for multilingual multi-label emotion classification that explicitly aligns learning with annotation uncertainty. The proposed approach uses a shared multilingual encoder with language-specific optimization and an entropy-based ambiguity weighting mechanism that down-weights highly ambiguous training instances rather than treating missing labels as negative evidence. A mask-aware objective with positive-unlabeled regularization is further incorporated to enable robust learning under partial supervision. Experiments on English, Spanish, and Arabic emotion classification benchmarks demonstrate consistent improvements over strong baselines across multiple evaluation metrics, along with improved training stability, robustness to annotation sparsity, and enhanced interpretability.

</details>


### [32] [LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation](https://arxiv.org/abs/2602.05493)
*Bingru Li*

Main category: cs.CL

TL;DR: LinguistAgent是一个用于人文学科复杂语义标注的集成平台，采用反思性多模型架构和双代理工作流，支持提示工程、检索增强生成和微调三种范式，以隐喻识别为例展示其有效性。


<details>
  <summary>Details</summary>
Motivation: 人文学科和社会科学中的数据标注，特别是复杂语义任务如隐喻识别，仍然是一个重大瓶颈。尽管大语言模型显示出潜力，但其理论能力与实际研究效用之间存在显著差距。

Method: 引入LinguistAgent平台，采用反思性多模型架构和双代理工作流（标注者和审阅者），模拟专业同行评审过程。支持三种实验范式：提示工程（零样本/少样本）、检索增强生成和微调。

Result: 以隐喻识别任务为例，展示了LinguistAgent的有效性，提供实时token级评估（精确率、召回率和F1分数）并与人类黄金标准对比。平台和代码已开源发布。

Conclusion: LinguistAgent为研究人员提供了一个用户友好的自动化语言标注平台，通过多模型架构和双代理工作流弥合了大语言模型理论能力与实际应用之间的差距。

Abstract: Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the theoretical capability of LLMs and their practical utility for researchers. This paper introduces LinguistAgent, an integrated, user-friendly platform that leverages a reflective multi-model architecture to automate linguistic annotation. The system implements a dual-agent workflow, comprising an Annotator and a Reviewer, to simulate a professional peer-review process. LinguistAgent supports comparative experiments across three paradigms: Prompt Engineering (Zero/Few-shot), Retrieval-Augmented Generation, and Fine-tuning. We demonstrate LinguistAgent's efficacy using the task of metaphor identification as an example, providing real-time token-level evaluation (Precision, Recall, and $F_1$ score) against human gold standards. The application and codes are released on https://github.com/Bingru-Li/LinguistAgent.

</details>


### [33] [Transport and Merge: Cross-Architecture Merging for Large Language Models](https://arxiv.org/abs/2602.05495)
*Chenhang Cui,Binyun Yang,Fei Shen,Yuxin Chen,Jingnan Zheng,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 提出基于最优传输的跨架构模型合并框架，实现从大型高资源LLMs到异构低资源小模型的知识迁移


<details>
  <summary>Details</summary>
Motivation: 现实部署常使用小模型或低资源数据训练，但大模型拥有更强能力，需要将大模型知识迁移到异构小模型的方法

Method: 基于最优传输对齐异构模型的激活，推断跨神经元对应关系，然后指导权重空间融合，仅需少量输入

Result: 在低资源语言和专门领域的广泛实验中，相比目标模型获得一致改进

Conclusion: 提出的跨架构合并框架能有效实现高资源到低资源的知识迁移，解决异构模型知识转移问题

Abstract: Large language models (LLMs) achieve strong capabilities by scaling model capacity and training data, yet many real-world deployments rely on smaller models trained or adapted from low-resource data. This gap motivates the need for mechanisms to transfer knowledge from large, high-resource models to smaller, low-resource targets. While model merging provides an effective transfer mechanism, most existing approaches assume architecture-compatible models and therefore cannot directly transfer knowledge from large high-resource LLMs to heterogeneous low-resource targets. In this work, we propose a cross-architecture merging framework based on optimal transport (OT) that aligns activations to infer cross-neuron correspondences between heterogeneous models. The resulting transport plans are then used to guide direct weight-space fusion, enabling effective high-resource to low-resource transfer using only a small set of inputs. Extensive experiments across low-resource languages and specialized domains demonstrate consistent improvements over target models.

</details>


### [34] [A Human-in-the-Loop, LLM-Centered Architecture for Knowledge-Graph Question Answering](https://arxiv.org/abs/2602.05512)
*Larissa Pusch,Alexandre Courtiol,Tim Conrad*

Main category: cs.CL

TL;DR: 提出一个交互式框架，让LLM生成和解释Cypher图查询，用户通过自然语言迭代优化，提高知识图谱的可访问性，同时保持事实准确性和语义严谨性。


<details>
  <summary>Details</summary>
Motivation: LLM在知识密集型领域存在幻觉、信息过时和可解释性有限的问题。基于文本的检索增强生成（RAG）难以处理多跳推理，而知识图谱（KG）支持精确、可解释的查询，但需要掌握查询语言知识。

Method: 开发交互式框架，LLM生成和解释Cypher图查询，用户通过自然语言迭代优化。在真实世界KG上应用，包括合成电影KG、Hyena KG和MaRDI（数学研究数据倡议）KG。

Result: 核心定量评估是在合成电影KG上的90个查询基准测试，测量查询解释质量和故障检测能力，辅以两个较小的真实生活查询生成实验。框架提高了复杂数据集的可访问性，同时保持事实准确性和语义严谨性。

Conclusion: 该交互式框架使LLM能够有效生成和解释知识图谱查询，通过自然语言交互降低使用门槛，为不同领域的模型性能变化提供洞察，平衡了可访问性与事实准确性。

Abstract: Large Language Models (LLMs) excel at language understanding but remain limited in knowledge-intensive domains due to hallucinations, outdated information, and limited explainability. Text-based retrieval-augmented generation (RAG) helps ground model outputs in external sources but struggles with multi-hop reasoning. Knowledge Graphs (KGs), in contrast, support precise, explainable querying, yet require a knowledge of query languages. This work introduces an interactive framework in which LLMs generate and explain Cypher graph queries and users iteratively refine them through natural language. Applied to real-world KGs, the framework improves accessibility to complex datasets while preserving factual accuracy and semantic rigor and provides insight into how model performance varies across domains. Our core quantitative evaluation is a 90-query benchmark on a synthetic movie KG that measures query explanation quality and fault detection across multiple LLMs, complemented by two smaller real-life query-generation experiments on a Hyena KG and the MaRDI (Mathematical Research Data Initiative) KG.

</details>


### [35] [Multi-Task GRPO: Reliable LLM Reasoning Across Tasks](https://arxiv.org/abs/2602.05547)
*Shyam Sundhar Ramesh,Xiaotong Ji,Matthieu Zimmer,Sangwoong Yoon,Zhiyong Wang,Haitham Bou Ammar,Aurelien Lucchi,Ilija Bogunovic*

Main category: cs.CL

TL;DR: MT-GRPO：一种多任务GRPO算法，通过动态任务权重调整和比例保持采样器，解决多任务强化学习中的不平衡问题，显著提升最差任务性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署需要模型在多样化任务上都有可靠表现。标准的GRPO在多任务适应中常导致不平衡结果——某些任务主导优化而其他任务停滞不前。此外，不同任务中提示产生零优势（从而零梯度）的频率差异很大，进一步扭曲了优化信号的有效贡献。

Method: 提出MT-GRPO算法：1）动态调整任务权重，明确优化最差任务性能，促进任务间平衡进展；2）引入比例保持采样器，确保任务级策略梯度反映调整后的权重。

Result: 在3任务和9任务设置中，MT-GRPO在保持竞争力的平均准确率的同时，在最差任务性能上比标准GRPO提升16-28%，比DAPO提升6%。在3任务设置中，达到50%最差任务准确率所需的训练步骤减少50%。

Conclusion: MT-GRPO通过动态任务权重调整和比例保持采样机制，有效解决了多任务强化学习中的不平衡问题，显著提升了跨任务的最差性能，同时保持了训练效率。

Abstract: RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.

</details>


### [36] [CASTLE: A Comprehensive Benchmark for Evaluating Student-Tailored Personalized Safety in Large Language Models](https://arxiv.org/abs/2602.05633)
*Rui Jia,Ruiyi Lan,Fengrui Liu,Zhongxiang Dai,Bo Jiang,Jing Shao,Jingyuan Chen,Guandong Xu,Fei Wu,Min Zhang*

Main category: cs.CL

TL;DR: CASTLE是一个基于教育理论构建的个性化安全评估基准，涵盖15种教育安全风险和14种学生属性，包含92,908个双语场景。实验显示当前LLM在个性化安全保障方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在个性化学习中存在同质化响应问题，忽视了学生认知和心理的异质性，对弱势群体构成潜在安全风险。现有安全评估主要依赖事实准确性、偏见或毒性等与上下文无关的指标，无法捕捉相同响应对不同学生属性可能造成的不同危害。

Method: 提出"学生定制个性化安全"概念，构建CASTLE基准，涵盖15种教育安全风险和14种学生属性，包含92,908个双语场景。设计三个评估指标：风险敏感性（检测风险能力）、情感共情（识别学生状态能力）和学生对齐（响应与学生属性匹配度）。

Result: 在18个最先进的LLM上进行实验，所有模型在5分制中的平均安全评分低于2.3分，表明在个性化安全保障方面存在显著缺陷。CASTLE基准对现有模型构成了重大挑战。

Conclusion: LLM在教育个性化应用中存在严重的安全隐患，需要开发能够理解学生异质性并提供个性化安全响应的模型。CASTLE基准为评估和改进LLM在教育领域的个性化安全性能提供了重要工具。

Abstract: Large language models (LLMs) have advanced the development of personalized learning in education. However, their inherent generation mechanisms often produce homogeneous responses to identical prompts. This one-size-fits-all mechanism overlooks the substantial heterogeneity in students cognitive and psychological, thereby posing potential safety risks to vulnerable groups. Existing safety evaluations primarily rely on context-independent metrics such as factual accuracy, bias, or toxicity, which fail to capture the divergent harms that the same response might cause across different student attributes. To address this gap, we propose the concept of Student-Tailored Personalized Safety and construct CASTLE based on educational theories. This benchmark covers 15 educational safety risks and 14 student attributes, comprising 92,908 bilingual scenarios. We further design three evaluation metrics: Risk Sensitivity, measuring the model ability to detect risks; Emotional Empathy, evaluating the model capacity to recognize student states; and Student Alignment, assessing the match between model responses and student attributes. Experiments on 18 SOTA LLMs demonstrate that CASTLE poses a significant challenge: all models scored below an average safety rating of 2.3 out of 5, indicating substantial deficiencies in personalized safety assurance.

</details>


### [37] [Modelling the Morphology of Verbal Paradigms: A Case Study in the Tokenization of Turkish and Hebrew](https://arxiv.org/abs/2602.05648)
*Giuseppe Samo,Paola Merlo*

Main category: cs.CL

TL;DR: 研究Transformer模型如何表示土耳其语和现代希伯来语的复杂动词范式，重点关注分词策略如何影响这种能力。


<details>
  <summary>Details</summary>
Motivation: 探究不同分词策略如何影响Transformer模型处理具有不同形态特征的语言（土耳其语的透明形态标记vs希伯来语的非连接性形态）的能力。

Method: 使用Blackbird Language Matrices任务在自然数据上测试，比较不同分词策略（原子分词、小子词单元、字符级分词、语素感知分词）在单语和多语模型中的表现。

Result: 土耳其语：单语和多语模型都能成功，无论使用原子分词还是小子词单元分词。希伯来语：单语和多语模型表现不同，多语模型使用字符级分词无法捕捉非连接性形态，但单语模型使用语素感知分词表现良好。所有模型在更合成化的数据集上表现都有提升。

Conclusion: 分词策略对模型处理不同形态特征的语言至关重要，特别是对于希伯来语这样的非连接性形态语言，需要专门的语素感知分词才能获得良好表现。

Abstract: We investigate how transformer models represent complex verb paradigms in Turkish and Modern Hebrew, concentrating on how tokenization strategies shape this ability. Using the Blackbird Language Matrices task on natural data, we show that for Turkish -- with its transparent morphological markers -- both monolingual and multilingual models succeed, either when tokenization is atomic or when it breaks words into small subword units. For Hebrew, instead, monolingual and multilingual models diverge. A multilingual model using character-level tokenization fails to capture the language non-concatenative morphology, but a monolingual model with morpheme-aware segmentation performs well. Performance improves on more synthetic datasets, in all models.

</details>


### [38] [MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations](https://arxiv.org/abs/2602.05692)
*Congbo Ma,Yichun Zhang,Yousef Al-Jazzazi,Ahamed Foisal,Laasya Sharma,Yousra Sadqi,Khaled Saleh,Jihad Mallat,Farah E. Shamout*

Main category: cs.CL

TL;DR: MedErrBench是首个多语言临床文本错误检测、定位和纠正基准，涵盖英语、阿拉伯语和中文，包含10种常见错误类型，旨在评估LLM在医疗应用中的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有或生成的临床文本不准确可能导致严重后果（如误诊或错误治疗建议）。随着LLM在医疗应用中的广泛使用，需要全面的评估基准，但目前缺乏跨语言和跨环境的此类数据集。

Method: 在临床专家指导下开发多语言基准MedErrBench，基于扩展的10种常见错误类型分类法，涵盖英语、阿拉伯语和中文，包含自然临床案例并由领域专家标注和审查。

Result: 评估了通用、语言特定和医疗领域语言模型在所有三个任务（错误检测、定位和纠正）上的表现，结果显示显著性能差距，特别是在非英语环境中。

Conclusion: 需要基于临床基础、语言感知的系统来提升多语言临床NLP，促进全球更安全、更公平的AI医疗。公开MedErrBench数据集和评估协议以推动该领域发展。

Abstract: Inaccuracies in existing or generated clinical text may lead to serious adverse consequences, especially if it is a misdiagnosis or incorrect treatment suggestion. With Large Language Models (LLMs) increasingly being used across diverse healthcare applications, comprehensive evaluation through dedicated benchmarks is crucial. However, such datasets remain scarce, especially across diverse languages and contexts. In this paper, we introduce MedErrBench, the first multilingual benchmark for error detection, localization, and correction, developed under the guidance of experienced clinicians. Based on an expanded taxonomy of ten common error types, MedErrBench covers English, Arabic and Chinese, with natural clinical cases annotated and reviewed by domain experts. We assessed the performance of a range of general-purpose, language-specific, and medical-domain language models across all three tasks. Our results reveal notable performance gaps, particularly in non-English settings, highlighting the need for clinically grounded, language-aware systems. By making MedErrBench and our evaluation protocols publicly-available, we aim to advance multilingual clinical NLP to promote safer and more equitable AI-based healthcare globally. The dataset is available in the supplementary material. An anonymized version of the dataset is available at: https://github.com/congboma/MedErrBench.

</details>


### [39] [Consensus-Aligned Neuron Efficient Fine-Tuning Large Language Models for Multi-Domain Machine Translation](https://arxiv.org/abs/2602.05694)
*Shuting Jiang,Ran Song,Yuxin Huang,Yan Xiang,Yantuan Xian,Shengxiang Gao,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出了一种基于共识对齐神经元的微调框架，用于多领域机器翻译，通过最大化神经元行为与领域特征之间的互信息来选择神经元，有效缓解参数干扰和领域过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在机器翻译方面表现出色，但领域适应仍然是一个挑战。现有的多领域机器翻译方法（如上下文学习和参数高效微调）存在领域偏移、参数干扰和泛化能力有限的问题。

Method: 提出神经元高效微调框架，通过最大化神经元行为与领域特征之间的互信息来识别和更新LLMs中的共识对齐神经元，然后基于这些神经元指导微调过程。

Result: 在三个大语言模型上，对十个德英和中英翻译领域进行了全面实验，结果表明该方法在已见和未见领域都优于强大的参数高效微调基线，达到了最先进的性能。

Conclusion: 该方法通过识别和微调共识对齐神经元，能够同时捕捉可泛化的翻译模式和领域特定细微差别，有效缓解参数干扰和领域特定过拟合问题，在多领域机器翻译任务中表现出色。

Abstract: Multi-domain machine translation (MDMT) aims to build a unified model capable of translating content across diverse domains. Despite the impressive machine translation capabilities demonstrated by large language models (LLMs), domain adaptation still remains a challenge for LLMs. Existing MDMT methods such as in-context learning and parameter-efficient fine-tuning often suffer from domain shift, parameter interference and limited generalization. In this work, we propose a neuron-efficient fine-tuning framework for MDMT that identifies and updates consensus-aligned neurons within LLMs. These neurons are selected by maximizing the mutual information between neuron behavior and domain features, enabling LLMs to capture both generalizable translation patterns and domain-specific nuances. Our method then fine-tunes LLMs guided by these neurons, effectively mitigating parameter interference and domain-specific overfitting. Comprehensive experiments on three LLMs across ten German-English and Chinese-English translation domains evidence that our method consistently outperforms strong PEFT baselines on both seen and unseen domains, achieving state-of-the-art performance.

</details>


### [40] [OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale](https://arxiv.org/abs/2602.05711)
*Jingze Shi,Zhangyang Peng,Yizhang Zhu,Yifan Wu,Guang Liu,Yuyu Luo*

Main category: cs.CL

TL;DR: OmniMoE提出了一种系统-算法协同设计的框架，将专家粒度推到极致，通过原子专家和笛卡尔积路由器等技术，在保持高准确率的同时大幅提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE架构在专家专业化粒度和硬件执行效率之间存在固有权衡。粗粒度专家效率高但专业化不足，细粒度专家专业化强但路由复杂、内存访问效率低。

Method: 1. 引入向量级原子专家，实现单层MoE内的可扩展路由和执行；2. 笛卡尔积路由器将大规模索引空间分解，将路由复杂度从O(N)降至O(√N)；3. 专家中心调度反转执行顺序，将分散的内存受限查找转化为高效的稠密矩阵运算。

Result: 在七个基准测试中，OmniMoE（17亿活跃参数）实现了50.9%的零样本准确率，优于粗粒度（DeepSeekMoE）和细粒度（PEER）基线。推理延迟从73ms降至6.7ms（10.9倍加速），证明大规模细粒度MoE可以既快速又准确。

Conclusion: OmniMoE通过系统-算法协同设计解决了细粒度MoE的路由复杂性和内存访问瓶颈，实现了专家粒度与硬件效率的最佳平衡，为大规模MoE模型的实际部署提供了可行方案。

Abstract: Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.

</details>


### [41] [CompactRAG: Reducing LLM Calls and Token Overhead in Multi-Hop Question Answering](https://arxiv.org/abs/2602.05728)
*Hao Yang,Zhiyu Yang,Xupeng Zhang,Wei Wei,Yunjie Zhang,Lin Yang*

Main category: cs.CL

TL;DR: CompactRAG：一种高效的检索增强生成框架，通过离线知识库重构和在线推理解耦，显著减少LLM调用次数和token消耗，实现多跳问答的高效推理。


<details>
  <summary>Details</summary>
Motivation: 现有多跳RAG系统效率低下，需要在每个推理步骤交替进行检索和推理，导致重复的LLM调用、高token消耗以及跨跳实体基础不稳定。需要一种更高效、成本更低的解决方案。

Method: 1. 离线阶段：LLM一次性读取语料库，将其转换为原子QA知识库，将知识表示为最小粒度的问答对。2. 在线阶段：复杂查询被分解并重写以保持实体一致性，通过密集检索和RoBERTa答案提取解决。整个推理过程仅调用LLM两次（子问题分解和最终答案合成）。

Result: 在HotpotQA、2WikiMultiHopQA和MuSiQue上的实验表明，CompactRAG在保持竞争力的准确率的同时，相比迭代式RAG基线显著减少了token消耗，实现了对大型知识语料库进行多跳推理的高效实用方法。

Conclusion: CompactRAG通过解耦离线语料重构和在线推理，为多跳知识密集型问答提供了一种成本效益高且实用的方法，显著降低了计算开销，同时保持了良好的性能。

Abstract: Retrieval-augmented generation (RAG) has become a key paradigm for knowledge-intensive question answering. However, existing multi-hop RAG systems remain inefficient, as they alternate between retrieval and reasoning at each step, resulting in repeated LLM calls, high token consumption, and unstable entity grounding across hops. We propose CompactRAG, a simple yet effective framework that decouples offline corpus restructuring from online reasoning.
  In the offline stage, an LLM reads the corpus once and converts it into an atomic QA knowledge base, which represents knowledge as minimal, fine-grained question-answer pairs. In the online stage, complex queries are decomposed and carefully rewritten to preserve entity consistency, and are resolved through dense retrieval followed by RoBERTa-based answer extraction. Notably, during inference, the LLM is invoked only twice in total - once for sub-question decomposition and once for final answer synthesis - regardless of the number of reasoning hops.
  Experiments on HotpotQA, 2WikiMultiHopQA, and MuSiQue demonstrate that CompactRAG achieves competitive accuracy while substantially reducing token consumption compared to iterative RAG baselines, highlighting a cost-efficient and practical approach to multi-hop reasoning over large knowledge corpora. The implementation is available at GitHub.

</details>


### [42] [LongR: Unleashing Long-Context Reasoning via Reinforcement Learning with Dense Utility Rewards](https://arxiv.org/abs/2602.05758)
*Bowen Ping,Zijun Chen,Yiyao Yu,Tingfeng Hui,Junchi Yan,Baobao Chang*

Main category: cs.CL

TL;DR: LongR：通过动态"思考-阅读"机制和上下文密度奖励增强长上下文推理的强化学习框架


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖稀疏的最终结果奖励，在长上下文推理中效果有限，因为粗粒度的信号难以有效指导复杂的推理过程

Method: 提出LongR统一框架，整合动态"思考-阅读"机制（交替进行推理和文档查阅），以及基于相对信息增益的上下文密度奖励来量化相关文档的效用

Result: 在LongBench v2上获得9%的性能提升，在RULER和InfiniteBench上表现一致改善，在不同RL算法（如DAPO、GSPO）上都能增强性能

Conclusion: LongR通过细粒度的奖励机制和动态推理-阅读交替策略，有效提升了模型在长上下文场景中的推理能力，并展示了良好的鲁棒性

Abstract: Reinforcement Learning has emerged as a key driver for LLM reasoning. This capability is equally pivotal in long-context scenarios--such as long-dialogue understanding and structured data analysis, where the challenge extends beyond consuming tokens to performing rigorous deduction. While existing efforts focus on data synthesis or architectural changes, recent work points out that relying solely on sparse, outcome-only rewards yields limited gains, as such coarse signals are often insufficient to effectively guide the complex long-context reasoning. To address this, we propose LongR, a unified framework that enhances long-context performance by integrating a dynamic "Think-and-Read" mechanism, which interleaves reasoning with document consultation, with a contextual density reward based on relative information gain to quantify the utility of the relevant documents. Empirically, LongR achieves a 9% gain on LongBench v2 and consistent improvements on RULER and InfiniteBench, demonstrating robust efficiency in navigating extensive contexts. Furthermore, LongR consistently enhances performance across diverse RL algorithms (e.g., DAPO, GSPO). Finally, we conduct in-depth analyses to investigate the impact of reasoning chain length on efficiency and the model's robustness against distractors.

</details>


### [43] [Different Time, Different Language: Revisiting the Bias Against Non-Native Speakers in GPT Detectors](https://arxiv.org/abs/2602.05769)
*Adnan Al Ali,Jindřich Helcl,Jindřich Libovický*

Main category: cs.CL

TL;DR: 研究重新评估了两年后捷克语环境中LLM文本检测器对非母语者的偏见问题，发现非母语者文本的困惑度并不低于母语者，且当代检测器有效且无系统性偏见


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等LLM助手的普及，学术界对其滥用的担忧增加。先前研究表明，基于困惑度的检测器常错误地将非母语者的文章标记为生成文本，本研究旨在两年后重新评估这一现象在捷克语环境中的情况

Method: 研究在捷克语环境中进行，首先比较了母语者和非母语者文本的困惑度，然后评估了来自三个不同家族的检测器，分析它们对非母语者文本的检测偏差

Result: 发现非母语者捷克语文本的困惑度并不低于母语者，三种检测器均未显示出对非母语者的系统性偏见，且当代检测器无需依赖困惑度也能有效工作

Conclusion: 与先前研究结论不同，在捷克语环境中，基于LLM的文本检测器对非母语者不存在系统性偏见，且现代检测器已发展出更有效的检测方法

Abstract: LLM-based assistants have been widely popularised after the release of ChatGPT. Concerns have been raised about their misuse in academia, given the difficulty of distinguishing between human-written and generated text. To combat this, automated techniques have been developed and shown to be effective, to some extent. However, prior work suggests that these methods often falsely flag essays from non-native speakers as generated, due to their low perplexity extracted from an LLM, which is supposedly a key feature of the detectors. We revisit these statements two years later, specifically in the Czech language setting. We show that the perplexity of texts from non-native speakers of Czech is not lower than that of native speakers. We further examine detectors from three separate families and find no systematic bias against non-native speakers. Finally, we demonstrate that contemporary detectors operate effectively without relying on perplexity.

</details>


### [44] [Reinforcement World Model Learning for LLM-based Agents](https://arxiv.org/abs/2602.05842)
*Xiao Yu,Baolin Peng,Ruize Xu,Yelong Shen,Pengcheng He,Suman Nath,Nikhil Singh,Jiangfeng Gao,Zhou Yu*

Main category: cs.CL

TL;DR: RWML是一种自监督学习方法，为基于LLM的智能体学习动作条件的世界模型，通过模拟到现实的差距奖励来对齐内部世界模拟与实际环境动态，显著提升智能体在ALFWorld和τ² Bench上的性能。


<details>
  <summary>Details</summary>
Motivation: LLM在语言任务中表现出色，但在智能体环境中难以预测动作后果和适应环境动态，需要世界建模能力来提升智能体的决策能力。

Method: 提出RWML（强化世界模型学习），一种自监督方法，在文本状态上为LLM智能体学习动作条件的世界模型。使用模拟到现实的差距奖励，在预训练嵌入空间中对齐模型生成的模拟下一状态与环境观察到的实际下一状态，确保内部世界模拟与实际环境动态的一致性。

Result: 在ALFWorld和τ² Bench上评估，相比基础模型有显著提升。与任务成功奖励结合时，在ALFWorld和τ² Bench上分别比直接任务成功奖励RL高出6.9和5.7分，性能与专家数据训练相当。

Conclusion: RWML提供了一种更鲁棒的训练信号，比下一状态token预测和LLM-as-a-judge方法更不易出现奖励黑客问题，有效提升了LLM智能体的世界建模能力。

Abstract: Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and $τ^2$ Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and $τ^2$ Bench respectively, while matching the performance of expert-data training.

</details>


### [45] [OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions](https://arxiv.org/abs/2602.05843)
*Fangzhi Xu,Hang Yan,Qiushi Sun,Jinyang Wu,Zixian Huang,Muye Huang,Jingyang Gong,Zichen Ding,Kanzhi Cheng,Yian Wang,Xinyu Che,Zeyi Sun,Jian Zhang,Zhangyue Yin,Haoran Luo,Xuanjing Huang,Ben Kao,Jun Liu,Qika Lin*

Main category: cs.CL

TL;DR: 提出OdysseyArena评估框架，专注于长时程、主动、归纳式交互，测试LLM智能体在复杂环境中的自主发现能力，发现前沿模型在归纳场景中存在明显缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体评估主要采用演绎范式，基于显式规则和静态目标执行任务，忽视了智能体从经验中自主发现潜在转移规律的归纳能力，这是实现智能体预见性和战略连贯性的关键。

Method: 1. 提出OdysseyArena框架，重新聚焦于长时程、主动、归纳式交互评估；2. 形式化并实例化四个原语，将抽象转移动态转化为具体交互环境；3. 建立OdysseyArena-Lite标准化基准，包含120个任务测量智能体的归纳效率和长时程发现能力；4. 推出OdysseyArena-Challenge，在极端交互时程（>200步）下压力测试智能体稳定性。

Result: 对15+个领先LLM的广泛实验表明，即使是前沿模型在归纳场景中也存在明显缺陷，揭示了在复杂环境中追求自主发现的关键瓶颈。

Conclusion: OdysseyArena填补了现有评估的空白，强调智能体从经验中自主发现规律的归纳能力，为评估和推进LLM智能体在复杂环境中的自主发现能力提供了重要框架和基准。

Abstract: The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena

</details>


### [46] [RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference](https://arxiv.org/abs/2602.05853)
*Siran Liu,Guoxia Wang,Sa Wang,Jinle Zeng,HaoYang Xie,Siyu Lou,JiaBin Yang,DianHai Yu,Haifeng Wang,Chao Yang*

Main category: cs.CL

TL;DR: RRAttention是一种新颖的动态稀疏注意力方法，通过头轮询采样策略，在保持查询独立性的同时实现高效全局模式发现，将复杂度从O(L²)降低到O(L²/S²)，恢复超过99%全注意力性能，计算仅需一半注意力块，在128K上下文长度下实现2.4倍加速。


<details>
  <summary>Details</summary>
Motivation: 注意力机制的二次复杂度是处理长上下文大语言模型的关键瓶颈。现有动态稀疏注意力方法面临基本权衡：需要预处理、缺乏全局评估、违反查询独立性或计算开销高。

Method: 提出RRAttention方法，采用头轮询采样策略，在每个步幅内跨注意力头旋转查询采样位置，保持查询独立性同时实现步幅级聚合的高效全局模式发现。将复杂度从O(L²)降低到O(L²/S²)，并采用自适应Top-τ选择实现最优稀疏度。

Result: 在自然语言理解（HELMET）和多模态视频理解（Video-MME）上的实验表明，RRAttention恢复超过99%的全注意力性能，仅计算一半注意力块，在128K上下文长度下实现2.4倍加速，优于现有动态稀疏注意力方法。

Conclusion: RRAttention通过头轮询采样策略，同时实现了动态稀疏注意力的所有理想特性，为解决长上下文处理中的注意力复杂度瓶颈提供了有效解决方案。

Abstract: The quadratic complexity of attention mechanisms poses a critical bottleneck for large language models processing long contexts. While dynamic sparse attention methods offer input-adaptive efficiency, they face fundamental trade-offs: requiring preprocessing, lacking global evaluation, violating query independence, or incurring high computational overhead. We present RRAttention, a novel dynamic sparse attention method that simultaneously achieves all desirable properties through a head \underline{r}ound-\underline{r}obin (RR) sampling strategy. By rotating query sampling positions across attention heads within each stride, RRAttention maintains query independence while enabling efficient global pattern discovery with stride-level aggregation. Our method reduces complexity from $O(L^2)$ to $O(L^2/S^2)$ and employs adaptive Top-$τ$ selection for optimal sparsity. Extensive experiments on natural language understanding (HELMET) and multimodal video comprehension (Video-MME) demonstrate that RRAttention recovers over 99\% of full attention performance while computing only half of the attention blocks, achieving 2.4$\times$ speedup at 128K context length and outperforming existing dynamic sparse attention methods.

</details>


### [47] [xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection](https://arxiv.org/abs/2602.05874)
*Adrián Girón,Pablo Miralles,Javier Huertas-Tato,Sergio D'Antonio,David Camacho*

Main category: cs.CL

TL;DR: 提出xList-Hate框架，将仇恨言论检测分解为基于规范标准的检查清单问题，使用LLM回答每个问题，再通过可解释决策树聚合结果，提高跨数据集鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统仇恨言论检测作为二元分类问题存在局限性：不同法律框架、平台政策和标注指南定义不一致，导致监督模型容易过拟合特定数据集定义，在领域迁移和标注噪声下鲁棒性差。

Method: 1. 将仇恨言论检测分解为基于广泛共享规范标准的明确概念级问题检查清单；2. 使用大语言模型独立回答每个问题，生成二进制诊断表示；3. 通过轻量级、完全可解释的决策树聚合诊断信号，生成透明可审计的预测。

Result: 在多个仇恨言论基准测试中，相比零样本LLM分类和领域内监督微调，该方法在跨数据集鲁棒性和领域迁移下的相对性能表现更优。定性分析表明框架对某些标注不一致和上下文模糊性更不敏感，同时提供细粒度可解释性。

Conclusion: 将仇恨言论检测重构为诊断推理任务而非单一分类问题，为内容审核提供了更鲁棒、可解释和可扩展的替代方案。xList-Hate框架通过显式决策路径和因素级分析实现透明预测。

Abstract: Hate speech detection is commonly framed as a direct binary classification problem despite being a composite concept defined through multiple interacting factors that vary across legal frameworks, platform policies, and annotation guidelines. As a result, supervised models often overfit dataset-specific definitions and exhibit limited robustness under domain shift and annotation noise.
  We introduce xList-Hate, a diagnostic framework that decomposes hate speech detection into a checklist of explicit, concept-level questions grounded in widely shared normative criteria. Each question is independently answered by a large language model (LLM), producing a binary diagnostic representation that captures hateful content features without directly predicting the final label. These diagnostic signals are then aggregated by a lightweight, fully interpretable decision tree, yielding transparent and auditable predictions.
  We evaluate it across multiple hate speech benchmarks and model families, comparing it against zero-shot LLM classification and in-domain supervised fine-tuning. While supervised methods typically maximize in-domain performance, we consistently improves cross-dataset robustness and relative performance under domain shift. In addition, qualitative analysis of disagreement cases provides evidence that the framework can be less sensitive to certain forms of annotation inconsistency and contextual ambiguity. Crucially, the approach enables fine-grained interpretability through explicit decision paths and factor-level analysis.
  Our results suggest that reframing hate speech detection as a diagnostic reasoning task, rather than a monolithic classification problem, provides a robust, explainable, and extensible alternative for content moderation.

</details>


### [48] [EuroLLM-22B: Technical Report](https://arxiv.org/abs/2602.05879)
*Miguel Moura Ramos,Duarte M. Alves,Hippolyte Gisserot-Boukhlef,João Alves,Pedro Henrique Martins,Patrick Fernandes,José Pombal,Nuno M. Guerreiro,Ricardo Rei,Nicolas Boizard,Amin Farajian,Mateusz Klimaszewski,José G. C. de Souza,Barry Haddow,François Yvon,Pierre Colombo,Alexandra Birch,André F. T. Martins*

Main category: cs.CL

TL;DR: EuroLLM-22B是一个从头训练的大语言模型，专门支持24种欧盟官方语言和11种额外语言，旨在解决欧洲语言在现有开源大模型中代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有开源大语言模型中欧洲语言代表性不足，无法满足欧洲公民的需求。作者希望开发一个专门支持欧洲多语言的大模型，覆盖欧盟所有官方语言。

Method: 从零开始训练EuroLLM-22B模型，包括：设计多语言分词器、确定架构规格、数据过滤和训练流程。模型支持35种语言，并发布了预训练数据、指令数据集和评估代码库。

Result: 在广泛的多语言基准测试中，EuroLLM-22B在推理、指令遵循和翻译方面表现出色，性能与同规模模型相当。模型在35种语言上都有良好表现。

Conclusion: EuroLLM-22B成功填补了欧洲语言在大语言模型中的空白，为欧洲多语言AI研究提供了重要资源。作者开源了模型、数据和代码以支持未来研究。

Abstract: This report presents EuroLLM-22B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-22B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. Across a broad set of multilingual benchmarks, EuroLLM-22B demonstrates strong performance in reasoning, instruction following, and translation, achieving results competitive with models of comparable size. To support future research, we release our base and instruction-tuned models, our multilingual web pretraining data and updated EuroBlocks instruction datasets, as well as our pre-training and evaluation codebases.

</details>


### [49] [Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models](https://arxiv.org/abs/2602.05897)
*Shuo Nie,Hexuan Deng,Chao Wang,Ruiyu Fang,Xuebo Liu,Shuangyong Song,Yu Li,Min Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: FaithRL是一种针对小型推理模型的强化学习方法，通过步骤级监督和截断重采样策略，减少推理过程中的不忠实幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 小型推理模型在资源受限环境中很重要，但容易在中间推理步骤产生不忠实的幻觉。现有的基于在线强化学习的方法依赖于结果奖励或粗粒度的CoT评估，当最终答案正确时可能无意中强化不忠实的推理。

Method: 提出Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL)，通过过程奖励模型提供明确的忠实性奖励进行步骤级监督，并结合隐式的截断重采样策略从忠实前缀生成对比信号。

Result: 在多个小型推理模型和Open-Book QA基准测试中，FaithRL持续减少了CoT和最终答案中的幻觉，实现了更忠实可靠的推理。

Conclusion: FaithRL通过步骤级监督和对比学习策略，有效解决了小型推理模型中的忠实性问题，为资源受限环境提供了更可靠的推理解决方案。

Abstract: As large language models become smaller and more efficient, small reasoning models (SRMs) are crucial for enabling chain-of-thought (CoT) reasoning in resource-constrained settings. However, they are prone to faithfulness hallucinations, especially in intermediate reasoning steps. Existing mitigation methods based on online reinforcement learning rely on outcome-based rewards or coarse-grained CoT evaluation, which can inadvertently reinforce unfaithful reasoning when the final answer is correct. To address these limitations, we propose Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL), introducing step-level supervision via explicit faithfulness rewards from a process reward model, together with an implicit truncated resampling strategy that generates contrastive signals from faithful prefixes. Experiments across multiple SRMs and Open-Book QA benchmarks demonstrate that FaithRL consistently reduces hallucinations in both the CoT and final answers, leading to more faithful and reliable reasoning. Code is available at https://github.com/Easy195/FaithRL.

</details>


### [50] [Codified Finite-state Machines for Role-playing](https://arxiv.org/abs/2602.05905)
*Letian Peng,Yupeng Hou,Kun Zhou,Jingbo Shang*

Main category: cs.CL

TL;DR: 提出CFSM和CPFSM框架，通过LLM自动将角色描述编码为有限状态机，解决角色扮演中潜在状态建模问题，提升角色一致性和交互质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法主要捕捉表面行为，难以追踪驱动交互的潜在状态，导致角色扮演不一致。传统手工规则有限状态机难以适应开放语义空间。

Method: 引入CFSM框架，使用LLM自动将文本角色描述编码为有限状态机，提取关键状态和转移。进一步扩展为CPFSM，将转移建模为状态上的概率分布。

Result: 在合成评估和真实角色扮演场景中，CFSM和CPFSM优于现有基线方法，在结构化任务和开放随机状态探索中均有效。

Conclusion: CFSM和CPFSM框架能有效建模角色潜在状态，提升角色扮演的一致性和质量，为开放语义空间的状态建模提供了新方法。

Abstract: Modeling latent character states is crucial for consistent and engaging role-playing (RP) with large language models (LLMs). Yet, existing prompting-based approaches mainly capture surface actions, often failing to track the latent states that drive interaction. We revisit finite-state machines (FSMs), long used in game design to model state transitions. While effective in small, well-specified state spaces, traditional hand-crafted, rule-based FSMs struggle to adapt to the open-ended semantic space of RP. To address this, we introduce Codified Finite-State Machines (CFSMs), a framework that automatically codifies textual character profiles into FSMs using LLM-based coding. CFSMs extract key states and transitions directly from the profile, producing interpretable structures that enforce character consistency. To further capture uncertainty and variability, we extend CFSMs into Codified Probabilistic Finite-State Machines (CPFSMs), where transitions are modeled as probability distributions over states. Through both synthetic evaluations and real-world RP scenarios in established artifacts, we demonstrate that CFSM and CPFSM outperform generally applied baselines, verifying effectiveness not only in structured tasks but also in open-ended stochastic state exploration.

</details>


### [51] [KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs](https://arxiv.org/abs/2602.05929)
*Jian Chen,Zhuoran Wang,Jiayu Qin,Ming Li,Meng Wang,Changyou Chen,Yin Chen,Qizhen Weng,Yirui Liu*

Main category: cs.CL

TL;DR: KV-CoRE：一种基于SVD的方法，用于量化KV缓存的数据依赖低秩可压缩性，揭示了可压缩性与模型架构、训练数据和语言覆盖的系统性关联。


<details>
  <summary>Details</summary>
Motivation: 随着上下文长度增长，KV缓存的读写会快速饱和GPU内存带宽。现有KV缓存压缩方法大多忽略了KV缓存的数据依赖特性及其在不同层间的变化。

Method: 提出KV-CoRE方法，基于SVD计算Frobenius范数下的最优低秩近似，该方法无需梯度且增量式，支持高效的数据集级、分层评估。

Result: 分析了多个模型和数据集（覆盖5个英文领域和16种语言），发现可压缩性与模型架构、训练数据和语言覆盖存在系统性关联，归一化有效秩与压缩性能下降强相关。

Conclusion: 建立了KV缓存可压缩性的原则性评估框架和首个大规模基准，为动态、数据感知的压缩和数据中心的模型开发提供了见解。

Abstract: Large language models rely on kv-caches to avoid redundant computation during autoregressive decoding, but as context length grows, reading and writing the cache can quickly saturate GPU memory bandwidth. Recent work has explored KV-cache compression, yet most approaches neglect the data-dependent nature of kv-caches and their variation across layers. We introduce KV-CoRE KV-cache Compressibility by Rank Evaluation), an SVD-based method for quantifying the data-dependent low-rank compressibility of kv-caches. KV-CoRE computes the optimal low-rank approximation under the Frobenius norm and, being gradient-free and incremental, enables efficient dataset-level, layer-wise evaluation. Using this method, we analyze multiple models and datasets spanning five English domains and sixteen languages, uncovering systematic patterns that link compressibility to model architecture, training data, and language coverage. As part of this analysis, we employ the Normalized Effective Rank as a metric of compressibility and show that it correlates strongly with performance degradation under compression. Our study establishes a principled evaluation framework and the first large-scale benchmark of kv-cache compressibility in LLMs, offering insights for dynamic, data-aware compression and data-centric model development.

</details>


### [52] [Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions](https://arxiv.org/abs/2602.05932)
*Léo Labat,Etienne Ollion,François Yvon*

Main category: cs.CL

TL;DR: 研究多语言大语言模型在价值取向多选题上的跨语言一致性，发现大型指令微调模型整体一致性较高，但某些问题仍存在语言特定行为。


<details>
  <summary>Details</summary>
Motivation: 虽然多语言对LLM事实回忆的影响已有研究，但价值取向多选题回答中的语言诱导变异尚未充分探索。研究者想了解多语言LLM在价值问题上是像理论上的多语者一样跨语言一致，还是像多个单语模型一样根据问题语言表达不同价值观。

Method: 发布新的Multilingual European Value Survey (MEVS)语料库，包含8种欧洲语言的人类翻译对齐调查问题。对30多个多语言LLM进行测试，控制提示变量（答案顺序、符号类型、尾部字符），分析模型在价值取向多选题上的跨语言一致性。

Result: 大型指令微调模型整体一致性较高，但响应稳健性在不同问题间差异很大。某些多选题在所有模型内外都获得完全一致回答，而其他问题则导致LLM回答分裂。所有一致的指令微调模型在某些问题上都表现出语言特定行为。

Conclusion: 多语言LLM在价值取向问题上并非完全一致的多语者，而是在某些问题上表现出语言特定行为。这需要进一步研究偏好微调的选择性效应，以及如何确保LLM在不同语言中表达一致的价值观。

Abstract: Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.

</details>


### [53] [Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training](https://arxiv.org/abs/2602.05940)
*Junxiao Liu,Zhijun Wang,Yixiao Li,Zhejian Lai,Liqian Huang,Xin Huang,Xue Han,Junlan Feng,Shujian Huang*

Main category: cs.CL

TL;DR: TRIT框架通过整合翻译训练到多语言推理中，解决大模型在非英语问题上的推理困难，无需外部反馈或额外数据即可提升多语言理解和生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前长推理模型在多语言环境下表现不佳：它们倾向于用英语推理非英语问题，而强制用问题语言推理时准确率大幅下降。这源于模型在多语言问题理解和推理两方面的能力有限。

Method: 提出TRIT（Translation-Reasoning Integrated Training）框架，将翻译训练整合到多语言推理训练中。这是一个自我改进的框架，无需外部反馈或额外多语言数据，联合增强多语言问题理解和响应生成能力。

Result: 在MMATH数据集上，该方法平均优于多个基线7个百分点，同时提高了答案正确性和语言一致性。分析显示，整合翻译训练使跨语言问题对齐提升超过10个百分点，并在数学问题和通用领域文本的翻译质量上获得最高8.4 COMET点的提升。

Conclusion: TRIT框架通过整合翻译和多语言推理训练，有效解决了大模型在多语言环境下的推理困难，显著提升了跨语言理解和生成能力，且无需额外数据或外部反馈。

Abstract: Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning. To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning. Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH, our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200.

</details>


### [54] [Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space](https://arxiv.org/abs/2602.05971)
*Felipe D. Toro-Hernández,Jesuino Vieira Filho,Rodrigo M. Cabral-Carvalho*

Main category: cs.CL

TL;DR: 提出一个将概念生成视为在嵌入空间中导航的框架，通过累积嵌入构建语义轨迹，提取几何和动态指标，用于区分临床群体和概念类型。


<details>
  <summary>Details</summary>
Motivation: 研究人类如何在语义几何空间中导航以检索和操纵意义，为语义表示搜索提供计算基础，减少传统语言学预处理的劳动密集型工作。

Method: 使用transformer文本嵌入模型构建参与者特定的语义轨迹（基于累积嵌入），提取距离、熵、速度、加速度等几何和动态指标，在四个跨语言数据集上评估。

Result: 框架能区分临床群体和概念类型；累积嵌入在长轨迹中效果最佳，短轨迹可能更适合非累积方法；不同嵌入模型结果相似，表明学习表示的共性。

Conclusion: 将语义导航框架化为嵌入空间中的结构化轨迹，连接认知建模与学习表示，为量化语义表示动态提供管道，应用于临床研究、跨语言分析和人工认知评估。

Abstract: Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Comparison with a non-cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, favoring the non-cumulative alternative. Critically, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.

</details>


### [55] [DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs](https://arxiv.org/abs/2602.05992)
*Lizhuo Luo,Shenggui Li,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: 提出Dynamic Sliding Block (DSB)方法，通过动态调整块大小来改进扩散大语言模型的块调度策略，提高生成质量和推理效率


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型使用固定的预定义块调度策略，无法适应语义难度，导致质量效率双输：可能过早确定不确定位置，同时延迟边界附近的简单位置

Method: 提出DSB方法，使用动态大小的滑动块来克服固定块的刚性；进一步提出DSB Cache，专为DSB设计的训练免费KV缓存机制

Result: 在多个模型和基准测试上的实验表明，DSB结合DSB Cache能一致提升扩散大语言模型的生成质量和推理效率

Conclusion: 动态适应语义难度的块调度对扩散大语言模型的可靠高效推理至关重要，DSB方法为此提供了有效的训练免费解决方案

Abstract: Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucial for avoiding order misalignment in global bidirectional decoding and improving output quality. However, the widely-used fixed, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, we propose Dynamic Sliding Block (DSB), a training-free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, we introduce DSB Cache, a training-free KV-cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, together with DSB Cache, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo-luo/DSB.

</details>


### [56] [A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies](https://arxiv.org/abs/2602.06015)
*Panagiotis Kaliosis,Adithya V Ganesan,Oscar N. E. Kjell,Whitney Ringwald,Scott Feltman,Melissa A. Carr,Dimitris Samaras,Camilo Ruggero,Benjamin J. Luft,Roman Kotov,Andrew H. Schwartz*

Main category: cs.CL

TL;DR: LLMs在零样本心理健康评估中的准确性受多种因素影响，包括上下文知识、建模策略等，最佳性能需要结合监督模型与LLM集成。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地用于零样本心理健康评估，但对其准确性影响因素了解有限，需要系统研究不同上下文知识和建模策略对评估性能的影响。

Method: 使用1,437名个体的临床数据集，评估11个最先进的LLMs，系统变化(i)上下文知识（子量表定义、分布摘要、访谈问题）和(ii)建模策略（零样本vs少样本、推理努力量、模型大小、结构化子量表vs直接标量预测、输出重缩放和九种集成方法）。

Result: (a)提供详细构造定义和叙述上下文时LLMs最准确；(b)增加推理努力提高估计准确性；(c)开源模型在70B参数后性能趋于稳定，闭源模型随新一代改进；(d)监督模型与零样本LLMs集成时性能最佳。

Conclusion: 上下文知识和建模策略的选择对于部署LLMs准确评估心理健康至关重要，最佳实践需要结合详细构造定义、充分推理努力和集成方法。

Abstract: Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, distribution summary, and interview questions, and (ii) modeling strategies including zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open-weight models (Llama, Deepseek), plateau beyond 70B parameters while closed-weight (o3-mini, gpt-5) models improve with newer generations; and (d) best performance is achieved when ensembling a supervised model with the zero-shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.

</details>


### [57] [Multi-Token Prediction via Self-Distillation](https://arxiv.org/abs/2602.06019)
*John Kirchenbauer,Abhimanyu Hans,Brian Bartoldson,Micah Goldblum,Ashwinee Panda,Tom Goldstein*

Main category: cs.CL

TL;DR: 提出一种新方法，将预训练自回归语言模型转换为快速的多令牌预测模型，无需训练辅助模型或复杂推理管道，实现3倍以上解码加速且精度损失小于5%


<details>
  <summary>Details</summary>
Motivation: 现有加速技术（如推测解码）需要训练辅助推测模型并构建复杂推理管道，部署复杂。本文寻求更简单的方法来加速语言模型推理

Method: 使用简单的在线蒸馏目标，将预训练自回归语言模型从慢速单令牌预测模型转换为快速独立的多令牌预测模型，保持与初始检查点完全相同的实现

Result: 在GSM8K上，该方法产生的模型平均解码速度提高3倍以上，相对于单令牌解码性能的准确率下降小于5%

Conclusion: 该方法提供了一种简单有效的语言模型加速方案，无需额外辅助验证器或专门推理代码，部署简便

Abstract: Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online distillation objective. The final model retains the exact same implementation as the pretrained initial checkpoint and is deployable without the addition of any auxiliary verifier or other specialized inference code. On GSM8K, our method produces models that can decode more than $3\times$ faster on average at $<5\%$ drop in accuracy relative to single token decoding performance.

</details>


### [58] [Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory](https://arxiv.org/abs/2602.06025)
*Haozhen Zhang,Haodong Yue,Tao Feng,Quanyu Long,Jianzhu Bao,Bowen Jin,Weizhi Zhang,Xiao Li,Jiaxuan You,Chengwei Qin,Wenya Wang*

Main category: cs.CL

TL;DR: BudgetMem是一个运行时代理内存框架，通过模块化设计和预算层级路由，在LLM代理中实现显式的查询感知性能-成本控制。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理内存系统大多依赖离线、查询无关的内存构建，效率低下且可能丢弃关键信息。运行时内存利用虽然自然，但先前工作通常带来显著开销且缺乏对性能-成本权衡的显式控制。

Method: 将内存处理结构化为多个内存模块，每个模块提供三个预算层级（低/中/高）。通过轻量级路由器执行跨模块的预算层级路由，使用强化学习训练的紧凑神经策略来平衡任务性能和内存构建成本。研究了三种实现预算层级的策略：实现（方法复杂度）、推理（推断行为）和容量（模块模型大小）。

Result: 在LoCoMo、LongMemEval和HotpotQA数据集上，BudgetMem在优先性能时超越强基线（高预算设置），在更紧预算下提供更好的准确率-成本边界。分析揭示了不同层级策略的优势和弱点，明确了在不同预算机制下每种策略何时提供最有利的权衡。

Conclusion: BudgetMem提供了一个统一的测试平台，用于研究运行时内存系统的性能-成本权衡，通过模块化设计和预算感知路由实现了显式的查询感知控制，为LLM代理内存管理提供了灵活高效的解决方案。

Abstract: Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \textsc{Low}/\textsc{Mid}/\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.

</details>


### [59] [DFlash: Block Diffusion for Flash Speculative Decoding](https://arxiv.org/abs/2602.06036)
*Jian Chen,Yesheng Liang,Zhijian Liu*

Main category: cs.CL

TL;DR: DFlash是一种使用轻量级块扩散模型进行并行草稿生成的推测解码框架，相比传统自回归草稿模型，能实现6倍无损加速和2.5倍于现有最佳方法的速度提升。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型虽然性能强大，但需要顺序解码，导致推理延迟高和GPU利用率低。现有推测解码方法仍然依赖自回归草稿模型，限制了实际加速效果。扩散模型虽然支持并行生成，但性能通常不如自回归模型。

Method: DFlash采用轻量级块扩散模型进行并行草稿生成，通过单次前向传递生成草稿token，并利用从目标模型中提取的上下文特征来条件化草稿模型，实现高质量输出和高接受率。

Result: 实验表明，DFlash在各种模型和任务上实现了超过6倍的无损加速，比当前最先进的推测解码方法EAGLE-3快2.5倍。

Conclusion: DFlash通过结合扩散模型的并行生成能力和推测解码框架，有效解决了自回归解码的瓶颈，实现了显著的速度提升，同时保持输出质量。

Abstract: Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation, but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates. Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [60] [Signal or 'Noise': Human Reactions to Robot Errors in the Wild](https://arxiv.org/abs/2602.05010)
*Maia Stiber,Sameer Khan,Russell Taylor,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 研究探索了在真实世界咖啡机器人部署中，人们对机器人错误的社交反应，发现参与者会表达丰富但"嘈杂"的社交信号，特别是在群体互动中。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器人经常出错，但人们对机器人错误的社会反应在实验室外了解甚少。先前研究表明社交信号在受限互动中对错误管理可靠有用，但不确定这在真实世界是否成立，特别是在非社交机器人、重复互动、群体互动以及连续或传播错误的情况下。

Method: 构建了一个咖啡机器人，在公共场所进行实地部署（N=49），观察参与者在机器人出错和其他刺激下的社交信号表达。

Result: 参与者对错误和其他刺激一致表达多样化的社交信号，特别是在群体互动中。真实世界的社交信号丰富（参与者自愿提供互动信息）但"嘈杂"。

Conclusion: 讨论了在真实世界人机交互中使用社交信号的教训、益处和挑战，表明社交信号在现实环境中具有价值但需要处理其复杂性。

Abstract: In the real world, robots frequently make errors, yet little is known about people's social responses to errors outside of lab settings. Prior work has shown that social signals are reliable and useful for error management in constrained interactions, but it is unclear if this holds in the real world - especially with a non-social robot in repeated and group interactions with successive or propagated errors. To explore this, we built a coffee robot and conducted a public field deployment ($N = 49$). We found that participants consistently expressed varied social signals in response to errors and other stimuli, particularly during group interactions. Our findings suggest that social signals in the wild are rich (with participants volunteering information about the interaction), but "noisy." We discuss lessons, benefits, and challenges for using social signals in real-world HRI.

</details>


### [61] [Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping](https://arxiv.org/abs/2602.05029)
*Octavio Arriaga,Proneet Sharma,Jichen Guo,Marc Otto,Siddhant Kadwe,Rebecca Adam*

Main category: cs.RO

TL;DR: 提出一种可微分神经图形模型，结合神经基础模型与基于物理的可微分渲染，实现零样本场景重建与机器人抓取，无需额外3D数据或测试时采样。


<details>
  <summary>Details</summary>
Motivation: 机器人在新环境中需要估计和交互未见物体，现有方法依赖大量训练数据和测试时采样构建黑盒场景表示，缺乏数据效率和可解释性。

Method: 结合神经基础模型与物理可微分渲染，通过约束优化问题估计物理一致的场景参数（网格、光照、材质、6D位姿），仅需单张RGBD图像和边界框。

Result: 在标准无模型少样本基准测试中超越现有算法；通过零样本抓取任务验证了场景重建的准确性。

Conclusion: 该方法实现了零样本、物理一致的场景重建与抓取，无需大量数据集或测试时采样，为更数据高效、可解释、可泛化的机器人自主性提供了途径。

Abstract: Operating effectively in novel real-world environments requires robotic systems to estimate and interact with previously unseen objects. Current state-of-the-art models address this challenge by using large amounts of training data and test-time samples to build black-box scene representations. In this work, we introduce a differentiable neuro-graphics model that combines neural foundation models with physics-based differentiable rendering to perform zero-shot scene reconstruction and robot grasping without relying on any additional 3D data or test-time samples. Our model solves a series of constrained optimization problems to estimate physically consistent scene parameters, such as meshes, lighting conditions, material properties, and 6D poses of previously unseen objects from a single RGBD image and bounding boxes. We evaluated our approach on standard model-free few-shot benchmarks and demonstrated that it outperforms existing algorithms for model-free few-shot pose estimation. Furthermore, we validated the accuracy of our scene reconstructions by applying our algorithm to a zero-shot grasping task. By enabling zero-shot, physically-consistent scene reconstruction and grasping without reliance on extensive datasets or test-time sampling, our approach offers a pathway towards more data efficient, interpretable and generalizable robot autonomy in novel environments.

</details>


### [62] [Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking](https://arxiv.org/abs/2602.05079)
*Vinal Asodia,Iman Sharifi,Saber Fallah*

Main category: cs.RO

TL;DR: 提出神经符号特征表示和软一阶逻辑奖励函数，提升自动驾驶强化学习的上下文感知和价值对齐决策能力


<details>
  <summary>Details</summary>
Motivation: 现有基于摄像头的深度强化学习方法存在两个问题：很少将高层场景上下文整合到特征表示中，以及依赖僵化的固定奖励函数。需要更全面的特征表示和更灵活的奖励机制来提升自动驾驶的安全性和鲁棒性。

Method: 1) 提出神经符号特征表示，包含语义、空间、形状信息以及动态实体的空间增强特征；2) 提出软一阶逻辑(SFOL)奖励函数，通过符号推理模块平衡人类价值观，从分割图中提取语义和空间谓词，应用于语言规则以获得奖励权重。

Result: 在CARLA仿真环境中的定量实验表明，与基线方法相比，提出的神经符号表示和SFOL奖励函数在不同交通密度和遮挡水平下，提高了策略鲁棒性和安全相关性能指标。

Conclusion: 将整体表示和软推理整合到强化学习中，可以支持自动驾驶中更具上下文感知和价值对齐的决策制定，证明了神经符号方法和灵活奖励机制的有效性。

Abstract: The problem with existing camera-based Deep Reinforcement Learning approaches is twofold: they rarely integrate high-level scene context into the feature representation, and they rely on rigid, fixed reward functions. To address these challenges, this paper proposes a novel pipeline that produces a neuro-symbolic feature representation that encompasses semantic, spatial, and shape information, as well as spatially boosted features of dynamic entities in the scene, with an emphasis on safety-critical road users. It also proposes a Soft First-Order Logic (SFOL) reward function that balances human values via a symbolic reasoning module. Here, semantic and spatial predicates are extracted from segmentation maps and applied to linguistic rules to obtain reward weights. Quantitative experiments in the CARLA simulation environment show that the proposed neuro-symbolic representation and SFOL reward function improved policy robustness and safety-related performance metrics compared to baseline representations and reward formulations across varying traffic densities and occlusion levels. The findings demonstrate that integrating holistic representations and soft reasoning into Reinforcement Learning can support more context-aware and value-aligned decision-making for autonomous driving.

</details>


### [63] [A Framework for Combining Optimization-Based and Analytic Inverse Kinematics](https://arxiv.org/abs/2602.05092)
*Thomas Cohn,Lihan Tang,Alexandre Amice,Russ Tedrake*

Main category: cs.RO

TL;DR: 提出一种新的优化逆运动学方法，通过解析解作为变量变换，使优化器更容易求解，在碰撞避免、抓取选择和仿人机器人稳定性等挑战性问题上获得更高成功率。


<details>
  <summary>Details</summary>
Motivation: 传统优化逆运动学方法在处理关节角度与末端执行器位姿之间的复杂非线性关系时，特别是与碰撞避免等非凸约束同时处理时，失败率较高。需要结合解析法和优化法的优势。

Method: 提出新的优化逆运动学公式，使用解析逆运动学解作为变量变换，从根本上简化优化问题的求解难度。在三种主流的约束非线性优化求解器上进行测试。

Result: 广泛的实验比较表明，新公式在碰撞避免、抓取选择和仿人机器人稳定性等各种挑战性逆运动学问题上，比旧公式和基线方法获得更高的成功率。

Conclusion: 通过将解析逆运动学解作为变量变换，提出的新优化逆运动学公式能够更好地结合解析法和优化法的优势，有效提高复杂约束条件下的求解成功率。

Abstract: Analytic and optimization methods for solving inverse kinematics (IK) problems have been deeply studied throughout the history of robotics. The two strategies have complementary strengths and weaknesses, but developing a unified approach to take advantage of both methods has proved challenging. A key challenge faced by optimization approaches is the complicated nonlinear relationship between the joint angles and the end-effector pose. When this must be handled concurrently with additional nonconvex constraints like collision avoidance, optimization IK algorithms may suffer high failure rates. We present a new formulation for optimization IK that uses an analytic IK solution as a change of variables, and is fundamentally easier for optimizers to solve. We test our methodology on three popular solvers, representing three different paradigms for constrained nonlinear optimization. Extensive experimental comparisons demonstrate that our new formulation achieves higher success rates than the old formulation and baseline methods across various challenging IK problems, including collision avoidance, grasp selection, and humanoid stability.

</details>


### [64] [PLATO Hand: Shaping Contact Behavior with Fingernails for Precise Manipulation](https://arxiv.org/abs/2602.05156)
*Dong Ho Kang,Aaron Kim,Mingyo Seo,Kazuto Yokoyama,Tetsuya Narita,Luis Sentis*

Main category: cs.RO

TL;DR: PLATO Hand是一种灵巧的机器人手，采用混合指尖设计（刚性指甲嵌入柔性指腹），通过结构化接触几何实现多种交互模式，提升了夹持稳定性、力感知能力和边缘敏感操作性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器人手在精确操作中面临接触行为控制困难的问题，特别是在处理不同几何形状物体时，需要一种能够适应多种交互模式的设计方法。

Method: 提出PLATO Hand机器人手设计，采用混合指尖结构（刚性指甲嵌入柔性指腹），开发基于应变能的弯曲-压痕模型指导指尖设计，通过引导接触保持局部压痕同时抑制全局弯曲。

Result: 实验结果显示：1）改进的夹持稳定性；2）增强的力可观测性；3）成功执行边缘敏感操作任务（纸张分离、卡片拾取、橙子剥皮）。

Conclusion: 结构化接触几何与力-运动透明机制的结合，为精确操作提供了一种基于物理原理的实现方法，展示了混合指尖设计在灵巧操作中的优势。

Abstract: We present the PLATO Hand, a dexterous robotic hand with a hybrid fingertip that embeds a rigid fingernail within a compliant pulp. This design shapes contact behavior to enable diverse interaction modes across a range of object geometries. We develop a strain-energy-based bending-indentation model to guide the fingertip design and to explain how guided contact preserves local indentation while suppressing global bending. Experimental results show that the proposed robotic hand design demonstrates improved pinching stability, enhanced force observability, and successful execution of edge-sensitive manipulation tasks, including paper singulation, card picking, and orange peeling. Together, these results show that coupling structured contact geometry with a force-motion transparent mechanism provides a principled, physically embodied approach to precise manipulation.

</details>


### [65] [Informative Path Planning with Guaranteed Estimation Uncertainty](https://arxiv.org/abs/2602.05198)
*Kalvik Jakkala,Saurav Agarwal,Jason O'Kane,Srinivas Akella*

Main category: cs.RO

TL;DR: 该论文提出了一种具有保证估计不确定性的信息路径规划方法，通过高斯过程模型和最短路径规划，确保监测区域内后验方差低于用户指定阈值。


<details>
  <summary>Details</summary>
Motivation: 环境监测机器人需要在距离和能量约束下重建空间场。传统的boustrophedon扫描方法提供几何覆盖保证但会过度采样可预测区域，而信息路径规划方法虽能减少过度采样但通常无法保证重建质量。需要一种既能利用空间相关性又能提供重建质量保证的方法。

Method: 采用三阶段方法：1) 从先验信息学习高斯过程模型；2) 将学习到的GP核转换为每个候选传感位置的二进制覆盖图，指示哪些位置的不确定性可以降低到指定目标以下；3) 规划一条接近最短的路径，其组合覆盖满足全局不确定性约束。该方法还包含非平稳核处理异质现象，并适应具有障碍物的非凸环境。

Result: 在真实地形数据上的实验表明，该规划器使用比基线更少的传感位置和更短的旅行距离就能满足不确定性目标。自主水面和水下航行器的现场测深实验证明了实际可行性。

Conclusion: 该方法成功地将经典覆盖方法与信息路径规划相结合，提供了具有保证估计不确定性的路径规划，在满足重建质量要求的同时优化了资源使用，为环境监测机器人提供了实用的解决方案。

Abstract: Environmental monitoring robots often need to reconstruct spatial fields (e.g., salinity, temperature, bathymetry) under tight distance and energy constraints. Classical boustrophedon lawnmower surveys provide geometric coverage guarantees but can waste effort by oversampling predictable regions. In contrast, informative path planning (IPP) methods leverage spatial correlations to reduce oversampling, yet typically offer no guarantees on reconstruction quality. This paper bridges these approaches by addressing informative path planning with guaranteed estimation uncertainty: computing the shortest path whose measurements ensure that the Gaussian-process (GP) posterior variance -- an intrinsic uncertainty measure that lower-bounds the mean-squared prediction error under the GP model -- falls below a user-specified threshold over the monitoring region.
  We propose a three-stage approach: (i) learn a GP model from available prior information; (ii) transform the learned GP kernel into binary coverage maps for each candidate sensing location, indicating which locations' uncertainty can be reduced below a specified target; and (iii) plan a near-shortest route whose combined coverage satisfies the global uncertainty constraint. To address heterogeneous phenomena, we incorporate a nonstationary kernel that captures spatially varying correlation structure, and we accommodate non-convex environments with obstacles. Algorithmically, we present methods with provable approximation guarantees for sensing-location selection and for the joint selection-and-routing problem under a travel budget. Experiments on real-world topographic data show that our planners meet the uncertainty target using fewer sensing locations and shorter travel distances than a recent baseline, and field experiments with bathymetry-mapping autonomous surface and underwater vehicles demonstrate real-world feasibility.

</details>


### [66] [MobileManiBench: Simplifying Model Verification for Mobile Manipulation](https://arxiv.org/abs/2602.05233)
*Wenbo Wang,Fangyun Wei,QiXiu Li,Xi Chen,Yaobo Liang,Chang Xu,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: 提出MobileManiBench大规模移动机器人操作基准，基于仿真优先框架验证VLA架构，包含300K轨迹数据，支持机器人本体、感知模态和策略架构的可控研究。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型依赖静态桌面场景的遥操作数据集，限制了移动机器人操作能力的发展，需要更全面的仿真基准来验证VLA架构。

Method: 基于NVIDIA Isaac Sim构建仿真优先框架，使用强化学习自动生成多样化操作轨迹，包含丰富的标注信息（语言指令、多视角RGB-D分割图像、同步状态和动作）。

Result: 创建了包含2种移动平台、630个物体、20个类别、5种技能、100个任务、100个场景的基准，生成了300K轨迹数据，并对代表性VLA模型进行了基准测试。

Conclusion: MobileManiBench为移动机器人操作提供了可控、可扩展的研究平台，加速了数据效率和泛化能力的研究，为复杂仿真环境中的感知、推理和控制提供了新见解。

Abstract: Vision-language-action models have advanced robotic manipulation but remain constrained by reliance on the large, teleoperation-collected datasets dominated by the static, tabletop scenes. We propose a simulation-first framework to verify VLA architectures before real-world deployment and introduce MobileManiBench, a large-scale benchmark for mobile-based robotic manipulation. Built on NVIDIA Isaac Sim and powered by reinforcement learning, our pipeline autonomously generates diverse manipulation trajectories with rich annotations (language instructions, multi-view RGB-depth-segmentation images, synchronized object/robot states and actions). MobileManiBench features 2 mobile platforms (parallel-gripper and dexterous-hand robots), 2 synchronized cameras (head and right wrist), 630 objects in 20 categories, 5 skills (open, close, pull, push, pick) with over 100 tasks performed in 100 realistic scenes, yielding 300K trajectories. This design enables controlled, scalable studies of robot embodiments, sensing modalities, and policy architectures, accelerating research on data efficiency and generalization. We benchmark representative VLA models and report insights into perception, reasoning, and control in complex simulated environments.

</details>


### [67] [Low-Cost Underwater In-Pipe Centering and Inspection Using a Minimal-Sensing Robot](https://arxiv.org/abs/2602.05265)
*Kalvik Jakkala,Jason O'Kane*

Main category: cs.RO

TL;DR: 水下机器人仅用IMU、压力传感器和两个声纳实现管道自主巡检，无需复杂传感器阵列或外部定位


<details>
  <summary>Details</summary>
Motivation: 水下管道巡检面临几何空间受限、水体浑浊、定位信息稀缺等挑战，需要开发轻量级、计算高效的自主导航方案

Method: 使用IMU、压力传感器、下视单波束声纳和旋转360度声纳；提出从单波束声纳强度数据提取距离估计的方法；建立闭式几何模型利用两个声纳距离估计管道中心；采用自适应置信度加权PD控制器保持对中

Result: 在46厘米直径淹没管道中使用BlueROV2进行实验，成功实现稳定对中和完整管道穿越，即使在环境水流和结构变形条件下也能正常工作

Conclusion: 轻量级、计算高效的传感处理架构可实现可靠的水下管道自主巡检，提升了受限环境中自主水下检查的实用性

Abstract: Autonomous underwater inspection of submerged pipelines is challenging due to confined geometries, turbidity, and the scarcity of reliable localization cues. This paper presents a minimal-sensing strategy that enables a free-swimming underwater robot to center itself and traverse a flooded pipe of known radius using only an IMU, a pressure sensor, and two sonars: a downward-facing single-beam sonar and a rotating 360 degree sonar. We introduce a computationally efficient method for extracting range estimates from single-beam sonar intensity data, enabling reliable wall detection in noisy and reverberant conditions. A closed-form geometric model leverages the two sonar ranges to estimate the pipe center, and an adaptive, confidence-weighted proportional-derivative (PD) controller maintains alignment during traversal. The system requires no Doppler velocity log, external tracking, or complex multi-sensor arrays. Experiments in a submerged 46 cm-diameter pipe using a Blue Robotics BlueROV2 heavy remotely operated vehicle demonstrate stable centering and successful full-pipe traversal despite ambient flow and structural deformations. These results show that reliable in-pipe navigation and inspection can be achieved with a lightweight, computationally efficient sensing and processing architecture, advancing the practicality of autonomous underwater inspection in confined environments.

</details>


### [68] [Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions](https://arxiv.org/abs/2602.05273)
*Hengxuan Xu,Fengbo Lan,Zhixin Zhao,Shengjie Wang,Mengqiao Liu,Jieqian Sun,Yu Cheng,Tao Zhang*

Main category: cs.RO

TL;DR: AIDE：一个双流框架，通过交互式探索与视觉语言推理结合，解决机器人在模糊指令下识别任务相关物体的问题，实现零样本可供性分析和实时任务执行。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的方法在模糊人类指令下（如"我渴了"需要识别杯子或饮料）存在推理效率低、缺乏环境交互的问题，阻碍了实时任务规划与执行。

Method: 提出AIDE双流框架：多阶段推理（MSI）作为决策流，加速决策（ADM）作为执行流，集成交互式探索与视觉语言推理，实现零样本可供性分析和模糊指令解释。

Result: 在仿真和真实环境实验中，AIDE达到超过80%的任务规划成功率，在10Hz频率下闭环连续执行准确率超过95%，在多样开放世界场景中优于现有VLM方法。

Conclusion: AIDE通过交互式探索与视觉语言推理的有效结合，显著提升了机器人在模糊指令下的任务理解和执行能力，为开放世界机器人应用提供了可行解决方案。

Abstract: Enabling robots to explore and act in unfamiliar environments under ambiguous human instructions by interactively identifying task-relevant objects (e.g., identifying cups or beverages for "I'm thirsty") remains challenging for existing vision-language model (VLM)-based methods. This challenge stems from inefficient reasoning and the lack of environmental interaction, which hinder real-time task planning and execution. To address this, We propose Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions (AIDE), a dual-stream framework that integrates interactive exploration with vision-language reasoning, where Multi-Stage Inference (MSI) serves as the decision-making stream and Accelerated Decision-Making (ADM) as the execution stream, enabling zero-shot affordance analysis and interpretation of ambiguous instructions. Extensive experiments in simulation and real-world environments show that AIDE achieves the task planning success rate of over 80\% and more than 95\% accuracy in closed-loop continuous execution at 10 Hz, outperforming existing VLM-based methods in diverse open-world scenarios.

</details>


### [69] [Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework](https://arxiv.org/abs/2602.05310)
*Jipeng Kong,Xinzhe Liu,Yuhang Lin,Jinrui Han,Sören Schwertfeger,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: PAiD提出了一种渐进式架构，将人形机器人足球技能学习分解为三个阶段：通过人体运动跟踪获取运动技能、轻量级感知-动作集成实现位置泛化、物理感知的仿真到现实迁移，从而解决现有方法中模块间不稳定或训练目标冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 足球对人形机器人提出了重大挑战，需要紧密集成的感知-动作能力。现有方法存在模块化管道中模块间不稳定的问题，或者端到端框架中训练目标冲突的问题。

Method: 提出感知-动作集成决策（PAiD）架构，将足球技能获取分解为三个阶段：1）通过人体运动跟踪获取运动技能；2）轻量级感知-动作集成实现位置泛化；3）物理感知的仿真到现实迁移。

Result: 在Unitree G1机器人上的实验展示了高保真的人形踢球能力，在静态或滚动球、不同位置和干扰等多种条件下表现出鲁棒性能，并在室内外场景中保持一致的执行效果。

Conclusion: 这种分而治之的策略推进了鲁棒的人形足球能力，并为复杂的具身技能获取提供了一个可扩展的框架。

Abstract: Soccer presents a significant challenge for humanoid robots, demanding tightly integrated perception-action capabilities for tasks like perception-guided kicking and whole-body balance control. Existing approaches suffer from inter-module instability in modular pipelines or conflicting training objectives in end-to-end frameworks. We propose Perception-Action integrated Decision-making (PAiD), a progressive architecture that decomposes soccer skill acquisition into three stages: motion-skill acquisition via human motion tracking, lightweight perception-action integration for positional generalization, and physics-aware sim-to-real transfer. This staged decomposition establishes stable foundational skills, avoids reward conflicts during perception integration, and minimizes sim-to-real gaps. Experiments on the Unitree G1 demonstrate high-fidelity human-like kicking with robust performance under diverse conditions-including static or rolling balls, various positions, and disturbances-while maintaining consistent execution across indoor and outdoor scenarios. Our divide-and-conquer strategy advances robust humanoid soccer capabilities and offers a scalable framework for complex embodied skill acquisition. The project page is available at https://soccer-humanoid.github.io/.

</details>


### [70] [RoboPaint: From Human Demonstration to Any Robot and Any View](https://arxiv.org/abs/2602.05325)
*Jiacheng Fan,Zhiyue Zhao,Yiqian Zhang,Chao Chen,Peide Wang,Hengdi Zhang,Zhengxue Cheng*

Main category: cs.RO

TL;DR: 提出Real-Sim-Real数据收集与编辑流程，将人类演示转化为机器人可执行的训练数据，无需直接遥操作，用于扩展视觉-语言-动作模型在灵巧操作中的应用。


<details>
  <summary>Details</summary>
Motivation: 获取大规模、高保真度的机器人演示数据是扩展视觉-语言-动作模型在灵巧操作中应用的关键瓶颈。传统遥操作方法成本高、可扩展性差。

Method: 1) 建立标准化数据采集室，捕获多模态人类演示数据；2) 提出触觉感知的重定向方法，通过几何和力引导优化将人手状态映射到机器人灵巧手状态；3) 在逼真的Isaac Sim环境中渲染重定向后的机器人轨迹生成训练数据。

Result: 1) 重定向的灵巧手轨迹在10个多样化物体操作任务中达到84%成功率；2) 仅使用生成数据训练的VLA策略(Pi0.5)在三个代表性任务(拾取放置、推、倾倒)上达到80%平均成功率。

Conclusion: 通过Real-Sim-Real数据流程，可以从人类演示中高效"绘制"机器人训练数据，为复杂灵巧操作提供可扩展、经济高效的遥操作替代方案，性能损失最小。

Abstract: Acquiring large-scale, high-fidelity robot demonstration data remains a critical bottleneck for scaling Vision-Language-Action (VLA) models in dexterous manipulation. We propose a Real-Sim-Real data collection and data editing pipeline that transforms human demonstrations into robot-executable, environment-specific training data without direct robot teleoperation. Standardized data collection rooms are built to capture multimodal human demonstrations (synchronized 3 RGB-D videos, 11 RGB videos, 29-DoF glove joint angles, and 14-channel tactile signals). Based on these human demonstrations, we introduce a tactile-aware retargeting method that maps human hand states to robot dex-hand states via geometry and force-guided optimization. Then the retargeted robot trajectories are rendered in a photorealistic Isaac Sim environment to build robot training data. Real world experiments have demonstrated: (1) The retargeted dex-hand trajectories achieve an 84\% success rate across 10 diverse object manipulation tasks. (2) VLA policies (Pi0.5) trained exclusively on our generated data achieve 80\% average success rate on three representative tasks, i.e., pick-and-place, pushing and pouring. To conclude, robot training data can be efficiently "painted" from human demonstrations using our real-sim-real data pipeline. We offer a scalable, cost-effective alternative to teleoperation with minimal performance loss for complex dexterous manipulation.

</details>


### [71] [Benchmarking Affordance Generalization with BusyBox](https://arxiv.org/abs/2602.05441)
*Dean Fortier,Timothy Adamson,Tess Hellebrekers,Teresa LaScala,Kofi Ennin,Michael Murray,Andrey Kolobov,Galen Mullins*

Main category: cs.RO

TL;DR: BusyBox是一个用于评估视觉-语言-动作模型物理泛化能力的基准测试平台，包含6个可互换模块，通过3D打印和开源设计促进社区研究。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在视觉和语言泛化方面已有进展，但缺乏对物理操作泛化能力（affordance generalization）的系统评估方法，即模型能否操纵具有熟悉物理特征的新物体。

Method: 设计了BusyBox物理基准平台，包含开关、滑块、电线、按钮、显示屏和旋钮6个模块，这些模块可互换和旋转以创建多种变体，同时保持相同的物理操作特性。平台设计易于在机器人实验室中构建，并发布了完整的CAD文件、材料清单和演示数据集。

Result: 实验表明，即使对于强大的开源VLA模型如π₀.₅和GR00T-N1.6，在BusyBox变体间的泛化仍然极具挑战性，验证了该基准的有效性。

Conclusion: BusyBox为VLA模型的物理操作泛化能力评估提供了系统化的半自动测试平台，通过开源设计促进社区研究，有助于推动VLA模型在实际物理环境中的泛化能力发展。

Abstract: Vision-Language-Action (VLA) models have been attracting the attention of researchers and practitioners thanks to their promise of generalization. Although single-task policies still offer competitive performance, VLAs are increasingly able to handle commands and environments unseen in their training set. While generalization in vision and language space is undoubtedly important for robust versatile behaviors, a key meta-skill VLAs need to possess is affordance generalization -- the ability to manipulate new objects with familiar physical features.
  In this work, we present BusyBox, a physical benchmark for systematic semi-automatic evaluation of VLAs' affordance generalization. BusyBox consists of 6 modules with switches, sliders, wires, buttons, a display, and a dial. The modules can be swapped and rotated to create a multitude of BusyBox variations with different visual appearances but the same set of affordances. We empirically demonstrate that generalization across BusyBox variants is highly challenging even for strong open-weights VLAs such as $π_{0.5}$ and GR00T-N1.6. To encourage the research community to evaluate their own VLAs on BusyBox and to propose new affordance generalization experiments, we have designed BusyBox to be easy to build in most robotics labs. We release the full set of CAD files for 3D-printing its parts as well as a bill of materials for (optionally) assembling its electronics. We also publish a dataset of language-annotated demonstrations that we collected using the common bimanual Mobile Aloha robot on the canonical BusyBox configuration. All of the released materials are available at https://microsoft.github.io/BusyBox.

</details>


### [72] [Ontology-Driven Robotic Specification Synthesis](https://arxiv.org/abs/2602.05456)
*Maksym Figat,Ryan M. Mackey,Michel D. Ingham*

Main category: cs.RO

TL;DR: 提出RSTM2方法，通过本体驱动的分层随机时间Petri网，将高层任务目标转化为可执行的形式化规范，支持机器人系统的蒙特卡洛仿真和架构权衡分析。


<details>
  <summary>Details</summary>
Motivation: 解决安全关键和任务关键机器人应用中，高层目标与可执行形式化规范之间的鸿沟，为复杂多机器人系统（如NASA CADRE任务）提供系统工程技术支持。

Method: RSTM2（机器人系统任务到模型转换方法），基于本体驱动的分层方法，使用带资源的随机时间Petri网，支持任务、系统和子系统层面的蒙特卡洛仿真。

Result: 通过假设案例研究展示了RSTM2方法如何支持架构权衡、资源分配和不确定性下的性能分析，本体概念还支持可解释AI助手实现完全自主的规范合成。

Conclusion: 该方法特别适用于复杂多机器人系统，代表了未来去中心化、资源感知和自适应自主系统的发展方向，为NASA CADRE等任务提供重要工程支持。

Abstract: This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchical approach using stochastic timed Petri nets with resources, enabling Monte Carlo simulations at mission, system, and subsystem levels. A hypothetical case study demonstrates how the RSTM2 method supports architectural trades, resource allocation, and performance analysis under uncertainty. Ontological concepts further enable explainable AI-based assistants, facilitating fully autonomous specification synthesis. The methodology offers particular benefits to complex multi-robot systems, such as the NASA CADRE mission, representing decentralized, resource-aware, and adaptive autonomous systems of the future.

</details>


### [73] [TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation](https://arxiv.org/abs/2602.05468)
*Pranav Ponnivalavan,Satoshi Funabashi,Alexander Schmitz,Tetsuya Ogata,Shigeki Sugano*

Main category: cs.RO

TL;DR: 提出TaSA框架，通过两阶段深度预测学习解决机器人手自接触感知问题，实现精细操作


<details>
  <summary>Details</summary>
Motivation: 人类能够通过感觉衰减机制区分自接触和外部接触的触觉信号，而现有机器人方法通常忽略自接触或避免自接触，限制了在真实场景中的泛化能力

Method: TaSA两阶段深度预测学习框架：第一阶段学习自接触动力学模型，预测机器人自身动作产生的触觉反馈；第二阶段将学习模型整合到运动学习中，突出物体接触信号

Result: 在铅笔芯插入自动铅笔、硬币插入槽口、回形针固定在纸张等精细操作任务中，TaSA训练的策略相比基线方法显著提高了成功率

Conclusion: 基于感觉衰减的结构化触觉感知对于灵巧机器人操作至关重要，TaSA框架通过区分自接触和外部接触信号，实现了精细的触觉辨别能力

Abstract: Humans can achieve diverse in-hand manipulations, such as object pinching and tool use, which often involve simultaneous contact between the object and multiple fingers. This is still an open issue for robotic hands because such dexterous manipulation requires distinguishing between tactile sensations generated by their self-contact and those arising from external contact. Otherwise, object/robot breakage happens due to contacts/collisions. Indeed, most approaches ignore self-contact altogether, by constraining motion to avoid/ignore self-tactile information during contact. While this reduces complexity, it also limits generalization to real-world scenarios where self-contact is inevitable. Humans overcome this challenge through self-touch perception, using predictive mechanisms that anticipate the tactile consequences of their own motion, through a principle called sensory attenuation, where the nervous system differentiates predictable self-touch signals, allowing novel object stimuli to stand out as relevant. Deriving from this, we introduce TaSA, a two-phased deep predictive learning framework. In the first phase, TaSA explicitly learns self-touch dynamics, modeling how a robot's own actions generate tactile feedback. In the second phase, this learned model is incorporated into the motion learning phase, to emphasize object contact signals during manipulation. We evaluate TaSA on a set of insertion tasks, which demand fine tactile discrimination: inserting a pencil lead into a mechanical pencil, inserting coins into a slot, and fixing a paper clip onto a sheet of paper, with various orientations, positions, and sizes. Across all tasks, policies trained with TaSA achieve significantly higher success rates than baseline methods, demonstrating that structured tactile perception with self-touch based on sensory attenuation is critical for dexterous robotic manipulation.

</details>


### [74] [DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter](https://arxiv.org/abs/2602.05513)
*Xukun Li,Yu Sun,Lei Zhang,Bosheng Huang,Yibo Peng,Yuan Meng,Haojun Jiang,Shaoxuan Xie,Guacai Yao,Alois Knoll,Zhenshan Bing,Xinlong Wang,Zhenguo Sun*

Main category: cs.RO

TL;DR: DECO是一个基于DiT的策略框架，通过解耦多模态条件来实现灵巧操作，并附带包含触觉感知的双手机器人数据集DECO-50。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人策略在处理多模态输入（图像、动作、本体感知、触觉等）时存在耦合问题，需要一种能够有效整合多种感知信息并实现灵巧操作的框架。

Method: DECO采用DiT架构，通过联合自注意力处理图像和动作token，通过自适应层归一化注入本体感知状态和可选条件，通过交叉注意力注入触觉信号，并使用轻量级LoRA适配器微调预训练策略。

Result: 开发了DECO-50数据集，包含4个场景、28个子任务、超过50小时数据、约500万帧和8000条成功轨迹的双手机器人灵巧操作数据集。

Conclusion: DECO提供了一个解耦多模态条件的DiT策略框架，配合大规模触觉感知数据集，为机器人灵巧操作研究提供了重要工具。

Abstract: Overview of the Proposed DECO Framework.} DECO is a DiT-based policy that decouples multimodal conditioning. Image and action tokens interact via joint self attention, while proprioceptive states and optional conditions are injected through adaptive layer normalization. Tactile signals are injected via cross attention, while a lightweight LoRA-based adapter is used to efficiently fine-tune the pretrained policy. DECO is also accompanied by DECO-50, a bimanual dexterous manipulation dataset with tactile sensing, consisting of 4 scenarios and 28 sub-tasks, covering more than 50 hours of data, approximately 5 million frames, and 8,000 successful trajectories.

</details>


### [75] [Virtual-Tube-Based Cooperative Transport Control for Multi-UAV Systems in Constrained Environments](https://arxiv.org/abs/2602.05516)
*Runxiao Liu,Pengda Mao,Xiangli Le,Shuang Gu,Yapeng Chen,Quan Quan*

Main category: cs.RO

TL;DR: 提出基于虚拟管道理论和耗散系统理论的多无人机协同运输框架，用于受限环境中电缆悬挂负载的运输，具有低计算开销、高稳定性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决多无人机在受限环境中协同运输电缆悬挂负载的挑战，需要高效导航、张力分配和系统稳定性。

Method: 结合虚拟管道理论和耗散系统理论，设计动态适应障碍物布局的无人机配置调整机制，实现低计算开销的张力分配和协调运输。

Result: 通过大量仿真验证了方法的有效性，展示了大规模多无人机系统的可扩展性，并在室外场景中实验验证了实际可行性和鲁棒性。

Conclusion: 该框架为受限环境中多无人机协同运输提供了高效、稳定且鲁棒的解决方案，具有实际应用价值。

Abstract: This paper proposes a novel control framework for cooperative transportation of cable-suspended loads by multiple unmanned aerial vehicles (UAVs) operating in constrained environments. Leveraging virtual tube theory and principles from dissipative systems theory, the framework facilitates efficient multi-UAV collaboration for navigating obstacle-rich areas. The proposed framework offers several key advantages. (1) It achieves tension distribution and coordinated transportation within the UAV-cable-load system with low computational overhead, dynamically adapting UAV configurations based on obstacle layouts to facilitate efficient navigation. (2) By integrating dissipative systems theory, the framework ensures high stability and robustness, essential for complex multi-UAV operations. The effectiveness of the proposed approach is validated through extensive simulations, demonstrating its scalability for large-scale multi-UAV systems. Furthermore, the method is experimentally validated in outdoor scenarios, showcasing its practical feasibility and robustness under real-world conditions.

</details>


### [76] [VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator](https://arxiv.org/abs/2602.05552)
*Bessie Dominguez-Dager,Sergio Suescun-Ferrandiz,Felix Escalona,Francisco Gomez-Donoso,Miguel Cazorla*

Main category: cs.RO

TL;DR: VLN-Pilot是一个使用大型视觉语言模型作为室内无人机导航"飞行员"的新框架，通过自然语言指令和视觉感知实现自主导航，无需GPS。


<details>
  <summary>Details</summary>
Motivation: 传统室内无人机导航依赖基于规则或几何的路径规划，需要大量任务特定工程。本文旨在利用VLLM的多模态推理能力，实现更自然、语义理解驱动的自主导航，减少操作员工作量并提高安全性。

Method: VLN-Pilot框架让大型视觉语言模型充当无人机飞行员，通过解释自由形式的自然语言指令，并将其与视觉观察相结合，来规划和执行无人机轨迹。框架集成了语言驱动的语义理解和视觉感知，支持空间关系推理、避障和对意外事件的动态响应。

Result: 在定制的逼真室内仿真基准测试中，VLLM驱动的智能体在复杂指令跟随任务上取得了高成功率，包括具有多个语义目标的长期导航。结果表明语言引导的自主代理可以替代远程无人机飞行员。

Conclusion: VLLM为基础的飞行员可以显著减少操作员工作量，同时在受限室内环境中提高安全性和任务灵活性，为检查、搜救、设施监控等任务的可扩展、人性化室内无人机控制开辟了新途径。

Abstract: This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.

</details>


### [77] [TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards](https://arxiv.org/abs/2602.05596)
*Hokyun Lee,Woo-Jeong Baek,Junhyeok Cha,Jaeheung Park*

Main category: cs.RO

TL;DR: TOLEBI：首个基于学习的双足机器人容错框架，通过模拟关节锁定、断电和外部扰动来学习容错步态策略，结合在线关节状态模块实现实时故障分类。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在双足步态研究中取得了高成功率，但很少关注硬件故障处理。现实环境中，环境扰动或突发硬件故障可能导致严重后果，因此需要开发能够处理运行时故障的方法。

Method: 提出TOLEBI框架：1）在模拟中注入关节锁定、断电和外部扰动来学习容错步态策略；2）通过仿真到现实的迁移将策略应用到真实机器人；3）集成在线关节状态模块，根据实际观测实时分类关节状态。

Result: 在真实世界和模拟环境中使用TOCABI人形机器人进行验证实验，证明了所提方法的适用性。这是首个基于学习的双足步态容错框架。

Conclusion: 该论文提出了首个学习型双足步态容错框架TOLEBI，能够处理运行时硬件故障，促进了该领域高效学习方法的发展。

Abstract: With the growing employment of learning algorithms in robotic applications, research on reinforcement learning for bipedal locomotion has become a central topic for humanoid robotics. While recently published contributions achieve high success rates in locomotion tasks, scarce attention has been devoted to the development of methods that enable to handle hardware faults that may occur during the locomotion process. However, in real-world settings, environmental disturbances or sudden occurrences of hardware faults might yield severe consequences. To address these issues, this paper presents TOLEBI (A faulT-tOlerant Learning framEwork for Bipedal locomotIon) that handles faults on the robot during operation. Specifically, joint locking, power loss and external disturbances are injected in simulation to learn fault-tolerant locomotion strategies. In addition to transferring the learned policy to the real robot via sim-to-real transfer, an online joint status module incorporated. This module enables to classify joint conditions by referring to the actual observations at runtime under real-world conditions. The validation experiments conducted both in real-world and simulation with the humanoid robot TOCABI highlight the applicability of the proposed approach. To our knowledge, this manuscript provides the first learning-based fault-tolerant framework for bipedal locomotion, thereby fostering the development of efficient learning methods in this field.

</details>


### [78] [HiCrowd: Hierarchical Crowd Flow Alignment for Dense Human Environments](https://arxiv.org/abs/2602.05608)
*Yufei Zhu,Shih-Min Yang,Martin Magnusson,Allan Wang*

Main category: cs.RO

TL;DR: HiCrowd：分层框架结合强化学习和模型预测控制，利用行人运动作为引导，解决机器人在密集人群中的冻结问题


<details>
  <summary>Details</summary>
Motivation: 解决机器人在密集人群中的"冻结机器人问题"——机器人难以找到安全运动路径而被困在人群中。传统方法将行人视为动态障碍物，而本文提出利用行人运动作为引导的新思路

Method: 提出HiCrowd分层框架：高层RL策略生成跟随点，使机器人对齐到合适的行人群体；低层MPC安全跟踪该引导，进行短期规划。结合长期人群感知决策与安全短期执行

Result: 在真实世界数据集和合成人群数据集上的实验表明，HiCrowd在导航效率和安全性方面优于反应式和基于学习的基线方法，显著减少了冻结行为

Conclusion: 利用人类运动作为引导而非仅视为动态障碍物，为机器人在人群中的安全高效导航提供了有力原则。分层RL-MPC框架有效解决了冻结机器人问题

Abstract: Navigating through dense human crowds remains a significant challenge for mobile robots. A key issue is the freezing robot problem, where the robot struggles to find safe motions and becomes stuck within the crowd. To address this, we propose HiCrowd, a hierarchical framework that integrates reinforcement learning (RL) with model predictive control (MPC). HiCrowd leverages surrounding pedestrian motion as guidance, enabling the robot to align with compatible crowd flows. A high-level RL policy generates a follow point to align the robot with a suitable pedestrian group, while a low-level MPC safely tracks this guidance with short horizon planning. The method combines long-term crowd aware decision making with safe short-term execution. We evaluate HiCrowd against reactive and learning-based baselines in offline setting (replaying recorded human trajectories) and online setting (human trajectories are updated to react to the robot in simulation). Experiments on a real-world dataset and a synthetic crowd dataset show that our method outperforms in navigation efficiency and safety, while reducing freezing behaviors. Our results suggest that leveraging human motion as guidance, rather than treating humans solely as dynamic obstacles, provides a powerful principle for safe and efficient robot navigation in crowds.

</details>


### [79] [From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking](https://arxiv.org/abs/2602.05683)
*Chuwei Wang,Eduardo Sebastián,Amanda Prorok,Anastasia Bizyaeva*

Main category: cs.RO

TL;DR: 提出一种简约的神经形态控制框架，用于视觉引导导航和跟踪，通过动态神经元群体将视觉目标刺激直接转换为自我中心运动指令，利用动态分岔机制解决决策困境。


<details>
  <summary>Details</summary>
Motivation: 机器人导航长期面临反应式传感器控制与基于模型规划器决策能力之间的冲突。当目标之间缺乏主导选项导致决策困境时，反应式系统难以在不依赖计算密集型规划器的情况下打破对称性。

Method: 从机载摄像头获取图像像素，编码为动态神经元群体的输入，直接将视觉目标刺激转换为自我中心运动指令。采用动态分岔机制，延迟决策直到环境几何诱导达到临界点。受动物认知和意见动态机制模型启发，该控制器参数少且可解释。

Result: 在仿真环境和实验四旋翼平台上验证了该方法的有效性，实现了实时自主性，计算负担小，并能与特定应用的图像处理流程无缝集成。

Conclusion: 该神经形态控制框架成功弥合了反应式控制与模型规划之间的鸿沟，为视觉引导导航提供了简约、实时且可解释的解决方案，特别适用于解决决策困境场景。

Abstract: Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.

</details>


### [80] [Task-Oriented Robot-Human Handovers on Legged Manipulators](https://arxiv.org/abs/2602.05760)
*Andreea Tulbure,Carmen Scheidemann,Elias Steiner,Marco Hutter*

Main category: cs.RO

TL;DR: AFT-Handover是一个任务导向的物体交接框架，通过LLM驱动的可操作性推理和基于纹理的可操作性转移，实现零样本、可泛化的机器人-人类物体交接。


<details>
  <summary>Details</summary>
Motivation: 现有任务导向物体交接方法通常基于物体或任务特定的可操作性，但在新场景下的泛化能力有限。需要一种能够处理新颖物体-任务对的通用方法。

Method: 提出AFT-Handover框架：1）从数据库中检索代理示例；2）通过LLM推理建立部件级对应关系；3）纹理化可操作性用于基于特征的点云转移。

Result: 在多样化的任务-物体对上评估显示，相比基线方法提高了交接成功率并增强了泛化能力。用户研究表明，该框架显著优于当前最先进方法，有效减少了人类在使用工具前的重新抓取。

Conclusion: AFT-Handover框架通过集成LLM驱动的可操作性推理和纹理化转移，实现了零样本、可泛化的任务导向物体交接，并在四足机器人上展示了实际应用潜力。

Abstract: Task-oriented handovers (TOH) are fundamental to effective human-robot collaboration, requiring robots to present objects in a way that supports the human's intended post-handover use. Existing approaches are typically based on object- or task-specific affordances, but their ability to generalize to novel scenarios is limited. To address this gap, we present AFT-Handover, a framework that integrates large language model (LLM)-driven affordance reasoning with efficient texture-based affordance transfer to achieve zero-shot, generalizable TOH. Given a novel object-task pair, the method retrieves a proxy exemplar from a database, establishes part-level correspondences via LLM reasoning, and texturizes affordances for feature-based point cloud transfer. We evaluate AFT-Handover across diverse task-object pairs, showing improved handover success rates and stronger generalization compared to baselines. In a comparative user study, our framework is significantly preferred over the current state-of-the-art, effectively reducing human regrasping before tool use. Finally, we demonstrate TOH on legged manipulators, highlighting the potential of our framework for real-world robot-human handovers.

</details>


### [81] [Scalable and General Whole-Body Control for Cross-Humanoid Locomotion](https://arxiv.org/abs/2602.05791)
*Yufei Xue,YunFeng Lin,Wentao Dong,Yang Tang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Minghuan Liu,Weinan Zhang*

Main category: cs.RO

TL;DR: 提出XHugWBC框架，实现单策略跨多种人形机器人设计的通用控制，无需针对特定机器人训练


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的人形机器人全身控制器大多需要针对特定机器人进行训练，缺乏通用性。需要解决跨具身人形控制问题，使单一策略能适应不同机器人设计

Method: 提出XHugWBC框架，包含：(1)物理一致的形态随机化，(2)跨不同人形机器人的语义对齐观测和动作空间，(3)建模形态和动力学特性的有效策略架构。通过一次训练学习广泛分布的形态和动力学特征

Result: 在12个模拟人形机器人和7个真实机器人上实验验证，展示出强大的泛化能力和鲁棒性。策略能够零样本迁移到未见过的机器人

Conclusion: XHugWBC框架成功实现了跨具身人形控制，通过一次训练即可获得通用控制器，为通用人形机器人控制提供了有效解决方案

Abstract: Learning-based whole-body controllers have become a key driver for humanoid robots, yet most existing approaches require robot-specific training. In this paper, we study the problem of cross-embodiment humanoid control and show that a single policy can robustly generalize across a wide range of humanoid robot designs with one-time training. We introduce XHugWBC, a novel cross-embodiment training framework that enables generalist humanoid control through: (1) physics-consistent morphological randomization, (2) semantically aligned observation and action spaces across diverse humanoid robots, and (3) effective policy architectures modeling morphological and dynamical properties. XHugWBC is not tied to any specific robot. Instead, it internalizes a broad distribution of morphological and dynamical characteristics during training. By learning motion priors from diverse randomized embodiments, the policy acquires a strong structural bias that supports zero-shot transfer to previously unseen robots. Experiments on twelve simulated humanoids and seven real-world robots demonstrate the strong generalization and robustness of the resulting universal controller.

</details>


### [82] [A Hybrid Autoencoder for Robust Heightmap Generation from Fused Lidar and Depth Data for Humanoid Robot Locomotion](https://arxiv.org/abs/2602.05855)
*Dennis Bank,Joost Cordes,Thomas Seel,Simon F. G. Ehlers*

Main category: cs.RO

TL;DR: 提出基于学习的混合编码器-解码器框架，通过多模态传感器融合和时间一致性处理，提升人形机器人在非结构化环境中的地形感知可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统地形感知系统依赖手动设计的单传感器管道，在非结构化、以人为中心的环境中部署人形机器人时，需要更可靠的地形感知方法。

Method: 采用机器人中心的高度图表示，提出混合编码器-解码器结构，结合CNN提取空间特征和GRU保持时间一致性，融合Intel RealSense深度相机、LIVOX MID-360 LiDAR（通过球面投影处理）和IMU的多模态数据。

Result: 多模态融合相比仅使用深度相机提升7.2%重建精度，相比仅使用LiDAR提升9.9%；集成3.2秒时间上下文有效减少建图漂移。

Conclusion: 提出的学习型多模态融合框架显著提升地形感知精度和时间一致性，为人形机器人在非结构化环境中的可靠部署提供了有效解决方案。

Abstract: Reliable terrain perception is a critical prerequisite for the deployment of humanoid robots in unstructured, human-centric environments. While traditional systems often rely on manually engineered, single-sensor pipelines, this paper presents a learning-based framework that uses an intermediate, robot-centric heightmap representation. A hybrid Encoder-Decoder Structure (EDS) is introduced, utilizing a Convolutional Neural Network (CNN) for spatial feature extraction fused with a Gated Recurrent Unit (GRU) core for temporal consistency. The architecture integrates multimodal data from an Intel RealSense depth camera, a LIVOX MID-360 LiDAR processed via efficient spherical projection, and an onboard IMU. Quantitative results demonstrate that multimodal fusion improves reconstruction accuracy by 7.2% over depth-only and 9.9% over LiDAR-only configurations. Furthermore, the integration of a 3.2 s temporal context reduces mapping drift.

</details>


### [83] [Residual Reinforcement Learning for Waste-Container Lifting Using Large-Scale Cranes with Underactuated Tools](https://arxiv.org/abs/2602.05895)
*Qi Li,Karsten Berns*

Main category: cs.RO

TL;DR: 本文提出一种残差强化学习方法，用于液压装载起重机在垃圾回收任务中的容器吊装阶段，结合名义控制器与学习策略提升精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 城市环境中垃圾容器回收任务的容器吊装阶段面临严格几何公差挑战，需要精确轨迹跟踪和摆动抑制，而传统控制器难以应对未建模动态和参数变化。

Method: 采用残差强化学习方法，结合名义笛卡尔控制器（导纳控制轨迹跟踪+摆锤感知摆动阻尼）与PPO训练的残差策略，使用随机化初始化和域随机化增强泛化能力。

Result: 仿真结果显示，相比单独使用名义控制器，该方法提高了跟踪精度、减少了振荡、提升了吊装成功率。

Conclusion: 残差强化学习方法能有效补偿未建模动态和参数变化，提升液压起重机在严格几何公差任务中的性能，无需从头端到端学习。

Abstract: This paper studies the container lifting phase of a waste-container recycling task in urban environments, performed by a hydraulic loader crane equipped with an underactuated discharge unit, and proposes a residual reinforcement learning (RRL) approach that combines a nominal Cartesian controller with a learned residual policy. All experiments are conducted in simulation, where the task is characterized by tight geometric tolerances between the discharge-unit hooks and the container rings relative to the overall crane scale, making precise trajectory tracking and swing suppression essential. The nominal controller uses admittance control for trajectory tracking and pendulum-aware swing damping, followed by damped least-squares inverse kinematics with a nullspace posture term to generate joint velocity commands. A PPO-trained residual policy in Isaac Lab compensates for unmodeled dynamics and parameter variations, improving precision and robustness without requiring end-to-end learning from scratch. We further employ randomized episode initialization and domain randomization over payload properties, actuator gains, and passive joint parameters to enhance generalization. Simulation results demonstrate improved tracking accuracy, reduced oscillations, and higher lifting success rates compared to the nominal controller alone.

</details>


### [84] [From Bench to Flight: Translating Drone Impact Tests into Operational Safety Limits](https://arxiv.org/abs/2602.05922)
*Aziz Mohamed Mili,Louis Catar,Paul Gérard,Ilyass Tabiai,David St-Onge*

Main category: cs.RO

TL;DR: 开发了一套端到端工具链，将台架冲击测试转化为可部署的无人机安全控制器，用于室内微飞行器近人操作的安全管理。


<details>
  <summary>Details</summary>
Motivation: 室内微飞行器越来越多地用于需要接近人员的任务，但缺乏基于实测冲击风险调整运动限制的实用方法。

Method: 1) 设计紧凑可复制的冲击测试装置和协议，采集不同无人机和接触表面的力-时间曲线；2) 建立数据驱动模型，将碰撞前速度映射到冲量和接触持续时间；3) 开发脚本和ROS2节点在线执行速度限制并记录合规性。

Result: 在多种商用现成四旋翼无人机和代表性室内资产上验证了工作流程，证明推导的控制器能在满足安全利益相关者设定的力约束的同时保持任务吞吐量。

Conclusion: 提供了一套实用的从实测冲击到运行时限制的桥梁，包括可共享的数据集、代码和可重复流程，团队可采用此方法认证室内微飞行器在人类附近的操作。

Abstract: Indoor micro-aerial vehicles (MAVs) are increasingly used for tasks that require close proximity to people, yet practitioners lack practical methods to tune motion limits based on measured impact risk. We present an end-to-end, open toolchain that converts benchtop impact tests into deployable safety governors for drones. First, we describe a compact and replicable impact rig and protocol for capturing force-time profiles across drone classes and contact surfaces. Second, we provide data-driven models that map pre-impact speed to impulse and contact duration, enabling direct computation of speed bounds for a target force limit. Third, we release scripts and a ROS2 node that enforce these bounds online and log compliance, with support for facility-specific policies. We validate the workflow on multiple commercial off-the-shelf quadrotors and representative indoor assets, demonstrating that the derived governors preserve task throughput while meeting force constraints specified by safety stakeholders. Our contribution is a practical bridge from measured impacts to runtime limits, with shareable datasets, code, and a repeatable process that teams can adopt to certify indoor MAV operations near humans.

</details>


### [85] [Visuo-Tactile World Models](https://arxiv.org/abs/2602.06001)
*Carolina Higuera,Sergio Arnaud,Byron Boots,Mustafa Mukadam,Francois Robert Hogan,Franziska Meier*

Main category: cs.RO

TL;DR: 提出多任务视觉-触觉世界模型VT-WM，通过触觉推理捕捉接触物理，在接触丰富的操作任务中提升物理保真度和规划性能


<details>
  <summary>Details</summary>
Motivation: 纯视觉模型在遮挡或接触状态模糊时容易出现物体消失、瞬移或违反物理规律等失败模式，需要结合触觉感知来更好地理解机器人-物体交互

Method: 开发多任务视觉-触觉世界模型，通过触觉传感补充视觉信息，在多个接触丰富的操作任务上进行训练，学习接触动力学

Result: VT-WM在想象中提升物理保真度：物体持久性保持提升33%，运动规律符合度提升29%；零样本真实机器人实验中成功率提升高达35%，在接触丰富的多步任务中提升最明显

Conclusion: VT-WM通过触觉推理显著改善了接触物理的理解，提高了世界模型的物理保真度和规划性能，并能有效适应新任务，展示了接触动力学学习的下游泛化能力

Abstract: We introduce multi-task Visuo-Tactile World Models (VT-WM), which capture the physics of contact through touch reasoning. By complementing vision with tactile sensing, VT-WM better understands robot-object interactions in contact-rich tasks, avoiding common failure modes of vision-only models under occlusion or ambiguous contact states, such as objects disappearing, teleporting, or moving in ways that violate basic physics. Trained across a set of contact-rich manipulation tasks, VT-WM improves physical fidelity in imagination, achieving 33% better performance at maintaining object permanence and 29% better compliance with the laws of motion in autoregressive rollouts. Moreover, experiments show that grounding in contact dynamics also translates to planning. In zero-shot real-robot experiments, VT-WM achieves up to 35% higher success rates, with the largest gains in multi-step, contact-rich tasks. Finally, VT-WM demonstrates significant downstream versatility, effectively adapting its learned contact dynamics to a novel task and achieving reliable planning success with only a limited set of demonstrations.

</details>


### [86] [CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction](https://arxiv.org/abs/2602.06038)
*Xiaopan Zhang,Zejin Wang,Zhixu Li,Jianpeng Yao,Jiachen Li*

Main category: cs.RO

TL;DR: 论文提出CommCP框架，用于多智能体多任务具身问答（MM-EQA），通过LLM和保形预测提升异构机器人协作中的通信可靠性


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人部署需要异构机器人协作完成任务，但现有方法在信息收集和通信协调方面存在不足，特别是在多智能体多任务具身问答场景中

Method: 提出CommCP框架：基于LLM的去中心化通信框架，使用保形预测校准生成的消息，减少接收者干扰，提高通信可靠性

Result: 在提出的MM-EQA基准测试中，CommCP显著提高了任务成功率和探索效率，优于基线方法

Conclusion: CommCP框架有效解决了多智能体协作中的通信协调问题，为异构机器人协作提供了可靠的通信解决方案

Abstract: To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this component of the problem, we formalize the information-gathering process in a fully cooperative setting as an underexplored multi-agent multi-task Embodied Question Answering (MM-EQA) problem, which is a novel extension of canonical Embodied Question Answering (EQA), where effective communication is crucial for coordinating efforts without redundancy. To address this problem, we propose CommCP, a novel LLM-based decentralized communication framework designed for MM-EQA. Our framework employs conformal prediction to calibrate the generated messages, thereby minimizing receiver distractions and enhancing communication reliability. To evaluate our framework, we introduce an MM-EQA benchmark featuring diverse, photo-realistic household scenarios with embodied questions. Experimental results demonstrate that CommCP significantly enhances the task success rate and exploration efficiency over baselines. The experiment videos, code, and dataset are available on our project website: https://comm-cp.github.io.

</details>
