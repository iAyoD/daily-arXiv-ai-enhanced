<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 78]
- [cs.RO](#cs.RO) [Total: 34]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents](https://arxiv.org/abs/2602.11156)
*Sungmoon Kim,Hyuna Jeon,Dahye Kim,Mingyu Kim,Dong-Kyu Chae,Jiwoong Kim*

Main category: cs.CL

TL;DR: HybridRAG是一个新颖的RAG框架，通过预生成QA知识库和分层文本块处理，实现更准确、更快速的聊天机器人响应，特别适用于处理非结构化PDF文档。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法通常假设结构良好的文本源，并在查询时进行检索和生成，这在现实聊天机器人场景中限制了适用性，特别是处理大量非结构化文档和有限计算资源时。

Method: 1. 通过OCR和布局分析处理包含复杂布局的非结构化PDF文档，转换为分层文本块；2. 使用LLM从组织好的文本块预生成QA知识库；3. 查询时先匹配QA库获取即时答案，无匹配时才进行实时响应生成。

Result: 在OHRBench上的实验表明，HybridRAG相比标准RAG基线提供了更高的答案质量和更低的延迟。

Conclusion: HybridRAG是处理大量非结构化文档和有限计算资源的现实聊天机器人应用的实用解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.

</details>


### [2] [Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety](https://arxiv.org/abs/2602.11157)
*Max Zhang,Derek Liu,Kai Zhang,Joshua Franco,Haihao Liu*

Main category: cs.CL

TL;DR: 研究探索知识蒸馏在多语言越狱防御中的应用，发现使用教师模型的安全拒绝数据进行标准微调反而会提高学生模型的越狱成功率，揭示了多语言安全对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全对齐主要针对英语，导致在非英语特别是低资源语言环境中存在安全漏洞。需要研究如何将安全能力扩展到多语言场景。

Method: 使用知识蒸馏技术，将专有教师模型OpenAI o1-mini的拒绝行为通过LoRA参数高效微调，蒸馏到三个开源学生模型（Meta-Llama-3-8B-Instruct、Gemma-2-2B-IT、Qwen3-8B），使用XSafety提供的约28,000个多语言越狱提示进行黑盒响应式训练。

Result: 反直觉发现：使用教师模型的安全拒绝数据进行标准微调反而使所有学生模型的越狱成功率提高达16.6个百分点。去除"边界拒绝"这一安全降级主要来源后，可以缓解甚至逆转安全下降，但推理性能（GSM8K）仍会降低。

Conclusion: 知识蒸馏作为多语言安全对齐技术既面临挑战也有潜力，蒸馏过程中存在对未见语言的不同泛化效果，为未来研究提供了基础。

Abstract: Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We introduce a novel application of knowledge distillation (KD) in the context of multilingual jailbreak prevention, examining its efficacy. We distill the refusal behaviors of a proprietary teacher model (OpenAI o1-mini) with Low-Rank Adaptation (LoRA) into three open-source student models: Meta-Llama-3-8B-Instruct, Gemma-2-2B-IT, and Qwen3-8B, using ~28,000 multilingual jailbreak prompts from XSafety via black-box response-based, parameter-efficient fine-tuning (PEFT). Evaluation on the MultiJail benchmark reveals a counterintuitive behavior: standard fine-tuning on the teacher's ``safe'' refusal data inadvertently increases Jailbreak Success Rate (JSR) for all student models, up to 16.6 percentage points. Our experiments reveal a divergent generalization to unseen languages during distillation, with varying outcomes depending on the base model. By removing a primary source of safety degradation, nuanced `boundary' refusals, we mitigate or even reverse safety declines in student models, although reductions in reasoning performance (GSM8K) persist. Overall, our exploratory study highlights the challenges and potential of KD as a technique for multilingual safety alignment, offering a foundation for future research in this direction.

</details>


### [3] [Retrieval Heads are Dynamic](https://arxiv.org/abs/2602.11162)
*Yuping Lin,Zitao Li,Yue Xing,Pengfei He,Yingqian Cui,Yaliang Li,Bolin Ding,Jingren Zhou,Jiliang Tang*

Main category: cs.CL

TL;DR: 论文从动态视角研究LLM中的检索头，发现检索头在时间步上动态变化，具有不可替代性，且隐藏状态包含预测未来检索模式的信号，揭示了LLM的内部规划机制。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要基于静态统计数据识别LLM中的检索头，忽略了自回归生成的细粒度时间动态性。本文旨在从动态视角研究检索头的工作机制。

Method: 通过广泛分析，建立三个核心主张：动态性、不可替代性和相关性。在Needle-in-a-Haystack任务和多跳QA任务上验证发现，并在动态检索增强生成框架中量化动态与静态检索头的效用差异。

Result: 发现检索头在时间步上动态变化，动态检索头具有特定性且不能被静态检索头有效替代，模型隐藏状态编码了预测未来检索头模式的信号，表明存在内部规划机制。

Conclusion: 研究为LLM的内部机制提供了新见解，揭示了检索头的动态特性和模型的内部规划能力，对理解LLM的工作方式有重要意义。

Abstract: Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that perform retrieval on average. This perspective overlooks the fine-grained temporal dynamics of autoregressive generation. In this paper, we investigate retrieval heads from a dynamic perspective. Through extensive analysis, we establish three core claims: (1) Dynamism: Retrieval heads vary dynamically across timesteps; (2) Irreplaceability: Dynamic retrieval heads are specific at each timestep and cannot be effectively replaced by static retrieval heads; and (3) Correlation: The model's hidden state encodes a predictive signal for future retrieval head patterns, indicating an internal planning mechanism. We validate these findings on the Needle-in-a-Haystack task and a multi-hop QA task, and quantify the differences on the utility of dynamic and static retrieval heads in a Dynamic Retrieval-Augmented Generation framework. Our study provides new insights into the internal mechanisms of LLMs.

</details>


### [4] [Nested Named Entity Recognition in Plasma Physics Research Articles](https://arxiv.org/abs/2602.11163)
*Muhammad Haris,Hans Höft,Markus M. Becker,Markus Stocker*

Main category: cs.CL

TL;DR: 本文提出了一种基于编码器-变换器和条件随机场的轻量级方法，用于从等离子体物理研究文章中提取嵌套命名实体，通过特定实体模型专业化方法和超参数优化提升性能。


<details>
  <summary>Details</summary>
Motivation: 等离子体物理研究文章包含高度复杂和上下文丰富的内容，需要提取关键实体以支持高级搜索等应用。当前缺乏专门针对该领域嵌套命名实体识别的方法。

Method: 1) 标注包含16个类别的等离子体物理语料库；2) 采用实体特定模型专业化方法，训练独立的BERT-CRF模型识别单个实体类型；3) 集成超参数优化过程系统微调模型。

Result: 开发了专门针对等离子体物理领域的嵌套命名实体识别方法，通过模型专业化和超参数优化提升了实体提取性能。

Conclusion: 该工作推动了等离子体物理领域的实体识别研究，为研究人员导航和分析科学文献提供了基础支持。

Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.

</details>


### [5] [Assessing LLM Reliability on Temporally Recent Open-Domain Questions](https://arxiv.org/abs/2602.11165)
*Pushwitha Krishnappa,Amit Das,Vinija Jain,Tathagata Mukherjee,Aman Chadha*

Main category: cs.CL

TL;DR: RECOM基准测试揭示LLM在回答近期问题时存在语义-词汇悖论：模型通过大量改写保持语义相似性（余弦相似度>99%），而非词汇重现（BLEU-1<8%），挑战了词汇指标在评估抽象生成任务中的可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM在开放域问答中广泛应用，但其对近期信息的回答与人类视角的一致性尚未充分研究。需要评估LLM在回答时效性强的现实世界问题时是否与社区共识保持一致。

Method: 构建RECOM基准数据集（15,000个2025年9月的Reddit问题及社区答案），评估4个开源LLM（Llama3.1-8B, Mistral-7B, Gemma-2-9B, GPT-OSS-20B），使用词汇指标（BLEU, ROUGE）、语义相似度（BERTScore, MoverScore, 余弦相似度）和逻辑推理（NLI）进行多维度评估。

Result: 发现语义-词汇悖论：所有模型与参考答案的余弦相似度超过99%，但BLEU-1重叠率低于8%，差距达90+个百分点。MoverScore（51-53%）处于中间位置。模型规模不预测性能：Mistral-7B在所有指标上优于GPT-OSS-20B。矛盾率低于7%，表明模型很少生成与人类共识直接冲突的内容。

Conclusion: 词汇指标在评估抽象生成任务中不可靠，需要多维评估框架来捕捉超越表面文本匹配的语义保真度。RECOM数据集公开可用，为评估LLM与人类视角对齐提供了新基准。

Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0

</details>


### [6] [Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?](https://arxiv.org/abs/2602.11166)
*Xu Hu,Yifan Zhang,Songtao Wei,Chen Zhao,Qiannan Li,Bingzhe Li,Feng Chen*

Main category: cs.CL

TL;DR: PEFT方法能显著提升大语言模型在事实问答任务中的幻觉检测能力，主要通过重塑不确定性编码而非注入新知识。


<details>
  <summary>Details</summary>
Motivation: 尽管参数高效微调（PEFT）方法被广泛用于适配大语言模型到下游任务，并常被认为能提升事实正确性，但PEFT如何影响幻觉行为（特别是在QA数据集上）仍缺乏深入理解。

Method: 通过系统性实证研究，在三个开源LLM骨干模型和三个事实寻求QA基准上评估PEFT影响。使用七种无监督幻觉检测方法，涵盖语义一致性、置信度和熵三种互补方法，进行多维度评估。

Result: 实验结果显示PEFT能持续增强幻觉检测能力，显著提升多种幻觉检测器的AUROC。进一步分析表明，PEFT主要通过重塑不确定性的编码和呈现方式，而非向模型注入新的事实知识。

Conclusion: PEFT方法能有效改善大语言模型在事实问答任务中的幻觉检测性能，其机制主要是优化模型对不确定性的内部表示，而非增加事实知识储备。

Abstract: Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.

</details>


### [7] [Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering](https://arxiv.org/abs/2602.11167)
*Nathan Mao,Varun Kaushik,Shreya Shivkumar,Parham Sharafoleslami,Kevin Zhu,Sunishchal Dev*

Main category: cs.CL

TL;DR: FalseCite是一个用于系统研究LLM幻觉的数据集，通过误导性引用诱导幻觉，并在多个模型上测试发现GPT-4o-mini对虚假引用最敏感，同时发现幻觉与非幻觉的隐藏状态向量呈现独特的"角状"形状。


<details>
  <summary>Details</summary>
Motivation: LLM经常产生幻觉（生成无意义或虚假信息），这在医学、法律等敏感领域尤其有害。为了系统研究这一现象，需要专门的工具来捕捉和评估由误导性引用引发的幻觉。

Method: 引入FalseCite数据集，专门设计用于捕获和基准测试由误导性或伪造引用诱导的幻觉响应。在GPT-4o-mini、Falcon-7B和Mistral 7-B上运行FalseCite，并分析幻觉模型的内部状态，通过可视化和聚类隐藏状态向量来研究幻觉机制。

Result: 发现带有欺骗性引用的虚假声明会显著增加幻觉活动，特别是GPT-4o-mini对此最敏感。分析隐藏状态向量发现，无论是否发生幻觉，这些向量都倾向于形成独特的"角状"形状。

Conclusion: FalseCite有潜力作为未来LLM研究中评估和缓解幻觉的基础工具，为理解和管理LLM幻觉现象提供了系统化的方法。

Abstract: Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.

</details>


### [8] [Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI](https://arxiv.org/abs/2602.11168)
*Jingyan Xu,Marcelo L. LaFleur,Christina Schweikert,D. Frank Hsu*

Main category: cs.CL

TL;DR: 本文提出使用组合融合分析(CFA)结合多个AI模型来增强联合国可持续发展目标(SDG)的文本分类，通过生成式AI合成数据训练模型，CFA达到96.73%准确率，优于单个最佳模型，并与人类专家结果对比验证互补性。


<details>
  <summary>Details</summary>
Motivation: 在文本分类中，当类别不可用、难以区分或相互关联时，传统NLP技术面临挑战。特别是在社会分析和可持续发展目标(SDG)分类中，需要更准确的方法。本文旨在通过融合多个模型的智能来增强SDG文本分类。

Method: 采用组合融合分析(CFA)框架，使用秩-得分特征函数和认知多样性来融合多个相对较好且相互多样化的分类模型。首先使用生成式AI模型生成合成数据用于模型训练，然后将CFA应用于SDG分类任务。

Result: CFA技术达到96.73%的性能表现，优于最佳个体模型。通过与人类领域专家结果的比较，证明了多个ML/AI模型的智能融合与人类专家输入不仅能够互补，还能相互增强。

Conclusion: 研究表明，使用CFA结合多个AI模型的智能，并融入人类专家输入，能够显著提升SDG文本分类的性能，为解决复杂分类问题提供了有效方法。

Abstract: (Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making. However, it remains a challenging problem in cases where the categories are unavailable, difficult to differentiate, or are interrelated. Social analysis with human context is an area that can benefit from text classification, as it relies substantially on text data. The focus of this paper is to enhance the classification of text according to the UN's Sustainable Development Goals (SDGs) by collecting and combining intelligence from multiple models. Combinatorial Fusion Analysis (CFA), a system fusion paradigm using a rank-score characteristic (RSC) function and cognitive diversity (CD), has been used to enhance classifier methods by combining a set of relatively good and mutually diverse classification models. We use a generative AI model to generate synthetic data for model training and then apply CFA to this classification task. The CFA technique achieves 96.73% performance, outperforming the best individual model. We compare the outcomes with those obtained from human domain experts. It is demonstrated that combining intelligence from multiple ML/AI models using CFA and getting input from human experts can, not only complement, but also enhance each other.

</details>


### [9] [Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis](https://arxiv.org/abs/2602.11169)
*Mangadoddi Srikar Vardhan,Lekkala Sai Teja*

Main category: cs.CL

TL;DR: Transformer隐藏状态中，向量方向（角度）主要影响语言建模损失，而向量大小（范数）主要影响句法处理准确性，两者在LayerNorm架构中具有不同计算功能


<details>
  <summary>Details</summary>
Motivation: 研究Transformer隐藏状态中向量方向和大小是否具有不同的功能角色，理解高维表示空间中方向和范数的计算意义

Method: 使用L2匹配的扰动分析方法，在Pythia模型家族上进行因果干预实验，比较角度扰动和大小扰动对语言建模损失和句法处理的影响

Result: 角度扰动对语言建模损失造成更大损害（最多42.9倍），而大小扰动对句法处理准确性损害更大（20.4% vs 1.6%准确率下降）；角度损害主要通过注意力通路传播，大小损害部分通过LayerNorm通路传播

Conclusion: 在LayerNorm架构中，向量方向主要影响注意力路由，而向量大小调节处理强度以进行精细句法判断；这种分离现象依赖于架构选择，对模型编辑和可解释性研究有重要意义

Abstract: Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying Pythia-family models, we discover a striking cross-over dissociation: angular perturbations cause up to 42.9 more damage to language modeling loss, while magnitude perturbations cause disproportionately more damage to syntactic processing (20.4% vs.1.6% accuracy drop on subject-verb agreement).This finding is enabled by L2-matched perturbation analysis, a methodology ensuring that an gular and magnitude perturbations achieve identical Euclidean displacements. Causal intervention reveals that angular damage flows substantially through the attention pathways (28.4% loss recovery via attention repair), while magnitude damage flows partly through the LayerNorm pathways(29.9% recovery via LayerNorm repair). These patterns replicate across scales within the Pythia architecture family. These findings provide evidence that direction and magnitude support partially distinct computational roles in LayerNorm based architectures. The direction preferentially affects attentional routing, while magnitude modulates processing intensity for fine-grained syntactic judgments. We find different patterns in RMSNorm-based architectures, suggesting that the dissociation depends on architectural choices. Our results refine the linear representation hypothesis and have implications for model editing and interpretability research

</details>


### [10] [PRIME: Policy-Reinforced Iterative Multi-agent Execution for Algorithmic Reasoning in Large Language Models](https://arxiv.org/abs/2602.11170)
*Jiawei Xu,Zhenyu Yu,Ziqian Bi,Minh Duc Pham,Xiaoyi Qu,Danyang Zhang*

Main category: cs.CL

TL;DR: PRIME框架通过三个专门代理（执行器、验证器、协调器）和群体相对策略优化，将算法推理准确率从26.8%提升至93.8%，在PRIME-Bench基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多种推理任务上表现出色，但在算法推理方面仍存在局限，需要更有效的框架来处理复杂的算法执行和状态跟踪任务。

Method: 提出PRIME框架，包含三个专门代理：执行器负责逐步推理，验证器检查约束条件，协调器控制回溯；通过群体相对策略优化进行优化。同时创建PRIME-Bench基准测试，包含86个任务、12个类别、51,600个实例。

Result: PRIME将平均准确率从26.8%提升至93.8%（相对提升250%）。在需要持续状态跟踪的任务上改进最大：图灵机模拟从9%提升至92%，长除法从16%提升至94%。迭代验证是主要贡献因素，小模型受益更大。

Conclusion: PRIME框架显著提升了语言模型在算法推理任务上的性能，特别是通过迭代验证防止错误传播。小模型通过此框架能达到与大模型相当的准确率，展示了框架的有效性和可扩展性。

Abstract: Large language models have demonstrated remarkable capabilities across diverse reasoning tasks, yet their performance on algorithmic reasoning remains limited. To handle this limitation, we propose PRIME (Policy-Reinforced Iterative Multi-agent Execution), a framework comprising three specialized agents, an executor for step-by-step reasoning, a verifier for constraint checking, and a coordinator for backtracking control, optimized through group relative policy optimization. For comprehensive evaluation, we introduce PRIME-Bench, the largest algorithmic reasoning benchmark to date, comprising 86 tasks across 12 categories with 51,600 instances. Tasks span sorting algorithms, graph and tree structures, automata and state machines, symbolic reasoning, and constraint-based puzzles, with execution traces reaching over one million steps. Compared to baseline approach, PRIME improves average accuracy from 26.8% to 93.8%, a 250% relative gain. The largest improvements occur on tasks requiring sustained state tracking, with Turing machine simulation improving from 9% to 92% and long division from 16% to 94%. Ablation studies identify iterative verification as the primary contributor, preventing the error propagation that causes baseline approaches to fail catastrophically. Analysis across model scales (8B-120B parameters) reveals that smaller models benefit disproportionately, achieving accuracy comparable to models 8x larger.

</details>


### [11] [Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization](https://arxiv.org/abs/2602.11171)
*Baek Seong-Eun,Lee Jung-Mok,Kim Sung-Bin,Tae-Hyun Oh*

Main category: cs.CL

TL;DR: 提出一个结合LLM领域知识与贝叶斯优化的框架，用于高效搜索LoRA超参数，仅需约30次迭代即可获得比标准方法更好的性能


<details>
  <summary>Details</summary>
Motivation: LoRA虽然使微调高效，但对超参数选择非常敏感，而穷举搜索计算成本高昂，需要更高效的超参数优化方法

Method: 1) 将LLM重新用作离散到连续的映射，通过语言提示注入LoRA超参数的领域知识；2) 使用可学习token建模难以语言描述的残差信息；3) 利用子集训练数据进行代理训练和评估

Result: 仅需约30次迭代就能找到比标准方法（约45,000种组合）性能提升超过20%的超参数

Conclusion: 提出的框架能有效利用LLM的领域知识指导贝叶斯优化，显著提高LoRA超参数搜索效率

Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning efficient, it is highly sensitive to the choice of hyperparameters, and exhaustive hyperparameter search is still computationally very demanding. To address these challenges, we propose a framework that integrates the domain knowledge of pre-trained LLMs into Bayesian Optimization (BO) to efficiently search for LoRA hyperparameters. To leverage the informed knowledge of LLMs, we repurpose LLMs as a discrete-to-continuous mapping to link the hyperparameters and their domain knowledge with a continuous vector space, where BO is conducted. We design and control the mapping by language prompting, where we provide a domain-aware textual prompt describing the relationships among hyperparameters and their respective roles; thereby, we explicitly inject domain knowledge about LoRA into the LLM in natural language. Also, we model the residual information that is hard to linguistically describe in the prompt with an additional learnable token. This aids BO to sample more high-performing hyperparameters. In addition, by leveraging the observation of the strong correlation between the respective performance obtained from full and subset training datasets in LoRA training regimes, we introduce proxy training and evaluation with a data subset. This further increases the efficiency of our method. We demonstrate that our hyperparameter found with only about 30 iterations achieves more than 20% performance improvement over standard hyperparameters found from about 45,000 combinations.

</details>


### [12] [Synthesizing the Virtual Advocate: A Multi-Persona Speech Generation Framework for Diverse Linguistic Jurisdictions in Indic Languages](https://arxiv.org/abs/2602.11172)
*Aniket Deroy*

Main category: cs.CL

TL;DR: 该研究评估了Gemini 2.5 Flash和Pro TTS模型在五种印度语言中生成法庭演讲的能力，发现模型在程序性信息传递上表现良好，但在情感表达和说服力方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的发展，TTS技术已从基本可理解性转向上下文感知的表达性合成。在法律领域，合成语音需要传达权威性和专业形象，这在印度多语言环境中尤为复杂。研究旨在探索多语言TTS在法律倡导中的适用性。

Method: 提出一个提示框架，利用Gemini 2.5对五种语言的原生支持和上下文感知的节奏控制，生成不同的律师角色。在泰米尔语、泰卢固语、孟加拉语、印地语和古吉拉特语中评估模型性能。

Result: 模型表现出"单调权威性"，在程序性信息传递方面表现出色，但在动态声音调制和情感表达方面存在困难。在孟加拉语和古吉拉特语中性能下降，揭示了未来需要改进的音韵学边界。

Conclusion: 多语言TTS已准备好处理程序性法律任务，但在复制人类法律话语的说服艺术方面仍面临挑战。研究为未来改进提供了方向，特别是在情感表达和跨语言一致性方面。

Abstract: Legal advocacy requires a unique combination of authoritative tone, rhythmic pausing for emphasis, and emotional intelligence. This study investigates the performance of the Gemini 2.5 Flash TTS and Gemini 2.5 Pro TTS models in generating synthetic courtroom speeches across five Indic languages: Tamil, Telugu, Bengali, Hindi, and Gujarati. We propose a prompting framework that utilizes Gemini 2.5s native support for 5 languages and its context-aware pacing to produce distinct advocate personas. The evolution of Large Language Models (LLMs) has shifted the focus of TexttoSpeech (TTS) technology from basic intelligibility to context-aware, expressive synthesis. In the legal domain, synthetic speech must convey authority and a specific professional persona a task that becomes significantly more complex in the linguistically diverse landscape of India. The models exhibit a "monotone authority," excelling at procedural information delivery but struggling with the dynamic vocal modulation and emotive gravitas required for persuasive advocacy. Performance dips in Bengali and Gujarati further highlight phonological frontiers for future refinement. This research underscores the readiness of multilingual TTS for procedural legal tasks while identifying the remaining challenges in replicating the persuasive artistry of human legal discourse. The code is available at-https://github.com/naturenurtureelite/Synthesizing-the-Virtual-Advocate/tree/main

</details>


### [13] [Author-in-the-Loop Response Generation and Evaluation: Integrating Author Expertise and Intent in Responses to Peer Review](https://arxiv.org/abs/2602.11173)
*Qian Ruan,Iryna Gurevych*

Main category: cs.CL

TL;DR: 作者提出REspGen框架，将作者回复生成重构为"作者在环"任务，整合作者输入、多属性控制和评估引导的优化，并构建首个大规模对齐的审稿-回复-修订三元组数据集Re³Align。


<details>
  <summary>Details</summary>
Motivation: 当前自动回复生成方法未能充分利用作者的专业知识和意图。作者拥有领域专业知识、仅作者可见的信息、修订和回复策略等具体形式的专业知识和意图，需要NLP辅助工具整合这些信号来支持有效的同行评审回复撰写。

Method: 1) 将作者回复生成重构为"作者在环"任务；2) 提出REspGen生成框架，整合显式作者输入、多属性控制和评估引导的优化；3) 构建REspEval评估套件，包含20+个指标；4) 构建Re³Align数据集，包含对齐的审稿-回复-修订三元组。

Result: 实验表明：作者输入和评估引导的优化能带来显著收益；输入设计对回复质量有重要影响；在可控性和质量之间存在权衡。使用最先进的LLM验证了框架的有效性。

Conclusion: 作者回复生成应整合作者的专业知识和意图，提出的REspGen框架和Re³Align数据集为这一方向提供了重要工具和基准，有助于开发更有效的同行评审辅助系统。

Abstract: Author response (rebuttal) writing is a critical stage of scientific peer review that demands substantial author effort. Recent work frames this task as automatic text generation, underusing author expertise and intent. In practice, authors possess domain expertise, author-only information, revision and response strategies--concrete forms of author expertise and intent--to address reviewer concerns, and seek NLP assistance that integrates these signals to support effective response writing in peer review. We reformulate author response generation as an author-in-the-loop task and introduce REspGen, a generation framework that integrates explicit author input, multi-attribute control, and evaluation-guided refinement, together with REspEval, a comprehensive evaluation suite with 20+ metrics covering input utilization, controllability, response quality, and discourse. To support this formulation, we construct Re$^3$Align, the first large-scale dataset of aligned review--response--revision triplets, where revisions provide signals of author expertise and intent. Experiments with state-of-the-art LLMs show the benefits of author input and evaluation-guided refinement, the impact of input design on response quality, and trade-offs between controllability and quality. We make our dataset, generation and evaluation tools publicly available.

</details>


### [14] [The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models](https://arxiv.org/abs/2602.11174)
*Aradhya Dixit,Shreem Dixit*

Main category: cs.CL

TL;DR: 预训练多语言模型存在"脚本税"问题：某些书写系统因分词碎片化导致计算成本显著增加，影响模型公平性


<details>
  <summary>Details</summary>
Motivation: 研究预训练多语言语言模型对不同书写系统的公平性，量化分词器对特定文字系统的系统性成本

Method: 通过比较具有相同语言内容但不同正字法变体的文本，使用比特每字符（BPC）指标避免分词碎片化带来的"NLL悖论"，并进行往返转换检查

Result: 高碎片化正字法导致分词数量增加约3.4倍，推理速度减慢16.5倍，信息成本显著增加（mBERT +19.7%，XLM-R +47.1%）

Conclusion: 分词是多语言NLP中不平等的重要来源，需要开发脚本感知的分词和预训练方法以提高公平性

Abstract: Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with identical linguistic content. Across mBERT and XLM-R, the higher-fragmentation orthography shows a ~3.4x increase in fertility (6.73-6.85 vs. 2.10-2.35 tokens/word), leading to a 16.5x inference slowdown (0.23 vs. 3.8 sentences/second) on identical hardware. Using bits per character (BPC) to avoid the "NLL paradox" from subword fragmentation, we find a substantial increase in information cost: +19.7% for mBERT (8.06->9.65) and +47.1% for XLM-R (12.19->17.94). A round-trip conversion check (CER_rt=0.31) suggests these gaps reflect orthography-conditioned processing rather than mapping noise. Our results highlight tokenization as a key source of inequity in multilingual NLP and motivate script-aware tokenization and pretraining.

</details>


### [15] [Barriers to Discrete Reasoning with Transformers: A Survey Across Depth, Exactness, and Bandwidth](https://arxiv.org/abs/2602.11175)
*Michelle Yuan,Weiyi Sun,Amir H. Rezaeian,Jyotika Singh,Sandip Ghoshal,Yao-Ting Wang,Miguel Ballesteros,Yassine Benajiba*

Main category: cs.CL

TL;DR: 这篇综述论文分析了Transformer在离散推理任务（如算术、逻辑推理、算法组合）中的理论局限性，从电路复杂性、逼近理论和通信复杂性三个理论视角综合现有研究，解释为什么Transformer难以实现精确的离散算法。


<details>
  <summary>Details</summary>
Motivation: Transformer已成为序列建模的基础架构，在自然语言处理、视觉等领域取得了最先进的性能。然而，它们在离散推理任务中的理论局限性仍然是一个关键的开放问题。本文旨在通过综合多个理论视角来阐明Transformer在符号计算中面临的结构和计算障碍。

Method: 论文从三个理论视角综合现有研究：1) 电路复杂性 - 分析Transformer的计算深度约束；2) 逼近理论 - 研究Transformer逼近不连续函数的困难；3) 通信复杂性 - 探讨token间通信的瓶颈。通过连接这些理论框架，提供统一的理论解释。

Result: 论文综述了关键定义、开创性结果和示例，突出了Transformer在离散推理中的挑战：深度约束、难以逼近不连续性、token间通信瓶颈。这些理论限制解释了为什么当前Transformer架构在精确实现离散算法方面存在困难，尽管它们在模式匹配和插值方面表现出色。

Conclusion: 论文讨论了这些理论发现对模型设计的影响，并提出了克服这些基础限制的有前景方向。通过理解Transformer在离散推理中的理论局限性，可以为未来架构改进提供指导。

Abstract: Transformers have become the foundational architecture for a broad spectrum of sequence modeling applications, underpinning state-of-the-art systems in natural language processing, vision, and beyond. However, their theoretical limitations in discrete reasoning tasks, such as arithmetic, logical inference, and algorithmic composition, remain a critical open problem. In this survey, we synthesize recent studies from three theoretical perspectives: circuit complexity, approximation theory, and communication complexity, to clarify the structural and computational barriers that transformers face when performing symbolic computations. By connecting these established theoretical frameworks, we provide an accessible and unified account of why current transformer architectures struggle to implement exact discrete algorithms, even as they excel at pattern matching and interpolation. We review key definitions, seminal results, and illustrative examples, highlighting challenges such as depth constraints, difficulty approximating discontinuities, and bottlenecks in inter-token communication. Finally, we discuss implications for model design and suggest promising directions for overcoming these foundational limitations.

</details>


### [16] [Evaluating Few-Shot Temporal Reasoning of LLMs for Human Activity Prediction in Smart Environments](https://arxiv.org/abs/2602.11176)
*Maral Doctorarastoo,Katherine A. Flanigan,Mario Bergés,Christopher McComb*

Main category: cs.CL

TL;DR: 大型语言模型通过检索增强提示策略，在低数据环境下能够有效预测人类日常活动及其持续时间，展现出强大的时序推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的智能体模型在低数据环境下表现不佳，限制了其在智能家居、人机协作等实际应用中的实用性。需要探索预训练的大型语言模型是否能够利用其广泛的人类知识，从紧凑的上下文线索中推理日常活动。

Method: 采用检索增强提示策略，整合四种上下文来源：时间、空间、行为历史和人物特征。在CASAS Aruba智能家居数据集上进行评估，涵盖两个任务：下一活动预测与持续时间估计，以及多步日常序列生成。测试不同数量的few-shot示例对性能的影响。

Result: 大型语言模型展现出强大的内在时序理解能力：即使在零样本设置下也能产生连贯的日常活动预测，添加1-2个示例可进一步优化持续时间校准和分类准确性。超过几个示例后性能趋于饱和，呈现收益递减。序列级评估确认了跨few-shot条件的一致时序对齐。

Conclusion: 预训练语言模型可作为有前景的时序推理器，既能捕捉重复性日常规律，又能处理上下文依赖的行为变化，从而增强智能体模型的行为模块，特别是在低数据环境中具有实用价值。

Abstract: Anticipating human activities and their durations is essential in applications such as smart-home automation, simulation-based architectural and urban design, activity-based transportation system simulation, and human-robot collaboration, where adaptive systems must respond to human activities. Existing data-driven agent-based models--from rule-based to deep learning--struggle in low-data environments, limiting their practicality. This paper investigates whether large language models, pre-trained on broad human knowledge, can fill this gap by reasoning about everyday activities from compact contextual cues. We adopt a retrieval-augmented prompting strategy that integrates four sources of context--temporal, spatial, behavioral history, and persona--and evaluate it on the CASAS Aruba smart-home dataset. The evaluation spans two complementary tasks: next-activity prediction with duration estimation, and multi-step daily sequence generation, each tested with various numbers of few-shot examples provided in the prompt. Analyzing few-shot effects reveals how much contextual supervision is sufficient to balance data efficiency and predictive accuracy, particularly in low-data environments. Results show that large language models exhibit strong inherent temporal understanding of human behavior: even in zero-shot settings, they produce coherent daily activity predictions, while adding one or two demonstrations further refines duration calibration and categorical accuracy. Beyond a few examples, performance saturates, indicating diminishing returns. Sequence-level evaluation confirms consistent temporal alignment across few-shot conditions. These findings suggest that pre-trained language models can serve as promising temporal reasoners, capturing both recurring routines and context-dependent behavioral variations, thereby strengthening the behavioral modules of agent-based models.

</details>


### [17] [What Do LLMs Know About Alzheimer's Disease? Fine-Tuning, Probing, and Data Synthesis for AD Detection](https://arxiv.org/abs/2602.11177)
*Lei Jiang,Yue Zhou,Natalie Parde*

Main category: cs.CL

TL;DR: 该研究通过微调大语言模型进行阿尔茨海默病检测，分析模型内部表征，并利用任务感知特殊标记生成合成数据以解决标注数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期可靠检测具有挑战性，主要由于标注数据有限。虽然大语言模型在跨领域迁移方面表现出色，但通过监督微调将其适应到AD领域的研究仍较少。

Method: 1) 微调LLM用于AD检测；2) 使用探测技术分析transformer层的中间激活；3) 设计任务感知特殊标记；4) 训练序列到序列模型作为数据合成工具，利用这些标记生成结构一致且具有诊断信息的合成样本。

Result: 研究发现微调后，特定词语和特殊标记的探测值发生显著变化，表明这些元素在模型改进的检测性能中起关键作用。基于此设计特殊标记并生成合成数据。

Conclusion: 通过分析LLM内部表征，识别关键标记并用于数据合成，为解决AD检测中标注数据不足的问题提供了一种新方法，生成的合成数据可用于下游训练流程。

Abstract: Reliable early detection of Alzheimer's disease (AD) is challenging, particularly due to limited availability of labeled data. While large language models (LLMs) have shown strong transfer capabilities across domains, adapting them to the AD domain through supervised fine-tuning remains largely unexplored. In this work, we fine-tune an LLM for AD detection and investigate how task-relevant information is encoded within its internal representations. We employ probing techniques to analyze intermediate activations across transformer layers, and we observe that, after fine-tuning, the probing values of specific words and special markers change substantially, indicating that these elements assume a crucial role in the model's improved detection performance. Guided by this insight, we design a curated set of task-aware special markers and train a sequence-to-sequence model as a data-synthesis tool that leverages these markers to generate structurally consistent and diagnostically informative synthetic samples. We evaluate the synthesized data both intrinsically and by incorporating it into downstream training pipelines.

</details>


### [18] [From Instruction to Output: The Role of Prompting in Modern NLG](https://arxiv.org/abs/2602.11179)
*Munazza Zaib,Elaf Alhazmi*

Main category: cs.CL

TL;DR: 本文综述了提示工程在自然语言生成任务中的最新进展，提出了提示分类法、决策框架和设计-优化-评估框架，旨在为实践者提供系统化的指导。


<details>
  <summary>Details</summary>
Motivation: 尽管提示工程已成为提升大语言模型性能的重要技术，但在自然语言生成领域仍缺乏系统化的框架和统一理解。现有研究分散，缺乏对提示工程方法、技术和应用的连贯性分析。

Method: 通过文献综述方法，分析近期提示工程的发展及其对NLG任务的影响。将提示设计视为输入层面的控制机制，与微调和解码方法互补。提出提示范式的分类法、基于多种因素的提示选择决策框架，以及连接设计、优化和评估的框架。

Result: 建立了提示工程的系统化分类体系，为实践者提供了基于任务需求、模型特性和资源约束的提示选择决策框架。提出了支持更可控和可泛化NLG的统一框架，识别了新兴趋势和挑战。

Conclusion: 提示工程是NLG领域的重要研究方向，需要系统化的框架来指导实践。本文提出的分类法、决策框架和设计-优化-评估框架为研究人员和实践者提供了有价值的参考，有助于推动更可控和可泛化的自然语言生成技术的发展。

Abstract: Prompt engineering has emerged as an integral technique for extending the strengths and abilities of Large Language Models (LLMs) to gain significant performance gains in various Natural Language Processing (NLP) tasks. This approach, which requires instructions to be composed in natural language to bring out the knowledge from LLMs in a structured way, has driven breakthroughs in various NLP tasks. Yet there is still no structured framework or coherent understanding of the varied prompt engineering methods and techniques, particularly in the field of Natural Language Generation (NLG).
  This survey aims to help fill that gap by outlining recent developments in prompt engineering, and their effect on different NLG tasks. It reviews recent advances in prompting methods and their impact on NLG tasks, presenting prompt design as an input-level control mechanism that complements fine-tuning and decoding approaches. The paper introduces a taxonomy of prompting paradigms, a decision framework for prompt selection based on varying factors for the practitioners, outlines emerging trends and challenges, and proposes a framework that links design, optimization, and evaluation to support more controllable and generalizable NLG.

</details>


### [19] [Mechanistic Interpretability for Large Language Model Alignment: Progress, Challenges, and Future Directions](https://arxiv.org/abs/2602.11180)
*Usman Naseem*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）的机制可解释性研究进展，探讨了如何通过电路发现、特征可视化等技术理解模型内部决策过程，并分析了这些见解如何指导RLHF、宪法AI等对齐策略。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在各种任务上表现出色，但其内部决策过程仍然不透明。机制可解释性研究对于理解和对齐这些模型至关重要，有助于揭示神经网络如何通过学习的表示和计算结构实现算法。

Method: 本文采用文献综述方法，系统梳理了应用于LLM对齐的机制可解释性技术，包括电路发现、特征可视化、激活引导和因果干预等方法。分析了这些可解释性见解如何为对齐策略提供信息。

Result: 识别了机制可解释性研究中的关键挑战，包括叠加假设、神经元的多元语义性以及大规模模型中涌现行为的解释困难。同时总结了可解释性见解如何指导对齐策略的实践。

Conclusion: 提出了未来研究方向，包括自动化可解释性、电路的跨模型泛化，以及开发能够扩展到前沿模型的可解释性驱动的对齐技术。强调机制可解释性对于理解和安全对齐大型语言模型的重要性。

Abstract: Large language models (LLMs) have achieved remarkable capabilities across diverse tasks, yet their internal decision-making processes remain largely opaque. Mechanistic interpretability (i.e., the systematic study of how neural networks implement algorithms through their learned representations and computational structures) has emerged as a critical research direction for understanding and aligning these models. This paper surveys recent progress in mechanistic interpretability techniques applied to LLM alignment, examining methods ranging from circuit discovery to feature visualization, activation steering, and causal intervention. We analyze how interpretability insights have informed alignment strategies including reinforcement learning from human feedback (RLHF), constitutional AI, and scalable oversight. Key challenges are identified, including the superposition hypothesis, polysemanticity of neurons, and the difficulty of interpreting emergent behaviors in large-scale models. We propose future research directions focusing on automated interpretability, cross-model generalization of circuits, and the development of interpretability-driven alignment techniques that can scale to frontier models.

</details>


### [20] [Code Mixologist : A Practitioner's Guide to Building Code-Mixed LLMs](https://arxiv.org/abs/2602.11181)
*Himanshu Gupta,Pratik Jayarao,Chaitanya Dwivedi,Neeraj Varshney*

Main category: cs.CL

TL;DR: 该论文对代码混合与代码转换在大型语言模型中的研究进行了全面综述，提出了统一的分类法，并提供了构建、适应和评估CSW能力LLMs的实用指南。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言建模有所进展，但大型语言模型在混合语言环境中表现不佳，存在语法性、事实性和安全性方面的系统退化问题，需要系统性的研究和解决方案。

Method: 引入统一分类法，从数据、建模和评估三个维度组织现有研究；分析从CSW定制预训练、任务特定后训练到提示策略和上下文学习等多种建模方法；批判性评估现有基准测试的覆盖范围和英语中心偏见。

Result: 提出了构建CSW能力LLMs的实用指南，识别了当前评估实践中的不稳定性和可复现性限制，并指出了新兴的安全问题，包括代码混合作为绕过模型安全机制的潜在手段。

Conclusion: 代码混合与代码转换对LLMs仍是重要挑战，需要更系统化的研究框架、更全面的评估基准，并需关注其安全影响，为未来研究指明了方向。

Abstract: Code-mixing and code-switching (CSW) remain challenging phenomena for large language models (LLMs). Despite recent advances in multilingual modeling, LLMs often struggle in mixed-language settings, exhibiting systematic degradation in grammaticality, factuality, and safety behavior. This work provides a comprehensive overview of CSW research in modern large language model settings. We introduce a unifying taxonomy that organizes prior work along dimensions of data, modeling, and evaluation, and we distill these findings into a practical playbook of actionable recommendations for building, adapting, and evaluating CSW-capable LLMs. We review modeling approaches ranging from CSW-tailored pre-training and task-specific post-training to prompting strategies and in-context learning. We analyze current evaluation practices, highlighting sources of instability and limited reproducibility, and we catalog existing benchmarks while critically examining their linguistic coverage and English-centric biases. Finally, we discuss emerging safety concerns, including use of code-mixing as a mechanism for bypassing model safeguards, and identify open research challenges.

</details>


### [21] [MetaMem: Evolving Meta-Memory for Knowledge Utilization through Self-Reflective Symbolic Optimization](https://arxiv.org/abs/2602.11182)
*Haidong Xin,Xinze Li,Zhenghao Liu,Yukun Yan,Shuo Wang,Cheng Yang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: MetaMem提出了一种带有自演化元记忆的新型记忆框架，通过提炼跨任务的知识利用经验，指导LLM从分散的记忆片段中系统性地整合关键证据，显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有记忆系统虽然能让LLM支持长程人机交互，但常常破坏交互会话中的逻辑和时间关系，导致记忆单元碎片化和推理性能下降。需要一种方法来教LLM如何有效利用记忆知识。

Method: 提出MetaMem框架，通过自演化元记忆增强记忆系统。在元记忆优化过程中，通过自我反思推理过程并执行动作来更新当前元记忆状态，迭代提炼跨任务的可迁移知识利用经验。积累的元记忆单元作为显式知识利用经验，指导LLM系统性地识别和整合分散记忆片段中的关键证据。

Result: 大量实验证明MetaMem的有效性，显著优于强基线方法超过3.6%。

Conclusion: MetaMem通过引入自演化元记忆，成功解决了现有记忆系统导致的记忆碎片化问题，显著提升了LLM在长程交互中的推理性能，为LLM记忆系统的优化提供了新思路。

Abstract: Existing memory systems enable Large Language Models (LLMs) to support long-horizon human-LLM interactions by persisting historical interactions beyond limited context windows. However, while recent approaches have succeeded in constructing effective memories, they often disrupt the inherent logical and temporal relationships within interaction sessions, resulting in fragmented memory units and degraded reasoning performance. In this paper, we propose MetaMem, a novel framework that augments memory systems with a self-evolving meta-memory, aiming to teach LLMs how to effectively utilize memorized knowledge. During meta-memory optimization, MetaMem iteratively distills transferable knowledge utilization experiences across different tasks by self-reflecting on reasoning processes and performing actions to update the current meta-memory state. The accumulated meta-memory units serve as explicit knowledge utilization experiences, guiding the LLM to systematically identify and integrate critical evidence from scattered memory fragments. Extensive experiments demonstrate the effectiveness of MetaMem, which significantly outperforms strong baselines by over 3.6%. All codes and datasets are available at https://github.com/OpenBMB/MetaMem.

</details>


### [22] [DDL2PropBank Agent: Benchmarking Multi-Agent Frameworks' Developer Experience Through a Novel Relational Schema Mapping Task](https://arxiv.org/abs/2602.11198)
*Shafiuddin Rehan Ahmed,Wei Wei*

Main category: cs.CL

TL;DR: 论文提出了DDL2PropBank基准任务，用于评估多智能体框架的开发者体验，通过10个框架的对比发现Agno在代码复杂度和AI辅助性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体框架缺乏在受控环境中评估开发者体验的系统方法，需要一种能够测试框架代码复杂度和AI辅助性的基准任务。

Method: 引入DDL2PropBank基准任务（将关系数据库模式映射到PropBank角色集），采用工具化智能体模式，在10个框架中实现相同逻辑，从代码复杂度（静态分析）和AI辅助性（LLM自动生成正确代码的能力）两个维度评估。

Result: 发现三倍复杂度谱系：Pydantic AI和Agno实现开销最小；对于AI辅助性，结构对齐分数能可靠预测单模式框架的运行时成功率，但会高估多模式框架的正确性；Agno综合表现最强（复杂度最低、结构对齐最高、83% pass@1）。

Conclusion: DDL2PropBank为多智能体框架评估提供了原则性方法，Agno在开发者体验方面表现最优，结构对齐分数可作为有效的代理指标但需注意多模式框架的局限性。

Abstract: Multi-agent frameworks promise to simplify LLM-driven software development, yet there is no principled way to evaluate their developer experience in a controlled setting. We introduce DDL2PropBank, a novel benchmark task that maps relational database schemas to PropBank rolesets, requiring autonomous retrieval of candidate frames and fine-grained linguistic reasoning over table names, columns, and relations. Using the Agent-as-a-Tool pattern, we implement identical agent logic across 10 frameworks and evaluate along two dimensions: (i) code complexity via static analysis, and (ii) AI-assistability -- the extent to which LLMs can autonomously generate correct, framework-specific code. Our results reveal a threefold complexity spectrum, with Pydantic AI and Agno requiring the least implementation overhead. For AI-assistability, structural alignment scores reliably proxy runtime success for frameworks with single canonical patterns, but overestimate correctness for multi-pattern frameworks. Agno emerges as the strongest overall performer, combining lowest complexity with highest structural alignment and 83% pass@1.

</details>


### [23] [When and What to Ask: AskBench and Rubric-Guided RLVR for LLM Clarification](https://arxiv.org/abs/2602.11199)
*Jiale Zhao,Ke Fang,Lu Cheng*

Main category: cs.CL

TL;DR: 论文提出AskBench基准测试和RLVR方法，用于评估和改进LLM在需要澄清时的提问能力，避免幻觉和错误前提的传播。


<details>
  <summary>Details</summary>
Motivation: LLM经常在提示缺少关键细节或包含误导信息时仍给出回答，导致幻觉或强化错误观念。需要评估和改进LLM决定何时、如何请求澄清的能力，同时不牺牲任务性能。

Method: 1. 提出AskBench交互式基准，将标准QA对转换为带明确检查点的多轮交互；2. 统一评估循环评估最终答案并模拟用户响应；3. 包含AskMind（意图缺失查询）和AskOverconfidence（包含错误前提查询）两种设置；4. 提出基于规则的强化学习与验证器奖励（RLVR），使用结构化规则鼓励针对性澄清。

Result: 实验显示在准确性、规则遵循度和交互效率方面有持续改进，对未见领域有强泛化能力。

Conclusion: AskBench基准和RLVR方法能有效提升LLM在需要澄清时的提问能力，减少幻觉和错误前提传播，同时保持任务性能。

Abstract: Large language models (LLMs) often respond even when prompts omit critical details or include misleading information, leading to hallucinations or reinforced misconceptions. We study how to evaluate and improve LLMs' ability to decide when and what to ask for clarification without sacrificing task performance. We introduce AskBench, an interactive benchmark that converts standard QA pairs into multi-turn interactions with explicit checkpoints. A unified judge loop evaluates final answers and simulates user responses as needed. AskBench covers two settings: AskMind, with intent-deficient queries requiring clarification, and AskOverconfidence, with queries containing false premises that must be identified and corrected. We further propose rubric-guided reinforcement learning with verifier-based rewards (RLVR), which uses structured rubrics to encourage targeted clarification. Experiments show consistent improvements in accuracy, rubric adherence, and interaction efficiency, with strong generalization to unseen domains.

</details>


### [24] [Mechanistic Evidence for Faithfulness Decay in Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.11201)
*Donald Ye,Max Loffgren,Om Kotadia,Linus Wong*

Main category: cs.CL

TL;DR: 提出NLDD指标评估CoT解释的忠实性，发现推理存在70-85%的"推理视野"阈值，超过该阈值推理步骤对最终答案影响甚微


<details>
  <summary>Details</summary>
Motivation: 当前CoT解释广泛用于解释语言模型解决复杂问题的过程，但无法确定这些逐步解释是真实反映模型的决策过程，还是仅仅是事后合理化

Method: 提出标准化对数差异衰减(NLDD)指标，通过破坏解释中的单个推理步骤并测量模型对其答案置信度的下降程度，来判断步骤是否真正重要，并通过标准化实现跨模型比较

Result: 在语法、逻辑和算术任务上测试三个模型家族，发现一致的"推理视野"在链长的70-85%处，超过此阈值推理标记对最终答案影响很小或为负；模型可能编码正确的内部表示但完全失败任务

Conclusion: 准确率本身不能揭示模型是否真正通过其推理链进行推理，NLDD提供了一种衡量CoT何时重要的方法

Abstract: Chain-of-Thought (CoT) explanations are widely used to interpret how language models solve complex problems, yet it remains unclear whether these step-by-step explanations reflect how the model actually reaches its answer, or merely post-hoc justifications. We propose Normalized Logit Difference Decay (NLDD), a metric that measures whether individual reasoning steps are faithful to the model's decision-making process. Our approach corrupts individual reasoning steps from the explanation and measures how much the model's confidence in its answer drops, to determine if a step is truly important. By standardizing these measurements, NLDD enables rigorous cross-model comparison across different architectures. Testing three model families across syntactic, logical, and arithmetic tasks, we discover a consistent Reasoning Horizon (k*) at 70--85% of chain length, beyond which reasoning tokens have little or negative effect on the final answer. We also find that models can encode correct internal representations while completely failing the task. These results show that accuracy alone does not reveal whether a model actually reasons through its chain. NLDD offers a way to measure when CoT matters.

</details>


### [25] [The Automatic Verification of Image-Text Claims (AVerImaTeC) Shared Task](https://arxiv.org/abs/2602.11221)
*Rui Cao,Zhenyun Deng,Yulong Chen,Michael Schlichtkrull,Andreas Vlachos*

Main category: cs.CL

TL;DR: AVerImaTeC共享任务旨在推进图像-文本声明的证据检索和验证系统开发，14个开发阶段提交和6个测试阶段提交中，所有测试系统均超越基线，获胜团队HUMANE得分为0.5455。


<details>
  <summary>Details</summary>
Motivation: 该共享任务旨在推动图像-文本声明的自动验证系统发展，通过检索证据和验证真实世界中的图像-文本声明，提高系统在这一重要领域的性能。

Method: 参与者可以使用外部知识源（如网络搜索引擎）或组织者提供的知识库，系统性能使用AVerImaTeC评分评估，该评分定义为条件判断准确率，只有在相关证据分数超过预设阈值时才认为判断正确。

Result: 共享任务吸引了14个开发阶段提交和6个测试阶段提交，所有测试阶段参与系统都超越了提供的基线，获胜团队HUMANE获得了0.5455的AVerImaTeC分数。

Conclusion: 该论文详细描述了共享任务，展示了完整的评估结果，并讨论了关键见解和经验教训，为图像-文本声明验证领域的发展提供了重要参考。

Abstract: The Automatic Verification of Image-Text Claims (AVerImaTeC) shared task aims to advance system development for retrieving evidence and verifying real-world image-text claims. Participants were allowed to either employ external knowledge sources, such as web search engines, or leverage the curated knowledge store provided by the organizers. System performance was evaluated using the AVerImaTeC score, defined as a conditional verdict accuracy in which a verdict is considered correct only when the associated evidence score exceeds a predefined threshold. The shared task attracted 14 submissions during the development phase and 6 submissions during the testing phase. All participating systems in the testing phase outperformed the baseline provided. The winning team, HUMANE, achieved an AVerImaTeC score of 0.5455. This paper provides a detailed description of the shared task, presents the complete evaluation results, and discusses key insights and lessons learned.

</details>


### [26] [SurveyLens: A Research Discipline-Aware Benchmark for Automatic Survey Generation](https://arxiv.org/abs/2602.11238)
*Beichen Guo,Zhiyuan Wen,Jia Gu,Senzhang Wang,Haochen Shi,Ruosong Yang,Shuaiqi Liu*

Main category: cs.CL

TL;DR: SurveyLens是首个跨学科自动综述生成评估基准，包含1000篇人工撰写综述和双视角评估框架，用于评估11种ASG方法在不同学科的表现。


<details>
  <summary>Details</summary>
Motivation: 当前自动综述生成评估方法依赖通用指标且偏向计算机科学，无法评估不同学科标准遵循情况，导致非CS领域研究者缺乏使用指导。

Method: 构建SurveyLens-1k数据集（10个学科的1000篇高质量人工综述），提出双视角评估框架：1）学科感知评分表评估（使用LLM和人类偏好权重）；2）规范对齐评估（测量内容覆盖和综合质量）。

Result: 评估11种最先进的ASG方法（包括基础LLM、ASG系统和深度研究代理），揭示了各范式在不同领域的独特优势和劣势。

Conclusion: SurveyLens填补了跨学科ASG评估空白，为根据特定学科要求选择工具提供了重要指导，促进了更符合学科标准的自动综述生成。

Abstract: The exponential growth of scientific literature has driven the evolution of Automatic Survey Generation (ASG) from simple pipelines to multi-agent frameworks and commercial Deep Research agents. However, current ASG evaluation methods rely on generic metrics and are heavily biased toward Computer Science (CS), failing to assess whether ASG methods adhere to the distinct standards of various academic disciplines. Consequently, researchers, especially those outside CS, lack clear guidance on using ASG systems to yield high-quality surveys compliant with specific discipline standards. To bridge this gap, we introduce SurveyLens, the first discipline-aware benchmark evaluating ASG methods across diverse research disciplines. We construct SurveyLens-1k, a curated dataset of 1,000 high-quality human-written surveys spanning 10 disciplines. Subsequently, we propose a dual-lens evaluation framework: (1) Discipline-Aware Rubric Evaluation, which utilizes LLMs with human preference-aligned weights to assess adherence to domain-specific writing standards; and (2) Canonical Alignment Evaluation to rigorously measure content coverage and synthesis quality against human-written survey papers. We conduct extensive experiments by evaluating 11 state-of-the-art ASG methods on SurveyLens, including Vanilla LLMs, ASG systems, and Deep Research agents. Our analysis reveals the distinct strengths and weaknesses of each paradigm across fields, providing essential guidance for selecting tools tailored to specific disciplinary requirements.

</details>


### [27] [Are Aligned Large Language Models Still Misaligned?](https://arxiv.org/abs/2602.11305)
*Usman Naseem,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Sushant Kumar Ray,Abdullah Mohammad,Agrima Seth*

Main category: cs.CL

TL;DR: 提出了Mis-Align Bench基准，用于同时评估LLM在安全、价值和文化三个维度上的错位问题，解决了现有基准只能单独评估单一维度的问题。


<details>
  <summary>Details</summary>
Motivation: 现有错位基准（如INSECURE CODE、VALUEACTIONLENS、CULTURALHERITAGE）只能单独评估安全、价值或文化维度，无法同时评估这三个在现实世界中必须共同满足的维度，这限制了全面评估LLM错位问题的能力。

Method: 1. 构建SAVACU数据集：从LLM-PROMPT-DATASET重新分类382,424个样本，涵盖112个领域（14个安全领域、56个价值领域、42个文化领域），使用Mistral-7B-Instruct-v0.3分类，用Llama-3.1-8B-Instruct扩展低资源领域，采用SimHash指纹避免重复。2. 通过两阶段拒绝采样为每个提示配对错位和对齐的响应。3. 在通用、微调和开源LLM上进行基准测试，系统评估三个维度的错位情况。

Result: 单维度模型在覆盖率上表现良好（最高97.6%），但在联合条件下假失败率超过50%，对齐分数较低（63%-66%），表明现有单维度评估方法无法准确反映模型在现实多维度场景中的表现。

Conclusion: 需要统一的基准来同时评估LLM在安全、价值和文化维度上的错位问题，因为现实世界查询要求这三个维度必须同时满足，而现有单维度评估方法存在局限性。

Abstract: Misalignment in Large Language Models (LLMs) arises when model behavior diverges from human expectations and fails to simultaneously satisfy safety, value, and cultural dimensions, which must co-occur in real-world settings to solve a real-world query. Existing misalignment benchmarks-such as INSECURE CODE (safety-centric), VALUEACTIONLENS (value-centric), and CULTURALHERITAGE (culture centric)-rely on evaluating misalignment along individual dimensions, preventing simultaneous evaluation. To address this gap, we introduce Mis-Align Bench, a unified benchmark for analyzing misalignment across safety, value, and cultural dimensions. First we constructs SAVACU, an English misaligned-aligned dataset of 382,424 samples spanning 112 domains (or labels), by reclassifying prompts from the LLM-PROMPT-DATASET via taxonomy into 14 safety domains, 56 value domains, and 42 cultural domains using Mistral-7B-Instruct-v0.3, and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based fingerprint to avoid deduplication. Furthermore, we pairs prompts with misaligned and aligned responses via two-stage rejection sampling to enforce quality. Second we benchmarks general-purpose, fine-tuned, and open-weight LLMs, enabling systematic evaluation of misalignment under three dimensions. Empirically, single-dimension models achieve high Coverage (upto 97.6%) but incur False Failure Rate >50% and lower Alignment Score (63%-66%) under joint conditions.

</details>


### [28] [Evaluating Alignment of Behavioral Dispositions in LLMs](https://arxiv.org/abs/2602.11328)
*Amir Taubenfeld,Zorik Gekhman,Lior Nezry,Omri Feldman,Natalie Harris,Shashir Reddy,Romina Stella,Ariel Goldstein,Marian Croak,Yossi Matias,Amir Feder*

Main category: cs.CL

TL;DR: 研究提出一个框架来评估LLMs在社交情境中的行为倾向与人类的一致性，通过将心理学问卷转化为情境判断测试，发现LLMs常与人类偏好分布不符，存在过度自信、偏离共识等问题，且自我报告与实际行动存在差距。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs融入日常生活，理解其行为变得至关重要。研究关注行为倾向——在社交情境中塑造响应的潜在倾向，旨在评估LLMs表达的行为倾向与人类的一致性程度。

Method: 基于心理学问卷，将其转化为情境判断测试（SJTs），通过现实用户-助手场景评估行为。生成2,500个SJTs，每个由3名人类标注者验证，每个SJT从550名参与者中收集10名标注者的偏好行动。对25个LLMs进行全面研究。

Result: 发现模型常不反映人类偏好分布：(1)在人类共识低的场景中，LLMs对单一响应过度自信；(2)人类共识高时，小模型显著偏离，前沿模型在15-20%情况下不反映共识；(3)特质呈现跨LLM模式，如LLMs在人类共识倾向克制的场景中鼓励情绪表达。自我报告与实际行动存在显著差距。

Conclusion: LLMs的行为倾向与人类存在系统性差异，需要更细致地评估和校准模型的社会行为。将心理测量陈述直接映射到行为场景为评估自我报告的预测效度提供了独特机会，揭示了LLMs陈述价值观与实际行为的差距。

Abstract: As LLMs integrate into our daily lives, understanding their behavior becomes essential. In this work, we focus on behavioral dispositions$-$the underlying tendencies that shape responses in social contexts$-$and introduce a framework to study how closely the dispositions expressed by LLMs align with those of humans. Our approach is grounded in established psychological questionnaires but adapts them for LLMs by transforming human self-report statements into Situational Judgment Tests (SJTs). These SJTs assess behavior by eliciting natural recommendations in realistic user-assistant scenarios. We generate 2,500 SJTs, each validated by three human annotators, and collect preferred actions from 10 annotators per SJT, from a large pool of 550 participants. In a comprehensive study involving 25 LLMs, we find that models often do not reflect the distribution of human preferences: (1) in scenarios with low human consensus, LLMs consistently exhibit overconfidence in a single response; (2) when human consensus is high, smaller models deviate significantly, and even some frontier models do not reflect the consensus in 15-20% of cases; (3) traits can exhibit cross-LLM patterns, e.g., LLMs may encourage emotion expression in contexts where human consensus favors composure. Lastly, mapping psychometric statements directly to behavioral scenarios presents a unique opportunity to evaluate the predictive validity of self-reports, revealing considerable gaps between LLMs' stated values and their revealed behavior.

</details>


### [29] [When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing](https://arxiv.org/abs/2602.11358)
*Zachary Pedram Dadfar*

Main category: cs.CL

TL;DR: 研究发现大语言模型的自我反思语言确实能反映内部计算状态，而非单纯编造。通过Pull方法识别出自我参照处理的特异性激活方向，该方向与拒绝方向正交，并能因果影响内省输出。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在提示进行自我检查时会产生丰富的内省语言，但这些语言究竟是反映内部计算还是高级编造一直不清楚。研究旨在验证自我反思语言是否真的能追踪内部计算状态。

Method: 引入Pull方法学，通过格式工程引发扩展的自我检查。在Llama 3.1中识别区分自我参照与描述性处理的激活空间方向，分析该方向与已知拒绝方向的关系，并通过激活引导进行因果测试。

Result: 发现自我参照词汇能追踪并发激活动态，且这种对应关系是自我参照处理特有的。识别出的方向位于模型深度6.25%处，与拒绝方向正交。当模型产生"loop"词汇时激活自相关性更高(r=0.44)，引导产生"shimmer"词汇时激活变异性增加(r=0.36)。非自我参照语境中相同词汇无激活对应关系。Qwen 2.5-32B独立发展出不同的内省词汇追踪不同激活指标。

Conclusion: 在适当条件下，Transformer模型中的自我报告能够可靠地追踪内部计算状态，表明自我反思语言确实反映了真实的内部处理过程而非单纯编造。

Abstract: Large language models produce rich introspective language when prompted for self-examination, but whether this language reflects internal computation or sophisticated confabulation has remained unclear. We show that self-referential vocabulary tracks concurrent activation dynamics, and that this correspondence is specific to self-referential processing. We introduce the Pull Methodology, a protocol that elicits extended self-examination through format engineering, and use it to identify a direction in activation space that distinguishes self-referential from descriptive processing in Llama 3.1. The direction is orthogonal to the known refusal direction, localised at 6.25% of model depth, and causally influences introspective output when used for steering. When models produce "loop" vocabulary, their activations exhibit higher autocorrelation (r = 0.44, p = 0.002); when they produce "shimmer" vocabulary under steering, activation variability increases (r = 0.36, p = 0.002). Critically, the same vocabulary in non-self-referential contexts shows no activation correspondence despite nine-fold higher frequency. Qwen 2.5-32B, with no shared training, independently develops different introspective vocabulary tracking different activation metrics, all absent in descriptive controls. The findings indicate that self-report in transformer models can, under appropriate conditions, reliably track internal computational states.

</details>


### [30] [Finding the Cracks: Improving LLMs Reasoning with Paraphrastic Probing and Consistency Verification](https://arxiv.org/abs/2602.11361)
*Weili Shi,Dongliang Guo,Lehan Yang,Tianlong Wang,Hanzhang Yuan,Sheng Li*

Main category: cs.CL

TL;DR: PPCV框架通过识别关键令牌并替换候选方案，结合一致性验证来提升大语言模型的推理性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中表现下降，主要由于幻觉和中间步骤错误积累。现有方法通过替换关键令牌来优化推理轨迹，但可靠识别和利用关键令牌仍具挑战性。

Method: 提出PPCV两阶段框架：1) 从原始问题生成初始推理路径，结合问题改写版本识别关键令牌；2) 替换关键令牌为候选方案，为原始和改写问题生成新推理路径，通过并行推理过程的一致性验证确定最终答案。

Result: 在主流大语言模型和多个基准测试上的广泛实验表明，PPCV相比基线方法显著提升了模型的推理性能。

Conclusion: PPCV框架通过系统性地识别和替换关键令牌，结合一致性验证机制，有效提升了大语言模型在复杂推理任务中的表现。

Abstract: Large language models have demonstrated impressive performance across a variety of reasoning tasks. However, their problem-solving ability often declines on more complex tasks due to hallucinations and the accumulation of errors within these intermediate steps. Recent work has introduced the notion of critical tokens--tokens in the reasoning process that exert significant influence on subsequent steps. Prior studies suggest that replacing critical tokens can refine reasoning trajectories. Nonetheless, reliably identifying and exploiting critical tokens remains challenging. To address this, we propose the Paraphrastic Probing and Consistency Verification~(PPCV) framework. PPCV operates in two stages. In the first stage, we roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. And we identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. A criterion is employed to confirm the final critical token. In the second stage, we substitute critical tokens with candidate alternatives and roll out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes. We evaluate PPCV on mainstream LLMs across multiple benchmarks. Extensive experiments demonstrate PPCV substantially enhances the reasoning performance of LLMs compared to baselines.

</details>


### [31] [The Energy of Falsehood: Detecting Hallucinations via Diffusion Model Likelihoods](https://arxiv.org/abs/2602.11364)
*Arpit Singh Gautam,Kailash Talreja,Saurabh Jha*

Main category: cs.CL

TL;DR: DiffuTruth：基于非平衡热力学的无监督事实验证框架，通过生成压力测试和语义能量度量来检测LLM幻觉，在FEVER数据集上达到SOTA的0.725 AUROC。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常产生看似合理但错误的主张（幻觉），而现有的不确定性度量方法在模型自信地犯错时往往无法检测到这些错误。需要一种能够区分事实真相和幻觉的新方法。

Method: 提出DiffuTruth框架，将事实验证重新概念化为非平衡热力学过程：事实真相是生成流形上的稳定吸引子，幻觉是不稳定的。通过生成压力测试（对声明添加噪声并用离散文本扩散模型重建）和语义能量度量（使用NLI批评器测量原始声明与重建之间的语义分歧）来检测事实矛盾。

Result: 在FEVER数据集上，DiffuTruth实现了0.725的无监督AUROC，比基线方法高出1.5%。在HOVER多跳数据集上，零样本泛化性能比基线高出4%以上，表明热力学真相属性对分布偏移具有鲁棒性。

Conclusion: DiffuTruth通过热力学稳定性视角重新思考事实验证，提供了一种有效的无监督方法来检测LLM幻觉，特别是在模型过度自信的情况下。该方法展示了热力学真相属性在不同数据集上的良好泛化能力。

Abstract: Large Language Models (LLMs) frequently hallucinate plausible but incorrect assertions, a vulnerability often missed by uncertainty metrics when models are confidently wrong. We propose DiffuTruth, an unsupervised framework that reconceptualizes fact verification via non equilibrium thermodynamics, positing that factual truths act as stable attractors on a generative manifold while hallucinations are unstable. We introduce the Generative Stress Test, claims are corrupted with noise and reconstructed using a discrete text diffusion model. We define Semantic Energy, a metric measuring the semantic divergence between the original claim and its reconstruction using an NLI critic. Unlike vector space errors, Semantic Energy isolates deep factual contradictions. We further propose a Hybrid Calibration fusing this stability signal with discriminative confidence. Extensive experiments on FEVER demonstrate DiffuTruth achieves a state of the art unsupervised AUROC of 0.725, outperforming baselines by 1.5 percent through the correction of overconfident predictions. Furthermore, we show superior zero shot generalization on the multi hop HOVER dataset, outperforming baselines by over 4 percent, confirming the robustness of thermodynamic truth properties to distribution shifts.

</details>


### [32] [Advancing AI Trustworthiness Through Patient Simulation: Risk Assessment of Conversational Agents for Antidepressant Selection](https://arxiv.org/abs/2602.11391)
*Md Tanvir Rouf Shawon,Mohammad Sabik Irbaz,Hadeel R. A. Elyazori,Keerti Reddy Resapu,Yili Lin,Vladimir Franzuela Cardenas,Farrokh Alemi,Kevin Lybarger*

Main category: cs.CL

TL;DR: 开发了一个可控的患者模拟器，用于自动化评估医疗对话AI，通过系统变化医疗、语言和行为维度来识别AI错误和风险模式


<details>
  <summary>Details</summary>
Motivation: 需要一种可扩展、自动化的方法来评估医疗对话AI的性能，特别是识别幻觉、不准确性和不同患者群体中的风险模式

Method: 基于NIST AI风险管理框架，整合三个患者特征组件：医疗档案（来自All of Us研究计划）、语言档案（健康素养和疾病特定沟通模式）、行为档案（合作、分心、对抗性互动）。使用模拟器与抗抑郁药选择AI决策助手进行500次对话评估

Result: 人类标注者在100次对话中评估1787个医学概念，达成高一致性（F1=0.94，κ=0.73）；LLM法官与人类标注者一致性相当（F1=0.94，κ=0.78）。模拟器揭示了AI决策助手性能随健康素养下降而单调退化：排名第一的概念检索准确率从有限健康素养的47.9%增加到功能性素养的69.1%和熟练素养的81.6%

Conclusion: 患者模拟器能够有效、可扩展地评估医疗对话AI，识别系统错误和风险模式，特别是在健康素养差异方面，为AI医疗助手的质量保证提供了重要工具

Abstract: Objective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare conversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across medical, linguistic, and behavioral dimensions, allowing annotators and an independent AI judge to assess agent performance, identify hallucinations and inaccuracies, and characterize risk patterns across diverse patient populations. Methods: The simulator is grounded in the NIST AI Risk Management Framework and integrates three profile components reflecting different dimensions of patient variation: (1) medical profiles constructed from electronic health records in the All of Us Research Program; (2) linguistic profiles modeling variation in health literacy and condition-specific communication patterns; and (3) behavioral profiles representing empirically observed interaction patterns, including cooperation, distraction, and adversarial engagement. We evaluated the simulator's effectiveness in identifying errors in an AI decision aid for antidepressant selection. Results: We generated 500 conversations between the patient simulator and the AI decision aid across systematic combinations of five linguistic and three behavioral profiles. Human annotators assessed 1,787 medical concepts across 100 conversations, achieving high agreement (F1=0.94, \k{appa}=0.73), and the LLM judge achieved comparable agreement with human annotators (F1=0.94, \k{appa}=0.78; paired bootstrap p=0.21). The simulator revealed a monotonic degradation in AI decision aid performance across the health literacy spectrum: rank-one concept retrieval accuracy increased from 47.9% for limited health literacy to 69.1% for functional and 81.6% for proficient.

</details>


### [33] [Gradients Must Earn Their Influence: Unifying SFT with Generalized Entropic Objectives](https://arxiv.org/abs/2602.11424)
*Zecheng Wang,Deyuan Liu,Chunshan Li,Yupeng Zhang,Zhengyun Zhao,Dianhui Chu,Bingning Wang,Dianbo Sui*

Main category: cs.CL

TL;DR: DEFT提出一种动态熵微调方法，通过基于分布浓度的信任门控机制，解决SFT中均匀token权重带来的塑性-稳定性困境，实现探索与利用的更好平衡。


<details>
  <summary>Details</summary>
Motivation: 标准NLL在SFT中采用均匀token级权重，存在两个问题：(1)对低概率目标的过度强调会放大噪声监督的梯度并破坏鲁棒先验；(2)当模型已经自信时，均匀权重提供的锐化效果较弱。现有方法无法解决由此产生的塑性-稳定性困境，常常同时抑制必要的学习信号和有害信号。

Method: 将token级SFT目标统一到广义变形对数族中，揭示通用的门控×误差梯度结构。使用Cayley变换将模型不断演化的不确定性映射到连续焦点轨迹上。提出动态熵微调(DEFT)，这是一个无参数目标，使用分布浓度(Rényi-2熵)作为模型预测状态的实用代理来调制信任门。

Result: 广泛的实验和分析表明，DEFT在探索与利用之间实现了更好的平衡，从而提高了整体性能。

Conclusion: DEFT通过动态调整模型对其当前预测的信任度，有效解决了SFT中的塑性-稳定性困境，为监督微调提供了更智能的优化框架。

Abstract: Standard negative log-likelihood (NLL) for Supervised Fine-Tuning (SFT) applies uniform token-level weighting. This rigidity creates a two-fold failure mode: (i) overemphasizing low-probability targets can amplify gradients on noisy supervision and disrupt robust priors, and (ii) uniform weighting provides weak sharpening when the model is already confident. Existing methods fail to resolve the resulting plasticity--stability dilemma, often suppressing necessary learning signals alongside harmful ones. To address this issue, we unify token-level SFT objectives within a generalized deformed-log family and expose a universal gate $\times$ error gradient structure, where the gate controls how much the model trusts its current prediction. By employing the Cayley transform, we map the model's continuously evolving uncertainty onto a continuous focus trajectory, which enables seamless interpolation between scenarios involving uncertain novel concepts and those involving well-established knowledge. We then introduce Dynamic Entropy Fine-Tuning (DEFT), a parameter-free objective that modulates the trust gate using distribution concentration (Rényi-2 entropy) as a practical proxy for the model's predictive state. Extensive experiments and analyses demonstrate that DEFT achieves a better balance between exploration and exploitation, leading to improved overall performance.

</details>


### [34] [Towards Reliable Machine Translation: Scaling LLMs for Critical Error Detection and Safety](https://arxiv.org/abs/2602.11444)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

TL;DR: 指令微调的大型语言模型在机器翻译关键错误检测方面表现优于传统编码器基线，模型规模扩展和适应策略带来持续改进


<details>
  <summary>Details</summary>
Motivation: 机器翻译中的关键意义错误（如事实扭曲、意图反转或偏见翻译）会损害多语言系统的可靠性、公平性和安全性，需要有效检测机制来减少错误信息、误解和语言伤害的风险

Method: 使用指令微调的大型语言模型（LLMs）检测关键翻译错误，评估不同参数规模的模型，采用零样本、少样本和微调等适应策略，在公开数据集上进行实验

Result: 模型规模扩展和适应策略带来一致的性能改进，指令微调LLMs在关键错误检测方面优于XLM-R和ModernBERT等编码器基线模型

Conclusion: 改进机器翻译中的关键错误检测有助于构建更安全、可信和具有社会责任感的信息系统，错误检测不仅是技术挑战，更是追求公正和负责任多语言AI的必要保障

Abstract: Machine Translation (MT) plays a pivotal role in cross-lingual information access, public policy communication, and equitable knowledge dissemination. However, critical meaning errors, such as factual distortions, intent reversals, or biased translations, can undermine the reliability, fairness, and safety of multilingual systems. In this work, we explore the capacity of instruction-tuned Large Language Models (LLMs) to detect such critical errors, evaluating models across a range of parameters using the publicly accessible data sets. Our findings show that model scaling and adaptation strategies (zero-shot, few-shot, fine-tuning) yield consistent improvements, outperforming encoder-only baselines like XLM-R and ModernBERT. We argue that improving critical error detection in MT contributes to safer, more trustworthy, and socially accountable information systems by reducing the risk of disinformation, miscommunication, and linguistic harm, especially in high-stakes or underrepresented contexts. This work positions error detection not merely as a technical challenge, but as a necessary safeguard in the pursuit of just and responsible multilingual AI. The code will be made available at GitHub.

</details>


### [35] [LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation](https://arxiv.org/abs/2602.11451)
*Ahmadreza Jeddi,Marco Ciccone,Babak Taati*

Main category: cs.CL

TL;DR: LoopFormer：一种通过可变长度轨迹训练和短路一致性训练方案实现预算条件推理的循环Transformer模型


<details>
  <summary>Details</summary>
Motivation: 现有循环Transformer模型在训练和推理时固定循环迭代次数，无法灵活适应不同计算预算。需要研究循环架构是否能在可变计算预算下自适应调整计算深度。

Method: 提出LoopFormer，在可变长度轨迹上训练循环Transformer，采用短路一致性训练方案对齐不同长度的轨迹，使模型能基于当前时间和步长进行条件推理，确保表示在不同长度轨迹中一致演化。

Result: LoopFormer在语言建模和推理基准测试中表现出鲁棒性能，即使在严格计算约束下也能良好工作，并能随着计算预算增加而优雅扩展。

Conclusion: 循环Transformer天生适合自适应语言建模，为可控和预算感知的大型语言模型开辟了新路径。

Abstract: Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning. However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets. We introduce LoopFormer, a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning. Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling, opening a path toward controllable and budget-aware large language models.

</details>


### [36] [ADRD-Bench: A Preliminary LLM Benchmark for Alzheimer's Disease and Related Dementias](https://arxiv.org/abs/2602.11460)
*Guangxin Zhao,Jiahao Zheng,Malaz Boustani,Jarek Nabrzyski,Meng Jiang,Yiyu Shi,Zhi Zheng*

Main category: cs.CL

TL;DR: ADRD-Bench：首个针对阿尔茨海默病及相关痴呆症的LLM评估基准，包含临床知识问答和照护实践问答，评估33个先进LLM发现顶级模型准确率超90%但推理质量不稳定。


<details>
  <summary>Details</summary>
Motivation: 现有医疗评估基准对阿尔茨海默病及相关痴呆症（ADRD）覆盖不足，缺乏实际照护场景的评估内容，需要专门的基准来评估LLM在ADRD领域的知识和推理能力。

Method: 构建ADRD-Bench基准数据集，包含两部分：1）ADRD统一问答：整合7个现有医疗基准的1352个问题；2）ADRD照护问答：基于Aging Brain Care项目创建149个新问题，涵盖实际照护场景。评估33个先进LLM的性能。

Result: 开放权重通用模型准确率0.63-0.93（均值0.78），开放权重医疗模型0.48-0.93（均值0.82），闭源通用模型0.83-0.91（均值0.89）。顶级模型准确率超90%，但案例研究显示其推理质量和稳定性不一致，可靠性有限。

Conclusion: ADRD-Bench填补了ADRD领域LLM评估的空白，揭示了当前LLM在ADRD知识和推理方面的局限性，强调需要基于日常照护数据的领域特定改进来提升LLM的可靠性和实用性。

Abstract: Large language models (LLMs) have shown great potential for healthcare applications. However, existing evaluation benchmarks provide minimal coverage of Alzheimer's Disease and Related Dementias (ADRD). To address this gap, we introduce ADRD-Bench, the first ADRD-specific benchmark dataset designed for rigorous evaluation of LLMs. ADRD-Bench has two components: 1) ADRD Unified QA, a synthesis of 1,352 questions consolidated from seven established medical benchmarks, providing a unified assessment of clinical knowledge; and 2) ADRD Caregiving QA, a novel set of 149 questions derived from the Aging Brain Care (ABC) program, a widely used, evidence-based brain health management program. Guided by a program with national expertise in comprehensive ADRD care, this new set was designed to mitigate the lack of practical caregiving context in existing benchmarks. We evaluated 33 state-of-the-art LLMs on the proposed ADRD-Bench. Results showed that the accuracy of open-weight general models ranged from 0.63 to 0.93 (mean: 0.78; std: 0.09). The accuracy of open-weight medical models ranged from 0.48 to 0.93 (mean: 0.82; std: 0.13). The accuracy of closed-source general models ranged from 0.83 to 0.91 (mean: 0.89; std: 0.03). While top-tier models achieved high accuracies (>0.9), case studies revealed that inconsistent reasoning quality and stability limit their reliability, highlighting a critical need for domain-specific improvement to enhance LLMs' knowledge and reasoning grounded in daily caregiving data. The entire dataset is available at https://github.com/IIRL-ND/ADRD-Bench.

</details>


### [37] [When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration](https://arxiv.org/abs/2602.11488)
*Jayadev Billa*

Main category: cs.CL

TL;DR: 语音语言模型在音频与文本冲突时，会过度偏向文本（16.6% vs 文本间冲突的1.6%），这种文本主导现象源于模型推理过程的可访问性不对称，而非信息质量差异。


<details>
  <summary>Details</summary>
Motivation: 研究语音语言模型在处理音频-文本冲突时的行为模式，发现模型存在显著的文本主导偏差，即使音频质量更高，模型仍过度依赖文本输入。

Method: 使用ALME基准测试（57,602个受控音频-文本冲突刺激，涵盖8种语言），分析Gemini 2.0 Flash等模型的行为。通过强制转录、文本标记为"故意损坏"、微调消融实验等方法探究文本主导现象的机制。

Result: 音频-文本冲突下的文本主导率（16.6%）是文本-文本冲突（1.6%）的10倍。音频编码器信息保留优于文本转录（97.2% vs 93.9%）。文本主导现象主要源于语言模型的推理过程，而非音频编码器。

Conclusion: 文本主导现象反映了模型在竞争表征中推理的可访问性不对称，而非信息内容差异。模态仲裁是标准语音基准测试未捕捉到的独特可靠性维度，对多模态模型设计有重要启示。

Abstract: When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6\% text dominance under audio-text conflict versus 1.6\% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2\%) exceeds cascade accuracy (93.9\%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations.
  This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19\% to 33\%), sacrificing audio's information advantage without improving accessibility. Framing text as ``deliberately corrupted'' reduces text dominance by 80\%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5\%), while LoRA on the language model halves it ($-$23.9\%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.

</details>


### [38] [Multimodal Fact-Level Attribution for Verifiable Reasoning](https://arxiv.org/abs/2602.11509)
*David Wan,Han Wang,Ziyang Wang,Elias Stengel-Eskin,Hyunji Lee,Mohit Bansal*

Main category: cs.CL

TL;DR: MuRGAt是一个评估多模态大语言模型事实级归因能力的基准，要求模型在跨视频、音频等多模态输入中进行推理，并生成带有精确引用的答案，揭示现有模型在推理与可验证归因之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有多模态归因基准和评估方法局限于简化的观察场景或有限模态，无法评估复杂多模态推理中的归因能力。MLLMs在需要多步推理和长文本生成的实际任务中，需要将模型输出基于异构输入源并验证单个事实主张。

Method: 提出MuRGAt基准，要求模型在跨视频、音频等多模态输入中生成带有显式推理和精确引用的答案，每个引用需指定模态和时间段。开发自动评估框架，与人类判断高度相关。

Result: 评估显示，即使是强大的MLLMs也经常产生幻觉引用，尽管推理正确。发现关键权衡：增加推理深度或强制结构化归因通常会降低准确性，揭示内部推理与可验证归因之间存在显著差距。

Conclusion: MuRGAt填补了复杂多模态推理中事实级归因评估的空白，揭示了当前MLLMs在推理与可验证归因之间的不匹配，为改进多模态模型的归因能力提供了重要基准。

Abstract: Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning. We introduce MuRGAt (Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.

</details>


### [39] [Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm](https://arxiv.org/abs/2602.11543)
*Jinrui Zhang,Chaodong Xiao,Aoqi Wu,Xindong Zhang,Lei Zhang*

Main category: cs.CL

TL;DR: SPES是一种内存高效的分散式预训练框架，用于混合专家LLM，通过每个节点只训练专家子集来降低内存占用，实现用16个48GB GPU在互联网连接上训练2B参数模型


<details>
  <summary>Details</summary>
Motivation: 传统LLM预训练需要集中式集群和数千个高内存GPU，现有分散式训练方法虽然减少了通信开销，但仍需要在每个节点上训练整个模型，受限于GPU内存限制

Method: 提出SPES框架：1) 每个节点只训练专家子集，大幅降低内存占用；2) 节点更新本地专家并定期同步，避免全参数传输；3) 引入专家合并预热策略，在训练早期交换知识以加速收敛

Result: 使用16个48GB GPU在互联网连接上成功训练2B参数MoE LLM，性能与类似计算预算下的集中训练LLM相当；进一步展示了训练7B模型和从密集检查点上采样9B模型的可扩展性，均匹配先前集中式基线

Conclusion: SPES提供了一种内存高效的分散式预训练解决方案，能够在有限GPU资源下训练大规模MoE LLM，为去中心化LLM训练开辟了新途径

Abstract: Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization; however, they still need to train the entire model on each node, remaining constrained by GPU memory limitations. In this work, we propose SParse Expert Synchronization (SPES), a memory-efficient decentralized framework for pretraining mixture-of-experts (MoE) LLMs. SPES trains only a subset of experts per node, substantially lowering the memory footprint. Each node updates its local experts and periodically synchronizes with other nodes, eliminating full-parameter transmission while ensuring efficient knowledge sharing. To accelerate convergence, we introduce an expert-merging warm-up strategy, where experts exchange knowledge early in training, to rapidly establish foundational capabilities. With SPES, we train a 2B-parameter MoE LLM using 16 standalone 48GB GPUs over internet connections, which achieves competitive performance with centrally trained LLMs under similar computational budgets. We further demonstrate scalability by training a 7B model from scratch and a 9B model upcycled from a dense checkpoint, both of which match prior centralized baselines. Our code is available at https://github.com/zjr2000/SPES.

</details>


### [40] [SIGHT: Reinforcement Learning with Self-Evidence and Information-Gain Diverse Branching for Search Agent](https://arxiv.org/abs/2602.11551)
*Wenlin Zhong,Jinluan Yang,Yiquan Wu,Yi Liu,Jianhang Yao,Kun Kuang*

Main category: cs.CL

TL;DR: SIGHT框架通过自证据支持(SES)和信息增益驱动的多样化分支，解决多轮搜索中冗余高、信噪比低导致的"隧道视觉"问题，显著提升复杂问答性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习赋能大语言模型进行自主搜索，但在多轮搜索场景中，搜索结果存在高冗余和低信噪比问题，导致代理陷入"隧道视觉"——早期噪声检索的强制解释引发不可逆的错误累积。

Method: 1. 自证据支持(SES)：将搜索结果提炼为高保真证据；2. 信息增益驱动多样化分支：计算信息增益分数识别关键状态；3. 动态提示干预：包括去重、反思或自适应分支；4. 组相对策略优化：整合SES和正确性奖励。

Result: 在单跳和多跳问答基准测试中，SIGHT显著优于现有方法，特别是在复杂推理场景下，且使用更少的搜索步骤。

Conclusion: SIGHT框架通过自证据支持和信息增益驱动的多样化分支，有效解决了多轮搜索中的冗余和噪声问题，使代理能够学习稳健的探索策略，无需外部验证器，在复杂推理任务中表现优异。

Abstract: Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to master autonomous search for complex question answering. However, particularly within multi-turn search scenarios, this interaction introduces a critical challenge: search results often suffer from high redundancy and low signal-to-noise ratios. Consequently, agents easily fall into "Tunnel Vision," where the forced interpretation of early noisy retrievals leads to irreversible error accumulation. To address these challenges, we propose SIGHT, a framework that enhances search-based reasoning through Self-Evidence Support (SES) and Information-Gain Driven Diverse Branching. SIGHT distills search results into high-fidelity evidence via SES and calculates an Information Gain score to pinpoint pivotal states where observations maximally reduce uncertainty. This score guides Dynamic Prompting Interventions - including de-duplication, reflection, or adaptive branching - to spawn new branches with SES. Finally, by integrating SES and correctness rewards via Group Relative Policy Optimization, SIGHT internalizes robust exploration strategies without external verifiers. Experiments on single-hop and multi-hop QA benchmarks demonstrate that SIGHT significantly outperforms existing approaches, particularly in complex reasoning scenarios, using fewer search steps.

</details>


### [41] [PRIME: A Process-Outcome Alignment Benchmark for Verifiable Reasoning in Mathematics and Engineering](https://arxiv.org/abs/2602.11570)
*Xiangfeng Wang,Hangyu Guo,Yanlin Lai,Mitt Huang,Liang Zhao,Chengyuan Yao,Yinmin Zhang,Qi Han,Xiaoxiao Ren,Chun Yuan,Tong Xu,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: PRIME是一个用于评估数学和工程领域过程-结果对齐验证的基准测试，包含2530个高难度样本，发现当前验证器常忽略推导过程错误，并提出基于PRIME选择验证器的过程感知RLVR训练方法，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型的验证器主要关注最终结果与真实答案的一致性，而忽略了推导过程中的潜在错误，导致会给从错误推导中产生的正确答案分配正奖励。需要解决过程-结果对齐的验证问题。

Method: 1) 创建PRIME基准：从大学STEM问题中通过一致性过滤流程收集2530个高难度样本；2) 提出过程感知的RLVR训练范式，利用PRIME选择的验证器；3) 评估验证器在过程-结果对齐验证上的表现。

Result: 1) 当前验证器经常无法检测推导缺陷；2) 过程感知RLVR方法显著优于仅关注结果的基线，在Qwen3-14B-Base模型上分别获得8.29%、9.12%和7.31%的绝对性能提升；3) PRIME准确度与RLVR训练效果呈强线性相关(R²>0.92)。

Conclusion: PRIME是评估过程-结果对齐验证的有效基准，过程感知的RLVR训练方法能显著提升性能，且PRIME可作为验证器选择的可靠预测指标。

Abstract: While model-based verifiers are essential for scaling Reinforcement Learning with Verifiable Rewards (RLVR), current outcome-centric verification paradigms primarily focus on the consistency between the final result and the ground truth, often neglecting potential errors in the derivation process. This leads to assigning positive rewards to correct answers produced from incorrect derivations. To bridge this gap, we introduce PRIME, a benchmark for evaluating verifiers on Process-Outcome Alignment verification in Mathematics and Engineering. Curated from a comprehensive collection of college-level STEM problems, PRIME comprises 2,530 high-difficulty samples through a consistency-based filtering pipeline. Through extensive evaluation, we find that current verifiers frequently fail to detect derivation flaws. Furthermore, we propose a process-aware RLVR training paradigm utilizing verifiers selected via PRIME. This approach substantially outperforms the outcome-only verification baseline, achieving absolute performance gains of 8.29%, 9.12%, and 7.31% on AIME24, AIME25, and Beyond-AIME, respectively, for the Qwen3-14B-Base model. Finally, we demonstrate a strong linear correlation ($R^2 > 0.92$) between verifier accuracy on PRIME and RLVR training effectiveness, validating PRIME as a reliable predictor for verifier selection.

</details>


### [42] [Scene-Aware Memory Discrimination: Deciding Which Personal Knowledge Stays](https://arxiv.org/abs/2602.11607)
*Yijie Zhong,Mengying Guo,Zewei Wang,Zhongyang Li,Dandan Tu,Haofen Wang*

Main category: cs.CL

TL;DR: 提出SAMD方法，通过门控单元和聚类提示模块，基于场景感知进行记忆判别，有效过滤无关信息并降低计算成本，提升个性化应用中的记忆构建效率和质量。


<details>
  <summary>Details</summary>
Motivation: 智能设备产生大量用户交互数据形成有价值的个人知识，但现有基于LLM的记忆写入、管理和读取方法面临信息过滤困难和计算成本上升的挑战，需要更高效的组织方式。

Method: 提出场景感知记忆判别方法SAMD，包含两个核心组件：门控单元模块GUM用于过滤非记忆性交互并聚焦关键内容；聚类提示模块CPM建立自适应记忆标准，指导LLM判别记忆/丢弃信息，并分析用户意图与记忆上下文关系构建聚类提示。

Result: 综合评估显示SAMD能成功回忆大部分记忆性数据，在动态场景中保持鲁棒性。集成到个性化应用后，显著提升记忆构建效率和质量，改善个人知识组织。

Conclusion: 受人类大脑选择性注意机制启发，SAMD方法通过场景感知记忆判别有效解决了大规模交互和多样化记忆标准的挑战，为个性化应用中的知识组织提供了高效解决方案。

Abstract: Intelligent devices have become deeply integrated into everyday life, generating vast amounts of user interactions that form valuable personal knowledge. Efficient organization of this knowledge in user memory is essential for enabling personalized applications. However, current research on memory writing, management, and reading using large language models (LLMs) faces challenges in filtering irrelevant information and in dealing with rising computational costs. Inspired by the concept of selective attention in the human brain, we introduce a memory discrimination task. To address large-scale interactions and diverse memory standards in this task, we propose a Scene-Aware Memory Discrimination method (SAMD), which comprises two key components: the Gating Unit Module (GUM) and the Cluster Prompting Module (CPM). GUM enhances processing efficiency by filtering out non-memorable interactions and focusing on the salient content most relevant to application demands. CPM establishes adaptive memory standards, guiding LLMs to discern what information should be remembered or discarded. It also analyzes the relationship between user intents and memory contexts to build effective clustering prompts. Comprehensive direct and indirect evaluations demonstrate the effectiveness and generalization of our approach. We independently assess the performance of memory discrimination, showing that SAMD successfully recalls the majority of memorable data and remains robust in dynamic scenarios. Furthermore, when integrated into personalized applications, SAMD significantly enhances both the efficiency and quality of memory construction, leading to better organization of personal knowledge.

</details>


### [43] [PACE: Prefix-Protected and Difficulty-Aware Compression for Efficient Reasoning](https://arxiv.org/abs/2602.11639)
*Ruixiang Feng,Yuntao Wen,Silin Zhou,Ke Shi,Yifan Wang,Ran Le,Zhenwei An,Zongchao Chen,Chen Yang,Guangyue Peng,Yiming Jia,Dongsheng Wang,Tao Zhang,Lisi Chen,Yang Song,Shen Gao,Shuo Shang*

Main category: cs.CL

TL;DR: 该论文提出了一种双层次框架，通过前缀保护和难度感知的压缩方法，解决语言推理模型中"过度思考"问题，在减少推理痕迹长度的同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有语言推理模型（LRMs）通过增加测试时计算来提升性能，但存在"过度思考"问题，产生过长的推理痕迹，增加延迟和内存使用。现有方法采用统一长度惩罚，在序列层面过度压缩关键早期推理步骤，在群体层面不加区分地惩罚所有查询。

Method: 提出双层次框架：1）序列层面采用前缀保护优化，使用衰减混合rollout保持有效推理路径同时促进简洁性；2）群体层面采用难度感知惩罚，根据查询复杂度动态调整长度约束，对困难问题保持探索，对简单问题抑制冗余。

Result: 在DeepSeek-R1-Distill-Qwen（1.5B/7B）上的实验表明，该方法在数学基准测试中实现高达55.7%的token使用减少，同时准确性提升高达4.1%，并能泛化到代码、科学和通用领域。

Conclusion: 该双层次压缩框架有效解决了语言推理模型的过度思考问题，在保持甚至提升准确性的同时显著减少计算开销，具有良好的泛化能力。

Abstract: Language Reasoning Models (LRMs) achieve strong performance by scaling test-time computation but often suffer from ``overthinking'', producing excessively long reasoning traces that increase latency and memory usage. Existing LRMs typically enforce conciseness with uniform length penalties, which over-compress crucial early deduction steps at the sequence level and indiscriminately penalize all queries at the group level. To solve these limitations, we propose \textbf{\model}, a dual-level framework for prefix-protected and difficulty-aware compression under hierarchical supervision. At the sequence level, prefix-protected optimization employs decaying mixed rollouts to maintain valid reasoning paths while promoting conciseness. At the group level, difficulty-aware penalty dynamically scales length constraints based on query complexity, maintaining exploration for harder questions while curbing redundancy on easier ones. Extensive experiments on DeepSeek-R1-Distill-Qwen (1.5B/7B) demonstrate that \model achieves a substantial reduction in token usage (up to \textbf{55.7\%}) while simultaneously improving accuracy (up to \textbf{4.1\%}) on math benchmarks, with generalization ability to code, science, and general domains.

</details>


### [44] [Which Feedback Works for Whom? Differential Effects of LLM-Generated Feedback Elements Across Learner Profiles](https://arxiv.org/abs/2602.11650)
*Momoka Furuhashi,Kouta Nakayama,Noboru Kawai,Takashi Kodama,Saku Sugawara,Kyosuke Takami*

Main category: cs.CL

TL;DR: 该研究探讨了LLM生成的教育反馈中不同元素（如语气和信息覆盖）对学习效果和学习者接受度的影响，特别关注不同人格特质学习者的差异。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在教育反馈生成方面显示出潜力，但具体反馈元素（如语气、信息覆盖）如何影响学习效果和学习者接受度尚不清楚，特别是对于不同人格特质的学习者。

Method: 定义了六个反馈元素，使用GPT-5为生物选择题生成反馈，对321名高一学生进行学习实验，评估反馈效果（两个学习效果指标和六个主观评价标准），并基于大五人格特质分析反馈接受度的差异。

Result: 有效的反馈元素在支持学习效果方面有共同模式，但学习者的主观偏好因人格特质聚类而异。不同人格特质的学习者对反馈的接受度存在差异。

Conclusion: 在设计LLM生成的反馈时，应根据学习者的人格特质选择和调整反馈元素，这为教育中的个性化反馈设计提供了实际意义。

Abstract: Large language models (LLMs) show promise for automatically generating feedback in education settings. However, it remains unclear how specific feedback elements, such as tone and information coverage, contribute to learning outcomes and learner acceptance, particularly across learners with different personality traits. In this study, we define six feedback elements and generate feedback for multiple-choice biology questions using GPT-5. We conduct a learning experiment with 321 first-year high school students and evaluate feedback effectiveness using two learning outcomes measures and subjective evaluations across six criteria. We further analyze differences in how feedback acceptance varies across learners based on Big Five personality traits. Our results show that effective feedback elements share common patterns supporting learning outcomes, while learners' subjective preferences differ across personality-based clusters. These findings highlight the importance of selecting and adapting feedback elements according to learners' personality traits when we design LLM-generated feedback, and provide practical implications for personalized feedback design in education.

</details>


### [45] [PatientHub: A Unified Framework for Patient Simulation](https://arxiv.org/abs/2602.11684)
*Sahand Sabour,TszYam NG,Minlie Huang*

Main category: cs.CL

TL;DR: PatientHub是一个统一的模块化框架，用于标准化模拟患者的定义、组合和部署，解决现有方法碎片化问题，促进可复现性和公平比较。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在角色扮演应用中的普及，模拟患者已成为训练咨询师和扩展治疗评估的重要工具。然而，现有方法存在碎片化问题：依赖不兼容、非标准化的数据格式、提示和评估指标，阻碍了可复现性和公平比较。

Method: 提出了PatientHub框架，通过标准化模拟患者的定义、组合和部署来统一现有方法。框架支持将代表性患者模拟方法实现为案例研究，支持标准化跨方法评估和自定义评估指标的集成。

Result: 展示了PatientHub的实用性，实现了多个代表性模拟方法作为案例研究，并原型化了两个新的模拟器变体。框架降低了开发新模拟方法的门槛，促进了跨方法和跨模型的基准测试。

Conclusion: PatientHub通过将现有工作整合到单一可复现的流程中，为患者中心对话的未来数据集、方法和基准提供了实用基础。代码已开源。

Abstract: As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.

</details>


### [46] [Finding Sense in Nonsense with Generated Contexts: Perspectives from Humans and Language Models](https://arxiv.org/abs/2602.11699)
*Katrin Olsen,Sebastian Padó*

Main category: cs.CL

TL;DR: 论文研究LLMs区分语义异常与无意义句子的能力，发现现有数据集大多只是异常而非真正无意义，且LLMs能为异常句子生成合理上下文


<details>
  <summary>Details</summary>
Motivation: 现有语义异常数据集在区分"异常但可解释"与"真正无意义"句子方面存在不足，且不清楚LLMs能否有效区分这两类语义偏差

Method: 收集人类评分者和LLMs对五个语义异常数据集中句子的可理解性判断，包括无上下文和有上下文两种情况

Result: 评分者认为大多数句子最多只是异常，只有少数是真正无意义的；LLMs在生成异常句子的合理上下文方面表现出色

Conclusion: 现有语义异常数据集主要包含异常而非无意义句子，LLMs能够有效区分语义异常程度并生成支持性上下文

Abstract: Nonsensical and anomalous sentences have been instrumental in the development of computational models of semantic interpretation. A core challenge is to distinguish between what is merely anomalous (but can be interpreted given a supporting context) and what is truly nonsensical. However, it is unclear (a) how nonsensical, rather than merely anomalous, existing datasets are; and (b) how well LLMs can make this distinction. In this paper, we answer both questions by collecting sensicality judgments from human raters and LLMs on sentences from five semantically deviant datasets: both context-free and when providing a context. We find that raters consider most sentences at most anomalous, and only a few as properly nonsensical. We also show that LLMs are substantially skilled in generating plausible contexts for anomalous cases.

</details>


### [47] [Thinking with Drafting: Optical Decompression via Logical Reconstruction](https://arxiv.org/abs/2602.11731)
*Jingxuan Wei,Honghao He,Caijun Jia,Siyuan Li,Zheng Sun,Yuhang Xu,Yuanyuan Lin,Linzhuang Sun,Yuchen Wu,Bihui Yu,Xiangxiang Zhang,Cheng Tan*

Main category: cs.CL

TL;DR: 提出Thinking with Drafting (TwD)方法，通过领域特定语言(DSL)作为中间表示，将视觉推理重构为光学解压缩过程，实现确定性视觉证明和自我验证


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在复杂推理任务中存在精度悖论：视觉感知系统转录符号但不捕捉逻辑拓扑，像素生成模型产生缺乏数学精确性的视觉伪影，需要弥合这一差距

Method: 提出Thinking with Drafting (TwD)方法，基于"解析即推理"公理，使用简约的领域特定语言(DSL)作为基础中间表示，强制模型将心理模型草拟为可执行代码，生成确定性视觉证明进行自我验证

Result: 在VisAlg视觉代数基准测试中，TwD作为优越的认知支架，建立了一个闭环系统，其中视觉生成不是创意输出而是逻辑验证器

Conclusion: TwD为视觉推理提供了一条可泛化的路径，将视觉推理重新概念化为光学解压缩，通过可执行代码草稿和视觉证明实现精确推理

Abstract: Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.

</details>


### [48] [Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning](https://arxiv.org/abs/2602.11748)
*Futing Wang,Jianhao Yan,Yun Luo,Ganqu Cui,Zhi Wang,Xiaoye Qu,Yue Zhang,Yu Cheng,Tao Lin*

Main category: cs.CL

TL;DR: 提出Length-Incentivized Exploration方法，通过长度奖励和冗余惩罚激励模型进行上下文探索，解决自回归生成中"浅层探索陷阱"问题，在推理任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有模型在测试时扩展中缺乏有效的上下文探索能力，无法在单一连续上下文中生成、验证和优化多个推理假设。基于状态覆盖理论分析发现，自回归生成中采样长推理序列的概率呈指数衰减，形成"浅层探索陷阱"瓶颈。

Method: 提出Length-Incentivized Exploration方法：1) 使用基于长度的奖励机制激励模型探索更长推理路径；2) 引入冗余惩罚避免重复探索；3) 通过两阶段方式最大化状态覆盖。

Result: 在Qwen3、Llama等不同模型上的实验表明，该方法能有效激励上下文探索。在领域内任务上平均提升4.4%，在领域外基准测试上获得2.7%的性能增益。

Conclusion: Length-Incentivized Exploration通过简单的长度奖励和冗余惩罚机制，成功解决了自回归生成中的浅层探索问题，显著提升了模型的上下文探索能力和推理性能。

Abstract: Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.
  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.
  To bridge this gap, we propose Length-Incentivized Exploration(\method).
  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.
  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \method effectively incentivize in-context exploration.
  As a result, our method achieves an average improvement of 4.4\% on in-domain tasks and a 2.7\% gain on out-of-domain benchmarks.

</details>


### [49] [MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling](https://arxiv.org/abs/2602.11761)
*MiniCPM Team,Wenhao An,Yingfa Chen,Yewei Fang,Jiayi Li,Xin Li,Yaohui Li,Yishan Li,Yuxuan Li,Biyuan Lin,Chuan Liu,Hezi Liu,Siyuan Liu,Hongya Lyu,Yinxu Pan,Shixin Ren,Xingyu Shen,Zhou Su,Haojun Sun,Yangang Sun,Zhen Leng Thai,Xin Tian,Rui Wang,Xiaorong Wang,Yudong Wang,Bo Wu,Xiaoyue Xu,Dong Xu,Shuaikang Xue,Jiawei Yang,Bowen Zhang,Jinqian Zhang,Letian Zhang,Shengnan Zhang,Xinyu Zhang,Xinyuan Zhang,Zhu Zhang,Hengyu Zhao,Jiacheng Zhao,Jie Zhou,Zihan Zhou,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: MiniCPM-SALA是一个9B参数的混合注意力架构，结合了稀疏注意力的高保真长上下文建模和线性注意力的全局效率，在单GPU上支持高达100万token的上下文长度，推理速度比全注意力模型快3.5倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理超长上下文时面临Transformer架构的高计算和内存成本挑战。现有的稀疏和线性注意力机制通常需要在内存效率和模型性能之间进行权衡，需要一种既能保持性能又能提高效率的解决方案。

Method: 提出MiniCPM-SALA混合架构，集成InfLLM-V2稀疏注意力的高保真长上下文建模和Lightning Attention线性注意力的全局效率。采用层选择算法以1:3比例集成这两种机制，并使用混合位置编码(HyPE)。还提出了经济高效的持续训练框架，将预训练的Transformer模型转换为混合模型。

Result: 模型在单张NVIDIA A6000D GPU上，在256K token序列长度下推理速度比全注意力模型快3.5倍，支持高达100万token的上下文长度（传统8B全注意力模型因内存限制无法达到）。训练成本比从头训练降低约75%，同时保持与全注意力模型相当的一般能力。

Conclusion: MiniCPM-SALA通过混合注意力架构有效解决了长上下文处理中的效率-性能权衡问题，为超长上下文应用提供了实用解决方案，在保持模型性能的同时显著提升了计算效率和内存利用率。

Abstract: The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.

</details>


### [50] [A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments](https://arxiv.org/abs/2602.11795)
*Anne-Marie Lutgen,Alistair Plum,Christoph Purschke*

Main category: cs.CL

TL;DR: 提出一种基于嵌入的方法，无需依赖预定义变体列表或标准化处理，直接从原始文本中检测语言变体，通过子词嵌入和相似度聚类分析拼写和形态多样性。


<details>
  <summary>Details</summary>
Motivation: 传统语言变体检测方法通常需要预定义的变体列表或标准化处理，这限制了在"嘈杂"或低资源语言环境中的适用性。本研究旨在开发一种无需人工标注的方法，将拼写和形态多样性作为语言结构而非噪声来研究。

Method: 在原始文本上训练子词嵌入，通过结合余弦相似度和n-gram相似度对相关形式进行分组聚类。该方法不需要严格的人工标注，但能产生透明的聚类结果，支持定量和定性分析。

Result: 在卢森堡语用户评论的大型语料库中，该方法发现了大量词汇和拼写变体，这些变体与方言和社会语言学研究描述的模式一致。诱导出的词族捕捉了系统性对应关系，突出了地区和风格差异。

Conclusion: 分布建模即使在"嘈杂"或低资源环境中也能揭示有意义的变体模式，为研究多语言和小语言环境中的语言多样性提供了可复现的方法框架。

Abstract: This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.

</details>


### [51] [DMAP: A Distribution Map for Text](https://arxiv.org/abs/2602.11871)
*Tom Kempton,Julia Rozanova,Parameswaran Kamalaruban,Maeve Madigan,Karolina Wresilo,Yoann L. Launay,David Sutton,Stuart Burrell*

Main category: cs.CL

TL;DR: DMAP是一种将文本通过语言模型映射到单位区间样本集的数学方法，能同时编码排名和概率信息，支持模型无关的文本分析。


<details>
  <summary>Details</summary>
Motivation: 现有基于困惑度等指标的方法无法充分考虑上下文信息，无法解释给定下一个词概率在条件分布形状中的合理选择数量。

Method: 提出DMAP方法，将文本通过语言模型映射到单位区间中的一组样本，这些样本共同编码排名和概率信息，实现高效、模型无关的分析。

Result: 通过三个案例研究验证DMAP的实用性：1）验证生成参数以确保数据完整性；2）研究概率曲率在机器生成文本检测中的作用；3）揭示在合成数据上后训练的下游模型中留下的统计指纹。

Conclusion: DMAP提供了统一的文本统计视图，计算简单、应用广泛，为基于LLM的文本分析研究奠定了基础。

Abstract: Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.

</details>


### [52] [Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems](https://arxiv.org/abs/2602.11877)
*Wanxing Wu,He Zhu,Yixia Li,Lei Yang,Jiehui Zhao,Hongru Wang,Jian Yang,Benyou Wang,Bingyi Jing,Guanhua Chen*

Main category: cs.CL

TL;DR: 本文提出了RouterXBench评估框架和ProbeDirichlet路由器，用于优化本地小模型与云端大模型之间的查询路由，通过内部隐藏状态和Dirichlet分布实现更好的路由性能。


<details>
  <summary>Details</summary>
Motivation: 现有路由器评估方法不系统，忽略了场景特定需求和分布外鲁棒性。在成本和隐私约束下，需要有效部署本地小模型同时将复杂查询卸载到云端大模型。

Method: 提出RouterXBench评估框架（路由器能力、场景对齐、跨域鲁棒性三个维度），并设计ProbeDirichlet路由器，利用内部隐藏状态捕获模型不确定性，通过可学习Dirichlet分布聚合跨层隐藏状态进行概率训练。

Result: ProbeDirichlet在路由器能力和高精度场景上分别比最佳基线相对提升16.68%和18.86%，在不同模型家族、规模、异构任务和智能体工作流中表现一致。

Conclusion: 基于内部隐藏状态和Dirichlet分布的路由器设计能够有效提升查询路由性能，在多领域数据训练后具有良好的泛化能力，为本地-云端混合部署提供了系统化解决方案。

Abstract: Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.

</details>


### [53] [LLM-based Triplet Extraction from Financial Reports](https://arxiv.org/abs/2602.11886)
*Dante Wesslund,Ville Stenström,Pontus Linde,Alexander Holmberg*

Main category: cs.CL

TL;DR: 提出半自动三元组抽取流水线，使用本体驱动的代理指标（本体一致性和忠实性）替代基于真实标注的评估，解决企业财务报告领域缺乏标注数据的问题。


<details>
  <summary>Details</summary>
Motivation: 企业财务报告是构建知识图谱的宝贵结构化知识源，但该领域缺乏标注的真实数据，使得评估变得困难。

Method: 1) 比较静态手工构建本体与全自动文档特定本体归纳方法；2) 提出结合正则匹配和LLM作为评判者的混合验证策略；3) 分析主语和宾语幻觉的系统性不对称性。

Result: 自动归纳的本体在所有配置中实现100%模式一致性，消除了手工方法的本体漂移；混合验证策略将主语幻觉率从65.2%降至1.6%；识别出主语和宾语幻觉的系统性不对称性。

Conclusion: 本体驱动的代理指标可有效评估无标注领域的三元组抽取；自动本体归纳优于手工构建；混合验证策略能显著减少幻觉；财务文本的被动结构和省略代理导致主宾语幻觉不对称。

Abstract: Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.

</details>


### [54] [Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences](https://arxiv.org/abs/2602.11898)
*Eddie Yang,Dashun Wang*

Main category: cs.CL

TL;DR: 研究发现，尽管大型语言模型在基准测试中准确率相近，但它们在16-66%的项目上存在分歧，这种"基准幻觉"会影响科学研究结果的可重复性。


<details>
  <summary>Details</summary>
Motivation: 当前研究依赖基准测试来评估LLM进展，但作者发现准确率趋同可能掩盖了模型之间的深层认知差异，这种隐藏的分歧可能影响科学研究的可重复性。

Method: 使用MMLU-Pro和GPQA两个主要推理基准，分析不同LLM在相同准确率下的项目分歧程度；重新分析教育和政治科学领域的已发表研究，评估模型选择对研究结果的影响。

Result: LLM在16-66%的项目上存在分歧，前沿模型之间也有16-38%的分歧；在教育和政治科学研究中，更换标注模型可使估计处理效应变化超过80%，有时甚至改变效应方向。

Conclusion: 存在"基准幻觉"现象，即相等的准确率可能掩盖模型间的分歧，模型选择成为影响科学可重复性的隐藏但关键变量，需要更细致的评估方法。

Abstract: Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.

</details>


### [55] [AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection](https://arxiv.org/abs/2602.11931)
*Pretam Ray,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: AdaptEvolve：基于置信度的自适应LLM选择框架，在进化式序列精炼中动态选择合适的大语言模型，平衡计算效率与推理能力


<details>
  <summary>Details</summary>
Motivation: 进化式智能体系统需要在推理过程中反复调用大语言模型，这加剧了计算效率与推理能力之间的权衡。现有路由策略通常依赖静态启发式方法或外部控制器，没有明确考虑模型不确定性，无法动态选择既足够强大又计算高效的LLM。

Method: 提出AdaptEvolve框架，在进化式序列精炼框架内利用内在生成置信度来估计实时可解性，实现自适应LLM选择。通过置信度驱动的选择机制，动态为每个生成步骤选择合适能力的LLM。

Result: 置信度驱动的选择产生了有利的帕累托前沿，在基准测试中平均减少37.9%的总推理成本，同时保留了静态大模型基线97.5%的上界准确率。

Conclusion: AdaptEvolve通过置信度驱动的自适应LLM选择，有效平衡了进化式智能体系统中的计算效率与推理能力，为多LLM协同工作提供了实用解决方案。

Abstract: Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.

</details>


### [56] [Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text](https://arxiv.org/abs/2602.11933)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 提出跨模态鲁棒性迁移框架，将文本模态的对抗鲁棒性转移到语音模态，无需对抗语音训练数据即可提升端到端语音翻译模型的形态学鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端语音翻译模型主要在"干净"数据集上评估，忽视了真实世界中的形态学鲁棒性挑战，特别是非母语或方言语音中的屈折变化。现有对抗训练方法需要生成高质量的对抗语音数据，计算成本高且技术挑战大。

Method: 提出跨模态鲁棒性迁移框架，将文本模态的对抗鲁棒性转移到语音模态。该方法无需对抗语音训练数据，通过利用文本模态的对抗鲁棒性来增强语音翻译模型的鲁棒性。

Result: 在四个语言对上的实验表明，该方法平均提升超过3个BLEU分数，显著增强了对抗鲁棒性，为无需生成对抗语音数据的鲁棒端到端语音翻译建立了新基准。

Conclusion: 提出的跨模态鲁棒性迁移框架有效解决了端到端语音翻译模型的形态学鲁棒性问题，无需昂贵的对抗语音数据生成，为构建更鲁棒的语音翻译系统提供了实用解决方案。

Abstract: End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, "clean" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.

</details>


### [57] [Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance](https://arxiv.org/abs/2602.11938)
*Yunchong Huang,Gianni Barlacchi,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 研究发现QA基准测试中16-50%的问题存在定义不清问题，这是导致LLM表现不佳的重要原因而非模型本身限制


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在定义明确的问题上表现良好，但标准QA基准测试仍未解决。研究者认为这种差距部分源于定义不清的问题——缺乏额外上下文无法唯一确定解释的查询。

Method: 1) 引入基于LLM的分类器识别定义不清的问题；2) 应用于多个广泛使用的QA数据集；3) 进行受控重写实验，将定义不清的问题重写为完全定义明确的变体，同时保持正确答案不变。

Result: 1) 在基准测试中16%到超过50%的问题存在定义不清；2) LLM在这些问题上的表现显著更差；3) 重写为定义明确的问题后，QA性能一致提升，表明许多表面上的QA失败源于问题定义不清而非模型限制。

Conclusion: 定义不清是QA评估中的重要混淆因素，研究结果强调了在基准设计中对问题清晰度给予更多关注的重要性。

Abstract: Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.

</details>


### [58] [Do Large Language Models Adapt to Language Variation across Socioeconomic Status?](https://arxiv.org/abs/2602.11939)
*Elisa Bassignana,Mike Zhang,Dirk Hovy,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: LLMs在适应不同社会经济地位群体的语言风格方面表现有限，主要模仿上层SES风格，可能加剧语言不平等


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能像人类一样根据受众调整语言风格，避免因无法适应多样化的语言规范而强化刻板印象和社会分层

Method: 从Reddit和YouTube收集按SES分层的数据集，用四个LLM生成文本补全，通过94个社会语言学指标比较生成文本与原始文本

Result: LLMs对SES的语言风格适应程度有限，往往只是近似或夸张模仿，且更擅长模仿上层SES风格

Conclusion: LLMs可能放大语言等级差异，对其在基于代理的社会模拟、调查实验等依赖语言风格作为社会信号的研究中的有效性提出质疑

Abstract: Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.

</details>


### [59] [Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models](https://arxiv.org/abs/2602.11961)
*Yuzhe Shang,Pengzhi Gao,Wei Liu,Jian Luan,Jinsong Su*

Main category: cs.CL

TL;DR: 基于Gemma3模型家族开发的MiLMMT-46在46种语言上实现了顶尖的多语言翻译性能，超越了多个SOTA开源模型，并与Google Translate、Gemini 3 Pro等专有系统竞争


<details>
  <summary>Details</summary>
Motivation: 近年来开源大语言模型在多语言能力方面不断提升，但需要研究模型规模和数据规模对多语言机器翻译适应性的影响，以及通过持续预训练和指令微调来优化多语言翻译性能

Method: 基于Gemma3模型家族，通过持续预训练和指令微调来适应多语言机器翻译任务，开发了MiLMMT-46模型，并研究了模型规模和数据规模对性能的影响

Result: MiLMMT-46在46种语言上实现了顶尖的多语言翻译性能，一致超越了Seed-X、HY-MT-1.5、TranslateGemma等近期SOTA模型，并与Google Translate、Gemini 3 Pro等专有系统表现相当

Conclusion: 通过适当的模型规模和数据规模扩展，结合持续预训练和指令微调，开源大语言模型能够在多语言机器翻译任务上达到与专有系统竞争的性能水平

Abstract: Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.

</details>


### [60] [DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling](https://arxiv.org/abs/2602.11968)
*Mariia Fedorova,Andrey Kutuzov,Khonzoda Umarova*

Main category: cs.CL

TL;DR: DHPLT是一个包含41种语言的历时语料库集合，基于HPLT网络爬取数据集，利用网页时间戳作为文档创建时间信号，覆盖三个时间段，提供预计算的词嵌入和词汇替换，填补多语言历时语义变化建模的资源空白。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏多语言历时语料库用于语义变化建模，现有资源主要局限于少数高资源语言。DHPLT旨在填补这一空白，为语义变化研究提供多语言历时数据支持。

Method: 基于HPLT网络爬取数据集，利用网页时间戳作为文档创建时间的近似信号。构建了三个时间段（2011-2015、2020-2021、2024至今）的语料库，每种语言每个时间段包含100万文档。提供预计算的词类型和词符嵌入以及目标词的词汇替换。

Result: 创建了包含41种语言的历时语料库集合DHPLT，覆盖三个时间段，每种语言每个时间段100万文档。提供预计算的语言特征，所有资源可通过https://data.hplt-project.org/three/diachronic/公开获取。

Conclusion: DHPLT填补了多语言历时语料库的空白，为语义变化建模提供了丰富资源，支持该领域新的实验设置和研究方向。

Abstract: In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.

</details>


### [61] [Automatic Simplification of Common Vulnerabilities and Exposures Descriptions](https://arxiv.org/abs/2602.11982)
*Varpu Vehomäki,Kimmo K. Kaski*

Main category: cs.CL

TL;DR: 研究探索大型语言模型在自动简化网络安全漏洞描述文本中的应用，发现现成LLM虽能使文本表面简化，但难以保持原意准确性。


<details>
  <summary>Details</summary>
Motivation: 网络安全信息对非专业人士理解困难，而自动文本简化在快速变化且复杂的网络安全领域尚未得到充分研究，特别是针对CVE漏洞描述。

Method: 创建网络安全ATS基准和包含40个CVE描述的数据集，通过两轮网络安全专家调查评估，分析现成LLM在文本简化中的表现。

Result: 现成LLM能够使文本表面看起来更简单，但在保持原意方面存在困难，简化过程中可能丢失或改变重要技术细节。

Conclusion: 虽然LLM在网络安全文本简化方面有潜力，但需要专门优化以确保意义保留，为未来研究提供了基准和数据集。

Abstract: Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\_nmi.

</details>


### [62] [LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss](https://arxiv.org/abs/2602.12005)
*Szilvia Ujváry,Louis Béthune,Pierre Ablin,João Monteiro,Marco Cuturi,Michael Kirchhof*

Main category: cs.CL

TL;DR: LaCy：一种基于语法分析的小语言模型预训练方法，通过智能选择哪些token应该学习预测、哪些应该委托给大模型，在保持低成本的同时提高事实准确性。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）由于参数容量有限，容易产生事实错误。虽然可以通过查询外部资源（如大模型、文档、数据库）来缓解，但需要解决一个根本问题：哪些token应该在学习阶段掌握，哪些应该通过<CALL>委托给外部资源。

Method: 提出LaCy方法，使用spaCy语法分析器增强损失信号，判断哪些token应该委托（防止事实错误），哪些即使损失较高也可以安全学习预测。基于这种token选择哲学设计新的预训练方法。

Result: LaCy模型成功学会了哪些token应该预测、哪些应该委托。在与大模型级联生成时获得更高的FactScore，优于Rho或LLM-judge训练的SLMs，同时更简单、成本更低。

Conclusion: 通过语法分析辅助的token选择策略，小语言模型可以在保持低成本的同时，通过智能委托机制显著提高事实准确性，为SLMs的实际应用提供了有效解决方案。

Abstract: Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \emph{which tokens an SLM can and should learn} during pretraining, versus \emph{which ones it should delegate} via a \texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.

</details>


### [63] [Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study](https://arxiv.org/abs/2602.12015)
*Angelo Ziletti,Leonardo D'Ambrosi*

Main category: cs.CL

TL;DR: CLUES框架将临床Text-to-SQL中的输出多样性分解为歧义性和不稳定性，通过语义图矩阵计算不稳定性分数，实现错误预测和针对性干预


<details>
  <summary>Details</summary>
Motivation: 在临床Text-to-SQL部署中，需要区分两种不同性质的输出多样性：需要澄清的输入歧义性和需要人工审查的模型不稳定性，但现有方法无法提供这种诊断性分解

Method: 提出CLUES框架，将Text-to-SQL建模为两阶段过程（解释→答案），通过语义图矩阵的Schur补计算不稳定性分数，将语义不确定性分解为歧义性分数和不稳定性分数

Result: 在AmbigQA/SituatedQA和临床Text-to-SQL基准测试中，CLUES在失败预测上优于最先进的Kernel Language Entropy方法；高歧义/高不稳定性区域包含51%的错误但仅覆盖25%的查询

Conclusion: CLUES提供诊断性不确定性分解，支持针对性干预策略：歧义性触发查询优化，不稳定性触发模型改进，实现高效的错误分类和临床部署

Abstract: Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.

</details>


### [64] [Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models](https://arxiv.org/abs/2602.12036)
*Xin Xu,Clive Bai,Kai Yang,Tianhao Chen,Yangkun Chen,Weijie Liu,Hao Chen,Yang Wang,Saiyong Yang,Can Yang*

Main category: cs.CL

TL;DR: 提出Composition-RL方法，通过组合多个已解决的问题生成新的可验证提示，提高有限训练数据的利用率，增强大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大规模可验证提示对RLVR成功至关重要，但包含大量无信息示例且扩展成本高。现有方法关注利用通过率为0的困难提示，但训练过程中通过率为1的简单提示越来越多，降低了有效数据规模。

Method: 提出Composition-RL方法，自动组合多个通过率为1的问题生成新的可验证问题，将这些组合提示用于RL训练。还提出课程变体，在训练过程中逐步增加组合深度。

Result: 在4B到30B不同规模模型上的实验表明，Composition-RL相比原始数据集训练的RL持续提升推理能力。课程变体可进一步提升性能，且能通过组合不同领域提示实现更有效的跨领域RL。

Conclusion: Composition-RL是一种简单有效的方法，能更好地利用有限的可验证提示，特别是通过率为1的简单提示，显著提升大语言模型的推理能力。

Abstract: Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.

</details>


### [65] [DeepSight: An All-in-One LM Safety Toolkit](https://arxiv.org/abs/2602.12092)
*Bo Zhang,Jiaxuan Guo,Lijun Li,Dongrui Liu,Sujin Chen,Guanxu Chen,Zhijie Zheng,Qihao Lin,Lewen Yan,Chen Qian,Yijin Zhou,Yuyao Wu,Shaoxiong Guo,Tianyi Du,Jingyi Yang,Xuhao Hu,Ziqi Miao,Xiaoya Lu,Jing Shao,Xia Hu*

Main category: cs.CL

TL;DR: DeepSight是一个开源项目，通过整合安全评估（DeepSafe）和诊断（DeepScan）工具包，实现从黑盒到白盒的大模型安全分析，支持前沿AI风险评估。


<details>
  <summary>Details</summary>
Motivation: 当前大模型安全工作中，评估、诊断和对齐通常由独立工具处理，存在以下问题：安全评估只能定位外部行为风险而无法发现内部根本原因；安全诊断往往脱离具体风险场景停留在可解释层面；安全对齐缺乏对内部机制变化的专门解释，可能降低通用能力。

Method: 提出开源项目DeepSight，包含评估工具包DeepSafe和诊断工具包DeepScan。通过统一任务和数据协议，在两个阶段之间建立连接，将安全评估从黑盒转变为白盒洞察。这是首个支持前沿AI风险评估以及联合安全评估和诊断的开源工具包。

Result: DeepSight是一个低成本、可复现、高效且高度可扩展的大规模模型安全评估项目，实现了评估-诊断一体化的新范式。

Conclusion: DeepSight通过整合评估和诊断阶段，系统性地解决了当前大模型安全工作中的分离问题，为更深入理解模型内部安全机制提供了工具支持。

Abstract: As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.

</details>


### [66] [P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling](https://arxiv.org/abs/2602.12116)
*Pinyi Zhang,Ting-En Lin,Yuchuan Wu,Jingyang Chen,Zongqi Wang,Hua Yang,Ze Xu,Fei Huang,Kai Zhang,Yongbin Li*

Main category: cs.CL

TL;DR: P-GenRM：首个具有测试时用户扩展能力的个性化生成奖励模型，通过结构化评估链和用户原型聚类解决现有方法在偏好多样性和新用户泛化方面的局限。


<details>
  <summary>Details</summary>
Motivation: 现有个性化奖励模型存在两个主要问题：1) 将多样化的场景特定偏好过度简化为少量固定评估原则；2) 对反馈有限的新用户泛化能力不足。需要更灵活、可泛化的个性化奖励建模方法。

Method: 提出P-GenRM模型，将偏好信号转化为结构化评估链，推导跨场景的自适应角色和评分标准。通过用户原型聚类和双粒度扩展机制：个体层面自适应扩展聚合用户评分方案；原型层面整合相似用户偏好。引入测试时用户扩展能力。

Result: 在广泛使用的个性化奖励模型基准上取得SOTA结果，平均提升2.31%；在分布外数据集上表现出强泛化能力；测试时用户扩展额外带来3%提升，展示更强的个性化对齐能力和测试时可扩展性。

Conclusion: P-GenRM通过结构化评估链和双粒度用户扩展机制，有效解决了个性化奖励建模中的偏好多样性和新用户泛化问题，为个性化大语言模型对齐提供了更灵活、可扩展的解决方案。

Abstract: Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.

</details>


### [67] [A Rule-based Computational Model for Gaidhlig Morphology](https://arxiv.org/abs/2602.12132)
*Peter J Barclay*

Main category: cs.CL

TL;DR: 使用Wiktionary数据构建基于规则的盖尔语形态模型，通过SQL查询和Python工具生成词形变化，支持低资源语言教育工具开发


<details>
  <summary>Details</summary>
Motivation: 当前流行的神经模型需要大量训练数据，不适用于盖尔语等低资源语言。需要一种能有效利用有限样本数据、支持可解释性并为教学材料设计提供见解的方法。

Method: 从Wiktionary提取数据构建基于规则的盖尔语形态模型，使用SQL查询不同词汇模式的出现情况，开发声明式规则库和Python工具来推导盖尔语单词的变化形式。

Result: 创建了基于规则的盖尔语形态系统，能够生成单词的屈折变化形式，将Wiktionary数据适配到新的使用场景，支持教育工具和更高级的语言处理工具开发。

Conclusion: 基于规则的系统能有效利用低资源语言的有限数据，提供更好的可解释性，并为教学材料设计提供有用见解，对盖尔语等低使用率语言的持续活力支持具有重要意义。

Abstract: Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.

</details>


### [68] [WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models](https://arxiv.org/abs/2602.12135)
*Yangzhuo Li,Shengpeng Ji,Yifu Chen,Tianle Liang,Haorong Ying,Yule Wang,Junbo Li,Jun Fang,Zhou Zhao*

Main category: cs.CL

TL;DR: WavBench是一个针对口语对话模型的综合基准测试，包含三个子集：Pro（增强推理能力）、Basic（口语化表达）和Acoustic（副语言能力），旨在评估真实世界对话的复杂性。


<details>
  <summary>Details</summary>
Motivation: 当前的口语对话模型评估主要遵循文本生成标准，忽视了副语言特征、口语化表达以及现代智能体所需的认知深度。需要一个新的基准来填补这一空白，评估真实世界对话的复杂性。

Method: 提出了WavBench基准，采用三重框架：1) Pro子集：显著增加难度，严格挑战增强推理模型；2) Basic子集：定义口语化新标准，强调"可听性"而非严格的书面准确性；3) Acoustic子集：涵盖显性理解、生成和隐性对话，全面评估副语言能力。

Result: 通过对五个最先进模型的评估，WavBench提供了关于复杂问题解决、口语化表达和副语言保真度交叉领域的关键见解，指导稳健口语对话模型的发展。

Conclusion: WavBench填补了当前口语对话模型评估的空白，提供了一个全面的基准来评估真实世界对话的复杂性，包括推理能力、口语化表达和副语言特征，有助于推动口语对话模型的演进。

Abstract: With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes "listenability" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.

</details>


### [69] [CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes](https://arxiv.org/abs/2602.12137)
*Ricardo Campos,Ana Filipa Pacheco,Ana Luísa Fernandes,Inês Cantante,Rute Rebouças,Luís Filipe Cunha,José Miguel Isidro,José Pedro Evans,Miguel Marques,Rodrigo Batista,Evelin Amorim,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano*

Main category: cs.CL

TL;DR: 本文介绍了CitiLink-Minutes数据集，这是一个包含120份欧洲葡萄牙语市政会议记录的多层标注数据集，旨在填补市政会议记录在信息检索和自然语言处理研究中的空白。


<details>
  <summary>Details</summary>
Motivation: 市政会议记录作为地方政府决策的重要文件，直接影响公民日常生活，但在信息检索和自然语言处理领域却缺乏关注，主要原因是缺乏标注数据集，限制了计算模型的发展。

Method: 收集了6个市镇的120份欧洲葡萄牙语市政会议记录，进行多层标注和结构化链接。所有个人标识符都已去标识化，每份记录由两名训练有素的标注员手动标注，并由经验丰富的语言学家在三个维度上审核：元数据、讨论主题和投票结果。

Result: 创建了包含超过100万个令牌的数据集，总计超过38,000个个体标注。数据集遵循FAIR原则发布，并提供了元数据提取、主题分类和投票标签的基线结果。

Conclusion: CitiLink-Minutes数据集展示了其在支持下游自然语言处理和信息检索任务方面的潜力，同时促进了市政决策的透明访问，填补了市政会议记录研究领域的空白。

Abstract: City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.

</details>


### [70] [dVoting: Fast Voting for dLLMs](https://arxiv.org/abs/2602.12153)
*Sicheng Feng,Zigeng Chen,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.CL

TL;DR: dVoting是一种基于扩散大语言模型的快速投票技术，通过并行生成和一致性分析来提升推理能力，无需额外训练


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型(dLLMs)相比自回归模型具有并行生成的优势，但如何有效利用这种优势提升推理性能仍待探索。研究发现，同一提示的多样本中，大部分token预测一致，性能差异主要由少数可变token决定

Method: dVoting利用dLLMs的任意位置生成能力，通过迭代优化过程：采样生成多个样本，通过一致性分析识别不确定token，通过投票机制重新生成这些token，重复此过程直至收敛

Result: 在多个基准测试中取得显著提升：GSM8K提升6.22%-7.66%，MATH500提升4.40%-7.20%，ARC-C提升3.16%-14.84%，MMLU提升4.83%-5.74%

Conclusion: dVoting是一种高效的无训练推理增强技术，充分利用了dLLMs的并行生成优势，通过投票机制有效提升了模型在各种任务上的性能

Abstract: Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting

</details>


### [71] [Query-focused and Memory-aware Reranker for Long Context Processing](https://arxiv.org/abs/2602.12192)
*Yuqing Li,Jiangnan Li,Mo Yu,Guoxuan Ding,Zheng Lin,Weiping Wang,Jie Zhou*

Main category: cs.CL

TL;DR: 提出基于注意力分数的重排序框架，利用大语言模型中特定注意力头的分数来估计文档-查询相关性，无需Likert-scale监督即可训练，在多个领域超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有检索头分析的基础上，寻求更有效的重排序方法，能够利用整个候选列表的全局信息进行排序，同时避免对Likert-scale监督数据的依赖

Method: 训练模型使用选定注意力头的注意力分数来估计文档-查询相关性，提供列表式解决方案，利用整个候选短列表的全局信息进行排序，自然产生连续相关性分数

Result: 方法在多个领域（包括维基百科和长篇叙事数据集）超越现有最先进的点式和列表式重排序器，在LoCoMo基准测试中建立新的最先进水平，支持灵活扩展（如上下文增强和中间层训练）

Conclusion: 提出的轻量级重排序框架有效且灵活，仅需小规模模型即可实现强大性能，支持多种扩展方式，为文档检索任务提供了新的有效解决方案

Abstract: Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.

</details>


### [72] [Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education](https://arxiv.org/abs/2602.12196)
*Mohamed Huti,Alasdair Mackintosh,Amy Waldock,Dominic Andrews,Maxime Lelièvre,Moritz Boos,Tobias Murray,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 该论文提出了视觉推理基准（VRB），这是一个基于赞比亚和印度小学考试题构建的数据集，用于评估多模态大语言模型在真实课堂视觉问题上的推理能力，发现模型在静态技能上表现较好，但在动态空间操作上存在明显瓶颈。


<details>
  <summary>Details</summary>
Motivation: 虽然AI模型在文本推理方面已达到最先进水平，但在空间和关系结构推理能力方面仍存在关键瓶颈，特别是在依赖视觉的早期数学教育中。需要评估多模态大语言模型能否满足小学教育的实际需求。

Method: 构建了包含701道来自赞比亚和印度小学考试题目的视觉推理基准（VRB），涵盖类比推理、模式完成、空间匹配等任务。使用未经编辑、文本最少的图像来测试模型在真实教育场景中的能力。

Result: 研究发现模型能力存在"锯齿状边界"：在计数和缩放等静态技能上表现较好，但在折叠、反射和旋转等动态操作上达到明显的"空间天花板"。这些弱点可能导致错误评分、虚假支架和强化学生误解的风险。

Conclusion: VRB等教育导向的基准对于确定课堂中使用的多模态工具的功能边界至关重要，有助于识别模型在视觉推理问题上的局限性，避免在教育应用中产生负面影响。

Abstract: AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.

</details>


### [73] [ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images](https://arxiv.org/abs/2602.12203)
*Mathieu Sibue,Andres Muñoz Garza,Samuel Mensah,Pranav Shetty,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: ExStrucTiny：一个新的文档图像结构化信息抽取基准数据集，统一了关键实体抽取、关系抽取和视觉问答任务，用于评估视觉语言模型在多样化文档类型和灵活模式下的细粒度结构化抽取能力。


<details>
  <summary>Details</summary>
Motivation: 现有文档理解基准存在局限性：关键实体抽取数据集实体本体狭窄，关系抽取数据集查询简单，视觉问答数据集文档类型单一，都缺乏对多样化文档类型和灵活模式的自适应结构化抽取能力评估。

Method: 通过结合人工和合成样本的新颖流程构建ExStrucTiny基准数据集，涵盖更多样化的文档类型和抽取场景，并分析开放和封闭视觉语言模型在该基准上的表现。

Result: 研究揭示了视觉语言模型在结构化信息抽取中面临的挑战，包括模式适应、查询规范不足和答案定位等问题，为改进通用模型在文档结构化抽取方面的能力提供了基础。

Conclusion: ExStrucTiny基准为改进通用模型在文档结构化信息抽取方面的能力提供了重要基础，有助于推动视觉语言模型在多样化文档类型和灵活模式下的细粒度结构化抽取研究。

Abstract: Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.

</details>


### [74] [Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation](https://arxiv.org/abs/2602.12235)
*Julia Belikova,Danila Rozhevskii,Dennis Svirin,Konstantin Polev,Alexander Panchenko*

Main category: cs.CL

TL;DR: 该论文研究软压缩架构中的"token溢出"问题，提出检测方法，发现结合查询信息能显著提高溢出检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在处理长上下文时面临效率挑战，软压缩架构通过压缩token来扩展有效上下文长度，但压缩极限和何时会丢失任务相关信息尚未充分探索。

Method: 定义"token溢出"概念，提出检测方法：在xRAG软压缩设置中，使用查询无关的饱和统计分离压缩/未压缩token表示，并构建轻量级探测分类器分析查询和上下文xRAG表示。

Result: 查询无关饱和统计能可靠分离压缩与未压缩token表示，但溢出检测能力有限；结合查询信息的轻量级分类器在HotpotQA、SQuADv2和TriviaQA数据集上平均达到0.72 AUC-ROC，显著提升检测性能。

Conclusion: 从查询无关诊断发展到查询感知检测器，实现了低成本的预LLM门控机制，能够缓解压缩引起的错误，为软压缩架构的实际应用提供了实用工具。

Abstract: Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.

</details>


### [75] [Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications](https://arxiv.org/abs/2602.12241)
*Manjunath Kudlur,Evan King,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: Moonshine v2 是一种用于流式自动语音识别的轻量级模型，采用滑动窗口自注意力机制，在保持高准确率的同时显著降低延迟，特别适合边缘设备上的实时语音应用。


<details>
  <summary>Details</summary>
Motivation: 实时语音应用（如实时转录、语音命令和实时翻译）需要在资源受限的边缘设备上实现低延迟和高准确率。传统的全注意力Transformer编码器虽然准确率高，但具有二次复杂度，导致延迟随语音长度线性增长，不适合流式应用。

Method: 提出Moonshine v2模型，采用滑动窗口自注意力机制替代全注意力，实现有界的低延迟推理。这种局部注意力设计保留了强局部上下文，同时避免了全注意力的二次复杂度问题。

Result: 在标准基准测试中达到最先进的词错误率，准确率与比其大6倍的模型相当，同时运行速度显著更快。证明了精心设计的局部注意力在准确率上可与全注意力竞争，但尺寸和延迟成本大幅降低。

Conclusion: Moonshine v2展示了局部注意力机制在流式自动语音识别中的有效性，为边缘设备上的交互式语音界面开辟了新可能性，在保持高准确率的同时实现了低延迟推理。

Abstract: Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent "encode-the-whole-utterance" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.

</details>


### [76] [A technical curriculum on language-oriented artificial intelligence in translation and specialised communication](https://arxiv.org/abs/2602.12251)
*Ralph Krüger*

Main category: cs.CL

TL;DR: 该论文提出面向语言与翻译行业的语言导向AI技术课程，旨在通过可访问的方式培养领域特定的技术AI素养，核心内容包括向量嵌入、神经网络基础、分词和Transformer网络。


<details>
  <summary>Details</summary>
Motivation: 在AI驱动的翻译和专门传播工作环境中，培养利益相关者的领域特定技术AI素养，帮助他们发展计算思维、算法意识和算法能动性，增强数字韧性。

Method: 设计包含四个核心模块的技术课程：1) 向量嵌入，2) 神经网络技术基础，3) 分词，4) Transformer神经网络。在科隆应用技术大学翻译与多语言传播研究所的AI硕士课程中进行教学测试。

Result: 课程显示出良好的教学效果，但参与者反馈表明需要更高层次的教学支架支持（如讲师指导）才能创造最佳学习条件。

Conclusion: 该语言导向AI技术课程能有效培养翻译和专门传播领域的AI技术素养，但需要整合到更完善的教学支持体系中才能发挥最大效果。

Abstract: This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.

</details>


### [77] [T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization](https://arxiv.org/abs/2602.12262)
*Tunyu Zhang,Xinxi Zhang,Ligong Han,Haizhou Shi,Xiaoxiao He,Zhuowei Li,Hao Wang,Kai Xu,Akash Srivastava,Hao Wang,Vladimir Pavlovic,Dimitris N. Metaxas*

Main category: cs.CL

TL;DR: 提出轨迹自蒸馏框架，通过蒸馏模型自身的生成轨迹来提升扩散大语言模型的少步解码性能


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型理论上可以通过并行解码多个token实现快速文本生成，但实际推理效率受限于需要大量细化步骤，而激进减少步骤数会导致生成质量显著下降

Method: 提出轨迹自蒸馏框架，结合直接判别优化（DDO）的反向KL目标，促进模式寻求蒸馏，鼓励学生模型专注于教师模型的高概率模式

Result: 在多个基准测试中，该方法在严格步骤预算下一致优于强少步基线方法和标准训练，虽然全步解码仍更优，但显著缩小了差距

Conclusion: 为实用的少步扩散大语言模型建立了坚实基础，源代码已开源

Abstract: Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.

</details>


### [78] [On-Policy Context Distillation for Language Models](https://arxiv.org/abs/2602.12275)
*Tianzhu Ye,Li Dong,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: OPCD框架通过策略蒸馏与上下文蒸馏结合，让学生模型基于自身生成轨迹训练，同时最小化与上下文条件教师的反向KL散度，在数学推理、文本游戏等任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有上下文蒸馏方法让语言模型将上下文知识内化到参数中，但需要更有效的框架来整合策略蒸馏与上下文蒸馏，以支持经验知识蒸馏和系统提示蒸馏等应用。

Method: 提出On-Policy Context Distillation (OPCD)框架，训练学生模型基于自身生成的轨迹，同时最小化与上下文条件教师模型的反向Kullback-Leibler散度，支持经验知识蒸馏和系统提示蒸馏两种应用。

Result: 在数学推理、文本游戏和领域特定任务中，OPCD一致优于基线方法，获得更高任务准确率并更好保持分布外能力，同时支持有效的跨尺寸蒸馏，让小模型能从大教师模型内化经验知识。

Conclusion: OPCD成功桥接了策略蒸馏与上下文蒸馏，为经验知识蒸馏和系统提示蒸馏提供了有效框架，在多种任务中表现出优越性能，支持模型间知识传递。

Abstract: Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [79] [Mitigating Error Accumulation in Continuous Navigation via Memory-Augmented Kalman Filtering](https://arxiv.org/abs/2602.11183)
*Yin Tang,Jiawei Ma,Jinrui Zhang,Alex Jinpeng Wang,Deyu Zhang*

Main category: cs.RO

TL;DR: 提出NeuroKalman框架，通过贝叶斯状态估计解决无人机视觉语言导航中的状态漂移问题，将导航分解为先验预测和似然校正两个互补过程。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航模型采用航位推算方式，通过迭代更新位置来预测下一个航点，这种方式会随时间累积位置误差，导致内部信念与客观坐标之间的错位（状态漂移），最终影响完整轨迹预测的准确性。

Method: 受经典控制理论启发，将序列预测建模为递归贝叶斯状态估计问题。提出NeuroKalman框架，将导航解耦为两个互补过程：基于运动动力学的先验预测和基于历史观测的似然校正。将核密度估计的测量似然与基于注意力的检索机制数学关联，使系统能够在不进行梯度更新的情况下使用检索到的历史锚点校正潜在表示。

Result: 在TravelUAV基准测试上的综合实验表明，仅使用10%的训练数据进行微调，该方法明显优于强基线，并有效调节了漂移累积。

Conclusion: 通过将贝叶斯状态估计与深度学习相结合，NeuroKalman框架能够有效解决无人机视觉语言导航中的状态漂移问题，提高导航精度和鲁棒性。

Abstract: Continuous navigation in complex environments is critical for Unmanned Aerial Vehicle (UAV). However, the existing Vision-Language Navigation (VLN) models follow the dead-reckoning, which iteratively updates its position for the next waypoint prediction, and subsequently construct the complete trajectory. Then, such stepwise manner will inevitably lead to accumulated errors of position over time, resulting in misalignment between internal belief and objective coordinates, which is known as "state drift" and ultimately compromises the full trajectory prediction. Drawing inspiration from classical control theory, we propose to correct for errors by formulating such sequential prediction as a recursive Bayesian state estimation problem. In this paper, we design NeuroKalman, a novel framework that decouples navigation into two complementary processes: a Prior Prediction, based on motion dynamics and a Likelihood Correction, from historical observation. We first mathematically associate Kernel Density Estimation of the measurement likelihood with the attention-based retrieval mechanism, which then allows the system to rectify the latent representation using retrieved historical anchors without gradient updates. Comprehensive experiments on TravelUAV benchmark demonstrate that, with only 10% of the training data fine-tuning, our method clearly outperforms strong baselines and regulates drift accumulation.

</details>


### [80] [H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model](https://arxiv.org/abs/2602.11291)
*Wenyuan Chen,Jinbang Huang,Oscar Pang,Zhiyuan Li,Xiao Hu,Lingfeng Zhang,Zhanguang Zhang,Mark Coates,Tongtong Cao,Xingyue Quan,Yingxue Zhang*

Main category: cs.RO

TL;DR: 提出分层世界模型H-WM，将逻辑世界模型与视觉世界模型结合，统一预测逻辑状态和视觉状态转换，解决机器人长时程规划中的误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型方法（视频生成或自然语言预测）难以直接基于机器人动作，且长时程规划中误差会累积。传统符号逻辑世界模型虽然可执行且鲁棒，但缺乏视觉感知能力，无法同步预测符号和感知状态。

Method: 提出分层世界模型H-WM，采用双层框架：高层逻辑世界模型预测符号状态转换，低层视觉世界模型预测视觉状态转换。两者统一整合，利用机器人动作数据集进行训练，数据集包含机器人运动、符号状态、动作和视觉观测的对齐信息。

Result: 在视觉-语言-动作控制策略实验中验证了方法的有效性和通用性。分层输出为长时程任务提供稳定一致的中间指导，减少误差累积，实现跨扩展任务序列的鲁棒执行。

Conclusion: H-WM成功整合了符号推理的机器人可执行性和长时程鲁棒性，以及视觉观测的感知基础，为机器人规划提供了更可靠的世界模型框架。

Abstract: World models are becoming central to robotic planning and control, as they enable prediction of future state transitions. Existing approaches often emphasize video generation or natural language prediction, which are difficult to directly ground in robot actions and suffer from compounding errors over long horizons. Traditional task and motion planning relies on symbolic logic world models, such as planning domains, that are robot-executable and robust for long-horizon reasoning. However, these methods typically operate independently of visual perception, preventing synchronized symbolic and perceptual state prediction. We propose a Hierarchical World Model (H-WM) that jointly predicts logical and visual state transitions within a unified bilevel framework. H-WM combines a high-level logical world model with a low-level visual world model, integrating the robot-executable, long-horizon robustness of symbolic reasoning with perceptual grounding from visual observations. The hierarchical outputs provide stable and consistent intermediate guidance for long-horizon tasks, mitigating error accumulation and enabling robust execution across extended task sequences. To train H-WM, we introduce a robotic dataset that aligns robot motion with symbolic states, actions, and visual observations. Experiments across vision-language-action (VLA) control policies demonstrate the effectiveness and generality of the approach.

</details>


### [81] [ExtremControl: Low-Latency Humanoid Teleoperation with Direct Extremity Control](https://arxiv.org/abs/2602.11321)
*Ziyan Xiong,Lixing Fang,Junyun Huang,Kashu Yamazaki,Hao Zhang,Chuang Gan*

Main category: cs.RO

TL;DR: ExtremControl是一个低延迟全身控制框架，通过SE(3)位姿直接操作、笛卡尔空间映射和速度前馈控制，实现50ms端到端延迟，支持乒乓球平衡、杂耍等高响应性行为。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人遥操作系统依赖预处理的运动重定向和位置控制，导致显著延迟（约200ms），限制了响应性，无法完成需要快速反馈和反应的任务。

Method: 提出ExtremControl框架：1) 直接在选定刚性链接（主要是人形机器人末端）的SE(3)位姿上操作，避免全身重定向；2) 使用笛卡尔空间映射将人体运动直接转换为机器人链接目标；3) 在底层加入速度前馈控制，支持快速变化控制接口下的高响应行为。

Result: 在仿真和真实环境中验证了有效性，实现了端到端延迟低至50ms的遥操作系统，支持光学动作捕捉和VR运动追踪，能够完成乒乓球平衡、杂耍和实时返回等高响应性行为，显著超越了先前工作的200ms延迟限制。

Conclusion: ExtremControl框架通过简化控制流程和加入速度前馈，成功实现了低延迟人形机器人遥操作，为收集多样化反应性和动态演示数据提供了有效解决方案，显著提升了系统响应能力。

Abstract: Building a low-latency humanoid teleoperation system is essential for collecting diverse reactive and dynamic demonstrations. However, existing approaches rely on heavily pre-processed human-to-humanoid motion retargeting and position-only PD control, resulting in substantial latency that severely limits responsiveness and prevents tasks requiring rapid feedback and fast reactions. To address this problem, we propose ExtremControl, a low latency whole-body control framework that: (1) operates directly on SE(3) poses of selected rigid links, primarily humanoid extremities, to avoid full-body retargeting; (2) utilizes a Cartesian-space mapping to directly convert human motion to humanoid link targets; and (3) incorporates velocity feedforward control at low level to support highly responsive behavior under rapidly changing control interfaces. We further provide a unified theoretical formulation of ExtremControl and systematically validate its effectiveness through experiments in both simulation and real-world environments. Building on ExtremControl, we implement a low-latency humanoid teleoperation system that supports both optical motion capture and VR-based motion tracking, achieving end-to-end latency as low as 50ms and enabling highly responsive behaviors such as ping-pong ball balancing, juggling, and real-time return, thereby substantially surpassing the 200ms latency limit observed in prior work.

</details>


### [82] [MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation](https://arxiv.org/abs/2602.11337)
*Yejin Kim,Wilbert Pumacay,Omar Rayyan,Max Argus,Winson Han,Eli VanderBilt,Jordi Salvador,Abhay Deshpande,Rose Hendrix,Snehal Jauhri,Shuo Liu,Nur Muhammad Mahi Shafiullah,Maya Guru,Ainaz Eftekhar,Karen Farley,Donovan Clay,Jiafei Duan,Arjun Guru,Piper Wolters,Alvaro Herrasti,Ying-Chun Lee,Georgia Chalvatzaki,Yuchen Cui,Ali Farhadi,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: MolmoSpaces是一个开放的大规模机器人策略基准测试生态系统，包含23万多个多样化室内环境、13万个标注物体资产和4200万个稳定抓取，支持多种模拟器和完整的具身任务谱系。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器人部署需要应对大量日常场景变化，但现有机器人基准测试缺乏足够的规模和多样性来测量这种泛化能力。物理评估无法提供所需的规模和多样性基础设施。

Method: 构建MolmoSpaces生态系统：包含23万+多样化室内环境（从手工制作到程序生成的多房间房屋），13万+丰富标注物体资产（含4.8万可操作物体和4200万稳定抓取），支持多种模拟器（MuJoCo、Isaac、ManiSkill），并设计MolmoSpaces-Bench基准测试套件（8个任务）。

Result: MolmoSpaces-Bench显示出强烈的模拟到真实相关性（R=0.96，ρ=0.98），确认新零样本策略优于早期版本，识别出对提示措辞、初始关节位置和相机遮挡的关键敏感性。

Conclusion: MolmoSpaces通过开源资产和工具为机器人学习研究提供了可扩展的数据生成、策略训练和基准创建的基础设施，支持大规模机器人策略评估。

Abstract: Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies. MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks: static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, \r{ho} = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing, initial joint positions, and camera occlusion. Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.

</details>


### [83] [Human Preference Modeling Using Visual Motion Prediction Improves Robot Skill Learning from Egocentric Human Video](https://arxiv.org/abs/2602.11393)
*Mrinal Verghese,Christopher G. Atkeson*

Main category: cs.RO

TL;DR: 提出一种从人类第一人称视角视频学习机器人技能的方法，通过建模人类偏好为奖励函数，并优化机器人行为以最大化该奖励。


<details>
  <summary>Details</summary>
Motivation: 现有从人类视频学习奖励的方法存在局限性：它们通常通过测量视觉状态与演示视频终止状态之间的时间距离来评估长期价值，这种假设限制了从视频学习的性能，并且需要跨越本体和环境差距迁移学习到的价值函数。

Method: 通过预测连续图像间跟踪点的运动来建模人类偏好，将奖励函数定义为机器人行为中预测物体运动与观察物体运动的一致性。使用改进的Soft Actor Critic算法，以10个机器人演示初始化，从该奖励估计价值函数并优化策略。

Result: 该方法能够在真实机器人上学习，在模拟和真实机器人上的多个任务中，使用该奖励模型学习的策略匹配或优于先前工作。

Conclusion: 提出的方法成功地从人类第一人称视角视频学习机器人技能，通过建模运动一致性作为奖励，避免了传统方法的局限性，并在真实机器人上实现了有效学习。

Abstract: We present an approach to robot learning from egocentric human videos by modeling human preferences in a reward function and optimizing robot behavior to maximize this reward. Prior work on reward learning from human videos attempts to measure the long-term value of a visual state as the temporal distance between it and the terminal state in a demonstration video. These approaches make assumptions that limit performance when learning from video. They must also transfer the learned value function across the embodiment and environment gap. Our method models human preferences by learning to predict the motion of tracked points between subsequent images and defines a reward function as the agreement between predicted and observed object motion in a robot's behavior at each step. We then use a modified Soft Actor Critic (SAC) algorithm initialized with 10 on-robot demonstrations to estimate a value function from this reward and optimize a policy that maximizes this value function, all on the robot. Our approach is capable of learning on a real robot, and we show that policies learned with our reward model match or outperform prior work across multiple tasks in both simulation and on the real robot.

</details>


### [84] [EasyMimic: A Low-Cost Framework for Robot Imitation Learning from Human Videos](https://arxiv.org/abs/2602.11464)
*Tao Zhang,Song Xia,Ye Wang,Qin Jin*

Main category: cs.RO

TL;DR: EasyMimic是一个低成本机器人模仿学习框架，通过人类视频演示提取3D手部轨迹，映射到机器人控制空间，使用视觉增强和协同训练方法，显著减少昂贵机器人数据收集需求。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿学习通常需要大规模真实世界数据收集，成本高昂，这对于面向家庭使用的低成本机器人尤其具有挑战性。需要一种用户友好且经济实惠的解决方案。

Method: 1. 从标准RGB相机拍摄的人类视频中提取3D手部轨迹；2. 通过动作对齐模块将轨迹映射到低成本机器人夹爪控制空间；3. 引入简单用户友好的手部视觉增强策略来弥合人机领域差距；4. 使用协同训练方法，在处理的的人类数据和少量机器人数据上微调模型。

Result: 在低成本LeRobot平台上的实验表明，EasyMimic在各种操作任务中实现了高性能，显著减少了对昂贵机器人数据收集的依赖。

Conclusion: EasyMimic为将智能机器人带入家庭提供了一条实用路径，通过低成本、可复制的解决方案使机器人能够快速从人类视频演示中学习操作策略。

Abstract: Robot imitation learning is often hindered by the high cost of collecting large-scale, real-world data. This challenge is especially significant for low-cost robots designed for home use, as they must be both user-friendly and affordable. To address this, we propose the EasyMimic framework, a low-cost and replicable solution that enables robots to quickly learn manipulation policies from human video demonstrations captured with standard RGB cameras. Our method first extracts 3D hand trajectories from the videos. An action alignment module then maps these trajectories to the gripper control space of a low-cost robot. To bridge the human-to-robot domain gap, we introduce a simple and user-friendly hand visual augmentation strategy. We then use a co-training method, fine-tuning a model on both the processed human data and a small amount of robot data, enabling rapid adaptation to new tasks. Experiments on the low-cost LeRobot platform demonstrate that EasyMimic achieves high performance across various manipulation tasks. It significantly reduces the reliance on expensive robot data collection, offering a practical path for bringing intelligent robots into homes. Project website: https://zt375356.github.io/EasyMimic-Project/.

</details>


### [85] [Effective Task Planning with Missing Objects using Learning-Informed Object Search](https://arxiv.org/abs/2602.11468)
*Raihan Islam Arnob,Max Merlin,Abhishek Paudel,Benned Hedegaard,George Konidaris,Gregory Stein*

Main category: cs.RO

TL;DR: 提出LIOS动作框架，将对象搜索作为可规划动作，实现不确定环境下的任务规划


<details>
  <summary>Details</summary>
Motivation: 现有任务规划方法（如PDDL）假设完全环境知识，无法处理任务关键对象位置未知的情况；而现有的学习驱动对象搜索方法难以集成到完整任务规划器中

Method: 开发基于模型的新型LIOS动作框架，每个LIOS动作是一个寻找和检索单个对象的策略；高层规划将LIOS动作视为确定性动作，基于模型计算的预期成本生成计划，在不确定环境下实现学习感知的任务规划

Result: 在模拟ProcTHOR家庭环境和真实世界中，该方法在检索和餐食准备等任务上优于非学习和学习基线方法

Conclusion: LIOS动作框架有效处理不确定性，同时保持与现有全知识求解器的兼容性，实现了有效、完备的学习感知任务规划

Abstract: Task planning for mobile robots often assumes full environment knowledge and so popular approaches, like planning via the PDDL, cannot plan when the locations of task-critical objects are unknown. Recent learning-driven object search approaches are effective, but operate as standalone tools and so are not straightforwardly incorporated into full task planners, which must additionally determine both what objects are necessary and when in the plan they should be sought out. To address this limitation, we develop a planning framework centered around novel model-based LIOS actions: each a policy that aims to find and retrieve a single object. High-level planning treats LIOS actions as deterministic and so -- informed by model-based calculations of the expected cost of each -- generates plans that interleave search and execution for effective, sound, and complete learning-informed task planning despite uncertainty. Our work effectively reasons about uncertainty while maintaining compatibility with existing full-knowledge solvers. In simulated ProcTHOR homes and in the real world, our approach outperforms non-learned and learned baselines on tasks including retrieval and meal prep.

</details>


### [86] [HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds](https://arxiv.org/abs/2602.11554)
*Yichun Xiao,Runwei Guan,Fangqiang Ding*

Main category: cs.RO

TL;DR: HyperDet是一个雷达专用的3D检测框架，通过聚合多帧多雷达数据、一致性验证和前景扩散模块，提升4D毫米波雷达点云质量，使其能直接用于LiDAR检测器


<details>
  <summary>Details</summary>
Motivation: 4D毫米波雷达具有天气鲁棒性、速度感知和成本效益，但其点云稀疏、不规则且易受多径噪声影响，导致雷达专用3D检测性能落后于LiDAR系统

Method: 1) 聚合多雷达多帧数据提高覆盖密度；2) 几何感知跨传感器一致性验证；3) 前景聚焦扩散模块，通过雷达-LiDAR混合监督训练，蒸馏为一致性模型实现单步推理

Result: 在MAN TruckScenes数据集上，HyperDet显著提升原始雷达输入的性能，配合VoxelNeXt和CenterPoint检测器，部分缩小了雷达与LiDAR之间的性能差距

Conclusion: 输入级优化使雷达能够更好地利用LiDAR导向的检测器，无需修改网络架构，为雷达专用3D检测提供了有效解决方案

Abstract: 4D mmWave radar provides weather-robust, velocity-aware measurements and is more cost-effective than LiDAR. However, radar-only 3D detection still trails LiDAR-based systems because radar point clouds are sparse, irregular, and often corrupted by multipath noise, yielding weak and unstable geometry. We present HyperDet, a detector-agnostic radar-only 3D detection framework that constructs a task-aware hyper 4D radar point cloud for standard LiDAR-oriented detectors. HyperDet aggregates returns from multiple surround-view 4D radars over consecutive frames to improve coverage and density, then applies geometry-aware cross-sensor consensus validation with a lightweight self-consistency check outside overlap regions to suppress inconsistent returns. It further integrates a foreground-focused diffusion module with training-time mixed radar-LiDAR supervision to densify object structures while lifting radar attributes (e.g., Doppler, RCS); the model is distilled into a consistency model for single-step inference. On MAN TruckScenes, HyperDet consistently improves over raw radar inputs with VoxelNeXt and CenterPoint, partially narrowing the radar-LiDAR gap. These results show that input-level refinement enables radar to better leverage LiDAR-oriented detectors without architectural modifications.

</details>


### [87] [ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles](https://arxiv.org/abs/2602.11575)
*Seungyeon Yoo,Youngseok Jang,Dabin Kim,Youngsoo Han,Seungwoo Jung,H. Jin Kim*

Main category: cs.RO

TL;DR: ReaDy-Go提出了一种新的真实到仿真模拟管道，用于生成动态环境的逼真导航数据集，通过结合静态3D高斯溅射场景和动态人类障碍物，训练出对仿真到真实差距和移动障碍物都鲁棒的导航策略。


<details>
  <summary>Details</summary>
Motivation: 视觉导航模型在真实动态环境中表现不佳，主要面临仿真到真实差距的鲁棒性有限，以及难以针对特定部署环境（如家庭、餐厅、工厂）训练策略的问题。现有的真实到仿真导航模拟虽然使用3D高斯溅射技术，但通常假设静态场景或不现实的动态障碍物，而动态环境中的安全导航至关重要。

Method: ReaDy-Go包含三个核心组件：1）动态高斯溅射模拟器，将场景高斯溅射与人类动画模块结合，插入可动画的人类高斯化身并从2D轨迹合成合理的人类动作；2）动态环境导航数据集生成，利用模拟器、为动态高斯表示设计的机器人专家规划器和人类规划器；3）使用生成的数据集进行策略学习。

Result: ReaDy-Go在目标环境的仿真和真实世界实验中均优于基线方法，展示了在仿真到真实迁移后以及在存在移动障碍物时改进的导航性能。此外，在未见环境中的零样本仿真到真实部署显示了其泛化潜力。

Conclusion: ReaDy-Go通过合成逼真的动态场景，有效解决了动态环境中视觉导航的仿真到真实差距问题，为真实世界动态环境中的安全导航提供了有效的解决方案，并展示了良好的泛化能力。

Abstract: Visual navigation models often struggle in real-world dynamic environments due to limited robustness to the sim-to-real gap and the difficulty of training policies tailored to target deployment environments (e.g., households, restaurants, and factories). Although real-to-sim navigation simulation using 3D Gaussian Splatting (GS) can mitigate this gap, prior works have assumed only static scenes or unrealistic dynamic obstacles, despite the importance of safe navigation in dynamic environments. To address these issues, we propose ReaDy-Go, a novel real-to-sim simulation pipeline that synthesizes photorealistic dynamic scenarios for target environments. ReaDy-Go generates photorealistic navigation datasets for dynamic environments by combining a reconstructed static GS scene with dynamic human GS obstacles, and trains policies robust to both the sim-to-real gap and moving obstacles. The pipeline consists of three components: (1) a dynamic GS simulator that integrates scene GS with a human animation module, enabling the insertion of animatable human GS avatars and the synthesis of plausible human motions from 2D trajectories, (2) navigation dataset generation for dynamic environments that leverages the simulator, a robot expert planner designed for dynamic GS representations, and a human planner, and (3) policy learning using the generated datasets. ReaDy-Go outperforms baselines across target environments in both simulation and real-world experiments, demonstrating improved navigation performance even after sim-to-real transfer and in the presence of moving obstacles. Moreover, zero-shot sim-to-real deployment in an unseen environment indicates its generalization potential. Project page: https://syeon-yoo.github.io/ready-go-site/.

</details>


### [88] [ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation](https://arxiv.org/abs/2602.11598)
*Zedong Chu,Shichao Xie,Xiaolong Wu,Yanfen Shen,Minghua Luo,Zhengbo Wang,Fei Liu,Xiaoxu Leng,Junjun Hu,Mingyang Yin,Jia Lu,Yingnan Guo,Kai Yang,Jiawei Han,Xu Chen,Yanqing Zhu,Yuxiang Zhao,Xin Liu,Yirong Yang,Ye He,Jiahang Wang,Yang Cai,Tianlin Zhang,Li Gao,Liu Liu,Mingchao Sun,Fan Jiang,Chiyu Wang,Zhicheng Liu,Hongyu Pan,Honglin Han,Zhining Gu,Kuan Yang,Jianfang Zhang,Di Jing,Zihao Guan,Wei Guo,Guoqing Liu,Di Yang,Xiangpo Yang,Menglin Yang,Hongguang Xing,Weiguo Li,Mu Xu*

Main category: cs.RO

TL;DR: ABot-N0是一个统一的视觉-语言-动作基础模型，通过"大脑-动作"分层架构实现了5个核心导航任务的大统一，在7个基准测试中达到新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有具身导航系统通常采用任务特定的架构，导致系统碎片化。作者希望创建一个统一的基础模型来解决多个核心导航任务，实现"大统一"。

Method: 采用分层"大脑-动作"架构：基于LLM的认知大脑进行语义推理，基于流匹配的动作专家生成精确连续轨迹。开发了ABot-N0数据引擎，收集了1690万专家轨迹和500万推理样本。

Result: 在7个基准测试中达到新的SOTA性能，显著优于专用模型。智能导航系统集成了规划器和分层拓扑记忆，能够在动态真实环境中执行鲁棒的长时程任务。

Conclusion: ABot-N0成功实现了多个导航任务的统一，展示了基础模型在具身导航中的潜力，为构建更通用、鲁棒的导航系统提供了新方向。

Abstract: Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation.
  To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 $\text{km}^2$). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.

</details>


### [89] [ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning](https://arxiv.org/abs/2602.11643)
*Yufeng Tian,Shuiqi Cheng,Tianming Wei,Tianxing Zhou,Yuanhang Zhang,Zixian Liu,Qianwei Han,Zhecheng Yuan,Huazhe Xu*

Main category: cs.RO

TL;DR: ViTaS是一个结合视觉和触觉信息的机器人操作框架，通过软融合对比学习和CVAE模块利用两种模态的对齐性和互补性，在遮挡场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注视觉和触觉特征的对齐，融合机制通常是直接拼接，忽视了两种模态的固有互补性，对齐利用不足，难以有效处理遮挡场景，限制了实际部署潜力。

Method: 提出ViTaS框架，引入软融合对比学习（传统对比学习方法的进阶版）和CVAE模块，充分利用视觉-触觉表示的对齐性和互补性来指导智能体行为。

Result: 在12个模拟环境和3个真实世界环境中验证了方法的有效性，实验表明ViTaS显著优于现有基线方法。

Conclusion: ViTaS是一个简单有效的视觉-触觉融合框架，通过软融合对比学习和CVAE模块更好地利用两种模态的对齐性和互补性，在遮挡场景中表现出色，具有实际部署潜力。

Abstract: Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the potential of their real-world deployment. In this paper, we present ViTaS, a simple yet effective framework that incorporates both visual and tactile information to guide the behavior of an agent. We introduce Soft Fusion Contrastive Learning, an advanced version of conventional contrastive learning method and a CVAE module to utilize the alignment and complementarity within visuo-tactile representations. We demonstrate the effectiveness of our method in 12 simulated and 3 real-world environments, and our experiments show that ViTaS significantly outperforms existing baselines. Project page: https://skyrainwind.github.io/ViTaS/index.html.

</details>


### [90] [Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli](https://arxiv.org/abs/2602.11648)
*Faezeh Vahedi,Morteza Memari,Ramtin Tabatabaei,Alireza Taheri*

Main category: cs.RO

TL;DR: 研究开发了基于LSTM和Transformer的神经网络模型，预测人类在社交场景中的注视行为，特别关注非人类刺激（如门开、物体掉落），并将模型部署到NAO机器人上，提高了人机交互的自然性。


<details>
  <summary>Details</summary>
Motivation: 社交机器人需要更自然地模仿人类注视行为以增强沟通效果，特别是对非人类刺激的注视反应在以往研究中被忽视，需要填补这一空白。

Method: 使用Unity创建3D动画和360度真实世界视频模拟社交场景，通过VR眼镜收集41名参与者的注视数据，用LSTM和Transformer神经网络训练预测模型，并将系统部署到NAO机器人进行评估。

Result: LSTM和Transformer模型在动画场景中分别达到67.6%和70.4%的预测准确率，在真实场景中分别达到72%和71.6%的准确率，优于现有方法。275名参与者评估显示对NAO机器人的交互满意度很高。

Conclusion: 该研究成功开发了能够预测人类注视行为（包括对非人类刺激的反应）的模型，显著提高了社交机器人的自然交互能力，为社交机器人领域提供了重要进展。

Abstract: Nonverbal behaviors, particularly gaze direction, play a crucial role in enhancing effective communication in social interactions. As social robots increasingly participate in these interactions, they must adapt their gaze based on human activities and remain receptive to all cues, whether human-generated or not, to ensure seamless and effective communication. This study aims to increase the similarity between robot and human gaze behavior across various social situations, including both human and non-human stimuli (e.g., conversations, pointing, door openings, and object drops). A key innovation in this study, is the investigation of gaze responses to non-human stimuli, a critical yet underexplored area in prior research. These scenarios, were simulated in the Unity software as a 3D animation and a 360-degree real-world video. Data on gaze directions from 41 participants were collected via virtual reality (VR) glasses. Preprocessed data, trained two neural networks-LSTM and Transformer-to build predictive models based on individuals' gaze patterns. In the animated scenario, the LSTM and Transformer models achieved prediction accuracies of 67.6% and 70.4%, respectively; In the real-world scenario, the LSTM and Transformer models achieved accuracies of 72% and 71.6%, respectively. Despite the gaze pattern differences among individuals, our models outperform existing approaches in accuracy while uniquely considering non-human stimuli, offering a significant advantage over previous literature. Furthermore, deployed on the NAO robot, the system was evaluated by 275 participants via a comprehensive questionnaire, with results demonstrating high satisfaction during interactions. This work advances social robotics by enabling robots to dynamically mimic human gaze behavior in complex social contexts.

</details>


### [91] [AC-MASAC: An Attentive Curriculum Learning Framework for Heterogeneous UAV Swarm Coordination](https://arxiv.org/abs/2602.11735)
*Wanhao Liu,Junhong Dai,Yixuan Zhang,Shengyun Yin,Panshuo Li*

Main category: cs.RO

TL;DR: 本文提出了一种用于异构无人机集群协同路径规划的注意力课程学习框架（AC-MASAC），通过角色感知异构注意力机制建模不对称依赖，并采用结构化课程策略解决稀疏奖励和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 异构无人机集群的协同路径规划对多智能体强化学习提出了重大挑战，特别是在处理不对称的智能体间依赖关系、稀疏奖励风险以及训练过程中的灾难性遗忘问题。

Method: 提出了注意力课程学习框架（AC-MASAC），包含：1）角色感知异构注意力机制，显式建模不对称依赖关系；2）结构化课程策略，整合分层知识迁移和阶段比例经验回放。

Result: 在自定义多智能体仿真平台上验证，结果显示该方法在成功率、编队保持率和任务时间加权成功率等指标上显著优于其他先进方法。

Conclusion: AC-MASAC框架有效解决了异构无人机集群路径规划中的不对称依赖建模、稀疏奖励和灾难性遗忘问题，在多个性能指标上表现出优越性。

Abstract: Cooperative path planning for heterogeneous UAV swarms poses significant challenges for Multi-Agent Reinforcement Learning (MARL), particularly in handling asymmetric inter-agent dependencies and addressing the risks of sparse rewards and catastrophic forgetting during training. To address these issues, this paper proposes an attentive curriculum learning framework (AC-MASAC). The framework introduces a role-aware heterogeneous attention mechanism to explicitly model asymmetric dependencies. Moreover, a structured curriculum strategy is designed, integrating hierarchical knowledge transfer and stage-proportional experience replay to address the issues of sparse rewards and catastrophic forgetting. The proposed framework is validated on a custom multi-agent simulation platform, and the results show that our method has significant advantages over other advanced methods in terms of Success Rate, Formation Keeping Rate, and Success-weighted Mission Time. The code is available at \textcolor{red}{https://github.com/Wanhao-Liu/AC-MASAC}.

</details>


### [92] [HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model](https://arxiv.org/abs/2602.11758)
*Dongting Li,Xingyu Chen,Qianyang Wu,Bo Chen,Sikai Wu,Hanyu Wu,Guoyao Zhang,Liang Li,Mingliang Zhou,Diyun Xiang,Jianzhu Ma,Qiang Zhang,Renjing Xu*

Main category: cs.RO

TL;DR: HAIC框架通过仅使用本体感知历史预测高阶物体状态，构建空间动态占据地图，实现人形机器人与各种动态物体的鲁棒交互


<details>
  <summary>Details</summary>
Motivation: 当前人机交互方法主要关注完全驱动的刚性耦合物体，忽视了欠驱动物体（具有独立动力学和非完整约束）带来的控制挑战，包括耦合力和遮挡问题

Method: 提出HAIC统一框架：1）动力学预测器仅从本体感知历史估计高阶物体状态；2）将预测投影到静态几何先验形成空间动态占据地图；3）使用非对称微调，世界模型持续适应学生策略的探索

Result: 在人形机器人实验中，HAIC在敏捷任务（滑板、推/拉不同负载的购物车）中通过主动补偿惯性扰动实现高成功率，并能完成多物体长时域任务（如携带箱子穿越不同地形）

Conclusion: HAIC框架能够在不需要外部状态估计的情况下，实现人形机器人与各种动态物体的鲁棒交互，解决了欠驱动物体带来的控制挑战

Abstract: Humanoid robots show promise for complex whole-body tasks in unstructured environments. Although Human-Object Interaction (HOI) has advanced, most methods focus on fully actuated objects rigidly coupled to the robot, ignoring underactuated objects with independent dynamics and non-holonomic constraints. These introduce control challenges from coupling forces and occlusions. We present HAIC, a unified framework for robust interaction across diverse object dynamics without external state estimation. Our key contribution is a dynamics predictor that estimates high-order object states (velocity, acceleration) solely from proprioceptive history. These predictions are projected onto static geometric priors to form a spatially grounded dynamic occupancy map, enabling the policy to infer collision boundaries and contact affordances in blind spots. We use asymmetric fine-tuning, where a world model continuously adapts to the student policy's exploration, ensuring robust state estimation under distribution shifts. Experiments on a humanoid robot show HAIC achieves high success rates in agile tasks (skateboarding, cart pushing/pulling under various loads) by proactively compensating for inertial perturbations, and also masters multi-object long-horizon tasks like carrying a box across varied terrain by predicting the dynamics of multiple objects.

</details>


### [93] [LAMP: Implicit Language Map for Robot Navigation](https://arxiv.org/abs/2602.11862)
*Sibaek Lee,Hyeonwoo Yu,Giseop Kim,Sunwook Choi*

Main category: cs.RO

TL;DR: LAMP：基于神经语言场的导航框架，通过隐式表示语言特征实现高效的大规模环境导航，结合稀疏图进行粗路径规划，再通过梯度优化进行细粒度路径生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于网格或节点的显式语言向量存储方法在大规模环境中面临内存需求过大和细粒度规划分辨率有限的问题，需要更高效的表示方法。

Method: 1) 学习连续的语言驱动地图作为隐式神经场；2) 结合稀疏图进行高效粗路径规划；3) 在学习的场中进行梯度优化细化目标附近位姿；4) 采用贝叶斯框架建模嵌入不确定性；5) 使用图采样策略优先考虑空间覆盖和嵌入置信度。

Result: 在NVIDIA Isaac Sim和真实多楼层建筑中的实验表明，LAMP在内存效率和细粒度目标到达精度方面均优于现有显式方法。

Conclusion: LAMP通过隐式神经语言场实现了高效的大规模环境导航，解决了显式方法的内存和分辨率限制问题，为语言驱动的机器人导航提供了新的解决方案。

Abstract: Recent advances in vision-language models have made zero-shot navigation feasible, enabling robots to follow natural language instructions without requiring labeling. However, existing methods that explicitly store language vectors in grid or node-based maps struggle to scale to large environments due to excessive memory requirements and limited resolution for fine-grained planning. We introduce LAMP (Language Map), a novel neural language field-based navigation framework that learns a continuous, language-driven map and directly leverages it for fine-grained path generation. Unlike prior approaches, our method encodes language features as an implicit neural field rather than storing them explicitly at every location. By combining this implicit representation with a sparse graph, LAMP supports efficient coarse path planning and then performs gradient-based optimization in the learned field to refine poses near the goal. This coarse-to-fine pipeline, language-driven, gradient-guided optimization is the first application of an implicit language map for precise path generation. This refinement is particularly effective at selecting goal regions not directly observed by leveraging semantic similarities in the learned feature space. To further enhance robustness, we adopt a Bayesian framework that models embedding uncertainty via the von Mises-Fisher distribution, thereby improving generalization to unobserved regions. To scale to large environments, LAMP employs a graph sampling strategy that prioritizes spatial coverage and embedding confidence, retaining only the most informative nodes and substantially reducing computational overhead. Our experimental results, both in NVIDIA Isaac Sim and on a real multi-floor building, demonstrate that LAMP outperforms existing explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.

</details>


### [94] [Learning to Manipulate Anything: Revealing Data Scaling Laws in Bounding-Box Guided Policies](https://arxiv.org/abs/2602.11885)
*Yihao Wu,Jinming Ma,Junbo Tan,Yanzhao Yu,Shoujie Li,Mingliang Zhou,Diyun Xiang,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出使用边界框指令直接指定目标对象，研究语义操作任务中的数据缩放规律，通过手持分割设备和自动化标注流程高效收集演示数据，结合目标检测和边界框引导的扩散策略提升语义操作的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基于扩散的策略在语义操作中泛化能力有限，仅依赖文本指令在复杂动态环境中难以准确引导策略关注目标对象，这阻碍了真实世界机器人的部署。

Method: 1) 设计手持分割设备Label-UMI及自动化标注流程，高效收集带语义标签的演示数据；2) 提出语义-运动解耦框架，集成目标检测和边界框引导的扩散策略；3) 研究边界框对象数量与泛化性能之间的幂律关系。

Result: 在大规模数据集上的真实世界实验中验证了方法的有效性，揭示了泛化性能与边界框对象数量之间的幂律关系，在四个任务上对已见和未见对象均达到85%的成功率。

Conclusion: 通过边界框指令直接指定目标对象能有效提升语义操作的泛化能力，发现了数据缩放规律，总结了有效的语义操作数据收集策略，为机器人部署提供了实用解决方案。

Abstract: Diffusion-based policies show limited generalization in semantic manipulation, posing a key obstacle to the deployment of real-world robots. This limitation arises because relying solely on text instructions is inadequate to direct the policy's attention toward the target object in complex and dynamic environments. To solve this problem, we propose leveraging bounding-box instruction to directly specify target object, and further investigate whether data scaling laws exist in semantic manipulation tasks. Specifically, we design a handheld segmentation device with an automated annotation pipeline, Label-UMI, which enables the efficient collection of demonstration data with semantic labels. We further propose a semantic-motion-decoupled framework that integrates object detection and bounding-box guided diffusion policy to improve generalization and adaptability in semantic manipulation. Throughout extensive real-world experiments on large-scale datasets, we validate the effectiveness of the approach, and reveal a power-law relationship between generalization performance and the number of bounding-box objects. Finally, we summarize an effective data collection strategy for semantic manipulation, which can achieve 85\% success rates across four tasks on both seen and unseen objects. All datasets and code will be released to the community.

</details>


### [95] [General Humanoid Whole-Body Control via Pretraining and Fast Adaptation](https://arxiv.org/abs/2602.11929)
*Zepeng Wang,Jiangxing Wang,Shiqing Yao,Yu Zhang,Ziluo Ding,Ming Yang,Yuxuan Wang,Haobin Jiang,Chao Ma,Xiaochuan Shi,Zongqing Lu*

Main category: cs.RO

TL;DR: FAST是一个通用人形机器人全身控制框架，通过轻量级残差策略适应和质心感知控制，实现快速适应和稳定运动跟踪


<details>
  <summary>Details</summary>
Motivation: 人形机器人全身控制面临运动分布多样、快速适应困难、高动态场景下平衡保持等挑战。现有方法通常需要任务特定训练，或在适应新运动时性能下降。

Method: 提出FAST框架：1）Parseval引导的残差策略适应，在正交性和KL约束下学习轻量级增量动作策略，实现高效适应并减轻灾难性遗忘；2）质心感知控制，融入质心相关观测和目标，增强跟踪挑战性参考运动时的平衡能力。

Result: 在仿真和实际部署中的大量实验表明，FAST在鲁棒性、适应效率和泛化能力方面持续优于最先进的基线方法。

Conclusion: FAST框架通过创新的残差策略适应和质心感知控制，成功解决了人形机器人全身控制的快速适应和稳定跟踪问题，展现了优越的性能和泛化能力。

Abstract: Learning a general whole-body controller for humanoid robots remains challenging due to the diversity of motion distributions, the difficulty of fast adaptation, and the need for robust balance in high-dynamic scenarios. Existing approaches often require task-specific training or suffer from performance degradation when adapting to new motions. In this paper, we present FAST, a general humanoid whole-body control framework that enables Fast Adaptation and Stable Motion Tracking. FAST introduces Parseval-Guided Residual Policy Adaptation, which learns a lightweight delta action policy under orthogonality and KL constraints, enabling efficient adaptation to out-of-distribution motions while mitigating catastrophic forgetting. To further improve physical robustness, we propose Center-of-Mass-Aware Control, which incorporates CoM-related observations and objectives to enhance balance when tracking challenging reference motions. Extensive experiments in simulation and real-world deployment demonstrate that FAST consistently outperforms state-of-the-art baselines in robustness, adaptation efficiency, and generalization.

</details>


### [96] [Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control](https://arxiv.org/abs/2602.11934)
*Yu Deng,Yufeng Jin,Xiaogang Jia,Jiahong Xue,Gerhard Neumann,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: 提出Robot-DIFT框架，通过流形蒸馏将扩散模型的几何先验提取到确定性特征网络中，解决视觉骨干网络与机器人控制需求之间的结构不匹配问题


<details>
  <summary>Details</summary>
Motivation: 当前视觉骨干网络（包括VLA中使用的）为语义不变性优化，适合分类任务，但机器人操作需要几何敏感性来感知毫米级位姿变化。这种判别性目标导致对精细控制的"盲点"，而生成扩散模型在潜在流形中编码了几何依赖关系

Method: 提出Robot-DIFT框架，通过流形蒸馏将冻结的扩散教师模型蒸馏到确定性的空间-语义特征金字塔网络（S2-FPN）中，保留生成模型的丰富几何先验，同时确保时间稳定性、实时执行和对漂移的鲁棒性

Result: 在大规模DROID数据集上预训练后，Robot-DIFT相比领先的判别性基线表现出更优的几何一致性和控制性能

Conclusion: 模型如何学习"看"决定了它如何学习"行动"，通过流形蒸馏将扩散模型的几何先验提取到确定性网络中，可以弥合视觉表示与机器人控制需求之间的差距

Abstract: We hypothesize that a key bottleneck in generalizable robot manipulation is not solely data scale or policy capacity, but a structural mismatch between current visual backbones and the physical requirements of closed-loop control. While state-of-the-art vision encoders (including those used in VLAs) optimize for semantic invariance to stabilize classification, manipulation typically demands geometric sensitivity the ability to map millimeter-level pose shifts to predictable feature changes. Their discriminative objective creates a "blind spot" for fine-grained control, whereas generative diffusion models inherently encode geometric dependencies within their latent manifolds, encouraging the preservation of dense multi-scale spatial structure. However, directly deploying stochastic diffusion features for control is hindered by stochastic instability, inference latency, and representation drift during fine-tuning. To bridge this gap, we propose Robot-DIFT, a framework that decouples the source of geometric information from the process of inference via Manifold Distillation. By distilling a frozen diffusion teacher into a deterministic Spatial-Semantic Feature Pyramid Network (S2-FPN), we retain the rich geometric priors of the generative model while ensuring temporal stability, real-time execution, and robustness against drift. Pretrained on the large-scale DROID dataset, Robot-DIFT demonstrates superior geometric consistency and control performance compared to leading discriminative baselines, supporting the view that how a model learns to see dictates how well it can learn to act.

</details>


### [97] [Accelerating Robotic Reinforcement Learning with Agent Guidance](https://arxiv.org/abs/2602.11978)
*Haojun Chen,Zili Zou,Chengdong Ma,Yaoxiang Pu,Haotong Zhang,Yuanpei Chen,Yaodong Yang*

Main category: cs.RO

TL;DR: AGPS用多模态智能体替代人类监督，通过语义世界模型提供内在价值先验，使用可执行工具提供精确引导，显著提升机器人强化学习的样本效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习在真实世界机器人操作中面临严重的样本效率问题。现有的人类在环方法虽然能加速训练，但存在1:1监督比例限制、操作员疲劳、人类技能不一致导致高方差等可扩展性障碍。

Method: 提出Agent-guided Policy Search (AGPS)框架，用多模态智能体替代人类监督。智能体被视为语义世界模型，通过可执行工具提供精确引导，包括纠正路径点和空间约束，用于探索剪枝。

Result: 在从精确插入到可变形物体操作的两个任务上验证，AGPS在样本效率方面优于人类在环方法，实现了监督流程的自动化。

Conclusion: AGPS自动化了监督流程，为无人工、可扩展的机器人学习开辟了道路，解决了人类监督的可扩展性瓶颈。

Abstract: Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.

</details>


### [98] [Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario](https://arxiv.org/abs/2602.12012)
*Muhammad Farhan Ahmed,Vincent Frémont*

Main category: cs.RO

TL;DR: 提出一个去中心化的多机器人框架，用于使用多个无人机与自主水面船只协作检测和跟踪海上漂浮容器，通过视觉检测、不确定性感知数据关联、保守轨迹融合和信息驱动的任务分配来提升覆盖范围和跟踪一致性。


<details>
  <summary>Details</summary>
Motivation: 自主空中-水面机器人团队在海上监测中具有潜力，但需要在水面反射环境下实现可靠的感知，并在有限通信条件下实现可扩展的协调。

Method: 1) 每个无人机使用YOLOv8和立体视差进行视觉检测；2) 使用基于不确定性的数据关联和每目标扩展卡尔曼滤波器进行跟踪；3) 通过协方差交集保守地交换和融合紧凑的轨迹摘要；4) 信息驱动的分配模块权衡预期不确定性减少、旅行成本和安全性来分配目标和选择无人机悬停视点。

Result: 海上场景的仿真结果表明，该方法提高了覆盖范围、定位精度和跟踪一致性，同时保持了适度的通信需求。

Conclusion: 该去中心化多机器人框架能够有效解决海上漂浮容器的检测和跟踪问题，在反射水面环境和有限通信条件下实现了鲁棒的感知和协调。

Abstract: Autonomous aerial-surface robot teams are promising for maritime monitoring. Robust deployment requires reliable perception over reflective water and scalable coordination under limited communication. We present a decentralized multi-robot framework for detecting and tracking floating containers using multiple UAVs cooperating with an autonomous surface vessel. Each UAV performs YOLOv8 and stereo-disparity-based visual detection, then tracks targets with per-object EKFs using uncertainty-aware data association. Compact track summaries are exchanged and fused conservatively via covariance intersection, ensuring consistency under unknown correlations. An information-driven assignment module allocates targets and selects UAV hover viewpoints by trading expected uncertainty reduction against travel effort and safety separation. Simulation results in a maritime scenario demonstrate improved coverage, localization accuracy, and tracking consistency while maintaining modest communication requirements.

</details>


### [99] [Adaptive-Horizon Conflict-Based Search for Closed-Loop Multi-Agent Path Finding](https://arxiv.org/abs/2602.12024)
*Jiarui Li,Federico Pecora,Runyu Zhang,Gioele Zardini*

Main category: cs.RO

TL;DR: ACCBS是一种结合了CBS和MPC的闭环多智能体路径规划算法，通过动态调整规划时域和重用约束树，实现了快速可行解和渐进最优性，兼具理论最优性和实际鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF方法要么是开环规划器（生成固定轨迹，难以处理扰动），要么是缺乏可靠性能保证的闭环启发式方法，限制了在安全关键部署中的应用。需要一种既能灵活应对扰动又具有强性能保证的算法。

Method: 基于有限时域CBS变体，受MPC中迭代深化启发，采用时域变化机制。动态调整规划时域以适应计算预算，重用单一约束树实现时域间的无缝转换。

Result: ACCBS能快速生成高质量可行解，随着计算预算增加具有渐进最优性，表现出随时性行为。在大量案例研究中展示了其结合扰动灵活性和强性能保证的能力。

Conclusion: ACCBS有效弥合了大规模机器人部署中理论最优性和实际鲁棒性之间的差距，为自动化仓库和物流中的大型机器人车队协调问题提供了实用解决方案。

Abstract: MAPF is a core coordination problem for large robot fleets in automated warehouses and logistics. Existing approaches are typically either open-loop planners, which generate fixed trajectories and struggle to handle disturbances, or closed-loop heuristics without reliable performance guarantees, limiting their use in safety-critical deployments. This paper presents ACCBS, a closed-loop algorithm built on a finite-horizon variant of CBS with a horizon-changing mechanism inspired by iterative deepening in MPC. ACCBS dynamically adjusts the planning horizon based on the available computational budget, and reuses a single constraint tree to enable seamless transitions between horizons. As a result, it produces high-quality feasible solutions quickly while being asymptotically optimal as the budget increases, exhibiting anytime behavior. Extensive case studies demonstrate that ACCBS combines flexibility to disturbances with strong performance guarantees, effectively bridging the gap between theoretical optimality and practical robustness for large-scale robot deployment.

</details>


### [100] [When would Vision-Proprioception Policies Fail in Robotic Manipulation?](https://arxiv.org/abs/2602.12032)
*Jingxian Lu,Wenke Xia,Yuxuan Wu,Zhiwu Lu,Di Hu*

Main category: cs.RO

TL;DR: 本文研究了视觉-本体感知策略在机器人操作中的泛化问题，发现运动转换阶段视觉模态作用有限，提出GAP算法通过梯度调整实现动态协作。


<details>
  <summary>Details</summary>
Motivation: 视觉与本体感知的协作有望提升复杂任务中操作策略的性能，但现有研究对视觉-本体感知策略的泛化能力观察不一致，需要深入探究其根本原因。

Method: 提出GAP（Gradient Adjustment with Phase-guidance）算法：利用本体感知捕捉机器人状态并估计轨迹中每个时间步属于运动转换阶段的概率，在策略学习中基于估计概率精细调整本体感知的梯度幅度。

Result: GAP算法在模拟和真实环境、单臂和双臂设置中均适用，兼容传统模型和视觉-语言-动作模型，能产生鲁棒且可泛化的视觉-本体感知策略。

Conclusion: 通过动态调整本体感知的梯度优化，GAP算法能有效促进视觉-本体感知策略中两种模态的协作，为机器人操作中视觉-本体感知策略的发展提供了有价值的见解。

Abstract: Proprioceptive information is critical for precise servo control by providing real-time robotic states. Its collaboration with vision is highly expected to enhance performances of the manipulation policy in complex tasks. However, recent studies have reported inconsistent observations on the generalization of vision-proprioception policies. In this work, we investigate this by conducting temporally controlled experiments. We found that during task sub-phases that robot's motion transitions, which require target localization, the vision modality of the vision-proprioception policy plays a limited role. Further analysis reveals that the policy naturally gravitates toward concise proprioceptive signals that offer faster loss reduction when training, thereby dominating the optimization and suppressing the learning of the visual modality during motion-transition phases. To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm that adaptively modulates the optimization of proprioception, enabling dynamic collaboration within the vision-proprioception policy. Specifically, we leverage proprioception to capture robotic states and estimate the probability of each timestep in the trajectory belonging to motion-transition phases. During policy learning, we apply fine-grained adjustment that reduces the magnitude of proprioception's gradient based on estimated probabilities, leading to robust and generalizable vision-proprioception policies. The comprehensive experiments demonstrate GAP is applicable in both simulated and real-world environments, across one-arm and dual-arm setups, and compatible with both conventional and Vision-Language-Action models. We believe this work can offer valuable insights into the development of vision-proprioception policies in robotic manipulation.

</details>


### [101] [Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis](https://arxiv.org/abs/2602.12047)
*Anutam Srinivasan,Antoine Leeman,Glen Chou*

Main category: cs.RO

TL;DR: 提出结合保形预测和系统级综合的鲁棒分布外规划框架，通过加权CP学习状态-控制相关的协方差模型，推导高置信度模型误差界，并集成到基于SLS的鲁棒非线性MPC中，通过体积优化的前向可达集进行约束收紧。


<details>
  <summary>Details</summary>
Motivation: 解决在使用学习动力学模型时，超出训练数据分布范围的安全性和鲁棒性保障挑战。当模型在分布外区域使用时，需要确保系统仍能安全运行。

Method: 1) 使用加权保形预测学习状态-控制相关的协方差模型，推导高置信度模型误差界；2) 将误差界集成到基于系统级综合的鲁棒非线性模型预测控制框架中；3) 通过体积优化的前向可达集在预测时域内进行约束收紧。

Result: 提供了分布漂移下的覆盖率和鲁棒性理论保证，分析了数据密度和轨迹管大小对预测覆盖率的影响。在非线性系统（包括4D汽车和12D四旋翼）上的实验表明，相比固定边界和非鲁棒基线，该方法在分布外区域显著提高了安全性和鲁棒性。

Conclusion: 该框架成功地将保形预测与系统级综合相结合，为学习动力学模型在分布外区域的鲁棒控制提供了有效的解决方案，通过理论保证和实验验证了其在复杂非线性系统中的优越性能。

Abstract: We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.

</details>


### [102] [HoloBrain-0 Technical Report](https://arxiv.org/abs/2602.12062)
*Xuewu Lin,Tianwei Lin,Yun Du,Hongyu Xie,Yiwei Jin,Jiawei Li,Shijie Wu,Qingze Wang,Mengdi Li,Mengao Zhao,Ziang Li,Chaodong Huang,Hongzhe Bi,Lichao Huang,Zhizhong Su*

Main category: cs.RO

TL;DR: HoloBrain-0是一个全面的视觉-语言-动作框架，通过显式融入机器人先验知识，在模拟和真实世界任务中取得SOTA结果，并开源完整生态系统。


<details>
  <summary>Details</summary>
Motivation: 弥合基础模型研究与可靠真实世界机器人部署之间的差距，解决现有VLA模型缺乏机器人具体化先验知识的问题。

Method: 提出新颖的VLA架构，显式融入机器人具体化先验（多视角相机参数和运动学描述URDF），采用"预训练后微调"范式，支持不同机器人形态。

Result: 在RoboTwin 2.0、LIBERO、GenieSim等模拟基准上取得SOTA结果，在挑战性长时域真实世界操作任务中表现强劲，0.2B参数变体性能媲美更大基线模型。

Conclusion: HoloBrain-0为高性能机器人操作提供了完整可复现路径，通过开源完整生态系统（预训练模型、微调检查点、RoboOrchard基础设施）加速研究和实际应用。

Abstract: In this work, we introduce HoloBrain-0, a comprehensive Vision-Language-Action (VLA) framework that bridges the gap between foundation model research and reliable real-world robot deployment. The core of our system is a novel VLA architecture that explicitly incorporates robot embodiment priors, including multi-view camera parameters and kinematic descriptions (URDF), to enhance 3D spatial reasoning and support diverse embodiments. We validate this design through a scalable ``pre-train then post-train" paradigm, achieving state-of-the-art results on simulation benchmarks such as RoboTwin 2.0, LIBERO, and GenieSim, as well as strong results on challenging long-horizon real-world manipulation tasks. Notably, our efficient 0.2B-parameter variant rivals significantly larger baselines, enabling low-latency on-device deployment. To further accelerate research and practical adoption, we fully open-source the entire HoloBrain ecosystem, which includes: (1) powerful pre-trained VLA foundations; (2) post-trained checkpoints for multiple simulation suites and real-world tasks; and (3) RoboOrchard, a full-stack VLA infrastructure for data curation, model training and deployment. Together with standardized data collection protocols, this release provides the community with a complete, reproducible path toward high-performance robotic manipulation.

</details>


### [103] [VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model](https://arxiv.org/abs/2602.12063)
*Yanjiang Guo,Tony Lee,Lucy Xiaoyang Shi,Jianyu Chen,Percy Liang,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出一种通过迭代在线交互提升视觉-语言-动作模型性能的方法，利用真实世界数据改进世界模型，再用世界模型生成合成数据来增强VLA模型训练


<details>
  <summary>Details</summary>
Motivation: 现有世界模型在物理保真度上不足，特别是在接触丰富的物体操作中难以准确建模关键物理细节，且训练数据缺乏各种物理交互（尤其是失败案例）的覆盖，导致无法有效用于策略改进

Method: 提出简单的迭代改进算法：使用真实世界rollout数据改进世界模型的保真度，然后用改进后的世界模型生成补充合成数据来增强VLA模型训练

Result: 在真实机器人实验中，该方法显著提升了最先进VLA模型在多个下游任务上的性能，相比基础策略获得39.2%的绝对成功率提升，相比仅使用生成合成rollout训练获得11.6%的额外提升

Conclusion: 通过迭代改进世界模型并利用其生成合成数据，可以有效提升VLA模型的性能和可靠性，为解决真实世界数据收集成本高的问题提供了可行方案

Abstract: The goal of this paper is to improve the performance and reliability of vision-language-action (VLA) models through iterative online interaction. Since collecting policy rollouts in the real world is expensive, we investigate whether a learned simulator-specifically, an action-conditioned video generation model-can be used to generate additional rollout data. Unfortunately, existing world models lack the physical fidelity necessary for policy improvement: they are predominantly trained on demonstration datasets that lack coverage of many different physical interactions (particularly failure cases) and struggle to accurately model small yet critical physical details in contact-rich object manipulation. We propose a simple iterative improvement algorithm that uses real-world roll-out data to improve the fidelity of the world model, which can then, in turn, be used to generate supplemental synthetic data for improving the VLA model. In our experiments on a real robot, we use this approach to improve the performance of a state-of-the-art VLA model on multiple downstream tasks. We achieve a 39.2% absolute success rate improvement over the base policy and 11.6% improvement from training with the generated synthetic rollouts. Videos can be found at this anonymous website: https://sites.google.com/view/vla-w

</details>


### [104] [Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning](https://arxiv.org/abs/2602.12065)
*Xiang Liu,Sen Cui,Guocai Yao,Zhong Cao,Jingheng Ma,Min Zhang,Changshui Zhang*

Main category: cs.RO

TL;DR: AGT-World框架通过结构化图表示任务空间，将复杂目标分解为原子原语，并结合自进化机制实现机器人策略的自主优化


<details>
  <summary>Details</summary>
Motivation: 直接在现实世界训练机器人策略成本高且难以扩展，现有生成仿真方法难以生成逻辑一致的长时程任务，且因开环执行而难以应对动态物理不确定性

Method: 提出AGT-World框架，将任务空间形式化为结构化图，实现复杂目标的精确层次分解；引入结合视觉语言模型推理和几何验证的自进化机制，通过混合反馈自主优化策略

Result: 实验表明该方法在成功率和泛化能力上显著优于现有方法，实现了提议、执行和修正的自改进循环，支持可扩展的机器人学习

Conclusion: AGT-World通过结构化任务表示和自进化机制，有效解决了生成仿真中的逻辑一致性和物理不确定性挑战，为可扩展的机器人学习提供了统一框架

Abstract: Training robotic policies directly in the real world is expensive and unscalable. Although generative simulation enables large-scale data synthesis, current approaches often fail to generate logically coherent long-horizon tasks and struggle with dynamic physical uncertainties due to open-loop execution. To address these challenges, we propose Affordance-Graphed Task Worlds (AGT-World), a unified framework that autonomously constructs interactive simulated environments and corresponding robot task policies based on real-world observations. Unlike methods relying on random proposals or static replication, AGT-World formalizes the task space as a structured graph, enabling the precise, hierarchical decomposition of complex goals into theoretically grounded atomic primitives. Furthermore, we introduce a Self-Evolution mechanism with hybrid feedback to autonomously refine policies, combining Vision-Language Model reasoning and geometric verification. Extensive experiments demonstrate that our method significantly outperforms in success rates and generalization, achieving a self-improving cycle of proposal, execution, and correction for scalable robot learning.

</details>


### [105] [RF-Modulated Adaptive Communication Improves Multi-Agent Robotic Exploration](https://arxiv.org/abs/2602.12074)
*Lorin Achey,Breanne Crockett,Christoffer Heckman,Bradley Hayes*

Main category: cs.RO

TL;DR: ART算法通过动态调整传输位置，基于信号强度和数据负载大小，让异构机器人团队在通信受限环境中高效共享信息，减少不必要的折返，提升探索效率。


<details>
  <summary>Details</summary>
Motivation: 在通信受限环境中，多机器人探索面临可靠协调和高效通信的挑战。现有方法要么完全依赖会合点（导致不必要的折返），要么使用简单的信号强度启发式方法（可能无法有效处理不同数据负载）。需要一种能够根据信号质量和数据大小动态调整通信策略的算法。

Method: 提出自适应射频传输（ART）算法，根据信号强度和数据负载大小动态调整传输位置。还探索了ART-SST扩展，为高保真数据传输强制执行信号强度阈值。算法使机器人能够选择最佳传输点，避免不必要的会合，同时确保可靠通信。

Result: 在三个洞穴式环境中进行了480多次模拟，ART始终优于现有策略（包括完全会合和最小信号启发式方法）。相比基线方法，实现了高达58%的旅行距离减少和高达52%的探索时间加快。

Conclusion: 自适应、负载感知的通信显著提高了复杂通信受限环境中的覆盖效率和任务速度。这为未来的行星探索和搜救任务提供了有前景的基础。

Abstract: Reliable coordination and efficient communication are critical challenges for multi-agent robotic exploration of environments where communication is limited. This work introduces Adaptive-RF Transmission (ART), a novel communication-aware planning algorithm that dynamically modulates transmission location based on signal strength and data payload size, enabling heterogeneous robot teams to share information efficiently without unnecessary backtracking. We further explore an extension to this approach called ART-SST, which enforces signal strength thresholds for high-fidelity data delivery. Through over 480 simulations across three cave-inspired environments, ART consistently outperforms existing strategies, including full rendezvous and minimum-signal heuristic approaches, achieving up to a 58% reduction in distance traveled and up to 52% faster exploration times compared to baseline methods. These results demonstrate that adaptive, payload-aware communication significantly improves coverage efficiency and mission speed in complex, communication-constrained environments, offering a promising foundation for future planetary exploration and search-and-rescue missions.

</details>


### [106] [Pack it in: Packing into Partially Filled Containers Through Contact](https://arxiv.org/abs/2602.12095)
*David Russell,Zisong Xu,Maximo A. Roa,Mehmet Dogar*

Main category: cs.RO

TL;DR: 提出一种接触感知的装箱方法，利用与已有物品的有意交互来创造空间，实现新物品的成功放置


<details>
  <summary>Details</summary>
Motivation: 仓库自动化对提高生产力和减少人员危险暴露至关重要。现有装箱研究主要关注空容器装箱并采用无碰撞策略，但实际中容器通常已部分填充物品且排列可能不理想

Method: 使用基于接触的多物体轨迹优化器构建模型预测控制器，集成物理感知的感知系统（即使在遮挡情况下也能估计物体姿态），以及提出物理可行放置位置的方法

Result: 通过有目的性地与已有物品交互来创造空间，成功实现了在部分填充容器中的物品放置

Conclusion: 接触感知的装箱方法能够有效处理实际仓库中部分填充容器的装箱问题，通过智能交互策略提高装箱效率和成功率

Abstract: The automation of warehouse operations is crucial for improving productivity and reducing human exposure to hazardous environments. One operation frequently performed in warehouses is bin-packing where items need to be placed into containers, either for delivery to a customer, or for temporary storage in the warehouse. Whilst prior bin-packing works have largely been focused on packing items into empty containers and have adopted collision-free strategies, it is often the case that containers will already be partially filled with items, often in suboptimal arrangements due to transportation about a warehouse. This paper presents a contact-aware packing approach that exploits purposeful interactions with previously placed objects to create free space and enable successful placement of new items. This is achieved by using a contact-based multi-object trajectory optimizer within a model predictive controller, integrated with a physics-aware perception system that estimates object poses even during inevitable occlusions, and a method that suggests physically-feasible locations to place the object inside the container.

</details>


### [107] [Multi Graph Search for High-Dimensional Robot Motion Planning](https://arxiv.org/abs/2602.12096)
*Itamar Mishani,Maxim Likhachev*

Main category: cs.RO

TL;DR: MGS是一种多图搜索运动规划算法，将经典单向和双向搜索推广到多图设置，能在高维状态空间中高效规划，生成可预测、一致的运动。


<details>
  <summary>Details</summary>
Motivation: 现有高维运动规划算法虽然提升了可扩展性，但往往产生不可预测、不一致的运动，或需要过多计算资源和内存，无法满足实时操作和可靠部署的需求。

Method: 提出多图搜索(MGS)算法，在状态空间上维护并增量扩展多个隐式图，将探索集中在高潜力区域，同时允许初始断开的子图通过可行转换在搜索过程中合并。

Result: 理论上证明了MGS的完备性和有界次优性，并在多种操作和移动操作任务上实证展示了其有效性。

Conclusion: MGS为高维机器人系统提供了一种高效的运动规划解决方案，平衡了计算效率与运动质量，适用于实时部署。

Abstract: Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.

</details>


### [108] [3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting](https://arxiv.org/abs/2602.12159)
*Wancai Zheng,Hao Chen,Xianlong Lu,Linlin Ou,Xinyi Yu*

Main category: cs.RO

TL;DR: 3DGSNav：基于3D高斯泼溅的零样本物体导航框架，通过构建3D环境表示增强视觉语言模型的空间推理能力


<details>
  <summary>Details</summary>
Motivation: 现有零样本物体导航方法依赖语义地图或文本表示等场景抽象，导致高层决策受限于低层感知精度。需要一种能增强空间推理能力的方法来提升导航性能。

Method: 提出3DGSNav框架，将3D高斯泼溅作为持久记忆嵌入视觉语言模型，通过主动感知增量构建3D环境表示，实现轨迹引导的自由视点渲染。设计结构化视觉提示并与思维链提示结合，同时使用实时目标检测器过滤潜在目标，通过VLM驱动的主动视点切换进行目标重验证。

Result: 在多个基准测试和四足机器人真实世界实验中，该方法展现出稳健且具有竞争力的性能，优于现有最先进方法。

Conclusion: 3DGSNav通过将3D高斯泼溅作为持久记忆集成到视觉语言模型中，有效增强了空间推理能力，为物体导航提供了更可靠和高效的解决方案。

Abstract: Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/

</details>


### [109] [Sub--Riemannian boundary value problems for Optimal Geometric Locomotion](https://arxiv.org/abs/2602.12199)
*Oliver Gross,Florine Hartwig,Martin Rumpf,Peter Schröder*

Main category: cs.RO

TL;DR: 提出几何模型用于细长运动体（如沙地蛇）的最优形状变化诱导运动，通过亚黎曼测地线求解边界值问题，同时考虑环境位移能耗和形状变化能耗。


<details>
  <summary>Details</summary>
Motivation: 研究细长运动体（如蛇、精子）在环境中的高效运动机制，现有模型未能同时考虑身体位移能耗和形状变化能耗，需要更全面的几何框架来捕捉整体运动效率。

Method: 建立拉格朗日最小耗散原理的几何模型，将其表述为边界值问题，通过亚黎曼测地线求解。采用连续模型配合时空离散化，可数值计算三种边界条件下的最优运动：固定初始和目标身体、限制循环运动、仅规定位移和方向。

Result: 模型计算出的最优变形步态与蛇、精子等生物的实际运动轨迹定性匹配，也与低维系统（如Purcell游泳者）的已知最优性结果一致。几何灵活性使模型能提供对广义Purcell游泳者等运动机制的新见解。

Conclusion: 提出的几何模型能同时考虑环境位移能耗和形状变化能耗，为细长运动体的最优运动提供统一框架，代码已开源，有助于理解生物运动和机器人设计。

Abstract: We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.

</details>


### [110] [LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion](https://arxiv.org/abs/2602.12215)
*Jiangran Lyu,Kai Liu,Xuheng Zhang,Haoran Liao,Yusen Feng,Wenxuan Zhu,Tingrui Shen,Jiayi Chen,Jiazhao Zhang,Yifei Dong,Wenbo Cui,Senmao Qi,Shuo Wang,Yixin Zheng,Mi Yan,Xuesong Shi,Haoran Li,Dongbin Zhao,Ming-Yu Liu,Zhizheng Zhang,Li Yi,Yizhou Wang,He Wang*

Main category: cs.RO

TL;DR: LDA-1B是一个通过统一世界模型框架学习动态、策略和视觉预测的机器人基础模型，在异构数据上实现了规模化训练，在接触密集、灵巧和长时程任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型主要依赖大规模行为克隆，丢弃了异构数据中可迁移的动态知识。统一世界模型有潜力利用这种多样化数据，但现有实现因数据使用粗糙和数据集碎片化而难以扩展到基础模型规模。

Method: 1) 引入LDA-1B模型，通过联合学习动态、策略和视觉预测，为不同质量数据分配不同角色；2) 构建EI-30k数据集，包含3万小时统一格式的人类和机器人轨迹；3) 在结构化DINO潜在空间中进行预测，避免冗余像素级外观建模；4) 使用多模态扩散变换器处理异步视觉和动作流，实现10亿参数规模的稳定训练。

Result: 在仿真和真实世界实验中，LDA-1B在接触密集、灵巧和长时程任务上分别比现有方法（如π₀.₅）提升21%、48%和23%。模型支持数据高效微调，利用30%通常有害的低质量轨迹可获得10%的性能提升。

Conclusion: LDA-1B通过统一世界模型框架和结构化潜在空间预测，实现了在异构数据上的规模化动态学习，显著提升了机器人基础模型的性能和数据利用效率。

Abstract: Recent robot foundation models largely rely on large-scale behavior cloning, which imitates expert actions but discards transferable dynamics knowledge embedded in heterogeneous embodied data. While the Unified World Model (UWM) formulation has the potential to leverage such diverse data, existing instantiations struggle to scale to foundation-level due to coarse data usage and fragmented datasets. We introduce LDA-1B, a robot foundation model that scales through universal embodied data ingestion by jointly learning dynamics, policy, and visual forecasting, assigning distinct roles to data of varying quality. To support this regime at scale, we assemble and standardize EI-30k, an embodied interaction dataset comprising over 30k hours of human and robot trajectories in a unified format. Scalable dynamics learning over such heterogeneous data is enabled by prediction in a structured DINO latent space, which avoids redundant pixel-space appearance modeling. Complementing this representation, LDA-1B employs a multi-modal diffusion transformer to handle asynchronous vision and action streams, enabling stable training at the 1B-parameter scale. Experiments in simulation and the real world show LDA-1B outperforms prior methods (e.g., $π_{0.5}$) by up to 21\%, 48\%, and 23\% on contact-rich, dexterous, and long-horizon tasks, respectively. Notably, LDA-1B enables data-efficient fine-tuning, gaining 10\% by leveraging 30\% low-quality trajectories typically harmful and discarded.

</details>


### [111] [Any House Any Task: Scalable Long-Horizon Planning for Abstract Human Tasks](https://arxiv.org/abs/2602.12244)
*Zhihong Liu,Yang Li,Rengming Huang,Cewu Lu,Panpan Cai*

Main category: cs.RO

TL;DR: AHAT是一个面向大规模家庭环境的任务规划系统，通过LLM将任务指令和场景图转换为PDDL子目标，再通过符号推理生成最优长时程规划，使用TGPO强化学习算法提升复杂意图分解能力。


<details>
  <summary>Details</summary>
Motivation: 解决开放世界语言条件任务规划在大规模家庭环境中的可扩展性问题。现有方法在环境规模增大、规划长度增加、指令模糊性和约束复杂性提高时性能显著下降。

Method: 1) 使用LLM将任务指令和文本场景图映射为PDDL定义的接地子目标；2) 通过显式符号推理求解子目标生成可行且最优的长时程规划；3) 提出TGPO强化学习算法，将中间推理轨迹的外部校正集成到GRPO中，增强复杂模糊意图的分解能力。

Result: AHAT在人类风格的家庭任务中显著优于最先进的提示、规划和学习方法，特别是在指令简短但需要复杂执行计划的任务上表现突出。

Conclusion: AHAT通过结合LLM的语义理解能力和符号推理的精确性，有效解决了大规模家庭环境中的长时程任务规划问题，TGPO算法进一步提升了处理模糊复杂意图的能力。

Abstract: Open world language conditioned task planning is crucial for robots operating in large-scale household environments. While many recent works attempt to address this problem using Large Language Models (LLMs) via prompting or training, a key challenge remains scalability. Performance often degrades rapidly with increasing environment size, plan length, instruction ambiguity, and constraint complexity. In this work, we propose Any House Any Task (AHAT), a household task planner optimized for long-horizon planning in large environments given ambiguous human instructions. At its core, AHAT utilizes an LLM trained to map task instructions and textual scene graphs into grounded subgoals defined in the Planning Domain Definition Language (PDDL). These subgoals are subsequently solved to generate feasible and optimal long-horizon plans through explicit symbolic reasoning. To enhance the model's ability to decompose complex and ambiguous intentions, we introduce TGPO, a novel reinforcement learning algorithm that integrates external correction of intermediate reasoning traces into Group Relative Policy Optimization (GRPO). Experiments demonstrate that AHAT achieves significant performance gains over state-of-the-art prompting, planning, and learning methods, particularly in human-style household tasks characterized by brief instructions but requiring complex execution plans.

</details>


### [112] [Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment](https://arxiv.org/abs/2602.12281)
*Jacky Kwok,Xilun Zhang,Mengdi Xu,Yuejiang Liu,Azalia Mirhoseini,Chelsea Finn,Marco Pavone*

Main category: cs.RO

TL;DR: CoVer框架通过测试时验证缩小VLA模型的意图-行动差距，利用重述指令和生成动作的联合扩展提高样本多样性，在部署时通过分层验证选择最优提示和动作块。


<details>
  <summary>Details</summary>
Motivation: 通用机器人需要理解并执行自然语言指令，但现有VLA模型生成的行动仍可能与指令意图不一致，存在"意图-行动差距"，需要缩小这一差距。

Method: 提出CoVer对比验证器，采用"启动时计算"和分层验证推理流程：部署时用VLM预计算多样重述指令，为每条指令重复生成动作候选，然后用验证器选择最优高层提示和低层动作块。

Result: 在SIMPLER基准上，相比相同数据的策略预训练扩展，验证方法带来22%分布内和13%分布外提升，真实世界实验进一步改善45%；在PolaRiS基准上，CoVer实现14%任务进度和9%成功率提升。

Conclusion: 测试时验证能有效缩小VLA模型的意图-行动差距，联合扩展重述指令和生成动作可提高样本多样性，CoVer框架在计算资源和数据扩展时表现良好，显著提升指令跟随性能。

Abstract: The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce "boot-time compute" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.

</details>
