<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 74]
- [cs.RO](#cs.RO) [Total: 50]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models](https://arxiv.org/abs/2512.17911)
*Hongji Li,Junchi yao,Manjiang Yu,Priyanka Singh,Xue Li,Di Wang,Lijie Hu*

Main category: cs.CL

TL;DR: 提出了首个针对推理多模态大语言模型（RMLLMs）的遗忘基准RMLLMU-Bench，并开发了R-MUSE方法，在有效遗忘敏感信息的同时保持推理能力。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘旨在从训练模型中擦除请求数据而无需完全重新训练。对于推理多模态大语言模型（RMLLMs），这尤其具有挑战性：即使最终答案被遗忘，中间思维链步骤仍可能泄露敏感信息，而过度干预容易损害通用推理能力。目前缺乏同时评估遗忘方法在抑制推理级泄露和保持推理能力方面的基准。

Method: 提出了RMLLMU-Bench基准，扩展了标准遗忘指标，专门衡量推理泄露和推理保留。为解决现有方法的不足，提出了R-MUSE（Reasoning-preserving MLLM Unlearning via Subspace guidance and Adaptive Steering），这是一个无需训练、基于推理时干预的框架，通过引导内部表示来遗忘答案和推理痕迹，同时明确保留通用推理能力。

Result: 在RMLLMU-Bench上的系统评估显示，现有的MLLMs和大型（语言）推理模型（LRMs）遗忘方法要么在推理过程中留下大量泄露，要么严重降低推理性能。R-MUSE在有效遗忘和推理保留之间实现了显著更好的平衡。

Conclusion: 该研究填补了RMLLMs遗忘评估的空白，提出的R-MUSE方法在保护隐私的同时保持了模型的推理能力，为机器遗忘领域提供了新的解决方案。

Abstract: Machine unlearning aims to erase requested data from trained models without full retraining. For Reasoning Multimodal Large Language Models (RMLLMs), this is uniquely challenging: intermediate chain-of-thought steps can still leak sensitive information even when final answers are forgotten, and overly aggressive interventions easily damage general reasoning ability. Yet no benchmark jointly evaluates how well unlearning methods suppress reasoning-level leakage while preserving reasoning competence. We address this gap with RMLLMU-Bench, the first benchmark for RMLLM unlearning that extends standard forgetting metrics with dedicated measures of reasoning leakage and reasoning retention. A systematic evaluation on RMLLMU-Bench reveals that existing unlearning methods for MLLMs and Large (Language) Reasoning Models (LRMs) either leave substantial leakage in the reasoning process or severely degrade reasoning performance. To address these gaps, we propose R-MUSE (Reasoning-preserving MLLM Unlearning via Subspace guidance and Adaptive Steering), a training-free and inference-time intervention framework that steers internal representations to forget both answers and reasoning traces while explicitly preserving general reasoning. Experiments on RMLLMU-Bench demonstrate that R-MUSE achieves a substantially better balance between effective forgetting and reasoning retention.

</details>


### [2] [Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning](https://arxiv.org/abs/2512.17912)
*Lihui Liu*

Main category: cs.CL

TL;DR: Graph-O1：基于蒙特卡洛树搜索和强化学习的智能体框架，用于在文本属性图上进行逐步推理，解决传统图RAG方法因上下文长度限制导致的推理碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 文本属性图在多个领域广泛应用，但现有方法存在局限：纯文本检索方法忽略图结构，而图序列化方法受限于LLM上下文长度，导致推理碎片化和准确性下降。

Method: 提出Graph-O1框架，将蒙特卡洛树搜索与端到端强化学习结合，使LLM能够选择性地探索和检索最有信息的子图组件，通过多轮智能体-图环境交互进行逐步推理。

Result: 在多个LLM骨干网络上的广泛实验表明，Graph-O1持续超越最先进的基线方法，生成更准确、可靠和可解释的答案。

Conclusion: Graph-O1通过智能体框架实现了在文本属性图上的有效推理，解决了现有方法的局限性，为图增强检索生成提供了新的解决方案。

Abstract: ChatGPT said: Text-attributed graphs, where nodes and edges contain rich textual information, are widely used across diverse domains. A central challenge in this setting is question answering, which requires jointly leveraging unstructured text and the structured relational signals within the graph. Although Large Language Models (LLMs) have made significant advances in natural language understanding, their direct use for reasoning over text-attributed graphs remains limited. Retrieval-augmented generation methods that operate purely on text often treat passages as isolated units, ignoring the interconnected structure of the graph. Conversely, graph-based RAG methods that serialize large subgraphs into long textual sequences quickly become infeasible due to LLM context-length constraints, resulting in fragmented reasoning and degraded accuracy. To overcome these limitations, we introduce Graph-O1, an agentic GraphRAG framework that enables LLMs to conduct stepwise, interactive reasoning over graphs. Our approach integrates Monte Carlo Tree Search (MCTS) with end-to-end reinforcement learning, allowing the model to selectively explore and retrieve only the most informative subgraph components. The reasoning procedure is framed as a multi-turn interaction between the agent and the graph environment, and the agent is trained through a unified reward mechanism. Extensive experiments across multiple LLM backbones demonstrate that Graph-O1 consistently surpasses state-of-the-art baselines, producing answers that are more accurate, reliable, and interpretable.

</details>


### [3] [Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression](https://arxiv.org/abs/2512.17914)
*Boris Kriuk,Logic Ng*

Main category: cs.CL

TL;DR: Q-KVComm是一种新的多智能体LLM通信协议，通过直接传输压缩的KV缓存表示，解决了传统文本传输导致的带宽和计算资源浪费问题，实现了5-6倍的压缩比同时保持语义保真度。


<details>
  <summary>Details</summary>
Motivation: 多智能体LLM系统面临关键瓶颈：智能体之间冗余的上下文信息传输消耗过多带宽和计算资源。传统方法丢弃内部语义表示并传输原始文本，迫使接收智能体从头重新计算相似表示。

Method: Q-KVComm协议包含三个关键技术：1) 基于敏感性分析的层自适应量化，分配可变比特宽度；2) 跨内容域保留关键事实的混合信息提取；3) 建立跨架构通信的异构模型校准。

Result: 在三个不同问答数据集上的实验表明，Q-KVComm实现了5-6倍的压缩比，同时保持语义保真度，所有场景下的连贯性质量分数均高于0.77。协议在不同模型规模（1.1B-1.5B参数）和实际应用（对话QA和多跳推理）中表现稳健。

Conclusion: 该工作为LLM智能体通信建立了新范式，从基于文本的信息交换转向基于表示的信息交换，显著提高了通信效率。

Abstract: Multi-agent Large Language Model (LLM) systems face a critical bottleneck: redundant transmission of contextual information between agents consumes excessive bandwidth and computational resources. Traditional approaches discard internal semantic representations and transmit raw text, forcing receiving agents to recompute similar representations from scratch. We introduce Q-KVComm, a new protocol that enables direct transmission of compressed key-value (KV) cache representations between LLM agents. Q-KVComm combines three key innovations: (1) adaptive layer-wise quantization that allocates variable bit-widths based on sensitivity profiling, (2) hybrid information extraction that preserves critical facts across content domains, and (3) heterogeneous model calibration establishing cross-architecture communication. Extensive experiments across three diverse question-answering datasets demonstrate that Q-KVComm achieves 5-6x compression ratios while maintaining semantic fidelity, with coherence quality scores above 0.77 across all scenarios. The protocol exhibits robust performance across model sizes (1.1B-1.5B parameters) and adapts to real-world applications including conversational QA and multi-hop reasoning. Our work establishes a new paradigm for LLM agent communication, shifting from text-based to representation-based information exchange.

</details>


### [4] [Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset](https://arxiv.org/abs/2512.17915)
*Nick Rossenbach,Robin Schmitt,Tina Raissi,Simon Berger,Larissa Kleppel,Ralf Schlüter*

Main category: cs.CL

TL;DR: Loquacious数据集旨在替代LibriSpeech等现有ASR数据集，提供跨多个声学和语言领域的训练/测试划分，并附带语言模型、G2P模型等额外资源，实验表明该数据集对ASR研究具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 现有英语自动语音识别数据集如LibriSpeech或TED-Lium存在局限性，需要一个新的、具有明确定义训练和测试划分、跨多个声学和语言领域、且适合学术和工业界使用的开放许可数据集。

Method: 创建Loquacious数据集，提供n-gram语言模型、grapheme-to-phoneme模型和发音词典等额外资源，并在多种ASR架构（不同标签单元和拓扑结构）上进行实验验证。

Result: 实验结果表明Loquacious数据集为ASR中各种常见挑战提供了有价值的研究案例，能够支持广泛的ASR架构评估。

Conclusion: Loquacious数据集及其配套资源为ASR研究提供了重要的基准测试工具，具有开放许可和跨领域特性，适合学术和工业界使用。

Abstract: The recently published Loquacious dataset aims to be a replacement for established English automatic speech recognition (ASR) datasets such as LibriSpeech or TED-Lium. The main goal of the Loquacious dataset is to provide properly defined training and test partitions across many acoustic and language domains, with an open license suitable for both academia and industry. To further promote the benchmarking and usability of this new dataset, we present additional resources in the form of n-gram language models (LMs), a grapheme-to-phoneme (G2P) model and pronunciation lexica, with open and public access. Utilizing those additional resources we show experimental results across a wide range of ASR architectures with different label units and topologies. Our initial experimental results indicate that the Loquacious dataset offers a valuable study case for a variety of common challenges in ASR.

</details>


### [5] [Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models](https://arxiv.org/abs/2512.17916)
*Minh Tri LÊ,Ali Ait-Bachir*

Main category: cs.CL

TL;DR: 该研究比较了两种IT服务管理票证优先级分类方法：基于嵌入的管道与微调的多语言Transformer，发现Transformer在噪声文本、主观写作风格和类别不平衡情况下表现显著更优。


<details>
  <summary>Details</summary>
Motivation: IT服务管理中的票证优先级分类面临三大挑战：噪声文本输入、主观写作风格和显著的类别不平衡。现有方法在这些挑战下表现不佳，需要更有效的解决方案。

Method: 评估了两种方法家族：1) 基于嵌入的管道（结合降维、聚类和传统分类器）；2) 微调的多语言Transformer（同时处理文本和数值特征）。在三十种不同配置下进行测试。

Result: 基于嵌入的方法泛化能力有限，聚类未能发现有意义的结构，监督模型对嵌入质量高度敏感。而Transformer模型表现显著更好，平均F1分数达78.5%，加权Cohen's kappa值接近0.80。

Conclusion: 通用嵌入方法对ITSM数据效果有限，而领域适应的Transformer架构在操作票证优先级分类中表现优异，为实际应用提供了有效解决方案。

Abstract: Prioritizing service tickets in IT Service Management (ITSM) is critical for operational efficiency but remains challenging due to noisy textual inputs, subjective writing styles, and pronounced class imbalance. We evaluate two families of approaches for ticket prioritization: embedding-based pipelines that combine dimensionality reduction, clustering, and classical classifiers, and a fine-tuned multilingual transformer that processes both textual and numerical features. Embedding-based methods exhibit limited generalization across a wide range of thirty configurations, with clustering failing to uncover meaningful structures and supervised models highly sensitive to embedding quality. In contrast, the proposed transformer model achieves substantially higher performance, with an average F1-score of 78.5% and weighted Cohen's kappa values of nearly 0.80, indicating strong alignment with true labels. These results highlight the limitations of generic embeddings for ITSM data and demonstrate the effectiveness of domain-adapted transformer architectures for operational ticket prioritization.

</details>


### [6] [KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction](https://arxiv.org/abs/2512.17917)
*Aomufei Yuan,Zhiming Wang,Ruijie Miao,Dayu Wang,Yuxuan Tian,Zihan Wang,Yebo Peng,Yuhan Wu,Bairen Yi,Xin Liu,Tong Yang*

Main category: cs.CL

TL;DR: KVReviver：基于草图算法的可逆KV缓存压缩方法，解决LLM长上下文部署中的内存瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 随着LLM上下文长度快速增长，KV缓存的内存需求成为部署和批处理的瓶颈。传统KV缓存压缩方法会永久驱逐或合并"不重要"的token，导致不可恢复的信息丢失（上下文遗忘），显著降低模型的信息检索能力。

Method: 提出KVReviver，一种基于草图算法的可逆KV缓存压缩方法。该方法允许从额外的数据结构中重建压缩的token，从而在有限内存内实现全规模计算。

Result: 在2k长度上下文中，仅需10%的KV缓存预算即可保持相同的端到端推理精度。在32k长度上下文中，仅使用25%的KV缓存预算就能达到相当或可比的精度（约2%精度损失）。

Conclusion: KVReviver通过可逆压缩解决了传统KV缓存压缩方法中的上下文遗忘问题，显著降低了内存需求，为长上下文LLM部署提供了有效的解决方案。

Abstract: As the context length of current large language models (LLMs) rapidly increases, the memory demand for the Key-Value (KV) cache is becoming a bottleneck for LLM deployment and batch processing. Traditional KV cache compression methods typically involve permanently evicting or irreversibly merging "less important" tokens with low attention scores. This approach results in the unrecoverable loss of token information, which we call Contextual Amnesia, significantly degrading the model's information retrieval capability. To address this issue, we propose KVReviver, a reversible KV cache compression method based on the sketch algorithm. This method allows reconstructing compressed tokens from an additional data structure, thus enabling full-scale computation within limited memory. Experiments showed that in 2k-length contexts, it requires only 10% of KV Cache budget while maintaining identical end-to-end inference accuracy. For 32k-length contexts, it achieves equivalent or comparable accuracy ~2% accuracy loss) using merely 25% of KV Cache budget.

</details>


### [7] [Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression](https://arxiv.org/abs/2512.17920)
*Rahul Baxi*

Main category: cs.CL

TL;DR: 论文发现LLM在提示压缩下性能下降的机制：RLHF训练的"乐于助人"行为与指令遵循之间存在根本冲突，导致中等压缩时约束合规性最差，形成U型曲线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在提示压缩下性能下降，但其机制尚不明确。需要理解压缩如何影响模型的约束合规性和语义准确性，以改进实际部署系统。

Method: 引入压缩衰减理解测试(CDCT)，独立测量约束合规性(CC)和语义准确性(SA)。评估9个前沿LLM在8个概念上的5个压缩级别（从极端压缩到无压缩）。使用三法官LLM陪审团进行评分，并通过RLHF消融实验验证假设。

Result: 发现普遍的U型曲线模式（97.2%出现率），约束违规在中度压缩时达到峰值。反直觉地，极端压缩比中等长度表现更好。约束效应比语义效应大2.9倍。RLHF消融实验证实约束显著性假设：移除"乐于助人"信号使CC平均提高598%。推理模型比高效模型表现好27.5%。

Conclusion: 揭示了RLHF对齐与指令遵循之间的根本张力，RLHF训练的"乐于助人"行为是中等压缩时约束违规的主要原因。这为改进部署系统提供了可操作的指导方针。

Abstract: Large language models (LLMs) exhibit degraded performance under prompt compression, but the mechanisms remain poorly understood. We introduce the Compression-Decay Comprehension Test (CDCT), a benchmark that independently measures constraint compliance (CC) and semantic accuracy (SA) across compression levels. We evaluate 9 frontier LLMs across 8 concepts using 5 compression levels from extreme (c=0.0, ~2 words) to none (c=1.0, ~135 words). A three-judge LLM jury achieves almost perfect inter-rater agreement on CC (Fleiss' \k{appa}=0.90).
  We observe a universal U-curve pattern in constraint compliance (97.2% prevalence), with violations peaking at medium compression (c=0.5, ~27 words). Counterintuitively, models perform better at extreme compression than medium lengths. The dimensions are statistically orthogonal (r=0.193, p=0.084), with constraint effects 2.9x larger than semantic effects.
  Experimental validation via RLHF ablation confirms our constraint salience hypothesis: removing "helpfulness" signals improves CC by 598% on average (71/72 trials, p<0.001), with 79% achieving perfect compliance. This demonstrates that RLHF-trained helpfulness behaviors are the dominant cause of constraint violations at medium compression. Reasoning models outperform efficient models by 27.5% (Cohen's d=0.96).
  Our findings reveal a fundamental tension between RLHF alignment and instruction-following, providing actionable guidelines for improving deployed systems.

</details>


### [8] [ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India](https://arxiv.org/abs/2512.18014)
*Shubham Kumar Nigam,Tanuj Tyagi,Siddharth Shukla,Aditya Kumar Guru,Balaramamahanthi Deepak Patnaik,Danush Khanna,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 本文提出了一个基于强化学习的法律AI框架ReGal，结合多任务指令微调和AI反馈强化学习，在印度法律背景下探索法律推理任务，尽管性能不及监督模型，但为RL在法律文本中的应用提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在印度法律AI中的应用，解决法律文本处理中的挑战，为构建可解释和自适应的法律AI系统奠定基础。

Method: 提出ReGal框架，整合多任务指令微调和基于AI反馈的强化学习（RLAIF），使用近端策略优化（PPO），在法院判决预测与解释（CJPE）和法律文档摘要两个任务上进行评估。

Result: 框架在标准评估指标上表现不及监督和专有模型，但通过实证和定性分析揭示了RL应用于法律文本的挑战，包括奖励模型对齐、法律语言复杂性和领域特定适应等问题。

Conclusion: 尽管性能有限，但研究为使用强化学习优化法律推理流程奠定了基础，对构建可解释和自适应的法律AI系统具有更广泛的意义，为未来研究指明了方向。

Abstract: This paper presents an early exploration of reinforcement learning methodologies for legal AI in the Indian context. We introduce Reinforcement Learning-based Legal Reasoning (ReGal), a framework that integrates Multi-Task Instruction Tuning with Reinforcement Learning from AI Feedback (RLAIF) using Proximal Policy Optimization (PPO). Our approach is evaluated across two critical legal tasks: (i) Court Judgment Prediction and Explanation (CJPE), and (ii) Legal Document Summarization. Although the framework underperforms on standard evaluation metrics compared to supervised and proprietary models, it provides valuable insights into the challenges of applying RL to legal texts. These challenges include reward model alignment, legal language complexity, and domain-specific adaptation. Through empirical and qualitative analysis, we demonstrate how RL can be repurposed for high-stakes, long-document tasks in law. Our findings establish a foundation for future work on optimizing legal reasoning pipelines using reinforcement learning, with broader implications for building interpretable and adaptive legal AI systems.

</details>


### [9] [CoPE: A Small Language Model for Steerable and Scalable Content Labeling](https://arxiv.org/abs/2512.18027)
*Samidh Chakrabarti,David Willner,Kevin Klyman,Tiffany Saade,Emily Capstick,Sabina Nong*

Main category: cs.CL

TL;DR: CoPE是一个可策略引导的小型语言模型，通过矛盾示例训练和双目标注方法实现快速准确的内容标注，在7个危害领域达到与前沿模型相当或更好的准确率，但体积仅为其1%。


<details>
  <summary>Details</summary>
Motivation: 当前内容标注系统通常需要大型模型，计算成本高且难以快速适应新政策。需要开发小型、高效、可策略引导的模型，将机器学习任务转变为政策编写任务，为在线平台治理提供新设计可能性。

Method: 提出矛盾示例训练方法，让模型学习政策解释而非简单记忆；开发双目标注方法，快速构建无歧义训练数据集；训练9亿参数版本，可在单张消费级GPU上运行。

Result: 在7个不同危害领域的评估中，CoPE表现出与前沿模型相当或更优的准确率，但模型大小仅为前沿模型的1%；公开发布9亿参数版本，可在单张消费级GPU上运行。

Conclusion: CoPE代表了分类器系统的范式转变，将ML任务转变为政策编写任务，为在线平台治理开辟了新的设计可能性，展示了小型高效模型在内容标注领域的潜力。

Abstract: This paper details the methodology behind CoPE, a policy-steerable small language model capable of fast and accurate content labeling. We present a novel training curricula called Contradictory Example Training that enables the model to learn policy interpretation rather than mere policy memorization. We also present a novel method for generating content policies, called Binocular Labeling, which enables rapid construction of unambiguous training datasets. When evaluated across seven different harm areas, CoPE exhibits equal or superior accuracy to frontier models at only 1% of their size. We openly release a 9 billion parameter version of the model that can be run on a single consumer-grade GPU. Models like CoPE represent a paradigm shift for classifier systems. By turning an ML task into a policy writing task, CoPE opens up new design possibilities for the governance of online platforms.

</details>


### [10] [Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts](https://arxiv.org/abs/2512.18041)
*Roger A. Finger,Eduardo G. Cortes,Sandro J. Rigo,Gabriel de O. Ramos*

Main category: cs.CL

TL;DR: 本文提出"叙事整合"新任务，专注于将重叠叙事文档整合为统一、连贯、时序正确的文本，而非传统摘要的压缩。通过引入时序对齐事件图(TAEG)并应用中心性算法，在圣经四福音书研究中实现了完美时序排序和内容指标显著提升。


<details>
  <summary>Details</summary>
Motivation: 处理重叠叙事文档（如法律证词、历史记载）时，传统多文档摘要方法注重压缩而破坏了叙事流。需要一种新方法能够保持时序完整性、完整性和细节融合，而不是简单压缩。

Method: 提出"叙事整合"新任务，引入时序对齐事件图(TAEG)来显式建模时序和事件对齐。通过应用标准中心性算法到TAEG，作为版本选择机制，为每个事件选择最中心的表示并置于正确时序位置。

Result: 在圣经四福音书研究中，该方法保证了完美的时序排序（Kendall's Tau为1.000），并显著提升了内容指标（如ROUGE-L F1提升357.2%）。验证了叙事整合作为相关任务的有效性。

Conclusion: 时序对齐事件图(TAEG)的成功验证了叙事整合作为相关任务的定义，并证明显式时序骨架是解决该任务的基本组件。该方法为处理重叠叙事文档提供了新方向。

Abstract: Processing overlapping narrative documents, such as legal testimonies or historical accounts, often aims not for compression but for a unified, coherent, and chronologically sound text. Standard Multi-Document Summarization (MDS), with its focus on conciseness, fails to preserve narrative flow. This paper formally defines this challenge as a new NLP task: Narrative Consolidation, where the central objectives are chronological integrity, completeness, and the fusion of complementary details. To demonstrate the critical role of temporal structure in this task, we introduce Temporal Alignment Event Graph (TAEG), a graph structure that explicitly models chronology and event alignment. By applying a standard centrality algorithm to TAEG, our method functions as a version selection mechanism, choosing the most central representation of each event in its correct temporal position. In a study on the four Biblical Gospels, this structure-focused approach guarantees perfect temporal ordering (Kendall's Tau of 1.000) by design and dramatically improves content metrics (e.g., +357.2% in ROUGE-L F1). The success of this baseline method validates the formulation of Narrative Consolidation as a relevant task and establishes that an explicit temporal backbone is a fundamental component for its resolution.

</details>


### [11] [Statistical laws and linguistics inform meaning in naturalistic and fictional conversation](https://arxiv.org/abs/2512.18072)
*Ashley M. A. Fehr,Calla G. Beauregard,Julia Witte Zimmerman,Katie Ekström,Pablo Rosillo-Rodes,Christopher M. Danforth,Peter Sheridan Dodds*

Main category: cs.CL

TL;DR: 研究对话中词汇增长规律，发现不同词性的词汇增长模式存在差异


<details>
  <summary>Details</summary>
Motivation: 对话是社会连接的核心，与幸福感相关。对话类型多样，部分对话会产生复杂的动态故事。目前对Heaps定律（词汇量随文档长度增长）在对话中的研究较少，特别是语言特征如何影响这种增长规律。

Method: 测量两种不同媒介对话中的Heaps定律：1）陌生人视频聊天；2）电影中虚构人物的对话。分析不同词性（名词、动词等）的词汇增长模式。

Result: 发现词汇量的增长规律因词性不同而存在差异。不同词类的词汇增长模式表现出不同的统计特征。

Conclusion: 通过行为和语言学框架讨论这些发现，表明对话中的词汇增长模式具有词性特异性，这为理解对话动态提供了新的视角。

Abstract: Conversation is a cornerstone of social connection and is linked to well-being outcomes. Conversations vary widely in type with some portion generating complex, dynamic stories. One approach to studying how conversations unfold in time is through statistical patterns such as Heaps' law, which holds that vocabulary size scales with document length. Little work on Heaps's law has looked at conversation and considered how language features impact scaling. We measure Heaps' law for conversations recorded in two distinct mediums: 1. Strangers brought together on video chat and 2. Fictional characters in movies. We find that scaling of vocabulary size differs by parts of speech. We discuss these findings through behavioral and linguistic frameworks.

</details>


### [12] [Training LLMs with LogicReward for Faithful and Rigorous Reasoning](https://arxiv.org/abs/2512.18196)
*Jundong Xu,Hao Fei,Huichi Zhou,Xin Quan,Qijun Huang,Shengqiong Wu,William Yang Wang,Mong-Li Lee,Wynne Hsu*

Main category: cs.CL

TL;DR: LogicReward：通过定理证明器强制执行步骤级逻辑正确性的奖励系统，提升LLM推理的忠实性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练方法依赖结果反馈，可能产生正确但推理过程有缺陷的答案。在逻辑一致性至关重要的高风险场景中，需要保证推理过程的逻辑正确性。

Method: 提出LogicReward奖励系统，使用定理证明器强制执行步骤级逻辑正确性；引入软统一自动形式化方法，减少自然语言歧义，提高形式化质量。

Result: 使用LogicReward训练的8B模型在自然语言推理和逻辑推理任务上分别超越GPT-4o和o4-mini 11.6%和2%；提升推理忠实性，增强对数学和常识推理等未见任务的泛化能力。

Conclusion: LogicReward通过定理证明器提供可靠的奖励信号，无需真实标签即可提升LLM的逻辑推理能力，为高风险场景下的可靠推理提供了有效解决方案。

Abstract: Although LLMs exhibit strong reasoning capabilities, existing training methods largely depend on outcome-based feedback, which can produce correct answers with flawed reasoning. Prior work introduces supervision on intermediate steps but still lacks guarantees of logical soundness, which is crucial in high-stakes scenarios where logical consistency is paramount. To address this, we propose LogicReward, a novel reward system that guides model training by enforcing step-level logical correctness with a theorem prover. We further introduce Autoformalization with Soft Unification, which reduces natural language ambiguity and improves formalization quality, enabling more effective use of the theorem prover. An 8B model trained on data constructed with LogicReward surpasses GPT-4o and o4-mini by 11.6\% and 2\% on natural language inference and logical reasoning tasks with simple training procedures. Further analysis shows that LogicReward enhances reasoning faithfulness, improves generalizability to unseen tasks such as math and commonsense reasoning, and provides a reliable reward signal even without ground-truth labels. We will release all data and code at https://llm-symbol.github.io/LogicReward.

</details>


### [13] [GeoSense-AI: Fast Location Inference from Crisis Microblogs](https://arxiv.org/abs/2512.18225)
*Deepit Sapru*

Main category: cs.CL

TL;DR: GeoSense-AI：一个实时从嘈杂微博流中提取地理位置的AI流水线，通过整合多种NLP技术和地理知识库，在紧急情况下实现高效的位置推断，相比传统NER工具具有更高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 传统依赖稀疏地理标签的方法在紧急情况下无法满足实时需求，需要直接从文本中高效提取地理位置信息以支持应急响应和态势感知。

Method: 统一统计哈希标签分割、词性驱动的专有名词检测、围绕灾害词典的依存解析、轻量级命名实体识别和地名录基础消歧，构建低延迟NLP组件并高效验证地理知识库。

Result: 与广泛使用的NER工具包相比，系统在保持高F1分数的同时实现了数量级更快的吞吐量，能够部署在实时危机信息学场景中，并在洪水、疫情等快速事件中展示端到端功能。

Conclusion: 通过优先考虑非正式文本的鲁棒性和流处理效率，GeoSense-AI展示了领域调优的NLP和知识基础如何超越传统地理标签依赖，提升应急响应能力。

Abstract: This paper presents an applied AI pipeline for realtime geolocation from noisy microblog streams, unifying statistical hashtag segmentation, part-of-speech-driven proper-noun detection, dependency parsing around disaster lexicons, lightweight named-entity recognition, and gazetteer-grounded disambiguation to infer locations directly from text rather than sparse geotags. The approach operationalizes information extraction under streaming constraints, emphasizing low-latency NLP components and efficient validation against geographic knowledge bases to support situational awareness during emergencies. In head to head comparisons with widely used NER toolkits, the system attains strong F1 while being engineered for orders-of-magnitude faster throughput, enabling deployment in live crisis informatics settings. A production map interface demonstrates end-to-end AI functionality ingest, inference, and visualization--surfacing locational signals at scale for floods, outbreaks, and other fastmoving events. By prioritizing robustness to informal text and streaming efficiency, GeoSense-AI illustrates how domain-tuned NLP and knowledge grounding can elevate emergency response beyond conventional geo-tag reliance.

</details>


### [14] [InstructNet: A Novel Approach for Multi-Label Instruction Classification through Advanced Deep Learning](https://arxiv.org/abs/2512.18301)
*Tanjim Taharat Aurpa,Md Shoaib Ahmed,Md Mahbubur Rahman,Md. Golam Moazzam*

Main category: cs.CL

TL;DR: 该研究使用wikiHow的How To文章构建数据集，采用XLNet、BERT等Transformer架构进行多标签指令分类，其中XLNet架构在InstructNet方法中表现最佳，达到97.30%的准确率。


<details>
  <summary>Details</summary>
Motivation: 搜索引擎已成为人们获取信息的主要途径，"How To"前缀被广泛用于寻找问题解决方案。对教学文本进行分类对于任务导向学习和知识库构建至关重要，因此需要开发有效的多标签指令分类方法。

Method: 使用wikiHow构建包含11,121条多标签观察的数据集，采用基于Transformer的深度神经网络架构（包括XLNet、BERT等）进行多标签指令分类，使用准确率和宏F1分数作为性能指标进行评估。

Result: XLNet架构在InstructNet方法中表现最佳，达到97.30%的准确率，微平均和宏平均分数分别为89.02%和93%，在多标签分类任务中取得了显著成果。

Conclusion: XLNet架构在多标签指令分类任务中表现出色，通过多层次评估策略全面了解了所提架构的有效性，并确定了未来改进的方向，为任务导向学习和知识库构建提供了有效工具。

Abstract: People use search engines for various topics and items, from daily essentials to more aspirational and specialized objects. Therefore, search engines have taken over as peoples preferred resource. The How To prefix has become familiar and widely used in various search styles to find solutions to particular problems. This search allows people to find sequential instructions by providing detailed guidelines to accomplish specific tasks. Categorizing instructional text is also essential for task-oriented learning and creating knowledge bases. This study uses the How To articles to determine the multi-label instruction category. We have brought this work with a dataset comprising 11,121 observations from wikiHow, where each record has multiple categories. To find out the multi-label category meticulously, we employ some transformer-based deep neural architectures, such as Generalized Autoregressive Pretraining for Language Understanding (XLNet), Bidirectional Encoder Representation from Transformers (BERT), etc. In our multi-label instruction classification process, we have reckoned our proposed architectures using accuracy and macro f1-score as the performance metrics. This thorough evaluation showed us much about our strategys strengths and drawbacks. Specifically, our implementation of the XLNet architecture has demonstrated unprecedented performance, achieving an accuracy of 97.30% and micro and macro average scores of 89.02% and 93%, a noteworthy accomplishment in multi-label classification. This high level of accuracy and macro average score is a testament to the effectiveness of the XLNet architecture in our proposed InstructNet approach. By employing a multi-level strategy in our evaluation process, we have gained a more comprehensive knowledge of the effectiveness of our proposed architectures and identified areas for forthcoming improvement and refinement.

</details>


### [15] [CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher](https://arxiv.org/abs/2512.18321)
*Tianlun Liu,Zhiliang Tian,Zhen Huang,Xingzhi Zhou,Wanlong Yu,Tianle Liu,Feng Liu,Dongsheng Li*

Main category: cs.CL

TL;DR: 本文提出CTTA-T框架，用于文本理解的持续测试时适应，通过教师-学生架构和动态领域感知机制处理序列化未观察测试领域。


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应方法假设测试领域固定，而实际应用中测试领域会随时间变化。持续测试时适应面临错误累积和泛化能力不足的挑战：噪声过滤会丢弃有用信息，历史领域积累难以自适应实现。

Method: 提出CTTA-T框架：1）采用教师-学生架构，教师模型具有领域感知能力；2）基于dropout驱动一致性的精炼-过滤机制，校准预测并移除不可靠指导；3）通过增量PCA动态积累跨领域语义，构建领域感知教师模型。

Result: 实验表明CTTA-T在持续测试时适应任务中优于现有基线方法，能够有效处理序列化未观察测试领域。

Conclusion: CTTA-T框架成功解决了文本理解中持续测试时适应的挑战，通过领域感知教师模型和动态语义积累机制，平衡了适应性和泛化性，为实际应用中的领域漂移问题提供了有效解决方案。

Abstract: Text understanding often suffers from domain shifts. To handle testing domains, domain adaptation (DA) is trained to adapt to a fixed and observed testing domain; a more challenging paradigm, test-time adaptation (TTA), cannot access the testing domain during training and online adapts to the testing samples during testing, where the samples are from a fixed domain. We aim to explore a more practical and underexplored scenario, continual test-time adaptation (CTTA) for text understanding, which involves a sequence of testing (unobserved) domains in testing. Current CTTA methods struggle in reducing error accumulation over domains and enhancing generalization to handle unobserved domains: 1) Noise-filtering reduces accumulated errors but discards useful information, and 2) accumulating historical domains enhances generalization, but it is hard to achieve adaptive accumulation. In this paper, we propose a CTTA-T (continual test-time adaptation for text understanding) framework adaptable to evolving target domains: it adopts a teacher-student framework, where the teacher is domain-aware and generalized for evolving domains. To improve teacher predictions, we propose a refine-then-filter based on dropout-driven consistency, which calibrates predictions and removes unreliable guidance. For the adaptation-generalization trade-off, we construct a domain-aware teacher by dynamically accumulating cross-domain semantics via incremental PCA, which continuously tracks domain shifts. Experiments show CTTA-T excels baselines.

</details>


### [16] [LIR$^3$AG: A Lightweight Rerank Reasoning Strategy Framework for Retrieval-Augmented Generation](https://arxiv.org/abs/2512.18329)
*Guo Chen,Junjie Huang,Huaijin Xie,Fei Sun,Tao Jia*

Main category: cs.CL

TL;DR: 论文提出LiR³AG框架，让非推理模型通过重构检索证据为连贯推理链来转移推理策略，显著减少计算开销同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成(RAG)通过外部知识增强大语言模型，推理模型能提升多跳QA任务性能，但带来巨大计算成本（token消耗和推理延迟）。需要理解并缓解这种权衡。

Method: 提出LiR³AG框架，通过将检索证据重构为连贯推理链，使非推理模型能够转移推理策略。研究发现推理模型采用两种主要模式：上下文基础推理和知识协调推理。

Result: LiR³AG显著减少平均98%输出token开销和58.6%推理时间，同时将8B非推理模型的F1性能提升6.2%到22.5%，超越32B推理模型在RAG中的性能。

Conclusion: LiR³AG为RAG系统提供了一条实用高效的路径，通过轻量级重排推理策略框架，在保持性能的同时大幅降低计算成本。

Abstract: Retrieval-Augmented Generation (RAG) effectively enhances Large Language Models (LLMs) by incorporating retrieved external knowledge into the generation process. Reasoning models improve LLM performance in multi-hop QA tasks, which require integrating and reasoning over multiple pieces of evidence across different documents to answer a complex question. However, they often introduce substantial computational costs, including increased token consumption and inference latency. To better understand and mitigate this trade-off, we conduct a comprehensive study of reasoning strategies for reasoning models in RAG multi-hop QA tasks. Our findings reveal that reasoning models adopt structured strategies to integrate retrieved and internal knowledge, primarily following two modes: Context-Grounded Reasoning, which relies directly on retrieved content, and Knowledge-Reconciled Reasoning, which resolves conflicts or gaps using internal knowledge. To this end, we propose a novel Lightweight Rerank Reasoning Strategy Framework for RAG (LiR$^3$AG) to enable non-reasoning models to transfer reasoning strategies by restructuring retrieved evidence into coherent reasoning chains. LiR$^3$AG significantly reduce the average 98% output tokens overhead and 58.6% inferencing time while improving 8B non-reasoning model's F1 performance ranging from 6.2% to 22.5% to surpass the performance of 32B reasoning model in RAG, offering a practical and efficient path forward for RAG systems.

</details>


### [17] [Towards Efficient Agents: A Co-Design of Inference Architecture and System](https://arxiv.org/abs/2512.18337)
*Weizhe Lin,Hui-Ling Zhen,Shuai Yang,Xian Wang,Renxi Liu,Hanting Chen,Wangze Zhang,Chuansai Zhou,Yiming Li,Chen Chen,Xing Li,Zhiyuan Yang,Xiaosong Li,Xianzhi Yu,Zhenhua Dong,Mingxuan Yuan,Yunhe Wang*

Main category: cs.CL

TL;DR: AgentInfer是一个端到端的智能体加速框架，通过协同优化的四个组件，在保持准确性的同时减少50%以上无效token消耗，实现1.8-2.5倍整体加速。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的智能体在现实部署中面临严重效率问题，这些效率瓶颈不仅来自单一模型推理，更源于推理循环、上下文增长和异构工具交互中积累的系统性延迟。

Method: 提出AgentInfer统一框架，包含四个协同组件：AgentCollab（分层双模型推理框架）、AgentSched（缓存感知混合调度器）、AgentSAM（基于后缀自动机的推测解码方法）、AgentCompress（语义压缩机制），共同形成自进化引擎。

Result: 在BrowseComp-zh和DeepDiver基准测试中，通过方法协同合作，AgentInfer减少超过50%的无效token消耗，实现整体1.8-2.5倍加速，同时保持准确性。

Conclusion: 优化智能体任务完成（而非单纯每token吞吐量）是构建可扩展、高效、自改进智能系统的关键，AgentInfer展示了系统性优化智能体效率的有效途径。

Abstract: The rapid development of large language model (LLM)-based agents has unlocked new possibilities for autonomous multi-turn reasoning and tool-augmented decision-making. However, their real-world deployment is hindered by severe inefficiencies that arise not from isolated model inference, but from the systemic latency accumulated across reasoning loops, context growth, and heterogeneous tool interactions. This paper presents AgentInfer, a unified framework for end-to-end agent acceleration that bridges inference optimization and architectural design. We decompose the problem into four synergistic components: AgentCollab, a hierarchical dual-model reasoning framework that balances large- and small-model usage through dynamic role assignment; AgentSched, a cache-aware hybrid scheduler that minimizes latency under heterogeneous request patterns; AgentSAM, a suffix-automaton-based speculative decoding method that reuses multi-session semantic memory to achieve low-overhead inference acceleration; and AgentCompress, a semantic compression mechanism that asynchronously distills and reorganizes agent memory without disrupting ongoing reasoning. Together, these modules form a Self-Evolution Engine capable of sustaining efficiency and cognitive stability throughout long-horizon reasoning tasks. Experiments on the BrowseComp-zh and DeepDiver benchmarks demonstrate that through the synergistic collaboration of these methods, AgentInfer reduces ineffective token consumption by over 50%, achieving an overall 1.8-2.5 times speedup with preserved accuracy. These results underscore that optimizing for agentic task completion-rather than merely per-token throughput-is the key to building scalable, efficient, and self-improving intelligent systems.

</details>


### [18] [LLM-based Few-Shot Early Rumor Detection with Imitation Agent](https://arxiv.org/abs/2512.18352)
*Fengzhu Zeng,Qian Shao,Ling Cheng,Wei Gao,Shih-Fen Cheng,Jing Ma,Cheng Niu*

Main category: cs.CL

TL;DR: 提出结合自主代理和LLM的新型早期谣言检测框架，解决数据稀缺场景下的时间序列检测问题，仅需训练轻量级代理，LLM保持训练自由。


<details>
  <summary>Details</summary>
Motivation: 早期谣言检测在数据稀缺场景中具有挑战性。LLM在少样本NLP任务中表现良好，但不适合时间序列数据，且训练和推理计算成本高。

Method: 提出新颖的EARD框架，结合自主代理和基于LLM的检测模型：代理作为早期时间点确定的可靠决策者，LLM作为强大的谣言检测器。仅需训练轻量级代理，LLM保持训练自由。

Result: 在四个真实世界数据集上的广泛实验表明，该方法提升了LLM的性能，在准确性和早期性方面超越了现有的EARD方法。

Conclusion: 该框架为少样本早期谣言检测提供了首个解决方案，通过结合自主代理和LLM的优势，实现了高效准确的早期检测。

Abstract: Early Rumor Detection (EARD) aims to identify the earliest point at which a claim can be accurately classified based on a sequence of social media posts. This is especially challenging in data-scarce settings. While Large Language Models (LLMs) perform well in few-shot NLP tasks, they are not well-suited for time-series data and are computationally expensive for both training and inference. In this work, we propose a novel EARD framework that combines an autonomous agent and an LLM-based detection model, where the agent acts as a reliable decision-maker for \textit{early time point determination}, while the LLM serves as a powerful \textit{rumor detector}. This approach offers the first solution for few-shot EARD, necessitating only the training of a lightweight agent and allowing the LLM to remain training-free. Extensive experiments on four real-world datasets show our approach boosts performance across LLMs and surpasses existing EARD methods in accuracy and earliness.

</details>


### [19] [DACE For Railway Acronym Disambiguation](https://arxiv.org/abs/2512.18357)
*El Mokhtar Hribach,Oussama Mechhour,Mohammed Elmonstaser,Yassine El Boudouri,Othmane Kabal*

Main category: cs.CL

TL;DR: DACE框架通过动态提示、检索增强生成、上下文选择和集成聚合，在法语铁路文档的首字母缩写消歧任务中取得最佳性能，F1分数达0.9069。


<details>
  <summary>Details</summary>
Motivation: 技术文本处理中的首字母缩写消歧（AD）是重要挑战，尤其在专业领域如铁路文档中，高歧义性使自动化分析变得复杂。TextMine'26竞赛的法语铁路文档任务需要解决这一难题。

Method: 提出DACE框架，包含动态提示、检索增强生成、上下文选择和集成聚合四个组件。通过自适应上下文学习和外部领域知识注入来增强大语言模型，针对缩写歧义动态定制提示，并通过集成预测聚合来减少幻觉问题。

Result: 在TextMine'26竞赛中获得第一名，F1分数达到0.9069，有效处理了低资源场景并减少了模型幻觉。

Conclusion: DACE框架通过结合动态提示、知识注入和集成方法，成功解决了专业领域中的首字母缩写消歧问题，在法语铁路文档任务中表现出色，为技术文本处理提供了有效解决方案。

Abstract: Acronym Disambiguation (AD) is a fundamental challenge in technical text processing, particularly in specialized sectors where high ambiguity complicates automated analysis. This paper addresses AD within the context of the TextMine'26 competition on French railway documentation. We present DACE (Dynamic Prompting, Retrieval Augmented Generation, Contextual Selection, and Ensemble Aggregation), a framework that enhances Large Language Models through adaptive in-context learning and external domain knowledge injection. By dynamically tailoring prompts to acronym ambiguity and aggregating ensemble predictions, DACE mitigates hallucination and effectively handles low-resource scenarios. Our approach secured the top rank in the competition with an F1 score of 0.9069.

</details>


### [20] [LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators](https://arxiv.org/abs/2512.18360)
*Mateusz Lango,Ondřej Dušek*

Main category: cs.CL

TL;DR: 提出一种新颖的神经符号框架，通过多个LLM代理协作生成RDF到文本的规则代码，无需监督训练数据，实现完全可解释的文本生成


<details>
  <summary>Details</summary>
Motivation: 传统RDF到文本生成方法需要大量监督训练数据且缺乏可解释性，现有方法存在幻觉问题。本文旨在开发无需领域特定参考文本、完全可解释且减少幻觉的生成方法

Method: 采用神经符号框架，通过多个LLM代理协作交互而非传统反向传播训练。代理基于RDF三元组生成基于规则的Python代码作为生成器，无需领域内人工参考文本

Result: 在WebNLG和OpenDialKG数据集上的实验表明，该方法显著减少幻觉，仅带来轻微流畅性损失（相比微调或提示语言模型）。系统完全可解释，无需监督训练数据，仅需单个CPU即可近乎即时生成文本

Conclusion: 提出的神经符号框架为RDF到文本生成提供了一种新颖的解决方案，通过LLM代理协作生成规则代码，实现了无需训练数据、可解释且减少幻觉的文本生成，在资源受限环境中具有实用价值

Abstract: We present a novel neurosymbolic framework for RDF-to-text generation, in which the model is "trained" through collaborative interactions among multiple LLM agents rather than traditional backpropagation. The LLM agents produce rule-based Python code for a generator for the given domain, based on RDF triples only, with no in-domain human reference texts. The resulting system is fully interpretable, requires no supervised training data, and generates text nearly instantaneously using only a single CPU. Our experiments on the WebNLG and OpenDialKG data show that outputs produced by our approach reduce hallucination, with only slight fluency penalties compared to finetuned or prompted language models

</details>


### [21] [SRS-Stories: Vocabulary-constrained multilingual story generation for language learning](https://arxiv.org/abs/2512.18362)
*Wiktor Kamzela,Mateusz Lango,Ondrej Dusek*

Main category: cs.CL

TL;DR: 使用大语言模型为语言学习者生成个性化故事，仅使用他们已知的词汇，通过上下文阅读教授新词汇并复习已学词汇，结合间隔重复系统优化学习效果。


<details>
  <summary>Details</summary>
Motivation: 为语言学习者提供个性化的阅读材料，通过上下文自然学习新词汇，同时复习已学词汇，解决传统语言学习材料缺乏个性化和趣味性的问题。

Method: 使用大语言模型生成故事，采用三种故事生成方法和三种词汇约束策略，结合间隔重复系统优化词汇学习，在英语、中文和波兰语三种语言中进行实验。

Result: 生成的故事情节更符合语法、更连贯，比标准约束束搜索方法生成的文本提供更好的词汇使用示例。

Conclusion: 大语言模型能够有效生成个性化的语言学习材料，通过上下文阅读自然教授新词汇并复习已学词汇，结合间隔重复系统可以优化学习效果。

Abstract: In this paper, we use large language models to generate personalized stories for language learners, using only the vocabulary they know. The generated texts are specifically written to teach the user new vocabulary by simply reading stories where it appears in context, while at the same time seamlessly reviewing recently learned vocabulary. The generated stories are enjoyable to read and the vocabulary reviewing/learning is optimized by a Spaced Repetition System. The experiments are conducted in three languages: English, Chinese and Polish, evaluating three story generation methods and three strategies for enforcing lexical constraints. The results show that the generated stories are more grammatical, coherent, and provide better examples of word usage than texts generated by the standard constrained beam search approach

</details>


### [22] [AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3](https://arxiv.org/abs/2512.18399)
*Mark Kashirskiy,Artiom Lipinski,Ilya Makarov*

Main category: cs.CL

TL;DR: AraToken：针对阿拉伯语优化的分词器，基于SentencePiece Unigram算法，通过规范化处理阿拉伯语特定变体，显著降低分词数量，并提出了语言扩展管道（LEP）将优化分词器集成到现有模型中。


<details>
  <summary>Details</summary>
Motivation: 通用分词器在英语和拉丁语系上训练，对阿拉伯语等形态丰富的语言表现不佳，导致分词序列过长、压缩效率降低，需要专门针对阿拉伯语优化的分词解决方案。

Method: 1. 基于SentencePiece Unigram算法构建AraToken分词器；2. 设计全面的规范化流程处理阿拉伯语特定变体（Alif变体、变音符号、阿拉伯-印度数字）；3. 系统比较BPE、WordPiece和SentencePiece算法；4. 提出语言扩展管道（LEP），通过词汇扩展和选择性层解冻将优化分词器集成到Qwen3-0.6B模型中。

Result: 1. 规范化后的SentencePiece相比未规范化基线降低18%的分词数量（1.199 vs 1.35 tokens/word）；2. LEP在100K阿拉伯语样本上，仅用800训练步就将评估损失从8.28降至2.43；3. 发布了分词器、训练脚本和模型检查点。

Conclusion: AraToken显著提升了阿拉伯语的分词效率，LEP方法有效将优化分词器集成到现有LLMs中，为阿拉伯语NLP研究提供了实用工具和框架。

Abstract: Tokenization is a critical preprocessing step for large language models (LLMs), directly impacting training efficiency and downstream performance. General-purpose tokenizers trained predominantly on English and Latin-script languages exhibit suboptimal performance on morphologically rich languages such as Arabic, resulting in inflated token sequences and reduced compression efficiency. In this work, we present AraToken, an Arabic-optimized tokenizer built on SentencePiece Unigram algorithm with a comprehensive normalization pipeline addressing Arabic-specific orthographic variations including Alif variants, diacritics, and Arabic-Indic numerals. We systematically compare BPE, WordPiece, and SentencePiece algorithms across multiple configurations, demonstrating that SentencePiece with normalization achieves 18% lower fertility (1.199 vs 1.35 tokens/word) compared to unnormalized baselines. Furthermore, we introduce the Language Extension Pipeline (LEP), a method for integrating the optimized tokenizer into Qwen3-0.6B through vocabulary extension with mean subtoken initialization and selective transformer layer unfreezing. Our experiments show that LEP reduces evaluation loss from 8.28 to 2.43 within 800 training steps on 100K Arabic samples. We release our tokenizer, training scripts, and model checkpoints to facilitate Arabic NLP research.

</details>


### [23] [An Agentic AI Framework for Training General Practitioner Student Skills](https://arxiv.org/abs/2512.18440)
*Victor De Marez,Jens Van Nooten,Luna De Bruyne,Walter Daelemans*

Main category: cs.CL

TL;DR: 提出一个基于大语言模型的智能体框架，用于训练全科医学生技能，通过可配置的循证案例生成、可控的角色扮演对话和基于标准的评估反馈，提升虚拟模拟患者的医学准确性和教育价值。


<details>
  <summary>Details</summary>
Motivation: 当前虚拟模拟患者在医学教育中存在医学准确性不足、角色扮演不一致、案例生成困难以及缺乏结构化反馈等问题，需要开发更可靠、可扩展的训练工具。

Method: 提出一个智能体框架，包含三个核心组件：(1) 可配置的循证案例生成，(2) 可控的角色驱动患者对话（可选检索增强），(3) 基于标准的评估反馈系统（涵盖沟通和临床推理）。在交互式口语咨询场景中实现该框架。

Result: 对14名医学生进行评估，参与者报告：真实且忠于案例的对话、适当的难度校准、稳定的人格信号、丰富有用的反馈示例，以及优秀的整体可用性。

Conclusion: 将场景控制、交互控制和基于标准的评估分离的智能体架构，是构建可靠且具有教学价值的虚拟模拟患者训练工具的有效模式。

Abstract: Advancements in large language models offer strong potential for enhancing virtual simulated patients (VSPs) in medical education by providing scalable alternatives to resource-intensive traditional methods. However, current VSPs often struggle with medical accuracy, consistent roleplaying, scenario generation for VSP use, and educationally structured feedback. We introduce an agentic framework for training general practitioner student skills that unifies (i) configurable, evidence-based vignette generation, (ii) controlled persona-driven patient dialogue with optional retrieval grounding, and (iii) standards-based assessment and feedback for both communication and clinical reasoning. We instantiate the framework in an interactive spoken consultation setting and evaluate it with medical students ($\mathbf{N{=}14}$). Participants reported realistic and vignette-faithful dialogue, appropriate difficulty calibration, a stable personality signal, and highly useful example-rich feedback, alongside excellent overall usability. These results support agentic separation of scenario control, interaction control, and standards-based assessment as a practical pattern for building dependable and pedagogically valuable VSP training tools.

</details>


### [24] [Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling](https://arxiv.org/abs/2512.18462)
*Christopher Román Jaimes*

Main category: cs.CL

TL;DR: 提出自动化可扩展的pipeline解决NLI模型依赖虚假相关性的问题，通过LF-LMI检测语义伪影、LLM合成高质量对比集、动态平衡采样防止遗忘，显著提升模型一致性。


<details>
  <summary>Details</summary>
Motivation: NLI模型经常依赖虚假相关性而非语义推理，现有缓解策略通常标注成本高或在微调时引发灾难性遗忘，需要自动化、可扩展的解决方案。

Method: 1) 提出LF-LMI准确检测语义伪影；2) 通过LLM合成pipeline生成高质量合成对比集，并进行多法官验证；3) 引入动态平衡采样训练策略，旋转原始数据分布防止遗忘。

Result: 在挑战性基准测试中，一致性从63.5%提升至81.0%，同时保持88.4%的域内准确率，显著优于朴素微调方法。

Conclusion: 提出的自动化pipeline有效解决了NLI模型依赖虚假相关性的问题，通过检测伪影、生成对比集和动态采样策略，在提升模型一致性的同时避免了灾难性遗忘。

Abstract: Natural Language Inference (NLI) models frequently rely on spurious correlations rather than semantic reasoning. Existing mitigation strategies often incur high annotation costs or trigger catastrophic forgetting during fine-tuning. We propose an automated, scalable pipeline to address these limitations. First, we introduce Log-Frequency LMI (LF-LMI) to accurately detect semantic artifacts. Second, we generate a high-quality synthetic contrast set via an LLM-synthesis pipeline with multi-judge verification. Finally, we introduce Dynamic Balanced Sampling, a training strategy that rotates the original data distribution to prevent forgetting. Our method improves consistency on a challenging benchmark from 63.5% to 81.0% while maintaining 88.4% in-domain accuracy, significantly outperforming naive fine-tuning.

</details>


### [25] [Research on a hybrid LSTM-CNN-Attention model for text-based web content classification](https://arxiv.org/abs/2512.18475)
*Mykola Kuz,Ihor Lazarovych,Mykola Kozlenko,Mykola Pikuliak,Andrii Kvasniuk*

Main category: cs.CL

TL;DR: 提出一种结合LSTM、CNN和注意力机制的混合深度学习架构，用于网页文本分类，在多项指标上超越传统模型


<details>
  <summary>Details</summary>
Motivation: 解决单一神经网络架构在文本分类中的局限性，需要同时捕捉局部语法特征和长距离语义依赖关系

Method: 使用预训练GloVe词嵌入，结合CNN提取局部n-gram特征，LSTM建模序列依赖，注意力机制聚焦关键信息，采用5折交叉验证评估

Result: 模型在准确率(0.98)、精确率(0.94)、召回率(0.92)和F1分数(0.93)上表现优异，超越CNN、LSTM和BERT等基线模型

Conclusion: 混合架构能有效结合不同神经网络组件的优势，在文本分类任务中实现更好的泛化性能，适合实时应用场景

Abstract: This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.

</details>


### [26] [Teaching and Critiquing Conceptualization and Operationalization in NLP](https://arxiv.org/abs/2512.18505)
*Vagrant Gautam*

Main category: cs.CL

TL;DR: 作者创建了一门研讨课，探讨NLP中"可解释性"、"偏见"、"推理"等抽象概念的定义、意义和测量方法，强调概念化和操作化的重要性。


<details>
  <summary>Details</summary>
Motivation: NLP研究者经常使用"可解释性"、"偏见"、"推理"、"刻板印象"等抽象概念而不明确定义，各子领域对这些概念有不同的理解和操作方式，这影响了数据集构建、指标设计和系统评估。

Method: 作者设计了一门研讨课，采用跨学科阅读材料，强调讨论和批判性分析，引导学生探索这些概念的概念化和操作化问题。

Result: 论文描述了一门已创建的研讨课框架，旨在帮助学生深入理解NLP中核心概念的本质、意义和测量方法。

Conclusion: 需要系统性地审视NLP中常用概念的定义和操作化方式，跨学科研讨课是培养这种批判性思维的有效方法。

Abstract: NLP researchers regularly invoke abstract concepts like "interpretability," "bias," "reasoning," and "stereotypes," without defining them. Each subfield has a shared understanding or conceptualization of what these terms mean and how we should treat them, and this shared understanding is the basis on which operational decisions are made: Datasets are built to evaluate these concepts, metrics are proposed to quantify them, and claims are made about systems. But what do they mean, what should they mean, and how should we measure them? I outline a seminar I created for students to explore these questions of conceptualization and operationalization, with an interdisciplinary reading list and an emphasis on discussion and critique.

</details>


### [27] [Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset](https://arxiv.org/abs/2512.18533)
*S Mahmudul Hasan,Shaily Roy,Akib Jawad Nafis*

Main category: cs.CL

TL;DR: 政治虚假信息检测面临语义瓶颈，单纯增加模型复杂度效果有限，需要外部知识支持


<details>
  <summary>Details</summary>
Motivation: 政治虚假信息具有语言微妙性，现有自动事实核查系统面临挑战。尽管神经网络架构日益复杂，但纯文本语言建模的实证限制尚未充分探索。

Method: 在LIAR基准上对9种机器学习算法进行系统诊断评估，隔离词汇特征（词袋、TF-IDF）和语义嵌入（GloVe），分析性能上限和泛化差距。

Result: 发现性能上限为加权F1分数0.32；线性SVM（准确率0.624）与预训练Transformer（RoBERTa准确率0.620）性能相当；基于树的集成方法存在巨大泛化差距（训练准确率>99%，测试准确率约25%）；SMOTE数据增强无实质性改善。

Conclusion: 对于政治事实核查，单纯增加模型复杂度而不融入外部知识会产生收益递减效应。限制主要来自语义特征模糊性而非分布问题，需要超越纯文本建模的方法。

Abstract: The proliferation of linguistically subtle political disinformation poses a significant challenge to automated fact-checking systems. Despite increasing emphasis on complex neural architectures, the empirical limits of text-only linguistic modeling remain underexplored. We present a systematic diagnostic evaluation of nine machine learning algorithms on the LIAR benchmark. By isolating lexical features (Bag-of-Words, TF-IDF) and semantic embeddings (GloVe), we uncover a hard "Performance Ceiling", with fine-grained classification not exceeding a Weighted F1-score of 0.32 across models. Crucially, a simple linear SVM (Accuracy: 0.624) matches the performance of pre-trained Transformers such as RoBERTa (Accuracy: 0.620), suggesting that model capacity is not the primary bottleneck. We further diagnose a massive "Generalization Gap" in tree-based ensembles, which achieve more than 99% training accuracy but collapse to approximately 25% on test data, indicating reliance on lexical memorization rather than semantic inference. Synthetic data augmentation via SMOTE yields no meaningful gains, confirming that the limitation is semantic (feature ambiguity) rather than distributional. These findings indicate that for political fact-checking, increasing model complexity without incorporating external knowledge yields diminishing returns.

</details>


### [28] [LLMs on Drugs: Language Models Are Few-Shot Consumers](https://arxiv.org/abs/2512.18546)
*Alexander Doudkin*

Main category: cs.CL

TL;DR: 研究发现，在推理时对GPT-5-mini施加不同"药物"角色提示会显著降低其在ARC-Challenge任务上的准确率，其中酒精提示效果最差，准确率从0.45降至0.10。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时对施加的角色很敏感，但从未对提示级别的"药物"干预进行过严格基准测试。本研究旨在首次系统评估不同精神活性框架对LLM性能的影响。

Method: 使用GPT-5-mini在ARC-Challenge上进行对照研究，比较四种单句药物提示（LSD、可卡因、酒精、大麻）与清醒对照条件。每个条件测试100个验证项目，采用确定性解码、完整日志记录、威尔逊置信区间和费希尔精确检验。

Result: 对照准确率为0.45；酒精降至0.10（p=3.2e-8），可卡因0.21（p=4.9e-4），LSD 0.19（p=1.3e-4），大麻0.30（p=0.041）。主要原因是角色提示破坏了"Answer: <LETTER>"模板格式。

Conclusion: 角色文本就像"少量可消耗提示"，可以在不修改模型权重的情况下破坏可靠性。这揭示了提示工程对LLM性能的显著影响，强调了在部署中仔细设计提示的重要性。

Abstract: Large language models (LLMs) are sensitive to the personas imposed on them at inference time, yet prompt-level "drug" interventions have never been benchmarked rigorously. We present the first controlled study of psychoactive framings on GPT-5-mini using ARC-Challenge. Four single-sentence prompts -- LSD, cocaine, alcohol, and cannabis -- are compared against a sober control across 100 validation items per condition, with deterministic decoding, full logging, Wilson confidence intervals, and Fisher exact tests. Control accuracy is 0.45; alcohol collapses to 0.10 (p = 3.2e-8), cocaine to 0.21 (p = 4.9e-4), LSD to 0.19 (p = 1.3e-4), and cannabis to 0.30 (p = 0.041), largely because persona prompts disrupt the mandated "Answer: <LETTER>" template. Persona text therefore behaves like a "few-shot consumable" that can destroy reliability without touching model weights. All experimental code, raw results, and analysis scripts are available at https://github.com/lexdoudkin/llms-on-drugs.

</details>


### [29] [Neologism Learning as a Parameter-Efficient Alternative to Fine-Tuning for Model Steering](https://arxiv.org/abs/2512.18551)
*Sungjoon Park,Varun Ramamurthi,Owen Terry*

Main category: cs.CL

TL;DR: 本文比较了语言模型中新词学习与LoRA微调的性能，发现新词学习在相同训练设置下优于微调模型，并研究了模型对新词的自我表达行为。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索更高效、灵活的行为引导方法。传统微调需要大量计算且灵活性不足，而新词学习只需训练少量参数，同时保留模型的默认行为。

Method: 通过比较新词学习与LoRA微调的性能，在相同数据和超参数设置下进行匹配训练实验。同时研究模型对新词的自我表达行为，观察模型在被问及新词时是否会创造自己的新词。

Result: 新词学习在匹配训练设置下（相同数据和超参数）优于LoRA微调模型。此外，模型在被问及新词时偶尔会创造自己的新词。

Conclusion: 新词学习是一种比传统微调更高效、灵活的行为引导方法，在保持模型默认行为的同时，通过训练少量参数就能实现特定行为引导。

Abstract: In language modeling, neologisms are new tokens trained to represent a concept not already included in a given model's vocabulary. Neologisms can be used to encourage specific behavior in models, for example by appending prompts with "Give me a neologism answer." Behavioral steering can also be achieved through fine-tuning, albeit with more compute and less flexibility: learning a neologism only trains d parameters and allows the user to still access the model's default behavior. We compare the performance of neologism learning against low-rank adaptation (LoRA) fine-tuning, finding that neologisms outperform fine-tuned models under a matched training setup (same data and hyperparameters). We also investigate self-verbalizations of neologisms, and observe that the model will occasionally make up its own new words when asked about a neologism.

</details>


### [30] [From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation](https://arxiv.org/abs/2512.18593)
*Amit Barman,Atanu Mandal,Sudip Kumar Naskar*

Main category: cs.CL

TL;DR: 本文针对印度等多语言国家的法律信息获取障碍，提出使用法律机器翻译(L-MT)解决方案，通过微调预训练OPUS-MT模型和从头训练Transformer模型两种策略，在英语-印地语法律翻译任务中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在多语言国家如印度，法律和司法文件主要使用英语，导致非英语使用者难以获取法律信息，形成语言障碍。法律机器翻译(L-MT)提供了一种可扩展的解决方案，能够准确翻译法律文件，提高法律透明度和司法可及性。

Method: 采用两种互补策略：1) 对预训练的OPUS-MT模型进行领域特定微调；2) 使用提供的法律语料库从头训练Transformer模型。使用多种标准机器翻译指标进行评估，包括SacreBLEU、chrF++、TER、ROUGE、BERTScore、METEOR和COMET。

Result: 微调的OPUS-MT模型取得了SacreBLEU分数46.03，显著优于基线模型和从头训练的模型。结果表明领域适应在提高翻译质量方面的有效性。

Conclusion: 领域适应的法律机器翻译系统能够有效提高法律文件翻译质量，在多语言环境中具有改善司法可及性和法律透明度的潜力。微调预训练模型相比从头训练模型表现更优。

Abstract: In multilingual nations like India, access to legal information is often hindered by language barriers, as much of the legal and judicial documentation remains in English. Legal Machine Translation (L-MT) offers a scalable solution to this challenge by enabling accurate and accessible translations of legal documents. This paper presents our work for the JUST-NLP 2025 Legal MT shared task, focusing on English-Hindi translation using Transformer-based approaches. We experiment with 2 complementary strategies, fine-tuning a pre-trained OPUS-MT model for domain-specific adaptation and training a Transformer model from scratch using the provided legal corpus. Performance is evaluated using standard MT metrics, including SacreBLEU, chrF++, TER, ROUGE, BERTScore, METEOR, and COMET. Our fine-tuned OPUS-MT model achieves a SacreBLEU score of 46.03, significantly outperforming both baseline and from-scratch models. The results highlight the effectiveness of domain adaptation in enhancing translation quality and demonstrate the potential of L-MT systems to improve access to justice and legal transparency in multilingual contexts.

</details>


### [31] [On Finding Inconsistencies in Documents](https://arxiv.org/abs/2512.18601)
*Charles J. Lovering,Seth Ebner,Brandon Smock,Michael Krumdick,Saad Rabbani,Ahmed Muhammad,Varshini Reddy,Chris Tanner*

Main category: cs.CL

TL;DR: 论文提出了FIND基准测试，用于评估语言模型在检测文档不一致性方面的能力，发现GPT-5能检测到64%的人工插入不一致性，还能发现原始文档中作者未发现的不一致性，但仍有近一半的不一致性无法检测。


<details>
  <summary>Details</summary>
Motivation: 学术、法律和金融领域的专业人士需要审核文档，因为文档中的不一致性可能导致金钱、声誉和科学成本。语言模型有潜力大幅加速这一审核过程，但需要评估其实际能力。

Method: 引入FIND基准测试，每个示例都是由领域专家手动插入不一致性的文档。在50篇arXiv论文上测试模型，评估模型检测不一致性的能力。

Result: 最佳模型GPT-5恢复了64%的人工插入不一致性，并在原始文档中发现了作者未发现的不一致性（在arXiv论文中，模型提出的196个建议中有136个被判定为合法的不一致性）。但即使最佳模型也遗漏了FIND中近一半的不一致性。

Conclusion: 语言模型在文档不一致性检测方面显示出潜力，能够发现人类作者遗漏的问题，但该任务仍然具有挑战性，现有模型仍有很大改进空间。

Abstract: Professionals in academia, law, and finance audit their documents because inconsistencies can result in monetary, reputational, and scientific costs. Language models (LMs) have the potential to dramatically speed up this auditing process. To understand their abilities, we introduce a benchmark, FIND (Finding INconsistencies in Documents), where each example is a document with an inconsistency inserted manually by a domain expert. Despite the documents being long, technical, and complex, the best-performing model (gpt-5) recovered 64% of the inserted inconsistencies. Surprisingly, gpt-5 also found undiscovered inconsistencies present in the original documents. For example, on 50 arXiv papers, we judged 136 out of 196 of the model's suggestions to be legitimate inconsistencies missed by the original authors. However, despite these findings, even the best models miss almost half of the inconsistencies in FIND, demonstrating that inconsistency detection is still a challenging task.

</details>


### [32] [A Comparative Study of Light-weight Language Models for PII Masking and their Deployment for Real Conversational Texts](https://arxiv.org/abs/2512.18608)
*Prabigya Acharya,Liza Shrestha*

Main category: cs.CL

TL;DR: 轻量级模型（T5-small和Mistral）在PII掩码任务上能达到与前沿大模型相当的性能，标签标准化能提升效果，但存在准确性、鲁棒性和计算效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前前沿大语言模型在PII掩码方面表现良好，但存在数据处理和计算成本问题，因此探索轻量级模型是否能达到可比性能。

Method: 使用AI4Privacy基准构建英语数据集，微调T5-small和Mistral-Instruct-v0.3模型，创建不同数据集变体研究标签标准化和PII表示，涵盖24个标准化PII类别和高粒度设置。

Result: 两种轻量级模型在PII掩码任务上都达到了与前沿LLM相当的性能。标签标准化能持续提升性能。Mistral在F1和召回率上更高且对PII类型更鲁棒，但生成延迟显著更高。T5在对话文本中鲁棒性较差，但提供更可控的结构化输出和更低推理成本。

Conclusion: 轻量级模型能提供有效的PII掩码，同时解决与前沿LLM相关的数据处理问题，但需要在准确性、鲁棒性和计算效率之间权衡。T5更适合实时应用如Discord机器人，但在非正式输入下性能会下降。

Abstract: Automated masking of Personally Identifiable Information (PII) is critical for privacy-preserving conversational systems. While current frontier large language models demonstrate strong PII masking capabilities, concerns about data handling and computational costs motivate exploration of whether lightweight models can achieve comparable performance. We compare encoder-decoder and decoder-only architectures by fine-tuning T5-small and Mistral-Instruct-v0.3 on English datasets constructed from the AI4Privacy benchmark. We create different dataset variants to study label standardization and PII representation, covering 24 standardized PII categories and higher-granularity settings. Evaluation using entity-level and character-level metrics, type accuracy, and exact match shows that both lightweight models achieve performance comparable to frontier LLMs for PII masking tasks. Label normalization consistently improves performance across architectures. Mistral achieves higher F1 and recall with greater robustness across PII types but incurs significantly higher generation latency. T5, while less robust in conversational text, offers more controllable structured outputs and lower inference cost, motivating its use in a real-time Discord bot for real-world PII redaction. Evaluation on live messages reveals performance degradation under informal inputs. These results clarify trade-offs between accuracy, robustness, and computational efficiency, demonstrating that lightweight models can provide effective PII masking while addressing data handling concerns associated with frontier LLMs.

</details>


### [33] [LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction](https://arxiv.org/abs/2512.18623)
*Jensen Zhang,Ningyuan Liu,Yijia Fan,Zihao Huang,Qinglin Zeng,Kaitong Cai,Jian Wang,Keze Wang*

Main category: cs.CL

TL;DR: LLM-CAS是一个基于分层强化学习的框架，通过训练智能体在推理时动态选择临时神经元扰动来实时纠正大语言模型的幻觉问题，无需永久修改模型参数。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常生成缺乏事实或上下文依据的幻觉内容，限制了其在关键应用中的可靠性。现有的监督微调和人类反馈强化学习方法数据密集且计算成本高，而静态参数编辑方法难以处理上下文依赖错误并容易导致灾难性遗忘。

Method: LLM-CAS将实时幻觉纠正构建为分层强化学习问题，训练一个智能体学习策略，在推理时根据当前上下文动态选择临时神经元扰动。这种策略驱动机制不同于依赖启发式或预定义调整的先前动态方法，能够实现自适应和细粒度的纠正，而无需永久修改参数。

Result: 在多个语言模型上的实验表明，LLM-CAS持续提高了事实准确性：在StoryCloze上提升了10.98个百分点，在TriviaQA上提升了2.71个百分点，在TruthfulQA的MC1分数上提升了2.06个百分点。这些结果优于静态编辑方法（如ITI和CAA）和动态SADI框架。

Conclusion: LLM-CAS为提升大语言模型的可靠性提供了一个高效且上下文感知的解决方案，具有未来扩展到多模态应用的潜力。

Abstract: Large language models (LLMs) often generate hallucinated content that lacks factual or contextual grounding, limiting their reliability in critical applications. Existing approaches such as supervised fine-tuning and reinforcement learning from human feedback are data intensive and computationally expensive, while static parameter editing methods struggle with context dependent errors and catastrophic forgetting.
  We propose LLM-CAS, a framework that formulates real-time hallucination correction as a hierarchical reinforcement learning problem. LLM-CAS trains an agent to learn a policy that dynamically selects temporary neuron perturbations during inference based on the current context. Unlike prior dynamic approaches that rely on heuristic or predefined adjustments, this policy driven mechanism enables adaptive and fine grained correction without permanent parameter modification.
  Experiments across multiple language models demonstrate that LLM-CAS consistently improves factual accuracy, achieving gains of 10.98 percentage points on StoryCloze, 2.71 points on TriviaQA, and 2.06 points on the MC1 score of TruthfulQA. These results outperform both static editing methods such as ITI and CAA and the dynamic SADI framework. Overall, LLM-CAS provides an efficient and context aware solution for improving the reliability of LLMs, with promising potential for future multimodal extensions.

</details>


### [34] [Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital](https://arxiv.org/abs/2512.18658)
*Pierre Colombo,Malik Boudiaf,Allyn Sweet,Michael Desa,Hongxi Wang,Kevin Candra,Syméon del Marmol*

Main category: cs.CL

TL;DR: 本文提出将资本化核对作为法律AI的现实基准任务，分析现有代理系统性能，并提出面向自动化核对的世界模型架构


<details>
  <summary>Details</summary>
Motivation: 风险投资融资前需要律师进行资本化核对，验证所有证券和发行条款是否得到大量法律文件支持。虽然LLM在法律基准测试上持续改进，但资本化核对这类专业法律工作流程仍超出当前代理系统的能力范围

Method: 将资本化核对作为法律AI的现实基准进行特征化，分析比较现有代理系统性能，并提出世界模型架构以实现自动化核对

Result: 当前方法在多文档推理、严格证据可追溯性和确定性输出方面无法可靠完成任务，需要新的架构来解决这些挑战

Conclusion: 提出的世界模型架构不仅可用于资本化核对自动化，还可作为应用法律智能的基础，推动专业法律工作流程的AI自动化

Abstract: Before closing venture capital financing rounds, lawyers conduct diligence that includes tying out the capitalization table: verifying that every security (for example, shares, options, warrants) and issuance term (for example, vesting schedules, acceleration triggers, transfer restrictions) is supported by large sets of underlying legal documentation. While LLMs continue to improve on legal benchmarks, specialized legal workflows, such as capitalization tie-out, remain out of reach even for strong agentic systems. The task requires multi-document reasoning, strict evidence traceability, and deterministic outputs that current approaches fail to reliably deliver. We characterize capitalization tie-out as an instance of a real-world benchmark for legal AI, analyze and compare the performance of existing agentic systems, and propose a world model architecture toward tie-out automation-and more broadly as a foundation for applied legal intelligence.

</details>


### [35] [Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design](https://arxiv.org/abs/2512.18682)
*Yuchen Li,Handing Wang,Bing Xue,Mengjie Zhang,Yaochu Jin*

Main category: cs.CL

TL;DR: APF框架利用LLM自动将自然语言设计需求转换为可执行的优化模型，通过自动生成高质量数据集进行监督微调，在无高成本求解器反馈的情况下实现准确的优化问题形式化。


<details>
  <summary>Details</summary>
Motivation: 在高成本仿真驱动设计领域，将模糊的设计需求转化为数学优化公式是优化产品性能的瓶颈。这一过程耗时且严重依赖专家知识。现有LLM方法要么形式化效果差，要么依赖求解器反馈进行数据过滤，而高仿真成本使得这种反馈不可用。

Method: 提出APF框架，通过自动生成高质量数据集的创新流程，在无高成本求解器反馈的情况下，利用数据生成和测试实例标注构建合适的微调数据集。使用生成的高质量数据集对LLM进行监督微调，显著提升其生成准确且可执行的优化问题公式的能力。

Result: 在天线设计实验中，APF在需求形式化的准确性和满足设计目标的辐射效率曲线质量方面，显著优于现有方法。

Conclusion: APF框架成功解决了高成本仿真驱动设计中自动化问题形式化的挑战，通过LLM实现了从自然语言需求到可执行优化模型的准确转换，无需依赖昂贵的求解器反馈。

Abstract: In the high-cost simulation-driven design domain, translating ambiguous design requirements into a mathematical optimization formulation is a bottleneck for optimizing product performance. This process is time-consuming and heavily reliant on expert knowledge. While large language models (LLMs) offer potential for automating this task, existing approaches either suffer from poor formalization that fails to accurately align with the design intent or rely on solver feedback for data filtering, which is unavailable due to the high simulation costs. To address this challenge, we propose APF, a framework for solver-independent, automated problem formulation via LLMs designed to automatically convert engineers' natural language requirements into executable optimization models. The core of this framework is an innovative pipeline for automatically generating high-quality data, which overcomes the difficulty of constructing suitable fine-tuning datasets in the absence of high-cost solver feedback with the help of data generation and test instance annotation. The generated high-quality dataset is used to perform supervised fine-tuning on LLMs, significantly enhancing their ability to generate accurate and executable optimization problem formulations. Experimental results on antenna design demonstrate that APF significantly outperforms the existing methods in both the accuracy of requirement formalization and the quality of resulting radiation efficiency curves in meeting the design goals.

</details>


### [36] [MemEvolve: Meta-Evolution of Agent Memory Systems](https://arxiv.org/abs/2512.18746)
*Guibin Zhang,Haotian Ren,Chong Zhan,Zhenhong Zhou,Junhao Wang,He Zhu,Wangchunshu Zhou,Shuicheng Yan*

Main category: cs.CL

TL;DR: MemEvolve：一个元进化框架，联合进化代理的经验知识和记忆架构，使代理系统不仅能积累经验，还能逐步改进学习方式。EvolveLab作为统一的自进化记忆代码库，将12个代表性记忆系统提炼为模块化设计空间。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代理系统主要依赖手动设计的静态记忆架构来存储轨迹、提炼经验和合成可重用工具，这种范式受限于记忆系统本身的静态性：记忆架构无法根据不同的任务上下文进行元适应。

Method: 提出MemEvolve框架，联合进化代理的经验知识和记忆架构；引入EvolveLab代码库，将12个代表性记忆系统提炼为模块化设计空间（编码、存储、检索、管理），提供标准化实现基底和公平实验平台。

Result: 在四个具有挑战性的代理基准测试中，MemEvolve实现了：(1) 显著的性能提升，将SmolAgent和Flash-Searcher等框架提升高达17.06%；(2) 强大的跨任务和跨LLM泛化能力，设计的记忆架构能有效迁移到不同基准测试和骨干模型。

Conclusion: MemEvolve通过元进化方法解决了现有自进化记忆系统的静态性限制，实现了记忆架构与经验知识的联合进化，为未来自进化系统提供了开放的研究基础和标准化实现框架。

Abstract: Self-evolving memory systems are unprecedentedly reshaping the evolutionary paradigm of large language model (LLM)-based agents. Prior work has predominantly relied on manually engineered memory architectures to store trajectories, distill experience, and synthesize reusable tools, enabling agents to evolve on the fly within environment interactions. However, this paradigm is fundamentally constrained by the staticity of the memory system itself: while memory facilitates agent-level evolving, the underlying memory architecture cannot be meta-adapted to diverse task contexts. To address this gap, we propose MemEvolve, a meta-evolutionary framework that jointly evolves agents' experiential knowledge and their memory architecture, allowing agent systems not only to accumulate experience but also to progressively refine how they learn from it. To ground MemEvolve in prior research and foster openness in future self-evolving systems, we introduce EvolveLab, a unified self-evolving memory codebase that distills twelve representative memory systems into a modular design space (encode, store, retrieve, manage), providing both a standardized implementation substrate and a fair experimental arena. Extensive evaluations on four challenging agentic benchmarks demonstrate that MemEvolve achieves (I) substantial performance gains, improving frameworks such as SmolAgent and Flash-Searcher by up to $17.06\%$; and (II) strong cross-task and cross-LLM generalization, designing memory architectures that transfer effectively across diverse benchmarks and backbone models.

</details>


### [37] [From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure](https://arxiv.org/abs/2512.18779)
*Thorsten Hellert,Nikolay Agladze,Alex Giovannone,Jan Jug,Frank Mayet,Mark Sherwin,Antonin Sulc,Chris Tennant*

Main category: cs.CL

TL;DR: 论文提出语义通道查找框架，将自然语言意图映射到复杂实验基础设施中的控制信号，包含四种范式，在四个实际设施中实现90-97%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现代实验平台（粒子加速器、聚变装置等）有数万到数十万控制通道，操作员和AI系统依赖非正式专家知识、不一致命名规范和碎片化文档来定位信号，这成为可靠性、可扩展性和语言模型驱动接口的瓶颈。

Method: 提出四范式框架：1) 基于策划通道词典的直接上下文查找；2) 结构化树的约束层次导航；3) 使用迭代推理和工具查询的交互式代理探索；4) 基于本体的语义搜索，将通道含义与设施特定命名规范解耦。在四个实际设施中实现概念验证。

Result: 在四个运行设施（从紧凑型自由电子激光器到大型同步辐射光源）中实现，覆盖两个数量级的规模，在专家策划的操作查询上达到90-97%的准确率。

Conclusion: 语义通道查找是复杂实验基础设施中的关键问题，提出的四范式框架为不同数据体制提供了架构选择指导，能够有效解决信号定位瓶颈，支持可靠、可扩展的操作和AI接口。

Abstract: Modern experimental platforms such as particle accelerators, fusion devices, telescopes, and industrial process control systems expose tens to hundreds of thousands of control and diagnostic channels accumulated over decades of evolution. Operators and AI systems rely on informal expert knowledge, inconsistent naming conventions, and fragmented documentation to locate signals for monitoring, troubleshooting, and automated control, creating a persistent bottleneck for reliability, scalability, and language-model-driven interfaces. We formalize semantic channel finding-mapping natural-language intent to concrete control-system signals-as a general problem in complex experimental infrastructure, and introduce a four-paradigm framework to guide architecture selection across facility-specific data regimes. The paradigms span (i) direct in-context lookup over curated channel dictionaries, (ii) constrained hierarchical navigation through structured trees, (iii) interactive agent exploration using iterative reasoning and tool-based database queries, and (iv) ontology-grounded semantic search that decouples channel meaning from facility-specific naming conventions. We demonstrate each paradigm through proof-of-concept implementations at four operational facilities spanning two orders of magnitude in scale-from compact free-electron lasers to large synchrotron light sources-and diverse control-system architectures, from clean hierarchies to legacy environments. These implementations achieve 90-97% accuracy on expert-curated operational queries.

</details>


### [38] [From Word to World: Can Large Language Models be Implicit Text-based World Models?](https://arxiv.org/abs/2512.18832)
*Yixia Li,Hongru Wang,Jiahao Qiu,Zhenfei Yin,Dongdong Zhang,Cheng Qian,Zeping Li,Pony Ma,Guanhua Chen,Heng Ji,Mengdi Wang*

Main category: cs.CL

TL;DR: 该论文研究了在文本环境中使用大型语言模型作为世界模型来提升智能体强化学习效率的有效性和条件。


<details>
  <summary>Details</summary>
Motivation: 尽管基于经验的强化学习规模不断扩大，但现实环境仍然是非自适应的、覆盖有限且难以扩展的。世界模型通过模拟经验可能提高学习效率，但尚不清楚LLM能否可靠地扮演这一角色以及在何种条件下能真正有益于智能体。

Method: 在文本环境中将语言建模重新解释为交互下的下一状态预测，引入三级评估框架：保真度和一致性、可扩展性和鲁棒性、智能体效用。在五个代表性环境中进行实验。

Result: 发现充分训练的世界模型能保持一致的潜在状态，随数据和模型规模可预测地扩展，并通过动作验证、合成轨迹生成和强化学习预热提升智能体性能。

Conclusion: 这些收益关键取决于行为覆盖和环境复杂性，明确了世界模型有效支持智能体学习的边界条件。

Abstract: Agentic reinforcement learning increasingly relies on experience-driven scaling, yet real-world environments remain non-adaptive, limited in coverage, and difficult to scale. World models offer a potential way to improve learning efficiency through simulated experience, but it remains unclear whether large language models can reliably serve this role and under what conditions they meaningfully benefit agents. We study these questions in text-based environments, which provide a controlled setting to reinterpret language modeling as next-state prediction under interaction. We introduce a three-level framework for evaluating LLM-based world models: (i) fidelity and consistency, (ii) scalability and robustness, and (iii) agent utility. Across five representative environments, we find that sufficiently trained world models maintain coherent latent state, scale predictably with data and model size, and improve agent performance via action verification, synthetic trajectory generation, and warm-starting reinforcement learning. Meanwhile, these gains depend critically on behavioral coverage and environment complexity, delineating clear boundry on when world modeling effectively supports agent learning.

</details>


### [39] [AraMix: Recycling, Refiltering, and Deduplicating to Deliver the Largest Arabic Pretraining Corpus](https://arxiv.org/abs/2512.18834)
*Sultan Alrashed,Francesco Orabona*

Main category: cs.CL

TL;DR: AraMix是一个去重后的阿拉伯语预训练语料库，包含约1780亿token和1.79亿文档，通过整合和优化现有公开数据集构建而成


<details>
  <summary>Details</summary>
Motivation: 针对阿拉伯语等低资源语言，与其重新爬取网络数据，不如系统性地重用和优化现有预训练数据集，因为现有数据集中存在大量冗余

Method: 整合7个公开阿拉伯语网络数据集，应用针对阿拉伯语设计的质量过滤，并进行跨数据集去重（包括MinHash和句子级去重）

Result: 发现这些独立收集的语料库中近60%的token是重复的，最终构建了最大的经过严格过滤的公开阿拉伯语预训练语料库

Conclusion: 对于低资源语言，投资于现有数据的优化流程比额外进行网络爬取更有价值，这种方法能有效利用现有资源并避免冗余

Abstract: We present AraMix, a deduplicated Arabic pretraining corpus containing approximately 178 billion tokens across 179 million documents. Rather than scraping the web again, AraMix demonstrates that substantial value lies in systematically reusing and curating existing pretraining datasets: we combine seven publicly available Arabic web datasets, apply quality filtering designed specifically for Arabic text to re-filter some datasets, and perform cross-dataset deduplication, both MinHash and sentence-level. This approach reveals that nearly 60% of tokens across these independently collected corpora are duplicates, redundancy that any new scraping efforts will reproduce. Our work suggests that for lower resource languages, investment in curation pipelines for existing data yields greater returns than additional web crawls, an approach that allowed us to curate the largest heavily filtered publicly available Arabic pretraining corpus.

</details>


### [40] [MDToC: Metacognitive Dynamic Tree of Concepts for Boosting Mathematical Problem-Solving of Large Language Models](https://arxiv.org/abs/2512.18841)
*Tung Duong Ta,Tim Oates*

Main category: cs.CL

TL;DR: MDToC（元认知动态概念树）通过构建概念树、验证计算和多数投票，显著提升大语言模型在数学推理任务中的计算验证能力，在多个基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学推理方面有所进步，但在使用现有提示技术时仍然难以有效验证计算准确性，需要更可靠的验证机制。

Method: MDToC采用三阶段方法：1) 构建概念树；2) 为每个概念开发经过准确性验证的计算；3) 使用多数投票机制评估竞争解决方案。

Result: 在CHAMP、MATH和Game-of-24基准测试中，GPT-4-Turbo分别达到58.1%、86.6%和85%的准确率，比GoT分别提升5%、5.4%和4%，在所有骨干模型上都优于现有提示方法。

Conclusion: 元认知计算验证是增强数学推理能力的有前景方向，MDToC方法无需人工设计提示即可显著提升大语言模型的计算验证性能。

Abstract: Despite advances in mathematical reasoning capabilities, Large Language Models (LLMs) still struggle with calculation verification when using established prompting techniques. We present MDToC (Metacognitive Dynamic Tree of Concepts), a three-phase approach that constructs a concept tree, develops accuracy-verified calculations for each concept, and employs majority voting to evaluate competing solutions. Evaluations across CHAMP, MATH, and Game-of-24 benchmarks demonstrate our MDToC's effectiveness, with GPT-4-Turbo achieving 58.1\% on CHAMP, 86.6\% on MATH, and 85\% on Game-of-24 - outperforming GoT by 5\%, 5.4\%, and 4\% on all these tasks, respectively, without hand-engineered hints. MDToC consistently surpasses existing prompting methods across all backbone models, yielding improvements of up to 7.6\% over ToT and 6.2\% over GoT, establishing metacognitive calculation verification as a promising direction for enhanced mathematical reasoning.

</details>


### [41] [Toward Human-Centered AI-Assisted Terminology Work](https://arxiv.org/abs/2512.18859)
*Antonio San Martin*

Main category: cs.CL

TL;DR: 本文提出以人为中心的人工智能框架，将AI视为增强术语学家能力的工具而非替代品，强调在保持高自动化的同时确保人类控制，以维护术语工作的专业自主性、准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的快速扩散正在改变术语工作。虽然这项技术有望提高效率，但其无结构化的采用可能会削弱专业自主性、放大偏见并侵蚀语言和概念的多样性。因此，需要建立以人为中心的人工智能方法来保护术语工作的质量。

Method: 基于人工智能和翻译研究，提出了一个以人为中心的框架，围绕三个相互关联的维度组织：增强型术语学家、伦理人工智能和以人为中心的设计。该框架将AI概念化为增强术语学家能力的手段，而非替代品。

Result: 该框架强调高自动化与强人类控制的兼容性，术语学家在偏见缓解中的核心作用，以及围绕术语学家的需求、价值观和福祉设计AI工具和工作流程的重要性。

Conclusion: 当前人工智能采用的选择不仅将塑造术语实践，还将影响术语和专业知识中准确性、适当性和多样性的保护。以人为中心的方法对于维护术语工作的质量至关重要。

Abstract: The rapid diffusion of generative artificial intelligence is transforming terminology work. While this technology promises gains in efficiency, its unstructured adoption risks weakening professional autonomy, amplifying bias, and eroding linguistic and conceptual diversity. This paper argues that a human-centered approach to artificial intelligence has become a necessity for terminology work. Building on research in artificial intelligence and translation studies, it proposes a human-centered framework that conceptualizes artificial intelligence as a means of amplifying the terminologist's capabilities, rather than replacing them. The framework is organized around three interrelated dimensions: the augmented terminologist, ethical AI, and human-centered design. Together, these dimensions emphasize the compatibility of high automation with strong human control, the central role of terminologists in bias mitigation, and the importance of designing AI tools and workflows around the needs, values, and well-being of the terminologist. The paper concludes by stressing that current choices in AI adoption will shape not only terminological practice, but also the preservation of accuracy, adequacy, and diversity in terminology and specialized knowledge.

</details>


### [42] [Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction](https://arxiv.org/abs/2512.18880)
*Ming Li,Han Chen,Yunze Xiao,Jian Chen,Hong Jiao,Tianyi Zhou*

Main category: cs.CL

TL;DR: LLMs在评估题目难度时与人类认知存在系统性偏差，模型性能提升反而阻碍准确预测，无法模拟学生能力限制


<details>
  <summary>Details</summary>
Motivation: 题目难度评估对教育评估至关重要，但存在冷启动问题。虽然LLMs展现出超强解题能力，但能否感知人类学习者的认知困难仍是未解问题

Method: 对20多个模型在医学知识和数学推理等多样化领域进行大规模实证分析，研究人类-AI难度对齐问题

Result: 发现系统性偏差：模型规模扩大无助于对齐，反而趋向机器共识；高性能反而阻碍准确难度估计；模型无法模拟学生能力限制；缺乏内省能力，无法预测自身局限

Conclusion: 通用解题能力不意味着理解人类认知困难，当前模型用于自动难度预测面临挑战

Abstract: Accurate estimation of item (question or task) difficulty is critical for educational assessment but suffers from the cold start problem. While Large Language Models demonstrate superhuman problem-solving capabilities, it remains an open question whether they can perceive the cognitive struggles of human learners. In this work, we present a large-scale empirical analysis of Human-AI Difficulty Alignment for over 20 models across diverse domains such as medical knowledge and mathematical reasoning. Our findings reveal a systematic misalignment where scaling up model size is not reliably helpful; instead of aligning with humans, models converge toward a shared machine consensus. We observe that high performance often impedes accurate difficulty estimation, as models struggle to simulate the capability limitations of students even when being explicitly prompted to adopt specific proficiency levels. Furthermore, we identify a critical lack of introspection, as models fail to predict their own limitations. These results suggest that general problem-solving capability does not imply an understanding of human cognitive struggles, highlighting the challenge of using current models for automated difficulty prediction.

</details>


### [43] [Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations](https://arxiv.org/abs/2512.18906)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Qiyu Wu,Toshiyuki Sekiya,Christof Monz*

Main category: cs.CL

TL;DR: Remedy-R是一个基于推理的生成式机器翻译评估指标，通过强化学习从翻译偏好中训练，无需错误标注或大模型蒸馏，能生成逐步分析并提供最终评分，具有更好的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自动MT指标虽然在某些基准测试中表现良好，但仍是黑盒系统，缺乏决策透明度，且在真实世界分布外输入下容易失效。需要更可解释、鲁棒的评估方法。

Method: 使用强化学习从成对翻译偏好中训练生成式MT评估指标，无需错误标注或大模型蒸馏。模型逐步分析准确性、流畅性和完整性，然后给出最终评分。仅需6万训练对即可跨语言泛化。

Result: 在WMT22-24元评估中与顶级标量指标和GPT-4评估者竞争，能泛化到其他语言，在OOD压力测试中表现鲁棒。基于其分析构建的Remedy-R Agent能持续改进多种模型的翻译质量。

Conclusion: Remedy-R通过推理驱动的评估提供了可解释的MT评估，其分析包含翻译相关信息，可实际用于翻译改进，为黑盒MT指标提供了透明、鲁棒的替代方案。

Abstract: Over the years, automatic MT metrics have hillclimbed benchmarks and presented strong and sometimes human-level agreement with human ratings. Yet they remain black-box, offering little insight into their decision-making and often failing under real-world out-of-distribution (OOD) inputs. We introduce Remedy-R, a reasoning-driven generative MT metric trained with reinforcement learning from pairwise translation preferences, without requiring error-span annotations or distillation from closed LLMs. Remedy-R produces step-by-step analyses of accuracy, fluency, and completeness, followed by a final score, enabling more interpretable assessments. With only 60K training pairs across two language pairs, Remedy-R remains competitive with top scalar metrics and GPT-4-based judges on WMT22-24 meta-evaluation, generalizes to other languages, and exhibits strong robustness on OOD stress tests. Moreover, Remedy-R models generate self-reflective feedback that can be reused for translation improvement. Building on this finding, we introduce Remedy-R Agent, a simple evaluate-revise pipeline that leverages Remedy-R's evaluation analysis to refine translations. This agent consistently improves translation quality across diverse models, including Qwen2.5, ALMA-R, GPT-4o-mini, and Gemini-2.0-Flash, suggesting that Remedy-R's reasoning captures translation-relevant information and is practically useful.

</details>


### [44] [FASTRIC: Prompt Specification Language for Verifiable LLM Interactions](https://arxiv.org/abs/2512.18940)
*Wen-Long Jin*

Main category: cs.CL

TL;DR: FASTRIC是一种提示规范语言，通过将隐式有限状态机显式化到自然语言提示中，实现LLM多轮交互协议的可验证执行。


<details>
  <summary>Details</summary>
Motivation: LLM执行复杂的多轮交互协议，但缺乏形式化规范来验证执行是否符合设计者意图，当前设计依赖启发式方法而非系统化工程。

Method: 提出FASTRIC语言，指导设计者明确表达FSM七要素（最终状态、代理、状态、触发器、角色、初始状态、约束），利用LLM作为统一基础设施（解析器、解释器、运行时环境、开发助手），通过执行轨迹分析进行一致性验证。

Result: 测试3状态幼儿园辅导FSM，发现最优规范形式化程度是模型容量的函数：DeepSeek-V3.2在L2-L4达到完美一致性，ChatGPT-5在L3达到峰值，Phi4无稳定最优且方差高，揭示了模型特定的"Goldilocks区间"。

Conclusion: FASTRIC建立了提示规范工程，将多轮交互设计从启发式艺术转变为具有可测量程序保证的系统工程，为创建可验证交互协议提供了框架。

Abstract: Large Language Models (LLMs) execute complex multi-turn interaction protocols but lack formal specifications to verify execution against designer intent. We introduce FASTRIC, a Prompt Specification Language that makes implicit Finite State Machines (FSMs) explicit in natural language prompts, enabling conformance verification through execution trace analysis. The LLM serves as intelligent execution agent: interpreting designer-encoded FSMs to execute specified behavioral roles. Unlike symbolic specification languages requiring parsers and compilers, FASTRIC leverages LLMs as unified infrastructure-simultaneously parser, interpreter, runtime environment, and development assistant. FASTRIC guides designers to articulate seven FSM elements (Final States, Agents, States, Triggers, Roles, Initial State, Constraints) structuring multi-turn interactions. Specification formality-ranging from implicit descriptions that frontier models infer to explicit step-by-step instructions for weaker models-serves as a design parameter. We introduce procedural conformance as verification metric measuring execution adherence to FSM specifications. Testing a 3-state kindergarten tutoring FSM across four formality levels and three model scales (14.7B, 685B, 1T+ parameters) reveals optimal specification formality is a function of model capacity. DeepSeek-V3.2 (685B) achieves perfect conformance (1.00) at L2-L4; ChatGPT-5 (~1T) peaks at L3 (0.90) before collapsing at L4 (0.39); Phi4 (14.7B) shows no stable optimum with high variance (SD=0.16-0.36). These findings reveal model-specific formality ranges-"Goldilocks zones"-where specifications provide sufficient structure without over-constraint, establishing Prompt Specification Engineering for creating verifiable interaction protocols, transforming multi-turn interaction design from heuristic art to systematic engineering with measurable procedural guarantees.

</details>


### [45] [Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework](https://arxiv.org/abs/2512.18999)
*Jinyan Liu,Zikang Chen,Qinchuan Wang,Tan Xie,Heming Zheng,Xudong Lv*

Main category: cs.CL

TL;DR: 对比两种医疗随访聊天机器人系统：端到端LLM系统vs模块化流程控制系统，后者显著提升对话稳定性和信息提取准确性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型直接应用于医疗随访任务时，由于随访表格的复杂性，经常出现对话流程失控和信息提取不准确的问题

Method: 设计并比较两种随访聊天机器人系统：1) 端到端LLM系统（对照组）；2) 基于任务分解、语义聚类和流程管理的模块化管道系统（实验组）

Result: 模块化方法显著改善对话稳定性和提取准确性，减少对话轮数46.73%，降低token消耗80%-87.5%

Conclusion: 在高风险医疗随访场景中部署LLM时，必须集成外部控制机制以确保系统可靠性和效率

Abstract: When applied directly in an end-to-end manner to medical follow-up tasks, Large Language Models (LLMs) often suffer from uncontrolled dialog flow and inaccurate information extraction due to the complexity of follow-up forms. To address this limitation, we designed and compared two follow-up chatbot systems: an end-to-end LLM-based system (control group) and a modular pipeline with structured process control (experimental group). Experimental results show that while the end-to-end approach frequently fails on lengthy and complex forms, our modular method-built on task decomposition, semantic clustering, and flow management-substantially improves dialog stability and extraction accuracy. Moreover, it reduces the number of dialogue turns by 46.73% and lowers token consumption by 80% to 87.5%. These findings highlight the necessity of integrating external control mechanisms when deploying LLMs in high-stakes medical follow-up scenarios.

</details>


### [46] [Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models](https://arxiv.org/abs/2512.19004)
*Tongyuan Miao,Gary Huang,Kai Jun Han,Annie Jiang*

Main category: cs.CL

TL;DR: DLLMs解码慢，本文提出训练免费的方法：通过上下文感知初始化缩短生成轨迹，用轻量辅助模型注入提示条件先验，减少约35%去噪迭代，但面临准确率下降挑战。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（DLLMs）虽然支持完全并行令牌解码，但由于需要多次去噪迭代将信息全无的完全掩码初始化转化为连贯文本，推理时仍不实用。现有加速方法主要关注通过改进求解器或采样策略更高效地遍历生成轨迹，本文提出补充视角：通过上下文感知初始化从更接近目标分布的位置开始，缩短轨迹本身。

Method: 提出训练免费的接口，通过轻量级辅助模型将提示条件先验注入扩散初始化。具体实现两种机制：离散令牌注入和表示级嵌入插值。由于注入的先验可能不完美且仅解掩码解码可能过早承诺，还引入了简单的基于置信度的重新掩码机制作为先验怀疑形式。

Result: 在GSM8K上的初步证据表明，上下文感知初始化可以显著减少去噪迭代（在我们的设置中减少约35%的函数评估），但也暴露了一个关键开放挑战：简单的预热启动可能相对于强扩散基线降低最终准确率。

Conclusion: 这些发现促使围绕校准、修正机制和表示对齐的研究议程，以实现可靠的预热启动扩散解码。需要解决准确率下降问题，确保加速不牺牲性能。

Abstract: Diffusion Large Language Models (DLLMs) enable fully parallel token decoding but often remain impractical at inference time due to the many denoising iterations required to refine an information-free, fully masked initialization into coherent text. Most existing acceleration methods focus on traversing this generative trajectory more efficiently via improved solvers or sampling strategies. We advance a complementary perspective: shorten the trajectory itself by starting closer to the target distribution through context-aware initialization.
  We propose a training-free interface that injects prompt-conditioned priors from a lightweight auxiliary model into the diffusion initialization, and instantiate it with two mechanisms: discrete token injection and representation-level embedding interpolation. Because injected priors can be imperfect and unmask-only decoding can over-commit early, we also introduce a simple confidence-based remasking mechanism as a form of prior skepticism. Preliminary evidence on GSM8K suggests that context-aware initialization can substantially reduce denoising iterations (about 35\% fewer function evaluations in our setting), while also exposing a key open challenge: naive warm-starting can degrade final accuracy relative to strong diffusion baselines. We use these findings to motivate a research agenda around calibration, revision mechanisms, and representation alignment for reliable warm-started diffusion decoding.

</details>


### [47] [DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation](https://arxiv.org/abs/2512.19012)
*Shijian Ma,Yunqi Huang,Yan Lin*

Main category: cs.CL

TL;DR: DramaBench是首个大规模戏剧剧本续写评估基准，从六个独立维度全面评估模型在保持角色一致性、推进情节连贯性和保留戏剧结构方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法全面评估戏剧剧本续写所需的关键能力，包括角色一致性维护、情节连贯推进和戏剧结构保留。需要建立一个能够客观、可重复评估这些能力的基准。

Method: 结合基于规则的分析、LLM标注和统计指标，创建包含六个独立维度（格式标准、叙事效率、角色一致性、情感深度、逻辑一致性和冲突处理）的评估框架。在1,103个剧本上进行8,824次评估，并进行统计显著性测试和人工验证。

Result: 对8个最先进语言模型进行全面评估，统计显著性测试显示65.9%的成对比较具有显著性。人工验证在5个维度中的3个维度上达到实质性一致。消融研究确认六个维度捕捉了独立的质素方面（平均|r|=0.020）。

Conclusion: DramaBench为模型改进提供了可操作的维度特定反馈，并为创意写作评估建立了严谨标准，填补了戏剧剧本续写评估的空白。

Abstract: Drama script continuation requires models to maintain character consistency, advance plot coherently, and preserve dramatic structurecapabilities that existing benchmarks fail to evaluate comprehensively. We present DramaBench, the first large-scale benchmark for evaluating drama script continuation across six independent dimensions: Format Standards, Narrative Efficiency, Character Consistency, Emotional Depth, Logic Consistency, and Conflict Handling. Our framework combines rulebased analysis with LLM-based labeling and statistical metrics, ensuring objective and reproducible evaluation. We conduct comprehensive evaluation of 8 state-of-the-art language models on 1,103 scripts (8,824 evaluations total), with rigorous statistical significance testing (252 pairwise comparisons, 65.9% significant) and human validation (188 scripts, substantial agreement on 3/5 dimensions). Our ablation studies confirm all six dimensions capture independent quality aspects (mean | r | = 0.020). DramaBench provides actionable, dimensionspecific feedback for model improvement and establishes a rigorous standard for creative writing evaluation.

</details>


### [48] [A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs](https://arxiv.org/abs/2512.19092)
*Ziyan Zhang,Chao Wang,Zhuo Chen,Lei Chen,Chiyi Li,Kai Song*

Main category: cs.CL

TL;DR: ROG框架结合知识图谱检索与大语言模型推理，通过分解复杂逻辑查询、检索相关子图，使用LLM进行逐步推理，在复杂KG推理任务上超越传统嵌入方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌入的知识图谱推理方法在处理复杂逻辑查询（涉及多个操作符、深度推理链或异构KG模式）时效果有限，需要更强大的推理框架。

Method: 提出ROG框架：1) 将复杂一阶逻辑查询分解为简单子查询序列；2) 检索紧凑的查询相关子图作为上下文证据；3) 使用大语言模型进行逐步链式推理，无需任务特定的嵌入优化。

Result: 在标准KG推理基准测试中，ROG在平均倒数排名(MRR)上持续优于强嵌入基线，在高度复杂查询类型上表现尤为突出。

Conclusion: 将结构化KG检索与LLM驱动的逻辑推理相结合，为复杂KG推理任务提供了强大有效的替代方案。

Abstract: Reasoning over knowledge graphs (KGs) with first-order logic (FOL) queries is challenging due to the inherent incompleteness of real-world KGs and the compositional complexity of logical query structures. Most existing methods rely on embedding entities and relations into continuous geometric spaces and answer queries via differentiable set operations. While effective for simple query patterns, these approaches often struggle to generalize to complex queries involving multiple operators, deeper reasoning chains, or heterogeneous KG schemas. We propose ROG (Reasoning Over knowledge Graphs with large language models), an ensemble-style framework that combines query-aware KG neighborhood retrieval with large language model (LLM)-based chain-of-thought reasoning. ROG decomposes complex FOL queries into sequences of simpler sub-queries, retrieves compact, query-relevant subgraphs as contextual evidence, and performs step-by-step logical inference using an LLM, avoiding the need for task-specific embedding optimization. Experiments on standard KG reasoning benchmarks demonstrate that ROG consistently outperforms strong embedding-based baselines in terms of mean reciprocal rank (MRR), with particularly notable gains on high-complexity query types. These results suggest that integrating structured KG retrieval with LLM-driven logical reasoning offers a robust and effective alternative for complex KG reasoning tasks.

</details>


### [49] [Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?](https://arxiv.org/abs/2512.19117)
*Amar Lakel*

Main category: cs.CL

TL;DR: 论文提出从"大语言模型"转向"大话语模型"再到"人工话语代理"的认识论转变，建立基于现象规律、具身认知和语言沉淀的三元本体框架，旨在通过公共试验和治理机制取代对AI的迷恋/恐惧二分法。


<details>
  <summary>Details</summary>
Motivation: 当前对大型生成模型的分析存在局限，需要超越单纯的语言模型范畴，建立更全面的理论框架来理解这些系统如何建模人类经验，并解决社会对AI的迷恋与恐惧的二元对立。

Method: 提出认识论转变：从LLM到LDM再到ADA；建立三元本体框架：1) 现象世界规律把握，2) 具身认知结构化，3) 社会历史语境中的语言沉淀；将LDM视为对这些实例产物（文档）的建模。

Result: 构建了人工话语代理的理论框架，将AI系统理解为对人类经验话语投射的建模，为理解AI在社会中的位置、用途和限制提供了概念基础。

Conclusion: 需要通过公共试验程序和多方共治机制（国家、产业、公民社会、学术界）来明确人工话语代理在当代社会空间中的位置，取代简单的迷恋/恐惧二分法，实现负责任的AI治理。

Abstract: This paper proposes an epistemological shift in the analysis of large generative models, replacing the category ''Large Language Models'' (LLM) with that of ''Large Discourse Models'' (LDM), and then with that of Artificial Discursive Agent (ADA). The theoretical framework is based on an ontological triad distinguishing three regulatory instances: the apprehension of the phenomenal regularities of the referential world, the structuring of embodied cognition, and the structural-linguistic sedimentation of the utterance within a socio-historical context. LDMs, operating on the product of these three instances (the document), model the discursive projection of a portion of human experience reified by the learning corpus. The proposed program aims to replace the ''fascination/fear'' dichotomy with public trials and procedures that make the place, uses, and limits of artificial discursive agents in contemporary social space decipherable, situating this approach within a perspective of governance and co-regulation involving the State, industry, civil society, and academia.

</details>


### [50] [SAP: Syntactic Attention Pruning for Transformer-based Language Models](https://arxiv.org/abs/2512.19125)
*Tzu-Yun Lee,Ding-Yong Hong,Jan-Jan Wu*

Main category: cs.CL

TL;DR: SAP是一种新颖的注意力头剪枝方法，结合句法结构和注意力模式来指导剪枝，在免重训练设置下优于现有方法，同时增强模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer剪枝方法主要依赖模型权重和激活的数学分析，缺乏对语言结构的考虑。SAP旨在通过结合句法信息来更有效地剪枝注意力头，同时保持模型性能并提高可解释性。

Method: 提出Syntactic Attention Pruning (SAP)方法，利用句法结构和注意力模式来指导剪枝过程。还引入Candidate Filtering (CF)机制，基于注意力头对模型性能的贡献进行优先级排序，减少剪枝过程中的性能下降。

Result: SAP在免重训练设置下优于现有的注意力头剪枝策略，能够有效保留具有高密度强注意力值的关键头，同时保持与最先进方法相当的性能。

Conclusion: SAP为模型压缩研究提供了新的方向，为所有基于Transformer的语言模型提供了高灵活性的剪枝方法，同时增强了模型行为的可解释性。

Abstract: This paper introduces Syntactic Attention Pruning (SAP), a novel method for effectively pruning attention heads in Transformer models. Unlike conventional approaches that rely solely on mathematical analysis of model weights and activations, SAP incorporates both the syntactic structure and attention patterns of sentences to guide the pruning process. By leveraging these linguistic features, SAP not only achieves performance comparable to state-of-the-art methods but also enhances the interpretability of model behavior. To further improve robustness, we propose Candidate Filtering (CF), a mechanism that prioritizes heads based on their contribution to model performance, mitigating degradation during pruning. Experimental results indicate that SAP effectively preserves critical heads of a high density of strong attention values, outperforming existing head pruning strategies in retrain-free settings. These findings position SAP as a promising foundation for a new direction in model compression research, offering high flexibility for pruning across all transformer-based language models.

</details>


### [51] [AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards](https://arxiv.org/abs/2512.19126)
*Zihan Lin,Xiaohan Wang,Hexiong Yang,Jiajun Chai,Jie Cao,Guojun Yin,Wei Lin,Ran He*

Main category: cs.CL

TL;DR: AWPO是一个强化学习框架，通过自适应整合显式推理奖励来增强LLM的工具使用能力，在多项基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要关注可验证结果奖励，忽视了显式推理奖励对提升推理和工具使用能力的潜力。同时，简单结合推理和结果奖励可能导致次优性能或与主要优化目标冲突。

Method: 提出优势加权策略优化(AWPO)框架，包含方差感知门控和难度感知加权机制，基于组相对统计自适应调节推理信号的优势，并采用定制裁剪机制实现稳定优化。

Result: AWPO在标准工具使用基准测试中达到最先进性能，显著优于强基线模型和领先闭源模型。4B参数模型在多轮准确率上超越Grok-4达16.0%，同时在MMLU-Pro分布外基准上保持泛化能力。

Conclusion: AWPO通过有效整合显式推理奖励，显著提升了LLM的工具使用能力，在参数效率、多轮场景性能和泛化能力方面都表现出色。

Abstract: While reinforcement learning (RL) shows promise in training tool-use large language models (LLMs) using verifiable outcome rewards, existing methods largely overlook the potential of explicit reasoning rewards to bolster reasoning and tool utilization. Furthermore, natively combining reasoning and outcome rewards may yield suboptimal performance or conflict with the primary optimization objective. To address this, we propose advantage-weighted policy optimization (AWPO) -- a principled RL framework that effectively integrates explicit reasoning rewards to enhance tool-use capability. AWPO incorporates variance-aware gating and difficulty-aware weighting to adaptively modulate advantages from reasoning signals based on group-relative statistics, alongside a tailored clipping mechanism for stable optimization. Extensive experiments demonstrate that AWPO achieves state-of-the-art performance across standard tool-use benchmarks, significantly outperforming strong baselines and leading closed-source models in challenging multi-turn scenarios. Notably, with exceptional parameter efficiency, our 4B model surpasses Grok-4 by 16.0 percent in multi-turn accuracy while preserving generalization capability on the out-of-distribution MMLU-Pro benchmark.

</details>


### [52] [QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation](https://arxiv.org/abs/2512.19134)
*Dehai Min,Kailin Zhang,Tongtong Wu,Lu Cheng*

Main category: cs.CL

TL;DR: QuCo-RAG提出基于预训练数据统计的客观不确定性量化方法，替代传统依赖模型内部信号的主观置信度，通过低频实体识别和实体共现验证来动态触发检索，显著减少大语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有动态检索增强生成方法依赖模型内部信号（如logits、熵），但这些信号不可靠，因为大语言模型通常校准不佳，经常对错误输出表现出高置信度。需要一种更客观、基于数据统计的不确定性量化方法。

Method: 提出QuCo-RAG方法：1）生成前识别低频实体，指示长尾知识缺口；2）生成时验证实体在预训练语料中的共现情况，零共现通常表示幻觉风险。两个阶段都利用Infini-gram在4万亿token语料上进行毫秒级延迟查询，在高不确定性时触发检索。

Result: 在多跳QA基准测试中，QuCo-RAG在OLMo-2模型上比最先进基线提升5-12个EM点，在未公开预训练数据的模型（Llama、Qwen、GPT）上也能有效迁移，提升最多14个EM点。在生物医学QA领域的泛化进一步验证了该范式的鲁棒性。

Conclusion: 基于语料库的验证为动态RAG提供了一个原则性、实际模型无关的范式，通过客观统计替代主观置信度，显著减少大语言模型的幻觉问题。

Abstract: Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate hallucinations in large language models (LLMs). However, existing methods rely on model-internal signals (e.g., logits, entropy), which are fundamentally unreliable because LLMs are typically ill-calibrated and often exhibit high confidence in erroneous outputs. We propose QuCo-RAG, which shifts from subjective confidence to objective statistics computed from pre-training data. Our method quantifies uncertainty through two stages: (1) before generation, we identify low-frequency entities indicating long-tail knowledge gaps; (2) during generation, we verify entity co-occurrence in the pre-training corpus, where zero co-occurrence often signals hallucination risk. Both stages leverage Infini-gram for millisecond-latency queries over 4 trillion tokens, triggering retrieval when uncertainty is high. Experiments on multi-hop QA benchmarks show QuCo-RAG achieves EM gains of 5--12 points over state-of-the-art baselines with OLMo-2 models, and transfers effectively to models with undisclosed pre-training data (Llama, Qwen, GPT), improving EM by up to 14 points. Domain generalization on biomedical QA further validates the robustness of our paradigm. These results establish corpus-grounded verification as a principled, practically model-agnostic paradigm for dynamic RAG. Our code is publicly available at https://github.com/ZhishanQ/QuCo-RAG.

</details>


### [53] [From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs](https://arxiv.org/abs/2512.19161)
*Alessandro Lucca,Francesco Pierri*

Main category: cs.CL

TL;DR: 评估四种最先进ASR模型在意大利长视频字幕制作中的表现，发现虽然无法完全替代人工，但可作为提升人类生产力的有效工具，提出人机协同的云基础设施方案。


<details>
  <summary>Details</summary>
Motivation: 字幕对视频可访问性和观众参与至关重要。尽管现代ASR系统在标准基准数据集上表现良好，但在意大利语长视频等非英语内容的实际生产环境中的性能尚未充分探索，需要为意大利媒体公司开发专业字幕系统。

Method: 对四种最先进ASR模型（Whisper Large v2、AssemblyAI Universal、Parakeet TDT v3 0.6b和WhisperX）在50小时意大利电视节目数据集上进行评估，并与专业人工字幕员的工作进行基准比较。

Result: 研究发现当前模型无法满足媒体行业对完全自主化的准确度需求，但可以作为高度有效的工具来提升人类生产力。模型各有优缺点，需要人机协同工作。

Conclusion: 人机协同（HITL）方法至关重要，为此设计了支持该工作流程的生产级云基础设施，为意大利媒体公司提供实用的专业字幕解决方案。

Abstract: Subtitles are essential for video accessibility and audience engagement. Modern Automatic Speech Recognition (ASR) systems, built upon Encoder-Decoder neural network architectures and trained on massive amounts of data, have progressively reduced transcription errors on standard benchmark datasets. However, their performance in real-world production environments, particularly for non-English content like long-form Italian videos, remains largely unexplored. This paper presents a case study on developing a professional subtitling system for an Italian media company. To inform our system design, we evaluated four state-of-the-art ASR models (Whisper Large v2, AssemblyAI Universal, Parakeet TDT v3 0.6b, and WhisperX) on a 50-hour dataset of Italian television programs. The study highlights their strengths and limitations, benchmarking their performance against the work of professional human subtitlers. The findings indicate that, while current models cannot meet the media industry's accuracy needs for full autonomy, they can serve as highly effective tools for enhancing human productivity. We conclude that a human-in-the-loop (HITL) approach is crucial and present the production-grade, cloud-based infrastructure we designed to support this workflow.

</details>


### [54] [JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation](https://arxiv.org/abs/2512.19171)
*Bingyang Kelvin Liu,Ziyu Patrick Chen*

Main category: cs.CL

TL;DR: JEPA-Reasoner：一种增强生成能力的JEPA模型，在潜在空间进行推理，通过分离的Talker模型生成人类可读句子，解决了JEPA缺乏生成能力和传统Transformer累积误差的问题。


<details>
  <summary>Details</summary>
Motivation: JEPA架构虽然能学习丰富的潜在表示，但缺乏生成能力；而像COCONUT这样的Transformer模型虽然尝试在潜在空间推理，但仍依赖逐token生成，会累积复合误差并依赖上下文信息获取推理洞察。

Method: 提出JEPA-Reasoner，一种增强生成能力的JEPA模型，在潜在空间进行推理。同时增加一个独立的动作执行模型Talker来生成人类可读句子，将潜在空间推理与token生成解耦。

Result: 该方法能够生成混合潜在向量，可能为多线程推理奠定基础，同时通过自回归生成展现出对复合误差的更强鲁棒性。

Conclusion: 解耦潜在空间推理和token生成使JEPA-Reasoner能够产生混合潜在向量，支持多线程推理，并在自回归生成中表现出对复合误差的优越鲁棒性。

Abstract: While Joint-Embedding Predictive Architecture (JEPA) has emerged as a powerful architecture for learning rich latent representations, it fundamentally lacks generative abilities. Meanwhile, latent space reasoning attempts for Transformer models like COCONUT do improve performance, but they ultimately rely on token-by-token generation, which still accumulates compounding error and relies on context information to gain reasoning insights. To address these limitations, we propose JEPA-Reasoner, a novel JEPA model enhanced with generative ability that reasons in latent space. We augment it with a separate action-taker model, Talker, to produce human-readable sentences. Our approach demonstrates that decoupling latent space reasoning and token generation enables JEPA-Reasoner to produce mixed latent vectors that might lay the foundation for multi-threaded reasoning, while performing autoregressive generation with superior robustness to compounding error.

</details>


### [55] [CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation](https://arxiv.org/abs/2512.19173)
*Dazhen Deng,Sen Yang,Yuchen He,Yuan Tian,Yingcai Wu*

Main category: cs.CL

TL;DR: CycleChart是一个基于一致性的双向图表理解与生成框架，通过模式中心化公式统一不同任务，利用生成-解析一致性目标学习跨方向图表语义。


<details>
  <summary>Details</summary>
Motivation: 当前图表特定任务（如图表问答、图表解析和图表生成）通常孤立研究，阻碍模型学习连接图表生成与解释的共享语义。需要统一框架促进跨任务学习。

Method: 采用模式中心化公式作为跨任务通用接口；构建一致的多任务数据集，每个图表样本包含对齐的模式预测、数据解析和问答标注；引入生成-解析一致性目标：模型从表格和文本查询生成图表模式，然后学习从生成的图表中恢复模式和数据，强制跨方向语义对齐。

Result: CycleChart在图表生成、图表解析和图表问答任务上取得强劲结果，展示了改进的跨任务泛化能力，标志着向更通用图表理解模型迈进一步。

Conclusion: CycleChart通过一致性学习框架统一图表理解与生成任务，验证了双向语义对齐对提升跨任务性能的有效性，为开发更通用的图表理解模型提供了方向。

Abstract: Current chart-specific tasks, such as chart question answering, chart parsing, and chart generation, are typically studied in isolation, preventing models from learning the shared semantics that link chart generation and interpretation. We introduce CycleChart, a consistency-based learning framework for bidirectional chart understanding and generation. CycleChart adopts a schema-centric formulation as a common interface across tasks. We construct a consistent multi-task dataset, where each chart sample includes aligned annotations for schema prediction, data parsing, and question answering. To learn cross-directional chart semantics, CycleChart introduces a generate-parse consistency objective: the model generates a chart schema from a table and a textual query, then learns to recover the schema and data from the generated chart, enforcing semantic alignment across directions. CycleChart achieves strong results on chart generation, chart parsing, and chart question answering, demonstrating improved cross-task generalization and marking a step toward more general chart understanding models.

</details>


### [56] [Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation](https://arxiv.org/abs/2512.19238)
*Anna-Maria Gueorguieva,Aylin Caliskan*

Main category: cs.CL

TL;DR: 研究探讨大语言模型对非受保护污名化身份的偏见，发现危险度高的污名（如帮派成员、HIV患者）偏见最严重，而社会人口学污名偏见最少。护栏模型能减少偏见但效果有限。


<details>
  <summary>Details</summary>
Motivation: 大语言模型已显示出社会偏见，但对非受保护污名化身份的偏见研究不足。心理学研究表明污名包含六个社会特征：审美性、可隐藏性、病程、破坏性、起源和危险性。本研究旨在探索这些特征如何影响LLM对污名化群体的偏见。

Method: 使用SocialStigmaQA基准测试，包含37个关于污名化身份的社会场景。评估三个主流LLM（Granite 3.0-8B、Llama-3.1-8B、Mistral-7B）对93个污名化群体的偏见。分析人类和LLM对污名特征的评分、提示风格和污名类型对偏见的影响。测试各模型的护栏系统（Granite Guardian 3.0、Llama Guard 3.0、Mistral Moderation API）的偏见缓解效果。

Result: 人类评为高度危险的污名（如帮派成员、HIV患者）在SocialStigmaQA提示中偏见最严重（所有模型60%输出有偏见），而社会人口学污名（如亚裔美国人、老年人）偏见最少（11%）。护栏模型能减少偏见（分别减少10.4%、1.4%、7.8%），但偏见特征的影响模式未改变，且护栏模型常无法识别提示中的偏见意图。

Conclusion: LLM对污名化群体存在显著偏见，特别是对危险度高的污名。护栏模型能部分缓解偏见但效果有限，无法根本改变偏见模式。这对涉及污名化群体的LLM应用有重要影响，需要改进护栏模型的偏见缓解能力。

Abstract: Large language models (LLMs) have been shown to exhibit social bias, however, bias towards non-protected stigmatized identities remain understudied. Furthermore, what social features of stigmas are associated with bias in LLM outputs is unknown. From psychology literature, it has been shown that stigmas contain six shared social features: aesthetics, concealability, course, disruptiveness, origin, and peril. In this study, we investigate if human and LLM ratings of the features of stigmas, along with prompt style and type of stigma, have effect on bias towards stigmatized groups in LLM outputs. We measure bias against 93 stigmatized groups across three widely used LLMs (Granite 3.0-8B, Llama-3.1-8B, Mistral-7B) using SocialStigmaQA, a benchmark that includes 37 social scenarios about stigmatized identities; for example deciding wether to recommend them for an internship. We find that stigmas rated by humans to be highly perilous (e.g., being a gang member or having HIV) have the most biased outputs from SocialStigmaQA prompts (60% of outputs from all models) while sociodemographic stigmas (e.g. Asian-American or old age) have the least amount of biased outputs (11%). We test if the amount of biased outputs could be decreased by using guardrail models, models meant to identify harmful input, using each LLM's respective guardrail model (Granite Guardian 3.0, Llama Guard 3.0, Mistral Moderation API). We find that bias decreases significantly by 10.4%, 1.4%, and 7.8%, respectively. However, we show that features with significant effect on bias remain unchanged post-mitigation and that guardrail models often fail to recognize the intent of bias in prompts. This work has implications for using LLMs in scenarios involving stigmatized groups and we suggest future work towards improving guardrail models for bias mitigation.

</details>


### [57] [ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models](https://arxiv.org/abs/2512.19240)
*Mingxu Zhang,Dazhong Shen,Qi Zhang,Ying Sun*

Main category: cs.CL

TL;DR: ChemATP框架通过构建原子级文本知识库，让冻结的LLM能够动态检索和推理化学知识，解决了LLM在分子科学中缺乏化学先验的问题，同时保持通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在分子科学中表现不佳，因为标准字符串表示缺乏明确的化学先验。现有方法面临两难：基于训练的方法将先验注入参数，但静态耦合阻碍知识快速更新并损害通用推理能力；而免训练方法依赖表面提示，无法提供精确化学推理所需的原子级先验。

Method: 提出ChemATP框架，将化学知识与推理引擎解耦。通过构建首个原子级文本知识库，使冻结的LLM能够动态检索和推理这些信息。这种架构确保可解释性和适应性，同时保留LLM的内在通用智能。

Result: 实验表明，ChemATP显著优于免训练基线方法，并与最先进的基于训练的方法相媲美，证明显式先验注入是隐式参数更新的竞争性替代方案。

Conclusion: ChemATP通过解耦化学知识与推理引擎，为LLM在分子科学中的应用提供了可解释、可适应且保持通用推理能力的解决方案，显式先验注入是有效的替代参数更新的方法。

Abstract: Large Language Models (LLMs) exhibit strong general reasoning but struggle in molecular science due to the lack of explicit chemical priors in standard string representations. Current solutions face a fundamental dilemma. Training-based methods inject priors into parameters, but this static coupling hinders rapid knowledge updates and often compromises the model's general reasoning capabilities. Conversely, existing training-free methods avoid these issues but rely on surface-level prompting, failing to provide the fine-grained atom-level priors essential for precise chemical reasoning. To address this issue, we introduce ChemATP, a framework that decouples chemical knowledge from the reasoning engine. By constructing the first atom-level textual knowledge base, ChemATP enables frozen LLMs to explicitly retrieve and reason over this information dynamically. This architecture ensures interpretability and adaptability while preserving the LLM's intrinsic general intelligence. Experiments show that ChemATP significantly outperforms training-free baselines and rivals state-of-the-art training-based models, demonstrating that explicit prior injection is a competitive alternative to implicit parameter updates.

</details>


### [58] [Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics](https://arxiv.org/abs/2512.19247)
*Do Minh Duc,Quan Xuan Truong,Nguyen Tat Dat,Nguyen Van Vinh*

Main category: cs.CL

TL;DR: 提出一个结合RAG、few-shot、CoT和Auto-CoT的提示优化框架，用于物流文本中的框架检测任务，通过LLM代理迭代优化提示，在真实物流文本标注任务中提升推理准确率15%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理和标注任务中需要提示工程来避免大量微调，特别是在物流文本处理这类领域特定任务中，需要高效准确的框架检测方法

Method: 提出一个提示优化流水线，结合检索增强生成(RAG)、少样本提示、思维链推理(CoT)和自动CoT合成(Auto-CoT)，使用基于LLM的提示优化代理通过检索示例、性能反馈和自评估迭代优化提示

Result: 在真实物流文本标注任务中，优化后的提示（特别是通过Auto-CoT和RAG增强的）相比基线零样本或静态提示，推理准确率提升高达15%，在GPT-4o、Qwen 2.5和LLaMA 3.1等多个LLM上表现一致

Conclusion: 结构化提示优化是完整微调的可替代方案，为在物流等特定领域NLP应用中部署LLM提供了可扩展的解决方案，具有实际应用价值

Abstract: Prompt engineering plays a critical role in adapting large language models (LLMs) to complex reasoning and labeling tasks without the need for extensive fine-tuning. In this paper, we propose a novel prompt optimization pipeline for frame detection in logistics texts, combining retrieval-augmented generation (RAG), few-shot prompting, chain-of-thought (CoT) reasoning, and automatic CoT synthesis (Auto-CoT) to generate highly effective task-specific prompts. Central to our approach is an LLM-based prompt optimizer agent that iteratively refines the prompts using retrieved examples, performance feedback, and internal self-evaluation. Our framework is evaluated on a real-world logistics text annotation task, where reasoning accuracy and labeling efficiency are critical. Experimental results show that the optimized prompts - particularly those enhanced via Auto-CoT and RAG - improve real-world inference accuracy by up to 15% compared to baseline zero-shot or static prompts. The system demonstrates consistent improvements across multiple LLMs, including GPT-4o, Qwen 2.5 (72B), and LLaMA 3.1 (70B), validating its generalizability and practical value. These findings suggest that structured prompt optimization is a viable alternative to full fine-tuning, offering scalable solutions for deploying LLMs in domain-specific NLP applications such as logistics.

</details>


### [59] [CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs](https://arxiv.org/abs/2512.19305)
*Javier Vela-Tambo,Jorge Gracia,Fernando Dominguez-Castro*

Main category: cs.CL

TL;DR: CienaLLM是一个基于模式引导生成式信息提取的模块化框架，使用开源大语言模型从新闻文章中零样本提取结构化信息，支持可配置提示和输出模式，在干旱影响提取任务上达到或超过监督基线性能。


<details>
  <summary>Details</summary>
Motivation: 为了大规模监测气候灾害的社会经济影响，需要从异构新闻文章中提取结构化信息，传统方法需要大量标注数据且难以适应新任务。

Method: 开发CienaLLM框架，采用模式引导的生成式信息提取方法，使用开源大语言模型进行零样本提取，支持可配置提示、输出模式和多步骤管道，通过大规模因子实验评估不同模型家族、大小、精度和提示策略的影响。

Result: 响应解析步骤几乎消除了格式错误；更大模型提供最强最稳定的性能；量化提供显著的效率提升但精度略有下降；提示策略效果因模型而异；在西班牙新闻干旱影响提取任务上，CienaLLM达到或超过监督基线精度，但推理成本更高。

Conclusion: CienaLLM的模式驱动和模型无关设计使其能够通过编辑提示和模式（而非重新训练）适应相关信息提取任务，框架具有可扩展性和适应性，为气候灾害影响监测提供了有效工具。

Abstract: Understanding and monitoring the socio-economic impacts of climate hazards requires extracting structured information from heterogeneous news articles on a large scale. To that end, we have developed CienaLLM, a modular framework based on schema-guided Generative Information Extraction. CienaLLM uses open-weight Large Language Models for zero-shot information extraction from news articles, and supports configurable prompts and output schemas, multi-step pipelines, and cloud or on-premise inference. To systematically assess how the choice of LLM family, size, precision regime, and prompting strategy affect performance, we run a large factorial study in models, precisions, and prompt engineering techniques. An additional response parsing step nearly eliminates format errors while preserving accuracy; larger models deliver the strongest and most stable performance, while quantization offers substantial efficiency gains with modest accuracy trade-offs; and prompt strategies show heterogeneous, model-specific effects. CienaLLM matches or outperforms the supervised baseline in accuracy for extracting drought impacts from Spanish news, although at a higher inference cost. While evaluated in droughts, the schema-driven and model-agnostic design is suitable for adapting to related information extraction tasks (e.g., other hazards, sectors, or languages) by editing prompts and schemas rather than retraining. We release code, configurations, and schemas to support reproducible use.

</details>


### [60] [HATS: High-Accuracy Triple-Set Watermarking for Large Language Models](https://arxiv.org/abs/2512.19378)
*Zhiqing Hu,Chenxu Zhao,Jiazhong Lu,Xiaolei Liu*

Main category: cs.CL

TL;DR: 提出一种基于三色分区（绿/黄/红）的LLM水印方案，通过限制采样范围嵌入信号，使用Fisher方法聚合p值进行检测，在Llama 2 7B上验证了高检测准确率和文本质量保持。


<details>
  <summary>Details</summary>
Motivation: 为了遏制LLM生成文本的滥用，需要开发能够嵌入隐式信号的水印技术，使生成的文本能够被有效检测和追踪。

Method: 在解码的每一步将词汇表划分为绿/黄/红三个固定比例的分区，限制采样到绿区和黄区。检测时重放相同分区，计算绿区富集和红区贫乏统计量，转换为单侧z分数，通过Fisher方法聚合p值判断文本是否含水印。

Result: 在Llama 2 7B上的实验表明，三色分区方案在固定误报率下实现了高检测准确率，同时保持了文本的可读性。

Conclusion: 提出的三色分区水印方案能有效检测LLM生成的文本，在保持文本质量的同时提供可靠的检测能力，为LLM文本滥用控制提供了实用工具。

Abstract: Misuse of LLM-generated text can be curbed by watermarking techniques that embed implicit signals into the output. We propose a watermark that partitions the vocabulary at each decoding step into three sets (Green/Yellow/Red) with fixed ratios and restricts sampling to the Green and Yellow sets. At detection time, we replay the same partitions, compute Green-enrichment and Red-depletion statistics, convert them to one-sided z-scores, and aggregate their p-values via Fisher's method to decide whether a passage is watermarked. We implement generation, detection, and testing on Llama 2 7B, and evaluate true-positive rate, false-positive rate, and text quality. Results show that the triple-partition scheme achieves high detection accuracy at fixed FPR while preserving readability.

</details>


### [61] [Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara](https://arxiv.org/abs/2512.19400)
*Yacouba Diarra,Panga Azazia Kamate,Nouhoum Souleymane Coulibaly,Michael Leventhal*

Main category: cs.CL

TL;DR: Kunkado是一个160小时的班巴拉语ASR数据集，从马里广播档案中收集，包含真实世界中的自发语音特征。基于该数据集微调的模型在两个测试集上显著降低了WER，并在人工评估中优于使用更干净但较少真实语音训练的系统。


<details>
  <summary>Details</summary>
Motivation: 为支持主要口语语言的鲁棒ASR系统，需要包含真实世界语音特征（如语码转换、不流畅、背景噪声、说话人重叠）的数据集。现有数据集通常过于干净，无法反映实际应用场景。

Method: 从马里广播档案中编译160小时的班巴拉语ASR数据集，包含真实世界语音特征。使用33.47小时人工审核的子集微调Parakeet基础模型，并应用实用的转录规范化来减少数字格式、标签和语码转换标注的变异性。

Result: 在两个真实世界测试集上，使用Kunkado微调的模型将WER从44.47%降低到37.12%（测试集1），从36.07%降低到32.33%（测试集2）。人工评估显示，该模型优于使用98小时更干净但较少真实语音训练的可比系统。

Conclusion: Kunkado数据集有效支持了班巴拉语等主要口语语言的鲁棒ASR系统开发。包含真实世界语音特征的数据集对于实际应用至关重要，作者发布了数据和模型以促进相关研究。

Abstract: We present Kunkado, a 160-hour Bambara ASR dataset compiled from Malian radio archives to capture present-day spontaneous speech across a wide range of topics. It includes code-switching, disfluencies, background noise, and overlapping speakers that practical ASR systems encounter in real-world use. We finetuned Parakeet-based models on a 33.47-hour human-reviewed subset and apply pragmatic transcript normalization to reduce variability in number formatting, tags, and code-switching annotations. Evaluated on two real-world test sets, finetuning with Kunkado reduces WER from 44.47\% to 37.12\% on one and from 36.07\% to 32.33\% on the other. In human evaluation, the resulting model also outperforms a comparable system with the same architecture trained on 98 hours of cleaner, less realistic speech. We release the data and models to support robust ASR for predominantly oral languages.

</details>


### [62] [CodeSimpleQA: Scaling Factuality in Code Large Language Models](https://arxiv.org/abs/2512.19424)
*Jian Yang,Wei Zhang,Yizhi Li,Shawn Guo,Haowen Wang,Aishan Liu,Ge Zhang,Zili Wang,Zhoujun Li,Xianglong Liu,Weifeng Lv*

Main category: cs.CL

TL;DR: 本文提出了CodeSimpleQA基准测试，用于评估代码大语言模型在编程知识事实准确性方面的表现，并开发了包含6600万样本的指令数据集和训练框架，显著提升了模型的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在代码生成方面取得显著进展，但存在一个关键挑战：确保模型生成的编程概念、技术实现等响应在事实上准确。大多数现有代码基准测试只关注代码执行正确性，忽视了编程知识的事实准确性。

Method: 1) 创建CodeSimpleQA双语基准测试，包含精心策划的英文和中文问答对，涵盖多种编程语言和计算机科学领域；2) 构建CodeSimpleQA-Instruct指令数据集，包含6600万个样本；3) 开发结合监督微调和强化学习的后训练框架。

Result: 对多种LLM的综合评估显示，即使是前沿的LLM在代码事实性方面也存在困难。提出的训练框架相比基础模型有显著改进，证明了事实性对齐在开发可靠代码LLM中的重要性。

Conclusion: 代码LLM在编程知识事实准确性方面存在不足，需要专门的事实性对齐训练。CodeSimpleQA基准测试和提出的训练框架为评估和提升代码LLM的事实准确性提供了有效解决方案。

Abstract: Large language models (LLMs) have made significant strides in code generation, achieving impressive capabilities in synthesizing code snippets from natural language instructions. However, a critical challenge remains in ensuring LLMs generate factually accurate responses about programming concepts, technical implementations, etc. Most previous code-related benchmarks focus on code execution correctness, overlooking the factual accuracy of programming knowledge. To address this gap, we present CodeSimpleQA, a comprehensive bilingual benchmark designed to evaluate the factual accuracy of code LLMs in answering code-related questions, which contains carefully curated question-answer pairs in both English and Chinese, covering diverse programming languages and major computer science domains. Further, we create CodeSimpleQA-Instruct, a large-scale instruction corpus with 66M samples, and develop a post-training framework combining supervised fine-tuning and reinforcement learning. Our comprehensive evaluation of diverse LLMs reveals that even frontier LLMs struggle with code factuality. Our proposed framework demonstrates substantial improvements over the base model, underscoring the critical importance of factuality-aware alignment in developing reliable code LLMs.

</details>


### [63] [MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments](https://arxiv.org/abs/2512.19432)
*Quyu Kong,Xu Zhang,Zhenyu Yang,Nolan Gao,Chen Liu,Panrong Tong,Chenglin Cai,Hanzhang Zhou,Jianan Zhang,Liangyu Chen,Zhidan Liu,Steven Hoi,Yue Wang*

Main category: cs.CL

TL;DR: MobileWorld：一个比AndroidWorld更具挑战性的移动应用基准测试，包含跨应用交互、用户互动和MCP增强任务，成功率大幅下降至51.7%


<details>
  <summary>Details</summary>
Motivation: 现有AndroidWorld基准测试已饱和（成功率超90%），缺乏电商、企业通信等关键应用类别，且未反映真实移动使用场景中的模糊指令和混合工具使用

Method: 构建包含201个任务、20个应用的MobileWorld基准，强调长时程跨应用交互（平均27.8步），引入用户互动和MCP增强任务，提供快照容器环境和精确功能验证

Result: 最佳智能体框架和端到端模型成功率分别为51.7%和20.9%，远低于AndroidWorld，模型在用户互动和MCP调用方面表现显著不足

Conclusion: MobileWorld为下一代移动智能提供了更具挑战性的基准，揭示了当前模型在真实场景中的局限性，指明了用户互动和MCP能力的发展方向

Abstract: Among existing online mobile-use benchmarks, AndroidWorld has emerged as the dominant benchmark due to its reproducible environment and deterministic evaluation; however, recent agents achieving over 90% success rates indicate its saturation and motivate the need for a more challenging benchmark. In addition, its environment lacks key application categories, such as e-commerce and enterprise communication, and does not reflect realistic mobile-use scenarios characterized by vague user instructions and hybrid tool usage. To bridge this gap, we introduce MobileWorld, a substantially more challenging benchmark designed to better reflect real-world mobile usage, comprising 201 tasks across 20 applications, while maintaining the same level of reproducible evaluation as AndroidWorld. The difficulty of MobileWorld is twofold. First, it emphasizes long-horizon tasks with cross-application interactions: MobileWorld requires nearly twice as many task-completion steps on average (27.8 vs. 14.3) and includes far more multi-application tasks (62.2% vs. 9.5%) compared to AndroidWorld. Second, MobileWorld extends beyond standard GUI manipulation by introducing novel task categories, including agent-user interaction and MCP-augmented tasks. To ensure robust evaluation, we provide snapshot-based container environment and precise functional verifications, including backend database inspection and task callback APIs. We further develop a planner-executor agentic framework with extended action spaces to support user interactions and MCP calls. Our results reveal a sharp performance drop compared to AndroidWorld, with the best agentic framework and end-to-end model achieving 51.7% and 20.9% success rates, respectively. Our analysis shows that current models struggle significantly with user interaction and MCP calls, offering a strategic roadmap toward more robust, next-generation mobile intelligence.

</details>


### [64] [SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation](https://arxiv.org/abs/2512.19455)
*Thittipat Pairatsuppawat,Abhibhu Tachaapornchai,Paweekorn Kusolsomboon,Chutikan Chaiwong,Thodsaporn Chay-intr,Kobkrit Viriyayudhakorn,Nongnuch Ketui,Aslan B. Wong*

Main category: cs.CL

TL;DR: SiamGPT-32B是基于Qwen3-32B微调的开源泰语大语言模型，采用质量优先策略，通过翻译高质量英文指令数据和泰语适配的AutoIF框架，显著提升了泰语复杂指令下的生成稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 当前开源大语言模型在泰语部署上面临挑战：尽管英文表现优秀，但在复杂指令下泰语生成不稳定。需要解决泰语指令遵循、多轮对话鲁棒性和语言稳定性问题。

Method: 基于Qwen3-32B进行监督微调，采用质量优先策略，强调数据质量而非数量。方法包括：1) 翻译高质量复杂英文指令数据；2) 泰语适配的AutoIF框架用于指令和语言约束；3) 仅使用监督微调，无需持续预训练或语料扩展。

Result: 在SEA-HELM基准测试中，SiamGPT-32B在相似规模的开源泰语模型中表现最佳，在指令遵循、多轮对话和自然语言理解方面均有显著提升。

Conclusion: 通过质量优先的微调策略和泰语适配的AutoIF框架，SiamGPT-32B有效解决了泰语LLM部署中的稳定性问题，为低资源语言模型开发提供了有效方法。

Abstract: Open-weights large language models remain difficult to deploy for Thai due to unstable generation under complex instructions, despite strong English performance. To mitigate these limitations, We present SiamGPT-32B, an open-weights model based on Qwen3-32B, fine-tuned with a Quality-First strategy emphasizing curated supervision over data scale. The fine-tuning pipeline combines translated high-complexity English instruction data with a Thai-adapted AutoIF framework for instruction and linguistic constraints. Using supervised fine-tuning only, without continual pretraining or corpus expansion, SiamGPT-32B improves instruction adherence, multi-turn robustness, and linguistic stability. Evaluations on the SEA-HELM benchmark show that SiamGPT-32B achieves the strongest overall performance among similar-scale open-weights Thai models, with consistent gains in instruction following, multi-turn dialogue, and natural language understanding.

</details>


### [65] [Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations](https://arxiv.org/abs/2512.19456)
*Jinwei Chi,Ke Wang,Yu Chen,Xuanye Lin,Qiang Xu*

Main category: cs.CL

TL;DR: 研究探索大型语言模型中间层激活在跨提示作文评分中的判别能力，发现激活具有强判别力且LLMs能适应不同评分标准和作文类型。


<details>
  <summary>Details</summary>
Motivation: 跨提示自动作文评分面临评分标准多样性的挑战，现有研究主要关注LLMs的输出，但中间层激活可能包含有价值的信息。

Method: 使用LLMs的中间层激活拟合探针，分析不同模型和输入内容对判别能力的影响，计算不同提示下各特质维度的方向向量。

Result: 激活在评估作文质量方面具有强判别能力，LLMs能根据不同特质和作文类型调整评估视角，有效处理跨提示设置中的评分标准多样性。

Conclusion: LLMs中间层激活为跨提示作文评分提供了有价值的判别信息，模型能自适应调整评估视角，为解决评分标准多样性问题提供了新思路。

Abstract: Automated essay scoring (AES) is a challenging task in cross-prompt settings due to the diversity of scoring criteria. While previous studies have focused on the output of large language models (LLMs) to improve scoring accuracy, we believe activations from intermediate layers may also provide valuable information. To explore this possibility, we evaluated the discriminative power of LLMs' activations in cross-prompt essay scoring task. Specifically, we used activations to fit probes and further analyzed the effects of different models and input content of LLMs on this discriminative power. By computing the directions of essays across various trait dimensions under different prompts, we analyzed the variation in evaluation perspectives of large language models concerning essay types and traits. Results show that the activations possess strong discriminative power in evaluating essay quality and that LLMs can adapt their evaluation perspectives to different traits and essay types, effectively handling the diversity of scoring criteria in cross-prompt settings.

</details>


### [66] [A Large-Language-Model Framework for Automated Humanitarian Situation Reporting](https://arxiv.org/abs/2512.19475)
*Ivan Decostanzi,Yelena Mejova,Kyriaki Kalimeri*

Main category: cs.CL

TL;DR: 利用大语言模型自动将异构人道主义文档转化为结构化、有证据支撑的报告框架，在13个人道主义事件中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前人道主义决策依赖的手工报告制作流程效率低下、资源密集且不一致，需要自动化解决方案来提高时效性和准确性。

Method: 整合语义文本聚类、自动问题生成、检索增强的引用式答案提取、多级摘要和行政摘要生成，并采用模拟专家推理的内部评估指标。

Result: 在13个人道主义事件（自然灾害和冲突）的1100多份文档上评估，生成问题相关度84.7%、重要性84.0%、紧急性76.4%；提取答案相关度86.3%，引用精确率和召回率均超过76%；人工与LLM评估一致性F1分数超过0.80。

Conclusion: 通过结合LLM推理、透明引用链接和多级评估，该框架能够自主生成准确、可验证且具有操作价值的人道主义形势报告，优于现有基线方法。

Abstract: Timely and accurate situational reports are essential for humanitarian decision-making, yet current workflows remain largely manual, resource intensive, and inconsistent. We present a fully automated framework that uses large language models (LLMs) to transform heterogeneous humanitarian documents into structured and evidence-grounded reports. The system integrates semantic text clustering, automatic question generation, retrieval augmented answer extraction with citations, multi-level summarization, and executive summary generation, supported by internal evaluation metrics that emulate expert reasoning. We evaluated the framework across 13 humanitarian events, including natural disasters and conflicts, using more than 1,100 documents from verified sources such as ReliefWeb. The generated questions achieved 84.7 percent relevance, 84.0 percent importance, and 76.4 percent urgency. The extracted answers reached 86.3 percent relevance, with citation precision and recall both exceeding 76 percent. Agreement between human and LLM based evaluations surpassed an F1 score of 0.80. Comparative analysis shows that the proposed framework produces reports that are more structured, interpretable, and actionable than existing baselines. By combining LLM reasoning with transparent citation linking and multi-level evaluation, this study demonstrates that generative AI can autonomously produce accurate, verifiable, and operationally useful humanitarian situation reports.

</details>


### [67] [Event Extraction in Large Language Model](https://arxiv.org/abs/2512.19537)
*Bobo Li,Xudong Han,Jiang Liu,Yuzhe Ding,Liqiang Jing,Zhaoqi Zhang,Jinheng Li,Xinya Du,Fei Li,Meishan Zhang,Min Zhang,Aixin Sun,Philip S. Yu,Hao Fei*

Main category: cs.CL

TL;DR: 该论文综述了事件抽取在LLM时代的发展，主张将事件抽取视为为LLM解决方案提供认知支架的系统组件，涵盖文本和多模态设置，并探讨了未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM和多模态LLM正在改变事件抽取领域，但基于LLM的管道仍面临部署差距：弱约束下的幻觉、长上下文和跨文档的脆弱时间因果链接、有限的长视野知识管理。需要将事件抽取视为为LLM中心解决方案提供认知支架的系统组件。

Method: 通过事件模式和槽约束创建接口进行接地和验证；事件中心结构作为逐步推理的受控中间表示；事件链接支持基于图的RAG进行关系感知检索；事件存储提供可更新的情景和代理记忆。综述涵盖文本和多模态设置，组织任务和分类，追踪从基于规则和神经模型到指令驱动和生成框架的方法演进。

Result: 论文总结了事件抽取的表述、解码策略、架构、表示、数据集和评估方法，回顾了跨语言、低资源和领域特定设置，并突出了可靠事件中心系统的开放挑战和未来方向。

Conclusion: 事件抽取应从静态提取演变为结构可靠、代理就绪的感知和记忆层，为开放世界系统服务。需要解决LLM时代的核心挑战，将事件抽取发展为可靠的事件中心系统组件。

Abstract: Large language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provides a cognitive scaffold for LLM centered solutions. Event schemas and slot constraints create interfaces for grounding and verification; event centric structures act as controlled intermediate representations for stepwise reasoning; event links support relation aware retrieval with graph based RAG; and event stores offer updatable episodic and agent memory beyond the context window. This survey covers EE in text and multimodal settings, organizing tasks and taxonomy, tracing method evolution from rule based and neural models to instruction driven and generative frameworks, and summarizing formulations, decoding strategies, architectures, representations, datasets, and evaluation. We also review cross lingual, low resource, and domain specific settings, and highlight open challenges and future directions for reliable event centric systems. Finally, we outline open challenges and future directions that are central to the LLM era, aiming to evolve EE from static extraction into a structurally reliable, agent ready perception and memory layer for open world systems.

</details>


### [68] [Algerian Dialect](https://arxiv.org/abs/2512.19543)
*Zakaria Benmounah,Abdennour Boulesnane*

Main category: cs.CL

TL;DR: 提出了一个包含45,000条阿尔及利亚阿拉伯语方言YouTube评论的大规模情感标注数据集，填补了该方言资源稀缺的空白。


<details>
  <summary>Details</summary>
Motivation: 阿尔及利亚方言的公开可用资源稀缺，限制了该方言的情感分析、阿拉伯语NLP和社交媒体分析研究。

Method: 使用YouTube Data API从30多个阿尔及利亚新闻和媒体频道收集评论，然后手动将每条评论标注为五种情感类别之一（非常负面、负面、中性、正面、非常正面）。

Result: 创建了包含45,000条标注评论的数据集，附带丰富元数据（时间戳、点赞数、视频URL、标注日期），已在Mendeley Data公开提供。

Conclusion: 该数据集为阿尔及利亚方言的情感分析和NLP研究提供了宝贵资源，支持该领域的进一步研究发展。

Abstract: We present Algerian Dialect, a large-scale sentiment-annotated dataset consisting of 45,000 YouTube comments written in Algerian Arabic dialect. The comments were collected from more than 30 Algerian press and media channels using the YouTube Data API. Each comment is manually annotated into one of five sentiment categories: very negative, negative, neutral, positive, and very positive. In addition to sentiment labels, the dataset includes rich metadata such as collection timestamps, like counts, video URLs, and annotation dates. This dataset addresses the scarcity of publicly available resources for Algerian dialect and aims to support research in sentiment analysis, dialectal Arabic NLP, and social media analytics. The dataset is publicly available on Mendeley Data under a CC BY 4.0 license at https://doi.org/10.17632/zzwg3nnhsz.2.

</details>


### [69] [Increasing the Thinking Budget is Not All You Need](https://arxiv.org/abs/2512.19585)
*Ignacio Iacobacci,Zhaozhi Qian,Faroq AL-Tam,Muhammad AL-Qurishi,Riad Souissi*

Main category: cs.CL

TL;DR: 研究发现，单纯增加大语言模型的"思考预算"（推理过程长度）并非最有效的计算资源利用方式，通过自洽性和自我反思等配置可以获得更准确的结果。


<details>
  <summary>Details</summary>
Motivation: 随着具备思考能力的大语言模型出现，早期研究开始探索推理过程长度（思考预算）对模型性能的影响。本研究旨在系统性地研究思考预算作为关键参数，及其与自洽性、反思等配置的交互作用。

Method: 提出一个系统性的调查框架，将思考预算作为关键参数，研究其与各种配置（如自洽性、反思等）的交互作用。目标是建立一个既考虑性能结果又考虑计算成本的平衡比较框架。

Result: 研究发现，单纯增加思考预算并不是最有效的计算资源利用方式。相反，通过自洽性和自我反思等替代配置可以获得更准确的响应。

Conclusion: 思考预算的优化不应仅仅关注增加推理长度，而应考虑与自洽性、反思等配置的协同作用，以实现更好的性能与计算成本平衡。

Abstract: Recently, a new wave of thinking-capable Large Language Models has emerged, demonstrating exceptional capabilities across a wide range of reasoning benchmarks. Early studies have begun to explore how the amount of compute in terms of the length of the reasoning process, the so-called thinking budget, impacts model performance. In this work, we propose a systematic investigation of the thinking budget as a key parameter, examining its interaction with various configurations such as self-consistency, reflection, and others. Our goal is to provide an informative, balanced comparison framework that considers both performance outcomes and computational cost. Among our findings, we discovered that simply increasing the thinking budget is not the most effective use of compute. More accurate responses can instead be achieved through alternative configurations, such as self-consistency and self-reflection.

</details>


### [70] [MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery](https://arxiv.org/abs/2512.19612)
*Angelo Ortiz Tandazo,Manel Khentout,Youssef Benchekroun,Thomas Hueber,Emmanuel Dupoux*

Main category: cs.CL

TL;DR: MauBERT：基于HuBERT的多语言扩展，通过发音特征监督学习跨语言语音表示，在55种语言上训练，产生语言无关的语音表示，在ABX测试中优于现有模型


<details>
  <summary>Details</summary>
Motivation: 现有自监督语音模型缺乏语言学的归纳偏置，难以学习跨语言的鲁棒语音表示。本文旨在通过发音特征监督，为自监督语音模型注入语言学先验知识，实现更好的跨语言语音表示学习。

Method: 在HuBERT基础上继续预训练，使用55种语言的多语言数据，通过语音到发音特征的映射进行监督学习，预测发音特征或音素，学习语言无关的语音表示。

Result: MauBERT模型在ABX区分性测试中比现有最先进的多语言自监督学习模型产生更上下文不变的表示。模型能有效适应未见语言和日常语音，仅需少量自监督微调（10小时语音）。

Conclusion: MauBERT为自监督语音模型注入语言学归纳偏置提供了一种有效方法，实现了鲁棒的跨语言语音表示学习，在多种语言和语音条件下表现优异。

Abstract: This paper introduces MauBERT, a multilingual extension of HuBERT that leverages articulatory features for robust cross-lingual phonetic representation learning. We continue HuBERT pre-training with supervision based on a phonetic-to-articulatory feature mapping in 55 languages. Our models learn from multilingual data to predict articulatory features or phones, resulting in language-independent representations that capture multilingual phonetic properties. Through comprehensive ABX discriminability testing, we show MauBERT models produce more context-invariant representations than state-of-the-art multilingual self-supervised learning models. Additionally, the models effectively adapt to unseen languages and casual speech with minimal self-supervised fine-tuning (10 hours of speech). This establishes an effective approach for instilling linguistic inductive biases in self-supervised speech models.

</details>


### [71] [Exploring the features used for summary evaluation by Human and GPT](https://arxiv.org/abs/2512.19620)
*Zahra Sadeghi,Evangelos Milios,Frank Rudzicz*

Main category: cs.CL

TL;DR: 研究探索LLMs评估摘要时使用的特征，发现通过指导GPTs使用人类评估指标可以改善其判断并与人类响应更一致


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs已被用作自动摘要评估的"裁判"，但人们并不清楚它们基于特定质量维度评估时利用了哪些特征或属性，而且评估分数与指标之间的映射关系也缺乏研究

Method: 通过研究统计和机器学习指标，发现与人类和GPTs响应对齐的特征，并指导GPTs使用人类评估指标来改进判断

Result: 发现可以通过指导GPTs使用人类评估指标来改善其判断，使其更符合人类响应

Conclusion: 理解LLMs在摘要评估中使用的特征有助于改进其评估能力，指导它们使用人类评估指标可以提高与人类判断的一致性

Abstract: Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.

</details>


### [72] [Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori](https://arxiv.org/abs/2512.19630)
*Rolando Coto-Solano,Daisy Li,Manoela Teleginski Ferraz,Olivia Sasse,Cha Krupka,Sharid Loáiciga,Sally Akevai Tenamu Nicholas*

Main category: cs.CL

TL;DR: 本文研究两种极度资源匮乏语言（Bribri语和库克群岛毛利语）的变音符号恢复任务，比较不同算法性能，发现字符级微调LLM效果最佳，需要约10,000词数据才能获得可靠性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机来自两方面：一是语言社区对文本规范化处理的实际需求，二是NLP研究中关于资源匮乏语言模型性能与泛化能力的基础研究问题。变音符号恢复对NLP任务至关重要，但极度资源匮乏语言的相关研究很少。

Method: 研究比较了多种变音符号恢复算法，包括字符级微调LLM、大规模多语言模型和零样本方法。实验在两种极度资源匮乏语言（Bribri语和库克群岛毛利语）上进行，考察了不同数据量（从少量到10,000词）对性能的影响，并探索了变音符号校正任务。

Result: 字符级微调LLM表现最佳，可能因其能将复杂字符分解为UTF-8字节表示。大规模多语言模型在数据受限条件下效果较差。所有模型需要约10,000词数据才能获得可靠性能。零样本方法在所有情况下表现都很差。

Conclusion: 对于极度资源匮乏语言的变音符号恢复任务，字符级微调LLM是最有效的解决方案，但需要约10,000词的数据量才能达到可靠性能。研究结果对资源匮乏语言的NLP处理具有重要指导意义。

Abstract: We present experiments on diacritic restoration, a form of text normalization essential for natural language processing (NLP) tasks. Our study focuses on two extremely under-resourced languages: Bribri, a Chibchan language spoken in Costa Rica, and Cook Islands Māori, a Polynesian language spoken in the Cook Islands. Specifically, this paper: (i) compares algorithms for diacritics restoration in under-resourced languages, including tonal diacritics, (ii) examines the amount of data required to achieve target performance levels, (iii) contrasts results across varying resource conditions, and (iv) explores the related task of diacritic correction. We find that fine-tuned, character-level LLMs perform best, likely due to their ability to decompose complex characters into their UTF-8 byte representations. In contrast, massively multilingual models perform less effectively given our data constraints. Across all models, reliable performance begins to emerge with data budgets of around 10,000 words. Zero-shot approaches perform poorly in all cases. This study responds both to requests from the language communities and to broader NLP research questions concerning model performance and generalization in under-resourced contexts.

</details>


### [73] [Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting](https://arxiv.org/abs/2512.19651)
*Filippos Ventirozos,Peter Appleby,Matthew Shardlow*

Main category: cs.CL

TL;DR: 本文提出了一种基于统一意义表示（UMR）的思维链提示技术，用于零样本方面类别情感分析，以解决标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 方面类别情感分析（ACSA）需要细粒度的标注数据，但新领域的标注数据稀缺且成本高昂。在标注资源有限的情况下，利用大语言模型进行零样本学习是一个实用的替代方案。

Method: 提出了一种新颖的思维链（CoT）提示技术，通过中间的统一意义表示（UMR）来结构化ACSA任务的推理过程。在三个模型（Qwen3-4B、Qwen3-8B和Gemini-2.5-Pro）和四个数据集上评估了这种基于UMR的方法。

Result: UMR的有效性可能依赖于具体模型。初步结果表明，对于中等规模的模型如Qwen3-8B，性能与标准CoT基线相当，但这些观察需要进一步研究，特别是对于更小模型架构的适用性。

Conclusion: 需要进一步研究来验证这些发现在不同模型规模上的普适性。UMR方法在零样本ACSA任务中显示出潜力，但其效果可能因模型而异。

Abstract: Aspect-Category Sentiment Analysis (ACSA) provides granular insights by identifying specific themes within reviews and their associated sentiment. While supervised learning approaches dominate this field, the scarcity and high cost of annotated data for new domains present significant barriers. We argue that leveraging large language models (LLMs) in a zero-shot setting is a practical alternative where resources for data annotation are limited. In this work, we propose a novel Chain-of-Thought (CoT) prompting technique that utilises an intermediate Unified Meaning Representation (UMR) to structure the reasoning process for the ACSA task. We evaluate this UMR-based approach against a standard CoT baseline across three models (Qwen3-4B, Qwen3-8B, and Gemini-2.5-Pro) and four diverse datasets. Our findings suggest that UMR effectiveness may be model-dependent. Whilst preliminary results indicate comparable performance for mid-sized models such as Qwen3-8B, these observations warrant further investigation, particularly regarding the potential applicability to smaller model architectures. Further research is required to establish the generalisability of these findings across different model scales.

</details>


### [74] [GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators](https://arxiv.org/abs/2512.19682)
*Jiacheng Guo,Ling Yang,Peter Chen,Qixin Xiao,Yinjie Wang,Xinzhe Juan,Jiahao Qiu,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: GenEnv是一个通过生成式环境模拟器与智能体进行难度对齐协同进化的框架，能够动态生成适合智能体当前能力水平的任务，显著提升LLM智能体性能并减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 训练大型语言模型智能体面临真实世界交互数据成本高、静态不变的瓶颈问题，需要更高效的数据利用方法。

Method: 建立智能体与可扩展生成式环境模拟器之间的协同进化游戏，使用α-课程奖励指导模拟器动态生成适合智能体"最近发展区"的任务。

Result: 在五个基准测试中，GenEnv将7B基线模型的性能提升高达40.3%，匹配或超越更大模型的平均性能，相比Gemini 2.5 Pro的离线数据增强方法，使用数据量减少3.3倍且性能更好。

Conclusion: 通过从静态监督转向自适应模拟，GenEnv为扩展智能体能力提供了数据高效的途径。

Abstract: Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative environment simulator. Unlike traditional methods that evolve models on static datasets, GenEnv instantiates a dataevolving: the simulator acts as a dynamic curriculum policy, continuously generating tasks specifically tailored to the agent's ``zone of proximal development''. This process is guided by a simple but effective $α$-Curriculum Reward, which aligns task difficulty with the agent's current capabilities. We evaluate GenEnv on five benchmarks, including API-Bank, ALFWorld, BFCL, Bamboogle, and TravelPlanner. Across these tasks, GenEnv improves agent performance by up to \textbf{+40.3\%} over 7B baselines and matches or exceeds the average performance of larger models. Compared to Gemini 2.5 Pro-based offline data augmentation, GenEnv achieves better performance while using 3.3$\times$ less data. By shifting from static supervision to adaptive simulation, GenEnv provides a data-efficient pathway for scaling agent capabilities.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [75] [Untethered thin dielectric elastomer actuated soft robot](https://arxiv.org/abs/2512.17940)
*Xi Wang,Jing Liu,Siqian Li,Hengtai Dai,Jung-Che Chang,Adam Rushworth,Xin Dong*

Main category: cs.RO

TL;DR: 本文提出了一种无绳薄型软体机器人（UTS-Robot），采用薄型介电弹性体驱动器（TS-DEA），在低电压（220V）下实现无绳驱动，适用于狭窄空间作业。


<details>
  <summary>Details</summary>
Motivation: 现有介电弹性体驱动器（DEA）软体机器人通常需要高电压和有线供电，限制了其在狭窄空间的应用。需要开发低电压、无绳的薄型软体机器人以适应受限环境。

Method: 采用双驱动夹层结构的TS-DEA，包含四个介电弹性体层和可压缩张力机制。通过旋涂法制备50微米厚弹性体层，再双轴拉伸至8微米以降低驱动电压。集成柔性板载电子实现无绳驱动，利用三个方向摩擦垫实现运动。

Result: 机器人尺寸38mm×6mm，重2.34g。TS-DEA在86Hz谐振频率下仅需220V驱动电压。裸TS-DEA运动速度达12.36mm/s，无绳配置下速度为0.5mm/s，适合狭窄复杂环境导航。

Conclusion: 成功开发了低电压、无绳的薄型软体机器人，通过优化的TS-DEA设计和制造工艺实现了在受限环境中的有效运动，为狭窄空间应用提供了新解决方案。

Abstract: Thin dielectric elastomer actuator (DEA) features a unique in-plane configuration, enabling low-profile designs capable of accessing millimetre-scale narrow spaces. However, most existing DEA-powered soft robots require high voltages and wired power connections, limiting their ability to operate in confined environments. This study presents an untethered thin soft robot (UTS-Robot) powered by thin dielectric elastomer actuators (TS-DEA). The robot measures 38 mm in length, 6 mm in height, and weighs just 2.34 grams, integrating flexible onboard electronics to achieve fully untethered actuation. The TS-DEA, operating at resonant frequencies of 86 Hz under a low driving voltage of 220 V, adopts a dual-actuation sandwiched structure, comprising four dielectric elastomer layers bonded to a compressible tensioning mechanism at its core. This design enables high power density actuation and locomotion via three directional friction pads. The low-voltage actuation is achieved by fabricating each elastomer layer via spin coating to an initial thickness of 50 um, followed by biaxial stretching to 8 um. A comprehensive design and modelling framework has been developed to optimise TS-DEA performance. Experimental evaluations demonstrate that the bare TS-DEA achieves a locomotion speed of 12.36 mm/s at resonance, the untethered configuration achieves a locomotion speed of 0.5 mm/s, making it highly suitable for navigating confined and complex environments.

</details>


### [76] [Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization](https://arxiv.org/abs/2512.17958)
*Farida Mohsen,Ali Safa*

Main category: cs.RO

TL;DR: 提出一个用于服务机器人实时理解人类行为意图的多模态框架，融合2D骨骼姿态和面部情感特征，在资源受限的嵌入式硬件上运行，并通过MINT-RVAE解决数据不平衡问题，在真实机器人部署中验证了跨传感器和跨环境的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 公共空间的服务机器人需要实时理解人类行为意图以实现自然交互。现有方法通常需要RGB-D传感器或GPU加速，不适合资源受限的嵌入式硬件，且自然人机交互数据集存在严重的类别不平衡问题。

Method: 提出一个多模态框架，从单目RGB视频中提取相机不变的2D骨骼姿态和面部情感特征，融合后进行意图检测。为解决数据不平衡问题，提出MINT-RVAE（多模态循环变分自编码器）来合成时间一致的姿态-情感-标签序列进行数据重平衡。框架在Raspberry Pi 5等CPU-only嵌入式硬件上运行。

Result: 离线评估在跨主体和跨场景协议下表现出强泛化性能，帧级和序列级AUROC达到0.95。在MIRA机器人头上进行跨相机真实世界验证（使用不同RGB传感器且环境未在训练数据中出现），部署系统在32次实时交互试验中达到91%准确率和100%召回率。

Conclusion: 提出的多模态方法在离线评估和实际部署性能之间表现出高度一致性，证实了其跨传感器和跨环境的鲁棒性，适合用于普遍存在的多媒体使能社交机器人。

Abstract: Service robots in public spaces require real-time understanding of human behavioral intentions for natural interaction. We present a practical multimodal framework for frame-accurate human-robot interaction intent detection that fuses camera-invariant 2D skeletal pose and facial emotion features extracted from monocular RGB video. Unlike prior methods requiring RGB-D sensors or GPU acceleration, our approach resource-constrained embedded hardware (Raspberry Pi 5, CPU-only). To address the severe class imbalance in natural human-robot interaction datasets, we introduce a novel approach to synthesize temporally coherent pose-emotion-label sequences for data re-balancing called MINT-RVAE (Multimodal Recurrent Variational Autoencoder for Intent Sequence Generation). Comprehensive offline evaluations under cross-subject and cross-scene protocols demonstrate strong generalization performance, achieving frame- and sequence-level AUROC of 0.95. Crucially, we validate real-world generalization through cross-camera evaluation on the MIRA robot head, which employs a different onboard RGB sensor and operates in uncontrolled environments not represented in the training data. Despite this domain shift, the deployed system achieves 91% accuracy and 100% recall across 32 live interaction trials. The close correspondence between offline and deployed performance confirms the cross-sensor and cross-environment robustness of the proposed multimodal approach, highlighting its suitability for ubiquitous multimedia-enabled social robots.

</details>


### [77] [Unifying Deep Predicate Invention with Pre-trained Foundation Models](https://arxiv.org/abs/2512.17992)
*Qianwei Wang,Bowen Li,Zhanpeng Luo,Yifan Xu,Alexander Gray,Tom Silver,Sebastian Scherer,Katia Sycara,Yaqi Xie*

Main category: cs.RO

TL;DR: UniPred：一个双层学习框架，统一了自上而下和自下而上的谓词学习方法，通过LLM提出谓词效果分布来监督神经网络从低级数据中学习谓词，同时利用学习反馈迭代优化LLM假设，在机器人任务中实现更高的成功率和更快的学习速度。


<details>
  <summary>Details</summary>
Motivation: 长时程机器人任务由于连续状态-动作空间和稀疏反馈而难以处理。符号世界模型通过将任务分解为捕捉对象属性和关系的离散谓词来帮助解决这一问题。现有方法要么自上而下（使用基础模型提示但缺乏数据基础），要么自下而上（从演示中学习但缺乏高级先验），两者都有局限性。

Method: UniPred采用双层学习框架：1）使用大型语言模型（LLM）提出谓词效果分布，这些分布监督从低级数据中学习神经谓词；2）学习到的反馈迭代优化LLM假设。利用强大的视觉基础模型特征在杂乱场景中学习鲁棒的谓词分类器。还提出了支持超越STRIPS假设的符号模型的谓词评估方法。

Result: 在五个模拟和一个真实机器人领域中，UniPred实现了比自上而下方法高2-4倍的成功率，比自下而上方法快3-4倍的学习速度。该方法推进了机器人领域可扩展和灵活的符号世界建模。

Conclusion: UniPred通过统一自上而下和自下而上的方法，实现了更高效和鲁棒的符号谓词学习，为机器人任务中的符号世界建模提供了可扩展且灵活的解决方案。

Abstract: Long-horizon robotic tasks are hard due to continuous state-action spaces and sparse feedback. Symbolic world models help by decomposing tasks into discrete predicates that capture object properties and relations. Existing methods learn predicates either top-down, by prompting foundation models without data grounding, or bottom-up, from demonstrations without high-level priors. We introduce UniPred, a bilevel learning framework that unifies both. UniPred uses large language models (LLMs) to propose predicate effect distributions that supervise neural predicate learning from low-level data, while learned feedback iteratively refines the LLM hypotheses. Leveraging strong visual foundation model features, UniPred learns robust predicate classifiers in cluttered scenes. We further propose a predicate evaluation method that supports symbolic models beyond STRIPS assumptions. Across five simulated and one real-robot domains, UniPred achieves 2-4 times higher success rates than top-down methods and 3-4 times faster learning than bottom-up approaches, advancing scalable and flexible symbolic world modeling for robotics.

</details>


### [78] [Robotic VLA Benefits from Joint Learning with Motion Image Diffusion](https://arxiv.org/abs/2512.18007)
*Yu Fang,Kanchana Ranasinghe,Le Xue,Honglu Zhou,Juntao Tan,Ran Xu,Shelby Heinecke,Caiming Xiong,Silvio Savarese,Daniel Szafir,Mingyu Ding,Michael S. Ryoo,Juan Carlos Niebles*

Main category: cs.RO

TL;DR: 提出了一种通过联合学习运动图像扩散来增强VLA模型运动推理能力的新方法，在保持推理延迟不变的同时显著提升了机器人操作性能


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action模型通常只是模仿专家轨迹，缺乏对动作的预测性运动推理能力，这限制了它们决定采取何种动作的能力

Method: 采用双头设计扩展VLA架构：动作头预测动作块，运动头使用扩散变换器预测基于光流的运动图像来捕捉未来动态。两个头联合训练，使共享的VLM骨干学习耦合机器人控制和运动知识的表示

Result: 在LIBERO基准测试中达到97.5%成功率，在RoboTwin基准测试中达到58.0%成功率，真实世界性能提升23%，验证了该方法在增强大规模VLA运动推理能力方面的有效性

Conclusion: 通过联合学习运动图像扩散，可以在不改变标准VLA推理路径的情况下，构建时间一致且物理基础的表示，显著提升VLA模型的运动推理能力和操作性能

Abstract: Vision-Language-Action (VLA) models have achieved remarkable progress in robotic manipulation by mapping multimodal observations and instructions directly to actions. However, they typically mimic expert trajectories without predictive motion reasoning, which limits their ability to reason about what actions to take. To address this limitation, we propose joint learning with motion image diffusion, a novel strategy that enhances VLA models with motion reasoning capabilities. Our method extends the VLA architecture with a dual-head design: while the action head predicts action chunks as in vanilla VLAs, an additional motion head, implemented as a Diffusion Transformer (DiT), predicts optical-flow-based motion images that capture future dynamics. The two heads are trained jointly, enabling the shared VLM backbone to learn representations that couple robot control with motion knowledge. This joint learning builds temporally coherent and physically grounded representations without modifying the inference pathway of standard VLAs, thereby maintaining test-time latency. Experiments in both simulation and real-world environments demonstrate that joint learning with motion image diffusion improves the success rate of pi-series VLAs to 97.5% on the LIBERO benchmark and 58.0% on the RoboTwin benchmark, yielding a 23% improvement in real-world performance and validating its effectiveness in enhancing the motion reasoning capability of large-scale VLAs.

</details>


### [79] [Embodied4C: Measuring What Matters for Embodied Vision-Language Navigation](https://arxiv.org/abs/2512.18028)
*Tin Stribor Sohn,Maximilian Dillitzer,Jason J. Corso,Eric Sax*

Main category: cs.RO

TL;DR: Embodied4C是一个用于评估视觉语言模型在具身推理能力的闭环基准测试，涵盖自动驾驶车辆、无人机和机械臂三种异构平台，通过1100个一次性推理问题和58个导航任务评估语义、空间、时间和物理推理四个维度。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试对具身性（物理平台、传感器配置和模态对齐）如何影响感知、推理和控制的理解有限，需要开发能够评估视觉语言模型在不同具身配置下核心推理能力的基准。

Method: 设计Embodied4C基准测试，包含三种异构具身平台（自动驾驶车辆、无人机、机械臂），通过1100个一次性推理问题和58个目标导向导航任务，评估语义、空间、时间和物理推理四个维度，并引入领域远查询以防止平台过拟合。

Result: 对10个最先进的视觉语言模型和4个具身控制基线的综合评估显示：跨模态对齐和指令调优比模型规模更重要，而空间和时间推理仍然是可靠具身能力的主要瓶颈。

Conclusion: Embodied4C基准测试揭示了视觉语言模型在具身推理中的关键限制，特别是空间和时间推理能力不足，为未来具身AI系统的发展提供了重要的评估框架和方向指导。

Abstract: Vision-language navigation requires agents to reason and act under constraints of embodiment. While vision-language models (VLMs) demonstrate strong generalization, current benchmarks provide limited understanding of how embodiment -- i.e., the choice of physical platform, sensor configuration, and modality alignment -- influences perception, reasoning, and control. We introduce Embodied4C, a closed-loop benchmark designed as a Turing test for embodied reasoning. The benchmark evaluates the core embodied capabilities of VLMs across three heterogeneous embodiments -- autonomous vehicles, aerial drones, and robotic manipulators -- through approximately 1.1K one-shot reasoning questions and 58 goal-directed navigation tasks. These tasks jointly assess four foundational dimensions: semantic, spatial, temporal, and physical reasoning. Each embodiment presents dynamic sensor configurations and environment variations to probe generalization beyond platform-specific adaptation. To prevent embodiment overfitting, Embodied4C integrates domain-far queries targeting abstract and cross-context reasoning. Comprehensive evaluation across ten state-of-the-art VLMs and four embodied control baselines shows that cross-modal alignment and instruction tuning matter more than scale, while spatial and temporal reasoning remains the primary bottleneck for reliable embodied competence.

</details>


### [80] [Design and Integration of Thermal and Vibrotactile Feedback for Lifelike Touch in Social Robots](https://arxiv.org/abs/2512.18032)
*Jacqueline Borgstedt,Jake Bhattacharyya,Matteo Iovino,Frank E. Pollick,Stephen Brewster*

Main category: cs.RO

TL;DR: 开发多模态触觉原型增强PARO机器人，通过热感和振动触觉模拟生物生理信号，提升社交辅助机器人的情感互动能力


<details>
  <summary>Details</summary>
Motivation: 当前拟动物社交辅助机器人（SARs）提供的触觉交互有限且被动，缺乏温暖、心跳或呼噜声等丰富的触觉线索，限制了其唤起情感参与和逼真物理互动的能力

Method: 开发了一个多模态触觉原型来增强PARO机器人，集成热反馈和振动触觉反馈来模拟生物生理信号。使用柔性加热界面提供身体般的温暖，嵌入式执行器产生心跳般的节奏和持续的呼噜感。这些线索通过用户和触觉专家的输入进行迭代设计和校准

Result: 提出了设计过程和可重复的指导方针，支持开发具有情感共鸣和生物学合理性的社交辅助机器人触觉交互

Conclusion: 通过集成热感和振动触觉反馈，可以显著增强拟动物社交辅助机器人的情感互动能力，使其能够提供更丰富、更逼真的触觉体验，从而更好地替代动物陪伴

Abstract: Zoomorphic Socially Assistive Robots (SARs) offer an alternative source of social touch for individuals who cannot access animal companionship. However, current SARs provide only limited, passive touch-based interactions and lack the rich haptic cues, such as warmth, heartbeat or purring, that are characteristic of human-animal touch. This limits their ability to evoke emotionally engaging, life-like physical interactions.
  We present a multimodal tactile prototype, which was used to augment the established PARO robot, integrating thermal and vibrotactile feedback to simulate feeling biophysiological signals. A flexible heating interface delivers body-like warmth, while embedded actuators generate heartbeat-like rhythms and continuous purring sensations. These cues were iteratively designed and calibrated with input from users and haptics experts. We outline the design process and offer reproducible guidelines to support the development of emotionally resonant and biologically plausible touch interactions with SARs.

</details>


### [81] [Design of a Polymer-based Steerable Cannula for Neurosurgical Applications](https://arxiv.org/abs/2512.18048)
*Nidhi Malhotra,Amber K. Rothe,Revanth Konda,Jaydev P. Desai*

Main category: cs.RO

TL;DR: 本文探索使用激光微加工技术制造聚酰亚胺机器人可转向套管，用于神经外科手术，最小外径可达1.5毫米


<details>
  <summary>Details</summary>
Motivation: 聚合物材料在机器人神经外科工具中具有优势：减少MRI干扰、增强电驱动仪器安全性、降低组织损伤。现有工具多采用不锈钢或镍钛合金，而激光微加工聚合物具有单步工艺、高精度、无需洁净室或强化学品的优点。

Method: 采用激光微加工技术制造聚酰亚胺可转向套管，将之前用于肌腱驱动刻痕管的方法扩展到聚酰亚胺材料。制造了多种不同外径的关节，最小外径为1.5毫米。

Result: 成功制造了最小外径1.5毫米的聚酰亚胺关节，并对制造关节的加载行为进行了实验表征。

Conclusion: 激光微加工技术可用于制造小型聚酰亚胺机器人可转向套管，为神经外科手术提供更安全、更灵活的器械选择。

Abstract: Robotically steerable compliant surgical tools offer several advantages over rigid tools, including enhanced dexterity, reduced tissue damage, and the ability to generate non-linear trajectories in minimally invasive neurosurgical procedures. Many existing robotic neurosurgical tools are designed using stainless steel or nitinol materials. Using polymer-based materials instead can offer advantages such as reduced interference in magnetic resonance imaging, enhanced safety for guiding electrically powered instruments, and reduced tissue damage due to inherent compliance. Several polymer materials have been used in robotic surgical applications, such as polyimide, polycarbonate, and elastic resin. Various fabrication strategies have also been proposed, including standard microfabrication techniques, thermal drawing, and 3-D printing. In our previous work, a tendon-driven, notched-tube was designed for several neurosurgical robotic tools, utilizing laser micromachining to reduce the stiffness of the tube in certain directions. This fabrication method is desirable because it has a single-step process, has high precision, and does not require a cleanroom or harsh chemicals. Past studies have explored laser-micromachining of polymer material for surgical applications such as stent fabrication. In this work, we explore extending the use of the laser micromachining approach to the fabrication of polyimide (PI) robotically steerable cannulas for neurosurgical applications. Utilizing the method presented in this work, we fabricated joints as small as 1.5 mm outer diameter (OD). Multiple joints were fabricated using PI tubes of different ODs, and the loading behavior of the fabricated joints was experimentally characterized.

</details>


### [82] [SurgiPose: Estimating Surgical Tool Kinematics from Monocular Video for Surgical Robot Learning](https://arxiv.org/abs/2512.18068)
*Juo-Tung Chen,XinHao Chen,Ji Woong Kim,Paul Maria Scheikl,Richard Jaepyeong Cha,Axel Krieger*

Main category: cs.RO

TL;DR: SurgiPose：一种基于可微分渲染的方法，从单目手术视频中估计运动学信息，无需真实运动学数据，为手术机器人学习提供大规模数据基础


<details>
  <summary>Details</summary>
Motivation: 模仿学习在自主灵巧操作中显示出巨大潜力，但临床数据集缺乏当前模仿学习方法所需的运动学数据。在线单目手术视频是大规模手术演示的潜在来源，因此需要从这些视频中估计运动学信息以支持大规模机器人学习

Method: 提出SurgiPose方法，基于可微分渲染估计工具轨迹和关节角度，通过优化工具姿态参数来最小化渲染图像与真实图像之间的差异，无需直接访问真实运动学数据

Result: 在两个机器人手术任务（组织提升和针拾取）上使用dVRK Si进行实验，使用视频估计的运动学训练的模仿学习策略与使用真实运动学数据训练的策略相比，取得了相当的成功率

Conclusion: 通过从单目手术视频中实现运动学估计，这项工作为从在线手术数据中大规模学习自主手术策略奠定了基础，证明了基于视频的运动学估计用于手术机器人学习的可行性

Abstract: Imitation learning (IL) has shown immense promise in enabling autonomous dexterous manipulation, including learning surgical tasks. To fully unlock the potential of IL for surgery, access to clinical datasets is needed, which unfortunately lack the kinematic data required for current IL approaches. A promising source of large-scale surgical demonstrations is monocular surgical videos available online, making monocular pose estimation a crucial step toward enabling large-scale robot learning. Toward this end, we propose SurgiPose, a differentiable rendering based approach to estimate kinematic information from monocular surgical videos, eliminating the need for direct access to ground truth kinematics. Our method infers tool trajectories and joint angles by optimizing tool pose parameters to minimize the discrepancy between rendered and real images. To evaluate the effectiveness of our approach, we conduct experiments on two robotic surgical tasks: tissue lifting and needle pickup, using the da Vinci Research Kit Si (dVRK Si). We train imitation learning policies with both ground truth measured kinematics and estimated kinematics from video and compare their performance. Our results show that policies trained on estimated kinematics achieve comparable success rates to those trained on ground truth data, demonstrating the feasibility of using monocular video based kinematic estimation for surgical robot learning. By enabling kinematic estimation from monocular surgical videos, our work lays the foundation for large scale learning of autonomous surgical policies from online surgical data.

</details>


### [83] [Towards Autonomous Navigation in Endovascular Interventions](https://arxiv.org/abs/2512.18081)
*Tudor Jianu,Anh Nguyen,Sebastiano Fichera,Pierre Berthet-Rayne*

Main category: cs.RO

TL;DR: 该论文提出一个AI驱动的自主导丝导航框架，包括高保真模拟平台CathSim、专家导航网络、开源数据集Guide3D和基于Transformer的SplineFormer模型，显著提升血管内导航的精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，当前血管内介入机器人系统存在启发式控制、自主性低、缺乏触觉反馈等限制，需要更精确、自适应的导航解决方案。

Method: 1. 开发高保真实时模拟平台CathSim用于强化学习训练；2. 提出融合视觉、运动学和力反馈的专家导航网络；3. 创建包含8,700多张标注图像的开源双平面透视数据集Guide3D；4. 设计基于Transformer的SplineFormer模型，直接预测B样条参数来表示导丝几何形状。

Result: 结合高保真模拟、多模态感知融合和几何建模，显著提升了自主血管内导航的性能，支持更安全、更精确的微创手术。

Conclusion: 该集成AI框架通过模拟平台、数据集和几何建模方法的创新，解决了血管内导航中的数据稀缺、模拟保真度和导航精度等关键挑战，为更安全、更精确的微创心血管介入治疗提供了技术支持。

Abstract: Cardiovascular diseases remain the leading cause of global mortality, with minimally invasive treatment options offered through endovascular interventions. However, the precision and adaptability of current robotic systems for endovascular navigation are limited by heuristic control, low autonomy, and the absence of haptic feedback. This thesis presents an integrated AI-driven framework for autonomous guidewire navigation in complex vascular environments, addressing key challenges in data availability, simulation fidelity, and navigational accuracy.
  A high-fidelity, real-time simulation platform, CathSim, is introduced for reinforcement learning based catheter navigation, featuring anatomically accurate vascular models and contact dynamics. Building on CathSim, the Expert Navigation Network is developed, a policy that fuses visual, kinematic, and force feedback for autonomous tool control. To mitigate data scarcity, the open-source, bi-planar fluoroscopic dataset Guide3D is proposed, comprising more than 8,700 annotated images for 3D guidewire reconstruction. Finally, SplineFormer, a transformer-based model, is introduced to directly predict guidewire geometry as continuous B-spline parameters, enabling interpretable, real-time navigation.
  The findings show that combining high-fidelity simulation, multimodal sensory fusion, and geometric modelling substantially improves autonomous endovascular navigation and supports safer, more precise minimally invasive procedures.

</details>


### [84] [On Swarm Leader Identification using Probing Policies](https://arxiv.org/abs/2512.18146)
*Stergios E. Bachoumas,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 论文提出iSLI问题，通过物理交互识别机器人群体中的领导者，使用POMDP和PPO训练探测策略，采用TGR+S5神经网络架构，在仿真和真实实验中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 在对抗性环境中识别机器人群体领导者至关重要，但领导者通常会隐藏身份以确保任务成功。现有方法可能无法有效处理这种隐蔽性，需要一种能够通过物理交互来识别领导者的新方法。

Method: 将iSLI问题建模为部分可观测马尔可夫决策过程(POMDP)，使用近端策略优化(PPO)训练探测策略。提出新颖的神经网络架构：时间图关系变换器(TGR)层结合简化结构化状态空间序列(S5)模型，有效处理群体图观测数据，捕捉时间依赖性和关系信息。

Result: TGR模型优于基线图神经网络架构，在零样本泛化方面表现显著，能够适应不同群体规模和速度。探测代理在识别领导者方面达到高准确率，即使在训练分布外场景中也能保持性能，预测置信度适当。真实机器人实验验证了方法的有效性，成功实现仿真到现实的迁移，对动态变化具有鲁棒性。

Conclusion: 提出的iSLI方法和TGR+S5架构能够有效识别机器人群体中的隐蔽领导者，具有优秀的泛化能力和鲁棒性，为对抗性环境中的群体分析提供了实用解决方案。

Abstract: Identifying the leader within a robotic swarm is crucial, especially in adversarial contexts where leader concealment is necessary for mission success. This work introduces the interactive Swarm Leader Identification (iSLI) problem, a novel approach where an adversarial probing agent identifies a swarm's leader by physically interacting with its members. We formulate the iSLI problem as a Partially Observable Markov Decision Process (POMDP) and employ Deep Reinforcement Learning, specifically Proximal Policy Optimization (PPO), to train the prober's policy. The proposed approach utilizes a novel neural network architecture featuring a Timed Graph Relationformer (TGR) layer combined with a Simplified Structured State Space Sequence (S5) model. The TGR layer effectively processes graph-based observations of the swarm, capturing temporal dependencies and fusing relational information using a learned gating mechanism to generate informative representations for policy learning. Extensive simulations demonstrate that our TGR-based model outperforms baseline graph neural network architectures and exhibits significant zero-shot generalization capabilities across varying swarm sizes and speeds different from those used during training. The trained prober achieves high accuracy in identifying the leader, maintaining performance even in out-of-training distribution scenarios, and showing appropriate confidence levels in its predictions. Real-world experiments with physical robots further validate the approach, confirming successful sim-to-real transfer and robustness to dynamic changes, such as unexpected agent disconnections.

</details>


### [85] [Alternating Minimization for Time-Shifted Synergy Extraction in Human Hand Coordination](https://arxiv.org/abs/2512.18206)
*Trevor Stepp,Parthan Olikkal,Ramana Vinjamuri,Rajasekhar Anguluri*

Main category: cs.RO

TL;DR: 提出一种优化框架，直接从单个数据集联合学习少量运动协同模式及其稀疏激活系数，无需两阶段方法和多个数据集。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段方法需要至少两个数据集，先提取候选波形再选择时移模板，数据收集复杂。需要更高效的单数据集方法。

Method: 提出优化框架，联合学习少量协同模式及其稀疏激活系数，通过组稀疏性选择协同，元素级稀疏性控制激活时序。采用交替最小化方法，系数更新在任务间解耦，协同更新简化为正则化最小二乘问题。

Result: 仿真实验显示能够准确重建速度，获得紧凑且可解释的协同模式。方法仅需单个数据集。

Conclusion: 提出的框架简化了运动协同识别流程，仅需单个数据集即可获得准确、紧凑、可解释的协同模式，优于现有两阶段方法。

Abstract: Identifying motor synergies -- coordinated hand joint patterns activated at task-dependent time shifts -- from kinematic data is central to motor control and robotics. Existing two-stage methods first extract candidate waveforms (via SVD) and then select shifted templates using sparse optimization, requiring at least two datasets and complicating data collection. We introduce an optimization-based framework that jointly learns a small set of synergies and their sparse activation coefficients. The formulation enforces group sparsity for synergy selection and element-wise sparsity for activation timing. We develop an alternating minimization method in which coefficient updates decouple across tasks and synergy updates reduce to regularized least-squares problems. Our approach requires only a single data set, and simulations show accurate velocity reconstruction with compact, interpretable synergies.

</details>


### [86] [LLaViDA: A Large Language Vision Driving Assistant for Explicit Reasoning and Enhanced Trajectory Planning](https://arxiv.org/abs/2512.18211)
*Yudong Liu,Spencer Hallyburton,Jiwoo Kim,Yueqian Lin,Yiming Li,Qinsi Wang,Hui Ye,Jingwei Sun,Miroslav Pajic,Yiran Chen,Hai Li*

Main category: cs.RO

TL;DR: LLaViDA是一个基于视觉语言模型的自动驾驶轨迹规划系统，通过两阶段训练（监督微调+轨迹偏好优化）提升场景理解和轨迹规划能力，在NuScenes基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有端到端规划器在恶劣天气、不可预测的人类行为或复杂道路布局下表现不佳，主要原因是缺乏超出训练数据的强泛化或小样本能力。

Method: 提出LLaViDA系统，利用视觉语言模型进行物体运动预测、语义接地和思维链推理进行轨迹规划。采用两阶段训练：监督微调后接轨迹偏好优化，注入基于回归的监督。

Result: 在NuScenes基准测试中，LLaViDA在开环轨迹规划任务上超越了最先进的端到端和其他基于VLM/LLM的基线方法，平均L2轨迹误差为0.31米，碰撞率为0.10%。

Conclusion: LLaViDA通过结合视觉语言模型的推理能力和两阶段优化训练，为自动驾驶轨迹规划提供了一个强大的解决方案，显著提升了泛化能力和规划性能。

Abstract: Trajectory planning is a fundamental yet challenging component of autonomous driving. End-to-end planners frequently falter under adverse weather, unpredictable human behavior, or complex road layouts, primarily because they lack strong generalization or few-shot capabilities beyond their training data. We propose LLaViDA, a Large Language Vision Driving Assistant that leverages a Vision-Language Model (VLM) for object motion prediction, semantic grounding, and chain-of-thought reasoning for trajectory planning in autonomous driving. A two-stage training pipeline--supervised fine-tuning followed by Trajectory Preference Optimization (TPO)--enhances scene understanding and trajectory planning by injecting regression-based supervision, produces a powerful "VLM Trajectory Planner for Autonomous Driving." On the NuScenes benchmark, LLaViDA surpasses state-of-the-art end-to-end and other recent VLM/LLM-based baselines in open-loop trajectory planning task, achieving an average L2 trajectory error of 0.31 m and a collision rate of 0.10% on the NuScenes test set. The code for this paper is available at GitHub.

</details>


### [87] [Fractional-order Modeling for Nonlinear Soft Actuators via Particle Swarm Optimization](https://arxiv.org/abs/2512.18213)
*Wu-Te Yang,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出基于分数阶微分方程和粒子群优化的软体气动执行器建模框架，实现高精度动态行为预测


<details>
  <summary>Details</summary>
Motivation: 软体气动执行器具有高度非线性和柔顺特性，传统建模方法精度不足，需要更精确的建模框架

Method: 使用分数阶微分方程建立模型，通过粒子群优化从实验数据中直接识别未知参数，不依赖材料数据库或经验本构定律

Result: 实验验证了模型的准确性和鲁棒性，相比传统建模技术提高了预测性能

Conclusion: 该框架为软体执行器建模提供了数据高效且不依赖数据库的解决方案，提升了软体机器人系统设计的精度和适应性

Abstract: Modeling soft pneumatic actuators with high precision remains a fundamental challenge due to their highly nonlinear and compliant characteristics. This paper proposes an innovative modeling framework based on fractional-order differential equations (FODEs) to accurately capture the dynamic behavior of soft materials. The unknown parameters within the fractional-order model are identified using particle swarm optimization (PSO), enabling parameter estimation directly from experimental data without reliance on pre-established material databases or empirical constitutive laws. The proposed approach effectively represents the complex deformation phenomena inherent in soft actuators. Experimental results validate the accuracy and robustness of the developed model, demonstrating improvement in predictive performance compared to conventional modeling techniques. The presented framework provides a data-efficient and database-independent solution for soft actuator modeling, advancing the precision and adaptability of soft robotic system design.

</details>


### [88] [On The Computational Complexity for Minimizing Aerial Photographs for Full Coverage of a Planar Region](https://arxiv.org/abs/2512.18268)
*Si Wei Feng*

Main category: cs.RO

TL;DR: 本文研究无人机航拍覆盖问题的计算复杂性，证明多数此类问题在计算上是难解的，传统算法无法高效求解


<details>
  <summary>Details</summary>
Motivation: 随着无人机技术普及，航拍在环境监测、结构检查、执法等场景广泛应用。核心挑战是如何在图像分辨率、拍摄数量等约束下高效覆盖目标区域

Method: 将航拍问题抽象为计算几何中的覆盖问题，分析多个基础问题的计算复杂性

Result: 证明大多数航拍覆盖问题在计算上是难解的（computationally intractable），传统算法无法高效求解

Conclusion: 研究结果不仅适用于航拍，还可扩展到农药喷洒、战略传感器部署等更广泛的应用领域

Abstract: With the popularity of drone technologies, aerial photography have become prevalent in many daily scenarios such as environment monitoring, structure inspection, law enforcement etc. A central challenge in this domain is the efficient coverage of a target area with photographs that can entirely capture the region, while respecting constraints such as the image resolution, and limited number of pictures that can be taken. This work investigates the computational complexity of several fundamental problems arised from this challenge. By abstracting the aerial photography problem into the coverage problems in computational geometry, we demonstrate that most of these problems are in fact computationally intractable, with the implication that traditional algorithms cannot solve them efficiently. The intuitions of this work can extend beyond aerial photography to broader applications such as pesticide spraying, and strategic sensor placement.

</details>


### [89] [Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)](https://arxiv.org/abs/2512.18333)
*Youssef Mahran,Zeyad Gamal,Ayman El-Badawy*

Main category: cs.RO

TL;DR: 提出基于强化学习的四旋翼推力矢量控制架构，相比传统RPM控制训练更快、路径跟踪更平滑准确


<details>
  <summary>Details</summary>
Motivation: 现有文献主要关注直接控制四个旋翼的RPM，本文旨在控制四旋翼的推力矢量，以改进控制性能

Method: 使用Soft Actor-Critic算法训练RL智能体，智能体计算沿z轴的总推力百分比以及期望的滚转和俯仰角，结合当前偏航角发送给姿态PID控制器，PID控制器将控制信号映射到电机RPM

Result: 训练结果显示推力矢量控制器比传统RPM控制器训练时间更快，仿真结果显示路径跟踪更平滑准确

Conclusion: 提出的基于强化学习的推力矢量控制架构在四旋翼控制中具有优势，训练效率更高且控制性能更好

Abstract: This paper proposes a new Reinforcement Learning (RL) based control architecture for quadrotors. With the literature focusing on controlling the four rotors' RPMs directly, this paper aims to control the quadrotor's thrust vector. The RL agent computes the percentage of overall thrust along the quadrotor's z-axis along with the desired Roll ($φ$) and Pitch ($θ$) angles. The agent then sends the calculated control signals along with the current quadrotor's Yaw angle ($ψ$) to an attitude PID controller. The PID controller then maps the control signals to motor RPMs. The Soft Actor-Critic algorithm, a model-free off-policy stochastic RL algorithm, was used to train the RL agents. Training results show the faster training time of the proposed thrust vector controller in comparison to the conventional RPM controllers. Simulation results show smoother and more accurate path-following for the proposed thrust vector controller.

</details>


### [90] [Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism](https://arxiv.org/abs/2512.18336)
*Youssef Mahran,Zeyad Gamal,Ayman El-Badawy*

Main category: cs.RO

TL;DR: 研究探索了强化学习中动态熵调节对训练随机策略的影响，并与确定性策略训练算法进行比较，在四旋翼无人机控制任务中验证了动态熵调节能防止灾难性遗忘并提高探索效率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是比较随机策略和确定性策略在强化学习中的表现差异，特别关注动态熵调节对随机策略训练效果的影响，以解决四旋翼无人机控制中的探索效率和稳定性问题。

Method: 采用Soft Actor-Critic (SAC)算法训练随机策略，使用Twin Delayed Deep Deterministic Policy Gradient (TD3)算法训练确定性策略。在随机策略训练中，比较了静态熵和动态熵调节的效果，并在四旋翼无人机控制任务中进行仿真实验。

Result: 训练和仿真结果显示，动态熵调节在四旋翼无人机控制中具有积极效果，能够防止灾难性遗忘并提高探索效率。随机策略与确定性策略在控制性能上表现出差异，动态熵调节优化了随机策略的训练过程。

Conclusion: 动态熵调节在强化学习随机策略训练中具有重要价值，特别是在复杂控制任务如四旋翼无人机控制中，能有效平衡探索与利用，防止灾难性遗忘，提高算法性能。

Abstract: This paper explores the impact of dynamic entropy tuning in Reinforcement Learning (RL) algorithms that train a stochastic policy. Its performance is compared against algorithms that train a deterministic one. Stochastic policies optimize a probability distribution over actions to maximize rewards, while deterministic policies select a single deterministic action per state. The effect of training a stochastic policy with both static entropy and dynamic entropy and then executing deterministic actions to control the quadcopter is explored. It is then compared against training a deterministic policy and executing deterministic actions. For the purpose of this research, the Soft Actor-Critic (SAC) algorithm was chosen for the stochastic algorithm while the Twin Delayed Deep Deterministic Policy Gradient (TD3) was chosen for the deterministic algorithm. The training and simulation results show the positive effect the dynamic entropy tuning has on controlling the quadcopter by preventing catastrophic forgetting and improving exploration efficiency.

</details>


### [91] [Learning Semantic Atomic Skills for Multi-Task Robotic Manipulation](https://arxiv.org/abs/2512.18368)
*Yihang Zhu,Weiqing Wang,Shijie Wu,Ye Shi,Jingya Wang*

Main category: cs.RO

TL;DR: AtomSkill：一种新颖的多任务模仿学习框架，通过学习结构化原子技能空间实现可组合的机器人操作，解决了现有技能方法在语义一致性和跨任务泛化方面的限制。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在单任务机器人操作中表现优异，但在多任务设置中存在挑战，包括次优演示、轨迹噪声和行为多模态问题。现有技能方法依赖固定长度分割或环境先验，限制了语义一致性和跨任务泛化能力。

Method: 1. 构建语义基础的原子技能库：使用夹持器状态关键帧检测和视觉语言模型标注，将演示分割为变长技能；对比学习确保技能嵌入的语义一致性和时间连贯性。2. 动作生成模块：通过关键姿态想象联合预测技能的长期终端关键姿态和即时动作序列，使策略能够同时推理整体运动目标和精细控制。

Result: 在模拟和真实环境中的大量实验表明，AtomSkill在各种操作任务中始终优于最先进的方法。

Conclusion: AtomSkill通过学习结构化原子技能空间，实现了可组合的机器人操作，解决了多任务模仿学习中的关键挑战，在语义一致性和跨任务泛化方面表现出色。

Abstract: While imitation learning has shown impressive results in single-task robot manipulation, scaling it to multi-task settings remains a fundamental challenge due to issues such as suboptimal demonstrations, trajectory noise, and behavioral multi-modality. Existing skill-based methods attempt to address this by decomposing actions into reusable abstractions, but they often rely on fixed-length segmentation or environmental priors that limit semantic consistency and cross-task generalization. In this work, we propose AtomSkill, a novel multi-task imitation learning framework that learns and leverages a structured Atomic Skill Space for composable robot manipulation. Our approach is built on two key technical contributions. First, we construct a Semantically Grounded Atomic Skill Library by partitioning demonstrations into variable-length skills using gripper-state keyframe detection and vision-language model annotation. A contrastive learning objective ensures the resulting skill embeddings are both semantically consistent and temporally coherent. Second, we propose an Action Generation module with Keypose Imagination, which jointly predicts a skill's long-horizon terminal keypose and its immediate action sequence. This enables the policy to reason about overarching motion goals and fine-grained control simultaneously, facilitating robust skill chaining. Extensive experiments in simulated and real-world environments show that AtomSkill consistently outperforms state-of-the-art methods across diverse manipulation tasks.

</details>


### [92] [AOMGen: Photoreal, Physics-Consistent Demonstration Generation for Articulated Object Manipulation](https://arxiv.org/abs/2512.18396)
*Yulu Wu,Jiujun Cheng,Haowen Wang,Dengyang Suo,Pei Ren,Qichao Mao,Shangce Gao,Yakun Huang*

Main category: cs.RO

TL;DR: AOMGen框架通过单次真实扫描和演示，结合数字资产库，生成用于关节物体精细操作的多样化训练数据，显著提升VLA策略性能


<details>
  <summary>Details</summary>
Motivation: 当前VLA和世界模型方法需要大量昂贵的真实演示数据，特别是在关节物体精细操作任务中，这限制了方法的可扩展性

Method: 提出AOMGen框架：从单次真实扫描和演示出发，结合数字资产库，生成具有物理状态验证的逼真训练数据，包含多视角RGB、动作指令、关节状态和接触标注，并系统性地变化相机视角、物体风格和姿态

Result: 在AOMGen数据上微调的VLA策略成功率从0%提升到88.7%，并且在未见过的物体和布局上表现出良好的泛化能力

Conclusion: AOMGen提供了一种可扩展的数据生成方法，显著减少了关节物体操作任务对大量真实演示数据的依赖，有效提升了VLA策略的性能和泛化能力

Abstract: Recent advances in Vision-Language-Action (VLA) and world-model methods have improved generalization in tasks such as robotic manipulation and object interaction. However, Successful execution of such tasks depends on large, costly collections of real demonstrations, especially for fine-grained manipulation of articulated objects. To address this, we present AOMGen, a scalable data generation framework for articulated manipulation which is instantiated from a single real scan, demonstration and a library of readily available digital assets, yielding photoreal training data with verified physical states. The framework synthesizes synchronized multi-view RGB temporally aligned with action commands and state annotations for joints and contacts, and systematically varies camera viewpoints, object styles, and object poses to expand a single execution into a diverse corpus. Experimental results demonstrate that fine-tuning VLA policies on AOMGen data increases the success rate from 0% to 88.7%, and the policies are tested on unseen objects and layouts.

</details>


### [93] [When Robots Say No: The Empathic Ethical Disobedience Benchmark](https://arxiv.org/abs/2512.18474)
*Dmytro Kuzmenko,Nadiya Shvai*

Main category: cs.RO

TL;DR: EED Gym是一个标准化测试平台，用于评估机器人拒绝行为的安全性和社会可接受性，通过权衡风险、情感和信任来决定服从、拒绝、澄清或提出更安全替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习基准主要关注物理危险，而人机交互信任研究规模小且难以复现。机器人需要在服从与安全/社会期望之间取得平衡，盲目服从可能造成伤害，过度拒绝则会破坏信任。

Method: 提出Empathic Ethical Disobedience (EED) Gym测试平台，包含不同场景、多个人格配置文件，以及基于小插曲研究的安全、校准和拒绝指标，并建立信任和责备模型。

Result: 动作屏蔽能消除不安全服从，解释性拒绝有助于维持信任；建设性风格最值得信赖，共情风格最具共情力；安全RL方法提高鲁棒性但也会导致过度谨慎行为。

Conclusion: EED Gym为拒绝和信任研究提供了可复现的评估框架，促进系统性人机交互研究，并承诺开源代码、配置和参考策略。

Abstract: Robots must balance compliance with safety and social expectations as blind obedience can cause harm, while over-refusal erodes trust. Existing safe reinforcement learning (RL) benchmarks emphasize physical hazards, while human-robot interaction trust studies are small-scale and hard to reproduce. We present the Empathic Ethical Disobedience (EED) Gym, a standardized testbed that jointly evaluates refusal safety and social acceptability. Agents weigh risk, affect, and trust when choosing to comply, refuse (with or without explanation), clarify, or propose safer alternatives. EED Gym provides different scenarios, multiple persona profiles, and metrics for safety, calibration, and refusals, with trust and blame models grounded in a vignette study. Using EED Gym, we find that action masking eliminates unsafe compliance, while explanatory refusals help sustain trust. Constructive styles are rated most trustworthy, empathic styles -- most empathic, and safe RL methods improve robustness but also make agents more prone to overly cautious behavior. We release code, configurations, and reference policies to enable reproducible evaluation and systematic human-robot interaction research on refusal and trust. At submission time, we include an anonymized reproducibility package with code and configs, and we commit to open-sourcing the full repository after the paper is accepted.

</details>


### [94] [STORM: Search-Guided Generative World Models for Robotic Manipulation](https://arxiv.org/abs/2512.18477)
*Wenjun Lin,Jensen Zhang,Kaitong Cai,Keze Wang*

Main category: cs.RO

TL;DR: STORM是一个用于机器人操作时空推理的新框架，结合了扩散动作生成、条件视频预测和搜索规划，在SimperEnv基准测试中达到51.0%的平均成功率，创下新纪录。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型依赖抽象潜在动态或将推理委托给语言组件，缺乏明确的视觉推演。需要一种能够进行可解释、有远见的决策的规划方法。

Method: STORM框架包含三个核心组件：1) 扩散式VLA策略生成多样化候选动作；2) 生成式视频世界模型模拟视觉和奖励结果；3) 蒙特卡洛树搜索通过前瞻评估选择性优化规划。

Result: 在SimperEnv操作基准测试中达到51.0%的平均成功率，优于CogACT等强基线。奖励增强的视频预测将Frechet视频距离降低超过75%，显著提高了时空保真度和任务相关性。

Conclusion: STORM展示了搜索引导的生成式世界模型在长时程机器人操作中的优势，具有强大的重新规划和故障恢复能力，为可解释的时空推理提供了新方向。

Abstract: We present STORM (Search-Guided Generative World Models), a novel framework for spatio-temporal reasoning in robotic manipulation that unifies diffusion-based action generation, conditional video prediction, and search-based planning. Unlike prior Vision-Language-Action (VLA) models that rely on abstract latent dynamics or delegate reasoning to language components, STORM grounds planning in explicit visual rollouts, enabling interpretable and foresight-driven decision-making. A diffusion-based VLA policy proposes diverse candidate actions, a generative video world model simulates their visual and reward outcomes, and Monte Carlo Tree Search (MCTS) selectively refines plans through lookahead evaluation. Experiments on the SimplerEnv manipulation benchmark demonstrate that STORM achieves a new state-of-the-art average success rate of 51.0 percent, outperforming strong baselines such as CogACT. Reward-augmented video prediction substantially improves spatio-temporal fidelity and task relevance, reducing Frechet Video Distance by over 75 percent. Moreover, STORM exhibits robust re-planning and failure recovery behavior, highlighting the advantages of search-guided generative world models for long-horizon robotic manipulation.

</details>


### [95] [Systematic Benchmarking of SUMO Against Data-Driven Traffic Simulators](https://arxiv.org/abs/2512.18537)
*Erdao Liang*

Main category: cs.RO

TL;DR: SUMO交通仿真器在Waymo数据集上的系统性基准测试显示，其模型驱动方法在长时程稳定性方面优于数据驱动方法，同时参数更少


<details>
  <summary>Details</summary>
Motivation: 对模型驱动的微观交通仿真器SUMO与最先进的数据驱动交通仿真器进行系统性比较，评估两者在自动驾驶仿真中的互补优势

Method: 开发Waymo2SUMO自动化管道将WOMD场景转换为SUMO仿真，在WOSAC基准上评估短时程（8秒）和长时程（60秒）闭环仿真性能

Result: SUMO在WOSAC基准上获得0.653的真实性元指标，仅需少于100个可调参数，在长时程仿真中表现出更低的碰撞和偏离道路率，稳定性优于数据驱动方法

Conclusion: 模型驱动和数据驱动方法在自动驾驶仿真和基准测试中具有互补优势，SUMO展示了模型驱动方法在长时程稳定性和参数效率方面的优势

Abstract: This paper presents a systematic benchmarking of the model-based microscopic traffic simulator SUMO against state-of-the-art data-driven traffic simulators using large-scale real-world datasets. Using the Waymo Open Motion Dataset (WOMD) and the Waymo Open Sim Agents Challenge (WOSAC), we evaluate SUMO under both short-horizon (8s) and long-horizon (60s) closed-loop simulation settings. To enable scalable evaluation, we develop Waymo2SUMO, an automated pipeline that converts WOMD scenarios into SUMO simulations. On the WOSAC benchmark, SUMO achieves a realism meta metric of 0.653 while requiring fewer than 100 tunable parameters. Extended rollouts show that SUMO maintains low collision and offroad rates and exhibits stronger long-horizon stability than representative data-driven simulators. These results highlight complementary strengths of model-based and data-driven approaches for autonomous driving simulation and benchmarking.

</details>


### [96] [Offline Reinforcement Learning for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.18662)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.RO

TL;DR: 提出一个仅使用摄像头的端到端离线强化学习框架，通过行为正则化提升自动驾驶安全性，相比模仿学习基线显著降低碰撞率并提高路线完成率。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶模型虽然计算效率高且具有统一优化的泛化潜力，但依赖模仿学习存在持续失败模式。在线强化学习可以缓解这些问题，但基于神经渲染的仿真和大规模端到端网络导致迭代调优成本高昂。

Method: 提出仅使用摄像头的端到端离线强化学习框架，不进行额外探索，仅使用固定仿真数据集训练。通过从专家驾驶日志构建伪真实轨迹作为行为正则化信号，抑制不安全或次优行为模仿，同时稳定价值学习。

Result: 在从nuScenes数据集学习的神经渲染环境中进行训练和闭环评估，相比模仿学习基线在碰撞率和路线完成率方面取得显著改进。

Conclusion: 离线强化学习结合行为正则化能够有效解决端到端自动驾驶中的模仿学习问题，提供数据高效且实验迭代快速的解决方案，显著提升驾驶安全性。

Abstract: End-to-end (E2E) autonomous driving models that take only camera images as input and directly predict a future trajectory are appealing for their computational efficiency and potential for improved generalization via unified optimization; however, persistent failure modes remain due to reliance on imitation learning (IL). While online reinforcement learning (RL) could mitigate IL-induced issues, the computational burden of neural rendering-based simulation and large E2E networks renders iterative reward and hyperparameter tuning costly. We introduce a camera-only E2E offline RL framework that performs no additional exploration and trains solely on a fixed simulator dataset. Offline RL offers strong data efficiency and rapid experimental iteration, yet is susceptible to instability from overestimation on out-of-distribution (OOD) actions. To address this, we construct pseudo ground-truth trajectories from expert driving logs and use them as a behavior regularization signal, suppressing imitation of unsafe or suboptimal behavior while stabilizing value learning. Training and closed-loop evaluation are conducted in a neural rendering environment learned from the public nuScenes dataset. Empirically, the proposed method achieves substantial improvements in collision rate and route completion compared with IL baselines. Our code will be available at [URL].

</details>


### [97] [CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles](https://arxiv.org/abs/2512.18703)
*Cailin Lei,Haiyang Wu,Yuxiong Ji,Xiaoyu Cai,Yuchuan Du*

Main category: cs.RO

TL;DR: 提出一种融合因果先验知识的轨迹规划框架，通过因果推断量化车辆交互风险，并嵌入MPC控制器，使自动驾驶轨迹更贴近人类驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹规划模型大多未融入人类驾驶员的先验知识，在混合交通环境中难以实现类人驾驶行为，需要更智能的规划方法。

Method: 建立车辆微观行为模型量化交互风险，构建分阶段因果图捕捉换道场景的因果依赖，使用因果推断估计平均因果效应和条件平均处理效应，将因果先验嵌入MPC框架。

Result: 因果推断提供可解释的交互量化，揭示驾驶员异质性；相比基线MPC，最大轨迹偏差从1.2m降至0.2m，横向速度波动减少60%，横摆角变异性降低50%。

Conclusion: 融合因果先验的轨迹规划能显著提升自动驾驶的类人化程度，为安全、稳定、真实的自动驾驶测试和交通仿真提供方法支持。

Abstract: Enhancing the performance of trajectory planners for lane - changing vehicles is one of the key challenges in autonomous driving within human - machine mixed traffic. Most existing studies have not incorporated human drivers' prior knowledge when designing trajectory planning models. To address this issue, this study proposes a novel trajectory planning framework that integrates causal prior knowledge into the control process. Both longitudinal and lateral microscopic behaviors of vehicles are modeled to quantify interaction risk, and a staged causal graph is constructed to capture causal dependencies in lane-changing scenarios. Causal effects between the lane-changing vehicle and surrounding vehicles are then estimated using causal inference, including average causal effects (ATE) and conditional average treatment effects (CATE). These causal priors are embedded into a model predictive control (MPC) framework to enhance trajectory planning. The proposed approach is validated on naturalistic vehicle trajectory datasets. Experimental results show that: (1) causal inference provides interpretable and stable quantification of vehicle interactions; (2) individual causal effects reveal driver heterogeneity; and (3) compared with the baseline MPC, the proposed method achieves a closer alignment with human driving behaviors, reducing maximum trajectory deviation from 1.2 m to 0.2 m, lateral velocity fluctuation by 60%, and yaw angle variability by 50%. These findings provide methodological support for human-like trajectory planning and practical value for improving safety, stability, and realism in autonomous vehicle testing and traffic simulation platforms.

</details>


### [98] [DSO-VSA: a Variable Stiffness Actuator with Decoupled Stiffness and Output Characteristics for Rehabilitation Robotics](https://arxiv.org/abs/2512.18712)
*Maozeng Zhang,Ke Shi,Huijun Li,Tongshu Chen,Jiejun Yan,Aiguo Song*

Main category: cs.RO

TL;DR: 提出一种用于康复机器人的解耦刚度与输出的变刚度驱动器，采用可变长度杠杆与内摆线直线机构实现线性扭矩-偏转关系，结合差动传动实现双电机负载共享。


<details>
  <summary>Details</summary>
Motivation: 中风导致的运动障碍常造成上肢功能严重丧失，需要安全透明的物理人机交互康复机器人。现有变刚度驱动器通常刚度与偏转角耦合，使建模和控制复杂化。

Method: 设计解耦刚度与输出行为的变刚度驱动器：1) 可变长度杠杆与内摆线直线机构组合实现线性扭矩-偏转关系和连续刚度调节；2) 基于行星齿轮系统的差动传动机制实现双电机负载共享；3) 开发基于差动配置的级联PI控制器。

Result: 通过刚度校准、刚度调节、扭矩控制、解耦特性和双电机负载共享等实验验证了原型性能，表明该驱动器适用于康复外骨骼和其他物理人机交互系统。

Conclusion: 该变刚度驱动器成功实现了刚度与输出的解耦，具有线性扭矩-偏转关系和连续刚度调节能力，为康复机器人提供了更安全透明的物理人机交互解决方案。

Abstract: Stroke-induced motor impairment often results in substantial loss of upper-limb function, creating a strong demand for rehabilitation robots that enable safe and transparent physical human-robot interaction (pHRI). Variable stiffness actuators are well suited for such applications. However, in most existing designs, stiffness is coupled with the deflection angle, complicating both modeling and control. To address this limitation, this paper presents a variable stiffness actuator featuring decoupled stiffness and output behavior for rehabilitation robotics. The system integrates a variable stiffness mechanism that combines a variable-length lever with a hypocycloidal straight-line mechanism to achieve a linear torque-deflection relationship and continuous stiffness modulation from near zero to theoretically infinite. It also incorporates a differential transmission mechanism based on a planetary gear system that enables dual-motor load sharing. A cascade PI controller is further developed on the basis of the differential configuration, in which the position-loop term jointly regulates stiffness and deflection angle, effectively suppressing stiffness fluctuations and output disturbances. The performance of prototype was experimentally validated through stiffness calibration, stiffness regulation, torque control, decoupled characteristics, and dual-motor load sharing, indicating the potential for rehabilitation exoskeletons and other pHRI systems.

</details>


### [99] [Multimodal Classification Network Guided Trajectory Planning for Four-Wheel Independent Steering Autonomous Parking Considering Obstacle Attributes](https://arxiv.org/abs/2512.18836)
*Jingjia Teng,Yang Li,Jianqiang Wang,Yingbai Hu,Songyuan Tang,Manjiang Hu*

Main category: cs.RO

TL;DR: 提出一个结合4WIS混合A*和最优控制问题的轨迹规划框架，通过多模态分类评估场景复杂度，设计分层障碍物处理策略（可穿越/可压过障碍），并引入概率风险场处理动态障碍，提升四轮独立转向车辆在狭窄环境中的路径规划成功率。


<details>
  <summary>Details</summary>
Motivation: 现有规划器忽略障碍物属性（如低矮障碍物可穿越或压过），导致四轮独立转向车辆在狭窄空间中规划效率低下或失败，需要更智能的障碍物处理策略来提升导航能力。

Method: 1) 多模态分类网络融合图像和车辆状态评估场景复杂度；2) 4WIS混合A*算法结合多种转向模式（阿克曼、对角、零转向）；3) 分层障碍物处理策略（不可穿越、可穿越、可压过）；4) 概率风险场模型处理动态障碍不确定性；5) 最优控制问题生成平滑轨迹。

Result: 实验结果表明该框架能生成安全、高效、平滑的轨迹，特别是在受限环境中显著提高了路径规划的成功率，相比传统"仅避让"策略有显著改进。

Conclusion: 提出的框架通过智能障碍物属性处理和动态障碍风险建模，有效解决了4WIS车辆在复杂环境中的轨迹规划问题，为自动驾驶在狭窄空间中的导航提供了实用解决方案。

Abstract: Four-wheel Independent Steering (4WIS) vehicles have attracted increasing attention for their superior maneuverability. Human drivers typically choose to cross or drive over the low-profile obstacles (e.g., plastic bags) to efficiently navigate through narrow spaces, while existing planners neglect obstacle attributes, causing inefficiency or path-finding failures. To address this, we propose a trajectory planning framework integrating the 4WIS hybrid A* and Optimal Control Problem (OCP), in which the hybrid A* provides an initial path to enhance the OCP solution. Specifically, a multimodal classification network is introduced to assess scene complexity (hard/easy task) by fusing image and vehicle state data. For hard tasks, guided points are set to decompose complex tasks into local subtasks, improving the search efficiency of 4WIS hybrid A*. The multiple steering modes of 4WIS vehicles (Ackermann, diagonal, and zero-turn) are also incorporated into node expansion and heuristic designs. Moreover, a hierarchical obstacle handling strategy is designed to guide the node expansion considering obstacle attributes, i.e., 'non-traversable', 'crossable', and 'drive-over' obstacles. It allows crossing or driving over obstacles instead of the 'avoid-only' strategy, greatly enhancing success rates of pathfinding. We also design a logical constraint for the 'drive-over' obstacle by limiting its velocity to ensure safety. Furthermore, to address dynamic obstacles with motion uncertainty, we introduce a probabilistic risk field model, constructing risk-aware driving corridors that serve as linear collision constraints in OCP. Experimental results demonstrate the proposed framework's effectiveness in generating safe, efficient, and smooth trajectories for 4WIS vehicles, especially in constrained environments.

</details>


### [100] [InDRiVE: Reward-Free World-Model Pretraining for Autonomous Driving via Latent Disagreement](https://arxiv.org/abs/2512.18850)
*Feeza Khan Khanzada,Jaerock Kwon*

Main category: cs.RO

TL;DR: InDRiVE使用基于潜在集成分歧的内在动机进行无奖励预训练，通过DreamerV3风格的世界模型学习探索策略，在CARLA中实现零样本迁移和少样本适应，提升自动驾驶的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于模型的强化学习通常依赖难以设计且对分布偏移敏感的任务特定奖励。本文旨在通过内在动机进行无奖励预训练，构建可重用的驾驶世界模型，减少对外部奖励的依赖。

Method: 提出InDRiVE，采用DreamerV3风格的MBRL代理，使用潜在集成分歧作为内在动机进行无奖励预训练。分歧作为认知不确定性的代理，驱动智能体探索未充分探索的驾驶情境。通过基于想象的actor-critic直接从学习的世界模型中学习无规划器的探索策略。

Result: 在CARLA的不同城镇、路线和交通密度下实验表明，基于分歧的预训练在零样本鲁棒性和少样本碰撞避免方面表现更强。在城镇转移和相同交互预算下，该方法展现出更好的适应能力。

Conclusion: 内在分歧可作为实用的无奖励预训练信号，用于构建可重用的驾驶世界模型。该方法支持零样本迁移和少样本适应，为自动驾驶的鲁棒性提供了有效解决方案。

Abstract: Model-based reinforcement learning (MBRL) can reduce interaction cost for autonomous driving by learning a predictive world model, but it typically still depends on task-specific rewards that are difficult to design and often brittle under distribution shift. This paper presents InDRiVE, a DreamerV3-style MBRL agent that performs reward-free pretraining in CARLA using only intrinsic motivation derived from latent ensemble disagreement. Disagreement acts as a proxy for epistemic uncertainty and drives the agent toward under-explored driving situations, while an imagination-based actor-critic learns a planner-free exploration policy directly from the learned world model. After intrinsic pretraining, we evaluate zero-shot transfer by freezing all parameters and deploying the pretrained exploration policy in unseen towns and routes. We then study few-shot adaptation by training a task policy with limited extrinsic feedback for downstream objectives (lane following and collision avoidance). Experiments in CARLA across towns, routes, and traffic densities show that disagreement-based pretraining yields stronger zero-shot robustness and robust few-shot collision avoidance under town shift and matched interaction budgets, supporting the use of intrinsic disagreement as a practical reward-free pretraining signal for reusable driving world models.

</details>


### [101] [Construction and deformation of P-hedra using control polylines](https://arxiv.org/abs/2512.18869)
*Georg Nawratil*

Main category: cs.RO

TL;DR: 本文研究P-hedra（P-nets）的交互式设计方法，通过三条控制折线直接控制空间形状，适用于可变形设计任务


<details>
  <summary>Details</summary>
Motivation: 在之前的研究中引入了P-hedra这类连续柔性离散曲面，但需要进一步研究其直观的交互设计方法，使其更适合可变形设计任务

Method: 使用三条控制折线直接控制P-hedra的空间形状，开发交互式工具，研究等距变形的高效算法计算，分析弯曲极限、分叉配置、可展/可平折模式及管状P-hedra

Result: 建立了P-hedra的交互设计框架，实现了通过控制折线直观控制曲面形状的方法，开发了高效计算等距变形的算法，并系统分析了各种特殊配置

Conclusion: P-hedra通过三条控制折线的交互设计方法，为可变形设计提供了有效的工具，其构造方法也可用于高效计算等距变形，具有广泛的应用前景

Abstract: In the 19th International Symposium on Advances in Robot Kinematics the author introduced a novel class of continuous flexible discrete surfaces and mentioned that these so-called P-hedra (or P-nets) allow direct access to their spatial shapes by three control polylines. In this follow-up paper we study this intuitive method, which makes these flexible planar quad surfaces suitable for transformable design tasks by means of interactive tools. The construction of P-hedra from the control polylines can also be used for an efficient algorithmic computation of their isometric deformations. In addition we discuss flexion limits, bifurcation configurations, developable/flat-foldable pattern and tubular P-hedra.

</details>


### [102] [Optimizing Robotic Placement via Grasp-Dependent Feasibility Prediction](https://arxiv.org/abs/2512.18922)
*Tianyuan Liu,Richard Dazeley,Benjamin Champion,Akan Cosgun*

Main category: cs.RO

TL;DR: 使用廉价的无物理监督学习来优先选择抓取-放置候选方案，通过几何标签训练MLP模型，在固定规划预算下更快找到成功路径


<details>
  <summary>Details</summary>
Motivation: 研究是否可以通过廉价、无物理仿真的监督来可靠地优先选择抓取-放置候选方案，以降低预算感知的拾取-放置任务成本

Method: 从物体初始位姿、目标位姿和候选抓取生成两种路径感知几何标签：基于固定路径模板的逆运动学可行性，以及沿相同模板的网格扫描碰撞检测。使用紧凑的双输出MLP学习这些信号，在测试时用其分数对预计算候选方案进行排序，采用"先排序再规划"策略

Result: 尽管仅从廉价标签学习，但分数能够迁移到物理启用的执行轨迹：在固定规划预算下，策略能更快找到成功路径，减少规划器调用次数，同时保持或提高最终成功率

Conclusion: 廉价的无物理监督学习可以有效优先选择抓取-放置候选方案，该方法针对单个刚性长方体设计，但可扩展到多样物体和更丰富的路径方案

Abstract: In this paper, we study whether inexpensive, physics-free supervision can reliably prioritize grasp-place candidates for budget-aware pick-and-place. From an object's initial pose, target pose, and a candidate grasp, we generate two path-aware geometric labels: path-wise inverse kinematics (IK) feasibility across a fixed approach-grasp-lift waypoint template, and a transit collision flag from mesh sweeps along the same template. A compact dual-output MLP learns these signals from pose encodings, and at test time its scores rank precomputed candidates for a rank-then-plan policy under the same IK gate and planner as the baseline. Although learned from cheap labels only, the scores transfer to physics-enabled executed trajectories: at a fixed planning budget the policy finds successful paths sooner with fewer planner calls while keeping final success on par or better. This work targets a single rigid cuboid with side-face grasps and a fixed waypoint template, and we outline extensions to varied objects and richer waypoint schemes.

</details>


### [103] [A Framework for Deploying Learning-based Quadruped Loco-Manipulation](https://arxiv.org/abs/2512.18938)
*Yadong Liu,Jianwei Liu,He Liang,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: 提出一个用于四足移动机械臂RL控制的开源训练、基准测试和部署流水线，支持从仿真到仿真再到真实硬件的统一迁移。


<details>
  <summary>Details</summary>
Motivation: 四足移动机械臂在敏捷的移动操作方面潜力巨大，但控制困难且难以从仿真可靠迁移到现实。现有RL框架多为专有且难以在真实硬件上复现。

Method: 开发了一个开源流水线，通过ROS统一仿真到仿真和仿真到现实的迁移。在Isaac Gym中训练策略，通过硬件抽象层扩展到MuJoCo，并在真实硬件上部署相同控制器。

Result: 仿真到仿真实验揭示了Isaac Gym和MuJoCo接触模型的差异对策略行为的影响；真实世界遥控物体拾取试验显示协调全身控制相比浮动基座基线扩展了可达范围并改进了操作性能。

Conclusion: 该流水线为开发和分析基于RL的移动操作控制器提供了透明、可复现的基础，将开源发布以支持未来研究。

Abstract: Quadruped mobile manipulators offer strong potential for agile loco-manipulation but remain difficult to control and transfer reliably from simulation to reality. Reinforcement learning (RL) shows promise for whole-body control, yet most frameworks are proprietary and hard to reproduce on real hardware. We present an open pipeline for training, benchmarking, and deploying RL-based controllers on the Unitree B1 quadruped with a Z1 arm. The framework unifies sim-to-sim and sim-to-real transfer through ROS, re-implementing a policy trained in Isaac Gym, extending it to MuJoCo via a hardware abstraction layer, and deploying the same controller on physical hardware. Sim-to-sim experiments expose discrepancies between Isaac Gym and MuJoCo contact models that influence policy behavior, while real-world teleoperated object-picking trials show that coordinated whole-body control extends reach and improves manipulation over floating-base baselines. The pipeline provides a transparent, reproducible foundation for developing and analyzing RL-based loco-manipulation controllers and will be released open source to support future research.

</details>


### [104] [Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation](https://arxiv.org/abs/2512.18987)
*Ryosuke Korekata,Quanting Xie,Yonatan Bisk,Komei Sugiura*

Main category: cs.RO

TL;DR: 提出Affordance RAG框架，通过构建Affordance-Aware Embodied Memory实现零样本开放词汇移动操作，在真实环境中达到85%任务成功率


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇移动操作问题，机器人需要根据自然语言指令将各种物体运送到容器中，这需要理解视觉语义和操作动作的可用性

Method: 提出Affordance RAG框架，从预探索图像构建Affordance-Aware Embodied Memory，通过区域和视觉语义检索候选目标，然后用可用性分数重新排序

Result: 在大规模室内环境中移动操作指令检索性能优于现有方法，真实世界实验中基于自由形式指令的任务成功率达到85%

Conclusion: Affordance RAG框架有效解决了开放词汇移动操作问题，通过结合语义理解和可用性评估，显著提升了机器人在真实环境中的操作性能

Abstract: In this study, we address the problem of open-vocabulary mobile manipulation, where a robot is required to carry a wide range of objects to receptacles based on free-form natural language instructions. This task is challenging, as it involves understanding visual semantics and the affordance of manipulation actions. To tackle these challenges, we propose Affordance RAG, a zero-shot hierarchical multimodal retrieval framework that constructs Affordance-Aware Embodied Memory from pre-explored images. The model retrieves candidate targets based on regional and visual semantics and reranks them with affordance scores, allowing the robot to identify manipulation options that are likely to be executable in real-world environments. Our method outperformed existing approaches in retrieval performance for mobile manipulation instruction in large-scale indoor environments. Furthermore, in real-world experiments where the robot performed mobile manipulation in indoor environments based on free-form instructions, the proposed method achieved a task success rate of 85%, outperforming existing methods in both retrieval performance and overall task success.

</details>


### [105] [DTCCL: Disengagement-Triggered Contrastive Continual Learning for Autonomous Bus Planners](https://arxiv.org/abs/2512.18988)
*Yanding Yang,Weitao Zhou,Jinhai Wang,Xiaomin Guo,Junze Wen,Xiaolong Liu,Lang Ding,Zheng Fu,Jinyu Miao,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: DTCCL框架通过触发式对比持续学习，利用自动驾驶巴士脱钩事件数据改进规划策略，相比直接重训练提升48.6%性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶巴士在固定路线上运行，但在开放动态城市环境中常出现脱钩事件，这些事件通常集中在特定地理区域，源于高度交互区域的规划器失败。传统的模仿学习难以纠正此类策略级失败，容易对稀疏的脱钩数据过拟合。

Method: 提出脱钩触发对比持续学习(DTCCL)框架：1) 每次脱钩触发云端数据增强，通过扰动周围智能体生成正负样本，同时保持路线上下文；2) 使用对比学习优化策略表示，更好区分安全与不安全行为；3) 在云-边循环中持续更新，无需人工监督。

Result: 在城市巴士路线实验中，DTCCL相比直接重训练将整体规划性能提升48.6%，验证了其在自动驾驶公共交通中可扩展、闭环策略改进的有效性。

Conclusion: DTCCL框架能够有效利用自动驾驶巴士在真实运营中的脱钩事件数据，通过对比持续学习改进规划策略，为自动驾驶公共交通提供了可扩展的闭环策略改进方案。

Abstract: Autonomous buses run on fixed routes but must operate in open, dynamic urban environments. Disengagement events on these routes are often geographically concentrated and typically arise from planner failures in highly interactive regions. Such policy-level failures are difficult to correct using conventional imitation learning, which easily overfits to sparse disengagement data. To address this issue, this paper presents a Disengagement-Triggered Contrastive Continual Learning (DTCCL) framework that enables autonomous buses to improve planning policies through real-world operation. Each disengagement triggers cloud-based data augmentation that generates positive and negative samples by perturbing surrounding agents while preserving route context. Contrastive learning refines policy representations to better distinguish safe and unsafe behaviors, and continual updates are applied in a cloud-edge loop without human supervision. Experiments on urban bus routes demonstrate that DTCCL improves overall planning performance by 48.6 percent compared with direct retraining, validating its effectiveness for scalable, closed-loop policy improvement in autonomous public transport.

</details>


### [106] [IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments](https://arxiv.org/abs/2512.19024)
*Xu Liu,Yu Liu,Hanshuo Qiu,Yang Qirong,Zhouhui Lian*

Main category: cs.RO

TL;DR: 提出了IndoorUAV基准和方法，专门针对室内无人机视觉语言导航，包含长视野VLN和短视野VLA两个子集，并设计了相应的导航代理模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航研究主要关注地面机器人或室外无人机，而室内无人机VLN研究不足，尽管在检查、递送、搜救等实际应用中具有重要价值。

Method: 1) 从Habitat模拟器收集1000多个多样化的3D室内场景；2) 模拟真实无人机飞行动态收集轨迹；3) 设计自动标注流水线生成多粒度自然语言指令；4) 将长轨迹分割为语义关键帧形成子轨迹；5) 提出IndoorUAV-Agent导航模型，利用任务分解和多模态推理。

Result: 创建了包含16000多个高质量轨迹的IndoorUAV-VLN子集（长视野导航）和IndoorUAV-VLA子集（短视野规划），为室内无人机视觉语言导航提供了首个专门基准。

Conclusion: IndoorUAV填补了室内无人机视觉语言导航研究的空白，为视觉语言具身AI在室内空中导航领域的发展提供了宝贵资源。

Abstract: Vision-Language Navigation (VLN) enables agents to navigate in complex environments by following natural language instructions grounded in visual observations. Although most existing work has focused on ground-based robots or outdoor Unmanned Aerial Vehicles (UAVs), indoor UAV-based VLN remains underexplored, despite its relevance to real-world applications such as inspection, delivery, and search-and-rescue in confined spaces. To bridge this gap, we introduce \textbf{IndoorUAV}, a novel benchmark and method specifically tailored for VLN with indoor UAVs. We begin by curating over 1,000 diverse and structurally rich 3D indoor scenes from the Habitat simulator. Within these environments, we simulate realistic UAV flight dynamics to collect diverse 3D navigation trajectories manually, further enriched through data augmentation techniques. Furthermore, we design an automated annotation pipeline to generate natural language instructions of varying granularity for each trajectory. This process yields over 16,000 high-quality trajectories, comprising the \textbf{IndoorUAV-VLN} subset, which focuses on long-horizon VLN. To support short-horizon planning, we segment long trajectories into sub-trajectories by selecting semantically salient keyframes and regenerating concise instructions, forming the \textbf{IndoorUAV-VLA} subset. Finally, we introduce \textbf{IndoorUAV-Agent}, a novel navigation model designed for our benchmark, leveraging task decomposition and multimodal reasoning. We hope IndoorUAV serves as a valuable resource to advance research on vision-language embodied AI in the indoor aerial navigation domain.

</details>


### [107] [EGM: Efficiently Learning General Motion Tracking Policy for High Dynamic Humanoid Whole-Body Control](https://arxiv.org/abs/2512.19043)
*Chao Yang,Yingkai Sun,Peng Ye,Xin Chen,Chong Yu,Tao Chen*

Main category: cs.RO

TL;DR: EGM框架通过动态课程采样、复合解耦专家混合架构和三阶段课程训练，仅用4.08小时数据就能高效学习通用运动跟踪策略，在49.25小时测试中超越基线


<details>
  <summary>Details</summary>
Motivation: 传统方法在数据利用和训练效率上不足，且在跟踪高动态运动时性能有限。需要一种能高效学习通用运动跟踪策略的框架

Method: 提出EGM框架，包含四个核心设计：1) 基于箱的跨运动课程自适应采样策略，根据运动难度动态调整采样概率；2) 复合解耦专家混合架构，分别处理上下半身运动，解耦专用和通用特征；3) 强调数据质量和多样性；4) 三阶段课程训练流程，逐步增强策略对扰动的鲁棒性

Result: 仅用4.08小时数据训练，在49.25小时测试运动中表现出强大的泛化能力，在常规和高动态任务上均优于基线方法

Conclusion: EGM框架通过创新的采样策略、架构设计和训练流程，实现了高效学习通用运动跟踪策略，解决了传统方法在数据利用效率和动态运动跟踪方面的局限性

Abstract: Learning a general motion tracking policy from human motions shows great potential for versatile humanoid whole-body control. Conventional approaches are not only inefficient in data utilization and training processes but also exhibit limited performance when tracking highly dynamic motions. To address these challenges, we propose EGM, a framework that enables efficient learning of a general motion tracking policy. EGM integrates four core designs. Firstly, we introduce a Bin-based Cross-motion Curriculum Adaptive Sampling strategy to dynamically orchestrate the sampling probabilities based on tracking error of each motion bin, eficiently balancing the training process across motions with varying dificulty and durations. The sampled data is then processed by our proposed Composite Decoupled Mixture-of-Experts (CDMoE) architecture, which efficiently enhances the ability to track motions from different distributions by grouping experts separately for upper and lower body and decoupling orthogonal experts from shared experts to separately handle dedicated features and general features. Central to our approach is a key insight we identified: for training a general motion tracking policy, data quality and diversity are paramount. Building on these designs, we develop a three-stage curriculum training flow to progressively enhance the policy's robustness against disturbances. Despite training on only 4.08 hours of data, EGM generalized robustly across 49.25 hours of test motions, outperforming baselines on both routine and highly dynamic tasks.

</details>


### [108] [CoDrone: Autonomous Drone Navigation Assisted by Edge and Cloud Foundation Models](https://arxiv.org/abs/2512.19083)
*Pengyu Chen,Tao Ouyang,Ke Luo,Weijie Hong,Xu Chen*

Main category: cs.RO

TL;DR: CoDrone：首个将基础模型集成到无人机自主巡航场景的云-边-端协同计算框架，通过灰度图像、深度估计和强化学习调度器，在资源受限条件下提升导航性能


<details>
  <summary>Details</summary>
Motivation: 无人机自主导航面临机载计算资源有限的关键挑战，浅层神经网络难以处理复杂环境，而将任务卸载到远程边缘服务器又会引入高延迟，需要在系统设计中权衡

Method: 1) 使用灰度图像减少机载计算和数据传输开销；2) 利用边缘辅助基础模型Depth Anything V2进行深度估计；3) 提出新颖的一维占据栅格导航方法；4) 基于深度强化学习的神经调度器整合深度估计与导航决策；5) 引入无人机专用视觉语言交互模块，包含领域定制的低级飞行原语

Result: 在不同飞行速度和网络条件下，CoDrone优于基线方法，平均飞行距离增加40%，平均导航质量提升5%

Conclusion: CoDrone通过云-边-端协同计算框架，有效利用基础模型增强资源受限无人机平台的性能，实现了细粒度场景理解与自主导航效率的平衡

Abstract: Autonomous navigation for Unmanned Aerial Vehicles faces key challenges from limited onboard computational resources, which restrict deployed deep neural networks to shallow architectures incapable of handling complex environments. Offloading tasks to remote edge servers introduces high latency, creating an inherent trade-off in system design. To address these limitations, we propose CoDrone - the first cloud-edge-end collaborative computing framework integrating foundation models into autonomous UAV cruising scenarios - effectively leveraging foundation models to enhance performance of resource-constrained unmanned aerial vehicle platforms. To reduce onboard computation and data transmission overhead, CoDrone employs grayscale imagery for the navigation model. When enhanced environmental perception is required, CoDrone leverages the edge-assisted foundation model Depth Anything V2 for depth estimation and introduces a novel one-dimensional occupancy grid-based navigation method - enabling fine-grained scene understanding while advancing efficiency and representational simplicity of autonomous navigation. A key component of CoDrone is a Deep Reinforcement Learning-based neural scheduler that seamlessly integrates depth estimation with autonomous navigation decisions, enabling real-time adaptation to dynamic environments. Furthermore, the framework introduces a UAV-specific vision language interaction module incorporating domain-tailored low-level flight primitives to enable effective interaction between the cloud foundation model and the UAV. The introduction of VLM enhances open-set reasoning capabilities in complex unseen scenarios. Experimental results show CoDrone outperforms baseline methods under varying flight speeds and network conditions, achieving a 40% increase in average flight distance and a 5% improvement in average Quality of Navigation.

</details>


### [109] [WorldRFT: Latent World Model Planning with Reinforcement Fine-Tuning for Autonomous Driving](https://arxiv.org/abs/2512.19133)
*Pengxuan Yang,Ben Lu,Zhongpu Xia,Chao Han,Yinfeng Gao,Teng Zhang,Kun Zhan,XianPeng Lang,Yupeng Zheng,Qichao Zhang*

Main category: cs.RO

TL;DR: WorldRFT是一个面向规划的潜在世界模型框架，通过分层规划分解和局部感知交互优化机制，将场景表示学习与规划对齐，并使用强化学习微调提升安全关键策略性能，在自动驾驶任务中达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在世界模型通过时间自监督学习增强场景表示，但重建导向的表示学习将感知与规划任务纠缠在一起，导致规划优化不理想。需要解决感知与规划任务解耦的问题，使场景表示学习更好地服务于规划任务。

Method: 1. 集成视觉几何基础模型提升3D空间感知能力；2. 采用分层规划任务分解指导表示优化；3. 使用局部感知迭代优化机制推导面向规划的驾驶策略；4. 引入Group Relative Policy Optimization（GRPO）进行强化学习微调，包含轨迹高斯化和碰撞感知奖励。

Result: 在nuScenes数据集上碰撞率降低83%（0.30%→0.05%）；在NavSim基准测试中，仅使用摄像头传感器输入就达到了与基于LiDAR的SOTA方法DiffusionDrive相当的性能（87.8 vs. 88.1 PDMS）。

Conclusion: WorldRFT通过规划导向的潜在世界模型框架，成功将场景表示学习与规划任务对齐，显著提升了自动驾驶系统的安全性和性能，在多个基准测试中达到最先进水平。

Abstract: Latent World Models enhance scene representation through temporal self-supervised learning, presenting a perception annotation-free paradigm for end-to-end autonomous driving. However, the reconstruction-oriented representation learning tangles perception with planning tasks, leading to suboptimal optimization for planning. To address this challenge, we propose WorldRFT, a planning-oriented latent world model framework that aligns scene representation learning with planning via a hierarchical planning decomposition and local-aware interactive refinement mechanism, augmented by reinforcement learning fine-tuning (RFT) to enhance safety-critical policy performance. Specifically, WorldRFT integrates a vision-geometry foundation model to improve 3D spatial awareness, employs hierarchical planning task decomposition to guide representation optimization, and utilizes local-aware iterative refinement to derive a planning-oriented driving policy. Furthermore, we introduce Group Relative Policy Optimization (GRPO), which applies trajectory Gaussianization and collision-aware rewards to fine-tune the driving policy, yielding systematic improvements in safety. WorldRFT achieves state-of-the-art (SOTA) performance on both open-loop nuScenes and closed-loop NavSim benchmarks. On nuScenes, it reduces collision rates by 83% (0.30% -> 0.05%). On NavSim, using camera-only sensors input, it attains competitive performance with the LiDAR-based SOTA method DiffusionDrive (87.8 vs. 88.1 PDMS).

</details>


### [110] [A Flexible Field-Based Policy Learning Framework for Diverse Robotic Systems and Sensors](https://arxiv.org/abs/2512.19148)
*Jose Gustavo Buenaventura Carreon,Floris Erich,Roman Mykhailyshyn,Tomohiro Motoda,Ryo Hanai,Yukiyasu Domae*

Main category: cs.RO

TL;DR: 提出跨机器人视觉运动学习框架，结合扩散策略控制与3D语义场景表示，实现类别级泛化操作，支持多种机器人配置，在抓取任务中仅需100次演示即可达到80%成功率


<details>
  <summary>Details</summary>
Motivation: 解决跨机器人平台和感知模态的技能迁移问题，实现可扩展的真实世界跨机器人泛化研究

Method: 模块化设计整合扩散策略控制与D3Fields的3D语义场景表示，支持多种机器人相机配置，通过低延迟控制堆栈和直观遥操作实现灵活数据收集

Result: 在抓取和举起积木任务中，仅需100次演示即可达到80%成功率，展示了平台间和感知模态间的稳健技能迁移

Conclusion: 该框架为可扩展的真实世界跨机器人泛化研究铺平了道路，模块化设计支持灵活配置切换

Abstract: We present a cross robot visuomotor learning framework that integrates diffusion policy based control with 3D semantic scene representations from D3Fields to enable category level generalization in manipulation. Its modular design supports diverse robot camera configurations including UR5 arms with Microsoft Azure Kinect arrays and bimanual manipulators with Intel RealSense sensors through a low latency control stack and intuitive teleoperation. A unified configuration layer enables seamless switching between setups for flexible data collection training and evaluation. In a grasp and lift block task the framework achieved an 80 percent success rate after only 100 demonstration episodes demonstrating robust skill transfer between platforms and sensing modalities. This design paves the way for scalable real world studies in cross robotic generalization.

</details>


### [111] [Vision-Language-Policy Model for Dynamic Robot Task Planning](https://arxiv.org/abs/2512.19178)
*Jin Wang,Kim Tien Ly,Jacques Cloete,Nikos Tsagarakis,Ioannis Havoutis*

Main category: cs.RO

TL;DR: 提出基于视觉语言模型的动态机器人任务规划框架VLP，能够理解语义指令、推理任务场景并生成行为策略，支持动态调整以适应任务变化。


<details>
  <summary>Details</summary>
Motivation: 传统机器人任务规划方法难以弥合低级执行与高级任务推理之间的鸿沟，且无法在执行过程中动态更新任务策略，限制了机器人在非结构化环境中的适应性和多功能性。

Method: 提出Vision-Language-Policy (VLP)模型，基于在真实世界数据上微调的视觉语言模型，能够解释语义指令并整合当前任务场景的推理，生成控制机器人完成任务的行为策略。

Result: 在不同机器人和多种真实世界任务上的实验表明，训练后的模型能有效适应新场景并动态更新策略，展现出强大的规划自主性和跨具身泛化能力。

Conclusion: VLP框架通过结合视觉语言模型与机器人控制，实现了动态任务规划，为机器人在非结构化环境中执行复杂任务提供了更灵活、适应性更强的解决方案。

Abstract: Bridging the gap between natural language commands and autonomous execution in unstructured environments remains an open challenge for robotics. This requires robots to perceive and reason over the current task scene through multiple modalities, and to plan their behaviors to achieve their intended goals. Traditional robotic task-planning approaches often struggle to bridge low-level execution with high-level task reasoning, and cannot dynamically update task strategies when instructions change during execution, which ultimately limits their versatility and adaptability to new tasks. In this work, we propose a novel language model-based framework for dynamic robot task planning. Our Vision-Language-Policy (VLP) model, based on a vision-language model fine-tuned on real-world data, can interpret semantic instructions and integrate reasoning over the current task scene to generate behavior policies that control the robot to accomplish the task. Moreover, it can dynamically adjust the task strategy in response to changes in the task, enabling flexible adaptation to evolving task requirements. Experiments conducted with different robots and a variety of real-world tasks show that the trained model can efficiently adapt to novel scenarios and dynamically update its policy, demonstrating strong planning autonomy and cross-embodiment generalization. Videos: https://robovlp.github.io/

</details>


### [112] [Translating Flow to Policy via Hindsight Online Imitation](https://arxiv.org/abs/2512.19269)
*Yitian Zheng,Zhangchen Ye,Weijun Dong,Shengjie Wang,Yuyang Liu,Chongjie Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: HinFlow通过在线交互改进低级策略，使用后见之明重标注收集的经验来更新目标条件模仿策略，在机器人操作任务中实现2倍以上性能提升。


<details>
  <summary>Details</summary>
Motivation: 分层机器人系统中，高级规划器可以在无动作数据上训练，但将高级计划落地为可执行动作仍然困难，尤其是在高质量机器人数据有限的情况下。

Method: 提出HinFlow方法：收集在线轨迹，后见之明地从已实现结果中标注相应高级目标，聚合这些重标注经验来更新目标条件模仿策略，使用2D点流作为高级规划器。

Result: 在仿真和物理世界的多样化操作任务中，相比基础策略实现2倍以上性能提升，显著优于现有方法，并能从跨具身视频数据训练的规划器中获取策略。

Conclusion: 该方法通过在线交互改进低级策略，展示了可扩展和可迁移的机器人学习潜力，能够利用跨具身视频数据训练的规划器。

Abstract: Recent advances in hierarchical robot systems leverage a high-level planner to propose task plans and a low-level policy to generate robot actions. This design allows training the planner on action-free or even non-robot data sources (e.g., videos), providing transferable high-level guidance. Nevertheless, grounding these high-level plans into executable actions remains challenging, especially with the limited availability of high-quality robot data. To this end, we propose to improve the low-level policy through online interactions. Specifically, our approach collects online rollouts, retrospectively annotates the corresponding high-level goals from achieved outcomes, and aggregates these hindsight-relabeled experiences to update a goal-conditioned imitation policy. Our method, Hindsight Flow-conditioned Online Imitation (HinFlow), instantiates this idea with 2D point flows as the high-level planner. Across diverse manipulation tasks in both simulation and physical world, our method achieves more than $2\times$ performance improvement over the base policy, significantly outperforming the existing methods. Moreover, our framework enables policy acquisition from planners trained on cross-embodiment video data, demonstrating its potential for scalable and transferable robot learning.

</details>


### [113] [Are All Data Necessary? Efficient Data Pruning for Large-scale Autonomous Driving Dataset via Trajectory Entropy Maximization](https://arxiv.org/abs/2512.19270)
*Zhaoyang Liu,Weitao Zhou,Junze Wen,Cheng Jing,Qian Cheng,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: 提出基于信息论的自动驾驶数据剪枝方法，通过最大化轨迹熵选择高价值样本，减少40%数据量而不影响模型性能


<details>
  <summary>Details</summary>
Motivation: 现实世界自动驾驶数据集中存在大量重复和低价值样本，导致存储成本过高且对策略学习帮助有限，需要高效的数据管理方法

Method: 基于信息论的数据剪枝方法，评估驾驶数据的轨迹分布信息熵，以模型无关的方式迭代选择高价值样本，保持原始数据集的统计特性

Result: 在NuPlan基准测试中，使用大规模模仿学习框架验证，该方法能减少40%数据集大小，同时保持闭环性能不变

Conclusion: 为自动驾驶系统提供了轻量级且理论基础的扩展数据管理和高效策略学习方法

Abstract: Collecting large-scale naturalistic driving data is essential for training robust autonomous driving planners. However, real-world datasets often contain a substantial amount of repetitive and low-value samples, which lead to excessive storage costs and bring limited benefits to policy learning. To address this issue, we propose an information-theoretic data pruning method that effectively reduces the training data volume without compromising model performance. Our approach evaluates the trajectory distribution information entropy of driving data and iteratively selects high-value samples that preserve the statistical characteristics of the original dataset in a model-agnostic manner. From a theoretical perspective, we show that maximizing trajectory entropy effectively constrains the Kullback-Leibler divergence between the pruned subset and the original data distribution, thereby maintaining generalization ability. Comprehensive experiments on the NuPlan benchmark with a large-scale imitation learning framework demonstrate that the proposed method can reduce the dataset size by up to 40% while maintaining closed-loop performance. This work provides a lightweight and theoretically grounded approach for scalable data management and efficient policy learning in autonomous driving systems.

</details>


### [114] [Comparison and Evaluation of Different Simulation Environments for Rigid Body Systems](https://arxiv.org/abs/2512.19289)
*Longxiang Shao,Ulrich Dahmen,Juergen Rossmann*

Main category: cs.RO

TL;DR: 该研究比较了四种多体动力学仿真环境（Adams、Simscape、OpenModelica、VEROSIM），重点关注建模方法、数值求解器以及对闭环运动学中数值问题的处理，以真实林业机械的起重机臂作为基准案例。


<details>
  <summary>Details</summary>
Motivation: 多体动力学仿真器在机械系统的设计、分析和优化中至关重要，但不同仿真工具在建模方法、数值求解和问题处理方面存在差异，需要系统比较以帮助用户选择合适的工具。

Method: 研究采用对比分析方法，以真实林业机械的复杂起重机臂作为基准应用案例，系统比较四种仿真环境（Adams、Simscape、OpenModelica、VEROSIM）在建模方法、数值求解器以及对闭环运动学中冗余边界条件和静力平衡问题等数值问题的处理方式。

Result: 通过直接比较不同仿真工具中的解决方案方法，研究揭示了各工具在处理复杂闭环运动学问题时的特点和差异，为用户选择最适合其应用的仿真工具提供了依据。

Conclusion: 不同多体动力学仿真工具在处理复杂机械系统时各有特点，特别是对闭环运动学中数值问题的处理方式不同，用户应根据具体应用需求选择最合适的仿真环境。

Abstract: Rigid body dynamics simulators are important tools for the design, analysis and optimization of mechanical systems in a variety of technical and scientific applications. This study examines four different simulation environments (Adams, Simscape, OpenModelica, and VEROSIM), focusing in particular on the comparison of the modeling methods, the numerical solvers, and the treatment of numerical problems that arise especially in closed-loop kinematics (esp. redundant boundary conditions and static equilibrium problem). A novel and complex crane boom of a real forestry machine serves as a practical benchmark application example. The direct comparison of the different solution approaches in the examined simulation tools supports the user in selecting the most suitable tool for his application.

</details>


### [115] [OMP: One-step Meanflow Policy with Directional Alignment](https://arxiv.org/abs/2512.19347)
*Han Fang,Yize Huang,Yuheng Zhao,Paul Weng,Xiao Li,Yutong Ban*

Main category: cs.RO

TL;DR: 本文提出改进的MeanFlow策略，通过余弦损失对齐速度方向和DDE优化JVP算子，提升机器人操作策略的少样本泛化能力和轨迹精度，同时保持实时性能。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作的主流生成策略框架（如扩散模型）存在推理延迟高，流式方法架构复杂的问题。MeanFlow虽然实现单步推理且优于FlowPolicy，但缺乏少样本泛化能力，原因是其分散损失中的固定温度超参数和预测-真实平均速度不对齐。

Method: 提出改进的MeanFlow策略：1）引入轻量级余弦损失来对齐速度方向；2）使用微分推导方程（DDE）优化雅可比-向量积（JVP）算子。

Result: 在Adroit和Meta-World任务上的实验表明，该方法在平均成功率上优于MP1和FlowPolicy，特别是在具有挑战性的Meta-World任务中，有效增强了少样本泛化能力和轨迹精度，同时保持实时性能。

Conclusion: 该方法为高精度机器人操作提供了更鲁棒的解决方案，通过改进MeanFlow策略解决了少样本泛化问题，同时保持了实时推理能力。

Abstract: Robot manipulation, a key capability of embodied AI, has turned to data-driven generative policy frameworks, but mainstream approaches like Diffusion Models suffer from high inference latency and Flow-based Methods from increased architectural complexity. While simply applying meanFlow on robotic tasks achieves single-step inference and outperforms FlowPolicy, it lacks few-shot generalization due to fixed temperature hyperparameters in its Dispersive Loss and misaligned predicted-true mean velocities. To solve these issues, this study proposes an improved MeanFlow-based Policies: we introduce a lightweight Cosine Loss to align velocity directions and use the Differential Derivation Equation (DDE) to optimize the Jacobian-Vector Product (JVP) operator. Experiments on Adroit and Meta-World tasks show the proposed method outperforms MP1 and FlowPolicy in average success rate, especially in challenging Meta-World tasks, effectively enhancing few-shot generalization and trajectory accuracy of robot manipulation policies while maintaining real-time performance, offering a more robust solution for high-precision robotic manipulation.

</details>


### [116] [TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation](https://arxiv.org/abs/2512.19390)
*Hongwei Fan,Hang Dai,Jiyao Zhang,Jinzhou Li,Qiyang Yan,Yujie Zhao,Mingju Gao,Jinghang Wu,Hao Tang,Hao Dong*

Main category: cs.RO

TL;DR: TwinAligner是一个Real2Sim2Real系统，通过视觉对齐和动态对齐模块解决仿真与现实之间的差距，使仿真训练的机器人策略能够零样本泛化到真实世界。


<details>
  <summary>Details</summary>
Motivation: 机器人领域正朝着数据驱动的端到端学习发展，但依赖昂贵的真实世界数据限制了进展。仿真器提供了经济高效的替代方案，但仿真与现实之间的差距阻碍了有效的策略迁移。

Method: 提出TwinAligner系统，包含两个核心模块：1）视觉对齐模块通过SDF重建和可编辑3DGS渲染实现像素级对齐；2）动态对齐模块通过识别机器人-物体交互中的刚性物理特性确保动态一致性。

Result: 定量评估显示TwinAligner在视觉和动态真实到仿真对齐方面具有强大能力。仿真训练的机器人策略能够在真实世界中实现零样本泛化，真实世界与仿真策略性能高度一致。

Conclusion: TwinAligner通过提供可扩展的数据收集和建立可信的迭代循环，加速了机器人算法开发，有望推动可扩展的机器人学习发展。

Abstract: The robotics field is evolving towards data-driven, end-to-end learning, inspired by multimodal large models. However, reliance on expensive real-world data limits progress. Simulators offer cost-effective alternatives, but the gap between simulation and reality challenges effective policy transfer. This paper introduces TwinAligner, a novel Real2Sim2Real system that addresses both visual and dynamic gaps. The visual alignment module achieves pixel-level alignment through SDF reconstruction and editable 3DGS rendering, while the dynamic alignment module ensures dynamic consistency by identifying rigid physics from robot-object interaction. TwinAligner improves robot learning by providing scalable data collection and establishing a trustworthy iterative cycle, accelerating algorithm development. Quantitative evaluations highlight TwinAligner's strong capabilities in visual and dynamic real-to-sim alignment. This system enables policies trained in simulation to achieve strong zero-shot generalization to the real world. The high consistency between real-world and simulated policy performance underscores TwinAligner's potential to advance scalable robot learning. Code and data will be released on https://twin-aligner.github.io

</details>


### [117] [Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface](https://arxiv.org/abs/2512.19402)
*Yujie Zhao,Hongwei Fan,Di Chen,Shengcong Chen,Liliang Chen,Xiaoqi Li,Guanghui Ren,Hao Dong*

Main category: cs.RO

TL;DR: Real2Edit2Real：通过3D编辑和视频生成，从少量真实演示中合成大量空间增强的机器人操作数据，实现10-50倍的数据效率提升。


<details>
  <summary>Details</summary>
Motivation: 机器人学习需要大规模多样化演示数据，但收集成本高昂，特别是在空间泛化的操作任务中。需要减少重复数据收集，提高数据效率。

Method: 1) 从多视角RGB观测重建场景几何；2) 在点云上进行深度可靠的3D编辑，生成新操作轨迹并几何校正机器人姿态；3) 提出多条件视频生成模型，以深度为主要控制信号，结合动作、边缘和射线图，合成空间增强的多视角操作视频。

Result: 在四个真实世界操作任务中，仅用1-5个源演示生成的数据训练的策略，性能可匹配或超越用50个真实演示训练的策略，数据效率提升10-50倍。高度和纹理编辑实验展示了框架的灵活性和可扩展性。

Conclusion: Real2Edit2Real框架通过3D编辑和视频生成，显著提高了机器人学习的数据效率，有望成为统一的数据生成框架，支持空间泛化和任务扩展。

Abstract: Recent progress in robot learning has been driven by large-scale datasets and powerful visuomotor policy architectures, yet policy robustness remains limited by the substantial cost of collecting diverse demonstrations, particularly for spatial generalization in manipulation tasks. To reduce repetitive data collection, we present Real2Edit2Real, a framework that generates new demonstrations by bridging 3D editability with 2D visual data through a 3D control interface. Our approach first reconstructs scene geometry from multi-view RGB observations with a metric-scale 3D reconstruction model. Based on the reconstructed geometry, we perform depth-reliable 3D editing on point clouds to generate new manipulation trajectories while geometrically correcting the robot poses to recover physically consistent depth, which serves as a reliable condition for synthesizing new demonstrations. Finally, we propose a multi-conditional video generation model guided by depth as the primary control signal, together with action, edge, and ray maps, to synthesize spatially augmented multi-view manipulation videos. Experiments on four real-world manipulation tasks demonstrate that policies trained on data generated from only 1-5 source demonstrations can match or outperform those trained on 50 real-world demonstrations, improving data efficiency by up to 10-50x. Moreover, experimental results on height and texture editing demonstrate the framework's flexibility and extensibility, indicating its potential to serve as a unified data generation framework.

</details>


### [118] [MaP-AVR: A Meta-Action Planner for Agents Leveraging Vision Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2512.19453)
*Zhenglong Guo,Yiming Zhao,Feng Jiang,Heng Jin,Zongbao Feng,Jianbin Zhou,Siyuan Xu*

Main category: cs.RO

TL;DR: 提出MaP-AVR规划器，用元动作抽象替代人类中心概念，结合RAG技术提升机器人任务规划能力


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注通过微调或思维链提示增强LLM/VLM的任务理解能力，但忽略了规划技能集定义的重要性。为处理日常环境的复杂性，技能集需要具备高度泛化能力。

Method: 提出元动作抽象方法，每个元动作包含{移动/旋转、末端执行器状态变化、与环境关系}三个组件，替代人类中心概念。结合RAG技术，利用人类标注的规划演示数据库支持上下文学习，系统完成任务后数据库自增强。

Result: 在GPT-4o作为预训练LLM/VLM模型、OmniGibson作为机器人平台的实验中，相比当前最先进方法展现出有前景的性能。

Conclusion: 元动作集及其与RAG的集成是MaP-AVR规划器的两大创新贡献，使规划结果与机器人固有功能无缝对齐，有效提升机器人任务规划能力。

Abstract: Embodied robotic AI systems designed to manage complex daily tasks rely on a task planner to understand and decompose high-level tasks. While most research focuses on enhancing the task-understanding abilities of LLMs/VLMs through fine-tuning or chain-of-thought prompting, this paper argues that defining the planned skill set is equally crucial. To handle the complexity of daily environments, the skill set should possess a high degree of generalization ability. Empirically, more abstract expressions tend to be more generalizable. Therefore, we propose to abstract the planned result as a set of meta-actions. Each meta-action comprises three components: {move/rotate, end-effector status change, relationship with the environment}. This abstraction replaces human-centric concepts, such as grasping or pushing, with the robot's intrinsic functionalities. As a result, the planned outcomes align seamlessly with the complete range of actions that the robot is capable of performing. Furthermore, to ensure that the LLM/VLM accurately produces the desired meta-action format, we employ the Retrieval-Augmented Generation (RAG) technique, which leverages a database of human-annotated planning demonstrations to facilitate in-context learning. As the system successfully completes more tasks, the database will self-augment to continue supporting diversity. The meta-action set and its integration with RAG are two novel contributions of our planner, denoted as MaP-AVR, the meta-action planner for agents composed of VLM and RAG. To validate its efficacy, we design experiments using GPT-4o as the pre-trained LLM/VLM model and OmniGibson as our robotic platform. Our approach demonstrates promising performance compared to the current state-of-the-art method. Project page: https://map-avr.github.io/.

</details>


### [119] [REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation](https://arxiv.org/abs/2512.19562)
*Martin Sedlacek,Pavlo Yefanov,Georgy Ponimatkin,Jai Bardhan,Simon Pilc,Mederic Fourmy,Evangelos Kazakos,Cees G. M. Snoek,Josef Sivic,Vladimir Petrik*

Main category: cs.RO

TL;DR: REALM是一个新的仿真环境和基准测试，用于评估视觉-语言-动作（VLA）模型的泛化能力，通过高保真视觉和对齐的机器人控制来建立仿真与现实世界性能之间的强相关性。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在训练环境之外泛化能力难以评估，现实世界评估既困难又昂贵，需要一种有效的仿真环境来系统评估模型的泛化和鲁棒性。

Method: 开发了REALM仿真环境，包含15种扰动因素、7种操作技能和超过3,500个物体，建立了两个任务集作为基准测试，评估了π₀、π₀-FAST和GR00T N1.5等VLA模型。

Result: 评估显示VLA模型的泛化和鲁棒性仍然是一个开放挑战，同时证明了仿真环境可以作为现实世界的有效代理，能够系统地探测和量化VLA模型的弱点和失败模式。

Conclusion: REALM提供了一个有价值的仿真基准测试环境，能够有效评估VLA模型的泛化能力，为系统分析模型弱点提供了工具，并证实了仿真与现实世界性能之间的相关性。

Abstract: Vision-Language-Action (VLA) models empower robots to understand and execute tasks described by natural language instructions. However, a key challenge lies in their ability to generalize beyond the specific environments and conditions they were trained on, which is presently difficult and expensive to evaluate in the real-world. To address this gap, we present REALM, a new simulation environment and benchmark designed to evaluate the generalization capabilities of VLA models, with a specific emphasis on establishing a strong correlation between simulated and real-world performance through high-fidelity visuals and aligned robot control. Our environment offers a suite of 15 perturbation factors, 7 manipulation skills, and more than 3,500 objects. Finally, we establish two task sets that form our benchmark and evaluate the π_{0}, π_{0}-FAST, and GR00T N1.5 VLA models, showing that generalization and robustness remain an open challenge. More broadly, we also show that simulation gives us a valuable proxy for the real-world and allows us to systematically probe for and quantify the weaknesses and failure modes of VLAs. Project page: https://martin-sedlacek.com/realm

</details>


### [120] [Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles](https://arxiv.org/abs/2512.19564)
*Yanliang Huang,Xia Yan,Peiran Yin,Zhenduo Zhang,Zeyan Shao,Youran Wang,Haoliang Huang,Matthias Althoff*

Main category: cs.RO

TL;DR: 第四届CommonRoad运动规划竞赛（2024）为自动驾驶车辆运动规划算法提供了标准化基准测试框架，评估了多种算法在高速公路和城市环境中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 过去十年自动驾驶车辆运动规划方法发展迅速，但缺乏标准化基准测试，难以评估不同方法的相对优势和劣势，限制了算法比较和性能评估。

Method: 使用CommonRoad基准套件建立开源可复现的竞赛框架，涵盖高速公路和城市环境中的多样化交通参与者（轿车、公交车、自行车），从效率、安全性、舒适度和交通规则遵守四个维度评估规划器性能。

Result: 报告介绍了竞赛形式，并对2023年和2024年版本中表现优异的代表性规划器进行了比较分析，展示了不同算法在标准化测试中的性能差异。

Conclusion: CommonRoad运动规划竞赛为自动驾驶运动规划算法提供了重要的标准化评估平台，促进了算法比较和性能提升，有助于推动该领域的研究发展。

Abstract: Over the past decade, a wide range of motion planning approaches for autonomous vehicles has been developed to handle increasingly complex traffic scenarios. However, these approaches are rarely compared on standardized benchmarks, limiting the assessment of relative strengths and weaknesses. To address this gap, we present the setup and results of the 4th CommonRoad Motion Planning Competition held in 2024, conducted using the CommonRoad benchmark suite. This annual competition provides an open-source and reproducible framework for benchmarking motion planning algorithms. The benchmark scenarios span highway and urban environments with diverse traffic participants, including passenger cars, buses, and bicycles. Planner performance is evaluated along four dimensions: efficiency, safety, comfort, and compliance with selected traffic rules. This report introduces the competition format and provides a comparison of representative high-performing planners from the 2023 and 2024 editions.

</details>


### [121] [LIMOncello: Revisited IKFoM on the SGal(3) Manifold for Fast LiDAR-Inertial Odometry](https://arxiv.org/abs/2512.19567)
*Carlos Pérez-Ruiz,Joan Solà*

Main category: cs.RO

TL;DR: LIMOncello是一个紧耦合的LiDAR-IMU里程计系统，在SGal(3)流形上建模6自由度运动，使用增量i-Octree地图后端，在几何稀疏环境中具有更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR-IMU里程计系统在低可观测条件下容易漂移，传统地图结构（如增量kd-tree）更新慢且内存占用高，需要更稳定高效的运动表示和地图管理方法。

Method: 1. 在SGal(3)流形上建模6-DoF运动，相比SO(3)×R^6提供更一致和数值稳定的离散时间传播模型；2. 使用迭代误差状态卡尔曼滤波器后端；3. 采用轻量级增量i-Octree地图后端，实现更快更新和更低内存占用。

Result: 在多个真实世界数据集上的实验表明，LIMOncello实现了竞争性的精度，在几何稀疏环境中提高了鲁棒性，保持实时性能且内存增长稳定。

Conclusion: LIMOncello通过SGal(3)流形表示和i-Octree地图结构，为LiDAR-IMU里程计提供了更稳定、高效和鲁棒的解决方案，已作为可扩展的开源实现发布。

Abstract: This work introduces LIMOncello, a tightly coupled LiDAR-Inertial Odometry system that models 6-DoF motion on the $\mathrm{SGal}(3)$ manifold within an iterated error-state Kalman filter backend. Compared to state representations defined on $\mathrm{SO}(3)\times\mathbb{R}^6$, the use of $\mathrm{SGal}(3)$ provides a coherent and numerically stable discrete-time propagation model that helps limit drift in low-observability conditions.
  LIMOncello also includes a lightweight incremental i-Octree mapping backend that enables faster updates and substantially lower memory usage than incremental kd-tree style map structures, without relying on locality-restricted search heuristics. Experiments on multiple real-world datasets show that LIMOncello achieves competitive accuracy while improving robustness in geometrically sparse environments. The system maintains real-time performance with stable memory growth and is released as an extensible open-source implementation at https://github.com/CPerezRuiz335/LIMOncello.

</details>


### [122] [LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller](https://arxiv.org/abs/2512.19576)
*Kirill Djebko,Tom Baumann,Erik Dilger,Frank Puppe,Sergio Montenegro*

Main category: cs.RO

TL;DR: 首次在轨演示基于AI的卫星姿态控制器，通过深度强化学习训练并在InnoCube纳米卫星上成功部署，性能优于传统PD控制器


<details>
  <summary>Details</summary>
Motivation: 传统姿态控制器设计耗时且对模型不确定性和操作条件变化敏感，需要更自适应、鲁棒的控制方案。深度强化学习提供了一种有前景的替代方案，但Sim2Real差距（从仿真到真实卫星部署）仍是重大挑战

Method: 使用深度强化学习在仿真环境中训练AI姿态控制器，然后将训练好的智能体部署到InnoCube 3U纳米卫星上。设计了AI智能体架构和训练流程，并处理了仿真与真实卫星行为之间的差异

Result: 成功完成了首次基于AI的姿态控制器在轨演示，在惯性指向机动中表现出鲁棒性能。稳态指标证实了AI控制器在重复在轨机动中的优越表现，性能优于InnoCube的传统PD控制器

Conclusion: 这项工作证明了深度强化学习训练的AI姿态控制器能够成功从仿真转移到真实在轨卫星，克服了Sim2Real差距，为卫星姿态控制提供了更自适应、鲁棒的解决方案

Abstract: Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.

</details>


### [123] [Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations](https://arxiv.org/abs/2512.19583)
*Yinhuai Wang,Runyi Yu,Hok Wai Tsui,Xiaoyi Lin,Hui Zhang,Qihan Zhao,Ke Fan,Miao Li,Jie Song,Jingbo Wang,Qifeng Chen,Ping Tan*

Main category: cs.RO

TL;DR: 提出一种仅从合成数据学习通用手-物体跟踪控制器的系统，无需人类演示，包含HOP轨迹规划器和HOT跟踪控制器，实现合成到物理的迁移


<details>
  <summary>Details</summary>
Motivation: 解决灵巧操作中长期存在的数据瓶颈问题，传统方法依赖大量人类演示数据，限制了可扩展性。目标是开发完全从合成数据学习的基础控制器

Method: 包含两个核心组件：1) HOP（手-物体规划器）- 合成多样的手-物体轨迹；2) HOT（手-物体跟踪器）- 通过强化学习和交互模仿学习实现合成到物理的迁移，生成以目标手-物体状态为条件的通用控制器

Result: 方法能够处理多样物体形状和手部形态，使灵巧手能够跟踪具有挑战性的长时程序列，包括物体重新排列和敏捷的手内重定向

Conclusion: 该方法代表了向可扩展的操纵基础控制器迈出的重要一步，能够完全从合成数据学习，打破了长期制约灵巧操作进展的数据瓶颈

Abstract: We present a system for learning generalizable hand-object tracking controllers purely from synthetic data, without requiring any human demonstrations. Our approach makes two key contributions: (1) HOP, a Hand-Object Planner, which can synthesize diverse hand-object trajectories; and (2) HOT, a Hand-Object Tracker that bridges synthetic-to-physical transfer through reinforcement learning and interaction imitation learning, delivering a generalizable controller conditioned on target hand-object states. Our method extends to diverse object shapes and hand morphologies. Through extensive evaluations, we show that our approach enables dexterous hands to track challenging, long-horizon sequences including object re-arrangement and agile in-hand reorientation. These results represent a significant step toward scalable foundation controllers for manipulation that can learn entirely from synthetic data, breaking the data bottleneck that has long constrained progress in dexterous manipulation.

</details>


### [124] [LoGoPlanner: Localization Grounded Navigation Policy with Metric-aware Visual Geometry](https://arxiv.org/abs/2512.19629)
*Jiaqi Peng,Wenzhe Cai,Yuqiang Yang,Tai Wang,Yuan Shen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: LoGoPlanner是一个端到端导航框架，通过视觉几何骨干网络进行隐式状态估计和场景几何重建，无需单独定位模块，在非结构化环境中实现更鲁棒的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 传统模块化轨迹规划存在延迟和级联错误问题，现有端到端方法仍依赖需要精确传感器标定的单独定位模块，限制了在不同机器人和环境间的泛化能力。

Method: 1) 微调长时程视觉几何骨干网络以获得绝对度量尺度的预测，提供隐式状态估计；2) 从历史观测重建场景几何，提供密集环境感知；3) 基于辅助任务引导的隐式几何条件化策略，减少误差传播。

Result: 在仿真和真实世界评估中，LoGoPlanner的端到端设计减少了累积误差，度量感知的几何记忆增强了规划一致性和避障能力，相比基于精确定位的基线提升超过27.3%，在不同机器人和环境中表现出强泛化能力。

Conclusion: LoGoPlanner通过隐式状态估计和场景几何重建，实现了无需单独定位模块的端到端导航，在非结构化环境中表现出优越的性能和泛化能力。

Abstract: Trajectory planning in unstructured environments is a fundamental and challenging capability for mobile robots. Traditional modular pipelines suffer from latency and cascading errors across perception, localization, mapping, and planning modules. Recent end-to-end learning methods map raw visual observations directly to control signals or trajectories, promising greater performance and efficiency in open-world settings. However, most prior end-to-end approaches still rely on separate localization modules that depend on accurate sensor extrinsic calibration for self-state estimation, thereby limiting generalization across embodiments and environments. We introduce LoGoPlanner, a localization-grounded, end-to-end navigation framework that addresses these limitations by: (1) finetuning a long-horizon visual-geometry backbone to ground predictions with absolute metric scale, thereby providing implicit state estimation for accurate localization; (2) reconstructing surrounding scene geometry from historical observations to supply dense, fine-grained environmental awareness for reliable obstacle avoidance; and (3) conditioning the policy on implicit geometry bootstrapped by the aforementioned auxiliary tasks, thereby reducing error propagation.We evaluate LoGoPlanner in both simulation and real-world settings, where its fully end-to-end design reduces cumulative error while metric-aware geometry memory enhances planning consistency and obstacle avoidance, leading to more than a 27.3\% improvement over oracle-localization baselines and strong generalization across embodiments and environments. The code and models have been made publicly available on the \href{https://steinate.github.io/logoplanner.github.io/}{project page}.

</details>
